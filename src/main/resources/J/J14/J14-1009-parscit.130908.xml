<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9988085">
On the Problem of Theoretical Terms
in Empirical Computational Linguistics
</title>
<author confidence="0.997833">
Stefan Riezler*
</author>
<affiliation confidence="0.8924335">
Computational Linguistics
Heidelberg University, Germany
</affiliation>
<bodyText confidence="0.935948777777778">
Philosophy of science has pointed out a problem of theoretical terms in empirical sciences. This
problem arises if all known measuring procedures for a quantity of a theory presuppose the
validity of this very theory, because then statements containing theoretical terms are circular.
We argue that a similar circularity can happen in empirical computational linguistics, especially
in cases where data are manually annotated by experts. We define a criterion of T-non-theoretical
grounding as guidance to avoid such circularities, and exemplify how this criterion can be met
by crowdsourcing, by task-related data annotation, or by data in the wild. We argue that this
criterion should be considered as a necessary condition for an empirical science, in addition to
measures for reliability of data annotation.
</bodyText>
<sectionHeader confidence="0.994986" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999962315789474">
The recent history of computational linguistics (CL) shows a trend towards encoding
natural language processing (NLP) problems as machine learning tasks, with the goal
of applying task-specific learning machines to solve the encoded NLP problems. In the
following we will refer to such approaches as empirical CL approaches.
Machine learning tools and statistical learning theory play an important enabling
and guiding role for research in empirical CL. A recent discussion in the machine learn-
ing community claims an even stronger and more general role of machine learning. We
allude here to a discussion concerning the relation of machine learning and philosophy
of science. For example, Corfield, Sch¨olkopf, and Vapnik (2009) compare Popper’s ideas
of falsifiability of a scientific theory with “similar notions” from statistical learning the-
ory regarding Vapnik-Chervonenkis theory. A recent NIPS workshop on “Philosophy
and Machine Learning”1 presented a collection of papers investigating similar problems
and concepts in the two fields. Korb (2004) sums up the essence of the discussion by
directly advertising “Machine Learning as Philosophy of Science.”
In this article we argue that adopting machine learning theory as philosophy of
science for empirical CL has to be done with great care. A problem arises in the applica-
tion of machine learning methods to natural language data under the assumption that
input–output pairs are given and do not have to be questioned. In contrast to machine
learning, in empirical CL neither a representation of instances nor an association of
</bodyText>
<footnote confidence="0.898312">
* Department of Computational Linguistics, Heidelberg University, Im Neuenheimer Feld 325, 69120
Heidelberg, Germany. E-mail: riezler@cl.uni-heidelberg.de.
1 http://www.dsi.unive.it/PhiMaLe2011/.
doi:10.1162/COLI a 00182
</footnote>
<note confidence="0.84494">
© 2014 Association for Computational Linguistics
Computational Linguistics Volume 40, Number 1
</note>
<bodyText confidence="0.999553916666667">
instances and labels is always “given.” We show that especially in cases where data
are manually annotated by expert coders, a problem of circularity arises if one and the
same theory of measurement is used in data annotation and in feature construction. In
this article, we use insights from philosophy of science to understand this problem. We
particularly point to the “problem of theoretical terms,” introduced by Sneed (1971),
that shows how circularities can make empirical statements in sciences such as physics
impossible.
In the following, we will explain the problem of theoretical terms with the help
of a miniature physical theory used in philosophy of science (Section 2). We will then
exemplify this concept on examples from empirical CL (Section 3). We also make an
attempt at proposing solutions to this problem by using crowdsourcing techniques,
task-related annotation, or data in the wild (Section 4).
</bodyText>
<sectionHeader confidence="0.976915" genericHeader="method">
2. The Problem of Theoretical Terms in Philosophy of Science
</sectionHeader>
<bodyText confidence="0.995103052631579">
In order to characterize the logical structure of empirical science, philosophy of science
has extensively discussed the notions of “theoretical” and “observational” language.
Sneed (1971)2 was the first to suggest a distinction between “theoretical” and “non-
theoretical” terms of a given theory by means of the roles they play in that theory.
Balzer (1996, page 140) gives a general definition that states that a term is “theoretical
in theory T iff every determination of (a realization of) that term presupposes that T
has been successfully applied beforehand.” Because there are no theory-independent
terms in this view, an explicit reference to a theory T is always carried along when
characterizing terms as theoretical with respect to T (T-theoretical) or non-theoretical
with respect to T (T-non-theoretical). Stegm¨uller (1979) makes the notions of “determina-
tion” or “realization” more concrete by referring to procedures for measuring values of
quantities or functions in empirical science:
What does it mean to say that a quantity (function) f of a physical theory T is
T-theoretical?... In order to perform an empirical test of an empirical claim containing
the T-theoretical quantity f, we have to measure values of the function f . But all known
measuring procedures (or, if you like, all known theories of measurement off-values)
presuppose the validity of this very theory T. (page 17)
The “problem of theoretical terms” can then be stated as follows (see Stegm¨uller
1979): Suppose a statement of the form
</bodyText>
<equation confidence="0.942887">
xisaP (1)
</equation>
<bodyText confidence="0.8901546">
where x is an entity and P is a set-theoretic predicate by which a physical theory
is axiomatized. If this theory contains P-theoretic terms, then (1) is not an empirical
statement because another sentence of exactly the same form and with exactly the same
predicate is presupposed. An illustration of this concept can be given by Stegm¨uller
(1986)’s miniature theory of an Archimedian Statics. Let us assume that this miniature
theory is formalized by the set-theoretic predicate AS. The intended applications of the
theory AS are objects a1,. .. , an that are in balance around a pivot point. The theory uses
2 The following discussion of concepts of the “structuralist” or “non-statement view of theories” is based
on works by Stegm¨uller (1979, 1986) and Balzer and Moulines (1996) that are more accessible than the
original book by Sneed (1971). All translations from German are by the author.
</bodyText>
<page confidence="0.98731">
236
</page>
<note confidence="0.488434">
Riezler On the Problem of Theoretical Terms in Empirical CL
</note>
<bodyText confidence="0.8592794">
two functions that measure the distance d of the objects from the pivot point, and the
weight g. The central axiom of the theory states that the sum of the products d(ai)g(ai)
is the same for the objects on either side of the pivot point. The theory AS can then be
defined as follows:
x is an AS iff there is an A, d, g such that:
</bodyText>
<listItem confidence="0.982008333333333">
1. x = (A, d, g),
2. A = {a1,...,anb
3. d : A IR,
4. g : A IR,
5. daEA:g(a)&gt;0,
6. En i=1 d(ai)g(ai) = 0.
</listItem>
<bodyText confidence="0.94683372">
Entities that satisfy conditions (1) to (5) are called potential models of the theory. Enti-
ties that also satisfy the central axiom (6) are called models of the theory. An empirical
statement is a statement that a certain entity is a model of the theory.
Stegm¨uller (1986) uses the miniature theory AS to explain the problem of theoretical
terms as follows: Suppose we observe children sitting on a seesaw board. Suppose
further that the board is in balance. Translating this observation into the set-theoretic
language, we could denote by y the balanced seesaw including the children, and we
would be tempted to make the empirical statement that
y is an AS (2)
In order to verify the central axiom, we need to measure distance and weight of the
children. Suppose that we have a measuring tape available to measure distance, and
suppose further that our only method to measure weight is the use of beam balance
scales. Let us denote by z the entity consisting of the balanced beam scale, the child,
and the counterbalancing measuring weight; then the validity of our measuring result
depends on a statement
z is an AS (3)
Thus, in order to check statement (2), we have to presuppose statement (3), which
is of the very same form and uses the very same predicate. That means, in order to
measure the weight of the children, we have to presuppose successful applications of
the theory AS. But in order to decide for successful applications of AS, we need to be
able to measure the weight of the objects in such application. This epistemological circle
prevents us from claiming that our original statement (2) is an empirical statement.
The crux of the problem of theoretical terms for the miniature theory AS is the
measuring procedure for the function g that presupposes the validity of the theory AS.
The term g is thus AS-theoretical. There are two solutions to this problem:
</bodyText>
<footnote confidence="0.70802775">
1. In order to avoid the use of AS-theoretic terms such as g, we could discard
the assumption that our weight-measuring procedure uses beam balance
scales. Instead we could use AS-non-theoretic measuring procedures such
as spring scales. The miniature theory AS would no longer contain
</footnote>
<page confidence="0.980035">
237
</page>
<note confidence="0.332603">
Computational Linguistics Volume 40, Number 1
</note>
<bodyText confidence="0.978549705882353">
AS-theoretic terms. Thus we would be able to make empirical statements
of the form (2), that is, statements about certain entities being models of
the theory AS.
2. In complex physical theories such as particle mechanics there are no
simplified assumptions on measuring procedures that can be dropped
easily. Sneed (1971) proposed the so-called Ramsey solution3 that in
essence avoids AS-theoretical terms by existentially quantifying over them.
Solution (1), where T-theoretical terms are measured by applications of a theory
T&apos;, thus is the standard case in empirical sciences. Solution (2) is a special case where
we need theory T in order to measure some terms in theory T. Gadenne (1985) argues
that this case can be understood as a tentative assumption of theory T that still makes
empirical testing possible.4
The important point for our discussion is that in both solutions to the problem
of theoretical terms, whether we refer to another theory T&apos; (solution (1)) or whether
we tentatively assume theory T (solution (2)), we require an explicit dichotomy between
T-theoretical and T-non-theoretical terms. This insight is crucial in the following analysis
of possible circularities in the methodology of empirical CL.
</bodyText>
<sectionHeader confidence="0.947357" genericHeader="method">
3. The Problem of Theoretical Terms in Empirical CL
</sectionHeader>
<bodyText confidence="0.999495">
Most machine-learning approaches can be characterized as identifying a learning
problem as a problem of estimating a prediction function f (x) for given identically
and independently distributed (i.i.d.) data {(xi,yi)}Ni=1 of instances and labels. For
most approaches in empirical CL, this prediction function can be characterized by a
discriminant form of a function f where
</bodyText>
<equation confidence="0.9355245">
f (x; w, φ) = arg max F(x, y; w, φ)
y
</equation>
<bodyText confidence="0.821248388888889">
and where w E IRD denotes a D-dimensional parameter vector, φ(x, y) E IRD is a
D-dimensional vector of features (also called attributes or covariates) jointly represent-
ing input patterns x and outputs y (denoting categorical, scalar, or structured variables),
3 For the miniature theory AS, this is done by firstly stripping out statements (4)–(6) containing theoretical
terms, achieving a partial potential model. Secondly statements (4) and (5) are replaced by a so-called
theoretical extension that existentially quantifies over measuring procedures for terms like g. The
resulting Ramsey claim applies a theoretical extension to a partial potential model that also satisfies
condition (6). Because such a statement does not contain theoretical terms we can make empirical
statements about entities being models of the theory AS.
4 Critics of the structuralist theory of science have remarked that both of the solutions are instances of a
more general problem, the so-called Duhem-Quine problem, thus the focus of the structuralist program
on solution (2) seems to be an exaggeration of the actual problem (von Kutschera 1982; Gadenne 1985).
The Duhem-Quine thesis states that theoretical assumptions cannot be tested in isolation, but rather
whole systems of theoretical assumptions and auxiliary assumptions are subjected to empirical testing.
That is, if our predictions are not in accordance with our theory, we can only conclude that one of our
many theoretical assumptions must be wrong, but we cannot know which one, and we can always
modify our system of assumptions, leading to various ways of immunity of theories (Stegm¨uller 1986).
This problem arises in Solution (1) as well as in Solution (2)
</bodyText>
<page confidence="0.956135">
238
</page>
<note confidence="0.449428">
Riezler On the Problem of Theoretical Terms in Empirical CL
</note>
<bodyText confidence="0.991514448979592">
and F measures the compatibility of pairs (x, y), for example, in the form of a linear
discriminant function (Taskar et al. 2004; Tsochantaridis et al. 2005).5
The problem of theoretical terms arises in empirical CL in cases where a single
theoretical tier is used both in manual data annotation (i.e., in the assignment of labels
y to patterns x via the encoding of data pairs (x, y)), and in feature construction (i.e., in
the association of labels y to patterns x via features φ(x, y)).
This problem can be illustrated by looking at automatic methods for data an-
notation. For example, information retrieval (IR) in the patent domain uses citations
of patents in other patents to automatically create relevance judgments for ranking
(Graf and Azzopardi 2008). Learning-to-rank models such as that of Guo and Gomes
(2009) define domain knowledge features on patent pairs (e.g., same patent class in the
International Patent Classification [IPC], same inventor, same assignee company) and IR
score features (e.g., tf-idf, cosine similarity) to represent data in a structured prediction
framework. Clearly, one could have just as well used IPC classes to create automatic
relevance judgments, and patent citations as features in the structured prediction model.
It should also be evident that using the same criterion to automatically create relevance
labels and as feature representation would be circular. In terms of the philosophical con-
cepts introduced earlier, the theory of measurement of relevance used in data labeling
cannot be the same as the theory expressed by the features of the structured prediction
model; otherwise we exhibit the problem of theoretical terms.
This problem can also arise in scenarios of manual data annotation. One example is
data annotation by expert coders: The expert coder’s decisions of which labels to assign
to which types of patterns may be guided by implicit or tacit knowledge that is shared
among the community of experts. These experts may apply the very same knowledge to
design features for their machine learning models. For example, in attempts to construct
semantic annotations for machine learning purposes, the same criteria such as negation
tests might be used to distinguish presupposition from entailment in the labeling of
data, and in the construction of feature functions for a classifier to be trained and tested
on these data. Similar to the example of automatic data annotation in patent retrieval,
we exhibit the problem of theoretical terms in manual data annotation by experts in
that the theory of measurement used in data annotation and feature construction is
the same. This problem is exacerbated in the situation where a single expert annotator
codes the data and later assumes the role of a feature designer using the “given” data.
For example, in constructing a treebank for the purpose of learning a statistical disam-
biguation model for parsing with a hand-written grammar, the same person might act in
different roles as grammar writer, as manual annotator using the grammar’s analyses as
candidate annotations, and as feature designer for the statistical disambiguation model.
The sketched scenarios are inherently circular in the sense of the problem of the-
oretical terms described previously. Thus in all cases, we are prevented from making
empirical statements. High prediction accuracy of machine learning in such scenarios
indicates high consistency in the application of implicit knowledge in different roles of
a single expert or of groups of experts, but not more.
This problem of circularity in expert coding is related to the problem of reliability in
data annotation, a solution to which is sought by methods for measuring and enhancing
inter-annotator agreement. A seminal paper by Carletta (1996) and a follow-up survey
5 In this article, we concentrate on supervised machine learning. Semisupervised, transductive, active,
or unsupervised learning deal with machine learning from incomplete or missing labelings where the
general assumption of i.i.d. data is not questioned. See Dundar et al. (2007) for an approach of machine
learning from non-i.i.d. data.
</bodyText>
<page confidence="0.972558">
239
</page>
<note confidence="0.322232">
Computational Linguistics Volume 40, Number 1
</note>
<bodyText confidence="0.999659375">
paper by Artstein and Poesio (2008) have discussed this issue at length. Both papers
refer to Krippendorff (2004, 1980a, page 428) who recommends that reliability data
“have to be generated by coders that are widely available, follow explicit and commu-
nicable instructions (a data language), and work independently of each other.... [T]he
more coders participate in the process and the more common they are, the more likely
they can ensure the reliability of data.” Ironically, it seems as if the best inter-annotator
agreement is achieved by techniques that are in conflict with these recommendations,
namely, by using experts (Kilgarriff 1999) or intensively trained coders (Hovy et al. 2006)
for data annotation. Artstein and Poesio (2008) state explicitly that
experts as coders, particularly long-term collaborators, [... ] may agree not because they
are carefully following written instructions, but because they know the purpose of the
research very well–which makes it virtually impossible for others to reproduce the
results on the basis of the same coding scheme .... Practices which violate the third
requirement (independence) include asking the coders to discuss their judgments with
each other and reach their decisions by majority vote, or to consult with each other
when problems not foreseen in the coding instructions arise. Any of these practices
make the resulting data unusable for measuring reproducibility. (page 575)
Reidsma and Carletta (2007) and Beigman Klebanov and Beigman (2009) reach the
conclusion that high inter-annotator agreement is neither sufficient nor necessary to
achieve high reliability in data annotation. The problem lies in the implicit or tacit
knowledge that is shared among the community of experts. This implicit knowledge
is responsible for the high inter-annotator agreement, but hinders reproducibility. In
a similar way, implicit knowledge of expert coders can lead to a circularity in data
annotation and feature modeling.
</bodyText>
<sectionHeader confidence="0.800318" genericHeader="method">
4. Breaking the Circularity
</sectionHeader>
<bodyText confidence="0.999868176470588">
Finke (1979), in attempting to establish criteria for an empirical theory of linguistics,
demands that the use of a single theoretical strategy to identify and describe the entities
of interest shall be excluded from empirical analyses. He recommends that the possibility
of using T-non-theoretic strategies to identify observations be made the defining crite-
rion for empirical sciences. That is, in order to make an empirical statement, the two tiers
of a T-theoretical and a T-non-theoretical level are necessary because the use of a single
theoretical tier prevents distinguishing empirical statements from those that are not.
Let us call Finke’s requirement the criterion of T-non-theoretical grounding.6
Moulines (see Balzer 1996, page 141) gives a pragmatic condition for T-non-theoreticity
that can be used as a guideline: “Term t¯ is T-non-theoretical if there exists and acknowl-
edged method of determination of t¯ in some theory T&apos; different from T plus some link
from T&apos; to T which permits the transfer of realizations of t¯ from T&apos; into T.”
Balzer (1996) discusses a variety of more formal characterizations of the notion of
T-(non-)theoretical terms. Although the pragmatic definition cited here is rather infor-
mal, it is sufficient as a guideline in discussing concrete examples and strategies to break
the circlularity in the methodology of empirical CL. In the following, we will exemplify
how this criterion can be met by manual data annotation by using naive coders, or by
</bodyText>
<footnote confidence="0.951708">
6 Note that our criterion of T-non-theoretical grounding is related to the more specific concept of
operationalization in social sciences (Friedrichs 1973). Operationalization refers to the process of
developing indicators of the form “X is an a if Y is a b (at time t)” to connect T-theoretical and
T-non-theoretical levels. We will stick with the more general criterion in the rest of this article.
</footnote>
<page confidence="0.972798">
240
</page>
<note confidence="0.71062">
Riezler On the Problem of Theoretical Terms in Empirical CL
</note>
<bodyText confidence="0.9772115">
embedding data annotation into a task extrinsic to the theory to be tested, or by using
independently created language data that are available in the wild.
</bodyText>
<subsectionHeader confidence="0.987686">
4.1 T-non-theoretical Grounding by Naive Coders and Crowdsourcing
</subsectionHeader>
<bodyText confidence="0.999990034482759">
Now that we have defined the criterion of T-non-theoretical grounding, we see that
Krippendorff’s (2004) request for “coders that are widely available, follow explicit
and communicable instructions (a data language), and work independently of each
other” can be regarded as a concrete strategy to satisfy our criterion. The key is the
requirement for coders to be “widely available” and to work on the basis of “explicit
and communicable instructions.” The need to communicate the annotation task to non-
experts serves two purposes: On the one hand, the goal of reproducibility is supported
by having to communicate the annotation task explicitly in written form. Furthermore,
the “naive” nature of annotators requires a verbalization in words comprehensible to
non-experts, without the option of relying on implicit or tacit knowledge that is shared
among expert annotators. The researcher will thus be forced to describe the annotation
task without using technical terms that are common to experts, but are not known to
naive coders.
Annotation by naive coders can be achieved by using crowdsourcing services such
as Amazon’s Mechanical Turk,7 or alternatively, by creating games with a purpose (von
Ahn and Dabbish 2004; Poesio et al. 2013).8 Non-expert annotations created by crowd-
sourcing have been shown to provide expert-level quality if certain recommendations
on experiment design and quality control are met (Snow et al. 2008). Successful exam-
ples of the use of crowdsourcing techniques for data annotation and system evaluation
can be found throughout all areas of NLP (see Callison-Burch and Dredze [2010] for a
recent overview). The main advantage of these techniques lies in the ability to achieve
high-quality annotations at a fraction of the time and the expense of expert annotation.
However, a less apparent advantage is the need for researchers to provide succinct
and comprehensible descriptions of Human Intelligence Tasks, and the need to break
complex annotation tasks down to simpler basic units of work for annotators. Receiving
high-quality annotations with sufficient inter-worker agreement from crowdsourcing
can be seen as a possible litmus test for a successful T-non-theoretical grounding of
complex annotation tasks. Circularity issues will vanish because T-theoretical terms
cannot be communicated directly to naive coders.
</bodyText>
<subsectionHeader confidence="0.995263">
4.2 Grounding by Extrinsic Evaluation and Task-Related Annotation
</subsectionHeader>
<bodyText confidence="0.99991775">
Another way to achieve T-non-theoretical grounding is extrinsic evaluation of NLP
systems. This type of evaluation assesses “the effect of a system on something that
is external to it, for example, the effect on human performance at a given task or
the value added to an application” (Belz 2009) and has been demanded for at least
20 years (Sp¨arck Jones 1994). Extrinsic evaluation is advertised as a remedy against
“closed problem” approaches (Sp¨arck Jones 1994) or against “closed circles” in intrinsic
evaluation where system rankings produced by automatic measures are compared with
human rankings which are themselves unfalsifiable (Belz 2009).
</bodyText>
<footnote confidence="0.990199">
7 http://www.mturk.com.
8 See Fort, Adda, and Cohen (2011) for a discussion of the ethical dimensions of crowdsourcing services
and their alternatives.
</footnote>
<page confidence="0.979376">
241
</page>
<note confidence="0.539709">
Computational Linguistics Volume 40, Number 1
</note>
<bodyText confidence="0.999949380952381">
An example of an extrinsic evaluation in NLP is the evaluation of the effect of
syntactic parsers on retrieval quality in a biomedical IR task (Miyao et al. 2008). In-
terestingly, the extrinsic set-up revealed a different system ranking than the standard
intrinsic evaluation, according to F-scores on the Penn WSJ corpus. Another example
is the area of clustering. Deficiencies in current intrinsic clustering evaluation methods
have led von Luxburg, Williamson, and Guyon (2012) to pose the question “Clustering:
Science or Art?”. They recommend to measure the usefulness of a clustering method for
a particular task under consideration, that is, to always study clustering in the context
of its end use.
Extrinsic scenarios are not only useful for the purpose of evaluation. Rather, every
extrinsic evaluation creates data that can be used as training data for another learning
task (e.g., rankings of system outputs with respect to an extrinsic task can be used to
train discriminative (re)ranking models). For example, Kim and Mooney (2013) use
the successful completion of navigation tasks to create training data for reranking
in grounded language learning. Nikoulina et al. (2012) use retrieval performance of
translated queries to create data for reranking in statistical machine translation. Clarke
et al. (2010) use the correct response for a query to a database of geographical facts to
select data for structured learning of a semantic parser. Thus the extrinsic set-up can
be seen as a general technique for T-non-theoretical grounding in training as well as
in testing scenarios. Circularity issues will not arise in extrinsic set-ups because the
extrinsic task is by definition external to the system outputs to be tested or ranked.
</bodyText>
<subsectionHeader confidence="0.998443">
4.3 Grounded Data in the Wild
</subsectionHeader>
<bodyText confidence="0.999860692307692">
Halevy, Norvig, and Pereira (2009, page 8) mention statistical speech recognition
and statistical machine translation as “the biggest successes in natural-language-related
machine learning.” This success is due to the fact that “a large training set of the input–
output behavior that we seek to automate is available to us in the wild.” While they em-
phasize the large size of the training set, we think that the aspect that the training data
are given as a “natural task routinely done every day for a real human need” (Halevy,
Norvig, and Pereira 2009), is just as important as the size of the training set. This is
because a real-world task that is extrinsic and independent of any scientific theory
avoids any methodological circularity in data annotation and enforces an application-
based evaluation.
Speech and translation are not the only lucky areas where data are available in the
wild. Other data sets that have been “found” by NLP researchers are IMDb movie
reviews (exploited for sentiment analysis by Pang, Lee, and Vaithyanathan [2002]),
Amazon product reviews (used for multi-domain sentiment analysis by Blitzer, Dredze,
and Pereira [2007]), Yahoo! Answers (used for answer ranking by Surdeanu, Ciaramita,
and Zaragoza [2008]), reading comprehension tests (used for automated reading com-
prehension by Hirschman et al. [1999]), or Wikipedia (with too many uses to cite). Most
of these data were created by community-based efforts. This means that the data sets
are freely available and naturally increasing.
The extrinsic and independent aspect of data in the wild can also be created in
crowdsourcing approaches that enforce a distinction between data annotation tasks
and scientific modeling. For example, Denkowski, Al-Haj, and Lavie (2010) used
Amazon’s Mechanical Turk to create reference translations for statistical machine trans-
lation by monolingual phrase substitutions on existing references. “Translations” cre-
ated by workers that paraphrase given references without knowing the source can
never lead to the circularity that data annotation by experts is susceptible to. In a
</bodyText>
<page confidence="0.98677">
242
</page>
<note confidence="0.696079">
Riezler On the Problem of Theoretical Terms in Empirical CL
</note>
<bodyText confidence="0.9997476">
scenario of monolingual paraphrasing for reference translations even inter-annotator
agreement is not an issue anymore. Data created by single annotators (e.g., monolingual
meaning equivalents created for bilingual purposes [Dreyer and Marcu 2012]), can be
treated as “given” data for machine learning purposes, even if each network of meaning
equivalences is created by a single annotator.
</bodyText>
<sectionHeader confidence="0.992802" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999967391304348">
In this article, we have argued that the problem of theoretical terms as identified for
theoretical physics can occur in empirical CL in cases where data are not “given” as
commonly assumed in machine learning. We exemplified this problem on the example
of manual data annotation by experts, where the task of relating instances to labels in
manual data annotation and the task of relating instances to labels via modeling fea-
ture functions are intertwined. Inspired by the structuralist theory of science, we have
defined a criterion of T-non-theoretical grounding and exemplified how this criterion
can be met by manual data annotation by using naive coders, or by embedding data
annotation into a task extrinsic to the theory to be tested, or by using independently
created language data that are available in the wild.
Our suggestions for T-non-theoretical grounding are related to work on grounded
language learning that is based on weak supervision in the form of the use of sentences
in naturally occurring contexts. For example, the meaning of natural language express-
sions can be grounded in visual scenes (Roy 2002; Yu and Ballard 2004; Yu and Siskind
2013) or actions in games or navigation tasks (Chen and Mooney 2008, 2011). Because
of the ambiguous supervision, most such approaches work with latent representations
and use unsupervised techniques in learning. Our suggestions for T-non-theoretical
grounding can be used to avoid circularities in standard supervised learning. We think
that this criterion should be considered a necessary condition for an empirical science,
in addition to ensuring reliability of measurements. Our negligence of related issues
such as validity of measurements (see Krippendorff 1980b) shows that there is a vast
methodological area to be explored, perhaps with further opportunity for guidance by
philosophy of science.
</bodyText>
<sectionHeader confidence="0.995137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999416666666667">
We are grateful for feedback on earlier
versions of this work from Sebastian Pad´o,
Artem Sokolov, and Katharina W¨aschle.
Furthermore, we would like to thank Paola
Merlo for her suggestions and
encouragement.
</bodyText>
<sectionHeader confidence="0.9947" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.919025516129032">
Artstein, Ron and Massimo Poesio. 2008.
Inter-coder agreement for computational
linguistics. Computational Linguistics,
34(4):555–596.
Balzer, Wolfgang. 1996. Theoretical terms:
Recent developments. In Wolfgang
Balzer and C. Ulises Moulines, editors,
Structuralist Theory of Science. Focal
Issues, New Results. de Gruyter,
pages 139–166.
Balzer, Wolfgang and C. Ulises Moulines,
editors. 1996. Structuralist Theory of Science.
Focal Issues, New Results. de Gruyter.
Beigman Klebanov, Beata and Eyal Beigman.
2009. From annotator agreement to noise
models. Computational Linguistics,
35(4):495–503.
Belz, Anja. 2009. That’s nice ... what can you
do with it? Computational Linguistics,
35(1):111–118.
Blitzer, John, Mark Dredze, and Fernando
Pereira. 2007. Biographies, Bollywood,
boom-boxes and blenders: Domain
adaptation for sentiment classification. In
Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics
(ACL’07), pages 440–447, Prague.
Callison-Burch, Chris and Mark Dredze.
2010. Creating speech and language
data with Amazon’s Mechanical Turk.
In Proceedings of the NAACL-HLT 2010
</reference>
<page confidence="0.996626">
243
</page>
<figure confidence="0.428655333333333">
Computational Linguistics Volume 40, Number 1
Workshop on Creating Speech and Language
Data with Amazon’s Mechanical Turk,
</figure>
<reference confidence="0.974147301724138">
pages 1–12, Los Angeles, CA.
Carletta, Jean. 1996. Assessing agreement on
classification tasks: The kappa statistic.
Computational Linguistics, 22(2):1–6.
Chen, David L. and Raymond J. Mooney.
2008. Learning to sportscast: A test
of grounded language learning.
In Proceedings of the 25th International
Conference on Machine Learning (ICML’08),
pages 128–135, Helsinki.
Chen, David L. and Raymond J. Mooney.
2011. Learning to interpret natural
language navigation instructions from
observations. In Proceedings of the
25th AAAI Conference on Artificial
Intelligence (AAAI’11), pages 859–866,
San Francisco, CA.
Clarke, James, Dan Goldwasser, Wing-Wei
Chang, and Dan Roth. 2010. Driving
semantic parsing from the world’s
response. In Proceedings of the 14th
Conference on Natural Language Learning
(CoNLL’10), pages 18–27, Uppsala.
Corfield, David, Bernhard Sch¨olkopf, and
Vladimir Vapnik. 2009. Falsificationism
and statistical learning theory: Comparing
the Popper and Vapnik-Chervonenkis
dimensions. Journal for General Philosophy
of Science, 40:51–58.
Denkowski, Michael, Hassan Al-Haj,
and Alon Lavie. 2010. Turker-assisted
paraphrasing for English-Arabic
machine translation. In Proceedings of
the NAACL-HLT 2010 Workshop on
Creating Speech and Language Data with
Amazon’s Mechanical Turk, pages 66–70,
Los Angeles, CA.
Dreyer, Markus and Daniel Marcu. 2012.
HyTER: Meaning-equivalent semantics
for translation evaluation. In Proceedings of
2012 Conference of the North American
Chapter of the Association for Computational
Linguistics: Human Language Technologies
(NAACL-HLT 2012), pages 162–171,
Montreal.
Dundar, Murat, Balaji Krishnapuram, Jinbo
Bi, and R. Bharat Rao. 2007. Learning
classifiers when the training data is not
IID. In Proceedings of the 20th International
Joint Conference on Artifical Intelligence
(IJCAI’07), pages 756–761, Hyderabad.
Finke, Peter. 1979. Grundlagen einer
linguistischen Theorie. Empirie und
Begr¨undung in der Sprachwissenschaft.
Vieweg.
Fort, Kar¨en, Gilles Adda, and K. Bretonnel
Cohen. 2011. Amazon Mechanical Turk:
Gold mine or coal mine? Computational
Linguistics, 37(2):413–420.
Friedrichs, J¨urgen. 1973. Methoden empirischer
Sozialforschung. Opladen, Westdeutscher
Verlag,14th (1990) edition.
Gadenne, Volker. 1985. Theoretische Begriffe
und die Pr¨ufbarkeit von Theorien.
Zeitschrift f¨ur allgemeine
Wissenschaftstheorie, XVI(1):19–24.
Graf, Erik and Leif Azzopardi. 2008.
A methodology for building a patent
test collection for prior art search. In
Proceedings of the 2nd International Workshop
on Evaluating Information Access (EVIA),
pages 60–71, Tokyo.
Guo, Yunsong and Carla Gomes. 2009.
Ranking structured documents: A large
margin based approach for patent
prior art search. In Proceedings of the
International Joint Conference on Artificial
Intelligence (IJCAI’09), pages 1,058–1,064,
Pasadena, CA.
Halevy, Alon, Peter Norvig, and Fernando
Pereira. 2009. The unreasonable
effectiveness of data. IEEE Intelligent
Systems, 24:8–12.
Hirschman, Lynette, Marc Light, Eric Breck,
and John D. Burger. 1999. Deep read:
A reading comprehension system.
In Proceedings of the 37th Annual Meeting
of the Association for Computational
Linguistics (ACL’99), pages 325–332,
College Park, MD.
Hovy, Eduard, Mitchell Marcus, Martha
Palmer, Lance Ramshaw, and Ralph
Weischedel. 2006.Ontonotes: The 90%
solution. In Proceedings of the Human
Language Technology Conference of the
North American Chapter of the ACL
(HLT-NAACL’06), pages 57–60,
New York, NY.
Kilgarriff, Adam. 1999. 95% replicability for
manual word sense tagging. In Proceedings
of the Ninth Conference of the European
Chapter of the Association for Computational
Linguistics (EACL’99), pages 277–278,
Bergen.
Kim, Joohyun and Raymond J. Mooney.
2013. Adapting discriminative reranking
to grounded language learning.
In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics
(ACL’13), pages 218–277, Sofia.
Korb, Kevin. 2004. Introduction: Machine
learning as philosophy of science. Minds
and Machines, 14(4):1–7.
Krippendorff, Klaus. 1980a. Content Analysis.
An Introduction to Its Methodology. Sage,
third (2013) edition.
</reference>
<page confidence="0.996569">
244
</page>
<note confidence="0.80575">
Riezler On the Problem of Theoretical Terms in Empirical CL
</note>
<reference confidence="0.999813807017544">
Krippendorff, Klaus. 1980b. Validity
in content analysis. In Ekkehard
Mochmann, editor, Computerstrategien
f¨ur die Kommunikationsanalyse. Campus,
pages 69–112.
Krippendorff, Klaus. 2004. Reliability
in content analysis: Some common
misconceptions and recommendations.
Human Communication Research,
30(3):411–433.
Miyao, Yusuke, Rune Saetre, Kenji Sagae,
Takuya Matsuzaki, and Jun’ichi Tsujii.
2008. Task-oriented evaluation of
syntactic parsers and their representations.
In Proceedings of the 46th Annual
Meeting of the Association for
Computational Linguistics: Human
Language Technologies (ACL-HLT’08),
pages 46–54, Columbus, OH.
Nikoulina, Vassilina, Bogomil Kovachev,
Nikolaos Lagos, and Christof Monz. 2012.
Adaptation of statistical machine
translation model for cross-lingual
information retrieval in a service context.
In Proceedings of the 13th Conference of the
European Chapter of the Association for
Computational Linguistics (EACL’12),
pages 109–119, Avignon.
Pang, Bo, Lillian Lee, and Shivakumar
Vaithyanathan. 2002. Thumbs up?
Sentiment classification using machine
learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural
Language Processing (EMNLP’02),
pages 79–86, Philadelphia, PA.
Poesio, Massimo, Jon Chamberlain, Udo
Kruschwitz, Livio Robaldo, and Luca
Ducceschi. 2013. Phrase detectives:
Utilizing collective intelligence for
Internet-scale language resource creation.
ACM Transactions on Interactive Intelligent
Systems, 3(1):Article 3.
Reidsma, Dennis and Jean Carletta. 2007.
Reliability measurements without limits.
Computational Linguistics, 34(3):319–326.
Roy, Deb K. 2002. Learning visually
grounded words and syntax for a scene
description task. Computer Speech and
Language, 16:353–385.
Sneed, Joseph D. 1971. The Logical Structure
of Mathematical Physics. D. Reidel.
Snow, Rion, Brendan O’Connor, Daniel
Jurafsky, and Andrew Y. Ng. 2008. Cheap
and fast—but is it good? Evaluating
non-expert annotations for natural
language tasks. In Proceedings of the
Conference on Empirical Methods in
Natural Language Processing (EMNLP’08),
pages 254–263, Edinburgh.
Sp¨arck Jones, Karen. 1994. Towards better
NLP system evaluation. In Proceedings of
the Workshop on Human Language Technology
(HLT’94), pages 102–107, Plainsboro, NJ.
Stegm¨uller, Wolfgang. 1979. The Structuralist
View of Theories. A Possible Analogue of the
Bourbaki Programme in Physical Science.
Springer.
Stegm¨uller, Wolfgang. 1986. Probleme und
Resultate der Wissenschaftstheorie und
Analytischen Philosophie. Band II: Theorie
und Erfahrung. Springer.
Surdeanu, Mihai, Massimiliano Ciaramita,
and Hugo Zaragoza. 2008. Learning to
rank answers on large online QA
collections. In Proceedings of the 46th Annual
Meeting of the Association for Computational
Linguistics (ACL’08), pages 719–727,
Columbus, OH.
Taskar, Ben, Dan Klein, Michael Collins,
Daphne Koller, and Christopher Manning.
2004. Max-margin parsing. In Proceedings
of the 2004 Conference on Empirical Methods
in Natural Language Processing (EMNLP’04),
pages 1–8, Barcelona.
Tsochantaridis, Ioannis, Thorsten Joachims,
Thomas Hofmann, and Yasemin Altun.
2005. Large margin methods for structured
and interdependent output variables.
Journal of Machine Learning Research,
5:1453–1484.
von Ahn, Luis and Laura Dabbish. 2004.
Labeling images with a computer game.
In Proceedings of the Conference on Human
Factors in Computing Systems (CHI’04),
pages 319–326, Vienna.
von Kutschera, Franz. 1982. Grundfragen der
Erkenntnistheorie. de Gruyter.
von Luxburg, Ulrike, Robert C. Williamson,
and Isabelle Guyon. 2012. Clustering:
Science or art? In Proceedings of the ICML
2011 Workshop on Unsupervised and Transfer
Learning, pages 1–12, Bellevue, WA.
Yu, Chen and Dana H. Ballard. 2004. On
the integration of grounding language
and learning objects. In Proceedings of the
19th National Conference on Artificial
Intelligence (AAAI’04), pages 488–493,
San Jose, CA.
Yu, Haonan and Jeffrey Mark Siskind. 2013.
Grounded language learning from video
described with sentences. In Proceedings of
the 51st Annual Meeting of the Association
for Computational Linguistics (ACL’13),
pages 53–63, Sofia.
</reference>
<page confidence="0.998713">
245
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.366457">
<title confidence="0.92731">On the Problem of Theoretical Terms in Empirical Computational Linguistics</title>
<affiliation confidence="0.8820865">Computational Linguistics Heidelberg University, Germany</affiliation>
<abstract confidence="0.951175555555556">Philosophy of science has pointed out a problem of theoretical terms in empirical sciences. This problem arises if all known measuring procedures for a quantity of a theory presuppose the validity of this very theory, because then statements containing theoretical terms are circular. We argue that a similar circularity can happen in empirical computational linguistics, especially in cases where data are manually annotated by experts. We define a criterion of T-non-theoretical grounding as guidance to avoid such circularities, and exemplify how this criterion can be met by crowdsourcing, by task-related data annotation, or by data in the wild. We argue that this criterion should be considered as a necessary condition for an empirical science, in addition to measures for reliability of data annotation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ron Artstein</author>
<author>Massimo Poesio</author>
</authors>
<title>Inter-coder agreement for computational linguistics.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="16709" citStr="Artstein and Poesio (2008)" startWordPosition="2648" endWordPosition="2651"> the problem of reliability in data annotation, a solution to which is sought by methods for measuring and enhancing inter-annotator agreement. A seminal paper by Carletta (1996) and a follow-up survey 5 In this article, we concentrate on supervised machine learning. Semisupervised, transductive, active, or unsupervised learning deal with machine learning from incomplete or missing labelings where the general assumption of i.i.d. data is not questioned. See Dundar et al. (2007) for an approach of machine learning from non-i.i.d. data. 239 Computational Linguistics Volume 40, Number 1 paper by Artstein and Poesio (2008) have discussed this issue at length. Both papers refer to Krippendorff (2004, 1980a, page 428) who recommends that reliability data “have to be generated by coders that are widely available, follow explicit and communicable instructions (a data language), and work independently of each other.... [T]he more coders participate in the process and the more common they are, the more likely they can ensure the reliability of data.” Ironically, it seems as if the best inter-annotator agreement is achieved by techniques that are in conflict with these recommendations, namely, by using experts (Kilgar</context>
</contexts>
<marker>Artstein, Poesio, 2008</marker>
<rawString>Artstein, Ron and Massimo Poesio. 2008. Inter-coder agreement for computational linguistics. Computational Linguistics, 34(4):555–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Balzer</author>
</authors>
<title>Theoretical terms: Recent developments.</title>
<date>1996</date>
<booktitle>Structuralist Theory of Science. Focal Issues, New Results. de Gruyter,</booktitle>
<pages>139--166</pages>
<editor>In Wolfgang Balzer and C. Ulises Moulines, editors,</editor>
<contexts>
<context position="4218" citStr="Balzer (1996" startWordPosition="625" endWordPosition="626">xamples from empirical CL (Section 3). We also make an attempt at proposing solutions to this problem by using crowdsourcing techniques, task-related annotation, or data in the wild (Section 4). 2. The Problem of Theoretical Terms in Philosophy of Science In order to characterize the logical structure of empirical science, philosophy of science has extensively discussed the notions of “theoretical” and “observational” language. Sneed (1971)2 was the first to suggest a distinction between “theoretical” and “nontheoretical” terms of a given theory by means of the roles they play in that theory. Balzer (1996, page 140) gives a general definition that states that a term is “theoretical in theory T iff every determination of (a realization of) that term presupposes that T has been successfully applied beforehand.” Because there are no theory-independent terms in this view, an explicit reference to a theory T is always carried along when characterizing terms as theoretical with respect to T (T-theoretical) or non-theoretical with respect to T (T-non-theoretical). Stegm¨uller (1979) makes the notions of “determination” or “realization” more concrete by referring to procedures for measuring values of </context>
<context position="19414" citStr="Balzer 1996" startWordPosition="3056" endWordPosition="3057">theoretical strategy to identify and describe the entities of interest shall be excluded from empirical analyses. He recommends that the possibility of using T-non-theoretic strategies to identify observations be made the defining criterion for empirical sciences. That is, in order to make an empirical statement, the two tiers of a T-theoretical and a T-non-theoretical level are necessary because the use of a single theoretical tier prevents distinguishing empirical statements from those that are not. Let us call Finke’s requirement the criterion of T-non-theoretical grounding.6 Moulines (see Balzer 1996, page 141) gives a pragmatic condition for T-non-theoreticity that can be used as a guideline: “Term t¯ is T-non-theoretical if there exists and acknowledged method of determination of t¯ in some theory T&apos; different from T plus some link from T&apos; to T which permits the transfer of realizations of t¯ from T&apos; into T.” Balzer (1996) discusses a variety of more formal characterizations of the notion of T-(non-)theoretical terms. Although the pragmatic definition cited here is rather informal, it is sufficient as a guideline in discussing concrete examples and strategies to break the circlularity i</context>
</contexts>
<marker>Balzer, 1996</marker>
<rawString>Balzer, Wolfgang. 1996. Theoretical terms: Recent developments. In Wolfgang Balzer and C. Ulises Moulines, editors, Structuralist Theory of Science. Focal Issues, New Results. de Gruyter, pages 139–166.</rawString>
</citation>
<citation valid="true">
<date>1996</date>
<booktitle>Structuralist Theory of Science. Focal Issues, New Results. de Gruyter.</booktitle>
<editor>Balzer, Wolfgang and C. Ulises Moulines, editors.</editor>
<contexts>
<context position="6182" citStr="(1996)" startWordPosition="942" endWordPosition="942"> because another sentence of exactly the same form and with exactly the same predicate is presupposed. An illustration of this concept can be given by Stegm¨uller (1986)’s miniature theory of an Archimedian Statics. Let us assume that this miniature theory is formalized by the set-theoretic predicate AS. The intended applications of the theory AS are objects a1,. .. , an that are in balance around a pivot point. The theory uses 2 The following discussion of concepts of the “structuralist” or “non-statement view of theories” is based on works by Stegm¨uller (1979, 1986) and Balzer and Moulines (1996) that are more accessible than the original book by Sneed (1971). All translations from German are by the author. 236 Riezler On the Problem of Theoretical Terms in Empirical CL two functions that measure the distance d of the objects from the pivot point, and the weight g. The central axiom of the theory states that the sum of the products d(ai)g(ai) is the same for the objects on either side of the pivot point. The theory AS can then be defined as follows: x is an AS iff there is an A, d, g such that: 1. x = (A, d, g), 2. A = {a1,...,anb 3. d : A IR, 4. g : A IR, 5. daEA:g(a)&gt;0, 6. En i=1 d(</context>
<context position="16261" citStr="(1996)" startWordPosition="2585" endWordPosition="2585"> inherently circular in the sense of the problem of theoretical terms described previously. Thus in all cases, we are prevented from making empirical statements. High prediction accuracy of machine learning in such scenarios indicates high consistency in the application of implicit knowledge in different roles of a single expert or of groups of experts, but not more. This problem of circularity in expert coding is related to the problem of reliability in data annotation, a solution to which is sought by methods for measuring and enhancing inter-annotator agreement. A seminal paper by Carletta (1996) and a follow-up survey 5 In this article, we concentrate on supervised machine learning. Semisupervised, transductive, active, or unsupervised learning deal with machine learning from incomplete or missing labelings where the general assumption of i.i.d. data is not questioned. See Dundar et al. (2007) for an approach of machine learning from non-i.i.d. data. 239 Computational Linguistics Volume 40, Number 1 paper by Artstein and Poesio (2008) have discussed this issue at length. Both papers refer to Krippendorff (2004, 1980a, page 428) who recommends that reliability data “have to be generat</context>
<context position="19745" citStr="(1996)" startWordPosition="3115" endWordPosition="3115">theoretical and a T-non-theoretical level are necessary because the use of a single theoretical tier prevents distinguishing empirical statements from those that are not. Let us call Finke’s requirement the criterion of T-non-theoretical grounding.6 Moulines (see Balzer 1996, page 141) gives a pragmatic condition for T-non-theoreticity that can be used as a guideline: “Term t¯ is T-non-theoretical if there exists and acknowledged method of determination of t¯ in some theory T&apos; different from T plus some link from T&apos; to T which permits the transfer of realizations of t¯ from T&apos; into T.” Balzer (1996) discusses a variety of more formal characterizations of the notion of T-(non-)theoretical terms. Although the pragmatic definition cited here is rather informal, it is sufficient as a guideline in discussing concrete examples and strategies to break the circlularity in the methodology of empirical CL. In the following, we will exemplify how this criterion can be met by manual data annotation by using naive coders, or by 6 Note that our criterion of T-non-theoretical grounding is related to the more specific concept of operationalization in social sciences (Friedrichs 1973). Operationalization</context>
</contexts>
<marker>1996</marker>
<rawString>Balzer, Wolfgang and C. Ulises Moulines, editors. 1996. Structuralist Theory of Science. Focal Issues, New Results. de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beigman Klebanov</author>
<author>Beata</author>
<author>Eyal Beigman</author>
</authors>
<title>From annotator agreement to noise models.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>4</issue>
<marker>Klebanov, Beata, Beigman, 2009</marker>
<rawString>Beigman Klebanov, Beata and Eyal Beigman. 2009. From annotator agreement to noise models. Computational Linguistics, 35(4):495–503.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
</authors>
<title>That’s nice ... what can you do with it?</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<contexts>
<context position="23574" citStr="Belz 2009" startWordPosition="3704" endWordPosition="3705">agreement from crowdsourcing can be seen as a possible litmus test for a successful T-non-theoretical grounding of complex annotation tasks. Circularity issues will vanish because T-theoretical terms cannot be communicated directly to naive coders. 4.2 Grounding by Extrinsic Evaluation and Task-Related Annotation Another way to achieve T-non-theoretical grounding is extrinsic evaluation of NLP systems. This type of evaluation assesses “the effect of a system on something that is external to it, for example, the effect on human performance at a given task or the value added to an application” (Belz 2009) and has been demanded for at least 20 years (Sp¨arck Jones 1994). Extrinsic evaluation is advertised as a remedy against “closed problem” approaches (Sp¨arck Jones 1994) or against “closed circles” in intrinsic evaluation where system rankings produced by automatic measures are compared with human rankings which are themselves unfalsifiable (Belz 2009). 7 http://www.mturk.com. 8 See Fort, Adda, and Cohen (2011) for a discussion of the ethical dimensions of crowdsourcing services and their alternatives. 241 Computational Linguistics Volume 40, Number 1 An example of an extrinsic evaluation in </context>
</contexts>
<marker>Belz, 2009</marker>
<rawString>Belz, Anja. 2009. That’s nice ... what can you do with it? Computational Linguistics, 35(1):111–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07),</booktitle>
<pages>440--447</pages>
<location>Prague.</location>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>Blitzer, John, Mark Dredze, and Fernando Pereira. 2007. Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07), pages 440–447, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Mark Dredze</author>
</authors>
<title>Creating speech and language data with Amazon’s Mechanical Turk.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL-HLT</booktitle>
<pages>1--12</pages>
<location>Los Angeles, CA.</location>
<marker>Callison-Burch, Dredze, 2010</marker>
<rawString>Callison-Burch, Chris and Mark Dredze. 2010. Creating speech and language data with Amazon’s Mechanical Turk. In Proceedings of the NAACL-HLT 2010 pages 1–12, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="16261" citStr="Carletta (1996)" startWordPosition="2584" endWordPosition="2585">arios are inherently circular in the sense of the problem of theoretical terms described previously. Thus in all cases, we are prevented from making empirical statements. High prediction accuracy of machine learning in such scenarios indicates high consistency in the application of implicit knowledge in different roles of a single expert or of groups of experts, but not more. This problem of circularity in expert coding is related to the problem of reliability in data annotation, a solution to which is sought by methods for measuring and enhancing inter-annotator agreement. A seminal paper by Carletta (1996) and a follow-up survey 5 In this article, we concentrate on supervised machine learning. Semisupervised, transductive, active, or unsupervised learning deal with machine learning from incomplete or missing labelings where the general assumption of i.i.d. data is not questioned. See Dundar et al. (2007) for an approach of machine learning from non-i.i.d. data. 239 Computational Linguistics Volume 40, Number 1 paper by Artstein and Poesio (2008) have discussed this issue at length. Both papers refer to Krippendorff (2004, 1980a, page 428) who recommends that reliability data “have to be generat</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Carletta, Jean. 1996. Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22(2):1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to sportscast: A test of grounded language learning.</title>
<date>2008</date>
<contexts>
<context position="29710" citStr="Chen and Mooney 2008" startWordPosition="4655" endWordPosition="4658">et by manual data annotation by using naive coders, or by embedding data annotation into a task extrinsic to the theory to be tested, or by using independently created language data that are available in the wild. Our suggestions for T-non-theoretical grounding are related to work on grounded language learning that is based on weak supervision in the form of the use of sentences in naturally occurring contexts. For example, the meaning of natural language expresssions can be grounded in visual scenes (Roy 2002; Yu and Ballard 2004; Yu and Siskind 2013) or actions in games or navigation tasks (Chen and Mooney 2008, 2011). Because of the ambiguous supervision, most such approaches work with latent representations and use unsupervised techniques in learning. Our suggestions for T-non-theoretical grounding can be used to avoid circularities in standard supervised learning. We think that this criterion should be considered a necessary condition for an empirical science, in addition to ensuring reliability of measurements. Our negligence of related issues such as validity of measurements (see Krippendorff 1980b) shows that there is a vast methodological area to be explored, perhaps with further opportunity </context>
</contexts>
<marker>Chen, Mooney, 2008</marker>
<rawString>Chen, David L. and Raymond J. Mooney. 2008. Learning to sportscast: A test of grounded language learning.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 25th International Conference on Machine Learning (ICML’08),</booktitle>
<pages>128--135</pages>
<location>Helsinki.</location>
<marker></marker>
<rawString>In Proceedings of the 25th International Conference on Machine Learning (ICML’08), pages 128–135, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to interpret natural language navigation instructions from observations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI’11),</booktitle>
<pages>859--866</pages>
<location>San Francisco, CA.</location>
<marker>Chen, Mooney, 2011</marker>
<rawString>Chen, David L. and Raymond J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI’11), pages 859–866, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Dan Goldwasser</author>
<author>Wing-Wei Chang</author>
<author>Dan Roth</author>
</authors>
<title>Driving semantic parsing from the world’s response.</title>
<date>2010</date>
<booktitle>In Proceedings of the 14th Conference on Natural Language Learning (CoNLL’10),</booktitle>
<pages>18--27</pages>
<location>Uppsala.</location>
<contexts>
<context position="25454" citStr="Clarke et al. (2010)" startWordPosition="3986" endWordPosition="3989">use. Extrinsic scenarios are not only useful for the purpose of evaluation. Rather, every extrinsic evaluation creates data that can be used as training data for another learning task (e.g., rankings of system outputs with respect to an extrinsic task can be used to train discriminative (re)ranking models). For example, Kim and Mooney (2013) use the successful completion of navigation tasks to create training data for reranking in grounded language learning. Nikoulina et al. (2012) use retrieval performance of translated queries to create data for reranking in statistical machine translation. Clarke et al. (2010) use the correct response for a query to a database of geographical facts to select data for structured learning of a semantic parser. Thus the extrinsic set-up can be seen as a general technique for T-non-theoretical grounding in training as well as in testing scenarios. Circularity issues will not arise in extrinsic set-ups because the extrinsic task is by definition external to the system outputs to be tested or ranked. 4.3 Grounded Data in the Wild Halevy, Norvig, and Pereira (2009, page 8) mention statistical speech recognition and statistical machine translation as “the biggest successes</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>Clarke, James, Dan Goldwasser, Wing-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world’s response. In Proceedings of the 14th Conference on Natural Language Learning (CoNLL’10), pages 18–27, Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Corfield</author>
<author>Bernhard Sch¨olkopf</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Falsificationism and statistical learning theory: Comparing the Popper and Vapnik-Chervonenkis dimensions.</title>
<date>2009</date>
<journal>Journal for General Philosophy of Science,</journal>
<pages>40--51</pages>
<marker>Corfield, Sch¨olkopf, Vapnik, 2009</marker>
<rawString>Corfield, David, Bernhard Sch¨olkopf, and Vladimir Vapnik. 2009. Falsificationism and statistical learning theory: Comparing the Popper and Vapnik-Chervonenkis dimensions. Journal for General Philosophy of Science, 40:51–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Hassan Al-Haj</author>
<author>Alon Lavie</author>
</authors>
<title>Turker-assisted paraphrasing for English-Arabic machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL-HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk,</booktitle>
<pages>66--70</pages>
<location>Los Angeles, CA.</location>
<marker>Denkowski, Al-Haj, Lavie, 2010</marker>
<rawString>Denkowski, Michael, Hassan Al-Haj, and Alon Lavie. 2010. Turker-assisted paraphrasing for English-Arabic machine translation. In Proceedings of the NAACL-HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 66–70, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dreyer</author>
<author>Daniel Marcu</author>
</authors>
<title>HyTER: Meaning-equivalent semantics for translation evaluation.</title>
<date>2012</date>
<booktitle>In Proceedings of 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2012),</booktitle>
<pages>162--171</pages>
<location>Montreal.</location>
<contexts>
<context position="28322" citStr="Dreyer and Marcu 2012" startWordPosition="4429" endWordPosition="4432"> create reference translations for statistical machine translation by monolingual phrase substitutions on existing references. “Translations” created by workers that paraphrase given references without knowing the source can never lead to the circularity that data annotation by experts is susceptible to. In a 242 Riezler On the Problem of Theoretical Terms in Empirical CL scenario of monolingual paraphrasing for reference translations even inter-annotator agreement is not an issue anymore. Data created by single annotators (e.g., monolingual meaning equivalents created for bilingual purposes [Dreyer and Marcu 2012]), can be treated as “given” data for machine learning purposes, even if each network of meaning equivalences is created by a single annotator. 5. Conclusion In this article, we have argued that the problem of theoretical terms as identified for theoretical physics can occur in empirical CL in cases where data are not “given” as commonly assumed in machine learning. We exemplified this problem on the example of manual data annotation by experts, where the task of relating instances to labels in manual data annotation and the task of relating instances to labels via modeling feature functions </context>
</contexts>
<marker>Dreyer, Marcu, 2012</marker>
<rawString>Dreyer, Markus and Daniel Marcu. 2012. HyTER: Meaning-equivalent semantics for translation evaluation. In Proceedings of 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2012), pages 162–171, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Murat Dundar</author>
<author>Balaji Krishnapuram</author>
<author>Jinbo Bi</author>
<author>R Bharat Rao</author>
</authors>
<title>Learning classifiers when the training data is not IID.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI’07),</booktitle>
<pages>756--761</pages>
<location>Hyderabad.</location>
<contexts>
<context position="16565" citStr="Dundar et al. (2007)" startWordPosition="2626" endWordPosition="2629">ge in different roles of a single expert or of groups of experts, but not more. This problem of circularity in expert coding is related to the problem of reliability in data annotation, a solution to which is sought by methods for measuring and enhancing inter-annotator agreement. A seminal paper by Carletta (1996) and a follow-up survey 5 In this article, we concentrate on supervised machine learning. Semisupervised, transductive, active, or unsupervised learning deal with machine learning from incomplete or missing labelings where the general assumption of i.i.d. data is not questioned. See Dundar et al. (2007) for an approach of machine learning from non-i.i.d. data. 239 Computational Linguistics Volume 40, Number 1 paper by Artstein and Poesio (2008) have discussed this issue at length. Both papers refer to Krippendorff (2004, 1980a, page 428) who recommends that reliability data “have to be generated by coders that are widely available, follow explicit and communicable instructions (a data language), and work independently of each other.... [T]he more coders participate in the process and the more common they are, the more likely they can ensure the reliability of data.” Ironically, it seems as i</context>
</contexts>
<marker>Dundar, Krishnapuram, Bi, Rao, 2007</marker>
<rawString>Dundar, Murat, Balaji Krishnapuram, Jinbo Bi, and R. Bharat Rao. 2007. Learning classifiers when the training data is not IID. In Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI’07), pages 756–761, Hyderabad.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Finke</author>
</authors>
<title>Grundlagen einer linguistischen Theorie. Empirie und Begr¨undung in der Sprachwissenschaft.</title>
<date>1979</date>
<publisher>Vieweg.</publisher>
<contexts>
<context position="18692" citStr="Finke (1979)" startWordPosition="2949" endWordPosition="2950">suring reproducibility. (page 575) Reidsma and Carletta (2007) and Beigman Klebanov and Beigman (2009) reach the conclusion that high inter-annotator agreement is neither sufficient nor necessary to achieve high reliability in data annotation. The problem lies in the implicit or tacit knowledge that is shared among the community of experts. This implicit knowledge is responsible for the high inter-annotator agreement, but hinders reproducibility. In a similar way, implicit knowledge of expert coders can lead to a circularity in data annotation and feature modeling. 4. Breaking the Circularity Finke (1979), in attempting to establish criteria for an empirical theory of linguistics, demands that the use of a single theoretical strategy to identify and describe the entities of interest shall be excluded from empirical analyses. He recommends that the possibility of using T-non-theoretic strategies to identify observations be made the defining criterion for empirical sciences. That is, in order to make an empirical statement, the two tiers of a T-theoretical and a T-non-theoretical level are necessary because the use of a single theoretical tier prevents distinguishing empirical statements from th</context>
</contexts>
<marker>Finke, 1979</marker>
<rawString>Finke, Peter. 1979. Grundlagen einer linguistischen Theorie. Empirie und Begr¨undung in der Sprachwissenschaft. Vieweg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kar¨en Fort</author>
<author>Gilles Adda</author>
<author>K Bretonnel Cohen</author>
</authors>
<title>Amazon Mechanical Turk: Gold mine or coal mine?</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<marker>Fort, Adda, Cohen, 2011</marker>
<rawString>Fort, Kar¨en, Gilles Adda, and K. Bretonnel Cohen. 2011. Amazon Mechanical Turk: Gold mine or coal mine? Computational Linguistics, 37(2):413–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨urgen Friedrichs</author>
</authors>
<date>1973</date>
<booktitle>Methoden empirischer Sozialforschung. Opladen, Westdeutscher Verlag,14th</booktitle>
<note>edition.</note>
<contexts>
<context position="20325" citStr="Friedrichs 1973" startWordPosition="3203" endWordPosition="3204">of t¯ from T&apos; into T.” Balzer (1996) discusses a variety of more formal characterizations of the notion of T-(non-)theoretical terms. Although the pragmatic definition cited here is rather informal, it is sufficient as a guideline in discussing concrete examples and strategies to break the circlularity in the methodology of empirical CL. In the following, we will exemplify how this criterion can be met by manual data annotation by using naive coders, or by 6 Note that our criterion of T-non-theoretical grounding is related to the more specific concept of operationalization in social sciences (Friedrichs 1973). Operationalization refers to the process of developing indicators of the form “X is an a if Y is a b (at time t)” to connect T-theoretical and T-non-theoretical levels. We will stick with the more general criterion in the rest of this article. 240 Riezler On the Problem of Theoretical Terms in Empirical CL embedding data annotation into a task extrinsic to the theory to be tested, or by using independently created language data that are available in the wild. 4.1 T-non-theoretical Grounding by Naive Coders and Crowdsourcing Now that we have defined the criterion of T-non-theoretical groundin</context>
</contexts>
<marker>Friedrichs, 1973</marker>
<rawString>Friedrichs, J¨urgen. 1973. Methoden empirischer Sozialforschung. Opladen, Westdeutscher Verlag,14th (1990) edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Volker Gadenne</author>
</authors>
<title>Theoretische Begriffe und die Pr¨ufbarkeit von Theorien. Zeitschrift f¨ur allgemeine Wissenschaftstheorie,</title>
<date>1985</date>
<contexts>
<context position="9703" citStr="Gadenne (1985)" startWordPosition="1551" endWordPosition="1552">form (2), that is, statements about certain entities being models of the theory AS. 2. In complex physical theories such as particle mechanics there are no simplified assumptions on measuring procedures that can be dropped easily. Sneed (1971) proposed the so-called Ramsey solution3 that in essence avoids AS-theoretical terms by existentially quantifying over them. Solution (1), where T-theoretical terms are measured by applications of a theory T&apos;, thus is the standard case in empirical sciences. Solution (2) is a special case where we need theory T in order to measure some terms in theory T. Gadenne (1985) argues that this case can be understood as a tentative assumption of theory T that still makes empirical testing possible.4 The important point for our discussion is that in both solutions to the problem of theoretical terms, whether we refer to another theory T&apos; (solution (1)) or whether we tentatively assume theory T (solution (2)), we require an explicit dichotomy between T-theoretical and T-non-theoretical terms. This insight is crucial in the following analysis of possible circularities in the methodology of empirical CL. 3. The Problem of Theoretical Terms in Empirical CL Most machine-l</context>
<context position="11846" citStr="Gadenne 1985" startWordPosition="1884" endWordPosition="1885">r measuring procedures for terms like g. The resulting Ramsey claim applies a theoretical extension to a partial potential model that also satisfies condition (6). Because such a statement does not contain theoretical terms we can make empirical statements about entities being models of the theory AS. 4 Critics of the structuralist theory of science have remarked that both of the solutions are instances of a more general problem, the so-called Duhem-Quine problem, thus the focus of the structuralist program on solution (2) seems to be an exaggeration of the actual problem (von Kutschera 1982; Gadenne 1985). The Duhem-Quine thesis states that theoretical assumptions cannot be tested in isolation, but rather whole systems of theoretical assumptions and auxiliary assumptions are subjected to empirical testing. That is, if our predictions are not in accordance with our theory, we can only conclude that one of our many theoretical assumptions must be wrong, but we cannot know which one, and we can always modify our system of assumptions, leading to various ways of immunity of theories (Stegm¨uller 1986). This problem arises in Solution (1) as well as in Solution (2) 238 Riezler On the Problem of The</context>
</contexts>
<marker>Gadenne, 1985</marker>
<rawString>Gadenne, Volker. 1985. Theoretische Begriffe und die Pr¨ufbarkeit von Theorien. Zeitschrift f¨ur allgemeine Wissenschaftstheorie, XVI(1):19–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Graf</author>
<author>Leif Azzopardi</author>
</authors>
<title>A methodology for building a patent test collection for prior art search.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2nd International Workshop on Evaluating Information Access (EVIA),</booktitle>
<pages>60--71</pages>
<location>Tokyo.</location>
<contexts>
<context position="13237" citStr="Graf and Azzopardi 2008" startWordPosition="2110" endWordPosition="2113">ntaridis et al. 2005).5 The problem of theoretical terms arises in empirical CL in cases where a single theoretical tier is used both in manual data annotation (i.e., in the assignment of labels y to patterns x via the encoding of data pairs (x, y)), and in feature construction (i.e., in the association of labels y to patterns x via features φ(x, y)). This problem can be illustrated by looking at automatic methods for data annotation. For example, information retrieval (IR) in the patent domain uses citations of patents in other patents to automatically create relevance judgments for ranking (Graf and Azzopardi 2008). Learning-to-rank models such as that of Guo and Gomes (2009) define domain knowledge features on patent pairs (e.g., same patent class in the International Patent Classification [IPC], same inventor, same assignee company) and IR score features (e.g., tf-idf, cosine similarity) to represent data in a structured prediction framework. Clearly, one could have just as well used IPC classes to create automatic relevance judgments, and patent citations as features in the structured prediction model. It should also be evident that using the same criterion to automatically create relevance labels an</context>
</contexts>
<marker>Graf, Azzopardi, 2008</marker>
<rawString>Graf, Erik and Leif Azzopardi. 2008. A methodology for building a patent test collection for prior art search. In Proceedings of the 2nd International Workshop on Evaluating Information Access (EVIA), pages 60–71, Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunsong Guo</author>
<author>Carla Gomes</author>
</authors>
<title>Ranking structured documents: A large margin based approach for patent prior art search.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI’09),</booktitle>
<pages>1--058</pages>
<location>Pasadena, CA.</location>
<contexts>
<context position="13299" citStr="Guo and Gomes (2009)" startWordPosition="2120" endWordPosition="2123"> empirical CL in cases where a single theoretical tier is used both in manual data annotation (i.e., in the assignment of labels y to patterns x via the encoding of data pairs (x, y)), and in feature construction (i.e., in the association of labels y to patterns x via features φ(x, y)). This problem can be illustrated by looking at automatic methods for data annotation. For example, information retrieval (IR) in the patent domain uses citations of patents in other patents to automatically create relevance judgments for ranking (Graf and Azzopardi 2008). Learning-to-rank models such as that of Guo and Gomes (2009) define domain knowledge features on patent pairs (e.g., same patent class in the International Patent Classification [IPC], same inventor, same assignee company) and IR score features (e.g., tf-idf, cosine similarity) to represent data in a structured prediction framework. Clearly, one could have just as well used IPC classes to create automatic relevance judgments, and patent citations as features in the structured prediction model. It should also be evident that using the same criterion to automatically create relevance labels and as feature representation would be circular. In terms of the</context>
</contexts>
<marker>Guo, Gomes, 2009</marker>
<rawString>Guo, Yunsong and Carla Gomes. 2009. Ranking structured documents: A large margin based approach for patent prior art search. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI’09), pages 1,058–1,064, Pasadena, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Halevy</author>
<author>Peter Norvig</author>
<author>Fernando Pereira</author>
</authors>
<title>The unreasonable effectiveness of data.</title>
<date>2009</date>
<journal>IEEE Intelligent Systems,</journal>
<pages>24--8</pages>
<marker>Halevy, Norvig, Pereira, 2009</marker>
<rawString>Halevy, Alon, Peter Norvig, and Fernando Pereira. 2009. The unreasonable effectiveness of data. IEEE Intelligent Systems, 24:8–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Marc Light</author>
<author>Eric Breck</author>
<author>John D Burger</author>
</authors>
<title>Deep read: A reading comprehension system.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL’99),</booktitle>
<pages>325--332</pages>
<location>College Park, MD.</location>
<marker>Hirschman, Light, Breck, Burger, 1999</marker>
<rawString>Hirschman, Lynette, Marc Light, Eric Breck, and John D. Burger. 1999. Deep read: A reading comprehension system. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL’99), pages 325–332, College Park, MD.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>2006.Ontonotes: The 90% solution.</title>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL (HLT-NAACL’06),</booktitle>
<pages>57--60</pages>
<location>New York, NY.</location>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, </marker>
<rawString>Hovy, Eduard, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006.Ontonotes: The 90% solution. In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL (HLT-NAACL’06), pages 57–60, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>95% replicability for manual word sense tagging.</title>
<date>1999</date>
<booktitle>In Proceedings of the Ninth Conference of the European Chapter of the Association for Computational Linguistics (EACL’99),</booktitle>
<pages>277--278</pages>
<location>Bergen.</location>
<contexts>
<context position="17319" citStr="Kilgarriff 1999" startWordPosition="2744" endWordPosition="2745">(2008) have discussed this issue at length. Both papers refer to Krippendorff (2004, 1980a, page 428) who recommends that reliability data “have to be generated by coders that are widely available, follow explicit and communicable instructions (a data language), and work independently of each other.... [T]he more coders participate in the process and the more common they are, the more likely they can ensure the reliability of data.” Ironically, it seems as if the best inter-annotator agreement is achieved by techniques that are in conflict with these recommendations, namely, by using experts (Kilgarriff 1999) or intensively trained coders (Hovy et al. 2006) for data annotation. Artstein and Poesio (2008) state explicitly that experts as coders, particularly long-term collaborators, [... ] may agree not because they are carefully following written instructions, but because they know the purpose of the research very well–which makes it virtually impossible for others to reproduce the results on the basis of the same coding scheme .... Practices which violate the third requirement (independence) include asking the coders to discuss their judgments with each other and reach their decisions by majority</context>
</contexts>
<marker>Kilgarriff, 1999</marker>
<rawString>Kilgarriff, Adam. 1999. 95% replicability for manual word sense tagging. In Proceedings of the Ninth Conference of the European Chapter of the Association for Computational Linguistics (EACL’99), pages 277–278, Bergen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joohyun Kim</author>
<author>Raymond J Mooney</author>
</authors>
<title>Adapting discriminative reranking to grounded language learning.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13),</booktitle>
<pages>218--277</pages>
<location>Sofia.</location>
<contexts>
<context position="25177" citStr="Kim and Mooney (2013)" startWordPosition="3946" endWordPosition="3949">thods have led von Luxburg, Williamson, and Guyon (2012) to pose the question “Clustering: Science or Art?”. They recommend to measure the usefulness of a clustering method for a particular task under consideration, that is, to always study clustering in the context of its end use. Extrinsic scenarios are not only useful for the purpose of evaluation. Rather, every extrinsic evaluation creates data that can be used as training data for another learning task (e.g., rankings of system outputs with respect to an extrinsic task can be used to train discriminative (re)ranking models). For example, Kim and Mooney (2013) use the successful completion of navigation tasks to create training data for reranking in grounded language learning. Nikoulina et al. (2012) use retrieval performance of translated queries to create data for reranking in statistical machine translation. Clarke et al. (2010) use the correct response for a query to a database of geographical facts to select data for structured learning of a semantic parser. Thus the extrinsic set-up can be seen as a general technique for T-non-theoretical grounding in training as well as in testing scenarios. Circularity issues will not arise in extrinsic set</context>
</contexts>
<marker>Kim, Mooney, 2013</marker>
<rawString>Kim, Joohyun and Raymond J. Mooney. 2013. Adapting discriminative reranking to grounded language learning. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), pages 218–277, Sofia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Korb</author>
</authors>
<title>Introduction: Machine learning as philosophy of science.</title>
<date>2004</date>
<journal>Minds and Machines,</journal>
<volume>14</volume>
<issue>4</issue>
<contexts>
<context position="2032" citStr="Korb (2004)" startWordPosition="295" endWordPosition="296">ical CL. A recent discussion in the machine learning community claims an even stronger and more general role of machine learning. We allude here to a discussion concerning the relation of machine learning and philosophy of science. For example, Corfield, Sch¨olkopf, and Vapnik (2009) compare Popper’s ideas of falsifiability of a scientific theory with “similar notions” from statistical learning theory regarding Vapnik-Chervonenkis theory. A recent NIPS workshop on “Philosophy and Machine Learning”1 presented a collection of papers investigating similar problems and concepts in the two fields. Korb (2004) sums up the essence of the discussion by directly advertising “Machine Learning as Philosophy of Science.” In this article we argue that adopting machine learning theory as philosophy of science for empirical CL has to be done with great care. A problem arises in the application of machine learning methods to natural language data under the assumption that input–output pairs are given and do not have to be questioned. In contrast to machine learning, in empirical CL neither a representation of instances nor an association of * Department of Computational Linguistics, Heidelberg University, Im</context>
</contexts>
<marker>Korb, 2004</marker>
<rawString>Korb, Kevin. 2004. Introduction: Machine learning as philosophy of science. Minds and Machines, 14(4):1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Krippendorff</author>
</authors>
<title>Content Analysis. An Introduction to Its Methodology. Sage, third</title>
<date>1980</date>
<note>edition.</note>
<marker>Krippendorff, 1980</marker>
<rawString>Krippendorff, Klaus. 1980a. Content Analysis. An Introduction to Its Methodology. Sage, third (2013) edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Krippendorff</author>
</authors>
<title>Validity in content analysis.</title>
<date>1980</date>
<booktitle>In Ekkehard Mochmann, editor, Computerstrategien f¨ur die Kommunikationsanalyse. Campus,</booktitle>
<pages>69--112</pages>
<marker>Krippendorff, 1980</marker>
<rawString>Krippendorff, Klaus. 1980b. Validity in content analysis. In Ekkehard Mochmann, editor, Computerstrategien f¨ur die Kommunikationsanalyse. Campus, pages 69–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Krippendorff</author>
</authors>
<title>Reliability in content analysis: Some common misconceptions and recommendations.</title>
<date>2004</date>
<journal>Human Communication Research,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="16786" citStr="Krippendorff (2004" startWordPosition="2662" endWordPosition="2663">ods for measuring and enhancing inter-annotator agreement. A seminal paper by Carletta (1996) and a follow-up survey 5 In this article, we concentrate on supervised machine learning. Semisupervised, transductive, active, or unsupervised learning deal with machine learning from incomplete or missing labelings where the general assumption of i.i.d. data is not questioned. See Dundar et al. (2007) for an approach of machine learning from non-i.i.d. data. 239 Computational Linguistics Volume 40, Number 1 paper by Artstein and Poesio (2008) have discussed this issue at length. Both papers refer to Krippendorff (2004, 1980a, page 428) who recommends that reliability data “have to be generated by coders that are widely available, follow explicit and communicable instructions (a data language), and work independently of each other.... [T]he more coders participate in the process and the more common they are, the more likely they can ensure the reliability of data.” Ironically, it seems as if the best inter-annotator agreement is achieved by techniques that are in conflict with these recommendations, namely, by using experts (Kilgarriff 1999) or intensively trained coders (Hovy et al. 2006) for data annotati</context>
</contexts>
<marker>Krippendorff, 2004</marker>
<rawString>Krippendorff, Klaus. 2004. Reliability in content analysis: Some common misconceptions and recommendations. Human Communication Research, 30(3):411–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Rune Saetre</author>
<author>Kenji Sagae</author>
<author>Takuya Matsuzaki</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Task-oriented evaluation of syntactic parsers and their representations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT’08),</booktitle>
<pages>46--54</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="24295" citStr="Miyao et al. 2008" startWordPosition="3811" endWordPosition="3814">s a remedy against “closed problem” approaches (Sp¨arck Jones 1994) or against “closed circles” in intrinsic evaluation where system rankings produced by automatic measures are compared with human rankings which are themselves unfalsifiable (Belz 2009). 7 http://www.mturk.com. 8 See Fort, Adda, and Cohen (2011) for a discussion of the ethical dimensions of crowdsourcing services and their alternatives. 241 Computational Linguistics Volume 40, Number 1 An example of an extrinsic evaluation in NLP is the evaluation of the effect of syntactic parsers on retrieval quality in a biomedical IR task (Miyao et al. 2008). Interestingly, the extrinsic set-up revealed a different system ranking than the standard intrinsic evaluation, according to F-scores on the Penn WSJ corpus. Another example is the area of clustering. Deficiencies in current intrinsic clustering evaluation methods have led von Luxburg, Williamson, and Guyon (2012) to pose the question “Clustering: Science or Art?”. They recommend to measure the usefulness of a clustering method for a particular task under consideration, that is, to always study clustering in the context of its end use. Extrinsic scenarios are not only useful for the purpose </context>
</contexts>
<marker>Miyao, Saetre, Sagae, Matsuzaki, Tsujii, 2008</marker>
<rawString>Miyao, Yusuke, Rune Saetre, Kenji Sagae, Takuya Matsuzaki, and Jun’ichi Tsujii. 2008. Task-oriented evaluation of syntactic parsers and their representations. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT’08), pages 46–54, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vassilina Nikoulina</author>
<author>Bogomil Kovachev</author>
<author>Nikolaos Lagos</author>
<author>Christof Monz</author>
</authors>
<title>Adaptation of statistical machine translation model for cross-lingual information retrieval in a service context.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL’12),</booktitle>
<pages>109--119</pages>
<location>Avignon.</location>
<contexts>
<context position="25320" citStr="Nikoulina et al. (2012)" startWordPosition="3967" endWordPosition="3970">efulness of a clustering method for a particular task under consideration, that is, to always study clustering in the context of its end use. Extrinsic scenarios are not only useful for the purpose of evaluation. Rather, every extrinsic evaluation creates data that can be used as training data for another learning task (e.g., rankings of system outputs with respect to an extrinsic task can be used to train discriminative (re)ranking models). For example, Kim and Mooney (2013) use the successful completion of navigation tasks to create training data for reranking in grounded language learning. Nikoulina et al. (2012) use retrieval performance of translated queries to create data for reranking in statistical machine translation. Clarke et al. (2010) use the correct response for a query to a database of geographical facts to select data for structured learning of a semantic parser. Thus the extrinsic set-up can be seen as a general technique for T-non-theoretical grounding in training as well as in testing scenarios. Circularity issues will not arise in extrinsic set-ups because the extrinsic task is by definition external to the system outputs to be tested or ranked. 4.3 Grounded Data in the Wild Halevy, N</context>
</contexts>
<marker>Nikoulina, Kovachev, Lagos, Monz, 2012</marker>
<rawString>Nikoulina, Vassilina, Bogomil Kovachev, Nikolaos Lagos, and Christof Monz. 2012. Adaptation of statistical machine translation model for cross-lingual information retrieval in a service context. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL’12), pages 109–119, Avignon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’02),</booktitle>
<pages>79--86</pages>
<location>Philadelphia, PA.</location>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’02), pages 79–86, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Jon Chamberlain</author>
<author>Udo Kruschwitz</author>
<author>Livio Robaldo</author>
<author>Luca Ducceschi</author>
</authors>
<title>Phrase detectives: Utilizing collective intelligence for Internet-scale language resource creation.</title>
<date>2013</date>
<journal>ACM Transactions on Interactive Intelligent Systems,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>3</pages>
<contexts>
<context position="22099" citStr="Poesio et al. 2013" startWordPosition="3482" endWordPosition="3485">tation task explicitly in written form. Furthermore, the “naive” nature of annotators requires a verbalization in words comprehensible to non-experts, without the option of relying on implicit or tacit knowledge that is shared among expert annotators. The researcher will thus be forced to describe the annotation task without using technical terms that are common to experts, but are not known to naive coders. Annotation by naive coders can be achieved by using crowdsourcing services such as Amazon’s Mechanical Turk,7 or alternatively, by creating games with a purpose (von Ahn and Dabbish 2004; Poesio et al. 2013).8 Non-expert annotations created by crowdsourcing have been shown to provide expert-level quality if certain recommendations on experiment design and quality control are met (Snow et al. 2008). Successful examples of the use of crowdsourcing techniques for data annotation and system evaluation can be found throughout all areas of NLP (see Callison-Burch and Dredze [2010] for a recent overview). The main advantage of these techniques lies in the ability to achieve high-quality annotations at a fraction of the time and the expense of expert annotation. However, a less apparent advantage is the </context>
</contexts>
<marker>Poesio, Chamberlain, Kruschwitz, Robaldo, Ducceschi, 2013</marker>
<rawString>Poesio, Massimo, Jon Chamberlain, Udo Kruschwitz, Livio Robaldo, and Luca Ducceschi. 2013. Phrase detectives: Utilizing collective intelligence for Internet-scale language resource creation. ACM Transactions on Interactive Intelligent Systems, 3(1):Article 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Reidsma</author>
<author>Jean Carletta</author>
</authors>
<title>Reliability measurements without limits.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="18142" citStr="Reidsma and Carletta (2007)" startWordPosition="2866" endWordPosition="2869">t because they are carefully following written instructions, but because they know the purpose of the research very well–which makes it virtually impossible for others to reproduce the results on the basis of the same coding scheme .... Practices which violate the third requirement (independence) include asking the coders to discuss their judgments with each other and reach their decisions by majority vote, or to consult with each other when problems not foreseen in the coding instructions arise. Any of these practices make the resulting data unusable for measuring reproducibility. (page 575) Reidsma and Carletta (2007) and Beigman Klebanov and Beigman (2009) reach the conclusion that high inter-annotator agreement is neither sufficient nor necessary to achieve high reliability in data annotation. The problem lies in the implicit or tacit knowledge that is shared among the community of experts. This implicit knowledge is responsible for the high inter-annotator agreement, but hinders reproducibility. In a similar way, implicit knowledge of expert coders can lead to a circularity in data annotation and feature modeling. 4. Breaking the Circularity Finke (1979), in attempting to establish criteria for an empir</context>
</contexts>
<marker>Reidsma, Carletta, 2007</marker>
<rawString>Reidsma, Dennis and Jean Carletta. 2007. Reliability measurements without limits. Computational Linguistics, 34(3):319–326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deb K Roy</author>
</authors>
<title>Learning visually grounded words and syntax for a scene description task. Computer Speech and Language,</title>
<date>2002</date>
<pages>16--353</pages>
<contexts>
<context position="29605" citStr="Roy 2002" startWordPosition="4638" endWordPosition="4639">efined a criterion of T-non-theoretical grounding and exemplified how this criterion can be met by manual data annotation by using naive coders, or by embedding data annotation into a task extrinsic to the theory to be tested, or by using independently created language data that are available in the wild. Our suggestions for T-non-theoretical grounding are related to work on grounded language learning that is based on weak supervision in the form of the use of sentences in naturally occurring contexts. For example, the meaning of natural language expresssions can be grounded in visual scenes (Roy 2002; Yu and Ballard 2004; Yu and Siskind 2013) or actions in games or navigation tasks (Chen and Mooney 2008, 2011). Because of the ambiguous supervision, most such approaches work with latent representations and use unsupervised techniques in learning. Our suggestions for T-non-theoretical grounding can be used to avoid circularities in standard supervised learning. We think that this criterion should be considered a necessary condition for an empirical science, in addition to ensuring reliability of measurements. Our negligence of related issues such as validity of measurements (see Krippendorf</context>
</contexts>
<marker>Roy, 2002</marker>
<rawString>Roy, Deb K. 2002. Learning visually grounded words and syntax for a scene description task. Computer Speech and Language, 16:353–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph D Sneed</author>
</authors>
<date>1971</date>
<journal>The Logical Structure of Mathematical Physics. D. Reidel.</journal>
<contexts>
<context position="3310" citStr="Sneed (1971)" startWordPosition="484" endWordPosition="485">cl.uni-heidelberg.de. 1 http://www.dsi.unive.it/PhiMaLe2011/. doi:10.1162/COLI a 00182 © 2014 Association for Computational Linguistics Computational Linguistics Volume 40, Number 1 instances and labels is always “given.” We show that especially in cases where data are manually annotated by expert coders, a problem of circularity arises if one and the same theory of measurement is used in data annotation and in feature construction. In this article, we use insights from philosophy of science to understand this problem. We particularly point to the “problem of theoretical terms,” introduced by Sneed (1971), that shows how circularities can make empirical statements in sciences such as physics impossible. In the following, we will explain the problem of theoretical terms with the help of a miniature physical theory used in philosophy of science (Section 2). We will then exemplify this concept on examples from empirical CL (Section 3). We also make an attempt at proposing solutions to this problem by using crowdsourcing techniques, task-related annotation, or data in the wild (Section 4). 2. The Problem of Theoretical Terms in Philosophy of Science In order to characterize the logical structure o</context>
<context position="6246" citStr="Sneed (1971)" startWordPosition="952" endWordPosition="953">h exactly the same predicate is presupposed. An illustration of this concept can be given by Stegm¨uller (1986)’s miniature theory of an Archimedian Statics. Let us assume that this miniature theory is formalized by the set-theoretic predicate AS. The intended applications of the theory AS are objects a1,. .. , an that are in balance around a pivot point. The theory uses 2 The following discussion of concepts of the “structuralist” or “non-statement view of theories” is based on works by Stegm¨uller (1979, 1986) and Balzer and Moulines (1996) that are more accessible than the original book by Sneed (1971). All translations from German are by the author. 236 Riezler On the Problem of Theoretical Terms in Empirical CL two functions that measure the distance d of the objects from the pivot point, and the weight g. The central axiom of the theory states that the sum of the products d(ai)g(ai) is the same for the objects on either side of the pivot point. The theory AS can then be defined as follows: x is an AS iff there is an A, d, g such that: 1. x = (A, d, g), 2. A = {a1,...,anb 3. d : A IR, 4. g : A IR, 5. daEA:g(a)&gt;0, 6. En i=1 d(ai)g(ai) = 0. Entities that satisfy conditions (1) to (5) are ca</context>
<context position="9332" citStr="Sneed (1971)" startWordPosition="1492" endWordPosition="1493">terms such as g, we could discard the assumption that our weight-measuring procedure uses beam balance scales. Instead we could use AS-non-theoretic measuring procedures such as spring scales. The miniature theory AS would no longer contain 237 Computational Linguistics Volume 40, Number 1 AS-theoretic terms. Thus we would be able to make empirical statements of the form (2), that is, statements about certain entities being models of the theory AS. 2. In complex physical theories such as particle mechanics there are no simplified assumptions on measuring procedures that can be dropped easily. Sneed (1971) proposed the so-called Ramsey solution3 that in essence avoids AS-theoretical terms by existentially quantifying over them. Solution (1), where T-theoretical terms are measured by applications of a theory T&apos;, thus is the standard case in empirical sciences. Solution (2) is a special case where we need theory T in order to measure some terms in theory T. Gadenne (1985) argues that this case can be understood as a tentative assumption of theory T that still makes empirical testing possible.4 The important point for our discussion is that in both solutions to the problem of theoretical terms, wh</context>
</contexts>
<marker>Sneed, 1971</marker>
<rawString>Sneed, Joseph D. 1971. The Logical Structure of Mathematical Physics. D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Brendan O’Connor</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Cheap and fast—but is it good? Evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’08),</booktitle>
<pages>254--263</pages>
<location>Edinburgh.</location>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Snow, Rion, Brendan O’Connor, Daniel Jurafsky, and Andrew Y. Ng. 2008. Cheap and fast—but is it good? Evaluating non-expert annotations for natural language tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’08), pages 254–263, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sp¨arck Jones</author>
<author>Karen</author>
</authors>
<title>Towards better NLP system evaluation.</title>
<date>1994</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology (HLT’94),</booktitle>
<pages>102--107</pages>
<location>Plainsboro, NJ.</location>
<marker>Jones, Karen, 1994</marker>
<rawString>Sp¨arck Jones, Karen. 1994. Towards better NLP system evaluation. In Proceedings of the Workshop on Human Language Technology (HLT’94), pages 102–107, Plainsboro, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Stegm¨uller</author>
</authors>
<title>The Structuralist View of Theories. A Possible Analogue of the Bourbaki Programme in Physical Science.</title>
<date>1979</date>
<publisher>Springer.</publisher>
<marker>Stegm¨uller, 1979</marker>
<rawString>Stegm¨uller, Wolfgang. 1979. The Structuralist View of Theories. A Possible Analogue of the Bourbaki Programme in Physical Science. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Stegm¨uller</author>
</authors>
<title>Probleme und Resultate der Wissenschaftstheorie und Analytischen Philosophie. Band II: Theorie und Erfahrung.</title>
<date>1986</date>
<publisher>Springer.</publisher>
<marker>Stegm¨uller, 1986</marker>
<rawString>Stegm¨uller, Wolfgang. 1986. Probleme und Resultate der Wissenschaftstheorie und Analytischen Philosophie. Band II: Theorie und Erfahrung. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Massimiliano Ciaramita</author>
<author>Hugo Zaragoza</author>
</authors>
<title>Learning to rank answers on large online QA collections.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL’08),</booktitle>
<pages>719--727</pages>
<location>Columbus, OH.</location>
<marker>Surdeanu, Ciaramita, Zaragoza, 2008</marker>
<rawString>Surdeanu, Mihai, Massimiliano Ciaramita, and Hugo Zaragoza. 2008. Learning to rank answers on large online QA collections. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL’08), pages 719–727, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Dan Klein</author>
<author>Michael Collins</author>
<author>Daphne Koller</author>
<author>Christopher Manning</author>
</authors>
<title>Max-margin parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP’04),</booktitle>
<pages>1--8</pages>
<location>Barcelona.</location>
<contexts>
<context position="12605" citStr="Taskar et al. 2004" startWordPosition="2006" endWordPosition="2009">ns and auxiliary assumptions are subjected to empirical testing. That is, if our predictions are not in accordance with our theory, we can only conclude that one of our many theoretical assumptions must be wrong, but we cannot know which one, and we can always modify our system of assumptions, leading to various ways of immunity of theories (Stegm¨uller 1986). This problem arises in Solution (1) as well as in Solution (2) 238 Riezler On the Problem of Theoretical Terms in Empirical CL and F measures the compatibility of pairs (x, y), for example, in the form of a linear discriminant function (Taskar et al. 2004; Tsochantaridis et al. 2005).5 The problem of theoretical terms arises in empirical CL in cases where a single theoretical tier is used both in manual data annotation (i.e., in the assignment of labels y to patterns x via the encoding of data pairs (x, y)), and in feature construction (i.e., in the association of labels y to patterns x via features φ(x, y)). This problem can be illustrated by looking at automatic methods for data annotation. For example, information retrieval (IR) in the patent domain uses citations of patents in other patents to automatically create relevance judgments for r</context>
</contexts>
<marker>Taskar, Klein, Collins, Koller, Manning, 2004</marker>
<rawString>Taskar, Ben, Dan Klein, Michael Collins, Daphne Koller, and Christopher Manning. 2004. Max-margin parsing. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP’04), pages 1–8, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thorsten Joachims</author>
<author>Thomas Hofmann</author>
<author>Yasemin Altun</author>
</authors>
<title>Large margin methods for structured and interdependent output variables.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>5--1453</pages>
<contexts>
<context position="12634" citStr="Tsochantaridis et al. 2005" startWordPosition="2010" endWordPosition="2013">umptions are subjected to empirical testing. That is, if our predictions are not in accordance with our theory, we can only conclude that one of our many theoretical assumptions must be wrong, but we cannot know which one, and we can always modify our system of assumptions, leading to various ways of immunity of theories (Stegm¨uller 1986). This problem arises in Solution (1) as well as in Solution (2) 238 Riezler On the Problem of Theoretical Terms in Empirical CL and F measures the compatibility of pairs (x, y), for example, in the form of a linear discriminant function (Taskar et al. 2004; Tsochantaridis et al. 2005).5 The problem of theoretical terms arises in empirical CL in cases where a single theoretical tier is used both in manual data annotation (i.e., in the assignment of labels y to patterns x via the encoding of data pairs (x, y)), and in feature construction (i.e., in the association of labels y to patterns x via features φ(x, y)). This problem can be illustrated by looking at automatic methods for data annotation. For example, information retrieval (IR) in the patent domain uses citations of patents in other patents to automatically create relevance judgments for ranking (Graf and Azzopardi 20</context>
</contexts>
<marker>Tsochantaridis, Joachims, Hofmann, Altun, 2005</marker>
<rawString>Tsochantaridis, Ioannis, Thorsten Joachims, Thomas Hofmann, and Yasemin Altun. 2005. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 5:1453–1484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luis von Ahn</author>
<author>Laura Dabbish</author>
</authors>
<title>Labeling images with a computer game.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Human Factors in Computing Systems (CHI’04),</booktitle>
<pages>319--326</pages>
<location>Vienna.</location>
<marker>von Ahn, Dabbish, 2004</marker>
<rawString>von Ahn, Luis and Laura Dabbish. 2004. Labeling images with a computer game. In Proceedings of the Conference on Human Factors in Computing Systems (CHI’04), pages 319–326, Vienna.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz von Kutschera</author>
</authors>
<date>1982</date>
<booktitle>Grundfragen der Erkenntnistheorie. de Gruyter.</booktitle>
<marker>von Kutschera, 1982</marker>
<rawString>von Kutschera, Franz. 1982. Grundfragen der Erkenntnistheorie. de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrike von Luxburg</author>
<author>Robert C Williamson</author>
<author>Isabelle Guyon</author>
</authors>
<title>Clustering: Science or art?</title>
<date>2012</date>
<booktitle>In Proceedings of the ICML 2011 Workshop on Unsupervised and Transfer Learning,</booktitle>
<pages>1--12</pages>
<location>Bellevue, WA.</location>
<marker>von Luxburg, Williamson, Guyon, 2012</marker>
<rawString>von Luxburg, Ulrike, Robert C. Williamson, and Isabelle Guyon. 2012. Clustering: Science or art? In Proceedings of the ICML 2011 Workshop on Unsupervised and Transfer Learning, pages 1–12, Bellevue, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yu</author>
<author>Dana H Ballard</author>
</authors>
<title>On the integration of grounding language and learning objects.</title>
<date>2004</date>
<booktitle>In Proceedings of the 19th National Conference on Artificial Intelligence (AAAI’04),</booktitle>
<pages>488--493</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="29626" citStr="Yu and Ballard 2004" startWordPosition="4640" endWordPosition="4643">riterion of T-non-theoretical grounding and exemplified how this criterion can be met by manual data annotation by using naive coders, or by embedding data annotation into a task extrinsic to the theory to be tested, or by using independently created language data that are available in the wild. Our suggestions for T-non-theoretical grounding are related to work on grounded language learning that is based on weak supervision in the form of the use of sentences in naturally occurring contexts. For example, the meaning of natural language expresssions can be grounded in visual scenes (Roy 2002; Yu and Ballard 2004; Yu and Siskind 2013) or actions in games or navigation tasks (Chen and Mooney 2008, 2011). Because of the ambiguous supervision, most such approaches work with latent representations and use unsupervised techniques in learning. Our suggestions for T-non-theoretical grounding can be used to avoid circularities in standard supervised learning. We think that this criterion should be considered a necessary condition for an empirical science, in addition to ensuring reliability of measurements. Our negligence of related issues such as validity of measurements (see Krippendorff 1980b) shows that t</context>
</contexts>
<marker>Yu, Ballard, 2004</marker>
<rawString>Yu, Chen and Dana H. Ballard. 2004. On the integration of grounding language and learning objects. In Proceedings of the 19th National Conference on Artificial Intelligence (AAAI’04), pages 488–493, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haonan Yu</author>
<author>Jeffrey Mark Siskind</author>
</authors>
<title>Grounded language learning from video described with sentences.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13),</booktitle>
<pages>53--63</pages>
<location>Sofia.</location>
<contexts>
<context position="29648" citStr="Yu and Siskind 2013" startWordPosition="4644" endWordPosition="4647">oretical grounding and exemplified how this criterion can be met by manual data annotation by using naive coders, or by embedding data annotation into a task extrinsic to the theory to be tested, or by using independently created language data that are available in the wild. Our suggestions for T-non-theoretical grounding are related to work on grounded language learning that is based on weak supervision in the form of the use of sentences in naturally occurring contexts. For example, the meaning of natural language expresssions can be grounded in visual scenes (Roy 2002; Yu and Ballard 2004; Yu and Siskind 2013) or actions in games or navigation tasks (Chen and Mooney 2008, 2011). Because of the ambiguous supervision, most such approaches work with latent representations and use unsupervised techniques in learning. Our suggestions for T-non-theoretical grounding can be used to avoid circularities in standard supervised learning. We think that this criterion should be considered a necessary condition for an empirical science, in addition to ensuring reliability of measurements. Our negligence of related issues such as validity of measurements (see Krippendorff 1980b) shows that there is a vast methodo</context>
</contexts>
<marker>Yu, Siskind, 2013</marker>
<rawString>Yu, Haonan and Jeffrey Mark Siskind. 2013. Grounded language learning from video described with sentences. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), pages 53–63, Sofia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>