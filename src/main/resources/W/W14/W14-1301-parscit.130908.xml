<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001175">
<title confidence="0.9809665">
Mining Lexical Variants from Microblogs: An Unsupervised Multilingual
Approach
</title>
<author confidence="0.998071">
Alejandro Mosquera
</author>
<affiliation confidence="0.998137">
University of Alicante
</affiliation>
<address confidence="0.8827895">
San Vicente del Raspeig s/n - 03690
Alicante, Spain
</address>
<email confidence="0.998042">
amosquera@dlsi.ua.es
</email>
<sectionHeader confidence="0.993854" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874">
User-generated content has become a re-
current resource for NLP tools and ap-
plications, hence many efforts have been
made lately in order to handle the noise
present in short social media texts. The
use of normalisation techniques has been
proven useful for identifying and replac-
ing lexical variants on some of the most
informal genres such as microblogs. But
annotated data is needed in order to train
and evaluate these systems, which usu-
ally involves a costly process. Until now,
most of these approaches have been fo-
cused on English and they were not taking
into account demographic variables such
as the user location and gender. In this pa-
per we describe the methodology used for
automatically mining a corpus of variant
and normalisation pairs from English and
Spanish tweets.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999371941176471">
User-generated content (UGC), and specially the
microblog genre, has become an interesting re-
source for Natural Language Processing (NLP)
tools and applications. Many are the advantages
of exploiting this real-time stream of multilingual
textual data. Popular applications such as Twit-
ter has an heterogeneous user base of almost 600
million users that generate more than 60 million
new tweets every day. For this reason, Twitter
has become one of the most used sources of tex-
tual data for NLP with several applications such
as sentiment analysis (Tumasjan et al., 2010) or
realtime event detection (Sakaki et al., 2010). Re-
cent advances on machine translation or informa-
tion retrieval systems have been also making an
extensive use of UGC for both training and evalu-
ation purposes. However, tweets can be very noisy
</bodyText>
<author confidence="0.743111">
Paloma Moreda
</author>
<affiliation confidence="0.872852">
University of Alicante
</affiliation>
<address confidence="0.6953965">
San Vicente del Raspeig s/n - 03690
Alicante, Spain
</address>
<email confidence="0.940868">
moreda@dlsi.ua.es
</email>
<bodyText confidence="0.999861105263158">
and sometimes hard to understand for both hu-
mans (Mosquera et al., 2012) and NLP applica-
tions (Wang and Ng, 2013), so an additional pre-
processing step is usually required.
There have been different perceptions regard-
ing the lexical quality of social media (Rello and
Baeza-Yates, 2012) (Baldwin et al., 2013) and
even others suggested that 40% of the messages
of Twitter were “pointless babble” (PearAnalyt-
ics, 2009). Most of the out of vocabulary (OOV)
words present in social media texts can be cata-
logued as lexical variants (e.g. “See u 2moro” →
”See you tomorrow”), that are words lexically re-
lated with their canonic form.
The use of text normalisation techniques has
been proven useful in order to clean short and in-
formal texts such as tweets. However, the eval-
uation of these systems requires annotated data,
which usually involves costly human annotations.
There are previous works about automatically con-
structing normalisation dictionaries, but until now,
most of these approaches have been focused on
English and they were not taking into account de-
mographic variants. In this paper we describe the
methodology used for automatically mining lexi-
cal variants from English and Spanish tweets as-
sociated to a set of headwords. These formal and
informal pairs can be later used to train and eval-
uate existing social media text normalisation sys-
tems. Additional metadata from Twitter such as
geographic location and user gender is also col-
lected, opening the possibility to model and anal-
yse gender or location-specific variants.
This paper is organised as follows. We describe
the related work in Section 2. We then describe
our variant mining methodology in Section 3. The
obtained results are presented in Section 4. Sec-
tion 5, draws the conclusions and future work.
</bodyText>
<page confidence="0.803845">
1
</page>
<note confidence="0.8934555">
Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 1–7,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.998882" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999965788461538">
One way to handle the performance drop of NLP
tools on user-generated content (Foster et al.,
2011) is to re-train existing models on these in-
formal genres (Gimpel et al., 2011), (Liu et al.,
2011b). Another approaches make use of pre-
processing techniques such as text normalisation
in order to minimise the social media textual noise
(Han et al., 2013), (Mosquera and Moreda, 2012)
where OOV words were first identified and then
substituted using lexical and phonetic edit dis-
tances. In order to enhance both precision and
recall both OOV detection and translation dic-
tionaries were used. Moreover, the creative na-
ture of informal writing and the low availability
of manually-annotated corpora can make the im-
provement and evaluation of these systems chal-
lenging.
Motivated by the lack of annotated data and the
large amount of OOV words contained in Twitter,
several approaches for automatically construct-
ing a lexical normalisation dictionary were pro-
posed; In (Gouws et al., 2011) a normalisation
lexicon is generated based on distributional and
string similarity (Lodhi et al., 2002) from Twit-
ter. Using a similar technique, a wider-coverage
dictionary is constructed in (Han et al., 2012)
based on contextually-similar (OOV, IV) pairs.
More recently, (Hassan and Menezes, 2013) intro-
duced another context-based approach using ran-
dom walks on a contextual similarity graph.
Distributional-based methods can have some
drawbacks: they rely heavily on pairwise com-
parisons that make them computationally expen-
sive, and as the normalisation candidates are se-
lected based on context similarity they can be sen-
sitive to domain-specific variants that share similar
contexts. Moreover, these approaches were focus-
ing on extracting English lexical variants from so-
cial media texts, but due the heterogeneity of its
users, lexical distributions can be influenced by
geographical factors (Eisenstein et al., 2010) or
even gender (Thomson and Murachver, 2001).
To the best of our knowledge, there are not
multilingual approaches for mining lexical vari-
ants from short, noisy texts that also take into ac-
count demographic variables. For this reason, we
present an unsupervised method for mining En-
glish and Spanish lexical variants from Twitter that
collects demographic and contextual information.
These obtained pairs can be later used for training
and evaluating text normalisation and inverse text
normalisation systems.
</bodyText>
<sectionHeader confidence="0.981576" genericHeader="method">
3 Lexical Variant Mining
</sectionHeader>
<bodyText confidence="0.999960238095238">
Lexical variants are typically formed from their
standard forms through regular processes (Thur-
low and Brown, 2003) and these can be mod-
elled by using a set of basic character transfor-
mation rules such as letter insertion, deletion or
substitution (Liu et al., 2011a) e.g. (“tmrrw” →
“2morrow”) and combination of these (“2moro”).
The relation between formal and informal pairs is
not always 1-to-1, two different formal words can
share the same lexical variant (“t” in Spanish can
represent “te” or “t´u”) and one formal word can
have many different variants (e.g. “see you” us
commonly shortened as “c ya” or “see u”). As
a difference with previous approaches based on
contextual and distributional similarity, we have
chosen to model the generation of variant candi-
dates from a set of headwords using transforma-
tion rules. These candidates are later validated
based on their presence on a popular microblog
service, used in this case as a high-coverage cor-
pus.
</bodyText>
<subsectionHeader confidence="0.99965">
3.1 Candidate Generation
</subsectionHeader>
<bodyText confidence="0.993500333333333">
We have defined a set of 6 basic transforma-
tion rules (see Table 1) in order to automati-
cally generate candidate lexical variants from the
300k most frequent words of Web 1T 5-gram (En-
glish) (Brants and Franz, 2006) and SUBTLEX-
SP (Spanish) (Cuetos et al., 2011) corpora.
</bodyText>
<tableCaption confidence="0.996285">
Table 1: Transformation rules.
</tableCaption>
<bodyText confidence="0.990363111111111">
As modelling some variants may need more
than one basic operation, and lexically-related
variants are usually in an edit distance t where
t &lt;= 3 (Han et al., 2013), the aforementioned
rules were implemented using an engine based on
stacked transducers with the possibility to apply a
maximum of three concurrent transformations:
(a) Character duplication: For words with n
characters, while n&gt;19 each character were
</bodyText>
<figure confidence="0.9979725625">
Rule
Example
a) Character duplication
b) Number transliteration
c) Character deletion
d) Character replacement
e) Character transposition
f) Phonetic substitution
“goal” → “gooal”
“cansados” → “cansa2”
“tomorrow” → “tomrrw”
“friend” → “freend”
“maybe” → “mabye”
“coche” → “coxe”
g) Combination of above
“coche” → “coxeee”
</figure>
<page confidence="0.930002">
2
</page>
<listItem confidence="0.8009602">
duplicated n times (∀ n&gt;0, n&lt;4), generating
n3 candidate variants.
(b) Number transliteration: Words and num-
bers are transliterated following the language
rules defined in Table 2.
</listItem>
<subsectionHeader confidence="0.309786">
Rule Lang.
</subsectionHeader>
<equation confidence="0.991123764705882">
“uno” → “1” SP
“dos” → “2” SP
“one” → “1” EN
“two” → “2” EN
“to” → “2” EN
“three” → “3” EN
“for” → “4” EN
“four” → “4” EN
“eight” → “8” EN
“be” → “b” EN
“a” → “4” EN
“e” → “3” EN
“o” → “0” EN
“s” → “5” EN
“g” → “6” EN
“t” → “7” EN
“l” → “1” EN
</equation>
<tableCaption confidence="0.5027035">
Table 2: Transliteration table for English and
Spanish.
</tableCaption>
<listItem confidence="0.996340176470588">
(c) Character deletion: The candidate variants
from all possible one character deletion com-
binations plus the consonant skeleton of the
word will be generated.
(d) Character replacement: Candidate variants
are generated by replacing n characters (∀
n&gt;0, n&lt;7) by their neighbours taking into
account a QWERTY keyboard and an edit
distance of 1.
(e) Character transposition: In order to generate
candidate lexical variants the position of ad-
jacent characters are exchanged.
(f) Phonetic substitution: A maximum of three
character n-grams are substituted for char-
acters that sound similar following different
rules for Spanish (Table 3) and English (Ta-
ble 4).
</listItem>
<subsectionHeader confidence="0.999058">
3.2 Candidate Selection
</subsectionHeader>
<bodyText confidence="0.9992035">
We have explored several approaches for filtering
common typographical errors and misspellings, as
these are unintentional and can not be technically
considered lexical variants, in order to do this
we have used supervised machine learning tech-
niques. Also, with aim to filter uncommon or
</bodyText>
<figure confidence="0.993018875">
Rule
“b”→[“v“ or “w”]
“c”→[“k”]
“s”→[“z”]
“z”→[“s”]
“c”→[“s”]
“x”→[“s”]
“˜n”→[“ni”]
“ch”→[“x”]
“gu”→[“w”]
“qu”→[“k”]
“ll”→[“y”]
“ge”→[“je”]
“gi”→[“ji”]
“ll”→[“i”]
“hue”→[“we”]
</figure>
<tableCaption confidence="0.995343">
Table 3: Phonetic substitution table for Spanish.
</tableCaption>
<bodyText confidence="0.999854">
low quality variants, the Rovereto Twitter corpus
(Herdagdelen, 2013) was initially used in order
to rank the English candidates present in the cor-
pus by their frequencies. The 38% of the variants
generated by one transformation were successfully
found, however, performing direct Twitter search
API queries resulted to have better coverage than
using a static corpus (90% for English variants).
</bodyText>
<subsectionHeader confidence="0.723785">
3.2.1 Intentionality Filtering
</subsectionHeader>
<bodyText confidence="0.999959083333333">
Given an OOV word a and its IV version b we have
extracted character transformation rules from a to
b using the longest common substring (LCS) algo-
rithm (See Table 5). These lists of transformations
were encoded as a numeric array where the num-
ber each transformation counts were stored. We
have used NLTK (Bird, 2006) and the Sequence-
Matcher Python class in order to extract those sets
of transformations taking into account also the po-
sition of the character (beginning, middle or at the
end of the word).
A two-class SVM (Vapnik, 1995) model has
ben trained using a linear kernel with a corpus
composed by 4200 formal-variant pairs extracted
from Twitter 1, SMS2 and a corpus of the 4200
most common misspellings 3. In table 6 we show
the k-fold cross-validation results (k=10) of the
model, obtaining a 87% F1. This model has been
used in order to filter the English candidate vari-
ants classified as not-intentional.
To the best of our knowledge there are not simi-
lar annotated resources for Spanish, so this clas-
sifier was developed only for English variants.
However, would be possible to adapt it to work for
</bodyText>
<footnote confidence="0.999803666666667">
1http : //ww2.cs.mu.oz.au/ hanb/emnlp.tgz
2http : //www.cel.iitkgp.ernet.in/ monojit/sms
3http : //aspell.net/test/common − all/
</footnote>
<page confidence="0.994497">
3
</page>
<figure confidence="0.9970977">
Rule
”i”→[“e”]
“o”→[“a”]
“u”→[“o”]
“s”→[“z”]
“f”→[“ph”]
“j”→[“ge” or “g”]
“n”→[“kn” or “gn”]
“r”→[“wr”]
“z”→[“se” or “s”]
“ea”→[“e”]
“ex”→[“x”]
“ae”→[“ay” or “ai” or “a”]
“ee”→[“ea” or “ie” or “e”]
“ie”→[“igh” or “y” or “i”]
“oe”→[“oa” or “ow” or “o”]
“oo”→[“ou” or “u”]
“ar”→[“a”]
“ur”→[“ir” or “er” or “ear” or “or”]
“or”→[“oor” or “ar”]
“au”→[“aw” or “a”]
“er”→[“e”]
“ow”→[“ou”]
“oi”→[“oy”]
“sh”→[“ss” or “ch”]
“ex”→[“x”]
“sh”→[“ss” or “ch”]
“ng”→[“n”]
“air”→[“ear” or “are”]
“ear”→[“eer” or “ere”]
</figure>
<tableCaption confidence="0.979021">
Table 4: Phonetic substitution table for English.
</tableCaption>
<bodyText confidence="0.999936285714286">
another languages if the adequate corpora is pro-
vided. Because of the lack of this intentionality
detection step, the number of generated candidate
variants for Spanish was filtered by taking into ac-
count the number of transformations, removing all
the variants generated by more than two opera-
tions.
</bodyText>
<subsubsectionHeader confidence="0.491436">
3.2.2 Twitter Search
</subsubsectionHeader>
<bodyText confidence="0.998397058823529">
The variants filtered during the previous step were
searched on the real time Twitter stream for a pe-
riod of two months by processing more than 7.5
million tweets. Their absolute frequencies n were
used as a weighting factor in order to discard not
used words (n &gt; 0). Additionally, variants present
in another languages rather than English or Span-
ish were ignored by using the language identifica-
tion tags present in Twitter metadata.
There were important differences between the
final number of selected candidates for Spanish,
with 6 times less variant pairs and English (see Ta-
ble 7). Spanish language uses diacritics that are
commonly ignored on informal writing, for this
reason there is a higher number of possible com-
binations for candidate words that would not gen-
erate valid or used lexical variants.
</bodyText>
<table confidence="0.9995669">
Formal/Informal pair Transf. Pos.
house → h0use o → 0 middle
campaign → campaing n → ∅ end
∅ → n middle
happy → :) happy → :) middle
embarrass → embarass r→ ∅ middle
acquaintance → ∅ → q middle
aqcuaintance q → ∅ middle
virtually → virtualy l→ ∅ middle
cats → catz s→ z end
</table>
<tableCaption confidence="0.981112">
Table 5: Example of formal/informal pairs and the
extract transformations.
</tableCaption>
<table confidence="0.999939909090909">
Method Precision Recall F1
SVM 0.831 0.824 0.827
SVM+Pos. 0.878 0.874 0.876
Formal/Informal pair Verdict
you → yu intentional
accommodate → acommodate unintentional
business → bussiness unintentional
doing → doin intentional
acquaintance → aqcuaintance unintentional
basically → basicly unintentional
rules → rulez intentional
</table>
<tableCaption confidence="0.9681045">
Table 6: Cross-validation results of intentionality
classification with examples.
</tableCaption>
<sectionHeader confidence="0.999457" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.9998674375">
Besides the original message and the context of
the searched variant, additional metadata has been
collected from each tweet such as the gender and
the location of the user. In Twitter the gender is not
explicitly available, for this reason we applied an
heuristic approach based on the first name as it is
reported in the user profile. In order to do this, two
list of male and female names were used: the 1990
US census data 4 and popular baby names from
the US Social Security Administration’s statistics
between 1960 and 2010 5.
We have analysed the gender and language dis-
tribution of the 6 transformation rules across the
mined pairs (see Figure 1). On the one hand, lex-
ical variants generated by duplicating characters
were the most popular specially between female
</bodyText>
<footnote confidence="0.9971025">
4census.gov/genealogy/www/data/1990surnames
5ssa.gov/cgi − bin/popularnames.cgi
</footnote>
<page confidence="0.986203">
4
</page>
<table confidence="0.585694666666667">
Candidates Selected Lang.
2456627 48550 EN
1374078 8647 SP
</table>
<tableCaption confidence="0.9706305">
Table 7: Number of generated and selected vari-
ants after Twitter search.
</tableCaption>
<figureCaption confidence="0.998671">
Figure 1: Transformation trends by gender.
</figureCaption>
<bodyText confidence="0.999964448275862">
users with a 5% more than their male counter-
parts. On the other hand, variants generated by
character replacement and deletion were found a
2% more on tweets from male users. The differ-
ences between English and Spanish were notable,
mostly regarding the use of transliterations, that
were not found on Spanish tweets, and phonetic
substitutions, ten times less frequent than in En-
glish tweets.
For the distribution of transformations across
geographic areas, we have just taken into account
the countries where the analysed languages have
an official status. Lexical variants found in Tweets
from another areas are grouped into the “Non-
official” label (see Figure 2). The biggest dif-
ferences were found on the use of translitera-
tions (higher in UK and Ireland with more than
a 5%) and phonetic substitutions (higher in Pak-
istani users with more than a 22%). Transforma-
tion frequencies from non-official English speak-
ing countries were very similar as the ones regis-
tered for users based on United States and Canada.
Spanish results were less uniform and showed
more variance respect the use of character dupli-
cation (57% in Argentina), character replacement
(more than 24% in Mexico and Guatemala) and
character transposition (with more than a 19% for
users from Cuba, Colombia and Mexico) (see Fig-
ure 3).
</bodyText>
<sectionHeader confidence="0.977785" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999478058823529">
In this paper we have described a multilingual
and unsupervised method for mining English and
Spanish lexical variants from Twitter with aim to
close the gap regarding the lack of annotated cor-
pora. These obtained pairs can be later used for
the training and evaluation of text normalisation
systems without the need of costly human anno-
tations. Furthermore, the gathered demographic
and contextual information can be used in order to
model and generate variants similar to those that
can be found on specific geographic areas. This
has interesting applications in the field of inverse
text normalisation, that are left to a future work.
We also intend to explore the benefits of feature
engineering for the detection and categorisation
of lexical variants using machine learning tech-
niques.
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999920533333333">
This research is partially funded by the Eu-
ropean Commission under the Seventh (FP7 -
2007- 2013) Framework Programme for Re-
search and Technological Development through
the FIRST project (FP7-287607). This pub-
lication reflects the views only of the author,
and the Commission cannot be held responsi-
ble for any use which may be made of the in-
formation contained therein. Moreover, it has
been partially funded by the Spanish Govern-
ment through the project “An´alisis de Tenden-
cias Mediante T´ecnicas de Opini´on Sem´antica”
(TIN2012-38536-C03-03) and “T´ecnicas de De-
construcci´on en la Tecnologias del Lenguaje Hu-
mano” (TIN2012-31224).
</bodyText>
<sectionHeader confidence="0.998289" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994512">
Timothy Baldwin, Paul Cook, Marco Lui, Andrew
MacKinlay, and Li Wang. 2013. How noisy social
media text, how diffrnt social media sources. In Pro-
ceedings of the Sixth International Joint Conference
on Natural Language Processing, pages 356–364.
Steven Bird. 2006. Nltk: the natural language
toolkit. In Proceedings of the COLING/ACL on In-
teractive presentation sessions, COLING-ACL ’06,
pages 69–72, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-
gram corpus version 1. Technical report, Google
Research.
</reference>
<page confidence="0.99156">
5
</page>
<figureCaption confidence="0.9999845">
Figure 2: Transformation trends by English-speaking countries.
Figure 3: Transformation trends by Spanish-speaking countries.
</figureCaption>
<reference confidence="0.960078490566038">
Fernando Cuetos, Maria Glez-Nosti, Anala Barbn, and
Marc Brysbaert. 2011. Subtlex-esp: Spanish word
frequencies based on film subtitles. Psicolgica,
32(2).
Jacob Eisenstein, Brendan O’Connor, Noah A. Smith,
and Eric P. Xing. 2010. A latent variable model
for geographic lexical variation. In Proceedings of
the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP ’10, pages 1277–
1287, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Jennifer Foster, ¨Ozlem C¸etinoglu, Joachim Wagner,
Joseph Le Roux, Stephen Hogan, Joakim Nivre,
Deirdre Hogan, and Josef van Genabith. 2011.
#hardtoparse: Pos tagging and parsing the twitter-
verse. In Analyzing Microtext, volume WS-11-05 of
AAAI Workshops. AAAI.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: annotation, features, and experiments.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies: short papers - Volume 2,
HLT ’11, pages 42–47, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
S. Gouws, D. Hovy, and D. Metzler. 2011. Unsuper-
vised mining of lexical variants from noisy text. In
Proceedings of the First workshop on Unsupervised
Learning in NLP, page 82–90.
Bo Han, Paul Cook, and Timothy Baldwin. 2012. Au-
tomatically constructing a normalisation dictionary
for microblogs. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL 2012), pages 421–
432, Jeju Island, Korea.
Bo Han, Paul Cook, and Timothy Baldwin. 2013. Lex-
ical normalization for social media text. ACM Trans.
Intell. Syst. Technol., 4(1):5:1–5:27, February.
Hany Hassan and Arul Menezes. 2013. Social text
normalization using contextual graph random walks.
In Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1577–1586, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Ama Herdagdelen. 2013. Twitter n-gram corpus with
demographic metadata. Language Resources and
Evaluation, 47(4):1127–1147.
Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu.
2011a. Insertion, deletion, or substitution?: Nor-
malizing text messages without pre-categorization
</reference>
<page confidence="0.984401">
6
</page>
<reference confidence="0.999595403508772">
nor supervision. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies: Short Pa-
pers - Volume 2, HLT ’11, pages 71–76, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Xiaohua Liu, Shaodian Zhang, Furu Wei, and Ming
Zhou. 2011b. Recognizing named entities in tweets.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies - Volume 1, HLT ’11, pages
359–367, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Huma Lodhi, Craig Saunders, John Shawe-Taylor,
Nello Cristianini, and Chris Watkins. 2002. Text
classification using string kernels. J. Mach. Learn.
Res., 2:419–444, March.
Alejandro Mosquera and Paloma Moreda. 2012.
Tenor: A lexical normalisation tool for spanish web
2.0 texts. In Text, Speech and Dialogue - 15th Inter-
national Conference (TSD 2012). Springer.
Alejandro Mosquera, Elena Lloret, and Paloma
Moreda. 2012. Towards facilitating the accessibil-
ity of web 2.0 texts through text normalisation. In
Proceedings of the LREC workshop: Natural Lan-
guage Processing for Improving Textual Accessibil-
ity (NLP4ITA) ; Istanbul, Turkey., pages 9–14.
PearAnalytics. 2009. Twitter study. In Retrieved De-
cember 15, 2009 from http://pearanalytics.com/wp-
content/uploads/2009/08/Twitter-Study-August-
2009.pdf.
Luz Rello and Ricardo A Baeza-Yates. 2012. Social
media is not that bad! the lexical quality of social
media. In ICWSM.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes twitter users: Real-time
event detection by social sensors. In Proceedings
of the 19th International Conference on World Wide
Web, WWW ’10, pages 851–860, New York, NY,
USA. ACM.
Robert Thomson and Tamar Murachver. 2001. Pre-
dicting gender from electronic discourse.
Thurlow and Brown. 2003. Generation txt? the soci-
olinguistics of young people’s text-messaging.
A. Tumasjan, T.O. Sprenger, P.G. Sandner, and I.M.
Welpe. 2010. Predicting elections with twitter:
What 140 characters reveal about political senti-
ment. In Proceedings of the Fourth International
AAAI Conference on Weblogs and Social Media,
pages 178–185.
Vladimir N. Vapnik. 1995. The nature of statistical
learning theory. Springer-Verlag New York, Inc.,
New York, NY, USA.
Pidong Wang and Hwee Tou Ng. 2013. A beam-search
decoder for normalization of social media text with
application to machine translation. In HLT-NAACL,
pages 471–481.
</reference>
<page confidence="0.999517">
7
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.612864">
<title confidence="0.9973905">Mining Lexical Variants from Microblogs: An Unsupervised Multilingual Approach</title>
<author confidence="0.997524">Alejandro</author>
<affiliation confidence="0.9811">University of San Vicente del Raspeig s/n -</affiliation>
<address confidence="0.846121">Alicante,</address>
<email confidence="0.994674">amosquera@dlsi.ua.es</email>
<abstract confidence="0.988392571428572">User-generated content has become a recurrent resource for NLP tools and applications, hence many efforts have been made lately in order to handle the noise present in short social media texts. The use of normalisation techniques has been proven useful for identifying and replacing lexical variants on some of the most informal genres such as microblogs. But annotated data is needed in order to train and evaluate these systems, which usually involves a costly process. Until now, most of these approaches have been focused on English and they were not taking into account demographic variables such as the user location and gender. In this paper we describe the methodology used for automatically mining a corpus of variant and normalisation pairs from English and Spanish tweets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Paul Cook</author>
<author>Marco Lui</author>
<author>Andrew MacKinlay</author>
<author>Li Wang</author>
</authors>
<title>How noisy social media text, how diffrnt social media sources.</title>
<date>2013</date>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>356--364</pages>
<contexts>
<context position="2234" citStr="Baldwin et al., 2013" startWordPosition="351" endWordPosition="354">l., 2010). Recent advances on machine translation or information retrieval systems have been also making an extensive use of UGC for both training and evaluation purposes. However, tweets can be very noisy Paloma Moreda University of Alicante San Vicente del Raspeig s/n - 03690 Alicante, Spain moreda@dlsi.ua.es and sometimes hard to understand for both humans (Mosquera et al., 2012) and NLP applications (Wang and Ng, 2013), so an additional preprocessing step is usually required. There have been different perceptions regarding the lexical quality of social media (Rello and Baeza-Yates, 2012) (Baldwin et al., 2013) and even others suggested that 40% of the messages of Twitter were “pointless babble” (PearAnalytics, 2009). Most of the out of vocabulary (OOV) words present in social media texts can be catalogued as lexical variants (e.g. “See u 2moro” → ”See you tomorrow”), that are words lexically related with their canonic form. The use of text normalisation techniques has been proven useful in order to clean short and informal texts such as tweets. However, the evaluation of these systems requires annotated data, which usually involves costly human annotations. There are previous works about automatica</context>
</contexts>
<marker>Baldwin, Cook, Lui, MacKinlay, Wang, 2013</marker>
<rawString>Timothy Baldwin, Paul Cook, Marco Lui, Andrew MacKinlay, and Li Wang. 2013. How noisy social media text, how diffrnt social media sources. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 356–364.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
</authors>
<title>Nltk: the natural language toolkit.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Interactive presentation sessions, COLING-ACL ’06,</booktitle>
<pages>69--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10815" citStr="Bird, 2006" startWordPosition="1720" endWordPosition="1721">nt in the corpus by their frequencies. The 38% of the variants generated by one transformation were successfully found, however, performing direct Twitter search API queries resulted to have better coverage than using a static corpus (90% for English variants). 3.2.1 Intentionality Filtering Given an OOV word a and its IV version b we have extracted character transformation rules from a to b using the longest common substring (LCS) algorithm (See Table 5). These lists of transformations were encoded as a numeric array where the number each transformation counts were stored. We have used NLTK (Bird, 2006) and the SequenceMatcher Python class in order to extract those sets of transformations taking into account also the position of the character (beginning, middle or at the end of the word). A two-class SVM (Vapnik, 1995) model has ben trained using a linear kernel with a corpus composed by 4200 formal-variant pairs extracted from Twitter 1, SMS2 and a corpus of the 4200 most common misspellings 3. In table 6 we show the k-fold cross-validation results (k=10) of the model, obtaining a 87% F1. This model has been used in order to filter the English candidate variants classified as not-intentiona</context>
</contexts>
<marker>Bird, 2006</marker>
<rawString>Steven Bird. 2006. Nltk: the natural language toolkit. In Proceedings of the COLING/ACL on Interactive presentation sessions, COLING-ACL ’06, pages 69–72, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram corpus version 1.</title>
<date>2006</date>
<tech>Technical report, Google Research.</tech>
<contexts>
<context position="7555" citStr="Brants and Franz, 2006" startWordPosition="1198" endWordPosition="1201">mmonly shortened as “c ya” or “see u”). As a difference with previous approaches based on contextual and distributional similarity, we have chosen to model the generation of variant candidates from a set of headwords using transformation rules. These candidates are later validated based on their presence on a popular microblog service, used in this case as a high-coverage corpus. 3.1 Candidate Generation We have defined a set of 6 basic transformation rules (see Table 1) in order to automatically generate candidate lexical variants from the 300k most frequent words of Web 1T 5-gram (English) (Brants and Franz, 2006) and SUBTLEXSP (Spanish) (Cuetos et al., 2011) corpora. Table 1: Transformation rules. As modelling some variants may need more than one basic operation, and lexically-related variants are usually in an edit distance t where t &lt;= 3 (Han et al., 2013), the aforementioned rules were implemented using an engine based on stacked transducers with the possibility to apply a maximum of three concurrent transformations: (a) Character duplication: For words with n characters, while n&gt;19 each character were Rule Example a) Character duplication b) Number transliteration c) Character deletion d) Characte</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram corpus version 1. Technical report, Google Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Cuetos</author>
<author>Maria Glez-Nosti</author>
<author>Anala Barbn</author>
<author>Marc Brysbaert</author>
</authors>
<title>Subtlex-esp: Spanish word frequencies based on film subtitles.</title>
<date>2011</date>
<journal>Psicolgica,</journal>
<volume>32</volume>
<issue>2</issue>
<contexts>
<context position="7601" citStr="Cuetos et al., 2011" startWordPosition="1206" endWordPosition="1209">erence with previous approaches based on contextual and distributional similarity, we have chosen to model the generation of variant candidates from a set of headwords using transformation rules. These candidates are later validated based on their presence on a popular microblog service, used in this case as a high-coverage corpus. 3.1 Candidate Generation We have defined a set of 6 basic transformation rules (see Table 1) in order to automatically generate candidate lexical variants from the 300k most frequent words of Web 1T 5-gram (English) (Brants and Franz, 2006) and SUBTLEXSP (Spanish) (Cuetos et al., 2011) corpora. Table 1: Transformation rules. As modelling some variants may need more than one basic operation, and lexically-related variants are usually in an edit distance t where t &lt;= 3 (Han et al., 2013), the aforementioned rules were implemented using an engine based on stacked transducers with the possibility to apply a maximum of three concurrent transformations: (a) Character duplication: For words with n characters, while n&gt;19 each character were Rule Example a) Character duplication b) Number transliteration c) Character deletion d) Character replacement e) Character transposition f) Ph</context>
</contexts>
<marker>Cuetos, Glez-Nosti, Barbn, Brysbaert, 2011</marker>
<rawString>Fernando Cuetos, Maria Glez-Nosti, Anala Barbn, and Marc Brysbaert. 2011. Subtlex-esp: Spanish word frequencies based on film subtitles. Psicolgica, 32(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>A latent variable model for geographic lexical variation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>1277--1287</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Jacob Eisenstein, Brendan O’Connor, Noah A. Smith, and Eric P. Xing. 2010. A latent variable model for geographic lexical variation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 1277– 1287, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Foster</author>
<author>¨Ozlem C¸etinoglu</author>
<author>Joachim Wagner</author>
<author>Joseph Le Roux</author>
<author>Stephen Hogan</author>
<author>Joakim Nivre</author>
<author>Deirdre Hogan</author>
<author>Josef van Genabith</author>
</authors>
<title>hardtoparse: Pos tagging and parsing the twitterverse. In Analyzing Microtext, volume WS-11-05 of AAAI Workshops.</title>
<date>2011</date>
<publisher>AAAI.</publisher>
<marker>Foster, C¸etinoglu, Wagner, Le Roux, Hogan, Nivre, Hogan, van Genabith, 2011</marker>
<rawString>Jennifer Foster, ¨Ozlem C¸etinoglu, Joachim Wagner, Joseph Le Roux, Stephen Hogan, Joakim Nivre, Deirdre Hogan, and Josef van Genabith. 2011. #hardtoparse: Pos tagging and parsing the twitterverse. In Analyzing Microtext, volume WS-11-05 of AAAI Workshops. AAAI.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>42--47</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 42–47, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gouws</author>
<author>D Hovy</author>
<author>D Metzler</author>
</authors>
<title>Unsupervised mining of lexical variants from noisy text.</title>
<date>2011</date>
<booktitle>In Proceedings of the First workshop on Unsupervised Learning in NLP,</booktitle>
<pages>82--90</pages>
<contexts>
<context position="4893" citStr="Gouws et al., 2011" startWordPosition="781" endWordPosition="784">and Moreda, 2012) where OOV words were first identified and then substituted using lexical and phonetic edit distances. In order to enhance both precision and recall both OOV detection and translation dictionaries were used. Moreover, the creative nature of informal writing and the low availability of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annotated data and the large amount of OOV words contained in Twitter, several approaches for automatically constructing a lexical normalisation dictionary were proposed; In (Gouws et al., 2011) a normalisation lexicon is generated based on distributional and string similarity (Lodhi et al., 2002) from Twitter. Using a similar technique, a wider-coverage dictionary is constructed in (Han et al., 2012) based on contextually-similar (OOV, IV) pairs. More recently, (Hassan and Menezes, 2013) introduced another context-based approach using random walks on a contextual similarity graph. Distributional-based methods can have some drawbacks: they rely heavily on pairwise comparisons that make them computationally expensive, and as the normalisation candidates are selected based on context s</context>
</contexts>
<marker>Gouws, Hovy, Metzler, 2011</marker>
<rawString>S. Gouws, D. Hovy, and D. Metzler. 2011. Unsupervised mining of lexical variants from noisy text. In Proceedings of the First workshop on Unsupervised Learning in NLP, page 82–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatically constructing a normalisation dictionary for microblogs.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>421--432</pages>
<location>Jeju Island,</location>
<contexts>
<context position="5103" citStr="Han et al., 2012" startWordPosition="813" endWordPosition="816">s were used. Moreover, the creative nature of informal writing and the low availability of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annotated data and the large amount of OOV words contained in Twitter, several approaches for automatically constructing a lexical normalisation dictionary were proposed; In (Gouws et al., 2011) a normalisation lexicon is generated based on distributional and string similarity (Lodhi et al., 2002) from Twitter. Using a similar technique, a wider-coverage dictionary is constructed in (Han et al., 2012) based on contextually-similar (OOV, IV) pairs. More recently, (Hassan and Menezes, 2013) introduced another context-based approach using random walks on a contextual similarity graph. Distributional-based methods can have some drawbacks: they rely heavily on pairwise comparisons that make them computationally expensive, and as the normalisation candidates are selected based on context similarity they can be sensitive to domain-specific variants that share similar contexts. Moreover, these approaches were focusing on extracting English lexical variants from social media texts, but due the hete</context>
</contexts>
<marker>Han, Cook, Baldwin, 2012</marker>
<rawString>Bo Han, Paul Cook, and Timothy Baldwin. 2012. Automatically constructing a normalisation dictionary for microblogs. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012), pages 421– 432, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalization for social media text.</title>
<date>2013</date>
<journal>ACM Trans. Intell. Syst. Technol.,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="4262" citStr="Han et al., 2013" startWordPosition="682" endWordPosition="685">ction 4. Section 5, draws the conclusions and future work. 1 Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 1–7, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work One way to handle the performance drop of NLP tools on user-generated content (Foster et al., 2011) is to re-train existing models on these informal genres (Gimpel et al., 2011), (Liu et al., 2011b). Another approaches make use of preprocessing techniques such as text normalisation in order to minimise the social media textual noise (Han et al., 2013), (Mosquera and Moreda, 2012) where OOV words were first identified and then substituted using lexical and phonetic edit distances. In order to enhance both precision and recall both OOV detection and translation dictionaries were used. Moreover, the creative nature of informal writing and the low availability of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annotated data and the large amount of OOV words contained in Twitter, several approaches for automatically constructing a lexical normalisation dictionary were pr</context>
<context position="7805" citStr="Han et al., 2013" startWordPosition="1240" endWordPosition="1243">dates are later validated based on their presence on a popular microblog service, used in this case as a high-coverage corpus. 3.1 Candidate Generation We have defined a set of 6 basic transformation rules (see Table 1) in order to automatically generate candidate lexical variants from the 300k most frequent words of Web 1T 5-gram (English) (Brants and Franz, 2006) and SUBTLEXSP (Spanish) (Cuetos et al., 2011) corpora. Table 1: Transformation rules. As modelling some variants may need more than one basic operation, and lexically-related variants are usually in an edit distance t where t &lt;= 3 (Han et al., 2013), the aforementioned rules were implemented using an engine based on stacked transducers with the possibility to apply a maximum of three concurrent transformations: (a) Character duplication: For words with n characters, while n&gt;19 each character were Rule Example a) Character duplication b) Number transliteration c) Character deletion d) Character replacement e) Character transposition f) Phonetic substitution “goal” → “gooal” “cansados” → “cansa2” “tomorrow” → “tomrrw” “friend” → “freend” “maybe” → “mabye” “coche” → “coxe” g) Combination of above “coche” → “coxeee” 2 duplicated n times (∀ n</context>
</contexts>
<marker>Han, Cook, Baldwin, 2013</marker>
<rawString>Bo Han, Paul Cook, and Timothy Baldwin. 2013. Lexical normalization for social media text. ACM Trans. Intell. Syst. Technol., 4(1):5:1–5:27, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hany Hassan</author>
<author>Arul Menezes</author>
</authors>
<title>Social text normalization using contextual graph random walks.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1577--1586</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="5192" citStr="Hassan and Menezes, 2013" startWordPosition="825" endWordPosition="828">bility of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annotated data and the large amount of OOV words contained in Twitter, several approaches for automatically constructing a lexical normalisation dictionary were proposed; In (Gouws et al., 2011) a normalisation lexicon is generated based on distributional and string similarity (Lodhi et al., 2002) from Twitter. Using a similar technique, a wider-coverage dictionary is constructed in (Han et al., 2012) based on contextually-similar (OOV, IV) pairs. More recently, (Hassan and Menezes, 2013) introduced another context-based approach using random walks on a contextual similarity graph. Distributional-based methods can have some drawbacks: they rely heavily on pairwise comparisons that make them computationally expensive, and as the normalisation candidates are selected based on context similarity they can be sensitive to domain-specific variants that share similar contexts. Moreover, these approaches were focusing on extracting English lexical variants from social media texts, but due the heterogeneity of its users, lexical distributions can be influenced by geographical factors (</context>
</contexts>
<marker>Hassan, Menezes, 2013</marker>
<rawString>Hany Hassan and Arul Menezes. 2013. Social text normalization using contextual graph random walks. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1577–1586, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ama Herdagdelen</author>
</authors>
<title>Twitter n-gram corpus with demographic metadata.</title>
<date>2013</date>
<journal>Language Resources and Evaluation,</journal>
<volume>47</volume>
<issue>4</issue>
<contexts>
<context position="10139" citStr="Herdagdelen, 2013" startWordPosition="1610" endWordPosition="1611">Table 4). 3.2 Candidate Selection We have explored several approaches for filtering common typographical errors and misspellings, as these are unintentional and can not be technically considered lexical variants, in order to do this we have used supervised machine learning techniques. Also, with aim to filter uncommon or Rule “b”→[“v“ or “w”] “c”→[“k”] “s”→[“z”] “z”→[“s”] “c”→[“s”] “x”→[“s”] “˜n”→[“ni”] “ch”→[“x”] “gu”→[“w”] “qu”→[“k”] “ll”→[“y”] “ge”→[“je”] “gi”→[“ji”] “ll”→[“i”] “hue”→[“we”] Table 3: Phonetic substitution table for Spanish. low quality variants, the Rovereto Twitter corpus (Herdagdelen, 2013) was initially used in order to rank the English candidates present in the corpus by their frequencies. The 38% of the variants generated by one transformation were successfully found, however, performing direct Twitter search API queries resulted to have better coverage than using a static corpus (90% for English variants). 3.2.1 Intentionality Filtering Given an OOV word a and its IV version b we have extracted character transformation rules from a to b using the longest common substring (LCS) algorithm (See Table 5). These lists of transformations were encoded as a numeric array where the n</context>
</contexts>
<marker>Herdagdelen, 2013</marker>
<rawString>Ama Herdagdelen. 2013. Twitter n-gram corpus with demographic metadata. Language Resources and Evaluation, 47(4):1127–1147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Fuliang Weng</author>
<author>Bingqing Wang</author>
<author>Yang Liu</author>
</authors>
<title>Insertion, deletion, or substitution?: Normalizing text messages without pre-categorization nor supervision.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11,</booktitle>
<pages>71--76</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4105" citStr="Liu et al., 2011" startWordPosition="657" endWordPosition="660">s follows. We describe the related work in Section 2. We then describe our variant mining methodology in Section 3. The obtained results are presented in Section 4. Section 5, draws the conclusions and future work. 1 Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 1–7, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work One way to handle the performance drop of NLP tools on user-generated content (Foster et al., 2011) is to re-train existing models on these informal genres (Gimpel et al., 2011), (Liu et al., 2011b). Another approaches make use of preprocessing techniques such as text normalisation in order to minimise the social media textual noise (Han et al., 2013), (Mosquera and Moreda, 2012) where OOV words were first identified and then substituted using lexical and phonetic edit distances. In order to enhance both precision and recall both OOV detection and translation dictionaries were used. Moreover, the creative nature of informal writing and the low availability of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annota</context>
<context position="6616" citStr="Liu et al., 2011" startWordPosition="1042" endWordPosition="1045">to account demographic variables. For this reason, we present an unsupervised method for mining English and Spanish lexical variants from Twitter that collects demographic and contextual information. These obtained pairs can be later used for training and evaluating text normalisation and inverse text normalisation systems. 3 Lexical Variant Mining Lexical variants are typically formed from their standard forms through regular processes (Thurlow and Brown, 2003) and these can be modelled by using a set of basic character transformation rules such as letter insertion, deletion or substitution (Liu et al., 2011a) e.g. (“tmrrw” → “2morrow”) and combination of these (“2moro”). The relation between formal and informal pairs is not always 1-to-1, two different formal words can share the same lexical variant (“t” in Spanish can represent “te” or “t´u”) and one formal word can have many different variants (e.g. “see you” us commonly shortened as “c ya” or “see u”). As a difference with previous approaches based on contextual and distributional similarity, we have chosen to model the generation of variant candidates from a set of headwords using transformation rules. These candidates are later validated ba</context>
</contexts>
<marker>Liu, Weng, Wang, Liu, 2011</marker>
<rawString>Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu. 2011a. Insertion, deletion, or substitution?: Normalizing text messages without pre-categorization nor supervision. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11, pages 71–76, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Shaodian Zhang</author>
<author>Furu Wei</author>
<author>Ming Zhou</author>
</authors>
<title>Recognizing named entities in tweets.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>359--367</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4105" citStr="Liu et al., 2011" startWordPosition="657" endWordPosition="660">s follows. We describe the related work in Section 2. We then describe our variant mining methodology in Section 3. The obtained results are presented in Section 4. Section 5, draws the conclusions and future work. 1 Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 1–7, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work One way to handle the performance drop of NLP tools on user-generated content (Foster et al., 2011) is to re-train existing models on these informal genres (Gimpel et al., 2011), (Liu et al., 2011b). Another approaches make use of preprocessing techniques such as text normalisation in order to minimise the social media textual noise (Han et al., 2013), (Mosquera and Moreda, 2012) where OOV words were first identified and then substituted using lexical and phonetic edit distances. In order to enhance both precision and recall both OOV detection and translation dictionaries were used. Moreover, the creative nature of informal writing and the low availability of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annota</context>
<context position="6616" citStr="Liu et al., 2011" startWordPosition="1042" endWordPosition="1045">to account demographic variables. For this reason, we present an unsupervised method for mining English and Spanish lexical variants from Twitter that collects demographic and contextual information. These obtained pairs can be later used for training and evaluating text normalisation and inverse text normalisation systems. 3 Lexical Variant Mining Lexical variants are typically formed from their standard forms through regular processes (Thurlow and Brown, 2003) and these can be modelled by using a set of basic character transformation rules such as letter insertion, deletion or substitution (Liu et al., 2011a) e.g. (“tmrrw” → “2morrow”) and combination of these (“2moro”). The relation between formal and informal pairs is not always 1-to-1, two different formal words can share the same lexical variant (“t” in Spanish can represent “te” or “t´u”) and one formal word can have many different variants (e.g. “see you” us commonly shortened as “c ya” or “see u”). As a difference with previous approaches based on contextual and distributional similarity, we have chosen to model the generation of variant candidates from a set of headwords using transformation rules. These candidates are later validated ba</context>
</contexts>
<marker>Liu, Zhang, Wei, Zhou, 2011</marker>
<rawString>Xiaohua Liu, Shaodian Zhang, Furu Wei, and Ming Zhou. 2011b. Recognizing named entities in tweets. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 359–367, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huma Lodhi</author>
<author>Craig Saunders</author>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
<author>Chris Watkins</author>
</authors>
<title>Text classification using string kernels.</title>
<date>2002</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>2--419</pages>
<contexts>
<context position="4997" citStr="Lodhi et al., 2002" startWordPosition="796" endWordPosition="799">edit distances. In order to enhance both precision and recall both OOV detection and translation dictionaries were used. Moreover, the creative nature of informal writing and the low availability of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annotated data and the large amount of OOV words contained in Twitter, several approaches for automatically constructing a lexical normalisation dictionary were proposed; In (Gouws et al., 2011) a normalisation lexicon is generated based on distributional and string similarity (Lodhi et al., 2002) from Twitter. Using a similar technique, a wider-coverage dictionary is constructed in (Han et al., 2012) based on contextually-similar (OOV, IV) pairs. More recently, (Hassan and Menezes, 2013) introduced another context-based approach using random walks on a contextual similarity graph. Distributional-based methods can have some drawbacks: they rely heavily on pairwise comparisons that make them computationally expensive, and as the normalisation candidates are selected based on context similarity they can be sensitive to domain-specific variants that share similar contexts. Moreover, these</context>
</contexts>
<marker>Lodhi, Saunders, Shawe-Taylor, Cristianini, Watkins, 2002</marker>
<rawString>Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Chris Watkins. 2002. Text classification using string kernels. J. Mach. Learn. Res., 2:419–444, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alejandro Mosquera</author>
<author>Paloma Moreda</author>
</authors>
<title>Tenor: A lexical normalisation tool for spanish web 2.0 texts.</title>
<date>2012</date>
<booktitle>In Text, Speech and Dialogue - 15th International Conference (TSD</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="4291" citStr="Mosquera and Moreda, 2012" startWordPosition="686" endWordPosition="689">draws the conclusions and future work. 1 Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 1–7, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work One way to handle the performance drop of NLP tools on user-generated content (Foster et al., 2011) is to re-train existing models on these informal genres (Gimpel et al., 2011), (Liu et al., 2011b). Another approaches make use of preprocessing techniques such as text normalisation in order to minimise the social media textual noise (Han et al., 2013), (Mosquera and Moreda, 2012) where OOV words were first identified and then substituted using lexical and phonetic edit distances. In order to enhance both precision and recall both OOV detection and translation dictionaries were used. Moreover, the creative nature of informal writing and the low availability of manually-annotated corpora can make the improvement and evaluation of these systems challenging. Motivated by the lack of annotated data and the large amount of OOV words contained in Twitter, several approaches for automatically constructing a lexical normalisation dictionary were proposed; In (Gouws et al., 201</context>
</contexts>
<marker>Mosquera, Moreda, 2012</marker>
<rawString>Alejandro Mosquera and Paloma Moreda. 2012. Tenor: A lexical normalisation tool for spanish web 2.0 texts. In Text, Speech and Dialogue - 15th International Conference (TSD 2012). Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alejandro Mosquera</author>
<author>Elena Lloret</author>
<author>Paloma Moreda</author>
</authors>
<title>Towards facilitating the accessibility of web 2.0 texts through text normalisation.</title>
<date>2012</date>
<booktitle>In Proceedings of the LREC workshop: Natural Language Processing for Improving Textual Accessibility (NLP4ITA) ; Istanbul, Turkey.,</booktitle>
<pages>9--14</pages>
<contexts>
<context position="1998" citStr="Mosquera et al., 2012" startWordPosition="313" endWordPosition="316"> million new tweets every day. For this reason, Twitter has become one of the most used sources of textual data for NLP with several applications such as sentiment analysis (Tumasjan et al., 2010) or realtime event detection (Sakaki et al., 2010). Recent advances on machine translation or information retrieval systems have been also making an extensive use of UGC for both training and evaluation purposes. However, tweets can be very noisy Paloma Moreda University of Alicante San Vicente del Raspeig s/n - 03690 Alicante, Spain moreda@dlsi.ua.es and sometimes hard to understand for both humans (Mosquera et al., 2012) and NLP applications (Wang and Ng, 2013), so an additional preprocessing step is usually required. There have been different perceptions regarding the lexical quality of social media (Rello and Baeza-Yates, 2012) (Baldwin et al., 2013) and even others suggested that 40% of the messages of Twitter were “pointless babble” (PearAnalytics, 2009). Most of the out of vocabulary (OOV) words present in social media texts can be catalogued as lexical variants (e.g. “See u 2moro” → ”See you tomorrow”), that are words lexically related with their canonic form. The use of text normalisation techniques ha</context>
</contexts>
<marker>Mosquera, Lloret, Moreda, 2012</marker>
<rawString>Alejandro Mosquera, Elena Lloret, and Paloma Moreda. 2012. Towards facilitating the accessibility of web 2.0 texts through text normalisation. In Proceedings of the LREC workshop: Natural Language Processing for Improving Textual Accessibility (NLP4ITA) ; Istanbul, Turkey., pages 9–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>PearAnalytics</author>
</authors>
<title>Twitter study.</title>
<date>2009</date>
<booktitle>In Retrieved</booktitle>
<note>from http://pearanalytics.com/wpcontent/uploads/2009/08/Twitter-Study-August2009.pdf.</note>
<contexts>
<context position="2342" citStr="PearAnalytics, 2009" startWordPosition="369" endWordPosition="371">xtensive use of UGC for both training and evaluation purposes. However, tweets can be very noisy Paloma Moreda University of Alicante San Vicente del Raspeig s/n - 03690 Alicante, Spain moreda@dlsi.ua.es and sometimes hard to understand for both humans (Mosquera et al., 2012) and NLP applications (Wang and Ng, 2013), so an additional preprocessing step is usually required. There have been different perceptions regarding the lexical quality of social media (Rello and Baeza-Yates, 2012) (Baldwin et al., 2013) and even others suggested that 40% of the messages of Twitter were “pointless babble” (PearAnalytics, 2009). Most of the out of vocabulary (OOV) words present in social media texts can be catalogued as lexical variants (e.g. “See u 2moro” → ”See you tomorrow”), that are words lexically related with their canonic form. The use of text normalisation techniques has been proven useful in order to clean short and informal texts such as tweets. However, the evaluation of these systems requires annotated data, which usually involves costly human annotations. There are previous works about automatically constructing normalisation dictionaries, but until now, most of these approaches have been focused on En</context>
</contexts>
<marker>PearAnalytics, 2009</marker>
<rawString>PearAnalytics. 2009. Twitter study. In Retrieved December 15, 2009 from http://pearanalytics.com/wpcontent/uploads/2009/08/Twitter-Study-August2009.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luz Rello</author>
<author>Ricardo A Baeza-Yates</author>
</authors>
<title>Social media is not that bad! the lexical quality of social media.</title>
<date>2012</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="2211" citStr="Rello and Baeza-Yates, 2012" startWordPosition="347" endWordPosition="350">e event detection (Sakaki et al., 2010). Recent advances on machine translation or information retrieval systems have been also making an extensive use of UGC for both training and evaluation purposes. However, tweets can be very noisy Paloma Moreda University of Alicante San Vicente del Raspeig s/n - 03690 Alicante, Spain moreda@dlsi.ua.es and sometimes hard to understand for both humans (Mosquera et al., 2012) and NLP applications (Wang and Ng, 2013), so an additional preprocessing step is usually required. There have been different perceptions regarding the lexical quality of social media (Rello and Baeza-Yates, 2012) (Baldwin et al., 2013) and even others suggested that 40% of the messages of Twitter were “pointless babble” (PearAnalytics, 2009). Most of the out of vocabulary (OOV) words present in social media texts can be catalogued as lexical variants (e.g. “See u 2moro” → ”See you tomorrow”), that are words lexically related with their canonic form. The use of text normalisation techniques has been proven useful in order to clean short and informal texts such as tweets. However, the evaluation of these systems requires annotated data, which usually involves costly human annotations. There are previous</context>
</contexts>
<marker>Rello, Baeza-Yates, 2012</marker>
<rawString>Luz Rello and Ricardo A Baeza-Yates. 2012. Social media is not that bad! the lexical quality of social media. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Sakaki</author>
<author>Makoto Okazaki</author>
<author>Yutaka Matsuo</author>
</authors>
<title>Earthquake shakes twitter users: Real-time event detection by social sensors.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th International Conference on World Wide Web, WWW ’10,</booktitle>
<pages>851--860</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1622" citStr="Sakaki et al., 2010" startWordPosition="252" endWordPosition="255">User-generated content (UGC), and specially the microblog genre, has become an interesting resource for Natural Language Processing (NLP) tools and applications. Many are the advantages of exploiting this real-time stream of multilingual textual data. Popular applications such as Twitter has an heterogeneous user base of almost 600 million users that generate more than 60 million new tweets every day. For this reason, Twitter has become one of the most used sources of textual data for NLP with several applications such as sentiment analysis (Tumasjan et al., 2010) or realtime event detection (Sakaki et al., 2010). Recent advances on machine translation or information retrieval systems have been also making an extensive use of UGC for both training and evaluation purposes. However, tweets can be very noisy Paloma Moreda University of Alicante San Vicente del Raspeig s/n - 03690 Alicante, Spain moreda@dlsi.ua.es and sometimes hard to understand for both humans (Mosquera et al., 2012) and NLP applications (Wang and Ng, 2013), so an additional preprocessing step is usually required. There have been different perceptions regarding the lexical quality of social media (Rello and Baeza-Yates, 2012) (Baldwin e</context>
</contexts>
<marker>Sakaki, Okazaki, Matsuo, 2010</marker>
<rawString>Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. 2010. Earthquake shakes twitter users: Real-time event detection by social sensors. In Proceedings of the 19th International Conference on World Wide Web, WWW ’10, pages 851–860, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Thomson</author>
<author>Tamar Murachver</author>
</authors>
<title>Predicting gender from electronic discourse.</title>
<date>2001</date>
<contexts>
<context position="5861" citStr="Thomson and Murachver, 2001" startWordPosition="924" endWordPosition="927">h using random walks on a contextual similarity graph. Distributional-based methods can have some drawbacks: they rely heavily on pairwise comparisons that make them computationally expensive, and as the normalisation candidates are selected based on context similarity they can be sensitive to domain-specific variants that share similar contexts. Moreover, these approaches were focusing on extracting English lexical variants from social media texts, but due the heterogeneity of its users, lexical distributions can be influenced by geographical factors (Eisenstein et al., 2010) or even gender (Thomson and Murachver, 2001). To the best of our knowledge, there are not multilingual approaches for mining lexical variants from short, noisy texts that also take into account demographic variables. For this reason, we present an unsupervised method for mining English and Spanish lexical variants from Twitter that collects demographic and contextual information. These obtained pairs can be later used for training and evaluating text normalisation and inverse text normalisation systems. 3 Lexical Variant Mining Lexical variants are typically formed from their standard forms through regular processes (Thurlow and Brown, </context>
</contexts>
<marker>Thomson, Murachver, 2001</marker>
<rawString>Robert Thomson and Tamar Murachver. 2001. Predicting gender from electronic discourse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thurlow</author>
<author>Brown</author>
</authors>
<title>Generation txt? the sociolinguistics of young people’s text-messaging.</title>
<date>2003</date>
<contexts>
<context position="6466" citStr="Thurlow and Brown, 2003" startWordPosition="1014" endWordPosition="1018">nd Murachver, 2001). To the best of our knowledge, there are not multilingual approaches for mining lexical variants from short, noisy texts that also take into account demographic variables. For this reason, we present an unsupervised method for mining English and Spanish lexical variants from Twitter that collects demographic and contextual information. These obtained pairs can be later used for training and evaluating text normalisation and inverse text normalisation systems. 3 Lexical Variant Mining Lexical variants are typically formed from their standard forms through regular processes (Thurlow and Brown, 2003) and these can be modelled by using a set of basic character transformation rules such as letter insertion, deletion or substitution (Liu et al., 2011a) e.g. (“tmrrw” → “2morrow”) and combination of these (“2moro”). The relation between formal and informal pairs is not always 1-to-1, two different formal words can share the same lexical variant (“t” in Spanish can represent “te” or “t´u”) and one formal word can have many different variants (e.g. “see you” us commonly shortened as “c ya” or “see u”). As a difference with previous approaches based on contextual and distributional similarity, we</context>
</contexts>
<marker>Thurlow, Brown, 2003</marker>
<rawString>Thurlow and Brown. 2003. Generation txt? the sociolinguistics of young people’s text-messaging.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tumasjan</author>
<author>T O Sprenger</author>
<author>P G Sandner</author>
<author>I M Welpe</author>
</authors>
<title>Predicting elections with twitter: What 140 characters reveal about political sentiment.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>178--185</pages>
<contexts>
<context position="1572" citStr="Tumasjan et al., 2010" startWordPosition="244" endWordPosition="247">irs from English and Spanish tweets. 1 Introduction User-generated content (UGC), and specially the microblog genre, has become an interesting resource for Natural Language Processing (NLP) tools and applications. Many are the advantages of exploiting this real-time stream of multilingual textual data. Popular applications such as Twitter has an heterogeneous user base of almost 600 million users that generate more than 60 million new tweets every day. For this reason, Twitter has become one of the most used sources of textual data for NLP with several applications such as sentiment analysis (Tumasjan et al., 2010) or realtime event detection (Sakaki et al., 2010). Recent advances on machine translation or information retrieval systems have been also making an extensive use of UGC for both training and evaluation purposes. However, tweets can be very noisy Paloma Moreda University of Alicante San Vicente del Raspeig s/n - 03690 Alicante, Spain moreda@dlsi.ua.es and sometimes hard to understand for both humans (Mosquera et al., 2012) and NLP applications (Wang and Ng, 2013), so an additional preprocessing step is usually required. There have been different perceptions regarding the lexical quality of soc</context>
</contexts>
<marker>Tumasjan, Sprenger, Sandner, Welpe, 2010</marker>
<rawString>A. Tumasjan, T.O. Sprenger, P.G. Sandner, and I.M. Welpe. 2010. Predicting elections with twitter: What 140 characters reveal about political sentiment. In Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media, pages 178–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The nature of statistical learning theory.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York,</location>
<contexts>
<context position="11035" citStr="Vapnik, 1995" startWordPosition="1758" endWordPosition="1759">a static corpus (90% for English variants). 3.2.1 Intentionality Filtering Given an OOV word a and its IV version b we have extracted character transformation rules from a to b using the longest common substring (LCS) algorithm (See Table 5). These lists of transformations were encoded as a numeric array where the number each transformation counts were stored. We have used NLTK (Bird, 2006) and the SequenceMatcher Python class in order to extract those sets of transformations taking into account also the position of the character (beginning, middle or at the end of the word). A two-class SVM (Vapnik, 1995) model has ben trained using a linear kernel with a corpus composed by 4200 formal-variant pairs extracted from Twitter 1, SMS2 and a corpus of the 4200 most common misspellings 3. In table 6 we show the k-fold cross-validation results (k=10) of the model, obtaining a 87% F1. This model has been used in order to filter the English candidate variants classified as not-intentional. To the best of our knowledge there are not similar annotated resources for Spanish, so this classifier was developed only for English variants. However, would be possible to adapt it to work for 1http : //ww2.cs.mu.oz</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir N. Vapnik. 1995. The nature of statistical learning theory. Springer-Verlag New York, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pidong Wang</author>
<author>Hwee Tou Ng</author>
</authors>
<title>A beam-search decoder for normalization of social media text with application to machine translation.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>471--481</pages>
<contexts>
<context position="2039" citStr="Wang and Ng, 2013" startWordPosition="321" endWordPosition="324">n, Twitter has become one of the most used sources of textual data for NLP with several applications such as sentiment analysis (Tumasjan et al., 2010) or realtime event detection (Sakaki et al., 2010). Recent advances on machine translation or information retrieval systems have been also making an extensive use of UGC for both training and evaluation purposes. However, tweets can be very noisy Paloma Moreda University of Alicante San Vicente del Raspeig s/n - 03690 Alicante, Spain moreda@dlsi.ua.es and sometimes hard to understand for both humans (Mosquera et al., 2012) and NLP applications (Wang and Ng, 2013), so an additional preprocessing step is usually required. There have been different perceptions regarding the lexical quality of social media (Rello and Baeza-Yates, 2012) (Baldwin et al., 2013) and even others suggested that 40% of the messages of Twitter were “pointless babble” (PearAnalytics, 2009). Most of the out of vocabulary (OOV) words present in social media texts can be catalogued as lexical variants (e.g. “See u 2moro” → ”See you tomorrow”), that are words lexically related with their canonic form. The use of text normalisation techniques has been proven useful in order to clean sh</context>
</contexts>
<marker>Wang, Ng, 2013</marker>
<rawString>Pidong Wang and Hwee Tou Ng. 2013. A beam-search decoder for normalization of social media text with application to machine translation. In HLT-NAACL, pages 471–481.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>