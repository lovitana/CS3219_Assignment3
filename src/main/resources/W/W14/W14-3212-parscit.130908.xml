<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.979204">
Mining Themes and Interests in the Asperger’s and Autism Community
</title>
<author confidence="0.999643">
Yangfeng Ji, Hwajung Hong, Rosa Arriaga, Agata Rozga, Gregory Abowd, Jacob Eisenstein
</author>
<affiliation confidence="0.999134">
School of Interactive Computing
Georgia Institute of Technology
</affiliation>
<email confidence="0.995045">
{jiyfeng,hwajung,arriaga,agata,abowd,jacobe}@gatech.edu
</email>
<sectionHeader confidence="0.997331" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999893192307692">
Discussion forums offer a new source of
insight for the experiences and challenges
faced by individuals affected by mental
disorders. Language technology can help
domain experts gather insight from these
forums, by aggregating themes and user
behaviors across thousands of conversa-
tions. We present a novel model for web
forums, which captures both thematic con-
tent as well as user-specific interests. Ap-
plying this model to the Aspies Central fo-
rum (which covers issues related to As-
perger’s syndrome and autism spectrum
disorder), we identify several topics of
concern to individuals who report being on
the autism spectrum. We perform the eval-
uation on the data collected from Aspies
Central forum, including 1,939 threads,
29,947 posts and 972 users. Quantita-
tive evaluations demonstrate that the top-
ics extracted by this model are substan-
tially more than those obtained by Latent
Dirichlet Allocation and the Author-Topic
Model. Qualitative analysis by subject-
matter experts suggests intriguing direc-
tions for future investigation.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999761777777778">
Online forums can offer new insights on men-
tal disorders, by leveraging the experiences of af-
fected individuals — in their own words. Such
insights can potentially help mental health profes-
sionals and caregivers. Below is an example dia-
logue from the Aspies Central forum,1 where indi-
viduals who report being on the autism spectrum
(and their families and friends) exchange advice
and discuss their experiences:
</bodyText>
<footnote confidence="0.990836">
1http://www.aspiescentral.com
</footnote>
<listItem confidence="0.990983636363636">
• User A: Do you feel paranoid at work?
... What are some situations in which you
think you have been unfairly treated?
• User B: Actually I am going through some-
thing like that now, and it is very difficult to
keep it under control...
• User A: Yes, yes that is it. Exactly ... I think
it might be an Aspie trait to do that, I mean
over think everything and take it too literally?
• User B: It probably is an Aspie trait. I’ve
been told too that I am too hard on myself.
</listItem>
<bodyText confidence="0.984172823529412">
Aspies Central, like other related forums, has
thousands of such exchanges. However, aggregat-
ing insight from this wealth of information poses
obvious challenges. Manual analysis is extremely
time-consuming and labor-intensive, thus limiting
the scope of data that can be considered. In addi-
tion, manual coding systems raise validity ques-
tions, because they can tacitly impose the pre-
existing views of the experimenter on all sub-
sequent analysis. There is therefore a need for
computational tools that support large-scale ex-
ploratory textual analysis of such forums.
In this paper, we present a tool for automati-
cally mining web forums to explore textual themes
and user interests. Our system is based on Latent
Dirichlet Allocation (LDA; Blei et al, 2003), but is
customized for this setting in two key ways:
</bodyText>
<listItem confidence="0.976338888888889">
• By modeling sparsely-varying topics, we can
easily recover key terms of interest, while
retaining robustness to large vocabulary and
small counts (Eisenstein et al., 2011).
• By modeling author preference by topic, we
can quickly identify topics of interest for each
user, and simultaneously recover topics that
better distinguish the perspectives of each au-
thor.
</listItem>
<bodyText confidence="0.991953">
The key technical challenge in this work lies in
bringing together several disparate modalities into
</bodyText>
<page confidence="0.995889">
97
</page>
<note confidence="0.352439">
Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 97–106,
Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999734">
a single modeling framework: text, authorship,
and thread structure. We present a joint Bayesian
graphical model that unifies these facets, discov-
ering both an underlying set of topical themes,
and the relationship of these themes to authors.
We derive a variational inference algorithm for
this model, and apply the resulting software on a
dataset gathered from Aspies Central.
The topics and insights produced by our system
are evaluated both quantitatively and qualitatively.
In a blind comparison with LDA and the author-
topic model (Steyvers et al., 2004), both subject-
matter experts and lay users find the topics gener-
ated by our system to be substantially more coher-
ent and relevant. A subsequent qualitative analysis
aligns these topics with existing theory about the
autism spectrum, and suggests new potential in-
sights and avenues for future investigation.
</bodyText>
<sectionHeader confidence="0.991624" genericHeader="method">
2 Aspies Central Forum
</sectionHeader>
<bodyText confidence="0.999162903225806">
Aspies Central (AC) is an online forum for indi-
viduals on the autism spectrum, and has publicly
accessible discussion boards. Members of the site
do not necessarily have to have an official diag-
nosis of autism or a related condition. Neurotyp-
ical individuals (people not on the autism spec-
trum) are also allowed to participate in the fo-
rum. The forum includes more than 19 discussion
boards with subjects ranging from general discus-
sions about the autism spectrum to private discus-
sions about personal concerns. As of March 2014,
AC hosts 5,393 threads, 89,211 individual posts,
and 3,278 members.
AC consists of fifteen public discussion boards
and four private discussion boards that require
membership. We collected data only from
publicly-accessible discussion boards. In addition,
we excluded discussion boards that were website-
specific (announcement-and-introduce-yourself),
those mainly used by family and friends of in-
dividuals on the spectrum (friends-and-family) or
researchers (autism-news-and-research), and one
for amusement (forum-games). Thus, we focused
on ten discussion boards (aspergers-syndrome-
Autism-and-HFA, PDD-NOS-social-anxiety-and-
others, obsessions-and-interests, friendships-and-
social-skills, education-and-employment, love-
relationships-and-dating, autism-spectrum-help-
and-support, off-topic-discussion, entertainment-
discussion, computers-technology-discussion), in
which AC users discuss their everyday expe-
</bodyText>
<figureCaption confidence="0.96981125">
Figure 1: Plate diagram. Shaded notes represent observed
variables, clear nodes represent latent variables, arrows in-
dicate probabilistic dependencies, and plates indicate repeti-
tion.
</figureCaption>
<bodyText confidence="0.998655857142857">
riences, concerns, and challenges. Using the
python library Beautiful Soup, we collected 1,939
threads (29,947 individual posts) from the discus-
sion board archives over a time period from June
1, 2010 to July 27, 2013. For a given post, we
extracted associated metadata such as the author
identifier and posting timestamps.
</bodyText>
<sectionHeader confidence="0.912868" genericHeader="method">
3 Model Specification
</sectionHeader>
<bodyText confidence="0.99999225">
Our goal is to develop a model that captures the
preeminent themes and user behaviors from traces
of user behaviors in online forums. The model
should unite textual content with authorship and
thread structure, by connecting these observed
variables through a set of latent variables rep-
resenting conceptual topics and user preferences.
In this section, we present the statistical specifi-
cation of just such a model, using the machinery
of Bayesian graphical models. Specifically, the
model descibes a stochastic process by which the
observed variables are emitted from prior proba-
bility distributions shaped by the latent variables.
By performing Bayesian statistical inference in
this model, we can recover a probability distribu-
tion around the latent variables of interest.
We now describe the components of the model
that generate each set of observed variables. The
model is shown as a plate diagram in Figure 1, and
the notation is summarized in Table 1.
</bodyText>
<subsectionHeader confidence="0.999458">
3.1 Generating the text
</subsectionHeader>
<bodyText confidence="0.9998808">
The part of the model which produces the text it-
self is similar to standard latent Dirichlet alloca-
tion (LDA) (Blei et al., 2003). We assume a set
of K latent topics, which are distributions over
each word in a finite vocabulary. These topics are
</bodyText>
<figure confidence="0.780343933333333">
m
ηk
α ed
K
wdpn
zdpn
yik ρ
N
ad
P
D
Ω
bi
K
A
</figure>
<page confidence="0.938979">
98
</page>
<figure confidence="0.8396238">
Symbol Description
D number of threads
Pd number of posts in thread d
Np number of word tokens in post p
α parameter of topic distribution of threads
Bd the multinomial distribution of topics specific to the thread d
zdpn the topic associated with the nth token in post p of thread d
wdpn the nth token in post p of thread d
ad authorship distribution for question post and answer posts in
thread d respectively
yik the topic-preference indicator of author i on topic k
bi the Gaussian distribution of author i’s selection bias
ηk topic k in log linear space
m background topic
Ω topic weights matrix
v2 variance of feature weights
λ
v2 variance of selection bias
b
ρ prior probability of authors’ preference on any topic
</figure>
<tableCaption confidence="0.990299">
Table 1: Mathematical notations
</tableCaption>
<bodyText confidence="0.999905333333333">
shared among all D threads in the collection, but
each thread has its own distribution over the top-
ics.
We make use of the SAGE parametrization for
generative models of text (Eisenstein et al., 2011).
SAGE uses adaptive sparsity to induce topics that
deviate from a background word distribution in
only a few key words, without requiring a regular-
ization parameter. The background distribution is
written m, and the deviation for topic k is written
ηk, so that Pr(w = v1ηk, m) a exp (mv + ηkv).
Each word token wdpn (the nth word in post p of
thread d) is generated from the probability distri-
bution associated with a single topic, indexed by
the latent variable zdpn E {1... K}. This latent
variable is drawn from a prior θd, which is the
probability distribution over topics associated with
all posts in thread d.
</bodyText>
<subsectionHeader confidence="0.999836">
3.2 Generating the author
</subsectionHeader>
<bodyText confidence="0.996297878787879">
We have metadata indicating the author of each
post, and we assume that users are more likely
to participate in threads that relate to their topic-
specific preference. In addition, some people may
be more or less likely to participate overall. We
extend the LDA generative model to incorporate
each of these intuitions.
For each author i, we define a latent preference
vector yi, where yik E 10, 11 indicates whether
the author i prefers to answer questions about
topic k. We place a Bernoulli prior on each yik, so
that yik — Bern(ρ), where Bern(y; ρ) = ρy(1 —
ρ)(1−y). Induction of y is one of the key infer-
ence tasks for the model, since this captures topic-
specific preference.
It is also a fact that some individuals will partic-
ipate in a conversation regardless of whether they
have anything useful to add. To model this gen-
eral tendency, we add an “bias” variable bi E R.
When bi is negative, this means that author i will
be reluctant to participate even when she does have
relevant interests.
Finally, various topics may require different lev-
els of preference; some may capture only general
knowledge that many individuals are able to pro-
vide, while others may be more obscure. We in-
troduce a diagonal topic-weight matrix Q, where
Qkk = Wk &gt; 0 is the importance of preference for
topic k. We can easily generalize the model by in-
cluding non-zero off-diagonal elements, but leave
this for future work.
The generative distribution for the observed au-
thor variable is a log-linear function of y and b:
</bodyText>
<equation confidence="0.995871333333333">
exp(θdΩyi + bi)
Pr(adi = 1|θd, y, , b) =
(1)
</equation>
<bodyText confidence="0.995827733333333">
This distribution is multinomial over authors; each
author’s probability of responding to a thread de-
pends on the topics in the thread (θd), the author’s
preference on those topics (yi), the importance of
preference for each topic (Q), and the bias parame-
ter bi. We exponentiate and then normalize, yield-
ing a multinomial distribution.
The authorship distribution in Equation (1)
refers to a probability of user i authoring a single
response post in thread d (we will handle question
posts next). Let us construct a binary vector a(r)
d ,
where it is 1 if author i has authored any response
posts in thread d, and zero otherwise. The proba-
bility distribution for this vector can be written
</bodyText>
<equation confidence="0.99946675">
P(a(dr) |θd, y, Ω, b) a
a( (2)
exp(θdΩyi + bi) di
EAj=1 exp(θdΩyj + bj)
</equation>
<bodyText confidence="0.999819153846154">
One of the goals of this model is to distinguish
frequent responders (i.e., potential experts) from
individuals who post questions in a given topic.
Therefore, we make the probability of author i ini-
tiating thread d depend on the value 1 — yki for
each topic k. We write the binary vector a(q)
d ,
where a(q)
di = 1 if author i has written the ques-
tion post, and zero otherwise. Note that there can
only be one question post, so a(q)
d is an indicator
vector. Its probability is written as
</bodyText>
<equation confidence="0.914601272727273">
p(a(q)
d |θd, y, Ω, b) a
�a(q)
di (3)
exp(θ� dΩ(1 − yi) + bi)
EAj=1 exp(θd�Ω(1 − yj) + bj)
EAj=1 exp(θdΩyj + bj)
A
ri
A
i=1
</equation>
<page confidence="0.961921">
99
</page>
<bodyText confidence="0.999728">
We can put these pieces together for a complete
distribution over authorship for thread d:
</bodyText>
<equation confidence="0.995791125">
P(ad, |ed, y, Ω, b) a
!a(r)
di
exp(eT dΩyi + bi)
PAj=1 exp(eTdΩyj + bj)
(q)
exp(eTdΩ(1 − yi) + bi) ! di
PAj= 1 exp(edO(1 − y�) + bj)a
</equation>
<bodyText confidence="0.990336727272727">
where ad = {a(q)
d , a(r)
d 1. The probability
p(ad|Bd, y, Q, b) combines the authorship distri-
bution of authors from question post and answer
posts in thread d. The identity of the original ques-
tion poster does not appear in the answer vector,
since further posts are taken to be refinements of
the original question.
This model is similar in spirit to super-
vised latent Dirichlet allocation (sLDA) (Blei and
McAuliffe, 2007). However, there are two key dif-
ferences. First, sLDA uses point estimation to ob-
tain a weight for each topic. In contrast, we per-
form Bayesian inference on the author-topic pref-
erence y. Second, sLDA generates the metadata
from the dot-product of the weights and ¯z, while
we use θ directly. The sLDA paper argues that
there is a risk of overfitting, where some of the top-
ics serve only to explain the metadata and never
generate any of the text. This problem does not
arise in our experiments.
</bodyText>
<subsectionHeader confidence="0.992878">
3.3 Formal generative story
</subsectionHeader>
<bodyText confidence="0.9999535">
We are now ready to formally define the generative
process of our model:
</bodyText>
<equation confidence="0.7492825">
B. Draw word
wdpn — Mult(βzdpn)
</equation>
<sectionHeader confidence="0.987005" genericHeader="method">
4 Inference and estimation
</sectionHeader>
<bodyText confidence="0.999983793103448">
The purpose of inference and estimation is to re-
cover probability distributions and point estimates
for the quantities of interest: the content of the
topics, the assignment of topics to threads, au-
thor preferences for each topic, etc. While recent
progress in probabilistic programming has im-
proved capabilities for automating inference and
estimation directly from the model specification,2
here we develop a custom algorithm, based on
variational mean field (Wainwright and Jordan,
2008). Specifically, we approximate the distribu-
tion over topic proportions, topic indicators, and
author-topic preference P(θ, z, y|w, a, x) with a
mean field approximation
where Pd is the number of posts in thread d, K
is the number of topics, and Np is the number of
word tokens in post Pd. The variational parame-
ters of q(·) are γ, φ, ψ. We will write () to indicate
an expectation under the distribution q(θ, z, y).
We employ point estimates for the variables
b (author selection bias), λ (topic-time feature
weights), η (topic-word log-probability devia-
tions), and diagonal elements of Q (topic weights).
The estimation of η follows the procedure defined
in SAGE (Eisenstein et al., 2011); we explain the
estimation of the remaining parameters below.
Given the variational distribution in Equation
(5), the inference on our topic model can be for-
mulated as constrained optimization of this bound.
</bodyText>
<equation confidence="0.995416166666667">
min G(7, O, ψ; b, A, Ω)
s.t.7dk &gt; 0 `dd, k
Xφdpn &gt; 0, Odpnk = 1 `dd, p, n (6)
k
0 &lt; ψik &lt; 1 `di, k
ωk &gt; 0 `dk
</equation>
<bodyText confidence="0.999758333333333">
The constraints are due to the parametric form
of the variational approximation: q(θd|γd) is
Dirichlet, and requires non-negative parameters;
</bodyText>
<footnote confidence="0.9566295">
2see http://probabilistic-programming.
org/
</footnote>
<figure confidence="0.796382181818182">
q(e, z, y|7, O, ψ) =
D
Y
d=1
Pd
Y
p=1
Np,dY
n=1
q(zdpn|Odpn)
YA
i=1
K
Y
k=1
D
Y
d=1
q(yik|ψik)
q(Bd|7d)
(5)
YA
i=1
YA
�
i=1
(4)
1. For each topic k
(a) Set the word probabilities βk =
exp(m+ηk)
E.i exp(mi+ski)
2. For each author i
(a) Draw the selection bias bi — N(0, σ2b )
(b) For each topic k
i. Draw the author-topic preference
level yik — Bern(ρ)
3. For each thread d
(a) Draw topic proportions θd — Dir(α)
(b) Draw the author vector ad from Equa-
tion (4)
(c) For each post p
i. For each word in this post
A. Draw topic assignment zdpn —
Mult(θd)
</figure>
<page confidence="0.706042">
100
</page>
<listItem confidence="0.6583034">
q(zdpn|odpn) is multinomial, and requires that
odpn lie on the K − 1 simplex; q(yik|ψik) is
Bernoulli and requires that ψik be between 0 and
1. In addition, as a topic weight, ωk should also be
non-negative.
</listItem>
<bodyText confidence="0.765363333333333">
Algorithm 1 One pass of the variational inference
algorithm for our model.
for d = 1, ... ,D do
</bodyText>
<table confidence="0.80963885">
while not converged do
for p = 1, ... ,Pd do
for n = 1, ... ,Np,d do
Update φdpnk using Equation (7) for each k =
1, ... ,K
end for
end for
Update γdk by optimizing Equation (6) with Equa-
tion (10) for each k = 1, ... ,K
end while
end for
for i = 1, ... ,Ado
Update ψik by optimizing Equation (6) with Equa-
tion (13) for each k = 1, ... , K
Update ˆbi by optimizing Equation (6) with Equa-
tion (14)
end for
for k = 1, ... ,K do
Update ωk with Equation (15)
end for
</table>
<subsectionHeader confidence="0.950155">
4.1 Word-topic indicators
</subsectionHeader>
<bodyText confidence="0.9999825">
With the variational distribution in Equation (5),
the inference on φdpn for a given token n in post p
of thread d is same as in LDA. For the nth token
in post p of thread d,
</bodyText>
<subsectionHeader confidence="0.944922">
4.2 Document-topic distribution
</subsectionHeader>
<bodyText confidence="0.996518761904762">
The inference for document-topic proportions is
different from LDA, due to the generation of the
author vector ad, which depends on Od. For a
given thread d, the part of the bound associated
with the variational parameter γd is
d
+ dγdk hlog p(ad|θd, y, 0, b)i ,
where Ψ&apos;(·) is the trigramma function. The first
two lines of Equation (10) are identical to LDA’s
variational inference, which obtains a closed-form
solution by setting γdk = αdk + Pp,n φdpnk. The
additional term for generating the authorship vec-
tor ad eliminates this closed-form solution and
forces us to turn to gradient-based optimization.
The expectation on the log probability of the
authorship involves the expectation on the log
partition function, which we approximate using
Jensen’s inequality. We then derive the gradient,
Lγd = hlog p(θd|αd)i + hlog p(ad|θd, y, 0, b)i
hlog p(zdpn|θd)i − hq(θd|γd)i
and the derivative of Lγd with respect to γdk is
</bodyText>
<equation confidence="0.9933325">
dLγd = T�(γdk)(αdk + Pd Np,dX φdpnk − γdk)
dγdk X n=1
p=1
− T/( K γdk) K (αdk + Pd Np,dX φdpnk − γdk)
X X X n=1
k=1 k=1 p=1
Np,dX
n=1
Pd
+ X
p=1
φdpnk a βkwdpn exp((log θdk)) (7)
</equation>
<bodyText confidence="0.854181">
where β is defined in the generative story and
(log θdk) is the expectation of log θdk under the
distribution q(θdk|γd),
</bodyText>
<equation confidence="0.6639756875">
∂
hlog p(ad|θd, y, 0, b)i
∂γdk
E!
D
a(r)
ψik di |θd, y
≈ ωk
XA
i=1
adi ψik − A(r)
(r)
d
XA
i=1
(log θdk) = Ψ(γdk) − Ψ(
</equation>
<bodyText confidence="0.9998105">
where Ψ(·) is the Digamma function, the first
derivative of the log-gamma function.
For the other variational parameters γ and ψ, we
can not obtain a closed form solution. As the con-
straints on these parameters are all convex with re-
spect to each component, we employed a projected
quasi-Newton algorithm proposed in (Schmidt et
al., 2009) to optimize L in Equation (6). One pass
of the variational inference procedure is summa-
rized in Algorithm 1.Since every step in this algo-
rithm will not decrease the variational bound, the
overall algorithm is guaranteed to converge.
</bodyText>
<equation confidence="0.9972792">
E!
D
a(q)
ψik di |θd, y
(11)
</equation>
<bodyText confidence="0.9855668">
The convenience variable A(r)
d counts the number
of distinct response authors in thread d; recall that
there can be only one question author. The nota-
tion
</bodyText>
<equation confidence="0.9589965">
exp((OT) Ω (yi) + bi)
Dadi) |Od, yE = Pj exp((OT) Ω (yj) + bj),
</equation>
<bodyText confidence="0.9980588">
represents the generative probability of a(r)
di = 1
under the current variational distributions q(Od)
and q(yi). The notation Dadq)  |Od, yE is analo-
gous, but represents the question post indicator
</bodyText>
<equation confidence="0.992343454545454">
a(q)
di .
XK γdk) (8)
k=1
XA
i=1
− ωk
XA
i=1
adi ψik −
(q)
</equation>
<page confidence="0.99117">
101
</page>
<subsectionHeader confidence="0.987445">
4.3 Author-topic preference
</subsectionHeader>
<bodyText confidence="0.999943142857143">
The variational distribution over author-topic
preference is q(yik|ψik); as this distribution is
Bernoulli, (yik) = ψik, the parameter itself prox-
ies for the topic-specific author preference — how
much author i prefers to answer posts on topic k.
The part of the variational bound the relates to
the author preferences is
</bodyText>
<equation confidence="0.95491725">
hlog p(ad|θd, y, Ω, b)i
XA
+
i=1
</equation>
<bodyText confidence="0.8136934">
For author i on topic k, the derivative of
(log p(ad|θd, y, Q, b)) for document d with re-
spect to ψik is
d hlog P(ad|θd, y, Ω, b)i
dψik
</bodyText>
<equation confidence="0.9955414">
� D E D E~
a(r) a(r) a(q)
≈ hθdki ωk − a(q)
di − di |θd, y di + di |θd, y ,
(13)
</equation>
<bodyText confidence="0.893725">
where (θdk) =γdk
k� γdk� . Thus, participating as a
respondent increases ψik to the extent that topic k
is involved in the thread; participating as the ques-
tioner decreases ψik by a corresponding amount.
</bodyText>
<subsectionHeader confidence="0.997674">
4.4 Point estimates
</subsectionHeader>
<bodyText confidence="0.999956304347826">
We make point estimates of the following param-
eters: author selection bias bi and topic-specific
preference weights ωk. All updates are based
on maximum a posteriori estimation or maximum
likelihood estimation.
Selection bias For the selection bias bi of au-
thor i given a thread d, the objective function in
Equation (6) with the prior of bi — N(0, σ2b ) is
minimized by a quasi-Newton algorithm with the
following derivative
The zero-mean Gaussian prior shrinks bi towards
zero by subtracting bi/σ2b from this gradient. Note
that the gradient in Equation (14) is non-negative
whenever author i participates in thread d. This
means any post from this author, whether question
posts or answer posts, will have a positive contri-
bution of the author’s selection bias. This means
that any activity in the forum will elevate the se-
lection bias bi, but will not necessarily increase the
imputed preference level.
Topic weights The topic-specific preference
weight ωk is updated by considering the derivative
of variational bound with respect to ωk
</bodyText>
<equation confidence="0.923123">
∂ (p(ad|θd, y, Q, b)) (15)
∂ωk
</equation>
<bodyText confidence="0.995192">
where for a given document d,
</bodyText>
<equation confidence="0.992462125">
∂ hlog p(ad|θd, y, Ω, b)i ≈ hθdki ωk·
� D E
a(r) a(q)
ψik i − a(q)
i + di |θd, y
D E �
− A(r) a(r)
di |θd, y
</equation>
<bodyText confidence="0.88188975">
d
Thus, ωk will converge at a value where the ob-
served posting counts matches the expectations
under (log p(ad|θd, y, Q, b)).
</bodyText>
<sectionHeader confidence="0.996426" genericHeader="method">
5 Quantitative Evaluation
</sectionHeader>
<bodyText confidence="0.999979444444444">
To validate the topics identified by the model,
we performed a manual evaluation, combining the
opinions of both novices as well as subject matter
experts in Autism and Asberger’s Syndrome. The
purpose of the evaluation is to determine whether
the topics induced by the proposed model are more
coherent than topics from generic alternatives such
as LDA and the author-topic model, which are not
specifically designed for forums.
</bodyText>
<subsectionHeader confidence="0.979785">
5.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.9997888">
Preprocessing Preprocessing was minimal. We
tokenized texts using white space and removed
punctuations at the beginning/end of each token.
We removed words that appear less than five
times, resulting in a vocabulary of the 4903 most
frequently-used words.
Baseline Models We considered two baseline
models in the evaulation. The first baseline model
is latent Dirichlet allocation (LDA), which consid-
ers only the text and ignores the metadata (Blei
et al., 2003). The second baseline is the Author-
Topic (AT) model, which extends LDA by associ-
ating authors with topics (Rosen-Zvi et al., 2004;
Steyvers et al., 2004). Both baselines are im-
plemented in the Matlab Topic Modeling Tool-
box (Steyvers and Griffiths, 2005).
Parameter Settings For all three models, we set
K = 50. Our model includes the three tunable
parameters ρ, the Bernoulli prior on topic-specific
expertise; σ2b, the variance prior on use selection
</bodyText>
<equation confidence="0.998709037037037">
D
X
d=1
Lψ =
XA
i=1
hp(yik|ρ)i −
hq(yik|ψik)i
K
X
k=1
K
X
k=1
∂bi hlog P(ad|θd, y, Ω, b)i ≈ a(r)
∂ d,i− (14)
D E D E
a(r) + a(q) a(q)
di |θd, y d,i − di |θd, y
∂L
D
d=1
=
∂ωk
∂ωk
(12) XA
i=1
</equation>
<page confidence="0.988168">
102
</page>
<bodyText confidence="0.999957">
bias; and α, the prior on document-topic distri-
bution. In the following experiments, we chose
p = 0.2, Qb = 1.0, α = 1.0. LDA and AT share
two parameters, α, the symmetric Dirichlet prior
for document-topic distribution; Q, the symmetric
Dirichlet prior for the topic-word distribution. In
both models, we set α = 3.0 and Q = 0.01. All
parameters were selected in advance of the experi-
ments; further tuning of these paramters is left for
future work.
</bodyText>
<subsectionHeader confidence="0.996142">
5.2 Topic Coherence Evaluation
</subsectionHeader>
<bodyText confidence="0.999905128205128">
To be useful, a topic model should produce topics
that human readers judge to be coherent. While
some automated metrics have been shown to co-
here with human coherence judgments (Newman
et al., 2010), it is possible that naive raters might
have different judgments from subject matter ex-
perts. For this reason, we focused on human eval-
uation, including both expert and novice opinions.
One rater, R1, is an author of the paper (HH) and
a Ph.D. student focusing on designing technology
to understand and support individuals with autism
spectrum disorder. The remaining three raters are
not authors of the paper and are not domain ex-
perts.
In the evaluation protocol, raters were presented
with batteries of fifteen topics, from which they
were asked to select the three most coherent. In
each of the ten batteries, there were five topics
from each model, permuted at random. Thus, af-
ter completing the task, all 150 topics — 50 topics
from each model — were rated. The user interface
of topic coherence evaluation is given in Figure 2,
including the specific prompt.
We note that this evaluation differs from the
“intrusion task” proposed by Chang et al. (2009),
in which raters are asked to guess which word
was randomly inserted into a topic. While the in-
trusion task protocol avoids relying on subjective
judgments of the meaning of “coherence,” it pre-
vents expert raters from expressing a preference
for topics that might be especially useful for anal-
ysis of autism spectrum disorder. Prior work has
also shown that the variance of these tasks is high,
making it difficult to distinguish between models.
Table 2 shows, for each rater, the percentage of
topics were chosen from each model as the most
coherent within each battery. On average, 80% of
the topics were chosen from our proposed model.
If all three models are equally good at discover-
</bodyText>
<figureCaption confidence="0.99108">
Figure 2: The user interface of topic coherence
evaluation.
</figureCaption>
<table confidence="0.9791864">
Rater
Model R1 R2 R3 R4 Average
Our model 70% 93% 80% 77% 80%
AT 17% 7% 13% 10% 12%
LDA 13% 0% 7% 13% 8%
</table>
<tableCaption confidence="0.947263">
Table 2: Percentage of the most coherent topics that are
selected from three different topic models: our model, the
Author-Topic Model (AT), and latent Dirichlet allocation
(LDA).
</tableCaption>
<bodyText confidence="0.999913">
ing coherent topics, the average percentage across
three models should be roughly equal. Note that
the opinion of the expert rater R1 is generally sim-
ilar to the other three raters.
</bodyText>
<subsectionHeader confidence="0.714133">
6 Analysis of Aspies Central Topics
</subsectionHeader>
<bodyText confidence="0.9999815625">
In this section, we further use our model to ex-
plore more information about the Aspies Central
forum. We want to examine whether the autism-
related topics identified the model can support re-
searchers to gain qualitative understanding of the
needs and concerns of autism forum users. We are
also interested in understanding the users’ behav-
ioral patterns on autism-related topics. The anal-
ysis task has three components: first we will de-
scribe the interesting topics from the autism do-
main perpective. Then we will find out the pro-
portion of each topic, including autism related top-
ics. Finally, in order to understand the user activ-
ity patterns on these autism related topics we will
derive the topic-specific preference ranking of the
users from our model.
</bodyText>
<page confidence="0.996377">
103
</page>
<table confidence="0.941883663461538">
Index Proportion
1 1.7%
3 2.2%
5 1.1%
7 3.4%
9 1.7%
11 1.2%
13 1.6%
15 0.1%
17 0.6%
19 3.7%
21 0.4%
23 0.4%
25 1.5%
27 0.5%
29 2.7%
31 3.3%
33 4.6%
35 1.0%
37 1.3%
39 2.1%
41 1.2%
43 1.0%
45 1.3%
47 0.6%
49 0.9%
Top keywords
dont im organization couldnt construction
game watched games fallout played
nobody smell boss fool smelling
doesn’t it’s mandarin i’ve that’s
obsessions bookscollecting library authors
stims mom nails lip shoes
battery hawke charlie ive swing
chocolate pdd milk romance nose
eat burgers jokes memory foods
depression beleive christianity buddhism becouse
alma star gods alien sun
trilogy sci-fi cartoon iphone grandma
empathy smells compassion emotions emotional
list dedicate lists humor song
captain i’m film anime that’s
shave exhausting during terrified products
dictionary asks there’re offend fog
cave blonde hair bald disney
song joanna newsom rap favorites
heat iron adhd chaos pills
uk maths team teams op
husband narcissist husband’s he hyper
autism disorder spectrum disorders pervasive
relationship women relationships sexual sexually
him he his bernard je
Index Proportion
2 2.6%
4 3.5%
6 3.2%
8 2.1%
10 2.6%
12 1.8%
14 1.9%
16 5.8%
18 2.4%
20 1.4%
22 2.6%
24 2.7%
26 1.7%
28 4.6%
30 3.6%
32 5.6%
34 1.5%
36 1.9%
38 1.8%
40 3.6%
42 0.8%
44 1.1%
46 0.7%
48 0.9%
50 2.0%
Top keywords
yah supervisor behavior taboo phone
volunteering esteem community art self
firefox razor blades pc console
diagnosed facessenses visualize visual
ptsd central cure neurotypical we
classroom campus tag numbers exams
divorce william women marryrates
kinda holland neccesarily employment bucks
dryer martial dream wake schedule
grudges pairs glasses museum frames
facebook profiles befriend friendships friends
flapping stuffed toes curse animal
males evolution females originally constructive
nts aspies autie qc intuitive
homeless pic wild math laugh
you’re you your yourself hiring
grade ed school 7th diploma
diagnosis autism syndrome symptoms aspergers
poetry asleep children ghosts lots
bike zone rides zoning worrying
book books read reading kindle
songs guitar drums music synth
dog noise dogs barking noisy
weed marijuana pot smoking fishing
her she she’s kyoko she’ll
</table>
<tableCaption confidence="0.798882">
Table 3: 50 topics identified by our model. The “proportion” columns show the topic proportions in the
</tableCaption>
<bodyText confidence="0.9889233125">
dataset. Furthermore, 14 topics are highlighted as interesting topics for autism research.
Table 3 shows all 50 topics from our model. For
each topic, we show the top five words related to
this topic. We further identified fourteen topics
(highlighted with blue color), which are particu-
larly relevant to understand autism.
Among the identified topics, there are three
popular topics discussed in the Aspies Central fo-
rum: topic 4, topic 19 and topic 31. From the top
word list, we identified that topic 4 is composed
of keywords related to psychological (e.g., self-
esteem, art) and social (e.g., volunteering, com-
munity) well-being of the Aspies Central users.
Topic 19 includes discussion on mental health
issues (e.g., depression) and religious activities
(e.g., believe, christianity, buddhism) as coping
strategies. Topic 31 addresses a specific personal
hygiene issue — helping people with autism learn
to shave. This might be difficult for individuals
with sensory issues: for example, they may be
terrified by the sound and vibration generated by
the shaver. For example, topic 22 is about mak-
ing friends and maintaining friendship; topic 12 is
about educational issues ranging from seeking ed-
ucational resources to improving academic skills
and adjusting to college life.
In addition to identifying meaningful topics, an-
other capability of our model is to discover users’
topic preferences and expertise. Recall that, for
user i and topic k, our model estimates a author-
topic preference variable Oik. Each Oik ranges
from 0 to 1, indicating the probability of user i to
</bodyText>
<table confidence="0.992250545454545">
Topic User index
5 USER 1, USER 2, USER 3, USER 4, USER 5
8 USER 1, USER 2, USER 6, USER 5, USER 7
12 USER 1, USER 2, USER 4, USER 8, USER 3
19 USER 1, USER 2, USER 3, USER 4, USER 7
22 USER 1, USER 2, USER 3, USER 9, USER 7
31 USER 1, USER 3, USER 2, USER 6, USER 10
36 USER 1, USER 2, USER 4, USER 3, USER 11
45 USER 1, USER 3, USER 4, USER 12, USER 13
47 USER 2, USER 14, USER 15, USER 16 , USER 6
48 USER 5, USER 4, USER 6, USER 9, USER 2
</table>
<tableCaption confidence="0.99498">
Table 4: The ranking of user preference on some interest-
</tableCaption>
<bodyText confidence="0.9206356">
ing topics (we replace user IDs with user indices to avoid
any privacy-related issue). USER 1 is the moderator of this
forum. In total, our model identifies 16 user with high topic-
specific preference from 10 interesting topics. For the other
4 interesting topics, there is no user with significantly high
preference.
answer a question on topic k. As we set the prior
probability of author-topic preference to be 0.2,
we show topic-author pairs for which Oik &gt; 0.2
in Table 4.
The dominance of USER 1 in these topics is ex-
plained by the fact that this user is the moderator
of the forum. Besides, we also find some other
users participating in most of the interesting top-
ics, such as USER 2 and USER 3. On the other
hand, users like USER 14 and USER 15 only show
up in few topics. This observation is supported by
their activities on discussion boards. Searching on
the Aspies Certral forum, we found most answer
posts of user USER 15 are from the board “love-
</bodyText>
<page confidence="0.996737">
104
</page>
<bodyText confidence="0.914492">
relationships-and-dating”.
</bodyText>
<sectionHeader confidence="0.999858" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999973462962963">
Social media has become an important source of
health information (Choudhury et al., 2014). For
example, Twitter has been used both for mining
both public health information (Paul and Dredze,
2011) and for estimating individual health sta-
tus (Sokolova et al., 2013; Teodoro and Naaman,
2013). Domain-specific online communities, such
Aspies Central, have their own advantages, tar-
geting specific issues and featuring more close-
knit and long-term relationships among mem-
bers (Newton et al., 2009).
Previous studies on mining health information
show that technical models and tools from com-
putational linguistics are helpful for both under-
standing contents and providing informative fea-
tures. Sokolova and Bobicev (2011) use sentiment
analysis to analyze opinions expressed in health-
related Web messages; Hong et al. (2012) focus
on lexical differences to automatically distinguish
schizophrenic patients from healthy individuals.
Topic models have previously been used to
mine health information: Resnik et al. (2013) use
LDA to improve the prediction for neuroticism
and depression on college students, while Paul and
Dredze (2013) customize their factorial LDA to
model the joint effect of drug, aspect, and route
of administration. Most relevantly for the current
paper, Nguyen et al. (2013) use LDA to discover
autism-related topics, using a dataset of 10,000
posts from ten different autism commnities. How-
ever, their focus was on automated classification of
communities as autism-related or not, rather than
on analysis and on providing support for qualita-
tive autism researchers. The applicability of the
model developed in our paper towards classifica-
tion tasks is a potential direction for future re-
search.
In general, topic models capture latent themes
in document collections, characterizing each doc-
ument in the collection as a mixture of topics (Blei
et al., 2003). A natural extension of topic mod-
els is to infer the relationships between topics and
metadata such as authorship or time. A relatively
simple approach is to represent authors as an ag-
gregation of the topics in all documents they have
written (Wagner et al., 2012). More sophisticated
topic models, such as Author-Topic (AT) model
(Rosen-Zvi et al., 2004; Steyvers et al., 2004) as-
sume that each document is generated by a mix-
ture of its authors’ topic distributions. Our model
can be viewed as one further extension of topic
models by incorporating more metadata informa-
tion (authorship, thread structure) in online fo-
rums.
</bodyText>
<sectionHeader confidence="0.998594" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.99996972">
This paper describes how topic models can offer
insights on the issues and challenges faced by in-
dividuals on the autism spectrum. In particular,
we demonstrate that by unifying textual content
with authorship and thread structure metadata, we
can obtain more coherent topics and better under-
stand user activity patterns. This coherence is val-
idated by manual annotations from both experts
and non-experts. Thus, we believe that our model
provides a promising mechanism to capture be-
havioral and psychological attributes relating to
the special populations affected by their cognitive
disabilities, some of which may signal needs and
concerns about their mental health and social well-
being.
We hope that this paper encourages future ap-
plications of topic modeling to help psychologists
understand the autism spectrum and other psycho-
logical disorders — and we hope to obtain further
validation of our model through its utility in such
qualitative research. Other directions for future
work include replication of our results across mul-
tiple forums, and applications to other conditions
such as depression and attention deficit hyperac-
tivity disorder (ADHD).
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99988575">
This research was supported by a Google Faculty
Award to the last author. We thank the three re-
viewers for their detailed and helpful suggestions
to improve the paper.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997717">
David M. Blei and Jon D. McAuliffe. 2007. Super-
vised Topic Models. In NIPS.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. the Journal of ma-
chine Learning research, 3:993–1022.
Jonathan Chang, Jordan L. Boyd-Graber, Sean Gerrish,
Chong Wang, and David M. Blei. 2009. Reading
Tea Leaves: How Humans Interpret Topic Models.
In Yoshua Bengio, Dale Schuurmans, John D. Laf-
ferty, Christopher K. I. Williams, and Aron Culotta,
</reference>
<page confidence="0.983404">
105
</page>
<reference confidence="0.999793247311828">
editors, NIPS, pages 288–296. Curran Associates,
Inc.
Munmun De Choudhury, Meredith Ringel Morris, and
Ryen W. White. 2014. Seeking and Sharing Health
Information Online: Comparing Search Engines and
Social Media. In Procedings of CHI.
Jacob Eisenstein, Amr Ahmed, and Eric P. Xing. 2011.
Sparse Additive Generative Models of Text. In
ICML.
Kai Hong, Christian G. Kohler, Mary E. March, Am-
ber A. Parker, and Ani Nenkova. 2012. Lexi-
cal Differences in Autobiographical Narratives from
Schizophrenic Patients and Healthy Controls. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
37–47. Association for Computational Linguistics,
July.
David Newman, Jey Han Lau, Karl Grieser, and Tim-
othy Baldwin. 2010. Automatic evaluation of
topic coherence. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 100–108. Association for Computa-
tional Linguistics.
A. Taylor Newton, Adam D.I. Kramer, and Daniel N.
McIntosh. 2009. Autism online: a comparison
of word usage in bloggers with and without autism
spectrum disorders. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Sys-
tems, pages 463–466. ACM.
Thin Nguyen, Dinh Phung, and Svetha Venkatesh.
2013. Analysis of psycholinguistic processes and
topics in online autism communities. In Multimedia
and Expo (ICME), 2013 IEEE International Confer-
ence on, pages 1–6. IEEE.
Michael J. Paul and Mark Dredze. 2011. You Are
What You Tweet: Analyzing Twitter for Public
Health. In ICWSM.
Michael J. Paul and Mark Dredze. 2013. Drug Ex-
traction from the Web: Summarizing Drug Expe-
riences with Multi-Dimensional Topic Models. In
Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 168–178, Atlanta, Georgia, June. Association
for Computational Linguistics.
Philip Resnik, Anderson Garron, and Rebecca Resnik.
2013. Using Topic Modeling to Improve Prediction
of Neuroticism and Depression in College Students.
In Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing.
Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers,
and Padhraic Smyth. 2004. The Author-Topic
Model for Authors and Documents. In UAI.
Mark Schmidt, Ewout van den Berg, Michael P. Fried-
lander, and Kevin Muphy. 2009. Optimizing Costly
Functions with Simple Constraints: A Limited-
Memory Projected Quasi-Netton Algorithm. InAIS-
TATS.
Marina Sokolova and Victoria Bobicev. 2011. Sen-
timents and Opinions in Health-related Web mes-
sages. In Proceedings of the International Confer-
ence Recent Advances in Natural Language Pro-
cessing 2011, pages 132–139, Hissar, Bulgaria,
September. RANLP 2011 Organising Committee.
Marina Sokolova, Stan Matwin, Yasser Jafer, and
David Schramm. 2013. How Joe and Jane Tweet
about Their Health: Mining for Personal Health In-
formation on Twitter. In Proceedings of the In-
ternational Conference Recent Advances in Natu-
ral Language Processing RANLP 2013, pages 626–
632, Hissar, Bulgaria, September. INCOMA Ltd.
Shoumen, BULGARIA.
Mark Steyvers and Thomas Griffiths. 2005. Matlab
Topic Modeling Toolbox 1.4.
Mark Steyvers, Padhraic Smyth, and Thomas Griffiths.
2004. Probabilistic Author-Topic Models for Infor-
mation Discovery. In KDD.
Rannie Teodoro and Mor Naaman. 2013. Fitter with
Twitter: Understanding Personal Health and Fitness
Activity in Social Media. In Proceedings of the
7th International Conference on Weblogs and Social
Media.
Claudia Wagner, Vera Liao, Peter Pirolli, Les Nel-
son, and Markus Strohmaier. 2012. It’s not in
their tweets: Modeling topical expertise of Twitter
users. In ASE/IEEE International Conference on So-
cial Computing.
Martin J. Wainwright and Michael I. Jordan. 2008.
Graphical models, exponential families, and varia-
tional inference. Foundations and Trends in Ma-
chine Learning, 1(1-2):1–305.
</reference>
<page confidence="0.997321">
106
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.936207">
<title confidence="0.999523">Mining Themes and Interests in the Asperger’s and Autism Community</title>
<author confidence="0.999414">Yangfeng Ji</author>
<author confidence="0.999414">Hwajung Hong</author>
<author confidence="0.999414">Rosa Arriaga</author>
<author confidence="0.999414">Agata Rozga</author>
<author confidence="0.999414">Gregory Abowd</author>
<author confidence="0.999414">Jacob</author>
<affiliation confidence="0.997661">School of Interactive Georgia Institute of</affiliation>
<abstract confidence="0.997743407407407">Discussion forums offer a new source of insight for the experiences and challenges faced by individuals affected by mental disorders. Language technology can help domain experts gather insight from these forums, by aggregating themes and user behaviors across thousands of conversations. We present a novel model for web forums, which captures both thematic content as well as user-specific interests. Applying this model to the Aspies Central forum (which covers issues related to Asperger’s syndrome and autism spectrum disorder), we identify several topics of concern to individuals who report being on the autism spectrum. We perform the evaluation on the data collected from Aspies Central forum, including 1,939 threads, 29,947 posts and 972 users. Quantitative evaluations demonstrate that the topics extracted by this model are substantially more than those obtained by Latent Dirichlet Allocation and the Author-Topic Model. Qualitative analysis by subjectmatter experts suggests intriguing directions for future investigation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Jon D McAuliffe</author>
</authors>
<title>Supervised Topic Models.</title>
<date>2007</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="13050" citStr="Blei and McAuliffe, 2007" startWordPosition="2139" endWordPosition="2142">gether for a complete distribution over authorship for thread d: P(ad, |ed, y, Ω, b) a !a(r) di exp(eT dΩyi + bi) PAj=1 exp(eTdΩyj + bj) (q) exp(eTdΩ(1 − yi) + bi) ! di PAj= 1 exp(edO(1 − y�) + bj)a where ad = {a(q) d , a(r) d 1. The probability p(ad|Bd, y, Q, b) combines the authorship distribution of authors from question post and answer posts in thread d. The identity of the original question poster does not appear in the answer vector, since further posts are taken to be refinements of the original question. This model is similar in spirit to supervised latent Dirichlet allocation (sLDA) (Blei and McAuliffe, 2007). However, there are two key differences. First, sLDA uses point estimation to obtain a weight for each topic. In contrast, we perform Bayesian inference on the author-topic preference y. Second, sLDA generates the metadata from the dot-product of the weights and ¯z, while we use θ directly. The sLDA paper argues that there is a risk of overfitting, where some of the topics serve only to explain the metadata and never generate any of the text. This problem does not arise in our experiments. 3.3 Formal generative story We are now ready to formally define the generative process of our model: B. </context>
</contexts>
<marker>Blei, McAuliffe, 2007</marker>
<rawString>David M. Blei and Jon D. McAuliffe. 2007. Supervised Topic Models. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>the Journal of machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="3004" citStr="Blei et al, 2003" startWordPosition="471" endWordPosition="474">ses obvious challenges. Manual analysis is extremely time-consuming and labor-intensive, thus limiting the scope of data that can be considered. In addition, manual coding systems raise validity questions, because they can tacitly impose the preexisting views of the experimenter on all subsequent analysis. There is therefore a need for computational tools that support large-scale exploratory textual analysis of such forums. In this paper, we present a tool for automatically mining web forums to explore textual themes and user interests. Our system is based on Latent Dirichlet Allocation (LDA; Blei et al, 2003), but is customized for this setting in two key ways: • By modeling sparsely-varying topics, we can easily recover key terms of interest, while retaining robustness to large vocabulary and small counts (Eisenstein et al., 2011). • By modeling author preference by topic, we can quickly identify topics of interest for each user, and simultaneously recover topics that better distinguish the perspectives of each author. The key technical challenge in this work lies in bringing together several disparate modalities into 97 Workshop on Computational Linguistics and Clinical Psychology: From Linguist</context>
<context position="7706" citStr="Blei et al., 2003" startWordPosition="1162" endWordPosition="1165">bes a stochastic process by which the observed variables are emitted from prior probability distributions shaped by the latent variables. By performing Bayesian statistical inference in this model, we can recover a probability distribution around the latent variables of interest. We now describe the components of the model that generate each set of observed variables. The model is shown as a plate diagram in Figure 1, and the notation is summarized in Table 1. 3.1 Generating the text The part of the model which produces the text itself is similar to standard latent Dirichlet allocation (LDA) (Blei et al., 2003). We assume a set of K latent topics, which are distributions over each word in a finite vocabulary. These topics are m ηk α ed K wdpn zdpn yik ρ N ad P D Ω bi K A 98 Symbol Description D number of threads Pd number of posts in thread d Np number of word tokens in post p α parameter of topic distribution of threads Bd the multinomial distribution of topics specific to the thread d zdpn the topic associated with the nth token in post p of thread d wdpn the nth token in post p of thread d ad authorship distribution for question post and answer posts in thread d respectively yik the topic-prefere</context>
<context position="22470" citStr="Blei et al., 2003" startWordPosition="3836" endWordPosition="3839">coherent than topics from generic alternatives such as LDA and the author-topic model, which are not specifically designed for forums. 5.1 Experiment Setup Preprocessing Preprocessing was minimal. We tokenized texts using white space and removed punctuations at the beginning/end of each token. We removed words that appear less than five times, resulting in a vocabulary of the 4903 most frequently-used words. Baseline Models We considered two baseline models in the evaulation. The first baseline model is latent Dirichlet allocation (LDA), which considers only the text and ignores the metadata (Blei et al., 2003). The second baseline is the AuthorTopic (AT) model, which extends LDA by associating authors with topics (Rosen-Zvi et al., 2004; Steyvers et al., 2004). Both baselines are implemented in the Matlab Topic Modeling Toolbox (Steyvers and Griffiths, 2005). Parameter Settings For all three models, we set K = 50. Our model includes the three tunable parameters ρ, the Bernoulli prior on topic-specific expertise; σ2b, the variance prior on use selection D X d=1 Lψ = XA i=1 hp(yik|ρ)i − hq(yik|ψik)i K X k=1 K X k=1 ∂bi hlog P(ad|θd, y, Ω, b)i ≈ a(r) ∂ d,i− (14) D E D E a(r) + a(q) a(q) di |θd, y d,i </context>
<context position="34026" citStr="Blei et al., 2003" startWordPosition="5795" endWordPosition="5798">current paper, Nguyen et al. (2013) use LDA to discover autism-related topics, using a dataset of 10,000 posts from ten different autism commnities. However, their focus was on automated classification of communities as autism-related or not, rather than on analysis and on providing support for qualitative autism researchers. The applicability of the model developed in our paper towards classification tasks is a potential direction for future research. In general, topic models capture latent themes in document collections, characterizing each document in the collection as a mixture of topics (Blei et al., 2003). A natural extension of topic models is to infer the relationships between topics and metadata such as authorship or time. A relatively simple approach is to represent authors as an aggregation of the topics in all documents they have written (Wagner et al., 2012). More sophisticated topic models, such as Author-Topic (AT) model (Rosen-Zvi et al., 2004; Steyvers et al., 2004) assume that each document is generated by a mixture of its authors’ topic distributions. Our model can be viewed as one further extension of topic models by incorporating more metadata information (authorship, thread str</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Jordan L Boyd-Graber</author>
<author>Sean Gerrish</author>
<author>Chong Wang</author>
<author>David M Blei</author>
</authors>
<title>Reading Tea Leaves: How Humans Interpret Topic Models.</title>
<date>2009</date>
<pages>288--296</pages>
<editor>In Yoshua Bengio, Dale Schuurmans, John D. Lafferty, Christopher K. I. Williams, and Aron Culotta, editors, NIPS,</editor>
<publisher>Curran Associates, Inc.</publisher>
<contexts>
<context position="24758" citStr="Chang et al. (2009)" startWordPosition="4242" endWordPosition="4245">um disorder. The remaining three raters are not authors of the paper and are not domain experts. In the evaluation protocol, raters were presented with batteries of fifteen topics, from which they were asked to select the three most coherent. In each of the ten batteries, there were five topics from each model, permuted at random. Thus, after completing the task, all 150 topics — 50 topics from each model — were rated. The user interface of topic coherence evaluation is given in Figure 2, including the specific prompt. We note that this evaluation differs from the “intrusion task” proposed by Chang et al. (2009), in which raters are asked to guess which word was randomly inserted into a topic. While the intrusion task protocol avoids relying on subjective judgments of the meaning of “coherence,” it prevents expert raters from expressing a preference for topics that might be especially useful for analysis of autism spectrum disorder. Prior work has also shown that the variance of these tasks is high, making it difficult to distinguish between models. Table 2 shows, for each rater, the percentage of topics were chosen from each model as the most coherent within each battery. On average, 80% of the topi</context>
</contexts>
<marker>Chang, Boyd-Graber, Gerrish, Wang, Blei, 2009</marker>
<rawString>Jonathan Chang, Jordan L. Boyd-Graber, Sean Gerrish, Chong Wang, and David M. Blei. 2009. Reading Tea Leaves: How Humans Interpret Topic Models. In Yoshua Bengio, Dale Schuurmans, John D. Lafferty, Christopher K. I. Williams, and Aron Culotta, editors, NIPS, pages 288–296. Curran Associates, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Munmun De Choudhury</author>
<author>Meredith Ringel Morris</author>
<author>Ryen W White</author>
</authors>
<title>Seeking and Sharing Health Information Online: Comparing Search Engines and Social Media.</title>
<date>2014</date>
<booktitle>In Procedings of CHI.</booktitle>
<marker>De Choudhury, Morris, White, 2014</marker>
<rawString>Munmun De Choudhury, Meredith Ringel Morris, and Ryen W. White. 2014. Seeking and Sharing Health Information Online: Comparing Search Engines and Social Media. In Procedings of CHI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Amr Ahmed</author>
<author>Eric P Xing</author>
</authors>
<title>Sparse Additive Generative Models of Text.</title>
<date>2011</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="3231" citStr="Eisenstein et al., 2011" startWordPosition="507" endWordPosition="510">an tacitly impose the preexisting views of the experimenter on all subsequent analysis. There is therefore a need for computational tools that support large-scale exploratory textual analysis of such forums. In this paper, we present a tool for automatically mining web forums to explore textual themes and user interests. Our system is based on Latent Dirichlet Allocation (LDA; Blei et al, 2003), but is customized for this setting in two key ways: • By modeling sparsely-varying topics, we can easily recover key terms of interest, while retaining robustness to large vocabulary and small counts (Eisenstein et al., 2011). • By modeling author preference by topic, we can quickly identify topics of interest for each user, and simultaneously recover topics that better distinguish the perspectives of each author. The key technical challenge in this work lies in bringing together several disparate modalities into 97 Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 97–106, Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics a single modeling framework: text, authorship, and thread structure. We present a joint Bayes</context>
<context position="8826" citStr="Eisenstein et al., 2011" startWordPosition="1370" endWordPosition="1373">uthorship distribution for question post and answer posts in thread d respectively yik the topic-preference indicator of author i on topic k bi the Gaussian distribution of author i’s selection bias ηk topic k in log linear space m background topic Ω topic weights matrix v2 variance of feature weights λ v2 variance of selection bias b ρ prior probability of authors’ preference on any topic Table 1: Mathematical notations shared among all D threads in the collection, but each thread has its own distribution over the topics. We make use of the SAGE parametrization for generative models of text (Eisenstein et al., 2011). SAGE uses adaptive sparsity to induce topics that deviate from a background word distribution in only a few key words, without requiring a regularization parameter. The background distribution is written m, and the deviation for topic k is written ηk, so that Pr(w = v1ηk, m) a exp (mv + ηkv). Each word token wdpn (the nth word in post p of thread d) is generated from the probability distribution associated with a single topic, indexed by the latent variable zdpn E {1... K}. This latent variable is drawn from a prior θd, which is the probability distribution over topics associated with all po</context>
<context position="14885" citStr="Eisenstein et al., 2011" startWordPosition="2444" endWordPosition="2447">tions, topic indicators, and author-topic preference P(θ, z, y|w, a, x) with a mean field approximation where Pd is the number of posts in thread d, K is the number of topics, and Np is the number of word tokens in post Pd. The variational parameters of q(·) are γ, φ, ψ. We will write () to indicate an expectation under the distribution q(θ, z, y). We employ point estimates for the variables b (author selection bias), λ (topic-time feature weights), η (topic-word log-probability deviations), and diagonal elements of Q (topic weights). The estimation of η follows the procedure defined in SAGE (Eisenstein et al., 2011); we explain the estimation of the remaining parameters below. Given the variational distribution in Equation (5), the inference on our topic model can be formulated as constrained optimization of this bound. min G(7, O, ψ; b, A, Ω) s.t.7dk &gt; 0 `dd, k Xφdpn &gt; 0, Odpnk = 1 `dd, p, n (6) k 0 &lt; ψik &lt; 1 `di, k ωk &gt; 0 `dk The constraints are due to the parametric form of the variational approximation: q(θd|γd) is Dirichlet, and requires non-negative parameters; 2see http://probabilistic-programming. org/ q(e, z, y|7, O, ψ) = D Y d=1 Pd Y p=1 Np,dY n=1 q(zdpn|Odpn) YA i=1 K Y k=1 D Y d=1 q(yik|ψik) </context>
</contexts>
<marker>Eisenstein, Ahmed, Xing, 2011</marker>
<rawString>Jacob Eisenstein, Amr Ahmed, and Eric P. Xing. 2011. Sparse Additive Generative Models of Text. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Hong</author>
<author>Christian G Kohler</author>
<author>Mary E March</author>
<author>Amber A Parker</author>
<author>Ani Nenkova</author>
</authors>
<title>Lexical Differences in Autobiographical Narratives from Schizophrenic Patients and Healthy Controls.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>37--47</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="32971" citStr="Hong et al. (2012)" startWordPosition="5634" endWordPosition="5637">or estimating individual health status (Sokolova et al., 2013; Teodoro and Naaman, 2013). Domain-specific online communities, such Aspies Central, have their own advantages, targeting specific issues and featuring more closeknit and long-term relationships among members (Newton et al., 2009). Previous studies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatically distinguish schizophrenic patients from healthy individuals. Topic models have previously been used to mine health information: Resnik et al. (2013) use LDA to improve the prediction for neuroticism and depression on college students, while Paul and Dredze (2013) customize their factorial LDA to model the joint effect of drug, aspect, and route of administration. Most relevantly for the current paper, Nguyen et al. (2013) use LDA to discover autism-related topics, using a dataset of 10,000 posts from ten different autism commnities. However, their</context>
</contexts>
<marker>Hong, Kohler, March, Parker, Nenkova, 2012</marker>
<rawString>Kai Hong, Christian G. Kohler, Mary E. March, Amber A. Parker, and Ani Nenkova. 2012. Lexical Differences in Autobiographical Narratives from Schizophrenic Patients and Healthy Controls. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 37–47. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Newman</author>
<author>Jey Han Lau</author>
<author>Karl Grieser</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic evaluation of topic coherence.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>100--108</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="23797" citStr="Newman et al., 2010" startWordPosition="4080" endWordPosition="4083">e following experiments, we chose p = 0.2, Qb = 1.0, α = 1.0. LDA and AT share two parameters, α, the symmetric Dirichlet prior for document-topic distribution; Q, the symmetric Dirichlet prior for the topic-word distribution. In both models, we set α = 3.0 and Q = 0.01. All parameters were selected in advance of the experiments; further tuning of these paramters is left for future work. 5.2 Topic Coherence Evaluation To be useful, a topic model should produce topics that human readers judge to be coherent. While some automated metrics have been shown to cohere with human coherence judgments (Newman et al., 2010), it is possible that naive raters might have different judgments from subject matter experts. For this reason, we focused on human evaluation, including both expert and novice opinions. One rater, R1, is an author of the paper (HH) and a Ph.D. student focusing on designing technology to understand and support individuals with autism spectrum disorder. The remaining three raters are not authors of the paper and are not domain experts. In the evaluation protocol, raters were presented with batteries of fifteen topics, from which they were asked to select the three most coherent. In each of the </context>
</contexts>
<marker>Newman, Lau, Grieser, Baldwin, 2010</marker>
<rawString>David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic coherence. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 100–108. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Taylor Newton</author>
<author>Adam D I Kramer</author>
<author>Daniel N McIntosh</author>
</authors>
<title>Autism online: a comparison of word usage in bloggers with and without autism spectrum disorders.</title>
<date>2009</date>
<booktitle>In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,</booktitle>
<pages>463--466</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="32645" citStr="Newton et al., 2009" startWordPosition="5586" endWordPosition="5589">tral forum, we found most answer posts of user USER 15 are from the board “love104 relationships-and-dating”. 7 Related Work Social media has become an important source of health information (Choudhury et al., 2014). For example, Twitter has been used both for mining both public health information (Paul and Dredze, 2011) and for estimating individual health status (Sokolova et al., 2013; Teodoro and Naaman, 2013). Domain-specific online communities, such Aspies Central, have their own advantages, targeting specific issues and featuring more closeknit and long-term relationships among members (Newton et al., 2009). Previous studies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatically distinguish schizophrenic patients from healthy individuals. Topic models have previously been used to mine health information: Resnik et al. (2013) use LDA to improve the prediction for neuroticism and depression on college st</context>
</contexts>
<marker>Newton, Kramer, McIntosh, 2009</marker>
<rawString>A. Taylor Newton, Adam D.I. Kramer, and Daniel N. McIntosh. 2009. Autism online: a comparison of word usage in bloggers with and without autism spectrum disorders. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 463–466. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thin Nguyen</author>
<author>Dinh Phung</author>
<author>Svetha Venkatesh</author>
</authors>
<title>Analysis of psycholinguistic processes and topics in online autism communities.</title>
<date>2013</date>
<booktitle>In Multimedia and Expo (ICME), 2013 IEEE International Conference on,</booktitle>
<pages>1--6</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="33443" citStr="Nguyen et al. (2013)" startWordPosition="5704" endWordPosition="5707">rmative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatically distinguish schizophrenic patients from healthy individuals. Topic models have previously been used to mine health information: Resnik et al. (2013) use LDA to improve the prediction for neuroticism and depression on college students, while Paul and Dredze (2013) customize their factorial LDA to model the joint effect of drug, aspect, and route of administration. Most relevantly for the current paper, Nguyen et al. (2013) use LDA to discover autism-related topics, using a dataset of 10,000 posts from ten different autism commnities. However, their focus was on automated classification of communities as autism-related or not, rather than on analysis and on providing support for qualitative autism researchers. The applicability of the model developed in our paper towards classification tasks is a potential direction for future research. In general, topic models capture latent themes in document collections, characterizing each document in the collection as a mixture of topics (Blei et al., 2003). A natural exten</context>
</contexts>
<marker>Nguyen, Phung, Venkatesh, 2013</marker>
<rawString>Thin Nguyen, Dinh Phung, and Svetha Venkatesh. 2013. Analysis of psycholinguistic processes and topics in online autism communities. In Multimedia and Expo (ICME), 2013 IEEE International Conference on, pages 1–6. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Paul</author>
<author>Mark Dredze</author>
</authors>
<title>You Are What You Tweet: Analyzing Twitter for Public Health.</title>
<date>2011</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="32347" citStr="Paul and Dredze, 2011" startWordPosition="5542" endWordPosition="5545"> forum. Besides, we also find some other users participating in most of the interesting topics, such as USER 2 and USER 3. On the other hand, users like USER 14 and USER 15 only show up in few topics. This observation is supported by their activities on discussion boards. Searching on the Aspies Certral forum, we found most answer posts of user USER 15 are from the board “love104 relationships-and-dating”. 7 Related Work Social media has become an important source of health information (Choudhury et al., 2014). For example, Twitter has been used both for mining both public health information (Paul and Dredze, 2011) and for estimating individual health status (Sokolova et al., 2013; Teodoro and Naaman, 2013). Domain-specific online communities, such Aspies Central, have their own advantages, targeting specific issues and featuring more closeknit and long-term relationships among members (Newton et al., 2009). Previous studies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web mess</context>
</contexts>
<marker>Paul, Dredze, 2011</marker>
<rawString>Michael J. Paul and Mark Dredze. 2011. You Are What You Tweet: Analyzing Twitter for Public Health. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Paul</author>
<author>Mark Dredze</author>
</authors>
<title>Drug Extraction from the Web: Summarizing Drug Experiences with Multi-Dimensional Topic Models.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>168--178</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="33281" citStr="Paul and Dredze (2013)" startWordPosition="5678" endWordPosition="5681">dies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatically distinguish schizophrenic patients from healthy individuals. Topic models have previously been used to mine health information: Resnik et al. (2013) use LDA to improve the prediction for neuroticism and depression on college students, while Paul and Dredze (2013) customize their factorial LDA to model the joint effect of drug, aspect, and route of administration. Most relevantly for the current paper, Nguyen et al. (2013) use LDA to discover autism-related topics, using a dataset of 10,000 posts from ten different autism commnities. However, their focus was on automated classification of communities as autism-related or not, rather than on analysis and on providing support for qualitative autism researchers. The applicability of the model developed in our paper towards classification tasks is a potential direction for future research. In general, topi</context>
</contexts>
<marker>Paul, Dredze, 2013</marker>
<rawString>Michael J. Paul and Mark Dredze. 2013. Drug Extraction from the Web: Summarizing Drug Experiences with Multi-Dimensional Topic Models. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 168–178, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Anderson Garron</author>
<author>Rebecca Resnik</author>
</authors>
<title>Using Topic Modeling to Improve Prediction of Neuroticism and Depression in College Students.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="33166" citStr="Resnik et al. (2013)" startWordPosition="5660" endWordPosition="5663">issues and featuring more closeknit and long-term relationships among members (Newton et al., 2009). Previous studies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatically distinguish schizophrenic patients from healthy individuals. Topic models have previously been used to mine health information: Resnik et al. (2013) use LDA to improve the prediction for neuroticism and depression on college students, while Paul and Dredze (2013) customize their factorial LDA to model the joint effect of drug, aspect, and route of administration. Most relevantly for the current paper, Nguyen et al. (2013) use LDA to discover autism-related topics, using a dataset of 10,000 posts from ten different autism commnities. However, their focus was on automated classification of communities as autism-related or not, rather than on analysis and on providing support for qualitative autism researchers. The applicability of the model</context>
</contexts>
<marker>Resnik, Garron, Resnik, 2013</marker>
<rawString>Philip Resnik, Anderson Garron, and Rebecca Resnik. 2013. Using Topic Modeling to Improve Prediction of Neuroticism and Depression in College Students. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Rosen-Zvi</author>
<author>Thomas Griffiths</author>
<author>Mark Steyvers</author>
<author>Padhraic Smyth</author>
</authors>
<title>The Author-Topic Model for Authors and Documents.</title>
<date>2004</date>
<booktitle>In UAI.</booktitle>
<contexts>
<context position="22599" citStr="Rosen-Zvi et al., 2004" startWordPosition="3858" endWordPosition="3861">r forums. 5.1 Experiment Setup Preprocessing Preprocessing was minimal. We tokenized texts using white space and removed punctuations at the beginning/end of each token. We removed words that appear less than five times, resulting in a vocabulary of the 4903 most frequently-used words. Baseline Models We considered two baseline models in the evaulation. The first baseline model is latent Dirichlet allocation (LDA), which considers only the text and ignores the metadata (Blei et al., 2003). The second baseline is the AuthorTopic (AT) model, which extends LDA by associating authors with topics (Rosen-Zvi et al., 2004; Steyvers et al., 2004). Both baselines are implemented in the Matlab Topic Modeling Toolbox (Steyvers and Griffiths, 2005). Parameter Settings For all three models, we set K = 50. Our model includes the three tunable parameters ρ, the Bernoulli prior on topic-specific expertise; σ2b, the variance prior on use selection D X d=1 Lψ = XA i=1 hp(yik|ρ)i − hq(yik|ψik)i K X k=1 K X k=1 ∂bi hlog P(ad|θd, y, Ω, b)i ≈ a(r) ∂ d,i− (14) D E D E a(r) + a(q) a(q) di |θd, y d,i − di |θd, y ∂L D d=1 = ∂ωk ∂ωk (12) XA i=1 102 bias; and α, the prior on document-topic distribution. In the following experiment</context>
<context position="34381" citStr="Rosen-Zvi et al., 2004" startWordPosition="5854" endWordPosition="5857">e model developed in our paper towards classification tasks is a potential direction for future research. In general, topic models capture latent themes in document collections, characterizing each document in the collection as a mixture of topics (Blei et al., 2003). A natural extension of topic models is to infer the relationships between topics and metadata such as authorship or time. A relatively simple approach is to represent authors as an aggregation of the topics in all documents they have written (Wagner et al., 2012). More sophisticated topic models, such as Author-Topic (AT) model (Rosen-Zvi et al., 2004; Steyvers et al., 2004) assume that each document is generated by a mixture of its authors’ topic distributions. Our model can be viewed as one further extension of topic models by incorporating more metadata information (authorship, thread structure) in online forums. 8 Conclusion This paper describes how topic models can offer insights on the issues and challenges faced by individuals on the autism spectrum. In particular, we demonstrate that by unifying textual content with authorship and thread structure metadata, we can obtain more coherent topics and better understand user activity patt</context>
</contexts>
<marker>Rosen-Zvi, Griffiths, Steyvers, Smyth, 2004</marker>
<rawString>Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers, and Padhraic Smyth. 2004. The Author-Topic Model for Authors and Documents. In UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Schmidt</author>
<author>Ewout van den Berg</author>
<author>Michael P Friedlander</author>
<author>Kevin Muphy</author>
</authors>
<title>Optimizing Costly Functions with Simple Constraints: A LimitedMemory Projected Quasi-Netton Algorithm.</title>
<date>2009</date>
<publisher>InAISTATS.</publisher>
<marker>Schmidt, van den Berg, Friedlander, Muphy, 2009</marker>
<rawString>Mark Schmidt, Ewout van den Berg, Michael P. Friedlander, and Kevin Muphy. 2009. Optimizing Costly Functions with Simple Constraints: A LimitedMemory Projected Quasi-Netton Algorithm. InAISTATS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Sokolova</author>
<author>Victoria Bobicev</author>
</authors>
<title>Sentiments and Opinions in Health-related Web messages.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing</booktitle>
<pages>132--139</pages>
<location>Hissar, Bulgaria,</location>
<contexts>
<context position="32868" citStr="Sokolova and Bobicev (2011)" startWordPosition="5618" endWordPosition="5621"> For example, Twitter has been used both for mining both public health information (Paul and Dredze, 2011) and for estimating individual health status (Sokolova et al., 2013; Teodoro and Naaman, 2013). Domain-specific online communities, such Aspies Central, have their own advantages, targeting specific issues and featuring more closeknit and long-term relationships among members (Newton et al., 2009). Previous studies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatically distinguish schizophrenic patients from healthy individuals. Topic models have previously been used to mine health information: Resnik et al. (2013) use LDA to improve the prediction for neuroticism and depression on college students, while Paul and Dredze (2013) customize their factorial LDA to model the joint effect of drug, aspect, and route of administration. Most relevantly for the current paper, Nguyen et al. (2013) use LDA to discover auti</context>
</contexts>
<marker>Sokolova, Bobicev, 2011</marker>
<rawString>Marina Sokolova and Victoria Bobicev. 2011. Sentiments and Opinions in Health-related Web messages. In Proceedings of the International Conference Recent Advances in Natural Language Processing 2011, pages 132–139, Hissar, Bulgaria, September. RANLP 2011 Organising Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Sokolova</author>
<author>Stan Matwin</author>
<author>Yasser Jafer</author>
<author>David Schramm</author>
</authors>
<title>How Joe and Jane Tweet about Their Health: Mining for Personal Health Information on Twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013,</booktitle>
<pages>626--632</pages>
<publisher>INCOMA Ltd. Shoumen, BULGARIA.</publisher>
<location>Hissar, Bulgaria,</location>
<contexts>
<context position="32414" citStr="Sokolova et al., 2013" startWordPosition="5553" endWordPosition="5556"> of the interesting topics, such as USER 2 and USER 3. On the other hand, users like USER 14 and USER 15 only show up in few topics. This observation is supported by their activities on discussion boards. Searching on the Aspies Certral forum, we found most answer posts of user USER 15 are from the board “love104 relationships-and-dating”. 7 Related Work Social media has become an important source of health information (Choudhury et al., 2014). For example, Twitter has been used both for mining both public health information (Paul and Dredze, 2011) and for estimating individual health status (Sokolova et al., 2013; Teodoro and Naaman, 2013). Domain-specific online communities, such Aspies Central, have their own advantages, targeting specific issues and featuring more closeknit and long-term relationships among members (Newton et al., 2009). Previous studies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatica</context>
</contexts>
<marker>Sokolova, Matwin, Jafer, Schramm, 2013</marker>
<rawString>Marina Sokolova, Stan Matwin, Yasser Jafer, and David Schramm. 2013. How Joe and Jane Tweet about Their Health: Mining for Personal Health Information on Twitter. In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013, pages 626– 632, Hissar, Bulgaria, September. INCOMA Ltd. Shoumen, BULGARIA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Thomas Griffiths</author>
</authors>
<date>2005</date>
<journal>Matlab Topic Modeling Toolbox</journal>
<volume>1</volume>
<contexts>
<context position="22723" citStr="Steyvers and Griffiths, 2005" startWordPosition="3878" endWordPosition="3881">ved punctuations at the beginning/end of each token. We removed words that appear less than five times, resulting in a vocabulary of the 4903 most frequently-used words. Baseline Models We considered two baseline models in the evaulation. The first baseline model is latent Dirichlet allocation (LDA), which considers only the text and ignores the metadata (Blei et al., 2003). The second baseline is the AuthorTopic (AT) model, which extends LDA by associating authors with topics (Rosen-Zvi et al., 2004; Steyvers et al., 2004). Both baselines are implemented in the Matlab Topic Modeling Toolbox (Steyvers and Griffiths, 2005). Parameter Settings For all three models, we set K = 50. Our model includes the three tunable parameters ρ, the Bernoulli prior on topic-specific expertise; σ2b, the variance prior on use selection D X d=1 Lψ = XA i=1 hp(yik|ρ)i − hq(yik|ψik)i K X k=1 K X k=1 ∂bi hlog P(ad|θd, y, Ω, b)i ≈ a(r) ∂ d,i− (14) D E D E a(r) + a(q) a(q) di |θd, y d,i − di |θd, y ∂L D d=1 = ∂ωk ∂ωk (12) XA i=1 102 bias; and α, the prior on document-topic distribution. In the following experiments, we chose p = 0.2, Qb = 1.0, α = 1.0. LDA and AT share two parameters, α, the symmetric Dirichlet prior for document-topic</context>
</contexts>
<marker>Steyvers, Griffiths, 2005</marker>
<rawString>Mark Steyvers and Thomas Griffiths. 2005. Matlab Topic Modeling Toolbox 1.4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Padhraic Smyth</author>
<author>Thomas Griffiths</author>
</authors>
<title>Probabilistic Author-Topic Models for Information Discovery.</title>
<date>2004</date>
<booktitle>In KDD.</booktitle>
<contexts>
<context position="4297" citStr="Steyvers et al., 2004" startWordPosition="666" endWordPosition="669">une 27, 2014. c�2014 Association for Computational Linguistics a single modeling framework: text, authorship, and thread structure. We present a joint Bayesian graphical model that unifies these facets, discovering both an underlying set of topical themes, and the relationship of these themes to authors. We derive a variational inference algorithm for this model, and apply the resulting software on a dataset gathered from Aspies Central. The topics and insights produced by our system are evaluated both quantitatively and qualitatively. In a blind comparison with LDA and the authortopic model (Steyvers et al., 2004), both subjectmatter experts and lay users find the topics generated by our system to be substantially more coherent and relevant. A subsequent qualitative analysis aligns these topics with existing theory about the autism spectrum, and suggests new potential insights and avenues for future investigation. 2 Aspies Central Forum Aspies Central (AC) is an online forum for individuals on the autism spectrum, and has publicly accessible discussion boards. Members of the site do not necessarily have to have an official diagnosis of autism or a related condition. Neurotypical individuals (people not</context>
<context position="22623" citStr="Steyvers et al., 2004" startWordPosition="3862" endWordPosition="3865"> Setup Preprocessing Preprocessing was minimal. We tokenized texts using white space and removed punctuations at the beginning/end of each token. We removed words that appear less than five times, resulting in a vocabulary of the 4903 most frequently-used words. Baseline Models We considered two baseline models in the evaulation. The first baseline model is latent Dirichlet allocation (LDA), which considers only the text and ignores the metadata (Blei et al., 2003). The second baseline is the AuthorTopic (AT) model, which extends LDA by associating authors with topics (Rosen-Zvi et al., 2004; Steyvers et al., 2004). Both baselines are implemented in the Matlab Topic Modeling Toolbox (Steyvers and Griffiths, 2005). Parameter Settings For all three models, we set K = 50. Our model includes the three tunable parameters ρ, the Bernoulli prior on topic-specific expertise; σ2b, the variance prior on use selection D X d=1 Lψ = XA i=1 hp(yik|ρ)i − hq(yik|ψik)i K X k=1 K X k=1 ∂bi hlog P(ad|θd, y, Ω, b)i ≈ a(r) ∂ d,i− (14) D E D E a(r) + a(q) a(q) di |θd, y d,i − di |θd, y ∂L D d=1 = ∂ωk ∂ωk (12) XA i=1 102 bias; and α, the prior on document-topic distribution. In the following experiments, we chose p = 0.2, Qb </context>
<context position="34405" citStr="Steyvers et al., 2004" startWordPosition="5858" endWordPosition="5861"> paper towards classification tasks is a potential direction for future research. In general, topic models capture latent themes in document collections, characterizing each document in the collection as a mixture of topics (Blei et al., 2003). A natural extension of topic models is to infer the relationships between topics and metadata such as authorship or time. A relatively simple approach is to represent authors as an aggregation of the topics in all documents they have written (Wagner et al., 2012). More sophisticated topic models, such as Author-Topic (AT) model (Rosen-Zvi et al., 2004; Steyvers et al., 2004) assume that each document is generated by a mixture of its authors’ topic distributions. Our model can be viewed as one further extension of topic models by incorporating more metadata information (authorship, thread structure) in online forums. 8 Conclusion This paper describes how topic models can offer insights on the issues and challenges faced by individuals on the autism spectrum. In particular, we demonstrate that by unifying textual content with authorship and thread structure metadata, we can obtain more coherent topics and better understand user activity patterns. This coherence is </context>
</contexts>
<marker>Steyvers, Smyth, Griffiths, 2004</marker>
<rawString>Mark Steyvers, Padhraic Smyth, and Thomas Griffiths. 2004. Probabilistic Author-Topic Models for Information Discovery. In KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rannie Teodoro</author>
<author>Mor Naaman</author>
</authors>
<title>Fitter with Twitter: Understanding Personal Health and Fitness Activity in Social Media.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="32441" citStr="Teodoro and Naaman, 2013" startWordPosition="5557" endWordPosition="5560">ics, such as USER 2 and USER 3. On the other hand, users like USER 14 and USER 15 only show up in few topics. This observation is supported by their activities on discussion boards. Searching on the Aspies Certral forum, we found most answer posts of user USER 15 are from the board “love104 relationships-and-dating”. 7 Related Work Social media has become an important source of health information (Choudhury et al., 2014). For example, Twitter has been used both for mining both public health information (Paul and Dredze, 2011) and for estimating individual health status (Sokolova et al., 2013; Teodoro and Naaman, 2013). Domain-specific online communities, such Aspies Central, have their own advantages, targeting specific issues and featuring more closeknit and long-term relationships among members (Newton et al., 2009). Previous studies on mining health information show that technical models and tools from computational linguistics are helpful for both understanding contents and providing informative features. Sokolova and Bobicev (2011) use sentiment analysis to analyze opinions expressed in healthrelated Web messages; Hong et al. (2012) focus on lexical differences to automatically distinguish schizophren</context>
</contexts>
<marker>Teodoro, Naaman, 2013</marker>
<rawString>Rannie Teodoro and Mor Naaman. 2013. Fitter with Twitter: Understanding Personal Health and Fitness Activity in Social Media. In Proceedings of the 7th International Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Wagner</author>
<author>Vera Liao</author>
<author>Peter Pirolli</author>
<author>Les Nelson</author>
<author>Markus Strohmaier</author>
</authors>
<title>It’s not in their tweets: Modeling topical expertise of Twitter users.</title>
<date>2012</date>
<booktitle>In ASE/IEEE International Conference on Social Computing.</booktitle>
<contexts>
<context position="34291" citStr="Wagner et al., 2012" startWordPosition="5841" endWordPosition="5844">sis and on providing support for qualitative autism researchers. The applicability of the model developed in our paper towards classification tasks is a potential direction for future research. In general, topic models capture latent themes in document collections, characterizing each document in the collection as a mixture of topics (Blei et al., 2003). A natural extension of topic models is to infer the relationships between topics and metadata such as authorship or time. A relatively simple approach is to represent authors as an aggregation of the topics in all documents they have written (Wagner et al., 2012). More sophisticated topic models, such as Author-Topic (AT) model (Rosen-Zvi et al., 2004; Steyvers et al., 2004) assume that each document is generated by a mixture of its authors’ topic distributions. Our model can be viewed as one further extension of topic models by incorporating more metadata information (authorship, thread structure) in online forums. 8 Conclusion This paper describes how topic models can offer insights on the issues and challenges faced by individuals on the autism spectrum. In particular, we demonstrate that by unifying textual content with authorship and thread struc</context>
</contexts>
<marker>Wagner, Liao, Pirolli, Nelson, Strohmaier, 2012</marker>
<rawString>Claudia Wagner, Vera Liao, Peter Pirolli, Les Nelson, and Markus Strohmaier. 2012. It’s not in their tweets: Modeling topical expertise of Twitter users. In ASE/IEEE International Conference on Social Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Wainwright</author>
<author>Michael I Jordan</author>
</authors>
<title>Graphical models, exponential families, and variational inference. Foundations and Trends</title>
<date>2008</date>
<booktitle>in Machine Learning,</booktitle>
<pages>1--1</pages>
<contexts>
<context position="14196" citStr="Wainwright and Jordan, 2008" startWordPosition="2328" endWordPosition="2331">story We are now ready to formally define the generative process of our model: B. Draw word wdpn — Mult(βzdpn) 4 Inference and estimation The purpose of inference and estimation is to recover probability distributions and point estimates for the quantities of interest: the content of the topics, the assignment of topics to threads, author preferences for each topic, etc. While recent progress in probabilistic programming has improved capabilities for automating inference and estimation directly from the model specification,2 here we develop a custom algorithm, based on variational mean field (Wainwright and Jordan, 2008). Specifically, we approximate the distribution over topic proportions, topic indicators, and author-topic preference P(θ, z, y|w, a, x) with a mean field approximation where Pd is the number of posts in thread d, K is the number of topics, and Np is the number of word tokens in post Pd. The variational parameters of q(·) are γ, φ, ψ. We will write () to indicate an expectation under the distribution q(θ, z, y). We employ point estimates for the variables b (author selection bias), λ (topic-time feature weights), η (topic-word log-probability deviations), and diagonal elements of Q (topic weig</context>
</contexts>
<marker>Wainwright, Jordan, 2008</marker>
<rawString>Martin J. Wainwright and Michael I. Jordan. 2008. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1-2):1–305.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>