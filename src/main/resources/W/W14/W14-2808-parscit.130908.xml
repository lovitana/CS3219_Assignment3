<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.029853">
<title confidence="0.958265">
10 Open Questions in Computational Morphonology
</title>
<author confidence="0.99371">
Grzegorz Kondrak
</author>
<affiliation confidence="0.9988655">
Department of Computing Science
University of Alberta
</affiliation>
<email confidence="0.983801">
gkondrak@ualberta.ca
</email>
<sectionHeader confidence="0.993609" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998758875">
The objective of this paper is to initi-
ate discussion within the SIGMORPHON
community around several issues that in-
volve computational morphology, phonol-
ogy, phonetics, orthography, syllabifica-
tion, transliteration, machine translation,
inflection generation, and native language
identification.
</bodyText>
<sectionHeader confidence="0.933753" genericHeader="keywords">
1 Morphology in Machine Translation
</sectionHeader>
<bodyText confidence="0.99998875">
In contrast with English, which is a morpho-
logically simple language, many languages have
dozens of different wordforms for any given
lemma, some of which are unattested even in
large monolingual corpora. In Statistical Machine
Translation (SMT), lexical sparsity in such lan-
guages is often addressed by performing morpho-
logical segmentation, which simplifies the cor-
respondence between the tokens in the source
and target language. When translating into En-
glish from a morphologically complex language,
the segmentation is a form of preprocessing per-
formed before the the translation process. Since
the English words are not segmented, the output
of the decoder can be directly compared to the
reference translation. However, when translating
in the opposite direction, the segmentation must
be reversed to make the generated text readable.
Desegmentation is typically performed as a post-
processing step that is independent from the de-
coding process. Unfortunately, the pipeline ap-
proach may prevent the desegmenter from recov-
ering from errors made by the decoder, including
output morpheme sequences that cannot be com-
bined into valid words.
Salameh et al. (2014) propose to replace the
pipeline approach with a solution inspired by
finite-state methods. They perform desegmenta-
tion directly on the search graph of a phrase-based
decoder, which is represented as a lattice encoding
a large set of possible decoder outputs. The lattice,
which can be interpreted as a finite–state accep-
tor over target strings, is composed with a deseg-
menting transducer which consumes morphemes
and outputs desegmented words. The desegment-
ing transducer, in turn, is constructed from a ta-
ble that maps morpheme sequences to words. The
lattice desegmentation algorithm effectively com-
bines both segmented and desegmented views of
the target language, and allows for inclusion of
features related to the desegmentation process, as
well as an unsegmented language model. The re-
sults on English-to-Arabic indicate significant im-
provements in translation quality. However, the
morphology of Arabic is largely concatenative,
with relatively simple morpheme-boundary adap-
tations. In contrast, many European languages are
classified as inflecting, with affixes that represent
several rather than a single morpheme. The ques-
tion remains whether a morphologically-aware ap-
proach can be developed to improve translation
into inflecting languages as well.
</bodyText>
<sectionHeader confidence="0.985477" genericHeader="introduction">
2 Inflection Generation
</sectionHeader>
<bodyText confidence="0.99987775">
An alternative to the morphological segmentation
approach is to reduce the diverse forms in the
training bitext to lemmas, and, at test time, re-
construct the wordforms in the target language di-
rectly from lemmas annotated with morphological
features. Note that the wordforms that have not
been seen in training pose a problem for language
models, and are typically shunned by the current
SMT systems.
Although complex morphology leads to a high
type-to-token ratio, words tend fo fall into certain
inflectional paradigms. Individual inflections are
obtained by combining a specific affix with a stem.
These combinations are rarely concatenative, of-
ten affecting characters at the end or even in the
middle of a stem.
</bodyText>
<page confidence="0.991744">
64
</page>
<bodyText confidence="0.961901034482759">
Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 64–68,
Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics
For languages without hand-built morphologi-
cal analyzers and generators, automated learning
of morphological paradigms is the only option.
Dreyer and Eisner (2011) propose a Dirichlet pro-
cess mixture model and loopy belief propagation
to learn complete paradigms starting from an ini-
tial small set of seed paradigms. An unannotated
corpus is utilized to guide the predictions of the
model by reducing the likelihood of generating
unseen wordforms. Durrett and DeNero (2013)
align the lemmas with inflected forms to identify
spans that change for the inflections, and learn ex-
plicit rules for applying those changes in contexts
in which they appear. Their joint model is aware of
complete paradigms, and is able to correct errors
made on individual inflections.
Nicolai et al. (2014) train a discriminative
string transducer on lemma-inflection pairs, and
apply a separate re-ranking step to take advan-
tage of the paradigmatic constraints. In spite of
its relative simplicity, their string transduction ap-
proach outperforms the previous approaches to
learning morphological paradigms on several Eu-
ropean languages. The question remains whether
the string transduction approach is also superior to
more complex methods on languages with differ-
ent morphological systems.
</bodyText>
<sectionHeader confidence="0.980658" genericHeader="method">
3 From Syntax to Morphology
</sectionHeader>
<bodyText confidence="0.999747346153846">
In some languages, syntactic function of phrases is
mainly marked by word position and prepositions,
while other languages rely on morphology to a
greater degree. Similarly, verbal attributes such as
tense, person, and gender, can be either encoded
morphologically or lexically. Chahuneau et al.
(2013) propose a discriminative model for trans-
lating into morphologically rich languages that
predicts inflections of target words from source-
side annotations that include POS tags, depen-
dency parses, and semantic clusters. In other
words, they exploit the syntax of the source lan-
guage to select the most likely wordforms in the
target language,
The open question in this case is whether in-
stead of learning a prediction model separately
for each language pair, the morphological features
could be mapped directly on the source words. For
example, in the phrase she would have asked, the
actual morphological marking is minimal, but the
context disambiguates the person, number, gender,
and aspect of the verb. Explicit morphological an-
notation could not only help machine translation,
but also provide a rich source of information in the
monolingual context, which would go well beyond
POS tagging.
</bodyText>
<sectionHeader confidence="0.635927" genericHeader="method">
4 Transliteration and Morphology
</sectionHeader>
<bodyText confidence="0.999717488888889">
Transliteration is sometimes defined as “phonetic
translation” (Knight and Graehl, 1997). In fact, it
is straightforward to train a transliteration model
using SMT toolkits by treating individual char-
acters as words, and words as sentences. How-
ever, unless substantial modifications are made,
the accuracy of such a system will be mediocre.
Transliteration needs a dedicated approach in or-
der to fully exploit the source-side context and
other constraints.
The way we define tasks in NLP is important,
because the definitions (and shared tasks) tend to
guide research in a particular direction. New pa-
pers are expected to show improvement over pre-
viously published results, preferably on already
established benchmarks. Redefining a task car-
ries the risk of being interpreted as an attempt to
avoid a fair experimental comparison, or as a mis-
directed effort to investigate irrelevant problems.
The NEWS Shared Task on Machine Translit-
eration was held four times between 2009 and
2012 (Zhang et al., 2012). With the exception
of the 2010 edition that included a transliteration
mining task, the shared task was invariably de-
fined in terms of learning transliteration models
from the training sets of word pairs. This frame-
work seems to ignore the fact that many of the
transliteration target words can be found in mono-
lingual corpora, in a marked contrast with the
prevalent SMT practice of avoiding unseen words.
Cherry and Suzuki (2009) show that the inclusion
of a target lexicon dramatically improves translit-
eration accuracy. Unfortunately, the paper has
largely been ignored by the transliteration commu-
nity (perhaps because it strays from the standard
task formulation), as well as the SMT community
(perhaps because it shows only modest gains in
terms of BLEU score).
Another drawback of limiting the training data
to a list of name pairs is the lack of the con-
text that is required to account for morphologi-
cal alterations. For example, the title of the Rus-
sian Wikipedia page that corresponds to Pres-
idency of Barack Obama back-transliterates as
Presidentstvo Baraka Obamy, where the personal
</bodyText>
<page confidence="0.998231">
65
</page>
<bodyText confidence="0.999911">
name appears in the genetive case. Simply in-
cluding morphological variants in the training data
without their context is likely to confuse a translit-
eration model. How to best combine translitera-
tion with morphology remains an open question.
</bodyText>
<sectionHeader confidence="0.872406" genericHeader="method">
5 Transliteration and Orthography
</sectionHeader>
<bodyText confidence="0.999964153846154">
Transliteration is more than just phonetic transla-
tion. In the idealized model of Knight and Graehl
(1997) a human transliterator pronounces a name
in the source language, modifies the pronunciation
to fit the target language phonology, and writes
it down using the orthographic rules of the target
script. In reality, however, the source orthography
strongly influences the form of the transliteration.
For example, the Russian transliteration of the
name Dickens on Wikipedia back-transliterates as
Dikkens, although Dykynz would be much closer
to the original pronunciation. For less well-known
names that first appear in English-language news,
human transliterators are often in the dark because
the correct pronunciation may be difficult to guess
from the spelling.
Al-Onaizan and Knight (2002) report that a
spelling-based model outperforms a phonetic-
based model even when pronunciations are ex-
tracted from a pronunciation dictionary. Bhargava
and Kondrak (2012) present a re-ranking approach
that is able to improve spelling-based models by
consulting the supplied pronunciations. It remains
an open question how to design a superior joint
model that would generate transliterations directly
from both spelling and pronunciation.
</bodyText>
<sectionHeader confidence="0.99548" genericHeader="method">
6 Transliteration and Decipherment
</sectionHeader>
<bodyText confidence="0.9999865">
Although transliteration is typically defined as
conversion between writing scripts, the proper
form strongly depends on the particular target lan-
guage with its phonological and orthographic con-
straints. For example, the name of the city that
hosted the recent Winter Olympics is represented
in various European languages as Sochi, Sotchi,
Sotschi, Sotsji, Sotji, Sotˇsi, Soˇci, Soczi, Szocsi, etc.
In order to derive language-specific transliteration
models, we would need to collect training data for
thousands of possible language pairs.
Ravi and Knight (2009) introduce the task of
unsupervised transliteration without parallel re-
sources. They formulate the problem as decipher-
ment, and reconstruct cross-lingual phoneme map-
ping tables from Japanese words of English origin,
achieving approximately 50% character accuracy
on U.S. names written in the Katakana script.
Hauer et al. (2014) frame transliteration as
a substitution cipher, and apply a mixture of
character- and word-level language models to the
decipherment of a known language written in an
unknown script. The authors treat a short text in
Serbian as enciphered Croatian, and attempt to re-
cover the “key”, which is the mapping between the
characters in the two writing scripts. In reality,
Croatian and Serbian are distinct but closely re-
lated languages, that are written in different scripts
and exhibit differences in both lexicon and gram-
mar. In particular, 30 Serbian Cyrillic characters
correspond to 27 letters in Croatian Latin, with
three of the characters represented in the other
script as digraphs (e.g., nj). The decipherment
error rate plateaus at about 3% at the ciphertext
length of 50 words. In contrast, a pure frequency-
based approach fails on this task with a mapping
error rate close to 90%. The question remains
whether a more flexible approach could be applied
successfully to unsupervised transliteration of lan-
guages that are less closely related.
</bodyText>
<sectionHeader confidence="0.972334" genericHeader="method">
7 Phonetic Similarity of Translations
</sectionHeader>
<bodyText confidence="0.99970384">
Words that are phonetically similar across differ-
ent languages tend to be transliterations, or at least
share the same origin. For this reason, words
on two sides of a bitext are more likely to corre-
spond to each other if they exhibit phonetic simi-
larity (Kondrak, 2005). This is true even for com-
pletely unrelated languages because of the preva-
lence of loanwords, proper names, and techni-
cal terms. Orthographic similarity, which reflects
phonetic similarity, has been exploited in the past
to improve word and sentence alignment in SMT,
and other NLP tasks.
Surprisingly, the correlation with phonetic sim-
ilarity appears to hold for any translations, defined
as words that express the same meaning in some
context. Kondrak (2013) observes that even after
all cognates and loanwords are removed from con-
sideration, the similarity between the words from
different languages for the same concept is signif-
icantly higher on average than the similarity be-
tween the words for different concepts (as mea-
sured by the Longest Common Subsequence Ra-
tio). This seems to contradict the Saussurean prin-
ciple of the arbitrariness of the linguistic sign.
Kondrak (2013) proposes to explain this phe-
</bodyText>
<page confidence="0.978957">
66
</page>
<bodyText confidence="0.99990315">
nomenon by positing a chain of correlations be-
tween the following word characteristics: trans-
latability, frequency, length, and similarity. The
key observation is that translations are on aver-
age closer in terms of their length than random
words. First, pairs of cross-lingual translations ex-
hibit a correlation with respect to the logarithm of
their frequencies. Intuitively, translations refer to
the same semantic concepts, which tend to be ex-
pressed with similar frequency across languages.
Second, the connection between word frequency
and length is well established (Zipf, 1936). Fi-
nally, pairs of words that differ in length are less
likely to be considered similar, which is reflected
by word similarity measures. In summary, the rea-
son for the greater phonetic similarity of trans-
lations lies in the similarity of their frequencies,
which is reflected by the similarity of their lengths.
This hypothesis remains to be verified on other
languages and data sets.
</bodyText>
<subsectionHeader confidence="0.318761">
8 L1 Phonology in L2
</subsectionHeader>
<bodyText confidence="0.999966352941176">
The task of Native Language Identification (NLI)
is to determine the first language (L1) of the writer
of a text in another language (L2) (Tetreault et
al., 2013). Koppel et al. (2005) report 80% ac-
curacy in classifying a set of English texts into
five L1 languages using a multi-class linear SVM
with features including function words, POS bi-
grams, and character n-grams. Tsur and Rap-
poport (2007) observe that limiting the set of fea-
tures to the relative frequency of the 200 most fre-
quent character bigrams yields a respectable ac-
curacy of about 65%. They interpret this as evi-
dence that the choice of words in L2 is strongly
influenced by the phonology of L1. As the orthog-
raphy of alphabetic languages is representative of
their phonology, character bigrams appear to cap-
ture these phonetic preferences.
In order to test the above hypothesis, Nico-
lai and Kondrak (2014) design an algorithm to
identify the most discriminative words and the
corresponding character bigrams. They find that
the removal of such words results in a substan-
tial drop in the accuracy of the classifier that is
based exclusively on character bigrams, and that
the majority of the most indicative character bi-
grams are common among different language sets.
They conclude that the effectiveness of a bigram-
based classifier in identifying the native language
of a writer is primarily driven by the relative fre-
quency of words rather than by the influence of
the phonology of L1. Although this provides ev-
idence against the hypothesis of Tsur and Rap-
poport (2007), the question to what degree the L1
phonology affects L2 writing remains open.
</bodyText>
<sectionHeader confidence="0.761153" genericHeader="method">
9 English Orthography
</sectionHeader>
<bodyText confidence="0.9971293">
The English spelling system is notorious for its
irregularity. Kominek and Black (2006) estimate
that it is about 3 times more complex than German,
and 40 times more complex than Spanish. This is
confirmed by lower accuracy of letter-to-phoneme
systems on English (Bisani and Ney, 2008). A
survey of English spelling (Carney, 1994) devotes
120 pages to describe phoneme-to-letter corre-
spondences, and lists 226 letter-to-phoneme rules,
almost all of which admit exceptions.
In view of this, the claim of Chomsky and Halle
(1968) that English orthography is “close to opti-
mal” could be interpreted as facetious. The ques-
tion is how we could validate the accuracy of this
statement from the computational perspective. It
would seem to require answering at least the fol-
lowing three questions: (a) what is the optimal or-
thography for English, (b) how to measure the dis-
tance between alternative orthographies, and (c)
what distance should be considered “close”.
</bodyText>
<sectionHeader confidence="0.882888" genericHeader="conclusions">
10 Syllabification and Morphology
</sectionHeader>
<bodyText confidence="0.999806909090909">
Orthographic syllabification of words is some-
times referred to as hyphenation. Bartlett et al.
(2008) propose a sequence prediction approach to
syllabify out-of-dictionary words based on letter
n-gram features. Despite its high accuracy, their
system suffers from the lack of awareness of com-
pound nouns and other morphological phenom-
ena. For example, hold-o-ver is incorrectly syl-
labified as hol-dov-er.
Yao and Kondrak (2014) demonstrate that the
accuracy of orthographic syllabification can be
improved by using morphological information.
In particular, incorporating oracle morphological
segmentation substantially reduces the syllabifica-
tion error rate on English and German. If unsu-
pervised segmentation is used instead, the error
reduction is smaller but still significant. How-
ever, they are unable to achieve any error reduction
using a supervised segmentation approach, even
though it is much more accurate than the unsuper-
vised approach. The confirmation and explanation
of this surprising result remains an open question.
</bodyText>
<page confidence="0.999287">
67
</page>
<sectionHeader confidence="0.990027" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999531166666667">
Yaser Al-Onaizan and Kevin Knight. 2002. Machine
transliteration of names in Arabic texts. In Work-
shop on Computational Approaches to Semitic Lan-
guages.
Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2008. Automatic syllabification with structured
SVMs for letter-to-phoneme conversion. In ACL,
pages 568–576.
Aditya Bhargava and Grzegorz Kondrak. 2012. Lever-
aging supplemental representations for sequential
transduction. In NAACL-HLT, pages 396–406.
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434–451.
Edward Carney. 1994. A Survey of English Spelling.
Routledge.
Victor Chahuneau, Eva Schlinger, Noah A. Smith, and
Chris Dyer. 2013. Translating into morphologically
rich languages with synthetic phrases. In EMNLP,
pages 1677–1687.
Colin Cherry and Hisami Suzuki. 2009. Discrim-
inative substring decoding for transliteration. In
EMNLP, pages 1066–1075.
Noam Chomsky and Morris Halle. 1968. The Sound
Pattern ofEnglish. Harper &amp; Row.
Markus Dreyer and Jason Eisner. 2011. Discover-
ing morphological paradigms from plain text using a
Dirichlet process mixture model. In EMNLP, pages
616–627.
Greg Durrett and John DeNero. 2013. Supervised
learning of complete morphological paradigms. In
NAACL-HLT, pages 1185–1195.
Bradley Hauer, Ryan Hayward, and Grzegorz Kondrak.
2014. Solving substitution ciphers with combined
language models. Submitted for publication.
Kevin Knight and Jonathan Graehl. 1997. Machine
transliteration. In ACL, pages 128–135.
John Kominek and Alan W. Black. 2006. Learn-
ing pronunciation dictionaries: Language complex-
ity and word selection strategies. In HLT-NAACL,
pages 232–239.
Grzegorz Kondrak. 2005. Cognates and word align-
ment in bitexts. In MT Summit, pages 305–312.
Grzegorz Kondrak. 2013. Word similarity, cogna-
tion, and translational equivalence. In Lars Borin
and Anju Saxena, editors, Approaches to Measuring
Linguistic Differences, pages 375–386. De Gruyter
Mouton.
Moshe Koppel, Jonathan Schler, and Kfir Zigdon.
2005. Determining an author’s native language by
mining a text for errors. In SIGKDD, pages 624–
628.
Garrett Nicolai and Grzegorz Kondrak. 2014. Does
the phonology of L1 show up in L2 texts? In ACL.
Garret Nicolai et al. 2014. In preparation.
Sujith Ravi and Kevin Knight. 2009. Learning
phoneme mappings for transliteration without par-
allel data. In NAACL, pages 37–45.
Mohammad Salameh, Colin Cherry, and Grzegorz
Kondrak. 2014. Lattice desegmentation for statis-
tical machine translation. In ACL.
Joel Tetreault, Daniel Blanchard, and Aoife Cahill.
2013. A Report on the First Native Language Iden-
tification Shared Task. In Workshop on Innovative
Use of NLP for Building Educational Applications
(BEAR).
Oren Tsur and Ari Rappoport. 2007. Using classifier
features for studying the effect of native language
on the choice of written second language words. In
Workshop on Cognitive Aspects of Computational
Language Acquisition, pages 9–16.
Lei Yao and Grzegorz Kondrak. 2014. In preparation.
Min Zhang, Haizhou Li, A Kumaran, and Ming Liu.
2012. Report of NEWS 2012 machine transliter-
ation shared task. In 4th Named Entity Workshop,
pages 10–20.
George Zipf. 1936. The Psychobiology of Language.
Routledge.
</reference>
<page confidence="0.999436">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002682">
<title confidence="0.859962">10 Open Questions in Computational Morphonology</title>
<author confidence="0.799307">Grzegorz</author>
<affiliation confidence="0.9982815">Department of Computing University of</affiliation>
<email confidence="0.971589">gkondrak@ualberta.ca</email>
<abstract confidence="0.998914018324608">The objective of this paper is to initiate discussion within the SIGMORPHON community around several issues that involve computational morphology, phonology, phonetics, orthography, syllabification, transliteration, machine translation, inflection generation, and native language identification. 1 Morphology in Machine Translation In contrast with English, which is a morphologically simple language, many languages have dozens of different wordforms for any given lemma, some of which are unattested even in large monolingual corpora. In Statistical Machine Translation (SMT), lexical sparsity in such languages is often addressed by performing morphological segmentation, which simplifies the correspondence between the tokens in the source and target language. When translating into English from a morphologically complex language, the segmentation is a form of preprocessing performed before the the translation process. Since the English words are not segmented, the output of the decoder can be directly compared to the reference translation. However, when translating in the opposite direction, the segmentation must be reversed to make the generated text readable. typically performed as a postprocessing step that is independent from the decoding process. Unfortunately, the pipeline approach may prevent the desegmenter from recovering from errors made by the decoder, including output morpheme sequences that cannot be combined into valid words. Salameh et al. (2014) propose to replace the pipeline approach with a solution inspired by finite-state methods. They perform desegmentation directly on the search graph of a phrase-based which is represented as a a large set of possible decoder outputs. The lattice, which can be interpreted as a finite–state accepover target strings, is composed with a desegtransducer consumes morphemes and outputs desegmented words. The desegmenting transducer, in turn, is constructed from a table that maps morpheme sequences to words. The lattice desegmentation algorithm effectively combines both segmented and desegmented views of the target language, and allows for inclusion of features related to the desegmentation process, as well as an unsegmented language model. The results on English-to-Arabic indicate significant improvements in translation quality. However, the morphology of Arabic is largely concatenative, with relatively simple morpheme-boundary adaptations. In contrast, many European languages are as with affixes that represent several rather than a single morpheme. The question remains whether a morphologically-aware approach can be developed to improve translation into inflecting languages as well. 2 Inflection Generation An alternative to the morphological segmentation approach is to reduce the diverse forms in the training bitext to lemmas, and, at test time, reconstruct the wordforms in the target language directly from lemmas annotated with morphological features. Note that the wordforms that have not been seen in training pose a problem for language models, and are typically shunned by the current SMT systems. Although complex morphology leads to a high type-to-token ratio, words tend fo fall into certain inflectional paradigms. Individual inflections are obtained by combining a specific affix with a stem. These combinations are rarely concatenative, often affecting characters at the end or even in the middle of a stem. 64 of the 2014 Joint Meeting of SIGMORPHON and pages Maryland USA, June 27 2014. Association for Computational Linguistics For languages without hand-built morphological analyzers and generators, automated learning of morphological paradigms is the only option. Dreyer and Eisner (2011) propose a Dirichlet process mixture model and loopy belief propagation to learn complete paradigms starting from an initial small set of seed paradigms. An unannotated corpus is utilized to guide the predictions of the model by reducing the likelihood of generating unseen wordforms. Durrett and DeNero (2013) align the lemmas with inflected forms to identify spans that change for the inflections, and learn explicit rules for applying those changes in contexts in which they appear. Their joint model is aware of complete paradigms, and is able to correct errors made on individual inflections. Nicolai et al. (2014) train a discriminative string transducer on lemma-inflection pairs, and apply a separate re-ranking step to take advantage of the paradigmatic constraints. In spite of its relative simplicity, their string transduction approach outperforms the previous approaches to learning morphological paradigms on several European languages. The question remains whether the string transduction approach is also superior to more complex methods on languages with different morphological systems. 3 From Syntax to Morphology In some languages, syntactic function of phrases is mainly marked by word position and prepositions, while other languages rely on morphology to a greater degree. Similarly, verbal attributes such as tense, person, and gender, can be either encoded morphologically or lexically. Chahuneau et al. (2013) propose a discriminative model for translating into morphologically rich languages that predicts inflections of target words from sourceside annotations that include POS tags, dependency parses, and semantic clusters. In other words, they exploit the syntax of the source language to select the most likely wordforms in the target language, The open question in this case is whether instead of learning a prediction model separately for each language pair, the morphological features could be mapped directly on the source words. For in the phrase would have the actual morphological marking is minimal, but the context disambiguates the person, number, gender, and aspect of the verb. Explicit morphological annotation could not only help machine translation, but also provide a rich source of information in the monolingual context, which would go well beyond POS tagging. 4 Transliteration and Morphology Transliteration is sometimes defined as “phonetic translation” (Knight and Graehl, 1997). In fact, it is straightforward to train a transliteration model using SMT toolkits by treating individual characters as words, and words as sentences. However, unless substantial modifications are made, the accuracy of such a system will be mediocre. Transliteration needs a dedicated approach in order to fully exploit the source-side context and other constraints. The way we define tasks in NLP is important, because the definitions (and shared tasks) tend to guide research in a particular direction. New papers are expected to show improvement over previously published results, preferably on already established benchmarks. Redefining a task carries the risk of being interpreted as an attempt to avoid a fair experimental comparison, or as a misdirected effort to investigate irrelevant problems. The NEWS Shared Task on Machine Transliteration was held four times between 2009 and 2012 (Zhang et al., 2012). With the exception of the 2010 edition that included a transliteration mining task, the shared task was invariably defined in terms of learning transliteration models from the training sets of word pairs. This framework seems to ignore the fact that many of the transliteration target words can be found in monolingual corpora, in a marked contrast with the prevalent SMT practice of avoiding unseen words. Cherry and Suzuki (2009) show that the inclusion of a target lexicon dramatically improves transliteration accuracy. Unfortunately, the paper has largely been ignored by the transliteration community (perhaps because it strays from the standard task formulation), as well as the SMT community (perhaps because it shows only modest gains in terms of BLEU score). Another drawback of limiting the training data to a list of name pairs is the lack of the context that is required to account for morphological alterations. For example, the title of the Rus- Wikipedia page that corresponds to Presof Barack Obama as Baraka where the personal 65 name appears in the genetive case. Simply including morphological variants in the training data without their context is likely to confuse a transliteration model. How to best combine transliteration with morphology remains an open question. 5 Transliteration and Orthography Transliteration is more than just phonetic translation. In the idealized model of Knight and Graehl (1997) a human transliterator pronounces a name in the source language, modifies the pronunciation to fit the target language phonology, and writes it down using the orthographic rules of the target script. In reality, however, the source orthography strongly influences the form of the transliteration. For example, the Russian transliteration of the Wikipedia back-transliterates as although be much closer to the original pronunciation. For less well-known names that first appear in English-language news, human transliterators are often in the dark because the correct pronunciation may be difficult to guess from the spelling. Al-Onaizan and Knight (2002) report that a spelling-based model outperforms a phoneticbased model even when pronunciations are extracted from a pronunciation dictionary. Bhargava and Kondrak (2012) present a re-ranking approach that is able to improve spelling-based models by consulting the supplied pronunciations. It remains an open question how to design a superior joint model that would generate transliterations directly from both spelling and pronunciation. 6 Transliteration and Decipherment Although transliteration is typically defined as conversion between writing scripts, the proper form strongly depends on the particular target language with its phonological and orthographic constraints. For example, the name of the city that hosted the recent Winter Olympics is represented various European languages as etc. In order to derive language-specific transliteration models, we would need to collect training data for thousands of possible language pairs. Ravi and Knight (2009) introduce the task of unsupervised transliteration without parallel resources. They formulate the problem as decipherment, and reconstruct cross-lingual phoneme mapping tables from Japanese words of English origin, achieving approximately 50% character accuracy on U.S. names written in the Katakana script. Hauer et al. (2014) frame transliteration as a substitution cipher, and apply a mixture of characterand word-level language models to the decipherment of a known language written in an unknown script. The authors treat a short text in Serbian as enciphered Croatian, and attempt to recover the “key”, which is the mapping between the characters in the two writing scripts. In reality, Croatian and Serbian are distinct but closely related languages, that are written in different scripts and exhibit differences in both lexicon and grammar. In particular, 30 Serbian Cyrillic characters correspond to 27 letters in Croatian Latin, with three of the characters represented in the other as digraphs (e.g., The decipherment error rate plateaus at about 3% at the ciphertext length of 50 words. In contrast, a pure frequencybased approach fails on this task with a mapping error rate close to 90%. The question remains whether a more flexible approach could be applied successfully to unsupervised transliteration of languages that are less closely related. 7 Phonetic Similarity of Translations Words that are phonetically similar across different languages tend to be transliterations, or at least share the same origin. For this reason, words on two sides of a bitext are more likely to correspond to each other if they exhibit phonetic similarity (Kondrak, 2005). This is true even for completely unrelated languages because of the prevalence of loanwords, proper names, and technical terms. Orthographic similarity, which reflects phonetic similarity, has been exploited in the past to improve word and sentence alignment in SMT, and other NLP tasks. Surprisingly, the correlation with phonetic similarity appears to hold for any translations, defined as words that express the same meaning in some context. Kondrak (2013) observes that even after all cognates and loanwords are removed from consideration, the similarity between the words from different languages for the same concept is significantly higher on average than the similarity between the words for different concepts (as measured by the Longest Common Subsequence Ratio). This seems to contradict the Saussurean principle of the arbitrariness of the linguistic sign. (2013) proposes to explain this phe- 66 nomenon by positing a chain of correlations between the following word characteristics: translatability, frequency, length, and similarity. The key observation is that translations are on average closer in terms of their length than random words. First, pairs of cross-lingual translations exhibit a correlation with respect to the logarithm of their frequencies. Intuitively, translations refer to the same semantic concepts, which tend to be expressed with similar frequency across languages. Second, the connection between word frequency and length is well established (Zipf, 1936). Finally, pairs of words that differ in length are less likely to be considered similar, which is reflected by word similarity measures. In summary, the reason for the greater phonetic similarity of translations lies in the similarity of their frequencies, which is reflected by the similarity of their lengths. This hypothesis remains to be verified on other languages and data sets. 8 L1 Phonology in L2 The task of Native Language Identification (NLI) is to determine the first language (L1) of the writer of a text in another language (L2) (Tetreault et al., 2013). Koppel et al. (2005) report 80% accuracy in classifying a set of English texts into five L1 languages using a multi-class linear SVM with features including function words, POS biand character Tsur and Rappoport (2007) observe that limiting the set of features to the relative frequency of the 200 most frequent character bigrams yields a respectable accuracy of about 65%. They interpret this as evidence that the choice of words in L2 is strongly influenced by the phonology of L1. As the orthography of alphabetic languages is representative of their phonology, character bigrams appear to capture these phonetic preferences. In order to test the above hypothesis, Nicolai and Kondrak (2014) design an algorithm to identify the most discriminative words and the corresponding character bigrams. They find that the removal of such words results in a substantial drop in the accuracy of the classifier that is based exclusively on character bigrams, and that the majority of the most indicative character bigrams are common among different language sets. They conclude that the effectiveness of a bigrambased classifier in identifying the native language of a writer is primarily driven by the relative frequency of words rather than by the influence of the phonology of L1. Although this provides evidence against the hypothesis of Tsur and Rappoport (2007), the question to what degree the L1 phonology affects L2 writing remains open. 9 English Orthography The English spelling system is notorious for its irregularity. Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. In view of this, the claim of Chomsky and Halle (1968) that English orthography is “close to optimal” could be interpreted as facetious. The question is how we could validate the accuracy of this statement from the computational perspective. It would seem to require answering at least the following three questions: (a) what is the optimal orthography for English, (b) how to measure the distance between alternative orthographies, and (c) what distance should be considered “close”. 10 Syllabification and Morphology Orthographic syllabification of words is sometimes referred to as hyphenation. Bartlett et al. (2008) propose a sequence prediction approach to syllabify out-of-dictionary words based on letter features. Despite its high accuracy, their system suffers from the lack of awareness of compound nouns and other morphological phenom- For example, incorrectly sylas Yao and Kondrak (2014) demonstrate that the accuracy of orthographic syllabification can be improved by using morphological information. In particular, incorporating oracle morphological segmentation substantially reduces the syllabification error rate on English and German. If unsupervised segmentation is used instead, the error reduction is smaller but still significant. However, they are unable to achieve any error reduction a approach, even though it is much more accurate than the unsupervised approach. The confirmation and explanation of this surprising result remains an open question.</abstract>
<note confidence="0.843150115384615">67 References Yaser Al-Onaizan and Kevin Knight. 2002. Machine of names in Arabic texts. In Workshop on Computational Approaches to Semitic Lan- Susan Bartlett, Grzegorz Kondrak, and Colin Cherry. 2008. Automatic syllabification with structured for letter-to-phoneme conversion. In pages 568–576. Aditya Bhargava and Grzegorz Kondrak. 2012. Leveraging supplemental representations for sequential In pages 396–406. Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conver- 50(5):434–451. Carney. 1994. Survey of English Routledge. Victor Chahuneau, Eva Schlinger, Noah A. Smith, and Chris Dyer. 2013. Translating into morphologically languages with synthetic phrases. In pages 1677–1687. Colin Cherry and Hisami Suzuki. 2009. Discriminative substring decoding for transliteration. In pages 1066–1075. Chomsky and Morris Halle. 1968. Sound Harper &amp; Row.</note>
<author confidence="0.590738">Discover-</author>
<abstract confidence="0.741639555555555">ing morphological paradigms from plain text using a process mixture model. In pages 616–627. Greg Durrett and John DeNero. 2013. Supervised learning of complete morphological paradigms. In pages 1185–1195. Bradley Hauer, Ryan Hayward, and Grzegorz Kondrak. 2014. Solving substitution ciphers with combined language models. Submitted for publication.</abstract>
<note confidence="0.908670523809524">Kevin Knight and Jonathan Graehl. 1997. Machine In pages 128–135. John Kominek and Alan W. Black. 2006. Learning pronunciation dictionaries: Language complexand word selection strategies. In pages 232–239. Grzegorz Kondrak. 2005. Cognates and word alignin bitexts. In pages 305–312. Grzegorz Kondrak. 2013. Word similarity, cognation, and translational equivalence. In Lars Borin Anju Saxena, editors, to Measuring pages 375–386. De Gruyter Mouton. Moshe Koppel, Jonathan Schler, and Kfir Zigdon. 2005. Determining an author’s native language by a text for errors. In pages 624– 628. Garrett Nicolai and Grzegorz Kondrak. 2014. Does phonology of L1 show up in L2 texts? In Garret Nicolai et al. 2014. In preparation. Sujith Ravi and Kevin Knight. 2009. Learning</note>
<abstract confidence="0.661489833333333">phoneme mappings for transliteration without pardata. In pages 37–45. Mohammad Salameh, Colin Cherry, and Grzegorz Kondrak. 2014. Lattice desegmentation for statismachine translation. In Joel Tetreault, Daniel Blanchard, and Aoife Cahill. 2013. A Report on the First Native Language Iden- Shared Task. In on Innovative Use of NLP for Building Educational Applications Oren Tsur and Ari Rappoport. 2007. Using classifier features for studying the effect of native language on the choice of written second language words. In</abstract>
<note confidence="0.9195494">Workshop on Cognitive Aspects of Computational pages 9–16. Lei Yao and Grzegorz Kondrak. 2014. In preparation. Min Zhang, Haizhou Li, A Kumaran, and Ming Liu. 2012. Report of NEWS 2012 machine translitershared task. In Named Entity pages 10–20. Zipf. 1936. Psychobiology of Routledge. 68</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Machine transliteration of names in Arabic texts.</title>
<date>2002</date>
<booktitle>In Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="9525" citStr="Al-Onaizan and Knight (2002)" startWordPosition="1442" endWordPosition="1445"> modifies the pronunciation to fit the target language phonology, and writes it down using the orthographic rules of the target script. In reality, however, the source orthography strongly influences the form of the transliteration. For example, the Russian transliteration of the name Dickens on Wikipedia back-transliterates as Dikkens, although Dykynz would be much closer to the original pronunciation. For less well-known names that first appear in English-language news, human transliterators are often in the dark because the correct pronunciation may be difficult to guess from the spelling. Al-Onaizan and Knight (2002) report that a spelling-based model outperforms a phoneticbased model even when pronunciations are extracted from a pronunciation dictionary. Bhargava and Kondrak (2012) present a re-ranking approach that is able to improve spelling-based models by consulting the supplied pronunciations. It remains an open question how to design a superior joint model that would generate transliterations directly from both spelling and pronunciation. 6 Transliteration and Decipherment Although transliteration is typically defined as conversion between writing scripts, the proper form strongly depends on the pa</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002. Machine transliteration of names in Arabic texts. In Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Bartlett</author>
<author>Grzegorz Kondrak</author>
<author>Colin Cherry</author>
</authors>
<title>Automatic syllabification with structured SVMs for letter-to-phoneme conversion. In</title>
<date>2008</date>
<booktitle>ACL,</booktitle>
<pages>568--576</pages>
<contexts>
<context position="16889" citStr="Bartlett et al. (2008)" startWordPosition="2608" endWordPosition="2611">. In view of this, the claim of Chomsky and Halle (1968) that English orthography is “close to optimal” could be interpreted as facetious. The question is how we could validate the accuracy of this statement from the computational perspective. It would seem to require answering at least the following three questions: (a) what is the optimal orthography for English, (b) how to measure the distance between alternative orthographies, and (c) what distance should be considered “close”. 10 Syllabification and Morphology Orthographic syllabification of words is sometimes referred to as hyphenation. Bartlett et al. (2008) propose a sequence prediction approach to syllabify out-of-dictionary words based on letter n-gram features. Despite its high accuracy, their system suffers from the lack of awareness of compound nouns and other morphological phenomena. For example, hold-o-ver is incorrectly syllabified as hol-dov-er. Yao and Kondrak (2014) demonstrate that the accuracy of orthographic syllabification can be improved by using morphological information. In particular, incorporating oracle morphological segmentation substantially reduces the syllabification error rate on English and German. If unsupervised segm</context>
</contexts>
<marker>Bartlett, Kondrak, Cherry, 2008</marker>
<rawString>Susan Bartlett, Grzegorz Kondrak, and Colin Cherry. 2008. Automatic syllabification with structured SVMs for letter-to-phoneme conversion. In ACL, pages 568–576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aditya Bhargava</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Leveraging supplemental representations for sequential transduction.</title>
<date>2012</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>396--406</pages>
<contexts>
<context position="9694" citStr="Bhargava and Kondrak (2012)" startWordPosition="1466" endWordPosition="1469">thography strongly influences the form of the transliteration. For example, the Russian transliteration of the name Dickens on Wikipedia back-transliterates as Dikkens, although Dykynz would be much closer to the original pronunciation. For less well-known names that first appear in English-language news, human transliterators are often in the dark because the correct pronunciation may be difficult to guess from the spelling. Al-Onaizan and Knight (2002) report that a spelling-based model outperforms a phoneticbased model even when pronunciations are extracted from a pronunciation dictionary. Bhargava and Kondrak (2012) present a re-ranking approach that is able to improve spelling-based models by consulting the supplied pronunciations. It remains an open question how to design a superior joint model that would generate transliterations directly from both spelling and pronunciation. 6 Transliteration and Decipherment Although transliteration is typically defined as conversion between writing scripts, the proper form strongly depends on the particular target language with its phonological and orthographic constraints. For example, the name of the city that hosted the recent Winter Olympics is represented in v</context>
</contexts>
<marker>Bhargava, Kondrak, 2012</marker>
<rawString>Aditya Bhargava and Grzegorz Kondrak. 2012. Leveraging supplemental representations for sequential transduction. In NAACL-HLT, pages 396–406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<issue>5</issue>
<contexts>
<context position="16081" citStr="Bisani and Ney, 2008" startWordPosition="2482" endWordPosition="2485">entifying the native language of a writer is primarily driven by the relative frequency of words rather than by the influence of the phonology of L1. Although this provides evidence against the hypothesis of Tsur and Rappoport (2007), the question to what degree the L1 phonology affects L2 writing remains open. 9 English Orthography The English spelling system is notorious for its irregularity. Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. In view of this, the claim of Chomsky and Halle (1968) that English orthography is “close to optimal” could be interpreted as facetious. The question is how we could validate the accuracy of this statement from the computational perspective. It would seem to require answering at least the following three questions: (a) what is the optimal orthography for English, (b) how to measure the distance between altern</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50(5):434–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Carney</author>
</authors>
<title>A Survey of English Spelling.</title>
<date>1994</date>
<publisher>Routledge.</publisher>
<contexts>
<context position="16126" citStr="Carney, 1994" startWordPosition="2491" endWordPosition="2492">y driven by the relative frequency of words rather than by the influence of the phonology of L1. Although this provides evidence against the hypothesis of Tsur and Rappoport (2007), the question to what degree the L1 phonology affects L2 writing remains open. 9 English Orthography The English spelling system is notorious for its irregularity. Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. In view of this, the claim of Chomsky and Halle (1968) that English orthography is “close to optimal” could be interpreted as facetious. The question is how we could validate the accuracy of this statement from the computational perspective. It would seem to require answering at least the following three questions: (a) what is the optimal orthography for English, (b) how to measure the distance between alternative orthographies, and (c) what distance sh</context>
</contexts>
<marker>Carney, 1994</marker>
<rawString>Edward Carney. 1994. A Survey of English Spelling. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Chahuneau</author>
<author>Eva Schlinger</author>
<author>Noah A Smith</author>
<author>Chris Dyer</author>
</authors>
<title>Translating into morphologically rich languages with synthetic phrases.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>1677--1687</pages>
<contexts>
<context position="5416" citStr="Chahuneau et al. (2013)" startWordPosition="799" endWordPosition="802"> their string transduction approach outperforms the previous approaches to learning morphological paradigms on several European languages. The question remains whether the string transduction approach is also superior to more complex methods on languages with different morphological systems. 3 From Syntax to Morphology In some languages, syntactic function of phrases is mainly marked by word position and prepositions, while other languages rely on morphology to a greater degree. Similarly, verbal attributes such as tense, person, and gender, can be either encoded morphologically or lexically. Chahuneau et al. (2013) propose a discriminative model for translating into morphologically rich languages that predicts inflections of target words from sourceside annotations that include POS tags, dependency parses, and semantic clusters. In other words, they exploit the syntax of the source language to select the most likely wordforms in the target language, The open question in this case is whether instead of learning a prediction model separately for each language pair, the morphological features could be mapped directly on the source words. For example, in the phrase she would have asked, the actual morpholog</context>
</contexts>
<marker>Chahuneau, Schlinger, Smith, Dyer, 2013</marker>
<rawString>Victor Chahuneau, Eva Schlinger, Noah A. Smith, and Chris Dyer. 2013. Translating into morphologically rich languages with synthetic phrases. In EMNLP, pages 1677–1687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Hisami Suzuki</author>
</authors>
<title>Discriminative substring decoding for transliteration.</title>
<date>2009</date>
<booktitle>In EMNLP,</booktitle>
<pages>1066--1075</pages>
<contexts>
<context position="7782" citStr="Cherry and Suzuki (2009)" startWordPosition="1174" endWordPosition="1177">ental comparison, or as a misdirected effort to investigate irrelevant problems. The NEWS Shared Task on Machine Transliteration was held four times between 2009 and 2012 (Zhang et al., 2012). With the exception of the 2010 edition that included a transliteration mining task, the shared task was invariably defined in terms of learning transliteration models from the training sets of word pairs. This framework seems to ignore the fact that many of the transliteration target words can be found in monolingual corpora, in a marked contrast with the prevalent SMT practice of avoiding unseen words. Cherry and Suzuki (2009) show that the inclusion of a target lexicon dramatically improves transliteration accuracy. Unfortunately, the paper has largely been ignored by the transliteration community (perhaps because it strays from the standard task formulation), as well as the SMT community (perhaps because it shows only modest gains in terms of BLEU score). Another drawback of limiting the training data to a list of name pairs is the lack of the context that is required to account for morphological alterations. For example, the title of the Russian Wikipedia page that corresponds to Presidency of Barack Obama back-</context>
</contexts>
<marker>Cherry, Suzuki, 2009</marker>
<rawString>Colin Cherry and Hisami Suzuki. 2009. Discriminative substring decoding for transliteration. In EMNLP, pages 1066–1075.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
<author>Morris Halle</author>
</authors>
<title>The Sound Pattern ofEnglish.</title>
<date>1968</date>
<publisher>Harper &amp; Row.</publisher>
<contexts>
<context position="16323" citStr="Chomsky and Halle (1968)" startWordPosition="2519" endWordPosition="2522">question to what degree the L1 phonology affects L2 writing remains open. 9 English Orthography The English spelling system is notorious for its irregularity. Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. In view of this, the claim of Chomsky and Halle (1968) that English orthography is “close to optimal” could be interpreted as facetious. The question is how we could validate the accuracy of this statement from the computational perspective. It would seem to require answering at least the following three questions: (a) what is the optimal orthography for English, (b) how to measure the distance between alternative orthographies, and (c) what distance should be considered “close”. 10 Syllabification and Morphology Orthographic syllabification of words is sometimes referred to as hyphenation. Bartlett et al. (2008) propose a sequence prediction app</context>
</contexts>
<marker>Chomsky, Halle, 1968</marker>
<rawString>Noam Chomsky and Morris Halle. 1968. The Sound Pattern ofEnglish. Harper &amp; Row.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dreyer</author>
<author>Jason Eisner</author>
</authors>
<title>Discovering morphological paradigms from plain text using a Dirichlet process mixture model.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<pages>616--627</pages>
<contexts>
<context position="3981" citStr="Dreyer and Eisner (2011)" startWordPosition="581" endWordPosition="584">logy leads to a high type-to-token ratio, words tend fo fall into certain inflectional paradigms. Individual inflections are obtained by combining a specific affix with a stem. These combinations are rarely concatenative, often affecting characters at the end or even in the middle of a stem. 64 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 64–68, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics For languages without hand-built morphological analyzers and generators, automated learning of morphological paradigms is the only option. Dreyer and Eisner (2011) propose a Dirichlet process mixture model and loopy belief propagation to learn complete paradigms starting from an initial small set of seed paradigms. An unannotated corpus is utilized to guide the predictions of the model by reducing the likelihood of generating unseen wordforms. Durrett and DeNero (2013) align the lemmas with inflected forms to identify spans that change for the inflections, and learn explicit rules for applying those changes in contexts in which they appear. Their joint model is aware of complete paradigms, and is able to correct errors made on individual inflections. Ni</context>
</contexts>
<marker>Dreyer, Eisner, 2011</marker>
<rawString>Markus Dreyer and Jason Eisner. 2011. Discovering morphological paradigms from plain text using a Dirichlet process mixture model. In EMNLP, pages 616–627.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>John DeNero</author>
</authors>
<title>Supervised learning of complete morphological paradigms.</title>
<date>2013</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>1185--1195</pages>
<contexts>
<context position="4291" citStr="Durrett and DeNero (2013)" startWordPosition="630" endWordPosition="633">f the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 64–68, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics For languages without hand-built morphological analyzers and generators, automated learning of morphological paradigms is the only option. Dreyer and Eisner (2011) propose a Dirichlet process mixture model and loopy belief propagation to learn complete paradigms starting from an initial small set of seed paradigms. An unannotated corpus is utilized to guide the predictions of the model by reducing the likelihood of generating unseen wordforms. Durrett and DeNero (2013) align the lemmas with inflected forms to identify spans that change for the inflections, and learn explicit rules for applying those changes in contexts in which they appear. Their joint model is aware of complete paradigms, and is able to correct errors made on individual inflections. Nicolai et al. (2014) train a discriminative string transducer on lemma-inflection pairs, and apply a separate re-ranking step to take advantage of the paradigmatic constraints. In spite of its relative simplicity, their string transduction approach outperforms the previous approaches to learning morphological </context>
</contexts>
<marker>Durrett, DeNero, 2013</marker>
<rawString>Greg Durrett and John DeNero. 2013. Supervised learning of complete morphological paradigms. In NAACL-HLT, pages 1185–1195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley Hauer</author>
<author>Ryan Hayward</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Solving substitution ciphers with combined language models.</title>
<date>2014</date>
<note>Submitted for publication.</note>
<contexts>
<context position="10889" citStr="Hauer et al. (2014)" startWordPosition="1637" endWordPosition="1640">pics is represented in various European languages as Sochi, Sotchi, Sotschi, Sotsji, Sotji, Sotˇsi, Soˇci, Soczi, Szocsi, etc. In order to derive language-specific transliteration models, we would need to collect training data for thousands of possible language pairs. Ravi and Knight (2009) introduce the task of unsupervised transliteration without parallel resources. They formulate the problem as decipherment, and reconstruct cross-lingual phoneme mapping tables from Japanese words of English origin, achieving approximately 50% character accuracy on U.S. names written in the Katakana script. Hauer et al. (2014) frame transliteration as a substitution cipher, and apply a mixture of character- and word-level language models to the decipherment of a known language written in an unknown script. The authors treat a short text in Serbian as enciphered Croatian, and attempt to recover the “key”, which is the mapping between the characters in the two writing scripts. In reality, Croatian and Serbian are distinct but closely related languages, that are written in different scripts and exhibit differences in both lexicon and grammar. In particular, 30 Serbian Cyrillic characters correspond to 27 letters in Cr</context>
</contexts>
<marker>Hauer, Hayward, Kondrak, 2014</marker>
<rawString>Bradley Hauer, Ryan Hayward, and Grzegorz Kondrak. 2014. Solving substitution ciphers with combined language models. Submitted for publication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>Machine transliteration.</title>
<date>1997</date>
<booktitle>In ACL,</booktitle>
<pages>128--135</pages>
<contexts>
<context position="6433" citStr="Knight and Graehl, 1997" startWordPosition="955" endWordPosition="958">f learning a prediction model separately for each language pair, the morphological features could be mapped directly on the source words. For example, in the phrase she would have asked, the actual morphological marking is minimal, but the context disambiguates the person, number, gender, and aspect of the verb. Explicit morphological annotation could not only help machine translation, but also provide a rich source of information in the monolingual context, which would go well beyond POS tagging. 4 Transliteration and Morphology Transliteration is sometimes defined as “phonetic translation” (Knight and Graehl, 1997). In fact, it is straightforward to train a transliteration model using SMT toolkits by treating individual characters as words, and words as sentences. However, unless substantial modifications are made, the accuracy of such a system will be mediocre. Transliteration needs a dedicated approach in order to fully exploit the source-side context and other constraints. The way we define tasks in NLP is important, because the definitions (and shared tasks) tend to guide research in a particular direction. New papers are expected to show improvement over previously published results, preferably on </context>
<context position="8832" citStr="Knight and Graehl (1997)" startWordPosition="1341" endWordPosition="1344">e context that is required to account for morphological alterations. For example, the title of the Russian Wikipedia page that corresponds to Presidency of Barack Obama back-transliterates as Presidentstvo Baraka Obamy, where the personal 65 name appears in the genetive case. Simply including morphological variants in the training data without their context is likely to confuse a transliteration model. How to best combine transliteration with morphology remains an open question. 5 Transliteration and Orthography Transliteration is more than just phonetic translation. In the idealized model of Knight and Graehl (1997) a human transliterator pronounces a name in the source language, modifies the pronunciation to fit the target language phonology, and writes it down using the orthographic rules of the target script. In reality, however, the source orthography strongly influences the form of the transliteration. For example, the Russian transliteration of the name Dickens on Wikipedia back-transliterates as Dikkens, although Dykynz would be much closer to the original pronunciation. For less well-known names that first appear in English-language news, human transliterators are often in the dark because the co</context>
</contexts>
<marker>Knight, Graehl, 1997</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1997. Machine transliteration. In ACL, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kominek</author>
<author>Alan W Black</author>
</authors>
<title>Learning pronunciation dictionaries: Language complexity and word selection strategies.</title>
<date>2006</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>232--239</pages>
<contexts>
<context position="15882" citStr="Kominek and Black (2006)" startWordPosition="2449" endWordPosition="2452">vely on character bigrams, and that the majority of the most indicative character bigrams are common among different language sets. They conclude that the effectiveness of a bigrambased classifier in identifying the native language of a writer is primarily driven by the relative frequency of words rather than by the influence of the phonology of L1. Although this provides evidence against the hypothesis of Tsur and Rappoport (2007), the question to what degree the L1 phonology affects L2 writing remains open. 9 English Orthography The English spelling system is notorious for its irregularity. Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. In view of this, the claim of Chomsky and Halle (1968) that English orthography is “close to optimal” could be interpreted as facetious. The question is how we could validate the accuracy of this statement from th</context>
</contexts>
<marker>Kominek, Black, 2006</marker>
<rawString>John Kominek and Alan W. Black. 2006. Learning pronunciation dictionaries: Language complexity and word selection strategies. In HLT-NAACL, pages 232–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>Cognates and word alignment in bitexts.</title>
<date>2005</date>
<booktitle>In MT Summit,</booktitle>
<pages>305--312</pages>
<contexts>
<context position="12246" citStr="Kondrak, 2005" startWordPosition="1860" endWordPosition="1861">t 3% at the ciphertext length of 50 words. In contrast, a pure frequencybased approach fails on this task with a mapping error rate close to 90%. The question remains whether a more flexible approach could be applied successfully to unsupervised transliteration of languages that are less closely related. 7 Phonetic Similarity of Translations Words that are phonetically similar across different languages tend to be transliterations, or at least share the same origin. For this reason, words on two sides of a bitext are more likely to correspond to each other if they exhibit phonetic similarity (Kondrak, 2005). This is true even for completely unrelated languages because of the prevalence of loanwords, proper names, and technical terms. Orthographic similarity, which reflects phonetic similarity, has been exploited in the past to improve word and sentence alignment in SMT, and other NLP tasks. Surprisingly, the correlation with phonetic similarity appears to hold for any translations, defined as words that express the same meaning in some context. Kondrak (2013) observes that even after all cognates and loanwords are removed from consideration, the similarity between the words from different langua</context>
</contexts>
<marker>Kondrak, 2005</marker>
<rawString>Grzegorz Kondrak. 2005. Cognates and word alignment in bitexts. In MT Summit, pages 305–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>Word similarity, cognation, and translational equivalence.</title>
<date>2013</date>
<booktitle>In Lars Borin and Anju Saxena, editors, Approaches to Measuring Linguistic Differences,</booktitle>
<pages>375--386</pages>
<publisher>De Gruyter Mouton.</publisher>
<contexts>
<context position="12707" citStr="Kondrak (2013)" startWordPosition="1932" endWordPosition="1933">e origin. For this reason, words on two sides of a bitext are more likely to correspond to each other if they exhibit phonetic similarity (Kondrak, 2005). This is true even for completely unrelated languages because of the prevalence of loanwords, proper names, and technical terms. Orthographic similarity, which reflects phonetic similarity, has been exploited in the past to improve word and sentence alignment in SMT, and other NLP tasks. Surprisingly, the correlation with phonetic similarity appears to hold for any translations, defined as words that express the same meaning in some context. Kondrak (2013) observes that even after all cognates and loanwords are removed from consideration, the similarity between the words from different languages for the same concept is significantly higher on average than the similarity between the words for different concepts (as measured by the Longest Common Subsequence Ratio). This seems to contradict the Saussurean principle of the arbitrariness of the linguistic sign. Kondrak (2013) proposes to explain this phe66 nomenon by positing a chain of correlations between the following word characteristics: translatability, frequency, length, and similarity. The </context>
</contexts>
<marker>Kondrak, 2013</marker>
<rawString>Grzegorz Kondrak. 2013. Word similarity, cognation, and translational equivalence. In Lars Borin and Anju Saxena, editors, Approaches to Measuring Linguistic Differences, pages 375–386. De Gruyter Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel</author>
<author>Jonathan Schler</author>
<author>Kfir Zigdon</author>
</authors>
<title>Determining an author’s native language by mining a text for errors.</title>
<date>2005</date>
<booktitle>In SIGKDD,</booktitle>
<pages>624--628</pages>
<contexts>
<context position="14338" citStr="Koppel et al. (2005)" startWordPosition="2192" endWordPosition="2195">well established (Zipf, 1936). Finally, pairs of words that differ in length are less likely to be considered similar, which is reflected by word similarity measures. In summary, the reason for the greater phonetic similarity of translations lies in the similarity of their frequencies, which is reflected by the similarity of their lengths. This hypothesis remains to be verified on other languages and data sets. 8 L1 Phonology in L2 The task of Native Language Identification (NLI) is to determine the first language (L1) of the writer of a text in another language (L2) (Tetreault et al., 2013). Koppel et al. (2005) report 80% accuracy in classifying a set of English texts into five L1 languages using a multi-class linear SVM with features including function words, POS bigrams, and character n-grams. Tsur and Rappoport (2007) observe that limiting the set of features to the relative frequency of the 200 most frequent character bigrams yields a respectable accuracy of about 65%. They interpret this as evidence that the choice of words in L2 is strongly influenced by the phonology of L1. As the orthography of alphabetic languages is representative of their phonology, character bigrams appear to capture the</context>
</contexts>
<marker>Koppel, Schler, Zigdon, 2005</marker>
<rawString>Moshe Koppel, Jonathan Schler, and Kfir Zigdon. 2005. Determining an author’s native language by mining a text for errors. In SIGKDD, pages 624– 628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Garrett Nicolai</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Does the phonology of L1 show up in L2 texts?</title>
<date>2014</date>
<booktitle>In ACL. Garret Nicolai</booktitle>
<note>In preparation.</note>
<contexts>
<context position="15028" citStr="Nicolai and Kondrak (2014)" startWordPosition="2309" endWordPosition="2313">five L1 languages using a multi-class linear SVM with features including function words, POS bigrams, and character n-grams. Tsur and Rappoport (2007) observe that limiting the set of features to the relative frequency of the 200 most frequent character bigrams yields a respectable accuracy of about 65%. They interpret this as evidence that the choice of words in L2 is strongly influenced by the phonology of L1. As the orthography of alphabetic languages is representative of their phonology, character bigrams appear to capture these phonetic preferences. In order to test the above hypothesis, Nicolai and Kondrak (2014) design an algorithm to identify the most discriminative words and the corresponding character bigrams. They find that the removal of such words results in a substantial drop in the accuracy of the classifier that is based exclusively on character bigrams, and that the majority of the most indicative character bigrams are common among different language sets. They conclude that the effectiveness of a bigrambased classifier in identifying the native language of a writer is primarily driven by the relative frequency of words rather than by the influence of the phonology of L1. Although this prov</context>
</contexts>
<marker>Nicolai, Kondrak, 2014</marker>
<rawString>Garrett Nicolai and Grzegorz Kondrak. 2014. Does the phonology of L1 show up in L2 texts? In ACL. Garret Nicolai et al. 2014. In preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Learning phoneme mappings for transliteration without parallel data. In</title>
<date>2009</date>
<booktitle>NAACL,</booktitle>
<pages>37--45</pages>
<contexts>
<context position="10561" citStr="Ravi and Knight (2009)" startWordPosition="1590" endWordPosition="1593">ling and pronunciation. 6 Transliteration and Decipherment Although transliteration is typically defined as conversion between writing scripts, the proper form strongly depends on the particular target language with its phonological and orthographic constraints. For example, the name of the city that hosted the recent Winter Olympics is represented in various European languages as Sochi, Sotchi, Sotschi, Sotsji, Sotji, Sotˇsi, Soˇci, Soczi, Szocsi, etc. In order to derive language-specific transliteration models, we would need to collect training data for thousands of possible language pairs. Ravi and Knight (2009) introduce the task of unsupervised transliteration without parallel resources. They formulate the problem as decipherment, and reconstruct cross-lingual phoneme mapping tables from Japanese words of English origin, achieving approximately 50% character accuracy on U.S. names written in the Katakana script. Hauer et al. (2014) frame transliteration as a substitution cipher, and apply a mixture of character- and word-level language models to the decipherment of a known language written in an unknown script. The authors treat a short text in Serbian as enciphered Croatian, and attempt to recover</context>
</contexts>
<marker>Ravi, Knight, 2009</marker>
<rawString>Sujith Ravi and Kevin Knight. 2009. Learning phoneme mappings for transliteration without parallel data. In NAACL, pages 37–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Salameh</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Lattice desegmentation for statistical machine translation.</title>
<date>2014</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1646" citStr="Salameh et al. (2014)" startWordPosition="233" endWordPosition="236">ing performed before the the translation process. Since the English words are not segmented, the output of the decoder can be directly compared to the reference translation. However, when translating in the opposite direction, the segmentation must be reversed to make the generated text readable. Desegmentation is typically performed as a postprocessing step that is independent from the decoding process. Unfortunately, the pipeline approach may prevent the desegmenter from recovering from errors made by the decoder, including output morpheme sequences that cannot be combined into valid words. Salameh et al. (2014) propose to replace the pipeline approach with a solution inspired by finite-state methods. They perform desegmentation directly on the search graph of a phrase-based decoder, which is represented as a lattice encoding a large set of possible decoder outputs. The lattice, which can be interpreted as a finite–state acceptor over target strings, is composed with a desegmenting transducer which consumes morphemes and outputs desegmented words. The desegmenting transducer, in turn, is constructed from a table that maps morpheme sequences to words. The lattice desegmentation algorithm effectively c</context>
</contexts>
<marker>Salameh, Cherry, Kondrak, 2014</marker>
<rawString>Mohammad Salameh, Colin Cherry, and Grzegorz Kondrak. 2014. Lattice desegmentation for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Daniel Blanchard</author>
<author>Aoife Cahill</author>
</authors>
<title>A Report on the First Native Language Identification Shared Task.</title>
<date>2013</date>
<booktitle>In Workshop on Innovative Use of NLP for Building Educational Applications</booktitle>
<location>(BEAR).</location>
<contexts>
<context position="14316" citStr="Tetreault et al., 2013" startWordPosition="2188" endWordPosition="2191"> frequency and length is well established (Zipf, 1936). Finally, pairs of words that differ in length are less likely to be considered similar, which is reflected by word similarity measures. In summary, the reason for the greater phonetic similarity of translations lies in the similarity of their frequencies, which is reflected by the similarity of their lengths. This hypothesis remains to be verified on other languages and data sets. 8 L1 Phonology in L2 The task of Native Language Identification (NLI) is to determine the first language (L1) of the writer of a text in another language (L2) (Tetreault et al., 2013). Koppel et al. (2005) report 80% accuracy in classifying a set of English texts into five L1 languages using a multi-class linear SVM with features including function words, POS bigrams, and character n-grams. Tsur and Rappoport (2007) observe that limiting the set of features to the relative frequency of the 200 most frequent character bigrams yields a respectable accuracy of about 65%. They interpret this as evidence that the choice of words in L2 is strongly influenced by the phonology of L1. As the orthography of alphabetic languages is representative of their phonology, character bigrams</context>
</contexts>
<marker>Tetreault, Blanchard, Cahill, 2013</marker>
<rawString>Joel Tetreault, Daniel Blanchard, and Aoife Cahill. 2013. A Report on the First Native Language Identification Shared Task. In Workshop on Innovative Use of NLP for Building Educational Applications (BEAR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>Using classifier features for studying the effect of native language on the choice of written second language words.</title>
<date>2007</date>
<booktitle>In Workshop on Cognitive Aspects of Computational Language Acquisition,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="14552" citStr="Tsur and Rappoport (2007)" startWordPosition="2227" endWordPosition="2231">netic similarity of translations lies in the similarity of their frequencies, which is reflected by the similarity of their lengths. This hypothesis remains to be verified on other languages and data sets. 8 L1 Phonology in L2 The task of Native Language Identification (NLI) is to determine the first language (L1) of the writer of a text in another language (L2) (Tetreault et al., 2013). Koppel et al. (2005) report 80% accuracy in classifying a set of English texts into five L1 languages using a multi-class linear SVM with features including function words, POS bigrams, and character n-grams. Tsur and Rappoport (2007) observe that limiting the set of features to the relative frequency of the 200 most frequent character bigrams yields a respectable accuracy of about 65%. They interpret this as evidence that the choice of words in L2 is strongly influenced by the phonology of L1. As the orthography of alphabetic languages is representative of their phonology, character bigrams appear to capture these phonetic preferences. In order to test the above hypothesis, Nicolai and Kondrak (2014) design an algorithm to identify the most discriminative words and the corresponding character bigrams. They find that the r</context>
</contexts>
<marker>Tsur, Rappoport, 2007</marker>
<rawString>Oren Tsur and Ari Rappoport. 2007. Using classifier features for studying the effect of native language on the choice of written second language words. In Workshop on Cognitive Aspects of Computational Language Acquisition, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Yao</author>
<author>Grzegorz Kondrak</author>
</authors>
<date>2014</date>
<note>In preparation.</note>
<contexts>
<context position="17215" citStr="Yao and Kondrak (2014)" startWordPosition="2656" endWordPosition="2659">t is the optimal orthography for English, (b) how to measure the distance between alternative orthographies, and (c) what distance should be considered “close”. 10 Syllabification and Morphology Orthographic syllabification of words is sometimes referred to as hyphenation. Bartlett et al. (2008) propose a sequence prediction approach to syllabify out-of-dictionary words based on letter n-gram features. Despite its high accuracy, their system suffers from the lack of awareness of compound nouns and other morphological phenomena. For example, hold-o-ver is incorrectly syllabified as hol-dov-er. Yao and Kondrak (2014) demonstrate that the accuracy of orthographic syllabification can be improved by using morphological information. In particular, incorporating oracle morphological segmentation substantially reduces the syllabification error rate on English and German. If unsupervised segmentation is used instead, the error reduction is smaller but still significant. However, they are unable to achieve any error reduction using a supervised segmentation approach, even though it is much more accurate than the unsupervised approach. The confirmation and explanation of this surprising result remains an open ques</context>
</contexts>
<marker>Yao, Kondrak, 2014</marker>
<rawString>Lei Yao and Grzegorz Kondrak. 2014. In preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Haizhou Li</author>
<author>A Kumaran</author>
<author>Ming Liu</author>
</authors>
<title>machine transliteration shared task.</title>
<date>2012</date>
<journal>Report of NEWS</journal>
<booktitle>In 4th Named Entity Workshop,</booktitle>
<pages>10--20</pages>
<contexts>
<context position="7349" citStr="Zhang et al., 2012" startWordPosition="1102" endWordPosition="1105">n order to fully exploit the source-side context and other constraints. The way we define tasks in NLP is important, because the definitions (and shared tasks) tend to guide research in a particular direction. New papers are expected to show improvement over previously published results, preferably on already established benchmarks. Redefining a task carries the risk of being interpreted as an attempt to avoid a fair experimental comparison, or as a misdirected effort to investigate irrelevant problems. The NEWS Shared Task on Machine Transliteration was held four times between 2009 and 2012 (Zhang et al., 2012). With the exception of the 2010 edition that included a transliteration mining task, the shared task was invariably defined in terms of learning transliteration models from the training sets of word pairs. This framework seems to ignore the fact that many of the transliteration target words can be found in monolingual corpora, in a marked contrast with the prevalent SMT practice of avoiding unseen words. Cherry and Suzuki (2009) show that the inclusion of a target lexicon dramatically improves transliteration accuracy. Unfortunately, the paper has largely been ignored by the transliteration c</context>
</contexts>
<marker>Zhang, Li, Kumaran, Liu, 2012</marker>
<rawString>Min Zhang, Haizhou Li, A Kumaran, and Ming Liu. 2012. Report of NEWS 2012 machine transliteration shared task. In 4th Named Entity Workshop, pages 10–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Zipf</author>
</authors>
<title>The Psychobiology of Language.</title>
<date>1936</date>
<publisher>Routledge.</publisher>
<contexts>
<context position="13747" citStr="Zipf, 1936" startWordPosition="2093" endWordPosition="2094">oses to explain this phe66 nomenon by positing a chain of correlations between the following word characteristics: translatability, frequency, length, and similarity. The key observation is that translations are on average closer in terms of their length than random words. First, pairs of cross-lingual translations exhibit a correlation with respect to the logarithm of their frequencies. Intuitively, translations refer to the same semantic concepts, which tend to be expressed with similar frequency across languages. Second, the connection between word frequency and length is well established (Zipf, 1936). Finally, pairs of words that differ in length are less likely to be considered similar, which is reflected by word similarity measures. In summary, the reason for the greater phonetic similarity of translations lies in the similarity of their frequencies, which is reflected by the similarity of their lengths. This hypothesis remains to be verified on other languages and data sets. 8 L1 Phonology in L2 The task of Native Language Identification (NLI) is to determine the first language (L1) of the writer of a text in another language (L2) (Tetreault et al., 2013). Koppel et al. (2005) report 8</context>
</contexts>
<marker>Zipf, 1936</marker>
<rawString>George Zipf. 1936. The Psychobiology of Language. Routledge.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>