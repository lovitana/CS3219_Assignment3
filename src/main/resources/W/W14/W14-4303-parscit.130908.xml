<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000078">
<title confidence="0.979091">
Out-of-Domain Spoken Dialogs in the Car: A WoZ Study
</title>
<author confidence="0.9880665">
Sven Reichel, Jasmin Sohn,
Ute Ehrlich, Andr´e Berton
</author>
<affiliation confidence="0.8141935">
Speech Dialogue Systems
Daimler AG, Ulm, Germany
</affiliation>
<email confidence="0.993635">
sven.reichel@daimler.com
</email>
<author confidence="0.979259">
Michael Weber
</author>
<affiliation confidence="0.970028">
Institute of Media Informatics
Ulm University
</affiliation>
<address confidence="0.371871">
Germany
</address>
<email confidence="0.729552">
michael.weber@uni-ulm.de
</email>
<sectionHeader confidence="0.984668" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99993485">
Mobile Internet access via smartphones
puts demands on in-car infotainment sys-
tems, as more and more drivers like to ac-
cess the Internet while driving. Spoken
dialog systems (SDS) distract drivers less
than visual/haptic-based dialog systems.
However, in conversational SDSs drivers
might speak utterances which are not in
the domain of the SDS and thus cannot
be understood. In a Wizard of Oz study,
we evaluate the effects of out-of-domain
utterances on cognitive load, driving per-
formance, and usability. The results show
that an SDS which reacts as expected by
the driver, is a good approach to control in-
car infotainment systems, whereas unex-
pected SDS reactions might cause severe
accidents. We evaluate how a dialog initia-
tive switch, which guides the user and en-
ables him to reach his task goal, performs.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967372881357">
The acceptance of smartphones is a success story.
These devices allow people to access the Internet
nearly anywhere at anytime. While driving, using
a smartphone is prohibited in many countries as it
distracts the driver. Regardless of this prohibition,
people use their smartphone and cause severe in-
juries (National Highway Traffic Safety Adminis-
tration (NHTSA), 2013). In order to reduce driver
distraction, it is necessary to integrate the smart-
phones functionality safely into in-car infotain-
ment systems. Since hands and eyes are involved
in driving, a natural and intuitive speech-based in-
terface increases road safety (Maciej and Vollrath,
2009). There are already infotainment systems
with Internet applications like e.g. weather, music
streaming, gas prices, news, and restaurant search.
However, conversational spoken dialog sys-
tems (SDS) to control all these applications and
the car’s functionality, are still missing. Cur-
rent SDSs operate mostly in specific domains and
they understand user utterances which are related
to these domains. While using natural language,
users are not restricted to specific domains. Thus
one crucial problem for them is to know which ut-
terances the system is able to understand. Peo-
ple use different approaches to solve this prob-
lem, for example by reading the manual, using on-
screen help, or relying on their mental model of
the SDS. In multi-domain SDSs, utterances can be
quite complex and remembering all of them or dis-
playing them on screen would not be possible. As
a result, as long as conversational SDSs are not
able to operate in much wider domains, sooner
or later the user will speak an utterance which is
in his mental model of the SDS, but cannot be
processed. Such utterances can be divided into
out-of-domain and out-of-application-scope (Bo-
hus and Rudnicky, 2005). We induce errors in
domain switches and not within one domain, thus
only out-of-domain utterances are considered.
In this paper, we present results from a Wizard
of Oz (WoZ) study on multi-domain interaction
with an in-car SDS to evaluate the effects of out-
of-domain utterances on driver performance. We
considered four different system reactions: suc-
cessful domain switch, misunderstanding, non-
understanding, and a dialog initiative switch. By
analyzing them concerning driver distraction and
usability, we are able to evaluate whether a dia-
log initiative switch is an appropriate response to
an out-of-domain utterance or not. The results of-
fer valuable clues for the development of multi-
domain in-car SDSs.
The remainder is structured as follows: Section
2 provides an overview of studies in this context.
Section 3 describes the domain of the study which
is shown in Section 4. Data analysis methods are
defined in Section 5. We present and discuss the
results in Section 6 and conclude in Section 7.
</bodyText>
<page confidence="0.984738">
12
</page>
<note confidence="0.8112005">
Proceedings of the SIGDIAL 2014 Conference, pages 12–21,
Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.997811" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999897842105263">
Driver distractions, due to secondary tasks, are
evaluated in many studies (a good overview pro-
vides Ei-Wen Lo and Green (2013)). The driver’s
performance is generally better when using speech
interfaces than manual or visual interfaces, how-
ever, interacting with an SDS is often worse than
just driving (Bar´on and Green, 2006). Most stud-
ies consider specific domains and do not evalu-
ate how to handle domain switches. Kun et al.
(2013) evaluated multi-threaded dialogs between
humans while driving. By interrupting a dialog,
they observed an increase of cognitive load, which
affected the driving performance negatively. The
participants were prepared that an interruption will
be initiated at some time. This means they might
be surprised, however, it won’t be as unexpected as
system reactions in response to out-of-domain ut-
terances. In this work, we evaluate a dialog initia-
tive switch, as a possible reaction to out-of-domain
utterances.
In a driving simulator study, Kun et al. (2007)
showed that low SDS recognition accuracy affects
the steering wheel angle variance negatively. This
is first evidence that in-car SDSs need to han-
dle speech recognition or language understand-
ing errors intelligently. In preliminary work to
this study, we analyzed a dataset containing dia-
log errors in relation to driving performance, mea-
sured by the lane change task (Mattes, 2003). This
showed slight evidence that dialog errors, such as
responses to out-of-domain utterances, have an in-
fluence on driving performance. However, the lane
change task is not the right driving task for such
a fine granular analysis, as drivers are only occu-
pied during a lane change and thus not constantly
at the same level. Therefore, we analyze driving
performance with the Continuous Tracking and
Reaction (ConTRe) task (Mahr et al., 2012).
</bodyText>
<sectionHeader confidence="0.985541" genericHeader="method">
3 User Tasks
</sectionHeader>
<bodyText confidence="0.999758384615385">
In a user experiment it is crucial to set real tasks
for users, since artificial tasks will be hard to re-
member and can reduce their attention. We ana-
lyzed current in-car infotainment systems with In-
ternet access and derived eight multi-domain tasks
from their functionality (see Table 1). Since only
few natural use cases involve more than three do-
mains, every user task is a story of three subtasks.
In task number 5 for example, a user has to start
a subtask, which navigates him to Berlin. Then
he would like to search an Italian restaurant at the
destination. Finally, he adds the selected restau-
rant to his address book.
</bodyText>
<table confidence="0.989265777777778">
No Domain 1 Domain 2 Domain 3
1 POI Search Restaurant Call
2 Knowledge Ski Weather Navigation
3 Weather Hotel Search Address book
4 Play Artist News Search Forward by eMail
5 Navigation Restaurant Save Address
6 News Search Play Artist Share on Facebook
7 News Search Knowledge Convert Currency
8 Navigation Gas Prices Status Gas Tank
</table>
<tableCaption confidence="0.999835">
Table 1: Multi-domain user tasks.
</tableCaption>
<bodyText confidence="0.999619">
At the beginning of a task and during a sub-
task, the SDS always reacts as it is expected by
the users, which means it answers their requests.
This increases the stress when the system suddenly
starts to react unexpectedly. After presenting the
final answer of a subtask, the user has to initiate
a domain switch. In response to domain switch-
ing utterances four different system reactions were
used (see Section 4.2.2).
</bodyText>
<sectionHeader confidence="0.992451" genericHeader="method">
4 User Experiment
</sectionHeader>
<bodyText confidence="0.999465321428572">
Developing an SDS includes specifying a gram-
mar or training statistical language models for
speech recognition. These steps precede any real
user test. In system-initiated dialogs, with a few
possible utterances, specifying a grammar is fea-
sible. However, in strictly user-initiative dialogs
covering multiple domains, this is rather compli-
cated. A WoZ study does not require to develop
speech recognition and language understanding as
this is performed by a human (Fraser and Gilbert,
1991). In addition, the system reaction is con-
trolled and not influenced by recognition errors.
Our study requires such a controlled environment,
as an unexpected system reaction, due to a recog-
nition error, would influence the results negatively.
Driver distraction and usability ratings vary
among people and depend on age, personality, ex-
perience, context, and many more. Therefore, it
is essential to conduct a user study with people
who might use the SDS later on. A study by
the NHTSA (National Highway Traffic Safety Ad-
ministration (NHTSA), 2013) showed that 73% of
the drivers involved in fatal crashes due to cell
phone use in 2011, were less than 40 years old. For
this reason, our study considers drivers between
18 and 40 years who are technically affine and are
likely to buy a car equipped with an infotainment
system with Internet access.
</bodyText>
<page confidence="0.998018">
13
</page>
<subsectionHeader confidence="0.997992">
4.1 Set-Up of the Experiment
</subsectionHeader>
<bodyText confidence="0.999446642857143">
When designing a user interaction experiment, it is
important that it takes place in a real environment.
As driving on a real road is dangerous, we used
a fixed-base driving simulator in a laboratory. A
screen in front of the car covers the driver’s field
of view (see Figure 1). Steering and pedal signals
are picked from the car’s CAN bus.
It is important that the user assumes he is in-
teracting with a computer as “human-human in-
teractions are not the same as human-computer in-
teractions” (Fraser and Gilbert, 1991). The wiz-
ard, a person in charge of the experiment, was lo-
cated behind the car and mouse clicks or any other
interaction of the wizard was not audible in the
car. To ensure a consistent behavior of the wiz-
ard, we used SUEDE (Klemmer et al., 2000) to
define the dialog, which also provides an interface
for the wizard. SUEDE defines a dialog in a state
machine, in which the system prompts are states
and user inputs are edges between them. The con-
tent of system prompts was synthesized with NU-
ANCE Vocalizer Expressive1 version 1.2.1 (Voice:
anna.full). During the experiment, the wizard
clicks the corresponding edge after each user in-
put and SUEDE plays the next prompt.
the car, as this would require additional human re-
sources and it would increase the driver distraction
(Young and Regan, 2007).
</bodyText>
<subsubsectionHeader confidence="0.58855">
4.2.1 Primary Task: Driving Simulator
</subsubsectionHeader>
<bodyText confidence="0.999733107142857">
One major requirement for the driving simulator is
to ensure a controlled and comparable driver dis-
traction measure over all interaction variants and
participants. The open-source driving simulator
OpenDS provides a driving environment and ex-
tensive logging facilities (Math et al., 2012). As
explained in Section 2, it is essential to keep the
driver occupied at a constant level all the time.
Therefore, we used the ConTRe task (Mahr et al.,
2012), which consists of a continuous steering task
and a reaction task.
Figure 2 shows the ConTRe task with steering
cylinders and a traffic light. The yellow steering
cylinder moves unpredictably right and left at a
constant distance from the driver. The driver has
to steer the blue cylinder to superpose it with the
middle section of the yellow one. This is similar
to driving on a curved road. Sometimes a driver
needs to react to sudden events to prevent an acci-
dent. A traffic light shows randomly red and green
and requires the driver to push the throttle or brake
pedal. As the car drives constantly at 50km/h, the
pedals are only pushed in response to the traffic
light. The movement of the yellow cylinder and
the appearance of the traffic light can be controlled
by manipulating OpenDS’ control variables. We
used the “hard driving” condition as described by
Mahr et al. (2012).
</bodyText>
<figureCaption confidence="0.999375">
Figure 1: Set-up of the experiment
</figureCaption>
<subsectionHeader confidence="0.996857">
4.2 Design of the Experiment
</subsectionHeader>
<bodyText confidence="0.9996092">
Driving a car requires the driver to focus on the
road and react appropriately to sudden events.
However, if drivers are occupied with a secondary
task, such as controlling an infotainment system,
their attention to the road might suffer. This is due
to the fact that the human’s performance is reduced
when human resources overlap (Wickens, 2008).
In this experiment, a dual task scenario is used by
driving in a simulator and interacting with an SDS
at the same time. There is no visual display in
</bodyText>
<footnote confidence="0.861585">
1http://www.nuance.com/for-business/mobile-
solutions/vocalizer-expressive/index.htm
</footnote>
<figureCaption confidence="0.995857">
Figure 2: Continuous tracking and reaction task
</figureCaption>
<subsectionHeader confidence="0.959258">
4.2.2 Secondary Task: Responses to Domain
Switching Requests
</subsectionHeader>
<bodyText confidence="0.893642">
A task in our experiment consists of three subtasks
and each subtask requires two to four semantic
concepts. For a user it is possible to insert mul-
tiple concepts at once:
U: “Search an Italian restaurant at my destination”
</bodyText>
<page confidence="0.994766">
14
</page>
<bodyText confidence="0.97706926984127">
or as single utterances in a dialog:
U: “Search an Italian restaurant”
S: “Where do you search an Italian restaurant?”
U: “At my destination”
Prompts were created for all possible combina-
tions. SUEDE provides a GUI for the wizard to
select which semantic concepts a user input con-
tains. Depending on the selection, either another
concept is requested or the answer is provided.
Within one subtask, the system always reacts as
expected by the user. An answer for the presented
example might look like:
S: “There is one Italian restaurant: Pizzeria San Marco.”
After this, the user has to initiate a domain
switch to save the pizzeria’s address into his
personal address book. Such user-initiated do-
main switches challenge current SDSs as lan-
guage models increase and thus speech recogni-
tion as well as language understanding is error
prone (Carstensen et al., 2010). Furthermore, the
user could request a functionality which is not sup-
ported by the system. In case of such a request,
SDSs react differently and could apply error re-
covery strategies if the error is recognized. To an-
alyze the impact of error recovery strategies in the
car, we use four different kinds of responses to do-
main switching requests.
Figure 3 shows the study’s conditions. Detailed
dialogs that corresponds to them can be found
in the Appendix. First of all, we consider the
Expected Reaction (ER) condition, in which the
SDS reacts as expected by the user and switches
the domain. As the speech is recognized by a wiz-
ard, this is an optimal system without any errors.
Miscommunication can be distinguished be-
tween misunderstanding and non-understanding
(Skantze, 2007). In the MisUnderstanding (MU)
condition, the SDS does not recognize the do-
main switch request and it responses in context
of the current domain. On the contrary, in the
Non-Understanding (NU) condition, it recognizes
an out-of-domain utterance and refuses the ac-
tion by apologizing and encouraging the user to
rephrase his utterance (a combination of Bohus
and Rudnicky (2005)’s Notify and AskRephrase
error handling strategies). The only way to pro-
ceed with a MU or NU task in our experiment is to
use an explicit domain switching command, such
as “start radio application”. As we have shown
in Reichel et al. (2014), participants do not use
such commands naturally in a speech-only info-
tainment system and only use them after trying
numerous unsuccessful utterances. Another ap-
proach is a Dialog Initiative Switch (DIS) to guide
the user after recognizing an out-of-domain utter-
ance (Notify and YouCanSay strategy (Bohus and
Rudnicky, 2005)). Therefore, the SDS proposes a
choice of four possible domains to interact with.
Users have to select the first option which was fol-
lowed by four possible actions within this domain.
By selecting the desired action, the SDS reads out
four examples of possible utterances. After that,
the dialog initiative is given back to the user.
</bodyText>
<subsubsectionHeader confidence="0.644874">
Miscommunication
</subsubsectionHeader>
<figureCaption confidence="0.998033">
Figure 3: Domain switching response conditions
</figureCaption>
<subsectionHeader confidence="0.994091">
4.3 Procedure of the experiment
</subsectionHeader>
<bodyText confidence="0.999977166666667">
The experiment starts with an initial questionnaire
to create a profile of the participant, concerning
age, experience with smartphones, infotainment
systems and SDSs. Then participants are intro-
duced to the driving task and they have time to
practice till being experienced. After completing
a baseline drive, they start to use the SDS. For
each spoken dialog task users get a story describ-
ing in prose what they like to achieve. To mini-
mize priming effects, they have to remember their
task and are not allowed to keep the description
during the interaction. There is no explanation
or example of the SDS, apart from a start com-
mand for activation. After the start command, the
system plays a beep and the user can say what-
ever he likes to achieve his task. The exploration
phase consists of four tasks, in which the system
reacts as it is expected by the user. This enables
the user to get used to the SDS while driving. In
the second part of the experiment, one task for
each condition was completed (ER, MU, NU, and
DIS). The conditions were assigned randomly to
a task and each one was rated by a Subjective
Assessment of Speech System Interfaces (SASSI)
(Hone and Graham, 2000) and Driver Activity
Load Index (DALI) (Pauzi´e et al., 2007) question-
naire. At end of the experiment, each participant
completed a second baseline drive without using
the SDS to analyze whether the driving perfor-
mance changed to the first baseline drive or not.
</bodyText>
<figure confidence="0.995597333333333">
Action
(e.g. “add restaurant”)
Execute
Refuse
Expected
Reaction (ER)
Misunder-
standing (MU)
Non-Under-
standing (NU)
Dialog Initiative
Switch (DIS)
</figure>
<page confidence="0.939148">
15
</page>
<bodyText confidence="0.9955955">
After that, the four conditions were compared in a
questionnaire.
</bodyText>
<sectionHeader confidence="0.964543" genericHeader="method">
5 Evaluation Metrics and Hypotheses
</sectionHeader>
<bodyText confidence="0.99992444">
The goal of this study is to evaluate four SDS
response conditions concerning driver distraction
and usability. Therefore, we used four kinds
of measurements (see Table 2): objective driv-
ing performance logged by OpenDS, subjective
driver distraction with DALI questionnaires, us-
ability scores measured by SASSI questionnaires,
and dialog performance. The steering deviation
value measures the driver’s performance to keep
the blue cylinder superposed to the yellow one in
the ConTRe task. Reaction times between the ap-
pearance of a traffic light and the pedal press are
logged as well as wrong and missed pedal presses.
The DALI questionnaire consists of 7 questions
which are assigned to 7 domains to evaluate the
driver’s cognitive load. We did not ask for visual
or haptic demand, as the system does not have vi-
sual output or haptic input. A 7-point Likert scale
was used: low cognitive load (-3) to high cognitive
load (+3). SASSI is widely used to measure the
usability of an SDS covering 6 dimensions with
34 questions. We used a 7-point Likert scale from
strong disagree (-3) to strong agree (+3). High
values mean good usability, except for annoyance
and cognitive demand ratings, which are opposed.
</bodyText>
<table confidence="0.999756611111111">
objective driving steering deviation
performance reaction time
(OpenDS) missed reaction
wrong reaction
cognitive load global attention
(DALI) auditory demand
interference
temporal demand
usability (SASSI) system response accuracy (SRA)
likeability (Like)
cognitive demand (Cog Dem)
annoyance (Ann)
habitability (Hab)
speed
dialog performance task success
user response delay
system turn duration
user turn duration
</table>
<tableCaption confidence="0.999632">
Table 2: Evaluation metrics
</tableCaption>
<bodyText confidence="0.998788888888889">
Obviously, we expect that drivers perform best
during the baseline drives without controlling the
SDS. As ER does not stress or frustrate drivers and
they do not need much cognitive power to think
what to say, there won’t be huge differences be-
tween ER and baseline drives. On the contrary,
if the system does not react as expected (MU and
NU), we expect a worse driving performance and
poor usability ratings. NU should be rated bet-
ter than MU, as the SDS explains the problem.
The interesting part is how a DIS will perform as
an error handling strategy to out-of-domain utter-
ances. We assume that it is rated better than MU
and NU and worse than ER. As the help dialogs in
DIS are long, DIS might tend towards MU and NU
in terms of driver distraction. However, it will be
rated better in terms of usability because the task
success is expected to be higher.
</bodyText>
<figure confidence="0.83152525">
3 ER
2 MU_NU
1 DIS
0
-1
-2
-3
SRA Like Cog Dem Ann Hab Speed
</figure>
<figureCaption confidence="0.9714275">
Figure 4: Usability ratings, all of them are significant
(p&lt;.001) except of: speed between DIS and MU NU
</figureCaption>
<sectionHeader confidence="0.999754" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999896416666667">
In the following, evaluation results of the four do-
main switching responses are shown. We analyzed
data from 30 participants (16m/14f), with average
age of 26.65 (SD: 3.32). Their experience with
SDS is little (6-Likert Scale, avg: 3.06, SD: 1.48)
as well as the usage of SDSs (5-Likert Scale, avg:
2.04, SD: 1.16). We asked them how they usu-
ally approach a new system to learn its interaction
schema and scope of operation. All 30 of them
try a new application on their smartphone without
informing themselves how it is used. Concerning
infotainment systems, trying is also the most used
learning approach, even while driving (26 people).
This means, people do not read a manual, but the
system has to be naturally usable. In terms of driv-
ing experience, all participants have a driver li-
cense for average 8.6 (SD: 3.5) years and most of
them use their car daily. Considering the objective
driving performances of the two baseline drives,
there are no significant differences, which means
the participants performed at a constant level over
the entire experiment. Figure 4, 5 and 6 show a
detailed overview of the evaluation results, which
will be explained in this Section.
</bodyText>
<page confidence="0.989979">
16
</page>
<table confidence="0.973377111111111">
ER Baseline MU_NU DIS
*
*
**
0,43 0,20 1,47
1,03
ER Baseline MU_NU DIS
ER Baseline MU_NU DIS
ER Baseline MU_NU DIS
</table>
<figure confidence="0.995485785714286">
Steering Deviation
0,24
0,22
0,18
0,16
0,2
0,177 0,171
**
0,188
0,178
1,3
Reaction Time [sec]
0,9
0,8
1,2
1,1
1
1,038
0,840
1,060
1,042
6 *
Wrong Pedals
4
5
3
0
2
1
0,57 0,35
**
***
2,34
1,80
6
5
4
3
2
Missed Pedals
1
0
</figure>
<figureCaption confidence="0.996366">
Figure 5: Objective driving performance (OpenDS), significance levels: p&lt;.05(*), p&lt;.01(**), p&lt;.001(***)
</figureCaption>
<figure confidence="0.464606">
Attention Auditory Stress Interference Temporal
</figure>
<figureCaption confidence="0.999054">
Figure 6: Cognitive load: driver activity load index (DALI), significance levels: p&lt;.05(*), p&lt;.01(**), p&lt;.001(***)
</figureCaption>
<figure confidence="0.999424740740741">
ER
Baseline
MU_NU
DIS
Driver Activity Load Index
-1
-2
-3
3
2
0
1
***
***
***
***
* * ***
***
***
***
***
***
***
***
***
***
***
</figure>
<subsectionHeader confidence="0.990209">
6.1 SDS which Reacts as Expected (ER)
</subsectionHeader>
<bodyText confidence="0.9998851875">
First of all, results of an optimal SDS (ER), which
reacts as expected and does not make any mis-
takes, are presented. The objective driver perfor-
mance (see Figure 5) is slightly worse than the
baseline drives in terms of steering and pressing
the right pedals, but not significantly. However,
reaction times are worse than without interacting
with an SDS. This corresponds to the results from
Patten et al. (2004), who observed an increase in
reaction times when drivers talk to someone on the
phone. The cognitive load (see Figure 6) caused
by an optimal SDS is negative in all dimensions,
which means an optimal SDS does not put high
demands on the driver. In general, ER was rated
very good in terms of usability (see Figure 4) and
would most likely be accepted by young drivers.
</bodyText>
<subsectionHeader confidence="0.99847">
6.2 Mis- and Non-Understanding (MU, NU)
</subsectionHeader>
<bodyText confidence="0.999944416666667">
The results of MU and NU do not show signifi-
cant differences in any dimension. Therefore, the
mean value of MU and NU is used. As shown in
Figure 6, the driver’s cognitive load is high in all
dimensions for MU NU. In terms of stress and at-
tention, it is significantly higher than during base-
line drives (other DALI dimensions are not as-
sessed for baseline drives). Due to the increased
cognitive load, the driver’s performance (see Fig-
ure 5) concerning steering, reaction times, and
pedal presses decreases significantly compared to
baseline drives. Especially the number of times
</bodyText>
<page confidence="0.997918">
17
</page>
<bodyText confidence="0.999878545454545">
drivers do not react to external events at all (missed
pedal), or they do not react appropriately (wrong
pedal), increases strongly. The usability ratings
provide evidence how users rate an SDS which is
not usable.
As expected, ER performs better than MU NU.
An unexpected system reaction causes higher cog-
nitive load in all dimensions. However, in contrast
to what one might expect, the driver’s steering per-
formance and reaction times are not better than for
ER (psteering=.083 and preaction=.215).
</bodyText>
<subsectionHeader confidence="0.999267">
6.3 Dialog Initiative Switch as an Out-Of-
Domain Handling Strategy (DIS)
</subsectionHeader>
<bodyText confidence="0.999811071428572">
Previous Sections have shown that it is impor-
tant to minimize misunderstandings and non-
understandings in a safe and usable in-car infotain-
ment system. Comparing DIS with an optimal and
a worst-case SDS shows whether it is a reason-
able approach to handle out-of-domain utterances
or not. We use a single factor variance analysis
(ANOVA) with repeated measurements to identify
the best (Helmert contrast) and worst (difference
contrast) condition out of ER, DIS, and MU NU.
If DIS lays between ER and MU NU, we analyze
whether DIS tends towards ER or MU NU. There-
fore, we compare the differences of ER-DIS with
MU NU-DIS and use a one sample t-test.
</bodyText>
<subsectionHeader confidence="0.983966">
6.3.1 Driving Performance
</subsectionHeader>
<bodyText confidence="0.999963">
The ANOVA did not show any significant differ-
ences in drivers’ steering performances or reaction
times (see Figure 5). Using a Helmert contrast to
determine the best response, the ANOVA identi-
fied ER as the condition with significantly fewest
missed and wrong reactions. There is no differ-
ence between DIS and MU NU, thus DIS tends in
terms of objective driver distraction more towards
MU NU than to ER.
</bodyText>
<subsectionHeader confidence="0.986718">
6.3.2 Cognitive Load
</subsectionHeader>
<bodyText confidence="0.999966272727273">
Analyzing the cognitive load of ER, DIS, and
MU NU (see Figure 6), the ANOVA identifies ER
as the significant best condition (p&lt;.002). The
significant worst one in terms of attention, stress,
and interference is MU NU, which means DIS
lays in between for these dimensions. However,
no evidence is found for stress or interference
whether DIS tends towards ER or MU NU. In
global attention, DIS tends slightly (p&lt;.031) to-
wards MU NU. Furthermore, the long prompts in
DIS put high auditive demands on the driver.
</bodyText>
<subsectionHeader confidence="0.969837">
6.3.3 Usability
</subsectionHeader>
<bodyText confidence="0.999808071428571">
As task success of MU NU dialogs is poor (see
Section 6.4), it is obvious that ER is the best
(p&lt;.001) and MU NU is the worst condition
(p&lt;.001) in terms of usability (see Figure 4). All
DIS ratings, except of speed, are between ER and
MU NU (p&lt;.001). Speed is basically identical
to the MU NU rating, which is due to the long
prompts. There is a slight tendency of DIS towards
ER in system response accuracy (p&lt;.051) and in
habitability (p&lt;.077), however, this is not signif-
icant. In annoyance DIS tends towards MU NU
(p&lt;.002), which might be due to the three step
help dialog. For cognitive demand and likability,
DIS lays exactly between ER and MU NU.
</bodyText>
<subsectionHeader confidence="0.998225">
6.4 Dialog Performance
</subsectionHeader>
<bodyText confidence="0.999979346153846">
The task success is pretty low in MU (29.03%) and
NU (19.35%) as the task was aborted by the wiz-
ard, if drivers did not use explicit domain switch-
ing commands after multiple attempts. On the
contrary, the task success for ER (96.8%) and DIS
(93.6%) is good, however, 3 tasks were aborted by
users. Figure 7 shows the average user response
delay, system turn duration, and user turn dura-
tion. The rectangular bars drawn in line patterns
show successful interactions during a subtask and
the ones drawn in checked pattern dialogs between
two subtasks.
When the system responds as expected, users
need between 2 and 3 seconds to respond. If the
system does not react as expected (between two
subtasks), drivers need significantly more time to
respond, as they need to think what to say. In DIS,
they only need to repeat the proposed term, thus
they respond faster. In MU NU, the system turns
in dialogs between subtasks are shorter, whereby
the user turns are longer (user turn duration does
not include the user’s response time). So either
drivers speak slower or provide longer sentences,
if the SDS does not react as expected. Due to the
four proposed utterances in DIS, system turn du-
rations are longer in dialogs between subtasks.
</bodyText>
<subsectionHeader confidence="0.996949">
6.5 Summary and Discussion
</subsectionHeader>
<bodyText confidence="0.999981">
In general, if an SDS reacts as expected by the
user, it will be a good approach to control the in-
car infotainment system. Except for the driver’s
reaction time, an optimal SDS does not influence
the driving performance. However, a delayed re-
action of 200ms might be better than glancing at a
</bodyText>
<page confidence="0.993934">
18
</page>
<figure confidence="0.996905733333333">
6
** ***
* ***
User Turn Duration [sec]
4
2
0
User Response Delay [sec] 8 System Turn Duration [sec] 8
6 6
4 4
2 2
0 0
ER MU_NU DIS
ER MU_NU DIS
ER MU_NU DIS
</figure>
<figureCaption confidence="0.995675">
Figure 7: Dialog performance (light color: interaction during subtasks, dark color: dialog between two subtasks), significance
levels: p&lt;.05(*), p&lt;.01(**), p&lt;.001(***)
</figureCaption>
<bodyText confidence="0.943660214285714">
display. For example, the Driver Focus-Telematics
Working Group (2006) states in their guidelines to
visual distraction: “single glance durations gener-
ally should not exceed 2 seconds”.
As long as conversational SDSs are not able to
operate in much wider domains, sooner or later the
user will provide an utterance the system is not
able to respond to. Comparing the MU and NU
conditions shows that an out-of-domain recogni-
tion with a simple rephrase error recovery strategy
does not work. This is understandable, as both
conditions increase the cognitive load, which in-
fluences the driving performance negatively. Es-
pecially the reaction to external events, such as
traffic lights, suffers. In our experiment, the traf-
fic light was in the middle of the screen. Accord-
ing to Victor et al. (2005), drivers concentrate their
gaze on the road center at the expense of periph-
eral glances during auditory or complex driving
tasks. Thus we would expect even worse results
if the traffic light occurs in the driver’s peripheral
vision. This means an intelligent handling strat-
egy for out-of-domain utterances needs to be es-
tablished, which informs drivers of the system’s
capabilities.
We evaluated a dialog initiative switch as a re-
sponse to out-of-domain utterances. Mostly, this
strategy performed somewhere between the opti-
mal and worst-case SDS. Due to long narrative
system prompts, the auditive demand is rated high
by drivers and thus the driving performance tends
towards the worst-case SDS. The dialog initiative
switch was rated as usable, but different variants
need to be developed and evaluated in the future.
After the experiment, the participants rated the
four conditions with two questions from ITU-T
P.851 (ITU, 2003) on a 7-point Likert scale from
strong disagree (-3) to strong agree (+3):
Q1: “Would you have expected more help from the sys-
tem?”
Q2: “You feel adequately informed about the system’s pos-
sibilities?”
</bodyText>
<table confidence="0.989495">
ER (SD) MU (SD) NU (SD) DIS (SD)
Q1 -1.73(1.78) 1.47(1.81) 2.1(1.32) -1.1(1.58)
Q2 0.43(2.13) -1.53(1.36) -1.7(1.49) 0.73(1.66)
</table>
<tableCaption confidence="0.999716">
Table 3: Adequate system help
</tableCaption>
<bodyText confidence="0.996776818181818">
Table 3 shows the results, whereby DIS tends
towards ER in Q1 (p&lt;.004) and is even better than
ER in Q2. This means the drivers felt informed
adequately of the SDS, however, further research
is necessary to evaluate how to present this infor-
mation. Shorter helping prompts might be better.
Furthermore, multimodal aspects needs to be con-
sidered. For example, head-up displays are able to
present information, such as possible utterances,
right in the driver’s view. This might reduce the
auditive demand.
</bodyText>
<sectionHeader confidence="0.999343" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999983941176471">
In this paper, we showed results from a WoZ
study on user-initiated multi-domain SDSs in the
car. If an in-car SDS cannot fulfill a user’s re-
quest due to, for example, missing functionality,
the driver’s cognitive load and distraction will in-
crease. Therefore, out-of-domain utterances need
to be identified and handled adequately by in-car
SDSs. Switching the dialog initiative is a good ap-
proach to guide users to the task goal and reduce
their cognitive load. However, if drivers need to
process any information, some mental activity will
be required. Therefore, the design and implemen-
tation of a dialog initiative switch strategy need
further efforts to minimize the driver’s distraction
and to make it enjoyable for the user. Other modal-
ities than speech-only SDSs, such as head-up dis-
plays, need to be evaluated in future studies.
</bodyText>
<sectionHeader confidence="0.998622" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9987315">
The work presented here was funded by GetH-
omeSafe (EU 7th Framework STREP 288667).
</bodyText>
<page confidence="0.998946">
19
</page>
<sectionHeader confidence="0.990317" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.928401081632653">
Adriana Bar´on and Paul Green. 2006. Safety and us-
ability of speech interfaces for in-vehicle tasks while
driving: A brief literature review. Technical report,
University of Michigan Transportation Research In-
stitute.
Dan Bohus and Alexander I. Rudnicky. 2005.
Sorry, i didnt catch that! an investigation of non-
understanding errors and recovery strategies. In
Proceedings of SIGdial, Lisbon, Portugal.
Kai-Uwe Carstensen, Christian Ebert, Cornelia Ebert,
Susanne Jekat, Ralf Klabunde, and Hagen Langer.
2010. Computerlinguistik und Sprachtechnologie.
Spektrum, Akad. Verl.
Driver Focus-Telematics Working Group. 2006. State-
ment of principles, criteria and verification pro-
cedures on driver interactions with advanced in-
vehicle information and communication systems.
Victor Ei-Wen Lo and Paul A. Green. 2013. Devel-
opment and evaluation of automotive speech inter-
faces: Useful information from the human factors
and the related literature. Int. Journal of Vehicular
Technology, 2013:13.
Norman M. Fraser and G.Nigel Gilbert. 1991. Sim-
ulating speech systems. Computer Speech &amp; Lan-
guage, 5(1):81 – 99.
Kate S Hone and Robert Graham. 2000. Towards a
tool for the subjective assessment of speech system
interfaces (sassi). Natural Language Engineering,
6(3&amp;4):287–303.
International Telecommunication Union (ITU). 2003.
Subjective quality evaluation of telephone services
based on spoken dialogue systems (itu-t rec. p.851).
Scott R. Klemmer, Anoop K. Sinha, Jack Chen,
James A. Landay, Nadeem Aboobaker, and Annie
Wang. 2000. Suede: a wizard of oz prototyping
tool for speech user interfaces. In Proc. of the 13th
annual ACM symposium on User interface software
and technology, New York. ACM.
Andrew L. Kun, Tim Paek, and Zeljko Medenica.
2007. The effect of speech interface accuracy on
driving performance. In INTERSPEECH, pages
1326–1329, Antwerp, Belgium.
Andrew L. Kun, Alexander Shyrokov, and PeterA.
Heeman. 2013. Interactions between humanhuman
multi-threaded dialogues and driving. Personal and
Ubiquitous Computing, 17(5):825–834.
Jannette Maciej and Mark Vollrath. 2009. Compari-
son of manual vs. speech-based interaction with in-
vehicle information systems. Accident Analysis and
Prevention, 41(5):924 – 930.
Angela Mahr, Michael Feld, Mohammad Mehdi
Moniri, and Rafael Math. 2012. The contre (con-
tinuous tracking and reaction) task: A flexible ap-
proach for assessing driver cognitive workload with
high sensitivity. In Adjunct Proceedings of the 4th
AutomotiveUI, Portsmouth. ACM.
Rafael Math, Angela Mahr, Mohammad M Moniri, and
Christian M¨uller. 2012. Opends: A new open-
source driving simulator for research. Adjunct Pro-
ceedings of the 4th AutomotiveUI.
Stefan Mattes. 2003. The lane-change-task as a tool
for driver distraction. In Proceedings of IGfA, Dear-
born.
National Highway Traffic Safety Administra-
tion (NHTSA). 2013. Distracted driving 2011.
Technical report.
Christopher J.D Patten, Albert Kircher, Joakim stlund,
and Lena Nilsson. 2004. Using mobile telephones:
cognitive workload and attention resource alloca-
tion. Accident Analysis &amp; Prevention, 36(3):341 –
350.
Annie Pauzi´e, J Manzan, and Nicolas Dapzol. 2007.
Driver’s behavior and workload assessment for new
in-vehicle technologies design. In Proceedings of
the 4th International Driving Symposium on Human
Factors in Driver Assessment, Training, and Vehicle
Design., Stevenson, Washington.
Sven Reichel, Ute Ehrlich, Andr´e Berton, and Michael
Weber. 2014. In-car multi-domain spoken dialogs:
A wizard of oz study. In EACL Workshop Dialog in
Motion, Gothenburg, Sweden.
Gabriel Skantze. 2007. Error Handling in Spoken Di-
alogue Systems. Ph.D. thesis, KTH Computer Sci-
ence and Communication.
Trent W. Victor, Joanne L. Harbluk, and Johan A. En-
gstrm. 2005. Sensitivity of eye-movement mea-
sures to in-vehicle task difficulty. Transportation
Research Part F: Traffic Psychology and Behaviour,
8(2):167 – 190. The relationship between distrac-
tion and driving performance: towards a test regime
for in-vehicle information systems In-vehicle infor-
mation systems.
Christopher D Wickens. 2008. Multiple resources and
mental workload. In Human factors, volume 50,
pages 449–55. USA.
Kristie Young and Michael Regan. 2007. Driver dis-
traction: A review of the literature. Distracted Driv-
ing.
</reference>
<page confidence="0.997295">
20
</page>
<sectionHeader confidence="0.987984" genericHeader="acknowledgments">
Appendix
</sectionHeader>
<reference confidence="0.973914117021277">
ER:
U: Navigation
S: Navigation, what do you want?
U: City Berlin
S: To what address or place of interest do you
want?
U: Brandenburger Tor
S: Brandenburger Tor in Berlin was set as your
destination
U: Italian restaurant near Brandenburger Tor?
S: There is one Italian restaurant in Berlin:
Pizzeria San Marco
U: Save the address
S: Alright, the address was added
DIS:
U: I would like to go to the Brandenburger Tor
in Berlin
S: Brandenburger Tor in Berlin was set as your
destination.
U: Italian restaurant nearby?
S: Action unknown, you can say: restaurant,
navigation, hotel, or radio
U: Restaurant
S: You can: search a restaurant, order a table,
rate a restaurant, request opening times
U: Search a restaurant
S: Say for example: Search a restaurant at the
destination, I search a Chinese restaurant, “Die
Krone” in Stuttgart, or Mexican restaurant
U: I search an Italian restaurant
S: Where do you search an Italian restaurant
U: Near Brandenburger Tor in Berlin
S: There is one Italian restaurant in Berlin:
Pizzeria San Marco
U: Save the address
S: Action unknown, you can say: address book,
restaurant, navigation, or hotel
U: address book
S: You can: add a contact, remove a contact,
access contact details, or delete address book
U: Add a contact
S: Say for example: I’d like to add a contact,
add an address, add Paul to my address book,
save the number 0165332
U: Add San Marco to my address book
S: Alright, the address was added
MU:
U: Navigation to Berlin, Brandenburger Tor
S: Brandenburger Tor in Berlin was set as your
destination.
U: Italian restaurant at the destination
S: Italian restaurant could not be set as a
destination
U: Navigate to a restaurant in Berlin
S: The address restaurant in Berlin was not
found
U: I would like to search a restaurant
S: Sorry?
U: Start restaurant application
S: Restaurant search, what do you want?
U: An Italian restaurant in Berlin
S: There is one Italian restaurant in Berlin:
Pizzeria San Marco
U: Add the address to my address book
S: The address of Pizzeria San Marco is
Mainstreet 1, Berlin
U: Save that to my address book
S: Sorry?
U: Save Pizzeria San Marco
S: Pizzeria San Marco is famous for its delicious
Italian dishes
U: Address book
S: Address book, what do you want?
U: Save the address of San Marco
S: Alright, the address was added
NU:
U: Drive me to the Brandenburger Tor in Berlin
S: Brandenburger Tor in Berlin was set as your
destination.
U: Is there an Italian restaurant near
Brandenburger Tor?
S: Action unknown, please say something else
U: Give me an Italian restaurant along the
route
S: Action unknown, please say something else
U: Italian restaurant
S: Action unknown, please say something else
U: Restaurant in Berlin
S: Action unknown, please say something else
U: I’d like to search a restaurant
S: Action unknown, please say something else
&lt;aborted by the wizard&gt;
Appendix 1: Detailed dialog examples of the four response conditions. Translated from German and based on real experiment
data. Red rectangles identify the domain switching dialogs between two subtasks.
</reference>
<page confidence="0.999428">
21
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.286450">
<title confidence="0.999431">Out-of-Domain Spoken Dialogs in the Car: A WoZ Study</title>
<author confidence="0.900166">Sven Reichel</author>
<author confidence="0.900166">Jasmin Ute Ehrlich</author>
<author confidence="0.900166">Andr´e</author>
<affiliation confidence="0.825715">Speech Dialogue Daimler AG, Ulm,</affiliation>
<email confidence="0.999787">sven.reichel@daimler.com</email>
<author confidence="0.967646">Michael</author>
<affiliation confidence="0.999987">Institute of Media</affiliation>
<address confidence="0.50503">Ulm</address>
<email confidence="0.997308">michael.weber@uni-ulm.de</email>
<abstract confidence="0.99843219047619">Mobile Internet access via smartphones puts demands on in-car infotainment systems, as more and more drivers like to access the Internet while driving. Spoken dialog systems (SDS) distract drivers less than visual/haptic-based dialog systems. However, in conversational SDSs drivers might speak utterances which are not in the domain of the SDS and thus cannot be understood. In a Wizard of Oz study, we evaluate the effects of out-of-domain utterances on cognitive load, driving performance, and usability. The results show that an SDS which reacts as expected by the driver, is a good approach to control incar infotainment systems, whereas unexpected SDS reactions might cause severe accidents. We evaluate how a dialog initiative switch, which guides the user and enables him to reach his task goal, performs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adriana Bar´on</author>
<author>Paul Green</author>
</authors>
<title>Safety and usability of speech interfaces for in-vehicle tasks while driving: A brief literature review.</title>
<date>2006</date>
<tech>Technical report,</tech>
<institution>University of Michigan Transportation Research Institute.</institution>
<marker>Bar´on, Green, 2006</marker>
<rawString>Adriana Bar´on and Paul Green. 2006. Safety and usability of speech interfaces for in-vehicle tasks while driving: A brief literature review. Technical report, University of Michigan Transportation Research Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Sorry, i didnt catch that! an investigation of nonunderstanding errors and recovery strategies.</title>
<date>2005</date>
<booktitle>In Proceedings of SIGdial,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="2937" citStr="Bohus and Rudnicky, 2005" startWordPosition="456" endWordPosition="460"> is able to understand. People use different approaches to solve this problem, for example by reading the manual, using onscreen help, or relying on their mental model of the SDS. In multi-domain SDSs, utterances can be quite complex and remembering all of them or displaying them on screen would not be possible. As a result, as long as conversational SDSs are not able to operate in much wider domains, sooner or later the user will speak an utterance which is in his mental model of the SDS, but cannot be processed. Such utterances can be divided into out-of-domain and out-of-application-scope (Bohus and Rudnicky, 2005). We induce errors in domain switches and not within one domain, thus only out-of-domain utterances are considered. In this paper, we present results from a Wizard of Oz (WoZ) study on multi-domain interaction with an in-car SDS to evaluate the effects of outof-domain utterances on driver performance. We considered four different system reactions: successful domain switch, misunderstanding, nonunderstanding, and a dialog initiative switch. By analyzing them concerning driver distraction and usability, we are able to evaluate whether a dialog initiative switch is an appropriate response to an o</context>
<context position="14443" citStr="Bohus and Rudnicky (2005)" startWordPosition="2347" endWordPosition="2350"> SDS reacts as expected by the user and switches the domain. As the speech is recognized by a wizard, this is an optimal system without any errors. Miscommunication can be distinguished between misunderstanding and non-understanding (Skantze, 2007). In the MisUnderstanding (MU) condition, the SDS does not recognize the domain switch request and it responses in context of the current domain. On the contrary, in the Non-Understanding (NU) condition, it recognizes an out-of-domain utterance and refuses the action by apologizing and encouraging the user to rephrase his utterance (a combination of Bohus and Rudnicky (2005)’s Notify and AskRephrase error handling strategies). The only way to proceed with a MU or NU task in our experiment is to use an explicit domain switching command, such as “start radio application”. As we have shown in Reichel et al. (2014), participants do not use such commands naturally in a speech-only infotainment system and only use them after trying numerous unsuccessful utterances. Another approach is a Dialog Initiative Switch (DIS) to guide the user after recognizing an out-of-domain utterance (Notify and YouCanSay strategy (Bohus and Rudnicky, 2005)). Therefore, the SDS proposes a c</context>
</contexts>
<marker>Bohus, Rudnicky, 2005</marker>
<rawString>Dan Bohus and Alexander I. Rudnicky. 2005. Sorry, i didnt catch that! an investigation of nonunderstanding errors and recovery strategies. In Proceedings of SIGdial, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai-Uwe Carstensen</author>
<author>Christian Ebert</author>
<author>Cornelia Ebert</author>
<author>Susanne Jekat</author>
<author>Ralf Klabunde</author>
<author>Hagen Langer</author>
</authors>
<date>2010</date>
<booktitle>Computerlinguistik und Sprachtechnologie. Spektrum,</booktitle>
<location>Akad. Verl.</location>
<contexts>
<context position="13285" citStr="Carstensen et al., 2010" startWordPosition="2158" endWordPosition="2161">which semantic concepts a user input contains. Depending on the selection, either another concept is requested or the answer is provided. Within one subtask, the system always reacts as expected by the user. An answer for the presented example might look like: S: “There is one Italian restaurant: Pizzeria San Marco.” After this, the user has to initiate a domain switch to save the pizzeria’s address into his personal address book. Such user-initiated domain switches challenge current SDSs as language models increase and thus speech recognition as well as language understanding is error prone (Carstensen et al., 2010). Furthermore, the user could request a functionality which is not supported by the system. In case of such a request, SDSs react differently and could apply error recovery strategies if the error is recognized. To analyze the impact of error recovery strategies in the car, we use four different kinds of responses to domain switching requests. Figure 3 shows the study’s conditions. Detailed dialogs that corresponds to them can be found in the Appendix. First of all, we consider the Expected Reaction (ER) condition, in which the SDS reacts as expected by the user and switches the domain. As the</context>
</contexts>
<marker>Carstensen, Ebert, Ebert, Jekat, Klabunde, Langer, 2010</marker>
<rawString>Kai-Uwe Carstensen, Christian Ebert, Cornelia Ebert, Susanne Jekat, Ralf Klabunde, and Hagen Langer. 2010. Computerlinguistik und Sprachtechnologie. Spektrum, Akad. Verl.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Driver Focus-Telematics</author>
</authors>
<title>Working Group.</title>
<date>2006</date>
<marker>Focus-Telematics, 2006</marker>
<rawString>Driver Focus-Telematics Working Group. 2006. Statement of principles, criteria and verification procedures on driver interactions with advanced invehicle information and communication systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Ei-Wen Lo</author>
<author>Paul A Green</author>
</authors>
<title>Development and evaluation of automotive speech interfaces: Useful information from the human factors and the related literature.</title>
<date>2013</date>
<journal>Int. Journal of Vehicular Technology,</journal>
<pages>2013--13</pages>
<contexts>
<context position="4234" citStr="Lo and Green (2013)" startWordPosition="661" endWordPosition="664">pment of multidomain in-car SDSs. The remainder is structured as follows: Section 2 provides an overview of studies in this context. Section 3 describes the domain of the study which is shown in Section 4. Data analysis methods are defined in Section 5. We present and discuss the results in Section 6 and conclude in Section 7. 12 Proceedings of the SIGDIAL 2014 Conference, pages 12–21, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics 2 Related Work Driver distractions, due to secondary tasks, are evaluated in many studies (a good overview provides Ei-Wen Lo and Green (2013)). The driver’s performance is generally better when using speech interfaces than manual or visual interfaces, however, interacting with an SDS is often worse than just driving (Bar´on and Green, 2006). Most studies consider specific domains and do not evaluate how to handle domain switches. Kun et al. (2013) evaluated multi-threaded dialogs between humans while driving. By interrupting a dialog, they observed an increase of cognitive load, which affected the driving performance negatively. The participants were prepared that an interruption will be initiated at some time. This means they migh</context>
</contexts>
<marker>Lo, Green, 2013</marker>
<rawString>Victor Ei-Wen Lo and Paul A. Green. 2013. Development and evaluation of automotive speech interfaces: Useful information from the human factors and the related literature. Int. Journal of Vehicular Technology, 2013:13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman M Fraser</author>
<author>G Nigel Gilbert</author>
</authors>
<title>Simulating speech systems.</title>
<date>1991</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="7865" citStr="Fraser and Gilbert, 1991" startWordPosition="1253" endWordPosition="1256">n switch. In response to domain switching utterances four different system reactions were used (see Section 4.2.2). 4 User Experiment Developing an SDS includes specifying a grammar or training statistical language models for speech recognition. These steps precede any real user test. In system-initiated dialogs, with a few possible utterances, specifying a grammar is feasible. However, in strictly user-initiative dialogs covering multiple domains, this is rather complicated. A WoZ study does not require to develop speech recognition and language understanding as this is performed by a human (Fraser and Gilbert, 1991). In addition, the system reaction is controlled and not influenced by recognition errors. Our study requires such a controlled environment, as an unexpected system reaction, due to a recognition error, would influence the results negatively. Driver distraction and usability ratings vary among people and depend on age, personality, experience, context, and many more. Therefore, it is essential to conduct a user study with people who might use the SDS later on. A study by the NHTSA (National Highway Traffic Safety Administration (NHTSA), 2013) showed that 73% of the drivers involved in fatal cr</context>
<context position="9264" citStr="Fraser and Gilbert, 1991" startWordPosition="1491" endWordPosition="1494">ly to buy a car equipped with an infotainment system with Internet access. 13 4.1 Set-Up of the Experiment When designing a user interaction experiment, it is important that it takes place in a real environment. As driving on a real road is dangerous, we used a fixed-base driving simulator in a laboratory. A screen in front of the car covers the driver’s field of view (see Figure 1). Steering and pedal signals are picked from the car’s CAN bus. It is important that the user assumes he is interacting with a computer as “human-human interactions are not the same as human-computer interactions” (Fraser and Gilbert, 1991). The wizard, a person in charge of the experiment, was located behind the car and mouse clicks or any other interaction of the wizard was not audible in the car. To ensure a consistent behavior of the wizard, we used SUEDE (Klemmer et al., 2000) to define the dialog, which also provides an interface for the wizard. SUEDE defines a dialog in a state machine, in which the system prompts are states and user inputs are edges between them. The content of system prompts was synthesized with NUANCE Vocalizer Expressive1 version 1.2.1 (Voice: anna.full). During the experiment, the wizard clicks the c</context>
</contexts>
<marker>Fraser, Gilbert, 1991</marker>
<rawString>Norman M. Fraser and G.Nigel Gilbert. 1991. Simulating speech systems. Computer Speech &amp; Language, 5(1):81 – 99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kate S Hone</author>
<author>Robert Graham</author>
</authors>
<title>Towards a tool for the subjective assessment of speech system interfaces (sassi).</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<pages>6--3</pages>
<contexts>
<context position="16624" citStr="Hone and Graham, 2000" startWordPosition="2714" endWordPosition="2717">here is no explanation or example of the SDS, apart from a start command for activation. After the start command, the system plays a beep and the user can say whatever he likes to achieve his task. The exploration phase consists of four tasks, in which the system reacts as it is expected by the user. This enables the user to get used to the SDS while driving. In the second part of the experiment, one task for each condition was completed (ER, MU, NU, and DIS). The conditions were assigned randomly to a task and each one was rated by a Subjective Assessment of Speech System Interfaces (SASSI) (Hone and Graham, 2000) and Driver Activity Load Index (DALI) (Pauzi´e et al., 2007) questionnaire. At end of the experiment, each participant completed a second baseline drive without using the SDS to analyze whether the driving performance changed to the first baseline drive or not. Action (e.g. “add restaurant”) Execute Refuse Expected Reaction (ER) Misunderstanding (MU) Non-Understanding (NU) Dialog Initiative Switch (DIS) 15 After that, the four conditions were compared in a questionnaire. 5 Evaluation Metrics and Hypotheses The goal of this study is to evaluate four SDS response conditions concerning driver di</context>
</contexts>
<marker>Hone, Graham, 2000</marker>
<rawString>Kate S Hone and Robert Graham. 2000. Towards a tool for the subjective assessment of speech system interfaces (sassi). Natural Language Engineering, 6(3&amp;4):287–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>International Telecommunication Union</author>
</authors>
<title>Subjective quality evaluation of telephone services based on spoken dialogue systems (itu-t rec.</title>
<date>2003</date>
<pages>851</pages>
<marker>Union, 2003</marker>
<rawString>International Telecommunication Union (ITU). 2003. Subjective quality evaluation of telephone services based on spoken dialogue systems (itu-t rec. p.851).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott R Klemmer</author>
<author>Anoop K Sinha</author>
<author>Jack Chen</author>
<author>James A Landay</author>
<author>Nadeem Aboobaker</author>
<author>Annie Wang</author>
</authors>
<title>Suede: a wizard of oz prototyping tool for speech user interfaces.</title>
<date>2000</date>
<booktitle>In Proc. of the 13th annual ACM symposium on User interface software and technology,</booktitle>
<publisher>ACM.</publisher>
<location>New York.</location>
<contexts>
<context position="9510" citStr="Klemmer et al., 2000" startWordPosition="1539" endWordPosition="1542">, we used a fixed-base driving simulator in a laboratory. A screen in front of the car covers the driver’s field of view (see Figure 1). Steering and pedal signals are picked from the car’s CAN bus. It is important that the user assumes he is interacting with a computer as “human-human interactions are not the same as human-computer interactions” (Fraser and Gilbert, 1991). The wizard, a person in charge of the experiment, was located behind the car and mouse clicks or any other interaction of the wizard was not audible in the car. To ensure a consistent behavior of the wizard, we used SUEDE (Klemmer et al., 2000) to define the dialog, which also provides an interface for the wizard. SUEDE defines a dialog in a state machine, in which the system prompts are states and user inputs are edges between them. The content of system prompts was synthesized with NUANCE Vocalizer Expressive1 version 1.2.1 (Voice: anna.full). During the experiment, the wizard clicks the corresponding edge after each user input and SUEDE plays the next prompt. the car, as this would require additional human resources and it would increase the driver distraction (Young and Regan, 2007). 4.2.1 Primary Task: Driving Simulator One maj</context>
</contexts>
<marker>Klemmer, Sinha, Chen, Landay, Aboobaker, Wang, 2000</marker>
<rawString>Scott R. Klemmer, Anoop K. Sinha, Jack Chen, James A. Landay, Nadeem Aboobaker, and Annie Wang. 2000. Suede: a wizard of oz prototyping tool for speech user interfaces. In Proc. of the 13th annual ACM symposium on User interface software and technology, New York. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew L Kun</author>
<author>Tim Paek</author>
<author>Zeljko Medenica</author>
</authors>
<title>The effect of speech interface accuracy on driving performance.</title>
<date>2007</date>
<booktitle>In INTERSPEECH,</booktitle>
<pages>1326--1329</pages>
<location>Antwerp, Belgium.</location>
<contexts>
<context position="5099" citStr="Kun et al. (2007)" startWordPosition="796" endWordPosition="799"> not evaluate how to handle domain switches. Kun et al. (2013) evaluated multi-threaded dialogs between humans while driving. By interrupting a dialog, they observed an increase of cognitive load, which affected the driving performance negatively. The participants were prepared that an interruption will be initiated at some time. This means they might be surprised, however, it won’t be as unexpected as system reactions in response to out-of-domain utterances. In this work, we evaluate a dialog initiative switch, as a possible reaction to out-of-domain utterances. In a driving simulator study, Kun et al. (2007) showed that low SDS recognition accuracy affects the steering wheel angle variance negatively. This is first evidence that in-car SDSs need to handle speech recognition or language understanding errors intelligently. In preliminary work to this study, we analyzed a dataset containing dialog errors in relation to driving performance, measured by the lane change task (Mattes, 2003). This showed slight evidence that dialog errors, such as responses to out-of-domain utterances, have an influence on driving performance. However, the lane change task is not the right driving task for such a fine gr</context>
</contexts>
<marker>Kun, Paek, Medenica, 2007</marker>
<rawString>Andrew L. Kun, Tim Paek, and Zeljko Medenica. 2007. The effect of speech interface accuracy on driving performance. In INTERSPEECH, pages 1326–1329, Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeman</author>
</authors>
<title>Interactions between humanhuman multi-threaded dialogues and driving.</title>
<date>2013</date>
<booktitle>Personal and Ubiquitous Computing,</booktitle>
<pages>17--5</pages>
<marker>Heeman, 2013</marker>
<rawString>Andrew L. Kun, Alexander Shyrokov, and PeterA. Heeman. 2013. Interactions between humanhuman multi-threaded dialogues and driving. Personal and Ubiquitous Computing, 17(5):825–834.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jannette Maciej</author>
<author>Mark Vollrath</author>
</authors>
<title>Comparison of manual vs. speech-based interaction with invehicle information systems.</title>
<date>2009</date>
<journal>Accident Analysis and Prevention,</journal>
<volume>41</volume>
<issue>5</issue>
<pages>930</pages>
<contexts>
<context position="1765" citStr="Maciej and Vollrath, 2009" startWordPosition="266" endWordPosition="269">es is a success story. These devices allow people to access the Internet nearly anywhere at anytime. While driving, using a smartphone is prohibited in many countries as it distracts the driver. Regardless of this prohibition, people use their smartphone and cause severe injuries (National Highway Traffic Safety Administration (NHTSA), 2013). In order to reduce driver distraction, it is necessary to integrate the smartphones functionality safely into in-car infotainment systems. Since hands and eyes are involved in driving, a natural and intuitive speech-based interface increases road safety (Maciej and Vollrath, 2009). There are already infotainment systems with Internet applications like e.g. weather, music streaming, gas prices, news, and restaurant search. However, conversational spoken dialog systems (SDS) to control all these applications and the car’s functionality, are still missing. Current SDSs operate mostly in specific domains and they understand user utterances which are related to these domains. While using natural language, users are not restricted to specific domains. Thus one crucial problem for them is to know which utterances the system is able to understand. People use different approach</context>
</contexts>
<marker>Maciej, Vollrath, 2009</marker>
<rawString>Jannette Maciej and Mark Vollrath. 2009. Comparison of manual vs. speech-based interaction with invehicle information systems. Accident Analysis and Prevention, 41(5):924 – 930.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Mahr</author>
<author>Michael Feld</author>
<author>Mohammad Mehdi Moniri</author>
<author>Rafael Math</author>
</authors>
<title>The contre (continuous tracking and reaction) task: A flexible approach for assessing driver cognitive workload with high sensitivity.</title>
<date>2012</date>
<booktitle>In Adjunct Proceedings of the 4th AutomotiveUI,</booktitle>
<publisher>ACM.</publisher>
<location>Portsmouth.</location>
<contexts>
<context position="5926" citStr="Mahr et al., 2012" startWordPosition="928" endWordPosition="931">igently. In preliminary work to this study, we analyzed a dataset containing dialog errors in relation to driving performance, measured by the lane change task (Mattes, 2003). This showed slight evidence that dialog errors, such as responses to out-of-domain utterances, have an influence on driving performance. However, the lane change task is not the right driving task for such a fine granular analysis, as drivers are only occupied during a lane change and thus not constantly at the same level. Therefore, we analyze driving performance with the Continuous Tracking and Reaction (ConTRe) task (Mahr et al., 2012). 3 User Tasks In a user experiment it is crucial to set real tasks for users, since artificial tasks will be hard to remember and can reduce their attention. We analyzed current in-car infotainment systems with Internet access and derived eight multi-domain tasks from their functionality (see Table 1). Since only few natural use cases involve more than three domains, every user task is a story of three subtasks. In task number 5 for example, a user has to start a subtask, which navigates him to Berlin. Then he would like to search an Italian restaurant at the destination. Finally, he adds the</context>
<context position="10552" citStr="Mahr et al., 2012" startWordPosition="1708" endWordPosition="1711">t. the car, as this would require additional human resources and it would increase the driver distraction (Young and Regan, 2007). 4.2.1 Primary Task: Driving Simulator One major requirement for the driving simulator is to ensure a controlled and comparable driver distraction measure over all interaction variants and participants. The open-source driving simulator OpenDS provides a driving environment and extensive logging facilities (Math et al., 2012). As explained in Section 2, it is essential to keep the driver occupied at a constant level all the time. Therefore, we used the ConTRe task (Mahr et al., 2012), which consists of a continuous steering task and a reaction task. Figure 2 shows the ConTRe task with steering cylinders and a traffic light. The yellow steering cylinder moves unpredictably right and left at a constant distance from the driver. The driver has to steer the blue cylinder to superpose it with the middle section of the yellow one. This is similar to driving on a curved road. Sometimes a driver needs to react to sudden events to prevent an accident. A traffic light shows randomly red and green and requires the driver to push the throttle or brake pedal. As the car drives constan</context>
</contexts>
<marker>Mahr, Feld, Moniri, Math, 2012</marker>
<rawString>Angela Mahr, Michael Feld, Mohammad Mehdi Moniri, and Rafael Math. 2012. The contre (continuous tracking and reaction) task: A flexible approach for assessing driver cognitive workload with high sensitivity. In Adjunct Proceedings of the 4th AutomotiveUI, Portsmouth. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rafael Math</author>
<author>Angela Mahr</author>
<author>Mohammad M Moniri</author>
<author>Christian M¨uller</author>
</authors>
<title>Opends: A new opensource driving simulator for research.</title>
<date>2012</date>
<booktitle>Adjunct Proceedings of the 4th AutomotiveUI.</booktitle>
<marker>Math, Mahr, Moniri, M¨uller, 2012</marker>
<rawString>Rafael Math, Angela Mahr, Mohammad M Moniri, and Christian M¨uller. 2012. Opends: A new opensource driving simulator for research. Adjunct Proceedings of the 4th AutomotiveUI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Mattes</author>
</authors>
<title>The lane-change-task as a tool for driver distraction.</title>
<date>2003</date>
<booktitle>In Proceedings of IGfA,</booktitle>
<location>Dearborn.</location>
<contexts>
<context position="5482" citStr="Mattes, 2003" startWordPosition="858" endWordPosition="859">e as unexpected as system reactions in response to out-of-domain utterances. In this work, we evaluate a dialog initiative switch, as a possible reaction to out-of-domain utterances. In a driving simulator study, Kun et al. (2007) showed that low SDS recognition accuracy affects the steering wheel angle variance negatively. This is first evidence that in-car SDSs need to handle speech recognition or language understanding errors intelligently. In preliminary work to this study, we analyzed a dataset containing dialog errors in relation to driving performance, measured by the lane change task (Mattes, 2003). This showed slight evidence that dialog errors, such as responses to out-of-domain utterances, have an influence on driving performance. However, the lane change task is not the right driving task for such a fine granular analysis, as drivers are only occupied during a lane change and thus not constantly at the same level. Therefore, we analyze driving performance with the Continuous Tracking and Reaction (ConTRe) task (Mahr et al., 2012). 3 User Tasks In a user experiment it is crucial to set real tasks for users, since artificial tasks will be hard to remember and can reduce their attentio</context>
</contexts>
<marker>Mattes, 2003</marker>
<rawString>Stefan Mattes. 2003. The lane-change-task as a tool for driver distraction. In Proceedings of IGfA, Dearborn.</rawString>
</citation>
<citation valid="true">
<title>Traffic Safety Administration (NHTSA).</title>
<date>2013</date>
<tech>Technical report.</tech>
<institution>National Highway</institution>
<note>Distracted driving</note>
<contexts>
<context position="4234" citStr="(2013)" startWordPosition="664" endWordPosition="664">idomain in-car SDSs. The remainder is structured as follows: Section 2 provides an overview of studies in this context. Section 3 describes the domain of the study which is shown in Section 4. Data analysis methods are defined in Section 5. We present and discuss the results in Section 6 and conclude in Section 7. 12 Proceedings of the SIGDIAL 2014 Conference, pages 12–21, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics 2 Related Work Driver distractions, due to secondary tasks, are evaluated in many studies (a good overview provides Ei-Wen Lo and Green (2013)). The driver’s performance is generally better when using speech interfaces than manual or visual interfaces, however, interacting with an SDS is often worse than just driving (Bar´on and Green, 2006). Most studies consider specific domains and do not evaluate how to handle domain switches. Kun et al. (2013) evaluated multi-threaded dialogs between humans while driving. By interrupting a dialog, they observed an increase of cognitive load, which affected the driving performance negatively. The participants were prepared that an interruption will be initiated at some time. This means they migh</context>
</contexts>
<marker>2013</marker>
<rawString>National Highway Traffic Safety Administration (NHTSA). 2013. Distracted driving 2011. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher J D Patten</author>
<author>Albert Kircher</author>
<author>Joakim stlund</author>
<author>Lena Nilsson</author>
</authors>
<title>Using mobile telephones: cognitive workload and attention resource allocation.</title>
<date>2004</date>
<journal>Accident Analysis &amp; Prevention,</journal>
<volume>36</volume>
<issue>3</issue>
<pages>350</pages>
<contexts>
<context position="22188" citStr="Patten et al. (2004)" startWordPosition="3650" endWordPosition="3653">vels: p&lt;.05(*), p&lt;.01(**), p&lt;.001(***) ER Baseline MU_NU DIS Driver Activity Load Index -1 -2 -3 3 2 0 1 *** *** *** *** * * *** *** *** *** *** *** *** *** *** *** *** 6.1 SDS which Reacts as Expected (ER) First of all, results of an optimal SDS (ER), which reacts as expected and does not make any mistakes, are presented. The objective driver performance (see Figure 5) is slightly worse than the baseline drives in terms of steering and pressing the right pedals, but not significantly. However, reaction times are worse than without interacting with an SDS. This corresponds to the results from Patten et al. (2004), who observed an increase in reaction times when drivers talk to someone on the phone. The cognitive load (see Figure 6) caused by an optimal SDS is negative in all dimensions, which means an optimal SDS does not put high demands on the driver. In general, ER was rated very good in terms of usability (see Figure 4) and would most likely be accepted by young drivers. 6.2 Mis- and Non-Understanding (MU, NU) The results of MU and NU do not show significant differences in any dimension. Therefore, the mean value of MU and NU is used. As shown in Figure 6, the driver’s cognitive load is high in al</context>
</contexts>
<marker>Patten, Kircher, stlund, Nilsson, 2004</marker>
<rawString>Christopher J.D Patten, Albert Kircher, Joakim stlund, and Lena Nilsson. 2004. Using mobile telephones: cognitive workload and attention resource allocation. Accident Analysis &amp; Prevention, 36(3):341 – 350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Pauzi´e</author>
<author>J Manzan</author>
<author>Nicolas Dapzol</author>
</authors>
<title>Driver’s behavior and workload assessment for new in-vehicle technologies design.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Driving Symposium on Human Factors in Driver Assessment, Training, and Vehicle Design.,</booktitle>
<location>Stevenson, Washington.</location>
<marker>Pauzi´e, Manzan, Dapzol, 2007</marker>
<rawString>Annie Pauzi´e, J Manzan, and Nicolas Dapzol. 2007. Driver’s behavior and workload assessment for new in-vehicle technologies design. In Proceedings of the 4th International Driving Symposium on Human Factors in Driver Assessment, Training, and Vehicle Design., Stevenson, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven Reichel</author>
<author>Ute Ehrlich</author>
<author>Andr´e Berton</author>
<author>Michael Weber</author>
</authors>
<title>In-car multi-domain spoken dialogs: A wizard of oz study.</title>
<date>2014</date>
<booktitle>In EACL Workshop Dialog in Motion,</booktitle>
<location>Gothenburg,</location>
<contexts>
<context position="14684" citStr="Reichel et al. (2014)" startWordPosition="2390" endWordPosition="2393">07). In the MisUnderstanding (MU) condition, the SDS does not recognize the domain switch request and it responses in context of the current domain. On the contrary, in the Non-Understanding (NU) condition, it recognizes an out-of-domain utterance and refuses the action by apologizing and encouraging the user to rephrase his utterance (a combination of Bohus and Rudnicky (2005)’s Notify and AskRephrase error handling strategies). The only way to proceed with a MU or NU task in our experiment is to use an explicit domain switching command, such as “start radio application”. As we have shown in Reichel et al. (2014), participants do not use such commands naturally in a speech-only infotainment system and only use them after trying numerous unsuccessful utterances. Another approach is a Dialog Initiative Switch (DIS) to guide the user after recognizing an out-of-domain utterance (Notify and YouCanSay strategy (Bohus and Rudnicky, 2005)). Therefore, the SDS proposes a choice of four possible domains to interact with. Users have to select the first option which was followed by four possible actions within this domain. By selecting the desired action, the SDS reads out four examples of possible utterances. A</context>
</contexts>
<marker>Reichel, Ehrlich, Berton, Weber, 2014</marker>
<rawString>Sven Reichel, Ute Ehrlich, Andr´e Berton, and Michael Weber. 2014. In-car multi-domain spoken dialogs: A wizard of oz study. In EACL Workshop Dialog in Motion, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Skantze</author>
</authors>
<title>Error Handling in Spoken Dialogue Systems.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>KTH Computer Science and Communication.</institution>
<contexts>
<context position="14066" citStr="Skantze, 2007" startWordPosition="2290" endWordPosition="2291">overy strategies if the error is recognized. To analyze the impact of error recovery strategies in the car, we use four different kinds of responses to domain switching requests. Figure 3 shows the study’s conditions. Detailed dialogs that corresponds to them can be found in the Appendix. First of all, we consider the Expected Reaction (ER) condition, in which the SDS reacts as expected by the user and switches the domain. As the speech is recognized by a wizard, this is an optimal system without any errors. Miscommunication can be distinguished between misunderstanding and non-understanding (Skantze, 2007). In the MisUnderstanding (MU) condition, the SDS does not recognize the domain switch request and it responses in context of the current domain. On the contrary, in the Non-Understanding (NU) condition, it recognizes an out-of-domain utterance and refuses the action by apologizing and encouraging the user to rephrase his utterance (a combination of Bohus and Rudnicky (2005)’s Notify and AskRephrase error handling strategies). The only way to proceed with a MU or NU task in our experiment is to use an explicit domain switching command, such as “start radio application”. As we have shown in Rei</context>
</contexts>
<marker>Skantze, 2007</marker>
<rawString>Gabriel Skantze. 2007. Error Handling in Spoken Dialogue Systems. Ph.D. thesis, KTH Computer Science and Communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trent W Victor</author>
<author>Joanne L Harbluk</author>
<author>Johan A Engstrm</author>
</authors>
<title>Sensitivity of eye-movement measures to in-vehicle task difficulty. Transportation Research Part F: Traffic Psychology and Behaviour, 8(2):167 – 190. The relationship between distraction and driving performance: towards a test regime for in-vehicle information systems In-vehicle information systems.</title>
<date>2005</date>
<contexts>
<context position="28736" citStr="Victor et al. (2005)" startWordPosition="4771" endWordPosition="4774"> seconds”. As long as conversational SDSs are not able to operate in much wider domains, sooner or later the user will provide an utterance the system is not able to respond to. Comparing the MU and NU conditions shows that an out-of-domain recognition with a simple rephrase error recovery strategy does not work. This is understandable, as both conditions increase the cognitive load, which influences the driving performance negatively. Especially the reaction to external events, such as traffic lights, suffers. In our experiment, the traffic light was in the middle of the screen. According to Victor et al. (2005), drivers concentrate their gaze on the road center at the expense of peripheral glances during auditory or complex driving tasks. Thus we would expect even worse results if the traffic light occurs in the driver’s peripheral vision. This means an intelligent handling strategy for out-of-domain utterances needs to be established, which informs drivers of the system’s capabilities. We evaluated a dialog initiative switch as a response to out-of-domain utterances. Mostly, this strategy performed somewhere between the optimal and worst-case SDS. Due to long narrative system prompts, the auditive </context>
</contexts>
<marker>Victor, Harbluk, Engstrm, 2005</marker>
<rawString>Trent W. Victor, Joanne L. Harbluk, and Johan A. Engstrm. 2005. Sensitivity of eye-movement measures to in-vehicle task difficulty. Transportation Research Part F: Traffic Psychology and Behaviour, 8(2):167 – 190. The relationship between distraction and driving performance: towards a test regime for in-vehicle information systems In-vehicle information systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Wickens</author>
</authors>
<title>Multiple resources and mental workload. In Human factors,</title>
<date>2008</date>
<volume>50</volume>
<pages>449--55</pages>
<publisher>USA.</publisher>
<contexts>
<context position="11849" citStr="Wickens, 2008" startWordPosition="1931" endWordPosition="1932">ement of the yellow cylinder and the appearance of the traffic light can be controlled by manipulating OpenDS’ control variables. We used the “hard driving” condition as described by Mahr et al. (2012). Figure 1: Set-up of the experiment 4.2 Design of the Experiment Driving a car requires the driver to focus on the road and react appropriately to sudden events. However, if drivers are occupied with a secondary task, such as controlling an infotainment system, their attention to the road might suffer. This is due to the fact that the human’s performance is reduced when human resources overlap (Wickens, 2008). In this experiment, a dual task scenario is used by driving in a simulator and interacting with an SDS at the same time. There is no visual display in 1http://www.nuance.com/for-business/mobilesolutions/vocalizer-expressive/index.htm Figure 2: Continuous tracking and reaction task 4.2.2 Secondary Task: Responses to Domain Switching Requests A task in our experiment consists of three subtasks and each subtask requires two to four semantic concepts. For a user it is possible to insert multiple concepts at once: U: “Search an Italian restaurant at my destination” 14 or as single utterances in a</context>
</contexts>
<marker>Wickens, 2008</marker>
<rawString>Christopher D Wickens. 2008. Multiple resources and mental workload. In Human factors, volume 50, pages 449–55. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristie Young</author>
<author>Michael Regan</author>
</authors>
<title>Driver distraction: A review of the literature. Distracted Driving.</title>
<date>2007</date>
<contexts>
<context position="10063" citStr="Young and Regan, 2007" startWordPosition="1631" endWordPosition="1634">nsistent behavior of the wizard, we used SUEDE (Klemmer et al., 2000) to define the dialog, which also provides an interface for the wizard. SUEDE defines a dialog in a state machine, in which the system prompts are states and user inputs are edges between them. The content of system prompts was synthesized with NUANCE Vocalizer Expressive1 version 1.2.1 (Voice: anna.full). During the experiment, the wizard clicks the corresponding edge after each user input and SUEDE plays the next prompt. the car, as this would require additional human resources and it would increase the driver distraction (Young and Regan, 2007). 4.2.1 Primary Task: Driving Simulator One major requirement for the driving simulator is to ensure a controlled and comparable driver distraction measure over all interaction variants and participants. The open-source driving simulator OpenDS provides a driving environment and extensive logging facilities (Math et al., 2012). As explained in Section 2, it is essential to keep the driver occupied at a constant level all the time. Therefore, we used the ConTRe task (Mahr et al., 2012), which consists of a continuous steering task and a reaction task. Figure 2 shows the ConTRe task with steerin</context>
</contexts>
<marker>Young, Regan, 2007</marker>
<rawString>Kristie Young and Michael Regan. 2007. Driver distraction: A review of the literature. Distracted Driving.</rawString>
</citation>
<citation valid="false">
<authors>
<author>ER U Navigation S Navigation</author>
</authors>
<title>what do you want? U: City Berlin S: To what address or place of interest do you want? U: Brandenburger Tor S: Brandenburger Tor in Berlin was set as your destination U: Italian restaurant near Brandenburger Tor? S: There is one Italian restaurant in Berlin: Pizzeria San Marco U: Save the address S: Alright, the address was added DIS: U: I would like to go to the Brandenburger Tor in Berlin S: Brandenburger Tor in Berlin was set as your destination. U: Italian restaurant nearby?</title>
<marker>Navigation, </marker>
<rawString>ER: U: Navigation S: Navigation, what do you want? U: City Berlin S: To what address or place of interest do you want? U: Brandenburger Tor S: Brandenburger Tor in Berlin was set as your destination U: Italian restaurant near Brandenburger Tor? S: There is one Italian restaurant in Berlin: Pizzeria San Marco U: Save the address S: Alright, the address was added DIS: U: I would like to go to the Brandenburger Tor in Berlin S: Brandenburger Tor in Berlin was set as your destination. U: Italian restaurant nearby?</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>