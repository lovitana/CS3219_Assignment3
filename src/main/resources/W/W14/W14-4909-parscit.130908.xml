<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000124">
<title confidence="0.996299">
Annotating Uncertainty in Hungarian Webtext
</title>
<author confidence="0.994967">
Veronika Vincze1,2, Katalin Ilona Simk´o1, Viktor Varga1
</author>
<affiliation confidence="0.992949">
1University of Szeged
Department of Informatics
</affiliation>
<note confidence="0.457193">
2MTA-SZTE Research Group on Artificial Intelligence
</note>
<email confidence="0.9327685">
vinczev@inf.u-szeged.hu
{kata.simko,viktor.varga.1991}@gmail.com
</email>
<sectionHeader confidence="0.997339" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999353142857143">
Uncertainty detection has been a popular topic in natural language processing, which manifested
in the creation of several corpora for English. Here we show how the annotation guidelines origi-
nally developed for English standard texts can be adapted to Hungarian webtext. We annotated a
small corpus of Facebook posts for uncertainty phenomena and we illustrate the main character-
istics of such texts, with special regard to uncertainty annotation. Our results may be exploited
in adapting the guidelines to other languages or domains and later on, in the construction of
automatic uncertainty detectors.
</bodyText>
<sectionHeader confidence="0.993449" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.964877206896552">
Detecting uncertainty in natural language texts has received a considerable amount of attention in the
last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have
been created, which serve as training and test databases of state-of-the-art uncertainty detectors based
on supervised machine learning techniques. Most of these corpora are constructed for English, however,
their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008;
Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner
et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin,
2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze,
2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been
annotated for uncertainty, just to mention a few examples.
The diversity of the resources also manifests in the fact that the annotation principles behind the cor-
pora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three
corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic
uncertainty phenomena, on the basis of which these corpora were reannotated, using uniform guide-
lines. Some other uncertainty-related linguistic phenomena are described as discourse-level uncertainty
in Vincze (2013). As a first objective of our paper, we will carry out a pilot study and investigate how
these unified guidelines can be adapted to texts written in a language that is typologically different from
English, namely, Hungarian.
As a second goal, we will also focus on annotating texts in a new domain: social media texts –
apart from Wei et al. (2013) – have not been extensively investigated from the uncertainty detection
perspective. As the use and communication through the internet is becoming more and more important
in people’s lives, the huge amount of data available from this domain is a valuable source of information
for computation linguistics. However, processing texts from the web – especially social media texts from
blogs, status updates, chat logs and comments – revealed that they are very challenging for applications
trained on standard texts. Most studies in this area focus on English, for instance, sentiment analysis
from tweets has been the focus of recent challenges (Wilson et al., 2013) and Facebook posts have
been analysed from the perspective of computational psychology (Celli et al., 2013). A syntactically
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
</bodyText>
<page confidence="0.978199">
64
</page>
<note confidence="0.347133">
LAW VIII - The 8th Linguistic Annotation Workshop, pages 64–69,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.999150125">
annotated treebank of webtext has been also created for English (Bies et al., 2012). However, methods
developed for processing English webtext require serious alterations to be applicable to other languages,
for example Hungarian, which is very different from English syntactically and morphologically. Thus,
in our pilot study we will annotate Hungarian webtext for uncertainty and examine the possible effects
of the domain and the language on uncertainty detection.
In the following, we will present the uncertainty categories that were annotated in Hungarian webtext
and we will illustrate the difficulties of both annotating Hungarian webtext and annotating uncertainty
phenomena in them.
</bodyText>
<sectionHeader confidence="0.971248" genericHeader="introduction">
2 Uncertainty Categories
</sectionHeader>
<bodyText confidence="0.9999826">
Here we just briefly summarize uncertainty categories that we applied in the annotation, based on Szarvas
et al. (2012) and Vincze (2013).
Linguistic uncertainty is related to modality and the semantics of the sentence. For instance, the
sentence It may be raining does not contain enough information to determine whether it is really raining
(semantic uncertainty). There are several phenomena that are categorized as semantic uncertainty. A
proposition is epistemically uncertain if its truth value cannot be determined on the basis of world
knowledge. Conditionals and investigations also belong to this group – the latter is characteristic of
research papers, where research questions usually express this type of uncertainty. Non-epistemic types
of modality are also be listed here such as doxastic uncertainty, which is related to beliefs.
However, there are other linguistic phenomena that only become uncertain within the context of com-
munication. For instance, the sentence Many people think that Dublin is the best city in the world does
not reveal who exactly think that, hence the source of the proposition about Dublin remains uncertain.
This is a type of discourse-level uncertainty, more specifically, it is called weasel (Ganter and Strube,
2009). On the other hand, hedges make the meaning of words fuzzy: they blur the exact meaning of some
quality/quantity. Finally, peacock cues express unprovable evaluations, qualifications, understatements
and exaggerations.
The above categories proved to be applicable to Hungarian texts as well. However, the morpholog-
ically rich nature of Hungarian required some slight changes in the annotation process. For instance,
modal auxiliaries like may correspond to a derivational suffix in Hungarian, which required that in the
case of j¨ohet “may come” the whole word was annotated as uncertain, not just the suffix -het.
</bodyText>
<sectionHeader confidence="0.960036" genericHeader="method">
3 Annotating Hungarian Webtext
</sectionHeader>
<bodyText confidence="0.9999645">
Annotating uncertainty in webtexts comes with the usual difficulties of working with this domain. We
annotated Hungarian posts and comments from Facebook, which made the uncertainty annotation more
challenging than on standard texts. Texts were randomly selected from the public posts available at the
Facebook-sites of some well-known brands (like mobile companies, electronic devices, nutrition expert
companies etc.) and from the comments that users made on these posts. For our pilot annotation, we
used 1373 sentences and 18,327 tokens (as provided by magyarlanc, a linguistic preprocessing toolkit
developed for standard Hungarian texts (Zsibrita et al., 2013)).
One fundamental property of social media texts is their similarity to oral communication despite their
written form. The communication is online and multimodal; its speed causing a number of possibilities
for error. The quick typing makes typos, abbreviations and lack of capitalization, punctuation and accen-
tuated letters more common in these texts. Accentuated and unaccentuated vowels represent different
sounds in Hungarian that can change the meaning of words (kerek “round”, ker´ek “wheel” and k´erek “I
want”). Other types of linguistic creativity are also common, such as the use of emoticons and English
words and abbreviations in Hungarian texts. However, these attributes do not characterize social media
texts homogeneously. For instance, blog posts are closer to standard texts since they are usually written
by a PR expert from the side of the brand, who presumably spends more time with elaborating on the
text of the posts than an average user. On the other hand, comments and chat texts are closer to oral
communication because users here want to react as quickly as possible, making them harder to analyze.
</bodyText>
<page confidence="0.998229">
65
</page>
<bodyText confidence="0.999495333333333">
Our corpus of Facebook posts and comments exhibited a number of these properties. It contained
a lot of typos, abbreviations and letters that should have been accentuated. These sometimes caused
interpretation problems even for the human annotators; especially as these posts and comments were
annotated without broader context. Lack of capitalization and punctuation was more common in the
comment section of the corpus than in the posts. Emoticons were also frequent in both parts of the
corpus.
</bodyText>
<tableCaption confidence="0.308662">
Example 1: Typos in our corpus.
</tableCaption>
<bodyText confidence="0.842242">
ugya ilynem van csak fekete el˝ol es sz¨urke hcatcul – original
ugyanilyenem van csak fekete el¨ol ´es sz¨urke h´atul – standardized
(same.kind-POSS1SG have but black front and grey back)
“I have the same kind but its front is black and its back is grey.”
</bodyText>
<figure confidence="0.603132571428571">
Example 2: Abbreviation in our corpus.
Am´ugy meg sztem Nektek nem kellene a Saj´at oldalatokon magyar´azkodni! – original
Am´ugy meg szerintem Nektek nem kellene a saj´at oldalatokon magyar´azkodni! – standard-
ized
(by.the.way PART according.to-POSS1SG you-DAT not should the own site-POSS3PL-SUP
explain.yourselves-INF)
“By the way I think you should not be explaining yourselves on your own site.”
</figure>
<figureCaption confidence="0.467832">
Example 3: Lack of accentuation in our corpus.
</figureCaption>
<bodyText confidence="0.9551705">
es Marai Sandornak is ma van a szuletesnapja. – original
´es M´arai S´andornak is ma van a sz¨ulet´esnapja. – standardized
(and M´arai S´andor-GEN also today has the birthday-POSS3SG)
“And today is also M´arai S´andor’s birthday”
</bodyText>
<sectionHeader confidence="0.990599" genericHeader="method">
4 Uncertainty in Hungarian Webtext
</sectionHeader>
<bodyText confidence="0.964373789473684">
Apart from the above mentioned usual problems when dealing with webtext, other difficulties emerged
during their uncertainty annotation. Uncertainty is often related to opinions, but writers of these texts do
not usually express these as opinions, but as factual elements. Linguistic uncertainty is not annotated in
these cases, as these sentences do not hold uncertain meanings semantically, even if certain facts in them
are clearly not true or at least the writers obviously lack evidence to back them up.
Example 4: Information without evidence in our corpus.
´Uj megfigyeles, hogy az elektronok ´ugy viselkednek, mint az antioxid´ansok.
(new observation that the electrons that.way behave as the antioxidants)
“It is a new observation that electrons behave as antioxidants.”
The uncertainty annotation of this text differed greatly from our corpus of Hungarian Wikipedia arti-
cles and news (Vincze, 2014), which domains are much closer to standard language use. Table 1 shows
the distribution of the different types of uncertainty cues in these domains. Comparing this new subcorpus
with the other two shows certain domain specific characteristics. Unlike Facebook posts and comments,
the other two domains should not contain subjective opinions according to the objective nature of news
media and encyclopedias. This is consistent with the difference in the proportion of peacock cues in each
subcorpus: Facebook posts abound in them but their number is low in the other types of texts.
The relatively small number of hedges and epistemic uncertainty may be attributed to the previously
mentioned observation that the writers of these posts and comments often make confident statements,
even if these are not actual facts.
</bodyText>
<page confidence="0.978768">
66
</page>
<bodyText confidence="0.831977583333333">
The resemblance of Facebook posts and comments to oral communication also means that elements
that could also signify uncertainty can have different uses in this context. Certain phrases may indi-
cate politeness or other pragmatic functions that in a different domain would mean and be annotated as
linguistic uncertainty.
Example 5: The use of uncertain elements for politeness reasons in our corpus.
sajnos ´ugy t˝unik a fut´araink valami´ert val´oban nem ´erkeztek meg hozz´atok szombaton
(unfortunately that.way seems the carriers-POSS1PL something-CAU really not arrive-PAST-
3PL you-ALL Saturday-SUP)
“Unfortunately it seems like our carriers did not get to you on Saturday for some reason.”
The phrase ´ugy t˝unik “it seems” can express uncertainty in some contexts, but in the above example,
it is used as a marker of politeness, in order to apologize for and mitigate the inconvenience they caused
to their customers by not delivering some package in time.
</bodyText>
<table confidence="0.99971975">
Uncertainty cue Wikipedia News Webtext
# % # % # %
Weasel 1801 32.02 258 10.93 50 9.72
Hedge 2098 37.3 799 33.86 147 28.59
Peacock 787 14 94 3.98 192 37.35
Discourse-level total 4686 83.3 1151 48.77 389 75.6
Epistemic 439 7.8 358 15.16 21 4.08
Doxastic 315 5.6 710 30.08 44 8.56
Conditional 154 2.74 128 5.42 59 11.47
Investigation 31 0.55 13 0.55 1 0.19
Semantic total 939 16.69 1209 51.22 125 24.3
Total 5625 100 2360 100 514 100
</table>
<tableCaption confidence="0.999692">
Table 1: Uncertainty cues.
</tableCaption>
<sectionHeader confidence="0.996138" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999956375">
In this paper, we focused on annotating Hungarian Facebook posts and comments for uncertainty phe-
nomena. We adapted guidelines proposed for uncertainty annotation of standard English texts to Hun-
garian, and we also showed that this domain exhibit certain characteristics which are not present in other
domains that are more similar to standard language use. First, users usually express their opinions as
facts, thus relatively less markers of hedges or epistemic uncertainty occur in the corpus. Second, uncer-
tainty cue candidates can fulfill politeness functions, and apparently they do not signal uncertainty in
these contexts. Third, the characteristics of webtext may cause difficulties in annotation since in some
cases, the meaning of the text is vague due to typos or other errors.
Our pilot study of annotating Hungarian webtext for uncertainty leads us to conclude that the annota-
tion guidelines are mostly applicable to Hungarian as well and webtexts also exhibit the same uncertainty
categories as more standard texts, although the distribution of uncertainty categories differ among differ-
ent types of text. Besides, politeness factors should get more attention in this domain. Our results may be
employed in adapting annotation guidelines of uncertainty to other languages or domains as well. Later
on, we would like to extend our corpus and we would like to implement machine learning methods to
automatically detect uncertainty in Hungarian webtext, for which these findings will be most probably
fruitfully exploited.
</bodyText>
<sectionHeader confidence="0.989664" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<footnote confidence="0.499317">
This research was funded in part by the European Union and the European Social Fund through the
project FuturICT.hu (grant no.: T ´AMOP-4.2.2.C-11/1/KONV-2012-0013). Veronika Vincze was par-
</footnote>
<page confidence="0.999119">
67
</page>
<bodyText confidence="0.9999845">
tially funded by the National Excellence Program T ´AMOP-4.2.4.A/2-11/1-2012-0001 of the State of
Hungary, co-financed by the European Social Fund.
</bodyText>
<sectionHeader confidence="0.980394" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999435022222222">
Ann Bies, Justin Mott, Colin Warner, and Seth Kulick. 2012. English Web Treebank. Linguistic Data Consortium,
Philadelphia.
Fabio Celli, Fabio Pianesi, David Stilwell, and Michal Kosinski. 2013. Extracting evaluative conditions from
online reviews: Toward enhancing opinion mining. In Workshop on Computational Personality Recognition,
Boston, July.
Noa P. Cruz D´ıaz. 2013. Detecting negated and uncertain information in biomedical and review texts. In Proceed-
ings of the Student Research Workshop associated with RANLP 2013, pages 45–50, Hissar, Bulgaria, September.
RANLP 2013 Organising Committee.
Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-2010
Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the
Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1–
12, Uppsala, Sweden, July. Association for Computational Linguistics.
Viola Ganter and Michael Strube. 2009. Finding Hedges by Chasing Weasels: Hedge Detection Using Wikipedia
Tags and Shallow Linguistic Features. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,
pages 173–176, Suntec, Singapore, August. Association for Computational Linguistics.
Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. 2008. Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(Suppl 10).
Natalia Konstantinova, Sheila C.M. de Sousa, Noa P. Cruz, Manuel J. Mana, Maite Taboada, and Ruslan Mitkov.
2012. A review corpus annotated for negation, speculation and their scope. In Nicoletta Calzolari (Conference
Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mariani, Jan Odijk,
and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and
Evaluation (LREC’12), Istanbul, Turkey, may. European Language Resources Association (ELRA).
Ben Medlock and Ted Briscoe. 2007. Weakly Supervised Learning for Hedge Classification in Scientific Litera-
ture. In Proceedings of the ACL, pages 992–999, Prague, Czech Republic, June.
Roser Morante and Caroline Sporleder. 2012. Modality and negation: An introduction to the special issue.
Computational Linguistics, 38:223–260, June.
Raheel Nawaz, Paul Thompson, and Sophia Ananiadou. 2010. Evaluating a meta-knowledge annotation scheme
for bio-events. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,
pages 69–77, Uppsala, Sweden, July. University of Antwerp.
Victoria L. Rubin, Elizabeth D. Liddy, and Noriko Kando. 2005. Certainty identification in texts: Categorization
model and manual tagging results. In J.G. Shanahan, J. Qu, and J. Wiebe, editors, Computing attitude and affect
in text: Theory and applications (the information retrieval series), New York. Springer Verlag.
Victoria L. Rubin. 2010. Epistemic modality: From uncertainty to certainty in the context of information seeking
as interactions with texts. Information Processing &amp; Management, 46(5):533–540.
Roser Saur´ı and James Pustejovsky. 2009. FactBank: a corpus annotated with event factuality. Language
Resources and Evaluation, 43:227–268.
Burr Settles, Mark Craven, and Lewis Friedland. 2008. Active learning with real annotation costs. In Proceedings
of the NIPS Workshop on Cost-Sensitive Learning, pages 1–10.
Hagit Shatkay, Fengxia Pan, Andrey Rzhetsky, and W. John Wilbur. 2008. Multi-dimensional classification of
biomedical text: Toward automated, practical provision of high-utility text to diverse users. Bioinformatics,
24(18):2086–2093.
Gy¨orgy Szarvas, Veronika Vincze, Rich´ard Farkas, Gy¨orgy M´ora, and Iryna Gurevych. 2012. Cross-genre and
cross-domain detection of semantic uncertainty. Computational Linguistics, 38:335–367, June.
¨Ozlem Uzuner, Xiaoran Zhang, and Tawanda Sibanda. 2009. Machine Learning and Rule-based Approaches to
Assertion Classification. Journal of the American Medical Informatics Association, 16(1):109–115, January.
</reference>
<page confidence="0.988397">
68
</page>
<reference confidence="0.999483588235294">
Veronika Vincze, Gy¨orgy Szarvas, Rich´ard Farkas, Gy¨orgy M´ora, and J´anos Csirik. 2008. The BioScope Corpus:
Biomedical Texts Annotated for Uncertainty, Negation and their Scopes. BMC Bioinformatics, 9(Suppl 11):S9.
Veronika Vincze. 2013. Weasels, Hedges and Peacocks: Discourse-level Uncertainty in Wikipedia Articles.
In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 383–391,
Nagoya, Japan, October. Asian Federation of Natural Language Processing.
Veronika Vincze. 2014. Uncertainty detection in Hungarian texts. In Proceedings of Coling 2014.
Zhongyu Wei, Junwen Chen, Wei Gao, Binyang Li, Lanjun Zhou, Yulan He, and Kam-Fai Wong. 2013. An empir-
ical study on uncertainty identification in social media context. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Volume 2: Short Papers), pages 58–62, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara Rosenthal, Veselin Stoyanov, and Alan Ritter. 2013.
SemEval-2013 Task 2: Sentiment Analysis in Twitter. In Proceedings of the International Workshop on Seman-
tic Evaluation, SemEval ’13, June.
Theresa Ann Wilson. 2008. Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity,
and Attitudes of Private States. Ph.D. thesis, University of Pittsburgh, Pittsburgh.
J´anos Zsibrita, Veronika Vincze, and Rich´ard Farkas. 2013. magyarlanc: A Toolkit for Morphological and Depen-
dency Parsing of Hungarian. In Proceedings of RANLP-2013, pages 763–771, Hissar, Bulgaria.
</reference>
<page confidence="0.999318">
69
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002438">
<title confidence="0.998895">Annotating Uncertainty in Hungarian Webtext</title>
<author confidence="0.905893">Katalin Ilona Viktor</author>
<email confidence="0.375681">of</email>
<affiliation confidence="0.4738575">Department of Research Group on Artificial</affiliation>
<abstract confidence="0.986792616438356">Uncertainty detection has been a popular topic in natural language processing, which manifested in the creation of several corpora for English. Here we show how the annotation guidelines originally developed for English standard texts can be adapted to Hungarian webtext. We annotated a small corpus of Facebook posts for uncertainty phenomena and we illustrate the main characteristics of such texts, with special regard to uncertainty annotation. Our results may be exploited in adapting the guidelines to other languages or domains and later on, in the construction of automatic uncertainty detectors. 1 Background Detecting uncertainty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic uncertainty phenomena, on the basis of which these corpora were reannotated, using uniform guidelines. Some other uncertainty-related linguistic phenomena are described as discourse-level uncertainty in Vincze (2013). As a first objective of our paper, we will carry out a pilot study and investigate how these unified guidelines can be adapted to texts written in a language that is typologically different from English, namely, Hungarian. As a second goal, we will also focus on annotating texts in a new domain: social media texts – apart from Wei et al. (2013) – have not been extensively investigated from the uncertainty detection perspective. As the use and communication through the internet is becoming more and more important in people’s lives, the huge amount of data available from this domain is a valuable source of information for computation linguistics. However, processing texts from the web – especially social media texts from blogs, status updates, chat logs and comments – revealed that they are very challenging for applications trained on standard texts. Most studies in this area focus on English, for instance, sentiment analysis from tweets has been the focus of recent challenges (Wilson et al., 2013) and Facebook posts have been analysed from the perspective of computational psychology (Celli et al., 2013). A syntactically This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer added by the organizers. License details: 64 VIII - The 8th Linguistic Annotation pages Dublin, Ireland, August 23-24 2014. annotated treebank of webtext has been also created for English (Bies et al., 2012). However, methods developed for processing English webtext require serious alterations to be applicable to other languages, for example Hungarian, which is very different from English syntactically and morphologically. Thus, in our pilot study we will annotate Hungarian webtext for uncertainty and examine the possible effects of the domain and the language on uncertainty detection. In the following, we will present the uncertainty categories that were annotated in Hungarian webtext and we will illustrate the difficulties of both annotating Hungarian webtext and annotating uncertainty phenomena in them. 2 Uncertainty Categories Here we just briefly summarize uncertainty categories that we applied in the annotation, based on Szarvas et al. (2012) and Vincze (2013). Linguistic uncertainty is related to modality and the semantics of the sentence. For instance, the may be raining not contain enough information to determine whether it is really raining (semantic uncertainty). There are several phenomena that are categorized as semantic uncertainty. A is if its truth value cannot be determined on the basis of world belong to this group – the latter is characteristic of research papers, where research questions usually express this type of uncertainty. Non-epistemic types modality are also be listed here such as which is related to beliefs. However, there are other linguistic phenomena that only become uncertain within the context of com- For instance, the sentence people think that Dublin is the best city in the world not reveal who exactly think that, hence the source of the proposition about Dublin remains uncertain. is a type of discourse-level uncertainty, more specifically, it is called and Strube, On the other hand, the meaning of words fuzzy: they blur the exact meaning of some Finally, express unprovable evaluations, qualifications, understatements and exaggerations. The above categories proved to be applicable to Hungarian texts as well. However, the morphologically rich nature of Hungarian required some slight changes in the annotation process. For instance, auxiliaries like to a derivational suffix in Hungarian, which required that in the of come” the whole word was annotated as uncertain, not just the suffix 3 Annotating Hungarian Webtext Annotating uncertainty in webtexts comes with the usual difficulties of working with this domain. We annotated Hungarian posts and comments from Facebook, which made the uncertainty annotation more challenging than on standard texts. Texts were randomly selected from the public posts available at the Facebook-sites of some well-known brands (like mobile companies, electronic devices, nutrition expert companies etc.) and from the comments that users made on these posts. For our pilot annotation, we used 1373 sentences and 18,327 tokens (as provided by magyarlanc, a linguistic preprocessing toolkit developed for standard Hungarian texts (Zsibrita et al., 2013)). One fundamental property of social media texts is their similarity to oral communication despite their written form. The communication is online and multimodal; its speed causing a number of possibilities for error. The quick typing makes typos, abbreviations and lack of capitalization, punctuation and accentuated letters more common in these texts. Accentuated and unaccentuated vowels represent different in Hungarian that can change the meaning of words and want”). Other types of linguistic creativity are also common, such as the use of emoticons and English words and abbreviations in Hungarian texts. However, these attributes do not characterize social media texts homogeneously. For instance, blog posts are closer to standard texts since they are usually written by a PR expert from the side of the brand, who presumably spends more time with elaborating on the text of the posts than an average user. On the other hand, comments and chat texts are closer to oral communication because users here want to react as quickly as possible, making them harder to analyze. 65 Our corpus of Facebook posts and comments exhibited a number of these properties. It contained a lot of typos, abbreviations and letters that should have been accentuated. These sometimes caused interpretation problems even for the human annotators; especially as these posts and comments were annotated without broader context. Lack of capitalization and punctuation was more common in the comment section of the corpus than in the posts. Emoticons were also frequent in both parts of the corpus. Example 1: Typos in our corpus. ilynem csak fekete sz¨urke original csak fekete sz¨urke standardized (same.kind-POSS1SG have but black front and grey back) “I have the same kind but its front is black and its back is grey.” Example 2: Abbreviation in our corpus. meg nem kellene a Saj´at oldalatokon magyar´azkodni! original meg nem kellene a saj´at oldalatokon magyar´azkodni! – standardized (by.the.way PART according.to-POSS1SG you-DAT not should the own site-POSS3PL-SUP explain.yourselves-INF) “By the way I think you should not be explaining yourselves on your own site.” Example 3: Lack of accentuation in our corpus. Marai Sandornak is ma van a szuletesnapja. original ´es M´arai S´andornak is ma van a sz¨ulet´esnapja. – standardized (and M´arai S´andor-GEN also today has the birthday-POSS3SG) “And today is also M´arai S´andor’s birthday” 4 Uncertainty in Hungarian Webtext Apart from the above mentioned usual problems when dealing with webtext, other difficulties emerged during their uncertainty annotation. Uncertainty is often related to opinions, but writers of these texts do not usually express these as opinions, but as factual elements. Linguistic uncertainty is not annotated in these cases, as these sentences do not hold uncertain meanings semantically, even if certain facts in them are clearly not true or at least the writers obviously lack evidence to back them up. Example 4: Information without evidence in our corpus. ´Uj megfigyeles, hogy az elektronok ´ugy viselkednek, mint az antioxid´ansok. (new observation that the electrons that.way behave as the antioxidants) “It is a new observation that electrons behave as antioxidants.” The uncertainty annotation of this text differed greatly from our corpus of Hungarian Wikipedia articles and news (Vincze, 2014), which domains are much closer to standard language use. Table 1 shows the distribution of the different types of uncertainty cues in these domains. Comparing this new subcorpus with the other two shows certain domain specific characteristics. Unlike Facebook posts and comments, the other two domains should not contain subjective opinions according to the objective nature of news media and encyclopedias. This is consistent with the difference in the proportion of peacock cues in each subcorpus: Facebook posts abound in them but their number is low in the other types of texts. The relatively small number of hedges and epistemic uncertainty may be attributed to the previously mentioned observation that the writers of these posts and comments often make confident statements, even if these are not actual facts. 66 The resemblance of Facebook posts and comments to oral communication also means that elements that could also signify uncertainty can have different uses in this context. Certain phrases may indicate politeness or other pragmatic functions that in a different domain would mean and be annotated as linguistic uncertainty. Example 5: The use of uncertain elements for politeness reasons in our corpus. sajnos ´ugy t˝unik a fut´araink valami´ert val´oban nem ´erkeztek meg hozz´atok szombaton (unfortunately that.way seems the carriers-POSS1PL something-CAU really not arrive-PAST- 3PL you-ALL Saturday-SUP) “Unfortunately it seems like our carriers did not get to you on Saturday for some reason.” phrase t˝unik seems” can express uncertainty in some contexts, but in the above example, it is used as a marker of politeness, in order to apologize for and mitigate the inconvenience they caused to their customers by not delivering some package in time.</abstract>
<note confidence="0.7233">Uncertainty cue Wikipedia News Webtext Weasel 1801 32.02 258 10.93 50 9.72 Hedge 2098 37.3 799 33.86 147 28.59 Peacock 787 14 94 3.98 192 37.35 Discourse-level total 4686 83.3 1151 48.77 389 75.6 Epistemic 439 7.8 358 15.16 21 4.08 Doxastic 315 5.6 710 30.08 44 8.56 Conditional 154 2.74 128 5.42 59 11.47 Investigation 31 0.55 13 0.55 1 0.19 Semantic total 939 16.69 1209 51.22 125 24.3 Total 5625 100 2360 100 514 100 Table 1: Uncertainty cues. 5 Conclusions</note>
<abstract confidence="0.981564625">In this paper, we focused on annotating Hungarian Facebook posts and comments for uncertainty phenomena. We adapted guidelines proposed for uncertainty annotation of standard English texts to Hungarian, and we also showed that this domain exhibit certain characteristics which are not present in other domains that are more similar to standard language use. First, users usually express their opinions as facts, thus relatively less markers of hedges or epistemic uncertainty occur in the corpus. Second, uncertainty cue candidates can fulfill politeness functions, and apparently they do not signal uncertainty in these contexts. Third, the characteristics of webtext may cause difficulties in annotation since in some cases, the meaning of the text is vague due to typos or other errors. Our pilot study of annotating Hungarian webtext for uncertainty leads us to conclude that the annotation guidelines are mostly applicable to Hungarian as well and webtexts also exhibit the same uncertainty categories as more standard texts, although the distribution of uncertainty categories differ among different types of text. Besides, politeness factors should get more attention in this domain. Our results may be employed in adapting annotation guidelines of uncertainty to other languages or domains as well. Later on, we would like to extend our corpus and we would like to implement machine learning methods to automatically detect uncertainty in Hungarian webtext, for which these findings will be most probably fruitfully exploited.</abstract>
<note confidence="0.947987838709678">Acknowledgements This research was funded in part by the European Union and the European Social Fund through the FuturICT.hu (grant no.: T ´AMOP-4.2.2.C-11/1/KONV-2012-0013). Veronika Vincze was par- 67 tially funded by the National Excellence Program T ´AMOP-4.2.4.A/2-11/1-2012-0001 of the State of Hungary, co-financed by the European Social Fund. References Ann Bies, Justin Mott, Colin Warner, and Seth Kulick. 2012. English Web Treebank. Linguistic Data Consortium, Philadelphia. Fabio Celli, Fabio Pianesi, David Stilwell, and Michal Kosinski. 2013. Extracting evaluative conditions from reviews: Toward enhancing opinion mining. In on Computational Personality Boston, July. P. Cruz D´ıaz. 2013. Detecting negated and uncertain information in biomedical and review texts. In Proceedof the Student Research Workshop associated with RANLP pages 45–50, Hissar, Bulgaria, September. RANLP 2013 Organising Committee. Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-2010 Task: Learning to Detect Hedges and their Scope in Natural Language Text. In of the Conference on Computational Natural Language Learning (CoNLL-2010): Shared pages 1– 12, Uppsala, Sweden, July. Association for Computational Linguistics. Viola Ganter and Michael Strube. 2009. Finding Hedges by Chasing Weasels: Hedge Detection Using Wikipedia and Shallow Linguistic Features. In of the ACL-IJCNLP 2009 Conference Short pages 173–176, Suntec, Singapore, August. Association for Computational Linguistics. Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. 2008. Corpus annotation for mining biomedical events from 9(Suppl 10). Natalia Konstantinova, Sheila C.M. de Sousa, Noa P. Cruz, Manuel J. Mana, Maite Taboada, and Ruslan Mitkov. 2012. A review corpus annotated for negation, speculation and their scope. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, editors, of the Eight International Conference on Language Resources and Istanbul, Turkey, may. European Language Resources Association (ELRA). Ben Medlock and Ted Briscoe. 2007. Weakly Supervised Learning for Hedge Classification in Scientific Litera- In of the pages 992–999, Prague, Czech Republic, June.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Justin Mott</author>
<author>Colin Warner</author>
<author>Seth Kulick</author>
</authors>
<title>English Web Treebank. Linguistic Data Consortium,</title>
<date>2012</date>
<location>Philadelphia.</location>
<contexts>
<context position="3940" citStr="Bies et al., 2012" startWordPosition="582" endWordPosition="585">, sentiment analysis from tweets has been the focus of recent challenges (Wilson et al., 2013) and Facebook posts have been analysed from the perspective of computational psychology (Celli et al., 2013). A syntactically This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 64 LAW VIII - The 8th Linguistic Annotation Workshop, pages 64–69, Dublin, Ireland, August 23-24 2014. annotated treebank of webtext has been also created for English (Bies et al., 2012). However, methods developed for processing English webtext require serious alterations to be applicable to other languages, for example Hungarian, which is very different from English syntactically and morphologically. Thus, in our pilot study we will annotate Hungarian webtext for uncertainty and examine the possible effects of the domain and the language on uncertainty detection. In the following, we will present the uncertainty categories that were annotated in Hungarian webtext and we will illustrate the difficulties of both annotating Hungarian webtext and annotating uncertainty phenomen</context>
</contexts>
<marker>Bies, Mott, Warner, Kulick, 2012</marker>
<rawString>Ann Bies, Justin Mott, Colin Warner, and Seth Kulick. 2012. English Web Treebank. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Celli</author>
<author>Fabio Pianesi</author>
<author>David Stilwell</author>
<author>Michal Kosinski</author>
</authors>
<title>Extracting evaluative conditions from online reviews: Toward enhancing opinion mining.</title>
<date>2013</date>
<booktitle>In Workshop on Computational Personality Recognition,</booktitle>
<location>Boston,</location>
<contexts>
<context position="3524" citStr="Celli et al., 2013" startWordPosition="525" endWordPosition="528">nd more important in people’s lives, the huge amount of data available from this domain is a valuable source of information for computation linguistics. However, processing texts from the web – especially social media texts from blogs, status updates, chat logs and comments – revealed that they are very challenging for applications trained on standard texts. Most studies in this area focus on English, for instance, sentiment analysis from tweets has been the focus of recent challenges (Wilson et al., 2013) and Facebook posts have been analysed from the perspective of computational psychology (Celli et al., 2013). A syntactically This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 64 LAW VIII - The 8th Linguistic Annotation Workshop, pages 64–69, Dublin, Ireland, August 23-24 2014. annotated treebank of webtext has been also created for English (Bies et al., 2012). However, methods developed for processing English webtext require serious alterations to be applicable to other languages, for example Hungarian, which is very different from English</context>
</contexts>
<marker>Celli, Pianesi, Stilwell, Kosinski, 2013</marker>
<rawString>Fabio Celli, Fabio Pianesi, David Stilwell, and Michal Kosinski. 2013. Extracting evaluative conditions from online reviews: Toward enhancing opinion mining. In Workshop on Computational Personality Recognition, Boston, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noa P Cruz D´ıaz</author>
</authors>
<title>Detecting negated and uncertain information in biomedical and review texts.</title>
<date>2013</date>
<booktitle>In Proceedings of the Student Research Workshop associated with RANLP 2013,</booktitle>
<pages>45--50</pages>
<location>Hissar, Bulgaria,</location>
<marker>D´ıaz, 2013</marker>
<rawString>Noa P. Cruz D´ıaz. 2013. Detecting negated and uncertain information in biomedical and review texts. In Proceedings of the Student Research Workshop associated with RANLP 2013, pages 45–50, Hissar, Bulgaria, September. RANLP 2013 Organising Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1– 12,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1– 12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viola Ganter</author>
<author>Michael Strube</author>
</authors>
<title>Finding Hedges by Chasing Weasels: Hedge Detection Using Wikipedia Tags and Shallow Linguistic Features.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>173--176</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="1670" citStr="Ganter and Strube, 2009" startWordPosition="234" endWordPosition="237">eder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic uncertainty phenomena, on the basis of which these corpora were reannotated, using </context>
<context position="5838" citStr="Ganter and Strube, 2009" startWordPosition="864" endWordPosition="867">istic of research papers, where research questions usually express this type of uncertainty. Non-epistemic types of modality are also be listed here such as doxastic uncertainty, which is related to beliefs. However, there are other linguistic phenomena that only become uncertain within the context of communication. For instance, the sentence Many people think that Dublin is the best city in the world does not reveal who exactly think that, hence the source of the proposition about Dublin remains uncertain. This is a type of discourse-level uncertainty, more specifically, it is called weasel (Ganter and Strube, 2009). On the other hand, hedges make the meaning of words fuzzy: they blur the exact meaning of some quality/quantity. Finally, peacock cues express unprovable evaluations, qualifications, understatements and exaggerations. The above categories proved to be applicable to Hungarian texts as well. However, the morphologically rich nature of Hungarian required some slight changes in the annotation process. For instance, modal auxiliaries like may correspond to a derivational suffix in Hungarian, which required that in the case of j¨ohet “may come” the whole word was annotated as uncertain, not just t</context>
</contexts>
<marker>Ganter, Strube, 2009</marker>
<rawString>Viola Ganter and Michael Strube. 2009. Finding Hedges by Chasing Weasels: Hedge Detection Using Wikipedia Tags and Shallow Linguistic Features. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 173–176, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics, 9(Suppl</journal>
<volume>10</volume>
<contexts>
<context position="1407" citStr="Kim et al., 2008" startWordPosition="191" endWordPosition="194">nguages or domains and later on, in the construction of automatic uncertainty detectors. 1 Background Detecting uncertainty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly d</context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. 2008. Corpus annotation for mining biomedical events from literature. BMC Bioinformatics, 9(Suppl 10).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Natalia Konstantinova</author>
<author>Sheila C M de Sousa</author>
<author>Noa P Cruz</author>
<author>Manuel J Mana</author>
<author>Maite Taboada</author>
<author>Ruslan Mitkov</author>
</authors>
<title>A review corpus annotated for negation, speculation and their scope.</title>
<date>2012</date>
<booktitle>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors,</editor>
<location>Istanbul, Turkey,</location>
<marker>Konstantinova, de Sousa, Cruz, Mana, Taboada, Mitkov, 2012</marker>
<rawString>Natalia Konstantinova, Sheila C.M. de Sousa, Noa P. Cruz, Manuel J. Mana, Maite Taboada, and Ruslan Mitkov. 2012. A review corpus annotated for negation, speculation and their scope. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Medlock</author>
<author>Ted Briscoe</author>
</authors>
<title>Weakly Supervised Learning for Hedge Classification in Scientific Literature.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>992--999</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1389" citStr="Medlock and Briscoe, 2007" startWordPosition="187" endWordPosition="190"> the guidelines to other languages or domains and later on, in the construction of automatic uncertainty detectors. 1 Background Detecting uncertainty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpor</context>
</contexts>
<marker>Medlock, Briscoe, 2007</marker>
<rawString>Ben Medlock and Ted Briscoe. 2007. Weakly Supervised Learning for Hedge Classification in Scientific Literature. In Proceedings of the ACL, pages 992–999, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Caroline Sporleder</author>
</authors>
<title>Modality and negation: An introduction to the special issue.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<contexts>
<context position="1058" citStr="Morante and Sporleder, 2012" startWordPosition="142" endWordPosition="145">w how the annotation guidelines originally developed for English standard texts can be adapted to Hungarian webtext. We annotated a small corpus of Facebook posts for uncertainty phenomena and we illustrate the main characteristics of such texts, with special regard to uncertainty annotation. Our results may be exploited in adapting the guidelines to other languages or domains and later on, in the construction of automatic uncertainty detectors. 1 Background Detecting uncertainty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and </context>
</contexts>
<marker>Morante, Sporleder, 2012</marker>
<rawString>Roser Morante and Caroline Sporleder. 2012. Modality and negation: An introduction to the special issue. Computational Linguistics, 38:223–260, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raheel Nawaz</author>
<author>Paul Thompson</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Evaluating a meta-knowledge annotation scheme for bio-events.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,</booktitle>
<pages>69--77</pages>
<institution>University of Antwerp.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="1493" citStr="Nawaz et al., 2010" startWordPosition="207" endWordPosition="210">tors. 1 Background Detecting uncertainty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corp</context>
</contexts>
<marker>Nawaz, Thompson, Ananiadou, 2010</marker>
<rawString>Raheel Nawaz, Paul Thompson, and Sophia Ananiadou. 2010. Evaluating a meta-knowledge annotation scheme for bio-events. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 69–77, Uppsala, Sweden, July. University of Antwerp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria L Rubin</author>
<author>Elizabeth D Liddy</author>
<author>Noriko Kando</author>
</authors>
<title>Certainty identification in texts: Categorization model and manual tagging results.</title>
<date>2005</date>
<booktitle>Computing attitude and affect in text: Theory and applications (the information retrieval series),</booktitle>
<editor>In J.G. Shanahan, J. Qu, and J. Wiebe, editors,</editor>
<publisher>Springer Verlag.</publisher>
<location>New York.</location>
<contexts>
<context position="1611" citStr="Rubin et al., 2005" startWordPosition="226" endWordPosition="229">he last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic uncertainty phenomena, o</context>
</contexts>
<marker>Rubin, Liddy, Kando, 2005</marker>
<rawString>Victoria L. Rubin, Elizabeth D. Liddy, and Noriko Kando. 2005. Certainty identification in texts: Categorization model and manual tagging results. In J.G. Shanahan, J. Qu, and J. Wiebe, editors, Computing attitude and affect in text: Theory and applications (the information retrieval series), New York. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria L Rubin</author>
</authors>
<title>Epistemic modality: From uncertainty to certainty in the context of information seeking as interactions with texts.</title>
<date>2010</date>
<journal>Information Processing &amp; Management,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="1625" citStr="Rubin, 2010" startWordPosition="230" endWordPosition="231">as et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic uncertainty phenomena, on the basis of</context>
</contexts>
<marker>Rubin, 2010</marker>
<rawString>Victoria L. Rubin. 2010. Epistemic modality: From uncertainty to certainty in the context of information seeking as interactions with texts. Information Processing &amp; Management, 46(5):533–540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Saur´ı</author>
<author>James Pustejovsky</author>
</authors>
<title>FactBank: a corpus annotated with event factuality. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--227</pages>
<marker>Saur´ı, Pustejovsky, 2009</marker>
<rawString>Roser Saur´ı and James Pustejovsky. 2009. FactBank: a corpus annotated with event factuality. Language Resources and Evaluation, 43:227–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
<author>Mark Craven</author>
<author>Lewis Friedland</author>
</authors>
<title>Active learning with real annotation costs.</title>
<date>2008</date>
<booktitle>In Proceedings of the NIPS Workshop on Cost-Sensitive Learning,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="1429" citStr="Settles et al., 2008" startWordPosition="195" endWordPosition="198"> and later on, in the construction of automatic uncertainty detectors. 1 Background Detecting uncertainty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarv</context>
</contexts>
<marker>Settles, Craven, Friedland, 2008</marker>
<rawString>Burr Settles, Mark Craven, and Lewis Friedland. 2008. Active learning with real annotation costs. In Proceedings of the NIPS Workshop on Cost-Sensitive Learning, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagit Shatkay</author>
<author>Fengxia Pan</author>
<author>Andrey Rzhetsky</author>
<author>W John Wilbur</author>
</authors>
<title>Multi-dimensional classification of biomedical text: Toward automated, practical provision of high-utility text to diverse users.</title>
<date>2008</date>
<journal>Bioinformatics,</journal>
<volume>24</volume>
<issue>18</issue>
<contexts>
<context position="1451" citStr="Shatkay et al., 2008" startWordPosition="199" endWordPosition="202">construction of automatic uncertainty detectors. 1 Background Detecting uncertainty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to co</context>
</contexts>
<marker>Shatkay, Pan, Rzhetsky, Wilbur, 2008</marker>
<rawString>Hagit Shatkay, Fengxia Pan, Andrey Rzhetsky, and W. John Wilbur. 2008. Multi-dimensional classification of biomedical text: Toward automated, practical provision of high-utility text to diverse users. Bioinformatics, 24(18):2086–2093.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gy¨orgy Szarvas</author>
<author>Veronika Vincze</author>
<author>Rich´ard Farkas</author>
<author>Gy¨orgy M´ora</author>
<author>Iryna Gurevych</author>
</authors>
<title>Cross-genre and cross-domain detection of semantic uncertainty.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<pages>38--335</pages>
<marker>Szarvas, Vincze, Farkas, M´ora, Gurevych, 2012</marker>
<rawString>Gy¨orgy Szarvas, Veronika Vincze, Rich´ard Farkas, Gy¨orgy M´ora, and Iryna Gurevych. 2012. Cross-genre and cross-domain detection of semantic uncertainty. Computational Linguistics, 38:335–367, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>¨Ozlem Uzuner</author>
<author>Xiaoran Zhang</author>
<author>Tawanda Sibanda</author>
</authors>
<title>Machine Learning and Rule-based Approaches to Assertion Classification.</title>
<date>2009</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="1531" citStr="Uzuner et al., 2009" startWordPosition="213" endWordPosition="216">nty in natural language texts has received a considerable amount of attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel</context>
</contexts>
<marker>Uzuner, Zhang, Sibanda, 2009</marker>
<rawString>¨Ozlem Uzuner, Xiaoran Zhang, and Tawanda Sibanda. 2009. Machine Learning and Rule-based Approaches to Assertion Classification. Journal of the American Medical Informatics Association, 16(1):109–115, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gy¨orgy Szarvas</author>
<author>Rich´ard Farkas</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
</authors>
<title>The BioScope Corpus: Biomedical Texts Annotated for Uncertainty, Negation and their Scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<marker>Vincze, Szarvas, Farkas, M´ora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gy¨orgy Szarvas, Rich´ard Farkas, Gy¨orgy M´ora, and J´anos Csirik. 2008. The BioScope Corpus: Biomedical Texts Annotated for Uncertainty, Negation and their Scopes. BMC Bioinformatics, 9(Suppl 11):S9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
</authors>
<title>Weasels, Hedges and Peacocks: Discourse-level Uncertainty in Wikipedia Articles.</title>
<date>2013</date>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>383--391</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="1728" citStr="Vincze, 2013" startWordPosition="246" endWordPosition="247">hich serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic uncertainty phenomena, on the basis of which these corpora were reannotated, using uniform guidelines. Some other uncertainty-related linguis</context>
<context position="4713" citStr="Vincze (2013)" startWordPosition="695" endWordPosition="696">y different from English syntactically and morphologically. Thus, in our pilot study we will annotate Hungarian webtext for uncertainty and examine the possible effects of the domain and the language on uncertainty detection. In the following, we will present the uncertainty categories that were annotated in Hungarian webtext and we will illustrate the difficulties of both annotating Hungarian webtext and annotating uncertainty phenomena in them. 2 Uncertainty Categories Here we just briefly summarize uncertainty categories that we applied in the annotation, based on Szarvas et al. (2012) and Vincze (2013). Linguistic uncertainty is related to modality and the semantics of the sentence. For instance, the sentence It may be raining does not contain enough information to determine whether it is really raining (semantic uncertainty). There are several phenomena that are categorized as semantic uncertainty. A proposition is epistemically uncertain if its truth value cannot be determined on the basis of world knowledge. Conditionals and investigations also belong to this group – the latter is characteristic of research papers, where research questions usually express this type of uncertainty. Non-ep</context>
</contexts>
<marker>Vincze, 2013</marker>
<rawString>Veronika Vincze. 2013. Weasels, Hedges and Peacocks: Discourse-level Uncertainty in Wikipedia Articles. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 383–391, Nagoya, Japan, October. Asian Federation of Natural Language Processing. Veronika Vincze. 2014. Uncertainty detection in Hungarian texts. In Proceedings of Coling 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongyu Wei</author>
<author>Junwen Chen</author>
<author>Wei Gao</author>
<author>Binyang Li</author>
<author>Lanjun Zhou</author>
<author>Yulan He</author>
<author>Kam-Fai Wong</author>
</authors>
<title>An empirical study on uncertainty identification in social media context.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>58--62</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="1813" citStr="Wei et al., 2013" startWordPosition="258" endWordPosition="261">rs based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic uncertainty phenomena, on the basis of which these corpora were reannotated, using uniform guidelines. Some other uncertainty-related linguistic phenomena are described as discourse-level uncertainty in Vincze (2013). As a fir</context>
</contexts>
<marker>Wei, Chen, Gao, Li, Zhou, He, Wong, 2013</marker>
<rawString>Zhongyu Wei, Junwen Chen, Wei Gao, Binyang Li, Lanjun Zhou, Yulan He, and Kam-Fai Wong. 2013. An empirical study on uncertainty identification in social media context. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 58–62, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Zornitsa Kozareva</author>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Veselin Stoyanov</author>
<author>Alan Ritter</author>
</authors>
<title>SemEval-2013 Task 2: Sentiment Analysis in Twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13,</booktitle>
<contexts>
<context position="3416" citStr="Wilson et al., 2013" startWordPosition="509" endWordPosition="512">m the uncertainty detection perspective. As the use and communication through the internet is becoming more and more important in people’s lives, the huge amount of data available from this domain is a valuable source of information for computation linguistics. However, processing texts from the web – especially social media texts from blogs, status updates, chat logs and comments – revealed that they are very challenging for applications trained on standard texts. Most studies in this area focus on English, for instance, sentiment analysis from tweets has been the focus of recent challenges (Wilson et al., 2013) and Facebook posts have been analysed from the perspective of computational psychology (Celli et al., 2013). A syntactically This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 64 LAW VIII - The 8th Linguistic Annotation Workshop, pages 64–69, Dublin, Ireland, August 23-24 2014. annotated treebank of webtext has been also created for English (Bies et al., 2012). However, methods developed for processing English webtext require serious </context>
</contexts>
<marker>Wilson, Kozareva, Nakov, Rosenthal, Stoyanov, Ritter, 2013</marker>
<rawString>Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara Rosenthal, Veselin Stoyanov, and Alan Ritter. 2013. SemEval-2013 Task 2: Sentiment Analysis in Twitter. In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Ann Wilson</author>
</authors>
<title>Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity, and Attitudes of Private States.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pittsburgh,</institution>
<location>Pittsburgh.</location>
<contexts>
<context position="1591" citStr="Wilson, 2008" startWordPosition="224" endWordPosition="225">attention in the last decade (Farkas et al., 2010; Morante and Sporleder, 2012). Several manually annotated corpora have been created, which serve as training and test databases of state-of-the-art uncertainty detectors based on supervised machine learning techniques. Most of these corpora are constructed for English, however, their domains and genres are diverse: biological texts (Medlock and Briscoe, 2007; Kim et al., 2008; Settles et al., 2008; Shatkay et al., 2008; Vincze et al., 2008; Nawaz et al., 2010), clinical texts (Uzuner et al., 2009), pieces of news (Saur´ı and Pustejovsky, 2009; Wilson, 2008; Rubin et al., 2005; Rubin, 2010), encyclopedia texts (Ganter and Strube, 2009; Farkas et al., 2010; Szarvas et al., 2012; Vincze, 2013), reviews (Konstantinova et al., 2012; Cruz Diaz, 2013) and tweets (Wei et al., 2013) have been annotated for uncertainty, just to mention a few examples. The diversity of the resources also manifests in the fact that the annotation principles behind the corpora might slightly differ, which led Szarvas et al. (2012) to compare the annotation schemes of three corpora (BioScope, FactBank and WikiWeasel) and they offered a unified classification of semantic unce</context>
</contexts>
<marker>Wilson, 2008</marker>
<rawString>Theresa Ann Wilson. 2008. Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity, and Attitudes of Private States. Ph.D. thesis, University of Pittsburgh, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J´anos Zsibrita</author>
<author>Veronika Vincze</author>
<author>Rich´ard Farkas</author>
</authors>
<title>magyarlanc: A Toolkit for Morphological and Dependency Parsing of Hungarian.</title>
<date>2013</date>
<booktitle>In Proceedings of RANLP-2013,</booktitle>
<pages>763--771</pages>
<location>Hissar, Bulgaria.</location>
<contexts>
<context position="7151" citStr="Zsibrita et al., 2013" startWordPosition="1056" endWordPosition="1059">h the usual difficulties of working with this domain. We annotated Hungarian posts and comments from Facebook, which made the uncertainty annotation more challenging than on standard texts. Texts were randomly selected from the public posts available at the Facebook-sites of some well-known brands (like mobile companies, electronic devices, nutrition expert companies etc.) and from the comments that users made on these posts. For our pilot annotation, we used 1373 sentences and 18,327 tokens (as provided by magyarlanc, a linguistic preprocessing toolkit developed for standard Hungarian texts (Zsibrita et al., 2013)). One fundamental property of social media texts is their similarity to oral communication despite their written form. The communication is online and multimodal; its speed causing a number of possibilities for error. The quick typing makes typos, abbreviations and lack of capitalization, punctuation and accentuated letters more common in these texts. Accentuated and unaccentuated vowels represent different sounds in Hungarian that can change the meaning of words (kerek “round”, ker´ek “wheel” and k´erek “I want”). Other types of linguistic creativity are also common, such as the use of emoti</context>
</contexts>
<marker>Zsibrita, Vincze, Farkas, 2013</marker>
<rawString>J´anos Zsibrita, Veronika Vincze, and Rich´ard Farkas. 2013. magyarlanc: A Toolkit for Morphological and Dependency Parsing of Hungarian. In Proceedings of RANLP-2013, pages 763–771, Hissar, Bulgaria.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>