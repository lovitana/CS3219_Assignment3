<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000149">
<title confidence="0.995017">
Domain and Dialect Adaptation
for Machine Translation into Egyptian Arabic
</title>
<author confidence="0.993109">
Serena Jeblee&apos; , Weston Feely&apos; , Houda Bouamor2
Alon Lavie&apos;, Nizar Habash3 and Kemal Oflazer2
</author>
<affiliation confidence="0.974521">
&apos;Carnegie Mellon University
</affiliation>
<email confidence="0.936959">
{sjeblee, wfeely, alavie}@cs.cmu.edu
</email>
<affiliation confidence="0.441479">
2Carnegie Mellon University in Qatar
</affiliation>
<email confidence="0.982798">
hbouamor@qatar.cmu.edu, ko@cs.cmu.edu
</email>
<affiliation confidence="0.367224">
3New York University Abu Dhabi
</affiliation>
<email confidence="0.998089">
nizar.habash@nyu.edu
</email>
<sectionHeader confidence="0.993877" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999742714285714">
In this paper, we present a statistical ma-
chine translation system for English to Di-
alectal Arabic (DA), using Modern Stan-
dard Arabic (MSA) as a pivot. We cre-
ate a core system to translate from En-
glish to MSA using a large bilingual par-
allel corpus. Then, we design two separate
pathways for translation from MSA into
DA: a two-step domain and dialect adap-
tation system and a one-step simultane-
ous domain and dialect adaptation system.
Both variants of the adaptation systems are
trained on a 100k sentence tri-parallel cor-
pus of English, MSA, and Egyptian Arabic
generated by a rule-based transformation.
We test our systems on a held-out Egyp-
tian Arabic test set from the 100k sen-
tence corpus and we achieve our best per-
formance using the two-step domain and
dialect adaptation system with a BLEU
score of 42.9.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997630288461538">
While MSA is the shared official language of cul-
ture, media and education in the Arab world, it is
not the native language of any speakers of Ara-
bic. Most native speakers are unable to produce
sustained spontaneous discourse in MSA - they
usually resort to repeated code-switching between
their dialect and MSA (Abu-Melhim, 1991). Ara-
bic speakers are quite aware of the contextual fac-
tors and the differences between their dialects and
MSA, although they may not always be able to
pinpoint exact linguistic differences. In the con-
text of natural language processing (NLP), some
Arabic dialects have started receiving increas-
ing attention, particularly in the context of ma-
chine translation (Zbib et al., 2012; Salloum and
Habash, 2013; Salloum et al., 2014; Al-Mannai
et al., 2014) and in terms of data collection (Cot-
terell and Callison-Burch, 2014; Bouamor et al.,
2014; Salama et al., 2014) and basic enabling
technologies (Habash et al., 2012; Pasha et al.,
2014). However, the focus is on a small number
of iconic dialects, (e.g., Egyptian). The Egyptian
media industry has traditionally played a dominant
role in the Arab world, making the Egyptian di-
alect the most widely understood and used dialect.
DA is now emerging as the language of informal
communication online. DA differs phonologically,
lexically, morphologically, and syntactically from
MSA. And while MSA has an established stan-
dard orthography, the dialects do not: people write
words reflecting their phonology and sometimes
use roman script. Thus, MSA tools cannot ef-
fectively model DA; for instance, over one-third
of Levantine verbs cannot be analyzed using an
MSA morphological analyzer (Habash and Ram-
bow, 2006). These differences make the direct use
of MSA NLP tools and applications for handling
dialects impractical.
In this work, we design an MT system for En-
glish to Egyptian Arabic translation by using MSA
as an intermediary step. This includes different
challenges from those faced when translating into
English. Because MSA is the formal written va-
riety of Arabic, there is an abundance of written
data, including parallel corpora from sources like
the United Nations and newspapers, as well as var-
ious treebanks. Using these resources, many re-
searchers have created fairly reliable MSA trans-
lation systems. However, these systems are not
designed to deal with the other Arabic variants.
Egyptian Arabic is much closer to MSA than
it is to English, so one can get a system bet-
</bodyText>
<page confidence="0.982037">
196
</page>
<note confidence="0.8884005">
Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 196–206,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.998960384615385">
ter performance by translating first into MSA and
then translating from MSA to Egyptian Arabic,
which are far more similar. Our approach consists
of a core MT system trained on a large amount
of out-of-domain English-MSA parallel data, fol-
lowed by an adaptation system. We design and im-
plement two adaptation systems: a two-step sys-
tem first adapts to in-domain MSA and then sep-
arately adapts from MSA to Egyptian Arabic, and
a one-step system that adapts directly from out-of-
domain MSA to in-domain Egyptian Arabic.
Our research contributions are summarized as
follows:
</bodyText>
<listItem confidence="0.968318166666667">
(a) We build a machine translation system to
translate into, rather than out of, dialectal Ara-
bic (from English), using MSA as a pivot
point.
(b) We apply a domain adaptation technique to
improve the MSA results on our in-domain
dataset.
(c) We automatically generate the Egyptian side
of a 100k tri-parallel corpus covering MSA,
English and Egyptian.
(d) We use this domain adaptation technique to
adapt MSA into dialectal Arabic.
</listItem>
<bodyText confidence="0.999969833333333">
The remainder of this paper is structured as fol-
lows. We first review the main previous efforts
for dealing with DA in NLP, in Section 2. In Sec-
tion 3,we give a general description about using
phrase-based MT as an adaptation system. Sec-
tion 4 presents the dataset used in the different ex-
periments. Our approach for translating English
text into Egyptian Arabic is explained in Section 5.
Section 6 presents our experimental setup and the
results obtained. Then, we give an analysis of our
system output in Section 7. Finally, we conclude
and describe our future work in Section 8.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999797666666667">
Machine translation (MT) for dialectal Arabic
(DA) is quite challenging given the limited re-
sources to build rule-based models or train statis-
tical models for MT. While there has been a con-
siderable amount of work in the context of stan-
dard Arabic NLP (Habash, 2010), DA is impov-
erished in terms of available tools and resources
compared to MSA, e.g., there are few parallel DA-
English corpora (Zbib et al., 2012; Bouamor et
al., 2014). The majority of DA resources are for
speech recognition, although more and more re-
sources for machine translation and enabling tech-
nologies such as morphological analyzers are be-
coming available for specific dialects (Habash et
al., 2012; Habash et al., 2013).
For Arabic and its dialects, several researchers
have explored the idea of exploiting existing MSA
rich resources to build tools for DA NLP. Differ-
ent research work successfully translated DA to
MSA as a bridge to translate to English (Sawaf,
2010; Salloum and Habash, 2013), or to enhance
the performance of Arabic-based information re-
trieval systems (Shatnawi et al., 2012). Among the
efforts on translation from DA to MSA, Abo Bakr
et al. (2008) introduced a hybrid approach to trans-
fer a sentence from Egyptian Arabic to MSA.
Sajjad et al. (2013) used a dictionary of Egyp-
tian/MSA words to transform Egyptian to MSA
and showed improvement in the quality of ma-
chine translation. A similar but rule-based work
was done by Mohamed et al. (2012). Boujel-
bane et al. (2013) and Hamdi et al. (2014) built
a bilingual dictionary using explicit knowledge
about the relation between Tunisian Arabic and
MSA. These works are limited to a dictionary or
rules that are not available for all dialects. Zbib
et al. (2012) used crowdsourcing to translate sen-
tences from Egyptian and Levantine into English,
and thus built two bilingual corpora. The dialec-
tal sentences were selected from a large corpus
of Arabic web text. Then, they explored several
methods for dialect/English MT. Their best Egyp-
tian/English system was trained on dialect/English
parallel data. They argued that differences in genre
between MSA and DA make bridging through
MSA of limited value. For this reason, while piv-
oting through MSA, it is important to consider the
domain and add an additional step: domain adap-
tation.
The majority of previous efforts in DA MT has
been focusing on translating from dialectal Arabic
into other languages (mainly MSA or English). In
contrast, in this work we focus on building a sys-
tem to translate from English and MSA into DA.
Furthermore, to the best of our knowledge, this is
the first work in which we adapt the domain in ad-
dition to the dialect (Egyptian specifically).
</bodyText>
<sectionHeader confidence="0.936884" genericHeader="method">
3 Using Phrase-Based MT as an
Adaptation System
</sectionHeader>
<bodyText confidence="0.99027375">
For commercial use, MT output is usually post-
edited by a human translator in order to fix the er-
rors generated by the MT system. This is often
faster and cheaper than having a human translate
</bodyText>
<page confidence="0.99708">
197
</page>
<bodyText confidence="0.999899720930232">
the document from scratch. However, we can ap-
ply statistical phrase-based MT to create an auto-
matic machine post-editor (what we refer to in this
paper as an adaptation system) to improve the out-
put of an MT system, and make it more closely
resemble the references. Simard et al. (2007) used
a phrase-based MT system as an automatic post-
editor for the output of a commercial rule-based
MT system, showing that it produced better results
than both the rule-based system alone and a sin-
gle pass phrase-based MT system. This technique
is also useful for adapting to a specific domain or
dataset. Isabelle et al. (2007) used a statistical MT
system to automatically post-edit the output of a
generic rule-based MT system, to avoid manually
customizing a system dictionary and to reduce the
amount of manual post-editing required.
For our adaptation systems, we build a core
phrase-based MT system with a large amount of
out-of-domain data, which allows us to have better
coverage of the target language. For an adaptation
system, we then build a second phrase-based MT
system by translating the in-domain train, tune,
and test sets through the core translation system,
then using that data to build the second system.
This system uses only in-domain data: parallel
MT output from the core and the references. In
this system, instead of learning to translate one
language into another, the model learns to trans-
late erroneous MT output into more fluent output
of the same language, which more closely resem-
bles the references.
In this work, we apply this technique for
domain and dialect adaptation, treating Egyp-
tian Arabic as the target language, and the MT-
generated MSA as the erroneous MT output. We
use this approach to adapt to the domain of the
MSA data, and also to adapt to the Egyptian di-
alect. What we refer to as the “one-step” system is
a core system plus one adaptation system, whereas
the “two-step” system consists of the core plus two
subsequent adaptation systems. We describe the
systems in more detail in Section 5.
</bodyText>
<sectionHeader confidence="0.997809" genericHeader="method">
4 Data
</sectionHeader>
<bodyText confidence="0.9999518">
For the core English to MSA system, we use
the 5 million parallel sentences of English and
MSA from NIST 2012 as the training set. The
tuning set consists of 1,356 sentences from the
NIST 2008 Open Machine Translation Evalua-
tion (MT08) data (NIST Multimodal Information
Group, 2010a), and the test set consists of 1,313
sentences from NIST MT09 (NIST Multimodal
Information Group, 2010b).
We use a 5-gram MSA language model built
using the SRILM toolkit (Stolcke, 2002) on 260
million words of MSA from the Arabic Gigaword
(Parker et al., 2011). All our MSA parallel data
and monolingual MSA language modeling data
were tokenized with MADA v3.1 (Habash and
Rambow, 2005) using the ATB (Arabic Treebank)
tokenization scheme.
For the adaptation systems, we build a 100k
tri-parallel corpus Egyptian-MSA-English corpus.
The MSA and English parts are extracted from
the NIST corpus distributed by the Linguistic Data
Consortium. The Egyptian sentences are obtained
automatically by extending Mohamed et al. (2012)
method for generating Egyptian Arabic from mor-
phologically disambiguated MSA sentences. This
rule-based method relies on 103 transformation
rules covering essentially nouns, verbs and pro-
nouns as well as certain lexical items. For each
MSA sentence, this method provides more than
one possible candidate, in its original version, the
Egyptian sentence kept was chosen randomly. We
extend the selection algorithm by scoring the dif-
ferent sentences using a language model. For
this, we use SRILM with modified Kneser-Ney
smoothing to build a 5-gram language model. The
model is trained on a corpus including articles ex-
tracted from the Egyptian version of Wikipedia1
and the Egyptian side of the AOC corpus (Zaidan
and Callison-Burch, 2011). We chose to include
Egyptian Wikipedia for the formal level of sen-
tences in it different from the regular DA written
in blogs or microblogging websites (e.g., Twitter)
and closer to the ones generated by our system.
We split this data into train, tune, and test sets
of 98,027, 960, and 961 sentences respectively,
after removing duplicates across sets. The MSA
corpus was tokenized using MADA and the Egyp-
tian Arabic data was tokenized with MADA-ARZ
v0.4 (Habash et al., 2013), both using the ATB to-
kenization scheme, with alif/ya normalization.
</bodyText>
<sectionHeader confidence="0.981928" genericHeader="method">
5 System Design
</sectionHeader>
<bodyText confidence="0.9298228">
Figure 1 shows a diagram of our three English to
Egyptian Arabic MT systems: (1) the baseline MT
system, (2) the one-step adaptation MT system,
and (3) the two-step adaptation MT system. We
describe each system below.
</bodyText>
<footnote confidence="0.986104">
1http://arz.wikipedia.org/
</footnote>
<page confidence="0.98171">
198
</page>
<figure confidence="0.577228">
Baseline MT System
</figure>
<figureCaption confidence="0.995999">
Figure 1: An overview of the different system architectures.
</figureCaption>
<figure confidence="0.9996206">
100K sent.
5M sent.
MSA
Translation
Domain &amp;
Dialect
Adaptation
One-Step Adaptation MT System
English
Egyptian
Arabic
100K sent. 100K sent.
Dialect
Adaptation
Egyptian
Arabic
In-domain
MSA
Domain
Adaptation
Two-Step Adaptation MT System
English
5M sent.
Translation
MSA
English
100K sent.
Translation
Egyptian
Arabic
</figure>
<subsectionHeader confidence="0.55714">
Baseline System
</subsectionHeader>
<bodyText confidence="0.999484444444444">
Our baseline system is a single phrase-based En-
glish to Egyptian Arabic MT system, built using
Moses (Koehn et al., 2007) on the 100k corpus de-
scribed in Section 4. This system does not include
any MSA data, nor does it have an adaptation sys-
tem; it is a typical, one-pass MT system that trans-
lates English directly into Egyptian Arabic. We
will show that using adaptation systems improves
the results significantly.
</bodyText>
<subsectionHeader confidence="0.823638">
Core System
</subsectionHeader>
<bodyText confidence="0.9999708">
We base our systems on a core system built us-
ing Moses with the NIST data, a large amount of
parallel English-MSA data from different sources
than our in-domain data (the 100k dataset). Our
core system is also built using Moses. We use
this core system to translate the English side of our
100k train, tune, and test sets into MSA, the output
of which we refer to as MSA’. This MSA’ data is
what we use as the source side for the adaptation
systems.
</bodyText>
<subsectionHeader confidence="0.989129">
One-Step Adaptation System
</subsectionHeader>
<bodyText confidence="0.9999867">
To adapt to the domain and dialect of the 100k cor-
pus, we first build a single adaptation system that
translates the MSA’ output of the core directly into
Egyptian Arabic using the 100k corpus. The train-
ing data consists of parallel MSA’ (the output of
the core) and the Egyptian Arabic from the 100k
dataset. With this system, we can take an English
test set, translate it through the core to get MSA’
output, which we can translate through the adap-
tation system to get Egyptian Arabic.
</bodyText>
<subsectionHeader confidence="0.973175">
Two-Step Adaptation System
</subsectionHeader>
<bodyText confidence="0.999984416666667">
We also build a two-step adaptation system that
consists of two adaptation steps: one to adapt the
MSA output of the core system to the domain of
the MSA in the 100k corpus, and a second system
to translate the MSA output of the domain adap-
tation system into Egyptian Arabic. We use the
first adaptation system to translate the MSA’ train,
tune, and test sets (the output of the core, which is
out-of-domain MSA), into in-domain MSA. This
system is trained on the MSA’ output parallel with
the MSA references from the 100k dataset. We
refer to the output of this system as MSA”, be-
cause it has been translated from English into out-
of-domain MSA (MSA’), and then from out-of-
domain MSA to in-domain MSA.
The first adaptation system is used to translate
the MSA’ train, tune, and test sets into MSA”.
Then we use these MSA” sets with their parallel
Egyptian Arabic from the 100k dataset to build the
second adaptation system from in-domain MSA to
Egyptian Arabic. We do not use the dialect trans-
formation from (Mohamed et al., 2012) because it
is designed to work with gold-standard annotation
of the MSA text, which we do not have.
</bodyText>
<subsectionHeader confidence="0.922321">
System Variants
</subsectionHeader>
<bodyText confidence="0.999584428571429">
Since MSA and Egyptian are more similar to each
other than they are to English, we tried several dif-
ferent reordering window sizes to find the optimal
reordering distance for adapting MSA to Egyptian
Arabic, including the typical reordering window
of length 7, a smaller window of length 4, and no
reordering at all. We found a reordering window
</bodyText>
<page confidence="0.995354">
199
</page>
<bodyText confidence="0.995288176470588">
size of 7 to work best for all our systems, except
for the one-step adaptation system, where no re-
ordering produced the best result.
We also tested two different heuristics for sym-
metrizing the word alignments: grow-diag and
grow-diag-final-and (Och and Ney, 2003). We
found that using grow-diag as our symmetriza-
tion heuristic produced slightly better scores on
the 100k datasets. For the baseline and adaptation
systems we built 5-gram language models with
KenLM (Heafield et al., 2013) using the target side
of the training set, and for the core system we used
the large MSA language model described in sec-
tion 4. We use KenLM because it has been shown
(Heafield, 2011) to be faster and use less memory
than SRILM (Stolcke, 2002) and IRSTLM (Fed-
erico et al., 2008).
</bodyText>
<sectionHeader confidence="0.99636" genericHeader="evaluation">
6 Evaluation and Results
</sectionHeader>
<bodyText confidence="0.999964466666667">
For evaluation we use multeval (Clark et al.,
2011) to calculate BLEU (Papineni et al.,
2002), METEOR (Denkowski and Lavie, 2011),
TER (Snover et al., 2006), and length of the test set
for each system. We evaluate the core and adap-
tation systems on the MSA and Egyptian sides of
the test set drawn from the 100k corpus, which we
refer to as the 100k sets. The data used for evalua-
tion is a genuine Egyptian Arabic generated from
MSA, just like the data the systems were trained
on. It is not practical to evaluate on naturally-
generated Egyptian Arabic in this case because the
domain of our datasets is very formal, since most
of the text comes from news sources, and dialectal
Arabic is generally used in informal situations.2
Below we report BLEU scores from our evalua-
tion using tokenized and detokenized system out-
put. We separate our results into the baseline sys-
tem results, the results of the core, the results of
the adaptation systems, and a comparison section.
We specify scores of intermediate system output,
such as MSA, as BLEU (A), and the scores of fi-
nal system output as BLEU (B). For error analysis,
we use METEOR X-ray (Denkowski and Lavie,
2011) to visualize the alignments of our system
results with the references and each other.
For all MT systems we used grow-diag as our
symmetrization heuristic. For each system, we re-
port only the BLEU score of the best reordering
window variant, which is specified in the caption
</bodyText>
<footnote confidence="0.974627333333333">
2It is important to note that the Egyptian Arabic data we
use is more MSA-like than typical Egyptian because it was
generated directly from MSA.
</footnote>
<bodyText confidence="0.999864882352941">
below each table. The difference in scores be-
tween the different reordering window sizes (7, 4,
and 0) we tried for the adaptation systems was not
large (between 0 and 0.7 BLEU). In the following
tables we present the best results for each adapta-
tion system, which is a reordering window size of
7 for all systems, except for the phrase-based one-
step domain and dialect adaptation system, which
performs better with no reordering (0.2 BLEU bet-
ter than a window of 7, 0.6 BLEU better than a
window of 4), but these small differences in BLEU
scores are within noise. The greatest difference
in scores from the reordering windows was in the
two-step systems domain adaptation step (MSA to
MSA) on top of the phrase-based core, where a re-
ordering window of 7 was 0.7 BLEU better than a
window of 0.
</bodyText>
<subsectionHeader confidence="0.869342">
6.1 Baseline System Results
</subsectionHeader>
<table confidence="0.9992315">
BLEU (B)
Tokenized Detokenized
100k EGY Tune 22.6 22.3
100k EGY Test 21.5 21.1
</table>
<tableCaption confidence="0.9001755">
Table 1: Baseline results (English ➝ EGY) with a
reordering window size of 7.
</tableCaption>
<bodyText confidence="0.9991686">
The baseline system demonstrates the results of
building a basic MT system directly from English
to Egyptian Arabic. The goal of the core and adap-
tation systems is to achieve better scores than this
initial approach.
</bodyText>
<subsectionHeader confidence="0.999394">
6.2 Core System Results
</subsectionHeader>
<bodyText confidence="0.999756555555556">
In Table 2, we report BLEU scores for our core
system on its own tuning set, NIST MT08, and
NIST MT09 as a held-out MSA test set. We
also report scores on the tune and test sets used
to build our adaptation systems, both MSA and
Egyptian Arabic. This is not the final system out-
put, but rather these scores are for intermediate
output only, which becomes the input for our ada-
patation systems.
We notice that unsurprisingly the core system
performs much better on the 100k MSA test set
than on the 100k Egyptian Arabic test set, which
is to be expected because the core system is not
trained on any Egyptian Arabic data. This shows
the impact that the dialectal differences make on
MT output. The results on the Egyptian test
set here are the result of evaluating MSA output
against Egyptian Arabic references.
</bodyText>
<page confidence="0.95033">
200
</page>
<table confidence="0.999822375">
BLEU (A)
Tokenized Detokenized
NIST MT08 (Tune) 23.6 22.8
NIST MT09 (Test) 29.3 28.5
100k MSA Tune 39.8 39.3
100k MSA Test 39.4 39.0
100k EGY Tune 28.1 28.1
100k EGY Test 27.7 27.7
</table>
<tableCaption confidence="0.993208">
Table 2: Core system (English ➝ MSA) results
using a reordering window size of 7.
</tableCaption>
<subsectionHeader confidence="0.999403">
6.3 Adaptation System Results
</subsectionHeader>
<bodyText confidence="0.9998174">
The adaptation systems take as input the MSA out-
put of the core and attempt to improve the scores
on the Egyptian test set by adapting to the domain
of the 100k dataset, as well as to Egyptian Arabic,
in either one or two steps.
</bodyText>
<table confidence="0.9982235">
BLEU (B)
Tokenized Detokenized
100k EGY Tune 40.8 40.5
100k EGY Test 40.3 40.1
</table>
<tableCaption confidence="0.732558">
Table 3: One-Step Adaptation system (MSA’ ➝
Egyptian Arabic) results using a reordering win-
dow size of 0.
</tableCaption>
<bodyText confidence="0.9948133">
Table 3 shows the results of the single adapta-
tion system, which adapts directly from the MSA
output of the core to Egyptian Arabic. These
BLEU scores are already much better than the core
systems performance on the same test sets, im-
proving from 28.1 BLEU to 40.5 BLEU on the
Egyptian Arabic tuning set (a difference of 12.4
BLEU) and improving from 22.7 BLEU to 40.1
BLEU on the Egyptian Arabic test set (a differ-
ence of 17.4 BLEU).
Tables 4 and 5 below illustrate the results of the
first and second steps of the two-step adaptation
system: Table 4 contains the results of the first do-
main adaptation step from out-of-domain MSA to
in-domain MSA and Table 5 contains the results of
the second dialect adaptation step from in-domain
MSA to Egyptian Arabic.
An example of our system output for an English
sentence is given in Table 6. Its METEOR X-ray
alignment is illustrated in Figure 2.
</bodyText>
<subsectionHeader confidence="0.975837">
6.4 System Comparisons on 100k Test Sets
</subsectionHeader>
<bodyText confidence="0.998064">
In Table 7, we compare the results from the core
and the results from the first step of the two-step
</bodyText>
<table confidence="0.998861">
BLEU (A)
Tokenized Detokenized
100k MSA Tune 45.2 44.6
100k MSA Test 44.8 44.2
100k EGY Tune 32.2 32.2
100k EGY Test 32.0 32.0
</table>
<tableCaption confidence="0.985338">
Table 4: Domain Adaptation system (MSA’ ➝
MSA”) for Two-Step Adaptation System Results
using a reordering window size of 7.
</tableCaption>
<table confidence="0.99919725">
BLEU (B)
Tokenized Detokenized
100k EGY Tune 43.3 43.2
100k EGY Test 43.1 42.9
</table>
<tableCaption confidence="0.845191666666667">
Table 5: Dialect Adaptation system (MSA” ➝
Egyptian) for Two-Step Adaptation System Re-
sults using a reordering window size of 7.
</tableCaption>
<figure confidence="0.997067909090909">
■ ■ ممالا ةدحتملا قلغتب اهبتكم قباسلا يف ةيريبيل ادادعتسا ةمهمل ةديدج •◦
ممالا • ممالا
ةدحتملا • ةدحتملا
قلغتب • قلغتب
بتكم • اهبتكم
ةميدقلا ةميدقلا
يف • يف
ايريبيل • ةيريبيل
ادادعتسا • ادادعتسا
ةمهمل • ةمهمل
ةديدج • ةديدج
</figure>
<figureCaption confidence="0.99953">
Figure 2: METEOR X-ray alignment of the sen-
</figureCaption>
<bodyText confidence="0.847549">
P: 0700 v 0900 : 0200
tence in table 6. The left side is the output of the
</bodyText>
<equation confidence="0.767863">
R 070 vs 0.900 : 0200
</equation>
<bodyText confidence="0.985932583333333">
one-step system, the right side is the output of the
Frag: 0214 vs 0085 : 0.29-
two-step system, and the top is the reference. The
Score 055 vs 0823 : 0.273
shaded cells represent matches between the refer-
ence and the one-step system, and the dots repre-
sent matches between the reference and the two-
step system.
adaptation system on the MSA test set and we
see that adapting to the domain improves BLEU
scores on MSA.
Since our goal is to improve the output for
</bodyText>
<footnote confidence="0.973635857142857">
1One-Step System: Core + Domain and Dialect Adapta-
tion (MSA’ ➝ EGY)
2Two Step Adaptation System (Step 1): Core + Domain
Adaptation (MSA’ ➝ MSA”)
3Two Step Adaptation System (Step 2): Core + Domain
Adaptation (MSA’ ➝ MSA”) + Dialect Adaptation (MSA” ➝
EGY)
</footnote>
<page confidence="0.982512">
201
</page>
<table confidence="0.999218846153846">
English UN closes old office in Liberia in preparation for new mission
�
Egyptian Reference èYK�Yg. ¯� �‡K.A‚Ë@ AîD.�JºÓ �‡Ê �ª�JK. �èYj�JÖÏ@ Õ×B@
�éÒêÖÏ @X@Yª�Jƒ@ �éK�Q��J.J�Ë ú�
AAlAmm AAlmtHdp btglq mktbhA AAlsAbq fy lybyryp AAstEdAdA lmhmp jdydp
�
1-Step System èYK�Yg. ¯� �éÖß�Y�®Ë@ I. �JºÓ �‡Ê �ª�JK. �èYj�JÖÏ@ Õ×B@
�éÒêÖÏ @X@Yª�Jƒ@ AK�Q��J.J�Ë ú�
AAlAmm AAlmtHdp btglq mktb AAlqdymp fy lybyryA AAstEdAdA lmhmp jdydp
�
2-Step System (step2) èYK�Yg. ¯� �éÖß�Y�®Ë@ AîD.�JºÓ �‡Ê �ª�JK. �èYj�JÖÏ@ Õ×B@
�éÒêÖÏ @X@Yª�Jƒ@ �éK�Q��J.J�Ë ú�
AAlAmm AAlmtHdp btglq mktbhA AAlqdymp fy lybyryp AAstEdAdA lmhmp jdydp
</table>
<tableCaption confidence="0.991516">
Table 6: An example of system output from the Egyptian test set.
</tableCaption>
<table confidence="0.9281928">
BLEU (A)
Tokenized Detokenized
Core (English ➝ MSA’) 39.4 39.0
Core + Domain Adaptation (MSA’ ➝ MSA”) 44.2
44.8
</table>
<tableCaption confidence="0.998723">
Table 7: Comparison of results on 100k MSA test set.
</tableCaption>
<table confidence="0.999505857142857">
BLEU (A/B)
Tokenized Detokenized
Baseline (English ➝ EGY) 21.5 (B) 21.1
Core (English ➝ MSA&apos;) 27.7 (A) 27.7
One-Step Adaptation System 1 40.3 (B) 40.1
Two-Step Adaptation System (Step 1)2 32.0 (A) 32.0
Two-Step Adaptation System (Step 2)3 43.1 (B) 42.9
</table>
<tableCaption confidence="0.998324">
Table 8: Comparison of results on 100k EGY test data.
</tableCaption>
<table confidence="0.99981725">
BLEU (B) METEOR TER Length
Baseline System 21.1 38.5 66.1 102.7
One-Step System 40.1 53.4 51.3 100.0
Two-Step System: Step 2 (Dialect) 42.9 55.2 50.4 100.1
</table>
<tableCaption confidence="0.999658">
Table 9: Detokenized BLEU, METEOR, TER, and length scores for the best system results.
</tableCaption>
<bodyText confidence="0.998726314285715">
Egyptian Arabic, we examine the improvement of
scores through different steps of the system in Ta-
ble 8. These scores are all based on the same
Egyptian Arabic references, even though some of
the systems are designed to produce MSA output.
It is important to note that although the first step
of the two-step adaptation system (domain adap-
tation) is still producing MSA output, it performs
better on the Egyptian test set than the out-of-
domain MSA core. The domain adaptation sys-
tem built on top of the core performs better than
the core alone on the 100k corpus MSA test set
(+5.2 BLEU), as well as the 100k corpus Egyptian
Arabic test set (+4.3 BLEU). The best score we
achieve on the 100k corpus MSA test set is 44.2
BLEU, from the core plus the domain adaptation
system.
Table 9 shows the other detokenized scores
from multeval (Clark et al., 2011) from the final
output on the EGY test set from each system, and
Table 10 shows BLEU-1 through BLEU-4 scores
on the same detokenized results, which shows an
improvement at different n-gram levels in unigram
coverage from the baseline system to the adapta-
tion systems.
Overall, the two-step adaptation system built on
top of the core performs 15.2 BLEU better than
the core alone on the 100k corpus Egyptian Ara-
bic test set and the one-step adaptation system per-
forms 12.4 BLEU better than the core on the same
test set. The best score on the 100k EGY test set
is from the two-step adaptation system with 42.9
BLEU, which outperforms the one-step adaptation
system by 2.8 BLEU points. We consider possible
causes of these results in section 7.
</bodyText>
<page confidence="0.994035">
202
</page>
<table confidence="0.99972425">
BLEU-1 BLEU-2 BLEU-3 BLEU-4
Baseline System 53.4 26.6 15.3 9.1
One-Step System 64.3 43.5 33.5 27.1
Two-Step System: Step 2 (Dialect) 65.2 46.0 36.8 30.7
</table>
<tableCaption confidence="0.958376">
Table 10: Detokenized BLEU (B) scores on the 100k EGY test set at different n-gram levels.
</tableCaption>
<table confidence="0.999390666666667">
English US , Indonesia commit to closer trade , investment ties
Egyptian Reference ��HA�¯CªK. @ñÓ�Q��ÊJ�K. AJ�‚���KðY�K@ð �èYj�JÖÏ@ �HAK�BñË@
‡~Kð@ �éK�PAÒ�J��ƒ@ð �éK�PAm.��
AAlwlAyAt AAlmtHdp wAndwnysyA byltzmwA bElAqAt tjAryp wAstvmAryp AAwvq
Baseline output éK��PAÒ�J��ƒB@ð �éK�PAj. �JË@ �HA�¯CªË@ �‡J��Kñ�JK. Yêª��JK. AJ�‚���KðY�K@ �àA�¯ , A�K+
+nA , fAn AAndwnysyA bt Ehd btwvyq AAlElAqAt AAltjAryp wAlAstvmAryp
</table>
<tableCaption confidence="0.995072">
Table 11: An example of a Baseline system output sentence with no word matches.
</tableCaption>
<table confidence="0.9996244">
English Pakistan sends envoys to Arab countries
Egyptian Reference éJ��K.QªË@ ÈðYË@ ú
Í@ �á���KñªJ.Ó ÉƒQ��K. �àA�J‚»AK.
bAkstAn btrsl mbEwvyn AAly AAldwl AAlErbyp
One-Step System éJ��K.QªË@ ÈðYË@ ú
Í@ •���J�J« ÉƒQ��K. �àA�J‚»AK.
bAkstAn byrsl Envys AAly AAldwl AAlErbyp
Two-Step System (Step 2) éJ��K.QªË@ ÈðYË@ ú
Í@ •���J�J« ÉƒQ��K. �àA�J‚»AK.
bAkstAn btrsl Envys AAly AAldwl AAlErbyp
</table>
<tableCaption confidence="0.999376">
Table 12: An example of system output from the Egyptian test set.
</tableCaption>
<sectionHeader confidence="0.993498" genericHeader="evaluation">
7 Error Analysis
</sectionHeader>
<bodyText confidence="0.999969729166667">
In some of the output sentences, there are no exact
matches and the sentence gets a score of 0, such as
in the example from the Baseline system output in
Table 11. But there are actually four words in the
output that are present in the reference, but they
have different clitics attached to them. The third
word in the reference, AJ�‚���KðY K@ð/wAndwnysyA
“and Indonesia”, is present in the output as
just AJ�‚a;ðY�K@/AndwnysyA “Indonesia”. The same
is true -of the fifth, sixth, and seventh words
in the reference: :A�¯CªK./bElAqAt “with re-
lationships” is uA7qCªË@/AlElAqAt “the relation-
ships” in the output, L�PAm.��/tjAryp “commer-
cial” is aK�PAj. :J@/AltjAryp “commercial(definite)”,
and �éK�PAÒ~J��ƒ@ð/wAstvmAryp “and investment” is
éK��PAÒ~J��ƒB@ð/wAlAstvmAryp “and the investment”.
In tokenized output the base words would be
matched because the clitics would be separate.
This is one of the drawbacks of evaluating on deto-
kenized data.
Table 12 and Figure 3 show the output for a sen-
tence from the Egyptian test set from the two dif-
ferent adaptation systems. In Figure 3, the results
from the one-step and two-step adaptation systems
are almost the same, except that the two-step adap-
tation system (which scored 2.8 BLEU higher than
the one-step system overall) has one more word
correct (the second word). This word is actually
the same verb, but the two-step adaptation system
has produced the correct conjugation of the verb
(3rd person feminine), while the one-step system
produced the wrong conjugation (3rd person mas-
culine). In adapting to the domain first, the system
seems to produce better subject-verb agreement.
In Table 6 and Figure 2 in Section 6.3, the
transliteration of “Liberia” in the output of the
two-step system matches the reference. The one-
step system produces a different transliteration
which is also valid, but is not the same one the
reference uses. It also produces the correct object
clitic (AîD.-JºÓ/mktbhA “its office” vs. I. .:ºÓ/mktb
“office”). The output of the two-step system more
consistently matches the reference in transliter-
ation, subject-verb agreement, and clitic attach-
ment.
In general the output of the two-step adaptation
system appears to be in the correct order more of-
ten than the output of the one-step adaptation sys-
</bodyText>
<page confidence="0.998182">
203
</page>
<table confidence="0.997662230769231">
English man stabs nine at moscow synagogue
Egyptian Reference @ñºƒñÓ ú
¯� ø
XñîE� •~
J» ú
¯� 9 �á��ª¢J�K. H. Aƒ~
$Ab byTEnn 9 fy knys yhwdy fy mwskwA
One-Step System @ñºƒñÓ ú
¯� ø
XñîE� •~
J» ú
¯� éª‚~~ áª£ Ég. P@
rAjl TEn tsEh fy knys yhwdy fy mwskwA
</table>
<tableCaption confidence="0.998038">
Table 13: Comparison of reference and system output.
</tableCaption>
<table confidence="0.515727714285714">
■ ■ ������� cJ c _r— J1 J_a a,�ll •◦
ناتسكاب • ناتسكاب
لسريب • لسرتب
سيْثنع سيْثنع
يلا • يلا
J,دلا • J,دلا
ةيبرعلا • ةيبرعلا
</table>
<figureCaption confidence="0.9833035">
Figure 3: A comparison of the output of the
one-step domain and dialect adaptation system
</figureCaption>
<equation confidence="0.695054">
: 66 v 3 : 6
R 06.833 0.167
</equation>
<bodyText confidence="0.973437611111111">
(left column) and the two-step domain and dialect
Fg 0265 0194 0071
adaptation system (right column), both built on top
Score: 0490 vs 0672 0182
of the phrase-based core. The top is the reference
sentence.
tem, perhaps because we used a reordering win-
dow of 7 for the two-step system, whereas we used
a window of 0 for the one step system. Addition-
ally, the two-step system allows two passes of re-
ordering, one in each step. Each step of the sys-
tem produces a decrease in the fragmentation of
the output: the output of the core on the Egyptian
test set gets a fragmentation penalty of 0.204, the
one-step system gets a fragmentation penalty of
0.159, and the two step system gets 0.189 for the
first step (domain) and 0.139 for the second step
(dialect). Since the output of the two-step system
is less fragmented, there are longer sequences of
words that are in the correct order.
Additionally, the one-step system misses more
words, especially at the beginning of a sentence.
There are many ways to introduce a sentence in
Arabic, some of which correspond to the same En-
glish phrase. While the model will generate the
most probable one, there may be several accept-
able choices, and the reference may have a dif-
ferent one. For instance, in Table 13, the word
”man” is translated as H. A :ƒ/$Ab in the reference,
and Ég.@P/rAjl in the output of the one-step adapta-
tion system. This word is penalized for not match-
ing the reference, even though both are reason-
able translations of ”man”. This problem could
be helped by synonym matching in the evaluation
metrics, which is not currently available for Ara-
bic.
</bodyText>
<sectionHeader confidence="0.984413" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999985318181818">
We have shown that we can leverage a large
amount of out-of-domain MSA data and a domain
adaptation system to achieve better performance
on an in-domain test set. We apply the same tech-
nique to translating Arabic dialects, by adapting
from MSA to the Egyptian Arabic dialect as we
would adapt between domains of the same lan-
guage. Our results also show that when adapt-
ing to the domain, first by translating to MSA
as an intermediary step and then adapting to the
dialect, we can improve performance even more.
Our results also show the importance of consis-
tent and appropriate tokenization of the data. The
tri-parallel corpus of English, MSA, and Egyptian
gave us a unique opportunity to create this kind
of system, as parallel data for Arabic dialects is
hard to come by. However, this data is artificial
Egyptian, not natural generated dialectal Arabic.
In the future we hope to test our domain and di-
alect adaptation MT systems on more authentic
Egyptian Arabic data sets and to be able to apply
this technique to other Arabic dialects.
</bodyText>
<sectionHeader confidence="0.99495" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999737727272727">
This publication was made possible by grant
NPRP-09-1140-1-177 from the Qatar National
Research Fund (a member of the Qatar Founda-
tion) and by computing resources provided by the
NSF-sponsored XSEDE program under grant TG-
CCR110017. The statements made herein are
solely the responsibility of the authors. We thank
the reviewers for their comments. Nizar Habash
performed most of his contribution to this pa-
per while he was at the Center for Computational
Learning Systems at Columbia University.
</bodyText>
<page confidence="0.997862">
204
</page>
<sectionHeader confidence="0.98958" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999782780701754">
Hitham Abo Bakr, Khaled Shaalan, and Ibrahim
Ziedan. 2008. A Hybrid Approach for Convert-
ing Written Egyptian Colloquial Dialect into Dia-
critized Arabic. In Proceedings of the 6th Interna-
tional Conference on Informatics and Systems (IN-
FOS2008). Cairo University.
Abdel-Rahman Abu-Melhim. 1991. Code-switching
and Linguistic Accommodation in Arabic. In Per-
spectives on Arabic Linguistics III: Papers from the
Third Annual Symposium on Arabic Linguistics, vol-
ume 80, pages 231–250. John Benjamins Publish-
ing.
Kamla Al-Mannai, Hassan Sajjad, Alaa Khader, Fa-
had Al Obaidli, Preslav Nakov, and Stephan Vogel.
2014. Unsupervised Word Segmentation Improves
Dialectal Arabic to English Machine Translation. In
Proceedings of EMNLP Workshop on Arabic Natu-
ral Language Processing, Doha, Qatar.
Houda Bouamor, Nizar Habash, and Kemal Oflazer.
2014. A Multidialectal Parallel Corpus of Ara-
bic. In Proceedings of the Ninth International
Conference on Language Resources and Evaluation
(LREC’14), pages 1240–1245, Reykjavik, Iceland.
Rahma Boujelbane, Mariem Ellouze Khemekhem, and
Lamia Hadrich Belguith. 2013. Mapping Rules for
Building a Tunisian Dialect Lexicon and Generating
Corpora. In Proceedings of the Sixth International
Joint Conference on Natural Language Processing,
pages 419–428, Nagoya, Japan.
Jonathan Clark, Chris Dyer, Alon Lavie, and Noah
Smith. 2011. Better Hypothesis Testing for Sta-
tistical Machine Translation: Controlling for Opti-
mizer Instability. In Proceedings of the Association
for Computational Linguistics (ACL), Portland, Ore-
gon.
Ryan Cotterell and Chris Callison-Burch. 2014.
A Multi-Dialect, Multi-Genre Corpus of Informal
Written Arabic. In Proceedings of the Ninth In-
ternational Conference on Language Resources and
Evaluation (LREC’14), pages 241–245, Reykjavik,
Iceland.
Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization and
evaluation of machine translation systems. In Pro-
ceedings of the EMNLP 2011 Workshop on Statis-
tical Machine Translation, pages 1–4, Edinburgh,
Scotland.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: an open source toolkit for
handling large scale language models. In INTER-
SPEECH, pages 1618–1621.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-speech Tagging and Morphologi-
cal Disambiguation in One Fell Swoop. In Proceed-
ings of the Association for Computational Linguis-
tics, Ann Arbor, Michigan.
Nizar Habash and Owen Rambow. 2006. MAGEAD:
A Morphological Analyzer and Generator for the
Arabic Dialects. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Compu-
tational Linguistics, pages 681–688, Sydney, Aus-
tralia.
Nizar Habash, Ramy Eskander, and Abdelati Hawwari.
2012. A Morphological Analyzer for Egyptian Ara-
bic. In Proceedings of the Twelfth Meeting of the
Special Interest Group on Computational Morphol-
ogy and Phonology, pages 1–9, Montr´eal, Canada.
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-
kander, and Nadi Tomeh. 2013. Morphological
Analysis and Disambiguation for Dialectal Arabic.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 426–432, Atlanta, Georgia.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing, volume 3. Morgan &amp; Clay-
pool Publishers.
Ahmed Hamdi, Nuria Gala, and Alexis Nasr. 2014.
Automatically Building a Tunisian Lexicon for De-
verbal Nouns. In Proceedings of the First Workshop
on Applying NLP Tools to Similar Languages, Vari-
eties and Dialects, pages 95–102, Dublin, Ireland.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable Modfied
Kneser-Ney Language Model Estimation. In In Pro-
ceedings of the Association for Computational Lin-
guistics, Sofia, Bulgaria.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
EMNLP 2011 Sixth Workshop on Statistical Ma-
chine Translation, pages 187–197, Edinburgh, Scot-
land, United Kingdom, July.
Pierre Isabelle, Cyril Goutte, and Michel Simard.
2007. Domain Adaptation of MT Systems through
Automatic Post-Editing. In Proceedings of MT
Summit XI, pages 255–261, Copenhagen, Denmark.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-
pher Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Christopher Dyer, Ondrej Bo-
jar, Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open Source Toolkit for Statistical Ma-
chine Translation. In Proceedings of the 45th An-
nual Meeting of the Association for Computational
Linguistics Companion Volume Proceedings of the
Demo and Poster Sessions, pages 177–180, Prague,
Czech Republic.
Emad Mohamed, Behrang Mohit, and Kemal Oflazer.
2012. Transforming Standard Arabic to Colloquial
Arabic. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 176–180, Jeju
Island, Korea.
</reference>
<page confidence="0.979438">
205
</page>
<reference confidence="0.99987656043956">
NIST Multimodal Information Group. 2010a. NIST
2008 Open Machine Translation (OpenMT) Evalua-
tion LDC2010T21. Web Download.
NIST Multimodal Information Group. 2010b. NIST
2009 Open Machine Translation (OpenMT) Evalua-
tion LDC2010T23. Web Download.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. In Computational Linguistics, pages 19–
51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of the Association for Computational Linguistics,
Philadelphia, Pennsylvania.
Robert Parker, David Graff, Ke Chen, Junbo Kong, and
Kazuaki Maeda. 2011. Arabic Gigaword Fifth Edi-
tion LDC2011T11. Web Download.
Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,
Ahmed El Kholy, Ramy Eskander, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan Roth.
2014. MADAMIRA: A Fast, Comprehensive Tool
for Morphological Analysis and Disambiguation of
Arabic. In Proceedings of the Ninth International
Conference on Language Resources and Evaluation
(LREC’14), pages 1094–1101, Reykjavik, Iceland.
Hassan Sajjad, Kareem Darwish, and Yonatan Be-
linkov. 2013. Translating Dialectal Arabic to En-
glish. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 1–6, Sofia, Bulgaria.
Ahmed Salama, Houda Bouamor, Behrang Mohit, and
Kemal Oflazer. 2014. YouDACC: the Youtube Di-
alectal Arabic Comment Corpus. In Proceedings
of the Ninth International Conference on Language
Resources and Evaluation (LREC’14), pages 1246–
1251, Reykjavik, Iceland.
Wael Salloum and Nizar Habash. 2013. Dialectal
Arabic to English Machine Translation: Pivoting
through Modern Standard Arabic. In Proceedings of
the 2013 Conference of the North American Chapter
of the Association for Computational Linguistics:
Human Language Technologies, pages 348–358, At-
lanta, Georgia.
Wael Salloum, Heba Elfardy, Linda Alamir-Salloum,
Nizar Habash, and Mona Diab. 2014. Sentence
Level Dialect Identification for Machine Translation
System Selection. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers), pages 772–
778, Baltimore, Maryland.
Hassan Sawaf. 2010. Arabic Dialect Handling in Hy-
brid Machine Translation. In Proceedings of the
Ninth Conference of the Association for Machine
Translation in the Americas (AMTA 10), Denver,
Colorado.
Mohammed Q Shatnawi, Muneer Bani Yassein, and
Reem Mahafza. 2012. A Framework for Retriev-
ing Arabic Documents Based on Queries Written in
Arabic Slang Language. Journal of Information Sci-
ence, 38(4):350–365.
Michel Simard, Cyril Goutte, and Pierre Isabelle.
2007. Statistical Phrase-Based Post-Editing. In
Proceedings of NAACL-HLT-2007 Human Lan-
guage Technology: the Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 508–515, Rochester, NY.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proceedings of Association for Ma-
chine Translation in the Americas, Cambridge, Mas-
sachusetts.
Andreas Stolcke. 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In Proceedings of the In-
ternational Conference on Spoken Language Pro-
cessing, vol. 2, pages 901–904, Denver, CO, USA.
Omar F. Zaidan and Chris Callison-Burch. 2011. The
Arabic Online Commentary Dataset: an Annotated
Dataset of Informal Arabic with High Dialectal Con-
tent. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies, pages 37–41, Port-
land, Oregon, USA.
Rabih Zbib, Erika Malchiodi, Jacob Devlin, David
Stallard, Spyros Matsoukas, Richard Schwartz, John
Makhoul, Omar F. Zaidan, and Chris Callison-
Burch. 2012. Machine Translation for Arabic Di-
alects. In Proceedings of North American Chap-
ter of the Association for Computational Linguistics,
Montreal, Canada.
</reference>
<page confidence="0.998891">
206
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.111827">
<title confidence="0.996873">Domain and Dialect for Machine Translation into Egyptian Arabic</title>
<author confidence="0.896909">Weston Houda</author>
<title confidence="0.470014">Nizar and Kemal</title>
<author confidence="0.473616">Mellon</author>
<email confidence="0.559637">wfeely,</email>
<affiliation confidence="0.874564333333333">Mellon University in hbouamor@qatar.cmu.edu, York University Abu</affiliation>
<email confidence="0.998087">nizar.habash@nyu.edu</email>
<abstract confidence="0.9935555">In this paper, we present a statistical machine translation system for English to Dialectal Arabic (DA), using Modern Standard Arabic (MSA) as a pivot. We create a core system to translate from English to MSA using a large bilingual parallel corpus. Then, we design two separate pathways for translation from MSA into DA: a two-step domain and dialect adaptation system and a one-step simultaneous domain and dialect adaptation system. Both variants of the adaptation systems are trained on a 100k sentence tri-parallel corpus of English, MSA, and Egyptian Arabic generated by a rule-based transformation. We test our systems on a held-out Egyptian Arabic test set from the 100k sentence corpus and we achieve our best performance using the two-step domain and dialect adaptation system with a BLEU score of 42.9.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hitham Abo Bakr</author>
<author>Khaled Shaalan</author>
<author>Ibrahim Ziedan</author>
</authors>
<title>A Hybrid Approach for Converting Written Egyptian Colloquial Dialect into Diacritized Arabic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Informatics and Systems (INFOS2008).</booktitle>
<institution>Cairo University.</institution>
<contexts>
<context position="6590" citStr="Bakr et al. (2008)" startWordPosition="1068" endWordPosition="1071">or machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sente</context>
</contexts>
<marker>Bakr, Shaalan, Ziedan, 2008</marker>
<rawString>Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan. 2008. A Hybrid Approach for Converting Written Egyptian Colloquial Dialect into Diacritized Arabic. In Proceedings of the 6th International Conference on Informatics and Systems (INFOS2008). Cairo University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abdel-Rahman Abu-Melhim</author>
</authors>
<title>Code-switching and Linguistic Accommodation in Arabic.</title>
<date>1991</date>
<booktitle>In Perspectives on Arabic Linguistics III: Papers from the Third Annual Symposium on Arabic Linguistics,</booktitle>
<volume>80</volume>
<pages>231--250</pages>
<publisher>John Benjamins Publishing.</publisher>
<contexts>
<context position="1528" citStr="Abu-Melhim, 1991" startWordPosition="242" endWordPosition="243">A, and Egyptian Arabic generated by a rule-based transformation. We test our systems on a held-out Egyptian Arabic test set from the 100k sentence corpus and we achieve our best performance using the two-step domain and dialect adaptation system with a BLEU score of 42.9. 1 Introduction While MSA is the shared official language of culture, media and education in the Arab world, it is not the native language of any speakers of Arabic. Most native speakers are unable to produce sustained spontaneous discourse in MSA - they usually resort to repeated code-switching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Ha</context>
</contexts>
<marker>Abu-Melhim, 1991</marker>
<rawString>Abdel-Rahman Abu-Melhim. 1991. Code-switching and Linguistic Accommodation in Arabic. In Perspectives on Arabic Linguistics III: Papers from the Third Annual Symposium on Arabic Linguistics, volume 80, pages 231–250. John Benjamins Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamla Al-Mannai</author>
<author>Hassan Sajjad</author>
<author>Alaa Khader</author>
<author>Fahad Al Obaidli</author>
<author>Preslav Nakov</author>
<author>Stephan Vogel</author>
</authors>
<title>Unsupervised Word Segmentation Improves Dialectal Arabic to English Machine Translation.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP Workshop on Arabic Natural Language Processing,</booktitle>
<location>Doha, Qatar.</location>
<contexts>
<context position="1980" citStr="Al-Mannai et al., 2014" startWordPosition="313" endWordPosition="316">ive speakers are unable to produce sustained spontaneous discourse in MSA - they usually resort to repeated code-switching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an </context>
</contexts>
<marker>Al-Mannai, Sajjad, Khader, Obaidli, Nakov, Vogel, 2014</marker>
<rawString>Kamla Al-Mannai, Hassan Sajjad, Alaa Khader, Fahad Al Obaidli, Preslav Nakov, and Stephan Vogel. 2014. Unsupervised Word Segmentation Improves Dialectal Arabic to English Machine Translation. In Proceedings of EMNLP Workshop on Arabic Natural Language Processing, Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Houda Bouamor</author>
<author>Nizar Habash</author>
<author>Kemal Oflazer</author>
</authors>
<title>A Multidialectal Parallel Corpus of Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<pages>1240--1245</pages>
<location>Reykjavik, Iceland.</location>
<contexts>
<context position="2070" citStr="Bouamor et al., 2014" startWordPosition="328" endWordPosition="331">rt to repeated code-switching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an established standard orthography, the dialects do not: people write words reflecting their</context>
<context position="5879" citStr="Bouamor et al., 2014" startWordPosition="953" endWordPosition="956">r experimental setup and the results obtained. Then, we give an analysis of our system output in Section 7. Finally, we conclude and describe our future work in Section 8. 2 Related work Machine translation (MT) for dialectal Arabic (DA) is quite challenging given the limited resources to build rule-based models or train statistical models for MT. While there has been a considerable amount of work in the context of standard Arabic NLP (Habash, 2010), DA is impoverished in terms of available tools and resources compared to MSA, e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information ret</context>
</contexts>
<marker>Bouamor, Habash, Oflazer, 2014</marker>
<rawString>Houda Bouamor, Nizar Habash, and Kemal Oflazer. 2014. A Multidialectal Parallel Corpus of Arabic. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), pages 1240–1245, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahma Boujelbane</author>
<author>Mariem Ellouze Khemekhem</author>
<author>Lamia Hadrich Belguith</author>
</authors>
<title>Mapping Rules for Building a Tunisian Dialect Lexicon and Generating Corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>419--428</pages>
<location>Nagoya, Japan.</location>
<contexts>
<context position="6913" citStr="Boujelbane et al. (2013)" startWordPosition="1124" endWordPosition="1128">ent research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They argued that di</context>
</contexts>
<marker>Boujelbane, Khemekhem, Belguith, 2013</marker>
<rawString>Rahma Boujelbane, Mariem Ellouze Khemekhem, and Lamia Hadrich Belguith. 2013. Mapping Rules for Building a Tunisian Dialect Lexicon and Generating Corpora. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 419–428, Nagoya, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah Smith</author>
</authors>
<title>Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<location>Portland, Oregon.</location>
<contexts>
<context position="17134" citStr="Clark et al., 2011" startWordPosition="2843" endWordPosition="2846">row-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from n</context>
<context position="26228" citStr="Clark et al., 2011" startWordPosition="4447" endWordPosition="4450">utput. It is important to note that although the first step of the two-step adaptation system (domain adaptation) is still producing MSA output, it performs better on the Egyptian test set than the out-ofdomain MSA core. The domain adaptation system built on top of the core performs better than the core alone on the 100k corpus MSA test set (+5.2 BLEU), as well as the 100k corpus Egyptian Arabic test set (+4.3 BLEU). The best score we achieve on the 100k corpus MSA test set is 44.2 BLEU, from the core plus the domain adaptation system. Table 9 shows the other detokenized scores from multeval (Clark et al., 2011) from the final output on the EGY test set from each system, and Table 10 shows BLEU-1 through BLEU-4 scores on the same detokenized results, which shows an improvement at different n-gram levels in unigram coverage from the baseline system to the adaptation systems. Overall, the two-step adaptation system built on top of the core performs 15.2 BLEU better than the core alone on the 100k corpus Egyptian Arabic test set and the one-step adaptation system performs 12.4 BLEU better than the core on the same test set. The best score on the 100k EGY test set is from the two-step adaptation system w</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan Clark, Chris Dyer, Alon Lavie, and Noah Smith. 2011. Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability. In Proceedings of the Association for Computational Linguistics (ACL), Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Cotterell</author>
<author>Chris Callison-Burch</author>
</authors>
<title>A Multi-Dialect, Multi-Genre Corpus of Informal Written Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<pages>241--245</pages>
<location>Reykjavik, Iceland.</location>
<contexts>
<context position="2048" citStr="Cotterell and Callison-Burch, 2014" startWordPosition="323" endWordPosition="327">discourse in MSA - they usually resort to repeated code-switching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an established standard orthography, the dialects do not: people write </context>
</contexts>
<marker>Cotterell, Callison-Burch, 2014</marker>
<rawString>Ryan Cotterell and Chris Callison-Burch. 2014. A Multi-Dialect, Multi-Genre Corpus of Informal Written Arabic. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), pages 241–245, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Alon Lavie</author>
</authors>
<title>Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems.</title>
<date>2011</date>
<booktitle>In Proceedings of the EMNLP 2011 Workshop on Statistical Machine Translation,</booktitle>
<pages>1--4</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="17212" citStr="Denkowski and Lavie, 2011" startWordPosition="2855" endWordPosition="2858">s our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from news sources, and dialectal Arabic is generally used in informal situations.2 B</context>
</contexts>
<marker>Denkowski, Lavie, 2011</marker>
<rawString>Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems. In Proceedings of the EMNLP 2011 Workshop on Statistical Machine Translation, pages 1–4, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
</authors>
<title>IRSTLM: an open source toolkit for handling large scale language models.</title>
<date>2008</date>
<booktitle>In INTERSPEECH,</booktitle>
<pages>1618--1621</pages>
<contexts>
<context position="17056" citStr="Federico et al., 2008" startWordPosition="2829" endWordPosition="2833">ed two different heuristics for symmetrizing the word alignments: grow-diag and grow-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because </context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In INTERSPEECH, pages 1618–1621.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="11067" citStr="Habash and Rambow, 2005" startWordPosition="1829" endWordPosition="1832"> 5 million parallel sentences of English and MSA from NIST 2012 as the training set. The tuning set consists of 1,356 sentences from the NIST 2008 Open Machine Translation Evaluation (MT08) data (NIST Multimodal Information Group, 2010a), and the test set consists of 1,313 sentences from NIST MT09 (NIST Multimodal Information Group, 2010b). We use a 5-gram MSA language model built using the SRILM toolkit (Stolcke, 2002) on 260 million words of MSA from the Arabic Gigaword (Parker et al., 2011). All our MSA parallel data and monolingual MSA language modeling data were tokenized with MADA v3.1 (Habash and Rambow, 2005) using the ATB (Arabic Treebank) tokenization scheme. For the adaptation systems, we build a 100k tri-parallel corpus Egyptian-MSA-English corpus. The MSA and English parts are extracted from the NIST corpus distributed by the Linguistic Data Consortium. The Egyptian sentences are obtained automatically by extending Mohamed et al. (2012) method for generating Egyptian Arabic from morphologically disambiguated MSA sentences. This rule-based method relies on 103 transformation rules covering essentially nouns, verbs and pronouns as well as certain lexical items. For each MSA sentence, this metho</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the Association for Computational Linguistics, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>681--688</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2886" citStr="Habash and Rambow, 2006" startWordPosition="454" endWordPosition="458">ia industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an established standard orthography, the dialects do not: people write words reflecting their phonology and sometimes use roman script. Thus, MSA tools cannot effectively model DA; for instance, over one-third of Levantine verbs cannot be analyzed using an MSA morphological analyzer (Habash and Rambow, 2006). These differences make the direct use of MSA NLP tools and applications for handling dialects impractical. In this work, we design an MT system for English to Egyptian Arabic translation by using MSA as an intermediary step. This includes different challenges from those faced when translating into English. Because MSA is the formal written variety of Arabic, there is an abundance of written data, including parallel corpora from sources like the United Nations and newspapers, as well as various treebanks. Using these resources, many researchers have created fairly reliable MSA translation sys</context>
</contexts>
<marker>Habash, Rambow, 2006</marker>
<rawString>Nizar Habash and Owen Rambow. 2006. MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 681–688, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ramy Eskander</author>
<author>Abdelati Hawwari</author>
</authors>
<title>A Morphological Analyzer for Egyptian Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology,</booktitle>
<pages>1--9</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="2145" citStr="Habash et al., 2012" startWordPosition="340" endWordPosition="343">1). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an established standard orthography, the dialects do not: people write words reflecting their phonology and sometimes use roman script. Thus, MSA tools cannot effective</context>
<context position="6118" citStr="Habash et al., 2012" startWordPosition="990" endWordPosition="993">quite challenging given the limited resources to build rule-based models or train statistical models for MT. While there has been a considerable amount of work in the context of standard Arabic NLP (Habash, 2010), DA is impoverished in terms of available tools and resources compared to MSA, e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyp</context>
</contexts>
<marker>Habash, Eskander, Hawwari, 2012</marker>
<rawString>Nizar Habash, Ramy Eskander, and Abdelati Hawwari. 2012. A Morphological Analyzer for Egyptian Arabic. In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology, pages 1–9, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Ramy Eskander</author>
<author>Nadi Tomeh</author>
</authors>
<title>Morphological Analysis and Disambiguation for Dialectal Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>426--432</pages>
<location>Atlanta,</location>
<contexts>
<context position="6140" citStr="Habash et al., 2013" startWordPosition="994" endWordPosition="997">en the limited resources to build rule-based models or train statistical models for MT. While there has been a considerable amount of work in the context of standard Arabic NLP (Habash, 2010), DA is impoverished in terms of available tools and resources compared to MSA, e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to tran</context>
<context position="12624" citStr="Habash et al., 2013" startWordPosition="2072" endWordPosition="2075">ncluding articles extracted from the Egyptian version of Wikipedia1 and the Egyptian side of the AOC corpus (Zaidan and Callison-Burch, 2011). We chose to include Egyptian Wikipedia for the formal level of sentences in it different from the regular DA written in blogs or microblogging websites (e.g., Twitter) and closer to the ones generated by our system. We split this data into train, tune, and test sets of 98,027, 960, and 961 sentences respectively, after removing duplicates across sets. The MSA corpus was tokenized using MADA and the Egyptian Arabic data was tokenized with MADA-ARZ v0.4 (Habash et al., 2013), both using the ATB tokenization scheme, with alif/ya normalization. 5 System Design Figure 1 shows a diagram of our three English to Egyptian Arabic MT systems: (1) the baseline MT system, (2) the one-step adaptation MT system, and (3) the two-step adaptation MT system. We describe each system below. 1http://arz.wikipedia.org/ 198 Baseline MT System Figure 1: An overview of the different system architectures. 100K sent. 5M sent. MSA Translation Domain &amp; Dialect Adaptation One-Step Adaptation MT System English Egyptian Arabic 100K sent. 100K sent. Dialect Adaptation Egyptian Arabic In-domain </context>
</contexts>
<marker>Habash, Roth, Rambow, Eskander, Tomeh, 2013</marker>
<rawString>Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 426–432, Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing,</title>
<date>2010</date>
<volume>3</volume>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="5711" citStr="Habash, 2010" startWordPosition="925" endWordPosition="926">s the dataset used in the different experiments. Our approach for translating English text into Egyptian Arabic is explained in Section 5. Section 6 presents our experimental setup and the results obtained. Then, we give an analysis of our system output in Section 7. Finally, we conclude and describe our future work in Section 8. 2 Related work Machine translation (MT) for dialectal Arabic (DA) is quite challenging given the limited resources to build rule-based models or train statistical models for MT. While there has been a considerable amount of work in the context of standard Arabic NLP (Habash, 2010), DA is impoverished in terms of available tools and resources compared to MSA, e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work succ</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing, volume 3. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hamdi</author>
<author>Nuria Gala</author>
<author>Alexis Nasr</author>
</authors>
<title>Automatically Building a Tunisian Lexicon for Deverbal Nouns.</title>
<date>2014</date>
<booktitle>In Proceedings of the First Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects,</booktitle>
<pages>95--102</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="6937" citStr="Hamdi et al. (2014)" startWordPosition="1130" endWordPosition="1133">y translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They argued that differences in genre betwe</context>
</contexts>
<marker>Hamdi, Gala, Nasr, 2014</marker>
<rawString>Ahmed Hamdi, Nuria Gala, and Alexis Nasr. 2014. Automatically Building a Tunisian Lexicon for Deverbal Nouns. In Proceedings of the First Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects, pages 95–102, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Ivan Pouzyrevsky</author>
<author>Jonathan H Clark</author>
<author>Philipp Koehn</author>
</authors>
<title>Scalable Modfied Kneser-Ney Language Model Estimation. In</title>
<date>2013</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="16777" citStr="Heafield et al., 2013" startWordPosition="2777" endWordPosition="2780">g the typical reordering window of length 7, a smaller window of length 4, and no reordering at all. We found a reordering window 199 size of 7 to work best for all our systems, except for the one-step adaptation system, where no reordering produced the best result. We also tested two different heuristics for symmetrizing the word alignments: grow-diag and grow-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set dr</context>
</contexts>
<marker>Heafield, Pouzyrevsky, Clark, Koehn, 2013</marker>
<rawString>Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013. Scalable Modfied Kneser-Ney Language Model Estimation. In In Proceedings of the Association for Computational Linguistics, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and Smaller Language Model Queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>187--197</pages>
<location>Edinburgh, Scotland, United Kingdom,</location>
<contexts>
<context position="16961" citStr="Heafield, 2011" startWordPosition="2814" endWordPosition="2815">e one-step adaptation system, where no reordering produced the best result. We also tested two different heuristics for symmetrizing the word alignments: grow-diag and grow-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained </context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and Smaller Language Model Queries. In Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, United Kingdom, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Isabelle</author>
<author>Cyril Goutte</author>
<author>Michel Simard</author>
</authors>
<title>Domain Adaptation of MT Systems through Automatic Post-Editing.</title>
<date>2007</date>
<booktitle>In Proceedings of MT Summit XI,</booktitle>
<pages>255--261</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="8974" citStr="Isabelle et al. (2007)" startWordPosition="1477" endWordPosition="1480">te 197 the document from scratch. However, we can apply statistical phrase-based MT to create an automatic machine post-editor (what we refer to in this paper as an adaptation system) to improve the output of an MT system, and make it more closely resemble the references. Simard et al. (2007) used a phrase-based MT system as an automatic posteditor for the output of a commercial rule-based MT system, showing that it produced better results than both the rule-based system alone and a single pass phrase-based MT system. This technique is also useful for adapting to a specific domain or dataset. Isabelle et al. (2007) used a statistical MT system to automatically post-edit the output of a generic rule-based MT system, to avoid manually customizing a system dictionary and to reduce the amount of manual post-editing required. For our adaptation systems, we build a core phrase-based MT system with a large amount of out-of-domain data, which allows us to have better coverage of the target language. For an adaptation system, we then build a second phrase-based MT system by translating the in-domain train, tune, and test sets through the core translation system, then using that data to build the second system. T</context>
</contexts>
<marker>Isabelle, Goutte, Simard, 2007</marker>
<rawString>Pierre Isabelle, Cyril Goutte, and Michel Simard. 2007. Domain Adaptation of MT Systems through Automatic Post-Editing. In Proceedings of MT Summit XI, pages 255–261, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Christopher Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="13493" citStr="Koehn et al., 2007" startWordPosition="2203" endWordPosition="2206"> adaptation MT system. We describe each system below. 1http://arz.wikipedia.org/ 198 Baseline MT System Figure 1: An overview of the different system architectures. 100K sent. 5M sent. MSA Translation Domain &amp; Dialect Adaptation One-Step Adaptation MT System English Egyptian Arabic 100K sent. 100K sent. Dialect Adaptation Egyptian Arabic In-domain MSA Domain Adaptation Two-Step Adaptation MT System English 5M sent. Translation MSA English 100K sent. Translation Egyptian Arabic Baseline System Our baseline system is a single phrase-based English to Egyptian Arabic MT system, built using Moses (Koehn et al., 2007) on the 100k corpus described in Section 4. This system does not include any MSA data, nor does it have an adaptation system; it is a typical, one-pass MT system that translates English directly into Egyptian Arabic. We will show that using adaptation systems improves the results significantly. Core System We base our systems on a core system built using Moses with the NIST data, a large amount of parallel English-MSA data from different sources than our in-domain data (the 100k dataset). Our core system is also built using Moses. We use this core system to translate the English side of our 10</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Christopher Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emad Mohamed</author>
<author>Behrang Mohit</author>
<author>Kemal Oflazer</author>
</authors>
<title>Transforming Standard Arabic to Colloquial Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>176--180</pages>
<location>Jeju Island,</location>
<contexts>
<context position="6887" citStr="Mohamed et al. (2012)" startWordPosition="1120" endWordPosition="1123">ools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel</context>
<context position="11406" citStr="Mohamed et al. (2012)" startWordPosition="1877" endWordPosition="1880"> We use a 5-gram MSA language model built using the SRILM toolkit (Stolcke, 2002) on 260 million words of MSA from the Arabic Gigaword (Parker et al., 2011). All our MSA parallel data and monolingual MSA language modeling data were tokenized with MADA v3.1 (Habash and Rambow, 2005) using the ATB (Arabic Treebank) tokenization scheme. For the adaptation systems, we build a 100k tri-parallel corpus Egyptian-MSA-English corpus. The MSA and English parts are extracted from the NIST corpus distributed by the Linguistic Data Consortium. The Egyptian sentences are obtained automatically by extending Mohamed et al. (2012) method for generating Egyptian Arabic from morphologically disambiguated MSA sentences. This rule-based method relies on 103 transformation rules covering essentially nouns, verbs and pronouns as well as certain lexical items. For each MSA sentence, this method provides more than one possible candidate, in its original version, the Egyptian sentence kept was chosen randomly. We extend the selection algorithm by scoring the different sentences using a language model. For this, we use SRILM with modified Kneser-Ney smoothing to build a 5-gram language model. The model is trained on a corpus inc</context>
<context position="15822" citStr="Mohamed et al., 2012" startWordPosition="2619" endWordPosition="2622">MSA), into in-domain MSA. This system is trained on the MSA’ output parallel with the MSA references from the 100k dataset. We refer to the output of this system as MSA”, because it has been translated from English into outof-domain MSA (MSA’), and then from out-ofdomain MSA to in-domain MSA. The first adaptation system is used to translate the MSA’ train, tune, and test sets into MSA”. Then we use these MSA” sets with their parallel Egyptian Arabic from the 100k dataset to build the second adaptation system from in-domain MSA to Egyptian Arabic. We do not use the dialect transformation from (Mohamed et al., 2012) because it is designed to work with gold-standard annotation of the MSA text, which we do not have. System Variants Since MSA and Egyptian are more similar to each other than they are to English, we tried several different reordering window sizes to find the optimal reordering distance for adapting MSA to Egyptian Arabic, including the typical reordering window of length 7, a smaller window of length 4, and no reordering at all. We found a reordering window 199 size of 7 to work best for all our systems, except for the one-step adaptation system, where no reordering produced the best result. </context>
</contexts>
<marker>Mohamed, Mohit, Oflazer, 2012</marker>
<rawString>Emad Mohamed, Behrang Mohit, and Kemal Oflazer. 2012. Transforming Standard Arabic to Colloquial Arabic. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 176–180, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST Multimodal</author>
</authors>
<title>Information Group.</title>
<date>2010</date>
<marker>Multimodal, 2010</marker>
<rawString>NIST Multimodal Information Group. 2010a. NIST 2008 Open Machine Translation (OpenMT) Evaluation LDC2010T21. Web Download.</rawString>
</citation>
<citation valid="false">
<authors>
<author>NIST Multimodal</author>
</authors>
<title>Information Group.</title>
<booktitle>2010b. NIST 2009 Open Machine Translation (OpenMT) Evaluation LDC2010T23. Web Download.</booktitle>
<marker>Multimodal, </marker>
<rawString>NIST Multimodal Information Group. 2010b. NIST 2009 Open Machine Translation (OpenMT) Evaluation LDC2010T23. Web Download.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<booktitle>In Computational Linguistics,</booktitle>
<pages>19--51</pages>
<contexts>
<context position="16553" citStr="Och and Ney, 2003" startWordPosition="2742" endWordPosition="2745">nts Since MSA and Egyptian are more similar to each other than they are to English, we tried several different reordering window sizes to find the optimal reordering distance for adapting MSA to Egyptian Arabic, including the typical reordering window of length 7, a smaller window of length 4, and no reordering at all. We found a reordering window 199 size of 7 to work best for all our systems, except for the one-step adaptation system, where no reordering produced the best result. We also tested two different heuristics for symmetrizing the word alignments: grow-diag and grow-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. In Computational Linguistics, pages 19– 51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="17176" citStr="Papineni et al., 2002" startWordPosition="2850" endWordPosition="2853"> We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from news sources, and dialectal Arabic is gener</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the Association for Computational Linguistics, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Parker</author>
<author>David Graff</author>
<author>Ke Chen</author>
<author>Junbo Kong</author>
<author>Kazuaki Maeda</author>
</authors>
<title>Arabic Gigaword Fifth Edition LDC2011T11. Web Download.</title>
<date>2011</date>
<contexts>
<context position="10941" citStr="Parker et al., 2011" startWordPosition="1809" endWordPosition="1812">tation systems. We describe the systems in more detail in Section 5. 4 Data For the core English to MSA system, we use the 5 million parallel sentences of English and MSA from NIST 2012 as the training set. The tuning set consists of 1,356 sentences from the NIST 2008 Open Machine Translation Evaluation (MT08) data (NIST Multimodal Information Group, 2010a), and the test set consists of 1,313 sentences from NIST MT09 (NIST Multimodal Information Group, 2010b). We use a 5-gram MSA language model built using the SRILM toolkit (Stolcke, 2002) on 260 million words of MSA from the Arabic Gigaword (Parker et al., 2011). All our MSA parallel data and monolingual MSA language modeling data were tokenized with MADA v3.1 (Habash and Rambow, 2005) using the ATB (Arabic Treebank) tokenization scheme. For the adaptation systems, we build a 100k tri-parallel corpus Egyptian-MSA-English corpus. The MSA and English parts are extracted from the NIST corpus distributed by the Linguistic Data Consortium. The Egyptian sentences are obtained automatically by extending Mohamed et al. (2012) method for generating Egyptian Arabic from morphologically disambiguated MSA sentences. This rule-based method relies on 103 transform</context>
</contexts>
<marker>Parker, Graff, Chen, Kong, Maeda, 2011</marker>
<rawString>Robert Parker, David Graff, Ke Chen, Junbo Kong, and Kazuaki Maeda. 2011. Arabic Gigaword Fifth Edition LDC2011T11. Web Download.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arfath Pasha</author>
<author>Mohamed Al-Badrashiny</author>
<author>Mona Diab</author>
<author>Ahmed El Kholy</author>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Manoj Pooleery</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<pages>1094--1101</pages>
<location>Reykjavik, Iceland.</location>
<marker>Pasha, Al-Badrashiny, Diab, El Kholy, Eskander, Habash, Pooleery, Rambow, Roth, 2014</marker>
<rawString>Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab, Ahmed El Kholy, Ramy Eskander, Nizar Habash, Manoj Pooleery, Owen Rambow, and Ryan Roth. 2014. MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), pages 1094–1101, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sajjad</author>
<author>Kareem Darwish</author>
<author>Yonatan Belinkov</author>
</authors>
<title>Translating Dialectal Arabic to English.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>1--6</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="6692" citStr="Sajjad et al. (2013)" startWordPosition="1086" endWordPosition="1089">ble for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sen</context>
</contexts>
<marker>Sajjad, Darwish, Belinkov, 2013</marker>
<rawString>Hassan Sajjad, Kareem Darwish, and Yonatan Belinkov. 2013. Translating Dialectal Arabic to English. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 1–6, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Salama</author>
<author>Houda Bouamor</author>
<author>Behrang Mohit</author>
<author>Kemal Oflazer</author>
</authors>
<title>YouDACC: the Youtube Dialectal Arabic Comment Corpus.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<pages>1246--1251</pages>
<location>Reykjavik, Iceland.</location>
<contexts>
<context position="2092" citStr="Salama et al., 2014" startWordPosition="332" endWordPosition="335">itching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from MSA. And while MSA has an established standard orthography, the dialects do not: people write words reflecting their phonology and sometim</context>
</contexts>
<marker>Salama, Bouamor, Mohit, Oflazer, 2014</marker>
<rawString>Ahmed Salama, Houda Bouamor, Behrang Mohit, and Kemal Oflazer. 2014. YouDACC: the Youtube Dialectal Arabic Comment Corpus. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), pages 1246– 1251, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal Arabic to English Machine Translation: Pivoting through Modern Standard Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>348--358</pages>
<location>Atlanta,</location>
<contexts>
<context position="1933" citStr="Salloum and Habash, 2013" startWordPosition="305" endWordPosition="308">ive language of any speakers of Arabic. Most native speakers are unable to produce sustained spontaneous discourse in MSA - they usually resort to repeated code-switching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, an</context>
<context position="6416" citStr="Salloum and Habash, 2013" startWordPosition="1039" endWordPosition="1042">e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation betwe</context>
</contexts>
<marker>Salloum, Habash, 2013</marker>
<rawString>Wael Salloum and Nizar Habash. 2013. Dialectal Arabic to English Machine Translation: Pivoting through Modern Standard Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 348–358, Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Heba Elfardy</author>
<author>Linda Alamir-Salloum</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
</authors>
<title>Sentence Level Dialect Identification for Machine Translation System Selection.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>772--778</pages>
<location>Baltimore, Maryland.</location>
<contexts>
<context position="1955" citStr="Salloum et al., 2014" startWordPosition="309" endWordPosition="312">rs of Arabic. Most native speakers are unable to produce sustained spontaneous discourse in MSA - they usually resort to repeated code-switching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexically, morphologically, and syntactically from M</context>
</contexts>
<marker>Salloum, Elfardy, Alamir-Salloum, Habash, Diab, 2014</marker>
<rawString>Wael Salloum, Heba Elfardy, Linda Alamir-Salloum, Nizar Habash, and Mona Diab. 2014. Sentence Level Dialect Identification for Machine Translation System Selection. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 772– 778, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sawaf</author>
</authors>
<title>Arabic Dialect Handling in Hybrid Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas (AMTA 10),</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="6389" citStr="Sawaf, 2010" startWordPosition="1037" endWordPosition="1038">ared to MSA, e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowled</context>
</contexts>
<marker>Sawaf, 2010</marker>
<rawString>Hassan Sawaf. 2010. Arabic Dialect Handling in Hybrid Machine Translation. In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas (AMTA 10), Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammed Q Shatnawi</author>
<author>Muneer Bani Yassein</author>
<author>Reem Mahafza</author>
</authors>
<title>A Framework for Retrieving Arabic Documents Based on Queries Written in Arabic Slang Language.</title>
<date>2012</date>
<journal>Journal of Information Science,</journal>
<volume>38</volume>
<issue>4</issue>
<contexts>
<context position="6517" citStr="Shatnawi et al., 2012" startWordPosition="1054" endWordPosition="1057">f DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabic-based information retrieval systems (Shatnawi et al., 2012). Among the efforts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available f</context>
</contexts>
<marker>Shatnawi, Yassein, Mahafza, 2012</marker>
<rawString>Mohammed Q Shatnawi, Muneer Bani Yassein, and Reem Mahafza. 2012. A Framework for Retrieving Arabic Documents Based on Queries Written in Arabic Slang Language. Journal of Information Science, 38(4):350–365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Cyril Goutte</author>
<author>Pierre Isabelle</author>
</authors>
<title>Statistical Phrase-Based Post-Editing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL-HLT-2007 Human Language Technology: the Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>508--515</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="8645" citStr="Simard et al. (2007)" startWordPosition="1421" endWordPosition="1424">rst work in which we adapt the domain in addition to the dialect (Egyptian specifically). 3 Using Phrase-Based MT as an Adaptation System For commercial use, MT output is usually postedited by a human translator in order to fix the errors generated by the MT system. This is often faster and cheaper than having a human translate 197 the document from scratch. However, we can apply statistical phrase-based MT to create an automatic machine post-editor (what we refer to in this paper as an adaptation system) to improve the output of an MT system, and make it more closely resemble the references. Simard et al. (2007) used a phrase-based MT system as an automatic posteditor for the output of a commercial rule-based MT system, showing that it produced better results than both the rule-based system alone and a single pass phrase-based MT system. This technique is also useful for adapting to a specific domain or dataset. Isabelle et al. (2007) used a statistical MT system to automatically post-edit the output of a generic rule-based MT system, to avoid manually customizing a system dictionary and to reduce the amount of manual post-editing required. For our adaptation systems, we build a core phrase-based MT </context>
</contexts>
<marker>Simard, Goutte, Isabelle, 2007</marker>
<rawString>Michel Simard, Cyril Goutte, and Pierre Isabelle. 2007. Statistical Phrase-Based Post-Editing. In Proceedings of NAACL-HLT-2007 Human Language Technology: the Conference of the North American Chapter of the Association for Computational Linguistics, pages 508–515, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of Association for Machine Translation in the Americas,</booktitle>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="17239" citStr="Snover et al., 2006" startWordPosition="2860" endWordPosition="2863">oduced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Egyptian Arabic in this case because the domain of our datasets is very formal, since most of the text comes from news sources, and dialectal Arabic is generally used in informal situations.2 Below we report BLEU scores </context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of Association for Machine Translation in the Americas, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver, CO, USA.</location>
<contexts>
<context position="10866" citStr="Stolcke, 2002" startWordPosition="1797" endWordPosition="1798">s the “two-step” system consists of the core plus two subsequent adaptation systems. We describe the systems in more detail in Section 5. 4 Data For the core English to MSA system, we use the 5 million parallel sentences of English and MSA from NIST 2012 as the training set. The tuning set consists of 1,356 sentences from the NIST 2008 Open Machine Translation Evaluation (MT08) data (NIST Multimodal Information Group, 2010a), and the test set consists of 1,313 sentences from NIST MT09 (NIST Multimodal Information Group, 2010b). We use a 5-gram MSA language model built using the SRILM toolkit (Stolcke, 2002) on 260 million words of MSA from the Arabic Gigaword (Parker et al., 2011). All our MSA parallel data and monolingual MSA language modeling data were tokenized with MADA v3.1 (Habash and Rambow, 2005) using the ATB (Arabic Treebank) tokenization scheme. For the adaptation systems, we build a 100k tri-parallel corpus Egyptian-MSA-English corpus. The MSA and English parts are extracted from the NIST corpus distributed by the Linguistic Data Consortium. The Egyptian sentences are obtained automatically by extending Mohamed et al. (2012) method for generating Egyptian Arabic from morphologically </context>
<context position="17021" citStr="Stolcke, 2002" startWordPosition="2825" endWordPosition="2826">e best result. We also tested two different heuristics for symmetrizing the word alignments: grow-diag and grow-diag-final-and (Och and Ney, 2003). We found that using grow-diag as our symmetrization heuristic produced slightly better scores on the 100k datasets. For the baseline and adaptation systems we built 5-gram language models with KenLM (Heafield et al., 2013) using the target side of the training set, and for the core system we used the large MSA language model described in section 4. We use KenLM because it has been shown (Heafield, 2011) to be faster and use less memory than SRILM (Stolcke, 2002) and IRSTLM (Federico et al., 2008). 6 Evaluation and Results For evaluation we use multeval (Clark et al., 2011) to calculate BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), TER (Snover et al., 2006), and length of the test set for each system. We evaluate the core and adaptation systems on the MSA and Egyptian sides of the test set drawn from the 100k corpus, which we refer to as the 100k sets. The data used for evaluation is a genuine Egyptian Arabic generated from MSA, just like the data the systems were trained on. It is not practical to evaluate on naturallygenerated Eg</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - An Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing, vol. 2, pages 901–904, Denver, CO, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
<author>Chris Callison-Burch</author>
</authors>
<title>The Arabic Online Commentary Dataset: an Annotated Dataset of Informal Arabic with High Dialectal Content.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>37--41</pages>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="12145" citStr="Zaidan and Callison-Burch, 2011" startWordPosition="1991" endWordPosition="1994">thod relies on 103 transformation rules covering essentially nouns, verbs and pronouns as well as certain lexical items. For each MSA sentence, this method provides more than one possible candidate, in its original version, the Egyptian sentence kept was chosen randomly. We extend the selection algorithm by scoring the different sentences using a language model. For this, we use SRILM with modified Kneser-Ney smoothing to build a 5-gram language model. The model is trained on a corpus including articles extracted from the Egyptian version of Wikipedia1 and the Egyptian side of the AOC corpus (Zaidan and Callison-Burch, 2011). We chose to include Egyptian Wikipedia for the formal level of sentences in it different from the regular DA written in blogs or microblogging websites (e.g., Twitter) and closer to the ones generated by our system. We split this data into train, tune, and test sets of 98,027, 960, and 961 sentences respectively, after removing duplicates across sets. The MSA corpus was tokenized using MADA and the Egyptian Arabic data was tokenized with MADA-ARZ v0.4 (Habash et al., 2013), both using the ATB tokenization scheme, with alif/ya normalization. 5 System Design Figure 1 shows a diagram of our thr</context>
</contexts>
<marker>Zaidan, Callison-Burch, 2011</marker>
<rawString>Omar F. Zaidan and Chris Callison-Burch. 2011. The Arabic Online Commentary Dataset: an Annotated Dataset of Informal Arabic with High Dialectal Content. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 37–41, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rabih Zbib</author>
<author>Erika Malchiodi</author>
<author>Jacob Devlin</author>
<author>David Stallard</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>John Makhoul</author>
<author>Omar F Zaidan</author>
<author>Chris CallisonBurch</author>
</authors>
<title>Machine Translation for Arabic Dialects.</title>
<date>2012</date>
<booktitle>In Proceedings of North American Chapter of the Association for Computational Linguistics,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="1907" citStr="Zbib et al., 2012" startWordPosition="301" endWordPosition="304">, it is not the native language of any speakers of Arabic. Most native speakers are unable to produce sustained spontaneous discourse in MSA - they usually resort to repeated code-switching between their dialect and MSA (Abu-Melhim, 1991). Arabic speakers are quite aware of the contextual factors and the differences between their dialects and MSA, although they may not always be able to pinpoint exact linguistic differences. In the context of natural language processing (NLP), some Arabic dialects have started receiving increasing attention, particularly in the context of machine translation (Zbib et al., 2012; Salloum and Habash, 2013; Salloum et al., 2014; Al-Mannai et al., 2014) and in terms of data collection (Cotterell and Callison-Burch, 2014; Bouamor et al., 2014; Salama et al., 2014) and basic enabling technologies (Habash et al., 2012; Pasha et al., 2014). However, the focus is on a small number of iconic dialects, (e.g., Egyptian). The Egyptian media industry has traditionally played a dominant role in the Arab world, making the Egyptian dialect the most widely understood and used dialect. DA is now emerging as the language of informal communication online. DA differs phonologically, lexi</context>
<context position="5856" citStr="Zbib et al., 2012" startWordPosition="949" endWordPosition="952">ction 6 presents our experimental setup and the results obtained. Then, we give an analysis of our system output in Section 7. Finally, we conclude and describe our future work in Section 8. 2 Related work Machine translation (MT) for dialectal Arabic (DA) is quite challenging given the limited resources to build rule-based models or train statistical models for MT. While there has been a considerable amount of work in the context of standard Arabic NLP (Habash, 2010), DA is impoverished in terms of available tools and resources compared to MSA, e.g., there are few parallel DAEnglish corpora (Zbib et al., 2012; Bouamor et al., 2014). The majority of DA resources are for speech recognition, although more and more resources for machine translation and enabling technologies such as morphological analyzers are becoming available for specific dialects (Habash et al., 2012; Habash et al., 2013). For Arabic and its dialects, several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP. Different research work successfully translated DA to MSA as a bridge to translate to English (Sawaf, 2010; Salloum and Habash, 2013), or to enhance the performance of Arabi</context>
<context position="7152" citStr="Zbib et al. (2012)" startWordPosition="1165" endWordPosition="1168">ts on translation from DA to MSA, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic to MSA. Sajjad et al. (2013) used a dictionary of Egyptian/MSA words to transform Egyptian to MSA and showed improvement in the quality of machine translation. A similar but rule-based work was done by Mohamed et al. (2012). Boujelbane et al. (2013) and Hamdi et al. (2014) built a bilingual dictionary using explicit knowledge about the relation between Tunisian Arabic and MSA. These works are limited to a dictionary or rules that are not available for all dialects. Zbib et al. (2012) used crowdsourcing to translate sentences from Egyptian and Levantine into English, and thus built two bilingual corpora. The dialectal sentences were selected from a large corpus of Arabic web text. Then, they explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They argued that differences in genre between MSA and DA make bridging through MSA of limited value. For this reason, while pivoting through MSA, it is important to consider the domain and add an additional step: domain adaptation. The majority of previous e</context>
</contexts>
<marker>Zbib, Malchiodi, Devlin, Stallard, Matsoukas, Schwartz, Makhoul, Zaidan, CallisonBurch, 2012</marker>
<rawString>Rabih Zbib, Erika Malchiodi, Jacob Devlin, David Stallard, Spyros Matsoukas, Richard Schwartz, John Makhoul, Omar F. Zaidan, and Chris CallisonBurch. 2012. Machine Translation for Arabic Dialects. In Proceedings of North American Chapter of the Association for Computational Linguistics, Montreal, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>