<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000054">
<title confidence="0.99904">
Foreign Words and the Automatic Processing
of Arabic Social Media Text Written in Roman Script
</title>
<author confidence="0.994355">
Ramy Eskander, Mohamed Al-Badrashiny†, Nizar Habash$ and Owen Rambow
</author>
<affiliation confidence="0.988712">
Center for Computational Learning Systems, Columbia University
</affiliation>
<email confidence="0.737091">
{reskander,rambow}@ccls.columbia.edu
</email>
<affiliation confidence="0.987928">
†Department of Computer Science, The George Washington University
</affiliation>
<email confidence="0.987418">
†badrashiny@gwu.edu
</email>
<affiliation confidence="0.903618">
$Computer Science Department, New York University Abu Dhabi
</affiliation>
<email confidence="0.998146">
$nizar.habash@nyu.edu
</email>
<sectionHeader confidence="0.993889" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999940125">
Arabic on social media has all the prop-
erties of any language on social media
that make it tough for natural language
processing, plus some specific problems.
These include diglossia, the use of an
alternative alphabet (Roman), and code
switching with foreign languages. In this
paper, we present a system which can
process Arabic written in Roman alpha-
bet (“Arabizi”). It identifies whether each
word is a foreign word or one of an-
other four categories (Arabic, name, punc-
tuation, sound), and transliterates Arabic
words and names into the Arabic alphabet.
We obtain an overall system performance
of 83.8% on an unseen test set.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955438596491">
Written language used in social media shows dif-
ferences from that in other written genres: the
vocabulary is informal (and sometimes the syn-
tax is as well); there are intentional deviations
from standard orthography (such as repeated let-
ters for emphasis); there are typos; writers use
non-standard abbreviations; non-linguistic sounds
are written (haha); punctuation is used creatively;
non-linguistic signs such as emoticons often com-
pensate for the absence of a broader communica-
tion channel in written communication (which ex-
cludes, for example, prosody or visual feedback);
and, most importantly for this paper, there fre-
quently is code switching. These facts pose a well-
known problem for natural language processing of
social media texts, which has become an area of
interest as applications such as sentiment analy-
sis, information extraction, and machine transla-
tion turn to this genre.
This situation is exacerbated in the case of Ara-
bic social media. There are three principal rea-
sons. First, the Arabic language is a collection of
varieties: Modern Standard Arabic (MSA), which
is used in formal settings, and different forms of
Dialectal Arabic (DA), which are commonly used
informally. This situation is referred to as “diglos-
sia”. MSA has a standard orthography, while
the dialects do not. What is used in Arabic so-
cial media is typically DA. This means that there
is no standard orthography to begin with, result-
ing in an even broader variation in orthographic
forms found. Diglossia is seen in other linguistic
communities as well, including German-speaking
Switzerland, in the Czech Republic, or to a some-
what lesser extent among French speakers. Sec-
ond, while both MSA and DA are commonly writ-
ten in the Arabic script, DA is sometimes writ-
ten in the Roman script. Arabic written in Roman
is often called “Arabizi”. It is common in other
linguistic communities as well to write informal
communication in the Roman alphabet rather than
in the native writing system, for example, among
South Asians. And third, educated speakers of
Arabic are often bilingual or near-bilingual speak-
ers of another language as well (such as English
or French), and will code switch between DA and
the foreign language in the same utterance (and
sometimes MSA as well). As is well known, code
switching is common in many linguistic commu-
nities, for example among South Asians.
In this paper, we investigate the issue of pro-
cessing Arabizi input with code switching. There
are two tasks: identification of tokens that are
not DA or MSA (and should not be transliterated
into Arabic script for downstream processing), and
then the transliteration into Arabic script of the
parts identified as DA or MSA. In this paper, we
</bodyText>
<page confidence="0.825843">
1
</page>
<note confidence="0.8640235">
Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 1–12,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999962266666667">
use as a black box an existing component that we
developed to transliterate from Arabizi to Arabic
script (Al-Badrashiny et al., 2014). This paper
concentrates on the task of identifying which to-
kens should be transliterated. A recent release
of annotated data by the Linguistic Data Consor-
tium (LDC, 2014c; Bies et al., 2014) has enabled
novel research on this topic. The corpus pro-
vides each token with a tag, as well as a translit-
eration if appropriate. The tags identify foreign
words, as well as Arabic words, names, punctua-
tion, and sounds. Only Arabic words and names
are transliterated. (Note that code switching is not
distinguished from borrowing.) Emoticons, which
may be isolated or part of an input token, are also
identified, and converted into a conventional sym-
bol (#). This paper presents taggers for the tags,
and an end-to-end system which takes Arabizi in-
put and produces a complex output which consists
of a tag for each input token and a transliteration
of Arabic words and names into the Arabic script.
To our knowledge, this is the first system that han-
dles the complete task as defined by the LDC data.
This paper focuses on the task of identifying for-
eign words (as well as the other tags), on creating
a single system, and on evaluating the system as a
whole.
This paper makes three main contributions.
First, we clearly define the computational prob-
lem of dealing with social media Arabizi, and pro-
pose a new formulation of the evaluation metric
for the LDC corpus. Second, we present novel
modules for the detection of foreign words as well
as of emoticons, sounds, punctuation marks, and
names in Arabizi. Third, we compose a single sys-
tem from the various components, and evaluate the
complete system.
This paper is structured as follows. We start by
presenting related work (Section 2), and then we
present relevant linguistic facts and explain how
the data is annotated (Section 3). After summariz-
ing our system architecture (Section 4) and exper-
imental setup (Section 5), we present our systems
for tagging in Sections 6, 7 and 8. The evaluation
results are presented in Section 9.
</bodyText>
<sectionHeader confidence="0.999851" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999590070175439">
While natural language processing for English in
social media has attracted considerable attention
recently (Clark and Araki, 2011; Gimpel et al.,
2011; Gouws et al., 2011; Ritter et al., 2011; Der-
czynski et al., 2013), there has not been much
work on Arabic yet. We give a brief summary of
relevant work on Arabic.
Darwish et al. (2012) discuss NLP problems in
retrieving Arabic microblogs (tweets). They dis-
cuss many of the same issues we do, notably the
problems arising from the use of DA such as the
lack of a standard orthography. However, they do
not deal with DA written in the Roman alphabet
(though they do discuss non-Arabic characters).
There is some work on code switching be-
tween Modern Standard Arabic (MSA) and di-
alectal Arabic (DA). Zaidan and Callison-Burch
(2011) are interested in this problem at the inter-
sentence level. They crawl a large dataset of
MSA-DA news commentaries. They use Ama-
zon Mechanical Turk to annotate the dataset at the
sentence level. Then they use a language model-
ing approach to predict the class (MSA or DA)
for an unseen sentence. There is other work on
dialect identification, such as AIDA (Elfardy et
al., 2013; Elfardy et al., 2014). In AIDA, some
statistical and morphological analyses are applied
to capture code switching between MSA and DA
within the same sentence. Each word in the sen-
tence is tagged to be either DA or MSA based
on the context. The tagging process mainly de-
pends on the language modeling (LM) approach,
but if a word is unknown in the LM, then its tag is
assigned through MADAMIRA, a morphological
disambiguator Pasha et al. (2014).
Lui et al. (2014) proposed a system that does
language identification in multilingual documents,
using a generative mixture model that is based
on supervised topic modeling algorithms. This is
similar to our work in terms of identifying code
switching. However, our system deals with Ara-
bizi, a non-standard orthography with high vari-
ability, making the identification task much harder.
Concerning specifically NLP for Arabizi, Dar-
wish (2013) (published in an updated version as
(Darwish, 2014)) is similar to our work in that
he identifies English in Arabizi text and he also
transliterates Arabic text from Arabizi to Arabic
script. We compare our transliteration method to
his in Al-Badrashiny et al. (2014). For identifi-
cation of non-Arabic words in Arabizi, Darwish
(2013) uses word and sequence-level features with
CRF modeling; while we use SVMs and decision
trees. Darwish (2013) identifies three tags: Ara-
bic, foreign and others (such as email addresses
and URLs). In contrast, we identify a bigger
set: Arabic, foreign, names, sounds, punctuation
</bodyText>
<page confidence="0.98831">
2
</page>
<bodyText confidence="0.996506761904762">
and emoticons. Furthermore, Darwish (2013) uses
around 5K words for training his taggers and 3.5K
words for testing; this is considerably smaller than
our training and test sets of 113K and 32K words,
respectively.
Chalabi and Gerges (2012) presented a hybrid
approach for Arabizi transliteration. Their work
does not address the detection of English words,
punctuation, emoticons, and so on. They also do
not handle English when mixed with Arabizi.
Voss et al. (2014) deal with exactly the prob-
lem of classifying tokens in Arabizi as Arabic or
not. More specifically, they deal with Moroccan
Arabic, and with both French and English, mean-
ing they do a three-way classification. There are
many differences between our work and theirs:
they have noisy training data, and they have a
much more balanced test set. They also only deal
with foreignness, and do not address the other tags
we deal with, nor do they actually discuss translit-
eration itself.
</bodyText>
<sectionHeader confidence="0.7313" genericHeader="method">
3 Linguistic Facts and Data Annotation
</sectionHeader>
<subsectionHeader confidence="0.996135">
3.1 Arabizi
</subsectionHeader>
<bodyText confidence="0.99254428">
Arabizi refers to Arabic written using the Roman
script (Darwish, 2013; Voss et al., 2014). Ara-
bizi orthography is spontaneous and has no stan-
dard references, although there are numerous com-
monly used conventions making specific usage of
the so-called Arabic numerals and punctuation in
addition to Roman script letters. Arabizi is com-
monly used by Arabic speakers to write mostly in
dialectal Arabic in social media, SMS and chat ap-
plications.
Arabizi orthography decisions mainly depend
on a phoneme-to-grapheme mapping between the
Arabic pronunciation and the Roman script. This
is largely based on the phoneme-to-grapheme
mapping used in English (in Middle Eastern Arab
countries) or French (in Western North African
Arab countries). Since there is no standard or-
thography for Arabizi, it is not a simple translit-
eration of Arabic. For example, in Arabizi, words
omit vowels far less frequently than is done when
writers follow standard Arabic orthography. Fur-
thermore, there are several cases of many-to-many
mappings between Arabic phonemes and Roman
script letters: for example, the letter “t” is used to
represent the sound of the Arabic letters H~ t1 and
</bodyText>
<footnote confidence="0.889456">
1Arabic transliteration is presented in the Habash-Soudi-
Buckwalter scheme (Habash et al., 2007): (in alphabetical
</footnote>
<bodyText confidence="0.999541473684211">
T (which itself can be also be represented using
the digit “6”).
Text written in Arabizi also tends to have a large
number of foreign words, that are either borrow-
ings such as telephone, or code switching, such
as love you!. Note that Arabizi often uses the
source language orthography for borrowings (es-
pecially recent borrowings), even if the Arabic
pronunciation is somewhat modified. As a re-
sult, distinguishing borrowings from code switch-
ing is, as is usually the case, hard. And, as in any
language used in social media and chat, Arabizi
may also include abbreviations, such as isa which
means é&lt;Ë@ ZAƒ~ v@� ˇAn šA’ Allh ‘God willing’ and
lol ‘laugh out loud’.
The rows marked with Arabizi in Figure 1
demonstrate some of the salient features of Ara-
bizi. The constructed example in the figure is of
an SMS conversation in Egyptian Arabic.
</bodyText>
<subsectionHeader confidence="0.998874">
3.2 Data Annotation
</subsectionHeader>
<bodyText confidence="0.9746660625">
The data set we use in this paper was created by
the Linguistic Data Consortium (Bies et al., 2014;
LDC, 2014a; LDC, 2014b; LDC, 2014c). We
summarize below the annotation decisions. The
system we present in this paper aims at predicting
exactly this annotation automatically. The input
text is initially segregated into Arabic script and
Arabizi. Arabic script text is not modified in any
way. Arabizi text undergoes two sets of annotation
decisions: Arabizi word tagging and Arabizi-to-
Arabic transliteration. All of the Arabizi annota-
tions are initially done using an automatic process
(Al-Badrashiny et al., 2014) and then followed by
manual correction and validation.
Arabizi Word Tagging Each Arabizi word re-
ceives one of the following five tags:
</bodyText>
<listItem confidence="0.624354571428571">
• Foreign All words from languages other than
Arabic are tagged as Foreign if they would
be kept in the same orthographic form when
translated into their source language (which
in our corpus is almost always English).
Thus, non-Arabic words that include Arabic
affixes are not tagged as Foreign. The defini-
tion of “foreign” thus means that uninflected
borrowings spelled as in the source language
orthography are tagged as “foreign”, while
borrowings that are spelled differently, as
well as borrowing that have been inflected
order) AbtOjHxdðrzsšSDT ˇDSγfqklmnhwy and the additional
symbols: ’ Z, Â 1, Aˇ@�, A¯�@, wˆj , yˆZø , ¯h o, ý ø.
</listItem>
<page confidence="0.990725">
3
</page>
<table confidence="0.992431814814815">
Arabizi Youmna i need to know anti gaya wala la2 ?
Tag
Arabic
English
Name Foreign Foreign Foreign Foreign Arabic Arabic Arabic Arabic Punct
� y c
������ �� ��� ������ ������� ��
� æÖß� �� � �
ymný Ay nyd tw nw Anty jAy¯h wlA lÂ ?
Youmna I need to know you coming or not ?
Arabizi Mmmm ok ana 7aseb el sho3’l now w ageelk isa :-)
Tag
Arabic
English
Sound Foreign Arabic Arabic Arabic Arabic Foreign Arabic Arabic Arabic Arabic
ÕÜØ ������ e,} - #
mmm Awkyh AnA HAs nAw w[+] Ajy[-Ili An[-]šA’[-]Allh :-)
mmm OK I will-leave the work now and I-come-to-you God-willing
#
Arabizi qishta!:D
Tag
Arabic
English
Arabic
#[-]� ��� ����
qšT¯h![-]#
cream!:D (slang for cool!)
</table>
<figureCaption confidence="0.96358425">
Figure 1: A short constructed SMS conversation written in Arabizi together with annotation of word
tags and transliteration into Arabic script. A Romanized transliteration of the Arabic script and English
glosses are provided for clarity. The cells with gray background are the parts of the output that we
evaluate.
</figureCaption>
<bodyText confidence="0.9980878">
following Arabic morphology, are not tagged
as “foreign” (even if the stem is spelled as in
the source language, such as Almobile). The
Arabic transliterations of these words are not
manually corrected.
</bodyText>
<listItem confidence="0.83470092">
• Punct Punctuation marks are a set of conven-
tional signs that are used to aid interpretation
by indicating division of text into sentences
and clauses, etc. Examples of punctuation
marks are the semicolon ;, the exclamation
mark ! and the right brace }. Emoticons are
not considered punctuation and are handled
as part of the transliteration task discussed
below.
• Sound Sounds are a list of interjections that
have no grammatical meaning, but mimic
non-linguistic sounds that humans make, and
that often signify emotions. Examples of
sounds are hahaha (laughing), hmm (wonder-
ing) and eww (being disgusted). It is common
to stretch sounds out to make them stronger,
i.e., to express more intense emotions. For
example, hmm could be stretched out into
hmmmmm to express a stronger feeling of
wondering. The Arabic transliterations of
these words are not manually corrected.
• Name Proper names are tagged as such and
later manually corrected.
• Arabic All other words are tagged as Arabic
and are later manually corrected.
</listItem>
<bodyText confidence="0.999902888888889">
See the rows marked with Tag in Figure 1 for
examples of these different tags. It is impor-
tant to point out that the annotation of this data
was intended to serve a project focusing on ma-
chine translation from dialectal Arabic into En-
glish. This goal influenced some of the annotation
decisions and was part of the reason for this selec-
tion of word tags.
Arabizi-to-Arabic Transliteration The second
annotation task is about converting Arabizi to an
Arabic-script-based orthography. Since, dialectal
Arabic including Egyptian Arabic has no standard
orthography in Arabic script, the annotation uses a
conventionalized orthography for Dialectal Arabic
called CODA (Habash et al., 2012a; Eskander et
al., 2013; Zribi et al., 2014). Every word has a
single orthographic representation in CODA.
In the corpus we use, only words tagged as
Arabic or Name are manually checked and cor-
rected. The transliteration respects the white-
space boundaries of the original Arabizi words. In
cases where an Arabizi word represents a prefix
or suffix that should be joined in CODA to the
next or previous word, a [+] symbol is added to
mark this decision. Similarly, for Arabizi words
that should be split into multiple CODA words,
the CODA words are written with added [-] sym-
bol delimiting the word boundaries.
The Arabic transliteration task also includes
handling emoticons. Emoticons are digital icons
or sequences of keyboard symbols serving to rep-
resent facial expressions or to convey the writer’s
emotions. Examples of emoticons are :d, :-(, O.O
and Q used to represent laughing, sadness, being
surprised and positive emotion, respectively. All
emoticons, whether free-standing or attached to a
</bodyText>
<page confidence="0.989788">
4
</page>
<bodyText confidence="0.999967071428571">
word, are replaced by a single hash symbol (#).
Free-standing emoticons are tagged as Arabic. At-
tached emoticons are not tagged separately; the
word they are attached to is tagged according to
the usual rules. See Figure 1 for examples of these
different decisions.
Since words tagged as Foreign, Punct, or Sound
are not manually transliterated in the corpus, in
our performance evaluation we combine the de-
cisions of tags and transliteration. For foreign
words, punctuation and sounds, we only consider
the tags for accuracy computations; in contrast, for
names and Arabic words, we consider both the tag
and transliteration.
</bodyText>
<sectionHeader confidence="0.982979" genericHeader="method">
4 System Architecture
</sectionHeader>
<bodyText confidence="0.995784">
Figure 2 represent the overall architecture of our
system. We distinguish below between existing
components that we use and novel extensions that
we contribute in this paper.
</bodyText>
<subsectionHeader confidence="0.998066">
4.1 Existing Arabization System
</subsectionHeader>
<bodyText confidence="0.999928875">
For the core component of Arabizi-to-Arabic
transliteration, we use a previously published sys-
tem (Al-Badrashiny et al., 2014), which converts
Arabizi into Arabic text following CODA conven-
tions (see Section 3). The existing system uses a
finite state transducer trained on 8,500 Arabizi-to-
Arabic transliteration pairs at the character level to
obtain a large number of possible transliterations
for the input Arabizi words. The generated list is
then filtered using a dialectal Arabic morphologi-
cal analyzer. Finally, the best choice for each input
word is selected using a language model. We use
this component as a black box except that we re-
train it using additional training data. In Figure 2,
this component is represented using a central black
box.
</bodyText>
<subsectionHeader confidence="0.985653">
4.2 Novel Extension
</subsectionHeader>
<bodyText confidence="0.9999821875">
In this paper, we add Word Type Tagging as a
new set of modules. We tag the Arabizi words into
five categories as discussed above: Arabic, For-
eign, Names, Sounds, and Punctuation. Figure 2
illustrates the full proposed system. First, we pro-
cess the Arabizi input to do punctuation and sound
tagging, along with emoticon detection. Then we
run the transliteration system to produce the cor-
responding Arabic transliteration. The Arabizi in-
put and Arabic output are then used together to
do name tagging and foreign word tagging. The
Arabic tag is assigned to all untagged words, i.e.,
words not tagged as Foreign, Names, Sounds, or
Punctuation. The outputs from all steps are then
combined to produce the final Arabic translitera-
tion along with the tag.
</bodyText>
<sectionHeader confidence="0.999571" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.998558">
5.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.999934">
We define the following sets of data:
</bodyText>
<listItem confidence="0.998390454545455">
• Train-S: A small size dataset that is used to
train all taggers in all experiments to deter-
mine the best performing setup (feature engi-
neering).
• Train-L: A larger size dataset that is used to
train the best performing setup.
• Dev: The development set that is used to
measure the system performance in all exper-
iments
• Test: A blind set that is used to test the best
system (LDC, 2014a).
</listItem>
<bodyText confidence="0.9999154">
The training and development sets are extracted
from (LDC, 2014b). Table 1 represents the tags
distribution in each dataset. Almost one of every
five words is not Arabic text and around one of
every 10 words is foreign.
</bodyText>
<sectionHeader confidence="0.6758955" genericHeader="method">
5.2 Arabizi-to-Arabic Transliteration
Accuracy
</sectionHeader>
<bodyText confidence="0.999939130434783">
For the Arabizi-to-Arabic transliteration system,
we report on using the two training data sets
with two modifications. First, we include the
8,500 word pairs from Al-Badrashiny et al. (2014),
namely 2,200 Arabizi-to-Arabic script pairs from
the training data used by Darwish (2013) (man-
ually revised to be CODA-compliant) and about
6,300 pairs of proper names in Arabic and En-
glish from the Buckwalter Arabic Morphologi-
cal Analyzer (Buckwalter, 2004). (Since these
pairs are not tagged, we do not use them to train
the taggers.) Second, we exclude all the foreign
tagged words from training the transliteration sys-
tem since they were not manually corrected.
Table 2 shows the overall transliteration accu-
racy of Arabic words and names only, using dif-
ferent training data sets and evaluating on Dev
(as determined by the gold standard). The ac-
curacy when using the original Arabizi-to-Arabic
transliteration system from Al-Badrashiny et al.
(2014) gives an accuracy of 68.6%. Retraining it
on Train-S improves the accuracy to 76.9%. The
accuracy goes up further to 79.5% when using the
</bodyText>
<page confidence="0.833907">
5
</page>
<figure confidence="0.999092133333333">
Arabizi
Punctuation,
Sound &amp;
Emoticon
Detection
Foreign Word
Tagger
Arabizi-to-Arabic
Transliteration
Name Tagger
Combiner
Arabic
&amp;
Tagged
Arabizi
</figure>
<figureCaption confidence="0.807967666666667">
Figure 2: The architecture of our complete Arabizi processing system. The &amp;quot;Punctuation, Sound and
Emoticon Detection&amp;quot; component does labeling that is read by the &amp;quot;Name&amp;quot; and &amp;quot;Foreign Word&amp;quot; taggers,
While the actual Aribizi-to-Arabic transliteration system is used as a black box.
</figureCaption>
<table confidence="0.999921">
Data # Words Arabic Foreign Name Sound Punct Emoticon
Train-S 21,950 80.5% 12.1% 2.8% 1.7% 1.3% 1.6%
Train-L 113,490 82.3% 9.8% 2.4% 1.8% 1.1% 2.6%
Dev 5,061 76.3% 16.2% 2.9% 1.8% 1.2% 1.5%
Test 31,717 86.1% 6.0% 2.7% 1.6% 0.9% 2.8%
</table>
<tableCaption confidence="0.906138">
Table 1: Dataset Statistics
</tableCaption>
<table confidence="0.9998465">
Data Translit. Acc.
Al-Badrashiny et al. (2014) 68.6%
Train-S 76.9%
Train-L 79.5%
</table>
<tableCaption confidence="0.793186">
Table 2: Transliteration accuracy of Arabic words
and names when using different training sets and
evaluating on Dev
</tableCaption>
<bodyText confidence="0.766054333333333">
bigger training set Train-L. The overall transliter-
ation accuracy of Arabic words and names on Test
using the bigger training set Train-L is 83.6%.
</bodyText>
<sectionHeader confidence="0.99833" genericHeader="method">
6 Tagging Punctuation, Emoticons and
Sounds
</sectionHeader>
<subsectionHeader confidence="0.998606">
6.1 Approach
</subsectionHeader>
<bodyText confidence="0.999926444444444">
We start the tagging process by detecting three
types of closed classes: punctuation, sounds and
emoticons. Simple regular expressions perform
very well at detecting their occurrence in text. The
regular expressions are applied to the Arabizi in-
put, word by word, after lower-casing, since both
emoticons and sounds could contain either small
or capital letters.
Since emoticons can be composed of just con-
catenated punctuation marks, their detection is re-
quired before punctuation is tagged. Once de-
tected, emoticons are replaced by #. Then punctu-
ation marks are detected. If a non-emoticon word
is only composed of punctuation marks, then it
gets tagged as Punct. Sounds are targeted next.
A word gets tagged as Sound if it matches the
sound detection expression, after stripping out any
attached punctuation marks and/or emoticons.
</bodyText>
<subsectionHeader confidence="0.820707">
6.2 Results
</subsectionHeader>
<bodyText confidence="0.999875533333333">
Table 6 in Section 9 shows the accuracy, recall,
precision and F-score for the classification of the
Punct and Sound tags and detection of emoticons.
Since emoticons can be part of another word, and
in that case do not receive a specific tag (as spec-
ified in the annotation guidelines by the LDC),
emoticon evaluation is concerned with the num-
ber of detected emoticons within an Arabizi word,
as opposed to a binary tagging decision. In other
words, emoticon identification is counted as cor-
rect (“positive”) if the number of detected emoti-
cons in a word is correct in the test token. The
Punct and Sound tags represent standard binary
classification tasks and are evaluated in the usual
way.
</bodyText>
<sectionHeader confidence="0.946216" genericHeader="method">
7 Tagging Names
</sectionHeader>
<subsectionHeader confidence="0.958981">
7.1 Approach
</subsectionHeader>
<bodyText confidence="0.9998102">
We consider the following set of binary features
for learning a model of name tagging. The fea-
tures are used either separately or combined using
a modeling classifier implemented with decision
trees.
</bodyText>
<listItem confidence="0.9724805">
• Capitalization A word is considered a name
if the first letter in Arabizi is capitalized.
</listItem>
<page confidence="0.902309">
6
</page>
<listItem confidence="0.989245892857143">
• MADAMIRA MADAMIRA is a system for
morphological analysis and disambiguation
of Arabic (Pasha et al., 2014). We run
MADAMIRA on the Arabic output after run-
ning the Arabizi-to-Arabic transliteration. If
the selected part-of-speech (POS) of a word
is proper noun (NOUN_PROP), then the
word is tagged as Name.
• CALIMA CALIMA is a morphological an-
alyzer for Egyptian Arabic (Habash et al.,
2012b). If the Arabic transliteration of a
given Arabizi word has a possible proper
noun analysis in CALIMA, then the word is
tagged as Name.
• Maximum Likelihood Estimate (MLE) An
Arabizi word gets assigned the Name tag if
Name is the most associated tag for that word
in the training set.
• Tharwa Tharwa is a large scale Egyptian
Arabic-MSA-English lexicon that includes
POS tag information (Diab et al., 2014). If
an Arabizi word appears in Tharwa as an En-
glish gloss with a proper noun POS, then it is
tagged as Name.
• Name Language Model We use a list of
280K unique lower-cased English words as-
sociated with their probability of appearing
capitalized (Habash, 2009). When using this
</listItem>
<bodyText confidence="0.978878">
feature, any probability that is not equal to
one is rounded to zero.
All the features above are modeled after case-
lowering the Arabizi input, and removing speech
effects. Any attached punctuation marks and/or
emoticons are stripped out. One exception is the
capitalization feature, where the case of the first
letter of the Arabizi word is preserved. The tech-
niques above are then combined together using de-
cision trees. In this approach, the words tagged as
Name are given a weight that balances their infre-
quent occurrence in the data.
</bodyText>
<sectionHeader confidence="0.503777" genericHeader="method">
7.2 Results
</sectionHeader>
<bodyText confidence="0.999718125">
Table 3 shows the performance of the Name tag-
ging on Dev using Train-S. The best results are
obtained when looking up the MLE value in the
training data, with an accuracy and F-score of
97.8% and 56.0%, respectively. When using
Train-L, the accuracy and F-score given by MLE
go up to 98.1% and 63.9%, respectively. See Ta-
ble 6. The performance of the combined approach
</bodyText>
<table confidence="0.999908">
Feature Accuracy Recall Precision F-Score
Capitalization 85.6 28.3 6.4 10.4
MADAMIRA 95.9 24.8 28.3 26.5
CALIMA 86.3 50.3 10.9 17.9
MLE 97.8 46.9 69.4 56.0
THARWA 96.3 22.8 33.0 26.9
NAME-LM 84.5 30.3 6.3 10.4
All Combined 97.7 49.7 63.2 55.6
(Decision Trees)
</table>
<tableCaption confidence="0.999782">
Table 3: Name tagging results on Dev with Train-S
</tableCaption>
<bodyText confidence="0.99715725">
does not outperform the most effective single clas-
sifier, MLE. This is because adding other features
decreases the precision by an amount that exceeds
the increase in the recall.
</bodyText>
<sectionHeader confidence="0.975329" genericHeader="method">
8 Tagging Foreign Words
</sectionHeader>
<bodyText confidence="0.999994363636364">
As shown earlier, around 10% of all words in Ara-
bizi text are foreign, mostly English in our data set.
Tagging foreign words is challenging since there
are many words that can be either Arabic (in Ara-
bizi) or a word in a foreign languages. For exam-
ple the Arabizi word mesh can refer to the English
reading or the Arabic word :va mš ‘not’. There-
fore, simple dictionary lookup is not sufficient to
determine whether a word is Arabic or Foreign.
Our target in this section is to identify the foreign
words in the input Arabizi text .
</bodyText>
<subsectionHeader confidence="0.983594">
8.1 Baseline Experiments
</subsectionHeader>
<bodyText confidence="0.999552">
We define a foreignness index formula that gives
each word a score given its unigram probabili-
ties against Arabic and English language models
(LMs).
</bodyText>
<equation confidence="0.998116">
E (w) = αPE (w) + (1 − α) (1 − PA (wt)) (1)
</equation>
<bodyText confidence="0.99371425">
ε(w) is the foreignness score of the Arabizi word
w. PE(w) is the unigram probability of w in the
English LM, and PA(wt) is the unigram proba-
bility in the Arabic LM of the transliteration into
Arabic (wt) proposed by our system for the Ara-
bizi word w. α is a tuning parameter varying from
zero to one. From equation 1 we define the mini-
mum and maximum ε values as follows:
</bodyText>
<equation confidence="0.998707">
Emin = αPEmin + (1 − α) (1 − PAmax) (2)
Emax = αPEmax + (1 − α) (1 − PAmin)
</equation>
<bodyText confidence="0.991446">
Where PEmin and PEmax are the minimum and
maximum uni-gram probabilities in the English
LM. And PAmin and PAmax are the minimum
</bodyText>
<page confidence="0.998778">
7
</page>
<bodyText confidence="0.999191875">
and maximum uni-gram probabilities in the Ara-
bic LM. The foreignness index Foreignness(w)
is the normalized foreignness score derived using
equations 1 and 2 as follow:
If the foreignness index of a word is higher than
a certain threshold Q, we consider the word For-
eign. We define three baseline experiments as fol-
lows:
</bodyText>
<listItem confidence="0.9750948">
• FW-index-manual: Use brute force search
to find the best α and Q that maximize the
foreign words tagging on Dev.
• FW-index-SVM: Use the best α from above
and train an SVM model using the foreign-
ness index as sole feature. Then use this
model to classify each word in Dev.
• LM-lookup: The word is said to be Foreign
if it exists in the English LM and does not
exist in the Arabic LM.
</listItem>
<subsectionHeader confidence="0.996165">
8.2 Machine Learning Experiments
</subsectionHeader>
<bodyText confidence="0.9998474">
We conducted a suite of experiments by train-
ing different machine learning techniques using
WEKA (Hall et al., 2009) on the following groups
of features. We performed a two-stage feature ex-
ploration, where we did an exhaustive search over
all features in each group in the first phase, and
then exhaustively searched over all retained fea-
ture groups. In addition, we also performed an ex-
haustive search over all features in the first three
groups.
</bodyText>
<listItem confidence="0.996732888888889">
• Word n-gram features: Run the input Ara-
bizi word through an English LM and the cor-
responding Arabic transliteration through an
Arabic LM to get the set of features that are
defined in &amp;quot;Group1&amp;quot; in Table 4. Then find the
best combination of features that maximizes
the F-score on Dev.
• FW-char-n-gram features: Run the input
Arabizi word through a character-level n-
gram LM of the Arabizi words that are tagged
as foreign in the training data. We get the set
of features that are defined in &amp;quot;Group2&amp;quot; in Ta-
ble 4. Then find the best feature combination
from this group that maximizes the F-score
on Dev.
• AR-char-n-gram features: Run the input
Arabizi word through a character-level n-
gram LM of the Arabizi words that are tagged
</listItem>
<table confidence="0.7923834">
Group Description
Group1 Uni and bi-grams probabilities from English and
Arabic LMs
Group2 1,2,3,4, and 5 characters level n-grams of foreign
words
Group3 1,2,3,4, and 5 characters level n-grams of Arabic
words
Group4 Use the Arabizi word itself as a feature
Was the input Arabizi word tagged as foreign in
the gold training data?
Was the input Arabizi word tagged as Arabic in the
gold training data?
Group5 Does the input word has speech effects?
Word length
Is the Arabizi word capitalized?
</table>
<tableCaption confidence="0.968649833333333">
Table 4: List of the different features that are used
in the foreign word tagging
as non-foreign in the training data. We get the
set of features that are defined in &amp;quot;Group3&amp;quot; in
Table 4. Then find the best feature that maxi-
mizes the F-score on Dev.
</tableCaption>
<listItem confidence="0.99299145">
• Word identity: Use the input Arabizi word
to get all features that are defined in &amp;quot;Group4&amp;quot;
in Table 4. Then find the best combination of
features that maximizes the F-score on Dev.
• Word properties: Use the input Arabizi
word to get all features that are defined in
&amp;quot;Group5&amp;quot; in Table 4. Then find the best com-
bination of features that maximizes the F-
score on Dev.
• Best-of-all-groups: Use the best selected set
of features from each of the above experi-
ments. Then find the best combination of
these features that maximizes the F-score on
Dev.
• All-features: Use all features from all
groups.
• Probabilistic-features-only: Find the best
combination of features from &amp;quot;Group1&amp;quot;,
&amp;quot;Group2&amp;quot;, and &amp;quot;Group3&amp;quot; in Table 4 that max-
imizes the F-score on Dev.
</listItem>
<subsectionHeader confidence="0.79413">
8.3 Results
</subsectionHeader>
<bodyText confidence="0.999866777777778">
Table 5 shows the results on Dev using Train-S.
It can be seen that the decision tree classifier is
doing better than the SVM except in the &amp;quot;Word
properties&amp;quot; and &amp;quot;All-features&amp;quot; experiments. The
best performing setup is &amp;quot;Probabilistic-features-
only&amp;quot; with decision trees which has 87.3% F-
score. The best selected features are EN-Unigram,
AR-char-2-grams, FW-char-1-grams, FW-char-2-
grams, FW-char-5-grams.
</bodyText>
<figure confidence="0.52301325">
E (w) − Emin
Foreignness (w) =
Emax − Emin
(3)
</figure>
<page confidence="0.990116">
8
</page>
<table confidence="0.999852739130435">
Experiment Recall Precision F-Score Classifier Selected Features
LM-lookup 7.6 95.4 14.1
FW-index-manual 75.0 51.0 60.7 α =0.8 , β = 0.23
FW-index-SVM 4.0 89.0 7.7 SVM
Word n-gram features 76.7 73.2 74.9 SVM AR-unigram, EN-unigram
AR-char-n-gram features 55.4 34.8 42.8 AR-char-4-grams
FW-char-n-gram features 42.4 52.2 46.8 FW-char-3-grams
Word properties 2.4 28.6 4.5 Has-speech-effect, Word-length, Is-capitalized
Word identity 70.3 63.0 66.4 FW-tagged-list
Best-of-all-groups 82.1 76.1 79.0 AR-unigram, EN-unigram, Word-length
All-features 69.4 87.7 77.5 All features from all groups
Probabilistic-features-only 84.5 80.6 82.5 AR-unigram, EN-unigram, AR-char-3-grams, FW-
char-3-grams
Word n-gram features 82.8 80.5 81.6 Decision-Tree AR-unigram, EN-unigram
AR-char-n-gram features 80.6 63.2 70.8 AR-char-5-grams
FW-char-n-gram features 73.8 76.3 75.0 FW-char-3-grams
Word properties 1.9 25.4 3.6 Has-speech-effect, Word-length
Word identity 73.2 60.9 66.5 FW-tagged-list
Best-of-all-groups 87.0 81.5 84.1 AR-unigram, EN-unigram, AR-char-5-grams, FW-
char-3-grams
All-features 92.0 53.4 67.6 All features from all groups
Probabilistic-features- 89.9 84.9 87.3 EN-Unigram, AR-char-2-grams, FW-char-1-
only grams, FW-char-2-grams, FW-char-5-grams
</table>
<tableCaption confidence="0.998707">
Table 5: Foreign words tagging results on Dev in terms of F-score (%).
</tableCaption>
<sectionHeader confidence="0.928868" genericHeader="method">
9 System Evaluation
</sectionHeader>
<subsectionHeader confidence="0.99909">
9.1 Development and Blind Test Results
</subsectionHeader>
<bodyText confidence="0.999759882352941">
We report the results on Dev using Train-L and
with the best settings determined in the previous
three sections. Table 6 summarizes the recall, pre-
cision and F-score results for the classification of
the Punct, Sound, Foreign, Name and Arabic tags,
in addition to emoticon detection.
We report our results on Test, our blind test
set, using Train-L and with the best settings de-
termined in the previous three sections in Table 7.
The punctuation, sounds and emoticons have
high F-scores but lower than expected. This is
likely due to the limitations of the regular expres-
sions used. The performance on these tags drops
further on the test set. A similar drop is seen for
the Foreign tag. Name is the hardest tag overall.
But it performs slightly better in test compared to
the development set, and so does the Arabic tag.
</bodyText>
<table confidence="0.99939775">
Tag Accuracy Recall Precision F-Score
Punct 99.8 100.0 88.7 94.0
Sound 99.4 93.5 78.9 85.6
Foreign 95.8 91.6 84.0 87.6
Name 98.1 57.5 71.8 63.9
Arabic 94.5 95.6 97.3 96.4
Emoticon 100.0 97.5 98.7 98.1
Detection
</table>
<tableCaption confidence="0.980391">
Table 6: Tagging results on Dev using Train-L
</tableCaption>
<table confidence="0.99993725">
Tag Accuracy Recall Precision F-Score
Punct 99.8 98.2 80.1 88.3
Sound 99.3 87.4 74.2 80.3
Foreign 96.5 92.3 64.3 75.8
Name 98.6 53.7 90.2 67.3
Arabic 95.4 96.3 98.5 97.4
Emoticon 99.2 85.3 93.6 89.3
Detection
</table>
<tableCaption confidence="0.999139">
Table 7: Tagging results on Test using Train-L
</tableCaption>
<subsectionHeader confidence="0.989245">
9.2 Overall System Evaluation
</subsectionHeader>
<bodyText confidence="0.859027833333333">
In this subsection we report on evaluating the over-
all system accuracy. This includes the correct tag-
ging and Arabizi to Arabic transliteration. How-
ever, since there is no manually annotated gold
transliteration for foreign words, punctuation, or
sounds into Arabic, we cannot compare the system
transliteration of foreign words to the gold translit-
eration. Thus, we define the following metric to
judge the overall system accuracy.
Overall System Accuracy Metric A word is
said to be correctly transliterated according to the
following rules:
1. If the gold tag is anything other than Arabic
and Name, the produced tag must match the
gold tag.
2. If the gold tag is either Arabic or Name, the
produced tag and the produced transliteration
must both match the gold.
</bodyText>
<page confidence="0.988856">
9
</page>
<table confidence="0.998977666666667">
Data Baseline Accuracy System Accuracy
Dev 65.7% 82.5%
Test 76.8% 83.8%
</table>
<tableCaption confidence="0.986234">
Table 8: Baseline vs. System Accuracy
</tableCaption>
<table confidence="0.999706428571429">
Tag Gold Errors System Errors Typos
Not Over Not Over
Tagged generated Tagged generated
Punct 100.0 0.0 0.0 0.0 0.0
Sound 79.3 10.3 10.3 0.0 0.0
Foreign 47.2 1.9 12.3 20.3 18.4
Name 26.3 13.7 45.3 8.4 6.3
</table>
<tableCaption confidence="0.999629">
Table 9: Error Analysis of tag classification errors
</tableCaption>
<bodyText confidence="0.999939">
As a baseline, we use the most frequent tag,
which is Arabic in our case, along with the translit-
eration of the word using our black box system.
Then we apply the above evaluation metric on both
Dev and Test. The results are shown in table 8. The
baseline accuracies on Dev and Test are 65.7% and
76.8% respectively. By considering the actual out-
put of our system, the accuracy on the Dev and Test
data increases to 82.5% and 83.8% respectively.
</bodyText>
<subsectionHeader confidence="0.869188">
9.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999980666666667">
We conducted an error analysis for tag classifica-
tion on the development set. The analysis is done
for the tags that we built models for, which are
Punct, Sound, Foreign and Name.2 Table 9 shows
the different error types for classifying the tags.
Tagging errors could be either gold errors or sys-
tem errors. These errors could be either due to
tag over-generation or because the correct tag is
not detected. Additionally, there are typos in the
input Arabizi that sometimes prevent the system
from assigning the correct tags. Gold errors con-
tribute to a large portion of the tagging errors, rep-
resenting 100.0%, 89.6%, 49.1% and 40.0% for
the Punct, Sound, Foreign and Name tags, respec-
tively.
</bodyText>
<sectionHeader confidence="0.979456" genericHeader="conclusions">
10 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999954857142857">
We presented a system for automatic processing of
Arabic social media text written in Roman script,
or Arabizi. Our system not only transliterates the
Arabizi text in the Egyptian Arabic dialect but also
classifies input Arabizi tokens as sounds, punc-
tuation marks, names, foreign words, or Arabic
words, and detects emoticons. We define a new
</bodyText>
<footnote confidence="0.972162666666667">
2As mentioned in Section 4, the Arabic tag is assigned to
any remaining untagged words after running the classification
models.
</footnote>
<bodyText confidence="0.999410642857143">
task-specific metric for evaluating the complete
system. Our best setting achieves an overall per-
formance accuracy of 83.8% on a blind test set.
In the future, we plan to extend our work to
other Arabic dialects and other language contexts
such as Judeo-Arabic (Arabic written in Hebrew
script with code switching between Arabic and
Hebrew). We plan to explore the use of this com-
ponent in the context of specific applications such
as machine translation from Arabizi Arabic to En-
glish, and sentiment analysis in social media. We
also plan to make the system public so it can be
used by other people working on Arabic NLP tasks
related to Arabizi.
</bodyText>
<sectionHeader confidence="0.978693" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999729333333333">
This paper is based upon work supported by
DARPA Contract No. HR0011-12-C-0014. Any
opinions, findings and conclusions or recommen-
dations expressed in this paper are those of the au-
thors and do not necessarily reflect the views of
DARPA. Nizar Habash performed most of his con-
tribution to this paper while he was at the Center
for Computational Learning Systems at Columbia
University.
</bodyText>
<sectionHeader confidence="0.998099" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997754321428571">
Mohamed Al-Badrashiny, Ramy Eskander, Nizar
Habash, and Owen Rambow. 2014. Automatic
Transliteration of Romanized Dialectal Arabic. In
Proceedings of the Eighteenth Conference on Com-
putational Natural Language Learning, pages 30–
38, Ann Arbor, Michigan, June. Association for
Computational Linguistics.
Ann Bies, Zhiyi Song, Mohamed Maamouri, Stephen
Grimes, Haejoong Lee, Jonathan Wright, Stephanie
Strassel, Nizar Habash, Ramy Eskander, and Owen
Rabmow. 2014. Transliteration of Arabizi into Ara-
bic Orthography: Developing a Parallel Annotated
Arabizi-Arabic Script SMS/Chat Corpus. In Arabic
Natural Language Processing Workshop, EMNLP,
Doha, Qatar.
Tim Buckwalter. 2004. Buckwalter Arabic Morpho-
logical Analyzer Version 2.0. LDC catalog number
LDC2004L02, ISBN 1-58563-324-0.
Achraf Chalabi and Hany Gerges. 2012. Romanized
Arabic Transliteration. In Proceedings of the Sec-
ond Workshop on Advances in Text Input Methods
(WTIM 2012).
Eleanor Clark and Kenji Araki. 2011. Text normal-
ization in social media: Progress, problems and ap-
plications for a pre-processing system of casual en-
glish. Procedia - Social and Behavioral Sciences,
27(0):2 – 11. Computational Linguistics and Re-
lated Fields.
</reference>
<page confidence="0.949751">
10
</page>
<reference confidence="0.999932872881356">
Kareem Darwish, Walid Magdy, and Ahmed Mourad.
2012. Language Processing for Arabic Microblog
Retrieval. In Proceedings of the 21st ACM Inter-
national Conference on Information and Knowledge
Management, CIKM ’12, pages 2427–2430, New
York, NY, USA. ACM.
Kareem Darwish. 2013. Arabizi Detection and Con-
version to Arabic. CoRR.
Kareem Darwish. 2014. Arabizi Detection and Con-
version to Arabic. In Arabic Natural Language Pro-
cessing Workshop, EMNLP, Doha, Qatar.
Leon Derczynski, Alan Ritter, Sam Clark, and Kalina
Bontcheva. 2013. Twitter part-of-speech tagging
for all: Overcoming sparse and noisy data. In
Proceedings of the International Conference Recent
Advances in Natural Language Processing RANLP
2013, pages 198–206, Hissar, Bulgaria, September.
INCOMA Ltd. Shoumen, BULGARIA.
Mona Diab, Mohamed Al-Badrashiny, Maryam
Aminian, Mohammed Attia, Pradeep Dasigi, Heba
Elfardy, Ramy Eskander, Nizar Habash, Abdelati
Hawwari, and Wael Salloum. 2014. Tharwa: A
Large Scale Dialectal Arabic - Standard Arabic - En-
glish Lexicon. In Proceedings of the Language Re-
sources and Evaluation Conference (LREC), Reyk-
javik, Iceland.
Heba Elfardy, Mohamed Al-Badrashiny, and Mona
Diab. 2013. Code Switch Point Detection in Arabic.
In Proceedings of the 18th International Conference
on Application of Natural Language to Information
Systems (NLDB2013), MediaCity, UK, June.
Heba Elfardy, Mohamed Al-Badrashiny, and Mona
Diab. 2014. AIDA: Identifying Code Switching
in Informal Arabic Text. In Workshop on Compu-
tational Approaches to Linguistic Code Switching,
EMNLP, Doha, Qatar, October.
Ramy Eskander, Nizar Habash, Owen Rambow, and
Nadi Tomeh. 2013. Processing Spontaneous Or-
thography. In Proceedings of the 2013 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies (NAACL-HLT), Atlanta, GA.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: Annotation, features, and experiments.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies: Short Papers - Volume 2,
HLT ’11, pages 42–47, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Stephan Gouws, Donald Metzler, Congxing Cai, and
Eduard Hovy. 2011. Contextual bearing on lin-
guistic variation in social media. In Proceedings of
the Workshop on Languages in Social Media, LSM
’11, pages 20–29, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den
Bosch and A. Soudi, editors, Arabic Computa-
tional Morphology: Knowledge-based and Empiri-
cal Methods. Springer.
Nizar Habash, Mona Diab, and Owen Rabmow. 2012a.
Conventional Orthography for Dialectal Arabic. In
Proceedings of the Language Resources and Evalu-
ation Conference (LREC), Istanbul.
Nizar Habash, Ramy Eskander, and Abdelati Hawwari.
2012b. A Morphological Analyzer for Egyptian
Arabic. In Proceedings of the Twelfth Meeting of the
Special Interest Group on Computational Morphol-
ogy and Phonology, pages 1–9, Montréal, Canada.
Nizar Habash. 2009. REMOOV: A tool for online han-
dling of out-of-vocabulary words in machine trans-
lation. In Khalid Choukri and Bente Maegaard, ed-
itors, Proceedings of the Second International Con-
ference on Arabic Language Resources and Tools.
The MEDAR Consortium, April.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: an update.
SIGKDD Explorations, 11(1):10–18.
LDC. 2014a. BOLT Phase 2 SMS and Chat Ara-
bic DevTest Data – Source Annotation, Translit-
eration and Translation. LDC catalog number
LDC2014E28.
LDC. 2014b. BOLT Phase 2 SMS and Chat Ara-
bic Training Data – Source Annotation, Translit-
eration and Translation R1. LDC catalog number
LDC2014E48.
LDC. 2014c. BOLT Program: Romanized Arabic
(Arabizi) to Arabic Transliteration and Normaliza-
tion Guidelines. Version 3. Linguistic Data Consor-
tium.
Marco Lui, Jey Han Lau, and Timothy Baldwin. 2014.
Automatic detection and language identification of
multilingual documents. In Proceedings of LREC.
Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,
Ahmed El Kholy, Ramy Eskander, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan M. Roth.
2014. MADAMIRA: A Fast, Comprehensive Tool
for Morphological Analysis and Disambiguation of
Arabic. In Proceedings of the Language Resources
and Evaluation Conference (LREC), Reykjavik, Ice-
land.
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.
2011. Named entity recognition in tweets: An ex-
perimental study. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing, EMNLP ’11, pages 1524–1534, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Clare Voss, Stephen Tratz, Jamal Laoudi, and Dou-
glas Briesch. 2014. Finding Romanized Arabic
Dialect in Code-Mixed Tweets. In Nicoletta Cal-
zolari (Conference Chair), Khalid Choukri, Thierry
Declerck, Hrafn Loftsson, Bente Maegaard, Joseph
Mariani, Asuncion Moreno, Jan Odijk, and Stelios
</reference>
<page confidence="0.989835">
11
</page>
<reference confidence="0.999385428571428">
Piperidis, editors, Proceedings of the Ninth Interna-
tional Conference on Language Resources and Eval-
uation (LREC’14), Reykjavik, Iceland, may. Euro-
pean Language Resources Association (ELRA).
Omar F Zaidan and Chris Callison-Burch. 2011. The
Arabic online commentary dataset: an annotated
dataset of informal Arabic with high dialectal con-
tent. In Proceedings of ACL, pages 37–41.
Ines Zribi, Rahma Boujelbane, Abir Masmoudi,
Mariem Ellouze, Lamia Belguith, and Nizar Habash.
2014. A Conventional Orthography for Tunisian
Arabic. In Proceedings of the Language Resources
and Evaluation Conference (LREC), Reykjavik, Ice-
land.
</reference>
<page confidence="0.99843">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.310554">
<title confidence="0.983897">Foreign Words and the Automatic</title>
<author confidence="0.676551">of Arabic Social Media Text Written in Roman Script</author>
<affiliation confidence="0.81395475">Eskander, Mohamed Nizar Owen Center for Computational Learning Systems, Columbia of Computer Science, The George Washington Science Department, New York University Abu</affiliation>
<abstract confidence="0.998743647058824">Arabic on social media has all the properties of any language on social media that make it tough for natural language processing, plus some specific problems. These include diglossia, the use of an alternative alphabet (Roman), and code switching with foreign languages. In this paper, we present a system which can process Arabic written in Roman alphabet (“Arabizi”). It identifies whether each word is a foreign word or one of another four categories (Arabic, name, punctuation, sound), and transliterates Arabic words and names into the Arabic alphabet. We obtain an overall system performance of 83.8% on an unseen test set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohamed Al-Badrashiny</author>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Automatic Transliteration of Romanized Dialectal Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Eighteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>30--38</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="4110" citStr="Al-Badrashiny et al., 2014" startWordPosition="641" endWordPosition="644">gate the issue of processing Arabizi input with code switching. There are two tasks: identification of tokens that are not DA or MSA (and should not be transliterated into Arabic script for downstream processing), and then the transliteration into Arabic script of the parts identified as DA or MSA. In this paper, we 1 Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 1–12, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics use as a black box an existing component that we developed to transliterate from Arabizi to Arabic script (Al-Badrashiny et al., 2014). This paper concentrates on the task of identifying which tokens should be transliterated. A recent release of annotated data by the Linguistic Data Consortium (LDC, 2014c; Bies et al., 2014) has enabled novel research on this topic. The corpus provides each token with a tag, as well as a transliteration if appropriate. The tags identify foreign words, as well as Arabic words, names, punctuation, and sounds. Only Arabic words and names are transliterated. (Note that code switching is not distinguished from borrowing.) Emoticons, which may be isolated or part of an input token, are also identi</context>
<context position="8422" citStr="Al-Badrashiny et al. (2014)" startWordPosition="1370" endWordPosition="1373">al documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic text from Arabizi to Arabic script. We compare our transliteration method to his in Al-Badrashiny et al. (2014). For identification of non-Arabic words in Arabizi, Darwish (2013) uses word and sequence-level features with CRF modeling; while we use SVMs and decision trees. Darwish (2013) identifies three tags: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation 2 and emoticons. Furthermore, Darwish (2013) uses around 5K words for training his taggers and 3.5K words for testing; this is considerably smaller than our training and test sets of 113K and 32K words, respectively. Chalabi and Gerges (2012) presented </context>
<context position="12530" citStr="Al-Badrashiny et al., 2014" startWordPosition="2033" endWordPosition="2036"> Annotation The data set we use in this paper was created by the Linguistic Data Consortium (Bies et al., 2014; LDC, 2014a; LDC, 2014b; LDC, 2014c). We summarize below the annotation decisions. The system we present in this paper aims at predicting exactly this annotation automatically. The input text is initially segregated into Arabic script and Arabizi. Arabic script text is not modified in any way. Arabizi text undergoes two sets of annotation decisions: Arabizi word tagging and Arabizi-toArabic transliteration. All of the Arabizi annotations are initially done using an automatic process (Al-Badrashiny et al., 2014) and then followed by manual correction and validation. Arabizi Word Tagging Each Arabizi word receives one of the following five tags: • Foreign All words from languages other than Arabic are tagged as Foreign if they would be kept in the same orthographic form when translated into their source language (which in our corpus is almost always English). Thus, non-Arabic words that include Arabic affixes are not tagged as Foreign. The definition of “foreign” thus means that uninflected borrowings spelled as in the source language orthography are tagged as “foreign”, while borrowings that are spel</context>
<context position="18183" citStr="Al-Badrashiny et al., 2014" startWordPosition="2955" endWordPosition="2958">pus, in our performance evaluation we combine the decisions of tags and transliteration. For foreign words, punctuation and sounds, we only consider the tags for accuracy computations; in contrast, for names and Arabic words, we consider both the tag and transliteration. 4 System Architecture Figure 2 represent the overall architecture of our system. We distinguish below between existing components that we use and novel extensions that we contribute in this paper. 4.1 Existing Arabization System For the core component of Arabizi-to-Arabic transliteration, we use a previously published system (Al-Badrashiny et al., 2014), which converts Arabizi into Arabic text following CODA conventions (see Section 3). The existing system uses a finite state transducer trained on 8,500 Arabizi-toArabic transliteration pairs at the character level to obtain a large number of possible transliterations for the input Arabizi words. The generated list is then filtered using a dialectal Arabic morphological analyzer. Finally, the best choice for each input word is selected using a language model. We use this component as a black box except that we retrain it using additional training data. In Figure 2, this component is represent</context>
<context position="20509" citStr="Al-Badrashiny et al. (2014)" startWordPosition="3343" endWordPosition="3346">tup. • Dev: The development set that is used to measure the system performance in all experiments • Test: A blind set that is used to test the best system (LDC, 2014a). The training and development sets are extracted from (LDC, 2014b). Table 1 represents the tags distribution in each dataset. Almost one of every five words is not Arabic text and around one of every 10 words is foreign. 5.2 Arabizi-to-Arabic Transliteration Accuracy For the Arabizi-to-Arabic transliteration system, we report on using the two training data sets with two modifications. First, we include the 8,500 word pairs from Al-Badrashiny et al. (2014), namely 2,200 Arabizi-to-Arabic script pairs from the training data used by Darwish (2013) (manually revised to be CODA-compliant) and about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). (Since these pairs are not tagged, we do not use them to train the taggers.) Second, we exclude all the foreign tagged words from training the transliteration system since they were not manually corrected. Table 2 shows the overall transliteration accuracy of Arabic words and names only, using different training data sets and evaluating</context>
<context position="22140" citStr="Al-Badrashiny et al. (2014)" startWordPosition="3599" endWordPosition="3602">Tagger Combiner Arabic &amp; Tagged Arabizi Figure 2: The architecture of our complete Arabizi processing system. The &amp;quot;Punctuation, Sound and Emoticon Detection&amp;quot; component does labeling that is read by the &amp;quot;Name&amp;quot; and &amp;quot;Foreign Word&amp;quot; taggers, While the actual Aribizi-to-Arabic transliteration system is used as a black box. Data # Words Arabic Foreign Name Sound Punct Emoticon Train-S 21,950 80.5% 12.1% 2.8% 1.7% 1.3% 1.6% Train-L 113,490 82.3% 9.8% 2.4% 1.8% 1.1% 2.6% Dev 5,061 76.3% 16.2% 2.9% 1.8% 1.2% 1.5% Test 31,717 86.1% 6.0% 2.7% 1.6% 0.9% 2.8% Table 1: Dataset Statistics Data Translit. Acc. Al-Badrashiny et al. (2014) 68.6% Train-S 76.9% Train-L 79.5% Table 2: Transliteration accuracy of Arabic words and names when using different training sets and evaluating on Dev bigger training set Train-L. The overall transliteration accuracy of Arabic words and names on Test using the bigger training set Train-L is 83.6%. 6 Tagging Punctuation, Emoticons and Sounds 6.1 Approach We start the tagging process by detecting three types of closed classes: punctuation, sounds and emoticons. Simple regular expressions perform very well at detecting their occurrence in text. The regular expressions are applied to the Arabizi </context>
</contexts>
<marker>Al-Badrashiny, Eskander, Habash, Rambow, 2014</marker>
<rawString>Mohamed Al-Badrashiny, Ramy Eskander, Nizar Habash, and Owen Rambow. 2014. Automatic Transliteration of Romanized Dialectal Arabic. In Proceedings of the Eighteenth Conference on Computational Natural Language Learning, pages 30– 38, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Zhiyi Song</author>
<author>Mohamed Maamouri</author>
<author>Stephen Grimes</author>
<author>Haejoong Lee</author>
<author>Jonathan Wright</author>
<author>Stephanie Strassel</author>
<author>Nizar Habash</author>
<author>Ramy Eskander</author>
<author>Owen Rabmow</author>
</authors>
<title>Transliteration of Arabizi into Arabic Orthography: Developing a Parallel Annotated Arabizi-Arabic Script SMS/Chat Corpus.</title>
<date>2014</date>
<booktitle>In Arabic Natural Language Processing Workshop,</booktitle>
<location>EMNLP, Doha, Qatar.</location>
<contexts>
<context position="4302" citStr="Bies et al., 2014" startWordPosition="673" endWordPosition="676">processing), and then the transliteration into Arabic script of the parts identified as DA or MSA. In this paper, we 1 Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 1–12, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics use as a black box an existing component that we developed to transliterate from Arabizi to Arabic script (Al-Badrashiny et al., 2014). This paper concentrates on the task of identifying which tokens should be transliterated. A recent release of annotated data by the Linguistic Data Consortium (LDC, 2014c; Bies et al., 2014) has enabled novel research on this topic. The corpus provides each token with a tag, as well as a transliteration if appropriate. The tags identify foreign words, as well as Arabic words, names, punctuation, and sounds. Only Arabic words and names are transliterated. (Note that code switching is not distinguished from borrowing.) Emoticons, which may be isolated or part of an input token, are also identified, and converted into a conventional symbol (#). This paper presents taggers for the tags, and an end-to-end system which takes Arabizi input and produces a complex output which consists of</context>
<context position="12013" citStr="Bies et al., 2014" startWordPosition="1955" endWordPosition="1958">rabic pronunciation is somewhat modified. As a result, distinguishing borrowings from code switching is, as is usually the case, hard. And, as in any language used in social media and chat, Arabizi may also include abbreviations, such as isa which means é&lt;Ë@ ZAƒ~ v@� ˇAn šA’ Allh ‘God willing’ and lol ‘laugh out loud’. The rows marked with Arabizi in Figure 1 demonstrate some of the salient features of Arabizi. The constructed example in the figure is of an SMS conversation in Egyptian Arabic. 3.2 Data Annotation The data set we use in this paper was created by the Linguistic Data Consortium (Bies et al., 2014; LDC, 2014a; LDC, 2014b; LDC, 2014c). We summarize below the annotation decisions. The system we present in this paper aims at predicting exactly this annotation automatically. The input text is initially segregated into Arabic script and Arabizi. Arabic script text is not modified in any way. Arabizi text undergoes two sets of annotation decisions: Arabizi word tagging and Arabizi-toArabic transliteration. All of the Arabizi annotations are initially done using an automatic process (Al-Badrashiny et al., 2014) and then followed by manual correction and validation. Arabizi Word Tagging Each A</context>
</contexts>
<marker>Bies, Song, Maamouri, Grimes, Lee, Wright, Strassel, Habash, Eskander, Rabmow, 2014</marker>
<rawString>Ann Bies, Zhiyi Song, Mohamed Maamouri, Stephen Grimes, Haejoong Lee, Jonathan Wright, Stephanie Strassel, Nizar Habash, Ramy Eskander, and Owen Rabmow. 2014. Transliteration of Arabizi into Arabic Orthography: Developing a Parallel Annotated Arabizi-Arabic Script SMS/Chat Corpus. In Arabic Natural Language Processing Workshop, EMNLP, Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<date>2004</date>
<booktitle>Buckwalter Arabic Morphological Analyzer Version 2.0. LDC catalog number LDC2004L02, ISBN</booktitle>
<pages>1--58563</pages>
<contexts>
<context position="20769" citStr="Buckwalter, 2004" startWordPosition="3385" endWordPosition="3386">bution in each dataset. Almost one of every five words is not Arabic text and around one of every 10 words is foreign. 5.2 Arabizi-to-Arabic Transliteration Accuracy For the Arabizi-to-Arabic transliteration system, we report on using the two training data sets with two modifications. First, we include the 8,500 word pairs from Al-Badrashiny et al. (2014), namely 2,200 Arabizi-to-Arabic script pairs from the training data used by Darwish (2013) (manually revised to be CODA-compliant) and about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). (Since these pairs are not tagged, we do not use them to train the taggers.) Second, we exclude all the foreign tagged words from training the transliteration system since they were not manually corrected. Table 2 shows the overall transliteration accuracy of Arabic words and names only, using different training data sets and evaluating on Dev (as determined by the gold standard). The accuracy when using the original Arabizi-to-Arabic transliteration system from Al-Badrashiny et al. (2014) gives an accuracy of 68.6%. Retraining it on Train-S improves the accuracy to 76.9%. The accuracy goes </context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Tim Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer Version 2.0. LDC catalog number LDC2004L02, ISBN 1-58563-324-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Achraf Chalabi</author>
<author>Hany Gerges</author>
</authors>
<title>Romanized Arabic Transliteration.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second Workshop on Advances in Text Input Methods (WTIM</booktitle>
<contexts>
<context position="9011" citStr="Chalabi and Gerges (2012)" startWordPosition="1462" endWordPosition="1465">o his in Al-Badrashiny et al. (2014). For identification of non-Arabic words in Arabizi, Darwish (2013) uses word and sequence-level features with CRF modeling; while we use SVMs and decision trees. Darwish (2013) identifies three tags: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation 2 and emoticons. Furthermore, Darwish (2013) uses around 5K words for training his taggers and 3.5K words for testing; this is considerably smaller than our training and test sets of 113K and 32K words, respectively. Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration. Their work does not address the detection of English words, punctuation, emoticons, and so on. They also do not handle English when mixed with Arabizi. Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, they deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. There are many differences between our work and theirs: they have noisy training data, and they have a much more balanced test set. They also only deal with fore</context>
</contexts>
<marker>Chalabi, Gerges, 2012</marker>
<rawString>Achraf Chalabi and Hany Gerges. 2012. Romanized Arabic Transliteration. In Proceedings of the Second Workshop on Advances in Text Input Methods (WTIM 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleanor Clark</author>
<author>Kenji Araki</author>
</authors>
<title>Text normalization in social media: Progress, problems and applications for a pre-processing system of casual english.</title>
<date>2011</date>
<booktitle>Procedia - Social and Behavioral Sciences, 27(0):2 – 11. Computational Linguistics and Related</booktitle>
<contexts>
<context position="6237" citStr="Clark and Araki, 2011" startWordPosition="1000" endWordPosition="1003">d, we compose a single system from the various components, and evaluate the complete system. This paper is structured as follows. We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. We give a brief summary of relevant work on Arabic. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of DA such as the lack of a standard orthography. However, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dia</context>
</contexts>
<marker>Clark, Araki, 2011</marker>
<rawString>Eleanor Clark and Kenji Araki. 2011. Text normalization in social media: Progress, problems and applications for a pre-processing system of casual english. Procedia - Social and Behavioral Sciences, 27(0):2 – 11. Computational Linguistics and Related Fields.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
<author>Walid Magdy</author>
<author>Ahmed Mourad</author>
</authors>
<title>Language Processing for Arabic Microblog Retrieval.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM ’12,</booktitle>
<pages>2427--2430</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6444" citStr="Darwish et al. (2012)" startWordPosition="1040" endWordPosition="1043"> linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. We give a brief summary of relevant work on Arabic. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of DA such as the lack of a standard orthography. However, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are interested in this problem at the intersentence level. They crawl a large dataset of MSA-DA news commentaries. They use Amazon Mechanical Turk to anno</context>
</contexts>
<marker>Darwish, Magdy, Mourad, 2012</marker>
<rawString>Kareem Darwish, Walid Magdy, and Ahmed Mourad. 2012. Language Processing for Arabic Microblog Retrieval. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM ’12, pages 2427–2430, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
</authors>
<title>Arabizi Detection and Conversion to Arabic.</title>
<date>2013</date>
<publisher>CoRR.</publisher>
<contexts>
<context position="8154" citStr="Darwish (2013)" startWordPosition="1327" endWordPosition="1329">s on the language modeling (LM) approach, but if a word is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic text from Arabizi to Arabic script. We compare our transliteration method to his in Al-Badrashiny et al. (2014). For identification of non-Arabic words in Arabizi, Darwish (2013) uses word and sequence-level features with CRF modeling; while we use SVMs and decision trees. Darwish (2013) identifies three tags: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sound</context>
<context position="9842" citStr="Darwish, 2013" startWordPosition="1601" endWordPosition="1602">al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, they deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. There are many differences between our work and theirs: they have noisy training data, and they have a much more balanced test set. They also only deal with foreignness, and do not address the other tags we deal with, nor do they actually discuss transliteration itself. 3 Linguistic Facts and Data Annotation 3.1 Arabizi Arabizi refers to Arabic written using the Roman script (Darwish, 2013; Voss et al., 2014). Arabizi orthography is spontaneous and has no standard references, although there are numerous commonly used conventions making specific usage of the so-called Arabic numerals and punctuation in addition to Roman script letters. Arabizi is commonly used by Arabic speakers to write mostly in dialectal Arabic in social media, SMS and chat applications. Arabizi orthography decisions mainly depend on a phoneme-to-grapheme mapping between the Arabic pronunciation and the Roman script. This is largely based on the phoneme-to-grapheme mapping used in English (in Middle Eastern A</context>
<context position="20600" citStr="Darwish (2013)" startWordPosition="3358" endWordPosition="3359">: A blind set that is used to test the best system (LDC, 2014a). The training and development sets are extracted from (LDC, 2014b). Table 1 represents the tags distribution in each dataset. Almost one of every five words is not Arabic text and around one of every 10 words is foreign. 5.2 Arabizi-to-Arabic Transliteration Accuracy For the Arabizi-to-Arabic transliteration system, we report on using the two training data sets with two modifications. First, we include the 8,500 word pairs from Al-Badrashiny et al. (2014), namely 2,200 Arabizi-to-Arabic script pairs from the training data used by Darwish (2013) (manually revised to be CODA-compliant) and about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). (Since these pairs are not tagged, we do not use them to train the taggers.) Second, we exclude all the foreign tagged words from training the transliteration system since they were not manually corrected. Table 2 shows the overall transliteration accuracy of Arabic words and names only, using different training data sets and evaluating on Dev (as determined by the gold standard). The accuracy when using the original Arabizi-</context>
</contexts>
<marker>Darwish, 2013</marker>
<rawString>Kareem Darwish. 2013. Arabizi Detection and Conversion to Arabic. CoRR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
</authors>
<title>Arabizi Detection and Conversion to Arabic.</title>
<date>2014</date>
<booktitle>In Arabic Natural Language Processing Workshop,</booktitle>
<location>EMNLP, Doha, Qatar.</location>
<contexts>
<context position="8206" citStr="Darwish, 2014" startWordPosition="1336" endWordPosition="1337">ord is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic text from Arabizi to Arabic script. We compare our transliteration method to his in Al-Badrashiny et al. (2014). For identification of non-Arabic words in Arabizi, Darwish (2013) uses word and sequence-level features with CRF modeling; while we use SVMs and decision trees. Darwish (2013) identifies three tags: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation 2 and emoticons. Furthermore, Darwish</context>
</contexts>
<marker>Darwish, 2014</marker>
<rawString>Kareem Darwish. 2014. Arabizi Detection and Conversion to Arabic. In Arabic Natural Language Processing Workshop, EMNLP, Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leon Derczynski</author>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Kalina Bontcheva</author>
</authors>
<title>Twitter part-of-speech tagging for all: Overcoming sparse and noisy data.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013,</booktitle>
<pages>198--206</pages>
<publisher>INCOMA Ltd. Shoumen, BULGARIA.</publisher>
<location>Hissar, Bulgaria,</location>
<contexts>
<context position="6325" citStr="Derczynski et al., 2013" startWordPosition="1016" endWordPosition="1020">system. This paper is structured as follows. We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. We give a brief summary of relevant work on Arabic. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of DA such as the lack of a standard orthography. However, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are interested in this problem at t</context>
</contexts>
<marker>Derczynski, Ritter, Clark, Bontcheva, 2013</marker>
<rawString>Leon Derczynski, Alan Ritter, Sam Clark, and Kalina Bontcheva. 2013. Twitter part-of-speech tagging for all: Overcoming sparse and noisy data. In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013, pages 198–206, Hissar, Bulgaria, September. INCOMA Ltd. Shoumen, BULGARIA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
</authors>
<title>Mohamed Al-Badrashiny, Maryam Aminian, Mohammed Attia, Pradeep Dasigi, Heba Elfardy, Ramy Eskander, Nizar Habash, Abdelati Hawwari, and Wael Salloum.</title>
<date>2014</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik,</booktitle>
<marker>Diab, 2014</marker>
<rawString>Mona Diab, Mohamed Al-Badrashiny, Maryam Aminian, Mohammed Attia, Pradeep Dasigi, Heba Elfardy, Ramy Eskander, Nizar Habash, Abdelati Hawwari, and Wael Salloum. 2014. Tharwa: A Large Scale Dialectal Arabic - Standard Arabic - English Lexicon. In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heba Elfardy</author>
<author>Mohamed Al-Badrashiny</author>
<author>Mona Diab</author>
</authors>
<title>Code Switch Point Detection in Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 18th International Conference on Application of Natural Language to Information Systems (NLDB2013),</booktitle>
<location>MediaCity, UK,</location>
<contexts>
<context position="7265" citStr="Elfardy et al., 2013" startWordPosition="1181" endWordPosition="1184">owever, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are interested in this problem at the intersentence level. They crawl a large dataset of MSA-DA news commentaries. They use Amazon Mechanical Turk to annotate the dataset at the sentence level. Then they use a language modeling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA based on the context. The tagging process mainly depends on the language modeling (LM) approach, but if a word is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on superv</context>
</contexts>
<marker>Elfardy, Al-Badrashiny, Diab, 2013</marker>
<rawString>Heba Elfardy, Mohamed Al-Badrashiny, and Mona Diab. 2013. Code Switch Point Detection in Arabic. In Proceedings of the 18th International Conference on Application of Natural Language to Information Systems (NLDB2013), MediaCity, UK, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heba Elfardy</author>
<author>Mohamed Al-Badrashiny</author>
<author>Mona Diab</author>
</authors>
<title>AIDA: Identifying Code Switching in Informal Arabic Text.</title>
<date>2014</date>
<booktitle>In Workshop on Computational Approaches to Linguistic Code Switching, EMNLP,</booktitle>
<location>Doha, Qatar,</location>
<contexts>
<context position="7288" citStr="Elfardy et al., 2014" startWordPosition="1185" endWordPosition="1188">al with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are interested in this problem at the intersentence level. They crawl a large dataset of MSA-DA news commentaries. They use Amazon Mechanical Turk to annotate the dataset at the sentence level. Then they use a language modeling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA based on the context. The tagging process mainly depends on the language modeling (LM) approach, but if a word is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling alg</context>
</contexts>
<marker>Elfardy, Al-Badrashiny, Diab, 2014</marker>
<rawString>Heba Elfardy, Mohamed Al-Badrashiny, and Mona Diab. 2014. AIDA: Identifying Code Switching in Informal Arabic Text. In Workshop on Computational Approaches to Linguistic Code Switching, EMNLP, Doha, Qatar, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Nadi Tomeh</author>
</authors>
<title>Processing Spontaneous Orthography.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="16221" citStr="Eskander et al., 2013" startWordPosition="2644" endWordPosition="2647">mportant to point out that the annotation of this data was intended to serve a project focusing on machine translation from dialectal Arabic into English. This goal influenced some of the annotation decisions and was part of the reason for this selection of word tags. Arabizi-to-Arabic Transliteration The second annotation task is about converting Arabizi to an Arabic-script-based orthography. Since, dialectal Arabic including Egyptian Arabic has no standard orthography in Arabic script, the annotation uses a conventionalized orthography for Dialectal Arabic called CODA (Habash et al., 2012a; Eskander et al., 2013; Zribi et al., 2014). Every word has a single orthographic representation in CODA. In the corpus we use, only words tagged as Arabic or Name are manually checked and corrected. The transliteration respects the whitespace boundaries of the original Arabizi words. In cases where an Arabizi word represents a prefix or suffix that should be joined in CODA to the next or previous word, a [+] symbol is added to mark this decision. Similarly, for Arabizi words that should be split into multiple CODA words, the CODA words are written with added [-] symbol delimiting the word boundaries. The Arabic tr</context>
</contexts>
<marker>Eskander, Habash, Rambow, Tomeh, 2013</marker>
<rawString>Ramy Eskander, Nizar Habash, Owen Rambow, and Nadi Tomeh. 2013. Processing Spontaneous Orthography. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11,</booktitle>
<pages>42--47</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11, pages 42–47, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Gouws</author>
<author>Donald Metzler</author>
<author>Congxing Cai</author>
<author>Eduard Hovy</author>
</authors>
<title>Contextual bearing on linguistic variation in social media.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Languages in Social Media, LSM ’11,</booktitle>
<pages>20--29</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6278" citStr="Gouws et al., 2011" startWordPosition="1008" endWordPosition="1011">us components, and evaluate the complete system. This paper is structured as follows. We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. We give a brief summary of relevant work on Arabic. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of DA such as the lack of a standard orthography. However, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-B</context>
</contexts>
<marker>Gouws, Metzler, Cai, Hovy, 2011</marker>
<rawString>Stephan Gouws, Donald Metzler, Congxing Cai, and Eduard Hovy. 2011. Contextual bearing on linguistic variation in social media. In Proceedings of the Workshop on Languages in Social Media, LSM ’11, pages 20–29, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="11031" citStr="Habash et al., 2007" startWordPosition="1785" endWordPosition="1788">in English (in Middle Eastern Arab countries) or French (in Western North African Arab countries). Since there is no standard orthography for Arabizi, it is not a simple transliteration of Arabic. For example, in Arabizi, words omit vowels far less frequently than is done when writers follow standard Arabic orthography. Furthermore, there are several cases of many-to-many mappings between Arabic phonemes and Roman script letters: for example, the letter “t” is used to represent the sound of the Arabic letters H~ t1 and 1Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical T (which itself can be also be represented using the digit “6”). Text written in Arabizi also tends to have a large number of foreign words, that are either borrowings such as telephone, or code switching, such as love you!. Note that Arabizi often uses the source language orthography for borrowings (especially recent borrowings), even if the Arabic pronunciation is somewhat modified. As a result, distinguishing borrowings from code switching is, as is usually the case, hard. And, as in any language used in social media and chat, Arabizi may also include abbreviations, such </context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Owen Rabmow</author>
</authors>
<title>Conventional Orthography for Dialectal Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC),</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="16197" citStr="Habash et al., 2012" startWordPosition="2640" endWordPosition="2643">ifferent tags. It is important to point out that the annotation of this data was intended to serve a project focusing on machine translation from dialectal Arabic into English. This goal influenced some of the annotation decisions and was part of the reason for this selection of word tags. Arabizi-to-Arabic Transliteration The second annotation task is about converting Arabizi to an Arabic-script-based orthography. Since, dialectal Arabic including Egyptian Arabic has no standard orthography in Arabic script, the annotation uses a conventionalized orthography for Dialectal Arabic called CODA (Habash et al., 2012a; Eskander et al., 2013; Zribi et al., 2014). Every word has a single orthographic representation in CODA. In the corpus we use, only words tagged as Arabic or Name are manually checked and corrected. The transliteration respects the whitespace boundaries of the original Arabizi words. In cases where an Arabizi word represents a prefix or suffix that should be joined in CODA to the next or previous word, a [+] symbol is added to mark this decision. Similarly, for Arabizi words that should be split into multiple CODA words, the CODA words are written with added [-] symbol delimiting the word b</context>
<context position="24752" citStr="Habash et al., 2012" startWordPosition="4024" endWordPosition="4027">el of name tagging. The features are used either separately or combined using a modeling classifier implemented with decision trees. • Capitalization A word is considered a name if the first letter in Arabizi is capitalized. 6 • MADAMIRA MADAMIRA is a system for morphological analysis and disambiguation of Arabic (Pasha et al., 2014). We run MADAMIRA on the Arabic output after running the Arabizi-to-Arabic transliteration. If the selected part-of-speech (POS) of a word is proper noun (NOUN_PROP), then the word is tagged as Name. • CALIMA CALIMA is a morphological analyzer for Egyptian Arabic (Habash et al., 2012b). If the Arabic transliteration of a given Arabizi word has a possible proper noun analysis in CALIMA, then the word is tagged as Name. • Maximum Likelihood Estimate (MLE) An Arabizi word gets assigned the Name tag if Name is the most associated tag for that word in the training set. • Tharwa Tharwa is a large scale Egyptian Arabic-MSA-English lexicon that includes POS tag information (Diab et al., 2014). If an Arabizi word appears in Tharwa as an English gloss with a proper noun POS, then it is tagged as Name. • Name Language Model We use a list of 280K unique lower-cased English words asso</context>
</contexts>
<marker>Habash, Diab, Rabmow, 2012</marker>
<rawString>Nizar Habash, Mona Diab, and Owen Rabmow. 2012a. Conventional Orthography for Dialectal Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ramy Eskander</author>
<author>Abdelati Hawwari</author>
</authors>
<title>A Morphological Analyzer for Egyptian Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology,</booktitle>
<pages>1--9</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="16197" citStr="Habash et al., 2012" startWordPosition="2640" endWordPosition="2643">ifferent tags. It is important to point out that the annotation of this data was intended to serve a project focusing on machine translation from dialectal Arabic into English. This goal influenced some of the annotation decisions and was part of the reason for this selection of word tags. Arabizi-to-Arabic Transliteration The second annotation task is about converting Arabizi to an Arabic-script-based orthography. Since, dialectal Arabic including Egyptian Arabic has no standard orthography in Arabic script, the annotation uses a conventionalized orthography for Dialectal Arabic called CODA (Habash et al., 2012a; Eskander et al., 2013; Zribi et al., 2014). Every word has a single orthographic representation in CODA. In the corpus we use, only words tagged as Arabic or Name are manually checked and corrected. The transliteration respects the whitespace boundaries of the original Arabizi words. In cases where an Arabizi word represents a prefix or suffix that should be joined in CODA to the next or previous word, a [+] symbol is added to mark this decision. Similarly, for Arabizi words that should be split into multiple CODA words, the CODA words are written with added [-] symbol delimiting the word b</context>
<context position="24752" citStr="Habash et al., 2012" startWordPosition="4024" endWordPosition="4027">el of name tagging. The features are used either separately or combined using a modeling classifier implemented with decision trees. • Capitalization A word is considered a name if the first letter in Arabizi is capitalized. 6 • MADAMIRA MADAMIRA is a system for morphological analysis and disambiguation of Arabic (Pasha et al., 2014). We run MADAMIRA on the Arabic output after running the Arabizi-to-Arabic transliteration. If the selected part-of-speech (POS) of a word is proper noun (NOUN_PROP), then the word is tagged as Name. • CALIMA CALIMA is a morphological analyzer for Egyptian Arabic (Habash et al., 2012b). If the Arabic transliteration of a given Arabizi word has a possible proper noun analysis in CALIMA, then the word is tagged as Name. • Maximum Likelihood Estimate (MLE) An Arabizi word gets assigned the Name tag if Name is the most associated tag for that word in the training set. • Tharwa Tharwa is a large scale Egyptian Arabic-MSA-English lexicon that includes POS tag information (Diab et al., 2014). If an Arabizi word appears in Tharwa as an English gloss with a proper noun POS, then it is tagged as Name. • Name Language Model We use a list of 280K unique lower-cased English words asso</context>
</contexts>
<marker>Habash, Eskander, Hawwari, 2012</marker>
<rawString>Nizar Habash, Ramy Eskander, and Abdelati Hawwari. 2012b. A Morphological Analyzer for Egyptian Arabic. In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology, pages 1–9, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>REMOOV: A tool for online handling of out-of-vocabulary words in machine translation.</title>
<date>2009</date>
<booktitle>In Khalid Choukri and Bente Maegaard, editors, Proceedings of the Second International Conference on Arabic Language Resources and Tools. The MEDAR Consortium,</booktitle>
<contexts>
<context position="25421" citStr="Habash, 2009" startWordPosition="4143" endWordPosition="4144">d has a possible proper noun analysis in CALIMA, then the word is tagged as Name. • Maximum Likelihood Estimate (MLE) An Arabizi word gets assigned the Name tag if Name is the most associated tag for that word in the training set. • Tharwa Tharwa is a large scale Egyptian Arabic-MSA-English lexicon that includes POS tag information (Diab et al., 2014). If an Arabizi word appears in Tharwa as an English gloss with a proper noun POS, then it is tagged as Name. • Name Language Model We use a list of 280K unique lower-cased English words associated with their probability of appearing capitalized (Habash, 2009). When using this feature, any probability that is not equal to one is rounded to zero. All the features above are modeled after caselowering the Arabizi input, and removing speech effects. Any attached punctuation marks and/or emoticons are stripped out. One exception is the capitalization feature, where the case of the first letter of the Arabizi word is preserved. The techniques above are then combined together using decision trees. In this approach, the words tagged as Name are given a weight that balances their infrequent occurrence in the data. 7.2 Results Table 3 shows the performance o</context>
</contexts>
<marker>Habash, 2009</marker>
<rawString>Nizar Habash. 2009. REMOOV: A tool for online handling of out-of-vocabulary words in machine translation. In Khalid Choukri and Bente Maegaard, editors, Proceedings of the Second International Conference on Arabic Language Resources and Tools. The MEDAR Consortium, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="29058" citStr="Hall et al., 2009" startWordPosition="4796" endWordPosition="4799">Q, we consider the word Foreign. We define three baseline experiments as follows: • FW-index-manual: Use brute force search to find the best α and Q that maximize the foreign words tagging on Dev. • FW-index-SVM: Use the best α from above and train an SVM model using the foreignness index as sole feature. Then use this model to classify each word in Dev. • LM-lookup: The word is said to be Foreign if it exists in the English LM and does not exist in the Arabic LM. 8.2 Machine Learning Experiments We conducted a suite of experiments by training different machine learning techniques using WEKA (Hall et al., 2009) on the following groups of features. We performed a two-stage feature exploration, where we did an exhaustive search over all features in each group in the first phase, and then exhaustively searched over all retained feature groups. In addition, we also performed an exhaustive search over all features in the first three groups. • Word n-gram features: Run the input Arabizi word through an English LM and the corresponding Arabic transliteration through an Arabic LM to get the set of features that are defined in &amp;quot;Group1&amp;quot; in Table 4. Then find the best combination of features that maximizes the</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: an update. SIGKDD Explorations, 11(1):10–18.</rawString>
</citation>
<citation valid="false">
<booktitle>LDC. 2014a. BOLT Phase 2 SMS and Chat Arabic DevTest Data – Source Annotation, Transliteration and Translation. LDC catalog number LDC2014E28.</booktitle>
<marker></marker>
<rawString>LDC. 2014a. BOLT Phase 2 SMS and Chat Arabic DevTest Data – Source Annotation, Transliteration and Translation. LDC catalog number LDC2014E28.</rawString>
</citation>
<citation valid="false">
<booktitle>LDC. 2014b. BOLT Phase 2 SMS and Chat Arabic Training Data – Source Annotation, Transliteration and Translation R1. LDC catalog number LDC2014E48.</booktitle>
<marker></marker>
<rawString>LDC. 2014b. BOLT Phase 2 SMS and Chat Arabic Training Data – Source Annotation, Transliteration and Translation R1. LDC catalog number LDC2014E48.</rawString>
</citation>
<citation valid="false">
<authors>
<author>2014c</author>
</authors>
<title>BOLT Program: Romanized Arabic (Arabizi) to Arabic Transliteration and Normalization Guidelines. Version 3. Linguistic Data Consortium.</title>
<contexts>
<context position="7710" citStr="(2014)" startWordPosition="1262" endWordPosition="1262">uage modeling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA based on the context. The tagging process mainly depends on the language modeling (LM) approach, but if a word is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic</context>
<context position="9239" citStr="(2014)" startWordPosition="1501" endWordPosition="1501">reign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation 2 and emoticons. Furthermore, Darwish (2013) uses around 5K words for training his taggers and 3.5K words for testing; this is considerably smaller than our training and test sets of 113K and 32K words, respectively. Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration. Their work does not address the detection of English words, punctuation, emoticons, and so on. They also do not handle English when mixed with Arabizi. Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, they deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. There are many differences between our work and theirs: they have noisy training data, and they have a much more balanced test set. They also only deal with foreignness, and do not address the other tags we deal with, nor do they actually discuss transliteration itself. 3 Linguistic Facts and Data Annotation 3.1 Arabizi Arabizi refers to Arabic written using the Roman script (Darwish, 2</context>
<context position="20509" citStr="(2014)" startWordPosition="3346" endWordPosition="3346">opment set that is used to measure the system performance in all experiments • Test: A blind set that is used to test the best system (LDC, 2014a). The training and development sets are extracted from (LDC, 2014b). Table 1 represents the tags distribution in each dataset. Almost one of every five words is not Arabic text and around one of every 10 words is foreign. 5.2 Arabizi-to-Arabic Transliteration Accuracy For the Arabizi-to-Arabic transliteration system, we report on using the two training data sets with two modifications. First, we include the 8,500 word pairs from Al-Badrashiny et al. (2014), namely 2,200 Arabizi-to-Arabic script pairs from the training data used by Darwish (2013) (manually revised to be CODA-compliant) and about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). (Since these pairs are not tagged, we do not use them to train the taggers.) Second, we exclude all the foreign tagged words from training the transliteration system since they were not manually corrected. Table 2 shows the overall transliteration accuracy of Arabic words and names only, using different training data sets and evaluating</context>
<context position="22140" citStr="(2014)" startWordPosition="3602" endWordPosition="3602">c &amp; Tagged Arabizi Figure 2: The architecture of our complete Arabizi processing system. The &amp;quot;Punctuation, Sound and Emoticon Detection&amp;quot; component does labeling that is read by the &amp;quot;Name&amp;quot; and &amp;quot;Foreign Word&amp;quot; taggers, While the actual Aribizi-to-Arabic transliteration system is used as a black box. Data # Words Arabic Foreign Name Sound Punct Emoticon Train-S 21,950 80.5% 12.1% 2.8% 1.7% 1.3% 1.6% Train-L 113,490 82.3% 9.8% 2.4% 1.8% 1.1% 2.6% Dev 5,061 76.3% 16.2% 2.9% 1.8% 1.2% 1.5% Test 31,717 86.1% 6.0% 2.7% 1.6% 0.9% 2.8% Table 1: Dataset Statistics Data Translit. Acc. Al-Badrashiny et al. (2014) 68.6% Train-S 76.9% Train-L 79.5% Table 2: Transliteration accuracy of Arabic words and names when using different training sets and evaluating on Dev bigger training set Train-L. The overall transliteration accuracy of Arabic words and names on Test using the bigger training set Train-L is 83.6%. 6 Tagging Punctuation, Emoticons and Sounds 6.1 Approach We start the tagging process by detecting three types of closed classes: punctuation, sounds and emoticons. Simple regular expressions perform very well at detecting their occurrence in text. The regular expressions are applied to the Arabizi </context>
</contexts>
<marker>2014c, </marker>
<rawString>LDC. 2014c. BOLT Program: Romanized Arabic (Arabizi) to Arabic Transliteration and Normalization Guidelines. Version 3. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Jey Han Lau</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic detection and language identification of multilingual documents.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="7729" citStr="Lui et al. (2014)" startWordPosition="1263" endWordPosition="1266">eling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA based on the context. The tagging process mainly depends on the language modeling (LM) approach, but if a word is unknown in the LM, then its tag is assigned through MADAMIRA, a morphological disambiguator Pasha et al. (2014). Lui et al. (2014) proposed a system that does language identification in multilingual documents, using a generative mixture model that is based on supervised topic modeling algorithms. This is similar to our work in terms of identifying code switching. However, our system deals with Arabizi, a non-standard orthography with high variability, making the identification task much harder. Concerning specifically NLP for Arabizi, Darwish (2013) (published in an updated version as (Darwish, 2014)) is similar to our work in that he identifies English in Arabizi text and he also transliterates Arabic text from Arabizi </context>
</contexts>
<marker>Lui, Lau, Baldwin, 2014</marker>
<rawString>Marco Lui, Jey Han Lau, and Timothy Baldwin. 2014. Automatic detection and language identification of multilingual documents. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arfath Pasha</author>
<author>Mohamed Al-Badrashiny</author>
<author>Mona Diab</author>
<author>Ahmed El Kholy</author>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Manoj Pooleery</author>
<author>Owen Rambow</author>
<author>Ryan M Roth</author>
</authors>
<title>MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik,</booktitle>
<marker>Pasha, Al-Badrashiny, Diab, El Kholy, Eskander, Habash, Pooleery, Rambow, Roth, 2014</marker>
<rawString>Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab, Ahmed El Kholy, Ramy Eskander, Nizar Habash, Manoj Pooleery, Owen Rambow, and Ryan M. Roth. 2014. MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: An experimental study.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1524--1534</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6299" citStr="Ritter et al., 2011" startWordPosition="1012" endWordPosition="1015">valuate the complete system. This paper is structured as follows. We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3). After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8. The evaluation results are presented in Section 9. 2 Related Work While natural language processing for English in social media has attracted considerable attention recently (Clark and Araki, 2011; Gimpel et al., 2011; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. We give a brief summary of relevant work on Arabic. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of DA such as the lack of a standard orthography. However, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are inter</context>
</contexts>
<marker>Ritter, Clark, Mausam, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named entity recognition in tweets: An experimental study. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1524–1534, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Clare Voss</author>
<author>Stephen Tratz</author>
<author>Jamal Laoudi</author>
<author>Douglas Briesch</author>
</authors>
<title>Finding Romanized Arabic Dialect in Code-Mixed Tweets.</title>
<date>2014</date>
<booktitle>Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors,</editor>
<location>Reykjavik, Iceland,</location>
<contexts>
<context position="9239" citStr="Voss et al. (2014)" startWordPosition="1498" endWordPosition="1501">: Arabic, foreign and others (such as email addresses and URLs). In contrast, we identify a bigger set: Arabic, foreign, names, sounds, punctuation 2 and emoticons. Furthermore, Darwish (2013) uses around 5K words for training his taggers and 3.5K words for testing; this is considerably smaller than our training and test sets of 113K and 32K words, respectively. Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration. Their work does not address the detection of English words, punctuation, emoticons, and so on. They also do not handle English when mixed with Arabizi. Voss et al. (2014) deal with exactly the problem of classifying tokens in Arabizi as Arabic or not. More specifically, they deal with Moroccan Arabic, and with both French and English, meaning they do a three-way classification. There are many differences between our work and theirs: they have noisy training data, and they have a much more balanced test set. They also only deal with foreignness, and do not address the other tags we deal with, nor do they actually discuss transliteration itself. 3 Linguistic Facts and Data Annotation 3.1 Arabizi Arabizi refers to Arabic written using the Roman script (Darwish, 2</context>
</contexts>
<marker>Voss, Tratz, Laoudi, Briesch, 2014</marker>
<rawString>Clare Voss, Stephen Tratz, Jamal Laoudi, and Douglas Briesch. 2014. Finding Romanized Arabic Dialect in Code-Mixed Tweets. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
<author>Chris Callison-Burch</author>
</authors>
<title>The Arabic online commentary dataset: an annotated dataset of informal Arabic with high dialectal content. In</title>
<date>2011</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>37--41</pages>
<contexts>
<context position="6889" citStr="Zaidan and Callison-Burch (2011)" startWordPosition="1115" endWordPosition="1118">1; Gouws et al., 2011; Ritter et al., 2011; Derczynski et al., 2013), there has not been much work on Arabic yet. We give a brief summary of relevant work on Arabic. Darwish et al. (2012) discuss NLP problems in retrieving Arabic microblogs (tweets). They discuss many of the same issues we do, notably the problems arising from the use of DA such as the lack of a standard orthography. However, they do not deal with DA written in the Roman alphabet (though they do discuss non-Arabic characters). There is some work on code switching between Modern Standard Arabic (MSA) and dialectal Arabic (DA). Zaidan and Callison-Burch (2011) are interested in this problem at the intersentence level. They crawl a large dataset of MSA-DA news commentaries. They use Amazon Mechanical Turk to annotate the dataset at the sentence level. Then they use a language modeling approach to predict the class (MSA or DA) for an unseen sentence. There is other work on dialect identification, such as AIDA (Elfardy et al., 2013; Elfardy et al., 2014). In AIDA, some statistical and morphological analyses are applied to capture code switching between MSA and DA within the same sentence. Each word in the sentence is tagged to be either DA or MSA base</context>
</contexts>
<marker>Zaidan, Callison-Burch, 2011</marker>
<rawString>Omar F Zaidan and Chris Callison-Burch. 2011. The Arabic online commentary dataset: an annotated dataset of informal Arabic with high dialectal content. In Proceedings of ACL, pages 37–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Zribi</author>
<author>Rahma Boujelbane</author>
<author>Abir Masmoudi</author>
<author>Mariem Ellouze</author>
<author>Lamia Belguith</author>
<author>Nizar Habash</author>
</authors>
<title>A Conventional Orthography for Tunisian Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik,</booktitle>
<contexts>
<context position="16242" citStr="Zribi et al., 2014" startWordPosition="2648" endWordPosition="2651">hat the annotation of this data was intended to serve a project focusing on machine translation from dialectal Arabic into English. This goal influenced some of the annotation decisions and was part of the reason for this selection of word tags. Arabizi-to-Arabic Transliteration The second annotation task is about converting Arabizi to an Arabic-script-based orthography. Since, dialectal Arabic including Egyptian Arabic has no standard orthography in Arabic script, the annotation uses a conventionalized orthography for Dialectal Arabic called CODA (Habash et al., 2012a; Eskander et al., 2013; Zribi et al., 2014). Every word has a single orthographic representation in CODA. In the corpus we use, only words tagged as Arabic or Name are manually checked and corrected. The transliteration respects the whitespace boundaries of the original Arabizi words. In cases where an Arabizi word represents a prefix or suffix that should be joined in CODA to the next or previous word, a [+] symbol is added to mark this decision. Similarly, for Arabizi words that should be split into multiple CODA words, the CODA words are written with added [-] symbol delimiting the word boundaries. The Arabic transliteration task al</context>
</contexts>
<marker>Zribi, Boujelbane, Masmoudi, Ellouze, Belguith, Habash, 2014</marker>
<rawString>Ines Zribi, Rahma Boujelbane, Abir Masmoudi, Mariem Ellouze, Lamia Belguith, and Nizar Habash. 2014. A Conventional Orthography for Tunisian Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik, Iceland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>