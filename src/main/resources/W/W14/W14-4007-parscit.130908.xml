<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.967457">
Expanding the Language model in a low-resource hybrid MT system
</title>
<author confidence="0.617925">
George Tambouratzis Sokratis Sofianopoulos Marina Vassiliou
</author>
<affiliation confidence="0.515669">
ILSP, Athena R.C ILSP, Athena R.C ILSP, Athena R.C
</affiliation>
<email confidence="0.987325">
giorg_t@ilsp.gr s_sofian@ilsp.gr mvas@ilsp.gr
</email>
<sectionHeader confidence="0.99498" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.72692">
The present article investigates the fusion of
different language models to improve transla-
tion accuracy. A hybrid MT system, recently-
developed in the European Commission-
funded PRESEMT project that combines ex-
ample-based MT and Statistical MT princi-
ples is used as a starting point. In this article,
the syntactically-defined phrasal language
models (NPs, VPs etc.) used by this MT sys-
tem are supplemented by n-gram language
models to improve translation accuracy. For
specific structural patterns, n-gram statistics
are consulted to determine whether the pat-
tern instantiations are corroborated. Experi-
ments indicate improvements in translation
accuracy.
</bodyText>
<sectionHeader confidence="0.999115" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99948801369863">
Currently a major part of cutting-edge research
in MT revolves around the statistical machine
translation (SMT) paradigm. SMT has been in-
spired by the use of statistical methods to create
language models for a number of applications
including speech recognition. A number of dif-
ferent translation models of increasing complex-
ity and translation accuracy have been developed
(Brown et al., 1993). Today, several packages for
developing statistical language models are avail-
able for free use, including SRI (Stolke et al.,
2011), thus supporting research into statistical
methods. A main reason for the widespread
adoption of SMT is that it is directly amenable to
new language pairs using the same algorithms.
An integrated framework (MOSES) has been
developed for the creation of SMT systems
(Koehn et al., 2007). The more recent develop-
ments of SMT are summarised by Koehn (2010).
One particular advance in SMT has been the in-
tegration of syntactically motivated phrases in
order to establish correspondences between
source language (SL) and target language (TL)
(Koehn et al., 2003). Recently SMT has been
enhanced by using different levels of abstraction
e.g. word, lemma or part-of-speech (PoS), in fac-
tored SMT models so as to improve SMT per-
formance (Koehn &amp; Hoang, 2007).
The drawback of SMT is that SL-to-TL paral-
lel corpora of the order of millions of tokens are
required to extract meaningful models for trans-
lation. Such corpora are hard to obtain, particu-
larly for less resourced languages. For this rea-
son, SMT researchers are increasingly investigat-
ing the extraction of information from monolin-
gual corpora, including lexica (Koehn &amp; Knight,
2002 &amp; Klementiev et al., 2012), restructuring
(Nuhn et al., 2012) and topic-specific informa-
tion (Su et al., 2011).
As an alternative to pure SMT, the use of less
specialised but more readily available resources
has been proposed. Even if such approaches do
not provide a translation quality as high as SMT,
their ability to develop MT systems with very
limited resources confers to them an important
advantage. Carbonell et al. (2006) have proposed
an MT method that requires no parallel text, but
relies on a full-form bilingual dictionary and a
decoder using long-range context. Other systems
using low-cost resources include METIS
(Dologlou et al., 2003) and METIS-II (Markan-
tonatou et al., 2009), which are based only on
large monolingual corpora to translate SL texts.
Another recent trend in MT has been towards
hybrid MT systems, which combine characteris-
tics from multiple MT paradigms. The idea is
that by fusing characteristics from different para-
digms, a better translation performance can be
attained (Wu et al., 2005). In the present article,
the PRESEMT hybrid MT method using pre-
dominantly monolingual corpora (Sofianopoulos
et al., 2012 &amp; Tambouratzis et al., 2013) is ex-
tended by integrating n-gram information to im-
prove the translation accuracy. The focus of the
article is on how to extract, as comprehensively
as possible, information from monolingual cor-
pora by combining multiple models, to allow a
higher quality translation.
A review of the base MT system is performed
in section 2. The TL language model is then de-
tailed, allowing new work to be presented in sec-
tion 3. More specifically, via an error analysis, n-
gram based extensions are proposed to augment
</bodyText>
<page confidence="0.984711">
57
</page>
<note confidence="0.782302">
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 57–66,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9956605">
the language model. Experiments are presented
in section 4 and discussed in section 5.
</bodyText>
<sectionHeader confidence="0.589548" genericHeader="method">
2 The hybrid MT methodology in brief
</sectionHeader>
<bodyText confidence="0.999955272727273">
The PRESEMT methodology can be broken
down into the pre-processing stage, the post-
processing stage and two translation steps each
of which addresses different aspects of the trans-
lation process. The first translation step estab-
lishes the structure of the translation by perform-
ing a structural transformation of the source side
phrases based on a small bilingual corpus, to
capture long range reordering. The second step
makes lexical choices and performs local word
reordering within each phrase. By dividing the
translation process in these two steps the chal-
lenging task of both local and long distance reor-
dering is addressed.
Phrase-based SMT systems give accurate
translations for language pairs that only require a
limited number of short-range reorderings. On
the contrary, when translating between languages
with free word order, these models prove ineffi-
cient. Instead, reordering models need to be built,
which require large parallel training data, as
various reordering challenges must be tackled.
</bodyText>
<subsectionHeader confidence="0.997516">
2.1 Pre-processing
</subsectionHeader>
<bodyText confidence="0.999992333333334">
This involves PoS tagging, lemmatising and
shallow syntactic parsing (chunking) of the
source text. In terms of resources, the methodol-
ogy utilises a bilingual lemma dictionary, an ex-
tensive TL monolingual corpus, annotated with
PoS tags, lemmas and syntactic phrases (chunks),
and a very small parallel corpus of 200 sen-
tences, with tagged and lemmatised source side
and tagged, lemmatised and chunked target side.
The bilingual corpus provides samples of the
structural transformation from SL to TL. During
this phase, the translation methodology ports the
chunking from the TL- to the SL-side, alleviating
the need for an additional parser in SL. An ex-
ample of the pre-processing stage is shown in
Figure 1, for a sentence translated from Greek to
English. For this sentence, the chunk structure is
shown at the bottom part of Figure 1.
</bodyText>
<subsectionHeader confidence="0.999772">
2.2 Structure Selection
</subsectionHeader>
<bodyText confidence="0.99618475">
Structure selection transforms the input text us-
ing the limited bilingual corpus as a structural
knowledge base, closely resembling the “transla-
tion by analogy” aspect of EBMT systems (Hut-
chins, 2005). Using available structural informa-
tion, namely the order of syntactic phrases, the
PoS tag of the head token of each phrase and the
case of the head token (if available), we retrieve
the most similar source side sentence from the
parallel corpus. Based on the alignment informa-
tion from the bilingual corpus between SL and
TL, the input sentence structure is transformed to
the structure of the target side translation.
For the retrieval of the most similar source
side sentence, an algorithm from the dynamic
programming paradigm is adopted (Sofianopou-
los et al., 2012), treating the structure selection
process as a sequence alignment, aligning the
input sentence to an SL side sentence from the
aligned parallel corpus and assigning a similarity
score. The implementation is based on the Smith-
Waterman algorithm (Smith and Waterman,
1981), initially proposed for similarity detection
between protein sequences. The algorithm finds
the optimal local alignment between the two in-
put sequences at clause level.
The similarity of two clauses is calculated by
taking into account the edit operations (replace-
ment, insertion or removal) that must be applied
to the input sentence in order to transform it to a
source side sentence from the corpus. Each of
these operations has an associated cost, consid-
ered as a system parameter. The parallel corpus
sentence that achieves the highest similarity
score is the most similar one to the input source
sentence. For the example of Figure 1, the com-
parison of the SL sentence structure to the paral-
lel corpus is schematically depicted in Figure 2.
The resulting TL sentence structure is shown in
Figure 3 in terms of phrase types and heads.
Ήδη από τα τέλη Μαΐου 1821 παρουσιάσθηκε ζωηρή κινητοποίηση υπέρ των
αγωνιζόμενων Ελλήνων.
[Already by the end of May 1821 a lively mobilisation was presented in favour of
Greek contestants.]
</bodyText>
<equation confidence="0.977783">
(Ήδη) (από τα τέλη Μαΐου 1821) (παρουσιάσθηκε) (ζωηρή κινητοποίηση) (υπέρ
των αγωνιζόμενων Ελλήνων).
ADVC (ad,&lt;ήδη&gt;) PC (aspp,&lt;από&gt;,no,&lt;Mάιος&gt;) VC (vb,&lt;παρουσιάζω&gt;) PC
(no,&lt;κινητοποίηση&gt;) PC (aspp,&lt;υπέρ&gt;,np,&lt;Έλληνας&gt;).
</equation>
<figureCaption confidence="0.7959505">
Figure 1. Pre-processing of sentence (its gloss in
square brackets) into a chunk sequence.
</figureCaption>
<figure confidence="0.245197">
ADVC PC VC PC PC
</figure>
<page confidence="0.931836">
58
</page>
<figure confidence="0.651569">
SL-side TL-side
</figure>
<figureCaption confidence="0.982679333333333">
Figure 2. Comparing sentence structure to paral-
lel corpus templates, to determine the best-
matching SL structure (here, the 4th entry).
</figureCaption>
<figure confidence="0.79850275">
ADVC (ad,&lt;ήδη&gt;) PC (aspp,&lt;από&gt;,no,&lt;Mάιος&gt;) VC (vb,&lt;παρουσιάζω&gt;) PC
(no,&lt;κινητοποίηση&gt;) PC (aspp,&lt;υπέρ&gt;,np,&lt;Έλληνας&gt;).
advc (rb,&lt;already&gt;) pc (in,&lt;of&gt;,nn,&lt;May&gt;) pc (nn,&lt;mobilisation&gt;) vc (vv,&lt;present&gt;)
pc (in,&lt;in&gt;,nn,&lt;Greek&gt;).
</figure>
<figureCaption confidence="0.9357865">
Figure 3. SL-to-TL Structure transformation
based on the chosen parallel corpus template.
</figureCaption>
<subsectionHeader confidence="0.998945">
2.3 Translation equivalent selection
</subsectionHeader>
<bodyText confidence="0.999876333333333">
This second translation step performs word trans-
lation disambiguation, local word reordering
within each syntactic phrase as well as addition
and/or deletion of auxiliary verbs, articles and
prepositions. All of the above are performed by
using a syntactic phrase model extracted from a
purely monolingual TL corpus. The final transla-
tion is produced by the token generation compo-
nent, since all processing during the translation
process is lemma-based.
Each sentence contained within the text to be
translated is processed separately, so there is no
exploitation of inter-sentential information. The
first task is to select the correct TL translation of
each word. The second task involves establishing
the correct word order within each phrase. For
each phrase of the sentence being translated, the
algorithm searches the TL phrase model for simi-
lar phrases. All retrieved TL phrases are com-
pared to the phrase to be translated. The com-
parison is based on the words included, their tags
and lemmas and any other morphological fea-
tures (case, number etc.). The stable-marriage
algorithm (Gale &amp; Shapley, 1962) is applied for
calculating the similarity and aligning the words
of a phrase pair.
This word reordering process is performed si-
multaneously with the translation disambigua-
tion, using the same TL phrase model. During
word reordering the algorithm also resolves is-
sues regarding the insertion or deletion of articles
and other auxiliary tokens. Though translation
equivalent selection implements several tasks
simultaneously, it produces encouraging results
when translating from Greek (a free-word order
language) to English (an SVO language).
</bodyText>
<subsectionHeader confidence="0.999867">
2.4 Post-processing
</subsectionHeader>
<bodyText confidence="0.9999825">
In this stage, a token generator is applied to the
lemmas of the translated sentences together with
the morphological features of their equivalent
source words, to produce the final word forms.
</bodyText>
<subsectionHeader confidence="0.997566">
2.5 Comparison of the method to SMT
</subsectionHeader>
<bodyText confidence="0.999983333333333">
In the proposed methodology, the structure selec-
tion step performs long distance reordering with-
out resorting to syntactic parsers and without
employing any rules. In phrase-based SMT, long
distance reordering is performed by either using
SL syntax, with the use of complex reordering
rules, or by using syntactic trees.
The similarity calculation algorithms used in
the two translation steps of the proposed method
are of a similar nature to the extraction of trans-
lation models in factored-based SMT. In SMT,
different matrices are created for each model (i.e.
one for lemmas and another one for PoS tags),
while in the methodology studied here lemmas
and tags are handled at the same time.
The main advantage of the method studied
here is its ability to create a functioning MT sys-
tem with a parallel corpus of only a few sen-
tences (200 sentences in the present experi-
ments). On the contrary, it would not be possible
to create a working SMT with such a corpus.
</bodyText>
<sectionHeader confidence="0.9622955" genericHeader="method">
3 Information extraction from the
monolingual corpus
</sectionHeader>
<subsectionHeader confidence="0.999879">
3.1 Standard indexed phrase model
</subsectionHeader>
<bodyText confidence="0.999860375">
The TL monolingual corpus is processed to ex-
tract two complementary types of information,
both employed at the second phase of the transla-
tion process (cf. sub-section 2.3). The first im-
plements a disambiguation between multiple
possible translations, while the second provides
the micro-structural information to establish to-
ken order in the final translation.
</bodyText>
<figure confidence="0.892365909090909">
PC VC ADVC PC
ADVC PC VC PC PC
PC VC PC
PC VC PC
ADVC PC VC PC PC
advc pc pc vc pc
pc vc pc
pc advc vc pc
pc pc vc
advc pc pc vc pc
ADVC PC VC PC PC
</figure>
<page confidence="0.991947">
59
</page>
<bodyText confidence="0.999961032258065">
Both these types of information are extracted
from one model. More specifically, during pre-
processing of the corpus, a phrase model is es-
tablished that provides the micro-structural in-
formation on the translation output, to determine
intra-phrasal word order. The model is stored in
a file structure, where a separate file is created
for phrases according to their (i) type, (ii) head
and (iii) head PoS tag.
The TL phrases are then organised in a hash
map that allows the storage of multiple values for
each key, using as a key the three aforemen-
tioned criteria. For each phrase the number of
occurrences within the corpus is also retained.
Each hash map is stored independently in a file
for very fast access by the search algorithm. As a
result of this process hundreds of thousands of
files are generated, one for each combination of
the three aforementioned criteria. Each file is of
a small size and thus can be retrieved quickly.
For creating the model used here, a corpus of
30,000 documents has been processed for the
TL, where each document contains a concatena-
tion of independent texts of approximately
1MByte in size. The resulting phrase model con-
sists of 380,000 distinct files, apportioned into
12,000 files of adjectival chunks, 348,000 of
noun chunks, 17,000 of verb chunks and 3,000 of
adverbial chunks. A sample of the indexed file
corresponding to verb phrases with head ‘help’ is
shown in Figure 4.
</bodyText>
<figure confidence="0.738012333333333">
Occurrences Phrase structure
1 41448 help (VV)
2 29575 to(TO) help(VV)
3 5896 will(MD) help(VV)
4 4795 can(MD) help(VV)
5 2632 have(VHD) help(VVN)
</figure>
<figureCaption confidence="0.999127">
Figure 4. Example of indexed file for “help”.
</figureCaption>
<subsectionHeader confidence="0.997295">
3.2 Error analysis on translation output
</subsectionHeader>
<bodyText confidence="0.983559363636364">
In Table 1, the translation accuracy attained by
the proposed hybrid approach in comparison to
established systems is displayed. The proposed
method occupies the middle ground between the
two higher performing SMT-based systems
(Bing and Google) and the Systran and World-
Lingo commercial systems.
Though the BLEU score of the proposed
method is 0.17 BLEU points lower than the
Google score, the proposed method achieves
what is a respectable score with a parallel corpus
of only 200 sentences. Though the exact re-
sources for Google or Bing are not disclosed, it is
widely agreed that they are at least 3 orders of
magnitude larger (very likely even more) justify-
ing the lower scores achieved by the proposed
low-resource method.
Table 1. Values of performance metrics for data-
set1, using the baseline version of the proposed
method and other established systems.
The n-gram method proposed in this article for
supplementary language modelling is intended to
identify recurring errors in the output or to verify
translation choices made by the indexed mono-
lingual model. The errors mainly concern gen-
eration of tokens out of lemmata, positioning of
tokens within phrases as well as disambiguation
choices. An indicative list of errors encountered
for Greek to English translation follows:
Article introduction &amp; deletion: Given that
there is no 1:1 mapping between Greek and Eng-
lish concerning the use of the definite article, it is
essential to check whether it is correctly intro-
duced in specific cases (e.g. before proper
names).
Generation of verb forms: Specific errors of
the MT system involve cases of active/passive
voice mismatches between SL and TL and depo-
nent verbs, i.e. active verbs with mediopassive
morphology. For example, the Greek deponent
verb &amp;quot;Epxogαi,&amp;quot; (come) is translated to “be come”
by the system token generation component that
takes into account the verb’s passive morphology
in SL. This erroneous translation should be cor-
rected to “come”, i.e. the auxiliary verb “be”
must be deleted.
In-phrase token order: The correct ordering
of tokens within a given phrase (which occasion-
ally fails to be established by the proposed sys-
tem) can be verified via the n-gram model.
Prepositional complements: When translat-
ing the prepositional complement of a verb (cf.
“depend + on”), it is often the case that the incor-
rect preposition is selected during disambigua-
tion, given that no context information is avail-
</bodyText>
<figure confidence="0.99884090625">
Number of sentences 200 Resources stand.
Reference translations 1 Language EL–EN
pair
PRESEMT- 0.3462 6.974 0.3947 51.05
baseline
Bing
WorldLingo
Google
SYSTRAN
0.5259
0.4974
0.2930
0.2659
6.466
5.998
8.538
8.279
0.4609
0.4524
0.3830
0.3666
42.23
49.72
34.18
50.63
MT config.
BLEU
NIST
Me-
teor
TER
Metrics
</figure>
<page confidence="0.965888">
60
</page>
<bodyText confidence="0.953868384615385">
able. The n-gram model may be accessed to
identify the appropriate preposition.
Double preposition: Prepositions appearing
in succession within a sentence need to be re-
duced to one. For instance, the translation of the
NP “xαzdc zri 6tdcpxetα zris xoAtopxiαs” (= during
the siege) results in a prepositional sequence
(“during of”) due to the translation of the indi-
vidual parts as follows:
κατά τη διάρκεια = during
της = of the
πολιορκίας = siege
In this example a single preposition is needed.
</bodyText>
<subsectionHeader confidence="0.999379">
3.3 Introducing n-gram models
</subsectionHeader>
<bodyText confidence="0.9999579375">
A new model based on n-gram appearances is
intended to supplement phrase-based information
already extracted from the monolingual corpus
(cf. section 3.1). As the monolingual corpus is
already lemmatised, both lemma and token-based
n-grams are extracted. To simplify processing,
no phrase-boundary information is retained in the
n-gram models.
One issue is how the n-gram model will be
combined with the indexed phrase model of the
hybrid MT algorithm. The new n-gram model
can be applied at the same stage of the transla-
tion process. Alternatively, n-grams can be ap-
plied after the indexed phrase model, for verifi-
cation or revision of the translation produced by
using the indexed corpus. Then, the indexed
phrase model generates a first translation, which
represents a hypothesis Hi, upon which a number
of tests are performed. If the n-gram model cor-
roborates this hypothesis, no modification is ap-
plied, whilst if the n-gram likelihood estimates
lead to the rejection of the hypothesis, the trans-
lation is revised accordingly.
Having adopted this set-up, the main task is to
specify the hypotheses to be tested. To that end,
a data-driven approach based on the findings of
the error analysis (cf. section 3.2) is used.
The creation of the TL n-gram model is
straightforward and employs the publicly avail-
able SRILM tool (Stolke et al., 2011) to extract
n-gram probabilities. Both 2-gram and 3-gram
models have been extracted, creating both token-
based and lemma-based models to support que-
ries in factored representation levels. The n-gram
models have used 20,000 documents in English,
each document being an assimilation of web-
posted texts with a cumulative size of 1 Mbyte
(harvested without any restrictions in terms of
domain). Following a pre-processing to remove
words with non-English characters, the final cor-
pus contains a total of 707.6 million tokens and
forms part of the EnTenTen corpus1. When cre-
ating both 2-grams and 3-grams, Witten-Bell
smoothing is used and all n-grams with less than
5 occurrences are filtered out to reduce the model
size. Each n-gram model contains circa 25 mil-
lion entries, which are the SRILM-derived loga-
rithms of probabilities.
</bodyText>
<subsectionHeader confidence="0.996986">
3.4 Establishing translation hypotheses
</subsectionHeader>
<bodyText confidence="0.999614285714286">
A set of hypotheses has been established based
on the error analysis, to improve the translation
quality. Each hypothesis is expressed by a
mathematical formula which checks the likeli-
hood of an n-gram, via either the lemma-based n-
gram model (the relevant entry being denoted as
p_lem(), i.e. the probability of the n-gram of
lemmas) or the token-based model (the relevant
entry being denoted as p_tok). The relevant 2-
gram or 3-gram model is consulted depending on
whether the number of arguments is 2 or 3.
Hypothesis H1: This hypothesis checks for the
existence of a deponent verb, i.e. verb which is in
passive voice in SL but has an active voice trans-
lation. Instead of externally providing a list of
deponent verbs in Greek, the n-gram model is
used to determine translations for which the verb
is always in active voice, by searching the fre-
quency-of-occurrence in the TL corpus. As an
example of a correct rejection of hypothesis H1,
consider the verb “κοιgάgαι” [to sleep] which is
translated by the hybrid MT system into “be
slept” as in SL this verb has a medio-passive
morphology. As the pattern “be slept” is ex-
tremely infrequent in the monolingual corpus,
hypothesis H1 is rejected and lemma “be” is cor-
rectly deleted, to translate “κoιgά�αι” into
“sleep”. The corresponding hypothesis is:
</bodyText>
<equation confidence="0.495974">
H1 :p_lem (A,B)&gt;thres_h1,
</equation>
<bodyText confidence="0.938916363636364">
where Lem (A)=”be” and PoS(B) =”VVN”
If the aforementioned hypothesis does not
hold, (i.e. the probability of the 2-gram formed
by the auxiliary verb with lemma B is very rare)
then H1 is rejected and the auxiliary verb is de-
leted, as expressed by the following formula:
If (H1 == false) then {A, B} — {B}
Hypothesis H2: This hypothesis checks the in-
clusion of an article, within a trigram of word
forms. If this hypothesis is rejected based on n-
gram evidence, the article is deleted. Hypothesis
</bodyText>
<footnote confidence="0.9885805">
1http://www.sketchengine.co.uk/documentation/wiki/Corpor
a/enTenTen
</footnote>
<page confidence="0.995382">
61
</page>
<bodyText confidence="0.399954">
that the bigram frequency exceeds a given
threshold value (thres_6).
H2 is expressed as follows, where thres_h2 is a
minimum threshold margin:
</bodyText>
<equation confidence="0.793395">
H2: min{p_lem(A,the),p_lem(the,B)} - p_lem(A;B) &lt;
thres_h2
</equation>
<bodyText confidence="0.9446151">
An example of correctly rejecting H2 is for tri-
gram {see, the, France}, which is revised to {see,
France}.
If (H2 == false) then {A, the, B} → {A, B}
Hypothesis H3: This hypothesis is used to han-
dle cases where two consecutive prepositions
exist (for prepositions the PoS tag is “IN”). In
this case one of these prepositions must be de-
leted, based on the n-gram information. This
process is expressed as follows:
</bodyText>
<equation confidence="0.890683333333333">
H3 : max((p_lem(A;B),p_lem(A,C)), where PoS(A)==”IN”
&amp; PoS(B)==”IN”
If (H3==TRUE) then {A, B, C} → {A, C} or {B, C}
</equation>
<bodyText confidence="0.888694923076923">
Hypothesis H4: This hypothesis checks if there
exists a more suitable preposition than the one
currently selected for a given trigram {A, B, C},
where PoS(B) = “IN”. H4 is expressed as:
H4: p_lem(A,B,C)-max(p_lem(A,D,C)&gt;thres_h4 ,
for all D where PoS{D}==“IN”.
If this hypothesis is rejected, B is replaced by
D:
If (H4==FALSE) then ({A,B,C} → {A,D,C}
Hypothesis H5: This hypothesis checks if for a
bigram, the wordforms might be replaced by the
corresponding lemmas, as the wordform-based
pattern is too infrequent. This is formulated as:
</bodyText>
<equation confidence="0.776931">
H5: p_tok(A,B)- p_tok(lem(A),lem(B)) &gt; thres_h5
</equation>
<bodyText confidence="0.998486">
An example application would involve proc-
essing bigram {can, is} and revising it into the
correct {can, be} by rejecting H5:
</bodyText>
<subsubsectionHeader confidence="0.350811">
If (H5==FALSE) then {A,B } → {lem(A),lem(B)}
</subsubsectionHeader>
<bodyText confidence="0.9997616">
Similarly, H5 can revise the plural form “in-
formations” to the correct “information”.
Hypothesis H6: This hypothesis also handles
article deletion, by studying however bigrams,
rather than trigrams, (cf. H1). This hypothesis is
</bodyText>
<equation confidence="0.70835">
H6 :p_lem(2-gram(A, B))&gt;thres_h6, where PoS(A)=”DT”
</equation>
<bodyText confidence="0.675586">
If H6 is rejected, the corresponding article is
deleted, as indicated by the following formula:
If (H6==FALSE) then {A,B} → {B}
</bodyText>
<sectionHeader confidence="0.993901" genericHeader="method">
4 Objective Evaluation Experiments
</sectionHeader>
<subsectionHeader confidence="0.988444">
4.1 Experiment design
</subsectionHeader>
<bodyText confidence="0.999986772727273">
The experiments reported in the present article
focus on the Greek – English language pair, the
reason being that this is the language pair for
which the most extensive experimentation has
been reported for the PRESEMT system (Tam-
bouratzis et al., 2013). Thus, improvements in
the translation accuracy will be more difficult to
attain. Two datasets are used to evaluate transla-
tion accuracy, a development set (dataset1) and a
test set (dataset2), each containing 200 sentences
of length ranging from 7 to 40 tokens. These sets
of sentences are readily available for download
over the project website2. Two versions of the
bilingual lexicon have been used, a base version
and an expanded one.
Both sets are manually translated by Greek na-
tive speakers and then cross-checked by English
native speakers, with one reference translation
per sentence. A range of evaluation metrics are
employed, namely BLEU (Papineni et al., 2002),
NIST (NIST 2002), Meteor (Denkowski and La-
vie, 2011) and TER (Snover et al., 2006).
</bodyText>
<subsectionHeader confidence="0.982572">
4.2 Experimental results
</subsectionHeader>
<bodyText confidence="0.999989142857143">
The exact sequence with which hypotheses are
tested affects the results of the translation, since
only one hypothesis is allowed to be applied to
each sentence token at present. This simplifies
the evaluation of the hypotheses’ effectiveness.
As a result, hypotheses are applied in strict order
(i.e. first H1, then H2 etc.). The threshold values
of Table 2 were settled upon via limited experi-
mentation using sentences from dataset1.
Hypothesis testing was applied to both data-
sets. Notably, dataset1 has been used in the de-
velopment of the MT systems and thus the re-
sults obtained with dataset2 should be considered
the most representative ones, as they are com-
</bodyText>
<footnote confidence="0.940138">
2 www.presemt.eu
</footnote>
<page confidence="0.999174">
62
</page>
<bodyText confidence="0.851339">
pletely unbiased and the set of sentences was
unseen before the experiment and was only
translated once. The number of times each hy-
pothesis is tested for each dataset is quoted in
Table 3, for both the standard (denoted as
“stand”) and the enriched resources (“enrich”).
</bodyText>
<tableCaption confidence="0.99998">
Table 2. Parameter values for experiments
Table 3. Tested hypotheses per dataset
</tableCaption>
<bodyText confidence="0.93750745">
Since the first four hypotheses are only acti-
vated a few times each, when reporting the re-
sults, the applications of hypotheses H1 to H4
are grouped together. As hypotheses 5 and 6 are
tested more frequently, the application of each
one of them is reported separately.
Number of sentences 200 Resources stand.
Reference transla- 1 Language EL–EN
tions pair
ing to the n-gram model information. Still the
difference in Meteor scores is minor (less than
0.3%). The improvements in BLEU, NIST and
TER are respectively +1.6%, +1.0% and -1.2%
over the baseline, when using all 6 hypotheses.
Furthermore, as the number of hypotheses to be
tested increases, the performance for all three
metrics is improved.
Number of sentences 200 Resources enrich.
Reference transla- 1 Language EL–EN
tions pair
</bodyText>
<figure confidence="0.994149696428572">
thres_h4
thres_h5
thres_h6
(H6)Chk11
(H4)Chk8
(H5)chk2
-5.50
1.50
1.50
Parameter name
thres_h1
thres_h2
hypothesis
(H1) chk4
(H2)chk5
Exper.value
-4.50
-4.00
Hypothesis activations per experiment
Resource
H1
H2
H3
H4
H5
H6
stand.
68
32
2
7
6
1
dataset 1
enrich.
68
32
3
6
8
1
stand.
62
32
13
0
3
9
dataset 2
enrich
44
68
10
0
3
8
</figure>
<tableCaption confidence="0.74792">
Table 4. Metric scores for dataset1, using the
</tableCaption>
<bodyText confidence="0.9819409">
standard language resources, for the baseline sys-
tem and for different hypotheses.
In Table 4, the results are depicted for the four
MT objective evaluation metrics, when using
dataset 1. For each metric, the configuration giv-
ing the highest score is depicted in boldface. As
can be seen, the best BLEU score is obtained
when checking all 6 hypotheses, and the same
applies to NIST and TER. On the contrary, for
Meteor the best result is obtained without resort-
</bodyText>
<table confidence="0.557490730769231">
MT config.
0.3462
0.3479
0.3503
0.3517
7.006
7.049
6.974
6.985
0.3947
0.3941
0.3944
0.3935
50.42
51.05
50.84
50.80
Metrics
BLEU
NIST
Meteor
TER
H1 to H4
H1 to H5
H1 to H6
Baseline
</table>
<tableCaption confidence="0.751175">
Table 5. Metric scores for dataset1, using en-
</tableCaption>
<bodyText confidence="0.986468176470588">
riched language resources, for different systems.
In Table 5, the same experiment is repeated
using an enriched set of lexical resources includ-
ing a bilingual lexicon with higher coverage. No-
tably, on a case-by-case comparison, the scores
in Table 5 are higher than those of Table 4, con-
firming the benefits of using enriched lexical
resources. Focusing on Table 5, and comparing
the MT configurations without and with hy-
pothesis testing, the results obtained are qualita-
tively similar to those of Table 4. Again, the best
scores for Meteor are obtained when no hypothe-
ses are tested. On the other hand, for the other
metrics the n-gram modeling coupled with hy-
pothesis testing results in an improvement to the
scores obtained. The improvements obtained
amount to approximately 1.0% for each one of
BLEU, NIST and TER, over the baseline system
scores indicating a measurable improvement.
In Tables 6 and 7, the respective experiments
are reported, using dataset 2 instead of dataset 1,
with (i) standard and (ii) enriched lexical re-
sources. With standard resources (Table 6), con-
sistent improvements are achieved as more hy-
potheses are activated, for both BLEU and NIST.
In the case of Meteor, the best performance is
obtained when no hypotheses are activated, but
once again the Meteor score varies minimally
(by less than 0.2%). On the contrary, the im-
provement obtained by activating hypothesis-
checking is equal to 3.0% (BLEU), 1.4% (NIST)
and 1.2% (TER). As can be seen, the improve-
ment for previously unused dataset2 is propor-
tionally larger than for dataset1.
</bodyText>
<figure confidence="0.977335730769231">
MT config.
0.3518
0.3518
0.3541
0.3551
7.046
7.054
7.094
7.135
0.3997
0.3990
0.3995
0.3984
49.72
49.37
50.14
50.00
Metrics
BLEU
NIST
Meteor
TER
Baseline
H1 to H4
H1 to H5
H1 to H6
</figure>
<tableCaption confidence="0.801248333333333">
Table 6. Metric scores for dataset2, using stan-
dard language resources, for different systems.
Table 7. Metric scores for dataset2, using en-
</tableCaption>
<bodyText confidence="0.99378209375">
riched language resources, for different systems.
Using the enriched resources, as indicated in
Table 7, the best results for BLEU and Meteor
are obtained with hypotheses 1 to 5, while for
NIST and TER the best results are obtained when
all six hypotheses are tested. In the case of Me-
teor any improvement is marginal (of the order
of 0.2%). The improvements of the other metrics
are more substantial, being 3.3% for BLEU,
1.6% for NIST and 1.0% for TER.
A statistical analysis has been undertaken to
determine whether the additional n-gram model-
ling improves significantly the translation scores.
More specifically, paired t-tests were carried out
to determine whether the difference in translation
accuracy was statistically significant, comparing
the MT accuracy obtained with all six hypothe-
ses versus the baseline system. Two populations
were formed by scoring independently each
translated sentence with each one of the NIST,
BLEU and TER metrics, for dataset2. It was
found that when using the standard resources (cf.
Table 6), the translations were scored by TER to
be significantly better when using the 6 hypothe-
ses, in comparison to the baseline system, while
for BLEU and NIST the translations for the 2
systems were equivalent (at a 0.05 confidence
level). When using the enriched resources, no
statistically significant difference was detected
for any metric at a 0.05 confidence level, but
significant differences were detected for all 3
metrics at a 0.10 confidence level (cf. Table 7).
</bodyText>
<sectionHeader confidence="0.999672" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999950322580645">
According to the experimental results, the addi-
tion of a new model in the hybrid MT system has
contributed to an improved translation quality.
These improvements have been achieved using a
limited experimentation time and only a few hy-
potheses on what is an extensively developed
language pair, for the proposed MT methodol-
ogy. It is likely that as the suite of hypotheses is
increased, larger improvements in objective met-
rics can be obtained.
When applying the hypotheses, the initial sys-
tem translation is available both at token-level
and at lemma-level. Out of the 6 hypotheses
tested here, 5 involve token-based information
and only one involves lemmas. If additional hy-
potheses are added operating on lemmas, a fur-
ther improvement is expected.
Notably, the new n-gram modelling requires
no collection or annotation of additional re-
sources. The use of an established software
package (SRILM) for assembling an n-gram da-
tabase, via which hypotheses are rejected or con-
firmed, results in a straightforward implementa-
tion. In addition, multiple models can be effec-
tively combined to improve translation accuracy
by investigating different language aspects.
An interesting point is that the n-gram models
created are factored (i.e. including information at
both lemma and token level). Thus, different
types of queries may be supported, to improve
translation quality.
</bodyText>
<sectionHeader confidence="0.999915" genericHeader="discussions">
6 Future work
</sectionHeader>
<bodyText confidence="0.9999555">
The experiments reported here have shown that
improvements can be achieved, without specify-
ing in detail the templates searched for, but al-
lowing for more general formulations.
One aspect which should be addressed in fu-
ture work concerns evaluation. Currently, this is
limited to objective metrics. Still it is well-worth
investigating the extent to which translation im-
provement is reflected by subjective metrics,
which are the preferred instrument for quality
evaluation (Callison-Burch at al., 2011).
In addition, it is possible to achieve further
improvements if the hypothesis templates are
made more detailed, by supplementing the lexi-
cal information by detailed PoS information.
Tests performed so far have used empirically-
set parameter values for the hypotheses. It is pos-
sible to adopt a systematic methodology such as
MERT or genetic algorithms to optimise the ac-
tual values of the hypotheses parameters.
</bodyText>
<figure confidence="0.998239789473684">
Number of sentences 200 Resources stand.
Reference transla- 1 Language EL–EN
tions pair
MT config.
0.2747
0.2775
0.2815
0.2837
6.193
6.217
6.246
6.280
0.3406
0.3403
0.3400
0.3401
Baseline
H1 to H4
H1 to H5
H1 to H6
Baseline
H1 to H4
H1 to H5
H1 to H6
Metrics
BLEU
NIST
Meteor
Number of sentences 200 Resources enrich.
Reference transla- 1 Language pair EL–EN
tions
MT config.
0.3008
0.3059
0.3105
0.3096
6.541
6.569
6.593
6.643
0.3784
0.3790
0.3791
0.3779
54.64
55.21
54.96
54.75
Baseline
H1 to H4
H1 to H5
H1 to H6
Metrics
BLEU
NIST
Meteor
TER
</figure>
<page confidence="0.994038">
64
</page>
<bodyText confidence="0.999981916666667">
Another observation concerns the manner in
which the two distinct language models are ap-
plied. In the present article, n-grams are used to
correct a translation already established via the
phrase indexed model, having a second-level,
error-checking role. It is possible, however, to
revise the mode of application of the language
models, so that instead of a sequential applica-
tion, the two model families are consulted at the
same time. This leads to an MT system that ex-
ploits the information from multiple models con-
currently, and is the focus of future research.
</bodyText>
<sectionHeader confidence="0.9964" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998719333333333">
The research leading to these results has received
funding from the POLYTROPON project
(KRIPIS-GSRT, MIS: 448306).
</bodyText>
<sectionHeader confidence="0.999403" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999835164556962">
Chris Callison-Burch, Philip Koehn, Christof
Monz, and Omar F. Zaidan. 2011. Findings of
the 2011Workshop on Statistical Machine
Translation. Proceedings of the 6th Workshop
on Statistical Machine Translation, pp. 22–64,
Edinburgh, Scotland, UK, July 30–31, 2011.
Jaime Carbonell, Steve Klein, David Miller, Mi-
chael Steinbaum, Tomer Grassiany, and
Jochen Frey. 2006. Context-Based Machine
Translation. Proceedings of the 7th Confer-
ence of the Association for Machine Transla-
tion in the Americas, pages 19-28.
Michael Denkowski and Alon Lavie. 2011. Me-
teor 1.3: Automatic Metric for Reliable Opti-
mization and Evaluation of Machine Transla-
tion Systems. EMNLP 2011 Workshop on Sta-
tistical Machine Translation, Edinburgh, Scot-
land, pp. 85-91.
Yannis Dologlou, Stella Markantonatou, Olga
Yannoutsou, Soula Fourla, and Nikos Ioan-
nou. 2003. Using Monolingual Corpora for
Statistical Machine Translation: The METIS
System. Proceedings of the EAMT-CLAW’03
Workshop, Dublin, Ireland, 15-17 May, pp.
61-68.
David Gale and Lloyd S. Shapley. 1962. College
Admissions and the Stability of Marriage.
American Mathematical Monthly, Vol. 69, pp.
9-14.
John Hutchins. 2005. Example-Based Machine
Translation: a Review and Commentary. Ma-
chine Translation, Vol. 19, pp.197-211.
Alexandre Klementiev, Ann Irvine, Chris Calli-
son-Burch and David Yarowsky. 2012. To-
ward Statistical Machine Translation without
Parallel Corpora. Proceedings of EACL2012,
Avignon, France, 23-25 April, pp. 130-140.
Philip Koehn. 2010. Statistical Machine Transla-
tion. Cambridge University Press, Cambridge.
Philipp Koehn and Kevin Knight. 2002. Learning
a Translation Lexicon from Monolingual Cor-
pora. Proceedings of the ACL-02 workshop on
Unsupervised lexical acquisition, Vol.9, pp.9-
16.
Philipp Koehn, Franz Josef Och, and Daniel
Marcu, Statistical Phrase-Based Translation,
Proceedings of HLT/NAACL-2003 Confer-
ence, Vol.1, pp.48-54.
Philip Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison Burch, Marcello Federico, Ni-
cola Bertoldi, Brooke Cowan, Wade Shen,
Christine Moran, Richard Zens, Chris Dyer,
Ondrej Bojar, Alexandra Constantin, and Evan
Herbst. 2007. Moses: Open Source Toolkit for
Statistical Machine Translation. Proceedings
of the ACL-2007 Demo &amp; Posters Sessions,
Prague, June 2007, pp. 177-180.
Philipp Koehn, and Hieu Hoang. 2007. Factored
Translation Models. Proceedings of the 2007
Joint Conference on Empirical Methods in
Natural Language Processing and Computa-
tional Natural Language Learning, Prague,
Czech Republic, pp. 868-876.
Stella Markantonatou, Sokratis Sofianopoulos,
Olga Yannoutsou, and Marina Vassiliou.
2009. Hybrid Machine Translation for Low-
and Middle- Density Languages. Language
Engineering for Lesser-Studied Languages, S.
Nirenburg (ed.), pp.243-274. IOS Press.
ISBN: 978-1-58603-954-7
NIST 2002. Automatic Evaluation of Machine
Translation Quality Using n-gram Co-
occurrences Statistics.
Malte Nuhn, Arne Mauser, and Hermann Ney.
2012. Deciphering Foreign Language by
Combining Language Models and Context
Vectors. Proceedings of the 50th Annual
Meeting of the Association for Computational
Linguistics, Jeju, Korea, Vol.1, pp.156-164.
</reference>
<page confidence="0.990416">
65
</page>
<reference confidence="0.999603727272727">
Kishore Papineni, Salim Roukos, Todd Ward,
and Wei-Jing Zhu. 2002. BLEU: A Method
for Automatic Evaluation of Machine Transla-
tion. 40th Annual Meeting of the Association
for Computational Linguistics, Philadelphia,
USA, pp. 311-318.
Temple F. Smith, and Michael S. Waterman.
1981. Identification of Common Molecular
Subsequences. Journal of Molecular Biology,
Vol. 147, pp. 195-197.
Matthew Snover, Bonnie Dorr, Richard
Schwartz, Linnea Micciulla, and John Mak-
houl. 2006. A Study of Translation Edit Rate
with Targeted Human Annotation. In Proceed-
ings of the 7th Conference of the Association
for Machine Translation in the Americas,
Cambridge, Massachusetts, USA, pp. 223-231.
Sokratis Sofianopoulos, Marina Vassiliou, and
George Tambouratzis. 2012. Implementing a
language-independent MT methodology. In
Proceedings of the First Workshop on Multi-
lingual Modeling, held within the ACL-2012
Conference, Jeju, Republic of Korea, 13 July,
pp.1-10.
George Tambouratzis, Sokratis Sofianopoulos,
and Marina Vassiliou (2013) Language-
independent hybrid MT with PRESEMT. In
Proceedings of HYTRA-2013 Workshop, held
within the ACL-2013 Conference, Sofia, Bul-
garia, 8 August, pp. 123-130.
Vladimir I. Levenshtein (1966): Binary codes
capable of correcting deletions, insertions, and
reversals. Soviet Physics Doklady, Vol. 10, pp.
707–710.
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer (1993)
The Mathematics of Statistical Machine
Translation: Parameter Estimation, Computa-
tional Linguistics.
Andreas Stolcke, Jing Zheng, Wen Wang, and
Victor Abrash (2011) SRILM at Sixteen: Up-
date and Outlook. Proceedings of IEEE Auto-
matic Speech Recognition and Understanding
Workshop, December 2011.
Jinsong Su, Hua Wu, Haifeng Wang, Yidong
Chen, Xiaodong Shi, Huailin Dong, and Qun
Liu (2012) Translation Model Adaptation for
Statistical Machine Translation with Monolin-
gual Topic Information. Proceedings of
ACL2012, Jeju, Republic of Korea, pp. 459-
468.
Dekai Wu (2005) MT model space: Statistical
versus compositional versus example-based
machine translation. Machine Translation,
Vol. 19, pp. 213-227.
</reference>
<page confidence="0.988981">
66
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.243177">
<title confidence="0.999465">Expanding the Language model in a low-resource hybrid MT system</title>
<author confidence="0.7028125">George Tambouratzis Sokratis Sofianopoulos Marina Vassiliou ILSP</author>
<author confidence="0.7028125">Athena R C ILSP</author>
<author confidence="0.7028125">Athena R C ILSP</author>
<author confidence="0.7028125">R C Athena</author>
<email confidence="0.520088">giorg_t@ilsp.grs_sofian@ilsp.grmvas@ilsp.gr</email>
<abstract confidence="0.996516117647059">The present article investigates the fusion of different language models to improve translation accuracy. A hybrid MT system, recentlydeveloped in the European Commissionfunded PRESEMT project that combines example-based MT and Statistical MT principles is used as a starting point. In this article, the syntactically-defined phrasal language models (NPs, VPs etc.) used by this MT system are supplemented by n-gram language models to improve translation accuracy. For specific structural patterns, n-gram statistics are consulted to determine whether the pattern instantiations are corroborated. Experiments indicate improvements in translation accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philip Koehn</author>
<author>Christof Monz</author>
<author>Omar F Zaidan</author>
</authors>
<date>2011</date>
<booktitle>Findings of the 2011Workshop on Statistical Machine Translation. Proceedings of the 6th Workshop on Statistical Machine Translation,</booktitle>
<pages>22--64</pages>
<location>Edinburgh, Scotland, UK,</location>
<marker>Callison-Burch, Koehn, Monz, Zaidan, 2011</marker>
<rawString>Chris Callison-Burch, Philip Koehn, Christof Monz, and Omar F. Zaidan. 2011. Findings of the 2011Workshop on Statistical Machine Translation. Proceedings of the 6th Workshop on Statistical Machine Translation, pp. 22–64, Edinburgh, Scotland, UK, July 30–31, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Steve Klein</author>
<author>David Miller</author>
<author>Michael Steinbaum</author>
<author>Tomer Grassiany</author>
<author>Jochen Frey</author>
</authors>
<title>Context-Based Machine Translation.</title>
<date>2006</date>
<booktitle>Proceedings of the 7th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>pages</pages>
<contexts>
<context position="2994" citStr="Carbonell et al. (2006)" startWordPosition="458" endWordPosition="461">ly for less resourced languages. For this reason, SMT researchers are increasingly investigating the extraction of information from monolingual corpora, including lexica (Koehn &amp; Knight, 2002 &amp; Klementiev et al., 2012), restructuring (Nuhn et al., 2012) and topic-specific information (Su et al., 2011). As an alternative to pure SMT, the use of less specialised but more readily available resources has been proposed. Even if such approaches do not provide a translation quality as high as SMT, their ability to develop MT systems with very limited resources confers to them an important advantage. Carbonell et al. (2006) have proposed an MT method that requires no parallel text, but relies on a full-form bilingual dictionary and a decoder using long-range context. Other systems using low-cost resources include METIS (Dologlou et al., 2003) and METIS-II (Markantonatou et al., 2009), which are based only on large monolingual corpora to translate SL texts. Another recent trend in MT has been towards hybrid MT systems, which combine characteristics from multiple MT paradigms. The idea is that by fusing characteristics from different paradigms, a better translation performance can be attained (Wu et al., 2005). In</context>
</contexts>
<marker>Carbonell, Klein, Miller, Steinbaum, Grassiany, Frey, 2006</marker>
<rawString>Jaime Carbonell, Steve Klein, David Miller, Michael Steinbaum, Tomer Grassiany, and Jochen Frey. 2006. Context-Based Machine Translation. Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, pages 19-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Alon Lavie</author>
</authors>
<title>Meteor 1.3: Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems.</title>
<date>2011</date>
<booktitle>EMNLP 2011 Workshop on Statistical Machine Translation,</booktitle>
<pages>85--91</pages>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="24804" citStr="Denkowski and Lavie, 2011" startWordPosition="3939" endWordPosition="3943">ed to evaluate translation accuracy, a development set (dataset1) and a test set (dataset2), each containing 200 sentences of length ranging from 7 to 40 tokens. These sets of sentences are readily available for download over the project website2. Two versions of the bilingual lexicon have been used, a base version and an expanded one. Both sets are manually translated by Greek native speakers and then cross-checked by English native speakers, with one reference translation per sentence. A range of evaluation metrics are employed, namely BLEU (Papineni et al., 2002), NIST (NIST 2002), Meteor (Denkowski and Lavie, 2011) and TER (Snover et al., 2006). 4.2 Experimental results The exact sequence with which hypotheses are tested affects the results of the translation, since only one hypothesis is allowed to be applied to each sentence token at present. This simplifies the evaluation of the hypotheses’ effectiveness. As a result, hypotheses are applied in strict order (i.e. first H1, then H2 etc.). The threshold values of Table 2 were settled upon via limited experimentation using sentences from dataset1. Hypothesis testing was applied to both datasets. Notably, dataset1 has been used in the development of the M</context>
</contexts>
<marker>Denkowski, Lavie, 2011</marker>
<rawString>Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems. EMNLP 2011 Workshop on Statistical Machine Translation, Edinburgh, Scotland, pp. 85-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannis Dologlou</author>
<author>Stella Markantonatou</author>
<author>Olga Yannoutsou</author>
<author>Soula Fourla</author>
<author>Nikos Ioannou</author>
</authors>
<title>Using Monolingual Corpora for Statistical Machine Translation: The METIS System.</title>
<date>2003</date>
<booktitle>Proceedings of the EAMT-CLAW’03 Workshop,</booktitle>
<pages>61--68</pages>
<location>Dublin,</location>
<contexts>
<context position="3217" citStr="Dologlou et al., 2003" startWordPosition="492" endWordPosition="495">ructuring (Nuhn et al., 2012) and topic-specific information (Su et al., 2011). As an alternative to pure SMT, the use of less specialised but more readily available resources has been proposed. Even if such approaches do not provide a translation quality as high as SMT, their ability to develop MT systems with very limited resources confers to them an important advantage. Carbonell et al. (2006) have proposed an MT method that requires no parallel text, but relies on a full-form bilingual dictionary and a decoder using long-range context. Other systems using low-cost resources include METIS (Dologlou et al., 2003) and METIS-II (Markantonatou et al., 2009), which are based only on large monolingual corpora to translate SL texts. Another recent trend in MT has been towards hybrid MT systems, which combine characteristics from multiple MT paradigms. The idea is that by fusing characteristics from different paradigms, a better translation performance can be attained (Wu et al., 2005). In the present article, the PRESEMT hybrid MT method using predominantly monolingual corpora (Sofianopoulos et al., 2012 &amp; Tambouratzis et al., 2013) is extended by integrating n-gram information to improve the translation ac</context>
</contexts>
<marker>Dologlou, Markantonatou, Yannoutsou, Fourla, Ioannou, 2003</marker>
<rawString>Yannis Dologlou, Stella Markantonatou, Olga Yannoutsou, Soula Fourla, and Nikos Ioannou. 2003. Using Monolingual Corpora for Statistical Machine Translation: The METIS System. Proceedings of the EAMT-CLAW’03 Workshop, Dublin, Ireland, 15-17 May, pp. 61-68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Gale</author>
<author>Lloyd S Shapley</author>
</authors>
<title>College Admissions and the Stability of Marriage.</title>
<date>1962</date>
<journal>American Mathematical Monthly,</journal>
<volume>69</volume>
<pages>9--14</pages>
<contexts>
<context position="10480" citStr="Gale &amp; Shapley, 1962" startWordPosition="1615" endWordPosition="1618">text to be translated is processed separately, so there is no exploitation of inter-sentential information. The first task is to select the correct TL translation of each word. The second task involves establishing the correct word order within each phrase. For each phrase of the sentence being translated, the algorithm searches the TL phrase model for similar phrases. All retrieved TL phrases are compared to the phrase to be translated. The comparison is based on the words included, their tags and lemmas and any other morphological features (case, number etc.). The stable-marriage algorithm (Gale &amp; Shapley, 1962) is applied for calculating the similarity and aligning the words of a phrase pair. This word reordering process is performed simultaneously with the translation disambiguation, using the same TL phrase model. During word reordering the algorithm also resolves issues regarding the insertion or deletion of articles and other auxiliary tokens. Though translation equivalent selection implements several tasks simultaneously, it produces encouraging results when translating from Greek (a free-word order language) to English (an SVO language). 2.4 Post-processing In this stage, a token generator is </context>
</contexts>
<marker>Gale, Shapley, 1962</marker>
<rawString>David Gale and Lloyd S. Shapley. 1962. College Admissions and the Stability of Marriage. American Mathematical Monthly, Vol. 69, pp. 9-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hutchins</author>
</authors>
<title>Example-Based Machine Translation: a Review and Commentary.</title>
<date>2005</date>
<journal>Machine Translation,</journal>
<volume>19</volume>
<pages>197--211</pages>
<contexts>
<context position="6660" citStr="Hutchins, 2005" startWordPosition="1035" endWordPosition="1037">ples of the structural transformation from SL to TL. During this phase, the translation methodology ports the chunking from the TL- to the SL-side, alleviating the need for an additional parser in SL. An example of the pre-processing stage is shown in Figure 1, for a sentence translated from Greek to English. For this sentence, the chunk structure is shown at the bottom part of Figure 1. 2.2 Structure Selection Structure selection transforms the input text using the limited bilingual corpus as a structural knowledge base, closely resembling the “translation by analogy” aspect of EBMT systems (Hutchins, 2005). Using available structural information, namely the order of syntactic phrases, the PoS tag of the head token of each phrase and the case of the head token (if available), we retrieve the most similar source side sentence from the parallel corpus. Based on the alignment information from the bilingual corpus between SL and TL, the input sentence structure is transformed to the structure of the target side translation. For the retrieval of the most similar source side sentence, an algorithm from the dynamic programming paradigm is adopted (Sofianopoulos et al., 2012), treating the structure sel</context>
</contexts>
<marker>Hutchins, 2005</marker>
<rawString>John Hutchins. 2005. Example-Based Machine Translation: a Review and Commentary. Machine Translation, Vol. 19, pp.197-211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ann Irvine</author>
<author>Chris Callison-Burch</author>
<author>David Yarowsky</author>
</authors>
<title>Toward Statistical Machine Translation without Parallel Corpora.</title>
<date>2012</date>
<booktitle>Proceedings of EACL2012,</booktitle>
<pages>130--140</pages>
<location>Avignon,</location>
<contexts>
<context position="2589" citStr="Klementiev et al., 2012" startWordPosition="392" endWordPosition="395">(Koehn et al., 2003). Recently SMT has been enhanced by using different levels of abstraction e.g. word, lemma or part-of-speech (PoS), in factored SMT models so as to improve SMT performance (Koehn &amp; Hoang, 2007). The drawback of SMT is that SL-to-TL parallel corpora of the order of millions of tokens are required to extract meaningful models for translation. Such corpora are hard to obtain, particularly for less resourced languages. For this reason, SMT researchers are increasingly investigating the extraction of information from monolingual corpora, including lexica (Koehn &amp; Knight, 2002 &amp; Klementiev et al., 2012), restructuring (Nuhn et al., 2012) and topic-specific information (Su et al., 2011). As an alternative to pure SMT, the use of less specialised but more readily available resources has been proposed. Even if such approaches do not provide a translation quality as high as SMT, their ability to develop MT systems with very limited resources confers to them an important advantage. Carbonell et al. (2006) have proposed an MT method that requires no parallel text, but relies on a full-form bilingual dictionary and a decoder using long-range context. Other systems using low-cost resources include M</context>
</contexts>
<marker>Klementiev, Irvine, Callison-Burch, Yarowsky, 2012</marker>
<rawString>Alexandre Klementiev, Ann Irvine, Chris Callison-Burch and David Yarowsky. 2012. Toward Statistical Machine Translation without Parallel Corpora. Proceedings of EACL2012, Avignon, France, 23-25 April, pp. 130-140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Koehn</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2010</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="1781" citStr="Koehn (2010)" startWordPosition="263" endWordPosition="264">ber of different translation models of increasing complexity and translation accuracy have been developed (Brown et al., 1993). Today, several packages for developing statistical language models are available for free use, including SRI (Stolke et al., 2011), thus supporting research into statistical methods. A main reason for the widespread adoption of SMT is that it is directly amenable to new language pairs using the same algorithms. An integrated framework (MOSES) has been developed for the creation of SMT systems (Koehn et al., 2007). The more recent developments of SMT are summarised by Koehn (2010). One particular advance in SMT has been the integration of syntactically motivated phrases in order to establish correspondences between source language (SL) and target language (TL) (Koehn et al., 2003). Recently SMT has been enhanced by using different levels of abstraction e.g. word, lemma or part-of-speech (PoS), in factored SMT models so as to improve SMT performance (Koehn &amp; Hoang, 2007). The drawback of SMT is that SL-to-TL parallel corpora of the order of millions of tokens are required to extract meaningful models for translation. Such corpora are hard to obtain, particularly for les</context>
</contexts>
<marker>Koehn, 2010</marker>
<rawString>Philip Koehn. 2010. Statistical Machine Translation. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a Translation Lexicon from Monolingual Corpora.</title>
<date>2002</date>
<booktitle>Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition, Vol.9,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="2562" citStr="Koehn &amp; Knight, 2002" startWordPosition="387" endWordPosition="390">d target language (TL) (Koehn et al., 2003). Recently SMT has been enhanced by using different levels of abstraction e.g. word, lemma or part-of-speech (PoS), in factored SMT models so as to improve SMT performance (Koehn &amp; Hoang, 2007). The drawback of SMT is that SL-to-TL parallel corpora of the order of millions of tokens are required to extract meaningful models for translation. Such corpora are hard to obtain, particularly for less resourced languages. For this reason, SMT researchers are increasingly investigating the extraction of information from monolingual corpora, including lexica (Koehn &amp; Knight, 2002 &amp; Klementiev et al., 2012), restructuring (Nuhn et al., 2012) and topic-specific information (Su et al., 2011). As an alternative to pure SMT, the use of less specialised but more readily available resources has been proposed. Even if such approaches do not provide a translation quality as high as SMT, their ability to develop MT systems with very limited resources confers to them an important advantage. Carbonell et al. (2006) have proposed an MT method that requires no parallel text, but relies on a full-form bilingual dictionary and a decoder using long-range context. Other systems using l</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a Translation Lexicon from Monolingual Corpora. Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition, Vol.9, pp.9-16.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation,</title>
<booktitle>Proceedings of HLT/NAACL-2003 Conference, Vol.1,</booktitle>
<pages>48--54</pages>
<marker>Koehn, Och, Marcu, </marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu, Statistical Phrase-Based Translation, Proceedings of HLT/NAACL-2003 Conference, Vol.1, pp.48-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of the ACL-2007 Demo &amp; Posters Sessions,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="1713" citStr="Koehn et al., 2007" startWordPosition="249" endWordPosition="252">age models for a number of applications including speech recognition. A number of different translation models of increasing complexity and translation accuracy have been developed (Brown et al., 1993). Today, several packages for developing statistical language models are available for free use, including SRI (Stolke et al., 2011), thus supporting research into statistical methods. A main reason for the widespread adoption of SMT is that it is directly amenable to new language pairs using the same algorithms. An integrated framework (MOSES) has been developed for the creation of SMT systems (Koehn et al., 2007). The more recent developments of SMT are summarised by Koehn (2010). One particular advance in SMT has been the integration of syntactically motivated phrases in order to establish correspondences between source language (SL) and target language (TL) (Koehn et al., 2003). Recently SMT has been enhanced by using different levels of abstraction e.g. word, lemma or part-of-speech (PoS), in factored SMT models so as to improve SMT performance (Koehn &amp; Hoang, 2007). The drawback of SMT is that SL-to-TL parallel corpora of the order of millions of tokens are required to extract meaningful models fo</context>
</contexts>
<marker>Koehn, Hoang, Birch, Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philip Koehn, Hieu Hoang, Alexandra Birch, Chris Callison Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. Proceedings of the ACL-2007 Demo &amp; Posters Sessions, Prague, June 2007, pp. 177-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored Translation Models.</title>
<date>2007</date>
<booktitle>Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>868--876</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2178" citStr="Koehn &amp; Hoang, 2007" startWordPosition="325" endWordPosition="328">le to new language pairs using the same algorithms. An integrated framework (MOSES) has been developed for the creation of SMT systems (Koehn et al., 2007). The more recent developments of SMT are summarised by Koehn (2010). One particular advance in SMT has been the integration of syntactically motivated phrases in order to establish correspondences between source language (SL) and target language (TL) (Koehn et al., 2003). Recently SMT has been enhanced by using different levels of abstraction e.g. word, lemma or part-of-speech (PoS), in factored SMT models so as to improve SMT performance (Koehn &amp; Hoang, 2007). The drawback of SMT is that SL-to-TL parallel corpora of the order of millions of tokens are required to extract meaningful models for translation. Such corpora are hard to obtain, particularly for less resourced languages. For this reason, SMT researchers are increasingly investigating the extraction of information from monolingual corpora, including lexica (Koehn &amp; Knight, 2002 &amp; Klementiev et al., 2012), restructuring (Nuhn et al., 2012) and topic-specific information (Su et al., 2011). As an alternative to pure SMT, the use of less specialised but more readily available resources has bee</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn, and Hieu Hoang. 2007. Factored Translation Models. Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, Prague, Czech Republic, pp. 868-876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stella Markantonatou</author>
</authors>
<title>Sokratis Sofianopoulos, Olga Yannoutsou, and Marina Vassiliou.</title>
<date>2009</date>
<pages>243--274</pages>
<editor>S. Nirenburg (ed.),</editor>
<publisher>IOS Press. ISBN:</publisher>
<marker>Markantonatou, 2009</marker>
<rawString>Stella Markantonatou, Sokratis Sofianopoulos, Olga Yannoutsou, and Marina Vassiliou. 2009. Hybrid Machine Translation for Lowand Middle- Density Languages. Language Engineering for Lesser-Studied Languages, S. Nirenburg (ed.), pp.243-274. IOS Press. ISBN: 978-1-58603-954-7</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>Automatic Evaluation of Machine Translation Quality Using n-gram Cooccurrences Statistics.</title>
<date>2002</date>
<contexts>
<context position="24768" citStr="NIST 2002" startWordPosition="3936" endWordPosition="3937"> Two datasets are used to evaluate translation accuracy, a development set (dataset1) and a test set (dataset2), each containing 200 sentences of length ranging from 7 to 40 tokens. These sets of sentences are readily available for download over the project website2. Two versions of the bilingual lexicon have been used, a base version and an expanded one. Both sets are manually translated by Greek native speakers and then cross-checked by English native speakers, with one reference translation per sentence. A range of evaluation metrics are employed, namely BLEU (Papineni et al., 2002), NIST (NIST 2002), Meteor (Denkowski and Lavie, 2011) and TER (Snover et al., 2006). 4.2 Experimental results The exact sequence with which hypotheses are tested affects the results of the translation, since only one hypothesis is allowed to be applied to each sentence token at present. This simplifies the evaluation of the hypotheses’ effectiveness. As a result, hypotheses are applied in strict order (i.e. first H1, then H2 etc.). The threshold values of Table 2 were settled upon via limited experimentation using sentences from dataset1. Hypothesis testing was applied to both datasets. Notably, dataset1 has b</context>
</contexts>
<marker>NIST, 2002</marker>
<rawString>NIST 2002. Automatic Evaluation of Machine Translation Quality Using n-gram Cooccurrences Statistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malte Nuhn</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Deciphering Foreign Language by Combining Language Models and Context Vectors.</title>
<date>2012</date>
<booktitle>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Jeju, Korea, Vol.1,</booktitle>
<pages>156--164</pages>
<contexts>
<context position="2624" citStr="Nuhn et al., 2012" startWordPosition="397" endWordPosition="400">en enhanced by using different levels of abstraction e.g. word, lemma or part-of-speech (PoS), in factored SMT models so as to improve SMT performance (Koehn &amp; Hoang, 2007). The drawback of SMT is that SL-to-TL parallel corpora of the order of millions of tokens are required to extract meaningful models for translation. Such corpora are hard to obtain, particularly for less resourced languages. For this reason, SMT researchers are increasingly investigating the extraction of information from monolingual corpora, including lexica (Koehn &amp; Knight, 2002 &amp; Klementiev et al., 2012), restructuring (Nuhn et al., 2012) and topic-specific information (Su et al., 2011). As an alternative to pure SMT, the use of less specialised but more readily available resources has been proposed. Even if such approaches do not provide a translation quality as high as SMT, their ability to develop MT systems with very limited resources confers to them an important advantage. Carbonell et al. (2006) have proposed an MT method that requires no parallel text, but relies on a full-form bilingual dictionary and a decoder using long-range context. Other systems using low-cost resources include METIS (Dologlou et al., 2003) and ME</context>
</contexts>
<marker>Nuhn, Mauser, Ney, 2012</marker>
<rawString>Malte Nuhn, Arne Mauser, and Hermann Ney. 2012. Deciphering Foreign Language by Combining Language Models and Context Vectors. Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Jeju, Korea, Vol.1, pp.156-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: A Method for Automatic Evaluation of</title>
<date>2002</date>
<booktitle>Machine Translation. 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, USA,</location>
<contexts>
<context position="24750" citStr="Papineni et al., 2002" startWordPosition="3931" endWordPosition="3934">l be more difficult to attain. Two datasets are used to evaluate translation accuracy, a development set (dataset1) and a test set (dataset2), each containing 200 sentences of length ranging from 7 to 40 tokens. These sets of sentences are readily available for download over the project website2. Two versions of the bilingual lexicon have been used, a base version and an expanded one. Both sets are manually translated by Greek native speakers and then cross-checked by English native speakers, with one reference translation per sentence. A range of evaluation metrics are employed, namely BLEU (Papineni et al., 2002), NIST (NIST 2002), Meteor (Denkowski and Lavie, 2011) and TER (Snover et al., 2006). 4.2 Experimental results The exact sequence with which hypotheses are tested affects the results of the translation, since only one hypothesis is allowed to be applied to each sentence token at present. This simplifies the evaluation of the hypotheses’ effectiveness. As a result, hypotheses are applied in strict order (i.e. first H1, then H2 etc.). The threshold values of Table 2 were settled upon via limited experimentation using sentences from dataset1. Hypothesis testing was applied to both datasets. Notab</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: A Method for Automatic Evaluation of Machine Translation. 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia, USA, pp. 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Temple F Smith</author>
<author>Michael S Waterman</author>
</authors>
<title>Identification of Common Molecular Subsequences.</title>
<date>1981</date>
<journal>Journal of Molecular Biology,</journal>
<volume>147</volume>
<pages>195--197</pages>
<contexts>
<context position="7503" citStr="Smith and Waterman, 1981" startWordPosition="1169" endWordPosition="1172">ence from the parallel corpus. Based on the alignment information from the bilingual corpus between SL and TL, the input sentence structure is transformed to the structure of the target side translation. For the retrieval of the most similar source side sentence, an algorithm from the dynamic programming paradigm is adopted (Sofianopoulos et al., 2012), treating the structure selection process as a sequence alignment, aligning the input sentence to an SL side sentence from the aligned parallel corpus and assigning a similarity score. The implementation is based on the SmithWaterman algorithm (Smith and Waterman, 1981), initially proposed for similarity detection between protein sequences. The algorithm finds the optimal local alignment between the two input sequences at clause level. The similarity of two clauses is calculated by taking into account the edit operations (replacement, insertion or removal) that must be applied to the input sentence in order to transform it to a source side sentence from the corpus. Each of these operations has an associated cost, considered as a system parameter. The parallel corpus sentence that achieves the highest similarity score is the most similar one to the input sour</context>
</contexts>
<marker>Smith, Waterman, 1981</marker>
<rawString>Temple F. Smith, and Michael S. Waterman. 1981. Identification of Common Molecular Subsequences. Journal of Molecular Biology, Vol. 147, pp. 195-197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<location>Cambridge, Massachusetts, USA,</location>
<contexts>
<context position="24834" citStr="Snover et al., 2006" startWordPosition="3946" endWordPosition="3949"> a development set (dataset1) and a test set (dataset2), each containing 200 sentences of length ranging from 7 to 40 tokens. These sets of sentences are readily available for download over the project website2. Two versions of the bilingual lexicon have been used, a base version and an expanded one. Both sets are manually translated by Greek native speakers and then cross-checked by English native speakers, with one reference translation per sentence. A range of evaluation metrics are employed, namely BLEU (Papineni et al., 2002), NIST (NIST 2002), Meteor (Denkowski and Lavie, 2011) and TER (Snover et al., 2006). 4.2 Experimental results The exact sequence with which hypotheses are tested affects the results of the translation, since only one hypothesis is allowed to be applied to each sentence token at present. This simplifies the evaluation of the hypotheses’ effectiveness. As a result, hypotheses are applied in strict order (i.e. first H1, then H2 etc.). The threshold values of Table 2 were settled upon via limited experimentation using sentences from dataset1. Hypothesis testing was applied to both datasets. Notably, dataset1 has been used in the development of the MT systems and thus the results</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, Cambridge, Massachusetts, USA, pp. 223-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sokratis Sofianopoulos</author>
<author>Marina Vassiliou</author>
<author>George Tambouratzis</author>
</authors>
<title>Implementing a language-independent MT methodology.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Workshop on Multilingual Modeling, held within the ACL-2012 Conference, Jeju,</booktitle>
<pages>1--10</pages>
<location>Republic of</location>
<contexts>
<context position="3712" citStr="Sofianopoulos et al., 2012" startWordPosition="570" endWordPosition="573">ual dictionary and a decoder using long-range context. Other systems using low-cost resources include METIS (Dologlou et al., 2003) and METIS-II (Markantonatou et al., 2009), which are based only on large monolingual corpora to translate SL texts. Another recent trend in MT has been towards hybrid MT systems, which combine characteristics from multiple MT paradigms. The idea is that by fusing characteristics from different paradigms, a better translation performance can be attained (Wu et al., 2005). In the present article, the PRESEMT hybrid MT method using predominantly monolingual corpora (Sofianopoulos et al., 2012 &amp; Tambouratzis et al., 2013) is extended by integrating n-gram information to improve the translation accuracy. The focus of the article is on how to extract, as comprehensively as possible, information from monolingual corpora by combining multiple models, to allow a higher quality translation. A review of the base MT system is performed in section 2. The TL language model is then detailed, allowing new work to be presented in section 3. More specifically, via an error analysis, ngram based extensions are proposed to augment 57 Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and </context>
<context position="7232" citStr="Sofianopoulos et al., 2012" startWordPosition="1127" endWordPosition="1131">ion by analogy” aspect of EBMT systems (Hutchins, 2005). Using available structural information, namely the order of syntactic phrases, the PoS tag of the head token of each phrase and the case of the head token (if available), we retrieve the most similar source side sentence from the parallel corpus. Based on the alignment information from the bilingual corpus between SL and TL, the input sentence structure is transformed to the structure of the target side translation. For the retrieval of the most similar source side sentence, an algorithm from the dynamic programming paradigm is adopted (Sofianopoulos et al., 2012), treating the structure selection process as a sequence alignment, aligning the input sentence to an SL side sentence from the aligned parallel corpus and assigning a similarity score. The implementation is based on the SmithWaterman algorithm (Smith and Waterman, 1981), initially proposed for similarity detection between protein sequences. The algorithm finds the optimal local alignment between the two input sequences at clause level. The similarity of two clauses is calculated by taking into account the edit operations (replacement, insertion or removal) that must be applied to the input se</context>
</contexts>
<marker>Sofianopoulos, Vassiliou, Tambouratzis, 2012</marker>
<rawString>Sokratis Sofianopoulos, Marina Vassiliou, and George Tambouratzis. 2012. Implementing a language-independent MT methodology. In Proceedings of the First Workshop on Multilingual Modeling, held within the ACL-2012 Conference, Jeju, Republic of Korea, 13 July, pp.1-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Tambouratzis</author>
</authors>
<title>Sokratis Sofianopoulos, and Marina Vassiliou (2013) Languageindependent hybrid MT with PRESEMT.</title>
<date></date>
<booktitle>In Proceedings of HYTRA-2013 Workshop, held within the ACL-2013 Conference,</booktitle>
<volume>8</volume>
<pages>123--130</pages>
<location>Sofia, Bulgaria,</location>
<marker>Tambouratzis, </marker>
<rawString>George Tambouratzis, Sokratis Sofianopoulos, and Marina Vassiliou (2013) Languageindependent hybrid MT with PRESEMT. In Proceedings of HYTRA-2013 Workshop, held within the ACL-2013 Conference, Sofia, Bulgaria, 8 August, pp. 123-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady,</journal>
<volume>10</volume>
<pages>707--710</pages>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I. Levenshtein (1966): Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady, Vol. 10, pp. 707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguistics.</title>
<date>1993</date>
<contexts>
<context position="1295" citStr="Brown et al., 1993" startWordPosition="183" endWordPosition="186">nslation accuracy. For specific structural patterns, n-gram statistics are consulted to determine whether the pattern instantiations are corroborated. Experiments indicate improvements in translation accuracy. 1 Introduction Currently a major part of cutting-edge research in MT revolves around the statistical machine translation (SMT) paradigm. SMT has been inspired by the use of statistical methods to create language models for a number of applications including speech recognition. A number of different translation models of increasing complexity and translation accuracy have been developed (Brown et al., 1993). Today, several packages for developing statistical language models are available for free use, including SRI (Stolke et al., 2011), thus supporting research into statistical methods. A main reason for the widespread adoption of SMT is that it is directly amenable to new language pairs using the same algorithms. An integrated framework (MOSES) has been developed for the creation of SMT systems (Koehn et al., 2007). The more recent developments of SMT are summarised by Koehn (2010). One particular advance in SMT has been the integration of syntactically motivated phrases in order to establish </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer (1993) The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Jing Zheng</author>
<author>Wen Wang</author>
<author>Victor Abrash</author>
</authors>
<title>SRILM at Sixteen: Update and Outlook.</title>
<date>2011</date>
<booktitle>Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop,</booktitle>
<marker>Stolcke, Zheng, Wang, Abrash, 2011</marker>
<rawString>Andreas Stolcke, Jing Zheng, Wen Wang, and Victor Abrash (2011) SRILM at Sixteen: Update and Outlook. Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop, December 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinsong Su</author>
<author>Hua Wu</author>
</authors>
<title>Haifeng Wang, Yidong Chen, Xiaodong Shi, Huailin Dong, and Qun Liu</title>
<date>2012</date>
<booktitle>Proceedings of ACL2012, Jeju, Republic of Korea,</booktitle>
<pages>459--468</pages>
<marker>Su, Wu, 2012</marker>
<rawString>Jinsong Su, Hua Wu, Haifeng Wang, Yidong Chen, Xiaodong Shi, Huailin Dong, and Qun Liu (2012) Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information. Proceedings of ACL2012, Jeju, Republic of Korea, pp. 459-468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>MT model space: Statistical versus compositional versus example-based machine translation.</title>
<date>2005</date>
<journal>Machine Translation,</journal>
<volume>19</volume>
<pages>213--227</pages>
<marker>Wu, 2005</marker>
<rawString>Dekai Wu (2005) MT model space: Statistical versus compositional versus example-based machine translation. Machine Translation, Vol. 19, pp. 213-227.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>