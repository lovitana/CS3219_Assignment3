<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.7737775">
Proper Name Machine Translation
from Japanese to Japanese Sign Language
</title>
<author confidence="0.9421795">
Taro Miyazaki, Naoto Kato, Seiki Inoue,
Shuichi Umeda, Makiko Azuma, Nobuyuki Hiruma
</author>
<affiliation confidence="0.926261">
NHK Science &amp; Technology Research Laboratories
Tokyo, Japan
</affiliation>
<address confidence="0.498423">
{miyazaki.t-jw, katou.n-ga, inoue.s-li,
</address>
<email confidence="0.975177">
umeda.s-hg, azuma.m-ia, hiruma.n-dy}@nhk.or.jp
</email>
<author confidence="0.993983">
Yuji Nagashima
</author>
<affiliation confidence="0.949984666666667">
Faculty of Information,
Kogakuin University
Tokyo, japan
</affiliation>
<email confidence="0.995678">
nagasima@cc.kogakuin.ac.jp
</email>
<sectionHeader confidence="0.997358" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994653125">
This paper describes machine transla-
tion of proper names from Japanese to
Japanese Sign Language (JSL). “Proper
name transliteration” is a kind of machine
translation of proper names between spo-
ken languages and involves character-to-
character conversion based on pronunci-
ation. However, transliteration methods
cannot be applied to Japanese-JSL ma-
chine translation because proper names
in JSL are composed of words rather
than characters. Our method involves
not only pronunciation-based translation,
but also sense-based translation, because
kanji, which are ideograms that compose
most Japanese proper names, are closely
related to JSL words. These translation
methods are trained from parallel corpora.
The sense-based translation part is trained
via phrase alignment in sentence pairs
in a Japanese and JSL corpus. The
pronunciation-based translation part is
trained from a Japanese proper name cor-
pus and then post-processed with trans-
formation rules. We conducted a series
of evaluation experiments and obtained
75.3% of accuracy rate, increasing from
baseline method by 19.7 points. We also
developed a Japanese-JSL proper name
translation system, in which the translated
proper names are visualized with CG ani-
mations.
</bodyText>
<sectionHeader confidence="0.999504" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948725">
Sign language is a visual language in which sen-
tences are created using the fingers, hands, head,
face, and lips. For deaf people, sign language is
easier to understand than spoken language because
it is their mother tongue. To convey the meaning
of sentences in spoken language to deaf people,
the sentences need to be translated into sign lan-
guage.
To provide more information with sign lan-
guage, we have been studying machine translation
from Japanese to Japanese Sign Language (JSL).
As shown in Figure 1, our translation system au-
tomatically translates Japanese text into JSL com-
puter graphics (CG) animations. The system con-
sists of two major processes: text translation and
CG synthesis. Text translation translates word se-
quences in Japanese into word sequences in JSL.
CG synthesis generates seamless motion transi-
tions between each sign word motion by using a
motion interpolation technique. To improve the
machine translation system, we have been tack-
ling several problems with translating in JSL. In
this paper, we focus on the problem of proper
name translation, because proper names occur fre-
quently in TV news programs and are hard to
translate with conventional methods.
Proper name translation is one of the ma-
jor topics of machine translation. In particu-
lar, there are many methods that work with spo-
ken language, such as “proper name translitera-
tion,” which means character-to-character conver-
sion based on pronunciation (Knight et al., 1998;
Goto et al., 2003; Virga et al., 2003; Li et al.,
2004; Finch et al., 2010; Sudoh et al., 2013).
However, transliteration methods cannot be ap-
plied to Japanese-JSL proper name translation be-
cause proper names in JSL are not composed of
characters but rather of sign words. To translate
proper names using sign words, sense-based trans-
lation is required. Sense-based translation trans-
</bodyText>
<page confidence="0.961817">
67
</page>
<footnote confidence="0.735978">
Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 67–75,
October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics
</footnote>
<figureCaption confidence="0.999713">
Figure 1: Japanese-JSL translation system overview
</figureCaption>
<bodyText confidence="0.998999166666667">
lates kanji, which are ideograms that compose
most Japanese proper names, into closely related
JSL words. Moreover, although several methods
have been proposed to translate sentences in sign
language, there is as yet no method to translate
proper names (Mass´o et al., 2010; San-Segundo
et al., 2010; Morrissey, 2011; Stein et al., 2012;
Mazzei, 2012; Lugaresi et al., 2013).
This paper describes proper name translation
from Japanese into JSL. The method involves
sense-based translation and pronunciation-based
translation. Both conversions are based on a
statistical machine translation framework. The
sense-based translation is a sense-based character-
wise translation learned from phrase pairs in a
Japanese-JSL corpus. The pronunciation-based
translation is a pronunciation-based character-
wise translation learned from a Japanese proper
name corpus and is post-processed with transfor-
mation rules. We conducted a series of evaluation
experiments and obtained good results. We also
developed a proper name translation system from
Japanese to JSL, in which the translated proper
names are visualized with CG-animations.
</bodyText>
<sectionHeader confidence="0.979292" genericHeader="introduction">
2 Proper Names in JSL
</sectionHeader>
<subsectionHeader confidence="0.999788">
2.1 Types of proper name in JSL
</subsectionHeader>
<bodyText confidence="0.9992095">
In JSL, proper name representations are classified
into four types, as follows.
</bodyText>
<subsectionHeader confidence="0.71295">
Type 1: sense-based case
</subsectionHeader>
<bodyText confidence="0.99823925">
Here, each character in Japanese proper names is
translated into sign words in JSL. Most charac-
ters that make up Japanese proper names are kanji.
Kanji are ideograms, i.e., each kanji representing
concept, so they can be translated into words with
the concepts in JSL.
For example, in the Japanese place name “香川
(Kagawa),” the kanji-characters “香 (aroma)” and
“川 (river)” are respectively translated into sign
words “AROMA1” and “RIVER.” Accordingly,
the translation of “香川 (Kagawa)” is “AROMA
/ RIVER” in JSL.
</bodyText>
<subsectionHeader confidence="0.758374">
Type 2: Pronunciation-based case
</subsectionHeader>
<bodyText confidence="0.99990325">
Here, the pronunciations of the kanji are translit-
erated into the Japanese kana alphabet. The kana
are visualized by fingerspelling2. The transliter-
ation in this case is not a spelling-based transfor-
mation from the source language because kanji are
not phonograms3.
For example, in the Japanese personal name “茂
木” (Motegi, written in kana as “モテギ”), the two
kanji “茂” and “木” are respectively transliterated
into the kana “モテ (mote)” and “ギ (gi).”
Each of the three kana, “モ (mo),” “テ (te)” and
“ギ (gi),” is fingerspelled in JSL.
</bodyText>
<subsectionHeader confidence="0.844084">
Type 3: Mixed case
</subsectionHeader>
<bodyText confidence="0.999201666666667">
This type includes Type 1 and Type 2. That
is, some of the characters in the proper names
are translated into sign words and the others are
transliterated into kana and then visualized by fin-
gerspelling. For example, regarding the Japanese
place name “長野” (Nagano, written in kana as “
ナガノ”), the kanji “長” is translated into the sign
word “LONG” and “野” is transliterated into the
kana “ノ (no).”
</bodyText>
<footnote confidence="0.9981875">
1The words in JSL are represented using capitalized En-
glish words. This notation method is called “glosses” in the
sign language research community.
2All of the kana can be visualized by fingerspelling in
JSL.
3For example, the character “木” is pronounced “ki,” “gi,”
“moku,” “boku” etc. The decision as to which pronunciation
should be used is by context, meanings or idiom.
</footnote>
<page confidence="0.99919">
68
</page>
<subsectionHeader confidence="0.468078">
Type 4: Idiomatic case
</subsectionHeader>
<bodyText confidence="0.668359">
These proper names are traditionally defined as
fixed representations in JSL.
</bodyText>
<subsectionHeader confidence="0.998071">
2.2 Analysis of Proper Name Types in
Corpora
</subsectionHeader>
<bodyText confidence="0.9999213125">
To investigate the frequencies of these four types
in corpora, we analyzed a geographical dictionary
(JFD, 2009) of place names and our corpus (men-
tioned in section 4.2.1) of persons’ names. Table
1 shows the results of the analysis.
Proper names of Types 1, 2 and 3 needed to
be translated, while those of Type 4 needed to
be registered in an idiomatic translation dictio-
nary of proper names. Furthermore, the proper
name translations of Type 1, 2 and 3 reduce
to sense-based translations and/or pronunciation-
based translations.
Our translation method performs sense-based
translation and pronunciation-based translation on
the basis of statistical machine translation (SMT)
methods. The next section describes this method.
</bodyText>
<sectionHeader confidence="0.999044" genericHeader="method">
3 Our translation method
</sectionHeader>
<subsectionHeader confidence="0.99804">
3.1 Sense-based translation
3.1.1 Basic method (baseline)
</subsectionHeader>
<bodyText confidence="0.873015416666667">
The sense-based translation uses SMT, and the
translation probabilities (i.e. a lexicon model in
SMT) are trained on our news corpus consisting
of sentence pairs in Japanese and JSL. The basic
method of training the lexicon model uses the cor-
pus in a sentence-by-sentence manner (Figure 2-
(a)). It segments the sentences into characters in
Japanese and into words in JSL. Then, the model
is trained on the characters of the Japanese sen-
tences and the words of the JSL sentences. Re-
garding Sentence 1 below, the method segments it
into Sentence 2 in Japanese and trains the model.
Sentence 1
JP 香川は朝から晴れるでしょう
(It will be fine from the morning in Kagawa)
JSL AROMA / RIVER / MORNING /
FROM / FINE / DREAM
Sentence 2
JP 香/川/は/朝/か/ら/晴/れ/る/で/し/ょ/う
(It will be fine from the morning in Kagawa)
JSL AROMA / RIVER / MORNING /
FROM / FINE / DREAM
We took the basic method above to be the base-
line method for the evaluations.
</bodyText>
<subsectionHeader confidence="0.503707">
3.1.2 Our method
</subsectionHeader>
<bodyText confidence="0.999994058823529">
Our method uses the corpus in a phrase-by-phrase
manner. To use the phrase-segmented corpus,
the method is composed of two steps. The first
step aligns Japanese phrases to JSL phrases in
each of the sentence pairs in the corpus by us-
ing many-to-many word alignment. Using the re-
sults of the alignment, each sentence pair is di-
vided into phrase pairs. The second step segments
the phrases into characters in Japanese and trains
the sense-based translation part on the phrase pairs
(Figure 2-(b)).
Let us illustrate our method using Sentence 1.
The first step is dividing a sentence into phrase
pairs. We use alignment pairs, the result of
the many-to-many word alignment, as the phrase
pairs. The alignment pairs are combined into
phrase pairs, as shown in Phrase 1 below.
</bodyText>
<equation confidence="0.937024142857143">
Phrase 1
JP1 香川 / は (in Kagawa)
JSL1 AROMA/ RIVER
JP2 朝 / から (from the morning)
JSL2 MORNING/ FROM
JP3 晴れる / でしょ / う (it will be fine)
JSL3 FINE/ DREAM
</equation>
<bodyText confidence="0.999391666666667">
Alignment pairs that consist of many more or
fewer sign words than Japanese words are dis-
carded as alignment errors. In this paper, we
regard the alignment pair as the alignment error
when nsign &gt; (NiP + α) or (nsign + α) &lt; niP.
Here, nsign means the number of sign words in
</bodyText>
<tableCaption confidence="0.990089">
Table 1: Analysis of proper name types
</tableCaption>
<figure confidence="0.998928470588235">
Type 1
43%
Type 2
Type 3
Type 4
3%
10%
44%
Place name
Persons’ name
Type 1 60%
Type 2
Type 3
14%
21%
Type 4
21%
</figure>
<page confidence="0.761151">
69
</page>
<figureCaption confidence="0.9993">
Figure 2: Two ways of learning translation models
</figureCaption>
<bodyText confidence="0.9988546">
the alignment pair, and njp means the number of
Japanese words in the alignment pair. We chose α
to be 5, on the basis of preliminary experiment.
The second step segments Phrase 1 into charac-
ters in Japanese, as in Phrase 2 below.
</bodyText>
<equation confidence="0.871174">
Phrase 2
JP1 -MJ f l/I (in Kagawa)
JSL1 AROMA/ RIVER
JP2 */�/1; (from the morning)
JSL2 MORNING/ FROM
JP3 r/tL/6/2/L/1/7 (It will be fine)
JSL3 FINE/ DREAM
</equation>
<bodyText confidence="0.814036846153846">
Then, as shown in Example 1, the sense-based
translation is trained on the corpus of phrase pairs.
Example 1
� �AROMA
J f l RIVER
l (null)
...
Our method can reduce the combinations of
alignments between Japanese characters and JSL
words, because it segments sentences into phrases
in which the number of words is less than that in
the sentences. Therefore, it improves the align-
ment accuracy.
</bodyText>
<subsectionHeader confidence="0.991991">
3.2 Pronunciation-based translation
</subsectionHeader>
<bodyText confidence="0.999727666666667">
The pronunciation-based translation is not translit-
eration but translation, because kanji do not repre-
sent their pronunciation. Therefore, the translation
probabilities are also trained on a Japanese proper
name corpus as a lexicon model in the SMT train-
ing step.
</bodyText>
<figureCaption confidence="0.997098">
Figure 3: Patterns that cannot be aligned
</figureCaption>
<bodyText confidence="0.9907088">
Using the trained lexicon model, a decoder
aligns the kana with the kanji. However, some of
the kanji and kana are not aligned because of the
sparse data problem. Such non-aligned cases are
as follows.
</bodyText>
<table confidence="0.46472125">
Pattern (a) Aligned on neither the kanji nor the
kana side (Fig.3-(a)).
Pattern (b) Insertion occurred (Fig.3-(b)).
Pattern (c) Deletion occurred (Fig.3-(c)).
</table>
<bodyText confidence="0.965091">
The kanji-to-kana alignment is generally many-
to-many, but we restricted the alignment to one-to-
many.
To improve the result of these cases, we devised
transformation rules that use the word’s context,
as follows.
Rule (a) Align all of the non-aligned kana with
the non-aligned kanji.
Rule (b) Align the non-aligned kana to the kanji
with the lower probability by comparing the
translation probability of the left aligned
kanji with the translation probability of the
right aligned kanji.
Rule (c) Align the non-aligned kanji to the kana
with the lower probability and un-align the
</bodyText>
<figure confidence="0.9110906">
(a) (b)
; katakana character
; kanj/ character
(c)
70
</figure>
<figureCaption confidence="0.99988">
Figure 4: Japanese-JSL news corpus
</figureCaption>
<bodyText confidence="0.999818705882353">
old aligned kanji with the lower one by com-
paring the translation probability of the left
aligned kana with the translation probability
of the rightaligned kana.
Using these rules, our methods can align kanji
to kana even if the kanji and/or kana are not in
the training data. It has the advantage of robust-
ness to the data sparse problem unlike conven-
tional transliteration methods such as in (Finch et
al., 2010; Knight et al., 1998). There are many dif-
ferent family names in Japan4, so these character-
istics are important for translating Japanese proper
names.
Our method applies these rules to the non-
aligned kanji and kana from the beginning char-
acter in the sentences after the sense-based trans-
lation.
</bodyText>
<subsectionHeader confidence="0.9919265">
3.3 Combining sense-based and
pronunciation-based translation
</subsectionHeader>
<bodyText confidence="0.999633333333333">
In our proper name translation, sense-based trans-
lation is first applied to a Japanese proper name
and then pronunciation-based translation is ap-
plied to the characters that were not converted into
sign words. Such characters occur in the following
cases.
</bodyText>
<listItem confidence="0.9729715">
• The character does not appear in the training
data of the sense-based translation.
</listItem>
<footnote confidence="0.9222715">
4There are over 300,000 family names in Japan(Power,
2008).
</footnote>
<listItem confidence="0.587374333333333">
• The character is translated into kana because
the character is often translated into Kana in
the training data of sense-based translation.
</listItem>
<bodyText confidence="0.999048666666667">
In these cases, our system translates the charac-
ter into kana by using pronunciation-based trans-
lation.
</bodyText>
<sectionHeader confidence="0.998456" genericHeader="method">
4 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.985634">
4.1 Experimental setting
</subsectionHeader>
<bodyText confidence="0.999956421052632">
Our method uses GIZA++ and “grow-diag-final-
and” (Och et al., 2003) as the model training and
Moses (Koehn et al., 2007) as the decoding; it does
not use a language model because word context
and reordering are useless in proper name transla-
tion from Japanese to JSL.
The training sets were our Japanese-JSL
news corpus (including 21,995 sentence pairs)
for sense-based translation and a human-name
corpus (including 34,202 personal names) for
pronunciation-based translation. These corpora
are described below.
The test set consisted of persons’ names and
place names. Regarding the persons’ names, the
candidates for the test set were first randomly sam-
pled from a Japanese family name database5. The
100 sampled names were translated by three native
signers and if two or three of the signers gave the
same translation, the sample was added to the test
</bodyText>
<footnote confidence="0.962657">
5http://www.douseidoumei.net/prof.html
</footnote>
<page confidence="0.999258">
71
</page>
<tableCaption confidence="0.997795">
Table 2: Results of evaluation
</tableCaption>
<table confidence="0.999344642857143">
Person Place Total Type 1 Type 2 Type 3 Type 4
# in the test set 96 82 178 123 16 32 7
Baseline 61 37 99 86 2 9 2
(63.5%) (46.3%) (55.6%) (69.9%) (12.5%) (28.1%) (28.6%)
Pialign 75 41 118 97 3 15 3
(78.1%) (51.3%) (66.3%) (78.9%) (18.8%) (46.9%) (42.9%)
Proposed (sense-based) 77 43 121 95 3 20 3
(80.2%) (53.8%) (68.0%) (77.2%) (18.8%) (62.5%) (42.9%)
Baseline 69 44 114 86 5 21 2
+ pronunciation-based (71.9%) (55.0%) (64.0%) (69.9%) (31.3%) (65.6%) (28.6%)
Pialign 74 47 123 97 5 18 3
+pronunciation-based (77.1%) (58.8%) (69.1%) (78.9%) (31.3%) (56.3%) (42.9%)
Proposed (sense-based) 80 53 134 95 8 28 3
+ pronunciation-based (83.3%) (66.3%) (75.3%) (77.2%) (0.50%) (87.5%) (42.9%)
</table>
<bodyText confidence="0.9986098">
set. This procedure produced a test set consisting
of 96 names. The test set for place names was pro-
duced in the same way and amounted to 82 names.
The total number of names used in our evaluation
experiments was thus 178.
</bodyText>
<subsectionHeader confidence="0.7884445">
4.2 Training Corpora
4.2.1 Japanese-JSL corpus
</subsectionHeader>
<bodyText confidence="0.999984375">
We have been building up a Japanese-JSL news
corpus to study Japanese-to-JSL machine transla-
tion. The corpus was collected from daily NHK
Sign Language News programs, which are broad-
cast on NHK TV with Japanese narration and JSL
signs.
The corpus consists of Japanese transcriptions,
their JSL transcriptions, and their JSL movies.
The Japanese transcriptions are transcribed by re-
vising the speech recognition results of the news
programs. The transcriptions are carried out by
changing the sign gestures of the newscasters into
sequences of JSL words. The JSL movies are man-
ually extracted from the program by referring to
the time intervals of the transcribed JSL transcrip-
tions. The corpus currently includes about 22,000
sentence pairs taken from broadcasts running from
April 2009 to August 2010. Our bilingual corpus
is larger than other recent sign language corpora
built in various sign language research projects
(Bungeroth et al., 2006; Schembri, 2008; John-
ston, 2009; Balvet et al., 2010; Matthes et al.,
2012; Mesch et al., 2012). Figure 4 shows an ex-
ample of our corpus.
</bodyText>
<subsectionHeader confidence="0.712934">
4.2.2 Human Name Corpus
</subsectionHeader>
<bodyText confidence="0.999923333333333">
The human-name corpus was constructed by ex-
tracting personal names written in both kanji and
kana from the IPADIC dictionary6.
</bodyText>
<subsectionHeader confidence="0.999352">
4.3 Evaluation and Discussion
</subsectionHeader>
<bodyText confidence="0.998458041666667">
We conducted a series of experiments to evaluate
our method. Table 2 shows the translation accura-
cies for proper names. The tested methods were as
follows.
Baseline A simple baseline method (mentioned in
3.1.1)
Pialign The conventional character-based transla-
tion method (Neubig et al., 2012)
Proposed (sense-based) Our method for sense-
based translation (described in 3.1.2)
Pronunciation-based Our method for
pronunciation-based translation (described
in 3.2)
Our overall method is “Proposed (sense-based) +
pronunciation-based.” The upper row of each cell
in the table shows the number of the correct words,
whereas the lower row of each cell is the accuracy.
The table indicates that compared with the base-
line, our method is higher in accuracy by 19.7
points in total, 19.8 points on persons’ name, and
19.6 points on place names. It is higher in ac-
curacy than the baseline for each type of trans-
lation. The sense-based translation is effective
at the raising total translation accuracy, whereas
</bodyText>
<footnote confidence="0.973527">
6http://code.google.com/p/mecab/downloads
</footnote>
<page confidence="0.998146">
72
</page>
<bodyText confidence="0.998393641025641">
the pronunciation-based translation increases the
translation accuracy Types 2 and 3.
Each method had lower accuracy for place
names than for persons’ names. The reasons are
as follows. One problem is that some of the char-
acters in the place names are used only in place
names, and though they appear in the test set, they
do not appear in the training set. This is the out-of-
vocabulary problem, which is a major issue with
the corpus-based method. To tackle this problem,
we will make our corpus larger by using Japanese-
JSL place name dictionary. The other problem
is that some of the place names have ambiguous
Japanese-JSL translations. In this regard, the rate
of agreement of the signers making was lower for
place names (i.e. 82) than for personal names (i.e.
96).
The sense-based translation method is more ac-
curate than pialign especially in translating type
2 and 3. This is because our discard process is
able to delete infrequently used kanji in the corpus
from the training data. Infrequently used kanji are
often translated using their pronunciation because
native signers cannot imagine the sign word that
well represents the kanji.
Some of the type 4 words that occurred fre-
quently in the training data were translated with
the phrase-based method, however, the accuracy
was low. An idiomatic translation dictionary is re-
quired for this purpose.
A Japanese-JSL place name dictionary would
also improve the character-to-word conversion.
For example, our method mistranslated the char-
acter “* (god)” in a personal family name “*
V, (Kamiya)” into “KOBE (Kobe).” The cause of
this error is that our method trains the character-to-
word conversion “* (god) —* KOBE(Kobe)” from
Phrase 3.
Phrase 3
</bodyText>
<sectionHeader confidence="0.9175065" genericHeader="method">
JP *P (Kobe)
JSL KOBE
</sectionHeader>
<bodyText confidence="0.9999365">
Our method would be able to avoid such a conver-
sion error by deleting from the training set phrase
pairs such as Phrase 3 that are registered in the
place dictionary.
</bodyText>
<sectionHeader confidence="0.962874" genericHeader="method">
5 Proper Name Translation System
</sectionHeader>
<bodyText confidence="0.8146585">
Using our translation method, we developed a
proper name translation system from Japanese to
</bodyText>
<figureCaption confidence="0.999431">
Figure 5: Motion capture system
</figureCaption>
<bodyText confidence="0.999857238095238">
JSL. This system visualizes the translated proper
names as computer graphics (CG) animations.
The CG animation is a high-quality 3D model
of human hands and fingers, and the model is con-
trolled using motion-capture (MoCap) data. The
data is captured with an optical MoCap system
in which many markers are attached to fingers
to pick up their movements precisely. Figure5
shows the MoCap system. The CG-model has
about 100 joints with three rotation angles. The
CG-animation is rendered from scripts written in
TVML (TM program Making Language7), which
is a scripting language developed by NHK to de-
scribe full TV programs (Kaneko et al., 2010).
Figure 6 shows an example of the Japanese-
to-JSL proper name translation system. When a
proper name in Japanese is entered, a correspond-
ing sign language animation is created and shown
in the system. The translation system will be used
in subjective evaluation of proper name transla-
tions.
</bodyText>
<sectionHeader confidence="0.999383" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999780454545455">
We presented a Japanese-JSL proper name ma-
chine translation method. The method involves
sense-based translation and pronunciation-based
translation, both of which are based on statisti-
cal machine translation. We conducted a series of
evaluation experiments and obtained 75.3% of ac-
curacy, increasing from baseline method by 19.7
points.
We will incorporate our method of proper name
translation from Japanese to JSL in our machine
translation system.
</bodyText>
<footnote confidence="0.957933">
7http://www.nhk.or.jp/strl/tvml/english/player2/index.html
</footnote>
<page confidence="0.997489">
73
</page>
<figureCaption confidence="0.9604345">
Figure 6: Japanese-JSL proper name translation
system
</figureCaption>
<sectionHeader confidence="0.997718" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99995375">
The authors would like to express our deep grat-
itude to Hirokazu Kosugi for implementing the
experimental system for translating sign word se-
quences into sign language CG animations. They
would also like to express their gratitude to Hideki
Tanaka, Ichiro Yamada, Tadashi Kumano, Isao
Goto, and the anonymous reviewers for their valu-
able comments and suggestions.
</bodyText>
<sectionHeader confidence="0.999069" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99871985">
Antonio Balvet, Cyril Courtin, Dominique Boutet,
Christian Cuxac, Ivani Fusellier-Souza, Brigitte
Garcia, Marie-Th´er`ese L’Huillier and Marie-Anne
Sallandre. 2010. The Creagest Project: a Digi-
tized and Annotated Corpus for French Sign Lan-
guage (LSF) and Natural Gestural Languages. In-
ternational Conference on Language Resources and
Evaluation (LREC 2010): 469–475.
Jan Bungeroth, Daniel Stein, Philippe Dreuw, Morteza
Zahedi and Hermann Ney. 2006. A German Sign
Language corpus of the domain weather report. In-
ternational Conference on Language Resources and
Evaluation (LREC 2006): 2000–2003.
Andrew Finch, Keiji Yasuda, Hideo Okuma, Eiichiro
Sumita and Satoshi Nakamura. 2011. A Bayesian
Model of Transliteration and Its Human Evaluation
when Integrated into a Machine Translation Sys-
tem. IEICE transactions on Information and Sys-
tems: Vol. E94–D, No. 10, pp.1889–1900.
Isao Goto, Naoto Kato, Noriyoshi Uratani and Teru-
masa Ehara. 2003. Transliteration considering con-
text information based on the maximum entropy
method. The 9th Machine Translation Summit: 125–
132.
Japanese Federation of the Deaf (JFD). 2009. Place
names map in Japanese Sign Language in Japan (in
Japanese, “ Q�� &gt;7&amp;quot;”) Japanese Feder-
ation of the Deaf Press.
Trevor Johnston. 2009. Creating a corpus of Auslan
within an Australian national corpus. Selected Pro-
ceedings of the 2008 HCSNet Workshop on Design-
ing the Australian National Corpus: Mustering Lan-
guages.
Hiroyuki Kaneko, Narichika Hamaguchi, Mamoru
Doke and Seiki Inoue. 2010. Sign language anima-
tion using TVML. 9th ACM SIGGRAPH Interna-
tional Conference on Virtual-Reality Continuum and
Its Applications in Industry (VRCAI 2010), ACM
2010:289–292.
Kevin Knight, Jonathan Graehl. 1998. Machine
transliteration. Computer Linguistics, 24: 599–612.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowen, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. An-
nual meeting of the Association for Computational
Linguistics (ACL 2007), demonstration session.
Li Haizhou, Zhang Min, Su Jian. 2004 A joint source-
channel model for machine transliteration. Proceed-
ings of the 42nd Annual Meeting on Association for
Computational Linguistics (ACL ’04). Article No.
159.
Camillo Lugaresi and Barbara Di Eugenio. 2013.
Translating Italian connectives into Italian Sign Lan-
guage. Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (ACL
2013), pp 270–280. Sofia, Bulgaria, August.
Guillem Mass´o and Toni Badia. 2010. Dealing
with sign language morphemes in statistical machine
translation. 4th workshop on the representation and
processing of sign language: interactions between
corpus and lexicon at LREC 2010: 154–157.
Silke Matthes, Thomas Hanke, Anja Regan, Jakob
Storz, Satu Worseek, Eleni Efthimiou, Athanasia-
Lida Dimou, Annelies Braffort, John Glauert and
Eva Safar. 2012. Dicta-Sign – Building a multilin-
gual sign language corpus. 5th workshop on the rep-
resentation and processing of sign language: inter-
actions between corpus and lexicon at LREC 2012:
117–122.
Alessandro Mazzei. 2012. Sign language generation
with expert systems and ccg. Proceedings of the
Seventh International Natural Language Generation
Conference (INLG ’12): 105–109.
Johanna Mesch, Lars Wallin and Thomas Bj¨orkstrand.
2012. Sign language resources in Swedes: dictio-
nary and corpus. 5th workshop on the representa-
tion and processing of sign language: interactions
</reference>
<page confidence="0.980381">
74
</page>
<reference confidence="0.998187186046511">
between corpus and lexicon at LREC 2012: 127–
130.
Sara Morrissey. 2011. Assessing three representation
methods for sign language machine translation and
evaluation. 15th annual meeting of the European
Association for Machine Translation (EAMT 2011):
137–144.
Graham Neubig, Taro Watanabe, Shinsuke Mori and
Tatsuya Kawahara. 2012. Machine Translation
without Words through Substring Alignment. Pro-
ceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL2012) :
165–174.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics,29: 19–51.
John Power. 2008. Japanese Names. The Indexer,
Volume 26, No 2, pp. C4-2–C4-8.
Rub´en San-Segundo, Ver´onica L´opez, Raquel Martin,
David S´anchez, Adolfo Garcia. 2010. Language re-
sources for Spanish – Spanish Sign Language (LSE)
translation. The 4th workshop on the representation
and processing of sign languages: corpora and sign
language technologies at LREC 2010: 208–211.
Adam Schembri. 2008. British Sign Language cor-
pus project: open access archives and the observer’s
paradox. 3rd workshop on the representation and
processing of sign languages at LREC 2008.
Daniel Stein, Christoph Schmidt and Hermann Ney.
2012. Analysis, preparation, and optimization of
statistical sign language machine translation. Ma-
chine Translation 26: 325-357.
Katsuhito Sudoh, Shinsuke Mori and Masaaki Na-
gata. 2013. Noise-aware Character Alignment for
Bootstrapping Statistical Machine Translation from
Bilingual Corpora. Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP 2013): 204–209.
Paola Virga, Senjeev Khudanpur. 2003. Transliter-
ation of proper names in cross-lingual information
retrieval. MultiNER ’03 Proceeding of the ACL
2003 workshop on multilingual and mixed-language
named entity recognition Volume 15, pp 57–64.
</reference>
<page confidence="0.999089">
75
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.223088">
<title confidence="0.976514">Proper Name Machine from Japanese to Japanese Sign Language</title>
<author confidence="0.9129385">Taro Miyazaki</author>
<author confidence="0.9129385">Naoto Kato</author>
<author confidence="0.9129385">Seiki Shuichi Umeda</author>
<author confidence="0.9129385">Makiko Azuma</author>
<author confidence="0.9129385">Nobuyuki</author>
<affiliation confidence="0.999673">NHK Science &amp; Technology Research</affiliation>
<address confidence="0.710076">Tokyo,</address>
<email confidence="0.9395045">katou.n-ga,azuma.m-ia,</email>
<author confidence="0.760907">Yuji Nagashima</author>
<affiliation confidence="0.7555515">Faculty of Kogakuin</affiliation>
<address confidence="0.751802">Tokyo,</address>
<email confidence="0.989034">nagasima@cc.kogakuin.ac.jp</email>
<abstract confidence="0.996829454545455">This paper describes machine translation of proper names from Japanese to Japanese Sign Language (JSL). “Proper name transliteration” is a kind of machine translation of proper names between spoken languages and involves character-tocharacter conversion based on pronunciation. However, transliteration methods cannot be applied to Japanese-JSL machine translation because proper names in JSL are composed of words rather than characters. Our method involves not only pronunciation-based translation, but also sense-based translation, because kanji, which are ideograms that compose most Japanese proper names, are closely related to JSL words. These translation methods are trained from parallel corpora. The sense-based translation part is trained via phrase alignment in sentence pairs in a Japanese and JSL corpus. The pronunciation-based translation part is trained from a Japanese proper name corpus and then post-processed with transformation rules. We conducted a series of evaluation experiments and obtained 75.3% of accuracy rate, increasing from baseline method by 19.7 points. We also developed a Japanese-JSL proper name translation system, in which the translated proper names are visualized with CG animations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Antonio Balvet</author>
<author>Cyril Courtin</author>
<author>Dominique Boutet</author>
<author>Christian Cuxac</author>
<author>Ivani Fusellier-Souza</author>
<author>Brigitte Garcia</author>
</authors>
<title>Marie-Th´er`ese L’Huillier and Marie-Anne Sallandre.</title>
<date>2010</date>
<booktitle>and Natural Gestural Languages. International Conference on Language Resources and Evaluation (LREC 2010):</booktitle>
<pages>469--475</pages>
<contexts>
<context position="16683" citStr="Balvet et al., 2010" startWordPosition="2685" endWordPosition="2688">evising the speech recognition results of the news programs. The transcriptions are carried out by changing the sign gestures of the newscasters into sequences of JSL words. The JSL movies are manually extracted from the program by referring to the time intervals of the transcribed JSL transcriptions. The corpus currently includes about 22,000 sentence pairs taken from broadcasts running from April 2009 to August 2010. Our bilingual corpus is larger than other recent sign language corpora built in various sign language research projects (Bungeroth et al., 2006; Schembri, 2008; Johnston, 2009; Balvet et al., 2010; Matthes et al., 2012; Mesch et al., 2012). Figure 4 shows an example of our corpus. 4.2.2 Human Name Corpus The human-name corpus was constructed by extracting personal names written in both kanji and kana from the IPADIC dictionary6. 4.3 Evaluation and Discussion We conducted a series of experiments to evaluate our method. Table 2 shows the translation accuracies for proper names. The tested methods were as follows. Baseline A simple baseline method (mentioned in 3.1.1) Pialign The conventional character-based translation method (Neubig et al., 2012) Proposed (sense-based) Our method for se</context>
</contexts>
<marker>Balvet, Courtin, Boutet, Cuxac, Fusellier-Souza, Garcia, 2010</marker>
<rawString>Antonio Balvet, Cyril Courtin, Dominique Boutet, Christian Cuxac, Ivani Fusellier-Souza, Brigitte Garcia, Marie-Th´er`ese L’Huillier and Marie-Anne Sallandre. 2010. The Creagest Project: a Digitized and Annotated Corpus for French Sign Language (LSF) and Natural Gestural Languages. International Conference on Language Resources and Evaluation (LREC 2010): 469–475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Bungeroth</author>
<author>Daniel Stein</author>
<author>Philippe Dreuw</author>
<author>Morteza Zahedi</author>
<author>Hermann Ney</author>
</authors>
<title>A German Sign Language corpus of the domain weather report.</title>
<date>2006</date>
<booktitle>International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>2000--2003</pages>
<contexts>
<context position="16630" citStr="Bungeroth et al., 2006" startWordPosition="2676" endWordPosition="2679">movies. The Japanese transcriptions are transcribed by revising the speech recognition results of the news programs. The transcriptions are carried out by changing the sign gestures of the newscasters into sequences of JSL words. The JSL movies are manually extracted from the program by referring to the time intervals of the transcribed JSL transcriptions. The corpus currently includes about 22,000 sentence pairs taken from broadcasts running from April 2009 to August 2010. Our bilingual corpus is larger than other recent sign language corpora built in various sign language research projects (Bungeroth et al., 2006; Schembri, 2008; Johnston, 2009; Balvet et al., 2010; Matthes et al., 2012; Mesch et al., 2012). Figure 4 shows an example of our corpus. 4.2.2 Human Name Corpus The human-name corpus was constructed by extracting personal names written in both kanji and kana from the IPADIC dictionary6. 4.3 Evaluation and Discussion We conducted a series of experiments to evaluate our method. Table 2 shows the translation accuracies for proper names. The tested methods were as follows. Baseline A simple baseline method (mentioned in 3.1.1) Pialign The conventional character-based translation method (Neubig e</context>
</contexts>
<marker>Bungeroth, Stein, Dreuw, Zahedi, Ney, 2006</marker>
<rawString>Jan Bungeroth, Daniel Stein, Philippe Dreuw, Morteza Zahedi and Hermann Ney. 2006. A German Sign Language corpus of the domain weather report. International Conference on Language Resources and Evaluation (LREC 2006): 2000–2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Keiji Yasuda</author>
</authors>
<title>Hideo Okuma, Eiichiro Sumita and Satoshi Nakamura.</title>
<date>2011</date>
<booktitle>IEICE transactions on Information and Systems:</booktitle>
<volume>94</volume>
<pages>1889--1900</pages>
<marker>Finch, Yasuda, 2011</marker>
<rawString>Andrew Finch, Keiji Yasuda, Hideo Okuma, Eiichiro Sumita and Satoshi Nakamura. 2011. A Bayesian Model of Transliteration and Its Human Evaluation when Integrated into a Machine Translation System. IEICE transactions on Information and Systems: Vol. E94–D, No. 10, pp.1889–1900.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isao Goto</author>
<author>Naoto Kato</author>
<author>Noriyoshi Uratani</author>
<author>Terumasa Ehara</author>
</authors>
<title>Transliteration considering context information based on the maximum entropy method. The 9th Machine Translation Summit:</title>
<date>2003</date>
<pages>125--132</pages>
<contexts>
<context position="3133" citStr="Goto et al., 2003" startWordPosition="464" endWordPosition="467">using a motion interpolation technique. To improve the machine translation system, we have been tackling several problems with translating in JSL. In this paper, we focus on the problem of proper name translation, because proper names occur frequently in TV news programs and are hard to translate with conventional methods. Proper name translation is one of the major topics of machine translation. In particular, there are many methods that work with spoken language, such as “proper name transliteration,” which means character-to-character conversion based on pronunciation (Knight et al., 1998; Goto et al., 2003; Virga et al., 2003; Li et al., 2004; Finch et al., 2010; Sudoh et al., 2013). However, transliteration methods cannot be applied to Japanese-JSL proper name translation because proper names in JSL are not composed of characters but rather of sign words. To translate proper names using sign words, sense-based translation is required. Sense-based translation trans67 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 67–75, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics Figure 1: Japanese-JSL translation system overvie</context>
</contexts>
<marker>Goto, Kato, Uratani, Ehara, 2003</marker>
<rawString>Isao Goto, Naoto Kato, Noriyoshi Uratani and Terumasa Ehara. 2003. Transliteration considering context information based on the maximum entropy method. The 9th Machine Translation Summit: 125– 132.</rawString>
</citation>
<citation valid="true">
<title>Japanese Federation of the Deaf (JFD).</title>
<date>2009</date>
<booktitle>Place names map in Japanese Sign Language in Japan (in Japanese, “ Q�� &gt;7&amp;quot;”) Japanese Federation of the Deaf</booktitle>
<publisher>Press.</publisher>
<marker>2009</marker>
<rawString>Japanese Federation of the Deaf (JFD). 2009. Place names map in Japanese Sign Language in Japan (in Japanese, “ Q�� &gt;7&amp;quot;”) Japanese Federation of the Deaf Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Johnston</author>
</authors>
<title>Creating a corpus of Auslan within an Australian national corpus.</title>
<date>2009</date>
<booktitle>Selected Proceedings of the 2008 HCSNet Workshop on Designing the Australian National Corpus: Mustering Languages.</booktitle>
<contexts>
<context position="16662" citStr="Johnston, 2009" startWordPosition="2682" endWordPosition="2684">transcribed by revising the speech recognition results of the news programs. The transcriptions are carried out by changing the sign gestures of the newscasters into sequences of JSL words. The JSL movies are manually extracted from the program by referring to the time intervals of the transcribed JSL transcriptions. The corpus currently includes about 22,000 sentence pairs taken from broadcasts running from April 2009 to August 2010. Our bilingual corpus is larger than other recent sign language corpora built in various sign language research projects (Bungeroth et al., 2006; Schembri, 2008; Johnston, 2009; Balvet et al., 2010; Matthes et al., 2012; Mesch et al., 2012). Figure 4 shows an example of our corpus. 4.2.2 Human Name Corpus The human-name corpus was constructed by extracting personal names written in both kanji and kana from the IPADIC dictionary6. 4.3 Evaluation and Discussion We conducted a series of experiments to evaluate our method. Table 2 shows the translation accuracies for proper names. The tested methods were as follows. Baseline A simple baseline method (mentioned in 3.1.1) Pialign The conventional character-based translation method (Neubig et al., 2012) Proposed (sense-bas</context>
</contexts>
<marker>Johnston, 2009</marker>
<rawString>Trevor Johnston. 2009. Creating a corpus of Auslan within an Australian national corpus. Selected Proceedings of the 2008 HCSNet Workshop on Designing the Australian National Corpus: Mustering Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Kaneko</author>
<author>Narichika Hamaguchi</author>
<author>Mamoru Doke</author>
<author>Seiki Inoue</author>
</authors>
<title>Sign language animation using TVML.</title>
<date>2010</date>
<booktitle>9th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry (VRCAI 2010), ACM</booktitle>
<pages>2010--289</pages>
<contexts>
<context position="20690" citStr="Kaneko et al., 2010" startWordPosition="3336" endWordPosition="3339">izes the translated proper names as computer graphics (CG) animations. The CG animation is a high-quality 3D model of human hands and fingers, and the model is controlled using motion-capture (MoCap) data. The data is captured with an optical MoCap system in which many markers are attached to fingers to pick up their movements precisely. Figure5 shows the MoCap system. The CG-model has about 100 joints with three rotation angles. The CG-animation is rendered from scripts written in TVML (TM program Making Language7), which is a scripting language developed by NHK to describe full TV programs (Kaneko et al., 2010). Figure 6 shows an example of the Japaneseto-JSL proper name translation system. When a proper name in Japanese is entered, a corresponding sign language animation is created and shown in the system. The translation system will be used in subjective evaluation of proper name translations. 6 Conclusion We presented a Japanese-JSL proper name machine translation method. The method involves sense-based translation and pronunciation-based translation, both of which are based on statistical machine translation. We conducted a series of evaluation experiments and obtained 75.3% of accuracy, increas</context>
</contexts>
<marker>Kaneko, Hamaguchi, Doke, Inoue, 2010</marker>
<rawString>Hiroyuki Kaneko, Narichika Hamaguchi, Mamoru Doke and Seiki Inoue. 2010. Sign language animation using TVML. 9th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry (VRCAI 2010), ACM 2010:289–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>Machine transliteration.</title>
<date>1998</date>
<journal>Computer Linguistics,</journal>
<volume>24</volume>
<pages>599--612</pages>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight, Jonathan Graehl. 1998. Machine transliteration. Computer Linguistics, 24: 599–612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowen</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation. Annual meeting of the Association for Computational Linguistics (ACL 2007), demonstration session.</title>
<date>2007</date>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra</location>
<contexts>
<context position="13919" citStr="Koehn et al., 2007" startWordPosition="2236" endWordPosition="2239"> sign words. Such characters occur in the following cases. • The character does not appear in the training data of the sense-based translation. 4There are over 300,000 family names in Japan(Power, 2008). • The character is translated into kana because the character is often translated into Kana in the training data of sense-based translation. In these cases, our system translates the character into kana by using pronunciation-based translation. 4 Experiments and Results 4.1 Experimental setting Our method uses GIZA++ and “grow-diag-finaland” (Och et al., 2003) as the model training and Moses (Koehn et al., 2007) as the decoding; it does not use a language model because word context and reordering are useless in proper name translation from Japanese to JSL. The training sets were our Japanese-JSL news corpus (including 21,995 sentence pairs) for sense-based translation and a human-name corpus (including 34,202 personal names) for pronunciation-based translation. These corpora are described below. The test set consisted of persons’ names and place names. Regarding the persons’ names, the candidates for the test set were first randomly sampled from a Japanese family name database5. The 100 sampled names</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowen, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowen, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. Annual meeting of the Association for Computational Linguistics (ACL 2007), demonstration session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Haizhou</author>
<author>Zhang Min</author>
<author>Su Jian</author>
</authors>
<title>A joint sourcechannel model for machine transliteration.</title>
<date>2004</date>
<booktitle>Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL ’04). Article No. 159.</booktitle>
<marker>Haizhou, Min, Jian, 2004</marker>
<rawString>Li Haizhou, Zhang Min, Su Jian. 2004 A joint sourcechannel model for machine transliteration. Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL ’04). Article No. 159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Camillo Lugaresi</author>
<author>Barbara Di Eugenio</author>
</authors>
<title>Translating Italian connectives into Italian Sign Language.</title>
<date>2013</date>
<booktitle>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>270--280</pages>
<location>Sofia, Bulgaria,</location>
<marker>Lugaresi, Di Eugenio, 2013</marker>
<rawString>Camillo Lugaresi and Barbara Di Eugenio. 2013. Translating Italian connectives into Italian Sign Language. Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013), pp 270–280. Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillem Mass´o</author>
<author>Toni Badia</author>
</authors>
<title>Dealing with sign language morphemes in statistical machine translation. 4th workshop on the representation and processing of sign language: interactions between corpus and lexicon at LREC</title>
<date>2010</date>
<pages>154--157</pages>
<marker>Mass´o, Badia, 2010</marker>
<rawString>Guillem Mass´o and Toni Badia. 2010. Dealing with sign language morphemes in statistical machine translation. 4th workshop on the representation and processing of sign language: interactions between corpus and lexicon at LREC 2010: 154–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silke Matthes</author>
<author>Thomas Hanke</author>
<author>Anja Regan</author>
<author>Jakob Storz</author>
</authors>
<title>Satu Worseek, Eleni Efthimiou, AthanasiaLida Dimou, Annelies Braffort, John Glauert and Eva Safar.</title>
<date>2012</date>
<pages>117--122</pages>
<contexts>
<context position="16705" citStr="Matthes et al., 2012" startWordPosition="2689" endWordPosition="2692">cognition results of the news programs. The transcriptions are carried out by changing the sign gestures of the newscasters into sequences of JSL words. The JSL movies are manually extracted from the program by referring to the time intervals of the transcribed JSL transcriptions. The corpus currently includes about 22,000 sentence pairs taken from broadcasts running from April 2009 to August 2010. Our bilingual corpus is larger than other recent sign language corpora built in various sign language research projects (Bungeroth et al., 2006; Schembri, 2008; Johnston, 2009; Balvet et al., 2010; Matthes et al., 2012; Mesch et al., 2012). Figure 4 shows an example of our corpus. 4.2.2 Human Name Corpus The human-name corpus was constructed by extracting personal names written in both kanji and kana from the IPADIC dictionary6. 4.3 Evaluation and Discussion We conducted a series of experiments to evaluate our method. Table 2 shows the translation accuracies for proper names. The tested methods were as follows. Baseline A simple baseline method (mentioned in 3.1.1) Pialign The conventional character-based translation method (Neubig et al., 2012) Proposed (sense-based) Our method for sensebased translation (</context>
</contexts>
<marker>Matthes, Hanke, Regan, Storz, 2012</marker>
<rawString>Silke Matthes, Thomas Hanke, Anja Regan, Jakob Storz, Satu Worseek, Eleni Efthimiou, AthanasiaLida Dimou, Annelies Braffort, John Glauert and Eva Safar. 2012. Dicta-Sign – Building a multilingual sign language corpus. 5th workshop on the representation and processing of sign language: interactions between corpus and lexicon at LREC 2012: 117–122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Mazzei</author>
</authors>
<title>Sign language generation with expert systems and ccg.</title>
<date>2012</date>
<booktitle>Proceedings of the Seventh International Natural Language Generation Conference (INLG ’12):</booktitle>
<pages>105--109</pages>
<contexts>
<context position="4085" citStr="Mazzei, 2012" startWordPosition="610" endWordPosition="611">se-based translation trans67 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 67–75, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics Figure 1: Japanese-JSL translation system overview lates kanji, which are ideograms that compose most Japanese proper names, into closely related JSL words. Moreover, although several methods have been proposed to translate sentences in sign language, there is as yet no method to translate proper names (Mass´o et al., 2010; San-Segundo et al., 2010; Morrissey, 2011; Stein et al., 2012; Mazzei, 2012; Lugaresi et al., 2013). This paper describes proper name translation from Japanese into JSL. The method involves sense-based translation and pronunciation-based translation. Both conversions are based on a statistical machine translation framework. The sense-based translation is a sense-based characterwise translation learned from phrase pairs in a Japanese-JSL corpus. The pronunciation-based translation is a pronunciation-based characterwise translation learned from a Japanese proper name corpus and is post-processed with transformation rules. We conducted a series of evaluation experiments</context>
</contexts>
<marker>Mazzei, 2012</marker>
<rawString>Alessandro Mazzei. 2012. Sign language generation with expert systems and ccg. Proceedings of the Seventh International Natural Language Generation Conference (INLG ’12): 105–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johanna Mesch</author>
<author>Lars Wallin</author>
<author>Thomas Bj¨orkstrand</author>
</authors>
<title>Sign language resources in Swedes: dictionary and corpus. 5th workshop on the representation and processing of sign language: interactions between corpus and lexicon at LREC 2012:</title>
<date>2012</date>
<pages>127--130</pages>
<marker>Mesch, Wallin, Bj¨orkstrand, 2012</marker>
<rawString>Johanna Mesch, Lars Wallin and Thomas Bj¨orkstrand. 2012. Sign language resources in Swedes: dictionary and corpus. 5th workshop on the representation and processing of sign language: interactions between corpus and lexicon at LREC 2012: 127– 130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Morrissey</author>
</authors>
<title>Assessing three representation methods for sign language machine translation and evaluation. 15th annual meeting of the European Association for Machine Translation (EAMT</title>
<date>2011</date>
<pages>137--144</pages>
<contexts>
<context position="4051" citStr="Morrissey, 2011" startWordPosition="604" endWordPosition="605">se-based translation is required. Sense-based translation trans67 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 67–75, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics Figure 1: Japanese-JSL translation system overview lates kanji, which are ideograms that compose most Japanese proper names, into closely related JSL words. Moreover, although several methods have been proposed to translate sentences in sign language, there is as yet no method to translate proper names (Mass´o et al., 2010; San-Segundo et al., 2010; Morrissey, 2011; Stein et al., 2012; Mazzei, 2012; Lugaresi et al., 2013). This paper describes proper name translation from Japanese into JSL. The method involves sense-based translation and pronunciation-based translation. Both conversions are based on a statistical machine translation framework. The sense-based translation is a sense-based characterwise translation learned from phrase pairs in a Japanese-JSL corpus. The pronunciation-based translation is a pronunciation-based characterwise translation learned from a Japanese proper name corpus and is post-processed with transformation rules. We conducted </context>
</contexts>
<marker>Morrissey, 2011</marker>
<rawString>Sara Morrissey. 2011. Assessing three representation methods for sign language machine translation and evaluation. 15th annual meeting of the European Association for Machine Translation (EAMT 2011): 137–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Taro Watanabe</author>
<author>Shinsuke Mori</author>
<author>Tatsuya Kawahara</author>
</authors>
<title>Machine Translation without Words through Substring Alignment.</title>
<date>2012</date>
<booktitle>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL2012) :</booktitle>
<pages>165--174</pages>
<contexts>
<context position="17242" citStr="Neubig et al., 2012" startWordPosition="2775" endWordPosition="2778">l., 2006; Schembri, 2008; Johnston, 2009; Balvet et al., 2010; Matthes et al., 2012; Mesch et al., 2012). Figure 4 shows an example of our corpus. 4.2.2 Human Name Corpus The human-name corpus was constructed by extracting personal names written in both kanji and kana from the IPADIC dictionary6. 4.3 Evaluation and Discussion We conducted a series of experiments to evaluate our method. Table 2 shows the translation accuracies for proper names. The tested methods were as follows. Baseline A simple baseline method (mentioned in 3.1.1) Pialign The conventional character-based translation method (Neubig et al., 2012) Proposed (sense-based) Our method for sensebased translation (described in 3.1.2) Pronunciation-based Our method for pronunciation-based translation (described in 3.2) Our overall method is “Proposed (sense-based) + pronunciation-based.” The upper row of each cell in the table shows the number of the correct words, whereas the lower row of each cell is the accuracy. The table indicates that compared with the baseline, our method is higher in accuracy by 19.7 points in total, 19.8 points on persons’ name, and 19.6 points on place names. It is higher in accuracy than the baseline for each type </context>
</contexts>
<marker>Neubig, Watanabe, Mori, Kawahara, 2012</marker>
<rawString>Graham Neubig, Taro Watanabe, Shinsuke Mori and Tatsuya Kawahara. 2012. Machine Translation without Words through Substring Alignment. Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL2012) : 165–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models. Computational Linguistics,29:</title>
<date>2003</date>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics,29: 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Power</author>
</authors>
<title>Japanese Names. The Indexer,</title>
<date>2008</date>
<volume>26</volume>
<pages>4--2</pages>
<contexts>
<context position="13502" citStr="Power, 2008" startWordPosition="2172" endWordPosition="2173">ames. Our method applies these rules to the nonaligned kanji and kana from the beginning character in the sentences after the sense-based translation. 3.3 Combining sense-based and pronunciation-based translation In our proper name translation, sense-based translation is first applied to a Japanese proper name and then pronunciation-based translation is applied to the characters that were not converted into sign words. Such characters occur in the following cases. • The character does not appear in the training data of the sense-based translation. 4There are over 300,000 family names in Japan(Power, 2008). • The character is translated into kana because the character is often translated into Kana in the training data of sense-based translation. In these cases, our system translates the character into kana by using pronunciation-based translation. 4 Experiments and Results 4.1 Experimental setting Our method uses GIZA++ and “grow-diag-finaland” (Och et al., 2003) as the model training and Moses (Koehn et al., 2007) as the decoding; it does not use a language model because word context and reordering are useless in proper name translation from Japanese to JSL. The training sets were our Japanese</context>
</contexts>
<marker>Power, 2008</marker>
<rawString>John Power. 2008. Japanese Names. The Indexer, Volume 26, No 2, pp. C4-2–C4-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rub´en San-Segundo</author>
<author>Ver´onica L´opez</author>
<author>Raquel Martin</author>
<author>David S´anchez</author>
<author>Adolfo Garcia</author>
</authors>
<title>Language resources for Spanish – Spanish Sign Language (LSE) translation. The 4th workshop on the representation and processing of sign languages: corpora and sign language technologies at LREC</title>
<date>2010</date>
<pages>208--211</pages>
<marker>San-Segundo, L´opez, Martin, S´anchez, Garcia, 2010</marker>
<rawString>Rub´en San-Segundo, Ver´onica L´opez, Raquel Martin, David S´anchez, Adolfo Garcia. 2010. Language resources for Spanish – Spanish Sign Language (LSE) translation. The 4th workshop on the representation and processing of sign languages: corpora and sign language technologies at LREC 2010: 208–211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Schembri</author>
</authors>
<title>British Sign Language corpus project: open access archives and the observer’s paradox. 3rd workshop on the representation and processing of sign languages at LREC</title>
<date>2008</date>
<contexts>
<context position="16646" citStr="Schembri, 2008" startWordPosition="2680" endWordPosition="2681">nscriptions are transcribed by revising the speech recognition results of the news programs. The transcriptions are carried out by changing the sign gestures of the newscasters into sequences of JSL words. The JSL movies are manually extracted from the program by referring to the time intervals of the transcribed JSL transcriptions. The corpus currently includes about 22,000 sentence pairs taken from broadcasts running from April 2009 to August 2010. Our bilingual corpus is larger than other recent sign language corpora built in various sign language research projects (Bungeroth et al., 2006; Schembri, 2008; Johnston, 2009; Balvet et al., 2010; Matthes et al., 2012; Mesch et al., 2012). Figure 4 shows an example of our corpus. 4.2.2 Human Name Corpus The human-name corpus was constructed by extracting personal names written in both kanji and kana from the IPADIC dictionary6. 4.3 Evaluation and Discussion We conducted a series of experiments to evaluate our method. Table 2 shows the translation accuracies for proper names. The tested methods were as follows. Baseline A simple baseline method (mentioned in 3.1.1) Pialign The conventional character-based translation method (Neubig et al., 2012) Pro</context>
</contexts>
<marker>Schembri, 2008</marker>
<rawString>Adam Schembri. 2008. British Sign Language corpus project: open access archives and the observer’s paradox. 3rd workshop on the representation and processing of sign languages at LREC 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Stein</author>
<author>Christoph Schmidt</author>
<author>Hermann Ney</author>
</authors>
<title>Analysis, preparation, and optimization of statistical sign language machine translation.</title>
<date>2012</date>
<journal>Machine Translation</journal>
<volume>26</volume>
<pages>325--357</pages>
<contexts>
<context position="4071" citStr="Stein et al., 2012" startWordPosition="606" endWordPosition="609">ion is required. Sense-based translation trans67 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 67–75, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics Figure 1: Japanese-JSL translation system overview lates kanji, which are ideograms that compose most Japanese proper names, into closely related JSL words. Moreover, although several methods have been proposed to translate sentences in sign language, there is as yet no method to translate proper names (Mass´o et al., 2010; San-Segundo et al., 2010; Morrissey, 2011; Stein et al., 2012; Mazzei, 2012; Lugaresi et al., 2013). This paper describes proper name translation from Japanese into JSL. The method involves sense-based translation and pronunciation-based translation. Both conversions are based on a statistical machine translation framework. The sense-based translation is a sense-based characterwise translation learned from phrase pairs in a Japanese-JSL corpus. The pronunciation-based translation is a pronunciation-based characterwise translation learned from a Japanese proper name corpus and is post-processed with transformation rules. We conducted a series of evaluati</context>
</contexts>
<marker>Stein, Schmidt, Ney, 2012</marker>
<rawString>Daniel Stein, Christoph Schmidt and Hermann Ney. 2012. Analysis, preparation, and optimization of statistical sign language machine translation. Machine Translation 26: 325-357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsuhito Sudoh</author>
<author>Shinsuke Mori</author>
<author>Masaaki Nagata</author>
</authors>
<title>Noise-aware Character Alignment for Bootstrapping Statistical Machine Translation from Bilingual Corpora.</title>
<date>2013</date>
<booktitle>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013):</booktitle>
<pages>204--209</pages>
<contexts>
<context position="3211" citStr="Sudoh et al., 2013" startWordPosition="480" endWordPosition="483">ystem, we have been tackling several problems with translating in JSL. In this paper, we focus on the problem of proper name translation, because proper names occur frequently in TV news programs and are hard to translate with conventional methods. Proper name translation is one of the major topics of machine translation. In particular, there are many methods that work with spoken language, such as “proper name transliteration,” which means character-to-character conversion based on pronunciation (Knight et al., 1998; Goto et al., 2003; Virga et al., 2003; Li et al., 2004; Finch et al., 2010; Sudoh et al., 2013). However, transliteration methods cannot be applied to Japanese-JSL proper name translation because proper names in JSL are not composed of characters but rather of sign words. To translate proper names using sign words, sense-based translation is required. Sense-based translation trans67 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 67–75, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics Figure 1: Japanese-JSL translation system overview lates kanji, which are ideograms that compose most Japanese proper names, in</context>
</contexts>
<marker>Sudoh, Mori, Nagata, 2013</marker>
<rawString>Katsuhito Sudoh, Shinsuke Mori and Masaaki Nagata. 2013. Noise-aware Character Alignment for Bootstrapping Statistical Machine Translation from Bilingual Corpora. Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013): 204–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Virga</author>
<author>Senjeev Khudanpur</author>
</authors>
<title>Transliteration of proper names in cross-lingual information retrieval.</title>
<date>2003</date>
<booktitle>MultiNER ’03 Proceeding of the ACL 2003 workshop on multilingual and mixed-language named entity recognition</booktitle>
<volume>15</volume>
<pages>57--64</pages>
<marker>Virga, Khudanpur, 2003</marker>
<rawString>Paola Virga, Senjeev Khudanpur. 2003. Transliteration of proper names in cross-lingual information retrieval. MultiNER ’03 Proceeding of the ACL 2003 workshop on multilingual and mixed-language named entity recognition Volume 15, pp 57–64.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>