<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.776821">
Automatic diagnosis of understanding of medical words
</title>
<note confidence="0.9051125">
Thierry Hamon
LIMSI-CNRS, BP133, Orsay
Universit´e Paris 13
Sorbonne Paris Cit´e, France
</note>
<email confidence="0.919457">
hamon@limsi.fr
</email>
<note confidence="0.819915666666667">
Natalia Grabar
CNRS UMR 8163 STL
Universit´e Lille 3
59653 Villeneuve d’Ascq, France
natalia.grabar@univ-lille3.fr
Dany Amiot
CNRS UMR 8163 STL
Universit´e Lille 3
59653 Villeneuve d’Ascq, France
</note>
<email confidence="0.495305">
dany.amiot@univ-lille3.fr
</email>
<sectionHeader confidence="0.982476" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99981565">
Within the medical field, very specialized
terms are commonly used, while their un-
derstanding by laymen is not always suc-
cessful. We propose to study the under-
standability of medical words by laymen.
Three annotators are involved in the cre-
ation of the reference data used for training
and testing. The features of the words may
be linguistic (i.e., number of characters,
syllables, number of morphological bases
and affixes) and extra-linguistic (i.e., their
presence in a reference lexicon, frequency
on a search engine). The automatic cate-
gorization results show between 0.806 and
0.947 F-measure values. It appears that
several features and their combinations are
relevant for the analysis of understandabil-
ity (i.e., syntactic categories, presence in
reference lexica, frequency on the general
search engine, final substring).
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991680807017544">
The medical field has deeply penetrated our daily
life, which may be due to personal or family
health condition, watching TV and radio broad-
casts, reading novels and journals. Nevertheless,
the availability of this kind of information does not
guarantee its correct understanding, especially by
laymen, such as patients. The medical field has in-
deed a specific terminology (e.g., abdominoplasty,
hepatic, dermabrasion or hepatoduodenostomy)
commonly used by medical professionals. This
fact has been highlighted in several studies dedi-
cated for instance to the understanding of pharma-
ceutical labels (Patel et al., 2002), of information
provided by websites (Rudd et al., 1999; Berland
et al., 2001; McCray, 2005; Oregon Evidence-
based Practice Center, 2008), and more generally
the understanding between patients and medical
doctors (AMA, 1999; McCray, 2005; Jucks and
Bromme, 2007; Tran et al., 2009).
We propose to study the understanding of words
used in the medical field, which is the first step to-
wards the simplification of texts. Indeed, before
the simplification can be performed, it is neces-
sary to know which textual units may show under-
standing difficulty and should be simplified. We
work with data in French, such as provided by
an existing medical terminology. In the remain-
der, we present first some related work, especially
from specialized fields (section 2). We then intro-
duce the linguistic data (section 4) and methodol-
ogy (section 5) we propose to test. We present and
discuss the results (section 6), and conclude with
some directions for future work (section 7).
2 Studying the understanding of words
The understanding (of words) may be seen as a
scale going from I can understand to I cannot un-
derstand, and containing one or more intermediate
positions (i.e., I am not sure, I have seen it be-
fore but do not remember the meaning, I do not
know but can interpret). Notice that it is also re-
lated to the ability to provide correct explanation
and use of words. As we explain later, we con-
sider words out of context and use a three-position
scale. More generally, understanding is a complex
notion closely linked to several other notions stud-
ied in different research fields. For instance, lex-
ical complexity is studied in linguistics and gives
clues on lexical processes involved, that may im-
pact the word understanding (section 2.1). Work
in psycholinguistics is often oriented on study of
word opacity and the mental processes involved in
their understanding (Jarema et al., 1999; Libben et
al., 2003). Readability provides a set of methods
to compute and quantify the understandability of
words (section 2.3). The specificity of words to
specialized areas is another way to capture their
understandability (section 2.2). Finally, lexical
</bodyText>
<page confidence="0.992752">
11
</page>
<note confidence="0.994091">
Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 11–20,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.994625">
simplification aims at providing simpler words to
be used in a given context (section 2.3).
</bodyText>
<subsectionHeader confidence="0.928659">
2.1 Linguistics
</subsectionHeader>
<bodyText confidence="0.999813129629629">
In linguistics, the question is closely related to lex-
ical complexity and compoundings. It has been
indeed observed that at least five factors, linguis-
tic and extra-linguistic, may be involved in the se-
mantic complexity of the compounds. One factor
is related to the knowledge of the components of
the complex words. Formal (how the words, such
as aerenchyme, can be segmented) and seman-
tic (how the words can be understood and used)
points of view can be distinguished. A second
factor is that complexity is also due to the vari-
ety of morphological patterns and relations among
the components. For instance, erythrocyte (erythro-
cyte) and ovocyte (ovocyte) instantiate the [N1N2]
pattern in which N2 (cyte) can be seen as a con-
stant element (Booij, 2010), although the relations
between N1 and N2 are not of the same type in
these two compounds: in erythrocyte, N1 erythr(o)
denotes a property of N2 (color), while in ovo-
cyte, N1 ovo (egg) corresponds to a specific de-
velopment stage of female cells. Another factor
appears when some components are polysemous,
within a given field (i.e., medical field) or across
the fields. For instance, aer(o) does not always
convey the same meaning: in aeroc`ele, aer- de-
notes ’air’ (tumefaction (c`ele) formed by an air in-
filtration), but not in aerasthenie, which refers to
an asthenia (psychic disorder) observable among
jet pilots. Yet another factor may be due to the dif-
ference in the order of components: according to
whether the compounding is standard (in French,
the main semantic element is then on the left, such
as in pneu neige (snow tyre), which is fundamen-
tally a pneu (tyre)) or neoclassical (in French, the
main semantic element is then on the right, such as
erythrocyte, which is a kind of cyte cell /corpuscle
with red color). It is indeed complicated for a user
without medical training to correctly interpret a
word that he does not know and for which he can-
not reuse the existing standard compounding pat-
terns. This difficulty is common to all Roman lan-
guages (Iacobini, 2003), but not to Germanic lan-
guages (L¨udeling et al., 2002). Closely related is
the fact that with neoclassical compounds, a given
component may change its place according to the
global semantics of the compounds, such as path-
in pathology, polyneuropathe, cardiopathy. Fi-
nally, the formal similarity between some deriva-
tion processes (such as the derivation in -oide, like
in lipoid) and neoclassical compounding (such as
-ase in lipase), which apply completely different
interpretation patterns (Iacobini, 1997; Amiot and
Dal, 2005), can also make the understanding more
difficult.
</bodyText>
<subsectionHeader confidence="0.989669">
2.2 Terminology
</subsectionHeader>
<bodyText confidence="0.99991315">
In the terminology field, the automatic identifica-
tion of difficulty of terms and words remains im-
plicit, while this notion is fundamental in termi-
nology (W¨uster, 1981; Cabr´e and Estop`a, 2002;
Cabr´e, 2000). The specificity of terms to a given
field is usually studied. The notion of understand-
ability can be derived from it. Such studies can
be used for filtering the terms extracted from spe-
cialized corpora (Korkontzelos et al., 2008). The
features exploited include for instance the pres-
ence and the specificity of pivot words (Drouin
and Langlais, 2006), the neighborhood of the term
in corpus or the diversity of its components com-
puted with statistical measures such as C-Value or
PageRank (Daille, 1995; Frantzi et al., 1997; May-
nard and Ananiadou, 2000). Another possibility is
to check whether lexical units occur within refer-
ence terminologies and, if they do, they are con-
sidered to convey specialized meaning (Elhadad
and Sutaria, 2007).
</bodyText>
<subsectionHeader confidence="0.997871">
2.3 NLP studies
</subsectionHeader>
<bodyText confidence="0.999932619047619">
The application of the readability measures is an-
other way to evaluate the complexity of words and
terms. Among these measures, it is possible to dis-
tinguish classical readability measures and com-
putational readability measures (Franc¸ois, 2011).
Classical measures usually rely on number of let-
ters and/or of syllables a word contains and on
linear regression models (Flesch, 1948; Gunning,
1973), while computational readability measures
may involve vector models and a great variabil-
ity of features, among which the following have
been used to process the biomedical documents
and words: combination of classical readability
formulas with medical terminologies (Kokkinakis
and Toporowska Gronostaj, 2006); n-grams of
characters (Poprat et al., 2006), manually (Zheng
et al., 2002) or automatically (Borst et al., 2008)
defined weight of terms, stylistic (Grabar et al.,
2007) or discursive (Goeuriot et al., 2007) fea-
tures, lexicon (Miller et al., 2007), morphologi-
cal features (Chmielik and Grabar, 2011), combi-
</bodyText>
<page confidence="0.992426">
12
</page>
<table confidence="0.5906376">
Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%)
1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27)
2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2)
3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71)
Total annotations 29,641 29,641 29,641 22,925 28,763
</table>
<tableCaption confidence="0.879225">
Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2
and A3), and in the derived datasets unanimity and majority.
</tableCaption>
<bodyText confidence="0.993558227272727">
nations of different features (Wang, 2006; Zeng-
Treiler et al., 2007; Leroy et al., 2008).
Specific task has been dedicated to the lexi-
cal simplification within the SemEval challenge in
20121. Given a short input text and a target word
in English, and given several English substitutes
for the target word that fit the context, the goal
was to rank these substitutes according to how
”simple” they are (Specia et al., 2012). The par-
ticipants applied rule-based and/or machine learn-
ing systems. Combinations of various features
have been used: lexicon from spoken corpus
and Wikipedia, Google n-grams, WordNet (Sinha,
2012); word length, number of syllables, latent se-
mantic analysis, mutual information and word fre-
quency (Jauhar and Specia, 2012); Wikipedia fre-
quency, word length, n-grams of characters and of
words, random indexing and syntactic complexity
of documents (Johannsen et al., 2012); n-grams
and frequency from Wikipedia, Google n-grams
(Ligozat et al., 2012); WordNet and word fre-
quency (Amoia and Romanelli, 2012).
</bodyText>
<sectionHeader confidence="0.768729" genericHeader="introduction">
3 Aims of the present study
</sectionHeader>
<bodyText confidence="0.999900444444445">
We propose to investigate how the understandabil-
ity of French medical words can be diagnosed with
NLP methods. We rely on the reference annota-
tions performed by French speakers without medi-
cal training, which we associate with patients. The
experiments performed rely on machine learning
algorithms and a set of 24 features. The medical
words studied are provided by an existing medical
terminology.
</bodyText>
<sectionHeader confidence="0.772812" genericHeader="method">
4 Linguistic data and their preparation
</sectionHeader>
<bodyText confidence="0.9998308">
The linguistic data are obtained from the medical
terminology Snomed International (Cˆot´e, 1996).
This terminology’s aim is to describe the whole
medical field. It contains 151,104 medical terms
structured into eleven semantic axes such as dis-
</bodyText>
<footnote confidence="0.905935">
1http://www.cs.york.ac.uk/semeval-2012/
</footnote>
<bodyText confidence="0.99631916">
orders and abnormalities, procedures, chemical
products, living organisms, anatomy, social sta-
tus, etc. We keep here five axes related to the
main medical notions (disorders, abnormalities,
procedures, functions, anatomy). The objective
is not to consider axes such as chemical products
(trisulfure d’hydrog`ene (hydrogen sulfide)) and living
organisms (Sapromyces, Acholeplasma laidlawii)
that group very specific terms hardly known by
laymen. The 104,649 selected terms are tokenized
and segmented into words (or tokens) to ob-
tain 29,641 unique words: trisulfure d’hydrog`ene
gives three words (trisulfure, de, hydrog`ene).
This dataset contains compounds (abdominoplas-
tie (abdominoplasty), dermabrasion (dermabrasion)),
constructed (cardiaque (cardiac), acineux (acinic),
lipoide (lipoid)) and simple (acn´e (acne), fragment
(fragment)) words. These data are annotated by
three speakers 25-40 year-old, without medical
training, but with linguistic background. We ex-
pect the annotators to represent the average knowl-
edge of medical words amongst the population as
a whole. The annotators are presented with a list of
terms and asked to assign each word to one of the
three categories: (1) I can understand the word;
</bodyText>
<listItem confidence="0.9674665">
(2) I am not sure about the meaning of the word;
(3) I cannot understand the word. The assumption
is that the words, which are not understandable by
the annotators, are also difficult to understand by
patients. These manual annotations correspond to
the reference data (Table 1).
</listItem>
<sectionHeader confidence="0.994237" genericHeader="method">
5 Methodology
</sectionHeader>
<bodyText confidence="0.999982571428571">
The proposed method has two aspects: gener-
ation of the features associated to the analyzed
words and a machine learning system. The main
research question is whether the NLP methods
can distinguish between understandable and non-
understandable medical words and whether they
can diagnose these two categories.
</bodyText>
<page confidence="0.993905">
13
</page>
<subsectionHeader confidence="0.989966">
5.1 Generation of the features
</subsectionHeader>
<bodyText confidence="0.998481">
We exploit 24 linguistic and extra-linguistic fea-
tures related to general and specialized languages.
The features are computed automatically, and can
be grouped into ten classes:
Syntactic categories. Syntactic categories and
lemmas are computed by TreeTagger (Schmid,
1994) and then checked by Flemm (Namer, 2000).
The syntactic categories are assigned to words
within the context of their terms. If a given word
receives more than one category, the most fre-
quent one is kept as feature. Among the main
categories we find for instance nouns, adjectives,
proper names, verbs and abbreviations.
Presence of words in reference lexica. We ex-
ploit two reference lexica of the French language:
TLFi2 and lexique.org3. TLFi is a dictionary of the
French language covering XIX and XX centuries.
It contains almost 100,000 entries. lexique.org is a
lexicon created for psycholinguistic experiments.
It contains over 135,000 entries, among which in-
flectional forms of verbs, adjectives and nouns. It
contains almost 35,000 lemmas.
Frequency of words through a non specialized
search engine. For each word, we query the
Google search engine in order to know its fre-
quency attested on the web.
Frequency of words in the medical terminology.
We also compute the frequency of words in the
medical terminology Snomed International.
Number and types of semantic categories asso-
ciated to words. We exploit the information on the
semantic categories of Snomed International.
Length of words in number of their characters
and syllables. For each word, we compute the
number of its characters and syllables.
Number of bases and affixes. Each lemma
is analyzed by the morphological analyzer D´erif
(Namer and Zweigenbaum, 2004), adapted to the
treatment of medical words. It performs the de-
composition of lemmas into bases and affixes
known in its database and it provides also seman-
tic explanation of the analyzed lexemes. We ex-
ploit the morphological decomposition informa-
tion (number of affixes and bases).
Initial and final substrings of the words. We
compute the initial and final substrings of differ-
ent length, from three to five characters.
</bodyText>
<footnote confidence="0.999477">
2http://www.atilf.fr/
3http://www.lexique.org/
</footnote>
<bodyText confidence="0.996737">
Number and percentage of consonants, vowels
and other characters. We compute the number and
the percentage of consonants, vowels and other
characters (i.e., hyphen, apostrophe, comas).
Classical readability scores. We apply two clas-
sical readability measures: Flesch (Flesch, 1948)
and its variant Flesch-Kincaid (Kincaid et al.,
1975). Such measures are typically used for eval-
uating the difficulty level of a text. They exploit
surface characteristics of words (number of char-
acters and/or syllables) and normalize these values
with specifically designed coefficients.
</bodyText>
<subsectionHeader confidence="0.998943">
5.2 Machine learning system
</subsectionHeader>
<bodyText confidence="0.999987307692307">
The machine learning algorithms are used to study
whether they can distinguish between words un-
derstandable and non-understandable by laymen
and to study the importance of various features for
the task. The functioning of machine learning al-
gorithms is based on a set of positive and nega-
tive examples of the data to be processed, which
have to be described with suitable features such
as those presented above. The algorithms can then
detect the regularities within the training dataset to
generate a model, and apply the generated model
to process new unseen data. We apply various al-
gorithms available within the WEKA (Witten and
Frank, 2005) platform.
The annotations provided by the three annota-
tors constitute our reference data. We use on the
whole five reference datasets (Table 1): 3 sets of
separate annotations provided by the three anno-
tators (29,641 words each); 1 unanimity set, on
which all the annotators agree (n=22,925); 1 ma-
jority set, for which we can compute the major-
ity agreement (n=28,763). By definition, the two
last datasets should present a better coherence and
less annotation ambiguity because some ambigui-
ties have been resolved by unanimity or by major-
ity vote.
</bodyText>
<subsectionHeader confidence="0.970272">
5.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.9995699">
The inter-annotator agreement is computed with
the Cohen’s Kappa (Cohen, 1960), applied to pairs
of annotators, which values are then leveraged to
obtain the unique average value; and Fleiss’ Kappa
(Fleiss and Cohen, 1973), suitable for processing
data provided by more than two annotators. The
interpretation of the scores are for instance (Landis
and Koch, 1977): substantial agreement between
0.61 and 0.80, almost perfect agreement between
0.81 and 1.00.
</bodyText>
<page confidence="0.995503">
14
</page>
<bodyText confidence="0.9999653">
With machine learning, we perform a ten-fold
cross-validation, which means that the evaluation
test is performed ten times on different randomly
generated test sets (1/10 of the whole dataset),
while the remaining 9/10 of the whole dataset is
used for training the algorithm and creating the
model. In this way, each word is used during the
test step. The success of the applied algorithms is
evaluated with three classical measures: R recall,
P precision and F F-measure. In the perspective
of our work, these measures allow evaluating the
suitability of the methodology to the distinction
between understandable and non-understandable
words and the relevance of the chosen features.
The baseline corresponds to the assignment of
words to the biggest category, e.g., I cannot under-
stand, which represents 66 to 74%, according to
datasets. We can also compute the gain, which is
the effective improvement of performance P given
the baseline BL (Rittman, 2008):
</bodyText>
<sectionHeader confidence="0.976456666666667" genericHeader="method">
6 Automatic analysis of
understandability of medical words:
Results and Discussion
</sectionHeader>
<bodyText confidence="0.999951833333333">
We address the following aspects: annotations
(inter-annotator agreement, assignment of words
to three categories), quantitative results provided
by the machine learning algorithms, impact of the
individual features on the distinction between cat-
egories, and usefulness of the method.
</bodyText>
<subsectionHeader confidence="0.969166">
6.1 Annotations and inter-annotator
agreement
</subsectionHeader>
<bodyText confidence="0.998916333333333">
The time needed for performing the manual ref-
erence annotations depends on annotators and
ranges from 3 to 6 weeks. The annotation results
presented in Table 1 indicate that the annotators
1 and 2 often provide similar results on their un-
derstanding of the medical words, while for the
third annotator the task appears to be more difficult
as he indicates globally a higher number of non-
understandable words. The non-understandable
words are the most frequent for all annotators and
cover 66 to 70% of the whole dataset. The inter-
annotator agreement shows substantial agreement:
Fleiss’ Kappa 0.735 and Cohen’s Kappa 0.736.
This is a very good result, especially when work-
ing with linguistic data for which the agreement is
usually difficult to obtain.
The evolution of annotations per category (Fig-
ure 1), such as provided by the annotators, can dis-
</bodyText>
<figureCaption confidence="0.993645">
Figure 1: Evolution of the annotations within the
reference data.
</figureCaption>
<bodyText confidence="0.994749333333333">
tinguish easily between the three categories: (1)
the most frequently chosen category is I cannot
understand and it grows rapidly with new words;
</bodyText>
<listItem confidence="0.687579875">
(2) the next most frequently chosen category is I
can understand, although it grows more slowly;
(3) the third category, which gathers the words on
which the annotators show some hesitation, is very
small. Given the proximity between the lines in
each category, we can conclude that the annota-
tors have similar difficulties in understanding the
words from the dataset.
</listItem>
<subsectionHeader confidence="0.7385565">
6.2 Quantitative results obtained with
machine learning
</subsectionHeader>
<table confidence="0.999935142857143">
P R F
J48 0.876 0.889 0.881
RandomForest 0.880 0.892 0.884
REPTree 0.874 0.890 0.879
DecisionTable 0.872 0.891 0.880
LMT 0.876 0.895 0.884
SMO 0.858 0.876 0.867
</table>
<tableCaption confidence="0.994881">
Table 2: Performance obtained on the majority
</tableCaption>
<bodyText confidence="0.955760181818182">
dataset with various algorithms.
We tested several machine learning algorithms
to discover which of them are the most suitable
to the task at hand. In Table 2, with results com-
puted on the majority dataset, we can observe that
the algorithms provide with similar performance
(between 0.85 and 0.90 P and R). In the remain-
ing of the paper, we present results obtained with
J48 (Quinlan, 1993). Table 3 shows P, R and
F values for the five datasets: three annotators,
majority and unanimity datasets. We can observe
</bodyText>
<figure confidence="0.9997293125">
0 5000 10000 15000 20000 25000
Words
Number in each category
20000
15000
10000
5000
0
A1
A2
A3
I cannot understand
I can understand
I am not sure
P−BL
1−BL .
</figure>
<page confidence="0.941709">
15
</page>
<bodyText confidence="0.998890071428571">
that, among the three annotators, it is easier to
reproduce the annotations of the third annotator:
we gain then 0.040 with F comparing to the two
other annotators. The results become even better
with the majority dataset (F=0.881), and reach F
up to 0.947 on the unanimity dataset. As we ex-
pected, these two last datasets present less annota-
tion ambiguity. The best categorization results are
observed with I can understand and I cannot un-
derstand categories, while the I am not sure cate-
gory is poorly managed by machine learning algo-
rithms. Because this category is very small, the av-
erage performance obtained on all three categories
remains high.
</bodyText>
<table confidence="0.99837925">
A1 A2 A3 Una. Maj.
P 0.794 0.809 0.834 0.946 0.876
R 0.825 0.826 0.862 0.949 0.889
F 0.806 0.814 0.845 0.947 0.881
</table>
<tableCaption confidence="0.926206">
Table 3: J48 performance obtained on five datasets
(A1, A2, A3, unanimity and majority).
</tableCaption>
<bodyText confidence="0.999738166666667">
In Table 4, we indicate the gain obtained by J48
compared to baseline: it ranges from 0.13 to 0.20,
which is a good improvement, despite the cate-
gory I am not sure that is difficult to discriminate.
We also indicate the accuracy obtained on these
datasets.
</bodyText>
<table confidence="0.9984962">
A1 A2 A3 Una. Maj.
BL 0.66 0.67 0.70 0.74 0.71
F 0.806 0.814 0.845 0.947 0.881
gain 0.14 0.13 0.14 0.20 0.16
Acc. 0.825 0.826 0.862 0.948 0.889
</table>
<tableCaption confidence="0.9109185">
Table 4: Gain obtained for F by J48 on five
datasets (A1, A2, A3, unanimity and majority).
</tableCaption>
<subsectionHeader confidence="0.816032">
6.3 Impact of individual features on
understandability of medical words
</subsectionHeader>
<bodyText confidence="0.998884363636364">
To observe the impact of individual features, we
did several iterations of experiments during which
we incrementally increased the set of features: we
started with one feature and then, at each iteration,
we added one new feature, up to the 24 features
available. We tried several random orders. The
test presented here is done again on the majority
dataset. Figures 2 present the results obtained in
terms of P, R and F. Globally, we can observe
that some features show positive impact while oth-
ers show negative or null impact:
</bodyText>
<figureCaption confidence="0.992463">
Figure 2: Impact of individual features.
</figureCaption>
<listItem confidence="0.8713036">
• with the syntactic categories (POS-tags)
alone we obtain P and R between 0.65 and
0.7. The performance is then close to the
baseline performance. Often, proper names
and abbreviations are associated with the
non-understandable words. There is no dif-
ference between TreeTagger alone and the
combination of TreeTagger with Flemm;
• the initial and final substrings have positive
impact. Among the final substrings, those
with three and four characters (ie, -omie of
-tomie (meaning cut), -phie of -rraphie (mean-
ing stitch), -´emie (meaning blood)) show posi-
tive impact, but substrings with five charac-
ters have negative impact and the previously
gained improvement is lost. We may con-
clude that the five-character long final sub-
strings may be too specific;
• the length of words in characters have neg-
ative impact on the categorization results.
</listItem>
<bodyText confidence="0.937157">
There seems to be no strong link between this
feature and the understanding of words: short
and long words may be experienced as both
understandable or not by annotators;
</bodyText>
<listItem confidence="0.983657222222222">
• the presence of words in the reference lexica
(TLFI and lexique.org) is beneficial to both
precision and recall. We assume these lexica
may represent common lexical competence
of French speakers. For this reason, words
that are present in these lexica, are also easier
to understand;
• the frequencies of words computed through
a general search engine are beneficial.
</listItem>
<figure confidence="0.999091722222222">
5 10 15 20
Feature subsets
Performance
0.9
0.8
0.7
0.6
0.5
1
POS−tag
initial substrings
final substrings
word length
reference lexica
Precision
Recall
F−measure
web frequency
</figure>
<page confidence="0.990665">
16
</page>
<bodyText confidence="0.999969852941176">
Words with higher frequencies are often as-
sociated with a better understanding, al-
though the frequency range depends on the
words. For instance, coccyx (coccyx) or drain
(drain) show high frequencies (1,800,000 and
175,000,000, respectively) and they belong
indeed to the I can understand category.
Words like colique (diarrhea) or clitoridien
(clitoral) show lower frequencies (807,000 and
9,821, respectively), although they belong to
the same category. On contrary, other words
with quite high frequencies, like coagulase
(coagulase), clivage (cleavage) or douve (fluke)
(655,000, 1,350,000 and 1,030,000, respec-
tively) are not understood by the annotators.
According to these experiments, our results point
out that, among the most efficient features, we can
find syntactic categories, presence of words in the
reference lexica, frequencies of words on Google
and three- and four-character end substring. In
comparison to the existing studies, such as those
presented during the SemEval challenge (Specia
et al., 2012), we propose to exploit a more com-
plete set of features, several of which rely on the
NLP methods (e.g., syntactic tagging, morpholog-
ical analysis). Especially the syntactic tagging ap-
pears to be salient for the task. In comparison to
work done on general language data (Gala et al.,
2013), our experiment shows better results (be-
tween 0.825 and 0.948 accuracy against 0.62 ac-
curacy in the cited work), which indicates that spe-
cialized domains have indeed very specific words.
Additional tests should be performed to obtain a
more detailed impact of the features.
</bodyText>
<subsectionHeader confidence="0.999726">
6.4 Usefulness of the method
</subsectionHeader>
<bodyText confidence="0.98001275">
We applied the proposed method to words from
discharge summaries. The documents are pre-
processed according to the same protocol and the
words are assigned the same features as previ-
ously (section 5). The model learned on the una-
nimity set is applied. The results are shown in
Figure 3. Among the words categorized as non-
understandable (in red and underlined), we find:
</bodyText>
<listItem confidence="0.993275">
• abbreviations (NIHSS, OAP, NaCl, VNI);
• technical medical terms (hypoesth´esie
(hypoesthesia), par´esie (paresia), throm-
bolyse (thrombolysis), iatrog`ene (iatrogenic),
oxyg´enoth´erapie (oxygen therapy), d´esaturation
(desaturation));
</listItem>
<figureCaption confidence="0.77783">
Figure 3: Detection of non-understandable words
within discharge summaries.
</figureCaption>
<listItem confidence="0.910878">
• medication names (CALCIPARINE);
</listItem>
<bodyText confidence="0.749280666666667">
In the example from Figure 3, three types of errors
can be distinguished when common words are cat-
egorized as non-understandable:
</bodyText>
<listItem confidence="0.995971833333333">
• inflected forms of words (suites (conse-
quences), cardiologiques (cardiological));
• constructed forms of words (thrombolys´e
(with thrombolysis));
• hyphenated words (post-r´eanimation (post
emergency medical service)).
</listItem>
<bodyText confidence="0.989066277777778">
Notice that in other processed documents, other
errors occur. For instance, misspelled words and
words that miss accented characters (probleme
instead of probl`eme (problem), realise instead of
r´ealis´e (done), particularite instead particularit´e
(particularity)) are problematic. Another type of er-
rors may occur when technical words (e.g. pro-
lapsus (prolapsus), paroxysme (paroxysm), tricuspide
(tricuspid)) are considered as understandable.
Besides, only isolated words are currently pro-
cessed, which is the limitation of the current
method. Still, consideration of complex medi-
cal terms, that convey more complex medical no-
tions, should also be done. Such terms may indeed
change the understanding of words, as in these ex-
amples: AVC isch´emique (ischemic CVA (cerebrovas-
cular accident)), embolie pulmonaire basale droite
(right basal pulmonary embolism), d´esaturation a` 83 %
</bodyText>
<page confidence="0.997903">
17
</page>
<bodyText confidence="0.998761125">
(desaturation at 83%), anticoagulation curative (cu-
rative anticoagulation). In the same way, numerical
values may also arise misunderstanding of medi-
cal information. Processing of these additional as-
pects (inflected and constructed forms of words,
hyphenated or misspelled words, complex terms
composed with several words and numerical val-
ues) is part of the future work.
</bodyText>
<subsectionHeader confidence="0.999578">
6.5 Limitations of the current study
</subsectionHeader>
<bodyText confidence="0.999982292682927">
We proposed several experiments for analyzing
the understandability of medical words. We tried
to analyze these data from different points of view
to get a more complete picture. Still, there are
some limitations. These are mainly related to the
linguistic data and to their preparation.
The whole set of the analyzed words is large:
almost 30,000 entries. We assume it is possi-
ble that annotations provided may show some
intra-annotator inconsistencies due for instance to
the tiredness and instability of the annotators (for
instance, when a given unknown morphological
components is seen again and again, the meaning
of this component may be deduced by the anno-
tator). Nevertheless, in our daily life, we are also
confronted to the medical language (our personal
health or health of family or friend, TV and ra-
dio broadcast, various readings of newspapers and
novels) and then, it is possible that the new med-
ical notions may be learned during the annotation
period of the words, which lasted up to four weeks.
Nevertheless, the advantage of the data we have
built is that the whole set is completely annotated
by each annotator.
When computing the features of the words, we
have favored those, which are computed at the
word level. In the future work, it may be interest-
ing to take into account features computed at the
level of morphological components or of complex
terms. The main question will be to decide how
such features can be combined all together.
The annotators involved in the study have a
training in linguistics, although their relation with
the medical field is poor: they have no specific
health problems and no expertise in medical ter-
minology. We expect they may represent the av-
erage level of patients with moderate health lit-
eracy. Nevertheless, the observed results may re-
main specific to the category of young people with
linguistic training. Additional experiments are re-
quired to study this aspect better.
</bodyText>
<sectionHeader confidence="0.87983" genericHeader="conclusions">
7 Conclusion and Future research
</sectionHeader>
<bodyText confidence="0.9999945">
We proposed a study of words from the medi-
cal field, which are manually annotated as under-
standable, non-understandable and possibly un-
derstandable to laymen. The proposed approach
is based on machine learning and a set with 24
features. Among the features, which appear to be
salient for the diagnosis of understandable words,
we find for instance the presence of words in the
reference lexica, their syntactic categories, their fi-
nal substring, and their frequencies on the web.
Several features and their combinations can be dis-
tinguished, which shows that the understandability
of words is a complex notion, which involves sev-
eral linguistic and extra-linguistic criteria.
The avenue for future research includes for in-
stance the exploitation of corpora, while currently
we use features computed out of context. We
assume indeed that corpora may provide addi-
tional relevant information (semantic or statistical)
for the task aimed in this study. Additional as-
pects related to the processing of documents (in-
flected and constructed forms of words, hyphen-
ated or misspelled words, complex terms com-
posed with several words and numerical values) is
another perspective. Besides, the classical read-
ability measures exploited have been developed
for the processing of English language. Working
with French-language data, we should use mea-
sures, which are adapted to this language (Kandel
and Moles, 1958; Henry, 1975). In addition, we
can also explore various perspectives, which ap-
pear from the current limitations, such as comput-
ing and using features computed at different levels
(morphological components, words and complex
terms), applying other classical readability mea-
sures adapted to the French language, and adding
new reference annotations provided by laymen
from other social-professional categories.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999808">
This work is performed under the grant
ANR/DGA Tecsan (ANR-11-TECS-012) and
the support of MESHS (COMETE project). The
authors are thankful to the CHU de Bordeaux for
making available the clinical documents.
</bodyText>
<sectionHeader confidence="0.991389" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.51557">
AMA. 1999. Health literacy: report of the council
on scientific affairs. Ad hoc committee on health lit-
</reference>
<page confidence="0.996426">
18
</page>
<reference confidence="0.978856375000001">
eracy for the council on scientific affairs, American
Medical Association. JAMA, 281(6):552–7.
D Amiot and G Dal. 2005. Integrating combining
forms into a lexeme-based morphology. In Mediter-
ranean Morphology Meeting (MMM5), pages 323–
336.
M Amoia and M Romanelli. 2012. Sb: mmsystem -
using decompositional semantics for lexical simpli-
fication. In *SEM 2012, pages 482–486, Montr´eal,
Canada, 7-8 June. Association for Computational
Linguistics.
GK Berland, MN Elliott, LS Morales, JI Algazy,
RL Kravitz, MS Broder, DE Kanouse, JA Munoz,
JA Puyol, M Lara, KE Watkins, H Yang, and
EA McGlynn. 2001. Health information on the in-
ternet. accessibility, quality, and readability in en-
glish ans spanish. JAMA, 285(20):2612–2621.
Geert Booij. 2010. Construction Morphology. Oxford
University Press, Oxford.
A Borst, A Gaudinat, C Boyer, and N Grabar. 2008.
Lexically based distinction of readability levels of
health documents. In MIE 2008. Poster.
MT Cabr´e and R Estop`a. 2002. On the units of spe-
cialised meaning uses in professional com- muni-
cation. In International Network for Terminology,
pages 217–237.
TM Cabr´e. 2000. Terminologie et linguistique: la
thorie des portes. Terminologies nouvelles, 21:10–
15.
J Chmielik and N Grabar. 2011. D´etection de la
sp´ecialisation scientifique et technique des docu-
ments biom´edicaux grˆace aux informations mor-
phologiques. TAL, 51(2):151–179.
Jacob Cohen. 1960. A coefficient of agreement
for nominal scales. Educational and Psychological
Measurement, 20(1):37–46.
RA Cˆot´e, 1996. R´epertoire d’anatomopathologie de la
SNOMED internationale, v3.4. Universit´e de Sher-
brooke, Sherbrooke, Qu´ebec.
B Daille. 1995. Rep´erage et extraction de terminologie
par une approche mixte statistique et linguistique.
TraitementAutomatique des Langues (T.A.L.), 36(1-
2):101–118.
P Drouin and P Langlais. 2006. valuation du potentiel
terminologique de candidats termes. In JADT, pages
379–388.
N Elhadad and K Sutaria. 2007. Mining a lexicon
of technical terms and lay equivalents. In BioNLP,
pages 49–56.
JL Fleiss and J Cohen. 1973. The equivalence of
weighted kappa and the intraclass correlation coef-
ficient as measures of reliability. Educational and
Psychological Measurement, 33:613–619.
R Flesch. 1948. A new readability yardstick. Journal
ofApplied Psychology, 23:221–233.
T Franc¸ois. 2011. Les apports du traitements automa-
tique du langage la lisibilit du franais langue tran-
gre. Phd thesis, Universit Catholique de Louvain,
Louvain.
KT Frantzi, S Ananiadou, and J Tsujii. 1997. Auto-
matic term recognition using contextual clues. In
MULSAIC IJCAI, pages 73–79.
N Gala, T Franc¸ois, and C Fairon. 2013. Towards a
french lexicon with difficulty measures: NLP help-
ing to bridge the gap between traditional dictionaries
and specialized lexicons. In eLEX-2013.
L Goeuriot, N Grabar, and B Daille. 2007. Car-
act´erisation des discours scientifique et vulgaris´e en
franc¸ais, japonais et russe. In TALN, pages 93–102.
N Grabar, S Krivine, and MC Jaulent. 2007. Classifi-
cation of health webpages as expert and non expert
with a reduced set of cross-language features. In
AMIA, pages 284–288.
R Gunning. 1973. The art of clear writing. McGraw
Hill, New York, NY.
G Henry. 1975. Comment mesurer la lisibilit. Labor,
Bruxelles.
C Iacobini. 1997. Distinguishing derivational pre-
fixes from initial combining forms. In First mediter-
ranean conference of morphology, Mytilene, Island
of Lesbos, Greece, septembre.
C Iacobini, 2003. Composizione con elementi neoclas-
sici, pages 69–96.
Gonia Jarema, Cline Busson, Rossitza Nikolova,
Kyrana Tsapkini, and Gary Libben. 1999. Process-
ing compounds: A cross-linguistic study. Brain and
Language, 68(1-2):362–369.
SK Jauhar and L Specia. 2012. Uow-shef: Sim-
plex – lexical simplicity ranking based on contextual
and psycholinguistic features. In *SEM 2012, pages
477–481, Montr´eal, Canada, 7-8 June. Association
for Computational Linguistics.
A Johannsen, H Martinez, S Klerke, and A Søgaard.
2012. Emnlp@cph: Is frequency all there is to sim-
plicity? In *SEM 2012, pages 408–412, Montr´eal,
Canada, 7-8 June. Association for Computational
Linguistics.
R Jucks and R Bromme. 2007. Choice of words
in doctor-patient communication: an analysis of
health-related internet sites. Health Commun,
21(3):267–77.
L Kandel and A Moles. 1958. Application de lindice
de flesch la langue franaise. Cahiers tudes de
Radio-Tlvision, 19:253–274.
</reference>
<page confidence="0.983683">
19
</page>
<reference confidence="0.987125386792453">
JP Kincaid, RP Jr Fishburne, RL Rogers, and
BS Chissom. 1975. Derivation of new readabil-
ity formulas (automated readability index, fog count
and flesch reading ease formula) for navy enlisted
personnel. Technical report, Naval Technical Train-
ing, U. S. Naval Air Station, Memphis, TN.
D Kokkinakis and M Toporowska Gronostaj. 2006.
Comparing lay and professional language in cardio-
vascular disorders corpora. In Australia Pham T.,
James Cook University, editor, WSEAS Transactions
on BIOLOGY and BIOMEDICINE, pages 429–437.
I Korkontzelos, IP Klapaftis, and S Manandhar. 2008.
Reviewing and evaluating automatic term recogni-
tion techniques. In GoTAL, pages 248–259.
JR Landis and GG Koch. 1977. The measurement of
observer agreement for categorical data. Biometrics,
33:159–174.
G Leroy, S Helmreich, J Cowie, T Miller, and
W Zheng. 2008. Evaluating online health informa-
tion: Beyond readability formulas. In AMIA 2008,
pages 394–8.
Gary Libben, Martha Gibson, Yeo Bom Yoon, and Do-
miniek Sandra. 2003. Compound fracture: The role
of semantic transparency and morphological head-
edness. Brain and Language, 84(1):50–64.
AL Ligozat, C Grouin, A Garcia-Fernandez, and
D Bernhard. 2012. Annlor: A naive notation-
system for lexical outputs ranking. In *SEM 2012,
pages 487–492.
A L¨udeling, T Schmidt, and S Kiokpasoglou. 2002.
Neoclassical word formation in german. Yearbook
of Morphology, pages 253–283.
D Maynard and S Ananiadou. 2000. Identifying terms
by their family and friends. In Proceedings of COL-
ING 2000, pages 530–536, Saarbrucken, Germany.
A McCray. 2005. Promoting health literacy. J of Am
Med Infor Ass, 12:152–163.
T Miller, G Leroy, S Chatterjee, J Fan, and B Thoms.
2007. A classifier to evaluate language specificity of
medical documents. In HICSS, pages 134–140.
Fiammetta Namer and Pierre Zweigenbaum. 2004.
Acquiring meaning for French medical terminology:
contribution of morphosemantics. In Annual Sym-
posium of the American Medical Informatics Asso-
ciation (AMIA), San-Francisco.
F Namer. 2000. FLEMM : un analyseur flexionnel du
franc¸ais a` base de r`egles. Traitement automatique
des langues (TAL), 41(2):523–547.
Oregon Evidence-based Practice Center. 2008. Bar-
riers and drivers of health information technology
use for the elderly, chronically ill, and underserved.
Technical report, Agency for healthcare research and
quality.
V Patel, T Branch, and J Arocha. 2002. Errors in inter-
preting quantities as procedures : The case of phar-
maceutical labels. International journal of medical
informatics, 65(3):193–211.
M Poprat, K Mark´o, and U Hahn. 2006. A lan-
guage classifier that automatically divides medical
documents for experts and health care consumers.
In MIE 2006 - Proceedings of the XX International
Congress of the European Federation for Medical
Informatics, pages 503–508, Maastricht.
JR Quinlan. 1993. C4.5 Programs for Machine Learn-
ing. Morgan Kaufmann, San Mateo, CA.
R Rittman. 2008. Automatic discrimination of genres.
VDM, Saarbrucken, Germany.
R Rudd, B Moeykens, and T Colton, 1999. Annual
Review ofAdult Learning and Literacy, page ch 5.
H Schmid. 1994. Probabilistic part-of-speech tagging
using decision trees. In Proceedings of the Inter-
national Conference on New Methods in Language
Processing, pages 44–49, Manchester, UK.
R Sinha. 2012. Unt-simprank: Systems for lexical
simplification ranking. In *SEM 2012, pages 493–
496, Montr´eal, Canada, 7-8 June. Association for
Computational Linguistics.
L Specia, SK Jauhar, and R Mihalcea. 2012. Semeval-
2012 task 1: English lexical simplification. In *SEM
2012, pages 347–355.
TM Tran, H Chekroud, P Thiery, and A Julienne. 2009.
Internet et soins : un tiers invisible dans la relation
m´edecine/patient ? Ethica Clinica, 53:34–43.
Y Wang. 2006. Automatic recognition of text diffi-
culty from consumers health information. In IEEE,
editor, Computer-Based Medical Systems, pages
131–136.
I.H. Witten and E. Frank. 2005. Data mining: Practi-
cal machine learning tools and techniques. Morgan
Kaufmann, San Francisco.
Eugen W¨uster. 1981. L’tude scientifique gnrale de la
terminologie, zone frontalire entre la linguistique, la
logique, l’ontologie, l’informatique et les sciences
des choses. In G. Rondeau et H. Felber, editor,
Textes choisis de terminologie, volume I. Fonde-
ments thoriques de la terminologie, pages 55–114.
GISTERM, Universit de Laval, Qubec. sous la di-
rection de V.I. Siforov.
Q Zeng-Treiler, H Kim, S Goryachev, A Keselman,
L Slaugther, and CA Smith. 2007. Text charac-
teristics of clinical reports and their implications for
the readability of personal health records. In MED-
INFO, pages 1117–1121, Brisbane, Australia.
W Zheng, E Milios, and C Watters. 2002. Filtering
for medical news items using a machine learning ap-
proach. In AMIA, pages 949–53.
</reference>
<page confidence="0.994891">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.163424">
<title confidence="0.99485">Automatic diagnosis of understanding of medical words</title>
<author confidence="0.93776">Thierry</author>
<affiliation confidence="0.730145">LIMSI-CNRS, BP133, Universit´e Paris</affiliation>
<address confidence="0.966796">Sorbonne Paris Cit´e, France</address>
<email confidence="0.989667">hamon@limsi.fr</email>
<author confidence="0.744979">Natalia</author>
<affiliation confidence="0.866302">CNRS UMR 8163 Universit´e Lille</affiliation>
<address confidence="0.998248">59653 Villeneuve d’Ascq, France</address>
<email confidence="0.97167">natalia.grabar@univ-lille3.fr</email>
<author confidence="0.581603">Dany</author>
<affiliation confidence="0.8904135">CNRS UMR 8163 Universit´e Lille</affiliation>
<address confidence="0.999383">59653 Villeneuve d’Ascq, France</address>
<email confidence="0.991736">dany.amiot@univ-lille3.fr</email>
<abstract confidence="0.998067761904762">Within the medical field, very specialized terms are commonly used, while their understanding by laymen is not always successful. We propose to study the understandability of medical words by laymen. Three annotators are involved in the creation of the reference data used for training and testing. The features of the words may linguistic number of characters, syllables, number of morphological bases affixes) and extra-linguistic their presence in a reference lexicon, frequency on a search engine). The automatic categorization results show between 0.806 and 0.947 F-measure values. It appears that several features and their combinations are relevant for the analysis of understandabilsyntactic categories, presence in reference lexica, frequency on the general search engine, final substring).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>AMA</author>
</authors>
<title>Health literacy: report of the council on scientific affairs. Ad hoc committee on health literacy for the council on scientific affairs,</title>
<date>1999</date>
<journal>American Medical Association. JAMA,</journal>
<volume>281</volume>
<issue>6</issue>
<contexts>
<context position="2079" citStr="AMA, 1999" startWordPosition="300" endWordPosition="301"> does not guarantee its correct understanding, especially by laymen, such as patients. The medical field has indeed a specific terminology (e.g., abdominoplasty, hepatic, dermabrasion or hepatoduodenostomy) commonly used by medical professionals. This fact has been highlighted in several studies dedicated for instance to the understanding of pharmaceutical labels (Patel et al., 2002), of information provided by websites (Rudd et al., 1999; Berland et al., 2001; McCray, 2005; Oregon Evidencebased Practice Center, 2008), and more generally the understanding between patients and medical doctors (AMA, 1999; McCray, 2005; Jucks and Bromme, 2007; Tran et al., 2009). We propose to study the understanding of words used in the medical field, which is the first step towards the simplification of texts. Indeed, before the simplification can be performed, it is necessary to know which textual units may show understanding difficulty and should be simplified. We work with data in French, such as provided by an existing medical terminology. In the remainder, we present first some related work, especially from specialized fields (section 2). We then introduce the linguistic data (section 4) and methodology</context>
</contexts>
<marker>AMA, 1999</marker>
<rawString>AMA. 1999. Health literacy: report of the council on scientific affairs. Ad hoc committee on health literacy for the council on scientific affairs, American Medical Association. JAMA, 281(6):552–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Amiot</author>
<author>G Dal</author>
</authors>
<title>Integrating combining forms into a lexeme-based morphology.</title>
<date>2005</date>
<booktitle>In Mediterranean Morphology Meeting (MMM5),</booktitle>
<pages>323--336</pages>
<contexts>
<context position="6906" citStr="Amiot and Dal, 2005" startWordPosition="1094" endWordPosition="1097">rd compounding patterns. This difficulty is common to all Roman languages (Iacobini, 2003), but not to Germanic languages (L¨udeling et al., 2002). Closely related is the fact that with neoclassical compounds, a given component may change its place according to the global semantics of the compounds, such as pathin pathology, polyneuropathe, cardiopathy. Finally, the formal similarity between some derivation processes (such as the derivation in -oide, like in lipoid) and neoclassical compounding (such as -ase in lipase), which apply completely different interpretation patterns (Iacobini, 1997; Amiot and Dal, 2005), can also make the understanding more difficult. 2.2 Terminology In the terminology field, the automatic identification of difficulty of terms and words remains implicit, while this notion is fundamental in terminology (W¨uster, 1981; Cabr´e and Estop`a, 2002; Cabr´e, 2000). The specificity of terms to a given field is usually studied. The notion of understandability can be derived from it. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the specificity of pivot words </context>
</contexts>
<marker>Amiot, Dal, 2005</marker>
<rawString>D Amiot and G Dal. 2005. Integrating combining forms into a lexeme-based morphology. In Mediterranean Morphology Meeting (MMM5), pages 323– 336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Amoia</author>
<author>M Romanelli</author>
</authors>
<title>Sb: mmsystem -using decompositional semantics for lexical simplification.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>482--486</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<contexts>
<context position="10489" citStr="Amoia and Romanelli, 2012" startWordPosition="1660" endWordPosition="1663">pecia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, number of syllables, latent semantic analysis, mutual information and word frequency (Jauhar and Specia, 2012); Wikipedia frequency, word length, n-grams of characters and of words, random indexing and syntactic complexity of documents (Johannsen et al., 2012); n-grams and frequency from Wikipedia, Google n-grams (Ligozat et al., 2012); WordNet and word frequency (Amoia and Romanelli, 2012). 3 Aims of the present study We propose to investigate how the understandability of French medical words can be diagnosed with NLP methods. We rely on the reference annotations performed by French speakers without medical training, which we associate with patients. The experiments performed rely on machine learning algorithms and a set of 24 features. The medical words studied are provided by an existing medical terminology. 4 Linguistic data and their preparation The linguistic data are obtained from the medical terminology Snomed International (Cˆot´e, 1996). This terminology’s aim is to de</context>
</contexts>
<marker>Amoia, Romanelli, 2012</marker>
<rawString>M Amoia and M Romanelli. 2012. Sb: mmsystem -using decompositional semantics for lexical simplification. In *SEM 2012, pages 482–486, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GK Berland</author>
<author>MN Elliott</author>
<author>LS Morales</author>
<author>JI Algazy</author>
<author>RL Kravitz</author>
<author>MS Broder</author>
<author>JA Munoz DE Kanouse</author>
<author>JA Puyol</author>
<author>M Lara</author>
<author>KE Watkins</author>
<author>H Yang</author>
<author>EA McGlynn</author>
</authors>
<title>Health information on the internet. accessibility, quality, and readability in english ans spanish.</title>
<date>2001</date>
<journal>JAMA,</journal>
<volume>285</volume>
<issue>20</issue>
<marker>Berland, Elliott, Morales, Algazy, Kravitz, Broder, DE Kanouse, Puyol, Lara, Watkins, Yang, McGlynn, 2001</marker>
<rawString>GK Berland, MN Elliott, LS Morales, JI Algazy, RL Kravitz, MS Broder, DE Kanouse, JA Munoz, JA Puyol, M Lara, KE Watkins, H Yang, and EA McGlynn. 2001. Health information on the internet. accessibility, quality, and readability in english ans spanish. JAMA, 285(20):2612–2621.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert Booij</author>
</authors>
<title>Construction Morphology.</title>
<date>2010</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="5093" citStr="Booij, 2010" startWordPosition="796" endWordPosition="797">, linguistic and extra-linguistic, may be involved in the semantic complexity of the compounds. One factor is related to the knowledge of the components of the complex words. Formal (how the words, such as aerenchyme, can be segmented) and semantic (how the words can be understood and used) points of view can be distinguished. A second factor is that complexity is also due to the variety of morphological patterns and relations among the components. For instance, erythrocyte (erythrocyte) and ovocyte (ovocyte) instantiate the [N1N2] pattern in which N2 (cyte) can be seen as a constant element (Booij, 2010), although the relations between N1 and N2 are not of the same type in these two compounds: in erythrocyte, N1 erythr(o) denotes a property of N2 (color), while in ovocyte, N1 ovo (egg) corresponds to a specific development stage of female cells. Another factor appears when some components are polysemous, within a given field (i.e., medical field) or across the fields. For instance, aer(o) does not always convey the same meaning: in aeroc`ele, aer- denotes ’air’ (tumefaction (c`ele) formed by an air infiltration), but not in aerasthenie, which refers to an asthenia (psychic disorder) observabl</context>
</contexts>
<marker>Booij, 2010</marker>
<rawString>Geert Booij. 2010. Construction Morphology. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borst</author>
<author>A Gaudinat</author>
<author>C Boyer</author>
<author>N Grabar</author>
</authors>
<title>Lexically based distinction of readability levels of health documents. In</title>
<date>2008</date>
<publisher>Poster.</publisher>
<location>MIE</location>
<contexts>
<context position="8763" citStr="Borst et al., 2008" startWordPosition="1381" endWordPosition="1384">onal readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features (Chmielik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference cat</context>
</contexts>
<marker>Borst, Gaudinat, Boyer, Grabar, 2008</marker>
<rawString>A Borst, A Gaudinat, C Boyer, and N Grabar. 2008. Lexically based distinction of readability levels of health documents. In MIE 2008. Poster.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MT Cabr´e</author>
<author>R Estop`a</author>
</authors>
<title>On the units of specialised meaning uses in professional com- munication.</title>
<date>2002</date>
<booktitle>In International Network for Terminology,</booktitle>
<pages>217--237</pages>
<marker>Cabr´e, Estop`a, 2002</marker>
<rawString>MT Cabr´e and R Estop`a. 2002. On the units of specialised meaning uses in professional com- munication. In International Network for Terminology, pages 217–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TM Cabr´e</author>
</authors>
<title>Terminologie et linguistique: la thorie des portes. Terminologies nouvelles,</title>
<date>2000</date>
<pages>21--10</pages>
<marker>Cabr´e, 2000</marker>
<rawString>TM Cabr´e. 2000. Terminologie et linguistique: la thorie des portes. Terminologies nouvelles, 21:10– 15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chmielik</author>
<author>N Grabar</author>
</authors>
<title>D´etection de la sp´ecialisation scientifique et technique des documents biom´edicaux grˆace aux informations morphologiques.</title>
<date>2011</date>
<journal>TAL,</journal>
<volume>51</volume>
<issue>2</issue>
<contexts>
<context position="8950" citStr="Chmielik and Grabar, 2011" startWordPosition="1410" endWordPosition="1413"> Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features (Chmielik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2 and A3), and in the derived datasets unanimity and majority. nations of different features (Wang, 2006; ZengTreiler et al., 2007; Leroy et al., 2008). </context>
</contexts>
<marker>Chmielik, Grabar, 2011</marker>
<rawString>J Chmielik and N Grabar. 2011. D´etection de la sp´ecialisation scientifique et technique des documents biom´edicaux grˆace aux informations morphologiques. TAL, 51(2):151–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>20--1</pages>
<contexts>
<context position="17161" citStr="Cohen, 1960" startWordPosition="2678" endWordPosition="2679">vided by the three annotators constitute our reference data. We use on the whole five reference datasets (Table 1): 3 sets of separate annotations provided by the three annotators (29,641 words each); 1 unanimity set, on which all the annotators agree (n=22,925); 1 majority set, for which we can compute the majority agreement (n=28,763). By definition, the two last datasets should present a better coherence and less annotation ambiguity because some ambiguities have been resolved by unanimity or by majority vote. 5.3 Evaluation The inter-annotator agreement is computed with the Cohen’s Kappa (Cohen, 1960), applied to pairs of annotators, which values are then leveraged to obtain the unique average value; and Fleiss’ Kappa (Fleiss and Cohen, 1973), suitable for processing data provided by more than two annotators. The interpretation of the scores are for instance (Landis and Koch, 1977): substantial agreement between 0.61 and 0.80, almost perfect agreement between 0.81 and 1.00. 14 With machine learning, we perform a ten-fold cross-validation, which means that the evaluation test is performed ten times on different randomly generated test sets (1/10 of the whole dataset), while the remaining 9/</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20(1):37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>RA Cˆot´e</author>
</authors>
<date>1996</date>
<booktitle>R´epertoire d’anatomopathologie de la SNOMED internationale, v3.4. Universit´e de Sherbrooke,</booktitle>
<location>Sherbrooke, Qu´ebec.</location>
<marker>Cˆot´e, 1996</marker>
<rawString>RA Cˆot´e, 1996. R´epertoire d’anatomopathologie de la SNOMED internationale, v3.4. Universit´e de Sherbrooke, Sherbrooke, Qu´ebec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>Rep´erage et extraction de terminologie par une approche mixte statistique et linguistique.</title>
<date>1995</date>
<booktitle>TraitementAutomatique des Langues (T.A.L.),</booktitle>
<pages>36--1</pages>
<contexts>
<context position="7685" citStr="Daille, 1995" startWordPosition="1221" endWordPosition="1222">cit, while this notion is fundamental in terminology (W¨uster, 1981; Cabr´e and Estop`a, 2002; Cabr´e, 2000). The specificity of terms to a given field is usually studied. The notion of understandability can be derived from it. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the specificity of pivot words (Drouin and Langlais, 2006), the neighborhood of the term in corpus or the diversity of its components computed with statistical measures such as C-Value or PageRank (Daille, 1995; Frantzi et al., 1997; Maynard and Ananiadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate the complexity of words and terms. Among these measures, it is possible to distinguish classical readability measures and computational readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on </context>
</contexts>
<marker>Daille, 1995</marker>
<rawString>B Daille. 1995. Rep´erage et extraction de terminologie par une approche mixte statistique et linguistique. TraitementAutomatique des Langues (T.A.L.), 36(1-2):101–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Drouin</author>
<author>P Langlais</author>
</authors>
<title>valuation du potentiel terminologique de candidats termes.</title>
<date>2006</date>
<booktitle>In JADT,</booktitle>
<pages>379--388</pages>
<contexts>
<context position="7533" citStr="Drouin and Langlais, 2006" startWordPosition="1194" endWordPosition="1197"> can also make the understanding more difficult. 2.2 Terminology In the terminology field, the automatic identification of difficulty of terms and words remains implicit, while this notion is fundamental in terminology (W¨uster, 1981; Cabr´e and Estop`a, 2002; Cabr´e, 2000). The specificity of terms to a given field is usually studied. The notion of understandability can be derived from it. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the specificity of pivot words (Drouin and Langlais, 2006), the neighborhood of the term in corpus or the diversity of its components computed with statistical measures such as C-Value or PageRank (Daille, 1995; Frantzi et al., 1997; Maynard and Ananiadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate the complexity of words and terms. Among these measures, it is possible to distinguish classical readability measures an</context>
</contexts>
<marker>Drouin, Langlais, 2006</marker>
<rawString>P Drouin and P Langlais. 2006. valuation du potentiel terminologique de candidats termes. In JADT, pages 379–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Elhadad</author>
<author>K Sutaria</author>
</authors>
<title>Mining a lexicon of technical terms and lay equivalents. In BioNLP,</title>
<date>2007</date>
<pages>49--56</pages>
<contexts>
<context position="7924" citStr="Elhadad and Sutaria, 2007" startWordPosition="1257" endWordPosition="1260">t. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the specificity of pivot words (Drouin and Langlais, 2006), the neighborhood of the term in corpus or the diversity of its components computed with statistical measures such as C-Value or PageRank (Daille, 1995; Frantzi et al., 1997; Maynard and Ananiadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate the complexity of words and terms. Among these measures, it is possible to distinguish classical readability measures and computational readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents an</context>
</contexts>
<marker>Elhadad, Sutaria, 2007</marker>
<rawString>N Elhadad and K Sutaria. 2007. Mining a lexicon of technical terms and lay equivalents. In BioNLP, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JL Fleiss</author>
<author>J Cohen</author>
</authors>
<title>The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability.</title>
<date>1973</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>33--613</pages>
<contexts>
<context position="17305" citStr="Fleiss and Cohen, 1973" startWordPosition="2699" endWordPosition="2702">e annotations provided by the three annotators (29,641 words each); 1 unanimity set, on which all the annotators agree (n=22,925); 1 majority set, for which we can compute the majority agreement (n=28,763). By definition, the two last datasets should present a better coherence and less annotation ambiguity because some ambiguities have been resolved by unanimity or by majority vote. 5.3 Evaluation The inter-annotator agreement is computed with the Cohen’s Kappa (Cohen, 1960), applied to pairs of annotators, which values are then leveraged to obtain the unique average value; and Fleiss’ Kappa (Fleiss and Cohen, 1973), suitable for processing data provided by more than two annotators. The interpretation of the scores are for instance (Landis and Koch, 1977): substantial agreement between 0.61 and 0.80, almost perfect agreement between 0.81 and 1.00. 14 With machine learning, we perform a ten-fold cross-validation, which means that the evaluation test is performed ten times on different randomly generated test sets (1/10 of the whole dataset), while the remaining 9/10 of the whole dataset is used for training the algorithm and creating the model. In this way, each word is used during the test step. The succ</context>
</contexts>
<marker>Fleiss, Cohen, 1973</marker>
<rawString>JL Fleiss and J Cohen. 1973. The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability. Educational and Psychological Measurement, 33:613–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Flesch</author>
</authors>
<title>A new readability yardstick.</title>
<date>1948</date>
<journal>Journal ofApplied Psychology,</journal>
<pages>23--221</pages>
<contexts>
<context position="8323" citStr="Flesch, 1948" startWordPosition="1321" endWordPosition="1322">ynard and Ananiadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate the complexity of words and terms. Among these measures, it is possible to distinguish classical readability measures and computational readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features </context>
<context position="15556" citStr="Flesch, 1948" startWordPosition="2423" endWordPosition="2424">provides also semantic explanation of the analyzed lexemes. We exploit the morphological decomposition information (number of affixes and bases). Initial and final substrings of the words. We compute the initial and final substrings of different length, from three to five characters. 2http://www.atilf.fr/ 3http://www.lexique.org/ Number and percentage of consonants, vowels and other characters. We compute the number and the percentage of consonants, vowels and other characters (i.e., hyphen, apostrophe, comas). Classical readability scores. We apply two classical readability measures: Flesch (Flesch, 1948) and its variant Flesch-Kincaid (Kincaid et al., 1975). Such measures are typically used for evaluating the difficulty level of a text. They exploit surface characteristics of words (number of characters and/or syllables) and normalize these values with specifically designed coefficients. 5.2 Machine learning system The machine learning algorithms are used to study whether they can distinguish between words understandable and non-understandable by laymen and to study the importance of various features for the task. The functioning of machine learning algorithms is based on a set of positive an</context>
</contexts>
<marker>Flesch, 1948</marker>
<rawString>R Flesch. 1948. A new readability yardstick. Journal ofApplied Psychology, 23:221–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Franc¸ois</author>
</authors>
<title>Les apports du traitements automatique du langage la lisibilit du franais langue trangre. Phd thesis,</title>
<date>2011</date>
<institution>Universit Catholique de Louvain, Louvain.</institution>
<marker>Franc¸ois, 2011</marker>
<rawString>T Franc¸ois. 2011. Les apports du traitements automatique du langage la lisibilit du franais langue trangre. Phd thesis, Universit Catholique de Louvain, Louvain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>KT Frantzi</author>
<author>S Ananiadou</author>
<author>J Tsujii</author>
</authors>
<title>Automatic term recognition using contextual clues.</title>
<date>1997</date>
<booktitle>In MULSAIC IJCAI,</booktitle>
<pages>73--79</pages>
<contexts>
<context position="7707" citStr="Frantzi et al., 1997" startWordPosition="1223" endWordPosition="1226">s notion is fundamental in terminology (W¨uster, 1981; Cabr´e and Estop`a, 2002; Cabr´e, 2000). The specificity of terms to a given field is usually studied. The notion of understandability can be derived from it. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the specificity of pivot words (Drouin and Langlais, 2006), the neighborhood of the term in corpus or the diversity of its components computed with statistical measures such as C-Value or PageRank (Daille, 1995; Frantzi et al., 1997; Maynard and Ananiadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate the complexity of words and terms. Among these measures, it is possible to distinguish classical readability measures and computational readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on linear regression mode</context>
</contexts>
<marker>Frantzi, Ananiadou, Tsujii, 1997</marker>
<rawString>KT Frantzi, S Ananiadou, and J Tsujii. 1997. Automatic term recognition using contextual clues. In MULSAIC IJCAI, pages 73–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Gala</author>
<author>T Franc¸ois</author>
<author>C Fairon</author>
</authors>
<title>Towards a french lexicon with difficulty measures: NLP helping to bridge the gap between traditional dictionaries and specialized lexicons.</title>
<date>2013</date>
<booktitle>In eLEX-2013.</booktitle>
<marker>Gala, Franc¸ois, Fairon, 2013</marker>
<rawString>N Gala, T Franc¸ois, and C Fairon. 2013. Towards a french lexicon with difficulty measures: NLP helping to bridge the gap between traditional dictionaries and specialized lexicons. In eLEX-2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Goeuriot</author>
<author>N Grabar</author>
<author>B Daille</author>
</authors>
<title>Caract´erisation des discours scientifique et vulgaris´e en franc¸ais, japonais et russe.</title>
<date>2007</date>
<booktitle>In TALN,</booktitle>
<pages>93--102</pages>
<contexts>
<context position="8858" citStr="Goeuriot et al., 2007" startWordPosition="1396" endWordPosition="1399">tters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features (Chmielik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2 and A3), and in the derived datasets unanimity and majority</context>
</contexts>
<marker>Goeuriot, Grabar, Daille, 2007</marker>
<rawString>L Goeuriot, N Grabar, and B Daille. 2007. Caract´erisation des discours scientifique et vulgaris´e en franc¸ais, japonais et russe. In TALN, pages 93–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Grabar</author>
<author>S Krivine</author>
<author>MC Jaulent</author>
</authors>
<title>Classification of health webpages as expert and non expert with a reduced set of cross-language features.</title>
<date>2007</date>
<booktitle>In AMIA,</booktitle>
<pages>284--288</pages>
<contexts>
<context position="8820" citStr="Grabar et al., 2007" startWordPosition="1390" endWordPosition="1393">easures usually rely on number of letters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features (Chmielik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2 and A3), and in the d</context>
</contexts>
<marker>Grabar, Krivine, Jaulent, 2007</marker>
<rawString>N Grabar, S Krivine, and MC Jaulent. 2007. Classification of health webpages as expert and non expert with a reduced set of cross-language features. In AMIA, pages 284–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gunning</author>
</authors>
<title>The art of clear writing.</title>
<date>1973</date>
<publisher>McGraw Hill,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="8339" citStr="Gunning, 1973" startWordPosition="1323" endWordPosition="1324">iadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate the complexity of words and terms. Among these measures, it is possible to distinguish classical readability measures and computational readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features (Chmielik and Gr</context>
</contexts>
<marker>Gunning, 1973</marker>
<rawString>R Gunning. 1973. The art of clear writing. McGraw Hill, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Henry</author>
</authors>
<title>Comment mesurer la lisibilit.</title>
<date>1975</date>
<location>Labor, Bruxelles.</location>
<contexts>
<context position="32208" citStr="Henry, 1975" startWordPosition="5061" endWordPosition="5062">of context. We assume indeed that corpora may provide additional relevant information (semantic or statistical) for the task aimed in this study. Additional aspects related to the processing of documents (inflected and constructed forms of words, hyphenated or misspelled words, complex terms composed with several words and numerical values) is another perspective. Besides, the classical readability measures exploited have been developed for the processing of English language. Working with French-language data, we should use measures, which are adapted to this language (Kandel and Moles, 1958; Henry, 1975). In addition, we can also explore various perspectives, which appear from the current limitations, such as computing and using features computed at different levels (morphological components, words and complex terms), applying other classical readability measures adapted to the French language, and adding new reference annotations provided by laymen from other social-professional categories. Acknowledgments This work is performed under the grant ANR/DGA Tecsan (ANR-11-TECS-012) and the support of MESHS (COMETE project). The authors are thankful to the CHU de Bordeaux for making available the </context>
</contexts>
<marker>Henry, 1975</marker>
<rawString>G Henry. 1975. Comment mesurer la lisibilit. Labor, Bruxelles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Iacobini</author>
</authors>
<title>Distinguishing derivational prefixes from initial combining forms.</title>
<date>1997</date>
<booktitle>In First mediterranean conference of morphology, Mytilene, Island of Lesbos, Greece,</booktitle>
<pages>septembre.</pages>
<contexts>
<context position="6884" citStr="Iacobini, 1997" startWordPosition="1092" endWordPosition="1093"> existing standard compounding patterns. This difficulty is common to all Roman languages (Iacobini, 2003), but not to Germanic languages (L¨udeling et al., 2002). Closely related is the fact that with neoclassical compounds, a given component may change its place according to the global semantics of the compounds, such as pathin pathology, polyneuropathe, cardiopathy. Finally, the formal similarity between some derivation processes (such as the derivation in -oide, like in lipoid) and neoclassical compounding (such as -ase in lipase), which apply completely different interpretation patterns (Iacobini, 1997; Amiot and Dal, 2005), can also make the understanding more difficult. 2.2 Terminology In the terminology field, the automatic identification of difficulty of terms and words remains implicit, while this notion is fundamental in terminology (W¨uster, 1981; Cabr´e and Estop`a, 2002; Cabr´e, 2000). The specificity of terms to a given field is usually studied. The notion of understandability can be derived from it. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the speci</context>
</contexts>
<marker>Iacobini, 1997</marker>
<rawString>C Iacobini. 1997. Distinguishing derivational prefixes from initial combining forms. In First mediterranean conference of morphology, Mytilene, Island of Lesbos, Greece, septembre.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Iacobini</author>
</authors>
<title>Composizione con elementi neoclassici,</title>
<date>2003</date>
<pages>69--96</pages>
<contexts>
<context position="6376" citStr="Iacobini, 2003" startWordPosition="1016" endWordPosition="1017">in the order of components: according to whether the compounding is standard (in French, the main semantic element is then on the left, such as in pneu neige (snow tyre), which is fundamentally a pneu (tyre)) or neoclassical (in French, the main semantic element is then on the right, such as erythrocyte, which is a kind of cyte cell /corpuscle with red color). It is indeed complicated for a user without medical training to correctly interpret a word that he does not know and for which he cannot reuse the existing standard compounding patterns. This difficulty is common to all Roman languages (Iacobini, 2003), but not to Germanic languages (L¨udeling et al., 2002). Closely related is the fact that with neoclassical compounds, a given component may change its place according to the global semantics of the compounds, such as pathin pathology, polyneuropathe, cardiopathy. Finally, the formal similarity between some derivation processes (such as the derivation in -oide, like in lipoid) and neoclassical compounding (such as -ase in lipase), which apply completely different interpretation patterns (Iacobini, 1997; Amiot and Dal, 2005), can also make the understanding more difficult. 2.2 Terminology In t</context>
</contexts>
<marker>Iacobini, 2003</marker>
<rawString>C Iacobini, 2003. Composizione con elementi neoclassici, pages 69–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gonia Jarema</author>
<author>Cline Busson</author>
<author>Rossitza Nikolova</author>
<author>Kyrana Tsapkini</author>
<author>Gary Libben</author>
</authors>
<date>1999</date>
<booktitle>Processing compounds: A cross-linguistic study. Brain and Language,</booktitle>
<pages>68--1</pages>
<contexts>
<context position="3741" citStr="Jarema et al., 1999" startWordPosition="581" endWordPosition="584">t). Notice that it is also related to the ability to provide correct explanation and use of words. As we explain later, we consider words out of context and use a three-position scale. More generally, understanding is a complex notion closely linked to several other notions studied in different research fields. For instance, lexical complexity is studied in linguistics and gives clues on lexical processes involved, that may impact the word understanding (section 2.1). Work in psycholinguistics is often oriented on study of word opacity and the mental processes involved in their understanding (Jarema et al., 1999; Libben et al., 2003). Readability provides a set of methods to compute and quantify the understandability of words (section 2.3). The specificity of words to specialized areas is another way to capture their understandability (section 2.2). Finally, lexical 11 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 11–20, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics simplification aims at providing simpler words to be used in a given context (section 2.3). 2.1 Linguistics In</context>
</contexts>
<marker>Jarema, Busson, Nikolova, Tsapkini, Libben, 1999</marker>
<rawString>Gonia Jarema, Cline Busson, Rossitza Nikolova, Kyrana Tsapkini, and Gary Libben. 1999. Processing compounds: A cross-linguistic study. Brain and Language, 68(1-2):362–369.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SK Jauhar</author>
<author>L Specia</author>
</authors>
<title>Uow-shef: Simplex – lexical simplicity ranking based on contextual and psycholinguistic features.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>477--481</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<contexts>
<context position="10206" citStr="Jauhar and Specia, 2012" startWordPosition="1618" endWordPosition="1621"> to the lexical simplification within the SemEval challenge in 20121. Given a short input text and a target word in English, and given several English substitutes for the target word that fit the context, the goal was to rank these substitutes according to how ”simple” they are (Specia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, number of syllables, latent semantic analysis, mutual information and word frequency (Jauhar and Specia, 2012); Wikipedia frequency, word length, n-grams of characters and of words, random indexing and syntactic complexity of documents (Johannsen et al., 2012); n-grams and frequency from Wikipedia, Google n-grams (Ligozat et al., 2012); WordNet and word frequency (Amoia and Romanelli, 2012). 3 Aims of the present study We propose to investigate how the understandability of French medical words can be diagnosed with NLP methods. We rely on the reference annotations performed by French speakers without medical training, which we associate with patients. The experiments performed rely on machine learning</context>
</contexts>
<marker>Jauhar, Specia, 2012</marker>
<rawString>SK Jauhar and L Specia. 2012. Uow-shef: Simplex – lexical simplicity ranking based on contextual and psycholinguistic features. In *SEM 2012, pages 477–481, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Johannsen</author>
<author>H Martinez</author>
<author>S Klerke</author>
<author>A Søgaard</author>
</authors>
<title>Emnlp@cph: Is frequency all there is to simplicity?</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>408--412</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<contexts>
<context position="10356" citStr="Johannsen et al., 2012" startWordPosition="1640" endWordPosition="1643">substitutes for the target word that fit the context, the goal was to rank these substitutes according to how ”simple” they are (Specia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, number of syllables, latent semantic analysis, mutual information and word frequency (Jauhar and Specia, 2012); Wikipedia frequency, word length, n-grams of characters and of words, random indexing and syntactic complexity of documents (Johannsen et al., 2012); n-grams and frequency from Wikipedia, Google n-grams (Ligozat et al., 2012); WordNet and word frequency (Amoia and Romanelli, 2012). 3 Aims of the present study We propose to investigate how the understandability of French medical words can be diagnosed with NLP methods. We rely on the reference annotations performed by French speakers without medical training, which we associate with patients. The experiments performed rely on machine learning algorithms and a set of 24 features. The medical words studied are provided by an existing medical terminology. 4 Linguistic data and their preparati</context>
</contexts>
<marker>Johannsen, Martinez, Klerke, Søgaard, 2012</marker>
<rawString>A Johannsen, H Martinez, S Klerke, and A Søgaard. 2012. Emnlp@cph: Is frequency all there is to simplicity? In *SEM 2012, pages 408–412, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jucks</author>
<author>R Bromme</author>
</authors>
<title>Choice of words in doctor-patient communication: an analysis of health-related internet sites.</title>
<date>2007</date>
<journal>Health Commun,</journal>
<volume>21</volume>
<issue>3</issue>
<contexts>
<context position="2117" citStr="Jucks and Bromme, 2007" startWordPosition="304" endWordPosition="307">orrect understanding, especially by laymen, such as patients. The medical field has indeed a specific terminology (e.g., abdominoplasty, hepatic, dermabrasion or hepatoduodenostomy) commonly used by medical professionals. This fact has been highlighted in several studies dedicated for instance to the understanding of pharmaceutical labels (Patel et al., 2002), of information provided by websites (Rudd et al., 1999; Berland et al., 2001; McCray, 2005; Oregon Evidencebased Practice Center, 2008), and more generally the understanding between patients and medical doctors (AMA, 1999; McCray, 2005; Jucks and Bromme, 2007; Tran et al., 2009). We propose to study the understanding of words used in the medical field, which is the first step towards the simplification of texts. Indeed, before the simplification can be performed, it is necessary to know which textual units may show understanding difficulty and should be simplified. We work with data in French, such as provided by an existing medical terminology. In the remainder, we present first some related work, especially from specialized fields (section 2). We then introduce the linguistic data (section 4) and methodology (section 5) we propose to test. We pr</context>
</contexts>
<marker>Jucks, Bromme, 2007</marker>
<rawString>R Jucks and R Bromme. 2007. Choice of words in doctor-patient communication: an analysis of health-related internet sites. Health Commun, 21(3):267–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kandel</author>
<author>A Moles</author>
</authors>
<title>Application de lindice de flesch la langue franaise. Cahiers tudes de Radio-Tlvision,</title>
<date>1958</date>
<contexts>
<context position="32194" citStr="Kandel and Moles, 1958" startWordPosition="5057" endWordPosition="5060">e features computed out of context. We assume indeed that corpora may provide additional relevant information (semantic or statistical) for the task aimed in this study. Additional aspects related to the processing of documents (inflected and constructed forms of words, hyphenated or misspelled words, complex terms composed with several words and numerical values) is another perspective. Besides, the classical readability measures exploited have been developed for the processing of English language. Working with French-language data, we should use measures, which are adapted to this language (Kandel and Moles, 1958; Henry, 1975). In addition, we can also explore various perspectives, which appear from the current limitations, such as computing and using features computed at different levels (morphological components, words and complex terms), applying other classical readability measures adapted to the French language, and adding new reference annotations provided by laymen from other social-professional categories. Acknowledgments This work is performed under the grant ANR/DGA Tecsan (ANR-11-TECS-012) and the support of MESHS (COMETE project). The authors are thankful to the CHU de Bordeaux for making </context>
</contexts>
<marker>Kandel, Moles, 1958</marker>
<rawString>L Kandel and A Moles. 1958. Application de lindice de flesch la langue franaise. Cahiers tudes de Radio-Tlvision, 19:253–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JP Kincaid</author>
<author>RP Jr Fishburne</author>
<author>RL Rogers</author>
<author>BS Chissom</author>
</authors>
<title>Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel.</title>
<date>1975</date>
<tech>Technical report, Naval Technical</tech>
<location>Memphis, TN.</location>
<contexts>
<context position="15610" citStr="Kincaid et al., 1975" startWordPosition="2429" endWordPosition="2432">yzed lexemes. We exploit the morphological decomposition information (number of affixes and bases). Initial and final substrings of the words. We compute the initial and final substrings of different length, from three to five characters. 2http://www.atilf.fr/ 3http://www.lexique.org/ Number and percentage of consonants, vowels and other characters. We compute the number and the percentage of consonants, vowels and other characters (i.e., hyphen, apostrophe, comas). Classical readability scores. We apply two classical readability measures: Flesch (Flesch, 1948) and its variant Flesch-Kincaid (Kincaid et al., 1975). Such measures are typically used for evaluating the difficulty level of a text. They exploit surface characteristics of words (number of characters and/or syllables) and normalize these values with specifically designed coefficients. 5.2 Machine learning system The machine learning algorithms are used to study whether they can distinguish between words understandable and non-understandable by laymen and to study the importance of various features for the task. The functioning of machine learning algorithms is based on a set of positive and negative examples of the data to be processed, which</context>
</contexts>
<marker>Kincaid, Fishburne, Rogers, Chissom, 1975</marker>
<rawString>JP Kincaid, RP Jr Fishburne, RL Rogers, and BS Chissom. 1975. Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel. Technical report, Naval Technical Training, U. S. Naval Air Station, Memphis, TN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kokkinakis</author>
<author>M Toporowska Gronostaj</author>
</authors>
<title>Comparing lay and professional language in cardiovascular disorders corpora.</title>
<date>2006</date>
<booktitle>In Australia Pham</booktitle>
<pages>429--437</pages>
<editor>T., James Cook University, editor,</editor>
<marker>Kokkinakis, Gronostaj, 2006</marker>
<rawString>D Kokkinakis and M Toporowska Gronostaj. 2006. Comparing lay and professional language in cardiovascular disorders corpora. In Australia Pham T., James Cook University, editor, WSEAS Transactions on BIOLOGY and BIOMEDICINE, pages 429–437.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Korkontzelos</author>
<author>IP Klapaftis</author>
<author>S Manandhar</author>
</authors>
<title>Reviewing and evaluating automatic term recognition techniques.</title>
<date>2008</date>
<booktitle>In GoTAL,</booktitle>
<pages>248--259</pages>
<contexts>
<context position="7412" citStr="Korkontzelos et al., 2008" startWordPosition="1175" endWordPosition="1178">(such as -ase in lipase), which apply completely different interpretation patterns (Iacobini, 1997; Amiot and Dal, 2005), can also make the understanding more difficult. 2.2 Terminology In the terminology field, the automatic identification of difficulty of terms and words remains implicit, while this notion is fundamental in terminology (W¨uster, 1981; Cabr´e and Estop`a, 2002; Cabr´e, 2000). The specificity of terms to a given field is usually studied. The notion of understandability can be derived from it. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the specificity of pivot words (Drouin and Langlais, 2006), the neighborhood of the term in corpus or the diversity of its components computed with statistical measures such as C-Value or PageRank (Daille, 1995; Frantzi et al., 1997; Maynard and Ananiadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate</context>
</contexts>
<marker>Korkontzelos, Klapaftis, Manandhar, 2008</marker>
<rawString>I Korkontzelos, IP Klapaftis, and S Manandhar. 2008. Reviewing and evaluating automatic term recognition techniques. In GoTAL, pages 248–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JR Landis</author>
<author>GG Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>Biometrics,</journal>
<pages>33--159</pages>
<contexts>
<context position="17447" citStr="Landis and Koch, 1977" startWordPosition="2721" endWordPosition="2724">et, for which we can compute the majority agreement (n=28,763). By definition, the two last datasets should present a better coherence and less annotation ambiguity because some ambiguities have been resolved by unanimity or by majority vote. 5.3 Evaluation The inter-annotator agreement is computed with the Cohen’s Kappa (Cohen, 1960), applied to pairs of annotators, which values are then leveraged to obtain the unique average value; and Fleiss’ Kappa (Fleiss and Cohen, 1973), suitable for processing data provided by more than two annotators. The interpretation of the scores are for instance (Landis and Koch, 1977): substantial agreement between 0.61 and 0.80, almost perfect agreement between 0.81 and 1.00. 14 With machine learning, we perform a ten-fold cross-validation, which means that the evaluation test is performed ten times on different randomly generated test sets (1/10 of the whole dataset), while the remaining 9/10 of the whole dataset is used for training the algorithm and creating the model. In this way, each word is used during the test step. The success of the applied algorithms is evaluated with three classical measures: R recall, P precision and F F-measure. In the perspective of our wor</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>JR Landis and GG Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, 33:159–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leroy</author>
<author>S Helmreich</author>
<author>J Cowie</author>
<author>T Miller</author>
<author>W Zheng</author>
</authors>
<title>Evaluating online health information: Beyond readability formulas. In AMIA</title>
<date>2008</date>
<pages>394--8</pages>
<contexts>
<context position="9548" citStr="Leroy et al., 2008" startWordPosition="1514" endWordPosition="1517">lik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2 and A3), and in the derived datasets unanimity and majority. nations of different features (Wang, 2006; ZengTreiler et al., 2007; Leroy et al., 2008). Specific task has been dedicated to the lexical simplification within the SemEval challenge in 20121. Given a short input text and a target word in English, and given several English substitutes for the target word that fit the context, the goal was to rank these substitutes according to how ”simple” they are (Specia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, number of syllables, latent semantic analysis, mutua</context>
</contexts>
<marker>Leroy, Helmreich, Cowie, Miller, Zheng, 2008</marker>
<rawString>G Leroy, S Helmreich, J Cowie, T Miller, and W Zheng. 2008. Evaluating online health information: Beyond readability formulas. In AMIA 2008, pages 394–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary Libben</author>
<author>Martha Gibson</author>
<author>Yeo Bom Yoon</author>
<author>Dominiek Sandra</author>
</authors>
<title>Compound fracture: The role of semantic transparency and morphological headedness.</title>
<date>2003</date>
<journal>Brain and Language,</journal>
<volume>84</volume>
<issue>1</issue>
<contexts>
<context position="3763" citStr="Libben et al., 2003" startWordPosition="585" endWordPosition="588"> also related to the ability to provide correct explanation and use of words. As we explain later, we consider words out of context and use a three-position scale. More generally, understanding is a complex notion closely linked to several other notions studied in different research fields. For instance, lexical complexity is studied in linguistics and gives clues on lexical processes involved, that may impact the word understanding (section 2.1). Work in psycholinguistics is often oriented on study of word opacity and the mental processes involved in their understanding (Jarema et al., 1999; Libben et al., 2003). Readability provides a set of methods to compute and quantify the understandability of words (section 2.3). The specificity of words to specialized areas is another way to capture their understandability (section 2.2). Finally, lexical 11 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 11–20, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics simplification aims at providing simpler words to be used in a given context (section 2.3). 2.1 Linguistics In linguistics, the ques</context>
</contexts>
<marker>Libben, Gibson, Yoon, Sandra, 2003</marker>
<rawString>Gary Libben, Martha Gibson, Yeo Bom Yoon, and Dominiek Sandra. 2003. Compound fracture: The role of semantic transparency and morphological headedness. Brain and Language, 84(1):50–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AL Ligozat</author>
<author>C Grouin</author>
<author>A Garcia-Fernandez</author>
<author>D Bernhard</author>
</authors>
<title>Annlor: A naive notationsystem for lexical outputs ranking.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>487--492</pages>
<contexts>
<context position="10433" citStr="Ligozat et al., 2012" startWordPosition="1651" endWordPosition="1654">e substitutes according to how ”simple” they are (Specia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, number of syllables, latent semantic analysis, mutual information and word frequency (Jauhar and Specia, 2012); Wikipedia frequency, word length, n-grams of characters and of words, random indexing and syntactic complexity of documents (Johannsen et al., 2012); n-grams and frequency from Wikipedia, Google n-grams (Ligozat et al., 2012); WordNet and word frequency (Amoia and Romanelli, 2012). 3 Aims of the present study We propose to investigate how the understandability of French medical words can be diagnosed with NLP methods. We rely on the reference annotations performed by French speakers without medical training, which we associate with patients. The experiments performed rely on machine learning algorithms and a set of 24 features. The medical words studied are provided by an existing medical terminology. 4 Linguistic data and their preparation The linguistic data are obtained from the medical terminology Snomed Inter</context>
</contexts>
<marker>Ligozat, Grouin, Garcia-Fernandez, Bernhard, 2012</marker>
<rawString>AL Ligozat, C Grouin, A Garcia-Fernandez, and D Bernhard. 2012. Annlor: A naive notationsystem for lexical outputs ranking. In *SEM 2012, pages 487–492.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L¨udeling</author>
<author>T Schmidt</author>
<author>S Kiokpasoglou</author>
</authors>
<title>Neoclassical word formation in german. Yearbook of Morphology,</title>
<date>2002</date>
<pages>253--283</pages>
<marker>L¨udeling, Schmidt, Kiokpasoglou, 2002</marker>
<rawString>A L¨udeling, T Schmidt, and S Kiokpasoglou. 2002. Neoclassical word formation in german. Yearbook of Morphology, pages 253–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Maynard</author>
<author>S Ananiadou</author>
</authors>
<title>Identifying terms by their family and friends.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING 2000,</booktitle>
<pages>530--536</pages>
<location>Saarbrucken, Germany.</location>
<contexts>
<context position="7737" citStr="Maynard and Ananiadou, 2000" startWordPosition="1227" endWordPosition="1231">l in terminology (W¨uster, 1981; Cabr´e and Estop`a, 2002; Cabr´e, 2000). The specificity of terms to a given field is usually studied. The notion of understandability can be derived from it. Such studies can be used for filtering the terms extracted from specialized corpora (Korkontzelos et al., 2008). The features exploited include for instance the presence and the specificity of pivot words (Drouin and Langlais, 2006), the neighborhood of the term in corpus or the diversity of its components computed with statistical measures such as C-Value or PageRank (Daille, 1995; Frantzi et al., 1997; Maynard and Ananiadou, 2000). Another possibility is to check whether lexical units occur within reference terminologies and, if they do, they are considered to convey specialized meaning (Elhadad and Sutaria, 2007). 2.3 NLP studies The application of the readability measures is another way to evaluate the complexity of words and terms. Among these measures, it is possible to distinguish classical readability measures and computational readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 197</context>
</contexts>
<marker>Maynard, Ananiadou, 2000</marker>
<rawString>D Maynard and S Ananiadou. 2000. Identifying terms by their family and friends. In Proceedings of COLING 2000, pages 530–536, Saarbrucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCray</author>
</authors>
<title>Promoting health literacy.</title>
<date>2005</date>
<journal>J of Am Med Infor Ass,</journal>
<pages>12--152</pages>
<contexts>
<context position="1948" citStr="McCray, 2005" startWordPosition="282" endWordPosition="283">h condition, watching TV and radio broadcasts, reading novels and journals. Nevertheless, the availability of this kind of information does not guarantee its correct understanding, especially by laymen, such as patients. The medical field has indeed a specific terminology (e.g., abdominoplasty, hepatic, dermabrasion or hepatoduodenostomy) commonly used by medical professionals. This fact has been highlighted in several studies dedicated for instance to the understanding of pharmaceutical labels (Patel et al., 2002), of information provided by websites (Rudd et al., 1999; Berland et al., 2001; McCray, 2005; Oregon Evidencebased Practice Center, 2008), and more generally the understanding between patients and medical doctors (AMA, 1999; McCray, 2005; Jucks and Bromme, 2007; Tran et al., 2009). We propose to study the understanding of words used in the medical field, which is the first step towards the simplification of texts. Indeed, before the simplification can be performed, it is necessary to know which textual units may show understanding difficulty and should be simplified. We work with data in French, such as provided by an existing medical terminology. In the remainder, we present first s</context>
</contexts>
<marker>McCray, 2005</marker>
<rawString>A McCray. 2005. Promoting health literacy. J of Am Med Infor Ass, 12:152–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Miller</author>
<author>G Leroy</author>
<author>S Chatterjee</author>
<author>J Fan</author>
<author>B Thoms</author>
</authors>
<title>A classifier to evaluate language specificity of medical documents.</title>
<date>2007</date>
<booktitle>In HICSS,</booktitle>
<pages>134--140</pages>
<contexts>
<context position="8898" citStr="Miller et al., 2007" startWordPosition="1403" endWordPosition="1406">and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features (Chmielik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2 and A3), and in the derived datasets unanimity and majority. nations of different features (Wang, 2</context>
</contexts>
<marker>Miller, Leroy, Chatterjee, Fan, Thoms, 2007</marker>
<rawString>T Miller, G Leroy, S Chatterjee, J Fan, and B Thoms. 2007. A classifier to evaluate language specificity of medical documents. In HICSS, pages 134–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fiammetta Namer</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Acquiring meaning for French medical terminology: contribution of morphosemantics.</title>
<date>2004</date>
<booktitle>In Annual Symposium of the American Medical Informatics Association (AMIA), San-Francisco.</booktitle>
<contexts>
<context position="14806" citStr="Namer and Zweigenbaum, 2004" startWordPosition="2311" endWordPosition="2314">e. For each word, we query the Google search engine in order to know its frequency attested on the web. Frequency of words in the medical terminology. We also compute the frequency of words in the medical terminology Snomed International. Number and types of semantic categories associated to words. We exploit the information on the semantic categories of Snomed International. Length of words in number of their characters and syllables. For each word, we compute the number of its characters and syllables. Number of bases and affixes. Each lemma is analyzed by the morphological analyzer D´erif (Namer and Zweigenbaum, 2004), adapted to the treatment of medical words. It performs the decomposition of lemmas into bases and affixes known in its database and it provides also semantic explanation of the analyzed lexemes. We exploit the morphological decomposition information (number of affixes and bases). Initial and final substrings of the words. We compute the initial and final substrings of different length, from three to five characters. 2http://www.atilf.fr/ 3http://www.lexique.org/ Number and percentage of consonants, vowels and other characters. We compute the number and the percentage of consonants, vowels an</context>
</contexts>
<marker>Namer, Zweigenbaum, 2004</marker>
<rawString>Fiammetta Namer and Pierre Zweigenbaum. 2004. Acquiring meaning for French medical terminology: contribution of morphosemantics. In Annual Symposium of the American Medical Informatics Association (AMIA), San-Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Namer</author>
</authors>
<title>FLEMM : un analyseur flexionnel du franc¸ais a` base de r`egles. Traitement automatique des langues (TAL),</title>
<date>2000</date>
<pages>41--2</pages>
<contexts>
<context position="13413" citStr="Namer, 2000" startWordPosition="2092" endWordPosition="2093">on of the features associated to the analyzed words and a machine learning system. The main research question is whether the NLP methods can distinguish between understandable and nonunderstandable medical words and whether they can diagnose these two categories. 13 5.1 Generation of the features We exploit 24 linguistic and extra-linguistic features related to general and specialized languages. The features are computed automatically, and can be grouped into ten classes: Syntactic categories. Syntactic categories and lemmas are computed by TreeTagger (Schmid, 1994) and then checked by Flemm (Namer, 2000). The syntactic categories are assigned to words within the context of their terms. If a given word receives more than one category, the most frequent one is kept as feature. Among the main categories we find for instance nouns, adjectives, proper names, verbs and abbreviations. Presence of words in reference lexica. We exploit two reference lexica of the French language: TLFi2 and lexique.org3. TLFi is a dictionary of the French language covering XIX and XX centuries. It contains almost 100,000 entries. lexique.org is a lexicon created for psycholinguistic experiments. It contains over 135,00</context>
</contexts>
<marker>Namer, 2000</marker>
<rawString>F Namer. 2000. FLEMM : un analyseur flexionnel du franc¸ais a` base de r`egles. Traitement automatique des langues (TAL), 41(2):523–547.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oregon Evidence-based Practice Center</author>
</authors>
<title>Barriers and drivers of health information technology use for the elderly, chronically ill, and underserved. Technical report, Agency for healthcare research and quality.</title>
<date>2008</date>
<contexts>
<context position="1993" citStr="Center, 2008" startWordPosition="288" endWordPosition="289">s, reading novels and journals. Nevertheless, the availability of this kind of information does not guarantee its correct understanding, especially by laymen, such as patients. The medical field has indeed a specific terminology (e.g., abdominoplasty, hepatic, dermabrasion or hepatoduodenostomy) commonly used by medical professionals. This fact has been highlighted in several studies dedicated for instance to the understanding of pharmaceutical labels (Patel et al., 2002), of information provided by websites (Rudd et al., 1999; Berland et al., 2001; McCray, 2005; Oregon Evidencebased Practice Center, 2008), and more generally the understanding between patients and medical doctors (AMA, 1999; McCray, 2005; Jucks and Bromme, 2007; Tran et al., 2009). We propose to study the understanding of words used in the medical field, which is the first step towards the simplification of texts. Indeed, before the simplification can be performed, it is necessary to know which textual units may show understanding difficulty and should be simplified. We work with data in French, such as provided by an existing medical terminology. In the remainder, we present first some related work, especially from specialized</context>
</contexts>
<marker>Center, 2008</marker>
<rawString>Oregon Evidence-based Practice Center. 2008. Barriers and drivers of health information technology use for the elderly, chronically ill, and underserved. Technical report, Agency for healthcare research and quality.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Patel</author>
<author>T Branch</author>
<author>J Arocha</author>
</authors>
<title>Errors in interpreting quantities as procedures : The case of pharmaceutical labels.</title>
<date>2002</date>
<booktitle>International journal of medical informatics,</booktitle>
<pages>65--3</pages>
<contexts>
<context position="1856" citStr="Patel et al., 2002" startWordPosition="265" endWordPosition="268">he medical field has deeply penetrated our daily life, which may be due to personal or family health condition, watching TV and radio broadcasts, reading novels and journals. Nevertheless, the availability of this kind of information does not guarantee its correct understanding, especially by laymen, such as patients. The medical field has indeed a specific terminology (e.g., abdominoplasty, hepatic, dermabrasion or hepatoduodenostomy) commonly used by medical professionals. This fact has been highlighted in several studies dedicated for instance to the understanding of pharmaceutical labels (Patel et al., 2002), of information provided by websites (Rudd et al., 1999; Berland et al., 2001; McCray, 2005; Oregon Evidencebased Practice Center, 2008), and more generally the understanding between patients and medical doctors (AMA, 1999; McCray, 2005; Jucks and Bromme, 2007; Tran et al., 2009). We propose to study the understanding of words used in the medical field, which is the first step towards the simplification of texts. Indeed, before the simplification can be performed, it is necessary to know which textual units may show understanding difficulty and should be simplified. We work with data in Frenc</context>
</contexts>
<marker>Patel, Branch, Arocha, 2002</marker>
<rawString>V Patel, T Branch, and J Arocha. 2002. Errors in interpreting quantities as procedures : The case of pharmaceutical labels. International journal of medical informatics, 65(3):193–211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poprat</author>
<author>K Mark´o</author>
<author>U Hahn</author>
</authors>
<title>A language classifier that automatically divides medical documents for experts and health care consumers.</title>
<date>2006</date>
<booktitle>In MIE 2006 - Proceedings of the XX International Congress of the European Federation for Medical Informatics,</booktitle>
<pages>503--508</pages>
<location>Maastricht.</location>
<marker>Poprat, Mark´o, Hahn, 2006</marker>
<rawString>M Poprat, K Mark´o, and U Hahn. 2006. A language classifier that automatically divides medical documents for experts and health care consumers. In MIE 2006 - Proceedings of the XX International Congress of the European Federation for Medical Informatics, pages 503–508, Maastricht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JR Quinlan</author>
</authors>
<title>C4.5 Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA. R Rittman.</location>
<contexts>
<context position="21005" citStr="Quinlan, 1993" startWordPosition="3285" endWordPosition="3286">achine learning P R F J48 0.876 0.889 0.881 RandomForest 0.880 0.892 0.884 REPTree 0.874 0.890 0.879 DecisionTable 0.872 0.891 0.880 LMT 0.876 0.895 0.884 SMO 0.858 0.876 0.867 Table 2: Performance obtained on the majority dataset with various algorithms. We tested several machine learning algorithms to discover which of them are the most suitable to the task at hand. In Table 2, with results computed on the majority dataset, we can observe that the algorithms provide with similar performance (between 0.85 and 0.90 P and R). In the remaining of the paper, we present results obtained with J48 (Quinlan, 1993). Table 3 shows P, R and F values for the five datasets: three annotators, majority and unanimity datasets. We can observe 0 5000 10000 15000 20000 25000 Words Number in each category 20000 15000 10000 5000 0 A1 A2 A3 I cannot understand I can understand I am not sure P−BL 1−BL . 15 that, among the three annotators, it is easier to reproduce the annotations of the third annotator: we gain then 0.040 with F comparing to the two other annotators. The results become even better with the majority dataset (F=0.881), and reach F up to 0.947 on the unanimity dataset. As we expected, these two last da</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>JR Quinlan. 1993. C4.5 Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA. R Rittman. 2008. Automatic discrimination of genres. VDM, Saarbrucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rudd</author>
<author>B Moeykens</author>
<author>T Colton</author>
</authors>
<title>Annual Review ofAdult Learning and Literacy, page ch 5.</title>
<date>1999</date>
<contexts>
<context position="1912" citStr="Rudd et al., 1999" startWordPosition="274" endWordPosition="277">ch may be due to personal or family health condition, watching TV and radio broadcasts, reading novels and journals. Nevertheless, the availability of this kind of information does not guarantee its correct understanding, especially by laymen, such as patients. The medical field has indeed a specific terminology (e.g., abdominoplasty, hepatic, dermabrasion or hepatoduodenostomy) commonly used by medical professionals. This fact has been highlighted in several studies dedicated for instance to the understanding of pharmaceutical labels (Patel et al., 2002), of information provided by websites (Rudd et al., 1999; Berland et al., 2001; McCray, 2005; Oregon Evidencebased Practice Center, 2008), and more generally the understanding between patients and medical doctors (AMA, 1999; McCray, 2005; Jucks and Bromme, 2007; Tran et al., 2009). We propose to study the understanding of words used in the medical field, which is the first step towards the simplification of texts. Indeed, before the simplification can be performed, it is necessary to know which textual units may show understanding difficulty and should be simplified. We work with data in French, such as provided by an existing medical terminology. </context>
</contexts>
<marker>Rudd, Moeykens, Colton, 1999</marker>
<rawString>R Rudd, B Moeykens, and T Colton, 1999. Annual Review ofAdult Learning and Literacy, page ch 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="13373" citStr="Schmid, 1994" startWordPosition="2085" endWordPosition="2086">proposed method has two aspects: generation of the features associated to the analyzed words and a machine learning system. The main research question is whether the NLP methods can distinguish between understandable and nonunderstandable medical words and whether they can diagnose these two categories. 13 5.1 Generation of the features We exploit 24 linguistic and extra-linguistic features related to general and specialized languages. The features are computed automatically, and can be grouped into ten classes: Syntactic categories. Syntactic categories and lemmas are computed by TreeTagger (Schmid, 1994) and then checked by Flemm (Namer, 2000). The syntactic categories are assigned to words within the context of their terms. If a given word receives more than one category, the most frequent one is kept as feature. Among the main categories we find for instance nouns, adjectives, proper names, verbs and abbreviations. Presence of words in reference lexica. We exploit two reference lexica of the French language: TLFi2 and lexique.org3. TLFi is a dictionary of the French language covering XIX and XX centuries. It contains almost 100,000 entries. lexique.org is a lexicon created for psycholinguis</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sinha</author>
</authors>
<title>Unt-simprank: Systems for lexical simplification ranking.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<pages>493--496</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<contexts>
<context position="10081" citStr="Sinha, 2012" startWordPosition="1601" endWordPosition="1602">f different features (Wang, 2006; ZengTreiler et al., 2007; Leroy et al., 2008). Specific task has been dedicated to the lexical simplification within the SemEval challenge in 20121. Given a short input text and a target word in English, and given several English substitutes for the target word that fit the context, the goal was to rank these substitutes according to how ”simple” they are (Specia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, number of syllables, latent semantic analysis, mutual information and word frequency (Jauhar and Specia, 2012); Wikipedia frequency, word length, n-grams of characters and of words, random indexing and syntactic complexity of documents (Johannsen et al., 2012); n-grams and frequency from Wikipedia, Google n-grams (Ligozat et al., 2012); WordNet and word frequency (Amoia and Romanelli, 2012). 3 Aims of the present study We propose to investigate how the understandability of French medical words can be diagnosed with NLP methods. We rely on the reference annotations performed by F</context>
</contexts>
<marker>Sinha, 2012</marker>
<rawString>R Sinha. 2012. Unt-simprank: Systems for lexical simplification ranking. In *SEM 2012, pages 493– 496, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Specia</author>
<author>SK Jauhar</author>
<author>R Mihalcea</author>
</authors>
<date>2012</date>
<booktitle>Semeval2012 task 1: English lexical simplification. In *SEM 2012,</booktitle>
<pages>347--355</pages>
<contexts>
<context position="9882" citStr="Specia et al., 2012" startWordPosition="1571" endWordPosition="1574">9,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2 and A3), and in the derived datasets unanimity and majority. nations of different features (Wang, 2006; ZengTreiler et al., 2007; Leroy et al., 2008). Specific task has been dedicated to the lexical simplification within the SemEval challenge in 20121. Given a short input text and a target word in English, and given several English substitutes for the target word that fit the context, the goal was to rank these substitutes according to how ”simple” they are (Specia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, number of syllables, latent semantic analysis, mutual information and word frequency (Jauhar and Specia, 2012); Wikipedia frequency, word length, n-grams of characters and of words, random indexing and syntactic complexity of documents (Johannsen et al., 2012); n-grams and frequency from Wikipedia, Google n-grams (Ligozat et al., 2012); WordNet and word frequency (Amoia and Romanelli</context>
<context position="25866" citStr="Specia et al., 2012" startWordPosition="4082" endWordPosition="4085">ectively), although they belong to the same category. On contrary, other words with quite high frequencies, like coagulase (coagulase), clivage (cleavage) or douve (fluke) (655,000, 1,350,000 and 1,030,000, respectively) are not understood by the annotators. According to these experiments, our results point out that, among the most efficient features, we can find syntactic categories, presence of words in the reference lexica, frequencies of words on Google and three- and four-character end substring. In comparison to the existing studies, such as those presented during the SemEval challenge (Specia et al., 2012), we propose to exploit a more complete set of features, several of which rely on the NLP methods (e.g., syntactic tagging, morphological analysis). Especially the syntactic tagging appears to be salient for the task. In comparison to work done on general language data (Gala et al., 2013), our experiment shows better results (between 0.825 and 0.948 accuracy against 0.62 accuracy in the cited work), which indicates that specialized domains have indeed very specific words. Additional tests should be performed to obtain a more detailed impact of the features. 6.4 Usefulness of the method We appl</context>
</contexts>
<marker>Specia, Jauhar, Mihalcea, 2012</marker>
<rawString>L Specia, SK Jauhar, and R Mihalcea. 2012. Semeval2012 task 1: English lexical simplification. In *SEM 2012, pages 347–355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TM Tran</author>
<author>H Chekroud</author>
<author>P Thiery</author>
<author>A Julienne</author>
</authors>
<title>Internet et soins : un tiers invisible dans la relation m´edecine/patient ? Ethica Clinica,</title>
<date>2009</date>
<pages>53--34</pages>
<contexts>
<context position="2137" citStr="Tran et al., 2009" startWordPosition="308" endWordPosition="311">pecially by laymen, such as patients. The medical field has indeed a specific terminology (e.g., abdominoplasty, hepatic, dermabrasion or hepatoduodenostomy) commonly used by medical professionals. This fact has been highlighted in several studies dedicated for instance to the understanding of pharmaceutical labels (Patel et al., 2002), of information provided by websites (Rudd et al., 1999; Berland et al., 2001; McCray, 2005; Oregon Evidencebased Practice Center, 2008), and more generally the understanding between patients and medical doctors (AMA, 1999; McCray, 2005; Jucks and Bromme, 2007; Tran et al., 2009). We propose to study the understanding of words used in the medical field, which is the first step towards the simplification of texts. Indeed, before the simplification can be performed, it is necessary to know which textual units may show understanding difficulty and should be simplified. We work with data in French, such as provided by an existing medical terminology. In the remainder, we present first some related work, especially from specialized fields (section 2). We then introduce the linguistic data (section 4) and methodology (section 5) we propose to test. We present and discuss th</context>
</contexts>
<marker>Tran, Chekroud, Thiery, Julienne, 2009</marker>
<rawString>TM Tran, H Chekroud, P Thiery, and A Julienne. 2009. Internet et soins : un tiers invisible dans la relation m´edecine/patient ? Ethica Clinica, 53:34–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wang</author>
</authors>
<title>Automatic recognition of text difficulty from consumers health information.</title>
<date>2006</date>
<booktitle>In IEEE, editor, Computer-Based Medical Systems,</booktitle>
<pages>131--136</pages>
<contexts>
<context position="9501" citStr="Wang, 2006" startWordPosition="1507" endWordPosition="1508">, 2007), morphological features (Chmielik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percentage) of words assigned to reference categories by three annotators (A1, A2 and A3), and in the derived datasets unanimity and majority. nations of different features (Wang, 2006; ZengTreiler et al., 2007; Leroy et al., 2008). Specific task has been dedicated to the lexical simplification within the SemEval challenge in 20121. Given a short input text and a target word in English, and given several English substitutes for the target word that fit the context, the goal was to rank these substitutes according to how ”simple” they are (Specia et al., 2012). The participants applied rule-based and/or machine learning systems. Combinations of various features have been used: lexicon from spoken corpus and Wikipedia, Google n-grams, WordNet (Sinha, 2012); word length, numbe</context>
</contexts>
<marker>Wang, 2006</marker>
<rawString>Y Wang. 2006. Automatic recognition of text difficulty from consumers health information. In IEEE, editor, Computer-Based Medical Systems, pages 131–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data mining: Practical machine learning tools and techniques.</title>
<date>2005</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco.</location>
<contexts>
<context position="16519" citStr="Witten and Frank, 2005" startWordPosition="2573" endWordPosition="2576">lgorithms are used to study whether they can distinguish between words understandable and non-understandable by laymen and to study the importance of various features for the task. The functioning of machine learning algorithms is based on a set of positive and negative examples of the data to be processed, which have to be described with suitable features such as those presented above. The algorithms can then detect the regularities within the training dataset to generate a model, and apply the generated model to process new unseen data. We apply various algorithms available within the WEKA (Witten and Frank, 2005) platform. The annotations provided by the three annotators constitute our reference data. We use on the whole five reference datasets (Table 1): 3 sets of separate annotations provided by the three annotators (29,641 words each); 1 unanimity set, on which all the annotators agree (n=22,925); 1 majority set, for which we can compute the majority agreement (n=28,763). By definition, the two last datasets should present a better coherence and less annotation ambiguity because some ambiguities have been resolved by unanimity or by majority vote. 5.3 Evaluation The inter-annotator agreement is com</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>I.H. Witten and E. Frank. 2005. Data mining: Practical machine learning tools and techniques. Morgan Kaufmann, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugen W¨uster</author>
</authors>
<title>L’tude scientifique gnrale de la terminologie, zone frontalire entre la linguistique, la logique, l’ontologie, l’informatique et les sciences des choses.</title>
<date>1981</date>
<booktitle>Textes choisis de terminologie, volume I. Fondements thoriques de la terminologie,</booktitle>
<pages>55--114</pages>
<editor>In G. Rondeau et H. Felber, editor,</editor>
<publisher>Siforov.</publisher>
<marker>W¨uster, 1981</marker>
<rawString>Eugen W¨uster. 1981. L’tude scientifique gnrale de la terminologie, zone frontalire entre la linguistique, la logique, l’ontologie, l’informatique et les sciences des choses. In G. Rondeau et H. Felber, editor, Textes choisis de terminologie, volume I. Fondements thoriques de la terminologie, pages 55–114. GISTERM, Universit de Laval, Qubec. sous la direction de V.I. Siforov.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Zeng-Treiler</author>
<author>H Kim</author>
<author>S Goryachev</author>
<author>A Keselman</author>
<author>L Slaugther</author>
<author>CA Smith</author>
</authors>
<title>Text characteristics of clinical reports and their implications for the readability of personal health records.</title>
<date>2007</date>
<booktitle>In MEDINFO,</booktitle>
<pages>1117--1121</pages>
<location>Brisbane, Australia.</location>
<marker>Zeng-Treiler, Kim, Goryachev, Keselman, Slaugther, Smith, 2007</marker>
<rawString>Q Zeng-Treiler, H Kim, S Goryachev, A Keselman, L Slaugther, and CA Smith. 2007. Text characteristics of clinical reports and their implications for the readability of personal health records. In MEDINFO, pages 1117–1121, Brisbane, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Zheng</author>
<author>E Milios</author>
<author>C Watters</author>
</authors>
<title>Filtering for medical news items using a machine learning approach.</title>
<date>2002</date>
<booktitle>In AMIA,</booktitle>
<pages>949--53</pages>
<contexts>
<context position="8725" citStr="Zheng et al., 2002" startWordPosition="1375" endWordPosition="1378">cal readability measures and computational readability measures (Franc¸ois, 2011). Classical measures usually rely on number of letters and/or of syllables a word contains and on linear regression models (Flesch, 1948; Gunning, 1973), while computational readability measures may involve vector models and a great variability of features, among which the following have been used to process the biomedical documents and words: combination of classical readability formulas with medical terminologies (Kokkinakis and Toporowska Gronostaj, 2006); n-grams of characters (Poprat et al., 2006), manually (Zheng et al., 2002) or automatically (Borst et al., 2008) defined weight of terms, stylistic (Grabar et al., 2007) or discursive (Goeuriot et al., 2007) features, lexicon (Miller et al., 2007), morphological features (Chmielik and Grabar, 2011), combi12 Categories A1 (%) A2 (%) A3 (%) Unanimity (%) Majority (%) 1. I can understand 8,099 (28) 8,625 (29) 7,529 (25) 5,960 (26) 7,655 (27) 2. I am not sure 1,895 (6) 1,062 (4) 1,431 (5) 61 (0.3) 597 (2) 3. I cannot understand 19,647 (66) 19,954 (67) 20,681 (70) 16,904 (73.7) 20,511 (71) Total annotations 29,641 29,641 29,641 22,925 28,763 Table 1: Number (and percenta</context>
</contexts>
<marker>Zheng, Milios, Watters, 2002</marker>
<rawString>W Zheng, E Milios, and C Watters. 2002. Filtering for medical news items using a machine learning approach. In AMIA, pages 949–53.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>