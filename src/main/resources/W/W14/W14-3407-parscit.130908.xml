<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000340">
<title confidence="0.936015">
Coreference Resolution for Structured Drug Product Labels
</title>
<author confidence="0.855589">
Halil Kilicoglu and Dina Demner-Fushman
</author>
<affiliation confidence="0.783306">
National Library of Medicine
National Institutes of Health
</affiliation>
<address confidence="0.733668">
Bethesda, MD, 20894
</address>
<email confidence="0.998138">
{kilicogluh,ddemner}@mail.nih.gov
</email>
<sectionHeader confidence="0.994779" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999971703703704">
FDA drug package inserts provide com-
prehensive and authoritative information
about drugs. DailyMed database is a
repository of structured product labels ex-
tracted from these package inserts. Most
salient information about drugs remains
in free text portions of these labels. Ex-
tracting information from these portions
can improve the safety and quality of drug
prescription. In this paper, we present a
study that focuses on resolution of coref-
erential information from drug labels con-
tained in DailyMed. We generalized and
expanded an existing rule-based coref-
erence resolution module for this pur-
pose. Enhancements include resolution of
set/instance anaphora, recognition of ap-
positive constructions and wider use of
UMLS semantic knowledge. We obtained
an improvement of 40% over the baseline
with unweighted average Fi-measure us-
ing B-CUBED, MUC, and CEAF metrics.
The results underscore the importance of
set/instance anaphora and appositive con-
structions in this type of text and point out
the shortcomings in coreference annota-
tion in the dataset.
</bodyText>
<sectionHeader confidence="0.998881" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999900571428571">
Almost half of the US population uses at least one
prescription drug and over 75% of physician of-
fice visits involve drug therapy&apos;. Knowing how
these drugs will affect the patient is very impor-
tant, particularly, to over 20% of the patients that
are on three or more prescription drugs&apos;. FDA
drug package inserts (drug labels or Structured
</bodyText>
<footnote confidence="0.953223333333333">
1Centers for Disease Control and Preven-
tion: FASTSTATS - Therapeutic Drug Use:
http://www.cdc.gov/nchs/fastats/drugs.htm
</footnote>
<bodyText confidence="0.999081425">
Product Labels (SPLs)) provide curated informa-
tion about the prescription drugs and many over-
the-counter drugs. The drug labels for most drugs
are publicly available in XML format through Dai-
lyMed 2. Some information in these labels, such as
the drug identifiers and ingredients, could be eas-
ily extracted from the structured fields of the XML
documents. However, the salient content about in-
dications, side effects and drug-drug interactions,
among others, is buried in the free text of the
corresponding sections of the labels. Extracting
this information with natural language process-
ing techniques can facilitate automatic timely up-
dates to databases that support Electronic Health
Records in alerting physicians to potential drug in-
teractions, recommended doses, and contraindica-
tions.
Natural language processing methods are in-
creasingly used to support various clinical and
biomedical applications (Demner-Fushman et al.,
2009). Extraction of drug information is playing a
prominent role in these applications and research.
In addition to earlier research in extraction of med-
ications and relations involving medications from
clinical text and the biomedical literature (Rind-
flesch et al., 2000; Cimino et al., 2007), in the
third i2b2 shared task (Uzuner et al., 2010), 23
organizations have explored extraction of medica-
tions, their dosages, routes of administration, fre-
quencies, durations, and reasons for administra-
tion from clinical text. The best performing sys-
tems used rule-based and machine learning tech-
niques to achieve over 0.8 F-measure for extrac-
tion of medication names; however, the remain-
ing information was harder to extract. Researchers
have also tackled extraction of drug-drug interac-
tions (Herrero-Zazo et al., 2013), side effects (Xu
and Wang, 2014), and indications (Fung et al.,
2013) from various biomedical resources.
As for many other information extraction tasks,
</bodyText>
<footnote confidence="0.927457">
2DailyMed: http://dailymed.nlm.nih.gov/dailymed/about.cfm
</footnote>
<page confidence="0.984685">
45
</page>
<note confidence="0.788263">
Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 45–53,
Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.99961">
extracting drug information is often made more
difficult by coreference. Coreference is defined as
the relation between linguistic expressions that are
referring to the same entity (Zheng et al., 2011).
Coreference resolution is a fundamental task in
NLP and can benefit many downstream applica-
tions, such as relation extraction, summarization,
and question answering. Difficulty of the task is
due to the fact that various levels of linguistic in-
formation (lexical, syntactic, semantic, and dis-
course contextual features) generally play a role.
Coreference occurs frequently in all types of
biomedical text, including the drug package in-
serts. Consider the example below:
</bodyText>
<listItem confidence="0.925876">
(1) Since amiodarone is a substrate for
CYP3A and CYP2C8, drugs/substances
that inhibit these isoenzymes may decrease
the metabolism ....
</listItem>
<bodyText confidence="0.999903703703704">
In this example, the expression these isoenzymes
refer to CYP3A and CYP2C8. Resolving this
coreference instance would allow us to capture the
following drug interactions mentioned in the sen-
tence: inhibitors of CYP3A POTENTIATE amio-
darone and inhibitors of CYP2C8 POTENTIATE
amiodarone.
In this paper, we present a study that focuses on
identification of coreference links in drug labels,
with the view that these relations will facilitate
the downstream task of drug interaction recogni-
tion. The rule-based system presented is an exten-
sion of the previous work reported in Kilicoglu et
al. (2013). The main focus of the dataset, based
on SPLs, is drug interaction information. Coref-
erence is only annotated when it is relevant to ex-
tracting such information. In addition to evaluat-
ing the system against a baseline, we also manu-
ally assessed the system output for precision. Fur-
thermore, we also evaluated the system on a sim-
ilarly drug-focused corpus annotated for anaphora
(DrugNerAR) (Segura-Bedmar et al., 2010). Our
results demonstrate that set/instance anaphora res-
olution and appositive recognition can play a sig-
nificant role in this type of text and highlight some
of the major areas of difficulty and potential en-
hancements.
</bodyText>
<sectionHeader confidence="0.999809" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999975654545455">
We discuss two areas of research related to this
study in this section: processing of drug labels
and coreference resolution focusing on biomedi-
cal text. Drug labels, despite their availability and
the wealth of information contained within them,
remain underutilized. One of the reasons might be
the complexity of the text in the labels: in a review
of publicly available text sources that could be
used to augment a repository of drug indications
and adverse effects (ADEs), Smith et al. (2011)
concluded that many indication and adverse drug
event relationships in the drug labels are too com-
plex to be captured in the existing databases of in-
teractions and ADEs. Despite the complexity, the
labels were used to extract indications for drugs in
several studies. Elkin et al. (2011) automatically
extracted indications, mapped them to SNOMED-
CT and then automatically derived rules in the
form (”Drug” HasIndication ”SNOMED CT”).
Fung et al. (2013) used MetaMap (Aronson and
Lang, 2010) to extract indications and map them
to the UMLS (Lindberg et al., 1993), and then
manually validated the quality of the mappings.
Oprea et al. (2011) used information extracted
from the adverse reactions sections of 988 drugs
for computer-aided drug repurposing. Duke et
al. (2011) have developed a rule-based system that
extracted 534,125 ADEs from 5602 SPLs. Zhu
et al. (2013) extracted disease terms from five
SPL sections (indication, contraindication, ADE,
precaution, and warning) and combined the ex-
tracted terms with the drug and disease relation-
ships in NDF-RT to disambiguate the PharmGKB
drug and disease associations. A hybrid NLP sys-
tem, AutoMCExtractor, uses conditional random
fields and post-processing rules to extract medical
conditions from SPLs and build triplets in the form
of([drug name]-[medical condition]-[LOINC sec-
tion header]) (Li et al., 2013).
Coreference resolution in the biomedical do-
main was addressed in the 2011 i2b2/VA shared
task (Uzuner et al., 2012), and the 2011 BioNLP
Shared Task (Kim et al., 2012); however these
community-wide evaluations did not change much
the observation in the 2011 review by Zheng
et al. (2011) that only a handful of systems
were developed for handling anaphora and coref-
erence in clinical text and biomedical publica-
tions. Since this comprehensive article was pub-
lished, Yoshikawa et al. (2011) proposed two
coference resolution models based on support vec-
tor machine and joint Markov logic network to
aid the task of biological event extraction. Sim-
ilarly, Miwa et al. (2012) and Kilicoglu and
Bergler (2012) extended their biological event
</bodyText>
<page confidence="0.998807">
46
</page>
<bodyText confidence="0.9999189375">
extraction pipelines using rule-based corefer-
ence systems that rely on syntactic information
and predicate argument structures. Nguyen et
al. (2012) evaluated contribution of discourse pref-
erence, number agreement, and domain-specific
semantic information in capturing pronominal and
nominal anaphora referring to proteins. An ef-
fort similar to ours is that of Segura-Bedmar et
al. (2010), who resolve anaphora to support drug-
drug interaction extraction. They created a cor-
pus of 49 interactions sections extracted from the
DrugBank database, having on average 40 sen-
tences and 716 tokens. They then manually anno-
tated pronominal and nominal anaphora, and de-
veloped a rule-based approach that achieve 0.76
F1-measure in anaphora resolution.
</bodyText>
<sectionHeader confidence="0.998683" genericHeader="method">
3 Methods
</sectionHeader>
<subsectionHeader confidence="0.998414">
3.1 The dataset
</subsectionHeader>
<bodyText confidence="0.999979375">
We used a dataset extracted from FDA drug pack-
age labels by our collaborators at FDA interested
in extracting interactions between cardiovascu-
lar drugs. The dataset consists of 159 drug la-
bels, with an average of 105 sentences and 1787
tokens per label. It is annotated for three en-
tity types (Drug, Drug Class, and Substance) and
four drug interaction types (Caution, Decrease, In-
crease, and Specific). 377 instances of corefer-
ence were annotated. Two annotators separately
annotated the labels and one of the authors per-
formed the adjudication. The relatively low num-
ber of coreference instances is due to the fact that
coreference was annotated only when it would be
relevant to drug interaction recognition task. This
parsimonious approach to annotation presents dif-
ficulty in automatically evaluating the system, and
to mitigate this, we present an assessment of the
precision of our end-to-end coreference system, as
well. We split the dataset into training and test sets
by random sampling. Training data consists of 79
documents and the test set has 80 documents. We
used the training data for analysis and as the basis
of our enhancements.
</bodyText>
<subsectionHeader confidence="0.999882">
3.2 The system
</subsectionHeader>
<bodyText confidence="0.999995075000001">
The work described in this paper extends and
refines earlier work, described in Kilicoglu et
al. (2013), which focused on disease anaphora and
ellipsis in the context of consumer health ques-
tions. We briefly recap that system here. The sys-
tem begins by mapping named entities to UMLS
Metathesaurus concepts (CUIs). Next, it identifies
anaphoric expressions in text, which include per-
sonal (e.g., it, they) and demonstrative pronouns
(e.g., this, those), as well as sortal anaphora (def-
inite (e.g., with the) and demonstrative (e.g., with
that) noun phrases). The candidate antecedents
are then recognized using syntactic (person, gen-
der and number agreement, head word matching)
and semantic (hypernym and UMLS semantic type
matching) constraints. Finally, the co-referent is
then selected as the focus of the question, which is
taken as the first disease mention in the question.
The coreference resolution pipeline used in the
current work, while enhanced significantly, fol-
lows the same basic sequence. The relatively sim-
ple approach of earlier work is generally sufficient
for consumer health questions; however, we found
it insufficient when it comes to drug labels. Aside
from the obvious point that the approach was lim-
ited to diseases, there are other stylistic differences
that have an impact on coreference resolution. In
contrast to informal and casual style of consumer
health questions, drug labels are curated and pro-
vide complex indication and ADE information in
a formal style, more akin to biomedical literature.
Our analysis of the training data highlighted sev-
eral facts regarding coreference in drug labels: (1)
the set/instance anaphora (including those involv-
ing distributive anaphora such as both, each, ei-
ther) instances are prominent, (2) demonstrative
pronominal anaphora is non-existent in contrast
to consumer health questions, (3) the focus-based
salience scoring is simplistic for longer texts. We
describe the system enhancements below.
</bodyText>
<subsectionHeader confidence="0.9943565">
3.2.1 Generalizing from diseases to drugs
and beyond
</subsectionHeader>
<bodyText confidence="0.999877466666667">
We generalized from resolution of disease coref-
erence only to resolution of coreference involv-
ing other entity types. For this purpose, we para-
materized semantic groups and hypernym lists as-
sociated with each semantic group. We general-
ized the system in the sense that new semantic
types and hypernyms can be easily defined and
used by the system. In addition to Disorder se-
mantic group and Disorder hypernym list defined
in earlier work, we used Drug, Intervention, Pop-
ulation, Procedure, Anatomy, and Gene/Protein
semantic groups and hypernym lists. Semantic
group classification largely mimics coarse-grained
UMLS semantic groups (McCray et al., 2001).
For example, UMLS semantic types Pharmaco-
</bodyText>
<page confidence="0.996041">
47
</page>
<bodyText confidence="0.998476666666667">
logic Substance and Clinical Drug are aggregated
into both Drug and Intervention semantic groups,
while Therapeutic or Preventive Procedure is as-
signed to Procedure group only. Drug hypernyms,
such as medication, drug, agent, were derived
from the training data.
</bodyText>
<subsectionHeader confidence="0.847735">
3.2.2 Set/instance anaphora
</subsectionHeader>
<bodyText confidence="0.961858022727273">
Set/instance anaphora instances are prevalent in
drug labels. In our dataset, 19% of all anno-
tated anaphoric expressions indicate set/instance
anaphora (co-referring with 29% of antecedent
terms). An example was provided earlier (Ex-
ample 1). While recognizing anaphoric expres-
sions that indicate set/instance anaphora is not
necessarily difficult (i.e., recognizing these isoen-
zymes in the example), linking them to their an-
tecedents can be difficult, since it generally in-
volves correctly identifying syntactic coordina-
tion, a challenging syntactic parsing task (Ogren,
2010). Our identification of these structures re-
lies on collapsed Stanford dependency output (de
Marneffe et al., 2006) and uses syntactic and se-
mantic constraints. We examine all the depen-
dency relations extracted from a sentence and only
consider those with the type conj * (e.g., conj and,
conj or). For increased accuracy, we then check
the tokens involved in the dependency (conjuncts)
and ensure that there is a coordinating conjunc-
tion (e.g., and, or, , (comma), &amp; (ampersand)) be-
tween them. Once such a conjunction is identified,
we then examine the semantic compatibility of the
conjuncts. In the case of entities, the compatibil-
ity involves that at the semantic group level. In the
current work, we also began recognizing distribu-
tive anaphora, such as either, each as anaphoric
expressions. When the recognized anaphoric ex-
pression is plural (as in they, these agents or either
drug), we allow the coordinated structures previ-
ously identified in this fashion as candidate an-
tecedents. The current work does not address a
more complex kind of set/instance anaphora, in
which the instances are not syntactically coordi-
nated, such as in Example (2), where such agents
refer to thiazide diuretics, in the preceding sen-
tence, as well as Potassium-sparing diuretics and
potassium supplements.
(2) ... can attenuate potassium loss caused
by thiazide diuretics. Potassium-sparing
diuretics ... or potassium supplements can
increase .... if concomitant use of
such agents is indicated ...
</bodyText>
<subsectionHeader confidence="0.836232">
3.2.3 Appositive constructions
</subsectionHeader>
<bodyText confidence="0.9062174">
Coreference involving appositive constructions3
are annotated in some corpora, including the
BioNLP shared task coreference dataset (Kim
et al., 2012) and DrugNerAR corpus (Segura-
Bedmar et al., 2010). An example is given below,
in which the indefinite noun phrase a drug and the
drug lovastatin are appositives.
(3) PLETAL does not, however, appear to cause
increased blood levels of drugs metabolized
by CYP3A4, as it had no effect on lovastatin,
a drug with metabolism very sensitive to
CYP3A4 inhibition.
In our dataset, coreference involving apposi-
tive constructions were generally left unannotated.
However, it was consistently the case that when
one of the items in the construction is annotated
as the antecedent for an anaphoric expression,
the other item in the construction was also anno-
tated as such. Therefore, we identified appositive
constructions in text to aid the antecedent selec-
tion task. We used dependency relations for this
task, as well. Identifying appositives is relatively
straightforward using syntactic dependency rela-
tions. We adapted the following rule from Kil-
icoglu and Bergler (2012):
</bodyText>
<equation confidence="0.971916333333333">
APPOS(Antecedent,Anaphor) V
APPOS(Anaphor,Antecedent) ==&gt;-
COREF(Anaphor,Antecedent)
</equation>
<bodyText confidence="0.998774">
where APPOS E {appos, abbrev, prep including,
prep such as}. In our case, this rule becomes
</bodyText>
<equation confidence="0.99617025">
(APPOS(Antecedent1,Antecedent2) V
APPOS(Antecedent2,Antecedent1)) n
COREF(Anaphor,Antecedent1) ==&gt;-
COREF(Anaphor,Antecedent2)
</equation>
<bodyText confidence="0.998364090909091">
which essentially states that a candidate is taken as
an antecedent, only if its appositive has been rec-
ognized as an antecedent. Additionally, semantic
compatibility between the items is required.
This allows us to identify their and Class Ia an-
tiarrhythmic drugs as co-referents in the following
example, due to the fact that the exemplification
indicated by the appositive construction between
Class Ia antiarrythmic drugs and disopyramide is
recognized, the latter previously identified as an
antecedent for their.
</bodyText>
<footnote confidence="0.7649085">
3We use the term “appositive” to cover exemplifications,
as well.
</footnote>
<page confidence="0.994345">
48
</page>
<listItem confidence="0.9989184">
(4) Class Ia antiarrhythmic drugs, such as
disopyramide, quinidine and procainamide
and other Class III drugs (e.g., amiodarone)
are not recommended ... because of their
potential to prolong refractoriness.
</listItem>
<subsectionHeader confidence="0.530818">
3.2.4 Relative pronouns
</subsectionHeader>
<bodyText confidence="0.999283833333333">
Similar to appositive constructions, relative pro-
nouns are annotated as anaphoric expressions in
some corpora (same as those for appositives), but
not in our dataset. In the example below, the rela-
tive pronoun which refers to potassium-containing
salt substitutes.
</bodyText>
<listItem confidence="0.92777">
(5) ... the concomitant use of potassium-sparing
diuretics, potassium supplements, and/or
potassium-containing salt substitutes, which
should be used cautiously.. .
</listItem>
<bodyText confidence="0.999967">
Since we aim for generality and this type of
anaphora can be important for downstream ap-
plications, we implemented a rule, again taken
from Kilicoglu and Bergler (2012), which simply
states that the antecedent of a relative pronominal
anaphora is the noun phrase head it modifies.
</bodyText>
<equation confidence="0.9911395">
rel(X,Anaphor) n rcmod(Antecedent,X) ==&gt;.
COREF(Anaphor,Antecedent)
</equation>
<bodyText confidence="0.9995945">
where rel indicates a relative dependency, and rc-
mod a relative clause modifier dependency. We
extended this in the current work to include the
following rules:
</bodyText>
<listItem confidence="0.993860333333333">
(6) (a) LEFT(Antecedent,Anaphor) n
NO INT WORD(Antecedent,Anaphor)
==&gt;. COREF(Anaphor,Antecedent)
(b) LEFT(Antecedent,Anaphor) n rc-
mod(Antecedent,X) n LEFT(Anaphor,X)
==&gt;. COREF(Anaphor,Antecedent)
</listItem>
<bodyText confidence="0.99917475">
where LEFT indicates that the first argument is
to the left of the second and NO INT WORD in-
dicates that the arguments have no intervening
words between them.
</bodyText>
<subsectionHeader confidence="0.997989">
3.3 Drug ingredient/brand name synonymy
</subsectionHeader>
<bodyText confidence="0.994707875">
A specific, non-anaphoric type of coreference,
between drug ingredient name and drug’s brand
name, is commonly annotated in our dataset. An
example is provided below, where COREG CR is
the brand name for carvedilol.
(7) The concomitant administration of amio-
darone or other CYP2C9 inhibitors such as
fluconazole with COREG CR may enhance
the -blocking properties of carvedilol ....
To identify this type of coreference, we use se-
mantic information from UMLS Metathesaurus.
We stipulate that, to qualify as co-referents, both
terms under consideration should map to the same
UMLS concept (i.e., that they are considered syn-
onyms). If the terms are within the same sentence,
we further require that they are appositive.
</bodyText>
<subsectionHeader confidence="0.915056">
3.3.1 Demonstrative pronouns
</subsectionHeader>
<bodyText confidence="0.999464461538462">
Anaphoric expressions of demonstrative pronoun
type generally have discourse-deictic use; in other
words, they often refer to events, propositions de-
scribed in prior discourse or even to the full sen-
tences or paragraphs, rather than concrete objects
or entities (Webber, 1988). This fact was implic-
itly exploited in consumer health questions, since
the coreference resolution focused on diseases
only, which are essentially processes. However,
in drug labels, discourse-deictic use of demonstra-
tives is much more overt. Consider the sentence
below, where the demonstrative This refers to the
event of increasing the exposure to lovastatin.
</bodyText>
<listItem confidence="0.714385">
(8) Co-administration of lovastatin and SAMSCA
</listItem>
<bodyText confidence="0.962677">
increases the exposure to lovastatin and ....
This is not a clinically relevant change.
To handle such cases, we blocked entity an-
tecedents (such as drugs) for demonstrative pro-
nouns and only allowed predicates (verbs, nomi-
nalizations) as candidate antecedents.
</bodyText>
<subsubsectionHeader confidence="0.752486">
3.3.2 Pleonastic it
</subsubsectionHeader>
<bodyText confidence="0.999815875">
We recognized pleonastic instances of the pronoun
it to disqualify them as anaphoric expressions (for
instance, it in It may be necessary to ... ). Gen-
erally, lexical patterns involving sequence of to-
kens are used to recognize such instances (e.g.,
(Segura-Bedmar et al., 2010). We used a simple
dependency-based rule that mimics these patterns,
given below.
</bodyText>
<equation confidence="0.607524">
nsubj*(X,it) n DEP(X,Y) ==&gt;. PLEONASTIC(it)
</equation>
<bodyText confidence="0.999456333333333">
where nsubj* refers to nsubj or nsubjpass depen-
dencies and DEP is any dependency, where DEP
V {infmod, ccomp, xcomp}.
</bodyText>
<subsectionHeader confidence="0.685461">
3.3.3 Discourse-based constraints
</subsectionHeader>
<bodyText confidence="0.9998418">
Previously, we did not impose limits on how far
the co-referents could be from each other, since
the entire discourse was generally short and the
salient antecedent (often the topic of the question)
appeared early in discourse. This is often not the
</bodyText>
<page confidence="0.998754">
49
</page>
<bodyText confidence="0.999974866666667">
case in drug labels, especially because often intri-
cate interactions between the drug of interest and
other medications are discussed. Therefore, we
limit the discourse window from which candidate
antecedents are identified. Generally, the search
space for the antecedents is limited to the current
sentence as well as the two preceding sentences
(Segura-Bedmar et al., 2010; Nguyen et al., 2012).
In our dataset, we found that 98% of antecedents
occurred within this discourse window and, thus,
use the same search space. We make an exception
for the cases in which the anaphoric expression ap-
pear in the first sentence of a paragraph and no
compatible antecedent is found in the same sen-
tence. In this case, the search space is expanded to
the entire preceding paragraph.
We also extended the system to include different
types of salience scoring methods. For drug labels,
we use linear distance between the co-referents (in
terms of surface elements) as the salience score;
the lower this score, the better candidate the an-
tecedent is. Additionally, we implemented syn-
tactic tree distance between the co-referents as a
potential salience measure, even though this type
of salience scoring did not have an effect on our
results on drug labels.
Finally, we block candidate antecedents that
are in a direct syntactic dependency with the
anaphoric expression, except when the anaphor is
reflexive (e.g., itself).
</bodyText>
<subsectionHeader confidence="0.844806">
3.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.999973416666666">
To evaluate our approach, we used a baseline simi-
lar to that reported in Segura-Bedmar et al. (2010),
which consists of selecting the closest preceding
nominal phrase for the anaphoric expressions an-
notated in their corpus. These expressions in-
clude pronominal (personal, relative, demonstra-
tive, etc.) and nominal (definite, possessive,
etc.) anaphora. We compared our system to
this baseline using the unweighted average of F1-
measure over B-CUBED (Bagga and Baldwin,
1998), MUC (Vilain et al., 1995), and CEAF (Luo,
2005) metrics, the standard evaluation metrics for
coreference resolution. We used the scripts pro-
vided by i2b2 shared task organizers for this pur-
pose. Since coreference annotation was parsimo-
nious in our dataset, we also manually examined a
subset of the coreference relations extracted by the
system for precision. Additionally, we tested our
system on DrugNerAR corpus (Segura-Bedmar et
al., 2010), which similarly focuses on drug inter-
actions. We compared our results to theirs, us-
ing as evaluation metrics precision, recall, and F1-
measure, the metrics that were used in their evalu-
ation.
</bodyText>
<sectionHeader confidence="0.998833" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999704967741936">
With the drug label dataset, we obtained the best
results without relative pronominal anaphora reso-
lution and drug ingredient/brand name synonymy
strategies (OPTIMAL) and with linear distance
as the salience measure. In this setting, using
gold entity annotations, we recognized 318 coref-
erence chains, 54 of which were annotated in the
corpus. The baseline identified 1415 coreference
chains, only 10 of which were annotated. The im-
provement provided by the system over the base-
line is clear; however, the low precision/recall/F1-
measure, given in Table 1, should be taken with
caution due to the sparse coreference annotation
in the dataset. To get a better sense of how well
our system performs, we also performed end-to-
end coreference resolution and manually assessed
a subset of the system output (22 randomly se-
lected drug labels with 249 coreference instances).
Of these 249, 181 were deemed correct, yielding a
precision of 0.73. The baseline method extracted
1439 instances, 56 of which were deemed cor-
rect, yielding a precision of 0.04. The precision
of our method is more in line with what has been
reported in the literature (Segura-Bedmar et al.,
2010; Nguyen et al., 2012). For i2b2-style eval-
uation using the unweighted average F1 measure
over B-CUBED, MUC, and CEAF metrics, we
considered both exact and partial mention overlap.
These results, provided in Table 1, also indicate
that the system provides a clear improvement over
the baseline.
</bodyText>
<table confidence="0.998522777777778">
Metric Baseline OPTIMAL
With gold entity annotations
Unweighted F1 Partial 0.55 0.77
Unweighted F1 Exact 0.66 0.78
Precision 0.01 0.17
Recall 0.04 0.26
F1-measure 0.01 0.21
End-to-end coreference resolution
Precision 0.04 0.73
</table>
<tableCaption confidence="0.999904">
Table 1: Evaluation results on drug labels
</tableCaption>
<page confidence="0.992716">
50
</page>
<tableCaption confidence="0.670419">
We also assessed the effect of various resolution
strategies on results. These results are presented in
Table 2.
</tableCaption>
<table confidence="0.9997872">
Strategy Fl-measure
OPTIMAL 0.21
OPTIMAL - SIA 0.21
OPTIMAL - APPOS 0.15
OPTIMAL + DIBS 0.16 (0.39 recall)
</table>
<tableCaption confidence="0.999447">
Table 2: Effect of coreference strategies
</tableCaption>
<bodyText confidence="0.9983025">
Disregarding set/instance anaphora resolution
(SIA) does not appear to affect the results by
much; however, this is mostly due to the fact that
the “instance” mentions are generally exemplifica-
tions of a particular drug class which also appear
in text. In the absence of set/instance anaphora
resolution, the system often defaults to these drug
class mentions, which were annotated more often
than not, unlike the “instance” mentions. Take the
following example:
</bodyText>
<listItem confidence="0.6047422">
(9) Use of ZESTRIL with potassium-sparing
diuretics (e.g., spironolactone, eplerenone,
triamterene or amiloride) ... may lead to sig-
nificant increases ... if concomitant use of
these agents ...
</listItem>
<bodyText confidence="0.999382041095891">
Without set-instance anaphora resolution, the sys-
tem links these agents to potassium-sparing di-
uretics, an annotated relation. With set-instance
anaphora resolution, the same expression is linked
to individual drug names (spironolactone, etc.) as
well as the the drug class, creating a number of
false positives, which, in effect, offsets the im-
provement provided by this strategy.
On the other hand, recognizing appositive con-
structions (APPOS) appears to have a larger im-
pact; however, it should be noted that this is mostly
because it helps us expand the antecedent mention
list in the case of set/instance anaphora. For in-
stance, in Example (9), this strategy allows us to
establish the link between the anaphora and the
drug class (diuretics), since the drug class and in-
dividual drug name (spironolactone) are identified
earlier as appositive. We can conclude that, in gen-
eral, set/instance anaphora benefits from recogni-
tion of appositive constructions.
Recognizing drug ingredient/brand name syn-
onymy (DIBS) improved the recall and hurt the
precision significantly, the overall effect being
negative. Since this non-anaphoric type of coref-
erence is strictly semantic in nature and resources
from which this type of semantic information can
be derived already exist (UMLS, among others), it
is perhaps not of utmost importance that a coref-
erence resolution system recognizes such corefer-
ence.
We additionally processed the DrugNerAR cor-
pus with our system. The optimal setting for
this corpus was disregarding the drug ingredi-
ent/brand name synonymy but using relative pro-
noun anaphora resolution, based on the discus-
sion in Segura-Bedmar et al. (2010). Somewhat to
our surprise, our system did not fare well on this
corpus. We extracted 524 chains, 327 of which
(out of 669) were annotated in the corpus, yield-
ing a precision of 0.71, recall of 0.56, and Fl-
measure of 0.63. This is about 20% lower than
their reported results. When we used their base-
line method (explained earlier), we obtained simi-
larly lower scores (precision of 0.18, recall of 0.45,
Fl-measure of 0.26, about 40% lower than their
reported results). In light of this apparent discrep-
ancy, which clearly warrants further investigation,
it is perhaps more sensible to focus on “improve-
ment over baseline” (reported as 73% in their pa-
per and is 140% in our case).
We analyzed some of the annotations more
closely to get a better sense of the shortcomings
of the system. The majority of errors were due to
using linear distance as the salience score. For in-
stance, in the following example, they is linked to
ACE inhibitors due to proximity, whereas the true
antecedent is these reactions (itself an anaphor and
is presumably linked to another antecedent). It
could be possible to recover this link using prin-
ciples of Centering Theory (Grosz et al., 1995),
which suggests that subjects are more central than
objects and adjuncts in an utterance. Following
this principle, the subject (these reactions) would
be preferred to ACE inhibitors as the antecedent.
(10) In the same patients, these reactions were
avoided when ACE inhibitors were temporar-
ily withheld, but they reappeared upon inad-
vertent rechallenge.
Semantic (but not syntactic) coordination some-
times leads to number disagreement between the
anaphora and a true antecedent, as shown in Ex-
ample (11), leading to false negatives. In this ex-
ample, such diuretics refers to both ALDACTONE
</bodyText>
<page confidence="0.994809">
51
</page>
<bodyText confidence="0.9819725">
and a second diuretic; however, we are unable to
identify the link between them and the number dis-
agreement between the anaphora and either of the
antecedents blocks a potential coreference relation
between these items.
(11) If, after five days, an adequate diuretic re-
sponse to ALDACTONE has not occurred,
a second diuretic that acts more proximally
in the renal tubule may be added to the reg-
imen. Because of the additive effect of AL-
DACTONE when administered concurrently
with such diuretics ...
</bodyText>
<sectionHeader confidence="0.99864" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9997445">
We presented a coreference resolution system en-
hanced based on insights from a dataset of FDA
drug package inserts. Sparse coreference annota-
tion in the dataset presented difficulties in evaluat-
ing the results; however, based on various eval-
uation strategies, the performance improvement
due to the enhancements seems evident. Our re-
sults show that recognizing coordination and ap-
positive constructions are particularly useful and
that non-anaphoric cases of coreference can be
identified using synonymy in semantic resources,
such as UMLS. However, whether this is a task
for a coreference resolution system or a concept
normalization system is debatable. We exper-
imented with using hierarchical domain knowl-
edge in UMLS (for example, the knowledge that
lisinopril ISA angiotensin converting enzyme in-
hibitor) to resolve some cases of sortal anaphora.
Even though we did not see an improvement due
to using this type of information on our dataset,
further work is needed to assess its usefulness.
While the enhancements were evaluated on drug
labels only, they are not specific to this type of
text. Their portability to different text types is
limited only by the accuracy of underlying tools,
such as parsers, for the text type of interest and
the availability of domain knowledge in the form
of relevant semantic types, groups, hypernyms
for the entity types under consideration. The re-
sults also indicate that a more rigorous application
of syntactic constraints in the spirit of Centering
Theory (Grosz et al., 1995) could be beneficial.
Event (or clausal) anaphora and anaphora indicat-
ing discourse deixis, while rarely annotated in our
dataset, appear to occur fairly often in biomedical
text. These types of anaphora are known to be par-
ticularly challenging, and we plan to investigate
them in future research, as well.
</bodyText>
<sectionHeader confidence="0.987894" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999057666666667">
This work was supported by the intramural re-
search program at the U.S. National Library of
Medicine, National Institutes of Health.
</bodyText>
<sectionHeader confidence="0.997801" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999555813953488">
Alan R. Aronson and Franc¸ois-Michel Lang. 2010. An
overview of MetaMap: historical perspective and re-
cent advances. Journal of the American Medical In-
formatics Association (JAMIA), 17(3):229–236.
Amit Bagga and Breck Baldwin. 1998. Algorithms
for scoring coreference chains. In The First Interna-
tional Conference on Language Resources and Eval-
uation Workshop on Linguistics Coreference, pages
563–566.
James J. Cimino, Tiffani J. Bright, and Jianhua Li.
2007. Medication reconciliation using natural lan-
guage processing and controlled terminologies. In
Klaus A. Kuhn, James R. Warren, and Tze-Yun
Leong, editors, MedInfo, volume 129 of Studies in
Health Technology and Informatics, pages 679–683.
IOS Press.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of the 5th International Conference on
Language Resources and Evaluation, pages 449–
454.
Dina Demner-Fushman, Wendy W. Chapman, and
Clem J. McDonald. 2009. What can natural lan-
guage processing do for clinical decision support?
Journal of Biomedical Informatics, 5(42):760–762.
Jon Duke, Jeff Friedlin, and Patrick Ryan. 2011. A
quantitative analysis of adverse events and ”over-
warning” in drug labeling. Archives of internal
medicine, 10(171):944–946.
Peter L. Elkin, John S. Carter, Manasi Nabar, Mark
Tuttle, Michael Lincoln, and Steven H. Brown.
2011. Drug knowledge expressed as computable se-
mantic triples. Studies in health technology and in-
formatics, (166):38–47.
Kin Wah Fung, Chiang S. Jao, and Dina Demner-
Fushman. 2013. Extracting drug indication infor-
mation from structured product labels using natural
language processing. JAMIA, 20(3):482–488.
Barbara J. Grosz, Scott Weinstein, and Aravind K.
Joshi. 1995. Centering: a framework for model-
ing the local coherence of discourse. Computational
Linguistics, 21(2):203–225.
</reference>
<page confidence="0.973836">
52
</page>
<reference confidence="0.999843417475728">
Marfa Herrero-Zazo, Isabel Segura-Bedmar, Paloma
Martfnez, and Thierry Declerck. 2013. The DDI
corpus: An annotated corpus with pharmacological
substances and drug-drug interactions. Journal of
Biomedical Informatics, 46(5):914–920.
Halil Kilicoglu and Sabine Bergler. 2012. Biolog-
ical Event Composition. BMC Bioinformatics, 13
(Suppl 11):S7.
Halil Kilicoglu, Marcelo Fiszman, and Dina Demner-
Fushman. 2013. Interpreting consumer health ques-
tions: The role of anaphora and ellipsis. In Proceed-
ings of the 2013 Workshop on Biomedical Natural
Language Processing, pages 54–62.
Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun’ichi Tsu-
jii, Toshihisa Takagi, and Akinori Yonezawa. 2012.
The Genia Event and Protein Coreference tasks of
the BioNLP Shared Task 2011. BMC Bioinformat-
ics, 13(Suppl 11):S1.
Qi Li, Louise Deleger, Todd Lingren, Haijun Zhai,
Megan Kaiser, Laura Stoutenborough, Anil G.
Jegga, Kevin B. Cohen, and Imre Solti. 2013. Min-
ing FDA drug labels for medical conditions. BMC
medical informatics and decision making, 13(1):53.
Donald A. B. Lindberg, Betsy L. Humphreys, and
Alexa T. McCray. 1993. The Unified Medical Lan-
guage System. Methods of Information in Medicine,
32:281–291.
Xiaoqiang Luo. 2005. On coreference resolution
performance metrics. In In Proc. of HLT/EMNLP,
pages 25–32.
Alexa T. McCray, Anita Burgun, and Olivier Boden-
reider. 2001. Aggregating UMLS semantic types
for reducing conceptual complexity. Proceedings of
Medinfo, 10(pt 1):216–20.
Makoto Miwa, Paul Thompson, and Sophia Ana-
niadou. 2012. Boosting automatic event ex-
traction from the literature using domain adapta-
tion and coreference resolution. Bioinformatics,
28(13):1759–1765.
Ngan L. T. Nguyen, Jin-Dong Kim, Makoto Miwa,
Takuya Matsuzaki, and Junichi Tsujii. 2012. Im-
proving protein coreference resolution by simple se-
mantic classification. BMC Bioinformatics, 13:304.
Philip V. Ogren. 2010. Improving Syntactic Coor-
dination Resolution using Language Modeling. In
NAACL (Student Research Workshop), pages 1–6.
The Association for Computational Linguistics.
T.I. Oprea, S.K. Nielsen, O. Ursu, J.J. Yang,
O. Taboureau, S.L. Mathias, L. Kouskoumvekaki,
L.A. Sklar, and C.G. Bologa. 2011. Associat-
ing Drugs, Targets and Clinical Outcomes into an
Integrated Network Affords a New Platform for
Computer-Aided Drug Repurposing. Molecular in-
formatics, 2-3(30):100–111.
Thomas C. Rindflesch, Lorrie Tanabe, John N. We-
instein, and Lawrence Hunter. 2000. EDGAR:
Extraction of drugs, genes, and relations from the
biomedical literature. In Proceedings of Pacific
Symposium on Biocomputing, pages 514–525.
Isabel Segura-Bedmar, Mario Crespo, C´esar de Pablo-
S´anchez, and Paloma Martfnez. 2010. Resolving
anaphoras for the extraction of drug-drug interac-
tions in pharmacological documents. BMC Bioin-
formatics, 11 (Suppl 2):S1.
J.C. Smith, J.C. Denny, Q. Chen, H. Nian, A. 3rd
Spickard, S.T. Rosenbloom, and R. A. Miller. 2011.
Lessons learned from developing a drug evidence
base to support pharmacovigilance. Applied clinical
informatics, 4(4):596–617.
¨Ozlem Uzuner, Imre Solti, and Eithon Cadag. 2010.
Extracting medication information from clinical
text. JAMIA, 17(5):514–518.
¨Ozlem Uzuner, Andrea Bodnari, Shuying Shen, Tyler
Forbush, John Pestian, and Brett R. South. 2012.
Evaluating the state of the art in coreference res-
olution for electronic medical records. JAMIA,
19(5):786–791.
Marc B. Vilain, John D. Burger, John S. Aberdeen,
Dennis Connolly, and Lynette Hirschman. 1995.
A model-theoretic coreference scoring scheme. In
MUC, pages 45–52.
Bonnie L. Webber. 1988. Discourse Deixis: Reference
to Discourse Segments. In ACL, pages 113–122.
Rong Xu and QuanQiu Wang. 2014. Large-scale com-
bining signals from both biomedical literature and
the FDA Adverse Event Reporting System (FAERS)
to improve post-marketing drug safety signal detec-
tion. BMC Bioinformatics, 15:17.
Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hi-
rao, Masayuki Asahara, and Yuji Matsumoto. 2011.
Coreference Based Event-Argument Relation Ex-
traction on Biomedical Text. Journal of Biomedical
Semantics, 2 (Suppl 5):S6.
Jiaping Zheng, Wendy W. Chapman, Rebecca S. Crow-
ley, and Guergana K. Savova. 2011. Corefer-
ence resolution: A review of general methodologies
and applications in the clinical domain. Journal of
Biomedical Informatics, 44(6):1113–1122.
Qian Zhu, Robert R. Freimuth, Jyotishman Pathak,
Matthew J. Durski, and Christopher G. Chute. 2013.
Disambiguation of PharmGKB drug-disease rela-
tions with NDF-RT and SPL. Journal of Biomedical
Informatics, 46(4):690–696.
</reference>
<page confidence="0.999347">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.370034">
<title confidence="0.999191">Coreference Resolution for Structured Drug Product Labels</title>
<author confidence="0.758134">Halil Kilicoglu</author>
<author confidence="0.758134">Dina</author>
<affiliation confidence="0.8837405">National Library of National Institutes of</affiliation>
<address confidence="0.52439">Bethesda, MD,</address>
<abstract confidence="0.996354142857143">FDA drug package inserts provide comprehensive and authoritative information about drugs. DailyMed database is a repository of structured product labels extracted from these package inserts. Most salient information about drugs remains in free text portions of these labels. Extracting information from these portions can improve the safety and quality of drug prescription. In this paper, we present a study that focuses on resolution of coreferential information from drug labels contained in DailyMed. We generalized and expanded an existing rule-based coreference resolution module for this purpose. Enhancements include resolution of set/instance anaphora, recognition of appositive constructions and wider use of UMLS semantic knowledge. We obtained an improvement of 40% over the baseline unweighted average using B-CUBED, MUC, and CEAF metrics. The results underscore the importance of set/instance anaphora and appositive constructions in this type of text and point out the shortcomings in coreference annotation in the dataset.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan R Aronson</author>
<author>Franc¸ois-Michel Lang</author>
</authors>
<title>An overview of MetaMap: historical perspective and recent advances.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association (JAMIA),</journal>
<volume>17</volume>
<issue>3</issue>
<contexts>
<context position="6956" citStr="Aronson and Lang, 2010" startWordPosition="1043" endWordPosition="1046">vailable text sources that could be used to augment a repository of drug indications and adverse effects (ADEs), Smith et al. (2011) concluded that many indication and adverse drug event relationships in the drug labels are too complex to be captured in the existing databases of interactions and ADEs. Despite the complexity, the labels were used to extract indications for drugs in several studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the quality of the mappings. Oprea et al. (2011) used information extracted from the adverse reactions sections of 988 drugs for computer-aided drug repurposing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB </context>
</contexts>
<marker>Aronson, Lang, 2010</marker>
<rawString>Alan R. Aronson and Franc¸ois-Michel Lang. 2010. An overview of MetaMap: historical perspective and recent advances. Journal of the American Medical Informatics Association (JAMIA), 17(3):229–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In The First International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference,</booktitle>
<pages>563--566</pages>
<contexts>
<context position="23612" citStr="Bagga and Baldwin, 1998" startWordPosition="3571" endWordPosition="3574">edents that are in a direct syntactic dependency with the anaphoric expression, except when the anaphor is reflexive (e.g., itself). 3.4 Evaluation To evaluate our approach, we used a baseline similar to that reported in Segura-Bedmar et al. (2010), which consists of selecting the closest preceding nominal phrase for the anaphoric expressions annotated in their corpus. These expressions include pronominal (personal, relative, demonstrative, etc.) and nominal (definite, possessive, etc.) anaphora. We compared our system to this baseline using the unweighted average of F1- measure over B-CUBED (Bagga and Baldwin, 1998), MUC (Vilain et al., 1995), and CEAF (Luo, 2005) metrics, the standard evaluation metrics for coreference resolution. We used the scripts provided by i2b2 shared task organizers for this purpose. Since coreference annotation was parsimonious in our dataset, we also manually examined a subset of the coreference relations extracted by the system for precision. Additionally, we tested our system on DrugNerAR corpus (Segura-Bedmar et al., 2010), which similarly focuses on drug interactions. We compared our results to theirs, using as evaluation metrics precision, recall, and F1- measure, the metr</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In The First International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference, pages 563–566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James J Cimino</author>
<author>Tiffani J Bright</author>
<author>Jianhua Li</author>
</authors>
<title>Medication reconciliation using natural language processing and controlled terminologies.</title>
<date>2007</date>
<booktitle>of Studies in Health Technology and Informatics,</booktitle>
<volume>129</volume>
<pages>679--683</pages>
<editor>In Klaus A. Kuhn, James R. Warren, and Tze-Yun Leong, editors, MedInfo,</editor>
<publisher>IOS Press.</publisher>
<contexts>
<context position="2974" citStr="Cimino et al., 2007" startWordPosition="435" endWordPosition="438">an facilitate automatic timely updates to databases that support Electronic Health Records in alerting physicians to potential drug interactions, recommended doses, and contraindications. Natural language processing methods are increasingly used to support various clinical and biomedical applications (Demner-Fushman et al., 2009). Extraction of drug information is playing a prominent role in these applications and research. In addition to earlier research in extraction of medications and relations involving medications from clinical text and the biomedical literature (Rindflesch et al., 2000; Cimino et al., 2007), in the third i2b2 shared task (Uzuner et al., 2010), 23 organizations have explored extraction of medications, their dosages, routes of administration, frequencies, durations, and reasons for administration from clinical text. The best performing systems used rule-based and machine learning techniques to achieve over 0.8 F-measure for extraction of medication names; however, the remaining information was harder to extract. Researchers have also tackled extraction of drug-drug interactions (Herrero-Zazo et al., 2013), side effects (Xu and Wang, 2014), and indications (Fung et al., 2013) from </context>
</contexts>
<marker>Cimino, Bright, Li, 2007</marker>
<rawString>James J. Cimino, Tiffani J. Bright, and Jianhua Li. 2007. Medication reconciliation using natural language processing and controlled terminologies. In Klaus A. Kuhn, James R. Warren, and Tze-Yun Leong, editors, MedInfo, volume 129 of Studies in Health Technology and Informatics, pages 679–683. IOS Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>449--454</pages>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the 5th International Conference on Language Resources and Evaluation, pages 449– 454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dina Demner-Fushman</author>
<author>Wendy W Chapman</author>
<author>Clem J McDonald</author>
</authors>
<title>What can natural language processing do for clinical decision support?</title>
<date>2009</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>5</volume>
<issue>42</issue>
<contexts>
<context position="2685" citStr="Demner-Fushman et al., 2009" startWordPosition="391" endWordPosition="394">from the structured fields of the XML documents. However, the salient content about indications, side effects and drug-drug interactions, among others, is buried in the free text of the corresponding sections of the labels. Extracting this information with natural language processing techniques can facilitate automatic timely updates to databases that support Electronic Health Records in alerting physicians to potential drug interactions, recommended doses, and contraindications. Natural language processing methods are increasingly used to support various clinical and biomedical applications (Demner-Fushman et al., 2009). Extraction of drug information is playing a prominent role in these applications and research. In addition to earlier research in extraction of medications and relations involving medications from clinical text and the biomedical literature (Rindflesch et al., 2000; Cimino et al., 2007), in the third i2b2 shared task (Uzuner et al., 2010), 23 organizations have explored extraction of medications, their dosages, routes of administration, frequencies, durations, and reasons for administration from clinical text. The best performing systems used rule-based and machine learning techniques to ach</context>
</contexts>
<marker>Demner-Fushman, Chapman, McDonald, 2009</marker>
<rawString>Dina Demner-Fushman, Wendy W. Chapman, and Clem J. McDonald. 2009. What can natural language processing do for clinical decision support? Journal of Biomedical Informatics, 5(42):760–762.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Duke</author>
<author>Jeff Friedlin</author>
<author>Patrick Ryan</author>
</authors>
<title>A quantitative analysis of adverse events and ”overwarning” in drug labeling. Archives of internal medicine,</title>
<date>2011</date>
<pages>10--171</pages>
<contexts>
<context position="7238" citStr="Duke et al. (2011)" startWordPosition="1088" endWordPosition="1091">tions and ADEs. Despite the complexity, the labels were used to extract indications for drugs in several studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the quality of the mappings. Oprea et al. (2011) used information extracted from the adverse reactions sections of 988 drugs for computer-aided drug repurposing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, uses conditional random fields and post-processing rules to extract medical conditions from SPLs and build triplets in the form of([drug name]-[medical condition]-[LOINC section header]) (Li et al., 2013). Corefer</context>
</contexts>
<marker>Duke, Friedlin, Ryan, 2011</marker>
<rawString>Jon Duke, Jeff Friedlin, and Patrick Ryan. 2011. A quantitative analysis of adverse events and ”overwarning” in drug labeling. Archives of internal medicine, 10(171):944–946.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter L Elkin</author>
<author>John S Carter</author>
<author>Manasi Nabar</author>
<author>Mark Tuttle</author>
<author>Michael Lincoln</author>
<author>Steven H Brown</author>
</authors>
<title>Drug knowledge expressed as computable semantic triples.</title>
<date>2011</date>
<booktitle>Studies in health technology and informatics,</booktitle>
<pages>166--38</pages>
<contexts>
<context position="6753" citStr="Elkin et al. (2011)" startWordPosition="1013" endWordPosition="1016">, despite their availability and the wealth of information contained within them, remain underutilized. One of the reasons might be the complexity of the text in the labels: in a review of publicly available text sources that could be used to augment a repository of drug indications and adverse effects (ADEs), Smith et al. (2011) concluded that many indication and adverse drug event relationships in the drug labels are too complex to be captured in the existing databases of interactions and ADEs. Despite the complexity, the labels were used to extract indications for drugs in several studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the quality of the mappings. Oprea et al. (2011) used information extracted from the adverse reactions sections of 988 drugs for computer-aided drug repurposing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease</context>
</contexts>
<marker>Elkin, Carter, Nabar, Tuttle, Lincoln, Brown, 2011</marker>
<rawString>Peter L. Elkin, John S. Carter, Manasi Nabar, Mark Tuttle, Michael Lincoln, and Steven H. Brown. 2011. Drug knowledge expressed as computable semantic triples. Studies in health technology and informatics, (166):38–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kin Wah Fung</author>
<author>Chiang S Jao</author>
<author>Dina DemnerFushman</author>
</authors>
<title>Extracting drug indication information from structured product labels using natural language processing.</title>
<date>2013</date>
<journal>JAMIA,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="3568" citStr="Fung et al., 2013" startWordPosition="526" endWordPosition="529">00; Cimino et al., 2007), in the third i2b2 shared task (Uzuner et al., 2010), 23 organizations have explored extraction of medications, their dosages, routes of administration, frequencies, durations, and reasons for administration from clinical text. The best performing systems used rule-based and machine learning techniques to achieve over 0.8 F-measure for extraction of medication names; however, the remaining information was harder to extract. Researchers have also tackled extraction of drug-drug interactions (Herrero-Zazo et al., 2013), side effects (Xu and Wang, 2014), and indications (Fung et al., 2013) from various biomedical resources. As for many other information extraction tasks, 2DailyMed: http://dailymed.nlm.nih.gov/dailymed/about.cfm 45 Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 45–53, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics extracting drug information is often made more difficult by coreference. Coreference is defined as the relation between linguistic expressions that are referring to the same entity (Zheng et al., 2011). Coreference resolution is a fundamental task in NLP and ca</context>
<context position="6918" citStr="Fung et al. (2013)" startWordPosition="1037" endWordPosition="1040">labels: in a review of publicly available text sources that could be used to augment a repository of drug indications and adverse effects (ADEs), Smith et al. (2011) concluded that many indication and adverse drug event relationships in the drug labels are too complex to be captured in the existing databases of interactions and ADEs. Despite the complexity, the labels were used to extract indications for drugs in several studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the quality of the mappings. Oprea et al. (2011) used information extracted from the adverse reactions sections of 988 drugs for computer-aided drug repurposing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships i</context>
</contexts>
<marker>Fung, Jao, DemnerFushman, 2013</marker>
<rawString>Kin Wah Fung, Chiang S. Jao, and Dina DemnerFushman. 2013. Extracting drug indication information from structured product labels using natural language processing. JAMIA, 20(3):482–488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Scott Weinstein</author>
<author>Aravind K Joshi</author>
</authors>
<title>Centering: a framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="29759" citStr="Grosz et al., 1995" startWordPosition="4550" endWordPosition="4553">, it is perhaps more sensible to focus on “improvement over baseline” (reported as 73% in their paper and is 140% in our case). We analyzed some of the annotations more closely to get a better sense of the shortcomings of the system. The majority of errors were due to using linear distance as the salience score. For instance, in the following example, they is linked to ACE inhibitors due to proximity, whereas the true antecedent is these reactions (itself an anaphor and is presumably linked to another antecedent). It could be possible to recover this link using principles of Centering Theory (Grosz et al., 1995), which suggests that subjects are more central than objects and adjuncts in an utterance. Following this principle, the subject (these reactions) would be preferred to ACE inhibitors as the antecedent. (10) In the same patients, these reactions were avoided when ACE inhibitors were temporarily withheld, but they reappeared upon inadvertent rechallenge. Semantic (but not syntactic) coordination sometimes leads to number disagreement between the anaphora and a true antecedent, as shown in Example (11), leading to false negatives. In this example, such diuretics refers to both ALDACTONE 51 and a</context>
</contexts>
<marker>Grosz, Weinstein, Joshi, 1995</marker>
<rawString>Barbara J. Grosz, Scott Weinstein, and Aravind K. Joshi. 1995. Centering: a framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marfa Herrero-Zazo</author>
<author>Isabel Segura-Bedmar</author>
<author>Paloma Martfnez</author>
<author>Thierry Declerck</author>
</authors>
<title>The DDI corpus: An annotated corpus with pharmacological substances and drug-drug interactions.</title>
<date>2013</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="3497" citStr="Herrero-Zazo et al., 2013" startWordPosition="514" endWordPosition="517">cations from clinical text and the biomedical literature (Rindflesch et al., 2000; Cimino et al., 2007), in the third i2b2 shared task (Uzuner et al., 2010), 23 organizations have explored extraction of medications, their dosages, routes of administration, frequencies, durations, and reasons for administration from clinical text. The best performing systems used rule-based and machine learning techniques to achieve over 0.8 F-measure for extraction of medication names; however, the remaining information was harder to extract. Researchers have also tackled extraction of drug-drug interactions (Herrero-Zazo et al., 2013), side effects (Xu and Wang, 2014), and indications (Fung et al., 2013) from various biomedical resources. As for many other information extraction tasks, 2DailyMed: http://dailymed.nlm.nih.gov/dailymed/about.cfm 45 Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 45–53, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics extracting drug information is often made more difficult by coreference. Coreference is defined as the relation between linguistic expressions that are referring to the same entity (Zheng et</context>
</contexts>
<marker>Herrero-Zazo, Segura-Bedmar, Martfnez, Declerck, 2013</marker>
<rawString>Marfa Herrero-Zazo, Isabel Segura-Bedmar, Paloma Martfnez, and Thierry Declerck. 2013. The DDI corpus: An annotated corpus with pharmacological substances and drug-drug interactions. Journal of Biomedical Informatics, 46(5):914–920.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Halil Kilicoglu</author>
<author>Sabine Bergler</author>
</authors>
<title>Biological Event Composition.</title>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<volume>13</volume>
<note>(Suppl 11):S7.</note>
<contexts>
<context position="8535" citStr="Kilicoglu and Bergler (2012)" startWordPosition="1290" endWordPosition="1293">b2/VA shared task (Uzuner et al., 2012), and the 2011 BioNLP Shared Task (Kim et al., 2012); however these community-wide evaluations did not change much the observation in the 2011 review by Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to aid the task of biological event extraction. Similarly, Miwa et al. (2012) and Kilicoglu and Bergler (2012) extended their biological event 46 extraction pipelines using rule-based coreference systems that rely on syntactic information and predicate argument structures. Nguyen et al. (2012) evaluated contribution of discourse preference, number agreement, and domain-specific semantic information in capturing pronominal and nominal anaphora referring to proteins. An effort similar to ours is that of Segura-Bedmar et al. (2010), who resolve anaphora to support drugdrug interaction extraction. They created a corpus of 49 interactions sections extracted from the DrugBank database, having on average 40 </context>
<context position="16723" citStr="Kilicoglu and Bergler (2012)" startWordPosition="2546" endWordPosition="2550"> CYP3A4 inhibition. In our dataset, coreference involving appositive constructions were generally left unannotated. However, it was consistently the case that when one of the items in the construction is annotated as the antecedent for an anaphoric expression, the other item in the construction was also annotated as such. Therefore, we identified appositive constructions in text to aid the antecedent selection task. We used dependency relations for this task, as well. Identifying appositives is relatively straightforward using syntactic dependency relations. We adapted the following rule from Kilicoglu and Bergler (2012): APPOS(Antecedent,Anaphor) V APPOS(Anaphor,Antecedent) ==&gt;- COREF(Anaphor,Antecedent) where APPOS E {appos, abbrev, prep including, prep such as}. In our case, this rule becomes (APPOS(Antecedent1,Antecedent2) V APPOS(Antecedent2,Antecedent1)) n COREF(Anaphor,Antecedent1) ==&gt;- COREF(Anaphor,Antecedent2) which essentially states that a candidate is taken as an antecedent, only if its appositive has been recognized as an antecedent. Additionally, semantic compatibility between the items is required. This allows us to identify their and Class Ia antiarrhythmic drugs as co-referents in the follow</context>
<context position="18446" citStr="Kilicoglu and Bergler (2012)" startWordPosition="2783" endWordPosition="2786">ness. 3.2.4 Relative pronouns Similar to appositive constructions, relative pronouns are annotated as anaphoric expressions in some corpora (same as those for appositives), but not in our dataset. In the example below, the relative pronoun which refers to potassium-containing salt substitutes. (5) ... the concomitant use of potassium-sparing diuretics, potassium supplements, and/or potassium-containing salt substitutes, which should be used cautiously.. . Since we aim for generality and this type of anaphora can be important for downstream applications, we implemented a rule, again taken from Kilicoglu and Bergler (2012), which simply states that the antecedent of a relative pronominal anaphora is the noun phrase head it modifies. rel(X,Anaphor) n rcmod(Antecedent,X) ==&gt;. COREF(Anaphor,Antecedent) where rel indicates a relative dependency, and rcmod a relative clause modifier dependency. We extended this in the current work to include the following rules: (6) (a) LEFT(Antecedent,Anaphor) n NO INT WORD(Antecedent,Anaphor) ==&gt;. COREF(Anaphor,Antecedent) (b) LEFT(Antecedent,Anaphor) n rcmod(Antecedent,X) n LEFT(Anaphor,X) ==&gt;. COREF(Anaphor,Antecedent) where LEFT indicates that the first argument is to the left </context>
</contexts>
<marker>Kilicoglu, Bergler, 2012</marker>
<rawString>Halil Kilicoglu and Sabine Bergler. 2012. Biological Event Composition. BMC Bioinformatics, 13 (Suppl 11):S7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Halil Kilicoglu</author>
<author>Marcelo Fiszman</author>
<author>Dina DemnerFushman</author>
</authors>
<title>Interpreting consumer health questions: The role of anaphora and ellipsis.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Workshop on Biomedical Natural Language Processing,</booktitle>
<pages>54--62</pages>
<contexts>
<context position="5315" citStr="Kilicoglu et al. (2013)" startWordPosition="778" endWordPosition="781">rease the metabolism .... In this example, the expression these isoenzymes refer to CYP3A and CYP2C8. Resolving this coreference instance would allow us to capture the following drug interactions mentioned in the sentence: inhibitors of CYP3A POTENTIATE amiodarone and inhibitors of CYP2C8 POTENTIATE amiodarone. In this paper, we present a study that focuses on identification of coreference links in drug labels, with the view that these relations will facilitate the downstream task of drug interaction recognition. The rule-based system presented is an extension of the previous work reported in Kilicoglu et al. (2013). The main focus of the dataset, based on SPLs, is drug interaction information. Coreference is only annotated when it is relevant to extracting such information. In addition to evaluating the system against a baseline, we also manually assessed the system output for precision. Furthermore, we also evaluated the system on a similarly drug-focused corpus annotated for anaphora (DrugNerAR) (Segura-Bedmar et al., 2010). Our results demonstrate that set/instance anaphora resolution and appositive recognition can play a significant role in this type of text and highlight some of the major areas of </context>
<context position="10605" citStr="Kilicoglu et al. (2013)" startWordPosition="1615" endWordPosition="1618">ted only when it would be relevant to drug interaction recognition task. This parsimonious approach to annotation presents difficulty in automatically evaluating the system, and to mitigate this, we present an assessment of the precision of our end-to-end coreference system, as well. We split the dataset into training and test sets by random sampling. Training data consists of 79 documents and the test set has 80 documents. We used the training data for analysis and as the basis of our enhancements. 3.2 The system The work described in this paper extends and refines earlier work, described in Kilicoglu et al. (2013), which focused on disease anaphora and ellipsis in the context of consumer health questions. We briefly recap that system here. The system begins by mapping named entities to UMLS Metathesaurus concepts (CUIs). Next, it identifies anaphoric expressions in text, which include personal (e.g., it, they) and demonstrative pronouns (e.g., this, those), as well as sortal anaphora (definite (e.g., with the) and demonstrative (e.g., with that) noun phrases). The candidate antecedents are then recognized using syntactic (person, gender and number agreement, head word matching) and semantic (hypernym a</context>
</contexts>
<marker>Kilicoglu, Fiszman, DemnerFushman, 2013</marker>
<rawString>Halil Kilicoglu, Marcelo Fiszman, and Dina DemnerFushman. 2013. Interpreting consumer health questions: The role of anaphora and ellipsis. In Proceedings of the 2013 Workshop on Biomedical Natural Language Processing, pages 54–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Ngan Nguyen</author>
<author>Yue Wang</author>
<author>Jun’ichi Tsujii</author>
<author>Toshihisa Takagi</author>
<author>Akinori Yonezawa</author>
</authors>
<date>2012</date>
<booktitle>The Genia Event and Protein Coreference tasks of the BioNLP Shared Task 2011. BMC Bioinformatics, 13(Suppl 11):S1.</booktitle>
<contexts>
<context position="7998" citStr="Kim et al., 2012" startWordPosition="1204" endWordPosition="1207">s (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, uses conditional random fields and post-processing rules to extract medical conditions from SPLs and build triplets in the form of([drug name]-[medical condition]-[LOINC section header]) (Li et al., 2013). Coreference resolution in the biomedical domain was addressed in the 2011 i2b2/VA shared task (Uzuner et al., 2012), and the 2011 BioNLP Shared Task (Kim et al., 2012); however these community-wide evaluations did not change much the observation in the 2011 review by Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to aid the task of biological event extraction. Similarly, Miwa et al. (2012) and Kilicoglu and Bergler (2012) extended their biological event 46 extraction pipelines using </context>
<context position="15757" citStr="Kim et al., 2012" startWordPosition="2396" endWordPosition="2399">t/instance anaphora, in which the instances are not syntactically coordinated, such as in Example (2), where such agents refer to thiazide diuretics, in the preceding sentence, as well as Potassium-sparing diuretics and potassium supplements. (2) ... can attenuate potassium loss caused by thiazide diuretics. Potassium-sparing diuretics ... or potassium supplements can increase .... if concomitant use of such agents is indicated ... 3.2.3 Appositive constructions Coreference involving appositive constructions3 are annotated in some corpora, including the BioNLP shared task coreference dataset (Kim et al., 2012) and DrugNerAR corpus (SeguraBedmar et al., 2010). An example is given below, in which the indefinite noun phrase a drug and the drug lovastatin are appositives. (3) PLETAL does not, however, appear to cause increased blood levels of drugs metabolized by CYP3A4, as it had no effect on lovastatin, a drug with metabolism very sensitive to CYP3A4 inhibition. In our dataset, coreference involving appositive constructions were generally left unannotated. However, it was consistently the case that when one of the items in the construction is annotated as the antecedent for an anaphoric expression, t</context>
</contexts>
<marker>Kim, Nguyen, Wang, Tsujii, Takagi, Yonezawa, 2012</marker>
<rawString>Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun’ichi Tsujii, Toshihisa Takagi, and Akinori Yonezawa. 2012. The Genia Event and Protein Coreference tasks of the BioNLP Shared Task 2011. BMC Bioinformatics, 13(Suppl 11):S1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Louise Deleger</author>
<author>Todd Lingren</author>
<author>Haijun Zhai</author>
<author>Megan Kaiser</author>
<author>Laura Stoutenborough</author>
<author>Anil G Jegga</author>
<author>Kevin B Cohen</author>
<author>Imre Solti</author>
</authors>
<title>Mining FDA drug labels for medical conditions. BMC medical informatics and decision making,</title>
<date>2013</date>
<pages>13--1</pages>
<contexts>
<context position="7829" citStr="Li et al., 2013" startWordPosition="1175" endWordPosition="1178">osing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, uses conditional random fields and post-processing rules to extract medical conditions from SPLs and build triplets in the form of([drug name]-[medical condition]-[LOINC section header]) (Li et al., 2013). Coreference resolution in the biomedical domain was addressed in the 2011 i2b2/VA shared task (Uzuner et al., 2012), and the 2011 BioNLP Shared Task (Kim et al., 2012); however these community-wide evaluations did not change much the observation in the 2011 review by Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to a</context>
</contexts>
<marker>Li, Deleger, Lingren, Zhai, Kaiser, Stoutenborough, Jegga, Cohen, Solti, 2013</marker>
<rawString>Qi Li, Louise Deleger, Todd Lingren, Haijun Zhai, Megan Kaiser, Laura Stoutenborough, Anil G. Jegga, Kevin B. Cohen, and Imre Solti. 2013. Mining FDA drug labels for medical conditions. BMC medical informatics and decision making, 13(1):53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald A B Lindberg</author>
<author>Betsy L Humphreys</author>
<author>Alexa T McCray</author>
</authors>
<title>The Unified Medical Language System.</title>
<date>1993</date>
<journal>Methods of Information in Medicine,</journal>
<pages>32--281</pages>
<contexts>
<context position="7028" citStr="Lindberg et al., 1993" startWordPosition="1056" endWordPosition="1059">indications and adverse effects (ADEs), Smith et al. (2011) concluded that many indication and adverse drug event relationships in the drug labels are too complex to be captured in the existing databases of interactions and ADEs. Despite the complexity, the labels were used to extract indications for drugs in several studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the quality of the mappings. Oprea et al. (2011) used information extracted from the adverse reactions sections of 988 drugs for computer-aided drug repurposing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, use</context>
</contexts>
<marker>Lindberg, Humphreys, McCray, 1993</marker>
<rawString>Donald A. B. Lindberg, Betsy L. Humphreys, and Alexa T. McCray. 1993. The Unified Medical Language System. Methods of Information in Medicine, 32:281–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>On coreference resolution performance metrics. In</title>
<date>2005</date>
<booktitle>In Proc. of HLT/EMNLP,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="23661" citStr="Luo, 2005" startWordPosition="3582" endWordPosition="3583">oric expression, except when the anaphor is reflexive (e.g., itself). 3.4 Evaluation To evaluate our approach, we used a baseline similar to that reported in Segura-Bedmar et al. (2010), which consists of selecting the closest preceding nominal phrase for the anaphoric expressions annotated in their corpus. These expressions include pronominal (personal, relative, demonstrative, etc.) and nominal (definite, possessive, etc.) anaphora. We compared our system to this baseline using the unweighted average of F1- measure over B-CUBED (Bagga and Baldwin, 1998), MUC (Vilain et al., 1995), and CEAF (Luo, 2005) metrics, the standard evaluation metrics for coreference resolution. We used the scripts provided by i2b2 shared task organizers for this purpose. Since coreference annotation was parsimonious in our dataset, we also manually examined a subset of the coreference relations extracted by the system for precision. Additionally, we tested our system on DrugNerAR corpus (Segura-Bedmar et al., 2010), which similarly focuses on drug interactions. We compared our results to theirs, using as evaluation metrics precision, recall, and F1- measure, the metrics that were used in their evaluation. 4 Results</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>Xiaoqiang Luo. 2005. On coreference resolution performance metrics. In In Proc. of HLT/EMNLP, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexa T McCray</author>
<author>Anita Burgun</author>
<author>Olivier Bodenreider</author>
</authors>
<title>Aggregating UMLS semantic types for reducing conceptual complexity.</title>
<date>2001</date>
<booktitle>Proceedings of Medinfo, 10(pt</booktitle>
<pages>1--216</pages>
<contexts>
<context position="13177" citStr="McCray et al., 2001" startWordPosition="2007" endWordPosition="2010">disease coreference only to resolution of coreference involving other entity types. For this purpose, we paramaterized semantic groups and hypernym lists associated with each semantic group. We generalized the system in the sense that new semantic types and hypernyms can be easily defined and used by the system. In addition to Disorder semantic group and Disorder hypernym list defined in earlier work, we used Drug, Intervention, Population, Procedure, Anatomy, and Gene/Protein semantic groups and hypernym lists. Semantic group classification largely mimics coarse-grained UMLS semantic groups (McCray et al., 2001). For example, UMLS semantic types Pharmaco47 logic Substance and Clinical Drug are aggregated into both Drug and Intervention semantic groups, while Therapeutic or Preventive Procedure is assigned to Procedure group only. Drug hypernyms, such as medication, drug, agent, were derived from the training data. 3.2.2 Set/instance anaphora Set/instance anaphora instances are prevalent in drug labels. In our dataset, 19% of all annotated anaphoric expressions indicate set/instance anaphora (co-referring with 29% of antecedent terms). An example was provided earlier (Example 1). While recognizing ana</context>
</contexts>
<marker>McCray, Burgun, Bodenreider, 2001</marker>
<rawString>Alexa T. McCray, Anita Burgun, and Olivier Bodenreider. 2001. Aggregating UMLS semantic types for reducing conceptual complexity. Proceedings of Medinfo, 10(pt 1):216–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Miwa</author>
<author>Paul Thompson</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Boosting automatic event extraction from the literature using domain adaptation and coreference resolution.</title>
<date>2012</date>
<journal>Bioinformatics,</journal>
<volume>28</volume>
<issue>13</issue>
<contexts>
<context position="8502" citStr="Miwa et al. (2012)" startWordPosition="1285" endWordPosition="1288">ddressed in the 2011 i2b2/VA shared task (Uzuner et al., 2012), and the 2011 BioNLP Shared Task (Kim et al., 2012); however these community-wide evaluations did not change much the observation in the 2011 review by Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to aid the task of biological event extraction. Similarly, Miwa et al. (2012) and Kilicoglu and Bergler (2012) extended their biological event 46 extraction pipelines using rule-based coreference systems that rely on syntactic information and predicate argument structures. Nguyen et al. (2012) evaluated contribution of discourse preference, number agreement, and domain-specific semantic information in capturing pronominal and nominal anaphora referring to proteins. An effort similar to ours is that of Segura-Bedmar et al. (2010), who resolve anaphora to support drugdrug interaction extraction. They created a corpus of 49 interactions sections extracted from the DrugBan</context>
</contexts>
<marker>Miwa, Thompson, Ananiadou, 2012</marker>
<rawString>Makoto Miwa, Paul Thompson, and Sophia Ananiadou. 2012. Boosting automatic event extraction from the literature using domain adaptation and coreference resolution. Bioinformatics, 28(13):1759–1765.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ngan L T Nguyen</author>
<author>Jin-Dong Kim</author>
<author>Makoto Miwa</author>
<author>Takuya Matsuzaki</author>
<author>Junichi Tsujii</author>
</authors>
<title>Improving protein coreference resolution by simple semantic classification.</title>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<pages>13--304</pages>
<contexts>
<context position="8719" citStr="Nguyen et al. (2012)" startWordPosition="1315" endWordPosition="1318">Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to aid the task of biological event extraction. Similarly, Miwa et al. (2012) and Kilicoglu and Bergler (2012) extended their biological event 46 extraction pipelines using rule-based coreference systems that rely on syntactic information and predicate argument structures. Nguyen et al. (2012) evaluated contribution of discourse preference, number agreement, and domain-specific semantic information in capturing pronominal and nominal anaphora referring to proteins. An effort similar to ours is that of Segura-Bedmar et al. (2010), who resolve anaphora to support drugdrug interaction extraction. They created a corpus of 49 interactions sections extracted from the DrugBank database, having on average 40 sentences and 716 tokens. They then manually annotated pronominal and nominal anaphora, and developed a rule-based approach that achieve 0.76 F1-measure in anaphora resolution. 3 Metho</context>
<context position="22105" citStr="Nguyen et al., 2012" startWordPosition="3331" endWordPosition="3334"> limits on how far the co-referents could be from each other, since the entire discourse was generally short and the salient antecedent (often the topic of the question) appeared early in discourse. This is often not the 49 case in drug labels, especially because often intricate interactions between the drug of interest and other medications are discussed. Therefore, we limit the discourse window from which candidate antecedents are identified. Generally, the search space for the antecedents is limited to the current sentence as well as the two preceding sentences (Segura-Bedmar et al., 2010; Nguyen et al., 2012). In our dataset, we found that 98% of antecedents occurred within this discourse window and, thus, use the same search space. We make an exception for the cases in which the anaphoric expression appear in the first sentence of a paragraph and no compatible antecedent is found in the same sentence. In this case, the search space is expanded to the entire preceding paragraph. We also extended the system to include different types of salience scoring methods. For drug labels, we use linear distance between the co-referents (in terms of surface elements) as the salience score; the lower this scor</context>
<context position="25464" citStr="Nguyen et al., 2012" startWordPosition="3868" endWordPosition="3871">e taken with caution due to the sparse coreference annotation in the dataset. To get a better sense of how well our system performs, we also performed end-toend coreference resolution and manually assessed a subset of the system output (22 randomly selected drug labels with 249 coreference instances). Of these 249, 181 were deemed correct, yielding a precision of 0.73. The baseline method extracted 1439 instances, 56 of which were deemed correct, yielding a precision of 0.04. The precision of our method is more in line with what has been reported in the literature (Segura-Bedmar et al., 2010; Nguyen et al., 2012). For i2b2-style evaluation using the unweighted average F1 measure over B-CUBED, MUC, and CEAF metrics, we considered both exact and partial mention overlap. These results, provided in Table 1, also indicate that the system provides a clear improvement over the baseline. Metric Baseline OPTIMAL With gold entity annotations Unweighted F1 Partial 0.55 0.77 Unweighted F1 Exact 0.66 0.78 Precision 0.01 0.17 Recall 0.04 0.26 F1-measure 0.01 0.21 End-to-end coreference resolution Precision 0.04 0.73 Table 1: Evaluation results on drug labels 50 We also assessed the effect of various resolution stra</context>
</contexts>
<marker>Nguyen, Kim, Miwa, Matsuzaki, Tsujii, 2012</marker>
<rawString>Ngan L. T. Nguyen, Jin-Dong Kim, Makoto Miwa, Takuya Matsuzaki, and Junichi Tsujii. 2012. Improving protein coreference resolution by simple semantic classification. BMC Bioinformatics, 13:304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip V Ogren</author>
</authors>
<title>Improving Syntactic Coordination Resolution using Language Modeling.</title>
<date>2010</date>
<booktitle>In NAACL (Student Research Workshop),</booktitle>
<pages>1--6</pages>
<contexts>
<context position="14090" citStr="Ogren, 2010" startWordPosition="2140" endWordPosition="2141">g data. 3.2.2 Set/instance anaphora Set/instance anaphora instances are prevalent in drug labels. In our dataset, 19% of all annotated anaphoric expressions indicate set/instance anaphora (co-referring with 29% of antecedent terms). An example was provided earlier (Example 1). While recognizing anaphoric expressions that indicate set/instance anaphora is not necessarily difficult (i.e., recognizing these isoenzymes in the example), linking them to their antecedents can be difficult, since it generally involves correctly identifying syntactic coordination, a challenging syntactic parsing task (Ogren, 2010). Our identification of these structures relies on collapsed Stanford dependency output (de Marneffe et al., 2006) and uses syntactic and semantic constraints. We examine all the dependency relations extracted from a sentence and only consider those with the type conj * (e.g., conj and, conj or). For increased accuracy, we then check the tokens involved in the dependency (conjuncts) and ensure that there is a coordinating conjunction (e.g., and, or, , (comma), &amp; (ampersand)) between them. Once such a conjunction is identified, we then examine the semantic compatibility of the conjuncts. In the</context>
</contexts>
<marker>Ogren, 2010</marker>
<rawString>Philip V. Ogren. 2010. Improving Syntactic Coordination Resolution using Language Modeling. In NAACL (Student Research Workshop), pages 1–6. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T I Oprea</author>
<author>S K Nielsen</author>
<author>O Ursu</author>
<author>J J Yang</author>
<author>O Taboureau</author>
<author>S L Mathias</author>
<author>L Kouskoumvekaki</author>
<author>L A Sklar</author>
<author>C G Bologa</author>
</authors>
<title>Associating Drugs, Targets and Clinical Outcomes into an Integrated Network Affords a New Platform for Computer-Aided Drug Repurposing. Molecular informatics,</title>
<date>2011</date>
<pages>2--3</pages>
<contexts>
<context position="7106" citStr="Oprea et al. (2011)" startWordPosition="1069" endWordPosition="1072">ndication and adverse drug event relationships in the drug labels are too complex to be captured in the existing databases of interactions and ADEs. Despite the complexity, the labels were used to extract indications for drugs in several studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the quality of the mappings. Oprea et al. (2011) used information extracted from the adverse reactions sections of 988 drugs for computer-aided drug repurposing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, uses conditional random fields and post-processing rules to extract medical condi</context>
</contexts>
<marker>Oprea, Nielsen, Ursu, Yang, Taboureau, Mathias, Kouskoumvekaki, Sklar, Bologa, 2011</marker>
<rawString>T.I. Oprea, S.K. Nielsen, O. Ursu, J.J. Yang, O. Taboureau, S.L. Mathias, L. Kouskoumvekaki, L.A. Sklar, and C.G. Bologa. 2011. Associating Drugs, Targets and Clinical Outcomes into an Integrated Network Affords a New Platform for Computer-Aided Drug Repurposing. Molecular informatics, 2-3(30):100–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas C Rindflesch</author>
<author>Lorrie Tanabe</author>
<author>John N Weinstein</author>
<author>Lawrence Hunter</author>
</authors>
<title>EDGAR: Extraction of drugs, genes, and relations from the biomedical literature.</title>
<date>2000</date>
<booktitle>In Proceedings of Pacific Symposium on Biocomputing,</booktitle>
<pages>514--525</pages>
<contexts>
<context position="2952" citStr="Rindflesch et al., 2000" startWordPosition="430" endWordPosition="434">e processing techniques can facilitate automatic timely updates to databases that support Electronic Health Records in alerting physicians to potential drug interactions, recommended doses, and contraindications. Natural language processing methods are increasingly used to support various clinical and biomedical applications (Demner-Fushman et al., 2009). Extraction of drug information is playing a prominent role in these applications and research. In addition to earlier research in extraction of medications and relations involving medications from clinical text and the biomedical literature (Rindflesch et al., 2000; Cimino et al., 2007), in the third i2b2 shared task (Uzuner et al., 2010), 23 organizations have explored extraction of medications, their dosages, routes of administration, frequencies, durations, and reasons for administration from clinical text. The best performing systems used rule-based and machine learning techniques to achieve over 0.8 F-measure for extraction of medication names; however, the remaining information was harder to extract. Researchers have also tackled extraction of drug-drug interactions (Herrero-Zazo et al., 2013), side effects (Xu and Wang, 2014), and indications (Fu</context>
</contexts>
<marker>Rindflesch, Tanabe, Weinstein, Hunter, 2000</marker>
<rawString>Thomas C. Rindflesch, Lorrie Tanabe, John N. Weinstein, and Lawrence Hunter. 2000. EDGAR: Extraction of drugs, genes, and relations from the biomedical literature. In Proceedings of Pacific Symposium on Biocomputing, pages 514–525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabel Segura-Bedmar</author>
<author>Mario Crespo</author>
<author>C´esar de PabloS´anchez</author>
<author>Paloma Martfnez</author>
</authors>
<title>Resolving anaphoras for the extraction of drug-drug interactions in pharmacological documents.</title>
<date>2010</date>
<journal>BMC Bioinformatics,</journal>
<volume>11</volume>
<note>(Suppl 2):S1.</note>
<marker>Segura-Bedmar, Crespo, de PabloS´anchez, Martfnez, 2010</marker>
<rawString>Isabel Segura-Bedmar, Mario Crespo, C´esar de PabloS´anchez, and Paloma Martfnez. 2010. Resolving anaphoras for the extraction of drug-drug interactions in pharmacological documents. BMC Bioinformatics, 11 (Suppl 2):S1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Smith</author>
<author>J C Denny</author>
<author>Q Chen</author>
<author>H Nian</author>
<author>A 3rd Spickard</author>
<author>S T Rosenbloom</author>
<author>R A Miller</author>
</authors>
<title>Lessons learned from developing a drug evidence base to support pharmacovigilance. Applied clinical informatics,</title>
<date>2011</date>
<pages>4--4</pages>
<contexts>
<context position="6465" citStr="Smith et al. (2011)" startWordPosition="965" endWordPosition="968">t role in this type of text and highlight some of the major areas of difficulty and potential enhancements. 2 Related Work We discuss two areas of research related to this study in this section: processing of drug labels and coreference resolution focusing on biomedical text. Drug labels, despite their availability and the wealth of information contained within them, remain underutilized. One of the reasons might be the complexity of the text in the labels: in a review of publicly available text sources that could be used to augment a repository of drug indications and adverse effects (ADEs), Smith et al. (2011) concluded that many indication and adverse drug event relationships in the drug labels are too complex to be captured in the existing databases of interactions and ADEs. Despite the complexity, the labels were used to extract indications for drugs in several studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the qua</context>
</contexts>
<marker>Smith, Denny, Chen, Nian, Spickard, Rosenbloom, Miller, 2011</marker>
<rawString>J.C. Smith, J.C. Denny, Q. Chen, H. Nian, A. 3rd Spickard, S.T. Rosenbloom, and R. A. Miller. 2011. Lessons learned from developing a drug evidence base to support pharmacovigilance. Applied clinical informatics, 4(4):596–617.</rawString>
</citation>
<citation valid="true">
<authors>
<author>¨Ozlem Uzuner</author>
</authors>
<title>Imre Solti, and Eithon Cadag.</title>
<date>2010</date>
<journal>JAMIA,</journal>
<volume>17</volume>
<issue>5</issue>
<marker>Uzuner, 2010</marker>
<rawString>¨Ozlem Uzuner, Imre Solti, and Eithon Cadag. 2010. Extracting medication information from clinical text. JAMIA, 17(5):514–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>¨Ozlem Uzuner</author>
<author>Andrea Bodnari</author>
<author>Shuying Shen</author>
<author>Tyler Forbush</author>
<author>John Pestian</author>
<author>Brett R South</author>
</authors>
<title>Evaluating the state of the art in coreference resolution for electronic medical records.</title>
<date>2012</date>
<journal>JAMIA,</journal>
<volume>19</volume>
<issue>5</issue>
<contexts>
<context position="7946" citStr="Uzuner et al., 2012" startWordPosition="1194" endWordPosition="1197">l. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, uses conditional random fields and post-processing rules to extract medical conditions from SPLs and build triplets in the form of([drug name]-[medical condition]-[LOINC section header]) (Li et al., 2013). Coreference resolution in the biomedical domain was addressed in the 2011 i2b2/VA shared task (Uzuner et al., 2012), and the 2011 BioNLP Shared Task (Kim et al., 2012); however these community-wide evaluations did not change much the observation in the 2011 review by Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to aid the task of biological event extraction. Similarly, Miwa et al. (2012) and Kilicoglu and Bergler (2012) extended t</context>
</contexts>
<marker>Uzuner, Bodnari, Shen, Forbush, Pestian, South, 2012</marker>
<rawString>¨Ozlem Uzuner, Andrea Bodnari, Shuying Shen, Tyler Forbush, John Pestian, and Brett R. South. 2012. Evaluating the state of the art in coreference resolution for electronic medical records. JAMIA, 19(5):786–791.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc B Vilain</author>
<author>John D Burger</author>
<author>John S Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In MUC,</booktitle>
<pages>45--52</pages>
<contexts>
<context position="23639" citStr="Vilain et al., 1995" startWordPosition="3576" endWordPosition="3579">tactic dependency with the anaphoric expression, except when the anaphor is reflexive (e.g., itself). 3.4 Evaluation To evaluate our approach, we used a baseline similar to that reported in Segura-Bedmar et al. (2010), which consists of selecting the closest preceding nominal phrase for the anaphoric expressions annotated in their corpus. These expressions include pronominal (personal, relative, demonstrative, etc.) and nominal (definite, possessive, etc.) anaphora. We compared our system to this baseline using the unweighted average of F1- measure over B-CUBED (Bagga and Baldwin, 1998), MUC (Vilain et al., 1995), and CEAF (Luo, 2005) metrics, the standard evaluation metrics for coreference resolution. We used the scripts provided by i2b2 shared task organizers for this purpose. Since coreference annotation was parsimonious in our dataset, we also manually examined a subset of the coreference relations extracted by the system for precision. Additionally, we tested our system on DrugNerAR corpus (Segura-Bedmar et al., 2010), which similarly focuses on drug interactions. We compared our results to theirs, using as evaluation metrics precision, recall, and F1- measure, the metrics that were used in their</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc B. Vilain, John D. Burger, John S. Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A model-theoretic coreference scoring scheme. In MUC, pages 45–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie L Webber</author>
</authors>
<title>Discourse Deixis: Reference to Discourse Segments. In</title>
<date>1988</date>
<booktitle>ACL,</booktitle>
<pages>113--122</pages>
<contexts>
<context position="20208" citStr="Webber, 1988" startWordPosition="3043" endWordPosition="3044">eference, we use semantic information from UMLS Metathesaurus. We stipulate that, to qualify as co-referents, both terms under consideration should map to the same UMLS concept (i.e., that they are considered synonyms). If the terms are within the same sentence, we further require that they are appositive. 3.3.1 Demonstrative pronouns Anaphoric expressions of demonstrative pronoun type generally have discourse-deictic use; in other words, they often refer to events, propositions described in prior discourse or even to the full sentences or paragraphs, rather than concrete objects or entities (Webber, 1988). This fact was implicitly exploited in consumer health questions, since the coreference resolution focused on diseases only, which are essentially processes. However, in drug labels, discourse-deictic use of demonstratives is much more overt. Consider the sentence below, where the demonstrative This refers to the event of increasing the exposure to lovastatin. (8) Co-administration of lovastatin and SAMSCA increases the exposure to lovastatin and .... This is not a clinically relevant change. To handle such cases, we blocked entity antecedents (such as drugs) for demonstrative pronouns and on</context>
</contexts>
<marker>Webber, 1988</marker>
<rawString>Bonnie L. Webber. 1988. Discourse Deixis: Reference to Discourse Segments. In ACL, pages 113–122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong Xu</author>
<author>QuanQiu Wang</author>
</authors>
<title>Large-scale combining signals from both biomedical literature and the FDA Adverse Event Reporting System (FAERS) to improve post-marketing drug safety signal detection.</title>
<date>2014</date>
<journal>BMC Bioinformatics,</journal>
<pages>15--17</pages>
<contexts>
<context position="3531" citStr="Xu and Wang, 2014" startWordPosition="520" endWordPosition="523">cal literature (Rindflesch et al., 2000; Cimino et al., 2007), in the third i2b2 shared task (Uzuner et al., 2010), 23 organizations have explored extraction of medications, their dosages, routes of administration, frequencies, durations, and reasons for administration from clinical text. The best performing systems used rule-based and machine learning techniques to achieve over 0.8 F-measure for extraction of medication names; however, the remaining information was harder to extract. Researchers have also tackled extraction of drug-drug interactions (Herrero-Zazo et al., 2013), side effects (Xu and Wang, 2014), and indications (Fung et al., 2013) from various biomedical resources. As for many other information extraction tasks, 2DailyMed: http://dailymed.nlm.nih.gov/dailymed/about.cfm 45 Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 45–53, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics extracting drug information is often made more difficult by coreference. Coreference is defined as the relation between linguistic expressions that are referring to the same entity (Zheng et al., 2011). Coreference resolutio</context>
</contexts>
<marker>Xu, Wang, 2014</marker>
<rawString>Rong Xu and QuanQiu Wang. 2014. Large-scale combining signals from both biomedical literature and the FDA Adverse Event Reporting System (FAERS) to improve post-marketing drug safety signal detection. BMC Bioinformatics, 15:17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsumasa Yoshikawa</author>
<author>Sebastian Riedel</author>
<author>Tsutomu Hirao</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Coreference Based Event-Argument Relation Extraction on Biomedical Text.</title>
<date>2011</date>
<journal>Journal of Biomedical Semantics,</journal>
<volume>2</volume>
<note>(Suppl 5):S6.</note>
<contexts>
<context position="8320" citStr="Yoshikawa et al. (2011)" startWordPosition="1255" endWordPosition="1258">cal conditions from SPLs and build triplets in the form of([drug name]-[medical condition]-[LOINC section header]) (Li et al., 2013). Coreference resolution in the biomedical domain was addressed in the 2011 i2b2/VA shared task (Uzuner et al., 2012), and the 2011 BioNLP Shared Task (Kim et al., 2012); however these community-wide evaluations did not change much the observation in the 2011 review by Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to aid the task of biological event extraction. Similarly, Miwa et al. (2012) and Kilicoglu and Bergler (2012) extended their biological event 46 extraction pipelines using rule-based coreference systems that rely on syntactic information and predicate argument structures. Nguyen et al. (2012) evaluated contribution of discourse preference, number agreement, and domain-specific semantic information in capturing pronominal and nominal anaphora referring to proteins. An effort similar to ours</context>
</contexts>
<marker>Yoshikawa, Riedel, Hirao, Asahara, Matsumoto, 2011</marker>
<rawString>Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hirao, Masayuki Asahara, and Yuji Matsumoto. 2011. Coreference Based Event-Argument Relation Extraction on Biomedical Text. Journal of Biomedical Semantics, 2 (Suppl 5):S6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiaping Zheng</author>
<author>Wendy W Chapman</author>
<author>Rebecca S Crowley</author>
<author>Guergana K Savova</author>
</authors>
<title>Coreference resolution: A review of general methodologies and applications in the clinical domain.</title>
<date>2011</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>44</volume>
<issue>6</issue>
<contexts>
<context position="4108" citStr="Zheng et al., 2011" startWordPosition="595" endWordPosition="598">., 2013), side effects (Xu and Wang, 2014), and indications (Fung et al., 2013) from various biomedical resources. As for many other information extraction tasks, 2DailyMed: http://dailymed.nlm.nih.gov/dailymed/about.cfm 45 Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 45–53, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics extracting drug information is often made more difficult by coreference. Coreference is defined as the relation between linguistic expressions that are referring to the same entity (Zheng et al., 2011). Coreference resolution is a fundamental task in NLP and can benefit many downstream applications, such as relation extraction, summarization, and question answering. Difficulty of the task is due to the fact that various levels of linguistic information (lexical, syntactic, semantic, and discourse contextual features) generally play a role. Coreference occurs frequently in all types of biomedical text, including the drug package inserts. Consider the example below: (1) Since amiodarone is a substrate for CYP3A and CYP2C8, drugs/substances that inhibit these isoenzymes may decrease the metabo</context>
<context position="8118" citStr="Zheng et al. (2011)" startWordPosition="1223" endWordPosition="1226">ase relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, uses conditional random fields and post-processing rules to extract medical conditions from SPLs and build triplets in the form of([drug name]-[medical condition]-[LOINC section header]) (Li et al., 2013). Coreference resolution in the biomedical domain was addressed in the 2011 i2b2/VA shared task (Uzuner et al., 2012), and the 2011 BioNLP Shared Task (Kim et al., 2012); however these community-wide evaluations did not change much the observation in the 2011 review by Zheng et al. (2011) that only a handful of systems were developed for handling anaphora and coreference in clinical text and biomedical publications. Since this comprehensive article was published, Yoshikawa et al. (2011) proposed two coference resolution models based on support vector machine and joint Markov logic network to aid the task of biological event extraction. Similarly, Miwa et al. (2012) and Kilicoglu and Bergler (2012) extended their biological event 46 extraction pipelines using rule-based coreference systems that rely on syntactic information and predicate argument structures. Nguyen et al. (2012</context>
</contexts>
<marker>Zheng, Chapman, Crowley, Savova, 2011</marker>
<rawString>Jiaping Zheng, Wendy W. Chapman, Rebecca S. Crowley, and Guergana K. Savova. 2011. Coreference resolution: A review of general methodologies and applications in the clinical domain. Journal of Biomedical Informatics, 44(6):1113–1122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qian Zhu</author>
<author>Robert R Freimuth</author>
<author>Jyotishman Pathak</author>
<author>Matthew J Durski</author>
<author>Christopher G Chute</author>
</authors>
<date>2013</date>
<journal>Disambiguation of PharmGKB drug-disease relations with NDF-RT and SPL. Journal of Biomedical Informatics,</journal>
<volume>46</volume>
<issue>4</issue>
<contexts>
<context position="7335" citStr="Zhu et al. (2013)" startWordPosition="1104" endWordPosition="1107">everal studies. Elkin et al. (2011) automatically extracted indications, mapped them to SNOMEDCT and then automatically derived rules in the form (”Drug” HasIndication ”SNOMED CT”). Fung et al. (2013) used MetaMap (Aronson and Lang, 2010) to extract indications and map them to the UMLS (Lindberg et al., 1993), and then manually validated the quality of the mappings. Oprea et al. (2011) used information extracted from the adverse reactions sections of 988 drugs for computer-aided drug repurposing. Duke et al. (2011) have developed a rule-based system that extracted 534,125 ADEs from 5602 SPLs. Zhu et al. (2013) extracted disease terms from five SPL sections (indication, contraindication, ADE, precaution, and warning) and combined the extracted terms with the drug and disease relationships in NDF-RT to disambiguate the PharmGKB drug and disease associations. A hybrid NLP system, AutoMCExtractor, uses conditional random fields and post-processing rules to extract medical conditions from SPLs and build triplets in the form of([drug name]-[medical condition]-[LOINC section header]) (Li et al., 2013). Coreference resolution in the biomedical domain was addressed in the 2011 i2b2/VA shared task (Uzuner et</context>
</contexts>
<marker>Zhu, Freimuth, Pathak, Durski, Chute, 2013</marker>
<rawString>Qian Zhu, Robert R. Freimuth, Jyotishman Pathak, Matthew J. Durski, and Christopher G. Chute. 2013. Disambiguation of PharmGKB drug-disease relations with NDF-RT and SPL. Journal of Biomedical Informatics, 46(4):690–696.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>