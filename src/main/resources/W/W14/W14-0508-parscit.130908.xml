<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014876">
<title confidence="0.9289775">
Towards a computational model of grammaticalization and
lexical diversity
</title>
<author confidence="0.998422">
Christian Bentz
</author>
<affiliation confidence="0.999199">
University of Cambridge, DTAL
</affiliation>
<address confidence="0.98726">
9 West Road, CB3 9DA
</address>
<email confidence="0.998837">
cb696@cam.ac.uk
</email>
<sectionHeader confidence="0.980076" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999825625">
Languages use different lexical inven-
tories to encode information, ranging
from small sets of simplex words to
large sets of morphologically complex
words. Grammaticalization theories
argue that this variation arises as
the outcome of diachronic processes
whereby co-occurring words merge
to one word and build up complex
morphology. To model these pro-
cesses we present a) a quantitative
measure of lexical diversity and b) a
preliminary computational model of
changes in lexical diversity over several
generations of merging higly frequent
collocates.
</bodyText>
<sectionHeader confidence="0.996303" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999887285714286">
All languages share the property of being car-
riers of information. However, they vastly dif-
fer in terms of the exact encoding strategies
they adopt. For example, German encodes in-
formation about number, gender, case, tense,
aspect, etc. in a multitude of different articles,
pronouns, nouns, adjectives and verbs. This
abundant set of word forms contrasts with a
smaller set of uninflected words in English.
Crucially, grammaticalization theories
(Heine and Kuteva, 2007, 2002; Bybee 2006,
2003; Hopper and Traugott, 2003; Lehmann,
1985) demonstrate that complex morpho-
logical marking can derive diachronically by
merging originally independent word forms
that frequently co-occur. Over several gen-
erations of language learning and usage such
grammaticalization and entrenchment pro-
cesses can gradually increase the complexity
of word forms and hence the lexical diversity
of languages.
</bodyText>
<author confidence="0.826243">
Paula Buttery
</author>
<affiliation confidence="0.955242">
University of Cambridge, DTAL
</affiliation>
<address confidence="0.947524">
9 West Road, CB3 9DA
</address>
<email confidence="0.990266">
pjb48@cam.ac.uk
</email>
<bodyText confidence="0.998391175">
To model these processes Section 2 will
present a quantitative measure of lexical diver-
sity based on Zipf-Mandelbrots law, which is
also used as a biodiversity index (Jost, 2006).
Based on this measure we present a prelimi-
nary computational model to reconstruct the
gradual change from lexically constrained to
lexically rich languages in Section 3. We
therefore use a simple grammaticalization al-
gorithm and show how historical developments
towards higher lexical diversity match the vari-
ation in lexical diversity of natural languages
today. This suggests that synchronic variation
in lexical diversity can be explained as the out-
come of diachronic language change.
The computational model we present will
therefore help to a) understand the diver-
sity of lexical encoding strategies across lan-
guages better, and b) to further uncover the
diachronic processes leading up to these syn-
chronic differences.
2 Zipf’s law as a measure of lexical
diversity
Zipf-Mandelbrot’s law (Mandelbrot, 1953;
Zipf, 1949) states that ordering of words ac-
cording to their frequencies in texts will render
frequency distributions of a specific shape: in
general, few words have high frequencies, fol-
lowed by a middle ground of medium frequen-
cies and a long tail of low frequency items.
However, a series of studies pointed out that
there are subtle differences in frequency dis-
tributions for different texts and languages
(Bentz et al., forthcoming; Ha et al., 2006;
Popescu and Altmann, 2008). Namely, lan-
guages with complex morphology tend to have
longer tails of low frequency words than lan-
guages with simplex morphology. The param-
eters of Zipf-Mandelbrot’s law reflect these dif-
ferences, and can be used as a quantitative
</bodyText>
<page confidence="0.989361">
38
</page>
<bodyText confidence="0.693084666666667">
Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 38–42,
Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics
measure of lexical diversity.
</bodyText>
<subsectionHeader confidence="0.984263">
2.1 Method
</subsectionHeader>
<bodyText confidence="0.998542">
We use the definition of ZM’s law as captured
by equation (1):
</bodyText>
<equation confidence="0.99914275">
C
f(rz) = ,
Q + ra
C &gt; 0, α &gt; 0, Q &gt; −1, i = 1, 2, ... , n (1)
</equation>
<bodyText confidence="0.993650092592593">
where f(rz) is the frequency of the word
of the ith rank (rz), n is the number of ranks,
C is a normalizing factor and α and Q are
parameters. To illustrate this, we use parallel
texts of the Universal Declaration of Human
Rights (UDHR) for Fijian, English, German
and Hungarian. For frequency distributions
of these texts (with tokens delimited by
white spaces) we can approximate the best
fitting parameters of the ZM law by means
of maximum likelihood estimation (Izs´ak,
2006; Murphy, 2013). In double logarithmic
space (see Figure 1) the normalizing factor
C would shift the line of best fit upwards or
downwards, α is the slope of this line and Q
is Mandelbrot’s (1953) corrective for the fact
that the line of best fit will deviate from a
straight line for higher frequencies (upper left
corner in Figure 1).
As can be seen in Figure 1 Fijian has higher
frequencies towards the lowest ranks (upper
left corner) but the shortest tail of words with
frequency one (horizontal bars in the lower
right corner). For Hungarian the pattern runs
the other way round: it has the lowest frequen-
cies towards the low ranks and a long tail of
words with frequency one. German and En-
glish lie between these. These patterns are re-
flected in ZM parameter values. Namely, Fi-
jian has the highest parameters, followed by
English, German and Hungarian. By trend
there is a negative relationship between ZM
parameters and lexical diversity: low lexical
diversity is associated with high parameters,
high diversity is associated with low param-
eters. Cross-linguistically this effect can be
used to measure lexical diversity by means of
approximating the parameters of ZM’s law for
parallel texts.
In the following, we will present a compu-
tational model to elicit the diachronic path-
ways of grammaticalization through which a
Figure 1: Zipf frequency distributions for four
natural languages (Fijian, English, German,
Hungarian). Plots are in log-log space, val-
ues 0.15, 0.1 and 0.05 were added to Fijian,
English and German log-frequencies to avoid
overplotting. Values for the Zipf-Mandelbrot
parameters are given in the legend. The
straight black line is the line of best fit for
Fijian.
low lexical diversity language like Fijian might
develop towards a high diversity language like
Hungarian.
</bodyText>
<sectionHeader confidence="0.967727" genericHeader="method">
3 Modelling changes in lexical
diversity
</sectionHeader>
<bodyText confidence="0.999514454545455">
Grammaticalization theorists have long
claimed that synchronic variation in word
complexity and lexical diversity might be the
outcome of diachronic processes. Namely, the
grammaticalization cline from content item
&gt;grammatical word &gt;clitic &gt;inflectional affix
is seen as a ubiquitous process in language
change (Hopper and Traugott, 2003: 7).
In the final stage frequently co-occurring
words merge by means of phonological fusion
(Bybee, 2003: 617) and hence ’morphologize’
to built inflections and derivations.
Typical examples of a full cline of grammat-
icalization are the Old English noun l¯ıc ’body’
becoming the derivational suffix -ly, the inflec-
tional future in Romance languages such as
Italian canter`o ’I will sing’ derived from Latin
cantare habeo ’I have to sing’, or Hungarian
inflectional elative and inessive case markers
derived from a noun originally meaning ‘in-
terior’ (Heine and Kuteva, 2007: 66). These
processes can cause languages to distinguish
</bodyText>
<page confidence="0.997164">
39
</page>
<bodyText confidence="0.999932428571429">
between a panoply of different word forms. For
example, Hungarian displays up to 20 different
noun forms where English would use a single
form (e.g. ship corresponding to Hungarian
haj´o ’ship’, haj´oban ’in the ship’, haj´oba ’into
the ship’, etc.).
As a consequence, once the full grammati-
calization cline is completed this will increase
the lexical diversity of a language. Note,
however, that borrowings (loanwords) and ne-
ologisms can also increase lexical diversity.
Hence, a model of changes in lexical diversity
will have to take both grammaticalization and
new vocabulary into account.
</bodyText>
<subsectionHeader confidence="0.956986">
3.1 The model
</subsectionHeader>
<bodyText confidence="0.999610206896552">
Text: We use the Fijian UDHR as our start-
ing point for two reasons: a) Fijian is a lan-
guage that is well known to be largely lack-
ing complex morphology, b) the UDHR is a
parallel text and hence allows us to compare
different languages by controlling for constant
information content. Fijian has relatively low
lexical diversity and high ZM parameter val-
ues (see Figure 1). The question is whether
we can simulate a simple merging process over
several generations that will transform the fre-
quency distribution of the original Fijian text
to fit the frequency distribution of the mor-
phologically and lexically rich Hungarian text.
To answer this question, we simulate the out-
come of grammaticalization on the frequency
distributions in the following steps:
Simulation: Our program takes a given
text of generation i, calculates a frequency
distribution for this generation, changes the
text along various operations given below, and
gives the frequency distribution of the text for
a new generation i + 1 as output.
We take the original UDHR in Fijian as our
starting point in generation 0 and run the pro-
gram for consecutive generations. We simulate
the change of this text over several generations
of language learning and usage by varying the
following variables:
</bodyText>
<listItem confidence="0.998841294117647">
• pm: Rank bigrams according to their fre-
quency and merge the highest pm per-
cent of them to one word. This simu-
lates a simple grammaticalization process
whereby two separate words that are fre-
quent collocates are merged to one word.
• pv: Percentage of words replaced by new
words. Choose pv of words randomly and
replace all instances of these words by in-
verting the letters. This simulates neolo-
gisms and loanwords replacing deprecated
words.
• rR: Range of ranks to be included in pv
replacements. If set to 0, vocabulary from
anywhere in the distribution will be ran-
domly replaced.
• nG: Number of generations to simulate.
</listItem>
<bodyText confidence="0.9869245">
This simulation essentially allows us to vary
the degree of grammaticalization by means of
varying pm, and also to control for the fact
that frequency distributions might change due
to loanword borrowing and introduction of
new vocabulary (pv). Additionally, rR allows
us to vary the range of ranks where new words
might replace deprecated ones. For frequency
distributions calculated by generations we ap-
proximate ZM parameters by maximum likeli-
hood estimations and therefore document the
change of their shape.
Results: Figure 2 illustrates a simulation
of how the low lexical diversity language Fi-
jian approaches quantitative lexical properties
similar to the Hungarian text just by means of
merging high-frequent collocates. While the
frequency distribution of Fijian in generation
0 still reflects the original ZM values, the
ZM parameter values after 6 generations of
grammaticalization have become much closer
to the values of the Hungarian UDHR:
Fij (nG = 0): α = 1.21,0 = 2.1,C = 812
Fij (nG = 6): α = 0.70,0 = −0.22,C = 73
Hun (nG = 0): α = 0.76,0 = −0.31,C = 90
Note, that in this model there is actu-
ally no replacement of vocabulary necessary
to arrive at frequency distributions that
correspond to high lexical diversity variants.
After only six generations of merging 2.5% of
bigrams to a single grammaticalized word the
Fijian UDHR has ZM parameter properties
very close to the Hungarian UDHR. However,
in future research we want to scrutinize the
effect of parameter changes on frequency
distributions in more depth and in accordance
</bodyText>
<page confidence="0.997781">
40
</page>
<figureCaption confidence="0.981901">
Figure 2: Simulation of grammaticalization processes and their reflections in Zipf distributions
</figureCaption>
<bodyText confidence="0.968971666666667">
for variable values pm = 2.5, pv = 0, rR = 0, nG = 10. Changes of α are shown in the upper left
panel, changes in Q are shown in the upper right panel, changes in C are shown in the lower left
panel, and changes in log-transformed frequency distributions are illustrated in the lower right
panel.
with estimations derived from historical
linguistic studies.
</bodyText>
<sectionHeader confidence="0.998823" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999349736842105">
We have pointed out in Section 2 that lexical
diversity can be measured cross-linguistically
by means of calculating frequency distribu-
tions for parallel texts and approximating the
corresponding ZM parameters in a maximum
likelihood estimation.
It is assumed that cross-linguistic variation
is the outcome of diachronic processes of gram-
maticalization, whereby highly frequent bi-
grams are merged into a single word. The
preliminary computational model in Section 3
showed that indeed even by a strongly sim-
plified grammaticalization process a text with
low lexical diversity (Fijian UDHR) can gain
lexical richness over several generations, and
finally match the quantitative properties of a
lexically rich language (Hungarian UDHR).
However, there are several caveats that need
to be addressed in future research:
</bodyText>
<listItem confidence="0.9904555">
• More models with varying parameters
need to be run to scrutinize the interac-
tion between new vocabulary (loanwords,
neologisms) and grammaticalization.
• The grammaticalization algorithm used is
overly simplified. A more realistic pic-
</listItem>
<bodyText confidence="0.9825928">
ture is possible by using POS tagged and
parsed texts to ensure that only certain
parts of speech in certain syntactic con-
texts grammaticalize (e.g. pre- and post-
positions in combination with nouns).
• The model could be elaborated by consid-
ering not only bigram frequencies but also
frequencies of the individual words and
more complex frequency measures (see
Schmid, 2010).
</bodyText>
<page confidence="0.999299">
41
</page>
<sectionHeader confidence="0.997958" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999475">
Languages display an astonishing diversity
when it comes to lexical encoding of informa-
tion. This synchronic variation in encoding
strategies is most likely the outcome of di-
achronic processes of language change. We
have argued that lexical diversity can be mea-
sured quantitatively with reference to the pa-
rameters of Zipf-Mandelbrot’s law, and that
pathways of change in lexical diversity can be
modelled computationally. Elaboration and
refinement of these models will help to bet-
ter understand linguistic diversity as the out-
come of processes on historical and evolution-
ary time scales.
</bodyText>
<sectionHeader confidence="0.997823" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.762122428571429">
Marco Baroni. 2009. Distributions in text.
In Anke L¨udeling and Merja Kyt¨o (eds.),
Corpus Linguistics. An international
handbook. Berlin/ New York, Mouton de
Gruyter, pages 803-826.
Christian Bentz, Douwe Kiela, Felix Hill,
and Paula Buttery. forthcoming. Zipf’s law
</reference>
<bodyText confidence="0.8703452">
and the grammar of languages. In Corpus
Linguistics and Linguistic Theory.
Joan Bybee. 2006. From usage to grammar:
The mind’s repsonse to repetition. In
Language, volume 82 (4), pages 711-733.
Joan Bybee. 2003. Mechanisms of change in
grammaticization: the role of frequency.
In B. D. Joseph and J. Janda(eds.), The
Handbook of Historical Linguistics. Oxford,
Blackwell, pages 711-733.
</bodyText>
<reference confidence="0.97158818367347">
Le Q. Ha, Darryl Stewart, Philip Hanna,
and F. Smith. 2006. Zipf and type-token
rules for the English, Spanish, Irish and
Latin languages. In Web Journal of Formal,
Computational and Cognitive Linguistics,
volume 8.
Bernd Heine and Tania Kuteva. 2007.
The Genesis of Grammar: A Reconstruc-
tion. Oxford University Press.
Bernd Heine and Tania Kuteva. 2002.
World lexicon of grammaticalization. Cam-
bridge University Press.
Paul J. Hopper and Elizabeth C. Traugott.
2003. Grammaticalization. Cambridge
University Press.
J´anos Izs´ak. 2006. Some practical aspects
of fitting and testing the Zipf-Mandelbrot
model: A short essay. In Scientometrics,
volume 67(1), pages 107-120.
Lou Jost. 2006. Entropy and diversity.
In OIKOS, volume 113(2), pages 363-375.
Christian Lehmann. 1985. Grammatical-
ization: Synchronic variation and di-
achronic change. In Lingua e stile, volume
20, pages 303-318.
Benoit Mandelbrot. 1953. An informa-
tional theory of the statistical structure
of language. In William Jackson (ed.),
Communication Theory. Butterworths
Scientific Publications, London, pages
468-502.
Laura Murphy. 2013. R package likeli-
hood: Methods for maximum likeli-
hood estimation. Retrieved from cran.r-
project.org/web/packages/likelihood
Ioan-Iovitz Popescu, and Gabriel Altmann.
2008. Hapax legomena and language typol-
ogy. In Journal of Quantitative Linguistics,
volume 15(4), pages 370378.
Hans-J. Schmid. 2010. Does frequency
in text instantiate entrenchment in the
cognitive system? In Dylan Glynn and
Kerstin Fischer (eds.), Quantitative meth-
ods in cognitive semantics: Corpus-driven
approaches. Berlin, Walter de Gruyter,
pages 101-133.
George K. Zipf. 1949. Human behavior
and the principle of least effort. Addison,
Cambridge (Massachusetts).
</reference>
<page confidence="0.999257">
42
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.927460">
<title confidence="0.996915">Towards a computational model of grammaticalization lexical diversity</title>
<author confidence="0.999774">Christian</author>
<affiliation confidence="0.999963">University of Cambridge,</affiliation>
<address confidence="0.998608">9 West Road, CB3</address>
<email confidence="0.991991">cb696@cam.ac.uk</email>
<abstract confidence="0.996579470588235">Languages use different lexical inventories to encode information, ranging from small sets of simplex words to large sets of morphologically complex words. Grammaticalization theories argue that this variation arises as the outcome of diachronic processes whereby co-occurring words merge to one word and build up complex morphology. To model these processes we present a) a quantitative measure of lexical diversity and b) a preliminary computational model of changes in lexical diversity over several generations of merging higly frequent collocates.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
</authors>
<title>Distributions in text.</title>
<date>2009</date>
<booktitle>In Anke L¨udeling and Merja Kyt¨o (eds.), Corpus Linguistics. An international handbook.</booktitle>
<pages>803--826</pages>
<location>Berlin/ New York, Mouton</location>
<marker>Baroni, 2009</marker>
<rawString>Marco Baroni. 2009. Distributions in text. In Anke L¨udeling and Merja Kyt¨o (eds.), Corpus Linguistics. An international handbook. Berlin/ New York, Mouton de Gruyter, pages 803-826.</rawString>
</citation>
<citation valid="false">
<authors>
<author>forthcoming</author>
</authors>
<note>Zipf’s law</note>
<marker>forthcoming, </marker>
<rawString>Christian Bentz, Douwe Kiela, Felix Hill, and Paula Buttery. forthcoming. Zipf’s law</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le Q Ha</author>
<author>Darryl Stewart</author>
<author>Philip Hanna</author>
<author>F Smith</author>
</authors>
<title>Zipf and type-token rules for the English, Spanish, Irish and Latin languages.</title>
<date>2006</date>
<journal>In Web Journal of Formal, Computational and Cognitive Linguistics,</journal>
<volume>8</volume>
<contexts>
<context position="3148" citStr="Ha et al., 2006" startWordPosition="471" endWordPosition="474">over the diachronic processes leading up to these synchronic differences. 2 Zipf’s law as a measure of lexical diversity Zipf-Mandelbrot’s law (Mandelbrot, 1953; Zipf, 1949) states that ordering of words according to their frequencies in texts will render frequency distributions of a specific shape: in general, few words have high frequencies, followed by a middle ground of medium frequencies and a long tail of low frequency items. However, a series of studies pointed out that there are subtle differences in frequency distributions for different texts and languages (Bentz et al., forthcoming; Ha et al., 2006; Popescu and Altmann, 2008). Namely, languages with complex morphology tend to have longer tails of low frequency words than languages with simplex morphology. The parameters of Zipf-Mandelbrot’s law reflect these differences, and can be used as a quantitative 38 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 38–42, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics measure of lexical diversity. 2.1 Method We use the definition of ZM’s law as captured by equation (1): C f(rz) = , Q + ra C &gt; 0, α &gt; 0, </context>
</contexts>
<marker>Ha, Stewart, Hanna, Smith, 2006</marker>
<rawString>Le Q. Ha, Darryl Stewart, Philip Hanna, and F. Smith. 2006. Zipf and type-token rules for the English, Spanish, Irish and Latin languages. In Web Journal of Formal, Computational and Cognitive Linguistics, volume 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Heine</author>
<author>Tania Kuteva</author>
</authors>
<title>The Genesis of Grammar: A Reconstruction.</title>
<date>2007</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1204" citStr="Heine and Kuteva, 2007" startWordPosition="173" endWordPosition="176"> and b) a preliminary computational model of changes in lexical diversity over several generations of merging higly frequent collocates. 1 Introduction All languages share the property of being carriers of information. However, they vastly differ in terms of the exact encoding strategies they adopt. For example, German encodes information about number, gender, case, tense, aspect, etc. in a multitude of different articles, pronouns, nouns, adjectives and verbs. This abundant set of word forms contrasts with a smaller set of uninflected words in English. Crucially, grammaticalization theories (Heine and Kuteva, 2007, 2002; Bybee 2006, 2003; Hopper and Traugott, 2003; Lehmann, 1985) demonstrate that complex morphological marking can derive diachronically by merging originally independent word forms that frequently co-occur. Over several generations of language learning and usage such grammaticalization and entrenchment processes can gradually increase the complexity of word forms and hence the lexical diversity of languages. Paula Buttery University of Cambridge, DTAL 9 West Road, CB3 9DA pjb48@cam.ac.uk To model these processes Section 2 will present a quantitative measure of lexical diversity based on Z</context>
<context position="7011" citStr="Heine and Kuteva, 2007" startWordPosition="1101" endWordPosition="1104">ess in language change (Hopper and Traugott, 2003: 7). In the final stage frequently co-occurring words merge by means of phonological fusion (Bybee, 2003: 617) and hence ’morphologize’ to built inflections and derivations. Typical examples of a full cline of grammaticalization are the Old English noun l¯ıc ’body’ becoming the derivational suffix -ly, the inflectional future in Romance languages such as Italian canter`o ’I will sing’ derived from Latin cantare habeo ’I have to sing’, or Hungarian inflectional elative and inessive case markers derived from a noun originally meaning ‘interior’ (Heine and Kuteva, 2007: 66). These processes can cause languages to distinguish 39 between a panoply of different word forms. For example, Hungarian displays up to 20 different noun forms where English would use a single form (e.g. ship corresponding to Hungarian haj´o ’ship’, haj´oban ’in the ship’, haj´oba ’into the ship’, etc.). As a consequence, once the full grammaticalization cline is completed this will increase the lexical diversity of a language. Note, however, that borrowings (loanwords) and neologisms can also increase lexical diversity. Hence, a model of changes in lexical diversity will have to take bo</context>
</contexts>
<marker>Heine, Kuteva, 2007</marker>
<rawString>Bernd Heine and Tania Kuteva. 2007. The Genesis of Grammar: A Reconstruction. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Heine</author>
<author>Tania Kuteva</author>
</authors>
<title>World lexicon of grammaticalization.</title>
<date>2002</date>
<publisher>Cambridge University Press.</publisher>
<marker>Heine, Kuteva, 2002</marker>
<rawString>Bernd Heine and Tania Kuteva. 2002. World lexicon of grammaticalization. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul J Hopper</author>
<author>Elizabeth C Traugott</author>
</authors>
<title>Grammaticalization.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1255" citStr="Hopper and Traugott, 2003" startWordPosition="181" endWordPosition="184">nges in lexical diversity over several generations of merging higly frequent collocates. 1 Introduction All languages share the property of being carriers of information. However, they vastly differ in terms of the exact encoding strategies they adopt. For example, German encodes information about number, gender, case, tense, aspect, etc. in a multitude of different articles, pronouns, nouns, adjectives and verbs. This abundant set of word forms contrasts with a smaller set of uninflected words in English. Crucially, grammaticalization theories (Heine and Kuteva, 2007, 2002; Bybee 2006, 2003; Hopper and Traugott, 2003; Lehmann, 1985) demonstrate that complex morphological marking can derive diachronically by merging originally independent word forms that frequently co-occur. Over several generations of language learning and usage such grammaticalization and entrenchment processes can gradually increase the complexity of word forms and hence the lexical diversity of languages. Paula Buttery University of Cambridge, DTAL 9 West Road, CB3 9DA pjb48@cam.ac.uk To model these processes Section 2 will present a quantitative measure of lexical diversity based on Zipf-Mandelbrots law, which is also used as a biodiv</context>
<context position="6438" citStr="Hopper and Traugott, 2003" startWordPosition="1012" endWordPosition="1015">erplotting. Values for the Zipf-Mandelbrot parameters are given in the legend. The straight black line is the line of best fit for Fijian. low lexical diversity language like Fijian might develop towards a high diversity language like Hungarian. 3 Modelling changes in lexical diversity Grammaticalization theorists have long claimed that synchronic variation in word complexity and lexical diversity might be the outcome of diachronic processes. Namely, the grammaticalization cline from content item &gt;grammatical word &gt;clitic &gt;inflectional affix is seen as a ubiquitous process in language change (Hopper and Traugott, 2003: 7). In the final stage frequently co-occurring words merge by means of phonological fusion (Bybee, 2003: 617) and hence ’morphologize’ to built inflections and derivations. Typical examples of a full cline of grammaticalization are the Old English noun l¯ıc ’body’ becoming the derivational suffix -ly, the inflectional future in Romance languages such as Italian canter`o ’I will sing’ derived from Latin cantare habeo ’I have to sing’, or Hungarian inflectional elative and inessive case markers derived from a noun originally meaning ‘interior’ (Heine and Kuteva, 2007: 66). These processes can </context>
</contexts>
<marker>Hopper, Traugott, 2003</marker>
<rawString>Paul J. Hopper and Elizabeth C. Traugott. 2003. Grammaticalization. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J´anos Izs´ak</author>
</authors>
<title>Some practical aspects of fitting and testing the Zipf-Mandelbrot model: A short essay.</title>
<date>2006</date>
<booktitle>In Scientometrics,</booktitle>
<volume>67</volume>
<issue>1</issue>
<pages>107--120</pages>
<marker>Izs´ak, 2006</marker>
<rawString>J´anos Izs´ak. 2006. Some practical aspects of fitting and testing the Zipf-Mandelbrot model: A short essay. In Scientometrics, volume 67(1), pages 107-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Jost</author>
</authors>
<title>Entropy and diversity.</title>
<date>2006</date>
<booktitle>In OIKOS,</booktitle>
<volume>113</volume>
<issue>2</issue>
<pages>363--375</pages>
<contexts>
<context position="1880" citStr="Jost, 2006" startWordPosition="274" endWordPosition="275">5) demonstrate that complex morphological marking can derive diachronically by merging originally independent word forms that frequently co-occur. Over several generations of language learning and usage such grammaticalization and entrenchment processes can gradually increase the complexity of word forms and hence the lexical diversity of languages. Paula Buttery University of Cambridge, DTAL 9 West Road, CB3 9DA pjb48@cam.ac.uk To model these processes Section 2 will present a quantitative measure of lexical diversity based on Zipf-Mandelbrots law, which is also used as a biodiversity index (Jost, 2006). Based on this measure we present a preliminary computational model to reconstruct the gradual change from lexically constrained to lexically rich languages in Section 3. We therefore use a simple grammaticalization algorithm and show how historical developments towards higher lexical diversity match the variation in lexical diversity of natural languages today. This suggests that synchronic variation in lexical diversity can be explained as the outcome of diachronic language change. The computational model we present will therefore help to a) understand the diversity of lexical encoding stra</context>
</contexts>
<marker>Jost, 2006</marker>
<rawString>Lou Jost. 2006. Entropy and diversity. In OIKOS, volume 113(2), pages 363-375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Lehmann</author>
</authors>
<title>Grammaticalization: Synchronic variation and diachronic change.</title>
<date>1985</date>
<booktitle>In Lingua e stile,</booktitle>
<volume>20</volume>
<pages>303--318</pages>
<contexts>
<context position="1271" citStr="Lehmann, 1985" startWordPosition="185" endWordPosition="186">ver several generations of merging higly frequent collocates. 1 Introduction All languages share the property of being carriers of information. However, they vastly differ in terms of the exact encoding strategies they adopt. For example, German encodes information about number, gender, case, tense, aspect, etc. in a multitude of different articles, pronouns, nouns, adjectives and verbs. This abundant set of word forms contrasts with a smaller set of uninflected words in English. Crucially, grammaticalization theories (Heine and Kuteva, 2007, 2002; Bybee 2006, 2003; Hopper and Traugott, 2003; Lehmann, 1985) demonstrate that complex morphological marking can derive diachronically by merging originally independent word forms that frequently co-occur. Over several generations of language learning and usage such grammaticalization and entrenchment processes can gradually increase the complexity of word forms and hence the lexical diversity of languages. Paula Buttery University of Cambridge, DTAL 9 West Road, CB3 9DA pjb48@cam.ac.uk To model these processes Section 2 will present a quantitative measure of lexical diversity based on Zipf-Mandelbrots law, which is also used as a biodiversity index (Jo</context>
</contexts>
<marker>Lehmann, 1985</marker>
<rawString>Christian Lehmann. 1985. Grammaticalization: Synchronic variation and diachronic change. In Lingua e stile, volume 20, pages 303-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Mandelbrot</author>
</authors>
<title>An informational theory of the statistical structure of language. In</title>
<date>1953</date>
<booktitle>Communication Theory. Butterworths Scientific Publications,</booktitle>
<pages>468--502</pages>
<editor>William Jackson (ed.),</editor>
<location>London,</location>
<contexts>
<context position="2693" citStr="Mandelbrot, 1953" startWordPosition="397" endWordPosition="398"> grammaticalization algorithm and show how historical developments towards higher lexical diversity match the variation in lexical diversity of natural languages today. This suggests that synchronic variation in lexical diversity can be explained as the outcome of diachronic language change. The computational model we present will therefore help to a) understand the diversity of lexical encoding strategies across languages better, and b) to further uncover the diachronic processes leading up to these synchronic differences. 2 Zipf’s law as a measure of lexical diversity Zipf-Mandelbrot’s law (Mandelbrot, 1953; Zipf, 1949) states that ordering of words according to their frequencies in texts will render frequency distributions of a specific shape: in general, few words have high frequencies, followed by a middle ground of medium frequencies and a long tail of low frequency items. However, a series of studies pointed out that there are subtle differences in frequency distributions for different texts and languages (Bentz et al., forthcoming; Ha et al., 2006; Popescu and Altmann, 2008). Namely, languages with complex morphology tend to have longer tails of low frequency words than languages with simp</context>
</contexts>
<marker>Mandelbrot, 1953</marker>
<rawString>Benoit Mandelbrot. 1953. An informational theory of the statistical structure of language. In William Jackson (ed.), Communication Theory. Butterworths Scientific Publications, London, pages 468-502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Murphy</author>
</authors>
<title>R package likelihood: Methods for maximum likelihood estimation. Retrieved from cran.rproject.org/web/packages/likelihood</title>
<date>2013</date>
<contexts>
<context position="4272" citStr="Murphy, 2013" startWordPosition="669" endWordPosition="670">the definition of ZM’s law as captured by equation (1): C f(rz) = , Q + ra C &gt; 0, α &gt; 0, Q &gt; −1, i = 1, 2, ... , n (1) where f(rz) is the frequency of the word of the ith rank (rz), n is the number of ranks, C is a normalizing factor and α and Q are parameters. To illustrate this, we use parallel texts of the Universal Declaration of Human Rights (UDHR) for Fijian, English, German and Hungarian. For frequency distributions of these texts (with tokens delimited by white spaces) we can approximate the best fitting parameters of the ZM law by means of maximum likelihood estimation (Izs´ak, 2006; Murphy, 2013). In double logarithmic space (see Figure 1) the normalizing factor C would shift the line of best fit upwards or downwards, α is the slope of this line and Q is Mandelbrot’s (1953) corrective for the fact that the line of best fit will deviate from a straight line for higher frequencies (upper left corner in Figure 1). As can be seen in Figure 1 Fijian has higher frequencies towards the lowest ranks (upper left corner) but the shortest tail of words with frequency one (horizontal bars in the lower right corner). For Hungarian the pattern runs the other way round: it has the lowest frequencies</context>
</contexts>
<marker>Murphy, 2013</marker>
<rawString>Laura Murphy. 2013. R package likelihood: Methods for maximum likelihood estimation. Retrieved from cran.rproject.org/web/packages/likelihood</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioan-Iovitz Popescu</author>
<author>Gabriel Altmann</author>
</authors>
<title>Hapax legomena and language typology.</title>
<date>2008</date>
<journal>In Journal of Quantitative Linguistics,</journal>
<volume>15</volume>
<issue>4</issue>
<pages>370378</pages>
<contexts>
<context position="3176" citStr="Popescu and Altmann, 2008" startWordPosition="475" endWordPosition="478">ic processes leading up to these synchronic differences. 2 Zipf’s law as a measure of lexical diversity Zipf-Mandelbrot’s law (Mandelbrot, 1953; Zipf, 1949) states that ordering of words according to their frequencies in texts will render frequency distributions of a specific shape: in general, few words have high frequencies, followed by a middle ground of medium frequencies and a long tail of low frequency items. However, a series of studies pointed out that there are subtle differences in frequency distributions for different texts and languages (Bentz et al., forthcoming; Ha et al., 2006; Popescu and Altmann, 2008). Namely, languages with complex morphology tend to have longer tails of low frequency words than languages with simplex morphology. The parameters of Zipf-Mandelbrot’s law reflect these differences, and can be used as a quantitative 38 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 38–42, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics measure of lexical diversity. 2.1 Method We use the definition of ZM’s law as captured by equation (1): C f(rz) = , Q + ra C &gt; 0, α &gt; 0, Q &gt; −1, i = 1, 2, ... , n (1</context>
</contexts>
<marker>Popescu, Altmann, 2008</marker>
<rawString>Ioan-Iovitz Popescu, and Gabriel Altmann. 2008. Hapax legomena and language typology. In Journal of Quantitative Linguistics, volume 15(4), pages 370378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-J Schmid</author>
</authors>
<title>Does frequency in text instantiate entrenchment in the cognitive system?</title>
<date>2010</date>
<booktitle>In Dylan Glynn and Kerstin Fischer (eds.), Quantitative methods in cognitive semantics: Corpus-driven approaches. Berlin, Walter de Gruyter,</booktitle>
<pages>101--133</pages>
<contexts>
<context position="13020" citStr="Schmid, 2010" startWordPosition="2075" endWordPosition="2076">h: • More models with varying parameters need to be run to scrutinize the interaction between new vocabulary (loanwords, neologisms) and grammaticalization. • The grammaticalization algorithm used is overly simplified. A more realistic picture is possible by using POS tagged and parsed texts to ensure that only certain parts of speech in certain syntactic contexts grammaticalize (e.g. pre- and postpositions in combination with nouns). • The model could be elaborated by considering not only bigram frequencies but also frequencies of the individual words and more complex frequency measures (see Schmid, 2010). 41 5 Conclusion Languages display an astonishing diversity when it comes to lexical encoding of information. This synchronic variation in encoding strategies is most likely the outcome of diachronic processes of language change. We have argued that lexical diversity can be measured quantitatively with reference to the parameters of Zipf-Mandelbrot’s law, and that pathways of change in lexical diversity can be modelled computationally. Elaboration and refinement of these models will help to better understand linguistic diversity as the outcome of processes on historical and evolutionary time </context>
</contexts>
<marker>Schmid, 2010</marker>
<rawString>Hans-J. Schmid. 2010. Does frequency in text instantiate entrenchment in the cognitive system? In Dylan Glynn and Kerstin Fischer (eds.), Quantitative methods in cognitive semantics: Corpus-driven approaches. Berlin, Walter de Gruyter, pages 101-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George K Zipf</author>
</authors>
<title>Human behavior and the principle of least effort.</title>
<date>1949</date>
<publisher>Addison,</publisher>
<location>Cambridge (Massachusetts).</location>
<contexts>
<context position="2706" citStr="Zipf, 1949" startWordPosition="399" endWordPosition="400">n algorithm and show how historical developments towards higher lexical diversity match the variation in lexical diversity of natural languages today. This suggests that synchronic variation in lexical diversity can be explained as the outcome of diachronic language change. The computational model we present will therefore help to a) understand the diversity of lexical encoding strategies across languages better, and b) to further uncover the diachronic processes leading up to these synchronic differences. 2 Zipf’s law as a measure of lexical diversity Zipf-Mandelbrot’s law (Mandelbrot, 1953; Zipf, 1949) states that ordering of words according to their frequencies in texts will render frequency distributions of a specific shape: in general, few words have high frequencies, followed by a middle ground of medium frequencies and a long tail of low frequency items. However, a series of studies pointed out that there are subtle differences in frequency distributions for different texts and languages (Bentz et al., forthcoming; Ha et al., 2006; Popescu and Altmann, 2008). Namely, languages with complex morphology tend to have longer tails of low frequency words than languages with simplex morpholog</context>
</contexts>
<marker>Zipf, 1949</marker>
<rawString>George K. Zipf. 1949. Human behavior and the principle of least effort. Addison, Cambridge (Massachusetts).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>