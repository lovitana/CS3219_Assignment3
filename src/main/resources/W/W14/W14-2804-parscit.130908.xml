<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000060">
<title confidence="0.98524">
Generalizing inflection tables into paradigms with finite state operations
</title>
<author confidence="0.986602">
Mans Hulden
</author>
<affiliation confidence="0.996711">
University of Helsinki
</affiliation>
<email confidence="0.98986">
mans.hulden@helsinki.fi
</email>
<sectionHeader confidence="0.997284" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999857">
Extracting and performing an alignment
of the longest common subsequence in in-
flection tables has been shown to be a
fruitful approach to supervised learning
of morphological paradigms. However,
finding the longest subsequence common
to multiple strings is well known to be
an intractable problem. Additional con-
straints on the solution sought complicate
the problem further—such as requiring
that the particular subsequence extracted,
if there is ambiguity, be one that is best
alignable in an inflection table. In this pa-
per we present and discuss the design of a
tool that performs the extraction through
some advanced techniques in finite state
calculus and does so efficiently enough for
the practical purposes of inflection table
generalization.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891807692308">
Supervised learning of morphological paradigms
from inflection tables has recently been ap-
proached from a number of directions. One ap-
proach is given in Hulden et al. (2014), where
morphological paradigm induction is performed
by extracting the longest common subsequence
(LCS) from a set of words representing an in-
flection table. Although that work presents en-
couraging results as regards learning morphologi-
cal paradigms from inflection tables, no details are
given as to how the paradigms themselves are ex-
tracted. The purpose of this paper is to describe
how such a paradigm extraction procedure can be
performed using only finite state operations.
Extracting the longest common subsequence
from a large number of strings is known as the
multiple longest common subsequence problem
(MLCS), and is computationally intractable. In
fields like bioinformatics specialized heuristic al-
gorithms have been developed for efficiently ex-
tracting common subsequences from DNA se-
quences. In linguistics applications where the goal
is to extract common patterns in an inflection ta-
ble, however, the problem manifests itself in a
different guise. While most applications in other
fields work with a small number of fairly long se-
quences, inflection tables may contain hundreds of
short sequences. Additionally, it is not enough to
extract the LCS from an inflection table. The LCS
itself is often ambiguous and may be factorized in
several different ways in a table. This means that
we operate under the additional constraint that the
LCS must not only be found, but, in case of ambi-
guity, its most contiguous factorization must also
be indicated, as this often produces linguistically
interesting generalizations.
In this paper we will address the problem of
extracting the minimal MLCS through entirely fi-
nite state means. Finite state methods lend them-
selves to solving this kind of an optimization prob-
lem concisely, and, as it turns out, also efficiently
enough for practical purposes.
This paper is laid out as follows. First, we
outline the MLCS-based approach to supervised
learning of morphological paradigms in section
2. We then describe in broad strokes the algo-
rithm required for generalizing inflection tables
into paradigms in section 3. Next, we give a finite
state implementation of the algorithm in section
4, followed by a brief discussion of a stand-alone
software tool based on this that extracts paradigms
from collections of inflection tables in section 5.
</bodyText>
<sectionHeader confidence="0.997214" genericHeader="method">
2 Supervised learning of morphological
paradigms
</sectionHeader>
<bodyText confidence="0.995505">
In the following, we operate with the central idea
of a model of word formation that organizes word
forms and their inflection patterns into paradigms
(Hockett, 1954; Robins, 1959; Matthews, 1972;
</bodyText>
<page confidence="0.987962">
29
</page>
<note confidence="0.788581">
Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 29–36,
Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.992752576923077">
Stump, 2001). In particular, we model paradigms
in a slightly more abstract manner than is custom-
arily done. For the purposes of this paper, we dif-
ferentiate between a paradigm and an inflection
table in the following way: an inflection table is
simply a list of words that represents a concrete
manifestation, or instantiation, of a paradigm. A
paradigm is also a list of words, but with spe-
cial symbols that represent variables interspersed.
These variables, when instantiated, represent par-
ticular strings shared across an inflection table.
In our representation, this kind of an abstract
paradigm is an ordered collection of strings,
where each string may additionally contain in-
terspersed variables denoted x1, x2, ... , xn. The
strings represent fixed, obligatory parts of a
paradigm, while the variables represent mutable
parts. A complete abstract paradigm captures
some generalization where the mutable parts rep-
resented by variables are instantiated the same
way for all forms in one particular inflection table.
For example, the fairly simple paradigm
x1 x1+s x1+ed x1+ing
could represent a set of English verb forms, where
x1 in this case would coincide with the infinitive
form of the verb—walk, climb, look, etc.1
</bodyText>
<subsectionHeader confidence="0.982961">
2.1 Learning paradigms from inflection
tables
</subsectionHeader>
<bodyText confidence="0.999873214285714">
As is seen from the above example, a general
enough paradigm can encode the inflection pat-
tern of a large number of words. When learning
such paradigms from data—i.e. complete inflec-
tion tables—we intuitively want to find the ‘com-
mon’ elements of a table and generalize those.
The core of the method is to factor the word
forms in an inflection table in such a manner that
the elements common to all entries are declared
variables, while the non-common elements are as-
sumed to be part of the inflection pattern. To illus-
trate the idea with an example, consider a short-
ened inflection table for the regular German verb
holen (to fetch):2
</bodyText>
<footnote confidence="0.977602111111111">
1Our formalization of a paradigm of strings and interven-
ing variables bears many similarities to so-called pattern lan-
guages (Angluin, 1980). In fact, each entry in a paradigm
could be considered a separate pattern language. Addition-
ally, all the individual pattern languages in one paradigm are
constrained to share the same variables and the variables are
constrained to collectively be instantiated the same way.
2We follow the convention that entries in an inflection ta-
ble are separated by #.
</footnote>
<equation confidence="0.839129">
hole#holst#holt#holen#holt#holen#geholt (1)
</equation>
<bodyText confidence="0.9996395">
Obviously, in this example, the element com-
mon to each entry in the inflection table is hol.
Declaring hol to be a variable, we can rewrite the
inflection table as:
</bodyText>
<equation confidence="0.868042">
x1+e#x1+st#x1+t#x1+en#x1+t#x1+en#ge+x1+t (2)
</equation>
<bodyText confidence="0.999915">
This extraction of the ‘common elements’ is
formalized in Hulden et al. (2014) to be equivalent
to extraction of the longest common subsequence
of the strings w1, ... , wn in an inflection table.3
The purpose of extracting the common parts and
labeling them variables is to provide a model for
generalization of inflection patterns. Under the as-
sumption that a variable xi in this paradigm rep-
resentation corresponds to a nonempty string, we
can instantiate an inflection table by simply pro-
viding the variable strings x1,... , xn. Thus, we
can talk about a paradigm-generating function
</bodyText>
<equation confidence="0.95266">
f : (x1,...,xn) → Σ∗
</equation>
<bodyText confidence="0.999758166666667">
that maps instantiations of variables to a string rep-
resenting the complete inflection table, in this case
a string where entries are #-separated.
To illustrate this, consider the simple paradigm
in (2). It implicitly defines a function f where, for
example, f(kauf) maps to the string
</bodyText>
<equation confidence="0.89311">
kaufe#kaufst#kauft#kaufen#kauft#kaufen#gekauft (3)
</equation>
<bodyText confidence="0.998463714285714">
i.e. produces the inflection table for the regular
verb kaufen (to buy), which behaves like holen.
Likewise, we can also consider the inverse func-
tion. Given an unknown word form, e.g. macht
(to make, 3pSg), we can see that the only way it
fits the paradigm in (2) is if it comes from an in-
flection table:
</bodyText>
<figure confidence="0.299899">
mache#machst#macht#machen#macht#machen#gemacht
(4)
</figure>
<footnote confidence="0.929243888888889">
that is, if macht is part of the output for f(mach).
3Not to be confused with the longest common substring,
which is a different problem, solvable in polynomial time
for n strings. Subsequences may be discontinuous while
substrings may not. For example, assume s = abcaa and
t = dbcadaa. The longest common substring shared by the
two is bca obtained from s by abcaa and t by dbcadaa. By
contrast, the longest common subsequence is bcaa, obtained
from s by abcaa and t by dbcadaa or dbcadaa or dbcadaa.
</footnote>
<page confidence="0.996881">
30
</page>
<figure confidence="0.844355666666667">
Input: ① Extract ② Fit LCS ③ Generalize ④ Collapse
inflection LCS to table to paradigms paradigms
tables
</figure>
<figureCaption confidence="0.999825">
Figure 1: Paradigm extraction strategy.
</figureCaption>
<bodyText confidence="0.999958954545455">
In other words, the extraction of multiple com-
mon longest subsequences (MLCS) from inflec-
tion tables immediately provides a (simple) gener-
alization mechanism of a grammar, and also sug-
gests a supervised learning strategy for morpho-
logical paradigms. In conjunction with statistical
machine learning methods, Hulden et al. (2014)
has shown that the paradigm extraction and gen-
eralization method provides competitive results
in various supervised and semi-supervised NLP
learning tasks. One such task is to provide a hy-
pothetical reconstruction of a complete inflection
table from an unseen base form after first witness-
ing a number of complete inflection tables. An-
other task is the semi-supervised collection of lex-
ical entries and matching them to paradigms by
observing distributions of word forms across all
the possible paradigms they can fit into. In gen-
eral, there is much current interest in similar tasks
in NLP; see e.g. Dreyer and Eisner (2011); Dur-
rett and DeNero (2013); Eskander et al. (2013) for
a variety of current methods.
</bodyText>
<sectionHeader confidence="0.979926" genericHeader="method">
3 Learning method
</sectionHeader>
<bodyText confidence="0.997716307692308">
The basic procedure as outlined by Hulden et al.
(2014) for learning paradigms from inflection ta-
bles can be represented by the four-step procedure
given in figure 1. Here, multiple inflection tables
are gathered, and the LCS to each table is found
individually. Following that, the LCS is fit into
the table, and contiguous segments that participate
in the LCS are labeled variables. After paradigm
generalization, it may turn out that several identi-
cal paradigms have been learned, which may then
be collapsed.
The first two steps of the method dictate that
one:
</bodyText>
<listItem confidence="0.999371">
1. Extract the longest common subsequence
(LCS) to all the entries in the inflection table.
2. Split the LCS(s)—of which there may be
</listItem>
<bodyText confidence="0.668545375">
several—into variables in such a way that the
number of variables is minimized. Two seg-
ments xy are always part of the same variable
if they occur together in every form of an in-
flection table. If some substring z intervenes
between x and y in some form, x and y must
be assigned separate variables.
These steps represent steps10 and 20 in figure
</bodyText>
<listItem confidence="0.851074">
1. After the variables have been identified, steps
O and ® in the figure are easily accomplished by
non-finite-state means.
</listItem>
<bodyText confidence="0.998877">
In the following, we will focus on the previ-
ously unaddressed problem of finding the LCS of
an inflection table (10), and of distributing possible
variables corresponding to contiguous sequences
of the LCS in a way that gives rise to the mini-
mum number of variables (20).
</bodyText>
<sectionHeader confidence="0.999152" genericHeader="method">
4 Finite-state implementation
</sectionHeader>
<bodyText confidence="0.999995210526316">
The main challenge in producing a paradigm from
an inflection table is not the extraction of the
longest common subsequences, but rather, doing
so with the added criterion of minimizing the num-
ber of variables used. Extracting the LCS from
multiple strings is known to be NP-hard (Maier,
1978) and naive implementations will fail quickly
for even a moderate number of strings found in in-
flection tables. While there exist specialized algo-
rithms that attempt to efficiently either calculate
(Irving and Fraser, 1992) or approximate (Wang
et al., 2010) the LCS, we find that extraction can
easily be accomplished with a simple transducer
calculation. The task of ascertaining that the LCS
is distributed in such a way as to minimize the
number of variables turns out to be more challeng-
ing; at the same time, however, it is a problem to
which the finite state calculus is particularly well
suited, as will be seen below.
</bodyText>
<subsectionHeader confidence="0.988871">
4.1 Notation and tool
</subsectionHeader>
<bodyText confidence="0.999957625">
The paradigm extraction tool was implemented
with the help of the foma toolkit (Hulden, 2009).
In the actual implementation, instead of directly
compiling regular expressions, we make use of
foma’s programming API, but in the following we
give regular expression equivalents to the method
used. Table 1 contains a summary of the regular
expression notation used.
</bodyText>
<figure confidence="0.99940488">
[r]i[ng]
rng [r]a[ng]
[r]u[ng]
[sw]i[m]
SWM [sw]a[m]
[sw]u[m]
x1+i+x2
x1+a+x2
x1+u+x2
x1+i+x2
x1+a+x2
x1+u+x2
}
}
x1+i+x2
x1+a+x2
x1+u+x2
}
}
ring
rang
rung
swim
swam
swum
</figure>
<page confidence="0.929776">
31
</page>
<figure confidence="0.960155272727273">
0 Empty string
? Any symbol in alphabet
.#. End or beginning of string
{xyz} String
AB Concatenation
A*, A+ Kleene star, Kleene plus
A|B Union
A &amp; B Intersection
A - B Difference
˜A Complement
A .o. B Composition
</figure>
<table confidence="0.8806265">
% Escape symbol
[ and ] Grouping brackets
A:B Cross product
T.2 Output projection of T
A -&gt; B Rewrite A as B
eq(X,L,R) Strings between L,R are equal
def W {word} Define FSM constant
def F(X,Y) X Y Regular expression macro
</table>
<tableCaption confidence="0.999422">
Table 1: Regular expression notation in fomes.
</tableCaption>
<subsectionHeader confidence="0.867079">
4.2 LCS extraction
</subsectionHeader>
<bodyText confidence="0.9996181">
As the first step, we assume that we have encoded
each word wi, ... , w,,, in an inflection table as an
automaton that accepts that word.4
In general, we can define the set of subse-
quences of any word by a general regular expres-
sion technique:
remove from X all strings shorter than the maxi-
mum.5
An automaton that contains all LCSs for a set of
words wi, ... , w,,, can thus be calculated as:
</bodyText>
<equation confidence="0.996491">
Max(SS(w1) &amp; ... &amp; SS(wn)) (5)
</equation>
<bodyText confidence="0.999967571428572">
The above two lines together represent a
surprisingly efficient manner of calculating the
MLCS for a large number of relatively similar
short sequences (less than 100 characters) and
is essentially equivalent to performing the same
calculation through dynamic programming algo-
rithms with some additional search heuristics.
</bodyText>
<subsectionHeader confidence="0.998875">
4.3 Minimizing variables
</subsectionHeader>
<bodyText confidence="0.999815571428571">
We can then assume that we have calculated the
LCS or LCSs for an inflection table and can rep-
resent it as an automaton. The following step is to
assign variables to segments that can correspond
to the LCS in a minimal way. The minimality re-
quirement is crucial for good generalization as is
seen in the illustration here:
</bodyText>
<figure confidence="0.875216666666667">
(a) (b)
x1 x1 x2
{
{
{
comprar comprar
compra compra
compro compro
def SS(X) [X .o. [?|?:0]*].2;
{
{
{
</figure>
<bodyText confidence="0.9885788">
SS(w) then contains all of the subsequences
of some word w. Taking advantage of this, we
may calculate the intersection of each set of sub-
sequences SS(w1) &amp; ...&amp; SS(w,,,), produc-
ing the language that contains all the common
subsequences to wi, ... , w,,,. From this, extract-
ing the longest subsequence or sequences could in
principle be performed by inspecting the resulting
automaton, but the same can also be done alge-
braically for finite sets:
</bodyText>
<equation confidence="0.846465">
def Max(X) X -
[[X .o. [?:a]* [?:0]+].2 .o. [a:?]*].2;
</equation>
<bodyText confidence="0.996977833333333">
Here, Max(X) is a regular expression tech-
nique of extracting the set of longest strings from
an automaton. We achieve this in practice by first
changing all symbols in X to an arbitrary sym-
bol (a in this case), removing at least one symbol
from the end, and using this intermediate result to
</bodyText>
<footnote confidence="0.956281">
4We abuse notation slightly by representing by wi both a
word and an automaton that accepts that word.
</footnote>
<equation confidence="0.838654">
x1 x1 x2
</equation>
<bodyText confidence="0.999982588235294">
The above shows two ways of breaking up the
LCS compr in the hypothetical three-word inflec-
tion table for Spanish. In case (a) the compr
has been located contiguously in inflection entries,
while in (b) there is a gap in the first form, leading
to the inevitable use of two variables to generalize
the table.
In the finite-state string encoding, the overall
intent of our effort to calculate the minimum-
variable MLCS assignment in the table is to
produce an automaton that contains the divi-
sions of variables marked up with brackets.
For example, given a hypothetical two-word ta-
ble holen#geholt, the LCS is obviously hol.
Now, there are several valid divisions of hol
into variables, e.g. [ho][l]en#ge[ho][l]t, which
would represent a two-variable division, while
</bodyText>
<footnote confidence="0.9452438">
5This is a rather inefficient way of extracting the set of
longest strings from an automaton. However, as the runtime
of this part represents only a minute fraction of the complete
procedure, we do so to preserve the benefit of clarity that us-
ing finite-state calculus offers.
</footnote>
<page confidence="0.997569">
32
</page>
<figure confidence="0.999108607142857">
pextract example
1 def SS(X) [X .o. [?|?:0]*].2;
2 def Max(X) X - [[X .o. ?:a* ?:0+].2 .o. a:?*].2;
3 def RedupN(X,Y) [_eq([LEFT X RIGHT [Y LEFT X RIGHT]*], LEFT, RIGHT) .o. LEFT|RIGHT -&gt; 0].l;
4 def NOBR ? - %[ - %] - %#;
5 def Order(X) [[X .o. 0:%# ?* 0:%# .o.
?* %# [NOBR  |%[:%&lt;  |%]:%&gt;]* %# ?* .o.
%[|%] -&gt; 0 .o.
[?* 0:%&gt; 0:%&lt; \[%&lt;|%&gt;|%[|%] ]+ %&gt; ?*]* .o.
%#:0 ?* %#:0 .o.
0 -&gt; %[|%] .o. %&lt; -&gt; %[ .o. %&gt; -&gt; %]] .o. X ].2;
6
7
8
9
10
11 def MarkRoot(X) [X .o. [?|0:%[ ?+ 0:%]]* ].2;
12 def RandomBracketing(X) [X .o. [?  |0:%[ NOBR* 0:%]]* ].2;
13 def AddExtraSegments(X) [X .o. [0:NOBR*  |%[ \%]* %]  |%#]* ].2;
14 def Filter(X) X - Order(X);
15
16 def Table {hole#holst#holt#holen#holt#holen#geholt};
17 def MLCS Max(SS({hole}) &amp; SS({holst}) &amp; SS({holt}) &amp; SS({holen}) &amp; SS({holt}) &amp; SS({holen}) &amp; SS({geholt}));
18 def BracketedMLCS AddExtraSegments(RedupN(MarkRoot(MLCS),%#));
19 def BracketedTable RandomBracketing(Table);
20
21 regex Filter(BracketedMLCS &amp; BracketedTable);
22 print words
</figure>
<figureCaption confidence="0.995308666666667">
Figure 2: Complete implementation of the extraction of the minimum-variable longest common subse-
quences as a foma-script. Here, a small German verb table is hard-coded for illustration purposes on
lines 16 and 17. The output is [hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t
</figureCaption>
<bodyText confidence="0.999629690909091">
[hol]en#ge[hol]t would represent a one-variable
division.
Naturally, these brackets will have to be divided
in such a way that there is no better way to achieve
the division—i.e. no markup such that fewer vari-
ables are instantiated.
The crux of the method used here is to first pro-
duce an automaton that accepts the set of all valid
markups of the MLCS in the table string, and then
use that set to in turn define the set of suboptimal
markups. Similar finite-state techniques have been
used by Gerdemann and van Noord (2000); Eisner
(2002); Karttunen (2010); Gerdemann and Hulden
(2012), to, among other things, define suboptimal
candidates in Optimality Theory. The trick is to set
up a transducer T that contains the input-output
pair (x, x&apos;), iff x&apos; represents a worse division of
variables than x does. In effect, T captures the
transitive closure of an ordering relation &gt;- of the
various factorizations of the strings into variables,
and T contains the string pair (x, x&apos;) when x &gt;-+
x&apos;. In general, supposing that we have an identity
transducer, i.e. automaton A, and a transducer T
that maps strings in A according to the transitive
closure of an ordering relation &gt;-, then we can al-
ways remove the suboptimal strings according to
&gt;- from A by calculating A − range(A o T).
Apart from this central idea, some bookkeep-
ing is required because we are working with string
representations of inflection tables. A complete
foma listing that captures the behavior of our im-
plementation is given in figure 2. The main com-
plication in the program is to produce the transitive
closure of the ordering by setting up a transducer
Order that, given some bracketed string, breaks
up continuous sequences of brackets into disconti-
nuities, e.g. [xyz] —* [x][yz],[xy][z], [x][y][z].
The main logic of the program appears on lines
18–21. The BracketedMLCS is the language
where the MLCS has been bracketed in various
ways and extra segments inserted arbitrarily. An
extra complication is that the MLCS must always
be bracketed the same way within a string, e.g.
[xy][z]#...#[xy][z], or [x][yz]#...#[x][yz] etc. That
is, the variable splits have to be equal across en-
tries.
The BracketedTable language is the lan-
guage that contains a string that represents the in-
flection table at hand, but with arbitrary bracket-
ings. The intersection of the two languages then
contain the valid MLCS bracketings of the inflec-
tion table. After the intersection is calculated, we
apply the ordering transducer and filter out those
strings with suboptimal bracket markup. Figure 3
illustrates the process.
</bodyText>
<subsectionHeader confidence="0.999278">
4.4 Optimizations and additions
</subsectionHeader>
<bodyText confidence="0.999980142857143">
In addition to the description given above, the
actual implementation contains a number of sec-
ondary optimization strategies. The foremost one
is the simple preprocessing move to locate first
the longest common prefix p in the inflection ta-
ble before any processing is done. This can, of
course, be discovered very efficiently. The prefix
</bodyText>
<page confidence="0.995453">
33
</page>
<figure confidence="0.997713631578947">
MLCS
hol
BracketedTable
[h]ole#ho[ls][t]#holt#h[o]len#ho[lt]#[ho][le][n]#[ge]h[ol][t]
h[o]le#h[ol][st]#[h]olt#holen#[hol]t#h[o][l]e[n]#g[eh]o[lt]
hole#[h]ol[st]#[ho]l[t]#[h][o][len]#holt#hol[en]#[g][eh][o]l[t]
...
BracketedMLCS &amp; BracketedTable
BracketedMLCS
X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X
X[hol]X#X[hol]X#X[hol]X#X[hol]X#X[hol]X#X[hol]X#X[hol]X
X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X
X[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]X
[ho][l]e#[ho][l]st#[ho][l]t#[ho][l]en#[ho][l]t#[ho][l]en#ge[ho][l]t
[hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t
[h][o][l]e#[h][o][l]st#[h][o][l]t#[h][o][l]en#[h][o][l]t#[h][o][l]en#ge[h][o][l]t
[h][ol]e#[h][ol]st#[h][ol]t#[h][ol]en#[h][ol]t#[h][ol]en#ge[h][ol]t
Filter(BracketedMLCS &amp; BracketedTable)
[hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t
</figure>
<figureCaption confidence="0.999477">
Figure 3: Illustrated steps in the process of extracting and identifying the MLCS. The MLCS language
</figureCaption>
<bodyText confidence="0.97049068">
contains only the longest common subsequence(s). From that language, the language BracketedMLCS
is generated, which contains arbitrary strings with the MLCS bracketed in different ways (X here repre-
sents any string from Σ∗). Intersecting that language with the BracketedTable language and filtering
out suboptimal bracketings yields the final generalization.
can be set aside until the main algorithm is com-
pleted, and then attached as a separate variable to
the paradigm that was extracted without p. This
has little noticeable effect in most cases, but does
speed up the variable minimization with large ta-
bles that contains words more than 30 characters
long. Although not included in the implementa-
tion, the same maneuver can subsequently be per-
formed on the longest common suffix of the re-
maining string after the prefix is extracted.
Additionally, there are still residual cases
where the LCS may be located in several ways
with the same number of variables. An ac-
tual example comes from a Swedish paradigm
with two options: [sege]l#[seg]l[e]n#[seg]l[e]t vs.
[seg]e[l]#[segl]en#[segl]et. The ambiguity here
is due to the two equally long LCSs sege and
segl. These are resolved in our implementation
through non-finite-state means by choosing the di-
vision that results in the smallest number of infix-
segments.
</bodyText>
<sectionHeader confidence="0.993867" genericHeader="method">
5 Implementation
</sectionHeader>
<bodyText confidence="0.999699111111111">
We have implemented the above paradigm ex-
tractor as a freely available stand-alone tool
pextract.6 The utility reads inflection tables,
generalizes them into paradigms and collapses re-
sulting identical paradigms. Steps ➂ and ➃ in
figure 1 are trivially performed by non-finite state
means. After paradigm generalization, bracketed
sequences are replaced by variable symbols (step
➂). As each paradigm is then represented as a sin-
</bodyText>
<footnote confidence="0.944132">
6http://pextract.googlecode.com
</footnote>
<bodyText confidence="0.998993766666667">
gle string, paradigm collapsing can be performed
by simply testing string equivalence.
The tool also implements some further global
restrictions on the nature of the generalizations al-
lowed. These include, for example, a linguistically
motivated attempt to minimize the number of in-
fixes in paradigms. It also stores information (see
figure 4) about the components of generalizations:
the variable instantiations seen, etc., which may be
useful for subsequent tools that take advantage of
its output.7
Figure 4 briefly illustrates through a toy exam-
ple the input and output to the extraction tool:
inputs are simply lists of entries in inflection ta-
bles, with or without morphological information,
and the output is a list of paradigms where num-
bers correspond to variables. In the event that sev-
eral paradigms can be collapsed, the tool collapses
them (as indeed is seen in figure 4). The actual in-
stantiations of the variables seen are also stored,
represented by the digits 1,... as are the complete
first (often base) forms, represented by 0. In effect,
all the seen inflection tables can in principle be re-
constructed from the resulting abstract paradigms.
Table 2 shows how the pextract tool gener-
alizes with five data sets covering German (DE),
Spanish (ES), and Finnish (FI), provided by Dur-
rett and DeNero (2013), along with running times.
Here, among other things, we see that the tool
has generalized 3,855 Spanish verb inflection ta-
</bodyText>
<footnote confidence="0.53305675">
7Statistical information about what the variables looked
like during generalization can be useful information when
performing classifying tasks, such as attempting to fit pre-
viously unseen words to already learned paradigms, etc.
</footnote>
<page confidence="0.994309">
34
</page>
<figure confidence="0.455493">
pextract
</figure>
<construct confidence="0.865201625">
katabtu perf-1-sg
katabta perf-2-m-sg
kutibu pass-perf-3-m-pl
kutibna pass-perf-3-f-pl
darastu perf-1-sg
darasta perf-2-m-sg
durisu pass-perf-3-m-pl
durisna pass-perf-3-f-pl
</construct>
<figure confidence="0.994144666666667">
1+a+2+a+3+tu#1+a+2+a+3+ta#1+u+2+i+3+u#1+u+2+i+3+na
0=katabtu
1=k
2=t
3=b
0=darastu
1=d
2=r
3=s
</figure>
<figureCaption confidence="0.995403">
Figure 4: Paradigm extraction tool. For the two toy Arabic inflection tables on the left, the pextract
</figureCaption>
<bodyText confidence="0.963374647058824">
tool produces one three-variable paradigm as output, and reports how the three variables have been
instantiated in the example data, and also how the first form (presumably often the base form) appeared
in its entirety.
bles into 97 distinct paradigms, and 6,200 Finnish
nouns and adjectives have been reduced to 258
paradigms. For comparison, the fairly com-
plete Thompson (1998) lists 79 classes of Span-
ish verbs, while the Kotus (2007) grammar de-
scription counts 51 Finnish noun and adjective
paradigms.
Much of the remaining redundancy in resulting
paradigms can be attributed to lack of phonologi-
cal modeling. That is, paradigms could be further
collapsed if phonological alternations were added
subsequently to paradigm extraction. Consider a
selection of four forms from the inflection table
for the Finnish verb aidata (to fence):
</bodyText>
<equation confidence="0.78052225">
aidata#aitaan#aitaat#aitasin (6)
This is generalized by the tool into
x1+d+x2+ta#x1+t+x2+an#x1+t+x2+at#x1+t+x2+sin
(7)
</equation>
<bodyText confidence="0.999599736842105">
The generalization is indeed correct, but the
method does not take into account a gen-
eral phonological process of consonant gradation
where t and d alternate depending on the syllable
type. With this additional information, paradigm
tables could in principle be collapsed further and
this particular paradigm merged with a more gen-
eral paradigm learned for Finnish verbs. The
same goes for other phonological processes which
sometimes cause the tool to produce superficially
different paradigms that could be collapsed further
by modeling vowel harmony and other phenom-
ena.
We may note that the word lengths and inflec-
tion table sizes encountered in the wild are far
larger than the examples used in this article. For
the Wiktionary data, for example, many inflection
tables have more than 50 entries and word lengths
of 50 characters.
</bodyText>
<table confidence="0.913484">
Input: Output: Comp.
Data inflection abstract time(s)
tables paradigms
DE-VERBS 1,827 140 123.6
DE-NOUNS 2,564 70 73.5
ES-VERBS 3,855 97 144.9
FI-VERBS 7,049 282 432.2
FI-NOUNS-ADJS 6,200 258 374.1
</table>
<tableCaption confidence="0.9580585">
Table 2: Paradigm generalization from
Wiktionary-gathered inflection tables.
</tableCaption>
<sectionHeader confidence="0.99869" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999974615384615">
In this work, we have presented a method for
extracting general paradigms from inflection ta-
bles through entirely finite state means. This in-
volves solving a constrained longest common sub-
sequence problem, for which the calculus offered
by modern finite state toolkits is well suited. Al-
though the problem in no way requires a finite
state solution, we find that addressing it with a
general-purpose programming language appears
far more complex a route.
We further note that finite state transducers can
be profitably employed after paradigm generaliza-
tion has occurred—to find all possible paradigms
and slots that an unknown word form might fit
into, to generate paradigms from base forms, and
so forth.
An interesting further potential optimization is
to try to address ambiguous LCS assignments with
the completely different strategy of attempting to
maximize similarity across paradigms, or mini-
mize the number of resulting paradigms, assuming
one is generalizing a batch of inflection tables at
the same time. Additionally, modeling phonolog-
ical phenomena as a separate step after morpho-
logical paradigm generalization provides opportu-
nities for further development of the system.
</bodyText>
<page confidence="0.998996">
35
</page>
<sectionHeader confidence="0.999105" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999399">
This article was much improved by the insightful
comments provided by the anonymous reviewers.
The research was partially funded by the Academy
of Finland under grant agreement 258373, Ma-
chine learning of rules in natural language mor-
phology and phonology. Additional important
support was provided by the Centre for Language
Technology and Spr˚akbanken at the University of
Gothenburg, where part of this research was un-
dertaken.
</bodyText>
<sectionHeader confidence="0.999381" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999544141025641">
Angluin, D. (1980). Finding patterns common to a
set of strings. Journal of Computer and System
Sciences, 21(1):46–62.
Dreyer, M. and Eisner, J. (2011). Discovering
morphological paradigms from plain text using
a Dirichlet process mixture model. In Proceed-
ings of the Conference on Empirical Methods in
Natural Language Processing, pages 616–627.
Association for Computational Linguistics.
Durrett, G. and DeNero, J. (2013). Supervised
learning of complete morphological paradigms.
In Proceedings of NAACL-HLT, pages 1185–
1195.
Eisner, J. (2002). Comprehension and compilation
in optimality theory. In Proceedings of the 40th
Annual Meeting on Association for Computa-
tional Linguistics, pages 56–63. Association for
Computational Linguistics.
Eskander, R., Habash, N., and Rambow, O.
(2013). Automatic extraction of morpholog-
ical lexicons from morphologically annotated
corpora. In Proceedings of the 2013 Confer-
ence on Empirical Methods in Natural Lan-
guage Processing, pages 1032–1043. Associa-
tion for Computational Linguistics.
Gerdemann, D. and Hulden, M. (2012). Practi-
cal finite state optimality theory. In 10th Inter-
national Workshop on Finite State Methods and
Natural Language Processing, page 10.
Gerdemann, D. and van Noord, G. (2000). Ap-
proximation and exactness in finite state opti-
mality theory. In Proceedings of the Fifth Work-
shop of the ACL Special Interest Group in Com-
putational Phonology.
Hockett, C. F. (1954). Two models of grammatical
description. Morphology: Critical Concepts in
Linguistics, 1:110–138.
Hulden, M. (2009). Foma: a finite-state compiler
and library. In Proceedings of the 12th Confer-
ence of the European Chapter of the European
Chapter of the Association for Computational
Linguistics: Demonstrations Session, pages 29–
32, Athens, Greece. Association for Computa-
tional Linguistics.
Hulden, M., Forsberg, M., and Ahlberg, M.
(2014). Semi-supervised learning of morpho-
logical paradigms and lexicons. In Proceedings
of the 14th Conference of the European Chap-
ter of the Association for Computational Lin-
guistics, pages 569–578, Gothenburg, Sweden.
Association for Computational Linguistics.
Irving, R. W. and Fraser, C. B. (1992). Two algo-
rithms for the longest common subsequence of
three (or more) strings. In Combinatorial Pat-
tern Matching, pages 214–229. Springer.
Karttunen, L. (2010). Update on finite state mor-
phology tools. Ms., Palo Alto Research Center.
Kotus (2007). Nykysuomen sanalista [Lexicon of
modern Finnish]. Kotus.
Maier, D. (1978). The complexity of some
problems on subsequences and supersequences.
Journal of the ACM (JACM), 25(2):322–336.
Matthews, P. H. (1972). Inflectional morphology:
A theoretical study based on aspects of Latin
verb conjugation. Cambridge University Press.
Robins, R. H. (1959). In defence of WP. Trans-
actions of the Philological Society, 58(1):116–
144.
Stump, G. T. (2001). A theory of paradigm struc-
ture. Cambridge University Press.
Thompson, S. J. (1998). 15,000 Spanish verbs:
fully conjugated in all the tenses using pattern
verbs. Center for Innovative Language Learn-
ing.
Wang, Q., Pan, M., Shang, Y., and Korkin, D.
(2010). A fast heuristic search algorithm for
finding the longest common subsequence of
multiple strings. In AAAI Proc.
</reference>
<page confidence="0.998937">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.899289">
<title confidence="0.999886">Generalizing inflection tables into paradigms with finite state operations</title>
<author confidence="0.999706">Mans Hulden</author>
<affiliation confidence="0.999753">University of Helsinki</affiliation>
<email confidence="0.977341">mans.hulden@helsinki.fi</email>
<abstract confidence="0.996018">Extracting and performing an alignment of the longest common subsequence in inflection tables has been shown to be a fruitful approach to supervised learning of morphological paradigms. However, finding the longest subsequence common to multiple strings is well known to be an intractable problem. Additional constraints on the solution sought complicate the problem further—such as requiring that the particular subsequence extracted, if there is ambiguity, be one that is best alignable in an inflection table. In this paper we present and discuss the design of a tool that performs the extraction through some advanced techniques in finite state calculus and does so efficiently enough for the practical purposes of inflection table generalization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Angluin</author>
</authors>
<title>Finding patterns common to a set of strings.</title>
<date>1980</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>21</volume>
<issue>1</issue>
<contexts>
<context position="5846" citStr="Angluin, 1980" startWordPosition="915" endWordPosition="916">.e. complete inflection tables—we intuitively want to find the ‘common’ elements of a table and generalize those. The core of the method is to factor the word forms in an inflection table in such a manner that the elements common to all entries are declared variables, while the non-common elements are assumed to be part of the inflection pattern. To illustrate the idea with an example, consider a shortened inflection table for the regular German verb holen (to fetch):2 1Our formalization of a paradigm of strings and intervening variables bears many similarities to so-called pattern languages (Angluin, 1980). In fact, each entry in a paradigm could be considered a separate pattern language. Additionally, all the individual pattern languages in one paradigm are constrained to share the same variables and the variables are constrained to collectively be instantiated the same way. 2We follow the convention that entries in an inflection table are separated by #. hole#holst#holt#holen#holt#holen#geholt (1) Obviously, in this example, the element common to each entry in the inflection table is hol. Declaring hol to be a variable, we can rewrite the inflection table as: x1+e#x1+st#x1+t#x1+en#x1+t#x1+en#</context>
</contexts>
<marker>Angluin, 1980</marker>
<rawString>Angluin, D. (1980). Finding patterns common to a set of strings. Journal of Computer and System Sciences, 21(1):46–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dreyer</author>
<author>J Eisner</author>
</authors>
<title>Discovering morphological paradigms from plain text using a Dirichlet process mixture model.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>616--627</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9365" citStr="Dreyer and Eisner (2011)" startWordPosition="1478" endWordPosition="1481">as shown that the paradigm extraction and generalization method provides competitive results in various supervised and semi-supervised NLP learning tasks. One such task is to provide a hypothetical reconstruction of a complete inflection table from an unseen base form after first witnessing a number of complete inflection tables. Another task is the semi-supervised collection of lexical entries and matching them to paradigms by observing distributions of word forms across all the possible paradigms they can fit into. In general, there is much current interest in similar tasks in NLP; see e.g. Dreyer and Eisner (2011); Durrett and DeNero (2013); Eskander et al. (2013) for a variety of current methods. 3 Learning method The basic procedure as outlined by Hulden et al. (2014) for learning paradigms from inflection tables can be represented by the four-step procedure given in figure 1. Here, multiple inflection tables are gathered, and the LCS to each table is found individually. Following that, the LCS is fit into the table, and contiguous segments that participate in the LCS are labeled variables. After paradigm generalization, it may turn out that several identical paradigms have been learned, which may th</context>
</contexts>
<marker>Dreyer, Eisner, 2011</marker>
<rawString>Dreyer, M. and Eisner, J. (2011). Discovering morphological paradigms from plain text using a Dirichlet process mixture model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 616–627. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Durrett</author>
<author>J DeNero</author>
</authors>
<title>Supervised learning of complete morphological paradigms.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>1185--1195</pages>
<contexts>
<context position="9392" citStr="Durrett and DeNero (2013)" startWordPosition="1482" endWordPosition="1486"> extraction and generalization method provides competitive results in various supervised and semi-supervised NLP learning tasks. One such task is to provide a hypothetical reconstruction of a complete inflection table from an unseen base form after first witnessing a number of complete inflection tables. Another task is the semi-supervised collection of lexical entries and matching them to paradigms by observing distributions of word forms across all the possible paradigms they can fit into. In general, there is much current interest in similar tasks in NLP; see e.g. Dreyer and Eisner (2011); Durrett and DeNero (2013); Eskander et al. (2013) for a variety of current methods. 3 Learning method The basic procedure as outlined by Hulden et al. (2014) for learning paradigms from inflection tables can be represented by the four-step procedure given in figure 1. Here, multiple inflection tables are gathered, and the LCS to each table is found individually. Following that, the LCS is fit into the table, and contiguous segments that participate in the LCS are labeled variables. After paradigm generalization, it may turn out that several identical paradigms have been learned, which may then be collapsed. The first </context>
<context position="24432" citStr="Durrett and DeNero (2013)" startWordPosition="3848" endWordPosition="3852">, and the output is a list of paradigms where numbers correspond to variables. In the event that several paradigms can be collapsed, the tool collapses them (as indeed is seen in figure 4). The actual instantiations of the variables seen are also stored, represented by the digits 1,... as are the complete first (often base) forms, represented by 0. In effect, all the seen inflection tables can in principle be reconstructed from the resulting abstract paradigms. Table 2 shows how the pextract tool generalizes with five data sets covering German (DE), Spanish (ES), and Finnish (FI), provided by Durrett and DeNero (2013), along with running times. Here, among other things, we see that the tool has generalized 3,855 Spanish verb inflection ta7Statistical information about what the variables looked like during generalization can be useful information when performing classifying tasks, such as attempting to fit previously unseen words to already learned paradigms, etc. 34 pextract katabtu perf-1-sg katabta perf-2-m-sg kutibu pass-perf-3-m-pl kutibna pass-perf-3-f-pl darastu perf-1-sg darasta perf-2-m-sg durisu pass-perf-3-m-pl durisna pass-perf-3-f-pl 1+a+2+a+3+tu#1+a+2+a+3+ta#1+u+2+i+3+u#1+u+2+i+3+na 0=katabtu </context>
</contexts>
<marker>Durrett, DeNero, 2013</marker>
<rawString>Durrett, G. and DeNero, J. (2013). Supervised learning of complete morphological paradigms. In Proceedings of NAACL-HLT, pages 1185– 1195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Comprehension and compilation in optimality theory.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>56--63</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="17887" citStr="Eisner (2002)" startWordPosition="2931" endWordPosition="2932"> 17. The output is [hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t [hol]en#ge[hol]t would represent a one-variable division. Naturally, these brackets will have to be divided in such a way that there is no better way to achieve the division—i.e. no markup such that fewer variables are instantiated. The crux of the method used here is to first produce an automaton that accepts the set of all valid markups of the MLCS in the table string, and then use that set to in turn define the set of suboptimal markups. Similar finite-state techniques have been used by Gerdemann and van Noord (2000); Eisner (2002); Karttunen (2010); Gerdemann and Hulden (2012), to, among other things, define suboptimal candidates in Optimality Theory. The trick is to set up a transducer T that contains the input-output pair (x, x&apos;), iff x&apos; represents a worse division of variables than x does. In effect, T captures the transitive closure of an ordering relation &gt;- of the various factorizations of the strings into variables, and T contains the string pair (x, x&apos;) when x &gt;-+ x&apos;. In general, supposing that we have an identity transducer, i.e. automaton A, and a transducer T that maps strings in A according to the transitiv</context>
</contexts>
<marker>Eisner, 2002</marker>
<rawString>Eisner, J. (2002). Comprehension and compilation in optimality theory. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 56–63. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Eskander</author>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Automatic extraction of morphological lexicons from morphologically annotated corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1032--1043</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9416" citStr="Eskander et al. (2013)" startWordPosition="1487" endWordPosition="1490">ion method provides competitive results in various supervised and semi-supervised NLP learning tasks. One such task is to provide a hypothetical reconstruction of a complete inflection table from an unseen base form after first witnessing a number of complete inflection tables. Another task is the semi-supervised collection of lexical entries and matching them to paradigms by observing distributions of word forms across all the possible paradigms they can fit into. In general, there is much current interest in similar tasks in NLP; see e.g. Dreyer and Eisner (2011); Durrett and DeNero (2013); Eskander et al. (2013) for a variety of current methods. 3 Learning method The basic procedure as outlined by Hulden et al. (2014) for learning paradigms from inflection tables can be represented by the four-step procedure given in figure 1. Here, multiple inflection tables are gathered, and the LCS to each table is found individually. Following that, the LCS is fit into the table, and contiguous segments that participate in the LCS are labeled variables. After paradigm generalization, it may turn out that several identical paradigms have been learned, which may then be collapsed. The first two steps of the method </context>
</contexts>
<marker>Eskander, Habash, Rambow, 2013</marker>
<rawString>Eskander, R., Habash, N., and Rambow, O. (2013). Automatic extraction of morphological lexicons from morphologically annotated corpora. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1032–1043. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gerdemann</author>
<author>M Hulden</author>
</authors>
<title>Practical finite state optimality theory.</title>
<date>2012</date>
<booktitle>In 10th International Workshop on Finite State Methods and Natural Language Processing,</booktitle>
<pages>10</pages>
<contexts>
<context position="17934" citStr="Gerdemann and Hulden (2012)" startWordPosition="2935" endWordPosition="2938">#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t [hol]en#ge[hol]t would represent a one-variable division. Naturally, these brackets will have to be divided in such a way that there is no better way to achieve the division—i.e. no markup such that fewer variables are instantiated. The crux of the method used here is to first produce an automaton that accepts the set of all valid markups of the MLCS in the table string, and then use that set to in turn define the set of suboptimal markups. Similar finite-state techniques have been used by Gerdemann and van Noord (2000); Eisner (2002); Karttunen (2010); Gerdemann and Hulden (2012), to, among other things, define suboptimal candidates in Optimality Theory. The trick is to set up a transducer T that contains the input-output pair (x, x&apos;), iff x&apos; represents a worse division of variables than x does. In effect, T captures the transitive closure of an ordering relation &gt;- of the various factorizations of the strings into variables, and T contains the string pair (x, x&apos;) when x &gt;-+ x&apos;. In general, supposing that we have an identity transducer, i.e. automaton A, and a transducer T that maps strings in A according to the transitive closure of an ordering relation &gt;-, then we c</context>
</contexts>
<marker>Gerdemann, Hulden, 2012</marker>
<rawString>Gerdemann, D. and Hulden, M. (2012). Practical finite state optimality theory. In 10th International Workshop on Finite State Methods and Natural Language Processing, page 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gerdemann</author>
<author>G van Noord</author>
</authors>
<title>Approximation and exactness in finite state optimality theory.</title>
<date>2000</date>
<booktitle>In Proceedings of the Fifth Workshop of the ACL Special Interest Group in Computational Phonology.</booktitle>
<marker>Gerdemann, van Noord, 2000</marker>
<rawString>Gerdemann, D. and van Noord, G. (2000). Approximation and exactness in finite state optimality theory. In Proceedings of the Fifth Workshop of the ACL Special Interest Group in Computational Phonology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Hockett</author>
</authors>
<title>Two models of grammatical description. Morphology: Critical Concepts in Linguistics,</title>
<date>1954</date>
<pages>1--110</pages>
<contexts>
<context position="3595" citStr="Hockett, 1954" startWordPosition="553" endWordPosition="554"> learning of morphological paradigms in section 2. We then describe in broad strokes the algorithm required for generalizing inflection tables into paradigms in section 3. Next, we give a finite state implementation of the algorithm in section 4, followed by a brief discussion of a stand-alone software tool based on this that extracts paradigms from collections of inflection tables in section 5. 2 Supervised learning of morphological paradigms In the following, we operate with the central idea of a model of word formation that organizes word forms and their inflection patterns into paradigms (Hockett, 1954; Robins, 1959; Matthews, 1972; 29 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 29–36, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics Stump, 2001). In particular, we model paradigms in a slightly more abstract manner than is customarily done. For the purposes of this paper, we differentiate between a paradigm and an inflection table in the following way: an inflection table is simply a list of words that represents a concrete manifestation, or instantiation, of a paradigm. A paradigm is also a list of words, but with special sym</context>
</contexts>
<marker>Hockett, 1954</marker>
<rawString>Hockett, C. F. (1954). Two models of grammatical description. Morphology: Critical Concepts in Linguistics, 1:110–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hulden</author>
</authors>
<title>Foma: a finite-state compiler and library.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the European Chapter of the Association for Computational Linguistics: Demonstrations Session,</booktitle>
<pages>29--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece.</location>
<contexts>
<context position="11975" citStr="Hulden, 2009" startWordPosition="1922" endWordPosition="1923"> specialized algorithms that attempt to efficiently either calculate (Irving and Fraser, 1992) or approximate (Wang et al., 2010) the LCS, we find that extraction can easily be accomplished with a simple transducer calculation. The task of ascertaining that the LCS is distributed in such a way as to minimize the number of variables turns out to be more challenging; at the same time, however, it is a problem to which the finite state calculus is particularly well suited, as will be seen below. 4.1 Notation and tool The paradigm extraction tool was implemented with the help of the foma toolkit (Hulden, 2009). In the actual implementation, instead of directly compiling regular expressions, we make use of foma’s programming API, but in the following we give regular expression equivalents to the method used. Table 1 contains a summary of the regular expression notation used. [r]i[ng] rng [r]a[ng] [r]u[ng] [sw]i[m] SWM [sw]a[m] [sw]u[m] x1+i+x2 x1+a+x2 x1+u+x2 x1+i+x2 x1+a+x2 x1+u+x2 } } x1+i+x2 x1+a+x2 x1+u+x2 } } ring rang rung swim swam swum 31 0 Empty string ? Any symbol in alphabet .#. End or beginning of string {xyz} String AB Concatenation A*, A+ Kleene star, Kleene plus A|B Union A &amp; B Inters</context>
</contexts>
<marker>Hulden, 2009</marker>
<rawString>Hulden, M. (2009). Foma: a finite-state compiler and library. In Proceedings of the 12th Conference of the European Chapter of the European Chapter of the Association for Computational Linguistics: Demonstrations Session, pages 29– 32, Athens, Greece. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hulden</author>
<author>M Forsberg</author>
<author>M Ahlberg</author>
</authors>
<title>Semi-supervised learning of morphological paradigms and lexicons.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>569--578</pages>
<institution>Gothenburg, Sweden. Association for Computational Linguistics.</institution>
<contexts>
<context position="1083" citStr="Hulden et al. (2014)" startWordPosition="157" endWordPosition="160"> on the solution sought complicate the problem further—such as requiring that the particular subsequence extracted, if there is ambiguity, be one that is best alignable in an inflection table. In this paper we present and discuss the design of a tool that performs the extraction through some advanced techniques in finite state calculus and does so efficiently enough for the practical purposes of inflection table generalization. 1 Introduction Supervised learning of morphological paradigms from inflection tables has recently been approached from a number of directions. One approach is given in Hulden et al. (2014), where morphological paradigm induction is performed by extracting the longest common subsequence (LCS) from a set of words representing an inflection table. Although that work presents encouraging results as regards learning morphological paradigms from inflection tables, no details are given as to how the paradigms themselves are extracted. The purpose of this paper is to describe how such a paradigm extraction procedure can be performed using only finite state operations. Extracting the longest common subsequence from a large number of strings is known as the multiple longest common subseq</context>
<context position="6536" citStr="Hulden et al. (2014)" startWordPosition="1018" endWordPosition="1021">tern language. Additionally, all the individual pattern languages in one paradigm are constrained to share the same variables and the variables are constrained to collectively be instantiated the same way. 2We follow the convention that entries in an inflection table are separated by #. hole#holst#holt#holen#holt#holen#geholt (1) Obviously, in this example, the element common to each entry in the inflection table is hol. Declaring hol to be a variable, we can rewrite the inflection table as: x1+e#x1+st#x1+t#x1+en#x1+t#x1+en#ge+x1+t (2) This extraction of the ‘common elements’ is formalized in Hulden et al. (2014) to be equivalent to extraction of the longest common subsequence of the strings w1, ... , wn in an inflection table.3 The purpose of extracting the common parts and labeling them variables is to provide a model for generalization of inflection patterns. Under the assumption that a variable xi in this paradigm representation corresponds to a nonempty string, we can instantiate an inflection table by simply providing the variable strings x1,... , xn. Thus, we can talk about a paradigm-generating function f : (x1,...,xn) → Σ∗ that maps instantiations of variables to a string representing the com</context>
<context position="8739" citStr="Hulden et al. (2014)" startWordPosition="1377" endWordPosition="1380">y abcaa and t by dbcadaa. By contrast, the longest common subsequence is bcaa, obtained from s by abcaa and t by dbcadaa or dbcadaa or dbcadaa. 30 Input:  Extract  Fit LCS  Generalize  Collapse inflection LCS to table to paradigms paradigms tables Figure 1: Paradigm extraction strategy. In other words, the extraction of multiple common longest subsequences (MLCS) from inflection tables immediately provides a (simple) generalization mechanism of a grammar, and also suggests a supervised learning strategy for morphological paradigms. In conjunction with statistical machine learning methods, Hulden et al. (2014) has shown that the paradigm extraction and generalization method provides competitive results in various supervised and semi-supervised NLP learning tasks. One such task is to provide a hypothetical reconstruction of a complete inflection table from an unseen base form after first witnessing a number of complete inflection tables. Another task is the semi-supervised collection of lexical entries and matching them to paradigms by observing distributions of word forms across all the possible paradigms they can fit into. In general, there is much current interest in similar tasks in NLP; see e.g</context>
</contexts>
<marker>Hulden, Forsberg, Ahlberg, 2014</marker>
<rawString>Hulden, M., Forsberg, M., and Ahlberg, M. (2014). Semi-supervised learning of morphological paradigms and lexicons. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 569–578, Gothenburg, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Irving</author>
<author>C B Fraser</author>
</authors>
<title>Two algorithms for the longest common subsequence of three (or more) strings.</title>
<date>1992</date>
<booktitle>In Combinatorial Pattern Matching,</booktitle>
<pages>214--229</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="11456" citStr="Irving and Fraser, 1992" startWordPosition="1829" endWordPosition="1832">s of the LCS in a way that gives rise to the minimum number of variables (20). 4 Finite-state implementation The main challenge in producing a paradigm from an inflection table is not the extraction of the longest common subsequences, but rather, doing so with the added criterion of minimizing the number of variables used. Extracting the LCS from multiple strings is known to be NP-hard (Maier, 1978) and naive implementations will fail quickly for even a moderate number of strings found in inflection tables. While there exist specialized algorithms that attempt to efficiently either calculate (Irving and Fraser, 1992) or approximate (Wang et al., 2010) the LCS, we find that extraction can easily be accomplished with a simple transducer calculation. The task of ascertaining that the LCS is distributed in such a way as to minimize the number of variables turns out to be more challenging; at the same time, however, it is a problem to which the finite state calculus is particularly well suited, as will be seen below. 4.1 Notation and tool The paradigm extraction tool was implemented with the help of the foma toolkit (Hulden, 2009). In the actual implementation, instead of directly compiling regular expressions</context>
</contexts>
<marker>Irving, Fraser, 1992</marker>
<rawString>Irving, R. W. and Fraser, C. B. (1992). Two algorithms for the longest common subsequence of three (or more) strings. In Combinatorial Pattern Matching, pages 214–229. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>Update on finite state morphology tools. Ms., Palo Alto Research Center.</title>
<date>2010</date>
<contexts>
<context position="17905" citStr="Karttunen (2010)" startWordPosition="2933" endWordPosition="2934"> is [hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t [hol]en#ge[hol]t would represent a one-variable division. Naturally, these brackets will have to be divided in such a way that there is no better way to achieve the division—i.e. no markup such that fewer variables are instantiated. The crux of the method used here is to first produce an automaton that accepts the set of all valid markups of the MLCS in the table string, and then use that set to in turn define the set of suboptimal markups. Similar finite-state techniques have been used by Gerdemann and van Noord (2000); Eisner (2002); Karttunen (2010); Gerdemann and Hulden (2012), to, among other things, define suboptimal candidates in Optimality Theory. The trick is to set up a transducer T that contains the input-output pair (x, x&apos;), iff x&apos; represents a worse division of variables than x does. In effect, T captures the transitive closure of an ordering relation &gt;- of the various factorizations of the strings into variables, and T contains the string pair (x, x&apos;) when x &gt;-+ x&apos;. In general, supposing that we have an identity transducer, i.e. automaton A, and a transducer T that maps strings in A according to the transitive closure of an or</context>
</contexts>
<marker>Karttunen, 2010</marker>
<rawString>Karttunen, L. (2010). Update on finite state morphology tools. Ms., Palo Alto Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kotus</author>
</authors>
<title>Nykysuomen sanalista [Lexicon of modern Finnish].</title>
<date>2007</date>
<publisher>Kotus.</publisher>
<contexts>
<context position="25606" citStr="Kotus (2007)" startWordPosition="4018" endWordPosition="4019">ta#1+u+2+i+3+u#1+u+2+i+3+na 0=katabtu 1=k 2=t 3=b 0=darastu 1=d 2=r 3=s Figure 4: Paradigm extraction tool. For the two toy Arabic inflection tables on the left, the pextract tool produces one three-variable paradigm as output, and reports how the three variables have been instantiated in the example data, and also how the first form (presumably often the base form) appeared in its entirety. bles into 97 distinct paradigms, and 6,200 Finnish nouns and adjectives have been reduced to 258 paradigms. For comparison, the fairly complete Thompson (1998) lists 79 classes of Spanish verbs, while the Kotus (2007) grammar description counts 51 Finnish noun and adjective paradigms. Much of the remaining redundancy in resulting paradigms can be attributed to lack of phonological modeling. That is, paradigms could be further collapsed if phonological alternations were added subsequently to paradigm extraction. Consider a selection of four forms from the inflection table for the Finnish verb aidata (to fence): aidata#aitaan#aitaat#aitasin (6) This is generalized by the tool into x1+d+x2+ta#x1+t+x2+an#x1+t+x2+at#x1+t+x2+sin (7) The generalization is indeed correct, but the method does not take into account </context>
</contexts>
<marker>Kotus, 2007</marker>
<rawString>Kotus (2007). Nykysuomen sanalista [Lexicon of modern Finnish]. Kotus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Maier</author>
</authors>
<title>The complexity of some problems on subsequences and supersequences.</title>
<date>1978</date>
<journal>Journal of the ACM (JACM),</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="11234" citStr="Maier, 1978" startWordPosition="1797" endWordPosition="1798">ite-state means. In the following, we will focus on the previously unaddressed problem of finding the LCS of an inflection table (10), and of distributing possible variables corresponding to contiguous sequences of the LCS in a way that gives rise to the minimum number of variables (20). 4 Finite-state implementation The main challenge in producing a paradigm from an inflection table is not the extraction of the longest common subsequences, but rather, doing so with the added criterion of minimizing the number of variables used. Extracting the LCS from multiple strings is known to be NP-hard (Maier, 1978) and naive implementations will fail quickly for even a moderate number of strings found in inflection tables. While there exist specialized algorithms that attempt to efficiently either calculate (Irving and Fraser, 1992) or approximate (Wang et al., 2010) the LCS, we find that extraction can easily be accomplished with a simple transducer calculation. The task of ascertaining that the LCS is distributed in such a way as to minimize the number of variables turns out to be more challenging; at the same time, however, it is a problem to which the finite state calculus is particularly well suite</context>
</contexts>
<marker>Maier, 1978</marker>
<rawString>Maier, D. (1978). The complexity of some problems on subsequences and supersequences. Journal of the ACM (JACM), 25(2):322–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P H Matthews</author>
</authors>
<title>Inflectional morphology: A theoretical study based on aspects of Latin verb conjugation.</title>
<date>1972</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3625" citStr="Matthews, 1972" startWordPosition="557" endWordPosition="558">radigms in section 2. We then describe in broad strokes the algorithm required for generalizing inflection tables into paradigms in section 3. Next, we give a finite state implementation of the algorithm in section 4, followed by a brief discussion of a stand-alone software tool based on this that extracts paradigms from collections of inflection tables in section 5. 2 Supervised learning of morphological paradigms In the following, we operate with the central idea of a model of word formation that organizes word forms and their inflection patterns into paradigms (Hockett, 1954; Robins, 1959; Matthews, 1972; 29 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 29–36, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics Stump, 2001). In particular, we model paradigms in a slightly more abstract manner than is customarily done. For the purposes of this paper, we differentiate between a paradigm and an inflection table in the following way: an inflection table is simply a list of words that represents a concrete manifestation, or instantiation, of a paradigm. A paradigm is also a list of words, but with special symbols that represent variables </context>
</contexts>
<marker>Matthews, 1972</marker>
<rawString>Matthews, P. H. (1972). Inflectional morphology: A theoretical study based on aspects of Latin verb conjugation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Robins</author>
</authors>
<title>In defence of WP.</title>
<date>1959</date>
<journal>Transactions of the Philological Society,</journal>
<volume>58</volume>
<issue>1</issue>
<pages>144</pages>
<contexts>
<context position="3609" citStr="Robins, 1959" startWordPosition="555" endWordPosition="556">rphological paradigms in section 2. We then describe in broad strokes the algorithm required for generalizing inflection tables into paradigms in section 3. Next, we give a finite state implementation of the algorithm in section 4, followed by a brief discussion of a stand-alone software tool based on this that extracts paradigms from collections of inflection tables in section 5. 2 Supervised learning of morphological paradigms In the following, we operate with the central idea of a model of word formation that organizes word forms and their inflection patterns into paradigms (Hockett, 1954; Robins, 1959; Matthews, 1972; 29 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 29–36, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics Stump, 2001). In particular, we model paradigms in a slightly more abstract manner than is customarily done. For the purposes of this paper, we differentiate between a paradigm and an inflection table in the following way: an inflection table is simply a list of words that represents a concrete manifestation, or instantiation, of a paradigm. A paradigm is also a list of words, but with special symbols that repr</context>
</contexts>
<marker>Robins, 1959</marker>
<rawString>Robins, R. H. (1959). In defence of WP. Transactions of the Philological Society, 58(1):116– 144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G T Stump</author>
</authors>
<title>A theory of paradigm structure.</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3807" citStr="Stump, 2001" startWordPosition="583" endWordPosition="584">on of the algorithm in section 4, followed by a brief discussion of a stand-alone software tool based on this that extracts paradigms from collections of inflection tables in section 5. 2 Supervised learning of morphological paradigms In the following, we operate with the central idea of a model of word formation that organizes word forms and their inflection patterns into paradigms (Hockett, 1954; Robins, 1959; Matthews, 1972; 29 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 29–36, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics Stump, 2001). In particular, we model paradigms in a slightly more abstract manner than is customarily done. For the purposes of this paper, we differentiate between a paradigm and an inflection table in the following way: an inflection table is simply a list of words that represents a concrete manifestation, or instantiation, of a paradigm. A paradigm is also a list of words, but with special symbols that represent variables interspersed. These variables, when instantiated, represent particular strings shared across an inflection table. In our representation, this kind of an abstract paradigm is an order</context>
</contexts>
<marker>Stump, 2001</marker>
<rawString>Stump, G. T. (2001). A theory of paradigm structure. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Thompson</author>
</authors>
<title>15,000 Spanish verbs: fully conjugated in all the tenses using pattern verbs. Center for Innovative Language Learning.</title>
<date>1998</date>
<contexts>
<context position="25548" citStr="Thompson (1998)" startWordPosition="4007" endWordPosition="4008">-perf-3-m-pl durisna pass-perf-3-f-pl 1+a+2+a+3+tu#1+a+2+a+3+ta#1+u+2+i+3+u#1+u+2+i+3+na 0=katabtu 1=k 2=t 3=b 0=darastu 1=d 2=r 3=s Figure 4: Paradigm extraction tool. For the two toy Arabic inflection tables on the left, the pextract tool produces one three-variable paradigm as output, and reports how the three variables have been instantiated in the example data, and also how the first form (presumably often the base form) appeared in its entirety. bles into 97 distinct paradigms, and 6,200 Finnish nouns and adjectives have been reduced to 258 paradigms. For comparison, the fairly complete Thompson (1998) lists 79 classes of Spanish verbs, while the Kotus (2007) grammar description counts 51 Finnish noun and adjective paradigms. Much of the remaining redundancy in resulting paradigms can be attributed to lack of phonological modeling. That is, paradigms could be further collapsed if phonological alternations were added subsequently to paradigm extraction. Consider a selection of four forms from the inflection table for the Finnish verb aidata (to fence): aidata#aitaan#aitaat#aitasin (6) This is generalized by the tool into x1+d+x2+ta#x1+t+x2+an#x1+t+x2+at#x1+t+x2+sin (7) The generalization is </context>
</contexts>
<marker>Thompson, 1998</marker>
<rawString>Thompson, S. J. (1998). 15,000 Spanish verbs: fully conjugated in all the tenses using pattern verbs. Center for Innovative Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Wang</author>
<author>M Pan</author>
<author>Y Shang</author>
<author>D Korkin</author>
</authors>
<title>A fast heuristic search algorithm for finding the longest common subsequence of multiple strings.</title>
<date>2010</date>
<booktitle>In AAAI Proc.</booktitle>
<contexts>
<context position="11491" citStr="Wang et al., 2010" startWordPosition="1835" endWordPosition="1838">the minimum number of variables (20). 4 Finite-state implementation The main challenge in producing a paradigm from an inflection table is not the extraction of the longest common subsequences, but rather, doing so with the added criterion of minimizing the number of variables used. Extracting the LCS from multiple strings is known to be NP-hard (Maier, 1978) and naive implementations will fail quickly for even a moderate number of strings found in inflection tables. While there exist specialized algorithms that attempt to efficiently either calculate (Irving and Fraser, 1992) or approximate (Wang et al., 2010) the LCS, we find that extraction can easily be accomplished with a simple transducer calculation. The task of ascertaining that the LCS is distributed in such a way as to minimize the number of variables turns out to be more challenging; at the same time, however, it is a problem to which the finite state calculus is particularly well suited, as will be seen below. 4.1 Notation and tool The paradigm extraction tool was implemented with the help of the foma toolkit (Hulden, 2009). In the actual implementation, instead of directly compiling regular expressions, we make use of foma’s programming</context>
</contexts>
<marker>Wang, Pan, Shang, Korkin, 2010</marker>
<rawString>Wang, Q., Pan, M., Shang, Y., and Korkin, D. (2010). A fast heuristic search algorithm for finding the longest common subsequence of multiple strings. In AAAI Proc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>