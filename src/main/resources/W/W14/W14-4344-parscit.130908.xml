<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003799">
<title confidence="0.995509">
Markovian Discriminative Modeling for Dialog State Tracking
</title>
<author confidence="0.998578">
Hang Ren, Weiqun Xu, Yonghong Yan
</author>
<affiliation confidence="0.996795">
The Key Laboratory of Speech Acoustics and Content Understanding
Institute of Acoustics, Chinese Academy of Sciences
</affiliation>
<address confidence="0.983918">
21 North 4th Ring West Road, Beijing, China, 100190
</address>
<email confidence="0.99665">
{renhang, xuweiqun, yanyonghong}@hccl.ioa.ac.cn
</email>
<sectionHeader confidence="0.997386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999777944444445">
Discriminative dialog state tracking has
become a hot topic in dialog research com-
munity recently. Compared to genera-
tive approach, it has the advantage of be-
ing able to handle arbitrary dependent fea-
tures, which is very appealing. In this
paper, we present our approach to the
DSTC2 challenge. We propose to use dis-
criminative Markovian models as a natu-
ral enhancement to the stationary discrim-
inative models. The Markovian structure
allows the incorporation of ‘transitional’
features, which can lead to more effi-
ciency and flexibility in tracking user goal
changes. Results on the DSTC2 dataset
show considerable improvements over the
baseline, and the effects of the Markovian
dependency is tested empirically.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999954071428572">
Spoken dialog systems (SDS) have become much
more popular these days, but still far from wide
adoption. One of the most outstanding problems
that affect user experience in an SDS is due to
automatic speech recognition (ASR) and spoken
language understanding (SLU) errors. While the
advancement of ASR technology has a positive ef-
fect on SDS, it is possible to improve the SDS user
experience by designing a module which explicitly
handles ASR and SLU errors. With accurately es-
timated dialog state, the dialog manager could se-
lect more effective and flexible dialog actions, re-
sulting in shorter dialogs and higher dialog success
rate. Dialog state tracking is the task of identifying
the correct dialog state (user action, user goal, etc.)
from ASR and SLU outputs in the presence of er-
rors. Commercial dialog systems these days usu-
ally use simple dialog state tracking strategies that
only consider the most probable SLU output. Pre-
vious research shows that several errors in dialog
state tracking can be rectified by considering the
full N-best results from the ASR and SLU compo-
nents (Williams, 2012). Thus it is very important
to develop robust and practical dialog state track-
ing models.
In statistical dialog state tracking, models
can be roughly divided into two major classes,
i.e. generative and discriminative. Generative
(Bayesian) dialog tracking models are prevalent
in early studies due to its close relationship with
the POMDP dialog management model (Young et
al., 2013). Generative models generally use Dy-
namic Bayesian Networks to model the observa-
tion probability P(Ot|St) and transition probabil-
ity P (St|St−1), where Ot and St are observations
and dialog state at turn t. In a discriminative
model, the conditional probability P(St|Ot1) is
modeled directly, where Ot1 is all the observations
from turn 1 to t. One problem with the generative
models is that the independent assumptions are al-
ways not realistic. For example, N-best hypothe-
ses are often assumed independent of each other,
which is flawed in realistic scenarios (Williams,
2012). Furthermore, it is intrinsically difficult for
generative models to handle overlapping features,
which prevents model designers from incorporat-
ing arbitrarily large feature set. Discriminative
model does not suffer from the above problems as
there is no need to make any assumptions about
the probabilistic dependencies of the features. As
a result. it is potentially able to handle much larger
feature sets and to make more accurate predic-
tions (Bohus and Rudnicky, 2006). Discrimina-
tive models also tend to be more data-driven, un-
like generative models in which many sub-models
parameters are heuristically tuned.
</bodyText>
<sectionHeader confidence="0.979124" genericHeader="introduction">
2 DSTC1 revisited
</sectionHeader>
<bodyText confidence="0.961809">
The first Dialog State Tracking Challenge
(DSTC1) for the first time provided a common
test bed for various state tracking methods, and
</bodyText>
<page confidence="0.976127">
327
</page>
<bodyText confidence="0.9607385">
Proceedings of the SIGDIAL 2014 Conference, pages 327–331,
Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics
several participants employed various discrimi-
native models in the challenge. DSTC1 provided
real user dialog corpora in the domain of bus
route service to evaluate performance of various
state tracking methods. In DSTC1 there are 9
teams with 27 submissions, where discriminative,
generative and rule-based models are used in the
challenge. Maximum entropy models (Lee and
Eskenazi, 2013), conditional random fields (Lee,
2013) and neural networks (Henderson et al.,
2013) are the most frequently used discriminative
models, which gave competitive results on several
metrics. It has been empirically analyzed that dis-
criminative methods are especially advantageous
when the ASR/SLU confidence scores are poorly
estimated (Williams et al., 2013).
</bodyText>
<sectionHeader confidence="0.9805415" genericHeader="method">
3 Discriminative modeling in dialog state
tracking
</sectionHeader>
<bodyText confidence="0.99999465625">
In the design of a slot-filling or task-oriented di-
alog systems, dialog state tracking can be consid-
ered as a classification problem, i.e. assigning pre-
defined values to a fixed number of slots. One
major problem in the formulation is that in com-
plex dialog scenarios the number of classes tends
to be very big, resulting in extremely sparse train-
ing instances for each class. This sparsity affects
the classification performance. A large predic-
tion domain also leads to computation inefficiency
which makes the model less practical. Usually we
could focus only on the on-list hypotheses, which
are the hypotheses appeared in the SLU results,
and all the other values in the slot value set are
grouped into a meta category Other. It is simi-
lar to the partition concept in HIS (Young et al.,
2010), and by doing this we could reduce the num-
ber of classes to a reasonable size. We use Yt to
denote the prediction domain at turn t. Although
the number of classes is reduced by focusing on
the dynamically generated Yt, some classes will
still suffer from the lack of training instances, and
what is even worse is that a large portion of the
classes will not have any training data, since in
practical SDS deployment it is hard to collect a
large dialog corpus. To handle the data sparseness
problem, parameters are often shared across dif-
ferent slots, or even data sets, and by doing this the
model complexity could be effectively controlled
and the overfitting problem would be alleviated.
Williams proposed to use various techniques from
multi-domain learning to improve model perfor-
</bodyText>
<equation confidence="0.343067">
Turn t-1 Turn t
</equation>
<figureCaption confidence="0.956492">
Figure 1: Markovian discriminative model depen-
</figureCaption>
<bodyText confidence="0.9830988">
dency diagram. In this figure the dialog state is
simplified to a single slot variable: date, the do-
main of the slot typically increases as dialog con-
tinues, which includes all the slot values appeared
as SLU results. As indicated by the arrows, St
depends on St−1 and Ot1. In stationary discrimi-
native model, there’s no dependency between ad-
jacent turns indicated by the upper arrow.
mance (Williams, 2013), which could be taken as
another way of parameter sharing.
</bodyText>
<subsectionHeader confidence="0.997224">
3.1 Markovian discriminative model
</subsectionHeader>
<bodyText confidence="0.9999885">
A dialog can be naturally seen as a temporal se-
quence involving a user and an agent, where strong
dependencies exist between adjacent turns. In typ-
ical task-oriented dialogs, users often change their
goals when their original object cannot be satis-
fied. Even when the true user goal stays constant
in a dialog session, the agent’s perception of it will
tend to evolve and be more accurate as the con-
versation proceeds, and thus the dialog state will
often change. The states at adjacent turns are sta-
tistically correlated, and therefore it is important
to leverage this natural temporal relationship in
tracking dialog state. We enhance the stationary
discriminative model in a similar way as described
in (McCallum et al., 2000), by assuming Marko-
vian dependency between adjacent turns.
Thus, the original probability P (St|Ot1) can be
factored into the following form:
</bodyText>
<equation confidence="0.983600666666667">
P(St|Ot1) = (1)
P(St|Ot1, St−1)P(St−1|Ot−1
1 )
</equation>
<bodyText confidence="0.911976">
The graphical model is shown is figure
</bodyText>
<figure confidence="0.948390416666667">
1. Unlike stationary discriminative models,
Monday: 0.5
Thursday: 0.2
Other: 0.3
Observations
from turn 1 to t
Monday: 0.7
Tuesday: 0.1
Thursday: 0.1
Other: 0.1
11
St−1ES
</figure>
<page confidence="0.990172">
328
</page>
<bodyText confidence="0.9987342">
we model the conditional transition probability
P(St|Ot1, St−1) instead of P(St|Ot1) and the dia-
log state is updated according to equation 1 at each
turn. The feature functions in the structured model
can depend on the state of the previous turn, which
we call transitional features.
It is worth noting that stationary discriminative
model can include features built from dialog his-
tory (Metallinou et al., 2013). The major dif-
ference in utilizing this information from our ap-
proach is that by explicitly assuming the Marko-
vian dependency, the structured model is able to
exploit the whole probabilistic dialog state distri-
bution of the previous turn. The previous dialog
state St−1 is inferred from previous dialog history
</bodyText>
<equation confidence="0.6985275">
Ot−1
1 , which contains higher level hypotheses than
</equation>
<bodyText confidence="0.99820925">
the raw history features. Apart from that, the struc-
tured model can also use any stationary features
built from Ot1, which makes the stationary model
a special case of the structured one.
</bodyText>
<subsectionHeader confidence="0.98993">
3.2 Neural network classifier
</subsectionHeader>
<bodyText confidence="0.999714">
We use the family of multi-layer neural net-
works to model the transition probability
</bodyText>
<equation confidence="0.8577275">
P(St|Ot−1
1 , St−1). To allow for the use of the
</equation>
<bodyText confidence="0.999921181818182">
dynamic prediction domain, we utilize a forward
network structure similar to (Henderson et al.,
2013). Feature vectors for each class in Yt are
fed into the model and forwarded through several
hidden layers for non-linear transformation in the
hope that deeper layers may form higher abstrac-
tion of the raw inputs. The parameter vectors for
each class are shared. For each feature vector
the model generates a real score. The scores for
all the classes in Yt are then normalized using a
softmax function resulting in valid probabilities.
</bodyText>
<equation confidence="0.999986">
yi = Wl−1 · gl−1(... g1(W1 · Xi) ...) (2)
Py = Softmax(y1,...,y|Yt|) (3)
</equation>
<bodyText confidence="0.999247833333333">
where g1 to gl−1 are sigmoid functions, Wi is the
weight matrix for linear transformation at layer i
and Xi = f(Ot1, yi) is the feature vector for class
i. We also test maximum entropy models, which
can be seen as a simple neural network without
hidden layers:
</bodyText>
<equation confidence="0.991480666666667">
1,y)
P(Y = y|Ot 1) = eλ�f(Ott1,y) (4)
EycY eλ
</equation>
<sectionHeader confidence="0.912354" genericHeader="method">
4 DSTC2 challenge
</sectionHeader>
<bodyText confidence="0.9760395">
DSTC2 is the second round of Dialog State Track-
ing Challenge, and it provides dialog corpora
collected from real human-machine dialogs in a
restaurant domain. The corpora are split into la-
beled training and development sets and unlabeled
test set. Test sets are collected from a SDS dif-
ferent from the training and development set to
reflect the mismatch in real deployment. Unlike
DSTC1, the user goal often changes in DSTC2
when the condition specified by the user cannot
be met. For evaluation DSTC2 defined a number
of metrics among which several featured metrics
are selected. Besides tracking user goals (the val-
ues of each slot), two additional states method and
requested slots are also defined, which track the
method to query and the slots requested by users
respectively. Further details about DSTC2 could
be found in (Henderson et al., 2014).
</bodyText>
<sectionHeader confidence="0.995295" genericHeader="method">
5 Feature set
</sectionHeader>
<bodyText confidence="0.991840083333333">
We briefly describe the feature set used in our sys-
tem. We only use the live SLU information pro-
vided by the organizers, and no extra external data
is used. The features used can be divided into two
classes.
stationary features which only depend on the
observations and the class (slot value) pre-
dicted at current turn in the form of f(yt, Ot).
transitional features that can also depends on
the predicted class at the previous turn in the
form of f(yt, yt−1, Ot).
Stationary features include:
</bodyText>
<listItem confidence="0.9604345">
• SLU Scores: confidence scores of the current
prediction binned into boolean values, raw
scores are also added as real features.
• SLU Status: whether the prediction is denied,
informed and confirmed in the current turn.
• Dialog history: whether the prediction has
been denied, informed and confirmed in all
the dialog turns until the current one.
• User/system action: The most probable user
action and the machine action in the current
turn.
The transitional features are as follows:
• Transition1: whether the predictions in the
previous and the current turn are the same.
</listItem>
<page confidence="0.995907">
329
</page>
<table confidence="0.9994622">
Name Model Class Hidden layers
Entry1 MEMM –
Entry2 Structured NN [50]
Entry3 Structured NN [50, 30]
MLP Stationary NN [50, 30]
</table>
<tableCaption confidence="0.998531">
Table 1: Configurations of models. The model
</tableCaption>
<bodyText confidence="0.9697955">
MLP uses the same structure as Entry3, but with-
out the transitional features described in section 5.
Number in brackets denotes the number of units
used in each hidden layers.
</bodyText>
<listItem confidence="0.754195">
• Transition2: joint feature of Transition1 in
</listItem>
<bodyText confidence="0.96377375">
conjunction with the machine action in cur-
rent turn, i.e. for each machine cation, Tran-
sision1 is replicated and only the one corre-
sponding to the machine action at current turn
is activated.
Transitional features are specific to Markovian
models while stationary features can be used in
any discriminative models.
</bodyText>
<sectionHeader confidence="0.887985" genericHeader="method">
6 Model training
</sectionHeader>
<bodyText confidence="0.999441296296296">
Markovian models in various forms are tested to
find the most appropriate structure for the task.
Models for ‘method’ and ‘state’ are built sepa-
rately using similar structured models.
When using the maximum entropy model to
build the conditional probability, the Markovian
model is equivalent to the maximum-entropy
Markov model (MEMM) model introduced in
(McCallum et al., 2000). More sophisticated neu-
ral networks with different configurations are used
to fit the model to more complex patterns in the
input features. In tracking the state ‘goal’, the
joint distribution of slots is built assuming differ-
ent slots are independent of each other. From the
perspective of practical implementation, one ad-
vantage of the simpler MEMM model is that the
training objective is convex. Thus the optimiza-
tion routine is guaranteed to find the global opti-
mum, while neural networks with hidden layers al-
ways have many local optima which require care-
ful initialization of the parameters. LBFGS (Liu
and Nocedal, 1989) is used in optimizing the batch
log-likelihood objective and L1 and L2 regulariz-
ers are used to penalize the model from overfitting.
We train the model on the training set, the devel-
opment set is used for model selection and models
produced at each training iteration are evaluated.
</bodyText>
<table confidence="0.99972375">
State Tracker ACC L2 CA05
Baseline 0.619 0.738 0.000
Entry1 0.707 0.447 0.223
Goal Entry2 0.713 0.437 0.207
Entry3 0.718 0.461 0.100
MLP 0.713 0.448 0.128
Baseline 0.875 0.217 0.000
Entry1 0.865 0.228 0.199
Method Entry2 0.871 0.211 0.290
Entry3 0.871 0.210 0.287
MLP 0.946 0.092 0.000
Baseline 0.884 0.196 0.000
Entry1 0.932 0.118 0.057
Requested Entry2 0.947 0.093 0.218
Entry3 0.951 0.085 0.225
MLP 0.863 0.231 0.291
</table>
<tableCaption confidence="0.996367">
Table 2: Evaluation results on the DSTC2 test set.
</tableCaption>
<bodyText confidence="0.976994166666667">
ACC stands for accuracy, L2 measures the Eu-
clidean distance between the predicted distribution
and the ground truth vector with only the correct
hypothesis set to 1. CA05 is the correct accep-
tance rate when false acceptance rate is 5%. De-
tails of the metrics can be found in (Henderson et
al., 2014). Except L2, the larger the scores, the
better the performance.
In DSTC2 we submitted 3 trackers, an additional
tracker without the transitional features is trained
afterwards for comparison. Configurations of the
models are described in table 1.
</bodyText>
<sectionHeader confidence="0.968391" genericHeader="evaluation">
7 Experiments and part of the results
</sectionHeader>
<bodyText confidence="0.999978777777778">
Featured metrics on the test set are shown in ta-
ble 2. By most metrics our models are superior
to the simple baseline. Especially in tracking user
goals which is the most important state to track in
DSTC2, the discriminative trackers show consid-
erable performance gain. Judging from the per-
formance of Entry1 to Entry3, we can conclude
that the more complex 2-layer neural networks
have better performance. Markovian neural net-
works can fit to the training instances with much
more flexibility than the simple MEMM model.
We have also trained a standard multi-layer neural
network (MLP) model by disabling all the transi-
tional features. By comparing the model ‘Entry 3’
and ‘MLP’, which share the same network struc-
ture, we explicitly test the effect of the Marko-
vian structure. On the state ‘goal’ and ‘requested’,
the Markovian model shows better tracking accu-
</bodyText>
<page confidence="0.991383">
330
</page>
<bodyText confidence="0.999968125">
racies, which means that the Markovian structure
has a positive effect on fitting the target. But in
tracking the state ‘method’, the MLP model has
the best performance among all the models com-
pared. Thus although the log-likelihood increases
considerably on the training set by adding the tran-
sitional features, the overfiting to the training set is
more serious in tracking ‘method’.
</bodyText>
<sectionHeader confidence="0.998507" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999966285714286">
We described the models used in the DSTC2 chal-
lenge. We proposed a novel approach to enhanc-
ing the model capability of stationary discrimina-
tive models in dialog state tracking by assuming
Markovian dependencies between adjacent turns.
The results showed better performance than the
simple baseline which uses the most probable hy-
pothesis, and we empirically compared the mod-
els with and without the Markovian dependency.
In future work, more discriminative models in dif-
ferent forms could be compared to evaluate their
capability, and the effects of the Markovian struc-
ture and transitional features needs to be further
studied.
</bodyText>
<sectionHeader confidence="0.998384" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999789538461538">
We would like to thank the DSTC committee for
their great efforts in organizing the challenge. We
also thank the anonymous reviewers for their con-
structive comments.
This work is partially supported by the Na-
tional Natural Science Foundation of China (Nos.
10925419, 90920302, 61072124, 11074275,
11161140319, 91120001), the Strategic Prior-
ity Research Program of the Chinese Academy
of Sciences (Grant Nos. XDA06030100,
XDA06030500), the National 863 Program (No.
2012AA012503) and the CAS Priority Deploy-
ment Project (No. KGZD-EW-103-2).
</bodyText>
<sectionHeader confidence="0.999255" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999499079365079">
Dan Bohus and Alex Rudnicky. 2006. A k-
hypotheses+ other belief updating model. In Proc.
of the AAAI Workshop on Statistical and Empirical
Methods in Spoken Dialogue Systems.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2013. Deep neural network approach for
the dialog state tracking challenge. In Proceedings
of the SIGDIAL 2013 Conference, pages 467–471,
Metz, France, August. Association for Computa-
tional Linguistics.
Matthew Henderson, Blaise Thomson, and Jason
Williams. 2014. The second dialog state tracking
challenge. In Proceedings of the SIGDIAL 2014
Conference, Baltimore, U.S.A., June.
Sungjin Lee and Maxine Eskenazi. 2013. Recipe for
building robust spoken dialog state trackers: Dialog
state tracking challenge system description. In Pro-
ceedings of the SIGDIAL 2013 Conference, pages
414–422, Metz, France, August. Association for
Computational Linguistics.
Sungjin Lee. 2013. Structured discriminative model
for dialog state tracking. In Proceedings of the
SIGDIAL 2013 Conference, pages 442–451, Metz,
France, August. Association for Computational Lin-
guistics.
Dong C Liu and Jorge Nocedal. 1989. On the limited
memory bfgs method for large scale optimization.
Mathematical programming, 45(1-3):503–528.
Andrew McCallum, Dayne Freitag, and Fernando C. N.
Pereira. 2000. Maximum entropy markov mod-
els for information extraction and segmentation. In
Pat Langley, editor, ICML, pages 591–598. Morgan
Kaufmann.
Angeliki Metallinou, Dan Bohus, and Jason Williams.
2013. Discriminative state tracking for spoken di-
alog systems. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics, pages 466–475, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the SIGDIAL 2013
Conference, page 404–413, Metz, France, August.
Association for Computational Linguistics.
Jason Williams. 2012. A critical analysis of two
statistical spoken dialog systems in public use. In
2012 IEEE Spoken Language Technology Workshop
(SLT), pages 55–60.
Jason Williams. 2013. Multi-domain learning and
generalization in dialog state tracking. In Proceed-
ings of the SIGDIAL 2013 Conference, pages 433–
441, Metz, France, August. Association for Compu-
tational Linguistics.
Steve Young, Milica Ga&amp;quot;si´c, Simon Keizer, Franc¸ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The hidden information state model:
A practical framework for POMDP-based spoken
dialogue management. Computer Speech &amp; Lan-
guage, 24(2):150–174.
Steve Young, Milica Ga&amp;quot;si´c, Blaise Thomson, and Ja-
son D Williams. 2013. Pomdp-based statistical spo-
ken dialog systems: A review. Proceedings of the
IEEE, 101(5):1160–1179.
</reference>
<page confidence="0.998806">
331
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.815730">
<title confidence="0.998997">Markovian Discriminative Modeling for Dialog State Tracking</title>
<author confidence="0.964355">Hang Ren</author>
<author confidence="0.964355">Weiqun Xu</author>
<author confidence="0.964355">Yonghong Yan</author>
<affiliation confidence="0.9500385">The Key Laboratory of Speech Acoustics and Content Understanding Institute of Acoustics, Chinese Academy of Sciences</affiliation>
<address confidence="0.998979">21 North 4th Ring West Road, Beijing, China, 100190</address>
<email confidence="0.957003">xuweiqun,</email>
<abstract confidence="0.997251">Discriminative dialog state tracking has become a hot topic in dialog research community recently. Compared to generative approach, it has the advantage of being able to handle arbitrary dependent features, which is very appealing. In this paper, we present our approach to the DSTC2 challenge. We propose to use discriminative Markovian models as a natural enhancement to the stationary discriminative models. The Markovian structure allows the incorporation of ‘transitional’ features, which can lead to more efficiency and flexibility in tracking user goal changes. Results on the DSTC2 dataset show considerable improvements over the baseline, and the effects of the Markovian dependency is tested empirically.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
<author>Alex Rudnicky</author>
</authors>
<title>A khypotheses+ other belief updating model.</title>
<date>2006</date>
<booktitle>In Proc. of the AAAI Workshop on Statistical and Empirical Methods in Spoken Dialogue Systems.</booktitle>
<contexts>
<context position="3588" citStr="Bohus and Rudnicky, 2006" startWordPosition="555" endWordPosition="558">ways not realistic. For example, N-best hypotheses are often assumed independent of each other, which is flawed in realistic scenarios (Williams, 2012). Furthermore, it is intrinsically difficult for generative models to handle overlapping features, which prevents model designers from incorporating arbitrarily large feature set. Discriminative model does not suffer from the above problems as there is no need to make any assumptions about the probabilistic dependencies of the features. As a result. it is potentially able to handle much larger feature sets and to make more accurate predictions (Bohus and Rudnicky, 2006). Discriminative models also tend to be more data-driven, unlike generative models in which many sub-models parameters are heuristically tuned. 2 DSTC1 revisited The first Dialog State Tracking Challenge (DSTC1) for the first time provided a common test bed for various state tracking methods, and 327 Proceedings of the SIGDIAL 2014 Conference, pages 327–331, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics several participants employed various discriminative models in the challenge. DSTC1 provided real user dialog corpora in the domain of bus route servic</context>
</contexts>
<marker>Bohus, Rudnicky, 2006</marker>
<rawString>Dan Bohus and Alex Rudnicky. 2006. A khypotheses+ other belief updating model. In Proc. of the AAAI Workshop on Statistical and Empirical Methods in Spoken Dialogue Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Steve Young</author>
</authors>
<title>Deep neural network approach for the dialog state tracking challenge.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<pages>467--471</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Metz, France,</location>
<contexts>
<context position="4510" citStr="Henderson et al., 2013" startWordPosition="690" endWordPosition="693">27 Proceedings of the SIGDIAL 2014 Conference, pages 327–331, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics several participants employed various discriminative models in the challenge. DSTC1 provided real user dialog corpora in the domain of bus route service to evaluate performance of various state tracking methods. In DSTC1 there are 9 teams with 27 submissions, where discriminative, generative and rule-based models are used in the challenge. Maximum entropy models (Lee and Eskenazi, 2013), conditional random fields (Lee, 2013) and neural networks (Henderson et al., 2013) are the most frequently used discriminative models, which gave competitive results on several metrics. It has been empirically analyzed that discriminative methods are especially advantageous when the ASR/SLU confidence scores are poorly estimated (Williams et al., 2013). 3 Discriminative modeling in dialog state tracking In the design of a slot-filling or task-oriented dialog systems, dialog state tracking can be considered as a classification problem, i.e. assigning predefined values to a fixed number of slots. One major problem in the formulation is that in complex dialog scenarios the num</context>
<context position="9343" citStr="Henderson et al., 2013" startWordPosition="1483" endWordPosition="1486">log state distribution of the previous turn. The previous dialog state St−1 is inferred from previous dialog history Ot−1 1 , which contains higher level hypotheses than the raw history features. Apart from that, the structured model can also use any stationary features built from Ot1, which makes the stationary model a special case of the structured one. 3.2 Neural network classifier We use the family of multi-layer neural networks to model the transition probability P(St|Ot−1 1 , St−1). To allow for the use of the dynamic prediction domain, we utilize a forward network structure similar to (Henderson et al., 2013). Feature vectors for each class in Yt are fed into the model and forwarded through several hidden layers for non-linear transformation in the hope that deeper layers may form higher abstraction of the raw inputs. The parameter vectors for each class are shared. For each feature vector the model generates a real score. The scores for all the classes in Yt are then normalized using a softmax function resulting in valid probabilities. yi = Wl−1 · gl−1(... g1(W1 · Xi) ...) (2) Py = Softmax(y1,...,y|Yt|) (3) where g1 to gl−1 are sigmoid functions, Wi is the weight matrix for linear transformation </context>
</contexts>
<marker>Henderson, Thomson, Young, 2013</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Steve Young. 2013. Deep neural network approach for the dialog state tracking challenge. In Proceedings of the SIGDIAL 2013 Conference, pages 467–471, Metz, France, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Jason Williams</author>
</authors>
<title>The second dialog state tracking challenge.</title>
<date>2014</date>
<booktitle>In Proceedings of the SIGDIAL 2014 Conference,</booktitle>
<location>Baltimore, U.S.A.,</location>
<contexts>
<context position="11031" citStr="Henderson et al., 2014" startWordPosition="1772" endWordPosition="1775">labeled test set. Test sets are collected from a SDS different from the training and development set to reflect the mismatch in real deployment. Unlike DSTC1, the user goal often changes in DSTC2 when the condition specified by the user cannot be met. For evaluation DSTC2 defined a number of metrics among which several featured metrics are selected. Besides tracking user goals (the values of each slot), two additional states method and requested slots are also defined, which track the method to query and the slots requested by users respectively. Further details about DSTC2 could be found in (Henderson et al., 2014). 5 Feature set We briefly describe the feature set used in our system. We only use the live SLU information provided by the organizers, and no extra external data is used. The features used can be divided into two classes. stationary features which only depend on the observations and the class (slot value) predicted at current turn in the form of f(yt, Ot). transitional features that can also depends on the predicted class at the previous turn in the form of f(yt, yt−1, Ot). Stationary features include: • SLU Scores: confidence scores of the current prediction binned into boolean values, raw </context>
<context position="14912" citStr="Henderson et al., 2014" startWordPosition="2414" endWordPosition="2417">8 0.128 Baseline 0.875 0.217 0.000 Entry1 0.865 0.228 0.199 Method Entry2 0.871 0.211 0.290 Entry3 0.871 0.210 0.287 MLP 0.946 0.092 0.000 Baseline 0.884 0.196 0.000 Entry1 0.932 0.118 0.057 Requested Entry2 0.947 0.093 0.218 Entry3 0.951 0.085 0.225 MLP 0.863 0.231 0.291 Table 2: Evaluation results on the DSTC2 test set. ACC stands for accuracy, L2 measures the Euclidean distance between the predicted distribution and the ground truth vector with only the correct hypothesis set to 1. CA05 is the correct acceptance rate when false acceptance rate is 5%. Details of the metrics can be found in (Henderson et al., 2014). Except L2, the larger the scores, the better the performance. In DSTC2 we submitted 3 trackers, an additional tracker without the transitional features is trained afterwards for comparison. Configurations of the models are described in table 1. 7 Experiments and part of the results Featured metrics on the test set are shown in table 2. By most metrics our models are superior to the simple baseline. Especially in tracking user goals which is the most important state to track in DSTC2, the discriminative trackers show considerable performance gain. Judging from the performance of Entry1 to Ent</context>
</contexts>
<marker>Henderson, Thomson, Williams, 2014</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Jason Williams. 2014. The second dialog state tracking challenge. In Proceedings of the SIGDIAL 2014 Conference, Baltimore, U.S.A., June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungjin Lee</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Recipe for building robust spoken dialog state trackers: Dialog state tracking challenge system description.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<pages>414--422</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Metz, France,</location>
<contexts>
<context position="4426" citStr="Lee and Eskenazi, 2013" startWordPosition="678" endWordPosition="681"> the first time provided a common test bed for various state tracking methods, and 327 Proceedings of the SIGDIAL 2014 Conference, pages 327–331, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics several participants employed various discriminative models in the challenge. DSTC1 provided real user dialog corpora in the domain of bus route service to evaluate performance of various state tracking methods. In DSTC1 there are 9 teams with 27 submissions, where discriminative, generative and rule-based models are used in the challenge. Maximum entropy models (Lee and Eskenazi, 2013), conditional random fields (Lee, 2013) and neural networks (Henderson et al., 2013) are the most frequently used discriminative models, which gave competitive results on several metrics. It has been empirically analyzed that discriminative methods are especially advantageous when the ASR/SLU confidence scores are poorly estimated (Williams et al., 2013). 3 Discriminative modeling in dialog state tracking In the design of a slot-filling or task-oriented dialog systems, dialog state tracking can be considered as a classification problem, i.e. assigning predefined values to a fixed number of slo</context>
</contexts>
<marker>Lee, Eskenazi, 2013</marker>
<rawString>Sungjin Lee and Maxine Eskenazi. 2013. Recipe for building robust spoken dialog state trackers: Dialog state tracking challenge system description. In Proceedings of the SIGDIAL 2013 Conference, pages 414–422, Metz, France, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungjin Lee</author>
</authors>
<title>Structured discriminative model for dialog state tracking.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<pages>442--451</pages>
<location>Metz, France,</location>
<contexts>
<context position="4465" citStr="Lee, 2013" startWordPosition="685" endWordPosition="686">us state tracking methods, and 327 Proceedings of the SIGDIAL 2014 Conference, pages 327–331, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics several participants employed various discriminative models in the challenge. DSTC1 provided real user dialog corpora in the domain of bus route service to evaluate performance of various state tracking methods. In DSTC1 there are 9 teams with 27 submissions, where discriminative, generative and rule-based models are used in the challenge. Maximum entropy models (Lee and Eskenazi, 2013), conditional random fields (Lee, 2013) and neural networks (Henderson et al., 2013) are the most frequently used discriminative models, which gave competitive results on several metrics. It has been empirically analyzed that discriminative methods are especially advantageous when the ASR/SLU confidence scores are poorly estimated (Williams et al., 2013). 3 Discriminative modeling in dialog state tracking In the design of a slot-filling or task-oriented dialog systems, dialog state tracking can be considered as a classification problem, i.e. assigning predefined values to a fixed number of slots. One major problem in the formulatio</context>
</contexts>
<marker>Lee, 2013</marker>
<rawString>Sungjin Lee. 2013. Structured discriminative model for dialog state tracking. In Proceedings of the SIGDIAL 2013 Conference, pages 442–451, Metz, France, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory bfgs method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical programming,</booktitle>
<pages>45--1</pages>
<contexts>
<context position="13858" citStr="Liu and Nocedal, 1989" startWordPosition="2236" endWordPosition="2239"> sophisticated neural networks with different configurations are used to fit the model to more complex patterns in the input features. In tracking the state ‘goal’, the joint distribution of slots is built assuming different slots are independent of each other. From the perspective of practical implementation, one advantage of the simpler MEMM model is that the training objective is convex. Thus the optimization routine is guaranteed to find the global optimum, while neural networks with hidden layers always have many local optima which require careful initialization of the parameters. LBFGS (Liu and Nocedal, 1989) is used in optimizing the batch log-likelihood objective and L1 and L2 regularizers are used to penalize the model from overfitting. We train the model on the training set, the development set is used for model selection and models produced at each training iteration are evaluated. State Tracker ACC L2 CA05 Baseline 0.619 0.738 0.000 Entry1 0.707 0.447 0.223 Goal Entry2 0.713 0.437 0.207 Entry3 0.718 0.461 0.100 MLP 0.713 0.448 0.128 Baseline 0.875 0.217 0.000 Entry1 0.865 0.228 0.199 Method Entry2 0.871 0.211 0.290 Entry3 0.871 0.210 0.287 MLP 0.946 0.092 0.000 Baseline 0.884 0.196 0.000 Ent</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C Liu and Jorge Nocedal. 1989. On the limited memory bfgs method for large scale optimization. Mathematical programming, 45(1-3):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Dayne Freitag</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Maximum entropy markov models for information extraction and segmentation.</title>
<date>2000</date>
<pages>591--598</pages>
<editor>In Pat Langley, editor, ICML,</editor>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="7710" citStr="McCallum et al., 2000" startWordPosition="1219" endWordPosition="1222">ies exist between adjacent turns. In typical task-oriented dialogs, users often change their goals when their original object cannot be satisfied. Even when the true user goal stays constant in a dialog session, the agent’s perception of it will tend to evolve and be more accurate as the conversation proceeds, and thus the dialog state will often change. The states at adjacent turns are statistically correlated, and therefore it is important to leverage this natural temporal relationship in tracking dialog state. We enhance the stationary discriminative model in a similar way as described in (McCallum et al., 2000), by assuming Markovian dependency between adjacent turns. Thus, the original probability P (St|Ot1) can be factored into the following form: P(St|Ot1) = (1) P(St|Ot1, St−1)P(St−1|Ot−1 1 ) The graphical model is shown is figure 1. Unlike stationary discriminative models, Monday: 0.5 Thursday: 0.2 Other: 0.3 Observations from turn 1 to t Monday: 0.7 Tuesday: 0.1 Thursday: 0.1 Other: 0.1 11 St−1ES 328 we model the conditional transition probability P(St|Ot1, St−1) instead of P(St|Ot1) and the dialog state is updated according to equation 1 at each turn. The feature functions in the structured mo</context>
<context position="13230" citStr="McCallum et al., 2000" startWordPosition="2134" endWordPosition="2137">sion1 is replicated and only the one corresponding to the machine action at current turn is activated. Transitional features are specific to Markovian models while stationary features can be used in any discriminative models. 6 Model training Markovian models in various forms are tested to find the most appropriate structure for the task. Models for ‘method’ and ‘state’ are built separately using similar structured models. When using the maximum entropy model to build the conditional probability, the Markovian model is equivalent to the maximum-entropy Markov model (MEMM) model introduced in (McCallum et al., 2000). More sophisticated neural networks with different configurations are used to fit the model to more complex patterns in the input features. In tracking the state ‘goal’, the joint distribution of slots is built assuming different slots are independent of each other. From the perspective of practical implementation, one advantage of the simpler MEMM model is that the training objective is convex. Thus the optimization routine is guaranteed to find the global optimum, while neural networks with hidden layers always have many local optima which require careful initialization of the parameters. L</context>
</contexts>
<marker>McCallum, Freitag, Pereira, 2000</marker>
<rawString>Andrew McCallum, Dayne Freitag, and Fernando C. N. Pereira. 2000. Maximum entropy markov models for information extraction and segmentation. In Pat Langley, editor, ICML, pages 591–598. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Metallinou</author>
<author>Dan Bohus</author>
<author>Jason Williams</author>
</authors>
<title>Discriminative state tracking for spoken dialog systems.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>466--475</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="8525" citStr="Metallinou et al., 2013" startWordPosition="1348" endWordPosition="1351">e graphical model is shown is figure 1. Unlike stationary discriminative models, Monday: 0.5 Thursday: 0.2 Other: 0.3 Observations from turn 1 to t Monday: 0.7 Tuesday: 0.1 Thursday: 0.1 Other: 0.1 11 St−1ES 328 we model the conditional transition probability P(St|Ot1, St−1) instead of P(St|Ot1) and the dialog state is updated according to equation 1 at each turn. The feature functions in the structured model can depend on the state of the previous turn, which we call transitional features. It is worth noting that stationary discriminative model can include features built from dialog history (Metallinou et al., 2013). The major difference in utilizing this information from our approach is that by explicitly assuming the Markovian dependency, the structured model is able to exploit the whole probabilistic dialog state distribution of the previous turn. The previous dialog state St−1 is inferred from previous dialog history Ot−1 1 , which contains higher level hypotheses than the raw history features. Apart from that, the structured model can also use any stationary features built from Ot1, which makes the stationary model a special case of the structured one. 3.2 Neural network classifier We use the family</context>
</contexts>
<marker>Metallinou, Bohus, Williams, 2013</marker>
<rawString>Angeliki Metallinou, Dan Bohus, and Jason Williams. 2013. Discriminative state tracking for spoken dialog systems. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 466–475, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Williams</author>
<author>Antoine Raux</author>
<author>Deepak Ramachandran</author>
<author>Alan Black</author>
</authors>
<title>The dialog state tracking challenge.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<pages>404--413</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Metz, France,</location>
<contexts>
<context position="4782" citStr="Williams et al., 2013" startWordPosition="728" endWordPosition="731">e domain of bus route service to evaluate performance of various state tracking methods. In DSTC1 there are 9 teams with 27 submissions, where discriminative, generative and rule-based models are used in the challenge. Maximum entropy models (Lee and Eskenazi, 2013), conditional random fields (Lee, 2013) and neural networks (Henderson et al., 2013) are the most frequently used discriminative models, which gave competitive results on several metrics. It has been empirically analyzed that discriminative methods are especially advantageous when the ASR/SLU confidence scores are poorly estimated (Williams et al., 2013). 3 Discriminative modeling in dialog state tracking In the design of a slot-filling or task-oriented dialog systems, dialog state tracking can be considered as a classification problem, i.e. assigning predefined values to a fixed number of slots. One major problem in the formulation is that in complex dialog scenarios the number of classes tends to be very big, resulting in extremely sparse training instances for each class. This sparsity affects the classification performance. A large prediction domain also leads to computation inefficiency which makes the model less practical. Usually we co</context>
</contexts>
<marker>Williams, Raux, Ramachandran, Black, 2013</marker>
<rawString>Jason Williams, Antoine Raux, Deepak Ramachandran, and Alan Black. 2013. The dialog state tracking challenge. In Proceedings of the SIGDIAL 2013 Conference, page 404–413, Metz, France, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Williams</author>
</authors>
<title>A critical analysis of two statistical spoken dialog systems in public use.</title>
<date>2012</date>
<booktitle>In 2012 IEEE Spoken Language Technology Workshop (SLT),</booktitle>
<pages>55--60</pages>
<contexts>
<context position="2154" citStr="Williams, 2012" startWordPosition="336" endWordPosition="337">og state, the dialog manager could select more effective and flexible dialog actions, resulting in shorter dialogs and higher dialog success rate. Dialog state tracking is the task of identifying the correct dialog state (user action, user goal, etc.) from ASR and SLU outputs in the presence of errors. Commercial dialog systems these days usually use simple dialog state tracking strategies that only consider the most probable SLU output. Previous research shows that several errors in dialog state tracking can be rectified by considering the full N-best results from the ASR and SLU components (Williams, 2012). Thus it is very important to develop robust and practical dialog state tracking models. In statistical dialog state tracking, models can be roughly divided into two major classes, i.e. generative and discriminative. Generative (Bayesian) dialog tracking models are prevalent in early studies due to its close relationship with the POMDP dialog management model (Young et al., 2013). Generative models generally use Dynamic Bayesian Networks to model the observation probability P(Ot|St) and transition probability P (St|St−1), where Ot and St are observations and dialog state at turn t. In a discr</context>
</contexts>
<marker>Williams, 2012</marker>
<rawString>Jason Williams. 2012. A critical analysis of two statistical spoken dialog systems in public use. In 2012 IEEE Spoken Language Technology Workshop (SLT), pages 55–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Williams</author>
</authors>
<title>Multi-domain learning and generalization in dialog state tracking.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<pages>433--441</pages>
<location>Metz, France,</location>
<contexts>
<context position="6886" citStr="Williams, 2013" startWordPosition="1086" endWordPosition="1087">ed and the overfitting problem would be alleviated. Williams proposed to use various techniques from multi-domain learning to improve model perforTurn t-1 Turn t Figure 1: Markovian discriminative model dependency diagram. In this figure the dialog state is simplified to a single slot variable: date, the domain of the slot typically increases as dialog continues, which includes all the slot values appeared as SLU results. As indicated by the arrows, St depends on St−1 and Ot1. In stationary discriminative model, there’s no dependency between adjacent turns indicated by the upper arrow. mance (Williams, 2013), which could be taken as another way of parameter sharing. 3.1 Markovian discriminative model A dialog can be naturally seen as a temporal sequence involving a user and an agent, where strong dependencies exist between adjacent turns. In typical task-oriented dialogs, users often change their goals when their original object cannot be satisfied. Even when the true user goal stays constant in a dialog session, the agent’s perception of it will tend to evolve and be more accurate as the conversation proceeds, and thus the dialog state will often change. The states at adjacent turns are statisti</context>
</contexts>
<marker>Williams, 2013</marker>
<rawString>Jason Williams. 2013. Multi-domain learning and generalization in dialog state tracking. In Proceedings of the SIGDIAL 2013 Conference, pages 433– 441, Metz, France, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Young</author>
<author>Milica Gasi´c</author>
<author>Simon Keizer</author>
<author>Franc¸ois Mairesse</author>
<author>Jost Schatzmann</author>
<author>Blaise Thomson</author>
<author>Kai Yu</author>
</authors>
<title>The hidden information state model: A practical framework for POMDP-based spoken dialogue management.</title>
<date>2010</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>24</volume>
<issue>2</issue>
<marker>Young, Gasi´c, Keizer, Mairesse, Schatzmann, Thomson, Yu, 2010</marker>
<rawString>Steve Young, Milica Ga&amp;quot;si´c, Simon Keizer, Franc¸ois Mairesse, Jost Schatzmann, Blaise Thomson, and Kai Yu. 2010. The hidden information state model: A practical framework for POMDP-based spoken dialogue management. Computer Speech &amp; Language, 24(2):150–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Young</author>
<author>Milica Gasi´c</author>
<author>Blaise Thomson</author>
<author>Jason D Williams</author>
</authors>
<title>Pomdp-based statistical spoken dialog systems: A review.</title>
<date>2013</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>101</volume>
<issue>5</issue>
<marker>Young, Gasi´c, Thomson, Williams, 2013</marker>
<rawString>Steve Young, Milica Ga&amp;quot;si´c, Blaise Thomson, and Jason D Williams. 2013. Pomdp-based statistical spoken dialog systems: A review. Proceedings of the IEEE, 101(5):1160–1179.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>