<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000266">
<title confidence="0.987494">
Computing Affect in Metaphors
</title>
<author confidence="0.732032">
Tomek Strzalkowski1,2, Samira Shaikh1, Kit Cho1, George Aaron Broadwell1, Laurie
</author>
<note confidence="0.531657">
Feldman1, Sarah Taylor3, Boris Yamrom1, Ting Liu1, Ignacio Cases1, Yuliya Peshkova1
and Kyle Elliot4
2Polish Academy of 3Sarah M. Taylor 4Plessas Experts
Sciences Consulting LLC Network
</note>
<email confidence="0.988345">
tomek@albany.edu
</email>
<affiliation confidence="0.533334">
1State University of
</affiliation>
<address confidence="0.467068">
New York - Univer-
sity at Albany
</address>
<sectionHeader confidence="0.959939" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99987275">
This article describes a novel approach to
automated determination of affect associ-
ated with metaphorical language. Affect
in language is understood to mean the at-
titude toward a topic that a writer at-
tempts to convey to the reader by using a
particular metaphor. This affect, which
we will classify as positive, negative or
neutral with various degrees of intensity,
may arise from the target of the meta-
phor, from the choice of words used to
describe it, or from other elements in its
immediate linguistic context. We attempt
to capture all these contributing elements
in an Affect Calculus and demonstrate
experimentally that the resulting method
can accurately approximate human
judgment. The work reported here is part
of a larger effort to develop a highly ac-
curate system for identifying, classifying,
and comparing metaphors occurring in
large volumes of text across four differ-
ent languages: English, Spanish, Russian,
and Farsi.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923375">
We present an approach to identification and val-
idation of affect in linguistic metaphors, i.e.,
metaphorical expressions occurring in written
language. Our method is specifically aimed at
isolating the affect conveyed in metaphors as
opposed to more broad approaches to sentiment
classification in the surrounding text. We
demonstrate experimentally that our basic Affect
Calculus captures metaphor-related affect with a
high degree of accuracy when applied to neutral
metaphor targets. These are targets that them-
selves do not carry any prior valuations. We sub-
sequently expanded and refined this method to
properly account for the contribution of the prior
affect associated with the target as well as its
immediate linguistic context.
</bodyText>
<sectionHeader confidence="0.831339" genericHeader="introduction">
2 Metaphor in Language
</sectionHeader>
<bodyText confidence="0.999870852941177">
Metaphors are mapping systems that allow the
semantics of a familiar Source domain to be ap-
plied to a new Target domain so as to invite new
frameworks for reasoning (usually by analogy) to
emerge in the target domain. The purpose of a
metaphor is (a) to simplify or enable reasoning
and communication about the target domain that
would otherwise be difficult (because of tech-
nical complexity) or impossible (due to lack of
agreed upon vocabulary) (e.g., Lakoff &amp; John-
son, 1980; 2004); or (b) to frame the target do-
main in a particular way that enables one form of
reasoning while inhibiting another (e.g.,
Thibodeau &amp; Boroditsky, 2011). The two rea-
sons for using metaphors are not necessarily mu-
tually exclusive, in other words, (a) and (b) can
operate at the same time. The distinction sug-
gested above has to do with affect: a metaphor
formed through (a) alone is likely to be neutral
(e.g., client/server, messenger DNA), while a
metaphor formed using (b) is likely to have a
polarizing affect (e.g., tax’s burden).
The Source and Target domains that serve as
endpoints of a metaphoric mapping can be repre-
sented in a variety of ways; however, in a nut-
shell they are composed of two kinds of things:
concepts and relations. In a Target domain the
concepts are typically abstract, disembodied, of-
ten fuzzy concepts, such as crime, mercy, or vio-
lence, but may also include more concrete, novel,
or elaborate concepts such as democracy or eco-
nomic inequality. In a Source domain, the con-
cepts are typically concrete and physical; howev-
er, mapping between two abstract domains is
</bodyText>
<page confidence="0.990321">
42
</page>
<note confidence="0.807017">
Proceedings of the Second Workshop on Metaphor in NLP, pages 42–51,
Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.997070555555555">
also possible. (E.g., crime may be both a target
and a source domain.)
The relations of interest are those that operate
between the concepts within a Source domain
and can be “borrowed” to link concepts within
the Target domain, e.g., “Crime(TARGET) spread
to(RELATION) previously safe areas” may be bor-
rowing from a DISEASE or a PARASITE source
domain.
</bodyText>
<sectionHeader confidence="0.999675" genericHeader="method">
3 Related Research: metaphor detection
</sectionHeader>
<bodyText confidence="0.999953559322034">
Most current research on metaphor falls into
three groups: (1) theoretical linguistic approach-
es (as defined by Lakoff &amp; Johnson, 1980; and
their followers) that generally look at metaphors
as abstract language constructs with complex
semantic properties; (2) quantitative linguistic
approaches (e.g., Charteris-Black, 2002;
O’Halloran, 2007) that attempt to correlate met-
aphor semantics with their usage in naturally oc-
curring text but generally lack robust tools to do
so; and (3) social science approaches, particular-
ly in psychology and anthropology that seek to
explain how people produce and understand met-
aphors in interaction, but which lack the neces-
sary computational tools to work with anything
other than relatively isolated examples.
In computational investigations of metaphor,
knowledge-based approaches include MetaBank
(Martin, 1994), a large knowledge base of meta-
phors empirically collected. Krishnakumaran and
Zhu (2007) use WordNet (Felbaum, 1998)
knowledge to differentiate between metaphors
and literal usage. Such approaches entail the ex-
istence of lexical resources that may not always
be present or satisfactorily robust in different
languages. Gedigan et al. (2006) identify a sys-
tem that can recognize metaphor; however their
approach is only shown to work in a narrow do-
main (The Wall Street Journal, for example).
Computational approaches to metaphor (largely
AI research) to date have yielded only limited
scale, often hand designed systems (Wilks, 1975;
Fass, 1991; Martin, 1994; Carbonell, 1980;
Feldman &amp; Narayan, 2004; Shutova &amp; Teufel,
2010; inter alia, also Shutova, 2010b for an over-
view). Baumer et al. (2010) used semantic role
labels and typed dependency parsing in an at-
tempt towards computational metaphor identifi-
cation. However, they describe their own work
as an initial exploration and hence, inconclusive.
Shutova et al. (2010a) employ an unsupervised
method of metaphor identification using nouns
and verb clustering to automatically impute met-
aphoricity in a large corpus using an annotated
training corpus of metaphors as seeds. Their
method relies on annotated training data, which
is difficult to produce in large quantities and may
not be easily generated in different languages.
Several other similar approaches were recently
reported at the Meta4NLP 1 workshop, e.g.,
(Mohler et al., 2013; Wilks et al., 2013; Hovy et
al., 2013).
Most recently, a significantly different ap-
proach to metaphor understanding based on lexi-
cal semantics and discourse analysis was intro-
duced by Strzalkowski et al. (2013). Space con-
straints limit our discussion about their work in
this article, however in the foregoing, our discus-
sion is largely consistent with their framework.
</bodyText>
<sectionHeader confidence="0.987273" genericHeader="method">
4 Affect in Metaphors
</sectionHeader>
<bodyText confidence="0.999808043478261">
Affect in language is understood to mean the atti-
tude toward a topic that a speaker/writer attempts
to convey to the reader or audience via text or
speech (van der Sluis and Mellish 2008). It is
expressed through multiple means, many of
which are unrelated to metaphor. While affect in
text is often associated, at least in theory, with a
variety of basic emotions (anger, fear, etc.), it is
generally possible to classify the set of possible
affective states by polarity: positive, negative,
and sometimes neutral. Affect is also considered
to have a graded strength, sometimes referred to
as intensity.
Our approach to affect in metaphor has been
vetted not only by our core linguistic team but
also by an independent team of linguist-analysts
with whom we work to understand metaphor
across several language-culture groups. Our re-
search continues to show no difficulties in com-
prehension or disagreement across languages
concerning the concept of linguistic affect, of its
application to metaphor, and of its having both
polarity and intensity.
</bodyText>
<sectionHeader confidence="0.962708" genericHeader="method">
5 Related Research: sentiment and af-
fect
</sectionHeader>
<bodyText confidence="0.998612571428571">
There is a relatively large volume of research on
sentiment analysis in language (Kim and Hovy,
2004; Strapparava and Mihalcea, 2007; Wiebe
and Cardie, 2005; inter alia) that aim at detecting
polarity of text, but is not specifically concerned
with metaphors. A number of systems were de-
veloped to automatically extract writer’s senti-
</bodyText>
<footnote confidence="0.974492">
1 The First Workshop on Metaphor in NLP.
http://aclweb.org/anthology//W/W13/W13-09.pdf
</footnote>
<page confidence="0.999868">
43
</page>
<bodyText confidence="0.999961283018868">
ment towards specific products or services such
as movies or hotels, from online reviews (e.g.,
Turney, 2002; Pang and Lee, 2008) or social me-
dia messages (e.g., Thelwall et al., 2010). None
of these techniques has been applied specifically
to metaphorical language, and it is unclear if the-
se alone would be sufficient due to the relatively
complex semantics involved in metaphor inter-
pretation. Socher et al. (2013 cite) have recently
used recursive neural tensor networks to classify
sentences into positive/negative categories.
However, the presence of largely negative con-
cepts such as “poverty” in a given sentence
overwhelms the sentiment for the sentence in
their method. Other relevant efforts in sentence
level sentiment analysis include Sem-Eval Task2.
While presence of affect in metaphorical lan-
guage is well documented in linguistic and psy-
cholinguistic literature (e.g., Osgood, 1980;
Pavio and Walsh, 1993; Caffi and Janney, 1994;
Steen, 1994), relatively little work was done to
detect affect automatically. Some notable recent
efforts include Zhang and Barnden (2010), Veale
and Li (2012), and Kozareva (2013), who pro-
posed various models of metaphor affect classifi-
cation based primarily on lexical features of the
surrounding text: specifically the word polarity
information. In these and other similar approach-
es, which are closely related to sentiment analy-
sis, affect is attributed to the entire text fragment:
a sentence or utterance containing a metaphor, or
in some cases the immediate textual context
around it.
In contrast, our objective is to isolate affect
due to the metaphor itself, independently of its
particular context, and also to determine how
various elements of the metaphoric expression
contribute to its polarity and strength. For exam-
ple, we may want to know what is the affect
conveyed about the Government as a target con-
cept of the metaphor in “Government regulations
are crushing small businesses.” and how it dif-
fers in “Government programs help to eradicate
poverty in rural areas.” or in “Feds plan to raise
the tax on the rich.” In all these examples, there
is a subtle interplay between the prior affect as-
sociated with certain words (e.g., “crush”, “pov-
erty”) and the semantic role they occupy in the
sentence (e.g., agent vs. patient vs. location,
etc.). Our objective is to develop an approach
that can better explain such differences. Not sur-
prisingly, in one of the target domains we are
investigating, the Economic Inequality domain,
</bodyText>
<footnote confidence="0.623518">
2 https://www.cs.york.ac.uk/semeval-2013/task2/
</footnote>
<bodyText confidence="0.999744615384615">
there is considerable agreement on the basic atti-
tudes across cultures towards the key target con-
cepts: poverty is negative, wealth is positive,
taxation is largely negative, and so on. This is in
a marked contrast with another Target domain,
the Governance domain where the target con-
cepts tend to be neutral (e.g. bureaucracy, regula-
tions etc.)
Another important motivation in developing
our approach (although not discussed in this pa-
per) is to obtain a model of affect that would help
to explain empirically why metaphorically rich
language is considered highly influential. Persua-
sion and influence literature (Soppory and
Dillard, 2002) indicates messages containing
metaphorical language produce somewhat great-
er attitude change than messages that do not.
However, some recent studies (e.g., Broadwell et
al., 2012) found that lexical models of affect,
sentiment, or emotion in language do not corre-
late with established measures of influence, con-
trary to expectations. Therefore, a different ap-
proach to affect is needed based both on lexical
and semantic features. We describe this new
model below, and show some preliminary results
in applications to metaphors interpretation.
</bodyText>
<sectionHeader confidence="0.986788" genericHeader="method">
6 Basic Affect Calculus
</sectionHeader>
<bodyText confidence="0.999990846153846">
The need for a new approach to affect arises
from the inability of the current methods of sen-
timent analysis to capture the affect that is con-
veyed by the metaphor itself, which may be only
a part of the overall affect expressed in a text.
Affect conveyed in metaphors, while often more
polarized than in literal language, is achieved
using subtler, less explicit, and more modulated
expressions. This presents a challenge for NLP
approaches that base affect determination upon
the presence of explicit sentiment markers in
language that may mask affect arising from a
metaphor. This problem becomes more challeng-
ing when strong, explicit sentiment markers are
present in a surrounding context or when the atti-
tude of the speaker/writer towards the target con-
cept is considered.
Our initial objective is thus to detect and clas-
sify the portion of affect that the speaker/writer is
trying to convey by choosing a specific meta-
phor. The observables here are the linguistic
metaphors that are actually uttered or written;
therefore, our method must be able to determine
affect present in the linguistic metaphors first
and then extrapolate to the conceptual metaphor
based on evidence across multiple uses of the
</bodyText>
<page confidence="0.995057">
44
</page>
<bodyText confidence="0.999977456790124">
same metaphor. Conceptual metaphors are posit-
ed by instances of linguistic metaphors that point
to the same source domain. We choose initially
to model the speaker/writer perspective; howev-
er, it may also be important to determine the ef-
fect that a metaphor has on the reader/listener,
which we do not address here.
Affect in metaphor arises from the juxtaposi-
tion of a Source and a Target domain through the
relations explicated in linguistic metaphors. The-
se relations typically involve one or more predi-
cates from the source domain that are applied to
a target concept. For example, in “Government
regulations are crushing small businesses.” the
relation “crushing” is borrowed from a concrete
source domain (e.g., Physical Burden), and used
with an abstract target concept of “government
regulation” which becomes the agentive argu-
ment, i.e., crushed(GovReg, X), where X is an
optional patientive argument, in this case “small
businesses”. Thus, government regulation is said
to be doing something akin to “crushing”, a
harmful and negative activity according to the
Affective Norms in English (ANEW) psycholin-
guistic database (Bradley and Lang, 1999). Since
“government regulation” is doing something
negative, the polarity of affect conveyed about it
is also negative. The ANEW lexicon we are us-
ing contains ratings of ~100K words. The origi-
nal ANEW lexicon by Bradley and Lang was
expanded following the work done by Liu et al.
(2014) in expanding the MRC imageability lexi-
con. While other sources of valence judgments
exist such as NRC (Mohammad et al., 2013) and
MPQA (Weibe and Cardie, 2005), there are limi-
tations Ð for instance Ð NRC lexicon rates each
words on a positive or negative scale, which does
not allow for more fine-grained analysis of
strength of valence.
Calculation from Table 1 is further general-
ized by incorporating the optional second argu-
ment of the relation and the role of the target
concept (i.e., agentive or patientive). Thus, if
X=‘small business’ as in the example above, the
complete relation becomes crushed(GovReg,
SmBus), which retains negative affect assuming
that ‘small business’ is considered positive or at
least neutral, an assessment that needs to be es-
tablished independently.
The above calculations are captured in the Af-
fect Calculus (AC), which was derived from the
sociolinguistic models of topical positioning and
disagreement in discourse (Broadwell et al.,
2013).
The Affect Calculus was conceived as a hypo-
thetical model of metaphorical affect, involving
the metaphor target, the source relation, as well
as the arguments of this relation, one of which is
the target itself. The basic version of the AC is
shown in Table 1. We should note that the AC
allows us to make affect inferences about any of
the elements of the metaphoric relation given the
values of the remaining elements. We should
also note that this calculus does not yet incorpo-
rate any discernable prior affect that the target
concept itself may carry. When the target con-
cept may be considered neutral (as is “govern-
ment regulation” when taken out of context) this
table allows us to compute the affect value of
any linguistic metaphor containing it. This is un-
like the target concepts such as “poverty” which
bring their prior affect into the metaphor. We
will return to this issue later.
In the Affect Calculus table, Relation denotes
a unary or binary predicate (typically a verb, an
adjective, or a noun). In the extended version of
the AC (Section 6) Relation may also denote a
compound consisting of a predicate and one or
more satellite arguments, i.e., arguments other
than AGENT or PATIENT, such as ORIGIN or DES-
TINATION for motion verbs, etc.
</bodyText>
<sectionHeader confidence="0.997307" genericHeader="method">
7 Extended Affect Calculus
</sectionHeader>
<bodyText confidence="0.999251428571428">
The basic Affect Calculus does not incorporate
any prior affect that the target concept might
bring into a metaphor. This is fine in some do-
mains (e.g., Government), where most target
concepts may be considered neutral. But in other
target domains, such as the Economic Inequality
domain, many of the target concepts have a
</bodyText>
<table confidence="0.999643571428572">
Relation type Type 1 (proper- Type 2 (agentive) Type 3 (patientive)
tive) Rel (Target, X) Rel(X, Target)
Rel(Target)
Relation/X X ≥ neutral X &lt; neutral X ≥ neutral X &lt; neutral
Positive POSITIVE POSITIVE &lt; UNSYMP POSITIVE &lt; SYMPAT
Negative NEGATIVE &lt; UNSYMP &gt; SYMPAT &lt; SYMPAT &gt; SYMPAT
Neutral NEUTRAL NEUTRAL &lt; NEUTRAL NEUTRAL &lt; NEUTRAL
</table>
<tableCaption confidence="0.9893875">
Table 1. A simple affect calculus specifies affect polarity for linguistic metaphors using a 5-point polar-
ity scale [negative &lt; unsympathetic &lt; neutral &lt; sympathetic &lt; positive]. X is the second argument.
</tableCaption>
<page confidence="0.996031">
45
</page>
<bodyText confidence="0.997012181818182">
strong prior affect in most cultures (e.g., ‘pov-
erty’ is universally considered negative). We
thus need to incorporate this prior affect into our
calculation whenever an affect-loaded target
concept is invoked in a metaphor. Where the
basic Affect Calculus simply imposes a context-
borne affect upon a neutral target concept, the
Advanced Affect Calculus must combine it with
the prior affect carried by the target concept, de-
pending upon the type of semantic context. As
already discussed, we differentiate 3 basic se-
</bodyText>
<listItem confidence="0.949549222222222">
mantic contexts (and additional contexts in the
extended Affect Calculus discussed in the next
section) where the target concept is positioned
with respect to other arguments in a metaphorical
expression:
• Propertive context is when a property of a
Target is specified (e.g. deep poverty, sea of
wealth)
• Agentive context is when the Target appears
as an agent of a relation that may involve an-
other concept (Argument X) in the patient
role (e.g. Government regulations are crush-
ingÉ, Government programs help...)
• Patientive context is when the Target ap-
pears in the patient role that involves another
concept (possibly implicit, Argument X) in
the agent role. (e.g. ...eradicate poverty.,
....navigate government bureaucracy)
</listItem>
<bodyText confidence="0.969627666666667">
Table 1 (in the previous section) specifies how
to calculate the affect expressed towards the tar-
get depending upon the affect associated with the
Relation and the Argument X. In the Advanced
Affect Calculus, this table specifies the context-
borne affect that interacts with the affect associ-
ated with the target. When the target prior affect
is unknown or assumed neutral, the AC table is
applied directly, as explained previously. When
the target has a known polarized affect, either
positive or negative, the values in the AC table
are used to calculate the final affect by combin-
ing the prior affect of the target with an appro-
priate value from the table. This is necessary for
affect-loaded target concepts such as “poverty”
or “wealth” that have strong prior affect and can-
not be considered neutral.
In order to calculate the combined affect we
define two operators O+ and O. These operators
form simple polarity algebra shown in Table 2.
When the Target is in a Patientive relation, we
use O to combine its affect with the context val-
ue from the AC table; otherwise, we use O+. In
the table for O+ operator, we note that combining
opposing affects from the Target and the Rela-
tion causes the final affect to be undetermined
(UND). In such cases we will take the affect of
the stronger element (more polarized score) to
prevail.
O pos neg neu O+ pos neg neu
pos pos neg pos pos pos UND pos
neg neg pos neg neg UND neg neg
neu pos neg neu neu pos neg neu
</bodyText>
<tableCaption confidence="0.8213685">
Table 2: Polarity algebra for extended affect
calculus
</tableCaption>
<bodyText confidence="0.999295818181818">
More specifically, in order to determine the
combined polarity score in these cases, we com-
pute the distance between each element’s ANEW
score and the closest boundary of the neutral
range of scores. For example, ANEW scores are
assigned on a 10-point continuum (derived from
human judgments on 10-point Likert scale) from
most negative (0) to most positive (9). Values in
the range of 3.0 to 5.0 may be considered neutral
(this range can be set differently for target con-
cepts and relations):
</bodyText>
<listItem confidence="0.99633925">
• Poverty affect score = 1.67 (ANEW) − 3
(neutral lower) = -1.33
• Grasp affect score = 5.45 (ANEW) – 5
(neutral upper)= +0.45
</listItem>
<bodyText confidence="0.9974932">
Consider the expression “poverty’s grasp”.
Since poverty is a polarized target concept in
Propertive position, we use O+ operator to com-
bine its affect value with that of Relation (grasp).
The result is negative:
</bodyText>
<listItem confidence="0.99964625">
• “Poverty’s grasp” affect score (via
ACO+) = -1.33 + 0.45 = -0.82 (negative)
When the combined score is close to 0 (-0.5 to
+0.5) the final affect is neutral.
</listItem>
<subsectionHeader confidence="0.979359">
7.1 Exceptions
</subsectionHeader>
<bodyText confidence="0.9933845">
The above calculus works in a majority of cases,
but there are exceptions requiring specialized
handling. An incomplete list of these is below
(and cases will be added as we encounter them):
Reflexive relations. In some cases the target is
in the agentive position but semantically it is also
a patient, as in “poverty is spreading”. These
cases need to be handled carefully – although the
current AC may be able to handle them in some
contexts. When interpreted as an agentive rela-
</bodyText>
<page confidence="0.998541">
46
</page>
<bodyText confidence="0.9999705">
tion, the affect of “poverty is spreading” comes
out as undetermined but would likely be output
as negative on the basis of the strong negative
affect associated with poverty (vs. weaker posi-
tive affect of “spreading”). When handled as a
patientive relation (an unknown force is spread-
ing poverty), it comes out clearly and strongly
negative. Similarly, “wealth is declining” is best
handled through patientive relation. Therefore,
for this AC we will treat intransitive relations as
patientive.
Causative relations. Some relations denoted
by causative verbs such as “alleviate”, “mitigate”
or “ease” appear to presuppose that their patient
argument has negative affect, and their positive
polarity already incorporates this assumption.
Thus, “alleviate” is best interpreted as “reduce
the negative of”, which inserts an extra negation
into the calculation. Without considering this
extra negation we would calculate “alleviate(+)
poverty(-)” as negative (doing something posi-
tive to a negative concept), which is not the ex-
pected reading. Therefore, the proposed special
handling is to treat “alleviate” and similar rela-
tions as always producing positive affect when
applied to negative targets.
</bodyText>
<sectionHeader confidence="0.860382" genericHeader="method">
8 Extensions to Basic Affect Calculus
</sectionHeader>
<bodyText confidence="0.996412826666667">
The basic model presented in the preceding sec-
tion oversimplifies certain more complex cases
where the metaphoric relation involves more
than 2 arguments. Consequently, we are consid-
ering several extensions to the basic Affect Cal-
culus as suggested below. The foregoing should
be treated as hypotheses subject to validation.
One possible extension involves relations rep-
resented by verbs of motion (which is a common
source domain) that involve satellite arguments
such as ORIGIN and DESTINATION in addition to
the main AGENT and PATIENT roles. Any polarity
associated with these arguments may impact af-
fect directed at the target concept appearing in
one of the main role positions. Likewise, we
need a mechanism to calculate affect for target
concepts found in one of the satellite roles. In
“Federal cuts could push millions into poverty”
the relation ‘push into’ involves three arguments:
AGENT (Federal cuts), PATIENT (millions [peo-
ple]) and DESTINATION (poverty). In calculating
affect towards ‘Federal cuts’ it is not sufficient to
consider the polarity of the predicate “push” (or
“push into”), but instead one must consider the
polarity of “push into (poverty)” as the compo-
site agentive relation involving ‘federal cuts’.
The polarity of this composite, in turn, depends
upon the polarity of its destination argument. In
other words:
polarity(Rel(DEST)) = polarity (DEST)
Thus, if ‘poverty’ is negative, then pushing
someone or something into poverty is a harmful
relation. Assuming that ‘millions [people]’ is
considered at least neutral, we obtain negative
affect for ‘Federal cuts’ from the basic Affect
Calculus table.
An analogous situation holds for the ‘ORIGIN’
argument, with the polarity reversed. Thus:
polarity (Rel (ORIGIN)) = ~polarity (ORIGIN)
In other words, the act of removing something
from a bad place is helpful and positive. For ex-
ample, in “Higher retail wages would lift Ameri-
cans out of poverty” the relation compound “lift
out of (poverty)” is considered helpful/positive.
Again, once the polarity of the relation com-
pound is established, the basic affect calculus
applies as usual, thus we obtain positive affect
towards ‘higher retail wages’. In situations when
both arguments are present at the same time and
point towards potentially conflicting outcomes,
we shall establish a precedence order based on
the evidence from human validation data.
Another class of multi-argument relations we
are considering includes verbs that take an IN-
STRUMENT argument, typically signaled by
‘with’ preposition. In this case, affect inference
for the relation compound is postulated as fol-
lows:
polarity (Rel (INSTR))
= polarity (INSTR) if polarity(INSTR) &lt; neutral
= polarity (Rel) otherwise
In other words, using a negative (bad) instru-
ment always makes the relation harmful, while
using a positive or neutral instrument has no ef-
fect on the base predicate polarity.
Other types of multi-argument relations may
require similar treatment, and we are currently
investigating further possible extensions. In all
cases not explicitly covered in the extended Af-
fect Calculus, we shall assume the default condi-
tion that other satellite arguments (such as TIME,
LOCATION, etc.) will have no impact on the po-
larity of the source relation compound. In other
words:
polarity (Rel (s-role)) =default polarity (Rel)
</bodyText>
<sectionHeader confidence="0.968739" genericHeader="evaluation">
9 Evaluation and Results
</sectionHeader>
<bodyText confidence="0.998703333333333">
For an evaluation, our objective is to construct a
test that can evaluate the ability of an automated
system to correctly identify and classify the af-
</bodyText>
<page confidence="0.998501">
47
</page>
<bodyText confidence="0.9982983">
fect associated with linguistic and conceptual
metaphors. A series of naturally occurring text
samples containing a linguistic metaphor about a
target concept are presented as input to the sys-
tem. The system outputs the affect associated
with the metaphor, as positive, negative, or neu-
tral. The system output is then compared to hu-
man generated answer key resulting in an accu-
racy score. The evaluation thus consists of two
components:
</bodyText>
<listItem confidence="0.991349">
1. Determining the ground truth about affect in
test samples;
2. Measuring the automated system’s ability to
identify affect correctly.
</listItem>
<bodyText confidence="0.999890666666666">
Step 1 is done using human assessors who
judge affect in a series of test samples. Assessors
are presented with brief passages where a target
concept and a relation are highlighted. They are
asked to rank their responses on a 7-point scale
for the following questions, among others:
</bodyText>
<listItem confidence="0.990987">
• To what degree does the above passage use
metaphor to describe the highlighted concept?
• To what degree does this passage convey an
idea that is either positive or negative?
</listItem>
<bodyText confidence="0.998604477272727">
It is strictly necessary that input to the system
be metaphorical sentences, since affect may be
associated with non-metaphoric expressions as
well; in fact, some direct expressions may carry
stronger affect than subtle and indirect meta-
phors. This is why both questions on the survey
are necessary: the first focuses the assessor’s at-
tention on the highlighted metaphor before ask-
ing about affect. If the purpose of the test is to
measure the accuracy of assigning affect to a
metaphor, then accuracy should be measured
against the subset of expressions judged to be
metaphorical.
The judgments collected from human asses-
sors are tested for reliability and validity. Relia-
bility among the raters is computed by measuring
intra-class correlation (ICC) (McGraw &amp; Wong,
1996; Shrout &amp; Fleiss, 1979). Typically, a coef-
ficient value above 0.7 indicates strong agree-
ment. In general, our analyses have shown that
we need approximately 30 or more subjects in
order to obtain a reliability coefficient of at least
0.7. In addition, certain precautions were taken to
ensure quality control in the data. We used the
following criteria to discard a subject’s data: (1)
completed the task too quickly (i.e., averaged
fewer than 10 seconds for each passage); (2)
gave the same answer to 85% or more of the test
items; (3) did not pass a simple language profi-
ciency test; or (4) did not provide correct an-
swers to a set of randomly inserted control pas-
sages which have been previously judged by ex-
perts to be unequivocally literal or metaphorical.
Human judgments are collected using Amazon’s
Mechanical Turk services. For each passage in
surveys, we would collect at least 30 viable
judgments. In addition, we have native language
speakers who have been rigorously trained to
provide expert judgments on metaphor and affect
identification task. Table 3 shows the intra-class
correlations for affect determination amongst
Mechanical Turk subjects. Experiments were
conducted in 4 languages: English, Spanish, Rus-
sian, and Farsi.
</bodyText>
<table confidence="0.998323666666666">
English Spanish Russian Farsi
Metaphor 0.864 0.853 0.916 0.720
Affect 0.924 0.791 0.713 0.797
</table>
<tableCaption confidence="0.999154">
Table 3: Intra-class correlations for metaphor
</tableCaption>
<bodyText confidence="0.967947909090909">
and affect assessment by Mechanical Turk sub-
jects
In Figure 1, we present partial evidence that
the human assessment collection method cap-
tures the phenomenon of affect associated with
metaphors. The chart clearly shows that affect
tends to be more polarized in metaphors than in
literal expressions. The chart is based on more
than 11,000 affect judgments for English linguis-
tic metaphors and literal expressions about Gov-
ernance concepts. We see a highly pronounced
tendency towards the polarization of affect (both
positive and negative). Ratings of affect (y-axis)
in metaphoric expressions (columns 5-7) are
judged to be stronger, and in particular more
negative than the literal expressions (columns 1-
3). A similar trend occurs with other target con-
cepts as well as other languages, although the
data are less reliable due to smaller test samples.
Once an answer key is established using the
aforementioned procedures, system accuracy can
be determined from a confusion matrix as shown
in Table 4. In Table 4, we show system assign-
ment of affect versus answer key for English
Governance and Economic Inequality target
metaphors. Overall accuracy across positive,
negative and neutral affect for English test set of
220 samples is 74.5%. Analogous confusion ma-
trices have been constructed for Spanish, Russian
and Farsi. NLP resources such as parser and lex-
icons for the languages other than English are not
as robust or well rounded; therefore affect classi-
fication accuracy in those languages is impacted.
</bodyText>
<page confidence="0.999073">
48
</page>
<figureCaption confidence="0.7534642">
Figure 1: Distribution of affect polarity in hu-
man judgment of English literal and metaphori-
cal expressions from the Governance domain.
Metaphoricity of an expression (x-axis) is judged
from highly literal (1) to highly metaphorical (7)
</figureCaption>
<bodyText confidence="0.998408666666667">
Table 5 shows the accuracy of affect detection
for expressions that the system determined to be
metaphors across all four languages under inves-
tigation. Evaluation set for numbers reported in
Table 5 contains a total of 526 linguistic meta-
phors in these four languages.
</bodyText>
<table confidence="0.999158777777778">
English Affect System identified as
Sample size =
220
Positive Negative Neutral
Answer Positive 40 16 3
Key
Nega- 12 109 1
tive
Neutral 10 14 15
</table>
<tableCaption confidence="0.9055995">
Table 4: Confusion matrix for affect classifi-
cation in English linguistic metaphors in Gov-
ernance and Economic Inequality Domain. Accu-
racy is 74.5%
</tableCaption>
<table confidence="0.9989265">
English Spanish Russian Farsi
Accuracy 74.5% 71% 59% 64%
</table>
<tableCaption confidence="0.9954255">
Table 5: Performance on affect classification for
linguistic metaphors in four languages
</tableCaption>
<sectionHeader confidence="0.955454" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.99903736">
In this paper we presented a new approach to
automatic computing of affect in metaphors that
exploits both lexical and semantic information in
metaphorical expressions. Our method was eval-
uated through a series of rigorous experiments
where more than several dozen of qualified as-
sessors judged hundreds of sentences (extracted
from online sources) that contained metaphorical
expressions. The objective was to capture affect
associated with the metaphor itself. Our system
can approximate human judgment with accuracy
ranging from 59% for Russian to 74% for Eng-
lish. These results are quite promising. The dif-
ferences are primarily due to varied robustness of
the language processing tools (such as parsers
and morphological analyzers) that are available
for each language. We note that a direct compar-
ison to lexical approaches such as described by
Kozareva (2013) is not possible at this time due
to differences in assessment methodology, alt-
hough it remains one of our objectives.
Our next step is to demonstrate that the new
way of calculating affect can lead to a reliable
model of affective language use that correlates
with other established measures of influence.
</bodyText>
<sectionHeader confidence="0.996939" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999538153846154">
Supported by the Intelligence Advanced Re-
search Projects Activity (IARPA) via Depart-
ment of Defense US Army Research Laboratory
contract number W911NF-12-C-0024. The U.S.
Government is authorized to reproduce and dis-
tribute reprints for Governmental purposes not-
withstanding any copyright annotation thereon.
Disclaimer: The views and conclusions con-
tained herein are those of the authors and should
not be interpreted as necessarily representing the
official policies or endorsements, either ex-
pressed or implied, of IARPA, DoD/ARL, or the
U.S. Government.
</bodyText>
<sectionHeader confidence="0.997799" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.989030789473684">
David W. Allbritton, Gail McKoon, and Richard J.
Gerrig. 1995. Metaphor-based schemas and text
Representations: making connections through
conceptual metaphors, Journal of Experimental
Psychology: Learning, Memory, and Cognition,
21(3):612-625.
Eric P. S. Baumer, James P. White, and Bill Tomlin-
son. 2010. Comparing semantic role labeling with
typed dependency parsing in computational meta-
phor identification. In Proceedings of the NAACL
HLT 2010 Second Workshop on Computational
Approaches to Linguistic Creativity, pages 14–22,
Los Angeles, California.
Margaret M. Bradley, and Peter Lang. 1999. Affective
norms for English words (ANEW): Instruction
manual and affective ratings. Technical Report C-
2. University of Florida, Gainesville, FL.
George Aaron Broadwell, Umit Boz, Ignacio Cases,
Tomek Strzalkowski, Laurie Feldman, Sarah Tay-
</reference>
<page confidence="0.995475">
49
</page>
<reference confidence="0.990230756302521">
lor, Samira Shaikh, Ting Liu, Kit Cho, and Nick
Webb. 2013. Using imageability and topic chain-
ing to locate metaphors in linguistic corpora. In
Proceedings of International Conference on So-
cial Computing, Behavioral-Cultural Modeling, &amp;
Prediction, pages 102–109. Washington D.C.
George Aaron Broadwell, Jennifer Stromer-Galley,
Tomek Strzalkowski, Samira Shaikh, Sarah Tay-
lor, Umit Boz, Alana Elia, Laura Jiao, Ting Liu
and Nick Webb. 2012. Modeling socio-cultural
phenomena in discourse. Journal of Natural Lan-
guage Engineering, pages 1–45. Cambridge
Press.
Claudia Caffi, and Richard W. Janney. 1994. Towards
a pragmatics of emotive communication. Jour-
nal of Pragmatics, 22:325–373.
Jaime Carbonell. 1980. Metaphor: A key to extensible
semantic analysis. In Proceedings of the 18th An-
nual Meeting on Association for Computational
Linguistics.
Jonathan, Charteris-Black. 2002. Second language
figurative proficiency: A comparative study of
Malay and English. Applied Linguistics
23(1):104–133.
Dan, Fass. 1991. met*: A Method for Discriminating
Metonymy and Metaphor by Computer. Computa-
tional Linguistics, 17:49-90
Jerome Feldman, and Srinivas Narayanan. 2004. Em-
bodied meaning in a neural theory of language.
Brain and Language, 89(2):385–392.
Christiane D. Fellbaum. 1998. WordNet: An electron-
ic lexical database (1st ed.). MIT Press.
Matt Gedigian, John Bryant, Srini Narayanan and
Branimir Ciric. 2006. Catching Metaphors. In
Proceedings of the Third Workshop on Scalable
Natural Language Understanding ScaNaLU 2006,
pages 41–48. New York City: NY.
Dirk Hovy, Shashank Shrivastava, Sujay Kumar Jau-
har, Mrinmaya Sachan, Kartik Goyal, Huying Li,
Whitney Sanders and Eduard Hovy. 2013. Identi-
fying Metaphorical Word Use with Tree Kernels.
In the Proceedings of the First Workshop on Met-
aphor in NLP, (NAACL). Atlanta.
Soo-Min Kim and Eduard Hovy. 2004. Determining
the sentiment of opinions. In Proceedings of the
20th international conference on Computational
Linguistics, COLING ’04.
Zornitsa Kozareva. 2013. Multilingual Affect Polarity
and Valence Prediction in Metaphor-Rich Texts.
In Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (ACL
2013)
Saisuresh Krishnakumaran and Xiaojin Zhu. 2007.
Hunting elusive metaphors using lexical resources.
In Proceedings of the Workshop on Computation-
al Approaches to Figurative Language, pages 13–
20. Rochester, NY.
George Lakoff, and Mark Johnson. 1980. Metaphors
we live by. University Of Chicago Press, Chicago,
Illinois.
George, Lakoff. 2001. Moral politics: what conserva-
tives know that liberals don’t. University of Chi-
cago Press, Chicago, Illinois.
Ting Liu, Kit Cho, George Aaron Broadwell, Samira
Shaikh, Tomek Strzalkowski, John Lien, Sarah
Taylor, Laurie Feldman, Boris Yamrom, Nick
Webb, Umit Boz and Ignacio Cases. 2014. Auto-
matic Expansion of the MRC Psycholinguistic Da-
tabase Imageability Ratings. In Proceedings of 9th
Language Resources and Evaluation Conference,
(LREC 2014)Reykjavik, Iceland.
Liisa, Malkki. 1992. National geographic: The root-
ing of people and the territorialization of national
identity among scholars and refugees. Society for
Cultural Anthropology, 7(1):24–44.
James Martin. 1988. A computational theory of meta-
phor. Ph.D. Dissertation.
Kenneth O. McGraw and S. P. Wong. 1996. Forming
inferences about some intraclass correlation coef-
ficients. Psychological Methods, 1(1): 30–46.
Mohammad, S.M., S. Kiritchenko, and X. Zhu. 2013.
NRC-Canada: Building the state-of-the-art insen-
timent analysis of tweets. In Proceedings of the
Seventh International Workshop on Semantic
Evaluation Exercises (SemEval-2013), Atlanta,
Georgia, USA, June 2013.
Michael Mohler, David Bracewell, David Hinote, and
Marc Tomlinson. 2013. Semantic signatures for
example-based linguistic metaphor detection. In
The Proceedings of the First Workshop on Meta-
phor in NLP, (NAACL), pages 46–54.
Musolff, Andreas. 2008. What can critical metaphor
analysis add to the understanding of racist ideolo-
gy? Recent studies of Hitler’s anti-semitic meta-
phors, critical approaches to discourse analysis
across disciplines. Critical Approaches to Dis-
course Analysis Across Disciplines, 2(2):1–10.
Kieran, O’Halloran. 2007. Critical discourse analysis
and the corpus-informed interpretation of meta-
phor at the register level. Oxford University Press
Charles E. Osgood. 1981. The cognitive dynamics of
synaesthesia and metaphor. In Proceedings of the
National Symposium for Research in Art. Learn-
ing in Art: Representation and Metaphor, pages
56-80. University of Illinois Press.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-
2):1–135, January.
Allan Pavio and Mary Walsh. 1993. Psychological
processes in metaphor comprehension and
memory. In Andrew Ortony, editor, Meta-
phor and thought (2nd ed.). Cambridge: Cambridge
University Press.
Patrick E Shrout and Joseph L Fleiss. 1979. Intraclass
correlations: Uses in assessing rater reliability.
Psychological Bulletin, 86(2):420–428.
Ekaterina Shutova. 2010. Models of metaphors in
NLP. In Proceedings of ACL 2010. Uppsala, Swe-
den.
</reference>
<page confidence="0.948732">
50
</page>
<reference confidence="0.999852467532468">
Ekaterina Shutova and Simone Teufel. 2010a. Meta-
phor corpus annotated for source - target domain
mappings. In Proceedings of Language Resources
and Evaluation Conference 2010. Malta.
Ekaterina Shutova. 2010b. Models of metaphor in nlp.
In Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics, ACL
’10, pages 688–697.
Ekaterina Shutova, Tim Van de Cruys, and Anna
Korhonen. 2012. Unsupervised metaphor para-
phrasing using a vector space model In Proceed-
ings of COLING 2012, Mumbai, India
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Chris Manning, Andrew Ng and Chris
Potts. 2013. In Proceedings Conference on Empir-
ical Methods in Natural Language Processing
(EMNLP 2013). Seattle, USA.
Sopory, P. and Dillard, J. P. (2002), The Persuasive
Effects of Metaphor: A Meta-Analysis. Human
Communication Research, 28: 382–419.
doi: 10.1111/j.1468-2958.2002.tb00813.x
Gerard Steen. 1994. Understanding metaphor in lit-
erature: An empirical approach. London: Long-
man.
Carlo, Strapparava, and Rada Mihalcea. 2007.
Semeval-2007 task 14: Affective text. In Proceed-
ings of the Fourth International Workshop on Se-
mantic Evaluations, pages 70–74. Association for
Computational Linguistics.
Tomek Strzalkowski, George Aaron Broadwell, Sarah
Taylor, Laurie Feldman, Boris Yamrom, Samira
Shaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio
Cases and Kyle Elliott. 2013. Robust extraction of
metaphor from novel data. In Proceedings of
Workshop on Metaphor in NLP, NAACL. Atlanta.
Mike Thelwall, Kevan Buckley, and Georgios Pato-
glou. Sentiment in Twitter events. 2011. Journal
of the American Society for Information Science
and Technology, 62(2):406–418.
Paul H. Thibodeau and Lera Boroditsky. 2011. Meta-
phors We Think With: The Role of Metaphor in
Reasoning. PLoS ONE 6(2): e16782.
Peter D, Turney. 2002. Thumbs up or thumbs down?
Semantic orientation applied to unsupervised clas-
sification of reviews. In Proceedings of the 40th
Annual Meeting on Association for Computational
Linguistics, ACL ’02, pages 417–424.
Ielka van der Sluis, and C. Mellish 2008. Toward
affective natural language deneration: Empirical
investigations. affective language in human and
machine. AISB 2008 Proceedings Volume 2.
Tony Veale and Guofu Li. 2012. Specifying view-
point and information need with affective meta-
phors: a system demonstration of the metaphor
magnet web app/service. In Proceedings of the
ACL 2012 System Demonstrations, ACL ’12, pag-
es 7–12.
Janyce, Wiebe and Claire Cardie. 2005. Annotating
expressions of opinions and emotions in language.
In Language Resources and Evaluation.
Yorick, Wilks. 1975. Preference semantics. Formal
Semantics of Natural Language, E. L. Keenan, Ed.
Cambridge University Press, Cambridge, U.K.,
329–348.
Yorick Wilks, Lucian Galescu, James Allen, Adam
Dalton. 2013. Automatic Metaphor Detection us-
ing Large-Scale Lexical Resources and Conven-
tional Metaphor Extraction. In the Proceedings of
the First Workshop on Metaphor in NLP,
(NAACL). Atlanta.
Wiebe, J., Wilson, T., and Cardie, C.: Annotating
expressions of opinions and emotions in lan-
guage. Language Resources and Evaluation, 39(2-
3), pp. 165-210 (2005).
Li Zhang and John Barnden. 2010. Affect and meta-
phor sensing in virtual drama. International Journal
of Computer Games Technology. Vol. 2010.
</reference>
<page confidence="0.999122">
51
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.029859">
<title confidence="0.999941">Computing Affect in Metaphors</title>
<author confidence="0.904185666666667">Samira Kit George Aaron Sarah Boris Ting Ignacio Yuliya Kyle</author>
<affiliation confidence="0.3448895">Academy of M. Taylor Experts Sciences Consulting LLC Network</affiliation>
<email confidence="0.990536">tomek@albany.edu</email>
<affiliation confidence="0.981163">University</affiliation>
<author confidence="0.791795">York</author>
<note confidence="0.395153">sity at Albany</note>
<abstract confidence="0.97762628">This article describes a novel approach to automated determination of affect associated with metaphorical language. Affect in language is understood to mean the attitude toward a topic that a writer attempts to convey to the reader by using a particular metaphor. This affect, which we will classify as positive, negative or neutral with various degrees of intensity, may arise from the target of the metaphor, from the choice of words used to describe it, or from other elements in its immediate linguistic context. We attempt to capture all these contributing elements in an Affect Calculus and demonstrate experimentally that the resulting method can accurately approximate human judgment. The work reported here is part of a larger effort to develop a highly accurate system for identifying, classifying, and comparing metaphors occurring in large volumes of text across four different languages: English, Spanish, Russian, and Farsi.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David W Allbritton</author>
<author>Gail McKoon</author>
<author>Richard J Gerrig</author>
</authors>
<title>Metaphor-based schemas and text Representations: making connections through conceptual metaphors,</title>
<date>1995</date>
<journal>Journal of Experimental Psychology: Learning, Memory, and Cognition,</journal>
<pages>21--3</pages>
<marker>Allbritton, McKoon, Gerrig, 1995</marker>
<rawString>David W. Allbritton, Gail McKoon, and Richard J. Gerrig. 1995. Metaphor-based schemas and text Representations: making connections through conceptual metaphors, Journal of Experimental Psychology: Learning, Memory, and Cognition, 21(3):612-625.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric P S Baumer</author>
<author>James P White</author>
<author>Bill Tomlinson</author>
</authors>
<title>Comparing semantic role labeling with typed dependency parsing in computational metaphor identification.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity,</booktitle>
<pages>14--22</pages>
<location>Los Angeles, California.</location>
<contexts>
<context position="5865" citStr="Baumer et al. (2010)" startWordPosition="916" endWordPosition="919">age. Such approaches entail the existence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al. (2006) identify a system that can recognize metaphor; however their approach is only shown to work in a narrow domain (The Wall Street Journal, for example). Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman &amp; Narayan, 2004; Shutova &amp; Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al. (2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantities and may not be easily generated in different languages. Several other </context>
</contexts>
<marker>Baumer, White, Tomlinson, 2010</marker>
<rawString>Eric P. S. Baumer, James P. White, and Bill Tomlinson. 2010. Comparing semantic role labeling with typed dependency parsing in computational metaphor identification. In Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity, pages 14–22, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret M Bradley</author>
<author>Peter Lang</author>
</authors>
<title>Affective norms for English words (ANEW): Instruction manual and affective ratings.</title>
<date>1999</date>
<tech>Technical Report C2.</tech>
<institution>University of Florida,</institution>
<location>Gainesville, FL.</location>
<contexts>
<context position="14587" citStr="Bradley and Lang, 1999" startWordPosition="2285" endWordPosition="2288">in that are applied to a target concept. For example, in “Government regulations are crushing small businesses.” the relation “crushing” is borrowed from a concrete source domain (e.g., Physical Burden), and used with an abstract target concept of “government regulation” which becomes the agentive argument, i.e., crushed(GovReg, X), where X is an optional patientive argument, in this case “small businesses”. Thus, government regulation is said to be doing something akin to “crushing”, a harmful and negative activity according to the Affective Norms in English (ANEW) psycholinguistic database (Bradley and Lang, 1999). Since “government regulation” is doing something negative, the polarity of affect conveyed about it is also negative. The ANEW lexicon we are using contains ratings of ~100K words. The original ANEW lexicon by Bradley and Lang was expanded following the work done by Liu et al. (2014) in expanding the MRC imageability lexicon. While other sources of valence judgments exist such as NRC (Mohammad et al., 2013) and MPQA (Weibe and Cardie, 2005), there are limitations Ð for instance Ð NRC lexicon rates each words on a positive or negative scale, which does not allow for more fine-grained analysis</context>
</contexts>
<marker>Bradley, Lang, 1999</marker>
<rawString>Margaret M. Bradley, and Peter Lang. 1999. Affective norms for English words (ANEW): Instruction manual and affective ratings. Technical Report C2. University of Florida, Gainesville, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Aaron Broadwell</author>
<author>Umit Boz</author>
<author>Ignacio Cases</author>
<author>Tomek Strzalkowski</author>
<author>Laurie Feldman</author>
<author>Sarah Taylor</author>
<author>Samira Shaikh</author>
<author>Ting Liu</author>
<author>Kit Cho</author>
<author>Nick Webb</author>
</authors>
<title>Using imageability and topic chaining to locate metaphors in linguistic corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of International Conference on Social Computing, Behavioral-Cultural Modeling, &amp; Prediction,</booktitle>
<pages>102--109</pages>
<location>Washington D.C.</location>
<contexts>
<context position="15851" citStr="Broadwell et al., 2013" startWordPosition="2489" endWordPosition="2492"> Table 1 is further generalized by incorporating the optional second argument of the relation and the role of the target concept (i.e., agentive or patientive). Thus, if X=‘small business’ as in the example above, the complete relation becomes crushed(GovReg, SmBus), which retains negative affect assuming that ‘small business’ is considered positive or at least neutral, an assessment that needs to be established independently. The above calculations are captured in the Affect Calculus (AC), which was derived from the sociolinguistic models of topical positioning and disagreement in discourse (Broadwell et al., 2013). The Affect Calculus was conceived as a hypothetical model of metaphorical affect, involving the metaphor target, the source relation, as well as the arguments of this relation, one of which is the target itself. The basic version of the AC is shown in Table 1. We should note that the AC allows us to make affect inferences about any of the elements of the metaphoric relation given the values of the remaining elements. We should also note that this calculus does not yet incorporate any discernable prior affect that the target concept itself may carry. When the target concept may be considered </context>
</contexts>
<marker>Broadwell, Boz, Cases, Strzalkowski, Feldman, Taylor, Shaikh, Liu, Cho, Webb, 2013</marker>
<rawString>George Aaron Broadwell, Umit Boz, Ignacio Cases, Tomek Strzalkowski, Laurie Feldman, Sarah Taylor, Samira Shaikh, Ting Liu, Kit Cho, and Nick Webb. 2013. Using imageability and topic chaining to locate metaphors in linguistic corpora. In Proceedings of International Conference on Social Computing, Behavioral-Cultural Modeling, &amp; Prediction, pages 102–109. Washington D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Aaron Broadwell</author>
<author>Jennifer Stromer-Galley</author>
<author>Tomek Strzalkowski</author>
<author>Samira Shaikh</author>
<author>Sarah Taylor</author>
</authors>
<title>Modeling socio-cultural phenomena in discourse.</title>
<date>2012</date>
<journal>Journal of Natural Language Engineering,</journal>
<pages>1--45</pages>
<publisher>Cambridge Press.</publisher>
<location>Umit Boz, Alana Elia, Laura Jiao, Ting Liu</location>
<contexts>
<context position="11830" citStr="Broadwell et al., 2012" startWordPosition="1846" endWordPosition="1849">marked contrast with another Target domain, the Governance domain where the target concepts tend to be neutral (e.g. bureaucracy, regulations etc.) Another important motivation in developing our approach (although not discussed in this paper) is to obtain a model of affect that would help to explain empirically why metaphorically rich language is considered highly influential. Persuasion and influence literature (Soppory and Dillard, 2002) indicates messages containing metaphorical language produce somewhat greater attitude change than messages that do not. However, some recent studies (e.g., Broadwell et al., 2012) found that lexical models of affect, sentiment, or emotion in language do not correlate with established measures of influence, contrary to expectations. Therefore, a different approach to affect is needed based both on lexical and semantic features. We describe this new model below, and show some preliminary results in applications to metaphors interpretation. 6 Basic Affect Calculus The need for a new approach to affect arises from the inability of the current methods of sentiment analysis to capture the affect that is conveyed by the metaphor itself, which may be only a part of the overall</context>
</contexts>
<marker>Broadwell, Stromer-Galley, Strzalkowski, Shaikh, Taylor, 2012</marker>
<rawString>George Aaron Broadwell, Jennifer Stromer-Galley, Tomek Strzalkowski, Samira Shaikh, Sarah Taylor, Umit Boz, Alana Elia, Laura Jiao, Ting Liu and Nick Webb. 2012. Modeling socio-cultural phenomena in discourse. Journal of Natural Language Engineering, pages 1–45. Cambridge Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Caffi</author>
<author>Richard W Janney</author>
</authors>
<title>Towards a pragmatics of emotive communication.</title>
<date>1994</date>
<journal>Journal of Pragmatics,</journal>
<pages>22--325</pages>
<contexts>
<context position="9413" citStr="Caffi and Janney, 1994" startWordPosition="1468" endWordPosition="1471"> to the relatively complex semantics involved in metaphor interpretation. Socher et al. (2013 cite) have recently used recursive neural tensor networks to classify sentences into positive/negative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2. While presence of affect in metaphorical language is well documented in linguistic and psycholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automatically. Some notable recent efforts include Zhang and Barnden (2010), Veale and Li (2012), and Kozareva (2013), who proposed various models of metaphor affect classification based primarily on lexical features of the surrounding text: specifically the word polarity information. In these and other similar approaches, which are closely related to sentiment analysis, affect is attributed to the entire text fragment: a sentence or utterance containing a metaphor, or in some cases the immediate textual context around it. In con</context>
</contexts>
<marker>Caffi, Janney, 1994</marker>
<rawString>Claudia Caffi, and Richard W. Janney. 1994. Towards a pragmatics of emotive communication. Journal of Pragmatics, 22:325–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
</authors>
<title>Metaphor: A key to extensible semantic analysis.</title>
<date>1980</date>
<booktitle>In Proceedings of the 18th Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5744" citStr="Carbonell, 1980" startWordPosition="897" endWordPosition="898">rishnakumaran and Zhu (2007) use WordNet (Felbaum, 1998) knowledge to differentiate between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al. (2006) identify a system that can recognize metaphor; however their approach is only shown to work in a narrow domain (The Wall Street Journal, for example). Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman &amp; Narayan, 2004; Shutova &amp; Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al. (2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data,</context>
</contexts>
<marker>Carbonell, 1980</marker>
<rawString>Jaime Carbonell. 1980. Metaphor: A key to extensible semantic analysis. In Proceedings of the 18th Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charteris-Black Jonathan</author>
</authors>
<title>Second language figurative proficiency: A comparative study of Malay and English.</title>
<date>2002</date>
<journal>Applied Linguistics</journal>
<volume>23</volume>
<issue>1</issue>
<marker>Jonathan, 2002</marker>
<rawString>Jonathan, Charteris-Black. 2002. Second language figurative proficiency: A comparative study of Malay and English. Applied Linguistics 23(1):104–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fass Dan</author>
</authors>
<title>met*: A Method for Discriminating Metonymy and Metaphor by Computer.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<pages>17--49</pages>
<marker>Dan, 1991</marker>
<rawString>Dan, Fass. 1991. met*: A Method for Discriminating Metonymy and Metaphor by Computer. Computational Linguistics, 17:49-90</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome Feldman</author>
<author>Srinivas Narayanan</author>
</authors>
<title>Embodied meaning in a neural theory of language.</title>
<date>2004</date>
<journal>Brain and Language,</journal>
<volume>89</volume>
<issue>2</issue>
<marker>Feldman, Narayanan, 2004</marker>
<rawString>Jerome Feldman, and Srinivas Narayanan. 2004. Embodied meaning in a neural theory of language. Brain and Language, 89(2):385–392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane D Fellbaum</author>
</authors>
<title>WordNet: An electronic lexical database (1st</title>
<date>1998</date>
<editor>ed.).</editor>
<publisher>MIT Press.</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane D. Fellbaum. 1998. WordNet: An electronic lexical database (1st ed.). MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gedigian</author>
<author>John Bryant</author>
<author>Srini Narayanan</author>
<author>Branimir Ciric</author>
</authors>
<title>Catching Metaphors.</title>
<date>2006</date>
<booktitle>In Proceedings of the Third Workshop on Scalable Natural Language Understanding ScaNaLU</booktitle>
<pages>41--48</pages>
<location>New York City: NY.</location>
<marker>Gedigian, Bryant, Narayanan, Ciric, 2006</marker>
<rawString>Matt Gedigian, John Bryant, Srini Narayanan and Branimir Ciric. 2006. Catching Metaphors. In Proceedings of the Third Workshop on Scalable Natural Language Understanding ScaNaLU 2006, pages 41–48. New York City: NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Hovy</author>
</authors>
<title>Shashank Shrivastava, Sujay Kumar Jauhar, Mrinmaya Sachan, Kartik Goyal, Huying Li, Whitney Sanders and Eduard Hovy.</title>
<date>2013</date>
<booktitle>In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL).</booktitle>
<publisher>Atlanta.</publisher>
<marker>Hovy, 2013</marker>
<rawString>Dirk Hovy, Shashank Shrivastava, Sujay Kumar Jauhar, Mrinmaya Sachan, Kartik Goyal, Huying Li, Whitney Sanders and Eduard Hovy. 2013. Identifying Metaphorical Word Use with Tree Kernels. In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL). Atlanta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04.</booktitle>
<contexts>
<context position="8144" citStr="Kim and Hovy, 2004" startWordPosition="1277" endWordPosition="1280">metimes referred to as intensity. Our approach to affect in metaphor has been vetted not only by our core linguistic team but also by an independent team of linguist-analysts with whom we work to understand metaphor across several language-culture groups. Our research continues to show no difficulties in comprehension or disagreement across languages concerning the concept of linguistic affect, of its application to metaphor, and of its having both polarity and intensity. 5 Related Research: sentiment and affect There is a relatively large volume of research on sentiment analysis in language (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; inter alia) that aim at detecting polarity of text, but is not specifically concerned with metaphors. A number of systems were developed to automatically extract writer’s senti1 The First Workshop on Metaphor in NLP. http://aclweb.org/anthology//W/W13/W13-09.pdf 43 ment towards specific products or services such as movies or hotels, from online reviews (e.g., Turney, 2002; Pang and Lee, 2008) or social media messages (e.g., Thelwall et al., 2010). None of these techniques has been applied specifically to metaphorical language, and it is</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
</authors>
<title>Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="9595" citStr="Kozareva (2013)" startWordPosition="1497" endWordPosition="1498">egative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2. While presence of affect in metaphorical language is well documented in linguistic and psycholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automatically. Some notable recent efforts include Zhang and Barnden (2010), Veale and Li (2012), and Kozareva (2013), who proposed various models of metaphor affect classification based primarily on lexical features of the surrounding text: specifically the word polarity information. In these and other similar approaches, which are closely related to sentiment analysis, affect is attributed to the entire text fragment: a sentence or utterance containing a metaphor, or in some cases the immediate textual context around it. In contrast, our objective is to isolate affect due to the metaphor itself, independently of its particular context, and also to determine how various elements of the metaphoric expression</context>
<context position="33537" citStr="Kozareva (2013)" startWordPosition="5350" endWordPosition="5351">several dozen of qualified assessors judged hundreds of sentences (extracted from online sources) that contained metaphorical expressions. The objective was to capture affect associated with the metaphor itself. Our system can approximate human judgment with accuracy ranging from 59% for Russian to 74% for English. These results are quite promising. The differences are primarily due to varied robustness of the language processing tools (such as parsers and morphological analyzers) that are available for each language. We note that a direct comparison to lexical approaches such as described by Kozareva (2013) is not possible at this time due to differences in assessment methodology, although it remains one of our objectives. Our next step is to demonstrate that the new way of calculating affect can lead to a reliable model of affective language use that correlates with other established measures of influence. Acknowledgements Supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense US Army Research Laboratory contract number W911NF-12-C-0024. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding a</context>
</contexts>
<marker>Kozareva, 2013</marker>
<rawString>Zornitsa Kozareva. 2013. Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saisuresh Krishnakumaran</author>
<author>Xiaojin Zhu</author>
</authors>
<title>Hunting elusive metaphors using lexical resources.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Figurative Language,</booktitle>
<pages>13--20</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="5157" citStr="Krishnakumaran and Zhu (2007)" startWordPosition="805" endWordPosition="808">-Black, 2002; O’Halloran, 2007) that attempt to correlate metaphor semantics with their usage in naturally occurring text but generally lack robust tools to do so; and (3) social science approaches, particularly in psychology and anthropology that seek to explain how people produce and understand metaphors in interaction, but which lack the necessary computational tools to work with anything other than relatively isolated examples. In computational investigations of metaphor, knowledge-based approaches include MetaBank (Martin, 1994), a large knowledge base of metaphors empirically collected. Krishnakumaran and Zhu (2007) use WordNet (Felbaum, 1998) knowledge to differentiate between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al. (2006) identify a system that can recognize metaphor; however their approach is only shown to work in a narrow domain (The Wall Street Journal, for example). Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman &amp; N</context>
</contexts>
<marker>Krishnakumaran, Zhu, 2007</marker>
<rawString>Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proceedings of the Workshop on Computational Approaches to Figurative Language, pages 13– 20. Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors we live by.</title>
<date>1980</date>
<publisher>University Of Chicago Press,</publisher>
<location>Chicago, Illinois.</location>
<contexts>
<context position="2568" citStr="Lakoff &amp; Johnson, 1980" startWordPosition="395" endWordPosition="399">y account for the contribution of the prior affect associated with the target as well as its immediate linguistic context. 2 Metaphor in Language Metaphors are mapping systems that allow the semantics of a familiar Source domain to be applied to a new Target domain so as to invite new frameworks for reasoning (usually by analogy) to emerge in the target domain. The purpose of a metaphor is (a) to simplify or enable reasoning and communication about the target domain that would otherwise be difficult (because of technical complexity) or impossible (due to lack of agreed upon vocabulary) (e.g., Lakoff &amp; Johnson, 1980; 2004); or (b) to frame the target domain in a particular way that enables one form of reasoning while inhibiting another (e.g., Thibodeau &amp; Boroditsky, 2011). The two reasons for using metaphors are not necessarily mutually exclusive, in other words, (a) and (b) can operate at the same time. The distinction suggested above has to do with affect: a metaphor formed through (a) alone is likely to be neutral (e.g., client/server, messenger DNA), while a metaphor formed using (b) is likely to have a polarizing affect (e.g., tax’s burden). The Source and Target domains that serve as endpoints of a</context>
<context position="4351" citStr="Lakoff &amp; Johnson, 1980" startWordPosition="692" endWordPosition="695">ages 42–51, Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics also possible. (E.g., crime may be both a target and a source domain.) The relations of interest are those that operate between the concepts within a Source domain and can be “borrowed” to link concepts within the Target domain, e.g., “Crime(TARGET) spread to(RELATION) previously safe areas” may be borrowing from a DISEASE or a PARASITE source domain. 3 Related Research: metaphor detection Most current research on metaphor falls into three groups: (1) theoretical linguistic approaches (as defined by Lakoff &amp; Johnson, 1980; and their followers) that generally look at metaphors as abstract language constructs with complex semantic properties; (2) quantitative linguistic approaches (e.g., Charteris-Black, 2002; O’Halloran, 2007) that attempt to correlate metaphor semantics with their usage in naturally occurring text but generally lack robust tools to do so; and (3) social science approaches, particularly in psychology and anthropology that seek to explain how people produce and understand metaphors in interaction, but which lack the necessary computational tools to work with anything other than relatively isolat</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff, and Mark Johnson. 1980. Metaphors we live by. University Of Chicago Press, Chicago, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lakoff George</author>
</authors>
<title>Moral politics: what conservatives know that liberals don’t.</title>
<date>2001</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, Illinois.</location>
<marker>George, 2001</marker>
<rawString>George, Lakoff. 2001. Moral politics: what conservatives know that liberals don’t. University of Chicago Press, Chicago, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ting Liu</author>
<author>Kit Cho</author>
<author>George Aaron Broadwell</author>
<author>Samira Shaikh</author>
<author>Tomek Strzalkowski</author>
<author>John Lien</author>
<author>Sarah Taylor</author>
<author>Laurie Feldman</author>
<author>Boris Yamrom</author>
<author>Nick Webb</author>
</authors>
<title>Umit Boz and Ignacio Cases.</title>
<date>2014</date>
<booktitle>In Proceedings of 9th Language Resources and Evaluation Conference, (LREC 2014)Reykjavik,</booktitle>
<contexts>
<context position="14873" citStr="Liu et al. (2014)" startWordPosition="2334" endWordPosition="2337">entive argument, i.e., crushed(GovReg, X), where X is an optional patientive argument, in this case “small businesses”. Thus, government regulation is said to be doing something akin to “crushing”, a harmful and negative activity according to the Affective Norms in English (ANEW) psycholinguistic database (Bradley and Lang, 1999). Since “government regulation” is doing something negative, the polarity of affect conveyed about it is also negative. The ANEW lexicon we are using contains ratings of ~100K words. The original ANEW lexicon by Bradley and Lang was expanded following the work done by Liu et al. (2014) in expanding the MRC imageability lexicon. While other sources of valence judgments exist such as NRC (Mohammad et al., 2013) and MPQA (Weibe and Cardie, 2005), there are limitations Ð for instance Ð NRC lexicon rates each words on a positive or negative scale, which does not allow for more fine-grained analysis of strength of valence. Calculation from Table 1 is further generalized by incorporating the optional second argument of the relation and the role of the target concept (i.e., agentive or patientive). Thus, if X=‘small business’ as in the example above, the complete relation becomes c</context>
</contexts>
<marker>Liu, Cho, Broadwell, Shaikh, Strzalkowski, Lien, Taylor, Feldman, Yamrom, Webb, 2014</marker>
<rawString>Ting Liu, Kit Cho, George Aaron Broadwell, Samira Shaikh, Tomek Strzalkowski, John Lien, Sarah Taylor, Laurie Feldman, Boris Yamrom, Nick Webb, Umit Boz and Ignacio Cases. 2014. Automatic Expansion of the MRC Psycholinguistic Database Imageability Ratings. In Proceedings of 9th Language Resources and Evaluation Conference, (LREC 2014)Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malkki Liisa</author>
</authors>
<title>National geographic: The rooting of people and the territorialization of national identity among scholars and refugees.</title>
<date>1992</date>
<journal>Society for Cultural Anthropology,</journal>
<volume>7</volume>
<issue>1</issue>
<marker>Liisa, 1992</marker>
<rawString>Liisa, Malkki. 1992. National geographic: The rooting of people and the territorialization of national identity among scholars and refugees. Society for Cultural Anthropology, 7(1):24–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>A computational theory of metaphor.</title>
<date>1988</date>
<note>Ph.D. Dissertation.</note>
<marker>Martin, 1988</marker>
<rawString>James Martin. 1988. A computational theory of metaphor. Ph.D. Dissertation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth O McGraw</author>
<author>S P Wong</author>
</authors>
<title>Forming inferences about some intraclass correlation coefficients.</title>
<date>1996</date>
<journal>Psychological Methods,</journal>
<volume>1</volume>
<issue>1</issue>
<pages>30--46</pages>
<contexts>
<context position="28808" citStr="McGraw &amp; Wong, 1996" startWordPosition="4600" endWordPosition="4603">act, some direct expressions may carry stronger affect than subtle and indirect metaphors. This is why both questions on the survey are necessary: the first focuses the assessor’s attention on the highlighted metaphor before asking about affect. If the purpose of the test is to measure the accuracy of assigning affect to a metaphor, then accuracy should be measured against the subset of expressions judged to be metaphorical. The judgments collected from human assessors are tested for reliability and validity. Reliability among the raters is computed by measuring intra-class correlation (ICC) (McGraw &amp; Wong, 1996; Shrout &amp; Fleiss, 1979). Typically, a coefficient value above 0.7 indicates strong agreement. In general, our analyses have shown that we need approximately 30 or more subjects in order to obtain a reliability coefficient of at least 0.7. In addition, certain precautions were taken to ensure quality control in the data. We used the following criteria to discard a subject’s data: (1) completed the task too quickly (i.e., averaged fewer than 10 seconds for each passage); (2) gave the same answer to 85% or more of the test items; (3) did not pass a simple language proficiency test; or (4) did no</context>
</contexts>
<marker>McGraw, Wong, 1996</marker>
<rawString>Kenneth O. McGraw and S. P. Wong. 1996. Forming inferences about some intraclass correlation coefficients. Psychological Methods, 1(1): 30–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Mohammad</author>
<author>S Kiritchenko</author>
<author>X Zhu</author>
</authors>
<title>NRC-Canada: Building the state-of-the-art insentiment analysis of tweets.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventh International Workshop on Semantic Evaluation Exercises (SemEval-2013),</booktitle>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="14999" citStr="Mohammad et al., 2013" startWordPosition="2355" endWordPosition="2358">hus, government regulation is said to be doing something akin to “crushing”, a harmful and negative activity according to the Affective Norms in English (ANEW) psycholinguistic database (Bradley and Lang, 1999). Since “government regulation” is doing something negative, the polarity of affect conveyed about it is also negative. The ANEW lexicon we are using contains ratings of ~100K words. The original ANEW lexicon by Bradley and Lang was expanded following the work done by Liu et al. (2014) in expanding the MRC imageability lexicon. While other sources of valence judgments exist such as NRC (Mohammad et al., 2013) and MPQA (Weibe and Cardie, 2005), there are limitations Ð for instance Ð NRC lexicon rates each words on a positive or negative scale, which does not allow for more fine-grained analysis of strength of valence. Calculation from Table 1 is further generalized by incorporating the optional second argument of the relation and the role of the target concept (i.e., agentive or patientive). Thus, if X=‘small business’ as in the example above, the complete relation becomes crushed(GovReg, SmBus), which retains negative affect assuming that ‘small business’ is considered positive or at least neutral</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Mohammad, S.M., S. Kiritchenko, and X. Zhu. 2013. NRC-Canada: Building the state-of-the-art insentiment analysis of tweets. In Proceedings of the Seventh International Workshop on Semantic Evaluation Exercises (SemEval-2013), Atlanta, Georgia, USA, June 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Mohler</author>
<author>David Bracewell</author>
<author>David Hinote</author>
<author>Marc Tomlinson</author>
</authors>
<title>Semantic signatures for example-based linguistic metaphor detection.</title>
<date>2013</date>
<booktitle>In The Proceedings of the First Workshop on Metaphor in NLP, (NAACL),</booktitle>
<pages>46--54</pages>
<contexts>
<context position="6561" citStr="Mohler et al., 2013" startWordPosition="1021" endWordPosition="1024"> computational metaphor identification. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantities and may not be easily generated in different languages. Several other similar approaches were recently reported at the Meta4NLP 1 workshop, e.g., (Mohler et al., 2013; Wilks et al., 2013; Hovy et al., 2013). Most recently, a significantly different approach to metaphor understanding based on lexical semantics and discourse analysis was introduced by Strzalkowski et al. (2013). Space constraints limit our discussion about their work in this article, however in the foregoing, our discussion is largely consistent with their framework. 4 Affect in Metaphors Affect in language is understood to mean the attitude toward a topic that a speaker/writer attempts to convey to the reader or audience via text or speech (van der Sluis and Mellish 2008). It is expressed t</context>
</contexts>
<marker>Mohler, Bracewell, Hinote, Tomlinson, 2013</marker>
<rawString>Michael Mohler, David Bracewell, David Hinote, and Marc Tomlinson. 2013. Semantic signatures for example-based linguistic metaphor detection. In The Proceedings of the First Workshop on Metaphor in NLP, (NAACL), pages 46–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Musolff</author>
</authors>
<title>What can critical metaphor analysis add to the understanding of racist ideology? Recent studies of Hitler’s anti-semitic metaphors, critical approaches to discourse analysis across disciplines. Critical Approaches to Discourse Analysis Across Disciplines,</title>
<date>2008</date>
<marker>Musolff, 2008</marker>
<rawString>Musolff, Andreas. 2008. What can critical metaphor analysis add to the understanding of racist ideology? Recent studies of Hitler’s anti-semitic metaphors, critical approaches to discourse analysis across disciplines. Critical Approaches to Discourse Analysis Across Disciplines, 2(2):1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O’Halloran Kieran</author>
</authors>
<title>Critical discourse analysis and the corpus-informed interpretation of metaphor at the register level.</title>
<date>2007</date>
<publisher>Oxford University Press</publisher>
<marker>Kieran, 2007</marker>
<rawString>Kieran, O’Halloran. 2007. Critical discourse analysis and the corpus-informed interpretation of metaphor at the register level. Oxford University Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles E Osgood</author>
</authors>
<title>The cognitive dynamics of synaesthesia and metaphor.</title>
<date>1981</date>
<booktitle>In Proceedings of the National Symposium for Research in Art. Learning in Art: Representation and Metaphor,</booktitle>
<pages>56--80</pages>
<publisher>University of Illinois Press.</publisher>
<marker>Osgood, 1981</marker>
<rawString>Charles E. Osgood. 1981. The cognitive dynamics of synaesthesia and metaphor. In Proceedings of the National Symposium for Research in Art. Learning in Art: Representation and Metaphor, pages 56-80. University of Illinois Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<pages>2--1</pages>
<contexts>
<context position="8597" citStr="Pang and Lee, 2008" startWordPosition="1344" endWordPosition="1347"> polarity and intensity. 5 Related Research: sentiment and affect There is a relatively large volume of research on sentiment analysis in language (Kim and Hovy, 2004; Strapparava and Mihalcea, 2007; Wiebe and Cardie, 2005; inter alia) that aim at detecting polarity of text, but is not specifically concerned with metaphors. A number of systems were developed to automatically extract writer’s senti1 The First Workshop on Metaphor in NLP. http://aclweb.org/anthology//W/W13/W13-09.pdf 43 ment towards specific products or services such as movies or hotels, from online reviews (e.g., Turney, 2002; Pang and Lee, 2008) or social media messages (e.g., Thelwall et al., 2010). None of these techniques has been applied specifically to metaphorical language, and it is unclear if these alone would be sufficient due to the relatively complex semantics involved in metaphor interpretation. Socher et al. (2013 cite) have recently used recursive neural tensor networks to classify sentences into positive/negative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentimen</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1–135, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allan Pavio</author>
<author>Mary Walsh</author>
</authors>
<title>Psychological processes in metaphor comprehension and memory.</title>
<date>1993</date>
<booktitle>Metaphor and thought (2nd ed.). Cambridge:</booktitle>
<editor>In Andrew Ortony, editor,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="9389" citStr="Pavio and Walsh, 1993" startWordPosition="1464" endWordPosition="1467">would be sufficient due to the relatively complex semantics involved in metaphor interpretation. Socher et al. (2013 cite) have recently used recursive neural tensor networks to classify sentences into positive/negative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2. While presence of affect in metaphorical language is well documented in linguistic and psycholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automatically. Some notable recent efforts include Zhang and Barnden (2010), Veale and Li (2012), and Kozareva (2013), who proposed various models of metaphor affect classification based primarily on lexical features of the surrounding text: specifically the word polarity information. In these and other similar approaches, which are closely related to sentiment analysis, affect is attributed to the entire text fragment: a sentence or utterance containing a metaphor, or in some cases the immediate textual c</context>
</contexts>
<marker>Pavio, Walsh, 1993</marker>
<rawString>Allan Pavio and Mary Walsh. 1993. Psychological processes in metaphor comprehension and memory. In Andrew Ortony, editor, Metaphor and thought (2nd ed.). Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick E Shrout</author>
<author>Joseph L Fleiss</author>
</authors>
<title>Intraclass correlations: Uses in assessing rater reliability.</title>
<date>1979</date>
<journal>Psychological Bulletin,</journal>
<volume>86</volume>
<issue>2</issue>
<contexts>
<context position="28832" citStr="Shrout &amp; Fleiss, 1979" startWordPosition="4604" endWordPosition="4607">essions may carry stronger affect than subtle and indirect metaphors. This is why both questions on the survey are necessary: the first focuses the assessor’s attention on the highlighted metaphor before asking about affect. If the purpose of the test is to measure the accuracy of assigning affect to a metaphor, then accuracy should be measured against the subset of expressions judged to be metaphorical. The judgments collected from human assessors are tested for reliability and validity. Reliability among the raters is computed by measuring intra-class correlation (ICC) (McGraw &amp; Wong, 1996; Shrout &amp; Fleiss, 1979). Typically, a coefficient value above 0.7 indicates strong agreement. In general, our analyses have shown that we need approximately 30 or more subjects in order to obtain a reliability coefficient of at least 0.7. In addition, certain precautions were taken to ensure quality control in the data. We used the following criteria to discard a subject’s data: (1) completed the task too quickly (i.e., averaged fewer than 10 seconds for each passage); (2) gave the same answer to 85% or more of the test items; (3) did not pass a simple language proficiency test; or (4) did not provide correct answer</context>
</contexts>
<marker>Shrout, Fleiss, 1979</marker>
<rawString>Patrick E Shrout and Joseph L Fleiss. 1979. Intraclass correlations: Uses in assessing rater reliability. Psychological Bulletin, 86(2):420–428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Models of metaphors in NLP.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL 2010.</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="5825" citStr="Shutova, 2010" startWordPosition="910" endWordPosition="911"> between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al. (2006) identify a system that can recognize metaphor; however their approach is only shown to work in a narrow domain (The Wall Street Journal, for example). Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman &amp; Narayan, 2004; Shutova &amp; Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al. (2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantities and may not be easily generate</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>Ekaterina Shutova. 2010. Models of metaphors in NLP. In Proceedings of ACL 2010. Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
</authors>
<title>Metaphor corpus annotated for source - target domain mappings.</title>
<date>2010</date>
<booktitle>In Proceedings of Language Resources and Evaluation Conference</booktitle>
<contexts>
<context position="5793" citStr="Shutova &amp; Teufel, 2010" startWordPosition="903" endWordPosition="906">Felbaum, 1998) knowledge to differentiate between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al. (2006) identify a system that can recognize metaphor; however their approach is only shown to work in a narrow domain (The Wall Street Journal, for example). Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman &amp; Narayan, 2004; Shutova &amp; Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al. (2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantitie</context>
</contexts>
<marker>Shutova, Teufel, 2010</marker>
<rawString>Ekaterina Shutova and Simone Teufel. 2010a. Metaphor corpus annotated for source - target domain mappings. In Proceedings of Language Resources and Evaluation Conference 2010. Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Models of metaphor in nlp.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>688--697</pages>
<contexts>
<context position="5825" citStr="Shutova, 2010" startWordPosition="910" endWordPosition="911"> between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfactorily robust in different languages. Gedigan et al. (2006) identify a system that can recognize metaphor; however their approach is only shown to work in a narrow domain (The Wall Street Journal, for example). Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman &amp; Narayan, 2004; Shutova &amp; Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al. (2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantities and may not be easily generate</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>Ekaterina Shutova. 2010b. Models of metaphor in nlp. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 688–697.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Tim Van de Cruys</author>
<author>Anna Korhonen</author>
</authors>
<title>Unsupervised metaphor paraphrasing using a vector space model</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<location>Mumbai, India</location>
<marker>Shutova, Van de Cruys, Korhonen, 2012</marker>
<rawString>Ekaterina Shutova, Tim Van de Cruys, and Anna Korhonen. 2012. Unsupervised metaphor paraphrasing using a vector space model In Proceedings of COLING 2012, Mumbai, India</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Wu</author>
<author>Jason Chuang</author>
<author>Chris Manning</author>
<author>Andrew Ng</author>
<author>Chris Potts</author>
</authors>
<date>2013</date>
<booktitle>In Proceedings Conference on Empirical Methods in Natural Language Processing (EMNLP 2013).</booktitle>
<location>Seattle, USA.</location>
<contexts>
<context position="8884" citStr="Socher et al. (2013" startWordPosition="1391" endWordPosition="1394">specifically concerned with metaphors. A number of systems were developed to automatically extract writer’s senti1 The First Workshop on Metaphor in NLP. http://aclweb.org/anthology//W/W13/W13-09.pdf 43 ment towards specific products or services such as movies or hotels, from online reviews (e.g., Turney, 2002; Pang and Lee, 2008) or social media messages (e.g., Thelwall et al., 2010). None of these techniques has been applied specifically to metaphorical language, and it is unclear if these alone would be sufficient due to the relatively complex semantics involved in metaphor interpretation. Socher et al. (2013 cite) have recently used recursive neural tensor networks to classify sentences into positive/negative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2. While presence of affect in metaphorical language is well documented in linguistic and psycholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automa</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. 2013. In Proceedings Conference on Empirical Methods in Natural Language Processing (EMNLP 2013). Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sopory</author>
<author>J P Dillard</author>
</authors>
<title>The Persuasive Effects of Metaphor: A Meta-Analysis.</title>
<date>2002</date>
<journal>Human Communication Research,</journal>
<volume>28</volume>
<pages>382--419</pages>
<marker>Sopory, Dillard, 2002</marker>
<rawString>Sopory, P. and Dillard, J. P. (2002), The Persuasive Effects of Metaphor: A Meta-Analysis. Human Communication Research, 28: 382–419. doi: 10.1111/j.1468-2958.2002.tb00813.x</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Steen</author>
</authors>
<title>Understanding metaphor in literature: An empirical approach.</title>
<date>1994</date>
<publisher>Longman.</publisher>
<location>London:</location>
<contexts>
<context position="9427" citStr="Steen, 1994" startWordPosition="1472" endWordPosition="1473">ex semantics involved in metaphor interpretation. Socher et al. (2013 cite) have recently used recursive neural tensor networks to classify sentences into positive/negative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2. While presence of affect in metaphorical language is well documented in linguistic and psycholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automatically. Some notable recent efforts include Zhang and Barnden (2010), Veale and Li (2012), and Kozareva (2013), who proposed various models of metaphor affect classification based primarily on lexical features of the surrounding text: specifically the word polarity information. In these and other similar approaches, which are closely related to sentiment analysis, affect is attributed to the entire text fragment: a sentence or utterance containing a metaphor, or in some cases the immediate textual context around it. In contrast, our obj</context>
</contexts>
<marker>Steen, 1994</marker>
<rawString>Gerard Steen. 1994. Understanding metaphor in literature: An empirical approach. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Strapparava Carlo</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semeval-2007 task 14: Affective text.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations,</booktitle>
<pages>70--74</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Carlo, Mihalcea, 2007</marker>
<rawString>Carlo, Strapparava, and Rada Mihalcea. 2007. Semeval-2007 task 14: Affective text. In Proceedings of the Fourth International Workshop on Semantic Evaluations, pages 70–74. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>George Aaron Broadwell</author>
<author>Sarah Taylor</author>
<author>Laurie Feldman</author>
<author>Boris Yamrom</author>
<author>Samira Shaikh</author>
</authors>
<title>Robust extraction of metaphor from novel data.</title>
<date>2013</date>
<booktitle>In Proceedings of Workshop on Metaphor in NLP, NAACL.</booktitle>
<publisher>Atlanta.</publisher>
<institution>Ting Liu, Kit Cho, Umit Boz, Ignacio Cases</institution>
<contexts>
<context position="6773" citStr="Strzalkowski et al. (2013)" startWordPosition="1055" endWordPosition="1058">ion using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantities and may not be easily generated in different languages. Several other similar approaches were recently reported at the Meta4NLP 1 workshop, e.g., (Mohler et al., 2013; Wilks et al., 2013; Hovy et al., 2013). Most recently, a significantly different approach to metaphor understanding based on lexical semantics and discourse analysis was introduced by Strzalkowski et al. (2013). Space constraints limit our discussion about their work in this article, however in the foregoing, our discussion is largely consistent with their framework. 4 Affect in Metaphors Affect in language is understood to mean the attitude toward a topic that a speaker/writer attempts to convey to the reader or audience via text or speech (van der Sluis and Mellish 2008). It is expressed through multiple means, many of which are unrelated to metaphor. While affect in text is often associated, at least in theory, with a variety of basic emotions (anger, fear, etc.), it is generally possible to clas</context>
</contexts>
<marker>Strzalkowski, Broadwell, Taylor, Feldman, Yamrom, Shaikh, 2013</marker>
<rawString>Tomek Strzalkowski, George Aaron Broadwell, Sarah Taylor, Laurie Feldman, Boris Yamrom, Samira Shaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio Cases and Kyle Elliott. 2013. Robust extraction of metaphor from novel data. In Proceedings of Workshop on Metaphor in NLP, NAACL. Atlanta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Patoglou</author>
</authors>
<title>Sentiment in Twitter events.</title>
<date>2011</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>62</volume>
<issue>2</issue>
<marker>Thelwall, Buckley, Patoglou, 2011</marker>
<rawString>Mike Thelwall, Kevan Buckley, and Georgios Patoglou. Sentiment in Twitter events. 2011. Journal of the American Society for Information Science and Technology, 62(2):406–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul H Thibodeau</author>
<author>Lera Boroditsky</author>
</authors>
<title>Metaphors We Think With: The Role of Metaphor in Reasoning.</title>
<date>2011</date>
<journal>PLoS ONE</journal>
<volume>6</volume>
<issue>2</issue>
<pages>16782</pages>
<contexts>
<context position="2727" citStr="Thibodeau &amp; Boroditsky, 2011" startWordPosition="423" endWordPosition="426">ors are mapping systems that allow the semantics of a familiar Source domain to be applied to a new Target domain so as to invite new frameworks for reasoning (usually by analogy) to emerge in the target domain. The purpose of a metaphor is (a) to simplify or enable reasoning and communication about the target domain that would otherwise be difficult (because of technical complexity) or impossible (due to lack of agreed upon vocabulary) (e.g., Lakoff &amp; Johnson, 1980; 2004); or (b) to frame the target domain in a particular way that enables one form of reasoning while inhibiting another (e.g., Thibodeau &amp; Boroditsky, 2011). The two reasons for using metaphors are not necessarily mutually exclusive, in other words, (a) and (b) can operate at the same time. The distinction suggested above has to do with affect: a metaphor formed through (a) alone is likely to be neutral (e.g., client/server, messenger DNA), while a metaphor formed using (b) is likely to have a polarizing affect (e.g., tax’s burden). The Source and Target domains that serve as endpoints of a metaphoric mapping can be represented in a variety of ways; however, in a nutshell they are composed of two kinds of things: concepts and relations. In a Targ</context>
</contexts>
<marker>Thibodeau, Boroditsky, 2011</marker>
<rawString>Paul H. Thibodeau and Lera Boroditsky. 2011. Metaphors We Think With: The Role of Metaphor in Reasoning. PLoS ONE 6(2): e16782.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Peter</author>
<author>Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>417--424</pages>
<marker>Peter, Turney, 2002</marker>
<rawString>Peter D, Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ielka van der Sluis</author>
<author>C Mellish</author>
</authors>
<title>Toward affective natural language deneration: Empirical investigations. affective language in human and machine. AISB</title>
<date>2008</date>
<booktitle>Proceedings</booktitle>
<volume>2</volume>
<marker>van der Sluis, Mellish, 2008</marker>
<rawString>Ielka van der Sluis, and C. Mellish 2008. Toward affective natural language deneration: Empirical investigations. affective language in human and machine. AISB 2008 Proceedings Volume 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
<author>Guofu Li</author>
</authors>
<title>Specifying viewpoint and information need with affective metaphors: a system demonstration of the metaphor magnet web app/service.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations, ACL ’12,</booktitle>
<pages>7--12</pages>
<contexts>
<context position="9574" citStr="Veale and Li (2012)" startWordPosition="1492" endWordPosition="1495">sentences into positive/negative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2. While presence of affect in metaphorical language is well documented in linguistic and psycholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automatically. Some notable recent efforts include Zhang and Barnden (2010), Veale and Li (2012), and Kozareva (2013), who proposed various models of metaphor affect classification based primarily on lexical features of the surrounding text: specifically the word polarity information. In these and other similar approaches, which are closely related to sentiment analysis, affect is attributed to the entire text fragment: a sentence or utterance containing a metaphor, or in some cases the immediate textual context around it. In contrast, our objective is to isolate affect due to the metaphor itself, independently of its particular context, and also to determine how various elements of the </context>
</contexts>
<marker>Veale, Li, 2012</marker>
<rawString>Tony Veale and Guofu Li. 2012. Specifying viewpoint and information need with affective metaphors: a system demonstration of the metaphor magnet web app/service. In Proceedings of the ACL 2012 System Demonstrations, ACL ’12, pages 7–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wiebe Janyce</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. In Language Resources and Evaluation.</title>
<date>2005</date>
<marker>Janyce, Cardie, 2005</marker>
<rawString>Janyce, Wiebe and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. In Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wilks Yorick</author>
</authors>
<title>Preference semantics. Formal Semantics of Natural Language,</title>
<date>1975</date>
<pages>329--348</pages>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, U.K.,</location>
<marker>Yorick, 1975</marker>
<rawString>Yorick, Wilks. 1975. Preference semantics. Formal Semantics of Natural Language, E. L. Keenan, Ed. Cambridge University Press, Cambridge, U.K., 329–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
<author>Lucian Galescu</author>
<author>James Allen</author>
<author>Adam Dalton</author>
</authors>
<title>Automatic Metaphor Detection using Large-Scale Lexical Resources and Conventional Metaphor Extraction.</title>
<date>2013</date>
<booktitle>In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL).</booktitle>
<publisher>Atlanta.</publisher>
<contexts>
<context position="6581" citStr="Wilks et al., 2013" startWordPosition="1025" endWordPosition="1028">or identification. However, they describe their own work as an initial exploration and hence, inconclusive. Shutova et al. (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is difficult to produce in large quantities and may not be easily generated in different languages. Several other similar approaches were recently reported at the Meta4NLP 1 workshop, e.g., (Mohler et al., 2013; Wilks et al., 2013; Hovy et al., 2013). Most recently, a significantly different approach to metaphor understanding based on lexical semantics and discourse analysis was introduced by Strzalkowski et al. (2013). Space constraints limit our discussion about their work in this article, however in the foregoing, our discussion is largely consistent with their framework. 4 Affect in Metaphors Affect in language is understood to mean the attitude toward a topic that a speaker/writer attempts to convey to the reader or audience via text or speech (van der Sluis and Mellish 2008). It is expressed through multiple mean</context>
</contexts>
<marker>Wilks, Galescu, Allen, Dalton, 2013</marker>
<rawString>Yorick Wilks, Lucian Galescu, James Allen, Adam Dalton. 2013. Automatic Metaphor Detection using Large-Scale Lexical Resources and Conventional Metaphor Extraction. In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL). Atlanta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
<author>C Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language.</title>
<date>2005</date>
<journal>Language Resources and Evaluation,</journal>
<volume>39</volume>
<issue>2</issue>
<pages>165--210</pages>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Wiebe, J., Wilson, T., and Cardie, C.: Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39(2-3), pp. 165-210 (2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhang</author>
<author>John Barnden</author>
</authors>
<title>Affect and metaphor sensing in virtual drama.</title>
<date>2010</date>
<journal>International Journal of Computer Games Technology.</journal>
<volume>Vol.</volume>
<contexts>
<context position="9553" citStr="Zhang and Barnden (2010)" startWordPosition="1488" endWordPosition="1491">nsor networks to classify sentences into positive/negative categories. However, the presence of largely negative concepts such as “poverty” in a given sentence overwhelms the sentiment for the sentence in their method. Other relevant efforts in sentence level sentiment analysis include Sem-Eval Task2. While presence of affect in metaphorical language is well documented in linguistic and psycholinguistic literature (e.g., Osgood, 1980; Pavio and Walsh, 1993; Caffi and Janney, 1994; Steen, 1994), relatively little work was done to detect affect automatically. Some notable recent efforts include Zhang and Barnden (2010), Veale and Li (2012), and Kozareva (2013), who proposed various models of metaphor affect classification based primarily on lexical features of the surrounding text: specifically the word polarity information. In these and other similar approaches, which are closely related to sentiment analysis, affect is attributed to the entire text fragment: a sentence or utterance containing a metaphor, or in some cases the immediate textual context around it. In contrast, our objective is to isolate affect due to the metaphor itself, independently of its particular context, and also to determine how var</context>
</contexts>
<marker>Zhang, Barnden, 2010</marker>
<rawString>Li Zhang and John Barnden. 2010. Affect and metaphor sensing in virtual drama. International Journal of Computer Games Technology. Vol. 2010.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>