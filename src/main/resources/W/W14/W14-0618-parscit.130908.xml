<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.998783">
Towards Automatic Wayang Ontology Construction using
Relation Extraction from Free Text
</title>
<author confidence="0.972999">
Hadaiq Rolis Sanabila Ruli Manurung
</author>
<affiliation confidence="0.9719825">
Faculty of Computer Science Faculty of Computer Science
Universitas Indonesia Universitas Indonesia
</affiliation>
<email confidence="0.986491">
hadaiq@cs.ui.ac.id maruli@cs.ui.ac.id
</email>
<sectionHeader confidence="0.9822" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999726909090909">
This paper reports on our work to
automatically construct and populate an
ontology of wayang (Indonesian shadow
puppet) mythology from free text using
relation extraction and relation clustering. A
reference ontology is used to evaluate the
generated ontology. The reference ontology
contains concepts and properties within the
wayang character domain. We examined the
influence of corpus data variations, threshold
value variations in the relation clustering
process, and the usage of entity pairs or entity
pair types during the feature extraction stages.
The constructed ontology is examined using
three evaluation methods, i.e. cluster purity
(CP), instance knowledge (IK), and relation
concept (RC). Based on the evaluation results,
the proposed method generates the best
ontology when using a consolidated corpus,
the threshold value in relation clustering is 1,
and entity pairs are used during feature
extraction.
</bodyText>
<sectionHeader confidence="0.995165" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995278">
As a country rich in cultural diversity, Indonesia
certainly has an outstanding wealth of national
culture. Wayang (shadow puppets performance
art) is one instance of Indonesian culture that has
cultural values and noble character. Although the
stories are generally taken from the Mahabharata
and Ramayana books, they involve the wisdom
and greatness of the Indonesian culture. Wayang
shows rely heavily on the knowledge and
creativity of the puppeteer (dalang). Often, the
story and knowledge about the shadow puppets
is known only to the puppeteer and not set forth
in writing. Such a lack of knowledge transfer
process results in a lot of knowledge that is
known only by the puppeteer cannot be shared to
others, which leads to the loss of cultural
richness. The knowledge held by the puppeteer
ought to be propagated to future generations in
order to be learned and developed.
Information about the shadow puppets can be
represented as textual data describing hundreds
of characters. Constructing an ontology manually
from such a large data source is time consuming
and labor intensive.
Work on relation extraction has already been
conducted in the past. Initially, supervised
learning approaches were used, for example
feature-based supervised learning (Kambhatla,
2004; Zhao and Grishman, 2005). Some features
that are generally used are words that lie among
the entities, the entity type, the number of words
between two entities, and the number of entities
between two entities. In addition, there are
several studies that use kernel-based approach.
The kernel K(x, y) defines the similarity between
objects x and y in the high-dimensional objects.
There are various elements used to construct
kernels such as word subsequence (Bunescu and
Mooney, 2005) and parse trees (Zelenko et al.,
2003; Culotta et al., 2004).
In addition, several studies use semi-
supervised learning. DIPRE (Brin, 1998) tries to
find the relationship between the author interest
and the book he/she had written. Snowball
(Agichtein and Gravano, 2000) uses an
architecture that is not very different from
DIPRE to determine the relationship between an
organization and its location. Meanwhile,
Knowitall (Etzioni at al., 2005) examines relation
extraction in heterogeneous domains of text data
</bodyText>
<page confidence="0.428259">
128
</page>
<note confidence="0.9981335">
Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 128–136,
Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999332604651163">
from the web automatically. Finally TextRunner
(Banko at al., 2007) is a system that
automatically searches the relationships between
entities that exist in a corpus. This method
produces a binary relation (e1, r, e2) where e1 and
e2 are entities and r is a relation between them.
Work on automatic ontology construction has
been done by several researchers. Celjuska et al.
(2004) developed a semi-automatic ontology
construction system named Ontosophie. The
system generates an ontology with the instances
derived from unstructured text. Shamsfard et al.
(2004) developed an automatic ontology
construction approach which utilizes a kernel
based method. Alani et al. (2003) tries to
construct an ontology using data from the web.
The system, named Artefakt, performs
information summarization about the artist.
Furthermore, the constructed ontology is used to
generate personalized narrative biographies. The
system consists of three components, namely
knowledge extraction, information management,
and biography construction component.
The majority of the information extraction
methods mentioned above require reliable NLP
tools and resources. Unfortunately these are not
readily available for Indonesian, the language
our wayang data is in. To overcome this
challenge, we employ information extraction
methods that only require simple resources such
as gazetteers and stopword lists, which are
potentially used in a variety of problem domains.
In this study, we explore methods to
automatically construct an ontology using a
corpus of wayang character descriptions using
relation extraction and clustering. This method
requires a gazetteer which contains a list of
entities from the text. The entity types that are
contained in the gazetteer are the name of the
puppet characters, their kingdoms of origin, and
their various artefacts such as weapons or spells.
We realize our method does not yet fully
constitute the development of a complete
</bodyText>
<figureCaption confidence="0.9702465">
Figure 1. Automatic ontology construction
and evaluation stages
</figureCaption>
<bodyText confidence="0.999473">
ontology, but provides an important step towards
that direction, namely the identification of
relations to be found within the ontology.
</bodyText>
<sectionHeader confidence="0.92446" genericHeader="method">
2 Automatic Ontology Construction
</sectionHeader>
<bodyText confidence="0.999980545454546">
We aim to automatically build a wayang
ontology from free text. The information or
knowledge that is contained within the text is
extracted by employing relation extraction. This
method will extract instance candidates that are
subsequently clustered using relation clustering.
Furthermore, the ontology will be evaluated
using a reference ontology to examine the quality
of the constructed ontology. The stages of
automatic ontology construction and evaluation
are depicted in Figure 1.
</bodyText>
<subsectionHeader confidence="0.996052">
2.1 Automatic Ontology Construction
</subsectionHeader>
<bodyText confidence="0.999807571428571">
During this stage, the system attempts to find all
possible relationships that occur between any
two entities. These relationships are further
analysed to obtain a set of valid relationships
between entities. The valid relations will be used
to construct the ontology. The ontology
construction stage is depicted in Figure 2.
</bodyText>
<figure confidence="0.999199714285714">
Free
Text
(raw
data)
Entity
tagging
Pronoun
Resolution
Relation
Extraction
Feature
extraction
Relation
Clustering
</figure>
<figureCaption confidence="0.997583">
Figure 2. The ontology construction stages
</figureCaption>
<figure confidence="0.748979714285714">
129
&lt;Person&gt; Anoman &lt;/Person&gt; kera berbulu putih
seperti kapas. Ia adalah anak &lt;Person&gt; Betara Guru
&lt;/Person&gt; dengan &lt;Person&gt; Dewi Anjani &lt;/Person&gt;,
seorang putri bermuka dan bertangan kera. &lt;Person&gt;
Anoman &lt;/Person&gt; juga bernama &lt;Person&gt; Maruti
&lt;/Person&gt;, karena mempunyai angin, seperti juga
</figure>
<construct confidence="0.968136266666667">
Raden &lt;Person&gt; Werkudara &lt;/Person&gt; dan oleh
karenanya &lt;Person&gt; Anoman &lt;/Person&gt; disebut juga
saudara &lt;Person&gt; Werkudara &lt;/Person&gt; yang
berkesaktian angin; &lt;Person&gt; Anoman &lt;/Person&gt;
juga bernama &lt;Person&gt; Ramadayapati &lt;/Person&gt;,
berarti yang diaku anak oleh Sri &lt;Person&gt; Rama
&lt;/Person&gt;;. &lt;Person&gt; Anoman &lt;/Person&gt; juga
bernama &lt;Person&gt; Bayutanaya &lt;/Person&gt;, berarti
yang diaku anak &lt;Person&gt; Betara Bayu &lt;/Person&gt;;.
&lt;Person&gt; Anoman &lt;/Person&gt; juga bernama
&lt;Person&gt; Kapiwara &lt;/Person&gt;,. Bermula &lt;Person&gt;
Anoman &lt;/Person&gt; hidup pada jaman Sri &lt;Person&gt;
Rama &lt;/Person&gt;, membela Sri Ramapada waktu
kehilangan permaisurinya, Dewi &lt;Person&gt; Sinta
&lt;/Person&gt;,yang dicuri oleh raja raksasa Prabu
</construct>
<figure confidence="0.7125795">
&lt;Person&gt; Dasamuka &lt;/Person&gt; dari negara
&lt;Kingdom&gt; Alengka &lt;/ Kingdom &gt;
</figure>
<figureCaption confidence="0.970921">
Figure 3. Tagging result using non-detailed
</figureCaption>
<bodyText confidence="0.98670928125">
entities
The raw data is free text that consists of
several paragraphs describing short biographies
of wayang characters. Firstly, the free text is
tagged using gazetteer data, i.e. a list of entities
contained in the text. Every word contained in
the gazetteer will be tagged in accordance to its
entity type. The number of entities in the
gazetteer is still general. Thus, the entities are
subdivided into more specific groups. The entity
group is based on Pitoyo Amrih (Amrih, 2011)
which consists of 29 groups. In this study we
used two tagging methods, i.e. by using a
wayang entity that has not been detailed and by
using detailed entities (based on the type of
wayang entity). Different tagging treatment was
conducted to examine whether this affects the
ontology result or not. The example of tagged
text using wayang entity that has not been
detailed and detailed entities can be seen in
Figures 3 and 4.
Subsequently, pronoun resolution is employed
to resolve the entity reference of a pronoun. The
system will then perform relation extraction by
analyzing the words occurring between tagged
entities. This process will generate candidate
relationship patterns between entities (X, r, Y),
where X and Y are entities and r is the textual
pattern that defines the relationship between the
two entities.
The patterns that are obtained from the
previous process are passed on to the next step
</bodyText>
<construct confidence="0.91249925">
&lt;BangsaKera&gt; Anoman &lt;/BangsaKera&gt; kera berbulu
putih seperti kapas. Ia adalah anak &lt;DewaDewi&gt;
Betara Guru &lt;/DewaDewi&gt; dengan &lt;BangsaKera&gt;
Dewi Anjani &lt;/BangsaKera&gt;, seorang putri bermuka
dan bertangan kera. &lt;BangsaKera&gt; Anoman
&lt;/BangsaKera&gt; juga bernama &lt;BangsaKera&gt; Maruti
&lt;/BangsaKera&gt;, karena mempunyai angin, seperti juga
Raden &lt;Pandawa&gt; Werkudara &lt;/Pandawa&gt; dan oleh
karenanya &lt;BangsaKera&gt; Anoman &lt;/BangsaKera&gt;
disebut juga saudara &lt;Pendawa&gt; Werkudara
&lt;/Pendawa&gt; yang berkesaktian angin. &lt;BangsaKera&gt;
Anoman &lt;/BangsaKera&gt; juga bernama &lt;BangsaKera&gt;
Ramadayapati &lt;/BangsaKera&gt;, berarti yang diaku anak
oleh Sri &lt;KerabatAyodya&gt; Rama
&lt;/KerabatAyodya&gt;;. &lt;BangsaKera&gt; Anoman
&lt;/BangsaKera&gt; juga bernama &lt;BangsaKera&gt;
Bayutanaya &lt;/BangsaKera&gt;, berarti yang diaku anak
&lt;DewaDewi&gt; Betara Bayu &lt;/DewaDewi&gt;;.
&lt;BangsaKera&gt; Anoman &lt;/BangsaKera&gt; juga bernama
&lt;BangsaKera&gt; Kapiwara &lt;/BangsaKera&gt;Bermula
&lt;BangsaKera&gt; Anoman &lt;/BangsaKera&gt; hidup pada
jaman Sri &lt;KerabatAyodya&gt; Rama
&lt;/KerabatAyodya&gt;, membela Sri Ramapada waktu
kehilangan permaisurinya, Dewi &lt;KerabatAyodya&gt;
Sinta &lt;/KerabatAyodya&gt;,yang dicuri oleh raja raksasa
Prabu &lt;KerabatAlengka&gt; Dasamuka
&lt;/KerabatAlengka&gt; dari negara &lt;Kingdom&gt; Alengka
&lt;/Kingdom&gt;.
</construct>
<figureCaption confidence="0.971879">
Figure 4. Tagging result using detailed entities
</figureCaption>
<bodyText confidence="0.887029333333333">
that is the process of eliminating irrelevant
information, so that only valid are used in the
next process. It runs as follows:
</bodyText>
<listItem confidence="0.995861346153846">
1. Discard stopwords and honorifics.
2. If there is a comma and punctuation located
at the beginning of a pattern then the relation
a) &lt;Person&gt; Anoman &lt;/Person&gt; anak &lt;Person&gt; Guru
&lt;/Person&gt;
b) &lt;Person&gt; Anoman &lt;/Person&gt; bernama &lt;Person&gt;
Maruti &lt;/Person&gt;
c) &lt;Person&gt; Anoman &lt;/Person&gt; disebut saudara
&lt;Person&gt; Werkudara &lt;/Person&gt;
d) &lt;Person&gt; Anoman &lt;/Person&gt; bernama &lt;Person&gt;
Ramadayapati &lt;/Person&gt;
e) &lt;Person&gt; Anoman &lt;/Person&gt; bernama &lt;Person&gt;
Bayutanaya &lt;/Person&gt;
f) &lt;Person&gt; Bayutanaya &lt;/Person&gt; berarti diaku anak
&lt;Person&gt; Bayu &lt;/Person&gt;
g) &lt;Person&gt; Anoman &lt;/Person&gt; bernama &lt;Person&gt;
Kapiwara &lt;/Person&gt;
h) &lt;Person&gt; Anoman &lt;/Person&gt; hidup jaman &lt;Person&gt;
Rama &lt;/Person&gt;
i) &lt;Person&gt; Rama &lt;/Person&gt;membela Ramapada
waktu kehilangan permaisurinya &lt;Person&gt; Sinta
&lt;/Person&gt;
j) &lt;Person&gt; Sinta &lt;/Person&gt; dicuri raja raksasa
&lt;Person&gt; Dasamuka &lt;/Person&gt;
k) &lt;Person&gt; Dasamuka &lt;/Person&gt; negara &lt;Kingdom&gt;
Alengka &lt;/Kingdom&gt;
</listItem>
<figureCaption confidence="0.9366355">
Figure 5 The list of patterns as a result of
eliminating irrelevant information
</figureCaption>
<figure confidence="0.305814">
130
</figure>
<listItem confidence="0.9215352">
is considered valid.
3. Discard punctuation and do the trimming.
4. If there is a pattern that is empty or exceeds
5 words, the pattern is considered invalid.
5. Change the pattern to lowercase.
</listItem>
<bodyText confidence="0.9980206875">
The result of the data in Figure 3 after this
process can be seen in Figure 5.
Subsequently, we perform feature extraction
by converting the textual data into matrix form.
This matrix contains the occurrence of candidate
patterns between all possible pairs of entities.
There are two types of feature extraction tried
out in this study, i.e. based on entity pairs and
entity type pairs. The cell in row i and column k
of this feature matrix is the occurrence frequency
of the ith pattern and the kth entity pair. The
matrix form of Figure 5 when using feature
extraction based on entity pairs is depicted in
Figure 6. The next step is to perform relation
clustering using semantic relational similarity as
a similarity measure in a feature domain. The
text patterns contained in each cluster are
deemed to represent the same relationship. The
clustering process will ignore candidate patterns
that occur less than twice in the corpus. The
result of this process is a set of clusters that each
contains textual patterns that have a greater or
equal similarity degree to a given threshold. The
pseudocode of this algorithm is depicted in
Figure 7.
The generated clusters in this process
comprise the relations found in the constructed
ontology. The representative pattern, i.e. the
candidate pattern that has the highest occurrence
frequency within a cluster, will be used as a
property that describes the relationship
represented by a cluster. Suppose there is a
</bodyText>
<figureCaption confidence="0.960244">
Figure 6. The matrix form of Figure 5
</figureCaption>
<figure confidence="0.674779">
Relation Clustering Algorithm
</figure>
<figureCaption confidence="0.999023">
Figure 7. Relation Clustering Pseudocode
</figureCaption>
<bodyText confidence="0.9998853">
cluster that contains three candidate patterns, e.g.
“anak” (child of) with an occurrence frequency
of 40, “putera” (son of) with an occurrence
frequency of 30, and “mendekati” (come near to),
with an occurrence frequency of 3. By using the
representative pattern “anak” as a property, it is
assigned as the relation between pairs of entities
found within this cluster. The illustration of the
constructed ontology after clustering is depicted
in Figure 8.
</bodyText>
<figureCaption confidence="0.936172">
Figure 8. The illustration of constructed
ontology subsequent to relation clustering
</figureCaption>
<figure confidence="0.702911772727273">
Input : pattern P = {p1, p2, .., pn}, threshold 0
Output: cluster C
SORT (P)
C F{}
for pattern pi c P do
max F -co
c* F null
for cluster cj c C do
sim F cosine (pi,cj)
if sim &gt; max then
max F sim
c* F c* cj
end if
end for
if max &gt; 0 then
c* F c* pi
else
C F CUO+
end if
end for
return C
131
</figure>
<subsectionHeader confidence="0.557003">
2.2 Evaluation
2.2.1 Reference Ontology
</subsectionHeader>
<bodyText confidence="0.999902444444444">
To measure and ensure that the quality of the
constructed ontology is in accordance with what
is desired, we evaluate the constructed ontology
against a reference ontology. The reference
ontology acts like a “label” on the testing data in
machine learning. The testing data label used in
the evaluation process is used to determine how
accurate and reliable the model established by
machine learning is in recognizing unseen data.
The evaluation process is performed by
comparing the relations in the constructed
ontology with the labeled testing data. As well as
the data labels in machine learning, the reference
ontology will be used to test how accurate the
system is able to generate ontology from free text.
We define several ontology components that
can be obtained from the knowledge of a
particular topic. This knowledge is obtained by
looking at the types of entities and relations
among them. It can also be obtained by looking
at the group/category of any entity in the text.
Each group/category defines the entity
relationship that will occur between one entity to
another one.
The ontology components which are defined
in the reference ontology are concept and
property. An illustration of the relationship
between concept and property can be seen in
Figures 9 and 10. A concept is something that is
described in the ontology and it can be one of:
objects, category or class. Concepts in the
reference ontology are entities that are
incorporated within the gazetteer categories i.e.
puppet character, spell, weapons, and nations.
The ontology property describes the
relationship between one concept to another. By
</bodyText>
<figureCaption confidence="0.99365375">
Figure 9. The relation between concept and
property in ontology
Figure 10. The example of concept and
property relation
</figureCaption>
<bodyText confidence="0.999979578947369">
observing the entity and relationship between
them we can obtain the potential properties. For
example, there are several entity groups, e.g.
puppet character, kingdoms, weapons, and spell.
Between each group there is the relationship that
may occur. This relationship may occur between
entities within the group/category or among
entities contained in different group/categories.
In this reference ontology, the authors define
certain properties that potentially appear in the
text. There are 14 properties which consist of 11
properties describing the relationship between
person and person, 1 property describing the
relationship between person and country, 1
property describing the relationship between
person and weapon, and 1 property describing
the relationship between person and spell. The
relationship between concepts in the reference
ontology is depicted in Figure 11.
</bodyText>
<subsubsectionHeader confidence="0.668404">
2.2.2 Evaluation method
</subsubsectionHeader>
<bodyText confidence="0.999897363636363">
After relation clustering, each cluster is grouped
based on the reference ontology property. This
grouping is performed based on the synonym of
the representative pattern on particular cluster
and the property of reference ontology. If the
representative pattern does not match (i.e. does
not contain a synonym) with the ontology
reference property then it is ignored.
In this research we use three evaluation
methods i.e. cluster purity, instances of
knowledge, and relations concept.
</bodyText>
<figure confidence="0.940501">
1. Cluster Purity (CP)
Cluster purity (CP) is the ratio between the
</figure>
<figureCaption confidence="0.9791795">
Figure 11. The relationship amongst
concept in a reference ontology
</figureCaption>
<page confidence="0.669906">
132
</page>
<bodyText confidence="0.988426625">
Based on that query, 3 instances are valid (1st,
2nd, 4th) and the rest is invalid. Thus, the IK value
is3,
number of representative patterns and the
number of all patterns in a cluster. Cluster Purity
(CP) calculation ignores singleton clusters, i.e.
when there is only one pattern in a cluster. It can
be formulated as seen below:
</bodyText>
<equation confidence="0.697436">
3. Relation Concept (RC)
CP =
</equation>
<bodyText confidence="0.91671925">
where 52 (521, 522, ..., 52j) is the set of
representative patterns for each cluster and I is
the number of patterns in a set of clusters.
Each cluster contains textual patterns and its
occurrence frequency. For example, the result of
relation clustering can be seen below.
Cluster 1 anak 32
putra 12
Cluster 2 raja 3
Cluster 3 negara 24
menangis 3
The CP value of that relation clustering is
</bodyText>
<equation confidence="0.882816">
  j
</equation>
<sectionHeader confidence="0.918944" genericHeader="method">
2. Instances Knowledge (IK)
</sectionHeader>
<bodyText confidence="0.9998528">
Instances Knowledge (IK) evaluation is intended
to measure the information degree on each
property. There is the possibility that the
relationship among two entities is valid but the
knowledge therein is not as expected. This
evaluation is performed by conducting queries of
multiple instance samples. The queries are
instance samples that have valid knowledge and
are taken randomly from the corpus for each
property. It can be formulated as seen below:
</bodyText>
<equation confidence="0.989790666666667">
IK (Propi) = Avg1Q .
I 1PLopi
1
</equation>
<bodyText confidence="0.999449368421053">
where Propi is the ith property, j is a query for the
ith property, and I is the number of queries for
the ith property.
For example, there are 6 instances for
property anak (child of). The instances are
Kakrasana putra Basudewa , Werkudara putra
Pandu., Kakrasana anak Baladewa, Rupakenca
putra Palasara, Basukesti negara Wirata, and
Dandunwacana negara Jodipati.
Then there are 5 queries for this property i.e.
Kakrasana putra Basudewa, Werkudara anak
Pandu, Arjuna putra Pandu, Rupakenca putra
Palasara, and Aswatama anak Durna.
Relation Concept is a measure to examine the
valid relations in each property. A valid relation
is an instance that has an appropriate relationship
with the defined property in the reference
ontology. This evaluation can be formulated
below:
</bodyText>
<equation confidence="0.769867">
(RC (Propi) =
</equation>
<bodyText confidence="0.880946">
where Propi is the ith property , is
</bodyText>
<note confidence="0.410053">
J
</note>
<bodyText confidence="0.998189416666667">
the valid instances of the ith property, and I is
the number of pattern.
For example, there are 6 instances for
property anak (child of). The instances are
Kakrasana putra Basudewa ,Werkudara putra
Pandu, Kakrasana anak Baladewa, Rupakenca
putra Palasara, Basukesti negara Wirata and
Dandunwacana negara Jodipati.
There are 4 instances (1st-4th) that are
appropriate and 2 instance (5th-6th) that are not
appropriate to property anak (child of). So that,
the RC value is4
</bodyText>
<sectionHeader confidence="0.878445" genericHeader="method">
3 Experimental Data and Setup
</sectionHeader>
<bodyText confidence="0.999956736842106">
In this research we obtain our raw web data from
two separate sources: ki-demang.com and
Wikipedia. Ki-demang.com is a website that
contains various Javanese culture such as
wayang, gamelan (Javanese orchestra), Javanese
songs, Javanese calendar and Javanese literature.
Meanwhile Wikipedia is the largest online
encyclopedia, it provides a summary of
Ramayana and Mahabharata characters.
In this study, we will only use corpora in the
Indonesian language, and use 3 types of corpora,
namely ki-demang corpus (derived from ki-
demang.com), Wikipedia corpus (derived from
id.wikipedia.org) and consolidated corpus
(combination of ki-demang and Wikipedia
corpus).
Ki-demang corpus is containing wayang
character annotations according to Javanese
cultural community. The ki-demang corpus
</bodyText>
<page confidence="0.887626">
133
</page>
<bodyText confidence="0.999971333333333">
writing and spelling is not as good as the
Wikipedia corpus. Punctuation and spelling
errors frequently occur, as well as fairly complex
sentence structures. This corpus consists of 363
wayang characters; where there are 187 puppet
characters that have annotations and 176 puppet
characters that do not have annotations.
The Wikipedia corpus has substances of
wayang character annotation from the
Mahabaratha and the Ramayana book and it also
contains the description of particular characters
in Indonesian culture. The Wikipedia corpus
consists of 180 puppet characters, which all have
their respective annotations.
The last corpus is a combination of ki-demang
and Wikipedia corpus. Merging data from both
corpora is expected to enrich the annotation of
wayang characters. Combining these data led to
two perspectives in wayang character annotation,
which is based on Mahabaratha/Ramayana book
and based on the Javanese culture community.
In this study, we will perform some
experiments to examine the influence of various
parameters. The parameters include the
corpus data variety, the threshold value in the
clustering process, and the usage of entity pair or
entity type pair during feature extraction.
</bodyText>
<sectionHeader confidence="0.993453" genericHeader="evaluation">
4 Result and Analysis
</sectionHeader>
<bodyText confidence="0.999765975609756">
We conduct experiments for various parameters.
The constructed ontology is evaluated using
cluster purity (CP), instances knowledge (IK),
and relation concept (RC). The experiment
results and details of various parameters can be
seen in Figures 12 and 13.
For the first experiment we want to evaluate
the corpus variation. The objective of this
experiment is to find the most representative
corpus used in ontology construction. Based on
the experiment, when the system is employing
entity type pairs in feature extraction, ki-demang
corpus has a high CP (76.54%) rate and a lower
IK (11.49%) and RC (44.8%) rate. When the CP
rate is high, it means that the pattern variation in
particular cluster is modest and tends to be a
singleton (only one pattern in a cluster). It is the
impact of the information homogeneity of ki-
demang corpus compared to the other corpora.
The IK and RC rate of Wikipedia corpus and
consolidated corpus is better than ki-demang
corpus. The Wikipedia corpus has better
information content compared to the ki-demang
corpus, thus the consolidated corpus has a better
RC and IK rate compared to individual corpora.
Meanwhile, when the system employs entity
pairs during feature extraction stage, the the
consolidated corpus has a fairly better result
compare to single corpus. It means that the
consolidated corpus has richer information than
ki-demang or Wikipedia corpus.
The second experiment was conducted to
evaluate the threshold value in clustering process.
The objective of this experiment is to find the
best threshold value for relation clustering. For
further analysis in a corpus variation, we used
the average value of cluster purity (CP),
instances knowledge (IK) and relation concept
(RC) for all corpora. When the system employs
entity type pairs during feature extraction, the CP
rate is 97.15%, IK rate is 49.43%, and RC rate is
</bodyText>
<table confidence="0.963606461538462">
Threshold 1 0.75 0.5 0.25
Corpus
CP IK RC CP IK RC CP IK RC CP IK RC
Ki-demang 96.53 19.54 63.95 96.52 19.54 63.95 95.88 19.54 62.02 94.27 12.64 58.83
Wikipedia 99.38 79.31 75.60 98.66 79.31 76.24 88.71 75.86 67.14 65.31 75.86 61.10
Consolidated 98.50 93.10 80.08 62.29 91.95 79.82 53.95 91.95 75.61 46.94 88.51 71.41
Figure 12. The evaluation result of entity pair usage in feature extraction
Threshold 1 0.75 0.5 0.25
Corpus
CP IK RC CP IK RC CP IK RC CP IK RC
Ki-demang 96.30 14.94 60.02 95.80 14.94 58.45 58.74 13.79 50.05 55.34 2.30 10.70
Wikipedia 97.57 55.17 61.62 83.02 17.24 42.43 27.92 10.34 16.61 12.29 5.75 10.86
Consolidated 97.58 78.16 71.60 42.74 57.47 63.49 59.01 12.64 8.97 44.24 14.94 21.05
</table>
<figureCaption confidence="0.965213">
Figure 3. The evaluation result of entity pair type usage in feature extraction
</figureCaption>
<page confidence="0.727034">
134
</page>
<bodyText confidence="0.999605">
64.41% for threshold value is 1. This result is
always higher than using other threshold value.
Hereafter, when the system employs entity
pairs during feature extraction, the CP rate is
98.14%, the IK rate is 49.43%, and RC rate is
64.41% for threshold value is 1. Given the
experiment result, it is clear that a threshold
value of 1 always gives a better result than the
other threshold values. The higher pattern
similarity in a cluster will yield a better
constructed ontology result.
The last experiment was conducted to
evaluate the consequence of using entity pairs or
entity type pairs during feature extraction to the
constructed ontology. For further analysis in a
feature extraction variation, we used the average
value of cluster purity (CP), instances knowledge
(IK) and relation concept (RC) for all threshold
value in a clustering process.. Based on the
experiment result above, the usage of entity pairs
in feature extraction always brings a better result
than the entity type pairs. When using entity type
pairs in feature extraction, it will reduce some
detail of extracted feature. The feature only
describes the relationship of entity type, not the
entity itself. This leads to suboptimally
constructed ontologies.
</bodyText>
<sectionHeader confidence="0.997699" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999997933333333">
This paper presented a model for automatic
ontology construction from free text. Firstly,
relation extraction is used to retrieve the
candidate patterns. Furthermore, relation
clustering is used to group relations that have the
same semantic tendency. An experiment has
been carried out on various parameters such as
on the corpus variety, the threshold value in
relation clustering process, the usage of simple
process for eliminating irrelevant information
and the usage of entity pairs or entity type pairs
during feature extraction.
Based on the experimental result, the
consolidated corpus (combination of ki-demang
and Wikipedia corpus) is most beneficial in
ontology construction. By integrating the corpus,
it will increase the information quality which
yields a better result. Meanwhile for the other
parameters, the most beneficial result is obtained
when using 1 as a threshold value in clustering
process, and using entity pairs during feature
extraction. The higher pattern similarity in a
cluster will yield a better resulting ontology.
Furthermore, simple processing is employed to
remove some punctuation, stopwords and
honorifics which are a source of noise in the
extracted patterns. The usage of entity type pairs
during feature extraction will result in reduced or
lost detail of pattern features and bring a
detrimental consequence to the ontology result.
</bodyText>
<sectionHeader confidence="0.996464" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999647125">
Agichtein, Eugene, &amp; Gravano, Luis. 2000. Snowball:
Extracting relations from large plain-text
collections. Proceedings of the Fifth ACM
International Conference on Digital Libraries,
Alani, Harith, Kim, Sanghee, Millard, David. E.,
Weal, Mark J., Hall, Wendy, Lewis, Paul. H. and
Shadbolt, Nigel. R. 2003. Automatic Ontology-
Based Knowledge Extraction from Web
Documents. IEEE Intelligent Systems, 18 (1). pp.
14-21,.
Amrih, Pitoyo. Galeri Wayang Pitoyo.com.
http://www.pitoyo.com/duniawayang/galery/index.
php (accessed at November 4th, 2011)
Banko, Michele, Michael J. Cafarella, Stephen
Soderland,Matt Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web.
InIJCAI’07: Proceedings of the 20th international
joint conference on Artifical intelligence, pages
2670–2676.
Brin, Sergey. 1998 . Extracting patterns and relations
from the world wide web. WebDB Workshop at
6th International Conference on Extending
Database Technology, EDBT
Bunescu, Razvan. C., &amp; Mooney, Raymond. J. 2005.
A shortest path dependency kernel for relation
extraction. HLT ’05: Proceedings of the conference
on Human LanguageTechnology and Empirical
Methods in Natural Language Processing (pp. 724–
731). Vancouver, British Columbia, Canada:
Association for Computational Linguistics
Celjuska, David and Vargas-Vera, Maria. 2004.
Ontosophie: A Semi-Automatic System for
Ontology Population from Text. In Proceedings
International Conference on Natural Language
Processing ICON., Hyderabad, India
Culotta, Aron, McCallum, Andrew, &amp; Betz, Jonathan.
2006. Integrating probabilistic extraction models
and data mining to discover relations and patterns
in text. Proceedings of the main conference on
Human Language Technology Conference of the
</reference>
<page confidence="0.619594">
135
</page>
<reference confidence="0.999774038461538">
North American Chapter of the Association of
Computational Linguistics (pp. 296–303). New
York, New York: Association for Computational
Linguistics.
Etzioni, Oren, Cafarella, Michael, Downey, Doug,
Popescu, Anna-Mariana, Shaked, Tal, Soderland,
Stephen, Weld, Daniel S., &amp; Yates, Alexander.
2005. Unsupervised Named-Entity Extraction from
the Web: An Experimental Study. Artificial
Intelligence (pp. 191–134).
Kambhatla, Nanda. 2004. Combining lexical,
syntactic, and semantic features with maximum
entropy models for extracting relations.
Proceedings of the ACL
Shamsfard Mehrnoush , Barforoush Ahmad
Abdollahzadeh. 2004. Learning Ontologies from
Natural Language Texts, International Journal of
Human- Computer Studies, No. 60, pp. 17-63,
Zelenko, Dmitry, Aone, Chinatsu, &amp; Richardella,
Anthony. Kernel methods for relation extraction.
Journal of Machine Learning Research, 2003 .
Zhao, Shubin, &amp; Grishman, Ralph. Extracting
relations with integrated information using kernel
methods. Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics (pp.
419–426, 2005
</reference>
<page confidence="0.946871">
136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.637815">
<title confidence="0.9861895">Towards Automatic Wayang Ontology Construction Relation Extraction from Free Text</title>
<author confidence="0.719553">Hadaiq Rolis Sanabila Ruli Manurung</author>
<affiliation confidence="0.9910865">Faculty of Computer Science Faculty of Computer Science Universitas Indonesia Universitas Indonesia</affiliation>
<abstract confidence="0.996251826086957">This paper reports on our work to automatically construct and populate an of shadow puppet) mythology from free text using relation extraction and relation clustering. A reference ontology is used to evaluate the generated ontology. The reference ontology contains concepts and properties within the domain. We examined the influence of corpus data variations, threshold value variations in the relation clustering process, and the usage of entity pairs or entity pair types during the feature extraction stages. The constructed ontology is examined using three evaluation methods, i.e. cluster purity (CP), instance knowledge (IK), and relation concept (RC). Based on the evaluation results, the proposed method generates the best ontology when using a consolidated corpus, the threshold value in relation clustering is 1, and entity pairs are used during feature extraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: Extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>Proceedings of the Fifth ACM International Conference on Digital Libraries,</booktitle>
<contexts>
<context position="3240" citStr="Agichtein and Gravano, 2000" startWordPosition="480" endWordPosition="483">ber of words between two entities, and the number of entities between two entities. In addition, there are several studies that use kernel-based approach. The kernel K(x, y) defines the similarity between objects x and y in the high-dimensional objects. There are various elements used to construct kernels such as word subsequence (Bunescu and Mooney, 2005) and parse trees (Zelenko et al., 2003; Culotta et al., 2004). In addition, several studies use semisupervised learning. DIPRE (Brin, 1998) tries to find the relationship between the author interest and the book he/she had written. Snowball (Agichtein and Gravano, 2000) uses an architecture that is not very different from DIPRE to determine the relationship between an organization and its location. Meanwhile, Knowitall (Etzioni at al., 2005) examines relation extraction in heterogeneous domains of text data 128 Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 128–136, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics from the web automatically. Finally TextRunner (Banko at al., 2007) is a system that automatically searches the relationsh</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Agichtein, Eugene, &amp; Gravano, Luis. 2000. Snowball: Extracting relations from large plain-text collections. Proceedings of the Fifth ACM International Conference on Digital Libraries,</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Weal</author>
<author>J Mark</author>
<author>Wendy Hall</author>
<author>Paul H Lewis</author>
<author>Nigel R Shadbolt</author>
</authors>
<title>Automatic OntologyBased Knowledge Extraction from Web Documents.</title>
<date>2003</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>18</volume>
<issue>1</issue>
<pages>14--21</pages>
<marker>Weal, Mark, Hall, Lewis, Shadbolt, 2003</marker>
<rawString>Alani, Harith, Kim, Sanghee, Millard, David. E., Weal, Mark J., Hall, Wendy, Lewis, Paul. H. and Shadbolt, Nigel. R. 2003. Automatic OntologyBased Knowledge Extraction from Web Documents. IEEE Intelligent Systems, 18 (1). pp. 14-21,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pitoyo Amrih</author>
</authors>
<title>Galeri Wayang Pitoyo.com. http://www.pitoyo.com/duniawayang/galery/index. php (accessed at</title>
<date>2011</date>
<contexts>
<context position="8484" citStr="Amrih, 2011" startWordPosition="1236" endWordPosition="1237">ksasa Prabu &lt;Person&gt; Dasamuka &lt;/Person&gt; dari negara &lt;Kingdom&gt; Alengka &lt;/ Kingdom &gt; Figure 3. Tagging result using non-detailed entities The raw data is free text that consists of several paragraphs describing short biographies of wayang characters. Firstly, the free text is tagged using gazetteer data, i.e. a list of entities contained in the text. Every word contained in the gazetteer will be tagged in accordance to its entity type. The number of entities in the gazetteer is still general. Thus, the entities are subdivided into more specific groups. The entity group is based on Pitoyo Amrih (Amrih, 2011) which consists of 29 groups. In this study we used two tagging methods, i.e. by using a wayang entity that has not been detailed and by using detailed entities (based on the type of wayang entity). Different tagging treatment was conducted to examine whether this affects the ontology result or not. The example of tagged text using wayang entity that has not been detailed and detailed entities can be seen in Figures 3 and 4. Subsequently, pronoun resolution is employed to resolve the entity reference of a pronoun. The system will then perform relation extraction by analyzing the words occurrin</context>
</contexts>
<marker>Amrih, 2011</marker>
<rawString>Amrih, Pitoyo. Galeri Wayang Pitoyo.com. http://www.pitoyo.com/duniawayang/galery/index. php (accessed at November 4th, 2011)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open information extraction from the web. InIJCAI’07: Proceedings of the 20th international joint conference on Artifical intelligence,</booktitle>
<pages>2670--2676</pages>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Banko, Michele, Michael J. Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. InIJCAI’07: Proceedings of the 20th international joint conference on Artifical intelligence, pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
</authors>
<title>Extracting patterns and relations from the world wide web.</title>
<date>1998</date>
<booktitle>WebDB Workshop at 6th International Conference on Extending Database Technology, EDBT</booktitle>
<contexts>
<context position="3109" citStr="Brin, 1998" startWordPosition="462" endWordPosition="463">hman, 2005). Some features that are generally used are words that lie among the entities, the entity type, the number of words between two entities, and the number of entities between two entities. In addition, there are several studies that use kernel-based approach. The kernel K(x, y) defines the similarity between objects x and y in the high-dimensional objects. There are various elements used to construct kernels such as word subsequence (Bunescu and Mooney, 2005) and parse trees (Zelenko et al., 2003; Culotta et al., 2004). In addition, several studies use semisupervised learning. DIPRE (Brin, 1998) tries to find the relationship between the author interest and the book he/she had written. Snowball (Agichtein and Gravano, 2000) uses an architecture that is not very different from DIPRE to determine the relationship between an organization and its location. Meanwhile, Knowitall (Etzioni at al., 2005) examines relation extraction in heterogeneous domains of text data 128 Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 128–136, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Lin</context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>Brin, Sergey. 1998 . Extracting patterns and relations from the world wide web. WebDB Workshop at 6th International Conference on Extending Database Technology, EDBT</rawString>
</citation>
<citation valid="true">
<authors>
<author>C</author>
<author>Raymond J Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>HLT ’05: Proceedings of the conference on Human LanguageTechnology and Empirical Methods in Natural Language Processing</booktitle>
<pages>724--731</pages>
<publisher>Association for Computational Linguistics</publisher>
<location>Vancouver, British Columbia, Canada:</location>
<marker>C, Mooney, 2005</marker>
<rawString>Bunescu, Razvan. C., &amp; Mooney, Raymond. J. 2005. A shortest path dependency kernel for relation extraction. HLT ’05: Proceedings of the conference on Human LanguageTechnology and Empirical Methods in Natural Language Processing (pp. 724– 731). Vancouver, British Columbia, Canada: Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Celjuska</author>
<author>Maria Vargas-Vera</author>
</authors>
<title>Ontosophie: A Semi-Automatic System for Ontology Population from Text.</title>
<date>2004</date>
<booktitle>In Proceedings International Conference on Natural Language Processing ICON.,</booktitle>
<location>Hyderabad, India</location>
<marker>Celjuska, Vargas-Vera, 2004</marker>
<rawString>Celjuska, David and Vargas-Vera, Maria. 2004. Ontosophie: A Semi-Automatic System for Ontology Population from Text. In Proceedings International Conference on Natural Language Processing ICON., Hyderabad, India</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
<author>Jonathan Betz</author>
</authors>
<title>Integrating probabilistic extraction models and data mining to discover relations and patterns in text.</title>
<date>2006</date>
<booktitle>Proceedings of the main conference on Human Language Technology Conference of the</booktitle>
<marker>Culotta, McCallum, Betz, 2006</marker>
<rawString>Culotta, Aron, McCallum, Andrew, &amp; Betz, Jonathan. 2006. Integrating probabilistic extraction models and data mining to discover relations and patterns in text. Proceedings of the main conference on Human Language Technology Conference of the</rawString>
</citation>
<citation valid="false">
<authors>
<author>North American</author>
</authors>
<title>Chapter of the Association of Computational Linguistics</title>
<pages>296--303</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York, New York:</location>
<marker>American, </marker>
<rawString>North American Chapter of the Association of Computational Linguistics (pp. 296–303). New York, New York: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>Anna-Mariana Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised Named-Entity Extraction from the Web: An Experimental Study.</title>
<date>2005</date>
<journal>Artificial Intelligence</journal>
<pages>191--134</pages>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Etzioni, Oren, Cafarella, Michael, Downey, Doug, Popescu, Anna-Mariana, Shaked, Tal, Soderland, Stephen, Weld, Daniel S., &amp; Yates, Alexander. 2005. Unsupervised Named-Entity Extraction from the Web: An Experimental Study. Artificial Intelligence (pp. 191–134).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nanda Kambhatla</author>
</authors>
<title>Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations.</title>
<date>2004</date>
<booktitle>Proceedings of the ACL</booktitle>
<contexts>
<context position="2483" citStr="Kambhatla, 2004" startWordPosition="363" endWordPosition="364"> known only by the puppeteer cannot be shared to others, which leads to the loss of cultural richness. The knowledge held by the puppeteer ought to be propagated to future generations in order to be learned and developed. Information about the shadow puppets can be represented as textual data describing hundreds of characters. Constructing an ontology manually from such a large data source is time consuming and labor intensive. Work on relation extraction has already been conducted in the past. Initially, supervised learning approaches were used, for example feature-based supervised learning (Kambhatla, 2004; Zhao and Grishman, 2005). Some features that are generally used are words that lie among the entities, the entity type, the number of words between two entities, and the number of entities between two entities. In addition, there are several studies that use kernel-based approach. The kernel K(x, y) defines the similarity between objects x and y in the high-dimensional objects. There are various elements used to construct kernels such as word subsequence (Bunescu and Mooney, 2005) and parse trees (Zelenko et al., 2003; Culotta et al., 2004). In addition, several studies use semisupervised le</context>
</contexts>
<marker>Kambhatla, 2004</marker>
<rawString>Kambhatla, Nanda. 2004. Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations. Proceedings of the ACL</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barforoush Ahmad Abdollahzadeh</author>
</authors>
<title>Learning Ontologies from Natural Language Texts,</title>
<date>2004</date>
<journal>International Journal of Human- Computer Studies,</journal>
<volume>60</volume>
<pages>17--63</pages>
<marker>Abdollahzadeh, 2004</marker>
<rawString>Shamsfard Mehrnoush , Barforoush Ahmad Abdollahzadeh. 2004. Learning Ontologies from Natural Language Texts, International Journal of Human- Computer Studies, No. 60, pp. 17-63,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
<author>Anthony Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>.</pages>
<contexts>
<context position="3008" citStr="Zelenko et al., 2003" startWordPosition="445" endWordPosition="448">d learning approaches were used, for example feature-based supervised learning (Kambhatla, 2004; Zhao and Grishman, 2005). Some features that are generally used are words that lie among the entities, the entity type, the number of words between two entities, and the number of entities between two entities. In addition, there are several studies that use kernel-based approach. The kernel K(x, y) defines the similarity between objects x and y in the high-dimensional objects. There are various elements used to construct kernels such as word subsequence (Bunescu and Mooney, 2005) and parse trees (Zelenko et al., 2003; Culotta et al., 2004). In addition, several studies use semisupervised learning. DIPRE (Brin, 1998) tries to find the relationship between the author interest and the book he/she had written. Snowball (Agichtein and Gravano, 2000) uses an architecture that is not very different from DIPRE to determine the relationship between an organization and its location. Meanwhile, Knowitall (Etzioni at al., 2005) examines relation extraction in heterogeneous domains of text data 128 Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ </context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2003</marker>
<rawString>Zelenko, Dmitry, Aone, Chinatsu, &amp; Richardella, Anthony. Kernel methods for relation extraction. Journal of Machine Learning Research, 2003 .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shubin Zhao</author>
<author>Ralph Grishman</author>
</authors>
<title>Extracting relations with integrated information using kernel methods.</title>
<date>2005</date>
<booktitle>Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</booktitle>
<pages>419--426</pages>
<contexts>
<context position="2509" citStr="Zhao and Grishman, 2005" startWordPosition="365" endWordPosition="368">e puppeteer cannot be shared to others, which leads to the loss of cultural richness. The knowledge held by the puppeteer ought to be propagated to future generations in order to be learned and developed. Information about the shadow puppets can be represented as textual data describing hundreds of characters. Constructing an ontology manually from such a large data source is time consuming and labor intensive. Work on relation extraction has already been conducted in the past. Initially, supervised learning approaches were used, for example feature-based supervised learning (Kambhatla, 2004; Zhao and Grishman, 2005). Some features that are generally used are words that lie among the entities, the entity type, the number of words between two entities, and the number of entities between two entities. In addition, there are several studies that use kernel-based approach. The kernel K(x, y) defines the similarity between objects x and y in the high-dimensional objects. There are various elements used to construct kernels such as word subsequence (Bunescu and Mooney, 2005) and parse trees (Zelenko et al., 2003; Culotta et al., 2004). In addition, several studies use semisupervised learning. DIPRE (Brin, 1998)</context>
</contexts>
<marker>Zhao, Grishman, 2005</marker>
<rawString>Zhao, Shubin, &amp; Grishman, Ralph. Extracting relations with integrated information using kernel methods. Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (pp. 419–426, 2005</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>