<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006677">
<title confidence="0.996903">
A cognitive study of subjectivity extraction in sentiment annotation
</title>
<author confidence="0.99395">
Abhijit Mishra1 Aditya Joshi1,2,3 Pushpak Bhattacharyya1
</author>
<affiliation confidence="0.946033333333333">
1IIT Bombay, India
2Monash University, Australia
3IITB-Monash Research Academy, India
</affiliation>
<email confidence="0.995666">
{abhijitmishra, adityaj, pb}@cse.iitb.ac.in
</email>
<sectionHeader confidence="0.993891" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999886285714286">
Existing sentiment analysers are weak AI
systems: they try to capture the function-
ality of human sentiment detection faculty,
without worrying about how such faculty
is realized in the hardware of the human.
These analysers are agnostic of the actual
cognitive processes involved. This, how-
ever, does not deliver when applications
demand order of magnitude facelift in ac-
curacy, as well as insight into characteris-
tics of sentiment detection process.
In this paper, we present a cognitive study
of sentiment detection from the perspec-
tive of strong AI. We study the sentiment
detection process of a set of human “sen-
timent readers”. Using eye-tracking, we
show that on the way to sentiment de-
tection, humans first extract subjectivity.
They focus attention on a subset of sen-
tences before arriving at the overall senti-
ment. This they do either through ”antici-
pation” where sentences are skipped dur-
ing the first pass of reading, or through
”homing” where a subset of the sentences
are read over multiple passes, or through
both. ”Homing” behaviour is also ob-
served at the sub-sentence level in com-
plex sentiment phenomena like sarcasm.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995675">
Over the years, supervised approaches using
polarity-annotated datasets have shown promise
for SA (Pang and Lee, 2008). However, an al-
ternate line of thought has co-existed. Pang and
Lee (2004) showed that for SA, instead of a doc-
ument in its entirety, an extract of the subjec-
tive sentences alone can be used. This process
of generating a subjective extract is referred to
as subjectivity extraction. Mukherjee and Bhat-
tacharyya (2012) show that for sentiment predic-
tion of movie reviews, subjectivity extraction may
be used to discard the sentences describing movie
plots since they do not contribute towards the
speaker’s view of the movie.
While subjectivity extraction helps sentiment
classification, the reason has not been sufficiently
examined from the perspective of strong AI. The
classical definition of strong AI suggests that a
machine must be perform sentiment analysis in
a manner and accuracy similar to human beings.
Our paper takes a step in this direction. We study
the cognitive processes underlying sentiment an-
notation using eye-fixation data of the participants.
Our work is novel in two ways:
</bodyText>
<listItem confidence="0.8980115">
• We view documents as a set of sentences
through which sentiment changes. We show
that the nature of these polarity oscillations
leads to changes in the reading behavior.
• To the best of our knowledge, the idea of us-
ing eye-tracking to validate assumptions is
novel in case of sentiment analysis and many
NLP applications.
</listItem>
<sectionHeader confidence="0.9684385" genericHeader="introduction">
2 Sentiment oscillations &amp; subjectivity
extraction
</sectionHeader>
<bodyText confidence="0.999866">
We categorize subjective documents as linear and
oscillating. A linear subjective document is the
one where all or most sentences have the same po-
larity. On the other hand, an oscillating subjective
document contains sentences of contrasting polar-
ity (viz. positive and negative). Our discussions
on two forms of subjectivity extraction use the
concepts of linear and oscillating subjective doc-
uments.
Consider a situation where a human reader
needs to annotate two documents with sentiment.
Assume that the first document is linear subjec-
tive - with ten sentences, all of them positive. In
</bodyText>
<page confidence="0.975051">
142
</page>
<bodyText confidence="0.991778217391304">
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 142–146,
Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics
case of this document, when he/she reads a cou-
ple of sentences with the same polarity, he/she be-
gins to assume that the next sentence will have the
same sentiment and hence, skips through it. We
refer to this behavior as anticipation. Now, let the
second document be an oscillating subjective doc-
ument with ten sentences, the first three positive,
the next four negative and the last three positive.
In this case, when a human annotator reads this
document and sees the sentiment flip early on, the
annotator begins to carefully read the document.
After completing a first pass of reading, the anno-
tator moves back to read certain crucial sentences.
We refer to this behavior as homing.
The following sections describe our observa-
tions in detail. Based on our experiments, we ob-
serve these two kinds of subjectivity extraction in
our participants: subjectivity extraction as a result
of anticipation and subjectivity extraction as a re-
sult of homing - for linear and oscillating docu-
ments respectively.
</bodyText>
<sectionHeader confidence="0.993184" genericHeader="method">
3 Experiment Setup
</sectionHeader>
<bodyText confidence="0.99990475">
This section describes the framework used for our
eye-tracking experiment. A participant is given
the task of annotating documents with one out of
the following labels: positive, negative and ob-
jective. While she reads the document, her eye-
fixations are recorded.
To log eye-fixation data, we use Tobii T120
remote eye-tracker with Translog(Carl, 2012).
Translog is a freeware for recording eye move-
ments and keystrokes during translation. We con-
figure Translog for reading with the goal of senti-
ment.
</bodyText>
<subsectionHeader confidence="0.999579">
3.1 Document description
</subsectionHeader>
<bodyText confidence="0.9999506">
We choose three movie reviews in English from
IMDB (http://www.imdb.com) and indicate them
as D0, D1 and D2. The lengths of D0, D1 and
D2 are 10, 9 and 13 sentences respectively. Using
the gold-standard rating given by the writer, we
derive the polarity of D0, D1 and D2 as positive,
negative and positive respectively. The three doc-
uments represent three different styles of reviews:
D0 is positive throughout (linear subjective), D1
contains sarcastic statements (linear subjective but
may be perceived as oscillating due to linguistic
difficulty) while D2 consists of many flips in sen-
timent (oscillating subjective).
It may seem that the data set is small and
may not lead to significant findings. However,
we wished to capture the most natural form of
sentiment-oriented reading. A larger data set
would have weakened the experiment because: (i)
Sentiment patterns (linear v/s subjective) begin to
become predictable to a participant if she reads
many documents one after the other. (ii) There
is a possibility that fatigue introduces unexpected
error. To ensure that our observations were signif-
icant despite the limited size of the data set, we
increased the number of our participants to 12.
</bodyText>
<subsectionHeader confidence="0.999849">
3.2 Participant description
</subsectionHeader>
<bodyText confidence="0.999813222222222">
Our participants are 24-30 year-old graduate stu-
dents with English as the primary language of aca-
demic instruction. We represent them as P0, P1
and so on. The polarity for the documents as re-
ported by the participants are shown in Table 1.
All participants correctly identified the polarity of
document D0. Participant P9 reported that D1 is
confusing. 4 out of 12 participants were unable to
detect correct opinion in D2.
</bodyText>
<subsectionHeader confidence="0.995699">
3.3 Experiment Description
</subsectionHeader>
<bodyText confidence="0.996096166666667">
We obtain two kinds of annotation from our an-
notators: (a) sentiment (positive, negative and ob-
jective), (b) eye-movement as recorded by an eye-
tracker. They are given a set of instructions before-
hand and can seek clarifications. This experiment
is conducted as follows:
</bodyText>
<listItem confidence="0.98927975">
1. A complete document is displayed on the
screen. The font size and line separation are
set to 17pt and 1.5 cm respectively to ensure
clear visibility and minimize recording error.
2. The annotator verbally states the sentiment of
this sentence, before (s)he can proceed to the
next.
3. While the annotator is reading the sentence,
a remote eye-tracker (Model: Tobii TX 300,
Sampling rate: 300Hz) records the eye-
movement data of the annotator. The eye-
tracker is linked to Translog II software (Carl,
2012) in order to record the data. A snap-
shot of the software is shown in figure 1. The
dots and circles represent position of eyes and
fixations of the annotator respectively. Each
eye-fixation that is recorded consists of: co-
ordinates, timestamp and duration. These
three parameters have been used to generate
sentence progression graphs.
</listItem>
<page confidence="0.984577">
143
</page>
<table confidence="0.898142">
Document Orig P0 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11
D0 +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve
D1 -ve -ve +ve -ve -ve -ve -ve -ve -ve -ve Neu/-ve -ve -ve
D2 +ve +ve +ve -ve +ve +ve Neu +ve Neu Neu +ve +ve +ve
</table>
<tableCaption confidence="0.976061">
Table 1: Polarity of documents as perceived by the writer (original) and the participants +ve, -ve and
Neu represent positive, negative and neutral polarities respectively.
</tableCaption>
<figureCaption confidence="0.990874333333333">
Figure 1: Gaze-data recording using Translog-II
Figure 2: Sentence progression graph for partici-
pant P7 document D0
</figureCaption>
<sectionHeader confidence="0.9654705" genericHeader="method">
4 Observations: Subjectivity extraction
through anticipation
</sectionHeader>
<bodyText confidence="0.996668285714286">
In this section, we describe a case in which partic-
ipants skip sentences. We show that anticipation
of sentiment is linked with subjectivity extraction.
Table 2 shows the number of unique and non-
unique sentences that participants read for each
document. The numbers in the last column in-
dicate average values. The table can be read as:
participant P1 reads 8 unique sentences of docu-
ment D0 (thus skipping two sentences) and includ-
ing repetitions, reads 26 sentences. Participant P0
skips as many as six sentences in case of document
D1.
The number of unique sentences read is lower
than sentence count for four out of twelve partic-
ipants in case of document D0. This skipping is
negligible in case of document D1 and D2. Also,
the average non-unique sentence fixations are 21
in case of D0 and 33.83 for D1 although the total
number of sentences in D0 and D1 is almost the
same. This verifies that participants tend to skip
sentences while reading D0.
Figure 2 shows sentence progression graph for
participant P7. The participant reads a series of
sentences and then skips two sentences. This im-
plies that anticipation behaviour was triggered af-
ter reading sentences of the same polarity. Sim-
ilar traits are observed in other participants who
skipped sentences while reading document D0.
</bodyText>
<sectionHeader confidence="0.8466635" genericHeader="method">
5 Observations: Subjectivity extraction
through homing
</sectionHeader>
<bodyText confidence="0.999907416666666">
This section presents a contrasting case of sub-
jectivity extraction. We refer to a reading pattern
as homing1 when a participant reads a document
completely and returns to read a selected subset of
sentences. We believe that during sentiment an-
notation, this subset is the subjective extract that
the user has created in her mind. We observe this
phenomenon in reading patterns of documents D1
and D2. The former contains sarcasm because of
which parts of sentences may appear to be of con-
trasting polarity while the latter is an oscillating
subjective document.
</bodyText>
<footnote confidence="0.9916225">
1The word is derived from missile guidance systems. The
definition2 of homing is “the process of determining the lo-
cation of something, sometimes the source of a transmission,
and going to it.”
</footnote>
<page confidence="0.996436">
144
</page>
<figure confidence="0.8776957">
Document P0 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 Avg.
Non-unique 9 26 23 17 18 18 35 16 33 19 15 23 21
D0
Unique 8 8 10 10 10 10 10 8 10 8 10 10
Non-unique 5 23 46 13 15 44 35 26 56 57 40 46 33.83
D1
Unique 3 9 9 9 9 9 8 9 9 9 9 9
Non-unique 36 29 67 21 23 51 64 48 54 59 73 80 50.42
D2
Unique 13 13 13 13 13 13 13 13 13 13 13 13
</figure>
<tableCaption confidence="0.515955">
Table 2: Number of unique and non-unique sentences read by each participant
</tableCaption>
<figureCaption confidence="0.967173333333333">
Figure 3: Sentence progression graph of partici-
pant P2 for document D1 (left) and document D2
(right)
</figureCaption>
<bodyText confidence="0.972242055555556">
Figure 3 shows sentence progression graphs of
participant P2 for documents D1 and D2. For doc-
ument D1, the participant performs one pass of
reading until sequence number 30. A certain sub-
set of sentences are re-visited in the second pass.
On analyzing sentences in the second pass of read-
ing, we observe a considerable overlap in case of
our participants. We also confirm that all of these
sentences are subjective. This means that the sen-
tences that are read after sequence number 30 form
the subjective extract of document D1.
Similar behaviour is observed in case of docu-
ment D2. The difference in this case is that there
is less overlap of sentences read in the second pass
among participants. This implies , for oscillat-
ing subjective documents, the subjective extract is
user/document-specific.
It may be argued that fixations corresponding
</bodyText>
<table confidence="0.999757333333333">
Participant TFD-SE PTFD TFC-SE
(secs) (%)
P5 7.3 8 21
P7 3.1 5 11
P9 51.94 10 26
P11 116.6 16 56
</table>
<tableCaption confidence="0.999049">
Table 3: Reading statistics for second pass reading
</tableCaption>
<bodyText confidence="0.9916094375">
for document D1; TFD: Total fixation duration for
subjective extract; PTFD: Proportion of total fix-
ation duration = (TFD)/(Total duration); TFC-SE:
Total fixation count for subjective extract
to second pass reading are stray fixations and not
subjective extracts. Hence, for the second pass
reading of document D1, we tabulate fixation du-
ration, fixation count and proportion of total dura-
tion in Table 3. The fixation duration and fixation
count are both recorded by the eye-tracker. The
fixation counts are substantial and the participants
spend around 5-15% of the total reading time in
the second pass reading. We also confirm that all
of these sentences are subjective. This means that
these portions indeed correspond to subjective ex-
tracts as a result of homing.
</bodyText>
<sectionHeader confidence="0.853008" genericHeader="method">
6 A note on linguistic challenges
</sectionHeader>
<bodyText confidence="0.999882333333333">
Our claim is that regression after reading an en-
tire document corresponds to the beginning of
a subjective extract. However, we observe that
some regressions may also happen due to senti-
ment changes at the sub-sentence level. Some of
these are as follows.
</bodyText>
<listItem confidence="0.573746">
1. Sarcasm: Sarcasm involves an implicit flip
</listItem>
<bodyText confidence="0.99387">
in the sentiment. Participant P9 does not cor-
rectly predict sentiment of Document D1. On
analyzing her data, we observe multiple re-
gressions on the sentence ‘Add to this mess
some of the cheesiest lines and concepts, and
</bodyText>
<page confidence="0.996649">
145
</page>
<bodyText confidence="0.999422533333334">
there you have it; I would call it a complete
waste of time, but in some sense it is so bad
it is almost worth seeing.’ This sentence has
some positive words but is negative towards
the movie. Hence, the participant reads this
portion back and forth.
2. Thwarted expectations: Thwarted expecta-
tions are expressions with a sentiment rever-
sal within a sentence/snippet. Homing is ob-
served in this case as well. Document D2
has a case of thwarted expectations from sen-
tences 10-12 where there is an unexpected
flip of sentiment. In case of some partici-
pants, we observe regression on these sen-
tences multiple times.
</bodyText>
<sectionHeader confidence="0.999957" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999964214285714">
The work closest to ours is by Scott et al. (2011)
who study the role of emotion words in read-
ing using eye-tracking. They show that the eye-
fixation duration for emotion words is consistently
less than neutral words with the exception of high-
frequency negative words. Eye-tracking3 technol-
ogy has also been used to study the cognitive as-
pects of language processing tasks like translation
and sense disambiguation. Dragsted (2010) ob-
serve co-ordination between reading and writing
during human translation. Similarly, Joshi et al.
(2011) use eye-tracking to correlate fixation dura-
tion with polysemy of words during word sense
disambiguation.
</bodyText>
<sectionHeader confidence="0.987817" genericHeader="conclusions">
8 Conclusion &amp; Future work
</sectionHeader>
<bodyText confidence="0.999464923076923">
We studied sentiment annotation in the context of
subjectivity extraction using eye-tracking. Based
on how sentiment changes through a document,
humans may perform subjectivity extraction as a
result of either: (a) anticipation or (b) homing.
These observations are in tandem with the past
work that shows benefit of subjectivity extraction
for automatic sentiment classification.
Our study is beneficial in three perspectives: (i)
Sentiment classifiers may use interaction between
sentiment of sentences. Specifically, this can be
modeled using features like sentiment run length
(i.e. maximal span of sentences bearing same
</bodyText>
<footnote confidence="0.410881">
3Related Terms:
Eye-fixation: Long stay of visual gaze on a single location
Regression: Revisiting a previously read segment
Sentence Progression Graph: Graph showing reading se-
quence of sentences
</footnote>
<bodyText confidence="0.996347">
sentiment) or sentiment flips (i.e. instances where
consecutive sentences bear opposite polarity),
(ii) Crowd-sourced sentiment annotation can
devise variable pricing models based on our study.
Based on anticipation and homing information
about documents, documents can be grouped into
difficulty categories and priced accordingly.
</bodyText>
<sectionHeader confidence="0.96431" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.94525325">
We thank Tobii Corporation for lending us their
eye-tracker for this study, and our annotators from
CFILT, IIT Bombay. Aditya is funded by the TCS
Research Fellowship Program.
</bodyText>
<sectionHeader confidence="0.996191" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998469366666667">
Bo Pang and Lillian Lee. 2004. A Sentimental Educa-
tion: Sentiment Analysis Using Subjectivity Sum-
marization Based on Minimum Cuts In Proceedings
of the ACL, 271-278.
Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis Foundations and Trends in In-
formation Retrieval, 2008, vol. 2, nos.12 1135.
B Dragsted. 2010. Co-ordination of reading and writ-
ing processes in translation. Contribution to Trans-
lation and Cognition. Shreve, G. and Angelone,
E.(eds.)Cognitive Science Society.
Michael Carl. 2012. Translog-II: A Program for
Recording UserActivity Data forEmpirical Reading
and Writing Research. In Proceedings of the Eight
International Conference on Language Resources
and Evaluation, European Language Resources As-
sociation.
Scott G. , ODonnell P and Sereno S. 2012. Emotion
Words Affect Eye Fixations During Reading. Jour-
nal of Experimental Psychology:Learning, Memory,
and Cognition 2012, Vol. 38, No. 3, 783792.
Salil Joshi, Diptesh Kanojia and Pushpak Bhat-
tacharyya. 2013. More than meets the eye: Study
of Human Cognition in Sense Annotation. NAACL
HLT 2013, Atlanta, USA.
Subhabrata Mukherjee and Pushpak Bhattacharyya.
2012. WikiSent : Weakly Supervised Senti-
ment Analysis Through Extractive Summarization
With Wikipedia European Conference on Machine
Learning (ECML PKDD 2012), Bristol, U.K.,
</reference>
<page confidence="0.998547">
146
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.760903">
<title confidence="0.999242">A cognitive study of subjectivity extraction in sentiment annotation</title>
<author confidence="0.989976">Aditya Pushpak</author>
<affiliation confidence="0.954668333333333">Bombay, University, Research Academy,</affiliation>
<email confidence="0.896943">adityaj,</email>
<abstract confidence="0.998959482758621">Existing sentiment analysers are weak AI they try to capture the functionhuman sentiment detection faculty, without worrying about how such faculty realized in the the human. These analysers are agnostic of the actual cognitive processes involved. This, however, does not deliver when applications demand order of magnitude facelift in accuracy, as well as insight into characteristics of sentiment detection process. In this paper, we present a cognitive study of sentiment detection from the perspective of strong AI. We study the sentiment detection process of a set of human “sentiment readers”. Using eye-tracking, we show that on the way to sentiment detection, humans first extract subjectivity. They focus attention on a subset of sentences before arriving at the overall sentiment. This they do either through ”anticipation” where sentences are skipped during the first pass of reading, or through ”homing” where a subset of the sentences are read over multiple passes, or through both. ”Homing” behaviour is also observed at the sub-sentence level in complex sentiment phenomena like sarcasm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>271--278</pages>
<contexts>
<context position="1609" citStr="Pang and Lee (2004)" startWordPosition="243" endWordPosition="246">jectivity. They focus attention on a subset of sentences before arriving at the overall sentiment. This they do either through ”anticipation” where sentences are skipped during the first pass of reading, or through ”homing” where a subset of the sentences are read over multiple passes, or through both. ”Homing” behaviour is also observed at the sub-sentence level in complex sentiment phenomena like sarcasm. 1 Introduction Over the years, supervised approaches using polarity-annotated datasets have shown promise for SA (Pang and Lee, 2008). However, an alternate line of thought has co-existed. Pang and Lee (2004) showed that for SA, instead of a document in its entirety, an extract of the subjective sentences alone can be used. This process of generating a subjective extract is referred to as subjectivity extraction. Mukherjee and Bhattacharyya (2012) show that for sentiment prediction of movie reviews, subjectivity extraction may be used to discard the sentences describing movie plots since they do not contribute towards the speaker’s view of the movie. While subjectivity extraction helps sentiment classification, the reason has not been sufficiently examined from the perspective of strong AI. The cl</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts In Proceedings of the ACL, 271-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis Foundations and Trends in Information Retrieval,</title>
<date>2008</date>
<volume>2</volume>
<pages>12--1135</pages>
<contexts>
<context position="1534" citStr="Pang and Lee, 2008" startWordPosition="230" endWordPosition="233">g, we show that on the way to sentiment detection, humans first extract subjectivity. They focus attention on a subset of sentences before arriving at the overall sentiment. This they do either through ”anticipation” where sentences are skipped during the first pass of reading, or through ”homing” where a subset of the sentences are read over multiple passes, or through both. ”Homing” behaviour is also observed at the sub-sentence level in complex sentiment phenomena like sarcasm. 1 Introduction Over the years, supervised approaches using polarity-annotated datasets have shown promise for SA (Pang and Lee, 2008). However, an alternate line of thought has co-existed. Pang and Lee (2004) showed that for SA, instead of a document in its entirety, an extract of the subjective sentences alone can be used. This process of generating a subjective extract is referred to as subjectivity extraction. Mukherjee and Bhattacharyya (2012) show that for sentiment prediction of movie reviews, subjectivity extraction may be used to discard the sentences describing movie plots since they do not contribute towards the speaker’s view of the movie. While subjectivity extraction helps sentiment classification, the reason h</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion Mining and Sentiment Analysis Foundations and Trends in Information Retrieval, 2008, vol. 2, nos.12 1135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dragsted</author>
</authors>
<title>Co-ordination of reading and writing processes in translation. Contribution to Translation and Cognition.</title>
<date>2010</date>
<editor>Shreve, G. and Angelone,</editor>
<publisher>E.(eds.)Cognitive Science Society.</publisher>
<contexts>
<context position="14633" citStr="Dragsted (2010)" startWordPosition="2433" endWordPosition="2434"> expectations from sentences 10-12 where there is an unexpected flip of sentiment. In case of some participants, we observe regression on these sentences multiple times. 7 Related Work The work closest to ours is by Scott et al. (2011) who study the role of emotion words in reading using eye-tracking. They show that the eyefixation duration for emotion words is consistently less than neutral words with the exception of highfrequency negative words. Eye-tracking3 technology has also been used to study the cognitive aspects of language processing tasks like translation and sense disambiguation. Dragsted (2010) observe co-ordination between reading and writing during human translation. Similarly, Joshi et al. (2011) use eye-tracking to correlate fixation duration with polysemy of words during word sense disambiguation. 8 Conclusion &amp; Future work We studied sentiment annotation in the context of subjectivity extraction using eye-tracking. Based on how sentiment changes through a document, humans may perform subjectivity extraction as a result of either: (a) anticipation or (b) homing. These observations are in tandem with the past work that shows benefit of subjectivity extraction for automatic senti</context>
</contexts>
<marker>Dragsted, 2010</marker>
<rawString>B Dragsted. 2010. Co-ordination of reading and writing processes in translation. Contribution to Translation and Cognition. Shreve, G. and Angelone, E.(eds.)Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Carl</author>
</authors>
<title>Translog-II: A Program for Recording UserActivity Data forEmpirical Reading and Writing Research.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation, European Language Resources Association.</booktitle>
<contexts>
<context position="5097" citStr="Carl, 2012" startWordPosition="800" endWordPosition="801">eriments, we observe these two kinds of subjectivity extraction in our participants: subjectivity extraction as a result of anticipation and subjectivity extraction as a result of homing - for linear and oscillating documents respectively. 3 Experiment Setup This section describes the framework used for our eye-tracking experiment. A participant is given the task of annotating documents with one out of the following labels: positive, negative and objective. While she reads the document, her eyefixations are recorded. To log eye-fixation data, we use Tobii T120 remote eye-tracker with Translog(Carl, 2012). Translog is a freeware for recording eye movements and keystrokes during translation. We configure Translog for reading with the goal of sentiment. 3.1 Document description We choose three movie reviews in English from IMDB (http://www.imdb.com) and indicate them as D0, D1 and D2. The lengths of D0, D1 and D2 are 10, 9 and 13 sentences respectively. Using the gold-standard rating given by the writer, we derive the polarity of D0, D1 and D2 as positive, negative and positive respectively. The three documents represent three different styles of reviews: D0 is positive throughout (linear subjec</context>
<context position="7726" citStr="Carl, 2012" startWordPosition="1228" endWordPosition="1229">n a set of instructions beforehand and can seek clarifications. This experiment is conducted as follows: 1. A complete document is displayed on the screen. The font size and line separation are set to 17pt and 1.5 cm respectively to ensure clear visibility and minimize recording error. 2. The annotator verbally states the sentiment of this sentence, before (s)he can proceed to the next. 3. While the annotator is reading the sentence, a remote eye-tracker (Model: Tobii TX 300, Sampling rate: 300Hz) records the eyemovement data of the annotator. The eyetracker is linked to Translog II software (Carl, 2012) in order to record the data. A snapshot of the software is shown in figure 1. The dots and circles represent position of eyes and fixations of the annotator respectively. Each eye-fixation that is recorded consists of: coordinates, timestamp and duration. These three parameters have been used to generate sentence progression graphs. 143 Document Orig P0 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 D0 +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve D1 -ve -ve +ve -ve -ve -ve -ve -ve -ve -ve Neu/-ve -ve -ve D2 +ve +ve +ve -ve +ve +ve Neu +ve Neu Neu +ve +ve +ve Table 1: Polarity of documents as perce</context>
</contexts>
<marker>Carl, 2012</marker>
<rawString>Michael Carl. 2012. Translog-II: A Program for Recording UserActivity Data forEmpirical Reading and Writing Research. In Proceedings of the Eight International Conference on Language Resources and Evaluation, European Language Resources Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P ODonnell</author>
<author>S Sereno</author>
</authors>
<title>Emotion Words Affect Eye Fixations During Reading.</title>
<date>2012</date>
<journal>Journal of Experimental Psychology:Learning, Memory, and Cognition</journal>
<volume>38</volume>
<pages>783792</pages>
<marker>ODonnell, Sereno, 2012</marker>
<rawString>Scott G. , ODonnell P and Sereno S. 2012. Emotion Words Affect Eye Fixations During Reading. Journal of Experimental Psychology:Learning, Memory, and Cognition 2012, Vol. 38, No. 3, 783792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Salil Joshi</author>
<author>Diptesh Kanojia</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>More than meets the eye: Study of Human Cognition</title>
<date>2013</date>
<booktitle>in Sense Annotation. NAACL HLT 2013,</booktitle>
<location>Atlanta, USA.</location>
<marker>Joshi, Kanojia, Bhattacharyya, 2013</marker>
<rawString>Salil Joshi, Diptesh Kanojia and Pushpak Bhattacharyya. 2013. More than meets the eye: Study of Human Cognition in Sense Annotation. NAACL HLT 2013, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Subhabrata Mukherjee</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>WikiSent : Weakly Supervised Sentiment Analysis Through Extractive Summarization With</title>
<date>2012</date>
<booktitle>Wikipedia European Conference on Machine Learning (ECML PKDD 2012),</booktitle>
<location>Bristol, U.K.,</location>
<contexts>
<context position="1852" citStr="Mukherjee and Bhattacharyya (2012)" startWordPosition="283" endWordPosition="287">e a subset of the sentences are read over multiple passes, or through both. ”Homing” behaviour is also observed at the sub-sentence level in complex sentiment phenomena like sarcasm. 1 Introduction Over the years, supervised approaches using polarity-annotated datasets have shown promise for SA (Pang and Lee, 2008). However, an alternate line of thought has co-existed. Pang and Lee (2004) showed that for SA, instead of a document in its entirety, an extract of the subjective sentences alone can be used. This process of generating a subjective extract is referred to as subjectivity extraction. Mukherjee and Bhattacharyya (2012) show that for sentiment prediction of movie reviews, subjectivity extraction may be used to discard the sentences describing movie plots since they do not contribute towards the speaker’s view of the movie. While subjectivity extraction helps sentiment classification, the reason has not been sufficiently examined from the perspective of strong AI. The classical definition of strong AI suggests that a machine must be perform sentiment analysis in a manner and accuracy similar to human beings. Our paper takes a step in this direction. We study the cognitive processes underlying sentiment annota</context>
</contexts>
<marker>Mukherjee, Bhattacharyya, 2012</marker>
<rawString>Subhabrata Mukherjee and Pushpak Bhattacharyya. 2012. WikiSent : Weakly Supervised Sentiment Analysis Through Extractive Summarization With Wikipedia European Conference on Machine Learning (ECML PKDD 2012), Bristol, U.K.,</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>