<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002530">
<title confidence="0.9931795">
Some issues on the normalization of a corpus of products reviews in
Portuguese
</title>
<author confidence="0.830108">
Magali S. Duran
</author>
<affiliation confidence="0.760328666666667">
NILC-ICMC
University of São Paulo
Brazil
</affiliation>
<email confidence="0.995296">
magali.duran@gmail.com
</email>
<author confidence="0.92093">
Lucas V. Avanço
</author>
<affiliation confidence="0.790737333333333">
NILC-ICMC
University of São Paulo
Brazil
</affiliation>
<email confidence="0.987619">
avanco89@gmail.com
</email>
<author confidence="0.979087">
Sandra M. Aluísio
</author>
<affiliation confidence="0.814694">
NILC-ICMC
University of São Paulo
Brazil
</affiliation>
<email confidence="0.992963">
sandra@icmc.usp.br
</email>
<author confidence="0.979023">
Thiago A. S. Pardo
</author>
<affiliation confidence="0.899480666666667">
NILC-ICMC
University of São Paulo
Brazil
</affiliation>
<email confidence="0.974002">
taspardo@icmc.usp.br
</email>
<author confidence="0.988803">
Maria G. V. Nunes
</author>
<affiliation confidence="0.899995666666667">
NILC-ICMC
University of São Paulo
Brazil
</affiliation>
<email confidence="0.964627">
gracan@icmc.usp.br
</email>
<sectionHeader confidence="0.991978" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999355125">
This paper describes the analysis of different
kinds of noises in a corpus of products
reviews in Brazilian Portuguese. Case
folding, punctuation, spelling and the use of
internet slang are the major kinds of noise we
face. After noting the effect of these noises
on the POS tagging task, we propose some
procedures to minimize them.
</bodyText>
<sectionHeader confidence="0.998212" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.998160269230769">
Corpus normalization has become a common
challenge for everyone interested in processing a
web corpus. Some normalization tasks are
language and genre independent, like boilerplate
removal and deduplication of texts. Others, like
orthographic errors correction and internet slang
handling, are not.
Two approaches to web corpus normalization
have been discussed in Web as a Corpus (WAC)
literature. One of them is to tackle the task as a
translation problem, being the web texts the
source language and the normalized texts the
target language (Aw et al., 2006; Contractor et
al., 2010; Schlippe et al., 2013). Such approach
requires a parallel corpus of original and
normalized texts of reasonable size for training a
system with acceptable accuracy. The other
approach is to tackle the problem as a number of
sub problems to be solved in sequence
(Ringlstetter et al., 2006; Bildhauer &amp; Schäfer,
2013; Schäfer et al., 2013).
The discussion we engage herein adopts the
second approach and is motivated by the
demand of preprocessing a Brazilian Portuguese
web corpus constituted of products reviews for
the specific purpose of building an opinion
mining classifier and summarizer. Our project
also includes the task of adding a layer of
semantic role labeling to the corpus. The roles
will be assigned to nodes of the syntactic trees
and, therefore, SRL subsumes the existence of
layers of morphosyntactic and syntactic
annotations. The annotated corpus will be used
as training corpus for a SRL classifier. The aim
of SRL classifier, on its turn, is to provide deep
semantic information that may be used as
features by the opinion miner. If the text is not
normalized, the POS tagger does not perform
well and compromise the parsing result, which,
as consequence, may generate defective trees,
compromising the assignment of role labels to
their nodes.
In fact, mining opinions from a web corpus is
a non-trivial NLP task which often requires some
language processing, such as POS tagging and
parsing. Most of taggers and parsers are made to
handle error-free texts; therefore they may
jeopardize the application results when they face
major noises. What constitutes a major noise and
which noise may be removed or corrected in
such a corpus is the challenge we are facing in
this project.
</bodyText>
<page confidence="0.953408">
22
</page>
<bodyText confidence="0.605398333333333">
Felix Bildhauer &amp; Roland Schäfer (eds.), Proceedings of the 9th Web as Corpus Workshop (WaC-9) @ EACL 2014, pages 22–28,
Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics
keeping the corrected form as an additional
</bodyText>
<sectionHeader confidence="0.904768" genericHeader="related work">
2. Related Work annotation layer, may be the best solution.
</sectionHeader>
<bodyText confidence="0.999918153846154">
Depending on the point of view, there are
several studies that face problems similar to
those faced by us. The general issue is: how to
convert a non-standard text into a standard one?
By non-standard text we mean a text produced
by people that have low literacy level or by
foreign language learners or by speech-to-text
converters, machine translators or even by
digitization process. Also included in this class
are the texts produced in special and informal
environments such as the web. Each one of these
non-standard texts has its own characteristics.
They may differ in what concerns spelling, non-
canonical use of case, hyphen, apostrophe,
punctuation, etc. Such characteristics are seen as
“noise” by NLP tools trained in well written texts
that represent what is commonly known as
standard language. Furthermore, with the
widespread use of web as corpus, other types of
noise need to be eliminated, as for example
duplication of texts and boilerplates.
The procedures that aim to adapt texts to
render them more similar to standard texts are
called normalization. Some normalization
procedures like deduplication and boilerplate
removal are less likely to cause destruction of
relevant material. The problem arises when the
noise category contains some forms that are
ambiguous to other forms of the standard
language. For example, the words “Oi” and
“Claro” are the names of two Brazilian mobile
network operators, but they are also common
words (“oi” = hi; “claro” = clear). Cases like
these led Lita et al. (2003) to consider case
normalization as a problem of word sense
disambiguation. Proper nouns which are derived
from common nouns (hence, distinguished only
by case) are one of the challenges for case
normalization reported by Manning et al. (2008).
Similar problem is reported by Bildhauer and
Schäfer (2013) regarding dehyphenation, that is,
the removal of hyphens used in typeset texts and
commonly found in digitized texts. In German,
there are many hyphenated words and the
challenge is to remove noisy hyphens without
affecting the correct ones. There are situations,
however, in which both the corrected and the
original text are desired. For example, social
media corpora are plain of noises that express
emotions, a rich material for sentiment analysis.
For these cases, the non-destructive strategy
proposed by Bildhauer and Schäfer (2013),
</bodyText>
<subsectionHeader confidence="0.644997">
3. Corpus of Products Reviews
</subsectionHeader>
<bodyText confidence="0.99977475">
To build the corpus of products reviews, we
have crawled a products reviews database of one
of the most traditional online services in Brazil,
called Buscapé, where customers post their
comments about several products. The comments
are written in a free format within a template
with three sections: Pros, Cons, and Opinion. We
gathered 85,910 reviews, totaling 4,088,718
tokens and 90,513 types. After removing stop
words, numbers and punctuation, the frequency
list totaled 63,917 types.
Customers have different levels of literacy
and some reviews are very well written whereas
others present several types of errors. In addition,
some reviewers adopt a standard language style,
whereas others incorporate features that are
typical of the internet informality, like abusive
use of abbreviations, missing or inadequate
punctuation; a high percentage of named entities
(many of which are misspelled); a high
percentage of foreign words; the use of internet
slang; non-conventional use of uppercase;
spelling errors and missing of diacritic signals.
A previous work (Hartmann et al. 2014)
investigated the nature and the distribution of the
34,774 words of the corpus Buscapé not
recognized by Unitex, a Brazilian Portuguese
lexicon (Muniz et. al. 2005). The words for
which only the diacritic signals were missing
(3,652 or 10.2%) have been automatically
corrected. Then, all the remaining words with
more than 2 occurrences (5775) were classified
in a double-blind annotation task, which obtained
0,752 of inter-annotator agreement (Kappa
statistics, Carletta, 1996). The results obtained
are shown in Table 1.
</bodyText>
<tableCaption confidence="0.9802345">
Table 1. Non-Recognized Words with more
than 2 occurrences in the corpus
</tableCaption>
<table confidence="0.999401777777778">
Common Portuguese misspelled words 44%
Acronyms 5%
Proper Nouns 24%
Abbreviations 2%
Internet Slang 4%
Foreign words used in Portuguese 8%
Units of Measurement 0%
Other problems 13%
Total 100%
</table>
<page confidence="0.996956">
23
</page>
<bodyText confidence="0.998691428571429">
The study reported herein aims to investigate The manual corrections of the sample were
how some of these problems occur in the corpus made by a linguist who followed some rules
and to what extent they may affect POS tagging. established in accordance with the project goals
Future improvements remain to be done in the and the MXPOST annotation guidelines1. As a
specific tools that individually tackle these result, only the punctuation correction allowed
problems. some subjective decisions; the other kinds of
correction were very objective.
</bodyText>
<sectionHeader confidence="0.9980605" genericHeader="method">
4. Methodology
5. Results of diagnosing experiments
</sectionHeader>
<bodyText confidence="0.999985694444445">
As the same corpus is to be used for different
subtasks – semantic role labeling, opinion
detection, classification and summarization – the
challenge is to normalize the corpus but also
keep some original occurrences that may be
relevant for such tasks. Maintaining two or more
versions of the corpus is also being considered.
To enable a semi-automatic qualitative and
quantitative investigation, a random 10-reviews
sample (1226 tokens) of the original corpus was
selected and POS tagged by the MXPOST tagger
which was trained on MAC-Morpho, a 1.2
million tokens corpus of Brazilian Portuguese
newspaper articles (Aluísio et al., 2003).
It is worthwhile to say that the sampling did
not follow statistical principles. In fact, we
randomly selected 10 texts (1226 tokens from a
corpus of 4,088,718 tokens), which we
considered a reasonable portion of text to
undertake the manual tasks required by the first
diagnosis experiments. Our aim was to explore
tendencies and not to have a precise statistical
description of the percentage of types of errors in
the corpus. Therefore, the probabilities of each
type of error may not reflect those of the entire
corpus.
We manually corrected the POS tagged
version to evaluate how many tags were
correctly assigned. The precision of MXPOST in
our sample is 88.74%, while its better precision,
of 96.98%, has been obtained in its training
corpus. As one may see, there was a decrease of
8.49% in performance, which is expected in such
change of text genre.
In the sequence, we created four manually
corrected versions of the sample, regarding each
of the following normalization categories:
spelling (including foreign words and named
entities); case use; punctuation; and use of
internet slang. This step produced four golden
corpus samples which were used for separate
evaluations. The calculation of the difference
between the original corpus sample and each of
the golden ones led us to the following
conclusions.
Regarding to spelling, 2 foreign words, 3
named entities and 19 common words were
detected as misspelled. A total of 24 (1.96%)
words have been corrected. There are 35 words
(2.90%) for which the case have been changed (6
upper to lower and 29 in the reverse direction).
Punctuation has showed to be a relevant
issue: 48 interventions (deletions, insertions or
substitutions) have been made to turn the texts
correct, representing 3.92% of the sample.
Regarding internet slang, only 3 occurrences
(0.24%) were detected in the sample, what
contradicted our expectation that such lexicon
would have a huge impact in our corpus.
However due to the size of our sample, this may
have occurred by chance.
The precision of the POS tagged sample has
been compared with the ones of the POS tagged
versions of golden samples. The results showed
us the impact of the above four normalization
categories on the tagger performance.
We have verified that there was improvement
after the correction of each category, reducing
the POS tagger errors as shown in Table 2. When
we combine all the categories of correction
before tagging the sample, the cumulative result
is an error reduction of 19.56%.
</bodyText>
<tableCaption confidence="0.8786385">
Table 2. Improvement of the tagger precision
in the sample
</tableCaption>
<table confidence="0.999524">
Case Correction + 15.94%
Punctuation Correction + 4.34%
Spelling + 2.90%
Internet Slang Convertion + 1.45%
Cumulative Error Reduction 19.56%
</table>
<bodyText confidence="0.99563875">
These first experiments revealed that case
correction has major relevance in the process of
normalizing our corpus of products reviews. It is
important to note that case information is largely
</bodyText>
<footnote confidence="0.955403">
1 Available at
http://www.nilc.icmc.usp.br/lacioweb/manuais.htm
</footnote>
<page confidence="0.998577">
24
</page>
<bodyText confidence="0.999510625">
used as feature by Named Entities Recognizers
(NER), POS taggers and parsers.
To evaluate whether the case use distribution
is different from that of a corpus of well written
texts, we compared the statistics of case use in
our corpus with those of a newspaper corpus
(http://www.linguateca.pt/CETENFolha/), as
shown in Table 3.
</bodyText>
<tableCaption confidence="0.954395">
Table 3. Percentage of case use in newspaper
and products reviews corpus genres
</tableCaption>
<table confidence="0.998412666666667">
CORPUS Newspaper Products
Reviews
Uppercase words 6.41% 5.30%
Initial uppercase 20.86% 7.30%
words
Lowercase words 70.79% 85.37%
</table>
<bodyText confidence="0.996012">
The differences observed led us to conclude
that the tendency observed in our sample (proper
names and acronyms written in lower case) is
probably a problem for the whole corpus.
To confirm such conclusion, we searched in
the corpus the 1,339 proper nouns identified in
our previous annotation task. They occurred
40,009 times with the case distribution shown in
</bodyText>
<tableCaption confidence="0.9713595">
Table 4.
Table 4. Case distribution of Proper Nouns
</tableCaption>
<bodyText confidence="0.8665167">
Initial uppercase words 15,148 38%
Uppercase words 7,392 18%
Lower case words 17,469 44%
Total 40,009 100%
The main result of these experiments is the
evidence that the four kind of errors investigated
do affect POS tagging. In the next section we
will detail the procedures envisaged to provide
normalization for each one of the four categories
of errors.
</bodyText>
<sectionHeader confidence="0.976405" genericHeader="method">
6. Towards automatic normalization
procedures
</sectionHeader>
<bodyText confidence="0.999978">
After diagnosing the needs of text
normalization of our corpus, we started to test
automatic procedures to meet them. The
processing of a new genre always poses a
question: should we normalize the new genre to
make it similar to the input expected by available
automatic tools or should we adapt the existing
tools to process the new genre? This is not a
question of choice, indeed. We argue that both
movements are needed. Furthermore, the
processing of a new genre is an opportunity not
only to make genre-adaptation, but also to
improve general purpose features of NLP tools.
</bodyText>
<subsectionHeader confidence="0.997606">
6.1 Case normalization: truecasing
</subsectionHeader>
<bodyText confidence="0.999970604651163">
In NLP the problem of case normalization is
usually called “truecasing” (Lita et al, 2003,
Manning et al., 2008). The challenge is to decide
when uppercase should be changed into lower
case and when lower case should be changed into
upper case. In brief, truecasing is the process of
correcting case use in badly-cased or non-cased
text.
The problem is particularly relevant in two
scenarios; speech recognition and informal web
texts.
We prioritized the case normalization for two
reasons: first, badly-cased text seems to be a
generalized problem in the genre of products
reviews and, second, it is important to make case
normalization before using a spell checker. This
is crucial to “protect” Named Entities from
spelling corrections because when non-
recognized lowercase words are checked by
spellers, there is the risk of wrong correction.
Indeed, the more extensive is the speller lexicon,
the greater is the risk of miscorrection.
The genre under inspection presents a
widespread misuse of case. By one side, lower
case is used in place of uppercase in the initial
letter of proper names. On the other side, upper
case is used to emphasize any kind of word.
Our first tentative to tackle the problem of
capitalization was to submit the samples to a
Named Entity Recognizer. We chose Rembrandt2
(Cardoso, 2012), a Portuguese NER that
enhances both lexical knowledge extracted from
Wikipedia and statistical knowledge.
The procedure was: 1) to submit the sample
to Rembrandt; 2) to capitalize the recognized
entities written in lower case; 3) to change all the
words capitalized, except the named entities, to
lower case. Then we tagged the sample with
MXPOST to evaluate the effect on POS tagging
accuracy.
The number of errors of POS tagging
increased (149) when compared to the one of the
sample without preprocessing (138). The
</bodyText>
<footnote confidence="0.98041">
2 The Portuguese named entity recognition is made by
system Rembrandt (http://xldb.di.fc.ul.pt/Rembrandt/)
</footnote>
<page confidence="0.999071">
25
</page>
<bodyText confidence="0.9896134125">
explanation for this is that among the words not
recognized as named entities there were
capitalized named entities which were lost by
this strategy.
Next we tried a new version of this same
experiment: we only changed into lower case the
words not recognized as named entities that were
simultaneously recognized by Unitex. The results
were slightly better (143 errors) compared to the
first version of the experiment, but still worse
than those of the sample without preprocessing.
Our expectation was to automatically
capitalize the recognized entities written in lower
case. In both experiments, however, no word was
changed from lower to upper case because all the
entities recognized by the NER were already
capitalized.
The sample contains 57 tokens of named
entities (corresponding to proper nouns and
acronyms) from which 24 were written in lower
case. The NER recognized 22 of the 57 or 18 of
the 38 types of named entities (a performance of
47.4%). Unfortunately the NER is strongly based
on the presence of capitalized initial letters and
was of no aid in the procedure we tested.
We argue that a finite list of known proper
nouns and acronyms, although useful for
improving evaluation figures, is of limited use
for an application such as an opinion miner. In
real scenarios this constitutes an open class and
new entities shall be recognized as well.
We observed that many of the named entities
found in the reviews relate to the product being
reviewed and to the company that produces it.
Then we realized an advantage of the source
from which we have crawled the reviews: the
customers are only allowed to review products
that have been previously registered in the site
database. The register of the name of the product
is kept in our corpus as metadata for each review.
This situation gave us the opportunity to
experiment another strategy: to identify named
entities of each review in its respective metadata
file. We first gathered all the words annotated as
Proper Nouns and Acronyms in our previous
annotation task3. Then we search for the matches.
The result is promising: from 1,334 proper nouns
and from 271 acronyms, respectively 676
3 Confusion matrix of our double annotated data show
that annotators diverged in what concerns Proper Nouns and
Acronyms. For our purposes, however, all of them are
named entities and need to be capitalized, so that this kind
of disagreement did not affect the use we have made of the
annotated words.
(50.67%) and 44 (16.23%) were found in the
metadata. Adding both types of named entities,
we have a match of 44.85% (720 of 1605). This
is pretty good mainly because the named entities
recognized are precisely the names of products
for which opinions will be mined.
However, we still need to solve the
recognition of the other named entities in order
to support the truecasing strategies.
Following Lita et al. (2003) and Beaufays and
Strope (2013), we are considering using a
language model. Lita et al. developed a truecaser
for news articles, a genre more “stable” than
products reviews. Beaufays and Strope, on their
turn, developed a truecaser to tackle texts
generated from speech recognition. Language
modeling may be a good approach to our
problem because many named entities of
products domain do not sound as Portuguese
words. For example, they frequently have the
consonants k, y and w, which are only used in
proper names in Portuguese. Other approaches to
truecasing reported in the literature include finite
state transducers automatically built from
language models and maximum entropy models
(Batista et al. 2008).
</bodyText>
<subsectionHeader confidence="0.999382">
6.2 Punctuation problems
</subsectionHeader>
<bodyText confidence="0.999990416666667">
Many reviews have no punctuation at all.
This prevents processing the text by most of NLP
tools which processes sentences. Some
grammatical rules may be used to correct the use
of comma, but the problem is more complex in
what concerns full stop. We are now training a
machine learning based program with a corpus of
well written texts by using features related to n-
grams. We aim at building a sentence
segmentation tool which does not depend on the
presence of punctuation or case folding, since
these are major noises in the corpus.
</bodyText>
<subsectionHeader confidence="0.999268">
6.3 Spelling correction
</subsectionHeader>
<bodyText confidence="0.999995272727273">
The common Portuguese words in the corpus
which were not recognized by Unitex have been
spell checked. Manual analysis is being
undertaken to determine whether the word has
been accurately corrected or not. Early results
evidenced opportunity to extend Unitex and to
improve our spellers with more phonetic rules in
order to suggest more adequate alternatives. As
we have already mentioned, product reviewers
have several levels of literacy and those of lower
level frequently swap the consonant letters that
</bodyText>
<page confidence="0.983726">
26
</page>
<bodyText confidence="0.999921428571429">
conveys the same phonetic value. For example,
in Portuguese the letters “s”, “c”, “xc” “ss” and
“ç” can have the same sound: /s/. Therefore, it is
a common mistake to employ one instead of the
other. These rules shall be incorporated in spell
checker. In addition, there are many words which
were correctly spelled, but were not part of
Unitex or of the speller’s dictionary or both.
Both lexicons will be extended with the missing
words.
In the same way, the foreign words of current use
in Brazilian Portuguese shall be incorporated in
the spell checkers in order to improve their
suggestions of correction. As a matter of fact,
foreign words are frequently misspelled. For
example, “touchscreen” appeared as 10 different
spelling forms in our corpus with more than 2
occurrences (“toch escreen”, “touch screem”,
“touch sreen”, “touche”, “touch scream”,
“touchscream”, “touchscreem”, “touch-screen”,
“touchsren”, “touch screen&amp;quot;).
</bodyText>
<subsectionHeader confidence="0.929426">
6.4 Internet slang normalization
</subsectionHeader>
<bodyText confidence="0.999981578947369">
Internet slang is a class that combines: 1)
words written in a different way and
abbreviations of recurrent expressions, for which
there is an equivalent in the standard language
(in this case the procedure is to substitute one for
another); 2) repeated letters and punctuation (e.g.
!!!!!!!!!!!!, and ameiiiiiiiiiiiiiiiiiiiiiii, in which the
word &amp;quot;amei&amp;quot; = “love” is being emphasized),
which may be normalized by eliminating
repetitions; and 3) sequences of letters related to
emotion expression, like emoticons (e.g. “:)”,
“:=(”), laughing (e.g. rsrsrsrs, heheheh,
kkkkkkkk), which for some purposes shall be
eliminated and for others shall not. The
procedures relating to internet slang will be
implemented carefully to allow the user to
activate each one of the three procedures
separately, depending on his/her interest in
preserving emotion expression or not.
</bodyText>
<sectionHeader confidence="0.982041" genericHeader="method">
7. Final Remarks
</sectionHeader>
<bodyText confidence="0.999905428571429">
This preliminary investigation about the
needs of text normalization for the genre of
products reviews led us to deep understand our
challenges and to envisage some solutions.
We have opened some avenues for future
works and established an agenda for the next
steps towards corpus normalization.
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99941325">
This research work is being carried on as part of
an academic agreement between University of
São Paulo and Samsung Eletrônica da Amazônia
Ltda.
</bodyText>
<sectionHeader confidence="0.99917" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999699069767442">
Aluísio, S. M.; Pelizzoni, J. M.; Marchi, A. R.;
Oliveira, L. H.; Manenti, R.; Marquivafável, V.
(2003). An account of the challenge of tagging a
reference corpus of Brazilian Portuguese. In:
Proceedings of PROPOR´2003. Springer Verlag,
2003, pp. 110-117.
Aw, A.; Zhang, M.; Xiao, J.; Su, J. (2006). A Phrase-
based Statistical Model for SMS Text
Normalization. In: Proceedings of the COLING-
2006 .ACL, Sydney, 2006, pp. 33–40.
Batista, F.; Caseiro, D. A.; Mamede, N. J.; Trancoso,
I. (2008). Recovering Capitalization and
Punctuation Marks for Automatic Speech
Recognition: Case Study for the Portuguese
Broadcast News, Speech Communication, vol. 50,
n. 10, pages 847-862, doi:
10.1016/j.specom.2008.05.008, October 2008
Beaufays, F.; Strope, B. (2013) Language Model
Capitalization. In: 2013 IEEE International
Conference on Acoustics, Speech and Signal
Processing (ICASSP), p. 6749 – 6752.
Bildhauer, F.; Schäfer, R. (2013) Token-level noise in
large Web corpora and non-destructive
normalization for linguistic applications. In:
Proceedings of Corpus Analysis with Noise in the
Signal (CANS 2013) .
Cardoso, N. (2012). Rembrandt - a named-entity
recognition framework. In: Proceedings of the
Eight International Conference on Language
Resources and Evaluation (LREC&apos;12). May, 23-25,
Istanbul, Turkey.
Carletta, J.: Assessing Agreement on Classification
Tasks: The Kappa Statistic. Computational
Linguistics, vol. 22, n. 2, pp. 249--254. (1996)
Contractor, D.; Tanveer A.; Faruquie; L.;
Subramaniam, V. (2010). Unsupervised cleansing
of noisy text. Coling 2010: Poster Volume, pages
189–196, Beijing, August 2010.
Hartmann, N. S.; Avanço. L.; Balage, P. P.; Duran,
M. S.; Nunes, M. G. V.; Pardo, T.; Aluísio, S.
(2014). A Large Opinion Corpus in Portuguese -
Tackling Out-Of-Vocabulary Words. In:
Proceedings of the Ninth International Conference
</reference>
<page confidence="0.966509">
27
</page>
<reference confidence="0.998569413793103">
on Language Resources and Evaluation (LREC
2014). Forthcoming.
Lita, L., Ittycheriah, A., Roukos, S. &amp; Kambhatla,N.
(2003), Truecasing, In: Proceedings of the 41st
Annual Meeting of the Association for
Computational Linguistics, Japan.
Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008).
Introduction to information retrieval (Vol. 1).
Cambridge: Cambridge university press.
Muniz, M.C.M.; Nunes, M.G.V.; Laporte. E. (2005)
&amp;quot;UNITEX-PB, a set of flexible language resources
for Brazilian Portuguese&amp;quot;, Proceedings of the
Workshop on Technology of Information and
Human Language (TIL), São Leopoldo (Brazil):
Unisinos.
Ringlstetter, C.; Schulz, K. U. and Mihov, S. (2006).
Orthographic Errors in Web Pages: Toward
Cleaner Web Corpora. In: Computational
Linguistics Volume 32, Number 3, p. 295-340.
Schäfer, R.; Barbaresi, A.; Bildhauer, F. (2013) The
Good, the Bad, and the Hazy: Design Decisions in
Web Corpus Construction. In: Proceedings of the
8th Web as Corpus Workshop (WAC-8).
Schlippe, T.; Zhu, C.; Gebhardt J.;, Schultz, T.(2013).
Text Normalization based on Statistical Machine
Translation and Internet User Support. In:
Proceedings of The 38th International Conference
on Acoustics, Speech, and Signal Processing
(ICASSP-2013) p. 8406 – 841.
</reference>
<page confidence="0.999028">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.217631">
<title confidence="0.978615">Some issues on the normalization of a corpus of products reviews in Portuguese</title>
<author confidence="0.960766">S Magali</author>
<affiliation confidence="0.904874">University of São Paulo Brazil</affiliation>
<email confidence="0.999223">magali.duran@gmail.com</email>
<author confidence="0.999702">V Lucas</author>
<affiliation confidence="0.8777105">University of São Paulo Brazil</affiliation>
<email confidence="0.992134">avanco89@gmail.com</email>
<author confidence="0.997814">M Sandra</author>
<affiliation confidence="0.998911">University of São</affiliation>
<address confidence="0.737582">Brazil</address>
<email confidence="0.983057">sandra@icmc.usp.br</email>
<author confidence="0.843795">A S Thiago</author>
<affiliation confidence="0.967426">University of São</affiliation>
<email confidence="0.719846">taspardo@icmc.usp.br</email>
<author confidence="0.98862">G V Maria</author>
<affiliation confidence="0.984412">University of São</affiliation>
<email confidence="0.902284">gracan@icmc.usp.br</email>
<abstract confidence="0.994801">This paper describes the analysis of different kinds of noises in a corpus of products reviews in Brazilian Portuguese. Case folding, punctuation, spelling and the use of internet slang are the major kinds of noise we face. After noting the effect of these noises on the POS tagging task, we propose some procedures to minimize them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S M Aluísio</author>
<author>J M Pelizzoni</author>
<author>A R Marchi</author>
<author>L H Oliveira</author>
<author>R Manenti</author>
<author>V Marquivafável</author>
</authors>
<title>An account of the challenge of tagging a reference corpus of Brazilian Portuguese. In:</title>
<date>2003</date>
<booktitle>Proceedings of PROPOR´2003.</booktitle>
<pages>110--117</pages>
<publisher>Springer Verlag,</publisher>
<contexts>
<context position="8952" citStr="Aluísio et al., 2003" startWordPosition="1399" endWordPosition="1402">us is to be used for different subtasks – semantic role labeling, opinion detection, classification and summarization – the challenge is to normalize the corpus but also keep some original occurrences that may be relevant for such tasks. Maintaining two or more versions of the corpus is also being considered. To enable a semi-automatic qualitative and quantitative investigation, a random 10-reviews sample (1226 tokens) of the original corpus was selected and POS tagged by the MXPOST tagger which was trained on MAC-Morpho, a 1.2 million tokens corpus of Brazilian Portuguese newspaper articles (Aluísio et al., 2003). It is worthwhile to say that the sampling did not follow statistical principles. In fact, we randomly selected 10 texts (1226 tokens from a corpus of 4,088,718 tokens), which we considered a reasonable portion of text to undertake the manual tasks required by the first diagnosis experiments. Our aim was to explore tendencies and not to have a precise statistical description of the percentage of types of errors in the corpus. Therefore, the probabilities of each type of error may not reflect those of the entire corpus. We manually corrected the POS tagged version to evaluate how many tags wer</context>
</contexts>
<marker>Aluísio, Pelizzoni, Marchi, Oliveira, Manenti, Marquivafável, 2003</marker>
<rawString>Aluísio, S. M.; Pelizzoni, J. M.; Marchi, A. R.; Oliveira, L. H.; Manenti, R.; Marquivafável, V. (2003). An account of the challenge of tagging a reference corpus of Brazilian Portuguese. In: Proceedings of PROPOR´2003. Springer Verlag, 2003, pp. 110-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aw</author>
<author>M Zhang</author>
<author>J Xiao</author>
<author>J Su</author>
</authors>
<title>A Phrasebased Statistical Model for SMS Text Normalization. In:</title>
<date>2006</date>
<booktitle>Proceedings of the COLING2006 .ACL,</booktitle>
<pages>33--40</pages>
<location>Sydney,</location>
<contexts>
<context position="1391" citStr="Aw et al., 2006" startWordPosition="207" endWordPosition="210">pose some procedures to minimize them. 1. Introduction Corpus normalization has become a common challenge for everyone interested in processing a web corpus. Some normalization tasks are language and genre independent, like boilerplate removal and deduplication of texts. Others, like orthographic errors correction and internet slang handling, are not. Two approaches to web corpus normalization have been discussed in Web as a Corpus (WAC) literature. One of them is to tackle the task as a translation problem, being the web texts the source language and the normalized texts the target language (Aw et al., 2006; Contractor et al., 2010; Schlippe et al., 2013). Such approach requires a parallel corpus of original and normalized texts of reasonable size for training a system with acceptable accuracy. The other approach is to tackle the problem as a number of sub problems to be solved in sequence (Ringlstetter et al., 2006; Bildhauer &amp; Schäfer, 2013; Schäfer et al., 2013). The discussion we engage herein adopts the second approach and is motivated by the demand of preprocessing a Brazilian Portuguese web corpus constituted of products reviews for the specific purpose of building an opinion mining class</context>
</contexts>
<marker>Aw, Zhang, Xiao, Su, 2006</marker>
<rawString>Aw, A.; Zhang, M.; Xiao, J.; Su, J. (2006). A Phrasebased Statistical Model for SMS Text Normalization. In: Proceedings of the COLING2006 .ACL, Sydney, 2006, pp. 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Batista</author>
<author>D A Caseiro</author>
<author>N J Mamede</author>
<author>I Trancoso</author>
</authors>
<title>Recovering Capitalization and Punctuation Marks for Automatic Speech Recognition: Case Study for the Portuguese Broadcast News,</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<contexts>
<context position="19428" citStr="Batista et al. 2008" startWordPosition="3100" endWordPosition="3103">loped a truecaser for news articles, a genre more “stable” than products reviews. Beaufays and Strope, on their turn, developed a truecaser to tackle texts generated from speech recognition. Language modeling may be a good approach to our problem because many named entities of products domain do not sound as Portuguese words. For example, they frequently have the consonants k, y and w, which are only used in proper names in Portuguese. Other approaches to truecasing reported in the literature include finite state transducers automatically built from language models and maximum entropy models (Batista et al. 2008). 6.2 Punctuation problems Many reviews have no punctuation at all. This prevents processing the text by most of NLP tools which processes sentences. Some grammatical rules may be used to correct the use of comma, but the problem is more complex in what concerns full stop. We are now training a machine learning based program with a corpus of well written texts by using features related to ngrams. We aim at building a sentence segmentation tool which does not depend on the presence of punctuation or case folding, since these are major noises in the corpus. 6.3 Spelling correction The common Por</context>
</contexts>
<marker>Batista, Caseiro, Mamede, Trancoso, 2008</marker>
<rawString>Batista, F.; Caseiro, D. A.; Mamede, N. J.; Trancoso, I. (2008). Recovering Capitalization and Punctuation Marks for Automatic Speech Recognition: Case Study for the Portuguese Broadcast News, Speech Communication, vol. 50,</rawString>
</citation>
<citation valid="true">
<authors>
<author>n</author>
</authors>
<date>2008</date>
<volume>10</volume>
<pages>847--862</pages>
<marker>n, 2008</marker>
<rawString>n. 10, pages 847-862, doi: 10.1016/j.specom.2008.05.008, October 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Beaufays</author>
<author>B Strope</author>
</authors>
<title>Language Model Capitalization. In:</title>
<date>2013</date>
<booktitle>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),</booktitle>
<pages>6749--6752</pages>
<contexts>
<context position="18747" citStr="Beaufays and Strope (2013)" startWordPosition="2993" endWordPosition="2996">r our purposes, however, all of them are named entities and need to be capitalized, so that this kind of disagreement did not affect the use we have made of the annotated words. (50.67%) and 44 (16.23%) were found in the metadata. Adding both types of named entities, we have a match of 44.85% (720 of 1605). This is pretty good mainly because the named entities recognized are precisely the names of products for which opinions will be mined. However, we still need to solve the recognition of the other named entities in order to support the truecasing strategies. Following Lita et al. (2003) and Beaufays and Strope (2013), we are considering using a language model. Lita et al. developed a truecaser for news articles, a genre more “stable” than products reviews. Beaufays and Strope, on their turn, developed a truecaser to tackle texts generated from speech recognition. Language modeling may be a good approach to our problem because many named entities of products domain do not sound as Portuguese words. For example, they frequently have the consonants k, y and w, which are only used in proper names in Portuguese. Other approaches to truecasing reported in the literature include finite state transducers automati</context>
</contexts>
<marker>Beaufays, Strope, 2013</marker>
<rawString>Beaufays, F.; Strope, B. (2013) Language Model Capitalization. In: 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), p. 6749 – 6752.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bildhauer</author>
<author>R Schäfer</author>
</authors>
<title>Token-level noise in large Web corpora and non-destructive normalization for linguistic applications. In:</title>
<date>2013</date>
<booktitle>Proceedings of Corpus Analysis with Noise in the Signal (CANS</booktitle>
<pages>.</pages>
<contexts>
<context position="5263" citStr="Bildhauer and Schäfer (2013)" startWordPosition="833" endWordPosition="836">ial. The problem arises when the noise category contains some forms that are ambiguous to other forms of the standard language. For example, the words “Oi” and “Claro” are the names of two Brazilian mobile network operators, but they are also common words (“oi” = hi; “claro” = clear). Cases like these led Lita et al. (2003) to consider case normalization as a problem of word sense disambiguation. Proper nouns which are derived from common nouns (hence, distinguished only by case) are one of the challenges for case normalization reported by Manning et al. (2008). Similar problem is reported by Bildhauer and Schäfer (2013) regarding dehyphenation, that is, the removal of hyphens used in typeset texts and commonly found in digitized texts. In German, there are many hyphenated words and the challenge is to remove noisy hyphens without affecting the correct ones. There are situations, however, in which both the corrected and the original text are desired. For example, social media corpora are plain of noises that express emotions, a rich material for sentiment analysis. For these cases, the non-destructive strategy proposed by Bildhauer and Schäfer (2013), 3. Corpus of Products Reviews To build the corpus of produ</context>
<context position="1733" citStr="Bildhauer &amp; Schäfer, 2013" startWordPosition="263" endWordPosition="266">ng handling, are not. Two approaches to web corpus normalization have been discussed in Web as a Corpus (WAC) literature. One of them is to tackle the task as a translation problem, being the web texts the source language and the normalized texts the target language (Aw et al., 2006; Contractor et al., 2010; Schlippe et al., 2013). Such approach requires a parallel corpus of original and normalized texts of reasonable size for training a system with acceptable accuracy. The other approach is to tackle the problem as a number of sub problems to be solved in sequence (Ringlstetter et al., 2006; Bildhauer &amp; Schäfer, 2013; Schäfer et al., 2013). The discussion we engage herein adopts the second approach and is motivated by the demand of preprocessing a Brazilian Portuguese web corpus constituted of products reviews for the specific purpose of building an opinion mining classifier and summarizer. Our project also includes the task of adding a layer of semantic role labeling to the corpus. The roles will be assigned to nodes of the syntactic trees and, therefore, SRL subsumes the existence of layers of morphosyntactic and syntactic annotations. The annotated corpus will be used as training corpus for a SRL class</context>
</contexts>
<marker>Bildhauer, Schäfer, 2013</marker>
<rawString>Bildhauer, F.; Schäfer, R. (2013) Token-level noise in large Web corpora and non-destructive normalization for linguistic applications. In: Proceedings of Corpus Analysis with Noise in the Signal (CANS 2013) .</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Cardoso</author>
</authors>
<title>Rembrandt - a named-entity recognition framework. In:</title>
<date>2012</date>
<booktitle>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12).</booktitle>
<pages>23--25</pages>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="15206" citStr="Cardoso, 2012" startWordPosition="2410" endWordPosition="2411"> Entities from spelling corrections because when nonrecognized lowercase words are checked by spellers, there is the risk of wrong correction. Indeed, the more extensive is the speller lexicon, the greater is the risk of miscorrection. The genre under inspection presents a widespread misuse of case. By one side, lower case is used in place of uppercase in the initial letter of proper names. On the other side, upper case is used to emphasize any kind of word. Our first tentative to tackle the problem of capitalization was to submit the samples to a Named Entity Recognizer. We chose Rembrandt2 (Cardoso, 2012), a Portuguese NER that enhances both lexical knowledge extracted from Wikipedia and statistical knowledge. The procedure was: 1) to submit the sample to Rembrandt; 2) to capitalize the recognized entities written in lower case; 3) to change all the words capitalized, except the named entities, to lower case. Then we tagged the sample with MXPOST to evaluate the effect on POS tagging accuracy. The number of errors of POS tagging increased (149) when compared to the one of the sample without preprocessing (138). The 2 The Portuguese named entity recognition is made by system Rembrandt (http://x</context>
</contexts>
<marker>Cardoso, 2012</marker>
<rawString>Cardoso, N. (2012). Rembrandt - a named-entity recognition framework. In: Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12). May, 23-25, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
</authors>
<title>Assessing Agreement on Classification Tasks: The Kappa Statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<pages>249--254</pages>
<contexts>
<context position="7403" citStr="Carletta, 1996" startWordPosition="1158" endWordPosition="1159">rnet slang; non-conventional use of uppercase; spelling errors and missing of diacritic signals. A previous work (Hartmann et al. 2014) investigated the nature and the distribution of the 34,774 words of the corpus Buscapé not recognized by Unitex, a Brazilian Portuguese lexicon (Muniz et. al. 2005). The words for which only the diacritic signals were missing (3,652 or 10.2%) have been automatically corrected. Then, all the remaining words with more than 2 occurrences (5775) were classified in a double-blind annotation task, which obtained 0,752 of inter-annotator agreement (Kappa statistics, Carletta, 1996). The results obtained are shown in Table 1. Table 1. Non-Recognized Words with more than 2 occurrences in the corpus Common Portuguese misspelled words 44% Acronyms 5% Proper Nouns 24% Abbreviations 2% Internet Slang 4% Foreign words used in Portuguese 8% Units of Measurement 0% Other problems 13% Total 100% 23 The study reported herein aims to investigate The manual corrections of the sample were how some of these problems occur in the corpus made by a linguist who followed some rules and to what extent they may affect POS tagging. established in accordance with the project goals Future impr</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Carletta, J.: Assessing Agreement on Classification Tasks: The Kappa Statistic. Computational Linguistics, vol. 22, n. 2, pp. 249--254. (1996)</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Contractor</author>
<author>A Tanveer</author>
<author>L Faruquie</author>
<author>V Subramaniam</author>
</authors>
<title>Unsupervised cleansing of noisy text. Coling 2010: Poster Volume,</title>
<date>2010</date>
<pages>189--196</pages>
<location>Beijing,</location>
<contexts>
<context position="1416" citStr="Contractor et al., 2010" startWordPosition="211" endWordPosition="214">res to minimize them. 1. Introduction Corpus normalization has become a common challenge for everyone interested in processing a web corpus. Some normalization tasks are language and genre independent, like boilerplate removal and deduplication of texts. Others, like orthographic errors correction and internet slang handling, are not. Two approaches to web corpus normalization have been discussed in Web as a Corpus (WAC) literature. One of them is to tackle the task as a translation problem, being the web texts the source language and the normalized texts the target language (Aw et al., 2006; Contractor et al., 2010; Schlippe et al., 2013). Such approach requires a parallel corpus of original and normalized texts of reasonable size for training a system with acceptable accuracy. The other approach is to tackle the problem as a number of sub problems to be solved in sequence (Ringlstetter et al., 2006; Bildhauer &amp; Schäfer, 2013; Schäfer et al., 2013). The discussion we engage herein adopts the second approach and is motivated by the demand of preprocessing a Brazilian Portuguese web corpus constituted of products reviews for the specific purpose of building an opinion mining classifier and summarizer. Our</context>
</contexts>
<marker>Contractor, Tanveer, Faruquie, Subramaniam, 2010</marker>
<rawString>Contractor, D.; Tanveer A.; Faruquie; L.; Subramaniam, V. (2010). Unsupervised cleansing of noisy text. Coling 2010: Poster Volume, pages 189–196, Beijing, August 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Balage</author>
<author>P P</author>
<author>M S Duran</author>
<author>M G V Nunes</author>
<author>T Pardo</author>
<author>S Aluísio</author>
</authors>
<title>A Large Opinion Corpus in Portuguese -Tackling Out-Of-Vocabulary Words. In:</title>
<date>2014</date>
<booktitle>Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC 2014). Forthcoming.</booktitle>
<marker>Balage, P, Duran, Nunes, Pardo, Aluísio, 2014</marker>
<rawString>Hartmann, N. S.; Avanço. L.; Balage, P. P.; Duran, M. S.; Nunes, M. G. V.; Pardo, T.; Aluísio, S. (2014). A Large Opinion Corpus in Portuguese -Tackling Out-Of-Vocabulary Words. In: Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC 2014). Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lita</author>
<author>A Ittycheriah</author>
<author>S Roukos</author>
<author>N Kambhatla</author>
</authors>
<title>Truecasing, In:</title>
<date>2003</date>
<booktitle>Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="4960" citStr="Lita et al. (2003)" startWordPosition="786" endWordPosition="789"> as for example duplication of texts and boilerplates. The procedures that aim to adapt texts to render them more similar to standard texts are called normalization. Some normalization procedures like deduplication and boilerplate removal are less likely to cause destruction of relevant material. The problem arises when the noise category contains some forms that are ambiguous to other forms of the standard language. For example, the words “Oi” and “Claro” are the names of two Brazilian mobile network operators, but they are also common words (“oi” = hi; “claro” = clear). Cases like these led Lita et al. (2003) to consider case normalization as a problem of word sense disambiguation. Proper nouns which are derived from common nouns (hence, distinguished only by case) are one of the challenges for case normalization reported by Manning et al. (2008). Similar problem is reported by Bildhauer and Schäfer (2013) regarding dehyphenation, that is, the removal of hyphens used in typeset texts and commonly found in digitized texts. In German, there are many hyphenated words and the challenge is to remove noisy hyphens without affecting the correct ones. There are situations, however, in which both the corre</context>
<context position="13979" citStr="Lita et al, 2003" startWordPosition="2207" endWordPosition="2210">matic procedures to meet them. The processing of a new genre always poses a question: should we normalize the new genre to make it similar to the input expected by available automatic tools or should we adapt the existing tools to process the new genre? This is not a question of choice, indeed. We argue that both movements are needed. Furthermore, the processing of a new genre is an opportunity not only to make genre-adaptation, but also to improve general purpose features of NLP tools. 6.1 Case normalization: truecasing In NLP the problem of case normalization is usually called “truecasing” (Lita et al, 2003, Manning et al., 2008). The challenge is to decide when uppercase should be changed into lower case and when lower case should be changed into upper case. In brief, truecasing is the process of correcting case use in badly-cased or non-cased text. The problem is particularly relevant in two scenarios; speech recognition and informal web texts. We prioritized the case normalization for two reasons: first, badly-cased text seems to be a generalized problem in the genre of products reviews and, second, it is important to make case normalization before using a spell checker. This is crucial to “p</context>
<context position="18716" citStr="Lita et al. (2003)" startWordPosition="2988" endWordPosition="2991"> Nouns and Acronyms. For our purposes, however, all of them are named entities and need to be capitalized, so that this kind of disagreement did not affect the use we have made of the annotated words. (50.67%) and 44 (16.23%) were found in the metadata. Adding both types of named entities, we have a match of 44.85% (720 of 1605). This is pretty good mainly because the named entities recognized are precisely the names of products for which opinions will be mined. However, we still need to solve the recognition of the other named entities in order to support the truecasing strategies. Following Lita et al. (2003) and Beaufays and Strope (2013), we are considering using a language model. Lita et al. developed a truecaser for news articles, a genre more “stable” than products reviews. Beaufays and Strope, on their turn, developed a truecaser to tackle texts generated from speech recognition. Language modeling may be a good approach to our problem because many named entities of products domain do not sound as Portuguese words. For example, they frequently have the consonants k, y and w, which are only used in proper names in Portuguese. Other approaches to truecasing reported in the literature include fi</context>
</contexts>
<marker>Lita, Ittycheriah, Roukos, Kambhatla, 2003</marker>
<rawString>Lita, L., Ittycheriah, A., Roukos, S. &amp; Kambhatla,N. (2003), Truecasing, In: Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>P Raghavan</author>
<author>H Schütze</author>
</authors>
<title>Introduction to information retrieval (Vol. 1). Cambridge: Cambridge university press.</title>
<date>2008</date>
<contexts>
<context position="5202" citStr="Manning et al. (2008)" startWordPosition="824" endWordPosition="827">are less likely to cause destruction of relevant material. The problem arises when the noise category contains some forms that are ambiguous to other forms of the standard language. For example, the words “Oi” and “Claro” are the names of two Brazilian mobile network operators, but they are also common words (“oi” = hi; “claro” = clear). Cases like these led Lita et al. (2003) to consider case normalization as a problem of word sense disambiguation. Proper nouns which are derived from common nouns (hence, distinguished only by case) are one of the challenges for case normalization reported by Manning et al. (2008). Similar problem is reported by Bildhauer and Schäfer (2013) regarding dehyphenation, that is, the removal of hyphens used in typeset texts and commonly found in digitized texts. In German, there are many hyphenated words and the challenge is to remove noisy hyphens without affecting the correct ones. There are situations, however, in which both the corrected and the original text are desired. For example, social media corpora are plain of noises that express emotions, a rich material for sentiment analysis. For these cases, the non-destructive strategy proposed by Bildhauer and Schäfer (2013</context>
<context position="14002" citStr="Manning et al., 2008" startWordPosition="2211" endWordPosition="2214">o meet them. The processing of a new genre always poses a question: should we normalize the new genre to make it similar to the input expected by available automatic tools or should we adapt the existing tools to process the new genre? This is not a question of choice, indeed. We argue that both movements are needed. Furthermore, the processing of a new genre is an opportunity not only to make genre-adaptation, but also to improve general purpose features of NLP tools. 6.1 Case normalization: truecasing In NLP the problem of case normalization is usually called “truecasing” (Lita et al, 2003, Manning et al., 2008). The challenge is to decide when uppercase should be changed into lower case and when lower case should be changed into upper case. In brief, truecasing is the process of correcting case use in badly-cased or non-cased text. The problem is particularly relevant in two scenarios; speech recognition and informal web texts. We prioritized the case normalization for two reasons: first, badly-cased text seems to be a generalized problem in the genre of products reviews and, second, it is important to make case normalization before using a spell checker. This is crucial to “protect” Named Entities </context>
</contexts>
<marker>Manning, Raghavan, Schütze, 2008</marker>
<rawString>Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008). Introduction to information retrieval (Vol. 1). Cambridge: Cambridge university press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E</author>
</authors>
<title>UNITEX-PB, a set of flexible language resources for Brazilian Portuguese&amp;quot;,</title>
<date>2005</date>
<booktitle>Proceedings of the Workshop on Technology of Information and Human Language (TIL), São</booktitle>
<location>Leopoldo (Brazil): Unisinos.</location>
<marker>E, 2005</marker>
<rawString>Muniz, M.C.M.; Nunes, M.G.V.; Laporte. E. (2005) &amp;quot;UNITEX-PB, a set of flexible language resources for Brazilian Portuguese&amp;quot;, Proceedings of the Workshop on Technology of Information and Human Language (TIL), São Leopoldo (Brazil): Unisinos.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ringlstetter</author>
<author>K U Schulz</author>
<author>S Mihov</author>
</authors>
<title>Orthographic Errors in Web Pages: Toward Cleaner Web Corpora. In:</title>
<date>2006</date>
<booktitle>Computational Linguistics Volume 32, Number 3,</booktitle>
<pages>295--340</pages>
<contexts>
<context position="1706" citStr="Ringlstetter et al., 2006" startWordPosition="259" endWordPosition="262">correction and internet slang handling, are not. Two approaches to web corpus normalization have been discussed in Web as a Corpus (WAC) literature. One of them is to tackle the task as a translation problem, being the web texts the source language and the normalized texts the target language (Aw et al., 2006; Contractor et al., 2010; Schlippe et al., 2013). Such approach requires a parallel corpus of original and normalized texts of reasonable size for training a system with acceptable accuracy. The other approach is to tackle the problem as a number of sub problems to be solved in sequence (Ringlstetter et al., 2006; Bildhauer &amp; Schäfer, 2013; Schäfer et al., 2013). The discussion we engage herein adopts the second approach and is motivated by the demand of preprocessing a Brazilian Portuguese web corpus constituted of products reviews for the specific purpose of building an opinion mining classifier and summarizer. Our project also includes the task of adding a layer of semantic role labeling to the corpus. The roles will be assigned to nodes of the syntactic trees and, therefore, SRL subsumes the existence of layers of morphosyntactic and syntactic annotations. The annotated corpus will be used as trai</context>
</contexts>
<marker>Ringlstetter, Schulz, Mihov, 2006</marker>
<rawString>Ringlstetter, C.; Schulz, K. U. and Mihov, S. (2006). Orthographic Errors in Web Pages: Toward Cleaner Web Corpora. In: Computational Linguistics Volume 32, Number 3, p. 295-340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schäfer</author>
<author>A Barbaresi</author>
<author>F Bildhauer</author>
</authors>
<title>The Good, the Bad, and the Hazy: Design Decisions in Web Corpus Construction. In:</title>
<date>2013</date>
<booktitle>Proceedings of the 8th Web as Corpus Workshop (WAC-8).</booktitle>
<contexts>
<context position="1756" citStr="Schäfer et al., 2013" startWordPosition="267" endWordPosition="270">pproaches to web corpus normalization have been discussed in Web as a Corpus (WAC) literature. One of them is to tackle the task as a translation problem, being the web texts the source language and the normalized texts the target language (Aw et al., 2006; Contractor et al., 2010; Schlippe et al., 2013). Such approach requires a parallel corpus of original and normalized texts of reasonable size for training a system with acceptable accuracy. The other approach is to tackle the problem as a number of sub problems to be solved in sequence (Ringlstetter et al., 2006; Bildhauer &amp; Schäfer, 2013; Schäfer et al., 2013). The discussion we engage herein adopts the second approach and is motivated by the demand of preprocessing a Brazilian Portuguese web corpus constituted of products reviews for the specific purpose of building an opinion mining classifier and summarizer. Our project also includes the task of adding a layer of semantic role labeling to the corpus. The roles will be assigned to nodes of the syntactic trees and, therefore, SRL subsumes the existence of layers of morphosyntactic and syntactic annotations. The annotated corpus will be used as training corpus for a SRL classifier. The aim of SRL c</context>
</contexts>
<marker>Schäfer, Barbaresi, Bildhauer, 2013</marker>
<rawString>Schäfer, R.; Barbaresi, A.; Bildhauer, F. (2013) The Good, the Bad, and the Hazy: Design Decisions in Web Corpus Construction. In: Proceedings of the 8th Web as Corpus Workshop (WAC-8).</rawString>
</citation>
<citation valid="false">
<authors>
<author>T Schlippe</author>
<author>C Zhu</author>
<author>J Gebhardt</author>
</authors>
<title>T.(2013). Text Normalization based on Statistical Machine Translation and Internet User Support. In:</title>
<booktitle>Proceedings of The 38th International Conference on Acoustics, Speech, and Signal Processing (ICASSP-2013)</booktitle>
<pages>8406--841</pages>
<marker>Schlippe, Zhu, Gebhardt, </marker>
<rawString>Schlippe, T.; Zhu, C.; Gebhardt J.;, Schultz, T.(2013). Text Normalization based on Statistical Machine Translation and Internet User Support. In: Proceedings of The 38th International Conference on Acoustics, Speech, and Signal Processing (ICASSP-2013) p. 8406 – 841.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>