<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000140">
<title confidence="0.9995535">
Unsupervised Techniques for Extracting and Clustering Complex Events
in News
</title>
<author confidence="0.981422">
Delia Rusu ∗
</author>
<affiliation confidence="0.756012333333333">
Joˇzef Stefan Institute and
Joˇzef Stefan International
Postgraduate School
</affiliation>
<address confidence="0.613428">
Ljubljana, Slovenia
</address>
<email confidence="0.996055">
delia.rusu@ijs.si
</email>
<sectionHeader confidence="0.993853" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999607944444444">
Structured machine-readable representa-
tions of news articles can radically change
the way we interact with information. One
step towards obtaining these representa-
tions is event extraction - the identification
of event triggers and arguments in text.
With previous approaches mainly focus-
ing on classifying events into a small set of
predefined types, we analyze unsupervised
techniques for complex event extraction.
In addition to extracting event mentions in
news articles, we aim at obtaining a more
general representation by disambiguating
to concepts defined in knowledge bases.
These concepts are further used as features
in a clustering application. Two evalua-
tion settings highlight the advantages and
shortcomings of the proposed approach.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999797176470588">
Event extraction is a key prerequisite for gener-
ating structured, machine-readable representations
of natural language. Such representations can aid
various tasks like a) question answering, by en-
abling systems to provide results for more com-
plex queries, b) machine translation, by enhanc-
ing different translation models or c) novelty de-
tection, as a basis for computing geometric dis-
tances or distributional similarities. Event extrac-
tion primarily requires identifying what has oc-
curred and who or what was involved, as well as
the time interval of the occurrence. Additional
information related to the event mention may in-
clude its location. Moreover, the event mention
can also be labeled as belonging to a certain event
type. Generally speaking, the goal of event ex-
traction is to identify the event trigger, i.e. the
</bodyText>
<footnote confidence="0.668275">
∗The work was carried out while the first author was an
intern with Bloomberg Labs.
</footnote>
<note confidence="0.96878525">
James Hodson, Anthony Kimball
Bloomberg Labs
New York, NY, USA
{jhodson2,akimball2}
</note>
<email confidence="0.957034">
@bloomberg.net
</email>
<bodyText confidence="0.999945097560975">
words that most clearly define the event, and the
event arguments. For example, the event mention
{Hurricane Katrina struck the coast of New Or-
leans in August 2005} belonging to the occurrence
of natural disasters type of events includes the lo-
cation of the disaster - New Orleans and the time
of occurrence - August 2005. The event trigger is
the verb struck while the other words represent the
arguments of this event. The generalized form of
the event mention is {natural disaster occurred at
location on date}. Another similar event mention
is {Hurricane Katrina hit New Orleans}, having
the generalized form {natural disaster occurred
at location}. Both event mentions can be gener-
alized to {natural disaster occurred at location},
with the first event mention providing additional
details regarding the date of the occurrence.
Supervised approaches imply classifying ex-
tracted event mentions according to predefined
event types (Hong et al., 2011; Li et al., 2013).
Lexical databases such as FrameNet (Baker et
al., 1998), VerbNet (Schuler, 2005) or Prop-
Bank (Kingsbury and Palmer, 2002) can serve as
training data. However, the coverage of this data
is still limited, especially for domain-specific ap-
plications, and acquiring more labeled data can be
expensive. Unsupervised approaches, on the other
hand, are usually used to extract large numbers
of untyped events (Fader et al., 2011; Nakashole
et al., 2012; Alfonseca et al., 2013; Lewis and
Steedman, 2013). Despite the coverage of these
techniques, some of the extracted events can suf-
fer from reduced quality in terms of both precision
and recall. Distant supervision aims at mitigating
the disadvantages of both supervised and unsuper-
vised techniques by leveraging events defined in
knowledge bases (Mintz et al., 2009).
In this work we investigate unsupervised tech-
niques for extracting and clustering complex
events from news articles. For clustering events
we are using their generalized representation ob-
</bodyText>
<page confidence="0.95597">
26
</page>
<note confidence="0.4521725">
Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 26–34,
Baltimore, Maryland, USA, June 22-27, 2014. c�2014 Association for Computational Linguistics
</note>
<table confidence="0.778767153846154">
Event pattern Explanation Event mention
{entity1, verb, entity2} an event having two named en- {Obama, apologized for prob-
tities as arguments; verb modi-
fiers are also included
lems with, ACA rollout}
{sub, verb} a sequence of inter-related {Obama, apologized}
{sub, verb, obj} events having as arguments a
subject and an object
{Obama, offered, fix}
{sub, entity1, verb, obj, an event having a subject, an {Hurricane Katrina, struck,
entity2} object and two named entities
as arguments
coast, of New Orleans}
</table>
<tableCaption confidence="0.993437">
Table 1: Examples of extracted events from text, where the event triggers are underlined and named
entities are marked in bold.
</tableCaption>
<bodyText confidence="0.988661">
tained by disambiguating events to concepts de-
fined in knowledge bases. We are primarily look-
ing at Bloomberg news articles which have a par-
ticular writing style: complicated sentence struc-
tures and numerous dependencies between words.
In such cases a first challenge is to correctly iden-
tify the event trigger and all event arguments.
Moreover, an event is described in news in dif-
ferent ways. Therefore, a second challenge is
to capture the relations between event mentions.
Thirdly, Bloomberg news mainly focuses on fi-
nancial news reporting. Lexical databases such as
FrameNet are intended for the general domain and
do not cover most of the events described in finan-
cial news.
</bodyText>
<sectionHeader confidence="0.9721" genericHeader="introduction">
2 General Approach
</sectionHeader>
<bodyText confidence="0.99970719047619">
We propose the following pipeline for extracting
and clustering complex events from news articles.
Firstly, we identify events based on the output
of a dependency parser. Parsers can capture de-
pendencies between words belonging to different
clauses, enabling the detection of sequences of
inter-related events. Section 3 describes two com-
plementary approaches to event extraction which
leverage dependencies between verbs and short-
est paths between entities. Secondly, we obtain
more general representations of the events by an-
notating them with concepts defined in (multilin-
gual) knowledge bases (see Section 4). We refer
to such generalized events as complex events. The
knowledge base structure allows us to experiment
with different levels of generalization. As a final
step we apply a data-driven clustering algorithm to
group similar generalized events. Clustering can
be seen as an alternative to labeling events with
predefined event types. Details regarding the clus-
tering approach can be found in Section 5.
</bodyText>
<sectionHeader confidence="0.995551" genericHeader="method">
3 Event Extraction
</sectionHeader>
<bodyText confidence="0.9998959375">
Most of the previous unsupervised information ex-
traction techniques have been developed for iden-
tifying semantic relations (Fader et al., 2011;
Nakashole et al., 2012; Lewis and Steedman,
2013). These approaches extract binary relations
following the pattern {arg1, relation, arg2}. An
example of such a relation is {EBX Group Co.,
founder, Eike Batista}, with the arguments of the
founder relation being EBX Group Co. and Eike
Batista. Similar to relations, events also have ar-
guments such as named entities or time expres-
sions (Li et al., 2013). In addition to the argu-
ments, events are also characterized by the pres-
ence of an event trigger. In this work we consider
verbs as event triggers, and identify events follow-
ing the pattern:
</bodyText>
<equation confidence="0.74964">
{verb, arg1, arg2,...,arg,,,}I
</equation>
<bodyText confidence="0.999970125">
where arg1, arg2,...,arg,,, is the list of event ar-
guments. Aside from named entities and time ex-
pressions, we find additional valid argument can-
didates to be the subject or object of the clause.
Together with the verb we also include its mod-
ifiers. Table 1 lists a few examples of extracted
events.
In order to extract the events, we use the out-
put of a dependency parser. Dependency parsing
has been widely used for relation and event ex-
traction (Nakashole et al., 2012; Alfonseca et al.,
2013; Lewis and Steedman, 2013). There are vari-
ous publicly-available tools providing dependency
parse at the sentence level. We use the output
of ZPar (Zhang and Clark, 2011), which imple-
ments an incremental parsing process with the de-
</bodyText>
<page confidence="0.994074">
27
</page>
<figure confidence="0.999889913043478">
(a)
Last week Obama apologized for ... and offered a fix telling insurers they do n’t have to cancel plans next year
PERSON
ROOT
VMOD
VMOD
VMOD
VMOD
OBJ
VC
VMOD
VMOD
SUB VMOD NMODNMOD OBJ SUB
VMOD
VMOD
OBJ NMOD
NMOD
VC VMOD
ROOT
VMOD
VMOD
Last week Obama apologized for ... and offered a fix telling insurers they do n’t have to cancel plans next year
(b) VBD VBD VBG VBP VB VB
</figure>
<figureCaption confidence="0.9413775">
Figure 1: (a) Example sentence with highlighted word dependencies and named entities. (b) Example
sentence marked with dependencies between verbs.
</figureCaption>
<bodyText confidence="0.998054529411765">
coding based on the Beam Search algorithm. The
parser processes around 100 sentences per second
at above 90% F-score.
The sentences that we are analyzing have a
rather complex structure, with numerous depen-
dencies between words. An example sentence is
presented in Figure 1 (a). In this example there is
a sequence of inter-related events which share the
same subject: {Obama apologized} and {Obama
offered fix}. Such events cannot be captured us-
ing only simple pattern matching techniques like
the one implemented by REVERB (Fader et al.,
2011). Other relations that are hard to identify are
the lexically distant ones - this is the case with the
dependence between the verb apologized and the
verb offered. Consequently, we consider the fol-
lowing two complementary approaches to event
</bodyText>
<listItem confidence="0.8678906">
extraction, both of them based on the output of the
dependency parser:
1. Identifying verbs (including verb modifiers)
and their arguments,
2. Identifying shortest paths between entities.
</listItem>
<subsectionHeader confidence="0.986447">
3.1 Identifying Verbs and Their Arguments
</subsectionHeader>
<bodyText confidence="0.997921714285714">
In order to identify inter-related events we extract
dependency sub-trees for the verbs in the sentence.
The verb sub-trees also allow us to extend the ar-
gument list with missing arguments. This is the
case of the event mention {Obama offered fix},
where the subject Obama is missing.
The example sentence in Figure 1 (b) contains
two verb sub-trees, the first one including the
nodes apologized and offered and the second one
including the nodes telling, do, have and cancel.
Once the sub-trees are identified, we can augment
them with their corresponding arguments. For de-
termining the arguments we use the REVERB re-
lation pattern:
</bodyText>
<equation confidence="0.900194">
V |V P|V W*P,
</equation>
<bodyText confidence="0.9999626">
where V matches any verb, V P matches a verb
followed by a preposition and VW*P matches a
verb followed by one or more nouns, adjectives,
adverbs or pronouns and ending with a preposi-
tion.
</bodyText>
<subsectionHeader confidence="0.9969295">
3.2 Identifying Shortest Paths between
Entities
</subsectionHeader>
<bodyText confidence="0.9997845625">
Manual qualitative analysis of the events extracted
using the approach described in Subsection 3.1
suggests that the verbs and arguments patterns
do not cover all the events that are of interest to
us. This is the case of events where two or more
named entities are involved. For example, for the
sentence in Figure 1 (a) we identify the event men-
tions {Obama apologized} and {Obama offered
fix} using verb and argument patterns, but we can-
not identify the event mention {Obama apologized
for problems with ACA rollout} which includes
two named entities: Obama and ACA (Affordable
Healthcare Act). We therefore expand our set of
extracted events by identifying the shortest path
connecting all identified entities. This is similar
to the work of Bunescu and Mooney (2005) which
</bodyText>
<page confidence="0.995305">
28
</page>
<note confidence="0.698344">
PERSON AFFORDABLE HEALTH CARE ACT
</note>
<figureCaption confidence="0.970788">
Figure 2: An event mention {Obama apologized
</figureCaption>
<bodyText confidence="0.965644166666667">
for problems with ACA rollout} identified using
the shortest path between entities approach.
build shortest path dependency kernels for relation
extraction, where the shortest path connects two
named entities in text.
We first use the Stanford Named Entity Recog-
nizer (Finkel et al., 2005) to detect named entities
and temporal expressions in the sentence. Next,
we determine the shortest path in the dependency
tree linking these entities. An example entity pat-
tern discovered using this approach is shown in
Figure 2.
</bodyText>
<sectionHeader confidence="0.995805" genericHeader="method">
4 Event Disambiguation
</sectionHeader>
<bodyText confidence="0.999948928571429">
We disambiguate the events by annotating each
word with WordNet (Fellbaum, 2005) super-
senses and BabelNet (Navigli and Ponzetto, 2012)
senses and hypernyms. WordNet super-senses of-
fer the highest level of generalization for events,
followed by BabelNet hypernyms and BabelNet
senses. The choice of annotating with Word-
Net concepts is motivated by its wide usage as
a knowledge base covering the common English
vocabulary. There are 41 WordNet super-sense
classes defined for nouns and verbs. Table 2 de-
picts example WordNet super-senses with a short
description.
Previous work on annotating text with WordNet
super-senses mainly used supervised techniques.
Ciaramita and Altun (2006) propose a sequential
labeling approach and train a discriminative Hid-
den Markov Model. Lacking labeled data we in-
vestigate simple unsupervised techniques. Firstly,
we take into account the first sense heuristic which
chooses, from all the possible senses for a given
word, the sense which is most frequent in a given
corpus. The first sense heuristic has been used
as a baseline in many evaluation settings, and it
is hard to overcome for unsupervised disambigua-
tion algorithms (Navigli, 2009). Secondly, we use
a kernel to compute the similarity between the sen-
tence and the super-sense definition. If x and y are
</bodyText>
<table confidence="0.999342">
Super-sense Description
communi- communicative processes
cation.noun and contents
quantity.noun quantities and units of mea-
possession.noun sure
possession and transfer of
possession
possession.verb buying, selling, owning
motion.verb walking, flying, swimming
stative.verb being, having, spatial rela-
tions
</table>
<tableCaption confidence="0.9525875">
Table 2: Example noun and verb super-sense la-
bels and descriptions taken from WordNet.
</tableCaption>
<bodyText confidence="0.9760305">
row vectors representing normalized counts of the
words in the sentence and the words in the super-
sense definition, respectively, the kernel is defined
as:
</bodyText>
<equation confidence="0.97934">
xyT
k(x, y) = �x� �y�
</equation>
<bodyText confidence="0.999867222222222">
BabelNet is a multilingual knowledge base,
mainly integrating concepts from WordNet and
Wikipedia. The current version 2.0 contains 50
languages. We use the BabelNet 1.0.1 knowledge
base and API to disambiguate words. As a start-
ing point we consider the PageRank-based disam-
biguation algorithm provided by the API, but fu-
ture work should investigate other graph-based al-
gorithms.
</bodyText>
<sectionHeader confidence="0.992875" genericHeader="method">
5 Event Clustering
</sectionHeader>
<bodyText confidence="0.993468142857143">
Events are clustered based on the features they
have in common. We aim at obtaining clusters for
the two types of extracted events: verbs and their
arguments and shortest paths between entities in
the dependency tree. The following two event pat-
terns are considered for this experiment, for both
event patterns: {sub, verb, obj} and {sub, verb,
obj, entities}, where the verb and arguments can
appear in the sentence in any order. Each event is
described using a set of features. These features
are extracted for the arguments of each event: the
sub, obj and entities. The following feature com-
binations are used for each argument in the event
argument list:
</bodyText>
<listItem confidence="0.998309">
• WordNet super-senses,
• BabelNet senses,
</listItem>
<figure confidence="0.721782571428571">
ACA rollout
Obama apologized for the problems with the
PMOD
PMOD
SUB VMOD
NMOD
NMOD
</figure>
<page confidence="0.979549">
29
</page>
<listItem confidence="0.989279">
• BabelNet hypernyms,
• WordNet super-senses, BabelNet senses and
hypernyms.
</listItem>
<bodyText confidence="0.92274696">
For the WordNet experiments we include both
disambiguation techniques - using the first sense
heuristic and the kernel for determining the sim-
ilarity between the sentence and the super-sense
definition. Similar to the WordNet disambigua-
tion approach we generate vectors for each event,
where a vector x includes normalized counts of the
argument features for the specific event. Thus we
can determine the similarity between two events
using the kernel defined in Section 4.
The Chinese Whispers algorithm (Biemann,
2006) presented in Algorithm 1 is used to cluster
the events. We opted for this graph-clustering al-
gorithm due to the fact that it is scalable and non-
parametric. The highest rank class in the neigh-
borhood of a given event ez is the class of the event
most similar to ez.
Data: set of events E
Result: class labels for events in E
for ez E E do class(ez) = i;
while not converged do
randomize order of events in E;
for ez E E do
class(ez) = highest ranked class in
the neighborhood of ez;
</bodyText>
<listItem confidence="0.516066666666667">
end
end
Algorithm 1: Chinese Whispers Algorithm.
</listItem>
<sectionHeader confidence="0.993592" genericHeader="method">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999994363636364">
We evaluated the extracted events, as well as the
clusters obtained for the disambiguated events.
For each set of experiments we prepared a dataset
by sampling Bloomberg news articles.
As there is no benchmark dataset for the news
articles that we are analyzing, we propose to eval-
uate event extraction in terms of completeness.
Clustering evaluation is done based on the model
itself, and for different feature combinations. In
what follows we describe the evaluation setting in
more detail.
</bodyText>
<subsectionHeader confidence="0.988924">
6.1 Event Extraction Evaluation
</subsectionHeader>
<bodyText confidence="0.999977956521739">
The evaluation dataset consists of a sample of 23
stories belonging to the MEDICARE topic, con-
taining a total of 1088 sentences. The event ex-
traction algorithms yields 229 entity paths and 515
verb and argument events. Each event is assessed
in terms of completeness; an event is deemed to
be complete if all event elements (the event trigger
and the arguments) are correctly identified. We
only analyze two event patterns: {sub, verb, obj}
and {sub, verb, obj, entities}, as events belong-
ing to other patterns are rather noisy. Two anno-
tators independently rate each event with 1 if all
event elements are correctly identified, and 0 oth-
erwise. Note that incomplete events receive a 0
score. Cohen’s kappa coefficient (Cohen, 1960)
of inter-annotator agreement for this experiment
was 0.70. The entity path approach correctly iden-
tified 78.6% of the entities while the verb argu-
ments approach identified 69.1% of the events.
Events obtained using entity paths tend to have a
higher number of arguments compared to the verb
arguments approach; this explains the higher score
obtained by this technique.
</bodyText>
<subsectionHeader confidence="0.99973">
6.2 Clustering Evaluation
</subsectionHeader>
<bodyText confidence="0.999892428571428">
As we do not know the cluster labels a priori, we
opt for evaluating the clusters using the model it-
self. To this end, we use the Silhouette Coeffi-
cient (Kaufman and Rousseeuw, 1990); we plan to
investigate other clustering evaluation metrics in
future work. The Silhouette Coefficient is defined
for each sample, and it incorporates two scores:
</bodyText>
<equation confidence="0.886892">
s = max(a, b),
</equation>
<bodyText confidence="0.999989722222222">
where a is the mean distance between a sample
and all other points within the same class whereas
b is the mean distance to all other points in the
next nearest class. To determine the coefficient for
a set of samples one needs to find the mean of the
coefficient for each sample. A higher coefficient
score is associated with a model having better de-
fined clusters. The best clustering model will ob-
tain a Silhouette coefficient of 1, while the worst
one will obtain a -1 score. Values close to 0 imply
overlapping clusters. Negative values signify that
the model assigned samples to the wrong cluster,
as a different cluster is more similar.
The evaluation dataset comprises 325 MEDI-
CARE news articles and 16,450 sentences. In
this dataset we identify 7,491 verb and argument
events and 2,046 shortest path events. Table 3
shows example events belonging to two event
</bodyText>
<figure confidence="0.906033">
b − a
</figure>
<page confidence="0.791446">
30
</page>
<figureCaption confidence="0.9836425">
Figure 3: Clustering evaluation results for verbs and arguments (left) and shortest paths between entities
(right) events, using different feature combinations.
</figureCaption>
<bodyText confidence="0.9972036">
clusters. The first cluster is obtained by extract-
ing verb argument events while the second cluster
is composed of shortest entity path events.
In Figure 3 we show clustering evaluation re-
sults for the (a) verbs and arguments and (b) short-
est paths between entities, using different feature
combinations. As expected, the best results are
obtained in the case of the WordNet super-senses,
which are the most generic senses assigned to the
events. There is less overlap among the BabelNet
senses and hypernyms, although results improve
as more data is available. The results also mark the
difference between the two types of events: verbs
and arguments versus shortest paths between en-
tities. Events extracted using the entity path ap-
proach tend to have a higher number of arguments,
which in turn implies a richer set of features. This
explains the higher scores obtained in the case of
shortest path events compared to verb argument
events.
</bodyText>
<sectionHeader confidence="0.999812" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.990257191489362">
The event extraction task have received a lot of at-
tention in recent years, and numerous approaches,
both supervised and unsupervised, have been pro-
posed. This section attempts to summarize the
main findings.
Supervised approaches. These approaches
classify events based on a number of predefined
event types. A popular dataset is the NIST Au-
tomatic Content Extraction (ACE) corpora (Dod-
dington et al., 2004) which consists of labeled
relations and events in text. State-of-the-art ap-
proaches mainly use sequential pipelines to sep-
arately identify the event trigger and the argu-
ments (Hong et al., 2011). More recently Li
et al. (2013) propose a joint framework which
considers event triggers and arguments together.
Their model is based on structured perceptron with
Beam Search. In another line of work (Alfonseca
et al., 2013) events extracted in an unsupervised
manner from the output of a dependency parser
are the building blocks of a Noisy-OR model for
headline generation. Tannier and Moriceau (2013)
identify event threads in news, i.e. a succession of
events in a story, using a cascade of classifiers.
Mintz et al. (2009) propose a distant supervi-
sion approach. They use Freebase relations and
find sentences which contain entities appearing in
these relations. From the sentences the authors ex-
tract a number of textual features which are used
for relation classification. Dependency parsing
features are used to identify relations that are lex-
ically distant.
Unsupervised approaches. Most unsuper-
vised approaches have been tailored to identify-
ing relations in text. Fader et al. (2011) extract
relations and their arguments based on part-of-
speech patterns. However, such patterns fail to
detect lexically distant relations between words.
Therefore, most state-of-the-art unsupervised ap-
proaches also rely on sentence parsing. For ex-
ample, Lewis and Steedman (2013) extract cross-
lingual semantic relations from the English and
French parses of sentences. Relational patterns ex-
tracted from the sentence parse tree have also been
generalized to syntactic-ontologic-lexical patterns
using a frequent itemset mining approach (Nakas-
hole et al., 2012). Poon and Domingos (2009)
</bodyText>
<page confidence="0.99973">
31
</page>
<table confidence="0.999596307692308">
Event Features
{owners are being incen- noun.person
tivized to drop their health noun.possession
insurance coverage}
{analysts are not permit- noun.person
ted receive compensation noun.possession
directly}
{HHS General issued re- noun.person
port in July 2013} noun.group
noun.time
{lawmakers asked Kath- noun.person
leen Sebelius to respond by noun.time
December 6}
</table>
<tableCaption confidence="0.756406">
Table 3: Example events belonging to two event
clusters. Each event is assigned WordNet super-
sense features.
</tableCaption>
<bodyText confidence="0.999312032258065">
learn a semantic parser using Markov logic by
converting dependency trees into quasi-logical
forms which are clustered.
DIRT (Lin and Pantel, 2001) is an unsuper-
vised method for discovering inference rules from
text. The authors leverage the dependency parse
of a sentence in order to extract indirect seman-
tic relations of the form ”X relation Y ” between
two words X and Y . Inference rules such as ”X
relation1 Y ≈ X relation2 Y ” are determined
based on the similarity of the relations.
ALICE (Banko and Etzioni, 2007) is a sys-
tem that iteratively discovers concepts, relations
and their generalizations from the Web. The sys-
tem uses a data-driven approach to expand the core
concepts defined by the WordNet lexical database
with instances from its Web corpus. These in-
stances are identified by applying predefined ex-
traction patterns. The relations extracted using
TextRunner (Banko et al., 2007) are generalized
using a clustering-based approach.
Our aim is to identify events rather than any re-
lation between two concepts. We therefore pro-
pose different extraction patterns based on the de-
pendency parse of a sentence which allow us to de-
tect event triggers and event arguments that can be
lexically distant. Events are generalized by map-
ping them to concepts from two different knowl-
edge bases (WordNet and BabelNet), allowing us
to experiment with multiple levels of generaliza-
tion.
</bodyText>
<sectionHeader confidence="0.987633" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999881111111111">
In this work we investigated different unsuper-
vised techniques for extracting and clustering
complex events from news articles. As a first
step we proposed two complementary event ex-
traction algorithms, based on identifying verbs and
their arguments and shortest paths between enti-
ties, respectively. Next, we obtained more gen-
eral representations of the event mentions by an-
notating the event trigger and arguments with con-
cepts from knowledge bases. The generalized ar-
guments were used as features for a clustering ap-
proach, thus determining related events.
As future work on the event extraction side,
we plan to improve event quality by learning a
model for filtering out noisy events. In the case
of event disambiguation we are looking into dif-
ferent graph-based disambiguation algorithms to
enhance concept annotations.
</bodyText>
<sectionHeader confidence="0.998559" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99997">
We would like to thank Pierre Brunelle and Kon-
stantine Arkoudas as well as the anonymous re-
viewers for their helpful comments. This work
was funded by Bloomberg LP and the ICT Pro-
gramme of the EC under XLike (ICT-STREP-
288342).
</bodyText>
<sectionHeader confidence="0.997013" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987958913043478">
[Alfonseca et al.2013] Enrique Alfonseca, Daniele
Pighin, and Guillermo Garrido. 2013. Heady:
News headline abstraction through event pattern
clustering. In Proceedings of the 51st Annual
Meeting of the Association for Computational
Linguistics, pages 1243–1253.
[Baker et al.1998] Collin F Baker, Charles J Fillmore,
and John B Lowe. 1998. The Berkeley Framenet
Project. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Compu-
tational Linguistics-Volume 1, pages 86–90. Associ-
ation for Computational Linguistics.
[Banko and Etzioni2007] Michele Banko and Oren Et-
zioni. 2007. Strategies for lifelong knowledge ex-
traction from the web. In Proceedings of the 4th in-
ternational conference on Knowledge capture, pages
95–102. ACM.
[Banko et al.2007] Michele Banko, Michael J Ca-
farella, Stephen Soderland, Matthew Broadhead,
and Oren Etzioni. 2007. Open information extrac-
tion for the web. In IJCAI, volume 7, pages 2670–
2676.
</reference>
<page confidence="0.993604">
32
</page>
<reference confidence="0.997941522123894">
[Biemann2006] Chris Biemann. 2006. Chinese whis-
pers: an efficient graph clustering algorithm and its
application to natural language processing problems.
In Proceedings of the first workshop on graph based
methods for natural language processing, pages 73–
80. Association for Computational Linguistics.
[Bunescu and Mooney2005] Razvan C Bunescu and
Raymond J Mooney. 2005. A shortest path depen-
dency kernel for relation extraction. In Proceedings
of the conference on Human Language Technology
and Empirical Methods in Natural Language Pro-
cessing, pages 724–731. Association for Computa-
tional Linguistics.
[Ciaramita and Altun2006] Massimiliano Ciaramita
and Yasemin Altun. 2006. Broad-coverage sense
disambiguation and information extraction with a
supersense sequence tagger. In Proceedings of the
2006 Conference on Empirical Methods in Natural
Language Processing, pages 594–602. Association
for Computational Linguistics.
[Cohen1960] Jacob Cohen. 1960. A coefficient of
agreement for nominal scales. Educational and Psy-
chological Measurement, 20(1):37–46.
[Doddington et al.2004] George R Doddington, Alexis
Mitchell, Mark A Przybocki, Lance A Ramshaw,
Stephanie Strassel, and Ralph M Weischedel. 2004.
The automatic content extraction (ace) program-
tasks, data, and evaluation. In LREC.
[Fader et al.2011] Anthony Fader, Stephen Soderland,
and Oren Etzioni. 2011. Identifying relations for
open information extraction. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1535–1545. Association
for Computational Linguistics.
[Fellbaum2005] Christiane Fellbaum. 2005. Wordnet
and wordnets. In Keith et al. Brown, editor, Ency-
clopedia of Language and Linguistics, pages 665–
670. Oxford: Elsevier, second edition.
[Finkel et al.2005] Jenny Rose Finkel, Trond Grenager,
and Christopher Manning. 2005. Incorporating
non-local information into information extraction
systems by gibbs sampling. In Proceedings of the
43rd Annual Meeting on Association for Computa-
tional Linguistics, pages 363–370. Association for
Computational Linguistics.
[Hong et al.2011] Yu Hong, Jianfeng Zhang, Bin Ma,
Jianmin Yao, Guodong Zhou, and Qiaoming Zhu.
2011. Using cross-entity inference to improve event
extraction. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies-Volume 1,
pages 1127–1136. Association for Computational
Linguistics.
[Kaufman and Rousseeuw1990] Leonard Kaufman and
Peter J Rousseeuw. 1990. Finding groups in data:
an introduction to cluster analysis. John Wiley &amp;
Sons.
[Kingsbury and Palmer2002] Paul Kingsbury and
Martha Palmer. 2002. From treebank to propbank.
In Proceedings of the International Conference on
Language Resources and Evaluation LREC.
[Lewis and Steedman2013] Mike Lewis and Mark
Steedman. 2013. Unsupervised induction of cross-
lingual semantic relations. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing EMNLP, pages 681–692.
[Li et al.2013] Qi Li, Heng Ji, and Liang Huang. 2013.
Joint event extraction via structured prediction with
global features. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics.
[Lin and Pantel2001] Dekang Lin and Patrick Pantel.
2001. Dirt - discovery of inference rules from text.
In Proceedings of the seventh ACM SIGKDD in-
ternational conference on Knowledge discovery and
data mining, pages 323–328. ACM.
[Mintz et al.2009] Mike Mintz, Steven Bills, Rion
Snow, and Dan Jurafsky. 2009. Distant supervision
for relation extraction without labeled data. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP: Volume 2, pages 1003–1011. Association
for Computational Linguistics.
[Nakashole et al.2012] Ndapandula Nakashole, Ger-
hard Weikum, and Fabian Suchanek. 2012. Patty: a
taxonomy of relational patterns with semantic types.
In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learn-
ing, pages 1135–1145. Association for Computa-
tional Linguistics.
[Navigli and Ponzetto2012] Roberto Navigli and Si-
mone Paolo Ponzetto. 2012. Babelnet: The auto-
matic construction, evaluation and application of a
wide-coverage multilingual semantic network. Arti-
ficialIntelligence, 193:217–250.
[Navigli2009] Roberto Navigli. 2009. Word sense dis-
ambiguation: A survey. ACM Computing Surveys
(CSUR), 41(2):10.
[Poon and Domingos2009] Hoifung Poon and Pedro
Domingos. 2009. Unsupervised semantic parsing.
In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1-Volume 1, pages 1–10. Association for Computa-
tional Linguistics.
[Schuler2005] Karin Kipper Schuler. 2005. Verbnet: A
broad-coverage, comprehensive verb lexicon.
[Tannier and Moriceau2013] Xavier Tannier and
V´eronique Moriceau. 2013. Building event threads
out of multiple news articles. Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing EMNLP.
</reference>
<page confidence="0.985691">
33
</page>
<reference confidence="0.97363075">
[Zhang and Clark2011] Yue Zhang and Stephen Clark.
2011. Syntactic processing using the generalized
perceptron and beam search. Computational Lin-
guistics, 37(1):105–151.
</reference>
<page confidence="0.999296">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.292436">
<title confidence="0.9972505">Unsupervised Techniques for Extracting and Clustering Complex Events in News</title>
<author confidence="0.652084333333333">Rusu Joˇzef Stefan Institute</author>
<author confidence="0.652084333333333">Joˇzef Stefan International</author>
<affiliation confidence="0.957489">Postgraduate School</affiliation>
<address confidence="0.975">Ljubljana, Slovenia</address>
<email confidence="0.996973">delia.rusu@ijs.si</email>
<abstract confidence="0.998018210526316">Structured machine-readable representations of news articles can radically change the way we interact with information. One step towards obtaining these representations is event extraction the identification of event triggers and arguments in text. With previous approaches mainly focusing on classifying events into a small set of predefined types, we analyze unsupervised techniques for complex event extraction. In addition to extracting event mentions in news articles, we aim at obtaining a more general representation by disambiguating to concepts defined in knowledge bases. These concepts are further used as features in a clustering application. Two evaluation settings highlight the advantages and shortcomings of the proposed approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Enrique Alfonseca</author>
<author>Daniele Pighin</author>
<author>Guillermo Garrido</author>
</authors>
<title>Heady: News headline abstraction through event pattern clustering.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1243--1253</pages>
<marker>[Alfonseca et al.2013]</marker>
<rawString>Enrique Alfonseca, Daniele Pighin, and Guillermo Garrido. 2013. Heady: News headline abstraction through event pattern clustering. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1243–1253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley Framenet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics-Volume 1,</booktitle>
<pages>86--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Baker et al.1998]</marker>
<rawString>Collin F Baker, Charles J Fillmore, and John B Lowe. 1998. The Berkeley Framenet Project. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics-Volume 1, pages 86–90. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
</authors>
<title>Strategies for lifelong knowledge extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th international conference on Knowledge capture,</booktitle>
<pages>95--102</pages>
<publisher>ACM.</publisher>
<marker>[Banko and Etzioni2007]</marker>
<rawString>Michele Banko and Oren Etzioni. 2007. Strategies for lifelong knowledge extraction from the web. In Proceedings of the 4th international conference on Knowledge capture, pages 95–102. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matthew Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction for the web. In</title>
<date>2007</date>
<booktitle>IJCAI,</booktitle>
<volume>7</volume>
<pages>2670--2676</pages>
<marker>[Banko et al.2007]</marker>
<rawString>Michele Banko, Michael J Cafarella, Stephen Soderland, Matthew Broadhead, and Oren Etzioni. 2007. Open information extraction for the web. In IJCAI, volume 7, pages 2670– 2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Biemann</author>
</authors>
<title>Chinese whispers: an efficient graph clustering algorithm and its application to natural language processing problems.</title>
<date>2006</date>
<booktitle>In Proceedings of the</booktitle>
<marker>[Biemann2006]</marker>
<rawString>Chris Biemann. 2006. Chinese whispers: an efficient graph clustering algorithm and its application to natural language processing problems. In Proceedings of the first workshop on graph based methods for natural language processing, pages 73– 80. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>724--731</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Bunescu and Mooney2005]</marker>
<rawString>Razvan C Bunescu and Raymond J Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 724–731. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Yasemin Altun</author>
</authors>
<title>Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>594--602</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Ciaramita and Altun2006]</marker>
<rawString>Massimiliano Ciaramita and Yasemin Altun. 2006. Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 594–602. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>20--1</pages>
<marker>[Cohen1960]</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20(1):37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George R Doddington</author>
<author>Alexis Mitchell</author>
<author>Mark A Przybocki</author>
<author>Lance A Ramshaw</author>
<author>Stephanie Strassel</author>
<author>Ralph M Weischedel</author>
</authors>
<title>The automatic content extraction (ace) programtasks, data, and evaluation.</title>
<date>2004</date>
<booktitle>In LREC.</booktitle>
<marker>[Doddington et al.2004]</marker>
<rawString>George R Doddington, Alexis Mitchell, Mark A Przybocki, Lance A Ramshaw, Stephanie Strassel, and Ralph M Weischedel. 2004. The automatic content extraction (ace) programtasks, data, and evaluation. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1535--1545</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Fader et al.2011]</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1535–1545. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>Wordnet and wordnets.</title>
<date>2005</date>
<booktitle>Encyclopedia of Language and Linguistics,</booktitle>
<pages>665--670</pages>
<editor>In Keith et al. Brown, editor,</editor>
<publisher>Elsevier,</publisher>
<location>Oxford:</location>
<note>second edition.</note>
<marker>[Fellbaum2005]</marker>
<rawString>Christiane Fellbaum. 2005. Wordnet and wordnets. In Keith et al. Brown, editor, Encyclopedia of Language and Linguistics, pages 665– 670. Oxford: Elsevier, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Finkel et al.2005]</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363–370. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Hong</author>
<author>Jianfeng Zhang</author>
<author>Bin Ma</author>
<author>Jianmin Yao</author>
<author>Guodong Zhou</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Using cross-entity inference to improve event extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1127--1136</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Hong et al.2011]</marker>
<rawString>Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao, Guodong Zhou, and Qiaoming Zhu. 2011. Using cross-entity inference to improve event extraction. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1127–1136. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Kaufman</author>
<author>Peter J Rousseeuw</author>
</authors>
<title>Finding groups in data: an introduction to cluster analysis.</title>
<date>1990</date>
<publisher>John Wiley &amp; Sons.</publisher>
<marker>[Kaufman and Rousseeuw1990]</marker>
<rawString>Leonard Kaufman and Peter J Rousseeuw. 1990. Finding groups in data: an introduction to cluster analysis. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>From treebank to propbank.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation LREC.</booktitle>
<marker>[Kingsbury and Palmer2002]</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2002. From treebank to propbank. In Proceedings of the International Conference on Language Resources and Evaluation LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>Unsupervised induction of crosslingual semantic relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing EMNLP,</booktitle>
<pages>681--692</pages>
<marker>[Lewis and Steedman2013]</marker>
<rawString>Mike Lewis and Mark Steedman. 2013. Unsupervised induction of crosslingual semantic relations. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing EMNLP, pages 681–692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Heng Ji</author>
<author>Liang Huang</author>
</authors>
<title>Joint event extraction via structured prediction with global features.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>[Li et al.2013]</marker>
<rawString>Qi Li, Heng Ji, and Liang Huang. 2013. Joint event extraction via structured prediction with global features. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Dirt - discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>323--328</pages>
<publisher>ACM.</publisher>
<marker>[Lin and Pantel2001]</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Dirt - discovery of inference rules from text. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 323–328. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Mintz et al.2009]</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Gerhard Weikum</author>
<author>Fabian Suchanek</author>
</authors>
<title>Patty: a taxonomy of relational patterns with semantic types.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1135--1145</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Nakashole et al.2012]</marker>
<rawString>Ndapandula Nakashole, Gerhard Weikum, and Fabian Suchanek. 2012. Patty: a taxonomy of relational patterns with semantic types. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1135–1145. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Babelnet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. ArtificialIntelligence,</title>
<date>2012</date>
<marker>[Navigli and Ponzetto2012]</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. Babelnet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. ArtificialIntelligence, 193:217–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys (CSUR),</journal>
<volume>41</volume>
<issue>2</issue>
<marker>[Navigli2009]</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Computing Surveys (CSUR), 41(2):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Poon and Domingos2009]</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2009. Unsupervised semantic parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 1–10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper Schuler</author>
</authors>
<title>Verbnet: A broad-coverage, comprehensive verb lexicon.</title>
<date>2005</date>
<marker>[Schuler2005]</marker>
<rawString>Karin Kipper Schuler. 2005. Verbnet: A broad-coverage, comprehensive verb lexicon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Tannier</author>
<author>V´eronique Moriceau</author>
</authors>
<title>Building event threads out of multiple news articles.</title>
<date>2013</date>
<booktitle>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing EMNLP.</booktitle>
<marker>[Tannier and Moriceau2013]</marker>
<rawString>Xavier Tannier and V´eronique Moriceau. 2013. Building event threads out of multiple news articles. Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Syntactic processing using the generalized perceptron and beam search.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<marker>[Zhang and Clark2011]</marker>
<rawString>Yue Zhang and Stephen Clark. 2011. Syntactic processing using the generalized perceptron and beam search. Computational Linguistics, 37(1):105–151.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>