<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.975759">
Incremental semantic scales by strings
</title>
<author confidence="0.996896">
Tim Fernando
</author>
<affiliation confidence="0.83256">
Computer Science Department
Trinity College Dublin
Dublin, Ireland
</affiliation>
<email confidence="0.982758">
Tim.Fernando@tcd.ie
</email>
<sectionHeader confidence="0.994457" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999881875">
Scales for natural language semantics are
analyzed as moving targets, perpetually
under construction and subject to ad-
justment. Projections, factorizations and
constraints are described on strings of
bounded but refinable granularities, shap-
ing types by the processes that put seman-
tics in flux.
</bodyText>
<sectionHeader confidence="0.998429" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993737787234043">
An important impetus for recent investigations
into type theory for natural language semantics is
the view of “semantics in flux,” correcting “the im-
pression” from, for example, Montague 1973 “of
natural languages as being regimented with mean-
ings determined once and for all” (Cooper 2012,
page 271). The present work concerns scales
for temporal expressions and gradable predicates.
Two questions that loom large from the perspec-
tive of semantics in flux are: how to construct
scales and align them against one another (e.g.
Klein and Rovatsos 2011). The formal study car-
ried out below keeps scales as simple as possi-
ble, whilst allowing for necessary refinements and
adjustments. The basic picture is that a scale is
a moving target finitely approximable as a string
over an alphabet which we can expand to refine
granularity. Reducing a scale to a string comes,
however, at a price; indivisible points must give
way to refinable intervals (embodying underspec-
ification).
Arguments for a semantic reorientation around
intervals (away from points) are hardly new. Best
known within linguistic semantics perhaps are
those in tense and aspect from Bennett and Partee
1972, which seem to have met less resistance than
arguments in the degree literature from Kennedy
2001 and Schwarzschild and Wilkinson 2002 (see
Solt 2013). At the center of the present argument
for intervals is a notion of finite approximabil-
ity, plausibly related to cognition. What objection
might there be to it? The fact that no finite lin-
ear order is dense raises the issue of compatibility
between finite approximability and density — no
small worry, given the popularity of dense linear
orders for time (e.g. Kamp and Reyle 1993, Pratt-
Hartmann 2005, Klein 2009) as well as measure-
ment (e.g. Fox and Hackl 2006).
Fortunately, finite linear orders can be orga-
nized into a system of approximations converging
at the limit to a dense linear order. The present
work details ways to form such systems and lim-
its, with density reanalyzed as refinability of ar-
bitrary finite approximations. A familiar example
provides some orientation.
Example A (calendar) We can represent a cal-
endar year as the string
</bodyText>
<note confidence="0.666239">
smo := Jan Feb Mar ··· Dec
</note>
<bodyText confidence="0.9782335">
of length 12, or, were we interested also in days
d1,d2...,d31, the string
</bodyText>
<equation confidence="0.9971055">
smo,dy := Jan,d1 Jan,d2 · · · Jan,d31
Feb,d1 · · · Dec,d31
</equation>
<bodyText confidence="0.9991725">
of length 365 for a non-leap year (Fernando
2011).1 In contrast to the points in the real line
R, a box can split, as Jan in smo does (30 times)
to
</bodyText>
<equation confidence="0.693435">
Jan,d1 Jan,d2 · · · Jan,d31
</equation>
<bodyText confidence="0.968613333333333">
in smo,dy, on introducing days d1, d2,..., d31
into the picture. Reversing direction and gener-
alizing from
</bodyText>
<footnote confidence="0.8314245">
mo := {Jan,Feb,...Dec}
1We draw boxes (instead of the usual curly braces { and })
around sets-as-symbols, stringing together “snapshots” much
like a cartoon/film strip.
</footnote>
<page confidence="0.984192">
63
</page>
<note confidence="0.993287">
Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 63–71,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.562129571428571">
to any set A, we define the function ρA on strings
(of sets) to componentwise intersect with A
ρA(α1 ··· αn) := (α1 ∩ A) ··· (αn ∩ A)
(throwing out non-A’s from each box) so that
the componentwise unions of strings α1 · · · αn and
β1 · · · βn of the same number n of sets for their su-
perposition
</bodyText>
<equation confidence="0.9927845">
α1 ··· αn &amp; β1 ··· βn := (α1 ∪ β1) ··· (αn ∪ βn)
ρmo(smo,dy) =
</equation>
<bodyText confidence="0.997053333333333">
Next, the block compression bc(s) of a string s
compresses all repeating blocks αn (for n ≥ 1)
of a box α in a string s to α for
</bodyText>
<equation confidence="0.99181425">
bc(αs0) if s = ααs0
α bc(βs0) if s = αβs0 with
α =6β
s otherwise
</equation>
<bodyText confidence="0.96446">
so that if bc(s) = α1 · · · αn then αi =6 αi+1 for i
from 1 to n − 1. In particular,
bc( Jan 31 Feb 28 · · · Dec 31) = smo.
Writing bcA for the function mapping s to
bc(ρA(s)), we have
</bodyText>
<equation confidence="0.923176">
bcmo(smo,dy) = smo.
</equation>
<bodyText confidence="0.734008666666667">
In general, we can refine a string sA of granu-
larity A to one sA0 of granularity A0 ⊇ A with
bcA(sA0) = sA. Iterating over a chain
</bodyText>
<equation confidence="0.8955896">
A ⊆ A0 ⊆ A00 ⊆ ···,
we can glue together strings sA, sA0, sA00, ... such
that
bcX(sX0) = sX for X ∈ {A, A0, A00, ...}.
Details in section 2.
</equation>
<bodyText confidence="0.9739059">
We shall refer to the expressions we can put in
a box as fluents (short for temporal propositions),
and assume they are the elements of a set Φ. While
the set Φ of fluents might be infinite, we restrict the
boxes that we string together to finite sets of flu-
ents. Writing Fin(Φ) for the set of finite subsets
of Φ and 2X for the powerset of X (i.e. the set
of X’s subsets), we will organize the strings over
the infinite alphabet Fin(Φ) around finite alpha-
bets 2A, for A ∈ Fin(Φ)
</bodyText>
<equation confidence="0.989367">
Fin(Φ)∗ = U (2A)∗.
A∈Fin(Φ)
</equation>
<bodyText confidence="0.9979146">
In addition to projecting Fin(Φ) down to 2A for
some A ∈ Fin(Φ), we can build up, forming
and superposing languages L and L0 over Fin(Φ)
by superposing strings in L and L0 of the same
length
</bodyText>
<equation confidence="0.99702125">
L &amp; L0 := {s&amp;s0  |s ∈ L, s0 ∈ L0 and
length(s) = length(s0)}
(Fernando 2004). For example,
smo,dy = ρmo(smo,dy) &amp; ρdy(smo,dy)
</equation>
<bodyText confidence="0.9797625">
where dy := {d1, d2 ..., d31}. More generally,
writing LA for the image of L under ρA
</bodyText>
<equation confidence="0.972906">
LA := {ρA(s)  |s ∈ L},
</equation>
<bodyText confidence="0.9980525">
observe that for L ⊆ (2B)∗ and A ⊆ B, L is
included in the superposition of LA and LB−A
</bodyText>
<equation confidence="0.996719666666667">
L ⊆ LA &amp; LB−A.
The next step is to identify a language L0 such that
L = (LA &amp; LB−A) ∩ L0 (1)
</equation>
<bodyText confidence="0.993547">
other than L0 = L. For a decomposition (1) of
L into (generic) contextual constraints L0 separate
from the (specific) components LA and LB−A,
it will be useful to sharpen LA, LB−A and &amp;,
factoring in bc and variants of bc (not to mention
∩). Measurements ranging from crude compar-
isons (of order) to quantitative judgments (mul-
tiplying unit magnitudes with real numbers) can
be expressed through fluents in Φ. We interpret
the fluents relative to suitable strings in Fin(Φ)∗,
presented below in category-theoretic terms con-
nected to type theory (e.g. Mac Lane and Moerdijk
1992). Central to this presentation is the notion of
a presheaf on Fin(Φ) — a functor from the op-
posite category Fin(Φ)op (a morphism in which
is a pair (B, A) of finite subsets of Φ such that
A ⊆ B) to the category Set of sets and functions.
The Fin(Φ)-indexed family of functions bcA (for
A ∈ Fin(Φ)) provides an important example that
we generalize in section 2.
An example of linguistic semantic interest to
which block compression bc applies is
</bodyText>
<equation confidence="0.634888">
31 Feb 28 ··· 31 .
Jan Dec
bc(s) := {
</equation>
<page confidence="0.876163">
64
</page>
<figure confidence="0.965856375">
(Dowty 1979). (†) holds also for the fluents in
the string (d) below for (b), where the subinterval
relation v is inclusion restricted to intervals,
Example B (continuous change) The pair (a),
(b) below superposes two events, soup cooling and
an hour passing, in different ways (Dowty 1979).
(a) The soup cooled in an hour.
(b) The soup cooled for an hour.
</figure>
<bodyText confidence="0.982349952380952">
A common intuition is that in an hour requires
an event that culminates, while for an hour re-
quires a homogeneous event. In the case of (a),
the culmination may be that some threshold tem-
perature (supplied by context) was reached, while
in (b), the homogeneity may be the steady drop
in temperature over that hour. We might track
soup cooling by a descending sequence of degrees,
d1 &gt; d2 &gt; · · · &gt; dn, with d1 at the beginning
of the hour, and dn at the end. But no sample of
finite size n can be complete. To overcome this
limitation, it is helpful to construe the ith box in
a string as a description of an interval Ii over the
real line R. We call a sequence I1 · · · In of inter-
vals asegmentation if Un i=1 Ii is an interval and for
1 ≤ i &lt; n, Ii &lt; Ii+1, where &lt; is full precedence
I &lt; I&apos; iff (∀r ∈ I)(∀r&apos; ∈ I&apos;) r &lt; r&apos;.
Now, assuming an assignment of degrees sDg(r)
to real numbers r representing temporal instants,
the idea is to define satisfaction |= between inter-
vals I and fluents sDg &lt; d according to
</bodyText>
<equation confidence="0.555618">
I |= sDg &lt; d iff (∀r ∈ I) sDg(r) &lt; d
</equation>
<bodyText confidence="0.981155333333333">
and similarly for d ≤ sDg. We then lift |= to
segmentations I1 · · · In and strings α1 · · · αn ∈
Fin(Φ)n of the same length n such that
</bodyText>
<equation confidence="0.792089">
I1 ··· In |= α1 · · · αn iff whenever 1 ≤ i ≤ n
</equation>
<bodyText confidence="0.9557032">
and co ∈ Ii, Ii |= coi
and analyze (a) above as (c) below, where d is
the contextually given threshold required by in an
hour, and x is the start of that hour, the end of
which is marked by hour(x).
</bodyText>
<listItem confidence="0.9843065">
(c) x, d ≤ sDg d ≤ sDg hour(x), sDg &lt; d
All fluents co in (c) have the stative property
(†) for all intervals I and I&apos; whose union I ∪ I&apos;
is an interval,
</listItem>
<equation confidence="0.953873">
I ∪ I&apos; |= co iff I |= co and I&apos; |= co
I |= [w]co iff (∀I&apos; v I) I&apos; |= co
and sDgj is the fluent
∃x (sDg &lt; x ∧ Prev(x ≤ sDg))
</equation>
<bodyText confidence="0.99150171875">
saying the degree drops (with I |= Prev(co) iff
(†) is intimately related to block compression bc
(Fernando 2013b), supporting derivations of (c)
and (d) by a modification &amp;bc of &amp; defined in §2.3
below.
Our third example directly concerns computa-
tional processes, which we take up in section 3.
Example C (finite automata) Given a finite al-
phabet A, a (non-deterministic) finite automaton
A over A is a quadruple (Q, 6, F, q0) consisting
of a finite set Q of states, a transition relation
6 ⊆ Q × A × Q, a subset F of Q consisting of
final (accepting) states, and an initial state q0 ∈ Q.
Aaccepts a string a1 · · · an ∈ A* precisely if there
is a string q1 · · · qn ∈ Qn such that
qn ∈ F and 6(qi_1, ai, qi) for 1 ≤ i ≤ n (2)
(where q0 is A’s designated initial state). The ac-
cepting runs of A are strings of the form
a1, q1 ··· an, qn ∈ (2AUQ)*
satisfying (2). While we can formulate such runs
as strings over the alphabet A × Q, we opt for the
alphabet 2AUQ (formed from A ∪ Q ∈ Fin(Φ))
to link up smoothly with examples where more
than one automata may be running, not all neces-
sarily known nor in perfect harmony with others.
Such examples are arguably of linguistic interest,
the so-called Imperfective Paradox (Dowty 1979)
being a case in point (Fernando 2008). That said,
the attention below is largely on certain category-
theoretic preliminaries for type theory.2
We adopt the following notational conventions.
Given a function f and a set X, we write
</bodyText>
<footnote confidence="0.474091666666667">
2Only the most rudimentary category-theoretic notions
are employed; explanations can be found in any number of in-
troductions to category theory available online (and in print).
</footnote>
<figure confidence="0.9635044">
an interval).
x [w]sDgj hour(x), [w]sDgj
I&apos;I |=
for some I&apos; &lt; I such that I ∪ I&apos; is
co
</figure>
<page confidence="0.994046">
65
</page>
<bodyText confidence="0.723249714285714">
- f r X for f restricted to X ∩ domain(f)
- image(f) for {f(x)  |x ∈ domain(f)}
- fX for image(f r X)
- f`X for {x ∈ domain(f)  |f(x) ∈ X}
and if g is a function for which image(f) ⊆
domain(g),
- f; g for f composed (left to right) with g
</bodyText>
<equation confidence="0.92459675">
(f;g)(x) := g(f(x))
for all x ∈ domain(f).
We say f is a function on X if
domain(f) = X ⊇ image(f)
</equation>
<bodyText confidence="0.812791">
— i.e., f : X → X. The kernel of f, ker(f), is
the equivalence relation on domain(f) that holds
between s, s&apos; such that f(s) = f(s&apos;). Clearly,
</bodyText>
<equation confidence="0.792138">
ker(f) ⊆ ker(f;g)
when f; g is defined.
</equation>
<bodyText confidence="0.794249333333333">
2 Some presheaves on Fin(Φ)
Given a function f on Fin(4b)* and A ∈ Fin(4b),
let us write fA for the function PA; f on Fin(4b)*
</bodyText>
<equation confidence="0.85482">
fA(s) := f(PA(s))
(recalling PA(α1 · · · αn) := (α1 ∩ A) · · · (αn ∩ A)
</equation>
<bodyText confidence="0.9767696">
and generalizing bnA from Example A). To extract
a presheaf on Fin(4b) from the Fin(4b)-indexed
family of functions fA, certain requirements on f
are helpful. Toward that end, let us agree that
- f preserves a function g with domain
</bodyText>
<equation confidence="0.523503666666667">
Fin(4b)* if g = f; g
- f is idempotent if f preserves itself (i.e., f =
f; f)
</equation>
<bodyText confidence="0.488894">
- the vocabulary voc(s) of s ∈ Fin(4b)* is the
set of fluents that occur in s
</bodyText>
<equation confidence="0.645917">
voc(α1 · · · αn) :=
whence s ∈ voc(s)*.
</equation>
<bodyText confidence="0.977028666666667">
Note that for idempotent f, image(f) consists of
canonical representatives f(s) of ker(f)’s equiva-
lence classes {s&apos; ∈ Fin(4b)*  |f(s&apos;) = f(s)}.
</bodyText>
<subsectionHeader confidence="0.988573">
2.1 4b-preserving functions
</subsectionHeader>
<bodyText confidence="0.753162666666667">
A function f on Fin(4b)* is 4b-preserving if f pre-
serves voc and fA, for all A ∈ Fin(4b). Note that
bn is 4b-preserving, as is the identity function id on
Fin(4b)*.
Proposition 1. If f is 4b-preserving then f is
idempotent and
</bodyText>
<equation confidence="0.829909833333333">
fB; fA = fAnB
for all A, B ∈ Fin(4b).
Let Pf be the function with domain
Fin(4b) ∪ {(B, A) ∈ Fin(4b)×Fin(4b)  |A ⊆ B}
mapping A ∈ Fin(4b) to f(2A)*
Pf(A) := {f(s)  |s ∈ (2A)*}
</equation>
<bodyText confidence="0.8989395">
and a Fin(4b)op-morphism (B, A) to the restric-
tion of fA to Pf(B)
</bodyText>
<equation confidence="0.580469333333333">
Pf(B, A) := fA P Pf(B).
Corollary 2. If f is 4b-preserving then Pf is a
presheaf on Fin(4b).
</equation>
<bodyText confidence="0.8259555">
Apart from bn, we get a 4b-preserving function
by stripping off any initial or final empty boxes
</bodyText>
<equation confidence="0.753450666666667">
unpad(s&apos;) ifs= s&apos; or
else s = s&apos;
s otherwise
</equation>
<bodyText confidence="0.8999285">
so that unpad(s) neither begins nor ends with
Notice that bn; unpad = unpad; bn.
Proposition 3. If f and g are 4b-preserving and
f; g = g; f, then f; g is 4b-preserving.
</bodyText>
<subsectionHeader confidence="0.999588">
2.2 The Grothendieck construction
</subsectionHeader>
<bodyText confidence="0.999348666666667">
Given a presheaf F on Fin(4b), the category f F
of elements of F (also known as the Grothendieck
construction for F) has
</bodyText>
<listItem confidence="0.9002815">
- objects (A, s) ∈ Fin(4b) × F(A) (making
EXEFin(Φ) F(X) the set of objects in f F)
- morphisms (B, s&apos;, A, s) from objects (B, s&apos;)
to (A, s) when A ⊆ B and F(B, A)(s&apos;) = s
</listItem>
<bodyText confidence="0.7471575">
(e.g. Mac Lane and Moerdijk 1992). Let 7rf be the
left projection
</bodyText>
<equation confidence="0.753648105263158">
7rf(A, s) = A
n
U αi
i=1
unpad(s) := {
.
66
from f Pf back to Fin(Φ). The inverse limit of
P f, lim←− P f, is the set of (f P f)-valued presheaves
p on Fin (Φ) (i.e. functors p : Fin(Φ)°p → f P f)
that are inverted by πf
πf(p(A)) = A for all A ∈ Fin(Φ).
That is, p(A) = (A, sA) for some sA ∈ f(2A)*
such that
(‡) sA = fA(sB) whenever A ⊆ B ∈ Fin(Φ).
(‡) is the essential restriction that lim ←− Pf adds
to objects {sX}XEFin(Φ) of the dependent type
H
XEFin(Φ) Pf(X).
</equation>
<subsectionHeader confidence="0.995759">
2.3 Superposition and non-determinism
</subsectionHeader>
<bodyText confidence="0.999605">
Taking the presheaf Pid induced by the identity
function id on Fin(Φ)*, observe that in f Pid,
there is a product of
The tag A in (A, s) differentiating (∅, ) from
({ϕ}, ) cannot be ignored when forming prod-
ucts in f Pid. A necessary and sufficient condition
for (A, s) and (B, s&apos;) to have a product is
</bodyText>
<equation confidence="0.969858">
ρB(s) = ρA(s&apos;)
</equation>
<bodyText confidence="0.7908445">
presupposed by the pullback of
(A, s) → (A ∩ B, ρB(s)) ← (B, s&apos;).
By comparison, the superposition s&amp;s&apos; exists (as
a string) if and only if
</bodyText>
<equation confidence="0.996115666666667">
ρO(s) = ρO(s&apos;)
for
(voc(s), s) → (∅, ρO(s)) ← (voc(s&apos;), s&apos;)
</equation>
<bodyText confidence="0.958308">
(or length(s) = length(s&apos;) as ρO(s) = length(s)).
Products in f Pid are superpositions, but superpo-
sitions need not be products.
Next, we step from id to other Φ-preserving
functions f such as bc and bc; unpad. A pair
(A, s) and (B, s&apos;) of f Pf-objects may fail to
have a product not because there is no f Pf-object
(A ∪ B, s&apos;&apos;) such that
(A, s) ← (A ∪ B, s&apos;&apos;) → (B, s&apos;)
but too many non-isomorphic choices for such s&apos;&apos;.
Consider the case of bc; unpad, with (∅, E) terminal
in f Pbc;unpad (where E is the null string of length
0). For distinct fluents a and b ∈ Φ, there are 13
strings s ∈ Pbc;unpad({a, b}) such that
({a}, a ) ← ({a, b}, s) → ({b}, b ))
corresponding to the 13 interval relations in Allen
1983 (Fernando 2007).
The explosion of solutions s&apos;&apos; ∈ Pf(A ∪ B) to
the equations
</bodyText>
<equation confidence="0.765745444444444">
fA(s&apos;&apos;) = s and fB(s&apos;&apos;) = s&apos;
given
(A, s) → (A ∩ B, fB(s)) ← (B, s&apos;)
(i.e., fB(s) = fA(s&apos;)) is paralleled by the trans-
formation, under f, of a language L to
Lf := f−1fL
used to turn the superposition L&amp;L&apos; of languages
L and L&apos; into
L &amp;f L&apos; := f(Lf &amp; L&apos;f).
</equation>
<bodyText confidence="0.954745285714286">
For f := bc; unpad, the set a &amp;f b consists of
the 13 strings mentioned above. (We follow the
usual practice of conflating a string s with the sin-
gleton language {s} whenever convenient.)
Stepping from strings to languages, we lift the
presheaf Pf to the presheaf Qf mapping A ∈
Fin(Φ) to
</bodyText>
<equation confidence="0.687553333333333">
Qf(A) := {fL  |L ⊆ (2A)*}
and a Fin(Φ)°p-morphism (B, A) to the function
Qf(B, A) := (λL ∈ Qf(B)) fAL
</equation>
<bodyText confidence="0.9655386">
sending L ∈ Qf(B) to fAL ∈ Qf(A). Then,
for non-identity morphisms between f Qf-objects
(A, L) and (A, L&apos;) where L ⊆ L&apos;, we add in-
clusions from (A, L) to (A, L&apos;) to the f Qf-
morphisms for the category (t(Φ, f) with
- objects the same as those in f Qf, and
- morphisms (B, L&apos;, A, L) from objects
(B, L&apos;) to (A, L) whenever A ⊆ B and
fAL&apos; ⊆ L.
(∅, ) and ({ϕ}, ϕ
</bodyText>
<figure confidence="0.646017">
)
but not of
({ϕ}, ) and ({ϕ},
).
ϕ
</figure>
<page confidence="0.995931">
67
</page>
<bodyText confidence="0.9999674">
As is the case with f Qf-morphisms, the sources
(domains) of (t(Φ, f)-morphisms entail their tar-
gets (codomains). To make these entailments pre-
cise, we can identify the space of possible worlds
with the inverse limit of Pf, and reduce (A, L) to
</bodyText>
<equation confidence="0.9781475">
[A,L]f := {p ∈ lim ←− Pf |
(∃s ∈ L) p(A) = (A, s)}.
The inclusion
[B, L0]f ⊆ [A, L]f
</equation>
<bodyText confidence="0.976465">
can then be pronounced: (B, L0) f-entails (A, L).
Proposition 4. Let f be a Φ-preserving function
and (A, L) and (B, L0) be f Qf-objects such that
A ⊆ B. (B, L0) f-entails (A, L) iff there is a
(t(Φ, f)-morphism from (B, L0) to (A, L).
Relaxing the assumption A ⊆ B, one can also
check that for f ∈ {be, unpad, (be; unpad)}, pull-
backs of
</bodyText>
<equation confidence="0.8678656">
(A, L) → (A ∩ B, (f∅L) ∩ f∅L0) ← (B, L0)
in (t(Φ, f) are given by
(A, L) ← (A ∪ B, L&amp;fL0) → (B, L0) (3)
although (3) need not hold for L&amp;fL0 to be well-
defined.
</equation>
<sectionHeader confidence="0.965487" genericHeader="introduction">
3 Constraints and finite automata
</sectionHeader>
<bodyText confidence="0.9999245">
We now bring finite automata into the picture, re-
calling from section 1 Example C’s superpositions
</bodyText>
<subsectionHeader confidence="0.998669">
3.1 Bottom ⊥ naturally
</subsectionHeader>
<bodyText confidence="0.996165">
If the function qA such that for a1 · · · an ∈ A∗,
</bodyText>
<equation confidence="0.915465">
qA(a1 ··· an) = a1 ··· an
</equation>
<bodyText confidence="0.98937675">
is to be the A-th component of a natural trans-
formation q : S ⇒ Pid, we need to specify
the presheaf S on Fin(Φ). To form a function
S(B, A) : S(B) → S(A) for A ⊆ B ∈ Fin(Φ)
with B∗ ⊆ S(B) and A∗ ⊆ S(A), it is handy to
introduce a bottom ⊥ for B − A, adjoining ⊥ to a
finite subset X of Φ for X⊥ := X + {⊥} before
forming the strings in S(X) := X⊥∗. We then set
</bodyText>
<equation confidence="0.849176444444444">
S(B, A) : B⊥∗ → A⊥∗
S(B,A)(c) := c
� β S(B, A)(s) if β ∈ A⊥
S(B, A)(βs) :=
⊥ S(B,A)(s) otherwise
(e.g. S({a, b}, {a})(ba⊥) = ⊥a⊥) and let qA :
A⊥∗ → (2A)∗ map c to itself, and
Proposition 5. q is a natural transformation
from S to Pid.
</equation>
<subsectionHeader confidence="0.999927">
3.2 Another presheaf and category
</subsectionHeader>
<bodyText confidence="0.99992075">
Turning now to finite automata, we recall a funda-
mental result about languages that are regular (i.e.,
accepted by finite automata),3 the B¨uchi-Elgot-
Trakhtenbrot theorem (e.g. Thomas 1997)
</bodyText>
<equation confidence="0.997384142857143">
�qA(αs) :=
qA(s) if α = ⊥
α qA(s) otherwise
(e.g. q{a}(⊥a⊥) =
a
).
a1 ··· an &amp; q1 ··· qn (4)
</equation>
<bodyText confidence="0.988802368421053">
where a1 · · · an is accepted by a finite automaton
A going through the sequence q1 · · · qn of (inter-
nal) states. We can assume the tape alphabet A ⊇
{a1, ... , an} and the state set Q ⊇ {q1, ... , qn}
are two disjoint subsets of the set Φ of fluents; flu-
ents in A are “observable” (on a tape), while flu-
ents in Q are “hidden” (inside a black box). Dis-
joint though they may be, A and Q are tightly cou-
pled by A’s transition table S ⊆ Q×A×Q (not to
mention the other components of A, its initial and
final states). That coupling can hardly be recreated
by superposition &amp; (or some simple modification
&amp;f) without the help of some machinery encoding
S. But first, there is the small matter of formulat-
ing the map a1 · · · an 7→ a1 ··· an implicit in
(4) above as a natural transformation.
for every finite alphabet A =6 ∅, a language
L ⊆ A+ is regular iff there is a sentence ϕ of
MSOA such that
</bodyText>
<equation confidence="0.971786">
L = {s ∈ A+  |s |=A ϕ} .
</equation>
<bodyText confidence="0.998346166666667">
MSOA is Monadic Second Order logic with a
unary relation symbol Ua for each a ∈ A, plus a
binary relation symbol S for successors. The pred-
icate |=A treats a string a1a2 · · · an over A as an
MSOA-model with universe {1, 2, ... , n}, Ua as
its subset {i  |ai = a}, and S as
</bodyText>
<footnote confidence="0.83085375">
{(1, 2), (2, 3), ... , (n − 1, n)}
3Whether or not this sense of regular has an interesting
connection with regular categories (which are, among other
things, finitely complete), I do not know.
</footnote>
<page confidence="0.997911">
68
</page>
<bodyText confidence="0.892347">
so that, for instance,
</bodyText>
<note confidence="0.586841">
a1 ··· an |=A ∃x∃y S(x, y) iff n ≥ 2 (5)
</note>
<bodyText confidence="0.930923846153846">
for all finite A =6 ∅. Notice that no a ∈ A is
required to interpret ∃x∃y S(x, y), which after all
is an MSO∅-sentence suited to strings ⊥n ∈ S(∅).
Furthermore, for a =6 b and {a, b} ⊆ A,
no string in A+ satisfies ∃x Ua(x) ∧ Ub(x) (6)
which makes it awkward to extend |=A to formulas
with free variables (requiring variable assignments
on top of strings in A+).
A simple way to accommodate variables is to
include them in A and interpret MSOA-formulas
not over A+ but over (2A)+, lifting |=A from
strings s over A to a predicate |=A on strings over
2A such that
</bodyText>
<subsectionHeader confidence="0.362986">
s |=A ϕ iff ηA(s) |=A ϕ (7)
</subsectionHeader>
<bodyText confidence="0.6166365">
for every MSOA-sentence ϕ (Fernando 2013a).
For all s ∈ (2A)+, we set
</bodyText>
<equation confidence="0.52549825">
s |=A S(x, y) iff ρ{x,y}(s) ∈ ∗ x
for a, b ∈ A.
Working back from (7)
s |=A ϕ iff ηA(s) |=A ϕ
</equation>
<bodyText confidence="0.998440666666667">
to the B¨uchi-Elgot-Trakhtenbrot theorem, one can
check that for every finite A and MSOA-formula
ϕ, the set
</bodyText>
<equation confidence="0.991663">
LA(ϕ) := {s ∈ (2A)+  |s |=A ϕ}
</equation>
<bodyText confidence="0.999376571428572">
of strings over 2A that |=A-satisfy ϕ is regular, us-
ing the fact that for all A0 ⊆ A, the restriction
of ρA, to (2A)∗ is computable by a finite state
transducer. But for A ⊆ Φ,4 ρA, r (2A)∗ is just
Pid(A, A0). In recognition of the role of these
functions in |=A, we effectivize the presheaf Qid
from §2.3 as follows. Let RD be the presheaf on
</bodyText>
<figure confidence="0.327435730769231">
Fin(Φ) mapping
- A ∈ Fin(Φ) to the set of languages over the
alphabet 2A that are regular
RD(A) := {L ∈ Qid(A)  |L is regular}
and
y
∗ (8)
for A ⊇ {x, y}, and - a Fin(Φ)op-morphism (B, A) to the restric-
s |=A Ua(x) iff ρ{a,x}(s) ∈ Ea a, x Ea (9) tion of Qid(B, A) to RD(B)
be careful to incorporate into the clauses defining
s |=A ϕ the presupposition that each first-order
variable x free in ϕ occurs uniquely in s — i.e.
s |=A x = x where
for x, y ∈ A. In particular, we restrict negation
¬ϕ to strings |=A-satisfying x = x, for each first-
order variable x free in ϕ. We can then put
s |=A ∃x ϕ iff (∃s0) ρA(s0) = ρA(s)
and s0 |=A∪{x} ϕ
and similarly for second-order existential quantifi-
cation. The equivalence (5) above then becomes
s |=A ∃x∃y S(x, y) iff ρ∅(s) ∈ + (11)
and in place of (6), we have
s |=A ∃x Ua(x) ∧ Ub(x) iff ρ{a,b}(s) ∈
(2{a,b})∗ a, b (2{a,b})∗ (12)
for A ⊇ {a, x}, where Ea := ( + a
)∗. We must
</figure>
<equation confidence="0.913046333333333">
s |=A x = y iff ρ{x,y}(s) ∈ ∗ x, y
∗ (10)
RD(B,A) := (λL ∈ RD(B)) ρAL.
</equation>
<bodyText confidence="0.950792133333333">
f RD-objects are then pairs (A, L) where A ∈
Fin(Φ) and L is a regular language over the al-
phabet 2A, while f RD-morphisms are quadru-
ples (B, L, A, ρAL) from (B, L) to (A, ρAL) for
A ⊆ B ∈ Fin(Φ). To account for the Boolean op-
erations in MSO (as opposed to the predications
(8)– (10) involving ρA), we add inclusions for a
category 9i(Φ) with
- the same objects as f RD
- morphisms all of those in (t(Φ, id) be-
tween objects in f RD — i.e., quadruples
(B, L0, A, L) such that A ⊆ B ∈ Fin(Φ),
L0 ⊆ (2B)∗ is regular, L ⊆ (2A)∗ is regular,
and ρAL0 ⊆ L.
Let us agree to write
</bodyText>
<equation confidence="0.304444">
(B, L0) ❀ (A, L)
</equation>
<footnote confidence="0.964929">
4Note an MSOA-formula ϕ is not strictly a fluent in Φ but
is formed in part from fluents.
</footnote>
<page confidence="0.998845">
69
</page>
<bodyText confidence="0.698229125">
to mean (B, L&apos;, A, L) is a N(b)-morphism.
Clearly, for s E (2A)+, A&apos; C_ A and L C_ (2A,)+,
ρA,(s) E L iff (A, {s}) ❀ (A&apos;, L).
In particular, for x E A and s E (2A)+,
s |=A x = x iff (A, {s}) ❀ ({x}, * x
and similarly for x = x replaced by the differ-
ent MSOA-formulas specified in clauses (8)–(12)
above. The MSOA-sentence
</bodyText>
<equation confidence="0.9924445">
�spec(A) := bx (Ua(x) ∧ � ¬Ub(x))
aEA bEA−{a}
</equation>
<bodyText confidence="0.985555">
associating a unique a E A with each string po-
sition (presupposed in |=A but not in |=A) fits the
same pattern
</bodyText>
<equation confidence="0.64201275">
s |=A spec(A) iff ρA(s) E { a  |a E A}+
iff (A U voc(s), {s}) ❀
(A, { a  |a E A}+)
iff ρA(s) E ηAA+.
</equation>
<bodyText confidence="0.957746035714286">
Let us define a string s E Fin(b)+ to be
- A-specified if s |=A spec(A)
- A-underspecified if ρA(s) E ηA(A1+ − A+)
- A-overspecified if ρA(s) E� image(ηA)
is A-overspecified. Given a finite automaton A
over A with set Q of states, its set AcRun(A) of
accepting runs (Example C) is both A-specified
and Q-specified, provided A ∩ Q = 0 (and other-
wise risks being A-overspecified). The language
accepted by A is the η−1
A -image of the language
ρAAcRun(A) that is Q-underspecified, in accor-
dance with the intuition that the states are hidden.
From the regularity of AcRun(A), however, it is
clear that we can make these states visible, with
AcRun(A) as the language accepted by a finite au-
tomaton A&apos; (over 2AUQ) that may (or may not)
have the same set Q of states.
The maps ρA and inclusions C_ underlying the
morphisms of R(b) represent the two ways in-
formation may grow from f RD-objects (A, L)
to (B, L&apos;) — expansively with A C_ B and L =
ρAL&apos;, and eliminatively with L&apos; C_ L and A = B.
The same notion of f-entailment defined in §2.3
through the sets QA, L]f applies, but we have been
careful here to fix f to id, in view of
Proposition 6. For A C_ B E Fin(b), ϕ an
MSOA-formula and s E (2B)+,
</bodyText>
<subsectionHeader confidence="0.59718">
s |=B ϕ iff ρA(s) |=A ϕ.
</subsectionHeader>
<bodyText confidence="0.99867725">
Proposition 6 says that s |=B ϕ depends only on
the part ρA(s) of s mentioned in ϕ. It is a par-
ticular instance of the satisfaction condition in in-
stitutions, expressing the invariance of truth under
change of notation (Goguen and Burstall 1992).
Proposition 6 breaks down if we replace ρA by
bcA or unpadA, as can be seen with A = 0, and
ϕ = lxly S(x, y), for which recall (11).
</bodyText>
<subsectionHeader confidence="0.999882">
3.3 Varying grain and span
</subsectionHeader>
<bodyText confidence="0.999582166666667">
Troublesome as they are, the maps bcA and
unpadA have some use. Just as we can vary tem-
poral grain through bc (Examples A and B in sec-
tion 1), we can vary temporal span through unpad.
For instance, we can combine runs of automata A1
over A1 and A2 over A2 in
</bodyText>
<equation confidence="0.958462">
L(A1, A2) := AcRun(A1) &amp;unpad AcRun(A2)
</equation>
<bodyText confidence="0.99982125">
with the subscript unpad on &amp; relaxing the re-
quirement that A1 and A2 start and finish together
(running in lockstep throughout). For i E {1, 2},
and Qi the state set for Ai,
</bodyText>
<equation confidence="0.996385">
AcRun(Ai) = unpadAiUQiL(A1, A2)
</equation>
<bodyText confidence="0.994937545454545">
assuming the sets A1, A2, Q1 and Q2 are pair-
wise disjoint. The disjointness assumption rules
out any communication (or interference) between
A1 and A2. As subsets of one large set b of
fluents, however, it is perfectly natural for these
sets to intersect (and communicate through a com-
mon vocabulary), and we might express very par-
tial constraints involving them through, for ex-
ample, MSO-formulas. Recalling the definition
LA(ϕ) := {s E (2A)+  |s |=A ϕ}, we can rewrite
the satisfaction condition
</bodyText>
<subsectionHeader confidence="0.638216">
s |=B ϕ iff fA(s) |=A ϕ
</subsectionHeader>
<bodyText confidence="0.7891535">
on MSOA-formulas ϕ, A C_ B E Fin(b) and s E
(2B)+ as
</bodyText>
<equation confidence="0.825062">
LB(ϕ) = {s E (2B)+  |fA(s) E LA(ϕ)}.
</equation>
<bodyText confidence="0.988119333333333">
This equation lifts any regular language LA(ϕ) to
a regular language LB(ϕ), provided f is computed
by a finite-state transducer (as in the case of bc or
unpad). Inverse images under such relations are a
useful addition to the stock of operations constitut-
ing MSO-formulas as well as regular expressions.
so that for a =� a&apos; and A = {a, a&apos;},
specified,
is A-underspecified, and a, a&apos; a
</bodyText>
<figure confidence="0.98863075">
is A-
a
a a
*)
</figure>
<page confidence="0.980066">
70
</page>
<bodyText confidence="0.9904405">
Richard Montague. 1973. The proper treatment of
quantification in ordinary English. In Approaches to
Natural Language, pages 221 – 42. D. Reidel, Dor-
drecht.
</bodyText>
<sectionHeader confidence="0.860587" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997554966666667">
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. C. ACM, 26(11):832–843.
Michael Bennett and Barbara Partee. 1972. Toward the
logic of tense and aspect in English. Technical re-
port, System Development Corporation, Santa Mon-
ica, California. Reprinted in Partee 2008.
Robin Cooper. 2012. Type theory and semantics in flux.
In Handbook of the Philosophy of Science. Volume
14: Philosophy of Linguistics. pages 271–323.
David R. Dowty. 1979. Word Meaning and Montague
Grammar. Reidel, Dordrecht.
Tim Fernando. 2004. A finite-state approach to events
in natural language semantics. J. Logic and Compu-
tation, 14(1):79–92.
Tim Fernando. 2007. Observing events and situations
in time. Linguistics and Philosophy 30(5):527–550.
Tim Fernando. 2008. Branching from inertia worlds. J.
Semantics 25(3):321–344.
Tim Fernando. 2011. Regular relations for temporal
propositions. Natural Language Engineering 17(2):
163–184.
Tim Fernando. 2013a. Finite state methods and descrip-
tion logics Proceedings of the 11th International
Conference on Finite State Methods and Natural
Language Processing, pages 63 – 71.
Tim Fernando. 2013b. Dowty’s aspect hypothesis seg-
mented. Proceedings of the 19th Amsterdam Collo-
quium, pages 107 – 114.
Danny Fox and Martin Hackl. 2006. The universal
density of measurement. Linguistics and Philosophy
29(5): 537 – 586.
Joseph Goguen and Rod Burstall. 1992., Institutions:
Abstract model theory for specification and pro-
gramming, J. ACM, 39(1):95–146.
Hans Kamp and Uwe Reyle. 1993. From Discourse to
Logic. Kluwer.
Christopher Kennedy. 2001. Polar opposition and the
ontology of degrees. Linguistics and Philosophy 24.
33 – 70.
Ewan Klein and Michael Rovatsos. 2011. Temporal
Vagueness, Coordination and Communication In
Vagueness in Communication 2009, LNAI 6517,
pages 108–126.
Wolfgang Klein. 2009. How time is encoded. In W.
Klein and P. Li, editors, The Expression of Time,
pages 39 – 81, Mouton De Gruyter.
Saunders Mac Lane and Ieke Moerdijk. 1992. Sheaves
in Geometry and Logic: A First Introduction to
Topos Theory. Springer.
Ian Pratt-Hartmann. 2005. Temporal prepositions and
their logic. Artificial Intelligence 166: 1–36.
Roger Schwarzschild and Karina Wilkinson. 2002.
Quantifiers in comparatives: A semantics of de-
gree based on intervals. Natural Language Seman-
tics 10(1):1–41.
Stephanie Solt. 2013. Scales in natural language.
Manuscript.
Wolfgang Thomas. 1997. Languages, automata and
logic. In Handbook of Formal Languages: Beyond
Words, volume 3, pages 389 – 455. Springer-Verlag.
</reference>
<page confidence="0.999134">
71
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.607607">
<title confidence="0.995048">Incremental semantic scales by strings</title>
<author confidence="0.997889">Tim</author>
<affiliation confidence="0.931405333333333">Computer Science Trinity College Dublin,</affiliation>
<email confidence="0.839523">Tim.Fernando@tcd.ie</email>
<abstract confidence="0.994168333333333">Scales for natural language semantics are analyzed as moving targets, perpetually under construction and subject to adjustment. Projections, factorizations and constraints are described on strings of bounded but refinable granularities, shaping types by the processes that put semantics in flux.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>C. ACM,</journal>
<volume>26</volume>
<issue>11</issue>
<contexts>
<context position="14759" citStr="Allen 1983" startWordPosition="2850" endWordPosition="2851">tions need not be products. Next, we step from id to other Φ-preserving functions f such as bc and bc; unpad. A pair (A, s) and (B, s&apos;) of f Pf-objects may fail to have a product not because there is no f Pf-object (A ∪ B, s&apos;&apos;) such that (A, s) ← (A ∪ B, s&apos;&apos;) → (B, s&apos;) but too many non-isomorphic choices for such s&apos;&apos;. Consider the case of bc; unpad, with (∅, E) terminal in f Pbc;unpad (where E is the null string of length 0). For distinct fluents a and b ∈ Φ, there are 13 strings s ∈ Pbc;unpad({a, b}) such that ({a}, a ) ← ({a, b}, s) → ({b}, b )) corresponding to the 13 interval relations in Allen 1983 (Fernando 2007). The explosion of solutions s&apos;&apos; ∈ Pf(A ∪ B) to the equations fA(s&apos;&apos;) = s and fB(s&apos;&apos;) = s&apos; given (A, s) → (A ∩ B, fB(s)) ← (B, s&apos;) (i.e., fB(s) = fA(s&apos;)) is paralleled by the transformation, under f, of a language L to Lf := f−1fL used to turn the superposition L&amp;L&apos; of languages L and L&apos; into L &amp;f L&apos; := f(Lf &amp; L&apos;f). For f := bc; unpad, the set a &amp;f b consists of the 13 strings mentioned above. (We follow the usual practice of conflating a string s with the singleton language {s} whenever convenient.) Stepping from strings to languages, we lift the presheaf Pf to the presheaf Qf</context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>James F. Allen. 1983. Maintaining knowledge about temporal intervals. C. ACM, 26(11):832–843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Bennett</author>
<author>Barbara Partee</author>
</authors>
<title>Toward the logic of tense and aspect in English.</title>
<date>1972</date>
<tech>Technical report,</tech>
<institution>System Development Corporation, Santa Monica, California.</institution>
<note>Reprinted in Partee</note>
<contexts>
<context position="1630" citStr="Bennett and Partee 1972" startWordPosition="244" endWordPosition="247">11). The formal study carried out below keeps scales as simple as possible, whilst allowing for necessary refinements and adjustments. The basic picture is that a scale is a moving target finitely approximable as a string over an alphabet which we can expand to refine granularity. Reducing a scale to a string comes, however, at a price; indivisible points must give way to refinable intervals (embodying underspecification). Arguments for a semantic reorientation around intervals (away from points) are hardly new. Best known within linguistic semantics perhaps are those in tense and aspect from Bennett and Partee 1972, which seem to have met less resistance than arguments in the degree literature from Kennedy 2001 and Schwarzschild and Wilkinson 2002 (see Solt 2013). At the center of the present argument for intervals is a notion of finite approximability, plausibly related to cognition. What objection might there be to it? The fact that no finite linear order is dense raises the issue of compatibility between finite approximability and density — no small worry, given the popularity of dense linear orders for time (e.g. Kamp and Reyle 1993, PrattHartmann 2005, Klein 2009) as well as measurement (e.g. Fox a</context>
</contexts>
<marker>Bennett, Partee, 1972</marker>
<rawString>Michael Bennett and Barbara Partee. 1972. Toward the logic of tense and aspect in English. Technical report, System Development Corporation, Santa Monica, California. Reprinted in Partee 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Type theory and semantics in flux.</title>
<date>2012</date>
<booktitle>In Handbook of the Philosophy of Science. Volume 14: Philosophy of Linguistics.</booktitle>
<pages>271--323</pages>
<contexts>
<context position="748" citStr="Cooper 2012" startWordPosition="105" endWordPosition="106">e Abstract Scales for natural language semantics are analyzed as moving targets, perpetually under construction and subject to adjustment. Projections, factorizations and constraints are described on strings of bounded but refinable granularities, shaping types by the processes that put semantics in flux. 1 Introduction An important impetus for recent investigations into type theory for natural language semantics is the view of “semantics in flux,” correcting “the impression” from, for example, Montague 1973 “of natural languages as being regimented with meanings determined once and for all” (Cooper 2012, page 271). The present work concerns scales for temporal expressions and gradable predicates. Two questions that loom large from the perspective of semantics in flux are: how to construct scales and align them against one another (e.g. Klein and Rovatsos 2011). The formal study carried out below keeps scales as simple as possible, whilst allowing for necessary refinements and adjustments. The basic picture is that a scale is a moving target finitely approximable as a string over an alphabet which we can expand to refine granularity. Reducing a scale to a string comes, however, at a price; in</context>
</contexts>
<marker>Cooper, 2012</marker>
<rawString>Robin Cooper. 2012. Type theory and semantics in flux. In Handbook of the Philosophy of Science. Volume 14: Philosophy of Linguistics. pages 271–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
</authors>
<title>Word Meaning and Montague Grammar.</title>
<date>1979</date>
<location>Reidel, Dordrecht.</location>
<contexts>
<context position="6659" citStr="Dowty 1979" startWordPosition="1206" endWordPosition="1207">n Fin(Φ)∗, presented below in category-theoretic terms connected to type theory (e.g. Mac Lane and Moerdijk 1992). Central to this presentation is the notion of a presheaf on Fin(Φ) — a functor from the opposite category Fin(Φ)op (a morphism in which is a pair (B, A) of finite subsets of Φ such that A ⊆ B) to the category Set of sets and functions. The Fin(Φ)-indexed family of functions bcA (for A ∈ Fin(Φ)) provides an important example that we generalize in section 2. An example of linguistic semantic interest to which block compression bc applies is 31 Feb 28 ··· 31 . Jan Dec bc(s) := { 64 (Dowty 1979). (†) holds also for the fluents in the string (d) below for (b), where the subinterval relation v is inclusion restricted to intervals, Example B (continuous change) The pair (a), (b) below superposes two events, soup cooling and an hour passing, in different ways (Dowty 1979). (a) The soup cooled in an hour. (b) The soup cooled for an hour. A common intuition is that in an hour requires an event that culminates, while for an hour requires a homogeneous event. In the case of (a), the culmination may be that some threshold temperature (supplied by context) was reached, while in (b), the homoge</context>
<context position="9944" citStr="Dowty 1979" startWordPosition="1886" endWordPosition="1887"> ∈ A* precisely if there is a string q1 · · · qn ∈ Qn such that qn ∈ F and 6(qi_1, ai, qi) for 1 ≤ i ≤ n (2) (where q0 is A’s designated initial state). The accepting runs of A are strings of the form a1, q1 ··· an, qn ∈ (2AUQ)* satisfying (2). While we can formulate such runs as strings over the alphabet A × Q, we opt for the alphabet 2AUQ (formed from A ∪ Q ∈ Fin(Φ)) to link up smoothly with examples where more than one automata may be running, not all necessarily known nor in perfect harmony with others. Such examples are arguably of linguistic interest, the so-called Imperfective Paradox (Dowty 1979) being a case in point (Fernando 2008). That said, the attention below is largely on certain categorytheoretic preliminaries for type theory.2 We adopt the following notational conventions. Given a function f and a set X, we write 2Only the most rudimentary category-theoretic notions are employed; explanations can be found in any number of introductions to category theory available online (and in print). an interval). x [w]sDgj hour(x), [w]sDgj I&apos;I |= for some I&apos; &lt; I such that I ∪ I&apos; is co 65 - f r X for f restricted to X ∩ domain(f) - image(f) for {f(x) |x ∈ domain(f)} - fX for image(f r X) -</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>David R. Dowty. 1979. Word Meaning and Montague Grammar. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>A finite-state approach to events in natural language semantics.</title>
<date>2004</date>
<journal>J. Logic and Computation,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="5244" citStr="Fernando 2004" startWordPosition="940" endWordPosition="941"> of fluents might be infinite, we restrict the boxes that we string together to finite sets of fluents. Writing Fin(Φ) for the set of finite subsets of Φ and 2X for the powerset of X (i.e. the set of X’s subsets), we will organize the strings over the infinite alphabet Fin(Φ) around finite alphabets 2A, for A ∈ Fin(Φ) Fin(Φ)∗ = U (2A)∗. A∈Fin(Φ) In addition to projecting Fin(Φ) down to 2A for some A ∈ Fin(Φ), we can build up, forming and superposing languages L and L0 over Fin(Φ) by superposing strings in L and L0 of the same length L &amp; L0 := {s&amp;s0 |s ∈ L, s0 ∈ L0 and length(s) = length(s0)} (Fernando 2004). For example, smo,dy = ρmo(smo,dy) &amp; ρdy(smo,dy) where dy := {d1, d2 ..., d31}. More generally, writing LA for the image of L under ρA LA := {ρA(s) |s ∈ L}, observe that for L ⊆ (2B)∗ and A ⊆ B, L is included in the superposition of LA and LB−A L ⊆ LA &amp; LB−A. The next step is to identify a language L0 such that L = (LA &amp; LB−A) ∩ L0 (1) other than L0 = L. For a decomposition (1) of L into (generic) contextual constraints L0 separate from the (specific) components LA and LB−A, it will be useful to sharpen LA, LB−A and &amp;, factoring in bc and variants of bc (not to mention ∩). Measurements rangin</context>
</contexts>
<marker>Fernando, 2004</marker>
<rawString>Tim Fernando. 2004. A finite-state approach to events in natural language semantics. J. Logic and Computation, 14(1):79–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Observing events and situations in time.</title>
<date>2007</date>
<journal>Linguistics and Philosophy</journal>
<volume>30</volume>
<issue>5</issue>
<contexts>
<context position="14775" citStr="Fernando 2007" startWordPosition="2852" endWordPosition="2853">ot be products. Next, we step from id to other Φ-preserving functions f such as bc and bc; unpad. A pair (A, s) and (B, s&apos;) of f Pf-objects may fail to have a product not because there is no f Pf-object (A ∪ B, s&apos;&apos;) such that (A, s) ← (A ∪ B, s&apos;&apos;) → (B, s&apos;) but too many non-isomorphic choices for such s&apos;&apos;. Consider the case of bc; unpad, with (∅, E) terminal in f Pbc;unpad (where E is the null string of length 0). For distinct fluents a and b ∈ Φ, there are 13 strings s ∈ Pbc;unpad({a, b}) such that ({a}, a ) ← ({a, b}, s) → ({b}, b )) corresponding to the 13 interval relations in Allen 1983 (Fernando 2007). The explosion of solutions s&apos;&apos; ∈ Pf(A ∪ B) to the equations fA(s&apos;&apos;) = s and fB(s&apos;&apos;) = s&apos; given (A, s) → (A ∩ B, fB(s)) ← (B, s&apos;) (i.e., fB(s) = fA(s&apos;)) is paralleled by the transformation, under f, of a language L to Lf := f−1fL used to turn the superposition L&amp;L&apos; of languages L and L&apos; into L &amp;f L&apos; := f(Lf &amp; L&apos;f). For f := bc; unpad, the set a &amp;f b consists of the 13 strings mentioned above. (We follow the usual practice of conflating a string s with the singleton language {s} whenever convenient.) Stepping from strings to languages, we lift the presheaf Pf to the presheaf Qf mapping A ∈ Fin</context>
</contexts>
<marker>Fernando, 2007</marker>
<rawString>Tim Fernando. 2007. Observing events and situations in time. Linguistics and Philosophy 30(5):527–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Branching from inertia worlds.</title>
<date>2008</date>
<journal>J. Semantics</journal>
<volume>25</volume>
<issue>3</issue>
<contexts>
<context position="9982" citStr="Fernando 2008" startWordPosition="1893" endWordPosition="1894">g q1 · · · qn ∈ Qn such that qn ∈ F and 6(qi_1, ai, qi) for 1 ≤ i ≤ n (2) (where q0 is A’s designated initial state). The accepting runs of A are strings of the form a1, q1 ··· an, qn ∈ (2AUQ)* satisfying (2). While we can formulate such runs as strings over the alphabet A × Q, we opt for the alphabet 2AUQ (formed from A ∪ Q ∈ Fin(Φ)) to link up smoothly with examples where more than one automata may be running, not all necessarily known nor in perfect harmony with others. Such examples are arguably of linguistic interest, the so-called Imperfective Paradox (Dowty 1979) being a case in point (Fernando 2008). That said, the attention below is largely on certain categorytheoretic preliminaries for type theory.2 We adopt the following notational conventions. Given a function f and a set X, we write 2Only the most rudimentary category-theoretic notions are employed; explanations can be found in any number of introductions to category theory available online (and in print). an interval). x [w]sDgj hour(x), [w]sDgj I&apos;I |= for some I&apos; &lt; I such that I ∪ I&apos; is co 65 - f r X for f restricted to X ∩ domain(f) - image(f) for {f(x) |x ∈ domain(f)} - fX for image(f r X) - f`X for {x ∈ domain(f) |f(x) ∈ X} and</context>
</contexts>
<marker>Fernando, 2008</marker>
<rawString>Tim Fernando. 2008. Branching from inertia worlds. J. Semantics 25(3):321–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Regular relations for temporal propositions.</title>
<date>2011</date>
<journal>Natural Language Engineering</journal>
<volume>17</volume>
<issue>2</issue>
<pages>163--184</pages>
<contexts>
<context position="2841" citStr="Fernando 2011" startWordPosition="455" endWordPosition="456">x and Hackl 2006). Fortunately, finite linear orders can be organized into a system of approximations converging at the limit to a dense linear order. The present work details ways to form such systems and limits, with density reanalyzed as refinability of arbitrary finite approximations. A familiar example provides some orientation. Example A (calendar) We can represent a calendar year as the string smo := Jan Feb Mar ··· Dec of length 12, or, were we interested also in days d1,d2...,d31, the string smo,dy := Jan,d1 Jan,d2 · · · Jan,d31 Feb,d1 · · · Dec,d31 of length 365 for a non-leap year (Fernando 2011).1 In contrast to the points in the real line R, a box can split, as Jan in smo does (30 times) to Jan,d1 Jan,d2 · · · Jan,d31 in smo,dy, on introducing days d1, d2,..., d31 into the picture. Reversing direction and generalizing from mo := {Jan,Feb,...Dec} 1We draw boxes (instead of the usual curly braces { and }) around sets-as-symbols, stringing together “snapshots” much like a cartoon/film strip. 63 Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 63–71, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics t</context>
</contexts>
<marker>Fernando, 2011</marker>
<rawString>Tim Fernando. 2011. Regular relations for temporal propositions. Natural Language Engineering 17(2): 163–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Finite state methods and description logics</title>
<date>2013</date>
<booktitle>Proceedings of the 11th International Conference on Finite State Methods and Natural Language Processing,</booktitle>
<pages>63--71</pages>
<contexts>
<context position="8826" citStr="Fernando 2013" startWordPosition="1665" endWordPosition="1666"> iff whenever 1 ≤ i ≤ n and co ∈ Ii, Ii |= coi and analyze (a) above as (c) below, where d is the contextually given threshold required by in an hour, and x is the start of that hour, the end of which is marked by hour(x). (c) x, d ≤ sDg d ≤ sDg hour(x), sDg &lt; d All fluents co in (c) have the stative property (†) for all intervals I and I&apos; whose union I ∪ I&apos; is an interval, I ∪ I&apos; |= co iff I |= co and I&apos; |= co I |= [w]co iff (∀I&apos; v I) I&apos; |= co and sDgj is the fluent ∃x (sDg &lt; x ∧ Prev(x ≤ sDg)) saying the degree drops (with I |= Prev(co) iff (†) is intimately related to block compression bc (Fernando 2013b), supporting derivations of (c) and (d) by a modification &amp;bc of &amp; defined in §2.3 below. Our third example directly concerns computational processes, which we take up in section 3. Example C (finite automata) Given a finite alphabet A, a (non-deterministic) finite automaton A over A is a quadruple (Q, 6, F, q0) consisting of a finite set Q of states, a transition relation 6 ⊆ Q × A × Q, a subset F of Q consisting of final (accepting) states, and an initial state q0 ∈ Q. Aaccepts a string a1 · · · an ∈ A* precisely if there is a string q1 · · · qn ∈ Qn such that qn ∈ F and 6(qi_1, ai, qi) fo</context>
<context position="19940" citStr="Fernando 2013" startWordPosition="3934" endWordPosition="3935">=6 ∅. Notice that no a ∈ A is required to interpret ∃x∃y S(x, y), which after all is an MSO∅-sentence suited to strings ⊥n ∈ S(∅). Furthermore, for a =6 b and {a, b} ⊆ A, no string in A+ satisfies ∃x Ua(x) ∧ Ub(x) (6) which makes it awkward to extend |=A to formulas with free variables (requiring variable assignments on top of strings in A+). A simple way to accommodate variables is to include them in A and interpret MSOA-formulas not over A+ but over (2A)+, lifting |=A from strings s over A to a predicate |=A on strings over 2A such that s |=A ϕ iff ηA(s) |=A ϕ (7) for every MSOA-sentence ϕ (Fernando 2013a). For all s ∈ (2A)+, we set s |=A S(x, y) iff ρ{x,y}(s) ∈ ∗ x for a, b ∈ A. Working back from (7) s |=A ϕ iff ηA(s) |=A ϕ to the B¨uchi-Elgot-Trakhtenbrot theorem, one can check that for every finite A and MSOA-formula ϕ, the set LA(ϕ) := {s ∈ (2A)+ |s |=A ϕ} of strings over 2A that |=A-satisfy ϕ is regular, using the fact that for all A0 ⊆ A, the restriction of ρA, to (2A)∗ is computable by a finite state transducer. But for A ⊆ Φ,4 ρA, r (2A)∗ is just Pid(A, A0). In recognition of the role of these functions in |=A, we effectivize the presheaf Qid from §2.3 as follows. Let RD be the preshe</context>
</contexts>
<marker>Fernando, 2013</marker>
<rawString>Tim Fernando. 2013a. Finite state methods and description logics Proceedings of the 11th International Conference on Finite State Methods and Natural Language Processing, pages 63 – 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Dowty’s aspect hypothesis segmented.</title>
<date>2013</date>
<booktitle>Proceedings of the 19th Amsterdam Colloquium,</booktitle>
<pages>107--114</pages>
<contexts>
<context position="8826" citStr="Fernando 2013" startWordPosition="1665" endWordPosition="1666"> iff whenever 1 ≤ i ≤ n and co ∈ Ii, Ii |= coi and analyze (a) above as (c) below, where d is the contextually given threshold required by in an hour, and x is the start of that hour, the end of which is marked by hour(x). (c) x, d ≤ sDg d ≤ sDg hour(x), sDg &lt; d All fluents co in (c) have the stative property (†) for all intervals I and I&apos; whose union I ∪ I&apos; is an interval, I ∪ I&apos; |= co iff I |= co and I&apos; |= co I |= [w]co iff (∀I&apos; v I) I&apos; |= co and sDgj is the fluent ∃x (sDg &lt; x ∧ Prev(x ≤ sDg)) saying the degree drops (with I |= Prev(co) iff (†) is intimately related to block compression bc (Fernando 2013b), supporting derivations of (c) and (d) by a modification &amp;bc of &amp; defined in §2.3 below. Our third example directly concerns computational processes, which we take up in section 3. Example C (finite automata) Given a finite alphabet A, a (non-deterministic) finite automaton A over A is a quadruple (Q, 6, F, q0) consisting of a finite set Q of states, a transition relation 6 ⊆ Q × A × Q, a subset F of Q consisting of final (accepting) states, and an initial state q0 ∈ Q. Aaccepts a string a1 · · · an ∈ A* precisely if there is a string q1 · · · qn ∈ Qn such that qn ∈ F and 6(qi_1, ai, qi) fo</context>
<context position="19940" citStr="Fernando 2013" startWordPosition="3934" endWordPosition="3935">=6 ∅. Notice that no a ∈ A is required to interpret ∃x∃y S(x, y), which after all is an MSO∅-sentence suited to strings ⊥n ∈ S(∅). Furthermore, for a =6 b and {a, b} ⊆ A, no string in A+ satisfies ∃x Ua(x) ∧ Ub(x) (6) which makes it awkward to extend |=A to formulas with free variables (requiring variable assignments on top of strings in A+). A simple way to accommodate variables is to include them in A and interpret MSOA-formulas not over A+ but over (2A)+, lifting |=A from strings s over A to a predicate |=A on strings over 2A such that s |=A ϕ iff ηA(s) |=A ϕ (7) for every MSOA-sentence ϕ (Fernando 2013a). For all s ∈ (2A)+, we set s |=A S(x, y) iff ρ{x,y}(s) ∈ ∗ x for a, b ∈ A. Working back from (7) s |=A ϕ iff ηA(s) |=A ϕ to the B¨uchi-Elgot-Trakhtenbrot theorem, one can check that for every finite A and MSOA-formula ϕ, the set LA(ϕ) := {s ∈ (2A)+ |s |=A ϕ} of strings over 2A that |=A-satisfy ϕ is regular, using the fact that for all A0 ⊆ A, the restriction of ρA, to (2A)∗ is computable by a finite state transducer. But for A ⊆ Φ,4 ρA, r (2A)∗ is just Pid(A, A0). In recognition of the role of these functions in |=A, we effectivize the presheaf Qid from §2.3 as follows. Let RD be the preshe</context>
</contexts>
<marker>Fernando, 2013</marker>
<rawString>Tim Fernando. 2013b. Dowty’s aspect hypothesis segmented. Proceedings of the 19th Amsterdam Colloquium, pages 107 – 114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danny Fox</author>
<author>Martin Hackl</author>
</authors>
<title>The universal density of measurement.</title>
<date>2006</date>
<journal>Linguistics and Philosophy</journal>
<volume>29</volume>
<issue>5</issue>
<pages>537--586</pages>
<contexts>
<context position="2244" citStr="Fox and Hackl 2006" startWordPosition="348" endWordPosition="351"> 1972, which seem to have met less resistance than arguments in the degree literature from Kennedy 2001 and Schwarzschild and Wilkinson 2002 (see Solt 2013). At the center of the present argument for intervals is a notion of finite approximability, plausibly related to cognition. What objection might there be to it? The fact that no finite linear order is dense raises the issue of compatibility between finite approximability and density — no small worry, given the popularity of dense linear orders for time (e.g. Kamp and Reyle 1993, PrattHartmann 2005, Klein 2009) as well as measurement (e.g. Fox and Hackl 2006). Fortunately, finite linear orders can be organized into a system of approximations converging at the limit to a dense linear order. The present work details ways to form such systems and limits, with density reanalyzed as refinability of arbitrary finite approximations. A familiar example provides some orientation. Example A (calendar) We can represent a calendar year as the string smo := Jan Feb Mar ··· Dec of length 12, or, were we interested also in days d1,d2...,d31, the string smo,dy := Jan,d1 Jan,d2 · · · Jan,d31 Feb,d1 · · · Dec,d31 of length 365 for a non-leap year (Fernando 2011).1 </context>
</contexts>
<marker>Fox, Hackl, 2006</marker>
<rawString>Danny Fox and Martin Hackl. 2006. The universal density of measurement. Linguistics and Philosophy 29(5): 537 – 586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Goguen</author>
<author>Rod Burstall</author>
</authors>
<title>Institutions: Abstract model theory for specification and programming,</title>
<date>1992</date>
<journal>J. ACM,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="24258" citStr="Goguen and Burstall 1992" startWordPosition="4829" endWordPosition="4832">wo ways information may grow from f RD-objects (A, L) to (B, L&apos;) — expansively with A C_ B and L = ρAL&apos;, and eliminatively with L&apos; C_ L and A = B. The same notion of f-entailment defined in §2.3 through the sets QA, L]f applies, but we have been careful here to fix f to id, in view of Proposition 6. For A C_ B E Fin(b), ϕ an MSOA-formula and s E (2B)+, s |=B ϕ iff ρA(s) |=A ϕ. Proposition 6 says that s |=B ϕ depends only on the part ρA(s) of s mentioned in ϕ. It is a particular instance of the satisfaction condition in institutions, expressing the invariance of truth under change of notation (Goguen and Burstall 1992). Proposition 6 breaks down if we replace ρA by bcA or unpadA, as can be seen with A = 0, and ϕ = lxly S(x, y), for which recall (11). 3.3 Varying grain and span Troublesome as they are, the maps bcA and unpadA have some use. Just as we can vary temporal grain through bc (Examples A and B in section 1), we can vary temporal span through unpad. For instance, we can combine runs of automata A1 over A1 and A2 over A2 in L(A1, A2) := AcRun(A1) &amp;unpad AcRun(A2) with the subscript unpad on &amp; relaxing the requirement that A1 and A2 start and finish together (running in lockstep throughout). For i E {</context>
</contexts>
<marker>Goguen, Burstall, 1992</marker>
<rawString>Joseph Goguen and Rod Burstall. 1992., Institutions: Abstract model theory for specification and programming, J. ACM, 39(1):95–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<date>1993</date>
<booktitle>From Discourse to Logic.</booktitle>
<publisher>Kluwer.</publisher>
<contexts>
<context position="2162" citStr="Kamp and Reyle 1993" startWordPosition="333" endWordPosition="336">linguistic semantics perhaps are those in tense and aspect from Bennett and Partee 1972, which seem to have met less resistance than arguments in the degree literature from Kennedy 2001 and Schwarzschild and Wilkinson 2002 (see Solt 2013). At the center of the present argument for intervals is a notion of finite approximability, plausibly related to cognition. What objection might there be to it? The fact that no finite linear order is dense raises the issue of compatibility between finite approximability and density — no small worry, given the popularity of dense linear orders for time (e.g. Kamp and Reyle 1993, PrattHartmann 2005, Klein 2009) as well as measurement (e.g. Fox and Hackl 2006). Fortunately, finite linear orders can be organized into a system of approximations converging at the limit to a dense linear order. The present work details ways to form such systems and limits, with density reanalyzed as refinability of arbitrary finite approximations. A familiar example provides some orientation. Example A (calendar) We can represent a calendar year as the string smo := Jan Feb Mar ··· Dec of length 12, or, were we interested also in days d1,d2...,d31, the string smo,dy := Jan,d1 Jan,d2 · · ·</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Hans Kamp and Uwe Reyle. 1993. From Discourse to Logic. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
</authors>
<title>Polar opposition and the ontology of degrees.</title>
<date>2001</date>
<journal>Linguistics and Philosophy</journal>
<volume>24</volume>
<pages>33--70</pages>
<contexts>
<context position="1728" citStr="Kennedy 2001" startWordPosition="262" endWordPosition="263">inements and adjustments. The basic picture is that a scale is a moving target finitely approximable as a string over an alphabet which we can expand to refine granularity. Reducing a scale to a string comes, however, at a price; indivisible points must give way to refinable intervals (embodying underspecification). Arguments for a semantic reorientation around intervals (away from points) are hardly new. Best known within linguistic semantics perhaps are those in tense and aspect from Bennett and Partee 1972, which seem to have met less resistance than arguments in the degree literature from Kennedy 2001 and Schwarzschild and Wilkinson 2002 (see Solt 2013). At the center of the present argument for intervals is a notion of finite approximability, plausibly related to cognition. What objection might there be to it? The fact that no finite linear order is dense raises the issue of compatibility between finite approximability and density — no small worry, given the popularity of dense linear orders for time (e.g. Kamp and Reyle 1993, PrattHartmann 2005, Klein 2009) as well as measurement (e.g. Fox and Hackl 2006). Fortunately, finite linear orders can be organized into a system of approximations</context>
</contexts>
<marker>Kennedy, 2001</marker>
<rawString>Christopher Kennedy. 2001. Polar opposition and the ontology of degrees. Linguistics and Philosophy 24. 33 – 70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ewan Klein</author>
<author>Michael Rovatsos</author>
</authors>
<title>Temporal Vagueness, Coordination and Communication</title>
<date>2011</date>
<booktitle>In Vagueness in Communication 2009, LNAI 6517,</booktitle>
<pages>108--126</pages>
<contexts>
<context position="1010" citStr="Klein and Rovatsos 2011" startWordPosition="145" endWordPosition="148">haping types by the processes that put semantics in flux. 1 Introduction An important impetus for recent investigations into type theory for natural language semantics is the view of “semantics in flux,” correcting “the impression” from, for example, Montague 1973 “of natural languages as being regimented with meanings determined once and for all” (Cooper 2012, page 271). The present work concerns scales for temporal expressions and gradable predicates. Two questions that loom large from the perspective of semantics in flux are: how to construct scales and align them against one another (e.g. Klein and Rovatsos 2011). The formal study carried out below keeps scales as simple as possible, whilst allowing for necessary refinements and adjustments. The basic picture is that a scale is a moving target finitely approximable as a string over an alphabet which we can expand to refine granularity. Reducing a scale to a string comes, however, at a price; indivisible points must give way to refinable intervals (embodying underspecification). Arguments for a semantic reorientation around intervals (away from points) are hardly new. Best known within linguistic semantics perhaps are those in tense and aspect from Ben</context>
</contexts>
<marker>Klein, Rovatsos, 2011</marker>
<rawString>Ewan Klein and Michael Rovatsos. 2011. Temporal Vagueness, Coordination and Communication In Vagueness in Communication 2009, LNAI 6517, pages 108–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Klein</author>
</authors>
<title>How time is encoded.</title>
<date>2009</date>
<booktitle>The Expression of Time, pages 39 – 81, Mouton De Gruyter.</booktitle>
<editor>In W. Klein and P. Li, editors,</editor>
<contexts>
<context position="2195" citStr="Klein 2009" startWordPosition="340" endWordPosition="341"> tense and aspect from Bennett and Partee 1972, which seem to have met less resistance than arguments in the degree literature from Kennedy 2001 and Schwarzschild and Wilkinson 2002 (see Solt 2013). At the center of the present argument for intervals is a notion of finite approximability, plausibly related to cognition. What objection might there be to it? The fact that no finite linear order is dense raises the issue of compatibility between finite approximability and density — no small worry, given the popularity of dense linear orders for time (e.g. Kamp and Reyle 1993, PrattHartmann 2005, Klein 2009) as well as measurement (e.g. Fox and Hackl 2006). Fortunately, finite linear orders can be organized into a system of approximations converging at the limit to a dense linear order. The present work details ways to form such systems and limits, with density reanalyzed as refinability of arbitrary finite approximations. A familiar example provides some orientation. Example A (calendar) We can represent a calendar year as the string smo := Jan Feb Mar ··· Dec of length 12, or, were we interested also in days d1,d2...,d31, the string smo,dy := Jan,d1 Jan,d2 · · · Jan,d31 Feb,d1 · · · Dec,d31 of </context>
</contexts>
<marker>Klein, 2009</marker>
<rawString>Wolfgang Klein. 2009. How time is encoded. In W. Klein and P. Li, editors, The Expression of Time, pages 39 – 81, Mouton De Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saunders Mac Lane</author>
<author>Ieke Moerdijk</author>
</authors>
<title>Sheaves in Geometry and Logic: A First Introduction to Topos Theory.</title>
<date>1992</date>
<publisher>Springer.</publisher>
<contexts>
<context position="6161" citStr="Lane and Moerdijk 1992" startWordPosition="1109" endWordPosition="1112">nguage L0 such that L = (LA &amp; LB−A) ∩ L0 (1) other than L0 = L. For a decomposition (1) of L into (generic) contextual constraints L0 separate from the (specific) components LA and LB−A, it will be useful to sharpen LA, LB−A and &amp;, factoring in bc and variants of bc (not to mention ∩). Measurements ranging from crude comparisons (of order) to quantitative judgments (multiplying unit magnitudes with real numbers) can be expressed through fluents in Φ. We interpret the fluents relative to suitable strings in Fin(Φ)∗, presented below in category-theoretic terms connected to type theory (e.g. Mac Lane and Moerdijk 1992). Central to this presentation is the notion of a presheaf on Fin(Φ) — a functor from the opposite category Fin(Φ)op (a morphism in which is a pair (B, A) of finite subsets of Φ such that A ⊆ B) to the category Set of sets and functions. The Fin(Φ)-indexed family of functions bcA (for A ∈ Fin(Φ)) provides an important example that we generalize in section 2. An example of linguistic semantic interest to which block compression bc applies is 31 Feb 28 ··· 31 . Jan Dec bc(s) := { 64 (Dowty 1979). (†) holds also for the fluents in the string (d) below for (b), where the subinterval relation v is </context>
<context position="12992" citStr="Lane and Moerdijk 1992" startWordPosition="2486" endWordPosition="2489"> stripping off any initial or final empty boxes unpad(s&apos;) ifs= s&apos; or else s = s&apos; s otherwise so that unpad(s) neither begins nor ends with Notice that bn; unpad = unpad; bn. Proposition 3. If f and g are 4b-preserving and f; g = g; f, then f; g is 4b-preserving. 2.2 The Grothendieck construction Given a presheaf F on Fin(4b), the category f F of elements of F (also known as the Grothendieck construction for F) has - objects (A, s) ∈ Fin(4b) × F(A) (making EXEFin(Φ) F(X) the set of objects in f F) - morphisms (B, s&apos;, A, s) from objects (B, s&apos;) to (A, s) when A ⊆ B and F(B, A)(s&apos;) = s (e.g. Mac Lane and Moerdijk 1992). Let 7rf be the left projection 7rf(A, s) = A n U αi i=1 unpad(s) := { . 66 from f Pf back to Fin(Φ). The inverse limit of P f, lim←− P f, is the set of (f P f)-valued presheaves p on Fin (Φ) (i.e. functors p : Fin(Φ)°p → f P f) that are inverted by πf πf(p(A)) = A for all A ∈ Fin(Φ). That is, p(A) = (A, sA) for some sA ∈ f(2A)* such that (‡) sA = fA(sB) whenever A ⊆ B ∈ Fin(Φ). (‡) is the essential restriction that lim ←− Pf adds to objects {sX}XEFin(Φ) of the dependent type H XEFin(Φ) Pf(X). 2.3 Superposition and non-determinism Taking the presheaf Pid induced by the identity function id on</context>
</contexts>
<marker>Lane, Moerdijk, 1992</marker>
<rawString>Saunders Mac Lane and Ieke Moerdijk. 1992. Sheaves in Geometry and Logic: A First Introduction to Topos Theory. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Pratt-Hartmann</author>
</authors>
<title>Temporal prepositions and their logic.</title>
<date>2005</date>
<journal>Artificial Intelligence</journal>
<volume>166</volume>
<pages>1--36</pages>
<marker>Pratt-Hartmann, 2005</marker>
<rawString>Ian Pratt-Hartmann. 2005. Temporal prepositions and their logic. Artificial Intelligence 166: 1–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Schwarzschild</author>
<author>Karina Wilkinson</author>
</authors>
<title>Quantifiers in comparatives: A semantics of degree based on intervals.</title>
<date>2002</date>
<journal>Natural Language Semantics</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="1765" citStr="Schwarzschild and Wilkinson 2002" startWordPosition="265" endWordPosition="268">stments. The basic picture is that a scale is a moving target finitely approximable as a string over an alphabet which we can expand to refine granularity. Reducing a scale to a string comes, however, at a price; indivisible points must give way to refinable intervals (embodying underspecification). Arguments for a semantic reorientation around intervals (away from points) are hardly new. Best known within linguistic semantics perhaps are those in tense and aspect from Bennett and Partee 1972, which seem to have met less resistance than arguments in the degree literature from Kennedy 2001 and Schwarzschild and Wilkinson 2002 (see Solt 2013). At the center of the present argument for intervals is a notion of finite approximability, plausibly related to cognition. What objection might there be to it? The fact that no finite linear order is dense raises the issue of compatibility between finite approximability and density — no small worry, given the popularity of dense linear orders for time (e.g. Kamp and Reyle 1993, PrattHartmann 2005, Klein 2009) as well as measurement (e.g. Fox and Hackl 2006). Fortunately, finite linear orders can be organized into a system of approximations converging at the limit to a dense l</context>
</contexts>
<marker>Schwarzschild, Wilkinson, 2002</marker>
<rawString>Roger Schwarzschild and Karina Wilkinson. 2002. Quantifiers in comparatives: A semantics of degree based on intervals. Natural Language Semantics 10(1):1–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Solt</author>
</authors>
<date>2013</date>
<note>Scales in natural language. Manuscript.</note>
<contexts>
<context position="1781" citStr="Solt 2013" startWordPosition="270" endWordPosition="271">cale is a moving target finitely approximable as a string over an alphabet which we can expand to refine granularity. Reducing a scale to a string comes, however, at a price; indivisible points must give way to refinable intervals (embodying underspecification). Arguments for a semantic reorientation around intervals (away from points) are hardly new. Best known within linguistic semantics perhaps are those in tense and aspect from Bennett and Partee 1972, which seem to have met less resistance than arguments in the degree literature from Kennedy 2001 and Schwarzschild and Wilkinson 2002 (see Solt 2013). At the center of the present argument for intervals is a notion of finite approximability, plausibly related to cognition. What objection might there be to it? The fact that no finite linear order is dense raises the issue of compatibility between finite approximability and density — no small worry, given the popularity of dense linear orders for time (e.g. Kamp and Reyle 1993, PrattHartmann 2005, Klein 2009) as well as measurement (e.g. Fox and Hackl 2006). Fortunately, finite linear orders can be organized into a system of approximations converging at the limit to a dense linear order. The</context>
</contexts>
<marker>Solt, 2013</marker>
<rawString>Stephanie Solt. 2013. Scales in natural language. Manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Thomas</author>
</authors>
<title>Languages, automata and logic.</title>
<date>1997</date>
<booktitle>In Handbook of Formal Languages: Beyond Words,</booktitle>
<volume>3</volume>
<pages>389--455</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="17763" citStr="Thomas 1997" startWordPosition="3480" endWordPosition="3481"> handy to introduce a bottom ⊥ for B − A, adjoining ⊥ to a finite subset X of Φ for X⊥ := X + {⊥} before forming the strings in S(X) := X⊥∗. We then set S(B, A) : B⊥∗ → A⊥∗ S(B,A)(c) := c � β S(B, A)(s) if β ∈ A⊥ S(B, A)(βs) := ⊥ S(B,A)(s) otherwise (e.g. S({a, b}, {a})(ba⊥) = ⊥a⊥) and let qA : A⊥∗ → (2A)∗ map c to itself, and Proposition 5. q is a natural transformation from S to Pid. 3.2 Another presheaf and category Turning now to finite automata, we recall a fundamental result about languages that are regular (i.e., accepted by finite automata),3 the B¨uchi-ElgotTrakhtenbrot theorem (e.g. Thomas 1997) �qA(αs) := qA(s) if α = ⊥ α qA(s) otherwise (e.g. q{a}(⊥a⊥) = a ). a1 ··· an &amp; q1 ··· qn (4) where a1 · · · an is accepted by a finite automaton A going through the sequence q1 · · · qn of (internal) states. We can assume the tape alphabet A ⊇ {a1, ... , an} and the state set Q ⊇ {q1, ... , qn} are two disjoint subsets of the set Φ of fluents; fluents in A are “observable” (on a tape), while fluents in Q are “hidden” (inside a black box). Disjoint though they may be, A and Q are tightly coupled by A’s transition table S ⊆ Q×A×Q (not to mention the other components of A, its initial and final </context>
</contexts>
<marker>Thomas, 1997</marker>
<rawString>Wolfgang Thomas. 1997. Languages, automata and logic. In Handbook of Formal Languages: Beyond Words, volume 3, pages 389 – 455. Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>