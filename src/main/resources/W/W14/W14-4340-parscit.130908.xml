<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000311">
<title confidence="0.9980695">
Word-Based Dialog State Tracking
with Recurrent Neural Networks
</title>
<author confidence="0.998762">
Matthew Henderson, Blaise Thomson and Steve Young
</author>
<affiliation confidence="0.9980615">
Department of Engineering,
University of Cambridge, U.K.
</affiliation>
<email confidence="0.993459">
{mh521, brmt2, sjy}@eng.cam.ac.uk
</email>
<sectionHeader confidence="0.99738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9976486875">
Recently discriminative methods for track-
ing the state of a spoken dialog have been
shown to outperform traditional generative
models. This paper presents a new word-
based tracking method which maps di-
rectly from the speech recognition results
to the dialog state without using an explicit
semantic decoder. The method is based on
a recurrent neural network structure which
is capable of generalising to unseen dialog
state hypotheses, and which requires very
little feature engineering. The method
is evaluated on the second Dialog State
Tracking Challenge (DSTC2) corpus and
the results demonstrate consistently high
performance across all of the metrics.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999952919354839">
While communicating with a user, statistical spo-
ken dialog systems must maintain a distribution
over possible dialog states in a process called di-
alog state tracking. This distribution, also called
the belief state, directly determines the system’s
decisions. In MDP-based systems, only the most
likely dialog state is considered and in this case
the primary metric is dialog state accuracy (Bo-
hus and Rudnicky, 2006). In POMDP-based sys-
tems, the full distribution is considered and then
the shape of the distribution as measured by an L2
norm is equally important (Young et al., 2009). In
both cases, good quality state tracking is essential
to maintaining good overall system performance.
Typically, state tracking has assumed the output
of a Spoken Language Understanding (SLU) com-
ponent in the form of a semantic decoder, which
maps the hypotheses from Automatic Speech
Recognition (ASR) to a list of semantic hypothe-
ses. This paper considers mapping directly from
ASR hypotheses to an updated belief state at each
turn in the dialog, omitting the intermediate SLU
processing step. This word-based state tracking
avoids the need for an explicit semantic represen-
tation and also avoids the possibility of informa-
tion loss at the SLU stage.
Recurrent neural networks (RNNs) provide a
natural model for state tracking in dialog, as
they are able to model and classify dynamic se-
quences with complex behaviours from step to
step. Whereas, most previous approaches to dis-
criminative state tracking have adapted station-
ary classifiers to the temporal process of dialog
(Bohus and Rudnicky, 2006; Lee and Eskenazi,
2013; Lee, 2013; Williams, 2013; Henderson et
al., 2013b). One notable exception is Ren et al.
(2013), which used conditional random fields to
model the sequence temporally.
Currently proposed methods of discriminative
state tracking require engineering of feature func-
tions to represent the turn in the dialog (Ren et
al., 2013; Lee and Eskenazi, 2013; Lee, 2013;
Williams, 2013; Henderson et al., 2013b). It is un-
clear whether differences in performance are due
to feature engineering or the underlying models.
This paper proposes a method of using simple n-
gram type features which avoid the need for fea-
ture engineering. Instead of using inputs with a se-
lect few very informative features, the approach is
to use high-dimensional inputs with all the infor-
mation to potentially reconstruct any such hand-
crafted feature. The impact of significantly in-
creasing the dimensionality of the inputs is man-
aged by careful initialisation of model parameters.
Accuracy on unseen or infrequent slot values
is an important concern, particularly for discrim-
inative classifiers which are prone to overfitting
training data. This is addressed by structuring
the recurrent neural network to include a compo-
nent which is independent of the actual slot value
in question. It thus learns general behaviours for
specifying slots enabling it to successfully decode
</bodyText>
<page confidence="0.952906">
292
</page>
<note confidence="0.732584">
Proceedings of the SIGDIAL 2014 Conference, pages 292–299,
Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9977745">
ASR output which includes previously unseen slot
values.
In summary, this paper presents a word-based
approach to dialog state tracking using recurrent
neural networks. The model is capable of gen-
eralising to unseen dialog state hypotheses, and
requires very little feature engineering. The ap-
proach is evaluated in the second Dialog State
Tracking Challenge (DSTC2) (Henderson et al.,
2014) where it is shown to be extremely competi-
tive, particularly in terms of the quality of its con-
fidence scores.
</bodyText>
<listItem confidence="0.9565858">
Following a brief outline of DSTC2 in section
2, the definition of the model is given in section
3. Section 4 then gives details on the initialisation
methods used for training. Finally results on the
DSTC2 evaluation are given in 5.
</listItem>
<sectionHeader confidence="0.980181" genericHeader="method">
2 The Second Dialog State Tracking
Challenge
</sectionHeader>
<bodyText confidence="0.9996285">
This section describes the domain and method-
ology of the second Dialog State Tracking Chal-
lenge (DSTC2). The challenge is based on a
large corpus collected using a variety of telephone-
based dialog systems in the domain of finding a
restaurant in Cambridge. In all cases, the subjects
were recruited using Amazon Mechanical Turk.
The data is split into a train, dev and test set.
The train and dev sets were supplied with labels,
and the test set was released unlabelled for a one
week period. At the end of the week, all partici-
pants were required to submit their trackers’ out-
put on the test set, and the labels were revealed. A
mis-match was ensured between training and test-
ing conditions by choosing dialogs for the eval-
uation collected using a separate dialog manager.
This emulates the mis-match a new tracker would
encounter if it were actually deployed in an end-
to-end system.
In summary, the datasets used are:
</bodyText>
<listItem confidence="0.978863888888889">
• dstc2 train - Labelled training consisting of
1612 dialogs with two dialog managers and
two acoustic conditions.
• dstc2 dev - Labelled dataset consisting
of 506 calls in the same conditions as
dstc2 train, but with no caller in common.
• dstc2 test - Evaluation dataset consisting of
1117 dialogs collected using a dialog man-
ager not seen in the labelled data.
</listItem>
<bodyText confidence="0.97822825">
In contrast with DSTC1, DSTC2 introduces dy-
namic user goals, tracking of requested slots and
tracking the restaurant search method. A DSTC2
tracker must therefore report:
</bodyText>
<listItem confidence="0.978758">
• Goals: A distribution over the user’s goal for
each slot. This is a distribution over the possi-
ble values for that slot, plus the special value
None, which means no valid value has been
mentioned yet.
• Requested slots: A reported probability for
each requestable slot that has been requested
by the user, and should be informed by the
system.
• Method: A distribution over methods, which
encodes how the user is trying to use the di-
alog system. E.g. ‘by constraints’, when the
user is trying to constrain the search, and ‘fin-
</listItem>
<bodyText confidence="0.958310625">
ished’, when the user wants to end the dialog.
A tracker may report the goals as a joint over
all slots, but in this paper the joint is reported as a
product of the marginal distributions per slot.
Full details of the challenge are given in Hen-
derson et al. (2013a), Henderson et al. (2014). The
trackers presented in this paper are identified un-
der ‘team4’ in the reported results.
</bodyText>
<sectionHeader confidence="0.975488" genericHeader="method">
3 Recurrent Neural Network Model
</sectionHeader>
<bodyText confidence="0.999890888888889">
This section defines the RNN structure used for
dialog state tracking. One such RNN is used per
slot, taking the most recent dialog turn (user input
plus last machine dialog act) as input, updating its
internal memory and calculating an updated belief
over the values for the slot. In what follows, the
notation a ⊕ b is used to denote the concatenation
of two vectors, a and b. The ith component of the
vector a is written a|i.
</bodyText>
<subsectionHeader confidence="0.999601">
3.1 Feature Representation
</subsectionHeader>
<bodyText confidence="0.998817">
Extracting n-grams from utterances and dialog
acts provides the feature representations needed
for input into the RNN. This process is very sim-
ilar to the feature extraction described in Hender-
son et al. (2012), and is outlined in figure 1.
For n-gram features extracted from the ASR
N-best list, unigram, bigram and trigram features
are calculated for each hypothesis. These are
then weighted by the N-best list probabilities and
summed to give a single vector.
Dialog acts in this domain consist of
a list of component acts of the form
acttype(slot=value) where the slot=value
pair is optional. The n-gram type features
</bodyText>
<page confidence="0.997286">
293
</page>
<bodyText confidence="0.979585605263158">
extracted from each such component act are
‘acttype’, ‘slot’, ‘value’, ‘acttype
slot’, ‘slot value’ and ‘acttype slot
value’, or just ‘acttype’ for the act acttype().
Each feature is given weight 1, and the features
from individual component acts are summed.
To provide a contrast, trackers have also been
implemented using the user dialog acts output by
an SLU rather than directly from the ASR output.
In this case, the SLU N-best dialog act list is en-
coded in the same way except that the n-grams
from each hypothesis are weighted by the corre-
sponding probabilities, and summed to give a sin-
gle feature vector.
Consider a word-based tracker which takes an
ASR N-best list and the last machine act as input
for each turn, as shown in figure 1. A combined
feature representation of both the ASR N-best list
and the last machine act is obtained by concate-
nating the vectors. This means that in figure 1 the
food feature from the ASR and the food feature
from the machine act contribute to separate com-
ponents of the final vector f.
Figure 1: Example of feature extraction for one
turn, giving f, fs and f„. Here s = food. For all
v /E{indian, jamaican}, f„ = 0.
Note that all the methods for tracking reported
in DSTC1 required designing feature functions.
For example, suggested feature functions included
the SLU score in the current turn, the probabil-
ity of an ‘affirm’ act when the value has been
confirmed by the system, the output from base-
line trackers etc. (e.g. Lee and Eskenazi (2013),
Williams (2013), Henderson et al. (2013b)). In
contrast, the approach described here is to present
the model with all the information it would need
to reconstruct any feature function that might be
useful.
</bodyText>
<subsectionHeader confidence="0.99986">
3.2 Generalisation to Unseen States
</subsectionHeader>
<bodyText confidence="0.999976652173913">
One key issue in applying machine learning to the
task of dialog state tracking is being able to deal
with states which have not been seen in training.
For example, the system should be able to recog-
nise any obscure food type which appears in the
set of possible food types. A naive neural net-
work structure mapping n-gram features to an up-
dated distribution for the food slot, with no tying
of weights, would require separate examples of
each of the food types to learn what n-grams are
associated with each. In reality however n-grams
like ‘&lt;value&gt; food’ and ‘serving &lt;value&gt;’ are likely
to correspond to the hypothesis food=‘&lt;value&gt;’ for
any food-type replacing ‘&lt;value&gt;’.
The approach taken here is to embed a network
which learns a generic model of the updated belief
of a slot-value assignment as a function of ‘tagged’
features, i.e. features which ignore the specific
identity of a value. This can be considered as re-
placing all occurrences of a particular value with
a tag like ‘&lt;value&gt;’. Figure 1 shows the process of
creating the tagged feature vectors, fs and f„ from
the untagged vector f.
</bodyText>
<subsectionHeader confidence="0.999263">
3.3 Model Definition
</subsectionHeader>
<bodyText confidence="0.963139933333333">
In this section an RNN is described for tracking
the goal for a given slot, s, throughout the se-
quence of a dialog. The RNN holds an internal
memory, m E RN-e- which is updated at each
step. If there are N possible values for slot s, then
the probability distribution output p is in RN+1,
with the last component p|N giving the probabil-
ity of the None hypothesis. Figure 2 provides an
overview of how p and m are updated in one turn
to give the new belief and memory, p&apos; and m&apos;.
One part of the neural network is used to learn
a mapping from the untagged inputs, full memory
and previous beliefs to a vector h E RN which
goes directly into the calculation of p&apos;:
h = NNet (f ® p ® m) E RN
</bodyText>
<figure confidence="0.999248670731708">
ASR
jamaican food 0.9
indian food 0.1
Machine Act
confirm(food=jamaican)
jamaican
jamaican food 0.9
jamaican &lt;slot&gt; 0.9
food
indian 0.1
indian food
indian &lt;slot&gt; 0.1
e.g. v = jamaican
&lt;slot&gt;
&lt;value&gt;
&lt;value&gt; &lt;slot&gt; 1.0
&lt;value&gt; food 1.0
&lt;value&gt; food
&lt;value&gt;
5 non-zero
elements
6 non-zero
elements
2 non-zero
elements
0.9
0.9
0.9
1.0
1.0
1.0
0.1
&lt;value&gt; 1.0
confirm food
&lt;value&gt;
food &lt;value&gt;
food &lt;value&gt;
confirm &lt;slot&gt;
jamaican
&lt;slot&gt;
jamaican
confirm &lt;slot&gt;
&lt;value&gt;
&lt;slot&gt; &lt;value&gt;
&lt;slot&gt; 1.0
&lt;value&gt; 1.0
confirm food
&lt;value&gt;
jamaican 1.0
confirm food
jamaican
food jamaican
food 1.0
confirm food
confirm 1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
for each value, v
3 non-zero
elements
6 non-zero
elements
8 non-zero
elements
14 non-zero
elements
11 non-zero
elements
5 non-zero
elements
fv
fs
f
</figure>
<figureCaption confidence="0.999988">
Figure 2: Calculation of p&apos; and m&apos; for one turn
</figureCaption>
<bodyText confidence="0.999771846153846">
where NNet(·) denotes a neural network function
of the input. In this paper all such networks have
one hidden layer with a sigmoidal activation func-
tion.
The sub-network for h requires examples of ev-
ery value in training, and is prone to poor general-
isation as explained in section 3.2. By including a
second sub-network for g which takes tagged fea-
tures as input, it is possible to exploit the obser-
vation that the string corresponding to a value in
various contexts is likely to be good evidence for
or against that value. For each value v, a compo-
nent of g is calculated using the neural network:
</bodyText>
<equation confidence="0.929118666666667">
� f ⊕ fs ⊕ fv⊕
g|v = NNet ∈ R
{p|v, p|N} ⊕ m
</equation>
<bodyText confidence="0.985139909090909">
By using regularisation, the learning will pre-
fer where possible to use the sub-network for g
rather than learning the individual weights for
each value required in the sub-network for h. This
sub-network is able to deal with unseen or infre-
quently seen dialog states, so long as the state can
be tagged in the feature extraction. This model can
also be shared across slots since fs is included as
an input, see section 4.2.
The sub-networks applied to tagged and un-
tagged inputs are combined to give the new belief:
p&apos; = softmax ([h + g] ⊕ {B}) ∈ RN+1
where B is a parameter of the RNN, contributing
to the None hypothesis. The contribution from g
may be seen as accounting for general behaviour
of tagged hypotheses, while h makes corrections
due to correlations with untagged features and
value specific behaviour e.g. special ways of ex-
pressing specific goals and fitting to specific ASR
confusions.
Finally, the memory is updated according to the
logistic regression:
</bodyText>
<equation confidence="0.62223">
m&apos; = Q (Wmof + Wmlm) ∈ RN---
</equation>
<bodyText confidence="0.997016">
where the Wmi are parameters of the RNN.
</bodyText>
<subsectionHeader confidence="0.987854">
3.4 Requested Slots and Method
</subsectionHeader>
<bodyText confidence="0.999046428571429">
A similar RNN is used to track the requested slots.
Here the v runs over all the requestable slots, and
requestable slot names are tagged in the feature
vectors fv. This allows the neural network calcu-
lating g to learn general patterns across slots just
as in the case of goals. The equation for p&apos; is
changed to:
</bodyText>
<equation confidence="0.869616">
p&apos; = Q (h + g)
</equation>
<bodyText confidence="0.9873482">
so each component of p&apos; represents the probability
(between 0 and 1) of a slot being requested.
For method classification, the same RNN struc-
ture as for a goal is used. No tagging of the feature
vectors is used in the case of methods.
</bodyText>
<sectionHeader confidence="0.996463" genericHeader="method">
4 Training
</sectionHeader>
<bodyText confidence="0.999975736842105">
The RNNs are trained using Stochastic Gradient
Descent (SGD), maximizing the log probability of
the sequences of observed beliefs in the training
data (Bottou, 1991). Gradient clipping is used to
avoid the problem of exploding gradients (Pascanu
et al., 2012). A regularisation term is included,
which penalises the l2 norm of all the parameters.
It is found empirically to be beneficial to give more
weight in the regularisation to the parameters used
in the network calculating h.
When using the ASR N-best list, f is typi-
cally of dimensionality around 3500. With so
many weights to learn, it is important to initialise
the parameters well before starting the SGD algo-
rithm. Two initialisation techniques have been in-
vestigated, the denoising autoencoder and shared
initialisation. These were evaluated by training
trackers on the dstc2 train set, and evaluating on
dstc2 dev (see table 1).
</bodyText>
<subsectionHeader confidence="0.997687">
4.1 Denoising Autoencoder
</subsectionHeader>
<bodyText confidence="0.999801">
The denoising autoencoder (dA), which provides
an unsupervised method for learning meaningful
</bodyText>
<figure confidence="0.997354588235294">
f
fs
fv
N. Net.
h
h+g
N. Net.
for each value, v
p’
softmax
pN
p m
g v
p v
for each slot, s
m’
logistic
</figure>
<page confidence="0.890698">
295
</page>
<table confidence="0.846239">
Joint Goals Method Requested
Acc L2 Acc L2 Acc L2
0.686 0.477 0.913 0.147 0.963 0.059
0.688 0.466 0.915 0.144 0.962 0.059
0.680 0.479 0.910 0.152 0.962 0.059
0.696 0.463 0.915 0.144 0.965 0.057
0.612 0.632 0.830 0.266 0.894 0.174
</table>
<figure confidence="0.6043664">
dA
init.
Shared
init.
Baseline:
</figure>
<figureCaption confidence="0.7251086">
Table 1: Performance on the dev set when varying initialisation techniques for word-based tracking. Acc
denotes the accuracy of the most likely belief at each turn, and L2 denotes the squared l2 norm between
the estimated belief distribution and correct (delta) distribution. For each row, 5 trackers are trained
and then combined using score averaging. The final row shows the results for the focus-based baseline
tracker (Henderson et al., 2014).
</figureCaption>
<bodyText confidence="0.999469214285714">
underlying representations of the input, has been
found effective as an initialisation technique in
deep learning (Vincent et al., 2008).
A dA is used to initialise the parameters of the
RNN which multiply the high-dimensional input
vector f. The dA learns a matrix WdA which re-
duces f to a lower dimensional vector such that
the original vector may be recovered with minimal
loss in the presence of noise.
For learning the dA, f is first mapped such that
feature values lie between 0 and 1. The dA takes as
input fnoisy, a noisy copy of f where each compo-
nent is set to 0 with probability p. This is mapped
to a lower dimensional hidden representation h:
</bodyText>
<equation confidence="0.727101">
h = Q (WdAfnoisy + b0)
</equation>
<bodyText confidence="0.989528">
A reconstructed vector, frec, is then calculated
as:
</bodyText>
<equation confidence="0.88658">
frec = Q (W T )
dAh + b1
</equation>
<bodyText confidence="0.9999774">
The cross-entropy between f and frec is used as
the objective function in gradient descent, with an
added l1 regularisation term to ensure the learning
of sparse weights. As the ASR features are likely
to be very noisy, dense weights would be prone to
overfitting the examples. 1
When using WdA to initialise weights in the
RNN, training is observed to converge faster. Ta-
ble 1 shows that dA initialisation leads to better
solutions, particularly for tracking the goals.
</bodyText>
<subsectionHeader confidence="0.989616">
4.2 Shared Initialisation
</subsectionHeader>
<bodyText confidence="0.999334">
It is possible to train a slot-independent RNN, us-
ing training data from all slots, by not including h
in the model (the dimensionality of h is dependent
</bodyText>
<footnote confidence="0.9941385">
1The state-of-the-art in dialog act classification with very
similar data also uses sparse weights Chen et al. (2013).
</footnote>
<bodyText confidence="0.952462">
on the slot). In shared initialisation, such an RNN
is trained for a few epochs, then the learnt param-
eters are used to initialise slot-dependent RNNs
for each slot. This follows the shared initialisation
procedure presented in Henderson et al. (2013b).
Table 1 suggests that shared initialisation when
combined with dA initialisation gives the best per-
formance.
</bodyText>
<subsectionHeader confidence="0.999567">
4.3 Model Combination
</subsectionHeader>
<bodyText confidence="0.999960357142857">
In DSTC1, the most competitive results were
achieved with model combination whereby the
output of multiple trackers were combined to give
more accurate classifications (Lee and Eskenazi,
2013). The technique for model combination used
here is score averaging, where the final score for
each component of the dialog state is computed as
the mean of the scores output by all the trackers
being combined. This is one of the simplest meth-
ods for model combination, and requires no extra
training data. It is guaranteed to improve the accu-
racy if the outputs from the individual trackers are
not correlated, and the individual trackers operate
at an accuracy &gt; 0.5.
Multiple runs of training the RNNs were found
to give results with high variability and model
combination provides a method to exploit this
variability. In order to demonstrate the effect,
10 trackers with varying regularisation parame-
ters were trained on dstc2 train and used to track
dstc2 dev. Figure 3 shows the effects of combin-
ing these trackers in larger groups. The mean ac-
curacy in the joint goals from combining m track-
ers is found to increase with m. The single output
from combining all 10 trackers outperforms any
single tracker in the group.
The approach taken for the DSTC2 challenge
was therefore to train multiple trackers with vary-
</bodyText>
<page confidence="0.994599">
296
</page>
<figure confidence="0.905895272727273">
0.72
Accuracy 0.71
0.70
0.69
0.68
0.67
0.66
0.65
0.64
1 2 3 4 5 6 7 8 9 10
# trackers combined, m
</figure>
<figureCaption confidence="0.970569285714286">
Figure 3: Joint goal accuracy on dstc2 dev from system
combination. Ten total trackers are trained with varying reg-
ularisation parameters. For each m = 1 ... 10, all subsets
of size m of the 10 trackers are used to generate 10CM com-
bined results, which are plotted as a boxplot. Boxplots show
minimum, maximum, the interquartile range and the median.
The mean values are plotted as connected points.
</figureCaption>
<bodyText confidence="0.999600545454545">
ing model hyper-parameters (e.g. regularisation
parameters, memory size) and combine their out-
put using score averaging. Note that maintaining
around 10 RNNs for each dialog state components
is entirely feasible for a realtime system, as the
RNN operations are quick to compute. An un-
optimised Python implementation of the tracker
including an RNN for each dialog state compo-
nent is able to do state tracking at a rate of around
50 turns per second on an Intel® CoreTM i7-970
3.2GHz processor.
</bodyText>
<sectionHeader confidence="0.999894" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999985333333334">
The strict blind evaluation procedure defined for
the DSTC2 challenge was used to investigate the
effect on performance of two contrasts. The first
contrast compares word-based tracking and con-
ventional tracking based on SLU output. The sec-
ond contrast investigates the effect of including
and omitting the sub-network for h in the RNN.
Recall h is the part of the model that allows learn-
ing special behaviours for particular dialog state
hypotheses, and correlations with untagged fea-
tures. These two binary contrasts resulted in a to-
tal of 4 system variants being entered in the chal-
lenge.
Each system is the score-averaged combined
output of 12 trackers trained with varying hyper-
parameters (see section 4.3). The performance of
the 4 entries on the featured metrics of the chal-
lenge are shown in table 2.
It should be noted that the live SLU used the
word confusion network, not made available in the
challenge. The word confusion network is known
to provide stronger features than the N-best list for
language understanding (Henderson et al., 2012;
T¨ur et al., 2013), so the word-based trackers us-
ing N-best ASR features were at a disadvantage
in that regard. Nevertheless, despite this hand-
icap, the best results were obtained from word-
based tracking directly on the ASR output, rather
than using the confusion network generated SLU
output. Including h always helps, though this is
far more pronounced for the word-based track-
ers. Note that trackers which do not include h are
value-independent and so are capable of handling
new values at runtime.
The RNN trackers performed very competi-
tively in the context of the challenge. Figure 4 vi-
sualises the performance of the four trackers rela-
tive to all the entries submitted to the challenge for
the featured metrics. For full details of the evalua-
tion metrics see Henderson et al. (2014). The box
in this figure gives the entry IDs under which the
results are reported in the DSTC (under the team
ID ‘team4’). The word-based tracker including
h (h-ASR), was top for joint goals L2 as well as
requested slots accuracy and L2. It was close to
the top for the other featured metrics, following
closely entries from team 2. The RNN trackers
performed particularly well on measures assessing
the quality of the scores such as L2.
There are hundreds of numbers reported in the
DSTC2 evaluation, and it was found that the h-
ASR tracker ranked top on many of them. Consid-
ering L2, accuracy, average probability, equal er-
ror rate, log probability and mean reciprocal rank
across all components of the the dialog state, these
give a total of 318 metrics. The h-ASR tracker
ranked top of all trackers in the challenge in 89 of
these metrics, more than any other tracker. The
ASR tracker omitting h came second, ranking top
in 33 of these metrics.
The trackers using SLU features ranked top
in all of the featured metrics among the trackers
which used only the SLU output.
</bodyText>
<sectionHeader confidence="0.999709" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999707571428572">
The RNN framework presented in this paper pro-
vides very good performance in terms of both ac-
curacy and the quality of reported probability dis-
tributions. Word-based tracking is shown to be one
of the most competitive approaches submitted to
DSTC2. By mapping straight from the ASR out-
put to a belief update, it avoids any information
</bodyText>
<page confidence="0.989005">
297
</page>
<table confidence="0.999583333333333">
Tracker Joint Goals Method Requested
Inputs
entry Live Live Acc L2 ROC Acc L2 ROC Acc L2 ROC
Include ASR SLU
h
0 ✓ ✓ 0.768 0.346 0.365 0.940 0.095 0.452 0.978 0.035 0.525
1 ✓ 0.746 0.381 0.383 0.939 0.097 0.423 0.977 0.038 0.490
2 ✓ ✓ 0.742 0.387 0.345 0.922 0.124 0.447 0.957 0.069 0.340
3 ✓ 0.737 0.406 0.321 0.922 0.125 0.406 0.957 0.073 0.385
</table>
<tableCaption confidence="0.993457">
Table 2: Featured metrics on the test set for the 4 RNN trackers entered to the challenge.
</tableCaption>
<figure confidence="0.610608">
Joint Goals Method Requested All
</figure>
<figureCaption confidence="0.998049166666667">
Figure 4: Relative performance of RNN trackers for fea-
tured metrics in DSTC2. Each dash is one of the 34 trackers
evaluated in the challenge. Note a lower L2 is better. ROC
metric is only comparable for systems of similar accuracies,
so is not plotted. The focus baseline system is shown as a
circle.
</figureCaption>
<bodyText confidence="0.999488842105263">
lost in the omitted SLU step.
In general, the RNN appears to be a promising
model, which deals naturally with sequential input
and outputs. High dimensional inputs are handled
well, with little feature engineering, particularly
when carefully initialised (e.g. as here using de-
noising autoencoders and shared initialisation).
Future work should include making joint pre-
dictions on components of the dialog state. In this
paper each component was tracked using its own
RNN. Though not presented in this paper, no im-
provement could be found by joining the RNNs.
However, this may not be the case for other do-
mains in which slot values are more highly cor-
related. The concept of tagging the feature func-
tions allows for generalisation to unseen values
and slots. This generalisation will be explored in
future work, particularly for dialogs in more open-
domains.
</bodyText>
<sectionHeader confidence="0.996025" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.617435">
Matthew Henderson is a Google Doctoral Fellow.
</bodyText>
<sectionHeader confidence="0.900661" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995819833333333">
Dan Bohus and Alex Rudnicky. 2006. A K-
hypotheses+ Other Belief Updating Model. Proc.
of the AAAI Workshop on Statistical and Empirical
Methods in Spoken Dialogue Systems.
L´eon Bottou. 1991. Stochastic gradient learning in
neural networks. In Proceedings of Neuro-Nimes
91, Nimes, France. EC2.
Yun-Nung Chen, William Yang Wang, and Alexan-
der I Rudnicky. 2013. An empirical investigation of
sparse log-linear models for improved dialogue act
classification. In Acoustics, Speech and Signal Pro-
cessing (ICASSP), 2013 IEEE International Confer-
ence on.
Matthew Henderson, Milica Gaˇsi´c, Blaise Thom-
son, Pirros Tsiakoulis, Kai Yu, and Steve Young.
2012. Discriminative Spoken Language Under-
standing Using Word Confusion Networks. In Spo-
ken Language Technology Workshop, 2012. IEEE.
</reference>
<figure confidence="0.999275947368421">
Accuracy
L2
0.8
0.6
0.4
0.2
0.0
0.8
0.6
0.4
1.0
word-based
SLU input
full model no h
entry0
entry2
baseline
entry1
entry3
</figure>
<page confidence="0.977701">
298
</page>
<reference confidence="0.999464913043478">
Matthew Henderson, Blaise Thomson, and Jason
Williams. 2013a. Dialog State Tracking Challenge
2 &amp; 3 Handbook. camdial.org/˜mh521/dstc/.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2013b. Deep Neural Network Approach for
the Dialog State Tracking Challenge. In Proceed-
ings of SIGdial, Metz, France, August.
Matthew Henderson, Blaise Thomson, and Jason
Williams. 2014. The second dialog state tracking
challenge. In Proceedings of the SIGdial 2014 Con-
ference, Baltimore, U.S.A., June.
Sungjin Lee and Maxine Eskenazi. 2013. Recipe for
building robust spoken dialog state trackers: Dialog
state tracking challenge system description. In Pro-
ceedings of the SIGDIAL 2013 Conference, Metz,
France, August.
Sungjin Lee. 2013. Structured discriminative model
for dialog state tracking. In Proceedings of the SIG-
DIAL 2013 Conference, Metz, France, August.
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio.
2012. Understanding the exploding gradient prob-
lem. CoRR.
Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan.
2013. Dialog state tracking using conditional ran-
dom fields. In Proceedings of the SIGDIAL 2013
Conference, Metz, France, August.
G¨okhan T¨ur, Anoop Deoras, and Dilek Hakkani-T¨ur.
2013. Semantic parsing using word confusion net-
works with conditional random fields. In INTER-
SPEECH.
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and
Pierre-Antoine Manzagol. 2008. Extracting and
composing robust features with denoising autoen-
coders. In Proceedings of the 25th International
Conference on Machine Learning, Helsinki, Fin-
land.
Jason Williams. 2013. Multi-domain learning and gen-
eralization in dialog state tracking. In Proceedings
of the SIGDIAL 2013 Conference, Metz, France, Au-
gust.
Steve Young, Milica Gaˇsi´c, Simon Keizer, Franc¸ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2009. The Hidden Information State model:
A practical framework for POMDP-based spoken
dialogue management. Computer Speech &amp; Lan-
guage.
</reference>
<page confidence="0.998647">
299
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.900142">
<title confidence="0.998807">Word-Based Dialog State with Recurrent Neural Networks</title>
<author confidence="0.999374">Matthew Henderson</author>
<author confidence="0.999374">Blaise Thomson</author>
<author confidence="0.999374">Steve</author>
<affiliation confidence="0.9999115">Department of University of Cambridge,</affiliation>
<email confidence="0.909858">brmt2,</email>
<abstract confidence="0.999504235294118">Recently discriminative methods for tracking the state of a spoken dialog have been shown to outperform traditional generative models. This paper presents a new wordbased tracking method which maps directly from the speech recognition results to the dialog state without using an explicit semantic decoder. The method is based on a recurrent neural network structure which is capable of generalising to unseen dialog state hypotheses, and which requires very little feature engineering. The method is evaluated on the second Dialog State Tracking Challenge (DSTC2) corpus and the results demonstrate consistently high performance across all of the metrics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
<author>Alex Rudnicky</author>
</authors>
<title>A Khypotheses+ Other Belief Updating Model.</title>
<date>2006</date>
<booktitle>Proc. of the AAAI Workshop on Statistical and Empirical Methods in Spoken Dialogue Systems.</booktitle>
<contexts>
<context position="1303" citStr="Bohus and Rudnicky, 2006" startWordPosition="188" endWordPosition="192">e feature engineering. The method is evaluated on the second Dialog State Tracking Challenge (DSTC2) corpus and the results demonstrate consistently high performance across all of the metrics. 1 Introduction While communicating with a user, statistical spoken dialog systems must maintain a distribution over possible dialog states in a process called dialog state tracking. This distribution, also called the belief state, directly determines the system’s decisions. In MDP-based systems, only the most likely dialog state is considered and in this case the primary metric is dialog state accuracy (Bohus and Rudnicky, 2006). In POMDP-based systems, the full distribution is considered and then the shape of the distribution as measured by an L2 norm is equally important (Young et al., 2009). In both cases, good quality state tracking is essential to maintaining good overall system performance. Typically, state tracking has assumed the output of a Spoken Language Understanding (SLU) component in the form of a semantic decoder, which maps the hypotheses from Automatic Speech Recognition (ASR) to a list of semantic hypotheses. This paper considers mapping directly from ASR hypotheses to an updated belief state at eac</context>
</contexts>
<marker>Bohus, Rudnicky, 2006</marker>
<rawString>Dan Bohus and Alex Rudnicky. 2006. A Khypotheses+ Other Belief Updating Model. Proc. of the AAAI Workshop on Statistical and Empirical Methods in Spoken Dialogue Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L´eon Bottou</author>
</authors>
<title>Stochastic gradient learning in neural networks.</title>
<date>1991</date>
<booktitle>In Proceedings of Neuro-Nimes 91,</booktitle>
<location>Nimes,</location>
<contexts>
<context position="15115" citStr="Bottou, 1991" startWordPosition="2560" endWordPosition="2561">are tagged in the feature vectors fv. This allows the neural network calculating g to learn general patterns across slots just as in the case of goals. The equation for p&apos; is changed to: p&apos; = Q (h + g) so each component of p&apos; represents the probability (between 0 and 1) of a slot being requested. For method classification, the same RNN structure as for a goal is used. No tagging of the feature vectors is used in the case of methods. 4 Training The RNNs are trained using Stochastic Gradient Descent (SGD), maximizing the log probability of the sequences of observed beliefs in the training data (Bottou, 1991). Gradient clipping is used to avoid the problem of exploding gradients (Pascanu et al., 2012). A regularisation term is included, which penalises the l2 norm of all the parameters. It is found empirically to be beneficial to give more weight in the regularisation to the parameters used in the network calculating h. When using the ASR N-best list, f is typically of dimensionality around 3500. With so many weights to learn, it is important to initialise the parameters well before starting the SGD algorithm. Two initialisation techniques have been investigated, the denoising autoencoder and shar</context>
</contexts>
<marker>Bottou, 1991</marker>
<rawString>L´eon Bottou. 1991. Stochastic gradient learning in neural networks. In Proceedings of Neuro-Nimes 91, Nimes, France. EC2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>William Yang Wang</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>An empirical investigation of sparse log-linear models for improved dialogue act classification.</title>
<date>2013</date>
<booktitle>In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on.</booktitle>
<contexts>
<context position="18306" citStr="Chen et al. (2013)" startWordPosition="3104" endWordPosition="3107">g of sparse weights. As the ASR features are likely to be very noisy, dense weights would be prone to overfitting the examples. 1 When using WdA to initialise weights in the RNN, training is observed to converge faster. Table 1 shows that dA initialisation leads to better solutions, particularly for tracking the goals. 4.2 Shared Initialisation It is possible to train a slot-independent RNN, using training data from all slots, by not including h in the model (the dimensionality of h is dependent 1The state-of-the-art in dialog act classification with very similar data also uses sparse weights Chen et al. (2013). on the slot). In shared initialisation, such an RNN is trained for a few epochs, then the learnt parameters are used to initialise slot-dependent RNNs for each slot. This follows the shared initialisation procedure presented in Henderson et al. (2013b). Table 1 suggests that shared initialisation when combined with dA initialisation gives the best performance. 4.3 Model Combination In DSTC1, the most competitive results were achieved with model combination whereby the output of multiple trackers were combined to give more accurate classifications (Lee and Eskenazi, 2013). The technique for m</context>
</contexts>
<marker>Chen, Wang, Rudnicky, 2013</marker>
<rawString>Yun-Nung Chen, William Yang Wang, and Alexander I Rudnicky. 2013. An empirical investigation of sparse log-linear models for improved dialogue act classification. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Milica Gaˇsi´c</author>
<author>Blaise Thomson</author>
<author>Pirros Tsiakoulis</author>
<author>Kai Yu</author>
<author>Steve Young</author>
</authors>
<title>Discriminative Spoken Language Understanding Using Word Confusion Networks.</title>
<date>2012</date>
<booktitle>In Spoken Language Technology Workshop,</booktitle>
<publisher>IEEE.</publisher>
<marker>Henderson, Gaˇsi´c, Thomson, Tsiakoulis, Yu, Young, 2012</marker>
<rawString>Matthew Henderson, Milica Gaˇsi´c, Blaise Thomson, Pirros Tsiakoulis, Kai Yu, and Steve Young. 2012. Discriminative Spoken Language Understanding Using Word Confusion Networks. In Spoken Language Technology Workshop, 2012. IEEE.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Jason Williams</author>
</authors>
<booktitle>2013a. Dialog State Tracking Challenge 2 &amp; 3 Handbook. camdial.org/˜mh521/dstc/.</booktitle>
<marker>Henderson, Thomson, Williams, </marker>
<rawString>Matthew Henderson, Blaise Thomson, and Jason Williams. 2013a. Dialog State Tracking Challenge 2 &amp; 3 Handbook. camdial.org/˜mh521/dstc/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Steve Young</author>
</authors>
<title>Deep Neural Network Approach for the Dialog State Tracking Challenge.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGdial,</booktitle>
<location>Metz, France,</location>
<contexts>
<context position="2553" citStr="Henderson et al., 2013" startWordPosition="389" endWordPosition="392">ng the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engineering. Instead of using inputs with a </context>
<context position="7022" citStr="Henderson et al. (2013" startWordPosition="1131" endWordPosition="1135">lid value has been mentioned yet. • Requested slots: A reported probability for each requestable slot that has been requested by the user, and should be informed by the system. • Method: A distribution over methods, which encodes how the user is trying to use the dialog system. E.g. ‘by constraints’, when the user is trying to constrain the search, and ‘finished’, when the user wants to end the dialog. A tracker may report the goals as a joint over all slots, but in this paper the joint is reported as a product of the marginal distributions per slot. Full details of the challenge are given in Henderson et al. (2013a), Henderson et al. (2014). The trackers presented in this paper are identified under ‘team4’ in the reported results. 3 Recurrent Neural Network Model This section defines the RNN structure used for dialog state tracking. One such RNN is used per slot, taking the most recent dialog turn (user input plus last machine dialog act) as input, updating its internal memory and calculating an updated belief over the values for the slot. In what follows, the notation a ⊕ b is used to denote the concatenation of two vectors, a and b. The ith component of the vector a is written a|i. 3.1 Feature Repres</context>
<context position="9792" citStr="Henderson et al. (2013" startWordPosition="1607" endWordPosition="1610">eature from the ASR and the food feature from the machine act contribute to separate components of the final vector f. Figure 1: Example of feature extraction for one turn, giving f, fs and f„. Here s = food. For all v /E{indian, jamaican}, f„ = 0. Note that all the methods for tracking reported in DSTC1 required designing feature functions. For example, suggested feature functions included the SLU score in the current turn, the probability of an ‘affirm’ act when the value has been confirmed by the system, the output from baseline trackers etc. (e.g. Lee and Eskenazi (2013), Williams (2013), Henderson et al. (2013b)). In contrast, the approach described here is to present the model with all the information it would need to reconstruct any feature function that might be useful. 3.2 Generalisation to Unseen States One key issue in applying machine learning to the task of dialog state tracking is being able to deal with states which have not been seen in training. For example, the system should be able to recognise any obscure food type which appears in the set of possible food types. A naive neural network structure mapping n-gram features to an updated distribution for the food slot, with no tying of we</context>
<context position="18558" citStr="Henderson et al. (2013" startWordPosition="3145" endWordPosition="3148">lisation leads to better solutions, particularly for tracking the goals. 4.2 Shared Initialisation It is possible to train a slot-independent RNN, using training data from all slots, by not including h in the model (the dimensionality of h is dependent 1The state-of-the-art in dialog act classification with very similar data also uses sparse weights Chen et al. (2013). on the slot). In shared initialisation, such an RNN is trained for a few epochs, then the learnt parameters are used to initialise slot-dependent RNNs for each slot. This follows the shared initialisation procedure presented in Henderson et al. (2013b). Table 1 suggests that shared initialisation when combined with dA initialisation gives the best performance. 4.3 Model Combination In DSTC1, the most competitive results were achieved with model combination whereby the output of multiple trackers were combined to give more accurate classifications (Lee and Eskenazi, 2013). The technique for model combination used here is score averaging, where the final score for each component of the dialog state is computed as the mean of the scores output by all the trackers being combined. This is one of the simplest methods for model combination, and </context>
</contexts>
<marker>Henderson, Thomson, Young, 2013</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Steve Young. 2013b. Deep Neural Network Approach for the Dialog State Tracking Challenge. In Proceedings of SIGdial, Metz, France, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Jason Williams</author>
</authors>
<title>The second dialog state tracking challenge.</title>
<date>2014</date>
<booktitle>In Proceedings of the SIGdial 2014 Conference,</booktitle>
<location>Baltimore, U.S.A.,</location>
<contexts>
<context position="4386" citStr="Henderson et al., 2014" startWordPosition="670" endWordPosition="673">earns general behaviours for specifying slots enabling it to successfully decode 292 Proceedings of the SIGDIAL 2014 Conference, pages 292–299, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics ASR output which includes previously unseen slot values. In summary, this paper presents a word-based approach to dialog state tracking using recurrent neural networks. The model is capable of generalising to unseen dialog state hypotheses, and requires very little feature engineering. The approach is evaluated in the second Dialog State Tracking Challenge (DSTC2) (Henderson et al., 2014) where it is shown to be extremely competitive, particularly in terms of the quality of its confidence scores. Following a brief outline of DSTC2 in section 2, the definition of the model is given in section 3. Section 4 then gives details on the initialisation methods used for training. Finally results on the DSTC2 evaluation are given in 5. 2 The Second Dialog State Tracking Challenge This section describes the domain and methodology of the second Dialog State Tracking Challenge (DSTC2). The challenge is based on a large corpus collected using a variety of telephonebased dialog systems in th</context>
<context position="7049" citStr="Henderson et al. (2014)" startWordPosition="1136" endWordPosition="1139">ed yet. • Requested slots: A reported probability for each requestable slot that has been requested by the user, and should be informed by the system. • Method: A distribution over methods, which encodes how the user is trying to use the dialog system. E.g. ‘by constraints’, when the user is trying to constrain the search, and ‘finished’, when the user wants to end the dialog. A tracker may report the goals as a joint over all slots, but in this paper the joint is reported as a product of the marginal distributions per slot. Full details of the challenge are given in Henderson et al. (2013a), Henderson et al. (2014). The trackers presented in this paper are identified under ‘team4’ in the reported results. 3 Recurrent Neural Network Model This section defines the RNN structure used for dialog state tracking. One such RNN is used per slot, taking the most recent dialog turn (user input plus last machine dialog act) as input, updating its internal memory and calculating an updated belief over the values for the slot. In what follows, the notation a ⊕ b is used to denote the concatenation of two vectors, a and b. The ith component of the vector a is written a|i. 3.1 Feature Representation Extracting n-grams</context>
<context position="16779" citStr="Henderson et al., 2014" startWordPosition="2835" endWordPosition="2838">0.688 0.466 0.915 0.144 0.962 0.059 0.680 0.479 0.910 0.152 0.962 0.059 0.696 0.463 0.915 0.144 0.965 0.057 0.612 0.632 0.830 0.266 0.894 0.174 dA init. Shared init. Baseline: Table 1: Performance on the dev set when varying initialisation techniques for word-based tracking. Acc denotes the accuracy of the most likely belief at each turn, and L2 denotes the squared l2 norm between the estimated belief distribution and correct (delta) distribution. For each row, 5 trackers are trained and then combined using score averaging. The final row shows the results for the focus-based baseline tracker (Henderson et al., 2014). underlying representations of the input, has been found effective as an initialisation technique in deep learning (Vincent et al., 2008). A dA is used to initialise the parameters of the RNN which multiply the high-dimensional input vector f. The dA learns a matrix WdA which reduces f to a lower dimensional vector such that the original vector may be recovered with minimal loss in the presence of noise. For learning the dA, f is first mapped such that feature values lie between 0 and 1. The dA takes as input fnoisy, a noisy copy of f where each component is set to 0 with probability p. This </context>
<context position="22852" citStr="Henderson et al. (2014)" startWordPosition="3867" endWordPosition="3870">were obtained from wordbased tracking directly on the ASR output, rather than using the confusion network generated SLU output. Including h always helps, though this is far more pronounced for the word-based trackers. Note that trackers which do not include h are value-independent and so are capable of handling new values at runtime. The RNN trackers performed very competitively in the context of the challenge. Figure 4 visualises the performance of the four trackers relative to all the entries submitted to the challenge for the featured metrics. For full details of the evaluation metrics see Henderson et al. (2014). The box in this figure gives the entry IDs under which the results are reported in the DSTC (under the team ID ‘team4’). The word-based tracker including h (h-ASR), was top for joint goals L2 as well as requested slots accuracy and L2. It was close to the top for the other featured metrics, following closely entries from team 2. The RNN trackers performed particularly well on measures assessing the quality of the scores such as L2. There are hundreds of numbers reported in the DSTC2 evaluation, and it was found that the hASR tracker ranked top on many of them. Considering L2, accuracy, avera</context>
</contexts>
<marker>Henderson, Thomson, Williams, 2014</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Jason Williams. 2014. The second dialog state tracking challenge. In Proceedings of the SIGdial 2014 Conference, Baltimore, U.S.A., June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungjin Lee</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Recipe for building robust spoken dialog state trackers: Dialog state tracking challenge system description.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<location>Metz, France,</location>
<contexts>
<context position="2502" citStr="Lee and Eskenazi, 2013" startWordPosition="381" endWordPosition="384">ted belief state at each turn in the dialog, omitting the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for f</context>
<context position="9751" citStr="Lee and Eskenazi (2013)" startWordPosition="1601" endWordPosition="1604">rs. This means that in figure 1 the food feature from the ASR and the food feature from the machine act contribute to separate components of the final vector f. Figure 1: Example of feature extraction for one turn, giving f, fs and f„. Here s = food. For all v /E{indian, jamaican}, f„ = 0. Note that all the methods for tracking reported in DSTC1 required designing feature functions. For example, suggested feature functions included the SLU score in the current turn, the probability of an ‘affirm’ act when the value has been confirmed by the system, the output from baseline trackers etc. (e.g. Lee and Eskenazi (2013), Williams (2013), Henderson et al. (2013b)). In contrast, the approach described here is to present the model with all the information it would need to reconstruct any feature function that might be useful. 3.2 Generalisation to Unseen States One key issue in applying machine learning to the task of dialog state tracking is being able to deal with states which have not been seen in training. For example, the system should be able to recognise any obscure food type which appears in the set of possible food types. A naive neural network structure mapping n-gram features to an updated distributi</context>
<context position="18885" citStr="Lee and Eskenazi, 2013" startWordPosition="3192" endWordPosition="3195"> also uses sparse weights Chen et al. (2013). on the slot). In shared initialisation, such an RNN is trained for a few epochs, then the learnt parameters are used to initialise slot-dependent RNNs for each slot. This follows the shared initialisation procedure presented in Henderson et al. (2013b). Table 1 suggests that shared initialisation when combined with dA initialisation gives the best performance. 4.3 Model Combination In DSTC1, the most competitive results were achieved with model combination whereby the output of multiple trackers were combined to give more accurate classifications (Lee and Eskenazi, 2013). The technique for model combination used here is score averaging, where the final score for each component of the dialog state is computed as the mean of the scores output by all the trackers being combined. This is one of the simplest methods for model combination, and requires no extra training data. It is guaranteed to improve the accuracy if the outputs from the individual trackers are not correlated, and the individual trackers operate at an accuracy &gt; 0.5. Multiple runs of training the RNNs were found to give results with high variability and model combination provides a method to expl</context>
</contexts>
<marker>Lee, Eskenazi, 2013</marker>
<rawString>Sungjin Lee and Maxine Eskenazi. 2013. Recipe for building robust spoken dialog state trackers: Dialog state tracking challenge system description. In Proceedings of the SIGDIAL 2013 Conference, Metz, France, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungjin Lee</author>
</authors>
<title>Structured discriminative model for dialog state tracking.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<location>Metz, France,</location>
<contexts>
<context position="2513" citStr="Lee, 2013" startWordPosition="385" endWordPosition="386"> turn in the dialog, omitting the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engi</context>
</contexts>
<marker>Lee, 2013</marker>
<rawString>Sungjin Lee. 2013. Structured discriminative model for dialog state tracking. In Proceedings of the SIGDIAL 2013 Conference, Metz, France, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Pascanu</author>
<author>Tomas Mikolov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Understanding the exploding gradient problem.</title>
<date>2012</date>
<publisher>CoRR.</publisher>
<contexts>
<context position="15209" citStr="Pascanu et al., 2012" startWordPosition="2573" endWordPosition="2576">learn general patterns across slots just as in the case of goals. The equation for p&apos; is changed to: p&apos; = Q (h + g) so each component of p&apos; represents the probability (between 0 and 1) of a slot being requested. For method classification, the same RNN structure as for a goal is used. No tagging of the feature vectors is used in the case of methods. 4 Training The RNNs are trained using Stochastic Gradient Descent (SGD), maximizing the log probability of the sequences of observed beliefs in the training data (Bottou, 1991). Gradient clipping is used to avoid the problem of exploding gradients (Pascanu et al., 2012). A regularisation term is included, which penalises the l2 norm of all the parameters. It is found empirically to be beneficial to give more weight in the regularisation to the parameters used in the network calculating h. When using the ASR N-best list, f is typically of dimensionality around 3500. With so many weights to learn, it is important to initialise the parameters well before starting the SGD algorithm. Two initialisation techniques have been investigated, the denoising autoencoder and shared initialisation. These were evaluated by training trackers on the dstc2 train set, and evalu</context>
</contexts>
<marker>Pascanu, Mikolov, Bengio, 2012</marker>
<rawString>Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. 2012. Understanding the exploding gradient problem. CoRR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Ren</author>
<author>Weiqun Xu</author>
<author>Yan Zhang</author>
<author>Yonghong Yan</author>
</authors>
<title>Dialog state tracking using conditional random fields.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<location>Metz, France,</location>
<contexts>
<context position="2599" citStr="Ren et al. (2013)" startWordPosition="397" endWordPosition="400">based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engineering. Instead of using inputs with a select few very informative features, the appr</context>
</contexts>
<marker>Ren, Xu, Zhang, Yan, 2013</marker>
<rawString>Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan. 2013. Dialog state tracking using conditional random fields. In Proceedings of the SIGDIAL 2013 Conference, Metz, France, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨okhan T¨ur</author>
<author>Anoop Deoras</author>
<author>Dilek Hakkani-T¨ur</author>
</authors>
<title>Semantic parsing using word confusion networks with conditional random fields.</title>
<date>2013</date>
<booktitle>In INTERSPEECH.</booktitle>
<marker>T¨ur, Deoras, Hakkani-T¨ur, 2013</marker>
<rawString>G¨okhan T¨ur, Anoop Deoras, and Dilek Hakkani-T¨ur. 2013. Semantic parsing using word confusion networks with conditional random fields. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Vincent</author>
<author>Hugo Larochelle</author>
<author>Yoshua Bengio</author>
<author>Pierre-Antoine Manzagol</author>
</authors>
<title>Extracting and composing robust features with denoising autoencoders.</title>
<date>2008</date>
<booktitle>In Proceedings of the 25th International Conference on Machine Learning,</booktitle>
<location>Helsinki, Finland.</location>
<contexts>
<context position="16917" citStr="Vincent et al., 2008" startWordPosition="2855" endWordPosition="2858">174 dA init. Shared init. Baseline: Table 1: Performance on the dev set when varying initialisation techniques for word-based tracking. Acc denotes the accuracy of the most likely belief at each turn, and L2 denotes the squared l2 norm between the estimated belief distribution and correct (delta) distribution. For each row, 5 trackers are trained and then combined using score averaging. The final row shows the results for the focus-based baseline tracker (Henderson et al., 2014). underlying representations of the input, has been found effective as an initialisation technique in deep learning (Vincent et al., 2008). A dA is used to initialise the parameters of the RNN which multiply the high-dimensional input vector f. The dA learns a matrix WdA which reduces f to a lower dimensional vector such that the original vector may be recovered with minimal loss in the presence of noise. For learning the dA, f is first mapped such that feature values lie between 0 and 1. The dA takes as input fnoisy, a noisy copy of f where each component is set to 0 with probability p. This is mapped to a lower dimensional hidden representation h: h = Q (WdAfnoisy + b0) A reconstructed vector, frec, is then calculated as: frec</context>
</contexts>
<marker>Vincent, Larochelle, Bengio, Manzagol, 2008</marker>
<rawString>Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. 2008. Extracting and composing robust features with denoising autoencoders. In Proceedings of the 25th International Conference on Machine Learning, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Williams</author>
</authors>
<title>Multi-domain learning and generalization in dialog state tracking.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<location>Metz, France,</location>
<contexts>
<context position="2529" citStr="Williams, 2013" startWordPosition="387" endWordPosition="388">e dialog, omitting the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engineering. Instead</context>
<context position="9768" citStr="Williams (2013)" startWordPosition="1605" endWordPosition="1606">gure 1 the food feature from the ASR and the food feature from the machine act contribute to separate components of the final vector f. Figure 1: Example of feature extraction for one turn, giving f, fs and f„. Here s = food. For all v /E{indian, jamaican}, f„ = 0. Note that all the methods for tracking reported in DSTC1 required designing feature functions. For example, suggested feature functions included the SLU score in the current turn, the probability of an ‘affirm’ act when the value has been confirmed by the system, the output from baseline trackers etc. (e.g. Lee and Eskenazi (2013), Williams (2013), Henderson et al. (2013b)). In contrast, the approach described here is to present the model with all the information it would need to reconstruct any feature function that might be useful. 3.2 Generalisation to Unseen States One key issue in applying machine learning to the task of dialog state tracking is being able to deal with states which have not been seen in training. For example, the system should be able to recognise any obscure food type which appears in the set of possible food types. A naive neural network structure mapping n-gram features to an updated distribution for the food s</context>
</contexts>
<marker>Williams, 2013</marker>
<rawString>Jason Williams. 2013. Multi-domain learning and generalization in dialog state tracking. In Proceedings of the SIGDIAL 2013 Conference, Metz, France, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Young</author>
<author>Milica Gaˇsi´c</author>
<author>Simon Keizer</author>
<author>Franc¸ois Mairesse</author>
<author>Jost Schatzmann</author>
<author>Blaise Thomson</author>
<author>Kai Yu</author>
</authors>
<title>The Hidden Information State model: A practical framework for POMDP-based spoken dialogue management.</title>
<date>2009</date>
<journal>Computer Speech &amp; Language.</journal>
<marker>Young, Gaˇsi´c, Keizer, Mairesse, Schatzmann, Thomson, Yu, 2009</marker>
<rawString>Steve Young, Milica Gaˇsi´c, Simon Keizer, Franc¸ois Mairesse, Jost Schatzmann, Blaise Thomson, and Kai Yu. 2009. The Hidden Information State model: A practical framework for POMDP-based spoken dialogue management. Computer Speech &amp; Language.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>