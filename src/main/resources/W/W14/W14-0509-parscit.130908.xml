<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000894">
<title confidence="0.9877545">
How Well Can a Corpus-Derived Co-Occurrence Network
Simulate Human Associative Behavior?
</title>
<note confidence="0.518881333333333">
Gemma Bel Enguix Reinhard Rapp Michael Zock
Aix-Marseille Universit6, Laboratoire d&apos;Informatique Fondamentale
UMR 7279, Case 901, 163 Avenue de Luminy, F-13288 Marseille
</note>
<email confidence="0.984364">
gemma.belenguix@gmail.com reinhardrapp@gmx.de zock@free.fr
</email>
<sectionHeader confidence="0.993548" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980807692308">
Free word associations are the words
people spontaneously come up with in re-
sponse to a stimulus word. Such informa-
tion has been collected from test persons
and stored in databases. A well known
example is the Edinburgh Associative
Thesaurus (EAT). We will show in this
paper that this kind of knowledge can be
acquired automatically from corpora, en-
abling the computer to produce similar
associative responses as people do. While
in the past test sets typically consisted of
approximately 100 words, we will use
here a large part of the EAT which, in to-
tal, comprises 8400 words. Apart from
extending the test set, we consider differ-
ent properties of words: saliency, fre-
quency and part-of-speech. For each fea-
ture categorize our test set, and we com-
pare the simulation results to those based
on the EAT. It turns out that there are
surprising similarities which supports our
claim that a corpus-derived co-occur-
rence network can simulate human asso-
ciative behavior, i.e. an important part of
language acquisition and verbal behavior.
</bodyText>
<sectionHeader confidence="0.999128" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9993517">
Word associations in general and free word asso-
ciation in particular (Galton, 1879) have been
used by psychologists of various schools1 to un-
derstand the human mind (memory, cognition,
language) and the hidden mechanisms driving
peoples’ thoughts, utterances, and actions. In the
case of free word associations, a person typically
hears or reads a word, and is asked to produce
the first other word coming to mind. Kent &amp; Ro-
sanoff (1910) have used this method for compar-
</bodyText>
<footnote confidence="0.703522">
1 For example, cognitive psychology (Collins and
Loftus, 1975,), psycholinguistics (Clark, 1970) and
psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906).
</footnote>
<bodyText confidence="0.999917444444445">
isons, introducing to this end 100 emotionally
neutral test words. Having conducted the first
large scale study of word associations (1000 test
persons) they reached the conclusion that there
was a great uniformity concerning people&apos;s asso-
ciations, that is, speakers of a language share sta-
ble, comparable associative networks (Istifci,
2010).
In this paper, we are mainly interested in the
automatic acquisition of associations by com-
puter. More precisely, we want to check whether
a corpus-based method allows us to build auto-
matically an associative network akin to the one
in peoples’ mind, that is, a network able to mim-
ic human behavior. This means, given a stimulus
word the system is supposed to produce the same
responses as people do. We know since the old
Greeks that thoughts and their expressions
(words) are linked via associations. Yet, what we
still do not know is the nature of these links. Al-
so, links vary in terms of strength. Associationist
learning theory (Schwartz &amp; Reisberg, 1991) ex-
plains how these strengths (or weights) are ac-
quired. The strength between two perceived
events increases by a constant fraction of a max-
imally possible increment at each co-occurrence,
and decreases in the opposite case.
Wettler et al. (2005) have shown that this
mechanism can be replicated by looking at word
co-occurrence frequencies in large text collec-
tions. But there had been earlier corpus-linguistic
work: For example, Wettler &amp; Rapp (1989) com-
pared several association measures in order to
find search terms to be used for queries in infor-
mation retrieval. Church &amp; Hanks (1990) sug-
gested to use mutual information, an information
theoretic measure, for computing association
strength. Prior to this, a lot of work had been
done without reliance of corpora. For example,
Collins &amp; Loftus (1975) used associative seman-
tic networks to show the distance between words.
Others (Rosenzweig, 1961:358; Ekpo-Ufot,
1978) tried to show the universal status of a large
subset of associations. While all these findings
are important, we will not consider them further
</bodyText>
<page confidence="0.997045">
43
</page>
<bodyText confidence="0.978747526315789">
Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 43–48,
Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics
here. Rather we will focus on the claim that a -
corpus-derived co-occurrence network is able to
mimic human associative behavior.
Such a network consists of nodes, which in
our case correspond to words (or lemmas), and
of weights connecting the nodes. The strengths
of these weights are computed on the basis of
word co-occurrence data, and by optionally ap-
plying an association measure. But there are
many association measures. Given their number
and diversity some researchers (Evert &amp; Krenn,
2001) felt that there was a need to define some
criteria and methods in order to allow for quanti-
tative comparisons via task-based evaluations.
Pursuing a similar goal, Pecina &amp; Schlesinger
(2006) compared 82 different association
measures for collocation extraction, while Hoang
et al. (2009) classified them. Michelbacher et al.
(2011) investigated the potential of asymmetric
association measures, i.e. &amp;quot;associations whose
associational strength is significantly greater in
one direction (e.g., from Pyrrhic to victory) than
in the other (e.g., from victory to Pyrrhic)&amp;quot;.
Washtell &amp; Markert (2009) tried to determine
whether word associations should be computed
via window-based co-occurrence counts or rather
via a windowless approach measuring the dis-
tances between words.
Our work is related to previous studies com-
paring human word associations with those de-
rived from corpus statistics (e.g. Wettler et al.,
2005; Tamir, 2005, Seidensticker, 2006). The
main differences are that we categorize our stim-
ulus words and present results for each class, and
that we have a stronger focus on the graph aspect
of our network.
</bodyText>
<sectionHeader confidence="0.88135" genericHeader="introduction">
2 Resources and processing
</sectionHeader>
<bodyText confidence="0.999901431818182">
In order to simulate human associative behavior
via corpora, we need them to encode knowledge
that people typically have, that is, encyclopedic
or universally shared knowledge (e.g. Paris capi-
tal of France) and episodic knowledge (i.e.
knowledge momentarily true: Nadal winner of
the French Open). To meet these goals we de-
cided to use the British National Corpus (BNC,
Burnard &amp; Aston, 1998) as it is well balanced
and relatively large (about 100 million words of
contemporary British English).
To lemmatize the corpus we used the NLTK
(Bird et al., 2009) which for this purpose utilizes
information from WordNet. Hence, inflected
forms (e.g. wheels or bigger) were replaced by
their base forms (e.g. wheel or big). This reduces
noise and data sparsity while improving speed
and accuracy during evaluation. Since this latter
is based on exact string matching, our system
would consider wheels, produced in response to
car, as a mistake as the primary associative re-
sponse of the test persons is wheel, the singular
form. Lemmatization solves this problem. Since
we were interested here only in content words
(nouns, verbs, and adjectives) we removed all
other words from the BNC.
To evaluate the performance of our system we
compared its results with the associations col-
lected by Kiss et al. (1973), the Edinburgh Asso-
ciative Thesaurus. The association norms of the
EAT were produced by presenting each stimulus
word to 100 subjects, and by collecting their re-
sponses. The subjects were 17 to 22 year old
British students. Table 1 shows the associations
produced by at least five participants in response
to the stimulus words bath and cold together with
the number of participants producing them.
bath cold
observed number of observed number of
response subjects response subjects
water 20 hot 34
tub 8 ice 10
clean 5 warm 7
hot 5 water 5
</bodyText>
<tableCaption confidence="0.955701">
Table 1: Extracts from the EAT for the stimulus words bath
and cold.
</tableCaption>
<bodyText confidence="0.999988875">
The EAT lists the associations to 8400 stimu-
lus words. Since we were only interested in
nouns, verbs, and adjectives, we eliminated all
other words and also multiword units (e.g. a lot).
After having lemmatized the data with the NLTK
we obtained a list of 5910 test items which is
considerably more than the usual 100 used in
many previous studies (e.g. Wettler et al., 2005).
</bodyText>
<sectionHeader confidence="0.6459555" genericHeader="method">
3 A graph-based approach for comput-
ing word associations
</sectionHeader>
<bodyText confidence="0.913106272727273">
Unlike previous work (Wettler et al. 2005;
Church &amp; Hanks, 1990) which is described in the
terminology of the well known vector space
model, in the construction of the current system
we had a graph-based approach in mind so we
describe the system in such terms. We built up a
graph on the basis of the nouns, verbs, and adjec-
tives occurring in the corpus, these tokens being
the nodes of the graph.2 The links (also called
2 As preliminary experiments have shown, including func-
tion words in the graph can create noise in the retrieval of
</bodyText>
<page confidence="0.996971">
44
</page>
<bodyText confidence="0.999904">
weights, connections, or edges) between these
nodes are zero at the beginning, and are incre-
mented by one whenever the two connected
words co-occur in the corpus as direct neigh-
bors.3 Put differently, the weight of each link
represents the number of times two words
(nodes) co-occur in the corpus.
The associations to a given stimulus word are
calculated by searching the nodes which are di-
rect neighbors of this stimulus word, and by
ranking them according to the weights of the
connections. Given a graph G=V,E with
V={i,j,É,n} as its set of vertices and E as its set
of edges linking pairs of nodes over V, we ex-
press by N(i) the neighborhood of a node i ∈V,
where N(i) is defined as every j∈V  |ei,j ∈E.
</bodyText>
<sectionHeader confidence="0.999938" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999939866666667">
Given the way this network is built, one could
expect the system to retrieve only syntagmati-
cally related words, i.e. words often occurring in
close proximity (e.g. blue → sky). Yet, to our
surprise, the system also retrieves many paradig-
matic associations, that is, words which can sub-
stitute each other (e.g. blue → red).
Table 2 shows some results. While not all
computed primary responses are identical to the
ones produced by humans (in the EAT), the re-
sponses seem perfectly plausible. This raises the
question whether the answers are within the
bandwidth of variation of human associative be-
havior.
We measured the quality of our results by
counting (for all 5910 items) the number of times
the subjects participating in the creation of the
EAT had given the same answer as our system.
This number is 6.2 on average. In comparison,
the number of other subjects giving the same an-
swer as an average test person is 5.8. If the two
numbers were identical, our system would be
perfectly within the range of variation of the hu-
man associative responses, i.e. our system&apos;s an-
swers could hardly be distinguished from the
ones given by a human. This is actually the case.
The answers of our system are, on average, even
slightly closer to the ones given by the test per-
sons than the answers of a randomly selected test
person.
</bodyText>
<footnote confidence="0.7098215">
associations. Hence we preferred to keep only these three
categories.
3 Note that this refers to the pre-processed corpus where all
stopwords have been removed.
</footnote>
<table confidence="0.998758416666667">
Stimulus Human Prima- Computed Pri-
Word ry Response mary Response
afraid fear person
anger hate frustration
baby boy mother
bath water shower
beautiful ugly woman
bed sleep hospital
bible book God
bitter sweet taste
black white white
blossom flower white
</table>
<tableCaption confidence="0.986983333333333">
Table 2: Comparison between human and computed associ-
ations for the 10 alphabetically first words of the Kent/Ro-
sanoff (1910) list.
</tableCaption>
<bodyText confidence="0.9996272">
In the following subsections we split our set of
5910 test items into three categories to check
how well each one of them matches our intuition
that a corpus-derived co-occurrence network can
indeed simulate human associative behavior.
</bodyText>
<subsectionHeader confidence="0.998675">
4.1 Word saliency
</subsectionHeader>
<bodyText confidence="0.999868636363636">
Our goal is twofold: find out to what extend the
saliency of a stimulus word has an effect on the
homogeneity of human responses, and whether
these findings can also be replicated in our com-
puter simulation.
To this end we divided our 5910 EAT stimu-
lus words into six categories, i.e. saliency classes
(SC). Saliency is defined here as the proportion
of subjects producing the Primary Associative
Response (PAR), this latter being the response
produced by the largest number of subjects.
</bodyText>
<table confidence="0.8068575">
SC 1: less than 10% producing the PAR (10.7%)
SC 2: 10 to 20% producing the PAR (36.0%)
SC 3: 20 to 30% producing the PAR (24.3%)
SC 4: 30 to 40% producing the PAR (13.3%)
SC 5: 40 to 50% producing the PAR (8.0%)
SC 6: more than 50% producing the PAR (7.6%)
</table>
<bodyText confidence="0.9881694">
The percentages at the end of each line denote
the proportion of words belonging to the respec-
tive saliency class. All classes are reasonably
well covered. Here are some representative
words for each class:
</bodyText>
<tableCaption confidence="0.579548">
SC 1: leader, professor, yellow
SC 2: horse, mountain, semaphore
SC 3: chief, jungle, kiss
SC 4: driver, monarchy, tornado
SC 5: aid, cell, gasoline
SC 6: black, aunt, woman
</tableCaption>
<page confidence="0.99935">
45
</page>
<bodyText confidence="0.999542166666667">
As can be seen from these examples, our intui-
tions do not easily allow us to make predictions
concerning the saliency classifications of words.
Figure 1 (blue curve) shows how well our sys-
tem performs for each class. For the words in
each class we counted the average number of
times a human subject had come up with the
same associative response as the system. It ap-
pears that the system&apos;s performance is best for
very salient words, performing less well in the
opposite case. Note that this correlates perfectly
well with the observed human associative behav-
ior: Our system tends to produce the same an-
swers as people for stimulus words yielding ho-
mogeneous human responses. Likewise, the sys-
tem’s answers tend to differ in cases where peo-
ples’ answers are heterogeneous.
The red curve in Figure 1 shows for each sali-
ency class the number of persons giving the same
associative answer as an average test person. As
can be seen this line is almost identical to the one
representing the system&apos;s performance, which
means that the system&apos;s behavior is very similar
to human behavior with respect to saliency.
</bodyText>
<figureCaption confidence="0.9807935">
Fig. 1: Quality of our system&apos;s (blue curve) and an average
test person&apos;s (red curve) performance (measured as the num-
ber of matching responses found in the EAT) with respect to
saliency.
</figureCaption>
<subsectionHeader confidence="0.998079">
4.2 Word frequency
</subsectionHeader>
<bodyText confidence="0.999883111111111">
Encouraged by the findings for saliency, we con-
ducted a similar experiment for word frequency.
In this case the EAT stimulus words were split
into frequency classes according to their corpus
frequencies in the BNC.
Since a logarithmic scale seems to be appro-
priate for word frequencies (Rapp, 2005; van
Heuven et al., in press), we used the following
six frequency classes (FC):
</bodyText>
<listItem confidence="0.836257666666667">
FC1: 1 occurrence BNC (0.5%)
FC2: from 1 to 10 occurrences BNC (9.2%)
FC3: form 10 to 100 occurrences BNC (30.2%)
FC4: from 100 to 1000 occurrences BNC (42.6%)
FC5: from 1000 to 10000 occurrences BNC (17.3%)
FC6: from 10000 to 100000 occurrences BNC (0.1%)
</listItem>
<bodyText confidence="0.999161555555556">
As can be seen from the percentages at the end of
each line, extremes, i.e. very high and very low
frequencies are covered only marginally.
In the first group we find words like cornuco-
pia, jewelry4 and quaff, each appearing only once
in the corpus, while the frequency class 6 con-
tains only high frequency words such as the
(auxiliary) verbs be, do, have, and make.
The results obtained for the frequency classes
are shown in Figure 2. As can be seen, the gen-
eral tendency is that the results improve with de-
creasing frequency. Our explanation for this is
that frequent words tend to be more polysemous,
and that increased ambiguity tends to yield more
heterogeneous responses. For example, the am-
biguous stimulus word palm is likely to evoke
not only responses related to its tree sense, but
also to its hand sense.
</bodyText>
<figureCaption confidence="0.998183333333333">
Fig. 2: Quality of our system&apos;s (blue curve) and an average
test person&apos;s (red curve) performance with respect to fre-
quency.
</figureCaption>
<bodyText confidence="0.99996">
Whereas for mid frequency words the results
for the test persons and in the simulation show a
high agreement, this is not the case for high fre-
quency and for low frequency words. For high
frequency words (FC 6) a plausible explanation
might be the sampling error due to the low sam-
ple size of only 0.1% of the stimulus words in
the EAT test set. However, for low frequency
words the sample sizes are larger and the dis-
crepancy is clearly systematic. Our explanation
is that in this case we might have a systematic
sampling error concerning the observed frequen-
cies. The simulation has an advantage because
the frequency classes were set up according to
</bodyText>
<footnote confidence="0.9812885">
4 Note that this is the American spelling which is rare in the
BNC. The British spelling is jewellery.
</footnote>
<page confidence="0.999516">
46
</page>
<bodyText confidence="0.999858428571428">
the BNC frequencies rather than according to the
subjective frequencies (= word familiarities) of
the test persons. For example, the words of FC 1
are guaranteed to occur in the BNC, while it is
not certain at all that the test persons ever en-
countered them. This leads to a systematic bias
in favor of the simulation results.
</bodyText>
<subsectionHeader confidence="0.999872">
4.3 Part of speech
</subsectionHeader>
<bodyText confidence="0.9996962">
In a last experiment we considered the results for
the three parts of speech used in our system,
namely nouns, verbs, and adjectives. We as-
signed to each word in the EAT test set its part of
speech. Syntactically ambiguous words (which
can belong to several parts of speech) were as-
signed to their most frequently occurring part of
speech. Of the 5910 EAT items, 89.2% were
classified as nouns, 2.4% as verbs, and 8.4% as
adjectives.
</bodyText>
<figureCaption confidence="0.998224666666667">
Fig. 3: Quality of our system&apos;s (blue curve) and an average
test person&apos;s (red curve) performance with respect to parts
of the speech.
</figureCaption>
<bodyText confidence="0.999986375">
For the three categories we obtained the re-
sults shown in Figure 3. The results are best for
nouns and worst for verbs. Our explanation for
this is once again average word ambiguity which
is higher for verbs than it is for nouns. As with
the saliency classes, we have again a high corre-
lation between the results produced by humans
and the ones produced by machine.
</bodyText>
<sectionHeader confidence="0.97273" genericHeader="conclusions">
5 Discussion and conclusion
</sectionHeader>
<bodyText confidence="0.999961355932204">
We have presented a novel graph-based algo-
rithm for the computation of word associations.
The goal was to check whether and to what ex-
tent an automatically built association network
based on a large text corpus would yield similar
results to the ones produced by humans. The re-
sults were evaluated with a test set comprising all
nouns, verbs, and adjectives of the EAT stimulus
words. This test set is considerably larger than
the ones used in most previous computational as-
sociation studies.
Contrary to what could be expected our sys-
tem predicts not only syntagmatic but also para-
digmatic relations. For instance, the pairs black
→ white, bread → butter and boy → girl are cor-
rectly computed. This shows that texts contain
not only word pairs encoding syntagmatic rela-
tions but also pairs encoding paradigmatic rela-
tions. The results also show that statistical co-
occurrence-based methods are suitable for tasks
that traditionally were supposed to require more
sophisticated symbolic approaches.
In sum, our approach allows not only to cor-
rectly predict thousands of associations, it also
matches human performance in other respects:
For the first time it was shown that the predic-
tions for salient words are much better than for
non-salient ones. Similarly, concerning word
frequency and part of speech the simulated re-
sults also closely mimic the behavior as found in
the human data.
Altogether, our results provide evidence that
human associative behavior as observed in the
classical association experiments can be modeled
by exploiting the co-occurrences of words in
large text corpora. There seems to be a circulari-
ty: (a) the word co-occurrences found in text and
speech5 appear to be externalized forms of the
associations stored in the human brain, and (b)
the associations stored in the brain appear to be
internalized forms of the co-occurrences as found
in text and speech. This contradiction disappears
as soon as we realize that time has elapsed be-
tween these two events. Hence, one network may
be fed by the other, and this may go on.
Note that our corpus-based approach has fur-
ther virtues: (a) it allows to generate associations
from corpora covering particular time spans; (b)
it can produce associations based on corpora
covering specific topics; (c) it accounts for the
fact that languages, hence associations, change
over time. Think of the ideas associated with
Dominique Strauss-Kahn, one of the top candi-
dates before the last presidential campaign in
France. While the associations prior to May 18,
2011 were probably IMF, politics or election, the
ones after the Sofitel event were probably quite
different, shifting towards a much more delicate
topic.
</bodyText>
<footnote confidence="0.56589">
5 Note that the BNC also contains transcribed speech.
</footnote>
<page confidence="0.999327">
47
</page>
<sectionHeader confidence="0.99833" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99964225">
This research was supported by the Marie Curie
Intra European Fellowships DynNetLAc and Au-
toWordNet within the 7th European Community
Framework Programme.
</bodyText>
<sectionHeader confidence="0.990294" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999792414141414">
Bird, S.; Klein, E. and Loper, E. (2009). Natural Lan-
guage Processing with Python. O&apos;Reilley Media.
Burnard, L. and Aston, G. (1998). The BNC Hand-
book: Exploring the British National Corpus. Ed-
inburgh: Edinburgh University Press.
Church, K.W. and Hanks, P. (1990). Word association
norms, mutual information, and lexicography.
Computational Linguistics 16 (1), 22–29.
Clark, H. H. (1970). Word associations and linguistic
theory. In J. Lyons (Ed.), New horizons in linguis-
tics (pp. 271-286). Baltimore: Penguin.
Collins, A. M. and Loftus, E. F. (1975). A spreading-
activation theory of semantic processing. Psycho-
logical Review 8. Vol. 82, No. 6, 407-428.
Ekpo-Ufot, A. (1978). Word associations: a compara-
tive study among college students in Nigeria and
the United States. Journal of Cross-Cultural Psy-
chology, Vol. 9(4), 455-468.
Evert, S. and Krenn, B. (2001). Methods for qualita-
tive evaluation of lexical association measures. In
Proceedings of the 39th Annual Meeting of the As-
sociation of Computational Linguistics, Toulouse,
France, 188-915.
Freud, S. (1901/1975). The psychopathology of eve-
ryday life. Harmondsworth: Penguin. http://psych-
classics.yorku.ca/Freud/Psycho/chap5.htm
Galton, F. (1879). Psychometric experiments. Brain
(2), 149-162.
Van Heuven, W.J.B., Mandera, P., Keuleers, E., &amp;
Brysbaert, M. (in press). Subtlex-UK: A new and
improved word frequency database for British
English. Quarterly Journal of Experimental
Psychology.
Hoang, H.H, Kim, S. N. and Kan, M.Y. (2009). A re-
examination of lexical association measures. Pro-
ceedings of the Workshop on Multiword Expres-
sions, ACL-IJCNLP 2009, Suntec, Singapore, 31-
39.
Istifci, I. (2010). Playing with words: a study on word
association responses. The Journal of International
Social Research, 3(10), 360–368
Jung, C. and F. Riklin. 1906. Experimentelle Untersu-
chungen über Assoziationen Gesunder. In Jung, C.
G., editor, Diagnostische Assoziationsstudien, 7–
145. Barth, Leipzig.
Kent, G.H. and Rosanoff, A.J. (1910). A study of as-
sociation in insanity. American Journal of Insanity,
67, 37–96, 317–390.
Kiss, G.R., Armstrong, C., Milroy, R., and Piper, J.
(1973). An associative thesaurus of English and its
computer analysis. In: A. Aitken, R. Beiley, N.
Hamilton-Smith (eds.): The Computer and Literary
Studies. Edinburgh University Press.
Michelbacher, L., Evert, S. and Schütze, H. (2011).
Asymmetry in corpus-derived and human associa-
tions. Corpus Linguistics and Linguistic Theory,
Vo. 7, No. 2, 245–276.
Pecina, P., and Schlesinger, P. (2006). Combining as-
sociation measures for collocation extraction. Pro-
ceedings of the 21th International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics (COLING/ACL 2006), Sydney, Australia, 651-
658.
Rapp, R. (2005). On the relationship between word
frequency and word familiarity. In: B. Fisseni; H.-
C. Schmitz; B. Schröder; P. Wagner (Hg.): Sprach-
technologie, mobile Kommunikation und linguisti-
sche Ressourcen. BeitrŠge zur GLDV-Tagung 2005
in Bonn. Frankfurt: Peter Lang. 249–263.
Rosenzweig, M. R. (1961). Comparisons among
word-assocation responses in English, French,
German, and Italian. The American Journal of Psy-
chology, Vol. 74, No. 3, 347-360.
Schwartz, B. and Reisberg, D. (1991). Learning and
Memory. New York: Norton.
Seidensticker, P. (2006). Simulation von Wortassozia-
tionen mit Hilfe von mathematischen Lernmodellen
in der Psychologie. Dissertation an der UniversitŠt
Paderborn.
Tamir, R. (2005). A Random Walk through Human
Associations. Proceedings of ICDM 2005: 442-
449.
Washtell, J.; Markert, K. (2009). A comparison of
windowless and window-based computational as-
sociation measures as predictors of syntagmatic
human associations. Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP &apos;09), Volume 2, 628-
637
Wettler, M. and Rapp, R. (1989). A connectionist sys-
tem to simulate lexical decisions in information re-
trieval. In: R. Pfeifer, Z. Schreter, F. Fogelman, L.
Steels (eds.): Connectionism in Perspective. Am-
sterdam: Elsevier, 463–469.
Wettler, M., Rapp, R. and Sedlmeier, P. (2005). Free
word associations correspond to contiguities be-
tween words in texts. Journal of Quantitative Lin-
guistics 12(2), 111–122.
</reference>
<page confidence="0.999351">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.332419">
<title confidence="0.910117">How Well Can a Corpus-Derived Co-Occurrence Simulate Human Associative Behavior?</title>
<author confidence="0.990288">Gemma Bel Enguix Reinhard Rapp Michael Zock</author>
<note confidence="0.527387">Aix-Marseille Universit6, Laboratoire d&apos;Informatique Fondamentale UMR 7279, Case 901, 163 Avenue de Luminy, F-13288 Marseille</note>
<email confidence="0.750184">gemma.belenguix@gmail.comreinhardrapp@gmx.dezock@free.fr</email>
<abstract confidence="0.999250777777778">Free word associations are the words people spontaneously come up with in response to a stimulus word. Such information has been collected from test persons and stored in databases. A well known example is the Edinburgh Associative Thesaurus (EAT). We will show in this paper that this kind of knowledge can be acquired automatically from corpora, enabling the computer to produce similar associative responses as people do. While in the past test sets typically consisted of approximately 100 words, we will use here a large part of the EAT which, in total, comprises 8400 words. Apart from extending the test set, we consider different properties of words: saliency, frequency and part-of-speech. For each feature categorize our test set, and we compare the simulation results to those based on the EAT. It turns out that there are surprising similarities which supports our claim that a corpus-derived co-occurrence network can simulate human associative behavior, i.e. an important part of language acquisition and verbal behavior.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>E Klein</author>
<author>E Loper</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python. O&apos;Reilley Media.</booktitle>
<contexts>
<context position="6482" citStr="Bird et al., 2009" startWordPosition="1014" endWordPosition="1017">n the graph aspect of our network. 2 Resources and processing In order to simulate human associative behavior via corpora, we need them to encode knowledge that people typically have, that is, encyclopedic or universally shared knowledge (e.g. Paris capital of France) and episodic knowledge (i.e. knowledge momentarily true: Nadal winner of the French Open). To meet these goals we decided to use the British National Corpus (BNC, Burnard &amp; Aston, 1998) as it is well balanced and relatively large (about 100 million words of contemporary British English). To lemmatize the corpus we used the NLTK (Bird et al., 2009) which for this purpose utilizes information from WordNet. Hence, inflected forms (e.g. wheels or bigger) were replaced by their base forms (e.g. wheel or big). This reduces noise and data sparsity while improving speed and accuracy during evaluation. Since this latter is based on exact string matching, our system would consider wheels, produced in response to car, as a mistake as the primary associative response of the test persons is wheel, the singular form. Lemmatization solves this problem. Since we were interested here only in content words (nouns, verbs, and adjectives) we removed all o</context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Bird, S.; Klein, E. and Loper, E. (2009). Natural Language Processing with Python. O&apos;Reilley Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Burnard</author>
<author>G Aston</author>
</authors>
<title>The BNC Handbook: Exploring the British National Corpus. Edinburgh:</title>
<date>1998</date>
<publisher>Edinburgh University Press.</publisher>
<contexts>
<context position="6318" citStr="Burnard &amp; Aston, 1998" startWordPosition="986" endWordPosition="989">amir, 2005, Seidensticker, 2006). The main differences are that we categorize our stimulus words and present results for each class, and that we have a stronger focus on the graph aspect of our network. 2 Resources and processing In order to simulate human associative behavior via corpora, we need them to encode knowledge that people typically have, that is, encyclopedic or universally shared knowledge (e.g. Paris capital of France) and episodic knowledge (i.e. knowledge momentarily true: Nadal winner of the French Open). To meet these goals we decided to use the British National Corpus (BNC, Burnard &amp; Aston, 1998) as it is well balanced and relatively large (about 100 million words of contemporary British English). To lemmatize the corpus we used the NLTK (Bird et al., 2009) which for this purpose utilizes information from WordNet. Hence, inflected forms (e.g. wheels or bigger) were replaced by their base forms (e.g. wheel or big). This reduces noise and data sparsity while improving speed and accuracy during evaluation. Since this latter is based on exact string matching, our system would consider wheels, produced in response to car, as a mistake as the primary associative response of the test persons</context>
</contexts>
<marker>Burnard, Aston, 1998</marker>
<rawString>Burnard, L. and Aston, G. (1998). The BNC Handbook: Exploring the British National Corpus. Edinburgh: Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<volume>16</volume>
<issue>1</issue>
<pages>22--29</pages>
<contexts>
<context position="3597" citStr="Church &amp; Hanks (1990)" startWordPosition="566" endWordPosition="569">y (Schwartz &amp; Reisberg, 1991) explains how these strengths (or weights) are acquired. The strength between two perceived events increases by a constant fraction of a maximally possible increment at each co-occurrence, and decreases in the opposite case. Wettler et al. (2005) have shown that this mechanism can be replicated by looking at word co-occurrence frequencies in large text collections. But there had been earlier corpus-linguistic work: For example, Wettler &amp; Rapp (1989) compared several association measures in order to find search terms to be used for queries in information retrieval. Church &amp; Hanks (1990) suggested to use mutual information, an information theoretic measure, for computing association strength. Prior to this, a lot of work had been done without reliance of corpora. For example, Collins &amp; Loftus (1975) used associative semantic networks to show the distance between words. Others (Rosenzweig, 1961:358; Ekpo-Ufot, 1978) tried to show the universal status of a large subset of associations. While all these findings are important, we will not consider them further 43 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 43–48, Goth</context>
<context position="8335" citStr="Church &amp; Hanks, 1990" startWordPosition="1327" endWordPosition="1330">r 20 hot 34 tub 8 ice 10 clean 5 warm 7 hot 5 water 5 Table 1: Extracts from the EAT for the stimulus words bath and cold. The EAT lists the associations to 8400 stimulus words. Since we were only interested in nouns, verbs, and adjectives, we eliminated all other words and also multiword units (e.g. a lot). After having lemmatized the data with the NLTK we obtained a list of 5910 test items which is considerably more than the usual 100 used in many previous studies (e.g. Wettler et al., 2005). 3 A graph-based approach for computing word associations Unlike previous work (Wettler et al. 2005; Church &amp; Hanks, 1990) which is described in the terminology of the well known vector space model, in the construction of the current system we had a graph-based approach in mind so we describe the system in such terms. We built up a graph on the basis of the nouns, verbs, and adjectives occurring in the corpus, these tokens being the nodes of the graph.2 The links (also called 2 As preliminary experiments have shown, including function words in the graph can create noise in the retrieval of 44 weights, connections, or edges) between these nodes are zero at the beginning, and are incremented by one whenever the two</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, K.W. and Hanks, P. (1990). Word association norms, mutual information, and lexicography. Computational Linguistics 16 (1), 22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
</authors>
<title>Word associations and linguistic theory. In</title>
<date>1970</date>
<pages>271--286</pages>
<editor>J. Lyons (Ed.),</editor>
<publisher>Penguin.</publisher>
<location>New</location>
<note>horizons in linguistics</note>
<contexts>
<context position="1944" citStr="Clark, 1970" startWordPosition="299" endWordPosition="300">quisition and verbal behavior. 1 Introduction Word associations in general and free word association in particular (Galton, 1879) have been used by psychologists of various schools1 to understand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples’ thoughts, utterances, and actions. In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind. Kent &amp; Rosanoff (1910) have used this method for compar1 For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906). isons, introducing to this end 100 emotionally neutral test words. Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people&apos;s associations, that is, speakers of a language share stable, comparable associative networks (Istifci, 2010). In this paper, we are mainly interested in the automatic acquisition of associations by computer. More precisely, we want to check whether a corpus-based method allows us to build automatically an ass</context>
</contexts>
<marker>Clark, 1970</marker>
<rawString>Clark, H. H. (1970). Word associations and linguistic theory. In J. Lyons (Ed.), New horizons in linguistics (pp. 271-286). Baltimore: Penguin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Collins</author>
<author>E F Loftus</author>
</authors>
<title>A spreadingactivation theory of semantic processing.</title>
<date>1975</date>
<journal>Psychological Review</journal>
<volume>8</volume>
<pages>407--428</pages>
<contexts>
<context position="1909" citStr="Collins and Loftus, 1975" startWordPosition="294" endWordPosition="297">behavior, i.e. an important part of language acquisition and verbal behavior. 1 Introduction Word associations in general and free word association in particular (Galton, 1879) have been used by psychologists of various schools1 to understand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples’ thoughts, utterances, and actions. In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind. Kent &amp; Rosanoff (1910) have used this method for compar1 For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906). isons, introducing to this end 100 emotionally neutral test words. Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people&apos;s associations, that is, speakers of a language share stable, comparable associative networks (Istifci, 2010). In this paper, we are mainly interested in the automatic acquisition of associations by computer. More precisely, we want to check whether a corpus-based method allo</context>
<context position="3813" citStr="Collins &amp; Loftus (1975)" startWordPosition="600" endWordPosition="603">ce, and decreases in the opposite case. Wettler et al. (2005) have shown that this mechanism can be replicated by looking at word co-occurrence frequencies in large text collections. But there had been earlier corpus-linguistic work: For example, Wettler &amp; Rapp (1989) compared several association measures in order to find search terms to be used for queries in information retrieval. Church &amp; Hanks (1990) suggested to use mutual information, an information theoretic measure, for computing association strength. Prior to this, a lot of work had been done without reliance of corpora. For example, Collins &amp; Loftus (1975) used associative semantic networks to show the distance between words. Others (Rosenzweig, 1961:358; Ekpo-Ufot, 1978) tried to show the universal status of a large subset of associations. While all these findings are important, we will not consider them further 43 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 43–48, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics here. Rather we will focus on the claim that a - corpus-derived co-occurrence network is able to mimic human associative behavior. Such </context>
</contexts>
<marker>Collins, Loftus, 1975</marker>
<rawString>Collins, A. M. and Loftus, E. F. (1975). A spreadingactivation theory of semantic processing. Psychological Review 8. Vol. 82, No. 6, 407-428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ekpo-Ufot</author>
</authors>
<title>Word associations: a comparative study among college students in Nigeria and the United States.</title>
<date>1978</date>
<journal>Journal of Cross-Cultural Psychology,</journal>
<volume>9</volume>
<issue>4</issue>
<pages>455--468</pages>
<contexts>
<context position="3931" citStr="Ekpo-Ufot, 1978" startWordPosition="618" endWordPosition="619">word co-occurrence frequencies in large text collections. But there had been earlier corpus-linguistic work: For example, Wettler &amp; Rapp (1989) compared several association measures in order to find search terms to be used for queries in information retrieval. Church &amp; Hanks (1990) suggested to use mutual information, an information theoretic measure, for computing association strength. Prior to this, a lot of work had been done without reliance of corpora. For example, Collins &amp; Loftus (1975) used associative semantic networks to show the distance between words. Others (Rosenzweig, 1961:358; Ekpo-Ufot, 1978) tried to show the universal status of a large subset of associations. While all these findings are important, we will not consider them further 43 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 43–48, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics here. Rather we will focus on the claim that a - corpus-derived co-occurrence network is able to mimic human associative behavior. Such a network consists of nodes, which in our case correspond to words (or lemmas), and of weights connecting the nodes. T</context>
</contexts>
<marker>Ekpo-Ufot, 1978</marker>
<rawString>Ekpo-Ufot, A. (1978). Word associations: a comparative study among college students in Nigeria and the United States. Journal of Cross-Cultural Psychology, Vol. 9(4), 455-468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Evert</author>
<author>B Krenn</author>
</authors>
<title>Methods for qualitative evaluation of lexical association measures.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<location>Toulouse,</location>
<contexts>
<context position="4778" citStr="Evert &amp; Krenn, 2001" startWordPosition="749" endWordPosition="752">CogACLL) @ EACL 2014, pages 43–48, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics here. Rather we will focus on the claim that a - corpus-derived co-occurrence network is able to mimic human associative behavior. Such a network consists of nodes, which in our case correspond to words (or lemmas), and of weights connecting the nodes. The strengths of these weights are computed on the basis of word co-occurrence data, and by optionally applying an association measure. But there are many association measures. Given their number and diversity some researchers (Evert &amp; Krenn, 2001) felt that there was a need to define some criteria and methods in order to allow for quantitative comparisons via task-based evaluations. Pursuing a similar goal, Pecina &amp; Schlesinger (2006) compared 82 different association measures for collocation extraction, while Hoang et al. (2009) classified them. Michelbacher et al. (2011) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) trie</context>
</contexts>
<marker>Evert, Krenn, 2001</marker>
<rawString>Evert, S. and Krenn, B. (2001). Methods for qualitative evaluation of lexical association measures. In Proceedings of the 39th Annual Meeting of the Association of Computational Linguistics, Toulouse, France, 188-915.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Freud</author>
</authors>
<date>1901</date>
<booktitle>The psychopathology of everyday life. Harmondsworth: Penguin. http://psychclassics.yorku.ca/Freud/Psycho/chap5.htm</booktitle>
<contexts>
<context position="1976" citStr="Freud, 1901" startWordPosition="303" endWordPosition="304">Introduction Word associations in general and free word association in particular (Galton, 1879) have been used by psychologists of various schools1 to understand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples’ thoughts, utterances, and actions. In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind. Kent &amp; Rosanoff (1910) have used this method for compar1 For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906). isons, introducing to this end 100 emotionally neutral test words. Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people&apos;s associations, that is, speakers of a language share stable, comparable associative networks (Istifci, 2010). In this paper, we are mainly interested in the automatic acquisition of associations by computer. More precisely, we want to check whether a corpus-based method allows us to build automatically an associative network akin to the one</context>
</contexts>
<marker>Freud, 1901</marker>
<rawString>Freud, S. (1901/1975). The psychopathology of everyday life. Harmondsworth: Penguin. http://psychclassics.yorku.ca/Freud/Psycho/chap5.htm</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Galton</author>
</authors>
<title>Psychometric experiments.</title>
<date>1879</date>
<journal>Brain</journal>
<volume>2</volume>
<pages>149--162</pages>
<contexts>
<context position="1461" citStr="Galton, 1879" startWordPosition="222" endWordPosition="223">arge part of the EAT which, in total, comprises 8400 words. Apart from extending the test set, we consider different properties of words: saliency, frequency and part-of-speech. For each feature categorize our test set, and we compare the simulation results to those based on the EAT. It turns out that there are surprising similarities which supports our claim that a corpus-derived co-occurrence network can simulate human associative behavior, i.e. an important part of language acquisition and verbal behavior. 1 Introduction Word associations in general and free word association in particular (Galton, 1879) have been used by psychologists of various schools1 to understand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples’ thoughts, utterances, and actions. In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind. Kent &amp; Rosanoff (1910) have used this method for compar1 For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906). isons, introducing to this end 100 emotionally neutral test w</context>
</contexts>
<marker>Galton, 1879</marker>
<rawString>Galton, F. (1879). Psychometric experiments. Brain (2), 149-162.</rawString>
</citation>
<citation valid="false">
<authors>
<author>W J B Van Heuven</author>
<author>P Mandera</author>
<author>E Keuleers</author>
<author>M Brysbaert</author>
</authors>
<title>(in press). Subtlex-UK: A new and improved word frequency database for British English.</title>
<journal>Quarterly Journal of Experimental Psychology.</journal>
<marker>Van Heuven, Mandera, Keuleers, Brysbaert, </marker>
<rawString>Van Heuven, W.J.B., Mandera, P., Keuleers, E., &amp; Brysbaert, M. (in press). Subtlex-UK: A new and improved word frequency database for British English. Quarterly Journal of Experimental Psychology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Hoang</author>
<author>S N Kim</author>
<author>M Y Kan</author>
</authors>
<title>A reexamination of lexical association measures.</title>
<date>2009</date>
<booktitle>Proceedings of the Workshop on Multiword Expressions, ACL-IJCNLP 2009, Suntec, Singapore,</booktitle>
<pages>31--39</pages>
<contexts>
<context position="5066" citStr="Hoang et al. (2009)" startWordPosition="793" endWordPosition="796"> in our case correspond to words (or lemmas), and of weights connecting the nodes. The strengths of these weights are computed on the basis of word co-occurrence data, and by optionally applying an association measure. But there are many association measures. Given their number and diversity some researchers (Evert &amp; Krenn, 2001) felt that there was a need to define some criteria and methods in order to allow for quantitative comparisons via task-based evaluations. Pursuing a similar goal, Pecina &amp; Schlesinger (2006) compared 82 different association measures for collocation extraction, while Hoang et al. (2009) classified them. Michelbacher et al. (2011) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words. Our work is related to previous studies comparing human word associations with those derived from corpus statistics</context>
</contexts>
<marker>Hoang, Kim, Kan, 2009</marker>
<rawString>Hoang, H.H, Kim, S. N. and Kan, M.Y. (2009). A reexamination of lexical association measures. Proceedings of the Workshop on Multiword Expressions, ACL-IJCNLP 2009, Suntec, Singapore, 31-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Istifci</author>
</authors>
<title>Playing with words: a study on word association responses.</title>
<date>2010</date>
<journal>The Journal of International Social Research,</journal>
<volume>3</volume>
<issue>10</issue>
<pages>360--368</pages>
<contexts>
<context position="2342" citStr="Istifci, 2010" startWordPosition="358" endWordPosition="359">rd, and is asked to produce the first other word coming to mind. Kent &amp; Rosanoff (1910) have used this method for compar1 For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906). isons, introducing to this end 100 emotionally neutral test words. Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people&apos;s associations, that is, speakers of a language share stable, comparable associative networks (Istifci, 2010). In this paper, we are mainly interested in the automatic acquisition of associations by computer. More precisely, we want to check whether a corpus-based method allows us to build automatically an associative network akin to the one in peoples’ mind, that is, a network able to mimic human behavior. This means, given a stimulus word the system is supposed to produce the same responses as people do. We know since the old Greeks that thoughts and their expressions (words) are linked via associations. Yet, what we still do not know is the nature of these links. Also, links vary in terms of stren</context>
</contexts>
<marker>Istifci, 2010</marker>
<rawString>Istifci, I. (2010). Playing with words: a study on word association responses. The Journal of International Social Research, 3(10), 360–368</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jung</author>
<author>F Riklin</author>
</authors>
<title>Experimentelle Untersuchungen über Assoziationen Gesunder.</title>
<date>1906</date>
<journal>Diagnostische Assoziationsstudien,</journal>
<volume>7</volume>
<pages>145</pages>
<editor>In Jung, C. G., editor,</editor>
<location>Barth, Leipzig.</location>
<contexts>
<context position="1998" citStr="Jung &amp; Riklin, 1906" startWordPosition="305" endWordPosition="308">Word associations in general and free word association in particular (Galton, 1879) have been used by psychologists of various schools1 to understand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples’ thoughts, utterances, and actions. In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind. Kent &amp; Rosanoff (1910) have used this method for compar1 For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906). isons, introducing to this end 100 emotionally neutral test words. Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people&apos;s associations, that is, speakers of a language share stable, comparable associative networks (Istifci, 2010). In this paper, we are mainly interested in the automatic acquisition of associations by computer. More precisely, we want to check whether a corpus-based method allows us to build automatically an associative network akin to the one in peoples’ mind, tha</context>
</contexts>
<marker>Jung, Riklin, 1906</marker>
<rawString>Jung, C. and F. Riklin. 1906. Experimentelle Untersuchungen über Assoziationen Gesunder. In Jung, C. G., editor, Diagnostische Assoziationsstudien, 7– 145. Barth, Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Kent</author>
<author>A J Rosanoff</author>
</authors>
<title>A study of association in insanity.</title>
<date>1910</date>
<journal>American Journal of Insanity,</journal>
<volume>67</volume>
<pages>37--96</pages>
<contexts>
<context position="1815" citStr="Kent &amp; Rosanoff (1910)" startWordPosition="278" endWordPosition="282">pports our claim that a corpus-derived co-occurrence network can simulate human associative behavior, i.e. an important part of language acquisition and verbal behavior. 1 Introduction Word associations in general and free word association in particular (Galton, 1879) have been used by psychologists of various schools1 to understand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples’ thoughts, utterances, and actions. In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind. Kent &amp; Rosanoff (1910) have used this method for compar1 For example, cognitive psychology (Collins and Loftus, 1975,), psycholinguistics (Clark, 1970) and psychoanalysis (Freud, 1901; Jung &amp; Riklin, 1906). isons, introducing to this end 100 emotionally neutral test words. Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people&apos;s associations, that is, speakers of a language share stable, comparable associative networks (Istifci, 2010). In this paper, we are mainly interested in the automatic acquisition of</context>
</contexts>
<marker>Kent, Rosanoff, 1910</marker>
<rawString>Kent, G.H. and Rosanoff, A.J. (1910). A study of association in insanity. American Journal of Insanity, 67, 37–96, 317–390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R Kiss</author>
<author>C Armstrong</author>
<author>R Milroy</author>
<author>J Piper</author>
</authors>
<title>An associative thesaurus of English and its computer analysis.</title>
<date>1973</date>
<editor>In: A. Aitken, R. Beiley, N. Hamilton-Smith (eds.):</editor>
<publisher>Edinburgh University Press.</publisher>
<contexts>
<context position="7226" citStr="Kiss et al. (1973)" startWordPosition="1135" endWordPosition="1138">ir base forms (e.g. wheel or big). This reduces noise and data sparsity while improving speed and accuracy during evaluation. Since this latter is based on exact string matching, our system would consider wheels, produced in response to car, as a mistake as the primary associative response of the test persons is wheel, the singular form. Lemmatization solves this problem. Since we were interested here only in content words (nouns, verbs, and adjectives) we removed all other words from the BNC. To evaluate the performance of our system we compared its results with the associations collected by Kiss et al. (1973), the Edinburgh Associative Thesaurus. The association norms of the EAT were produced by presenting each stimulus word to 100 subjects, and by collecting their responses. The subjects were 17 to 22 year old British students. Table 1 shows the associations produced by at least five participants in response to the stimulus words bath and cold together with the number of participants producing them. bath cold observed number of observed number of response subjects response subjects water 20 hot 34 tub 8 ice 10 clean 5 warm 7 hot 5 water 5 Table 1: Extracts from the EAT for the stimulus words bath</context>
</contexts>
<marker>Kiss, Armstrong, Milroy, Piper, 1973</marker>
<rawString>Kiss, G.R., Armstrong, C., Milroy, R., and Piper, J. (1973). An associative thesaurus of English and its computer analysis. In: A. Aitken, R. Beiley, N. Hamilton-Smith (eds.): The Computer and Literary Studies. Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Michelbacher</author>
<author>S Evert</author>
<author>H Schütze</author>
</authors>
<title>Asymmetry in corpus-derived and human associations.</title>
<date>2011</date>
<booktitle>Corpus Linguistics and Linguistic Theory,</booktitle>
<volume>7</volume>
<pages>245--276</pages>
<contexts>
<context position="5110" citStr="Michelbacher et al. (2011)" startWordPosition="799" endWordPosition="802">lemmas), and of weights connecting the nodes. The strengths of these weights are computed on the basis of word co-occurrence data, and by optionally applying an association measure. But there are many association measures. Given their number and diversity some researchers (Evert &amp; Krenn, 2001) felt that there was a need to define some criteria and methods in order to allow for quantitative comparisons via task-based evaluations. Pursuing a similar goal, Pecina &amp; Schlesinger (2006) compared 82 different association measures for collocation extraction, while Hoang et al. (2009) classified them. Michelbacher et al. (2011) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words. Our work is related to previous studies comparing human word associations with those derived from corpus statistics (e.g. Wettler et al., 2005; Tamir, 2005, Se</context>
</contexts>
<marker>Michelbacher, Evert, Schütze, 2011</marker>
<rawString>Michelbacher, L., Evert, S. and Schütze, H. (2011). Asymmetry in corpus-derived and human associations. Corpus Linguistics and Linguistic Theory, Vo. 7, No. 2, 245–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pecina</author>
<author>P Schlesinger</author>
</authors>
<title>Combining association measures for collocation extraction.</title>
<date>2006</date>
<booktitle>Proceedings of the 21th International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL 2006),</booktitle>
<pages>651--658</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="4969" citStr="Pecina &amp; Schlesinger (2006)" startWordPosition="780" endWordPosition="783">o-occurrence network is able to mimic human associative behavior. Such a network consists of nodes, which in our case correspond to words (or lemmas), and of weights connecting the nodes. The strengths of these weights are computed on the basis of word co-occurrence data, and by optionally applying an association measure. But there are many association measures. Given their number and diversity some researchers (Evert &amp; Krenn, 2001) felt that there was a need to define some criteria and methods in order to allow for quantitative comparisons via task-based evaluations. Pursuing a similar goal, Pecina &amp; Schlesinger (2006) compared 82 different association measures for collocation extraction, while Hoang et al. (2009) classified them. Michelbacher et al. (2011) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words. Our work is relate</context>
</contexts>
<marker>Pecina, Schlesinger, 2006</marker>
<rawString>Pecina, P., and Schlesinger, P. (2006). Combining association measures for collocation extraction. Proceedings of the 21th International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL 2006), Sydney, Australia, 651-658.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>On the relationship between word frequency and word</title>
<date>2005</date>
<pages>249--263</pages>
<contexts>
<context position="14399" citStr="Rapp, 2005" startWordPosition="2380" endWordPosition="2381">mance, which means that the system&apos;s behavior is very similar to human behavior with respect to saliency. Fig. 1: Quality of our system&apos;s (blue curve) and an average test person&apos;s (red curve) performance (measured as the number of matching responses found in the EAT) with respect to saliency. 4.2 Word frequency Encouraged by the findings for saliency, we conducted a similar experiment for word frequency. In this case the EAT stimulus words were split into frequency classes according to their corpus frequencies in the BNC. Since a logarithmic scale seems to be appropriate for word frequencies (Rapp, 2005; van Heuven et al., in press), we used the following six frequency classes (FC): FC1: 1 occurrence BNC (0.5%) FC2: from 1 to 10 occurrences BNC (9.2%) FC3: form 10 to 100 occurrences BNC (30.2%) FC4: from 100 to 1000 occurrences BNC (42.6%) FC5: from 1000 to 10000 occurrences BNC (17.3%) FC6: from 10000 to 100000 occurrences BNC (0.1%) As can be seen from the percentages at the end of each line, extremes, i.e. very high and very low frequencies are covered only marginally. In the first group we find words like cornucopia, jewelry4 and quaff, each appearing only once in the corpus, while the f</context>
</contexts>
<marker>Rapp, 2005</marker>
<rawString>Rapp, R. (2005). On the relationship between word frequency and word familiarity. In: B. Fisseni; H.-C. Schmitz; B. Schröder; P. Wagner (Hg.): Sprachtechnologie, mobile Kommunikation und linguistische Ressourcen. BeitrŠge zur GLDV-Tagung 2005 in Bonn. Frankfurt: Peter Lang. 249–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Rosenzweig</author>
</authors>
<title>Comparisons among word-assocation responses in</title>
<date>1961</date>
<journal>English, French, German, and Italian. The American Journal of Psychology,</journal>
<volume>74</volume>
<pages>347--360</pages>
<contexts>
<context position="3909" citStr="Rosenzweig, 1961" startWordPosition="616" endWordPosition="617">licated by looking at word co-occurrence frequencies in large text collections. But there had been earlier corpus-linguistic work: For example, Wettler &amp; Rapp (1989) compared several association measures in order to find search terms to be used for queries in information retrieval. Church &amp; Hanks (1990) suggested to use mutual information, an information theoretic measure, for computing association strength. Prior to this, a lot of work had been done without reliance of corpora. For example, Collins &amp; Loftus (1975) used associative semantic networks to show the distance between words. Others (Rosenzweig, 1961:358; Ekpo-Ufot, 1978) tried to show the universal status of a large subset of associations. While all these findings are important, we will not consider them further 43 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 43–48, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics here. Rather we will focus on the claim that a - corpus-derived co-occurrence network is able to mimic human associative behavior. Such a network consists of nodes, which in our case correspond to words (or lemmas), and of weights c</context>
</contexts>
<marker>Rosenzweig, 1961</marker>
<rawString>Rosenzweig, M. R. (1961). Comparisons among word-assocation responses in English, French, German, and Italian. The American Journal of Psychology, Vol. 74, No. 3, 347-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Schwartz</author>
<author>D Reisberg</author>
</authors>
<title>Learning and Memory.</title>
<date>1991</date>
<location>New York: Norton.</location>
<contexts>
<context position="3005" citStr="Schwartz &amp; Reisberg, 1991" startWordPosition="470" endWordPosition="473">sted in the automatic acquisition of associations by computer. More precisely, we want to check whether a corpus-based method allows us to build automatically an associative network akin to the one in peoples’ mind, that is, a network able to mimic human behavior. This means, given a stimulus word the system is supposed to produce the same responses as people do. We know since the old Greeks that thoughts and their expressions (words) are linked via associations. Yet, what we still do not know is the nature of these links. Also, links vary in terms of strength. Associationist learning theory (Schwartz &amp; Reisberg, 1991) explains how these strengths (or weights) are acquired. The strength between two perceived events increases by a constant fraction of a maximally possible increment at each co-occurrence, and decreases in the opposite case. Wettler et al. (2005) have shown that this mechanism can be replicated by looking at word co-occurrence frequencies in large text collections. But there had been earlier corpus-linguistic work: For example, Wettler &amp; Rapp (1989) compared several association measures in order to find search terms to be used for queries in information retrieval. Church &amp; Hanks (1990) suggest</context>
</contexts>
<marker>Schwartz, Reisberg, 1991</marker>
<rawString>Schwartz, B. and Reisberg, D. (1991). Learning and Memory. New York: Norton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Seidensticker</author>
</authors>
<title>Simulation von Wortassoziationen mit Hilfe von mathematischen Lernmodellen in der Psychologie. Dissertation an der</title>
<date>2006</date>
<institution>UniversitŠt Paderborn.</institution>
<contexts>
<context position="5728" citStr="Seidensticker, 2006" startWordPosition="890" endWordPosition="891">1) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words. Our work is related to previous studies comparing human word associations with those derived from corpus statistics (e.g. Wettler et al., 2005; Tamir, 2005, Seidensticker, 2006). The main differences are that we categorize our stimulus words and present results for each class, and that we have a stronger focus on the graph aspect of our network. 2 Resources and processing In order to simulate human associative behavior via corpora, we need them to encode knowledge that people typically have, that is, encyclopedic or universally shared knowledge (e.g. Paris capital of France) and episodic knowledge (i.e. knowledge momentarily true: Nadal winner of the French Open). To meet these goals we decided to use the British National Corpus (BNC, Burnard &amp; Aston, 1998) as it is </context>
</contexts>
<marker>Seidensticker, 2006</marker>
<rawString>Seidensticker, P. (2006). Simulation von Wortassoziationen mit Hilfe von mathematischen Lernmodellen in der Psychologie. Dissertation an der UniversitŠt Paderborn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tamir</author>
</authors>
<title>A Random Walk through Human Associations.</title>
<date>2005</date>
<booktitle>Proceedings of ICDM 2005:</booktitle>
<pages>442--449</pages>
<contexts>
<context position="5706" citStr="Tamir, 2005" startWordPosition="888" endWordPosition="889">r et al. (2011) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words. Our work is related to previous studies comparing human word associations with those derived from corpus statistics (e.g. Wettler et al., 2005; Tamir, 2005, Seidensticker, 2006). The main differences are that we categorize our stimulus words and present results for each class, and that we have a stronger focus on the graph aspect of our network. 2 Resources and processing In order to simulate human associative behavior via corpora, we need them to encode knowledge that people typically have, that is, encyclopedic or universally shared knowledge (e.g. Paris capital of France) and episodic knowledge (i.e. knowledge momentarily true: Nadal winner of the French Open). To meet these goals we decided to use the British National Corpus (BNC, Burnard &amp; </context>
</contexts>
<marker>Tamir, 2005</marker>
<rawString>Tamir, R. (2005). A Random Walk through Human Associations. Proceedings of ICDM 2005: 442-449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Washtell</author>
<author>K Markert</author>
</authors>
<title>A comparison of windowless and window-based computational association measures as predictors of syntagmatic human associations.</title>
<date>2009</date>
<booktitle>Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP &apos;09),</booktitle>
<volume>2</volume>
<pages>628--637</pages>
<contexts>
<context position="5373" citStr="Washtell &amp; Markert (2009)" startWordPosition="835" endWordPosition="838">earchers (Evert &amp; Krenn, 2001) felt that there was a need to define some criteria and methods in order to allow for quantitative comparisons via task-based evaluations. Pursuing a similar goal, Pecina &amp; Schlesinger (2006) compared 82 different association measures for collocation extraction, while Hoang et al. (2009) classified them. Michelbacher et al. (2011) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words. Our work is related to previous studies comparing human word associations with those derived from corpus statistics (e.g. Wettler et al., 2005; Tamir, 2005, Seidensticker, 2006). The main differences are that we categorize our stimulus words and present results for each class, and that we have a stronger focus on the graph aspect of our network. 2 Resources and processing In order to simulate human associative behavior</context>
</contexts>
<marker>Washtell, Markert, 2009</marker>
<rawString>Washtell, J.; Markert, K. (2009). A comparison of windowless and window-based computational association measures as predictors of syntagmatic human associations. Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP &apos;09), Volume 2, 628-637</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wettler</author>
<author>R Rapp</author>
</authors>
<title>A connectionist system to simulate lexical decisions in information retrieval.</title>
<date>1989</date>
<booktitle>Connectionism in Perspective.</booktitle>
<pages>463--469</pages>
<editor>In: R. Pfeifer, Z. Schreter, F. Fogelman, L. Steels (eds.):</editor>
<publisher>Elsevier,</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="3458" citStr="Wettler &amp; Rapp (1989)" startWordPosition="542" endWordPosition="545">ciations. Yet, what we still do not know is the nature of these links. Also, links vary in terms of strength. Associationist learning theory (Schwartz &amp; Reisberg, 1991) explains how these strengths (or weights) are acquired. The strength between two perceived events increases by a constant fraction of a maximally possible increment at each co-occurrence, and decreases in the opposite case. Wettler et al. (2005) have shown that this mechanism can be replicated by looking at word co-occurrence frequencies in large text collections. But there had been earlier corpus-linguistic work: For example, Wettler &amp; Rapp (1989) compared several association measures in order to find search terms to be used for queries in information retrieval. Church &amp; Hanks (1990) suggested to use mutual information, an information theoretic measure, for computing association strength. Prior to this, a lot of work had been done without reliance of corpora. For example, Collins &amp; Loftus (1975) used associative semantic networks to show the distance between words. Others (Rosenzweig, 1961:358; Ekpo-Ufot, 1978) tried to show the universal status of a large subset of associations. While all these findings are important, we will not cons</context>
</contexts>
<marker>Wettler, Rapp, 1989</marker>
<rawString>Wettler, M. and Rapp, R. (1989). A connectionist system to simulate lexical decisions in information retrieval. In: R. Pfeifer, Z. Schreter, F. Fogelman, L. Steels (eds.): Connectionism in Perspective. Amsterdam: Elsevier, 463–469.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wettler</author>
<author>R Rapp</author>
<author>P Sedlmeier</author>
</authors>
<title>Free word associations correspond to contiguities between words in texts.</title>
<date>2005</date>
<journal>Journal of Quantitative Linguistics</journal>
<volume>12</volume>
<issue>2</issue>
<pages>111--122</pages>
<contexts>
<context position="3251" citStr="Wettler et al. (2005)" startWordPosition="510" endWordPosition="513">man behavior. This means, given a stimulus word the system is supposed to produce the same responses as people do. We know since the old Greeks that thoughts and their expressions (words) are linked via associations. Yet, what we still do not know is the nature of these links. Also, links vary in terms of strength. Associationist learning theory (Schwartz &amp; Reisberg, 1991) explains how these strengths (or weights) are acquired. The strength between two perceived events increases by a constant fraction of a maximally possible increment at each co-occurrence, and decreases in the opposite case. Wettler et al. (2005) have shown that this mechanism can be replicated by looking at word co-occurrence frequencies in large text collections. But there had been earlier corpus-linguistic work: For example, Wettler &amp; Rapp (1989) compared several association measures in order to find search terms to be used for queries in information retrieval. Church &amp; Hanks (1990) suggested to use mutual information, an information theoretic measure, for computing association strength. Prior to this, a lot of work had been done without reliance of corpora. For example, Collins &amp; Loftus (1975) used associative semantic networks to</context>
<context position="5693" citStr="Wettler et al., 2005" startWordPosition="884" endWordPosition="887">fied them. Michelbacher et al. (2011) investigated the potential of asymmetric association measures, i.e. &amp;quot;associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)&amp;quot;. Washtell &amp; Markert (2009) tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words. Our work is related to previous studies comparing human word associations with those derived from corpus statistics (e.g. Wettler et al., 2005; Tamir, 2005, Seidensticker, 2006). The main differences are that we categorize our stimulus words and present results for each class, and that we have a stronger focus on the graph aspect of our network. 2 Resources and processing In order to simulate human associative behavior via corpora, we need them to encode knowledge that people typically have, that is, encyclopedic or universally shared knowledge (e.g. Paris capital of France) and episodic knowledge (i.e. knowledge momentarily true: Nadal winner of the French Open). To meet these goals we decided to use the British National Corpus (BN</context>
<context position="8212" citStr="Wettler et al., 2005" startWordPosition="1307" endWordPosition="1310">er of participants producing them. bath cold observed number of observed number of response subjects response subjects water 20 hot 34 tub 8 ice 10 clean 5 warm 7 hot 5 water 5 Table 1: Extracts from the EAT for the stimulus words bath and cold. The EAT lists the associations to 8400 stimulus words. Since we were only interested in nouns, verbs, and adjectives, we eliminated all other words and also multiword units (e.g. a lot). After having lemmatized the data with the NLTK we obtained a list of 5910 test items which is considerably more than the usual 100 used in many previous studies (e.g. Wettler et al., 2005). 3 A graph-based approach for computing word associations Unlike previous work (Wettler et al. 2005; Church &amp; Hanks, 1990) which is described in the terminology of the well known vector space model, in the construction of the current system we had a graph-based approach in mind so we describe the system in such terms. We built up a graph on the basis of the nouns, verbs, and adjectives occurring in the corpus, these tokens being the nodes of the graph.2 The links (also called 2 As preliminary experiments have shown, including function words in the graph can create noise in the retrieval of 44</context>
</contexts>
<marker>Wettler, Rapp, Sedlmeier, 2005</marker>
<rawString>Wettler, M., Rapp, R. and Sedlmeier, P. (2005). Free word associations correspond to contiguities between words in texts. Journal of Quantitative Linguistics 12(2), 111–122.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>