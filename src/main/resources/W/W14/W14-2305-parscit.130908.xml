<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000384">
<title confidence="0.989814">
Abductive Inference for Interpretation of Metaphors
</title>
<author confidence="0.890048">
Ekaterina Ovchinnikova*, Ross Israel*, Suzanne Wertheim+,
Vladimir Zaytsev*, Niloofar Montazeri*, Jerry Hobbs*
</author>
<affiliation confidence="0.3235">
* USC ISI, 4676 Admiralty Way, CA 90292, USA
</affiliation>
<email confidence="0.976457">
{katya,israel,vzaytsev,niloofar,hobbs}@isi.edu
</email>
<author confidence="0.391688">
+ Worthwhile Research &amp; Consulting, 430 1/2 N Genesee Av., Los Angeles, CA 90036, USA
</author>
<email confidence="0.993406">
worthwhileresearch@gmail.com
</email>
<sectionHeader confidence="0.997327" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997281">
This paper presents a metaphor interpre-
tation pipeline based on abductive infer-
ence. In this framework following (Hobbs,
1992) metaphor interpretation is modelled
as a part of the general discourse pro-
cessing problem, such that the overall dis-
course coherence is supported. We present
an experimental evaluation of the pro-
posed approach using linguistic data in
English and Russian.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999960666666666">
In this paper, we elaborate on a semantic pro-
cessing framework based on a mode of inference
called abduction, or inference to the best expla-
nation. In logic, abduction is a kind of inference
which arrives at an explanatory hypothesis given
an observation. (Hobbs et al., 1993) describe how
abduction can be applied to the discourse process-
ing problem, viewing the process of interpreting
sentences in discourse as the process of providing
the best explanation of why the sentence would be
true. (Hobbs et al., 1993) show that abductive rea-
soning as a discourse processing technique helps
to solve many pragmatic problems such as refer-
ence resolution, the interpretation of noun com-
pounds, detection of discourse relations, etc. as a
by-product. (Hobbs, 1992) explains how abduc-
tion can be applied to interpretation of metaphors.
The term conceptual metaphor (CM) refers
to the understanding of one concept or concep-
tual domain in terms of the properties of another
(Lakoff and Johnson, 1980; Lakoff, 1987). For ex-
ample, development can be understood as move-
ment (e.g., the economy moves forward, the en-
gine of the economy). In other words, a concep-
tual metaphor consists in mapping a target con-
ceptual domain (e.g., economy) to a source do-
main (e.g., vehicle) by comparing their properties
(e.g., an economy develops like a vehicle moves).
In text, conceptual metaphors are represented by
linguistic metaphors (LMs), i.e. natural language
phrases expressing the implied comparison of two
domains.
We present a metaphor interpretation approach
based on abduction. We developed an end-to-
end metaphor interpretation system that takes text
potentially containing linguistic metaphors as in-
put, detects linguistic metaphors, maps them to
conceptual metaphors, and interprets conceptual
metaphors in terms of both logical predicates and
natural language expressions. Currently, the sys-
tem can process linguistic metaphors mapping
predefined target and source domains.
We perform an experimental evaluation
of the proposed approach using linguistic
data in two languages: English and Rus-
sian. We select target concepts and generate
potential sources for them as described at
github.com/MetaphorExtractionTools/mokujin.
For top-ranked sources, we automatically find cor-
responding linguistic metaphors. These linguistic
metaphors are each then validated by three expert
linguists. For the validated linguistic metaphors,
we generate natural language interpretations,
which are also validated by three experts.
</bodyText>
<sectionHeader confidence="0.999947" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999468666666667">
Automatic interpretation of linguistic metaphors is
performed using two principal approaches: 1) de-
riving literal paraphrases for metaphorical expres-
sions from corpora (Shutova, 2010; Shutova et
al., 2012) and 2) reasoning with manually coded
knowledge (Hobbs, 1992; Narayanan, 1999; Barn-
den and Lee, 2002; Agerri et al., 2007; Veale and
Hao, 2008).
(Shutova, 2010; Shutova et al., 2012) present
methods for deriving paraphrases for linguis-
tic metaphors from corpora. For example, the
metaphorical expression &amp;quot;a carelessly leaked re-
</bodyText>
<page confidence="0.99035">
33
</page>
<note confidence="0.806395">
Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41,
Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999831852941176">
port&amp;quot; is paraphrased as &amp;quot;a carelessly disclosed re-
port&amp;quot;. This approach currently focuses on single-
word metaphors expressed by verbs only and does
not explain the target–source mapping.
The KARMA (Narayanan, 1999) and the ATT-
Meta (Barnden and Lee, 2002; Agerri et al., 2007)
systems perform reasoning with manually coded
world knowledge and operate mainly in the source
domain. The ATT-Meta system takes logical ex-
pressions that are representations of a small dis-
course fragment as input; i.e., it does not work
with natural language. KARMA focuses on dy-
namics and motion in space. For example, the
metaphorical expression the government is stum-
bling in its efforts is interpreted in terms of motion
in space: stumbling leads to falling, while falling
is a conventional metaphor for failing.
(Veale and Hao, 2008) suggest to derive
common-sense knowledge from WordNet and cor-
pora in order to obtain concept properties that can
be used for metaphor interpretation. Simple in-
ference operations, i.e. insertions, deletions and
substitution, allow the system to establish links be-
tween target and source concepts.
(Hobbs, 1992) understands metaphor interpre-
tation as a part of the general discourse processing
problem. According to Hobbs, a metaphorical ex-
pression should be interpreted in context. For ex-
ample, John is an elephant can be best interpreted
as &amp;quot;John is clumsy&amp;quot; in the context Mary is grace-
ful, but John is an elephant. In order to obtain
context-dependent interpretations, (Hobbs, 1992)
uses abductive inference linking parts of the dis-
course and ensuring discourse coherence.
</bodyText>
<sectionHeader confidence="0.993208" genericHeader="method">
3 Metaphor Interpretation System
</sectionHeader>
<bodyText confidence="0.999821266666667">
Our abduction-based metaphor interpretation sys-
tem is shown in Fig. 1. Text fragments possibly
containing linguistic metaphors are given as in-
put to the pipeline. The text fragments are parsed
and converted into logical forms (section 3.1).
The logical forms are input to the abductive rea-
soner (section 3.2) that is informed by a knowl-
edge base (section 4). The processing component
labelled &amp;quot;CM extractor &amp; scorer&amp;quot; extracts con-
ceptual metaphors from the logical abductive in-
terpretations and outputs scored CMs and Target-
Source mappings (section 3.3). The Target-Source
mappings are then translated into natural language
expressions by the NL generator module (sec-
tion 3.4).
</bodyText>
<subsectionHeader confidence="0.999241">
3.1 Logical Form Generation
</subsectionHeader>
<bodyText confidence="0.988307612903226">
A logical form (LF) is a conjunction of propo-
sitions which have argument links showing rela-
tionships among phrase constituents. We use logi-
cal representations of natural language texts as de-
scribed in (Hobbs, 1985). In order to obtain LFs
we convert dependency parses into logical repre-
sentations in two steps: 1) assign arguments to
each lemma, 2) apply rules to dependencies in or-
der to link arguments.
Consider the dependency structure for the sen-
tence, John decided to leave: [PRED decide
[SUBJ John] [OBJ leave]]. First, we
generate unlinked predicates for this structure:
John(e1, x1)ndecide(e2, x2, x3)nleave(e3, x4).
Then, based on the dependency labels, we link
argument x1 with x2, x3 with e3, and x1 with
x4 to obtain the following LF: John(e1, x1) n
decide(e2, x1, e3) n leave(e3, x1).
LFs are preferable to dependency structures in
this case because they generalize over syntax and
link arguments using long-distance dependencies.
Furthermore, we need logical representations in
order to apply abductive inference.
In order to produce logical forms for English,
we use the Boxer semantic parser (Bos et al.,
2004). As one of the possible formats, Boxer
outputs logical forms of sentences in the style of
(Hobbs, 1985). For Russian, we use the Malt de-
pendency parser (Nivre et al., 2006). We devel-
oped a converter turning Malt dependencies into
logical forms in the style of (Hobbs, 1985).1
</bodyText>
<subsectionHeader confidence="0.999079">
3.2 Abductive Inference
</subsectionHeader>
<bodyText confidence="0.869663533333334">
In order to detect conceptual metaphors and in-
fer explicit mappings between target and source
domains, we employ a mode of inference called
weighted abduction (Hobbs et al., 1993). This
framework is appealing because it is a realization
of the observation that we understand new mate-
rial by linking it with what we already know.
Abduction is inference to the best explanation.
Formally, logical abduction is defined as follows:
Given: Background knowledge B, observations
O, where both B and O are sets of first-order log-
ical formulas,
Find: A hypothesis H such that H UB S O, H U
B KL, where H is a set of first-order logical for-
mulas.
</bodyText>
<footnote confidence="0.9905505">
1The converter is freely available at
https://github.com/eovchinn/Metaphor-ADP.
</footnote>
<page confidence="0.998746">
34
</page>
<figureCaption confidence="0.999908">
Figure 1: Abduction-based metaphor interpretation system.
</figureCaption>
<bodyText confidence="0.999960048387097">
Typically, there exist several hypotheses H ex-
plaining O. To rank hypotheses according to plau-
sibility and select the best hypothesis, we use
the framework of weighted abduction (Hobbs et
al., 1993). Frequently, the best interpretation re-
sults from identifying two entities with each other,
so that their common properties only need to be
proved or assumed once. Weighted abduction fa-
vors those interpretations that link parts of obser-
vations together and supports discourse coherence,
which is crucial for discourse interpretation.
According to (Hobbs, 1985), metaphor interpre-
tation can be modelled as abductive inference re-
vealing conceptual overlap between the target and
the source domain. Consider the abductive inter-
pretation produced for the sentence We intend to
cure poverty, Fig. 2. In the top line of the figure,
we have the LF (cf. Sec. 3.1), where we can see
that a person (x1) is the agent for the verbs intend
(e1) and cure (e2) and that poverty (x2) is the ob-
ject of cure. In the first box in the next row, we
see that cure invokes the source concepts of DIS-
EASE, CURE, and DOCTOR, where DISEASE is
the object of CURE, and DOCTOR is the subject.
In the same row, we see that poverty invokes the
POVERTY concept in the target domain. Impor-
tantly, POVERTY and DISEASE share the same
argument (x2), which refers to poverty.
The next row contains two boxes with ellipses,
representing long chains of common-sense infer-
ences in the source and target domains of DIS-
EASE and POVERTY, respectively. For DIS-
EASE we know that linguistic tokens such as ill-
ness, sick, disease, etc. cause the afflicted to expe-
rience loss of health, loss of energy, and a general
lack of productivity. For POVERTY, we know that
tokens such as poor, broke, poverty mean that the
experiencer of poverty lacks money to buy things,
take care of basic needs, or have access to trans-
portation. The end result of both of these frame-
works is that the affected individuals (or commu-
nities) cannot function at a normal level, with re-
spect to unaffected peers. We can use this common
meaning of causing the individual to not function
to link the target to the source.
The next three rows provide the mapping
from the meaning of the source (CURE, DOC-
TOR, DISEASE) concepts to the target concept
(POVERTY). As explained above, we can con-
sider DISEASE as a CAUSING-AGENT that can
CAUSE NOT FUNCTION; POVERTY can be ex-
plained the same way, at a certain level of abstrac-
tion. Essentially, the interpretation of poverty in
this sentence is that it causes some entity not to
function, which is what a DISEASE does as well.
For CURE, we see that cure can CAUSE NOT EX-
IST, while looking for a CAUSING-AGENT (per-
son) and an EXISTING DISEASE (poverty).
In our system, we use the implementation of
weighted abduction based on Integer Linear Pro-
gramming (ILP) (Inoue and Inui, 2012), which
makes the inference scalable.
</bodyText>
<subsectionHeader confidence="0.999966">
3.3 CM Extractor and Scorer
</subsectionHeader>
<bodyText confidence="0.997887230769231">
The abductive reasoning system produces an inter-
pretation that contains mappings of lexical items
into Target and Source domains. Any Target-
Source pair detected in a text fragment constitutes
a potential CM. For some text fragments, the sys-
tem identifies multiple CMs. We score Target-
Source pairs according to the length of the depen-
dency path linking them in the predicate-argument
structure. Consider the following text fragment:
opponents argue that any state attempting to force
an out-of-state business to do its dirty work of tax
collection violates another state’s right to regulate
its own corporate residents and their commerce
</bodyText>
<page confidence="0.998224">
35
</page>
<figureCaption confidence="0.999314">
Figure 2: Abductive interpretation for the sentence We intend to cure poverty.
</figureCaption>
<bodyText confidence="0.999961333333333">
Suppose our target domain is TAXATION, trig-
gered by tax collection in the sentence above. In
our corpus, we find realizations of the CM TAXA-
TION is an ENEMY (fight against taxes). The lex-
eme opponent triggers the STRUGGLE/ENEMY
domain. However, the sentence does not trigger
the CM TAXATION is an ENEMY. Instead, it in-
stantiates the CM TAXATION is DIRT (dirty work
of tax collection). The length of the dependency
path between dirty and tax is equal to 2, whereas
the path between opponent and tax is equal to
9. Therefore, our procedure ranks TAXATION is
DIRT higher, which corresponds to the intuition
that target and source words should constitute a
syntactic phrase in order to trigger a CM.
</bodyText>
<sectionHeader confidence="0.6562935" genericHeader="method">
3.4 NL Representation of Metaphor
Interpretation
</sectionHeader>
<bodyText confidence="0.999276">
The output of the abduction engine is similar to
the logical forms provided in Fig. 2. In order to
make the output more reader friendly, we produce
a natural language representation of the metaphor
interpretation using templates for each CM. For
example, the text their rivers of money mean they
can offer far more than a single vote would invoke
the WEALTH is WATER CM, and the abduction
engine would output: LARGE-AMOUNT[river],
THING-LARGE-AMOUNT[money]. We then
take this information and use it as input for the
NL generation module to produce: &amp;quot;river&amp;quot; implies
that there is a large amount of &amp;quot;money&amp;quot;.
</bodyText>
<sectionHeader confidence="0.993852" genericHeader="method">
4 Knowledge Base
</sectionHeader>
<bodyText confidence="0.999991111111111">
In order to process metaphors with abduction, we
need a knowledge base that encodes the informa-
tion about the source domain, the target domain,
and the relationships between sources and targets.
We develop two distinct sets of axioms: lexical ax-
ioms that encode lexical items triggering domains,
and mapping axioms that encode knowledge used
to link source and target domains. We will discuss
the details of each axiom type next.
</bodyText>
<subsectionHeader confidence="0.99829">
4.1 Lexical Axioms
</subsectionHeader>
<bodyText confidence="0.999993642857143">
Every content word or phrase that can be expected
to trigger a source or target domain is included as a
lexical axiom in the knowledge base. For example,
the STRUGGLE domain contains words like war,
fight, combat, conquer, weapon, etc. An example
of how a lexical axiom encodes the system logic is
given in (1). On the left side, we have the linguistic
token, fight, along with its part-of-speech, vb, and
the argument structure for verbs where eo is the
eventuality (see (Hobbs, 1985)) of the action of
fighting, x is the subject of the verb, and y is the
object. On the right side, STRUGGLE is linked to
the action of fighting, the subject is marked as the
AGENT, and the object is marked as the ENEMY.
</bodyText>
<equation confidence="0.9378135">
(1) fight-vb(e0, x, y) → STRUGGLE(e0)∧
AGENT(x, eo) ∧ ENEMY(y, eo)
</equation>
<bodyText confidence="0.998582666666667">
The lexicon is not limited to single-token en-
tries; phrases can be included as single entries; For
example, the ABYSS domain has phrases such as
climb out of as a single entry. Encoding phrases
often proves useful, as function words can often
help to distinguish one domain from others. In
this case, climbing out of something usually de-
notes an abyss, whereas climbing up or on usually
does not. The lexical axioms also include the POS
</bodyText>
<page confidence="0.991648">
36
</page>
<bodyText confidence="0.999106066666667">
for each word. Thus a word like fight can be en-
tered as both a noun and a verb. In cases where a
single lexical axiom could be applied to multiple
domains, one can create multiple entries for the
axiom with different domains and assign weights
so that a certain domain is preferred over others.
Initial lexical axioms for each domain were de-
veloped based on intuition about each domain.
We then utilize ConceptNet (Havasi et al., 2007)
as a source for semi-automatically extracting a
large-scale lexicon. ConceptNet is a multilingual
semantic network that establishes links between
words and phrases. We query ConceptNet for
our initial lexical axioms to return a list of related
words and expressions.
</bodyText>
<subsectionHeader confidence="0.994573">
4.2 Mapping Axioms
</subsectionHeader>
<bodyText confidence="0.999962775">
Mapping axioms provide the underlying meanings
for metaphors and link source and target domains.
All of these axioms are written by hand based
on common-sense world knowledge about each
target-source pair. For each CM, we consider a
set of LMs that are realizations of this CM in an
effort to capture inferences that are common for
all of the LMs. We consider the linguistic contexts
of the LMs and overlapping properties of the tar-
get and source domains derived from corpora as
described in section 5.1.
We will outline the process of axiomatizing the
STRUGGLE domain here. We know that a verb
like fight includes concepts for the struggle it-
self, an agent, and an enemy. In the context of
a STRUGGLE, an enemy can be viewed as some
entity a that attempts to, or actually does, inhibit
the functioning of some entity b, often through ac-
tual physical means, but also psychologically, eco-
nomically, etc. The struggle, or fight, itself then,
is an attempt by a to rid itself of b so that a can en-
sure normal functionality. So, given a phrase like
poverty is our enemy, the intended meaning is that
poverty is hindering the functionality of some en-
tity (an individual, a community, a country, etc.)
and is seen as a problem that must be fought,
i.e. eliminated. In a phrase like the war against
poverty, war refers to an effort to stop the exis-
tence of poverty. These inferences are supported
by the overlapping property propositions extracted
from English Gigaword as described in Sec. 5.1,
e.g., scourge of X, country fights X, country pulls
of X, suffer from X, fight against X.
To extend the example in (1), consider (2).
Here, we encode a STRUGGLE action, e.g. fight,
as CAUSE NOT EXIST, the AGENT of the
fight as CAUSING-AGENT, and the ENEMY as
EXISTING-THING. Then, for a verb phrase like
we fight poverty, we is the AGENT that engages in
causing poverty, the ENEMY, to not exist.
</bodyText>
<equation confidence="0.926326">
(2) STRUGGLE(e0) h AGENT(x, e0) h
ENEMY (y, 20) — CAUSE(e0)hCAUSED(-n,, e0)h
NOT(-n,, ex) h EXIST(ex) h CAUSING —
AGENT(x, e0) h EXISTING — THING(y, ex)
</equation>
<bodyText confidence="0.999979785714286">
We use 75 mapping axioms to cover the valid
LMs discussed in Sec. 5.2. Some interesting
trends emerge when examining the core meanings
of the LMs. Following (Hobbs, 2005), we found
that over 65% of the valid LMs in this study could
be explained in terms of causality. The next most
prevalent aspect that these metaphors touch upon
is that of functionality (nearly 35%), with some of
these overlapping with the causality aspect where
the meaning has to do with X causing Y to function
or not function.
Many of the CMs covered in this study have
fairly transparent interpretations based on these
ideas of causality and functionality, such as
POVERTY is DISEASE, where the main under-
lying meaning is that a disease causes the suf-
ferer not to function properly. However, for some
CMs, the interpretation can be more difficult to
pin down. For example, the interpretation of
WEALTH is a GAME is quite opaque. Given a
sentence such as, Wealth is a game and you better
start playing the game, there are no obvious con-
nections to concepts such as causality or function-
ality. Instead, game raises such ideas as competi-
tion, winning, and losing. In the literal context of a
game, the competition itself, who the competitors
are, and what it means to win or lose are usually
clearly defined, but this is not so when speaking
metaphorically about wealth. To derive a meaning
of game that can apply to wealth, we must look
at a higher level of abstraction and define game as
the instantiation of a positive or negative outcome,
i.e. to win is to achieve a positive outcome, or
gain wealth. In the same sentence play implies that
some voluntary action must be taken to achieve a
positive outcome.
For some metaphors, a simple transfer of the
source properties to the target does not result in
a coherent interpretation at all. Given, for exam-
ple, the CM POVERTY is a PRICE, one LM from
this study is, poverty is the price of peace. In this
case, the meaning has to do with some notion of
</bodyText>
<page confidence="0.99868">
37
</page>
<bodyText confidence="0.999991928571428">
an exchange, where a negative consequence must
be accepted in order to achieve a desired outcome.
However, the metaphorical meaning of price dif-
fers from the literal meaning of the word. In literal
contexts, price refers to an amount of money or
goods with inherent value that must be given to ac-
quire something; the buyer has a supply of money
or goods that they willingly exchange for their
desired item. In the metaphorical sense, though,
there often is no buyer, and there is certainly not
an inherent value that can be assigned to poverty,
nor can one use a supply of it to acquire peace.
Another issue concerns cultural differences.
While writing the axioms to deal with English and
Russian source-target pairs we noticed that a ma-
jority of the axioms applied equally well to both
languages. However, there are some subtle dif-
ferences of aspect that impact the interpretation
of similar CMs across the two languages. Look-
ing again at the WEALTH is a GAME metaphor,
the Russian interpretation involves some nuance
of a lack of importance about the subject that
does not seem to be present in English when us-
ing words like game and play. Note that there
may be some notion of carelessness for English
(see Sec. 5.3), but for Russian, the notion of being
carefree, which is not the same as careless, about
wealth has a strong prevalence.
</bodyText>
<sectionHeader confidence="0.998039" genericHeader="method">
5 Experimental Validation
</sectionHeader>
<subsectionHeader confidence="0.991707">
5.1 Source Generation
</subsectionHeader>
<bodyText confidence="0.964731517241379">
Following from the definition of metaphor, the tar-
get and the source domain share certain proper-
ties. In natural language, concepts and properties
are represented by words and phrases. There is
a long-standing tradition for considering compu-
tational models derived from word co-occurrence
statistics as being capable of producing reason-
able property-based descriptions of concepts (Ba-
roni and Lenci, 2008). We use proposition stores
to derive salient properties of concepts that can be
potentially compared in a metaphor.
A proposition store is a collection of proposi-
tions such that each proposition is assigned its fre-
quency in a corpus. Propositions are tuples of
words that have a determined pattern of syntactic
relations among them (Clark and Harrison, 2009;
Peñas and Hovy, 2010; Tsao and Wible, 2013).
For example, the following propositions can be ex-
tracted from the sentence John decided to go to
school:
(NV John decide)
(NV John go)
(NVPN John go to school)
...
We generated proposition stores from parsed
English Gigaword (Parker et al., 2011) and Rus-
sian ruWac (Sharoff and Nivre, 2011). Given the
proposition stores, we generate potential sources
for a seed target lexeme l in three steps:
</bodyText>
<listItem confidence="0.9811955">
1. Find all propositions Pl containing l.
2. Find all potential source lexemes 5 such that
</listItem>
<bodyText confidence="0.5564174">
for each s ∈ 5 there are propositions p, p&apos;
in the proposition store such that l occurs at
position i in p and s occurs at position i in p&apos;.
The set of propositions containing l and s at
the same positions is denoted by Plus.
</bodyText>
<listItem confidence="0.997747">
3. Weight potential sources s ∈ 5 using the fol-
lowing equation:
</listItem>
<equation confidence="0.9796915">
weightl(s) = � weightl(t), (1)
p∈Pl,s
</equation>
<bodyText confidence="0.994627666666667">
The source generation procedure and
its validations are described in detail at
github.com/MetaphorExtractionTools/mokujin.2
In the experiment described below, we gener-
ated potential sources for the target domains of
POVERTY and WEALTH.
</bodyText>
<subsectionHeader confidence="0.9009385">
5.2 Linguistic Metaphors Extraction and
Validation
</subsectionHeader>
<bodyText confidence="0.9999793125">
For each potential CM, we look for supporting
LMs in corpora. A a large number of LMs sup-
porting a particular CM suggests that this CM
might be cognitively plausible. We use a simple
method for finding LMs. If a target lexeme and
a source lexeme are connected by a dependency
relation in a sentence, then we assume that this
dependency structure contains a LM. For exam-
ple, in the phrases medicine against poverty and
chronic poverty, the target word (poverty) is re-
lated via dependency arc with the source words
(medicine, chronic). LMs were extracted from En-
glish Gigaword (Parker et al., 2011) and Russian
ruWac (Sharoff and Nivre, 2011).
For the generated CMs, we select seed lexemes
for target and source domains. We expand the
</bodyText>
<footnote confidence="0.999429">
2The tools for generating proposition stores
and the obtained resources are freely available at
https://ovchinnikova.me/proj/metaphor.html.
</footnote>
<page confidence="0.998906">
38
</page>
<bodyText confidence="0.999480892857143">
sets of these target and source lexemes with se-
mantically related lexemes using English and Rus-
sian ConceptNet (Speer and Havasi, 2013) and top
ranked patterns from the proposition stores. For
example, the expansion of the lexeme disease re-
sults in the following set of lexemes: {disease,
symptom, syndrome, illness, unwellness, sickness,
sick, medicine, treatment, treat, cure, doctor, ... }
For each language, we select 20 top-ranked
sources per target. Then we randomly select at
most 10 sentences per each target-source pair.
These sentences are validated by 3 linguist experts
each. For each sentence, the experts are asked if
it contains a metaphor comparing an indicated tar-
get domain with an indicated source domain. The
inter-annotator agreement on the validation task is
defined as the percentage of judgements on which
the three experts agree. Agreement is 81% for En-
glish and 80% for Russian.
Tables 1 and 2 show 10 potential sources per
target with the best agreement. Column ALL pro-
vides the number of sentences per a proposed CM
such that all experts agreed that the sentence con-
tains a metaphor. Column TWO provides the num-
ber of sentences such that any two experts agreed
on, and Column ONE shows the number of sen-
tences such that a single expert thought it con-
tained a metaphor.
</bodyText>
<table confidence="0.999591619047619">
target source ALL TWO ONE
wealth blood 10 10 10
water 9 10 10
drug 9 10 10
food 9 9 10
body 9 9 10
power 8 9 10
game 8 9 9
security 7 9 10
resource 7 7 9
disease 7 8 9
poverty war 10 10 10
abyss 10 10 10
violence 9 9 10
price 8 9 9
location 7 8 8
disease 7 7 7
crime 4 5 6
crop 3 7 9
terrorism 3 3 5
cost 2 3 7
</table>
<tableCaption confidence="0.954007">
Table 1: Validation of English linguistic
metaphors found for potential sources.
</tableCaption>
<subsectionHeader confidence="0.896737">
5.3 Metaphor Interpretation Validation
</subsectionHeader>
<bodyText confidence="0.913918">
Metaphor interpretations were generated for posi-
tively validated linguistic metaphors, as described
</bodyText>
<table confidence="0.9996858">
6OãàTCTBO (wealth) ýíåpãèÿ (energy) 10 10 10
Bî,gà (water) 10 10 10
cBîáî,gà (freed♦m) 10 10 10
B.JàcTb (p♦wer) 9 10 10
áîã (g♦d) 9 10 10
KpîBb (bl♦♦d) 9 10 10
ïóTb (way) 9 10 10
èãpà (game) 8 10 10
c.JàBà (gl♦ry) 4 5 5
TîBàp (ware) 3 8 10
6åäHOCTb (p♦verty) ïpîïàcTb (abyss) 10 10 10
Bpàã (enemy) 9 10 10
áî.Jåçíb (disease) 9 9 9
B.JàcTb (p♦wer) 8 10 10
Tå.Jî (b♦dy) 6 6 6
áî.Jb (pain) 5 10 10
îT÷àÿíèå (despair) 5 10 10
uåíà (price) 4 4 4
cMåpTb (death) 3 5 6
cTpàx (fear) 3 9 10
</table>
<tableCaption confidence="0.984167">
Table 2: Validation of Russian linguistic
metaphors found for potential sources.
</tableCaption>
<bodyText confidence="0.99827909375">
in Sec. 3.4. Each interpretation was validated by
three expert linguists. We calculated strict and
relaxed agreement for the validated data. Strict
agreement is calculated over three categories: cor-
rect (C), partially correct (P), and incorrect (I). Re-
laxed agreement is calculated over two categories:
C/P and I. Partially correct means that the valida-
tor felt that something was missing from the inter-
pretation, but that what was there was not wrong.
Table 3 presents the validation results for both lan-
guages. As can be seen in the table, strict agree-
ment (AgrS) is 62% and 52% and strict system
accuracy (AccS ALL) is 62% and 50% for En-
glish and Russian, respectively. Relaxed agree-
ment (AgrR) results is 93% and 83%, and relaxed
accuracy (AccR ALL) is 91% and 78%.
Validators often marked things as only partially
correct if they felt that the interpretation was lack-
ing some aspect that was critical to the meaning of
the metaphor. A common feeling amongst the val-
idators, for example, is that the interpretation for
people who are terrorized by poverty should in-
clude some mention of &amp;quot;fear&amp;quot; as a crucial aspect
of the metaphor, as the interpretation provided
states only that &amp;quot;terrorize&amp;quot; implies that &amp;quot;poverty&amp;quot;
is causing &amp;quot;people&amp;quot; not to function. However, the
end result of &amp;quot;fear&amp;quot; itself is often that the experi-
encer cannot function, as in paralyzed by fear.
Tables 4 and 5 contain interpretation system ac-
curacy results by CM. We calculated the percent-
age of LMs evoking this CM that were validated
as C vs. I (strict) or P/C vs. I (relaxed) by all three
</bodyText>
<page confidence="0.998254">
39
</page>
<table confidence="0.993278">
AgrS AgrR AccS ALL AccS TWO AccS ONE AccR ALL AccR TWO AccR ONE
English 0.62 0.93 0.62 0.84 0.98 0.91 0.97 0.99
Russian 0.52 0.83 0.50 0.76 0.96 0.78 0.93 0.99
</table>
<tableCaption confidence="0.999822">
Table 3: Validation results for metaphor interpretation for English and Russian.
</tableCaption>
<bodyText confidence="0.999402333333333">
(ALL), or just two (TWO) validators. In most of
the cases, the system performs well on &amp;quot;simple&amp;quot;
CMs related to the concepts of causation and func-
tioning (e.g., WEALTH is POWER), cf. section 4,
whereas its accuracy is lower for richer metaphors
(e.g., WEALTH is a GAME).
</bodyText>
<table confidence="0.999815454545454">
target source ALL TWO
S R S R
wealth blood 0.8 1 1 1
water 1 1 1 1
drug 0.44 0.78 0.89 0.89
food 0.89 1 1 1
body 0.67 0.78 0.78 0.78
power 1 1 1 1
game 0.63 1 1 1
security 0.14 0.88 0.71 1
resource 1 1 1 1
disease 0 1 1 1
poverty war 0.9 0.9 1 1
abyss 0 0.5 0.4 1
violence 0 1 0.11 1
price 0.88 0.88 0.88 1
location 1 1 1 1
disease 0.43 0.86 0.86 0.86
crime 0.75 1 1 1
crop 1 1 1 1
terrorism 0 1 0.33 1
cost 1 1 1 1
</table>
<tableCaption confidence="0.982016">
Table 4: Accuracy of English interpretations for
each CM.
</tableCaption>
<bodyText confidence="0.8739475">
The data used in the described experiments, sys-
tem output, and expert validations are available
at http://ovchinnikova.me/suppl/AbductionSystem-
Metaphor-Validation.7z.
</bodyText>
<sectionHeader confidence="0.998085" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999419846153846">
The developed abduction-based metaphor
interpretation pipeline is available at
https://github.com/eovchinn/Metaphor-ADP
as a free open-source project. This pipeline
produces favorable results, with metaphor in-
terpretations that are rated as at least partially
correct, for over 90% of all valid metaphors it is
given for English, and close to 80% for Russian.
Granted, the current research is performed using a
small, controlled set of metaphors, so these results
could prove difficult to reproduce on a large scale
where any metaphor is possible. Still, the high
accuracies achieved on both languages indicate
</bodyText>
<table confidence="0.999901272727273">
T s♦urce ALL TWO
S R S R
6OãàTCTBO (wealth) ýíåpãèÿ (energy) 0.4 0.8 0.9 1
Bî,gà (water) 0 0.9 0.6 0.9
cBîáî,gà (freed♦m) 1 1 1 1
B.nàcTb (p♦wer) 1 1 1 1
áîã (g♦d) 0.67 1 0.89 1
KpîBb (bl♦♦d) 1 1 1 1
ïóTb (way) 0.78 0.78 0.89 0.89
èãpà (game) 0.1 0.2 0.2 0.3
c.nàBà (gl♦ry) 0 0.75 0.75 1
TîBàp (ware) 0 0 0 1
6åäHOCTb (p♦verty) ïpîïàcTb (abyss) 0.7 1 1 1
Bpàã (enemy) 0.56 1 1 1
áî.nåçíb (disease) 0.33 0.89 0.67 1
B.nàcTb (p♦wer) 0.5 0.5 1 1
Tå.nî (b♦dy) 0.17 0.17 0.17 0.83
áî.nb (pain) 1 1 1 1
îT÷àÿíèå (despair) 0.6 0.6 1 1
öåíà (price) 0.75 0.75 1 1
cMåpTb (death) 0 0 0.33 1
cTpàx (fear) 0 1 0.67 1
</table>
<tableCaption confidence="0.97689">
Table 5: Accuracy of Russian interpretations for
each CM.
</tableCaption>
<bodyText confidence="0.999904125">
that the approach is sound and there is potential
for future work.
The current axiomatization methodology is
based mainly on manually writing mapping ax-
ioms based on the axiom author’s intuition. Ob-
viously, this approach is subject to scrutiny re-
garding the appropriateness of the metaphors and
faces scalability issues. Thus, developing new au-
tomatic methods to construct the domain knowl-
edge bases is a main area for future consideration.
The mapping axioms present a significant chal-
lenge as far producing reliable output automati-
cally. One area for consideration is the afore-
mentioned prevalence of certain underlying mean-
ings such as causality and functionality. Gather-
ing enough examples of these by hand could lead
to generalizations in argument structure that could
then be applied to metaphorical phrases in cor-
pora to extract new metaphors with similar mean-
ings. Crowd-sourcing is another option that could
be applied to both axiom writing tasks in order to
develop a large-scale knowledge base in consid-
erably less time and at a lower cost than having
experts build the knowledge base manually.
</bodyText>
<page confidence="0.997794">
40
</page>
<sectionHeader confidence="0.998345" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999938051282051">
R. Agerri, J.A. Barnden, M.G. Lee, and A.M. Walling-
ton. 2007. Metaphor, inference and domain-
independent mappings. In Proc. of RANLP’07,
pages 17–23.
J. A. Barnden and M. G. Lee. 2002. An artificial intel-
ligence approach to metaphor understanding. Theo-
ria et Historia Scientiarum, 6(1):399–412.
M. Baroni and A. Lenci. 2008. Concepts and proper-
ties in word spaces. Italian Journal of Linguistics,
20(1):55–88.
J. Bos, S. Clark, M. Steedman, J. R. Curran, and
J. Hockenmaier. 2004. Wide-coverage semantic
representations from a ccg parser. In Proc. of COL-
ING’04, pages 1240–1246.
P. Clark and P. Harrison. 2009. Large-scale extrac-
tion and use of knowledge from text. In Proc. of the
5th international conference on Knowledge capture,
pages 153–160. ACM.
Catherine Havasi, Robert Speer, and Jason Alonso.
2007. Conceptnet 3: a flexible, multilingual se-
mantic network for common sense knowledge. In
Recent Advances in Natural Language Processing,
Borovets, Bulgaria, September.
J. R. Hobbs, M. Stickel, P. Martin, and D. Edwards.
1993. Interpretation as abduction. Artificial Intelli-
gence, 63:69–142.
J. R. Hobbs. 1985. Ontological promiscuity. In Proc.
of ACL, pages 61–69, Chicago, Illinois.
J. R. Hobbs. 1992. Metaphor and abduction. In
A. Ortony, J. Slack, and O. Stock, editors, Com-
munication from an Artificial Intelligence Perspec-
tive: Theoretical and Applied Issues, pages 35–58.
Springer, Berlin, Heidelberg.
Jerry R. Hobbs. 2005. Toward a useful concept of
causality for lexical semantics. Journal of Seman-
tics, 22(2):181–209.
N. Inoue and K. Inui. 2012. Large-scale cost-based
abduction in full-fledged first-order predicate logic
with cutting plane inference. In Proc. of JELIA,
pages 281–293.
G. Lakoff and M. Johnson. 1980. Metaphors we Live
by. University of Chicago Press.
G. Lakoff. 1987. Women, fire, and dangerous things:
what categories reveal about the mind. University
of Chicago Press.
S. Narayanan. 1999. Moving right along: A computa-
tional model of metaphoric reasoning about events.
In Proc. of AAAI/IAAI, pages 121–127.
J. Nivre, J. Hall, and J. Nilsson. 2006. Maltparser:
A data-driven parser-generator for dependency pars-
ing. In Proc. of LREC’06, volume 6, pages 2216–
2219.
R. Parker, D. Graff, J. Kong, K. Chen, and K. Maeda.
2011. English gigaword fifth edition. LDC.
A. Peñas and E. H. Hovy. 2010. Filling knowledge
gaps in text for machine reading. In Proc. of COL-
ING’10, pages 979–987.
S. Sharoff and J. Nivre. 2011. The proper place of
men and machines in language technology: Process-
ing Russian without any linguistic knowledge. In
Proc. Dialogue 2011, Russian Conference on Com-
putational Linguistics.
E. Shutova, T. Van de Cruys, and A. Korhonen. 2012.
Unsupervised metaphor paraphrasing using a vector
space model. In COLING (Posters), pages 1121–
1130.
E. Shutova. 2010. Automatic metaphor interpretation
as a paraphrasing task. In Proc. of NAACL’10.
R. Speer and C. Havasi. 2013. Conceptnet 5: A large
semantic network for relational knowledge. In The
People’s Web Meets NLP, pages 161–176. Springer.
N. Tsao and D. Wible. 2013. Word similarity us-
ing constructions as contextual features. In Proc.
JSSP’13, pages 51–59.
T. Veale and Y. Hao. 2008. A fluid knowledge repre-
sentation for understanding and generating creative
metaphors. In Proc. of COLING’08, pages 945–952.
ACL.
</reference>
<page confidence="0.999446">
41
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.294708">
<title confidence="0.991959">Abductive Inference for Interpretation of Metaphors</title>
<author confidence="0.799322">Ross Israel Ovchinnikova</author>
<author confidence="0.799322">Suzanne Vladimir Zaytsev</author>
<author confidence="0.799322">Niloofar Montazeri</author>
<author confidence="0.799322">Jerry Hobbs</author>
<affiliation confidence="0.774285">USC ISI, 4676 Admiralty Way, CA 90292,</affiliation>
<address confidence="0.967553">Research &amp; Consulting, 430 1/2 N Genesee Av., Los Angeles, CA 90036,</address>
<email confidence="0.999761">worthwhileresearch@gmail.com</email>
<abstract confidence="0.958384363636364">This paper presents a metaphor interpretation pipeline based on abductive inference. In this framework following (Hobbs, 1992) metaphor interpretation is modelled as a part of the general discourse processing problem, such that the overall discourse coherence is supported. We present an experimental evaluation of the proposed approach using linguistic data in English and Russian.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Agerri</author>
<author>J A Barnden</author>
<author>M G Lee</author>
<author>A M Wallington</author>
</authors>
<title>Metaphor, inference and domainindependent mappings.</title>
<date>2007</date>
<booktitle>In Proc. of RANLP’07,</booktitle>
<pages>17--23</pages>
<contexts>
<context position="3619" citStr="Agerri et al., 2007" startWordPosition="528" endWordPosition="531">ked sources, we automatically find corresponding linguistic metaphors. These linguistic metaphors are each then validated by three expert linguists. For the validated linguistic metaphors, we generate natural language interpretations, which are also validated by three experts. 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &amp;quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics port&amp;quot; is paraphrased as &amp;quot;a carelessly disclosed report&amp;quot;. This approach currently focuses on singleword metaphors expressed by verbs only and does not explain the target–source mapping. The KARMA (Narayanan, 1999) and the ATTMeta (Barnden an</context>
</contexts>
<marker>Agerri, Barnden, Lee, Wallington, 2007</marker>
<rawString>R. Agerri, J.A. Barnden, M.G. Lee, and A.M. Wallington. 2007. Metaphor, inference and domainindependent mappings. In Proc. of RANLP’07, pages 17–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Barnden</author>
<author>M G Lee</author>
</authors>
<title>An artificial intelligence approach to metaphor understanding.</title>
<date>2002</date>
<journal>Theoria et Historia Scientiarum,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="3598" citStr="Barnden and Lee, 2002" startWordPosition="523" endWordPosition="527">ls/mokujin. For top-ranked sources, we automatically find corresponding linguistic metaphors. These linguistic metaphors are each then validated by three expert linguists. For the validated linguistic metaphors, we generate natural language interpretations, which are also validated by three experts. 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &amp;quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics port&amp;quot; is paraphrased as &amp;quot;a carelessly disclosed report&amp;quot;. This approach currently focuses on singleword metaphors expressed by verbs only and does not explain the target–source mapping. The KARMA (Narayanan, 1999) and th</context>
</contexts>
<marker>Barnden, Lee, 2002</marker>
<rawString>J. A. Barnden and M. G. Lee. 2002. An artificial intelligence approach to metaphor understanding. Theoria et Historia Scientiarum, 6(1):399–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Baroni</author>
<author>A Lenci</author>
</authors>
<title>Concepts and properties in word spaces.</title>
<date>2008</date>
<journal>Italian Journal of Linguistics,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="21700" citStr="Baroni and Lenci, 2008" startWordPosition="3563" endWordPosition="3567">otion of carelessness for English (see Sec. 5.3), but for Russian, the notion of being carefree, which is not the same as careless, about wealth has a strong prevalence. 5 Experimental Validation 5.1 Source Generation Following from the definition of metaphor, the target and the source domain share certain properties. In natural language, concepts and properties are represented by words and phrases. There is a long-standing tradition for considering computational models derived from word co-occurrence statistics as being capable of producing reasonable property-based descriptions of concepts (Baroni and Lenci, 2008). We use proposition stores to derive salient properties of concepts that can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: (NV John decide) (NV John go) (NVPN John go to school) ... We generated proposition stores</context>
</contexts>
<marker>Baroni, Lenci, 2008</marker>
<rawString>M. Baroni and A. Lenci. 2008. Concepts and properties in word spaces. Italian Journal of Linguistics, 20(1):55–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bos</author>
<author>S Clark</author>
<author>M Steedman</author>
<author>J R Curran</author>
<author>J Hockenmaier</author>
</authors>
<title>Wide-coverage semantic representations from a ccg parser.</title>
<date>2004</date>
<booktitle>In Proc. of COLING’04,</booktitle>
<pages>1240--1246</pages>
<contexts>
<context position="7430" citStr="Bos et al., 2004" startWordPosition="1125" endWordPosition="1128"> leave]]. First, we generate unlinked predicates for this structure: John(e1, x1)ndecide(e2, x2, x3)nleave(e3, x4). Then, based on the dependency labels, we link argument x1 with x2, x3 with e3, and x1 with x4 to obtain the following LF: John(e1, x1) n decide(e2, x1, e3) n leave(e3, x1). LFs are preferable to dependency structures in this case because they generalize over syntax and link arguments using long-distance dependencies. Furthermore, we need logical representations in order to apply abductive inference. In order to produce logical forms for English, we use the Boxer semantic parser (Bos et al., 2004). As one of the possible formats, Boxer outputs logical forms of sentences in the style of (Hobbs, 1985). For Russian, we use the Malt dependency parser (Nivre et al., 2006). We developed a converter turning Malt dependencies into logical forms in the style of (Hobbs, 1985).1 3.2 Abductive Inference In order to detect conceptual metaphors and infer explicit mappings between target and source domains, we employ a mode of inference called weighted abduction (Hobbs et al., 1993). This framework is appealing because it is a realization of the observation that we understand new material by linking </context>
</contexts>
<marker>Bos, Clark, Steedman, Curran, Hockenmaier, 2004</marker>
<rawString>J. Bos, S. Clark, M. Steedman, J. R. Curran, and J. Hockenmaier. 2004. Wide-coverage semantic representations from a ccg parser. In Proc. of COLING’04, pages 1240–1246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Clark</author>
<author>P Harrison</author>
</authors>
<title>Large-scale extraction and use of knowledge from text.</title>
<date>2009</date>
<booktitle>In Proc. of the 5th international conference on Knowledge capture,</booktitle>
<pages>153--160</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="22058" citStr="Clark and Harrison, 2009" startWordPosition="3622" endWordPosition="3625">perties are represented by words and phrases. There is a long-standing tradition for considering computational models derived from word co-occurrence statistics as being capable of producing reasonable property-based descriptions of concepts (Baroni and Lenci, 2008). We use proposition stores to derive salient properties of concepts that can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: (NV John decide) (NV John go) (NVPN John go to school) ... We generated proposition stores from parsed English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). Given the proposition stores, we generate potential sources for a seed target lexeme l in three steps: 1. Find all propositions Pl containing l. 2. Find all potential source lexemes 5 such that for each s ∈ 5 there are propositions p, p&apos; in the proposition stor</context>
</contexts>
<marker>Clark, Harrison, 2009</marker>
<rawString>P. Clark and P. Harrison. 2009. Large-scale extraction and use of knowledge from text. In Proc. of the 5th international conference on Knowledge capture, pages 153–160. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Havasi</author>
<author>Robert Speer</author>
<author>Jason Alonso</author>
</authors>
<title>Conceptnet 3: a flexible, multilingual semantic network for common sense knowledge.</title>
<date>2007</date>
<booktitle>In Recent Advances in Natural Language Processing,</booktitle>
<location>Borovets, Bulgaria,</location>
<contexts>
<context position="15604" citStr="Havasi et al., 2007" startWordPosition="2512" endWordPosition="2515">inguish one domain from others. In this case, climbing out of something usually denotes an abyss, whereas climbing up or on usually does not. The lexical axioms also include the POS 36 for each word. Thus a word like fight can be entered as both a noun and a verb. In cases where a single lexical axiom could be applied to multiple domains, one can create multiple entries for the axiom with different domains and assign weights so that a certain domain is preferred over others. Initial lexical axioms for each domain were developed based on intuition about each domain. We then utilize ConceptNet (Havasi et al., 2007) as a source for semi-automatically extracting a large-scale lexicon. ConceptNet is a multilingual semantic network that establishes links between words and phrases. We query ConceptNet for our initial lexical axioms to return a list of related words and expressions. 4.2 Mapping Axioms Mapping axioms provide the underlying meanings for metaphors and link source and target domains. All of these axioms are written by hand based on common-sense world knowledge about each target-source pair. For each CM, we consider a set of LMs that are realizations of this CM in an effort to capture inferences t</context>
</contexts>
<marker>Havasi, Speer, Alonso, 2007</marker>
<rawString>Catherine Havasi, Robert Speer, and Jason Alonso. 2007. Conceptnet 3: a flexible, multilingual semantic network for common sense knowledge. In Recent Advances in Natural Language Processing, Borovets, Bulgaria, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
<author>M Stickel</author>
<author>P Martin</author>
<author>D Edwards</author>
</authors>
<title>Interpretation as abduction.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--69</pages>
<contexts>
<context position="1053" citStr="Hobbs et al., 1993" startWordPosition="149" endWordPosition="152">based on abductive inference. In this framework following (Hobbs, 1992) metaphor interpretation is modelled as a part of the general discourse processing problem, such that the overall discourse coherence is supported. We present an experimental evaluation of the proposed approach using linguistic data in English and Russian. 1 Introduction In this paper, we elaborate on a semantic processing framework based on a mode of inference called abduction, or inference to the best explanation. In logic, abduction is a kind of inference which arrives at an explanatory hypothesis given an observation. (Hobbs et al., 1993) describe how abduction can be applied to the discourse processing problem, viewing the process of interpreting sentences in discourse as the process of providing the best explanation of why the sentence would be true. (Hobbs et al., 1993) show that abductive reasoning as a discourse processing technique helps to solve many pragmatic problems such as reference resolution, the interpretation of noun compounds, detection of discourse relations, etc. as a by-product. (Hobbs, 1992) explains how abduction can be applied to interpretation of metaphors. The term conceptual metaphor (CM) refers to the</context>
<context position="7910" citStr="Hobbs et al., 1993" startWordPosition="1205" endWordPosition="1208">s in order to apply abductive inference. In order to produce logical forms for English, we use the Boxer semantic parser (Bos et al., 2004). As one of the possible formats, Boxer outputs logical forms of sentences in the style of (Hobbs, 1985). For Russian, we use the Malt dependency parser (Nivre et al., 2006). We developed a converter turning Malt dependencies into logical forms in the style of (Hobbs, 1985).1 3.2 Abductive Inference In order to detect conceptual metaphors and infer explicit mappings between target and source domains, we employ a mode of inference called weighted abduction (Hobbs et al., 1993). This framework is appealing because it is a realization of the observation that we understand new material by linking it with what we already know. Abduction is inference to the best explanation. Formally, logical abduction is defined as follows: Given: Background knowledge B, observations O, where both B and O are sets of first-order logical formulas, Find: A hypothesis H such that H UB S O, H U B KL, where H is a set of first-order logical formulas. 1The converter is freely available at https://github.com/eovchinn/Metaphor-ADP. 34 Figure 1: Abduction-based metaphor interpretation system. T</context>
</contexts>
<marker>Hobbs, Stickel, Martin, Edwards, 1993</marker>
<rawString>J. R. Hobbs, M. Stickel, P. Martin, and D. Edwards. 1993. Interpretation as abduction. Artificial Intelligence, 63:69–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Ontological promiscuity.</title>
<date>1985</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>61--69</pages>
<location>Chicago, Illinois.</location>
<contexts>
<context position="6518" citStr="Hobbs, 1985" startWordPosition="981" endWordPosition="982">) that is informed by a knowledge base (section 4). The processing component labelled &amp;quot;CM extractor &amp; scorer&amp;quot; extracts conceptual metaphors from the logical abductive interpretations and outputs scored CMs and TargetSource mappings (section 3.3). The Target-Source mappings are then translated into natural language expressions by the NL generator module (section 3.4). 3.1 Logical Form Generation A logical form (LF) is a conjunction of propositions which have argument links showing relationships among phrase constituents. We use logical representations of natural language texts as described in (Hobbs, 1985). In order to obtain LFs we convert dependency parses into logical representations in two steps: 1) assign arguments to each lemma, 2) apply rules to dependencies in order to link arguments. Consider the dependency structure for the sentence, John decided to leave: [PRED decide [SUBJ John] [OBJ leave]]. First, we generate unlinked predicates for this structure: John(e1, x1)ndecide(e2, x2, x3)nleave(e3, x4). Then, based on the dependency labels, we link argument x1 with x2, x3 with e3, and x1 with x4 to obtain the following LF: John(e1, x1) n decide(e2, x1, e3) n leave(e3, x1). LFs are preferab</context>
<context position="9068" citStr="Hobbs, 1985" startWordPosition="1388" endWordPosition="1389">e 1: Abduction-based metaphor interpretation system. Typically, there exist several hypotheses H explaining O. To rank hypotheses according to plausibility and select the best hypothesis, we use the framework of weighted abduction (Hobbs et al., 1993). Frequently, the best interpretation results from identifying two entities with each other, so that their common properties only need to be proved or assumed once. Weighted abduction favors those interpretations that link parts of observations together and supports discourse coherence, which is crucial for discourse interpretation. According to (Hobbs, 1985), metaphor interpretation can be modelled as abductive inference revealing conceptual overlap between the target and the source domain. Consider the abductive interpretation produced for the sentence We intend to cure poverty, Fig. 2. In the top line of the figure, we have the LF (cf. Sec. 3.1), where we can see that a person (x1) is the agent for the verbs intend (e1) and cure (e2) and that poverty (x2) is the object of cure. In the first box in the next row, we see that cure invokes the source concepts of DISEASE, CURE, and DOCTOR, where DISEASE is the object of CURE, and DOCTOR is the subje</context>
<context position="14442" citStr="Hobbs, 1985" startWordPosition="2304" endWordPosition="2305">code knowledge used to link source and target domains. We will discuss the details of each axiom type next. 4.1 Lexical Axioms Every content word or phrase that can be expected to trigger a source or target domain is included as a lexical axiom in the knowledge base. For example, the STRUGGLE domain contains words like war, fight, combat, conquer, weapon, etc. An example of how a lexical axiom encodes the system logic is given in (1). On the left side, we have the linguistic token, fight, along with its part-of-speech, vb, and the argument structure for verbs where eo is the eventuality (see (Hobbs, 1985)) of the action of fighting, x is the subject of the verb, and y is the object. On the right side, STRUGGLE is linked to the action of fighting, the subject is marked as the AGENT, and the object is marked as the ENEMY. (1) fight-vb(e0, x, y) → STRUGGLE(e0)∧ AGENT(x, eo) ∧ ENEMY(y, eo) The lexicon is not limited to single-token entries; phrases can be included as single entries; For example, the ABYSS domain has phrases such as climb out of as a single entry. Encoding phrases often proves useful, as function words can often help to distinguish one domain from others. In this case, climbing out</context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>J. R. Hobbs. 1985. Ontological promiscuity. In Proc. of ACL, pages 61–69, Chicago, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Metaphor and abduction. In</title>
<date>1992</date>
<booktitle>Communication from an Artificial Intelligence Perspective: Theoretical and Applied Issues,</booktitle>
<pages>35--58</pages>
<editor>A. Ortony, J. Slack, and O. Stock, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="1535" citStr="Hobbs, 1992" startWordPosition="227" endWordPosition="228">. In logic, abduction is a kind of inference which arrives at an explanatory hypothesis given an observation. (Hobbs et al., 1993) describe how abduction can be applied to the discourse processing problem, viewing the process of interpreting sentences in discourse as the process of providing the best explanation of why the sentence would be true. (Hobbs et al., 1993) show that abductive reasoning as a discourse processing technique helps to solve many pragmatic problems such as reference resolution, the interpretation of noun compounds, detection of discourse relations, etc. as a by-product. (Hobbs, 1992) explains how abduction can be applied to interpretation of metaphors. The term conceptual metaphor (CM) refers to the understanding of one concept or conceptual domain in terms of the properties of another (Lakoff and Johnson, 1980; Lakoff, 1987). For example, development can be understood as movement (e.g., the economy moves forward, the engine of the economy). In other words, a conceptual metaphor consists in mapping a target conceptual domain (e.g., economy) to a source domain (e.g., vehicle) by comparing their properties (e.g., an economy develops like a vehicle moves). In text, conceptua</context>
<context position="3558" citStr="Hobbs, 1992" startWordPosition="519" endWordPosition="520">thub.com/MetaphorExtractionTools/mokujin. For top-ranked sources, we automatically find corresponding linguistic metaphors. These linguistic metaphors are each then validated by three expert linguists. For the validated linguistic metaphors, we generate natural language interpretations, which are also validated by three experts. 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &amp;quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics port&amp;quot; is paraphrased as &amp;quot;a carelessly disclosed report&amp;quot;. This approach currently focuses on singleword metaphors expressed by verbs only and does not explain the target–source map</context>
<context position="5101" citStr="Hobbs, 1992" startWordPosition="760" endWordPosition="761"> with natural language. KARMA focuses on dynamics and motion in space. For example, the metaphorical expression the government is stumbling in its efforts is interpreted in terms of motion in space: stumbling leads to falling, while falling is a conventional metaphor for failing. (Veale and Hao, 2008) suggest to derive common-sense knowledge from WordNet and corpora in order to obtain concept properties that can be used for metaphor interpretation. Simple inference operations, i.e. insertions, deletions and substitution, allow the system to establish links between target and source concepts. (Hobbs, 1992) understands metaphor interpretation as a part of the general discourse processing problem. According to Hobbs, a metaphorical expression should be interpreted in context. For example, John is an elephant can be best interpreted as &amp;quot;John is clumsy&amp;quot; in the context Mary is graceful, but John is an elephant. In order to obtain context-dependent interpretations, (Hobbs, 1992) uses abductive inference linking parts of the discourse and ensuring discourse coherence. 3 Metaphor Interpretation System Our abduction-based metaphor interpretation system is shown in Fig. 1. Text fragments possibly contain</context>
</contexts>
<marker>Hobbs, 1992</marker>
<rawString>J. R. Hobbs. 1992. Metaphor and abduction. In A. Ortony, J. Slack, and O. Stock, editors, Communication from an Artificial Intelligence Perspective: Theoretical and Applied Issues, pages 35–58. Springer, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Toward a useful concept of causality for lexical semantics.</title>
<date>2005</date>
<journal>Journal of Semantics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="18099" citStr="Hobbs, 2005" startWordPosition="2943" endWordPosition="2944">mple in (1), consider (2). Here, we encode a STRUGGLE action, e.g. fight, as CAUSE NOT EXIST, the AGENT of the fight as CAUSING-AGENT, and the ENEMY as EXISTING-THING. Then, for a verb phrase like we fight poverty, we is the AGENT that engages in causing poverty, the ENEMY, to not exist. (2) STRUGGLE(e0) h AGENT(x, e0) h ENEMY (y, 20) — CAUSE(e0)hCAUSED(-n,, e0)h NOT(-n,, ex) h EXIST(ex) h CAUSING — AGENT(x, e0) h EXISTING — THING(y, ex) We use 75 mapping axioms to cover the valid LMs discussed in Sec. 5.2. Some interesting trends emerge when examining the core meanings of the LMs. Following (Hobbs, 2005), we found that over 65% of the valid LMs in this study could be explained in terms of causality. The next most prevalent aspect that these metaphors touch upon is that of functionality (nearly 35%), with some of these overlapping with the causality aspect where the meaning has to do with X causing Y to function or not function. Many of the CMs covered in this study have fairly transparent interpretations based on these ideas of causality and functionality, such as POVERTY is DISEASE, where the main underlying meaning is that a disease causes the sufferer not to function properly. However, for</context>
</contexts>
<marker>Hobbs, 2005</marker>
<rawString>Jerry R. Hobbs. 2005. Toward a useful concept of causality for lexical semantics. Journal of Semantics, 22(2):181–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Inoue</author>
<author>K Inui</author>
</authors>
<title>Large-scale cost-based abduction in full-fledged first-order predicate logic with cutting plane inference.</title>
<date>2012</date>
<booktitle>In Proc. of JELIA,</booktitle>
<pages>281--293</pages>
<contexts>
<context position="11355" citStr="Inoue and Inui, 2012" startWordPosition="1794" endWordPosition="1797">CTOR, DISEASE) concepts to the target concept (POVERTY). As explained above, we can consider DISEASE as a CAUSING-AGENT that can CAUSE NOT FUNCTION; POVERTY can be explained the same way, at a certain level of abstraction. Essentially, the interpretation of poverty in this sentence is that it causes some entity not to function, which is what a DISEASE does as well. For CURE, we see that cure can CAUSE NOT EXIST, while looking for a CAUSING-AGENT (person) and an EXISTING DISEASE (poverty). In our system, we use the implementation of weighted abduction based on Integer Linear Programming (ILP) (Inoue and Inui, 2012), which makes the inference scalable. 3.3 CM Extractor and Scorer The abductive reasoning system produces an interpretation that contains mappings of lexical items into Target and Source domains. Any TargetSource pair detected in a text fragment constitutes a potential CM. For some text fragments, the system identifies multiple CMs. We score TargetSource pairs according to the length of the dependency path linking them in the predicate-argument structure. Consider the following text fragment: opponents argue that any state attempting to force an out-of-state business to do its dirty work of ta</context>
</contexts>
<marker>Inoue, Inui, 2012</marker>
<rawString>N. Inoue and K. Inui. 2012. Large-scale cost-based abduction in full-fledged first-order predicate logic with cutting plane inference. In Proc. of JELIA, pages 281–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
<author>M Johnson</author>
</authors>
<title>Metaphors we Live by.</title>
<date>1980</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="1767" citStr="Lakoff and Johnson, 1980" startWordPosition="263" endWordPosition="266">ocess of interpreting sentences in discourse as the process of providing the best explanation of why the sentence would be true. (Hobbs et al., 1993) show that abductive reasoning as a discourse processing technique helps to solve many pragmatic problems such as reference resolution, the interpretation of noun compounds, detection of discourse relations, etc. as a by-product. (Hobbs, 1992) explains how abduction can be applied to interpretation of metaphors. The term conceptual metaphor (CM) refers to the understanding of one concept or conceptual domain in terms of the properties of another (Lakoff and Johnson, 1980; Lakoff, 1987). For example, development can be understood as movement (e.g., the economy moves forward, the engine of the economy). In other words, a conceptual metaphor consists in mapping a target conceptual domain (e.g., economy) to a source domain (e.g., vehicle) by comparing their properties (e.g., an economy develops like a vehicle moves). In text, conceptual metaphors are represented by linguistic metaphors (LMs), i.e. natural language phrases expressing the implied comparison of two domains. We present a metaphor interpretation approach based on abduction. We developed an end-toend m</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>G. Lakoff and M. Johnson. 1980. Metaphors we Live by. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
</authors>
<title>Women, fire, and dangerous things: what categories reveal about the mind.</title>
<date>1987</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="1782" citStr="Lakoff, 1987" startWordPosition="267" endWordPosition="268">ences in discourse as the process of providing the best explanation of why the sentence would be true. (Hobbs et al., 1993) show that abductive reasoning as a discourse processing technique helps to solve many pragmatic problems such as reference resolution, the interpretation of noun compounds, detection of discourse relations, etc. as a by-product. (Hobbs, 1992) explains how abduction can be applied to interpretation of metaphors. The term conceptual metaphor (CM) refers to the understanding of one concept or conceptual domain in terms of the properties of another (Lakoff and Johnson, 1980; Lakoff, 1987). For example, development can be understood as movement (e.g., the economy moves forward, the engine of the economy). In other words, a conceptual metaphor consists in mapping a target conceptual domain (e.g., economy) to a source domain (e.g., vehicle) by comparing their properties (e.g., an economy develops like a vehicle moves). In text, conceptual metaphors are represented by linguistic metaphors (LMs), i.e. natural language phrases expressing the implied comparison of two domains. We present a metaphor interpretation approach based on abduction. We developed an end-toend metaphor interpr</context>
</contexts>
<marker>Lakoff, 1987</marker>
<rawString>G. Lakoff. 1987. Women, fire, and dangerous things: what categories reveal about the mind. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Narayanan</author>
</authors>
<title>Moving right along: A computational model of metaphoric reasoning about events.</title>
<date>1999</date>
<booktitle>In Proc. of AAAI/IAAI,</booktitle>
<pages>121--127</pages>
<contexts>
<context position="3575" citStr="Narayanan, 1999" startWordPosition="521" endWordPosition="522">phorExtractionTools/mokujin. For top-ranked sources, we automatically find corresponding linguistic metaphors. These linguistic metaphors are each then validated by three expert linguists. For the validated linguistic metaphors, we generate natural language interpretations, which are also validated by three experts. 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &amp;quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics port&amp;quot; is paraphrased as &amp;quot;a carelessly disclosed report&amp;quot;. This approach currently focuses on singleword metaphors expressed by verbs only and does not explain the target–source mapping. The KARMA (</context>
</contexts>
<marker>Narayanan, 1999</marker>
<rawString>S. Narayanan. 1999. Moving right along: A computational model of metaphoric reasoning about events. In Proc. of AAAI/IAAI, pages 121–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>J Nilsson</author>
</authors>
<title>Maltparser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of LREC’06,</booktitle>
<volume>6</volume>
<pages>2216--2219</pages>
<contexts>
<context position="7603" citStr="Nivre et al., 2006" startWordPosition="1156" endWordPosition="1159">x1 with x2, x3 with e3, and x1 with x4 to obtain the following LF: John(e1, x1) n decide(e2, x1, e3) n leave(e3, x1). LFs are preferable to dependency structures in this case because they generalize over syntax and link arguments using long-distance dependencies. Furthermore, we need logical representations in order to apply abductive inference. In order to produce logical forms for English, we use the Boxer semantic parser (Bos et al., 2004). As one of the possible formats, Boxer outputs logical forms of sentences in the style of (Hobbs, 1985). For Russian, we use the Malt dependency parser (Nivre et al., 2006). We developed a converter turning Malt dependencies into logical forms in the style of (Hobbs, 1985).1 3.2 Abductive Inference In order to detect conceptual metaphors and infer explicit mappings between target and source domains, we employ a mode of inference called weighted abduction (Hobbs et al., 1993). This framework is appealing because it is a realization of the observation that we understand new material by linking it with what we already know. Abduction is inference to the best explanation. Formally, logical abduction is defined as follows: Given: Background knowledge B, observations </context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>J. Nivre, J. Hall, and J. Nilsson. 2006. Maltparser: A data-driven parser-generator for dependency parsing. In Proc. of LREC’06, volume 6, pages 2216– 2219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Parker</author>
<author>D Graff</author>
<author>J Kong</author>
<author>K Chen</author>
<author>K Maeda</author>
</authors>
<title>English gigaword fifth edition.</title>
<date>2011</date>
<publisher>LDC.</publisher>
<contexts>
<context position="22351" citStr="Parker et al., 2011" startWordPosition="3672" endWordPosition="3675">derive salient properties of concepts that can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: (NV John decide) (NV John go) (NVPN John go to school) ... We generated proposition stores from parsed English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). Given the proposition stores, we generate potential sources for a seed target lexeme l in three steps: 1. Find all propositions Pl containing l. 2. Find all potential source lexemes 5 such that for each s ∈ 5 there are propositions p, p&apos; in the proposition store such that l occurs at position i in p and s occurs at position i in p&apos;. The set of propositions containing l and s at the same positions is denoted by Plus. 3. Weight potential sources s ∈ 5 using the following equation: weightl(s) = � weightl(t), (1) p∈Pl,s The source generation procedure </context>
<context position="23802" citStr="Parker et al., 2011" startWordPosition="3919" endWordPosition="3922">traction and Validation For each potential CM, we look for supporting LMs in corpora. A a large number of LMs supporting a particular CM suggests that this CM might be cognitively plausible. We use a simple method for finding LMs. If a target lexeme and a source lexeme are connected by a dependency relation in a sentence, then we assume that this dependency structure contains a LM. For example, in the phrases medicine against poverty and chronic poverty, the target word (poverty) is related via dependency arc with the source words (medicine, chronic). LMs were extracted from English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). For the generated CMs, we select seed lexemes for target and source domains. We expand the 2The tools for generating proposition stores and the obtained resources are freely available at https://ovchinnikova.me/proj/metaphor.html. 38 sets of these target and source lexemes with semantically related lexemes using English and Russian ConceptNet (Speer and Havasi, 2013) and top ranked patterns from the proposition stores. For example, the expansion of the lexeme disease results in the following set of lexemes: {disease, symptom, syndrome, illness, unw</context>
</contexts>
<marker>Parker, Graff, Kong, Chen, Maeda, 2011</marker>
<rawString>R. Parker, D. Graff, J. Kong, K. Chen, and K. Maeda. 2011. English gigaword fifth edition. LDC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Peñas</author>
<author>E H Hovy</author>
</authors>
<title>Filling knowledge gaps in text for machine reading.</title>
<date>2010</date>
<booktitle>In Proc. of COLING’10,</booktitle>
<pages>979--987</pages>
<contexts>
<context position="22080" citStr="Peñas and Hovy, 2010" startWordPosition="3626" endWordPosition="3629"> words and phrases. There is a long-standing tradition for considering computational models derived from word co-occurrence statistics as being capable of producing reasonable property-based descriptions of concepts (Baroni and Lenci, 2008). We use proposition stores to derive salient properties of concepts that can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: (NV John decide) (NV John go) (NVPN John go to school) ... We generated proposition stores from parsed English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). Given the proposition stores, we generate potential sources for a seed target lexeme l in three steps: 1. Find all propositions Pl containing l. 2. Find all potential source lexemes 5 such that for each s ∈ 5 there are propositions p, p&apos; in the proposition store such that l occurs a</context>
</contexts>
<marker>Peñas, Hovy, 2010</marker>
<rawString>A. Peñas and E. H. Hovy. 2010. Filling knowledge gaps in text for machine reading. In Proc. of COLING’10, pages 979–987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sharoff</author>
<author>J Nivre</author>
</authors>
<title>The proper place of men and machines in language technology: Processing Russian without any linguistic knowledge.</title>
<date>2011</date>
<booktitle>In Proc. Dialogue 2011, Russian Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="22395" citStr="Sharoff and Nivre, 2011" startWordPosition="3680" endWordPosition="3683">at can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: (NV John decide) (NV John go) (NVPN John go to school) ... We generated proposition stores from parsed English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). Given the proposition stores, we generate potential sources for a seed target lexeme l in three steps: 1. Find all propositions Pl containing l. 2. Find all potential source lexemes 5 such that for each s ∈ 5 there are propositions p, p&apos; in the proposition store such that l occurs at position i in p and s occurs at position i in p&apos;. The set of propositions containing l and s at the same positions is denoted by Plus. 3. Weight potential sources s ∈ 5 using the following equation: weightl(s) = � weightl(t), (1) p∈Pl,s The source generation procedure and its validations are described in detail </context>
<context position="23846" citStr="Sharoff and Nivre, 2011" startWordPosition="3926" endWordPosition="3929">al CM, we look for supporting LMs in corpora. A a large number of LMs supporting a particular CM suggests that this CM might be cognitively plausible. We use a simple method for finding LMs. If a target lexeme and a source lexeme are connected by a dependency relation in a sentence, then we assume that this dependency structure contains a LM. For example, in the phrases medicine against poverty and chronic poverty, the target word (poverty) is related via dependency arc with the source words (medicine, chronic). LMs were extracted from English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). For the generated CMs, we select seed lexemes for target and source domains. We expand the 2The tools for generating proposition stores and the obtained resources are freely available at https://ovchinnikova.me/proj/metaphor.html. 38 sets of these target and source lexemes with semantically related lexemes using English and Russian ConceptNet (Speer and Havasi, 2013) and top ranked patterns from the proposition stores. For example, the expansion of the lexeme disease results in the following set of lexemes: {disease, symptom, syndrome, illness, unwellness, sickness, sick, medicine, treatment</context>
</contexts>
<marker>Sharoff, Nivre, 2011</marker>
<rawString>S. Sharoff and J. Nivre. 2011. The proper place of men and machines in language technology: Processing Russian without any linguistic knowledge. In Proc. Dialogue 2011, Russian Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shutova</author>
<author>T Van de Cruys</author>
<author>A Korhonen</author>
</authors>
<title>Unsupervised metaphor paraphrasing using a vector space model.</title>
<date>2012</date>
<booktitle>In COLING (Posters),</booktitle>
<pages>1121--1130</pages>
<marker>Shutova, Van de Cruys, Korhonen, 2012</marker>
<rawString>E. Shutova, T. Van de Cruys, and A. Korhonen. 2012. Unsupervised metaphor paraphrasing using a vector space model. In COLING (Posters), pages 1121– 1130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shutova</author>
</authors>
<title>Automatic metaphor interpretation as a paraphrasing task.</title>
<date>2010</date>
<booktitle>In Proc. of NAACL’10.</booktitle>
<contexts>
<context position="3475" citStr="Shutova, 2010" startWordPosition="506" endWordPosition="507"> We select target concepts and generate potential sources for them as described at github.com/MetaphorExtractionTools/mokujin. For top-ranked sources, we automatically find corresponding linguistic metaphors. These linguistic metaphors are each then validated by three expert linguists. For the validated linguistic metaphors, we generate natural language interpretations, which are also validated by three experts. 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &amp;quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics port&amp;quot; is paraphrased as &amp;quot;a carelessly disclosed report&amp;quot;. This approach currently focuses on sing</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>E. Shutova. 2010. Automatic metaphor interpretation as a paraphrasing task. In Proc. of NAACL’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Speer</author>
<author>C Havasi</author>
</authors>
<title>Conceptnet 5: A large semantic network for relational knowledge.</title>
<date>2013</date>
<booktitle>In The People’s Web Meets NLP,</booktitle>
<pages>161--176</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="24217" citStr="Speer and Havasi, 2013" startWordPosition="3980" endWordPosition="3983"> medicine against poverty and chronic poverty, the target word (poverty) is related via dependency arc with the source words (medicine, chronic). LMs were extracted from English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). For the generated CMs, we select seed lexemes for target and source domains. We expand the 2The tools for generating proposition stores and the obtained resources are freely available at https://ovchinnikova.me/proj/metaphor.html. 38 sets of these target and source lexemes with semantically related lexemes using English and Russian ConceptNet (Speer and Havasi, 2013) and top ranked patterns from the proposition stores. For example, the expansion of the lexeme disease results in the following set of lexemes: {disease, symptom, syndrome, illness, unwellness, sickness, sick, medicine, treatment, treat, cure, doctor, ... } For each language, we select 20 top-ranked sources per target. Then we randomly select at most 10 sentences per each target-source pair. These sentences are validated by 3 linguist experts each. For each sentence, the experts are asked if it contains a metaphor comparing an indicated target domain with an indicated source domain. The inter-</context>
</contexts>
<marker>Speer, Havasi, 2013</marker>
<rawString>R. Speer and C. Havasi. 2013. Conceptnet 5: A large semantic network for relational knowledge. In The People’s Web Meets NLP, pages 161–176. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tsao</author>
<author>D Wible</author>
</authors>
<title>Word similarity using constructions as contextual features.</title>
<date>2013</date>
<booktitle>In Proc. JSSP’13,</booktitle>
<pages>51--59</pages>
<contexts>
<context position="22103" citStr="Tsao and Wible, 2013" startWordPosition="3630" endWordPosition="3633">ere is a long-standing tradition for considering computational models derived from word co-occurrence statistics as being capable of producing reasonable property-based descriptions of concepts (Baroni and Lenci, 2008). We use proposition stores to derive salient properties of concepts that can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: (NV John decide) (NV John go) (NVPN John go to school) ... We generated proposition stores from parsed English Gigaword (Parker et al., 2011) and Russian ruWac (Sharoff and Nivre, 2011). Given the proposition stores, we generate potential sources for a seed target lexeme l in three steps: 1. Find all propositions Pl containing l. 2. Find all potential source lexemes 5 such that for each s ∈ 5 there are propositions p, p&apos; in the proposition store such that l occurs at position i in p and s</context>
</contexts>
<marker>Tsao, Wible, 2013</marker>
<rawString>N. Tsao and D. Wible. 2013. Word similarity using constructions as contextual features. In Proc. JSSP’13, pages 51–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>A fluid knowledge representation for understanding and generating creative metaphors.</title>
<date>2008</date>
<booktitle>In Proc. of COLING’08,</booktitle>
<pages>945--952</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="3641" citStr="Veale and Hao, 2008" startWordPosition="532" endWordPosition="535">atically find corresponding linguistic metaphors. These linguistic metaphors are each then validated by three expert linguists. For the validated linguistic metaphors, we generate natural language interpretations, which are also validated by three experts. 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &amp;quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, Baltimore, MD, USA, 26 June 2014. c�2014 Association for Computational Linguistics port&amp;quot; is paraphrased as &amp;quot;a carelessly disclosed report&amp;quot;. This approach currently focuses on singleword metaphors expressed by verbs only and does not explain the target–source mapping. The KARMA (Narayanan, 1999) and the ATTMeta (Barnden and Lee, 2002; Agerri et</context>
</contexts>
<marker>Veale, Hao, 2008</marker>
<rawString>T. Veale and Y. Hao. 2008. A fluid knowledge representation for understanding and generating creative metaphors. In Proc. of COLING’08, pages 945–952. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>