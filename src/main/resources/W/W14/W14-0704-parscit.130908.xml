<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.077190">
<title confidence="0.987554">
Studying the Semantic Context of two Dutch Causal Connectives
</title>
<author confidence="0.961928">
Iris Hendrickx and Wilbert Spooren
</author>
<affiliation confidence="0.855993">
Centre for Language Studies, Radboud University Nijmegen
</affiliation>
<address confidence="0.652026">
P.O. Box 9103, NL-6500 HD Nijmegen The Netherlands
</address>
<email confidence="0.87985">
i.hendrickx, w.spooren@let.ru.nl
</email>
<sectionHeader confidence="0.988901" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999942722222222">
We aim to study the difference of usage
between two causal connectives in their
semantic context. We present an ongo-
ing study of two Dutch backward causal
connectives omdat and want. Previous lin-
guistic research has shown that causal con-
structions with want are more subjective
and often express an opinion. Our hy-
pothesis is that the left and right context
surrounding the connectives are more se-
mantically similar in sentences with om-
dat than sentences with want. To test this
hypothesis we apply two techniques, La-
tent Semantic Analysis and n-gram over-
lap. We show that both methods indeed in-
dicate a substantial difference between the
two connectives but opposite to what we
had expected.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999515925925926">
Much corpus linguistic research has dealt with the
issue of subjectivity, i.e. the degree to which the
presence of the writer or speaker of a text is felt
((Sanders and Spooren, 2013), and the references
cited there). Subjectivity can be located at differ-
ent levels in a text. At the word level, some words
(e.g., evaluative adjectives and expletives) imply a
writer/speaker evaluation, whereas others do not.
At the sentence level, the description of facts is felt
to be more objective, whereas opinions are more
subjective. And at the supra-sentential level, sub-
jectivity can get expressed in the type of relation
that links the clauses or sentences. For example,
argumentative relations are more subjective than
statements. Interestingly, many languages make a
distinction between more objective or more sub-
jective causal connectives. In Dutch, for example,
omdat is typically used to express more or less ob-
jective backward causal relations, whereas want is
typically used for more subjective relations. How-
ever, these connectives are near synonyms and can
be used in the same context as shown in exam-
ple 1 and 2. There is subtle difference in meaning
because example 1 focuses on the reason relation
between the two segments whereas 2 focuses on
the argument relation. As the first segment is an
opinion, want is slightly more natural than omdat.
</bodyText>
<listItem confidence="0.987132333333333">
(1) Dat is vooral jammer omdat de
hoofdrolspeler uitstekend zingt.
(2) Dat is vooral jammer want de
hoofdrolspeler zingt uitstekend.
“That is particularly unfortunate because the
protagonist sings excellent.”
</listItem>
<bodyText confidence="0.998305583333333">
Note the difference in word order: want leads
to a coordinative conjunction while omdat gives a
subordinate conjunction.
We need more insight into this subtle difference
between connectives for example to allow natural
language generation systems to mimic the choices
that native speakers of Dutch make intuitively.
Another application would be sentiment analysis
where the difference in subjectivity of various con-
nectives can be used to identify subjective or opin-
ionated sentences.
Presently the corpus linguistic analyses of sub-
jective versus objective causal relations have very
much been a small-scale enterprise, in that corpus
examples were annotated manually. This is prob-
lematic for at least two reasons: manual annota-
tion relies on hand coding, with the accompanying
problems of poor inter-annotator reliability, and
the restricted size of the hand annotated corpora
limits the power of statistical generalization. Best-
gen et al. (2006) suggested to complement these
manual analyses with automatic analyses.
Bestgen and colleagues studied backward
causal connections in Dutch. They made use of
</bodyText>
<page confidence="0.989637">
28
</page>
<note confidence="0.83839">
Proceedings of the EACL 2014 Workshop on Computational Approaches to Causality in Language, pages 28–32,
Gothenburg, Sweden, April 26, 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.985800949152543">
two types of automatic analyses: Latent Semantic
Analysis (LSA) (Deerwester et al., 1990) and what
they call Thematic Text Analysis (Popping, 2000)
to show that the semantic connection between first
and second segment is weaker in a want connec-
tion than in a omdat connection, and that the first
segment of want connections contains more sub-
jective words than the first segment of omdat con-
nections. The materials that were used by Best-
gen et al. (2006) were texts from a large corpus of
newspaper language of 16.5 million tokens.
The purpose of our current ongoing research
project is to extend the automatic analyses in two
ways: on the one hand we want to reproduce the
LSA analysis of Bestgen et al. using a larger cor-
pus of about 30 million tokens; on the other hand,
we want to use n-gram analyses to investigate the
semantic connection between the segments in a
want versus omdat connection.
The use of n-grams to measure semantic over-
lap is a well known method, which has been ap-
plied in the standard evaluation metrics for tasks
like machine translation and automatic summa-
rization. In these tasks automatic systems aim to
produce a text as similar as possible to a manu-
ally constructed gold standard text. To evaluate the
quality of these automatically produced text, mea-
sures such as BLUE (Papineni et al., 2002) and
ROUGE (Lin and Hovy, 2003) measure n-gram
overlap between the system text and the gold stan-
dard text. Furthermore, in other types of research
like in the field of literary studies n-grams have
been applied, for example to discriminate between
genres (Louwerse et al., 2008) or for author dis-
crimination (Hirst and Feiguina, 2007).
Backward causal connectives denotes a cause
relation. The connective is positioned in a sen-
tence between the consequence (denoted as Q) and
the cause (denoted as P). For the sentence in exam-
ple 1 Q is the text segment before the connective,
and P contains all words after the connective as
follows:
Q Dat is vooral jammer
P de hoofdrolspeler uitstekend zingt.
Our hypothesis is that Q and P are more se-
mantically similar in sentences with omdat than
sentences with want. This implies that we expect
the average cosine between P and Q to be smaller
in omdat connections than in want connections.
We also hypothesize that the number of n-grams
shared between P and Q will be higher in omdat
sentences than in want sentences.
This paper presents work in progress. We first
describe the SoNaR corpus that was used in this
study in section 2. In section 3 we present the
experimental setup and results of the experiments
with LSA. In section 4 we detail our approach to
computing n-grams and we discuss our findings
and the next steps to take in 5.
</bodyText>
<sectionHeader confidence="0.959996" genericHeader="method">
2 Data Collection
</sectionHeader>
<bodyText confidence="0.999931057142857">
Unfortunately neither the corpus nor the data sam-
ple used by Bestgen et al. (2006) was available to
us. For this reason we chose a similar Duch corpus
to work with. The SoNaR corpus (Oostdijk et al.,
2013) is a reference corpus of 500 million writ-
ten words of contemporary Dutch sampled from
a wide variety of sources and genres. The corpus
has been automatically tokenized, part-of-speech
tagged and lemmatized. We took a sample of
100K news articles from the SoNaR corpus as our
experimental data set. As we are interested in se-
mantic overlap, we took the lemmatized versions
of the articles.
From this data set, we collected all sentences
containing the connectives omdat and want. As we
aim to study the semantic relation between Q and
P, we only selected sentences that have a mean-
ingful Q and P in the same sentence. We excluded
sentences with sentence initial connectives as they
only contain a P segment. Sentences with short
Q segments (containing one or two words), were
manually inspected. A sentence that starts with
dat komt omdat “ this is because” does not con-
tain a meaningful consequence because it refers
back to information in a previous sentence. On
the other hand, a short Q segment like tevergeefs,
want “in vain, because” does express a meaning-
ful consequence. In case of sentences with mul-
tiple connections, we took the first Q and P and
cut off the remainder parts using some handwritten
rules. Overall we excluded 20% of want sentences
and 25% of omdat sentences. In total we selected
18,260 for omdat and 14,449 sentences for want.
Some statistics about the sentences is shown in Ta-
ble 1.
</bodyText>
<sectionHeader confidence="0.997185" genericHeader="method">
3 LSA
</sectionHeader>
<bodyText confidence="0.666518">
Latent Semantic Analysis (LSA) is a mathematical
method for representing word meaning similarity
in a semantic space based on a term-by-documents
</bodyText>
<page confidence="0.99171">
29
</page>
<table confidence="0.999239">
Sentences length Q len P len
omdat 18,260 24.3 11.2 12.1
want 14,449 23.5 9.6 12.9
</table>
<tableCaption confidence="0.996973">
Table 1: Number of sentences and average length
</tableCaption>
<bodyText confidence="0.997666378378378">
in tokens of the full sentence, Q, and P in the data
set of want and omdat.
matrix. It applies singular value decomposition
to this matrix to condense it to a smaller seman-
tic representation of around 100 - 500 dimensions
(Landauer et al., 1998).
We applied LSA to measure the semantic over-
lap between Q and P of the omdat and want sen-
tences. We constructed a term-by-document ma-
trix based on the SoNaR news sample and con-
verted this to an LSA space with 300 dimensions.
Each Q and P was projected as a term vector in the
LSA space and we computed the cosine similarity
between each Q and P.
To build the document-by-term matrix for LSA,
words were lemmatized, and punctuation, digits
and stopwords (based on a stopword list of 221
words) were filtered out.
In our first analysis we used the top most fre-
quent words that occurred at least 15 times, lead-
ing to a text matrix of approximately 20,000 doc-
uments and 19,000 word terms. We calculated the
cosine between Q and P for each of the omdat
and want sequences. A Welch Two Sample t-test
showed that contrary to expectation the cosine be-
tween Q and P was lower for omdat (0.039) than
for want (0.045; t(29518)=-4.78, p &lt;.001).
In a second analysis we chose a sample of a dif-
ferent scale and we used a text matrix of 100,000
documents and the top 10,000 most frequent word
terms. A t-test showed that in this case the cosine
for omdat sequences was slightly but significantly
higher than for want sequences (omdat: 0.048;
want: 0.043; t(30175)=3.68, p &lt;.001).
In the final section we will go into possible ex-
planations for these unexpected and incompatible
results.
</bodyText>
<sectionHeader confidence="0.998217" genericHeader="method">
4 N-gram overlap
</sectionHeader>
<bodyText confidence="0.999899714285714">
In our study of n-grams, we looked both at pure bi-
gram statistics and at n-grams in a broader scope,
i.e. n-grams and skip-grams with a maximal
length of 10 tokens. All n-grams have a minimum
length of 2, and a minimum frequency of 2 in the
datasample. We use lemmatized words to reduce
the influence of morphological information. For
the n-gram analysis we used the Colibri software
package developed by Maarten van Gompel1 (van
Gompel, 2014). In the left part of Table 2 we show
the bigram statistics and on the right side the n-
gram statistics of n-grams that occur at least twice
in Q, P, and those occurring in both Q and P. We
present the following counts:
</bodyText>
<listItem confidence="0.987397714285714">
• Pattern - The number of distinct n-gram pat-
terns (n-gram type count)
• Coverage - The number of unigram word to-
kens covered as a fraction of the total number
of unigram tokens.
• Occurrences - Cumulative occurrence count
of all the patterns (n-gram token count).
</listItem>
<bodyText confidence="0.999961740740741">
We can observe that about 75% of the tokens
in Q and P is covered in this bigram analysis,
while the n-grams cover around 93% of the words.
Zooming in on the bigrams and n-grams that are
shared in Q and P, we can see that these cover
about 50% and 75% of the tokens respectively.
This shows that we can safely discard n-grams that
occur only once in our counts and still cover most
tokens in the data sample.
Based on the bigram occurrences in our data
set, we computed whether the bigram overlap be-
tween Q and P in omdat sentences is larger than
in want sentences. We used a loglikelihood test
to compare the relative frequencies as our samples
do not have the same size. We found that 72362
bigram occurrences (or 67.8%) overlap in omdat
sentences and 58213 bigrams (or 79.4%) for want
sentences (LL2(1)=808.40, p &lt;.01). This means
that, contrary to our hypothesis, we found more
overlap for want sentences.
We performed the same computation on the
larger set of n-grams. We saw that 81573 of n-
gram occurrences (44.9%) overlap in omdat sen-
tences and 65272 (51.1%) overlap in for want sen-
tences (LL2(1)=595.37, p &lt;.01). This then is
again a confirmation that we find more overlap be-
tween Q and P in want sentences.
</bodyText>
<sectionHeader confidence="0.996838" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.8498695">
In this paper we report two types of automatic
analyses of the differences between want and om-
</bodyText>
<footnote confidence="0.998403">
1available at: http://proycon.github.io/colibri-core/
</footnote>
<page confidence="0.991668">
30
</page>
<table confidence="0.999754875">
Category Bigrams n-grams
Patterns Coverage Occurrences Patterns Coverage Occurrences
omdat Q 18931 0.7312 106766 39780 0.9320 181506
omdat P 20649 0.7549 118414 45074 0.9380 208809
omdat Q&amp;P 7261 0.5042 72362 9213 0.8927 81573
want Q 12938 0.7474 73276 27654 0.9350 127723
want P 17564 0.7216 94685 37027 0.9271 159125
want Q&amp;P 5774 0.4847 58213 7365 0.7943 65272
</table>
<tableCaption confidence="0.903559">
Table 2: Counts of the bigrams and n-grams up to length 10 with minimal frequency 2 in Q, P, and those
n-grams that occur in both Q and P. Patterns refers to n-gram types, Occurrences to n-gram tokens and
Coverage refers to word token coverage.
</tableCaption>
<bodyText confidence="0.999931253521127">
dat, which have been claimed to differ in subjec-
tivity, i.e. the degree to which the writer is felt
present in the text. One part of our study is a repro-
duction of (Bestgen et al., 2006) and assessed the
semantic relationship between Q and P in terms
of a LSA cosine for want and omdat. Contrary to
the findings of Bestgen et al., our first LSA analy-
sis showed that the relationship between Q and P
is less strong for omdat than for want. A second
analysis found a small difference in the expected
direction. In the second part of our study we used
n-gram overlap as a different type of similarity
measure. Again, our hypothesis was not borne out
in that omdat showed a significantly smaller de-
gree of overlap than want.
At this moment we cannot explain why the two
LSA experiments presented in section 3 show sig-
nificant results in different directions. In the two
experiments the same connective sentences were
used, but the semantic space in which they were
projected was different. For our LSA analysis
we made use of the software package LSA in R.
To rule out the possibility that our results were
due to some implementation peculiarity, we ran a
small test sample with another LSA implementa-
tion Gensim (ˇReh˚uˇrek and Sojka, 2010). Both im-
plementations gave us similar cosine values for the
same sample.
A noticeable difference with the Bestgen et al.
study is the size of the cosines: Bestgen et al. re-
port mean cosines of 0.120 and 0.137 for want
and omdat, respectively, whereas in our study we
found mean cosines of 0.045 and 0.039, respec-
tively. This suggests that our data sample and ex-
perimental setup differ substantially from the work
of Bestgen et al. and we did not succeed in re-
producing their experiment. In our analysis the
semantic relationship between Q and P is much
weaker.
In order to be able to interpret these results, we
added a baseline experiment. Here we ran an LSA
experiment with segments composed of random
words of the exact same size for the omdat and
want sentences. For omdat this gave us a mean co-
sine similarity of 0.007 and for want 0.006. This
implies that the cosines we found are significantly
higher than comparing random strings of words.
Note that the analysis was carried out on a suffi-
ciently large corpus and sufficient numbers of oc-
currences of want and omdat. Moreover, the result
that semantic relationship is stronger in want than
in omdat is corroborated by our n-gram analysis.
One possible explanation of the results of the n-
gram analysis is the syntactic difference between
want and omdat sentences. In want sentences the
word order of Q and P is the same while for om-
dat the verb-predicate order is swapped. The n-
grams will pick up this difference. As a next step
we plan to run the n-gram analysis with alphabeti-
cally ordered n-grams to exclude the effect of this
syntactic difference2.
Another line of future research is to make genre
comparisons. The availability of the SoNaR cor-
pus makes it possible to investigate the subjectiv-
ity hypothesis for different text genres.
Finally we intend to follow up our analysis
with a machine learning experiment to investigate
whether a learner could distinguish a want sen-
tence from a omdat sentence by looking at a local
context window of words to automatically predict
want or omdat.
</bodyText>
<footnote confidence="0.876161">
2We wish to thank one of our anonymous reviewers for
bringing this suggestion to our attention.
</footnote>
<page confidence="0.999824">
31
</page>
<sectionHeader confidence="0.995877" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99940652">
Yves Bestgen, Liesbeth Degand, and Wilbert Spooren.
2006. Toward automatic determination of the se-
mantics of connectives in large newspaper corpora.
Discourse Processes, 41(2):175–193.
Scott C. Deerwester, Susan T Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American Society for Information Science,
41(6):391–407.
Graeme Hirst and Olga Feiguina. 2007. Bigrams
of syntactic labels for authorship discrimination of
short texts. Literary and Linguistic Computing,
22(4):405–417.
Thomas K Landauer, Peter W Foltz, and Darrell La-
ham. 1998. An introduction to latent semantic anal-
ysis. Discourse processes, 25(2-3):259–284.
C.-Y. Lin and E.H. Hovy. 2003. Automatic evaluation
of summaries using n-gram co-occurrence statistics.
In Proceedings of the Human Language Technol-
ogy Conference of the North American Chapter of
the Association for Computational Linguistics (HLT-
NAACL), pages 71 – 78, Edmonton, Canada.
Max Louwerse, Nick Benesh, and Bin Zhang, 2008.
Directions in Empirical Literary Studies: In honor
of Willie van Peer, chapter Computationally discrim-
inating literary from non-literary texts, pages 175–
191. John Benjamins Publishing.
Nelleke Oostdijk, Martin Reynaert, V´eronique Hoste,
and Ineke Schuurman. 2013. The construction of a
500-million-word reference corpus of contemporary
written dutch. In Essential Speech and Language
Technology for Dutch, pages 219–247. Springer.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei
jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. pages 311–318.
R. Popping. 2000. Computer-assisted text analysis.
Sage, London.
Radim ˇReh˚uˇrek and Petr Sojka. 2010. Software
Framework for Topic Modelling with Large Cor-
pora. In Proceedings of the LREC 2010 Workshop
on New Challenges for NLP Frameworks, pages 45–
50, Valletta, Malta, May. ELRA.
T.J.M. Sanders and W.P.M.S. Spooren. 2013. Excep-
tions to rules: a qualitative analysis of backward
causal connectives in Dutch naturalistic discourse.
Text &amp; Talk, 33(3):399–420.
Maarten van Gompel, 2014. Colibri Documentation,
Colibri Core 0.1. Centre for Language Studies,
Radboud University Nijmegen, The Netherlands.
http://proycon.github.io/colibri-core/doc/.
</reference>
<page confidence="0.999288">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.915538">
<title confidence="0.999878">Studying the Semantic Context of two Dutch Causal Connectives</title>
<author confidence="0.986106">Hendrickx</author>
<affiliation confidence="0.999815">Centre for Language Studies, Radboud University</affiliation>
<address confidence="0.966723">P.O. Box 9103, NL-6500 HD Nijmegen The</address>
<email confidence="0.984261">i.hendrickx,w.spooren@let.ru.nl</email>
<abstract confidence="0.998713789473684">We aim to study the difference of usage between two causal connectives in their semantic context. We present an ongoing study of two Dutch backward causal Previous linguistic research has shown that causal conwith more subjective and often express an opinion. Our hypothesis is that the left and right context surrounding the connectives are more sesimilar in sentences with omsentences with To test this hypothesis we apply two techniques, Latent Semantic Analysis and n-gram overlap. We show that both methods indeed indicate a substantial difference between the two connectives but opposite to what we had expected.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yves Bestgen</author>
<author>Liesbeth Degand</author>
<author>Wilbert Spooren</author>
</authors>
<title>Toward automatic determination of the semantics of connectives in large newspaper corpora.</title>
<date>2006</date>
<booktitle>Discourse Processes,</booktitle>
<pages>41--2</pages>
<contexts>
<context position="3463" citStr="Bestgen et al. (2006)" startWordPosition="536" endWordPosition="540">plication would be sentiment analysis where the difference in subjectivity of various connectives can be used to identify subjective or opinionated sentences. Presently the corpus linguistic analyses of subjective versus objective causal relations have very much been a small-scale enterprise, in that corpus examples were annotated manually. This is problematic for at least two reasons: manual annotation relies on hand coding, with the accompanying problems of poor inter-annotator reliability, and the restricted size of the hand annotated corpora limits the power of statistical generalization. Bestgen et al. (2006) suggested to complement these manual analyses with automatic analyses. Bestgen and colleagues studied backward causal connections in Dutch. They made use of 28 Proceedings of the EACL 2014 Workshop on Computational Approaches to Causality in Language, pages 28–32, Gothenburg, Sweden, April 26, 2014. c�2014 Association for Computational Linguistics two types of automatic analyses: Latent Semantic Analysis (LSA) (Deerwester et al., 1990) and what they call Thematic Text Analysis (Popping, 2000) to show that the semantic connection between first and second segment is weaker in a want connection </context>
<context position="6617" citStr="Bestgen et al. (2006)" startWordPosition="1073" endWordPosition="1076">en P and Q to be smaller in omdat connections than in want connections. We also hypothesize that the number of n-grams shared between P and Q will be higher in omdat sentences than in want sentences. This paper presents work in progress. We first describe the SoNaR corpus that was used in this study in section 2. In section 3 we present the experimental setup and results of the experiments with LSA. In section 4 we detail our approach to computing n-grams and we discuss our findings and the next steps to take in 5. 2 Data Collection Unfortunately neither the corpus nor the data sample used by Bestgen et al. (2006) was available to us. For this reason we chose a similar Duch corpus to work with. The SoNaR corpus (Oostdijk et al., 2013) is a reference corpus of 500 million written words of contemporary Dutch sampled from a wide variety of sources and genres. The corpus has been automatically tokenized, part-of-speech tagged and lemmatized. We took a sample of 100K news articles from the SoNaR corpus as our experimental data set. As we are interested in semantic overlap, we took the lemmatized versions of the articles. From this data set, we collected all sentences containing the connectives omdat and wan</context>
<context position="13174" citStr="Bestgen et al., 2006" startWordPosition="2233" endWordPosition="2236">208809 omdat Q&amp;P 7261 0.5042 72362 9213 0.8927 81573 want Q 12938 0.7474 73276 27654 0.9350 127723 want P 17564 0.7216 94685 37027 0.9271 159125 want Q&amp;P 5774 0.4847 58213 7365 0.7943 65272 Table 2: Counts of the bigrams and n-grams up to length 10 with minimal frequency 2 in Q, P, and those n-grams that occur in both Q and P. Patterns refers to n-gram types, Occurrences to n-gram tokens and Coverage refers to word token coverage. dat, which have been claimed to differ in subjectivity, i.e. the degree to which the writer is felt present in the text. One part of our study is a reproduction of (Bestgen et al., 2006) and assessed the semantic relationship between Q and P in terms of a LSA cosine for want and omdat. Contrary to the findings of Bestgen et al., our first LSA analysis showed that the relationship between Q and P is less strong for omdat than for want. A second analysis found a small difference in the expected direction. In the second part of our study we used n-gram overlap as a different type of similarity measure. Again, our hypothesis was not borne out in that omdat showed a significantly smaller degree of overlap than want. At this moment we cannot explain why the two LSA experiments pres</context>
</contexts>
<marker>Bestgen, Degand, Spooren, 2006</marker>
<rawString>Yves Bestgen, Liesbeth Degand, and Wilbert Spooren. 2006. Toward automatic determination of the semantics of connectives in large newspaper corpora. Discourse Processes, 41(2):175–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="3903" citStr="Deerwester et al., 1990" startWordPosition="598" endWordPosition="601">e accompanying problems of poor inter-annotator reliability, and the restricted size of the hand annotated corpora limits the power of statistical generalization. Bestgen et al. (2006) suggested to complement these manual analyses with automatic analyses. Bestgen and colleagues studied backward causal connections in Dutch. They made use of 28 Proceedings of the EACL 2014 Workshop on Computational Approaches to Causality in Language, pages 28–32, Gothenburg, Sweden, April 26, 2014. c�2014 Association for Computational Linguistics two types of automatic analyses: Latent Semantic Analysis (LSA) (Deerwester et al., 1990) and what they call Thematic Text Analysis (Popping, 2000) to show that the semantic connection between first and second segment is weaker in a want connection than in a omdat connection, and that the first segment of want connections contains more subjective words than the first segment of omdat connections. The materials that were used by Bestgen et al. (2006) were texts from a large corpus of newspaper language of 16.5 million tokens. The purpose of our current ongoing research project is to extend the automatic analyses in two ways: on the one hand we want to reproduce the LSA analysis of </context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>Olga Feiguina</author>
</authors>
<title>Bigrams of syntactic labels for authorship discrimination of short texts.</title>
<date>2007</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>22--4</pages>
<contexts>
<context position="5471" citStr="Hirst and Feiguina, 2007" startWordPosition="869" endWordPosition="872">tasks like machine translation and automatic summarization. In these tasks automatic systems aim to produce a text as similar as possible to a manually constructed gold standard text. To evaluate the quality of these automatically produced text, measures such as BLUE (Papineni et al., 2002) and ROUGE (Lin and Hovy, 2003) measure n-gram overlap between the system text and the gold standard text. Furthermore, in other types of research like in the field of literary studies n-grams have been applied, for example to discriminate between genres (Louwerse et al., 2008) or for author discrimination (Hirst and Feiguina, 2007). Backward causal connectives denotes a cause relation. The connective is positioned in a sentence between the consequence (denoted as Q) and the cause (denoted as P). For the sentence in example 1 Q is the text segment before the connective, and P contains all words after the connective as follows: Q Dat is vooral jammer P de hoofdrolspeler uitstekend zingt. Our hypothesis is that Q and P are more semantically similar in sentences with omdat than sentences with want. This implies that we expect the average cosine between P and Q to be smaller in omdat connections than in want connections. We </context>
</contexts>
<marker>Hirst, Feiguina, 2007</marker>
<rawString>Graeme Hirst and Olga Feiguina. 2007. Bigrams of syntactic labels for authorship discrimination of short texts. Literary and Linguistic Computing, 22(4):405–417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Peter W Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>An introduction to latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse processes,</booktitle>
<pages>25--2</pages>
<contexts>
<context position="8682" citStr="Landauer et al., 1998" startWordPosition="1432" endWordPosition="1435">at and 14,449 sentences for want. Some statistics about the sentences is shown in Table 1. 3 LSA Latent Semantic Analysis (LSA) is a mathematical method for representing word meaning similarity in a semantic space based on a term-by-documents 29 Sentences length Q len P len omdat 18,260 24.3 11.2 12.1 want 14,449 23.5 9.6 12.9 Table 1: Number of sentences and average length in tokens of the full sentence, Q, and P in the data set of want and omdat. matrix. It applies singular value decomposition to this matrix to condense it to a smaller semantic representation of around 100 - 500 dimensions (Landauer et al., 1998). We applied LSA to measure the semantic overlap between Q and P of the omdat and want sentences. We constructed a term-by-document matrix based on the SoNaR news sample and converted this to an LSA space with 300 dimensions. Each Q and P was projected as a term vector in the LSA space and we computed the cosine similarity between each Q and P. To build the document-by-term matrix for LSA, words were lemmatized, and punctuation, digits and stopwords (based on a stopword list of 221 words) were filtered out. In our first analysis we used the top most frequent words that occurred at least 15 tim</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas K Landauer, Peter W Foltz, and Darrell Laham. 1998. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-Y Lin</author>
<author>E H Hovy</author>
</authors>
<title>Automatic evaluation of summaries using n-gram co-occurrence statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLTNAACL), pages 71 – 78,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="5168" citStr="Lin and Hovy, 2003" startWordPosition="820" endWordPosition="823">30 million tokens; on the other hand, we want to use n-gram analyses to investigate the semantic connection between the segments in a want versus omdat connection. The use of n-grams to measure semantic overlap is a well known method, which has been applied in the standard evaluation metrics for tasks like machine translation and automatic summarization. In these tasks automatic systems aim to produce a text as similar as possible to a manually constructed gold standard text. To evaluate the quality of these automatically produced text, measures such as BLUE (Papineni et al., 2002) and ROUGE (Lin and Hovy, 2003) measure n-gram overlap between the system text and the gold standard text. Furthermore, in other types of research like in the field of literary studies n-grams have been applied, for example to discriminate between genres (Louwerse et al., 2008) or for author discrimination (Hirst and Feiguina, 2007). Backward causal connectives denotes a cause relation. The connective is positioned in a sentence between the consequence (denoted as Q) and the cause (denoted as P). For the sentence in example 1 Q is the text segment before the connective, and P contains all words after the connective as follo</context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>C.-Y. Lin and E.H. Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLTNAACL), pages 71 – 78, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Louwerse</author>
<author>Nick Benesh</author>
<author>Bin Zhang</author>
</authors>
<title>Directions in Empirical Literary Studies: In honor of Willie van Peer, chapter Computationally discriminating literary from non-literary texts,</title>
<date>2008</date>
<pages>175--191</pages>
<publisher>John Benjamins Publishing.</publisher>
<contexts>
<context position="5415" citStr="Louwerse et al., 2008" startWordPosition="860" endWordPosition="863"> been applied in the standard evaluation metrics for tasks like machine translation and automatic summarization. In these tasks automatic systems aim to produce a text as similar as possible to a manually constructed gold standard text. To evaluate the quality of these automatically produced text, measures such as BLUE (Papineni et al., 2002) and ROUGE (Lin and Hovy, 2003) measure n-gram overlap between the system text and the gold standard text. Furthermore, in other types of research like in the field of literary studies n-grams have been applied, for example to discriminate between genres (Louwerse et al., 2008) or for author discrimination (Hirst and Feiguina, 2007). Backward causal connectives denotes a cause relation. The connective is positioned in a sentence between the consequence (denoted as Q) and the cause (denoted as P). For the sentence in example 1 Q is the text segment before the connective, and P contains all words after the connective as follows: Q Dat is vooral jammer P de hoofdrolspeler uitstekend zingt. Our hypothesis is that Q and P are more semantically similar in sentences with omdat than sentences with want. This implies that we expect the average cosine between P and Q to be sm</context>
</contexts>
<marker>Louwerse, Benesh, Zhang, 2008</marker>
<rawString>Max Louwerse, Nick Benesh, and Bin Zhang, 2008. Directions in Empirical Literary Studies: In honor of Willie van Peer, chapter Computationally discriminating literary from non-literary texts, pages 175– 191. John Benjamins Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nelleke Oostdijk</author>
<author>Martin Reynaert</author>
<author>V´eronique Hoste</author>
<author>Ineke Schuurman</author>
</authors>
<title>The construction of a 500-million-word reference corpus of contemporary written dutch.</title>
<date>2013</date>
<booktitle>In Essential Speech and Language Technology for Dutch,</booktitle>
<pages>219--247</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6740" citStr="Oostdijk et al., 2013" startWordPosition="1096" endWordPosition="1099">red between P and Q will be higher in omdat sentences than in want sentences. This paper presents work in progress. We first describe the SoNaR corpus that was used in this study in section 2. In section 3 we present the experimental setup and results of the experiments with LSA. In section 4 we detail our approach to computing n-grams and we discuss our findings and the next steps to take in 5. 2 Data Collection Unfortunately neither the corpus nor the data sample used by Bestgen et al. (2006) was available to us. For this reason we chose a similar Duch corpus to work with. The SoNaR corpus (Oostdijk et al., 2013) is a reference corpus of 500 million written words of contemporary Dutch sampled from a wide variety of sources and genres. The corpus has been automatically tokenized, part-of-speech tagged and lemmatized. We took a sample of 100K news articles from the SoNaR corpus as our experimental data set. As we are interested in semantic overlap, we took the lemmatized versions of the articles. From this data set, we collected all sentences containing the connectives omdat and want. As we aim to study the semantic relation between Q and P, we only selected sentences that have a meaningful Q and P in t</context>
</contexts>
<marker>Oostdijk, Reynaert, Hoste, Schuurman, 2013</marker>
<rawString>Nelleke Oostdijk, Martin Reynaert, V´eronique Hoste, and Ineke Schuurman. 2013. The construction of a 500-million-word reference corpus of contemporary written dutch. In Essential Speech and Language Technology for Dutch, pages 219–247. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei jing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<pages>311--318</pages>
<contexts>
<context position="5137" citStr="Papineni et al., 2002" startWordPosition="814" endWordPosition="817">l. using a larger corpus of about 30 million tokens; on the other hand, we want to use n-gram analyses to investigate the semantic connection between the segments in a want versus omdat connection. The use of n-grams to measure semantic overlap is a well known method, which has been applied in the standard evaluation metrics for tasks like machine translation and automatic summarization. In these tasks automatic systems aim to produce a text as similar as possible to a manually constructed gold standard text. To evaluate the quality of these automatically produced text, measures such as BLUE (Papineni et al., 2002) and ROUGE (Lin and Hovy, 2003) measure n-gram overlap between the system text and the gold standard text. Furthermore, in other types of research like in the field of literary studies n-grams have been applied, for example to discriminate between genres (Louwerse et al., 2008) or for author discrimination (Hirst and Feiguina, 2007). Backward causal connectives denotes a cause relation. The connective is positioned in a sentence between the consequence (denoted as Q) and the cause (denoted as P). For the sentence in example 1 Q is the text segment before the connective, and P contains all word</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Popping</author>
</authors>
<title>Computer-assisted text analysis.</title>
<date>2000</date>
<location>Sage, London.</location>
<contexts>
<context position="3961" citStr="Popping, 2000" startWordPosition="609" endWordPosition="610"> restricted size of the hand annotated corpora limits the power of statistical generalization. Bestgen et al. (2006) suggested to complement these manual analyses with automatic analyses. Bestgen and colleagues studied backward causal connections in Dutch. They made use of 28 Proceedings of the EACL 2014 Workshop on Computational Approaches to Causality in Language, pages 28–32, Gothenburg, Sweden, April 26, 2014. c�2014 Association for Computational Linguistics two types of automatic analyses: Latent Semantic Analysis (LSA) (Deerwester et al., 1990) and what they call Thematic Text Analysis (Popping, 2000) to show that the semantic connection between first and second segment is weaker in a want connection than in a omdat connection, and that the first segment of want connections contains more subjective words than the first segment of omdat connections. The materials that were used by Bestgen et al. (2006) were texts from a large corpus of newspaper language of 16.5 million tokens. The purpose of our current ongoing research project is to extend the automatic analyses in two ways: on the one hand we want to reproduce the LSA analysis of Bestgen et al. using a larger corpus of about 30 million t</context>
</contexts>
<marker>Popping, 2000</marker>
<rawString>R. Popping. 2000. Computer-assisted text analysis. Sage, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radim ˇReh˚uˇrek</author>
<author>Petr Sojka</author>
</authors>
<title>Software Framework for Topic Modelling with Large Corpora.</title>
<date>2010</date>
<booktitle>In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,</booktitle>
<pages>45--50</pages>
<publisher>ELRA.</publisher>
<location>Valletta, Malta,</location>
<marker>ˇReh˚uˇrek, Sojka, 2010</marker>
<rawString>Radim ˇReh˚uˇrek and Petr Sojka. 2010. Software Framework for Topic Modelling with Large Corpora. In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pages 45– 50, Valletta, Malta, May. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T J M Sanders</author>
<author>W P M S Spooren</author>
</authors>
<title>Exceptions to rules: a qualitative analysis of backward causal connectives in Dutch naturalistic discourse.</title>
<date>2013</date>
<journal>Text &amp; Talk,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="1138" citStr="Sanders and Spooren, 2013" startWordPosition="178" endWordPosition="181">e subjective and often express an opinion. Our hypothesis is that the left and right context surrounding the connectives are more semantically similar in sentences with omdat than sentences with want. To test this hypothesis we apply two techniques, Latent Semantic Analysis and n-gram overlap. We show that both methods indeed indicate a substantial difference between the two connectives but opposite to what we had expected. 1 Introduction Much corpus linguistic research has dealt with the issue of subjectivity, i.e. the degree to which the presence of the writer or speaker of a text is felt ((Sanders and Spooren, 2013), and the references cited there). Subjectivity can be located at different levels in a text. At the word level, some words (e.g., evaluative adjectives and expletives) imply a writer/speaker evaluation, whereas others do not. At the sentence level, the description of facts is felt to be more objective, whereas opinions are more subjective. And at the supra-sentential level, subjectivity can get expressed in the type of relation that links the clauses or sentences. For example, argumentative relations are more subjective than statements. Interestingly, many languages make a distinction between</context>
</contexts>
<marker>Sanders, Spooren, 2013</marker>
<rawString>T.J.M. Sanders and W.P.M.S. Spooren. 2013. Exceptions to rules: a qualitative analysis of backward causal connectives in Dutch naturalistic discourse. Text &amp; Talk, 33(3):399–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maarten van Gompel</author>
</authors>
<date>2014</date>
<journal>Colibri Documentation, Colibri Core</journal>
<volume>0</volume>
<institution>Centre for Language Studies, Radboud University Nijmegen, The Netherlands.</institution>
<note>http://proycon.github.io/colibri-core/doc/.</note>
<marker>van Gompel, 2014</marker>
<rawString>Maarten van Gompel, 2014. Colibri Documentation, Colibri Core 0.1. Centre for Language Studies, Radboud University Nijmegen, The Netherlands. http://proycon.github.io/colibri-core/doc/.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>