<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003068">
<title confidence="0.867835">
Bilingual Markov Reordering Labels for Hierarchical SMT
</title>
<author confidence="0.986402">
Gideon Maillette de Buy Wenniger and Khalil Sima’an
</author>
<affiliation confidence="0.995896">
Institute for Logic, Language and Computation
University of Amsterdam
</affiliation>
<address confidence="0.6354265">
Science Park 107, 1098 XG Amsterdam, The Netherlands
gemdbw AT gmail.com, k.simaan AT uva.nl
</address>
<sectionHeader confidence="0.976435" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999822125">
Earlier work on labeling Hiero grammars
with monolingual syntax reports improved
performance, suggesting that such label-
ing may impact phrase reordering as well
as lexical selection. In this paper we ex-
plore the idea of inducing bilingual labels
for Hiero grammars without using any
additional resources other than original
Hiero itself does. Our bilingual labels
aim at capturing salient patterns of phrase
reordering in the training parallel corpus.
These bilingual labels originate from hier-
archical factorizations of the word align-
ments in Hiero’s own training data. In this
paper we take a Markovian view on syn-
chronous top-down derivations over these
factorizations which allows us to extract
0th- and 1st-order bilingual reordering la-
bels. Using exactly the same training
data as Hiero we show that the Marko-
vian interpretation of word alignment fac-
torization offers major benefits over the
unlabeled version. We report extensive
experiments with strict and soft bilingual
labeled Hiero showing improved perfor-
mance up to 1 BLEU points for Chinese-
English and about 0.1 BLEU points for
German-English.
Phrase reordering in Hiero (Chiang, 2007) is mod-
elled with synchronous rules consisting of phrase
pairs with at most two nonterminal gaps, thereby
embedding ITG permutations (Wu, 1997) in lexi-
cal context. It is by now recognized that Hiero’s
reordering can be strengthened either by labeling
(e.g., (Zollmann and Venugopal, 2006)) or by sup-
plementing the grammar with extra-grammatical
reordering models, e.g., (Xiao et al., 2011; Huck
et al., 2013; Nguyen and Vogel, 2013). In this
paper we concentrate on labeling approaches.
Conceptually, labeling Hiero rules aims at in-
troducing preference in the SCFG derivations for
frequently occurring lexicalized ordering constel-
lations over rare ones which also affects lexical se-
lection. In this paper, we present an approach for
distilling phrase reordering labels directly from
alignments (hence bilingual labels).
To extract bilingual labels from word
alignments we must first interpret the alignments
as a hierarchy of phrases. Luckily, every
word alignment factorizes into Normalized
Decomposition Trees (NDTs) (Zhang et al.,
2008), showing explicitly how the word alignment
recursively decomposes into phrase pairs. Zhang
et al. (2008) employ NDTs for extracting Hiero
grammars. In this work, we extend NDTs
with explicit phrase permutation operators also
extracted from the original word alignment
(Sima’an and Maillette de Buy Wenniger, 2013);
Every node in the NDT is equipped with a
node operator that specifies how the order of
the target phrases (children of this node) is
produced from the corresponding source phrases.
Subsequently, we cluster the node operators
in these enriched NDTs according to their
complexity, e.g., monotone (straight), inverted,
non-binary but one-to-one, and the more complex
case of discontinuous (Maillette de Buy Wenniger
and Sima’an, 2013).
Inspired by work on parsing (Klein and Man-
ning, 2003), we explore a vertical Markovian
labeling approach: intuitively, 0th-order labels
signify the reordering of the sub-phrases inside the
phrase pair (Zhang et al., 2008), 1st-order labels
signify reordering aspects of the direct context
(an embedding, parent phrase pair) of the phrase
pair, and so on. Like the phrase orientation
models this labeling approach does not employ
external resources (e.g., taggers, parsers) beyond
the training data used by Hiero.
We empirically explore this bucketing for 0th-
</bodyText>
<page confidence="0.992371">
11
</page>
<note confidence="0.7811765">
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 11–21,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999655666666667">
and 1st-order labels both as hard and soft labels.
In experiments on German-English and Chinese-
English we show that this extension of Hiero of-
ten significantly outperforms the unlabeled model
while using no external data or monolingual la-
beling mechanisms. This suggests the viability
of automatically inducing bilingual labels follow-
ing the Markov labeling approach on operator-
labelled NDTs as proposed in this paper.
</bodyText>
<sectionHeader confidence="0.805996" genericHeader="method">
1 Hierarchical models and related work
</sectionHeader>
<bodyText confidence="0.99322175">
Hiero SCFGs (Chiang, 2005; Chiang, 2007) allow
only up to two (pairs of) nonterminals on the right-
hand-side (RHS) of synchronous rules. The types
of permissible Hiero rules are:
</bodyText>
<equation confidence="0.999915">
X → hα, γi (1)
X → hα X1 β, δ X1 ζi (2)
X → hα X1 β X2 γ , δ X1 ζ X2 η i (3)
X → hα X1 β X2 γ , δ X2 ζ X1 η i (4)
</equation>
<bodyText confidence="0.996307352941177">
Here α,β, γ, δ, ζ, η are terminal sequences, possi-
bly empty. Equation 1 corresponds to a normal
phrase pair, 2 to a rule with one gap and 3 and 4
to the monotone- and inverting rules respectively.
Given an Hiero SCFG G, a source sentence s is
translated into a target sentence t by synchronous
derivations d, each is a finite sequence of well-
formed substitutions of synchronous productions
from G, see (Chiang, 2006). Existing phrase-
based models score a derivation der with linear
interpolation of a finite set of feature functions
((D(d)) of the derivation d, mostly working with
local feature functions φi of individual produc-
tions, the target side yield string t of d (target
language model features) and other features (see
experimental section): arg maxd∈G P(t, d  |s) ≈
arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are
</bodyText>
<equation confidence="0.850077">
i_1 �i• P [Ail
</equation>
<bodyText confidence="0.99836293220339">
optimized on a held-out parallel corpus by direct
error-minimization (Och, 2003).
A range of (distantly) related work exploits
syntax for Hiero models, e.g. (Liu et al., 2006;
Huang et al., 2006; Mi et al., 2008; Mi and
Huang, 2008; Zollmann and Venugopal, 2006;
Wu and Hkust, 1998). In terms of labeling
Hiero rules, SAMT (Zollmann and Venugopal,
2006; Mylonakis and Sima’an, 2011) exploits a
“softer notion” of syntax by fitting the CCG-like
syntactic labels to non-constituent phrases. The
work of (Xiao et al., 2011) adds a lexicalized
orientation model to Hiero, akin to (Tillmann,
2004) and achieves significant gains. The work
of (Huck et al., 2013; Nguyen and Vogel, 2013)
overcomes technical limitations of (Xiao et al.,
2011), making necessary changes to the decoder,
which involves delayed (re-)scoring at hypernodes
up in the derivation of nodes lower in the chart
whose orientations are affected by them. This
goes to show that phrase-orientation models are
not mere labelings of Hiero.
Soft syntactic constraints has been around for
some time now (Zhou et al., 2008; Venugopal et
al., 2009; Chiang, 2010). In (Zhou et al., 2008)
Hiero is reinforced with a linguistically motivated
prior. This prior is based on the level of syntactic
homogeneity between pairs of non-terminals
and the associated syntactic forests rooted at
these nonterminals, whereby tree-kernels are
applied to efficiently measure the amount of
overlap between all pairs of sub-trees induced
by the pairs of syntactic forests. Crucially, the
syntactic prior encourages derivations that are
more syntactically coherent but does not block
derivations when they are not. In (Venugopal
et al., 2009) the authors associate distributions
over compatible syntactic labelings with grammar
rules, and combine these preference distributions
during decoding, thus achieving a summation
rather than competition between compatible label
configurations. The latter approach requires
significant changes to the decoder and comes at a
considerable computational cost. An alternative
approach (Chiang, 2010) uses labels similar to
(Zollmann and Venugopal, 2006) together with
boolean features for rule-label and substituted-
label combinations; using discriminative training
(MIRA) it is learned what combinations are
associated with better translations.
The labeling approach presented next differs
from existing approaches. It is inspired by soft
labeling but employs novel, non-linguistic bilin-
gual labels. And it shares the bilingual intuition
with phrase orientation models but it is based on
a Markov approach for SCFG labeling, thereby
remaining within the confines of Hiero SCFG,
avoiding the need to make changes inside the
decoder.1
</bodyText>
<footnote confidence="0.9984036">
1Soft constraint decoding can easily be implemented
without adapting the decoder, through a smart application of
“label bridging” unary rules. In practice however, adapting
the decoder turns out to be computationally more efficient,
therefore we used this solution in our experiments.
</footnote>
<page confidence="0.995252">
12
</page>
<figure confidence="0.995517666666667">
1
6
3
7
5
2
S 0
accordingly
po
</figure>
<page confidence="0.995964">
14
</page>
<bodyText confidence="0.99994225">
is labeled “right-binding inverted” (R.B.I.); E.F.D.
and L.B.M. are similar abbreviations for “embed-
ded fully discontinuous” and “left-binding mono-
tone” respectively. As yet another example node
7 in Figure 3 is labeled “left-binding monotone”
(L.B.M.) since it is monotone, but the alignment
allows it only to bind to the left at the parent node,
as opposed to only to the right or to both sides
which cases would have yielded “right-binding
monotone” R.B.M. and “(embedded) fully mono-
tone” (E.F.M.) parent-relative reordering labels
respectively.
Note that for parent-relative labels the binding
direction of monotone and inverted may not be
informative. We therefore also form a set of
coarse parent-relative labels (“1stCoarse”) by col-
lapsing the label pairs Left/Right-Binding-Mono
and Left/Right-Binding-Inverted into single labels
One-Side-Binding-Mono and One-Side-Binding-
Inv3.
</bodyText>
<sectionHeader confidence="0.999715" genericHeader="method">
3 Features for soft bilingual labeling
</sectionHeader>
<bodyText confidence="0.948144516666667">
Labels used in hierarchical Statistical Machine
Translation (SMT) are typically adapted from ex-
ternal resources such as taggers and parsers. Like
in our case, these labels are typically not fitted to
the training data – with very few exceptions e.g.,
(Mylonakis and Sima’an, 2011; Mylonakis, 2012;
Hanneman and Lavie, 2013). Unfortunately this
means that the labels will either overfit or underfit,
and when they are used as strict constraints on
SCFG derivations they are likely to underperform.
Experience with mismatch between syntactic la-
bels and the data is abundant (Venugopal et al.,
2009; Marton et al., 2012; Chiang, 2010), and
using soft constraint decoding with suitable label
substitution features has been shown to be an
effective workaround solution. The intuition be-
hind soft constraint decoding is that even though
heuristic labels are not perfectly tailored to the
data, they do provide useful information provided
the model is “allowed to learn” to use them only
in as far as they can improve the final evaluation
metric (usually BLEU).
3We could also further coarsen the 1stlabels by
removing entirely all sub-distinctions of binding-type for
the binarizable cases, but that would make the labeling
essentially equal to the earlier mentioned 0thITG+ except for
looking at the reordering occurring at the parent rather than
inside the phrase itself. We did not explore this variant in this
work, as the high similarity to the already explored 0thITG+
variant made it not seem to add much extra information.
Figure 5: Label substitution features, schematic
view. Labels/Gaps with same filling in the figures
correspond to the situation of a nonterminal/gap
whose labels correspond (for N1/GAP1). Fillings
of different shades (as for N2/GAP2 on the right
in the two figures) indicates the situation were the
label of the nonterminal and the gap is different.
Next we introduce the set of label substitution
features used in our experiments.
Label substitution features consist of a unique
feature for every pair of labels (Lα, Lp) in the
grammar, signifying a rule with left-hand-side
label Lp substituting on a gap labeled Lα. These
features are combined with two more coarse
features, “Match” and “Nomatch”, indicating if
the substitution involves labels that match or not.
Figure 5 illustrates the concept of label substi-
tution features schematically. In this figure the
substituting rule is substituted onto two gaps in
the chart, which induces two label substitution
features indicated by the two ellipses. The sit-
uation is analogous for rules with just one gap.
To make things concrete, lets assume that both
the first nonterminal of the rule N1 as well as
the first gap it is substituted onto GAP1 have
label MONO. Furthermore lets assume the second
nonterminal N2 has label COMPLEX while the
label of the gap GAP2 it substitutes onto is INV.
This situation results in the following two specific
label substitution features:
</bodyText>
<listItem confidence="0.999743">
• subst(MONO,MONO)
• subst(INV,COMPLEX)
</listItem>
<bodyText confidence="0.992072142857143">
Canonical labeled rules. Typically when la-
beling Hiero rules there can be many different
labeled variants of every original Hiero rule. With
soft constraint decoding this leads to prohibitive
computational cost. This also has the effect of
making tuning the features more difficult. In
practice, soft constraint decoding usually exploits
</bodyText>
<figure confidence="0.987831888888889">
α
Decoder chart
Substituting rule
GAP1 11 GAP2 12
p
N1 11 N2 12
Label Substitution Features
LHS 10
Y
</figure>
<page confidence="0.906989">
15
</page>
<table confidence="0.999000666666667">
Systen Name Matching Type Label Order Label Granularity
Hiero-0thITG+ Strict 0th order Coarse
Hiero-0th Strict 0th order Fine
Hiero-1stCoarse Strict 1th order Coarse
Hiero-1st Strict 1th order Fine
Hiero-0thITG+-Sft Soft 0th order Coarse
Hiero-0th-Sft Soft 0th order Fine
Hiero-1stCoarse-Sft Soft 1th order Coarse
Hiero-1st-Sft Soft 1th order Fine
</table>
<tableCaption confidence="0.993135">
Table 1: Experiment names legend
</tableCaption>
<table confidence="0.999835133333333">
System Name DEV TEST
BLEU T METEOR T TER I KRS T BLEU T METEOR T TER I KRS T
German-English
Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44
SAMT 27.76 32.67 58.05 66.84&apos; 28.32 32.88 57.70&apos; &apos; 67.63
Hiero-0thITG+ 27.85 32.70 58.04&apos; &apos; 66.27 28.36 32.90&apos; 57.83&apos; &apos; 67.30
Hiero-0th 27.82 32.75 57.92&apos; &apos; 66.66 28.39 33.03&apos; &apos; 57.75&apos; &apos; 67.55
Hiero-1stCoarse 27.86 32.66 58.23 66.37 28.22&apos; 32.90 57.93 67.47
Hiero-1st 27.74&apos; 32.60&apos; &apos; 58.11 66.44 28.27 32.80&apos; &apos; 57.95 67.39
Chinese-English
Hiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03
Hiero-0thITG+ 31.54 30.97&apos; &apos; 62.79&apos; &apos; 59.54&apos;&apos; 31.94&apos; &apos; 30.84&apos; &apos; 60.76&apos; &apos; 59.45&apos; &apos;
Hiero-0th 31.66 30.95&apos; &apos; 62.20&apos; &apos; 60.00&apos;&apos; 31.90&apos; &apos; 30.79&apos; &apos; 60.11&apos; &apos; 59.68&apos; &apos;
Hiero-1stCoarse 31.64 30.75 61.37 59.48&apos;&apos; 31.57 30.57 59.58&apos; &apos; 59.13&apos; &apos;
Hiero-1st 31.74 30.79 61.94&apos; &apos; 60.22&apos;&apos; 31.77 30.62 60.13&apos; &apos; 59.89&apos; &apos;
</table>
<tableCaption confidence="0.998267">
Table 2: Mean results bilingual labels with strict matching.4
</tableCaption>
<bodyText confidence="0.9904015">
a single labeled version per Hiero rule, which
we call the “canonical labeled rule”. Following
(Chiang, 2010), this canonical form is the most
frequent labeled variant.
</bodyText>
<sectionHeader confidence="0.999673" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.983664625">
We evaluate our method on two language pairs:
using German/Chinese as source and English as
target. In all experiments we decode with a
4-gram language model smoothed with modified
Knesser-Ney discounting (Chen and Goodman,
1998). The data used for training the language
models differs per language pair, details are given
in the next paragraphs. All data is lowercased as
a last pre-processing step. In all experiments we
use our own grammar extractor for the generation
of all grammars, including the baseline Hiero
grammars. This enables us to use the same
features (as far as applicable given the grammar
formalism) and assure true comparability of the
grammars under comparison.
German-English
</bodyText>
<footnote confidence="0.881731666666667">
4Statistical significance is dependent on variance of
resampled scores, and hence sometimes different for same
mean scores across different systems.
</footnote>
<bodyText confidence="0.999897142857143">
The data for our German-English experiments
is derived from parliament proceedings sourced
from the Europarl corpus (Koehn, 2005), with
WMT-07 development and test data. We used a
maximum sentence length of 40 for filtering the
training data. We employ 1M sentence pairs for
training, 1K for development and 2K for test-
ing (single reference per source sentence). Both
source and target of all datasets are tokenized
using the Moses(Hoang et al., 2007) tokenization
script. For these experiments both the baseline
and our method use a language model trained
on the target side of the full original training set
(approximately 1M sentences).
</bodyText>
<subsectionHeader confidence="0.474381">
Chinese-English
</subsectionHeader>
<bodyText confidence="0.997856571428571">
The data for our Chinese-English experiments is
derived from a combination of MultiUn(Eisele
and Chen, 2010; Tiedemann, 2012)5 data and
Hong Kong Parallel Text data from the Linguistic
Data Consortium6. The Hong Kong Parallel Text
data is in traditional Chinese and is thus first
converted to simplified Chinese to be compatible
</bodyText>
<footnote confidence="0.999881666666667">
5Freely available and downloaded from
http://opus.lingfil.uu.se/
6The LDC catalog number of this dataset is LDC2004T08
</footnote>
<page confidence="0.982409">
16
</page>
<table confidence="0.999924">
System Name DEV TEST
BLEU T METEOR T TER 1 KRS T BLEU T METEOR T TER 1 KRS T
German-English
Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44
SAMT 27.76 32.67 58.05 66.84• 28.32 32.88 57.70•• 67.63
Hiero-0thITG+-Sft 28.00• 32.76•• 57.90•• 66.17 28.48 32.98 57.79•• 67.32
Hiero-0th-Sft 28.01• 32.71 57.95•• 66.24 28.45 32.98 57.73•• 67.51
Hiero-1stCoarse-Sft 27.94 32.69 57.91•• 66.26 28.45• 32.94 57.75•• 67.36
Hiero-1st-Sft 28.13•• 32.80•• 57.92•• 66.32 28.45 33.00• 57.79•• 67.45
Chinese-English
Hiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03
Hiero-0thITG+-Sft 31.88• 30.46•• 60.64•• 57.82• 31.93•• 30.37•• 58.86•• 57.60•
Hiero-0th-Sft 32.04•• 30.90•• 61.47•• 59.36•• 32.20•• 30.74•• 59.45• 58.92••
Hiero-1stCoarse-Sft 32.39•• 31.02•• 61.56•• 59.51•• 32.55•• 30.86•• 59.57•• 59.03••
Hiero-1st-Sft 32.63•• 31.22•• 62.00•• 60.43•• 32.61•• 30.98•• 60.19•• 59.84••
</table>
<tableCaption confidence="0.999745">
Table 3: Mean results bilingual labels with soft matching.4
</tableCaption>
<bodyText confidence="0.999837875">
with the rest of the data 7. We used a maximum
sentence length of 40 for filtering the training
data. The combined dataset has 7.34M sentence
pairs. The MulitUN dataset contains translated
documents from the United Nations, similar in
genre to the parliament domain. The Hong Kong
Parallel Text in contrast contains a richer mix
of domains, namely Hansards, Laws and News.
For the dev and test set we use the Multiple-
Translation Chinese datasets from LDC, part 1-48,
which contain sentences from the News domain.
We combined part 2 and 3 to form the dev set
(1813 sentence pairs) and part 1 and 4 to form the
test set (1912 sentence pairs). For both develop-
ment and testing we use 4 references. The Chinese
source side of all datasets is segmented using the
Stanford Segmenter(Chang et al., 2008)9. The
English target side of all datasets is tokenized
using the Moses tokenization script.
For these experiments both the baseline and
our method use a language model trained on
5.4M sentences of domain specific10 news data
taken from the “Xinhua” subcorpus of the English
Gigaword corpus of LDC. 11
</bodyText>
<footnote confidence="0.999413307692308">
7Using a simple conversion script downloaded from
http://www.mandarintools.com/zhcode.html
8LDC catalog numbers: LDC2002T01, DC2003T17,
LDC2004T07 and LDC2004T07
9Downloaded from
http://nlp.stanford.edu/software/segmenter.shtml
10For Chinese-English translation the different domain of
the train data (mainly parliament) and dev/test data (news)
requires usage of a domain specific language model to get
optimal results. For German-English, all data is from the
the parliament domain, so a language model trained on the
(translation model) training data is already domain-specific.
11The LDC catalog number of this dataset is LDC2003T05
</footnote>
<subsectionHeader confidence="0.991424">
4.1 Experimental Structure
</subsectionHeader>
<bodyText confidence="0.998552666666667">
In our experiments we explore the influence of
three dimensions of bilingual reordering labels on
translation accuracy. These dimensions are:
</bodyText>
<listItem confidence="0.987672333333333">
• label granularity: granularity of the labeling
{Coarse,Fine}
• label order : the type/order of the labeling
{0th, 1st}
• matching type : the type of label matching
performed during decoding {Strict,Soft}
</listItem>
<bodyText confidence="0.999869739130435">
Combining these dimensions gives 8 different
reordering labeled systems per language pair.
On top of that we use two baseline systems,
namely Hiero and Syntax Augmented Machine
Translation (SAMT) to measure these systems
against. An overview of the naming of our
reordering labeled systems is given in Table 1.
Training and decoding details Our experiments
use Joshua (Ganitkevitch et al., 2012) with Viterbi
best derivation. Baseline experiments use nor-
mal decoding whereas soft labeling experiments
use soft constraint decoding. For training we
use standard Hiero grammar extraction constraints
(Chiang, 2007) (phrase pairs with source spans
up to 10 words; abstract rules are forbidden).
During decoding maximum span 10 on the source
side is maintained. Following common practice,
we use relative frequency estimates for phrase
probabilities, lexical probabilities and generative
rule probability.
We train our systems using (batch-kbest) Mira
as borrowed by Joshua from the Moses codebase,
allowing up to 30 tuning iterations. Following
</bodyText>
<page confidence="0.997918">
17
</page>
<bodyText confidence="0.996010022222222">
standard practice, we tune on BLEU, and after
tuning we use the configuration with the highest
scores on the dev set with actual (corpus level)
BLEU evaluation. We report lowercase BLEU
(Papineni et al., 2002), METEOR (Denkowski
and Lavie, 2011) and TER (Snover et al., 2006)
scores for the tuned test set and also for the tuned
dev set, the latter mainly to observe any possible
overfitting. We use Multeval version 0.5.1.12 for
computing these metrics. We also use MultEval’s
implementation of statistical significance testing
between systems, which is based on multiple
optimizer runs and approximate randomization.
Multeval (Clark et al., 2011) randomly swaps
outputs between systems and estimates the prob-
ability that the observed score difference arose by
chance. Differences that are statistically signif-
icant and correspond to improvement/worsening
with respect to the baseline are marked with N/Hat
the p &lt;_ .05 level and NN/HHat the p &lt;_ .01 level. We
also report the Kendall Reordering Score (KRS),
which is the reordering-only variant of the LR-
score (Birch and Osborne, 2010) (without the
optional interpolation with BLEU) and which is
a sentence-level score. For the computation of
statistical significance of this metric we use our
own implementation of the sign test 13 (Dixon and
Mood, 1946), as also described in (Koehn, 2010).
In our experiments we repeated each experi-
ment three times to counter unreliable conclusions
due to optimizer variance. Scores are averages
over three runs of tuning plus testing. Scores
marked with N are significantly better than the
baseline, those marked with H are significantly
worse; according to the resampling test of Mul-
teval (Clark et al., 2011).
Preliminary experiment with strict matching
Initial experiments concerned 0th-order reorder-
ing labels in a strict matching approach (no soft
constraints). The results are shown in Table 2 for
both language pairs. The results for the Hiero and
SAMT14 baselines (Hiero and SAMT) are shown
in the first rows. Below it results for the 0th-order
(phrase-centric) bilingual labeled systems with
either the Coarse (Hiero-0thITG+) or Fine label
</bodyText>
<footnote confidence="0.993105428571429">
12https://github.com/jhclark/multeval
13To make optimal usage of the 3 runs we computed
equally weighted improvement/worsening counts for all
possible 3 × 3 baseline output / system output pairs and use
those weighted counts in the sign test.
14SAMT could only be ran for German-English and not
for Chinese-English, due to memory constraints.
</footnote>
<bodyText confidence="0.9758859">
variant (Hiero-0th) are shown, followed by the
results for Coarse and Fine variant of the 1th-order
(parent-relative) bilingual labeled systems (Hiero-
1stCoarse and Hiero-1st). All these systems use the
default decoding with strict label matching.
For German-English the effect of strict bilin-
gual labels is mostly positive: although we have
no improvement for BLEU we do achieve sig-
nificant improvements for METEOR and TER
on the test set. For Chinese-English, overall
Hiero-0thITG+ shows the biggest improvements,
namely significant improvements of +0.31 BLEU,
+0.28 METEOR and +1.42 KRS. TER is the
only metric that worsens, and considerably so
with +1.48 point. Hiero-1stachieves the highest
improvement of KRS, namely 1.86 point higher
than the Hiero baseline. Overall, this preliminary
experiment shows that strict labeling sometimes
gives improvements over Hiero, but sometimes it
leads to worsening in terms of some of the metrics.
Results with soft bilingual constraints Our ini-
tial experiments with strict bilingual labels in
combination with strict matching by the decoder
gave some hope such constraints could be useful.
At the same time the results showed no stable
improvements across language pairs, and thus
does not allow us to draw definite conclusions
about the merit of bilingual labels.
Results for experiments with soft bilingual la-
beling are shown in Table 3. Here Hiero corre-
sponds to the Hiero baseline. Below it are shown
the systems that use soft constraint decoding (
SCD). Hiero-0thITG+-Sft and Hiero-0th-Sft using
phrase-centric labels (0th-order) in Coarse or Fine
form. Similarly, Hiero-1stCoarse-Sft and Hiero-
1st-Sft correspond to the analog systems with
1st-order, parent-relative labels. For German-
English there are only minor improvements for
BLEU and METEOR, with somewhat bigger im-
provements for TER. For Chinese-English how-
ever the improvements are considerable, +0.98
BLEU improvement over the Hiero baseline for
Hiero-1st-Sft as well as +0.42 METEOR and
+1.81 KRS. TER is worsening with +0.85 for this
system. For Chinese-English the Fine version of
the labels gives overall superior results for both
0th-order and 1st-order labels.
Discussion Our best soft bilingual labeling system
for German-English shows small but significant
improvements of METEOR and TER while im-
</bodyText>
<page confidence="0.997974">
18
</page>
<bodyText confidence="0.999977117647059">
proving BLEU and KRS as well, but not signifi-
cantly. The results with soft-constraint matching
are better than those for strict-matching in general,
while there is no clear winner between the Coarse
and Fine variant of labels.
For Chinese-English we see considerable
improvements and overall the best results for
the combination of soft-constraint matching,
with the Fine 1st-order variant of the labeled
systems (Hiero-1st-Sft). For Chinese-English the
improvement of the word-order is also particularly
clear as indicated by the +1.81 KRS improvement
for this best system. Furthermore the negative
effects in terms of worsening of TER are also
reduced in the soft-matching setting, dropping
from +1.48 TER to +0.85 TER. The results for
Hiero-0th-Sft are also competitive, since though
it gives somewhat lower improvements of BLEU
and METEOR, it gives an improvement of +1.89
KRS, while TER only worsens by +0.17 for this
system.
We conclude that bilingual Markov labels can
make a big difference in improvement of hier-
archical SMT. We observe that going beyond
the basic reordering labels of ITG, refining the
cases not captured by ITG and even more ef-
fective: taking a 1st-order rather than oth-order
perspective on reordering are major factors for
the success of including reordering information to
hierarchical SMT through labeling. Crucial to the
success of this undertaking is also the usage of
a soft-constraint approach to label matching, as
opposed to strict-matching. Finally, comparison
of the German-English results with results for
Syntax-Augmented Machine Translation (SAMT)
reveals that SAMT loses performance compared
to the Hiero baseline for BLEU, the metric upon
which tuning is done, as well as METEOR, while
only TER and KRS show improvement. Since
the best bilingual labeled system for German-
English (Hiero-1st-Sft) improves METEOR and
TER significantly, while also improving BLEU
and KRS, though not significant, we believe our
labeling is highly competitive with syntax-based
labeling approaches, without the need for any
additional resources in the form of parsers or
taggers, as syntax-based systems require. Likely
complementarity of reordering information, and
(target) syntax, which improves fluency, makes
combining both a promising possibility we would
like to explore in future work.
</bodyText>
<sectionHeader confidence="0.993936" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999993609756098">
We presented a novel method to enrich Hierarchi-
cal Statistical Machine Translation with bilingual
labels that help to improve the translation quality.
Considerable and significant improvements of the
BLEU, METEOR and KRS are achieved simul-
taneously for Chinese-English translation while
tuning on BLEU, where the Kendall Reordering
Score is specifically designed to measure im-
provement of reordering in isolation. For German-
English more modest, statistically significant im-
provements of METEOR and TER (simultane-
ously) or BLEU (separately) are achieved. Our
work differs from related approaches that use
syntactic or part-of-speech information in the for-
mation of reordering constraints in that it needs no
such additional information. It also differs from
related work on reordering constraints based on
lexicalization in that it uses no such lexicaliza-
tion but instead strives to achieve more globally
coherent translations, afforded by global, holistic
constraints that take the local reordering history
of the derivation directly into account. Our exper-
iments also once again reinforce the established
wisdom that soft, rather than strict constraints,
are a necessity when aiming to include new in-
formation to an already strong system without the
risk of effectively worsening performance through
constraints that have not been directly tailored
to the data through a proper learning approach.
While lexicalized constraints on reordering have
proven to have great potential, un-lexicalized soft
bilingual constraints, which are more general and
transcend the rule level have their own place in
providing another agenda of improving transla-
tion which focusses more on the global coher-
ence direction by directly putting soft alignment-
informed constraints on the combination of rules.
Finally, while more research is necessary in this
direction, there are strong reasons to believe that
in the right setup these different approaches can be
made to further reinforce each other.
</bodyText>
<sectionHeader confidence="0.997751" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999565833333333">
This work is supported by The Netherlands Or-
ganization for Scientific Research (NWO) under
grant nr. 612.066.929. The authors would like to
thank Matt Post and Juri Ganitkevitch, for their
support with respect to the integration of Fuzzy
Matching Decoding into the Joshua codebase.
</bodyText>
<page confidence="0.998946">
19
</page>
<sectionHeader confidence="0.992995" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986503018691589">
Alexandra Birch and Miles Osborne. 2010. Lrscore
for evaluating lexical and reordering quality in mt.
In Proceedings of the Joint Fifth Workshop on
Statistical Machine Translation and MetricsMATR,
pages 327–332.
Pi-Chuan Chang, Michel Galley, and Christopher D.
Manning. 2008. Optimizing chinese word
segmentation for machine translation performance.
In Proceedings of the Third Workshop on Statistical
Machine Translation, pages 224–232.
Stanley F. Chen and Joshua T. Goodman. 1998.
An empirical study of smoothing techniques for
language modeling. Technical Report TR-10-98,
Computer Science Group, Harvard University.
David Chiang. 2005. A hierarchical phrase-
based model for statistical machine translation. In
Proceedings of the 43rd Annual Meeting of the ACL,
pages 263–270, June.
David Chiang. 2006. An introduction to synchronous
grammars.
David Chiang. 2007. Hierarchical phrase-based
translation. Computational Linguistics, 33(2):201–
228.
David Chiang. 2010. Learning to translate with
source and target syntax. In Proceedings of
the 48th Annual Meeting of the Association for
Computational Linguistics, pages 1443–1452.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis testing
for statistical machine translation: Controlling
for optimizer instability. In Proceedings of
the 49th Annual Meeting of the Association
for Computational Linguistics: HLTTechnologies:
Short Papers - Volume 2, pages 176–181.
Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization
and evaluation of machine translation systems. In
Proceedings of the Sixth Workshop on Statistical
Machine Translation, pages 85–91.
W. J. Dixon and A. M. Mood. 1946. The statistical
sign test. Journal of the American Statistical
Association, pages 557–566.
Andreas Eisele and Yu Chen. 2010. Multiun: A
multilingual corpus from united nation documents.
In Proceedings of the 7th International Conference
on Language Resources and Evaluation (LREC
2010), pages 2868–2872.
Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt
Post, and Chris Callison-Burch. 2012. Joshua
4.0: Packing, pro, and paraphrases. In Proceedings
of the Seventh Workshop on Statistical Machine
Translation, pages 283–291, Montr´eal, Canada,
June. Association for Computational Linguistics.
Greg Hanneman and Alon Lavie. 2013. Improving
syntax-augmented machine translation by coarsen-
ing the label set. In HLT-NAACL, pages 288–297.
Hieu Hoang, Alexandra Birch, Chris Callison-burch,
Richard Zens, Rwth Aachen, Alexandra Constantin,
Marcello Federico, Nicola Bertoldi, Chris Dyer,
Brooke Cowan, Wade Shen, Christine Moran, and
Ondrej Bojar. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings
of the 41st Annual Meeting on Association for
Computational Linguistics - Volume 1, pages 177–
180.
Liang Huang, Kevin Knight, and Aravind Joshi.
2006. A syntax-directed translator with extended
domain of locality. In Proceedings of the Workshop
on Computationally Hard Problems and Joint
Inference in Speech and Language Processing,
pages 1–8.
Matthias Huck, Joern Wuebker, Felix Rietig, and
Hermann Ney. 2013. A phrase orientation
model for hierarchical machine translation. In
ACL 2013 Eighth Workshop on Statistical Machine
Translation, pages 452–463.
Dan Klein and Christopher D. Manning. 2003.
Accurate unlexicalized parsing. In Proceedings
of the 41st Annual Meeting on Association for
Computational Linguistics - Volume 1, pages 423–
430.
P. Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. of MT
Summit.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York, NY, USA.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of the 21st International
Conference on Computational Linguistics and
the 44th Annual Meeting of the Association for
Computational Linguistics, pages 609–616.
Gideon Maillette de Buy Wenniger and Khalil
Sima’an. 2013. Hierarchical alignment decomposi-
tion labels for hiero grammar rules. In Proceedings
of the Seventh Workshop on Syntax, Semantics and
Structure in Statistical Translation, pages 19–28.
Yuval Marton, David Chiang, and Philip Resnik.
2012. Soft syntactic constraints for arabic—english
hierarchical phrase-based translation. Machine
Translation, 26(1-2):137–157.
Haitao Mi and Liang Huang. 2008. Forest-based
translation rule extraction. In Proceedings of
EMNLP.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of ACL: HLT,
June.
</reference>
<page confidence="0.906491">
20
</page>
<reference confidence="0.998498814814815">
Markos Mylonakis and Khalil Sima’an. 2011.
Learning hierarchical translation structure with
linguistic annotations. In Proceedings of the
49th Annual Meeting of the Association for
Computational Linguistics: Human Language
Technologies, pages 642–652.
Markos Mylonakis. 2012. Learning the Latent
Structure of Translation. Ph.D. thesis, University
of Amsterdam.
ThuyLinh Nguyen and Stephan Vogel. 2013.
Integrating phrase-based reordering features into a
chart-based decoder for machine translation. In
Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1587–1596.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings
of the 41st Annual Meeting on Association for
Computational Linguistics - Volume 1, pages 160–
167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting on Association for
Computational Linguistics, pages 311–318.
Khalil Sima’an and Gideon Maillette de Buy Wen-
niger. 2013. Hierarchical alignment trees:
A recursive factorization of reordering in word
alignments with empirical results. Internal Report.
Matthew Snover, Bonnie Dorr, Richard Schwartz,
Linnea Micciulla, and John Makhoul. 2006. A
study of translation edit rate with targeted human
annotation. In In Proceedings of Association for
Machine Translation in the Americas, pages 223–
231.
Jrg Tiedemann. 2012. Parallel data, tools and
interfaces in opus. In Proceedings of the 8th
International Conference on Language Resources
and Evaluation (LREC 2012), pages 2868–2872.
Christoph Tillmann. 2004. A unigram orientation
model for statistical machine translation. In
Proceedings of HLT-NAACL 2004: Short Papers,
pages 101–104.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2009. Preference grammars:
softening syntactic constraints to improve statistical
machine translation. In Proceedings of Human Lan-
guage Technologies: The 2009 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 236–244.
Dekai Wu and Hongsing Wong Hkust. 1998. Machine
translation with a stochastic grammatical channel.
In Proceedings of the 36th Annual Meeting of
the Association for Computational Linguistics and
17th International Conference on Computational
Linguistics - Volume 2, pages 1408–1415.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23:377–404.
Xinyan Xiao, Jinsong Su, Yang Liu, Qun Liu, and
Shouxun Lin. 2011. An orientation model
for hierarchical phrase-based translation. In
Proceedings of the 2011 International Conference
on Asian Language Processing, pages 165–168.
Hao Zhang, Daniel Gildea, and David Chiang.
2008. Extracting synchronous grammar rules
from word-level alignments in linear time. In
Proceedings of the 22nd International Conference
on Computational Linguistics - Volume 1, pages
1081–1088.
Bowen Zhou, Bing Xiang, Xiaodan Zhu, and Yuqing
Gao. 2008. Prior derivation models for formally
syntax-based translation using linguistically syntac-
tic parsing and tree kernels. In Proceedings of
the ACL-08: HLT Second Workshop on Syntax and
Structure in Statistical Translation (SSST-2), pages
19–27.
Andreas Zollmann and Ashish Venugopal. 2006.
Syntax augmented machine translation via chart
parsing. In NAACL 2006 - Workshop on statistical
machine translation, June.
</reference>
<page confidence="0.999438">
21
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.961281">Bilingual Markov Reordering Labels for Hierarchical SMT</title>
<author confidence="0.838741">Maillette de_Buy Wenniger</author>
<affiliation confidence="0.9848515">Institute for Logic, Language and University of</affiliation>
<address confidence="0.832647">Science Park 107, 1098 XG Amsterdam, The</address>
<email confidence="0.855193">gemdbwATgmail.com,k.simaanATuva.nl</email>
<abstract confidence="0.982840247422681">Earlier work on labeling Hiero grammars with monolingual syntax reports improved performance, suggesting that such labeling may impact phrase reordering as well as lexical selection. In this paper we exthe idea of inducing labels for Hiero grammars without using any additional resources other than original Hiero itself does. Our bilingual labels aim at capturing salient patterns of phrase reordering in the training parallel corpus. These bilingual labels originate from hierarchical factorizations of the word alignments in Hiero’s own training data. In this paper we take a Markovian view on synchronous top-down derivations over these factorizations which allows us to extract and bilingual reordering labels. Using exactly the same training data as Hiero we show that the Markovian interpretation of word alignment facmajor benefits over the unlabeled version. We report extensive experiments with strict and soft bilingual labeled Hiero showing improved performance up to 1 BLEU points for Chinese- English and about 0.1 BLEU points for German-English. Phrase reordering in Hiero (Chiang, 2007) is modelled with synchronous rules consisting of phrase pairs with at most two nonterminal gaps, thereby embedding ITG permutations (Wu, 1997) in lexical context. It is by now recognized that Hiero’s reordering can be strengthened either by labeling (e.g., (Zollmann and Venugopal, 2006)) or by supplementing the grammar with extra-grammatical reordering models, e.g., (Xiao et al., 2011; Huck et al., 2013; Nguyen and Vogel, 2013). In this paper we concentrate on labeling approaches. Conceptually, labeling Hiero rules aims at introducing preference in the SCFG derivations for frequently occurring lexicalized ordering constelover rare ones which also lexical selection. In this paper, we present an approach for distilling phrase reordering labels directly from (hence To extract bilingual labels from word alignments we must first interpret the alignments as a hierarchy of phrases. Luckily, word alignment factorizes into Normalized Decomposition Trees (NDTs) (Zhang et al., 2008), showing explicitly how the word alignment recursively decomposes into phrase pairs. Zhang et al. (2008) employ NDTs for extracting Hiero grammars. In this work, we extend NDTs with explicit phrase permutation operators also extracted from the original word alignment (Sima’an and Maillette de Buy Wenniger, 2013); Every node in the NDT is equipped with a operator specifies how the order of the target phrases (children of this node) is produced from the corresponding source phrases. Subsequently, we cluster the node operators in these enriched NDTs according to their complexity, e.g., monotone (straight), inverted, non-binary but one-to-one, and the more complex case of discontinuous (Maillette de Buy Wenniger and Sima’an, 2013). Inspired by work on parsing (Klein and Manning, 2003), we explore a vertical Markovian approach: intuitively, labels signify the reordering of the sub-phrases inside the pair (Zhang et al., 2008), labels signify reordering aspects of the direct context (an embedding, parent phrase pair) of the phrase pair, and so on. Like the phrase orientation models this labeling approach does not employ external resources (e.g., taggers, parsers) beyond the training data used by Hiero. empirically explore this bucketing for 11 of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical pages 25, 2014, Doha, Qatar. Association for Computational Linguistics labels both as hard and soft labels. In experiments on German-English and Chinese- English we show that this extension of Hiero often significantly outperforms the unlabeled model while using no external data or monolingual labeling mechanisms. This suggests the viability of automatically inducing bilingual labels following the Markov labeling approach on operatorlabelled NDTs as proposed in this paper. 1 Hierarchical models and related work Hiero SCFGs (Chiang, 2005; Chiang, 2007) allow only up to two (pairs of) nonterminals on the righthand-side (RHS) of synchronous rules. The types of permissible Hiero rules are: δ , δ , δ γ, δ, ζ, η terminal sequences, possibly empty. Equation 1 corresponds to a normal phrase pair, 2 to a rule with one gap and 3 and 4 to the monotoneand inverting rules respectively. an Hiero SCFG a source sentence into a target sentence synchronous each is a finite sequence of wellformed substitutions of synchronous productions see (Chiang, 2006). Existing phrasemodels score a derivation linear interpolation of a finite set of feature functions of the derivation mostly working with feature functions individual producthe target side yield string language model features) and other features (see section): arg parameters P optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes lower in the chart orientations are by them. This goes to show that phrase-orientation models are not mere labelings of Hiero. Soft syntactic constraints has been around for some time now (Zhou et al., 2008; Venugopal et al., 2009; Chiang, 2010). In (Zhou et al., 2008) Hiero is reinforced with a linguistically motivated prior. This prior is based on the level of syntactic homogeneity between pairs of non-terminals and the associated syntactic forests rooted at these nonterminals, whereby tree-kernels are to measure the amount of overlap between all pairs of sub-trees induced by the pairs of syntactic forests. Crucially, the syntactic prior encourages derivations that are more syntactically coherent but does not block derivations when they are not. In (Venugopal et al., 2009) the authors associate distributions over compatible syntactic labelings with grammar rules, and combine these preference distributions during decoding, thus achieving a summation rather than competition between compatible label configurations. The latter approach requires significant changes to the decoder and comes at a considerable computational cost. An alternative approach (Chiang, 2010) uses labels similar to (Zollmann and Venugopal, 2006) together with boolean features for rule-label and substitutedlabel combinations; using discriminative training (MIRA) it is learned what combinations are associated with better translations. labeling approach presented next from existing approaches. It is inspired by soft labeling but employs novel, non-linguistic bilingual labels. And it shares the bilingual intuition with phrase orientation models but it is based on a Markov approach for SCFG labeling, thereby remaining within the confines of Hiero SCFG, avoiding the need to make changes inside the constraint decoding can easily be implemented without adapting the decoder, through a smart application of “label bridging” unary rules. In practice however, adapting decoder turns out to be computationally more therefore we used this solution in our experiments. 12 1 6 3 7 5 2 S 0 accordingly po 14 is labeled “right-binding inverted” (R.B.I.); E.F.D. and L.B.M. are similar abbreviations for “embedded fully discontinuous” and “left-binding monotone” respectively. As yet another example node 7 in Figure 3 is labeled “left-binding monotone” (L.B.M.) since it is monotone, but the alignment allows it only to bind to the left at the parent node, as opposed to only to the right or to both sides which cases would have yielded “right-binding monotone” R.B.M. and “(embedded) fully monotone” (E.F.M.) parent-relative reordering labels respectively. Note that for parent-relative labels the binding direction of monotone and inverted may not be informative. We therefore also form a set of labels by colthe label pairs single labels One-Side-Binding- 3 Features for soft bilingual labeling Labels used in hierarchical Statistical Machine Translation (SMT) are typically adapted from external resources such as taggers and parsers. Like in our case, these labels are typically not fitted to the training data – with very few exceptions e.g., (Mylonakis and Sima’an, 2011; Mylonakis, 2012; Hanneman and Lavie, 2013). Unfortunately this means that the labels will either overfit or underfit, and when they are used as strict constraints on SCFG derivations they are likely to underperform. Experience with mismatch between syntactic labels and the data is abundant (Venugopal et al., 2009; Marton et al., 2012; Chiang, 2010), and using soft constraint decoding with suitable label substitution features has been shown to be an workaround solution. The intuition behind soft constraint decoding is that even though heuristic labels are not perfectly tailored to the data, they do provide useful information provided the model is “allowed to learn” to use them only in as far as they can improve the final evaluation metric (usually BLEU). could also further coarsen the by removing entirely all sub-distinctions of binding-type for the binarizable cases, but that would make the labeling equal to the earlier mentioned except for looking at the reordering occurring at the parent rather than inside the phrase itself. We did not explore this variant in this as the high similarity to the already explored variant made it not seem to add much extra information. Figure 5: Label substitution features, schematic with same filling in the figures to the situation of a labels correspond (for Fillings shades (as for on the right in the two figures) indicates the situation were the of the nonterminal and the gap is Next we introduce the set of label substitution features used in our experiments. substitution features of a unique for every pair of labels the grammar, signifying a rule with left-hand-side on a gap labeled These features are combined with two more coarse and indicating if the substitution involves labels that match or not. Figure 5 illustrates the concept of label substitution features schematically. In this figure the substituting rule is substituted onto two gaps in the chart, which induces two label substitution features indicated by the two ellipses. The situation is analogous for rules with just one gap. To make things concrete, lets assume that both first nonterminal of the rule as well as first gap it is substituted onto have Furthermore lets assume the second has label the of the gap it substitutes onto is This situation results in the following two specific label substitution features: • • labeled rules. when la- Hiero rules there can be many labeled variants of every original Hiero rule. With soft constraint decoding this leads to prohibitive cost. This also has the of tuning the features more In practice, soft constraint decoding usually exploits α Decoder chart Substituting rule GAP111 GAP212 p N111 Label Substitution Features Y 15</abstract>
<title confidence="0.9029965">Systen Name Matching Type Label Order Label Granularity Strict Strict Strict Strict order order order order Coarse Fine Coarse Fine Soft Soft Soft Soft order order order order Coarse Fine Coarse Fine Table 1: Experiment names legend System Name DEV TEST German-English</title>
<address confidence="0.8642006">Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44 SAMT 27.76 32.67 58.05 28.32 32.88 57.70&apos; &apos; 67.63 27.85 32.70 58.04&apos; &apos; 66.27 28.36 57.83&apos; &apos; 67.30 27.82 32.75 57.92&apos; &apos; 66.66 28.39 33.03&apos; &apos; 57.75&apos; &apos; 67.55 27.86 32.66 58.23 66.37 32.90 57.93 67.47</address>
<phone confidence="0.765003">32.60&apos; &apos; 58.11 66.44 28.27 32.80&apos; &apos; 57.95 67.39</phone>
<abstract confidence="0.958884303571429">Chinese-English Hiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03 31.54 30.97&apos; &apos; 62.79&apos; &apos; 31.94&apos; &apos; 30.84&apos; &apos; 60.76&apos; &apos; 59.45&apos; &apos; 31.66 30.95&apos; &apos; 62.20&apos; &apos; 31.90&apos; &apos; 30.79&apos; &apos; 60.11&apos; &apos; 59.68&apos; &apos; 31.64 30.75 61.37 31.57 30.57 59.58&apos; &apos; 59.13&apos; &apos; 31.74 30.79 61.94&apos; &apos; 31.77 30.62 60.13&apos; &apos; 59.89&apos; &apos; 2: Mean results bilingual labels with strict a single labeled version per Hiero rule, which we call the “canonical labeled rule”. Following (Chiang, 2010), this canonical form is the most frequent labeled variant. 4 Experiments We evaluate our method on two language pairs: as source and English as target. In all experiments we decode with a 4-gram language model smoothed with modified Knesser-Ney discounting (Chen and Goodman, 1998). The data used for training the language per language pair, details are given in the next paragraphs. All data is lowercased as a last pre-processing step. In all experiments we use our own grammar extractor for the generation of all grammars, including the baseline Hiero grammars. This enables us to use the same features (as far as applicable given the grammar formalism) and assure true comparability of the grammars under comparison. German-English significance is dependent on variance of scores, and hence sometimes for same scores across systems. The data for our German-English experiments is derived from parliament proceedings sourced from the Europarl corpus (Koehn, 2005), with WMT-07 development and test data. We used a maximum sentence length of 40 for filtering the training data. We employ 1M sentence pairs for training, 1K for development and 2K for testing (single reference per source sentence). Both source and target of all datasets are tokenized using the Moses(Hoang et al., 2007) tokenization script. For these experiments both the baseline and our method use a language model trained on the target side of the full original training set (approximately 1M sentences). Chinese-English The data for our Chinese-English experiments is from a combination of Chen, 2010; Tiedemann, data and Kong Parallel Text from the Linguistic The Kong Parallel Text is in Chinese is thus first to Chinese be compatible available and downloaded from LDC catalog number of this dataset is LDC2004T08 16</abstract>
<title confidence="0.458432">System Name DEV TEST German-English</title>
<address confidence="0.703384">Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44 SAMT 27.76 32.67 58.05 28.32 32.88 67.63 66.17 28.48 32.98 67.32 32.71 66.24 28.45 32.98 67.51 27.94 32.69 66.26 32.94 67.36</address>
<phone confidence="0.573286">66.32 28.45 67.45</phone>
<abstract confidence="0.992903704797048">Chinese-English Hiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03 3: Mean results bilingual labels with soft the rest of the data We used a maximum sentence length of 40 for filtering the training data. The combined dataset has 7.34M sentence The contains translated documents from the United Nations, similar in to the parliament domain. The Kong Text contrast contains a richer mix of domains, namely Hansards, Laws and News. the dev and test set we use the Multiple- Chinese from LDC, part which contain sentences from the News domain. We combined part 2 and 3 to form the dev set (1813 sentence pairs) and part 1 and 4 to form the test set (1912 sentence pairs). For both development and testing we use 4 references. The Chinese source side of all datasets is segmented using the Segmenter(Chang et al., The English target side of all datasets is tokenized using the Moses tokenization script. For these experiments both the baseline and our method use a language model trained on sentences of news data taken from the “Xinhua” subcorpus of the English corpus of LDC. a simple conversion script downloaded from catalog numbers: LDC2002T01, DC2003T17, LDC2004T07 and LDC2004T07 from Chinese-English translation the domain of train data (mainly parliament) and data (news) requires usage of a domain specific language model to get optimal results. For German-English, all data is from the the parliament domain, so a language model trained on the (translation model) training data is already domain-specific. LDC catalog number of this dataset is LDC2003T05 4.1 Experimental Structure In our experiments we explore the influence of three dimensions of bilingual reordering labels on translation accuracy. These dimensions are: label granularity of the labeling label order the of the labeling matching type the type of label matching during decoding these dimensions gives 8 reordering labeled systems per language pair. On top of that we use two baseline systems, namely Hiero and Syntax Augmented Machine Translation (SAMT) to measure these systems against. An overview of the naming of our reordering labeled systems is given in Table 1. and decoding details experiments use Joshua (Ganitkevitch et al., 2012) with Viterbi best derivation. Baseline experiments use normal decoding whereas soft labeling experiments use soft constraint decoding. For training we use standard Hiero grammar extraction constraints (Chiang, 2007) (phrase pairs with source spans up to 10 words; abstract rules are forbidden). During decoding maximum span 10 on the source side is maintained. Following common practice, we use relative frequency estimates for phrase probabilities, lexical probabilities and generative rule probability. We train our systems using (batch-kbest) Mira as borrowed by Joshua from the Moses codebase, allowing up to 30 tuning iterations. Following 17 standard practice, we tune on BLEU, and after tuning we use the configuration with the highest scores on the dev set with actual (corpus level) BLEU evaluation. We report lowercase BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011) and TER (Snover et al., 2006) scores for the tuned test set and also for the tuned dev set, the latter mainly to observe any possible We use Multeval version for computing these metrics. We also use MultEval’s implementation of statistical significance testing between systems, which is based on multiple optimizer runs and approximate randomization. Multeval (Clark et al., 2011) randomly swaps outputs between systems and estimates the probthat the observed score arose by that are statistically signifand correspond to respect to the baseline are marked with level and the level. We also report the Kendall Reordering Score (KRS), which is the reordering-only variant of the LRscore (Birch and Osborne, 2010) (without the optional interpolation with BLEU) and which is a sentence-level score. For the computation of statistical significance of this metric we use our implementation of the test 13(Dixon and Mood, 1946), as also described in (Koehn, 2010). In our experiments we repeated each experiment three times to counter unreliable conclusions due to optimizer variance. Scores are averages over three runs of tuning plus testing. Scores with Nare significantly better than the those marked with Hare significantly worse; according to the resampling test of Multeval (Clark et al., 2011). Preliminary experiment with strict matching experiments concerned reorderlabels in a matching (no soft constraints). The results are shown in Table 2 for both language pairs. The results for the Hiero and baselines (Hiero and SAMT) are shown the first rows. Below it results for the (phrase-centric) bilingual labeled systems with the or make optimal usage of the 3 runs we computed weighted counts for all 3 baseline output output pairs and use those weighted counts in the sign test. could only be ran for German-English and not for Chinese-English, due to memory constraints. are shown, followed by the for of the (parent-relative) bilingual labeled systems (Hiero- All these systems use the default decoding with strict label matching. German-English the of strict bilingual labels is mostly positive: although we have no improvement for BLEU we do achieve significant improvements for METEOR and TER on the test set. For Chinese-English, the biggest improvements, significant improvements of BLEU, METEOR and KRS. TER is the only metric that worsens, and considerably so point. the highest improvement of KRS, namely 1.86 point higher than the Hiero baseline. Overall, this preliminary experiment shows that strict labeling sometimes gives improvements over Hiero, but sometimes it leads to worsening in terms of some of the metrics. with soft bilingual constraints initial experiments with strict bilingual labels in combination with strict matching by the decoder gave some hope such constraints could be useful. At the same time the results showed no stable improvements across language pairs, and thus does not allow us to draw definite conclusions about the merit of bilingual labels. Results for experiments with soft bilingual laare shown in Table 3. Here corresponds to the Hiero baseline. Below it are shown the systems that use soft constraint decoding ( labels in Similarly, and Hieroto the analog systems with parent-relative labels. For German- English there are only minor improvements for BLEU and METEOR, with somewhat bigger improvements for TER. For Chinese-English howthe improvements are considerable, BLEU improvement over the Hiero baseline for as well as METEOR and KRS. TER is worsening with for this For Chinese-English the of the labels gives overall superior results for both and labels. best soft bilingual labeling system for German-English shows small but significant of METEOR and TER while im- 18 proving BLEU and KRS as well, but not significantly. The results with soft-constraint matching are better than those for strict-matching in general, there is no clear winner between the of labels. For Chinese-English we see considerable improvements and overall the best results for the combination of soft-constraint matching, the variant of the labeled For Chinese-English the improvement of the word-order is also particularly as indicated by the KRS improvement for this best system. Furthermore the negative in terms of worsening of TER are also reduced in the soft-matching setting, dropping TER to TER. The results for are also competitive, since though it gives somewhat lower improvements of BLEU METEOR, it gives an improvement of while TER only worsens by for this system. conclude that Markov labels a big in improvement of hierarchical SMT. We observe that going beyond the basic reordering labels of ITG, refining the cases not captured by ITG and even more eftaking a rather than perspective on reordering are major factors for the success of including reordering information to hierarchical SMT through labeling. Crucial to the success of this undertaking is also the usage of a soft-constraint approach to label matching, as opposed to strict-matching. Finally, comparison of the German-English results with results for Syntax-Augmented Machine Translation (SAMT) reveals that SAMT loses performance compared to the Hiero baseline for BLEU, the metric upon which tuning is done, as well as METEOR, while only TER and KRS show improvement. Since the best bilingual labeled system for Germanimproves METEOR and TER significantly, while also improving BLEU and KRS, though not significant, we believe our labeling is highly competitive with syntax-based labeling approaches, without the need for any additional resources in the form of parsers or taggers, as syntax-based systems require. Likely complementarity of reordering information, and (target) syntax, which improves fluency, makes combining both a promising possibility we would like to explore in future work. 5 Conclusion We presented a novel method to enrich Hierarchical Statistical Machine Translation with bilingual labels that help to improve the translation quality. Considerable and significant improvements of the BLEU, METEOR and KRS are achieved simultaneously for Chinese-English translation while tuning on BLEU, where the Kendall Reordering Score is specifically designed to measure improvement of reordering in isolation. For German- English more modest, statistically significant improvements of METEOR and TER (simultaneously) or BLEU (separately) are achieved. Our from related approaches that use syntactic or part-of-speech information in the formation of reordering constraints in that it needs no additional information. It also from related work on reordering constraints based on lexicalization in that it uses no such lexicalization but instead strives to achieve more globally translations, by global, holistic constraints that take the local reordering history of the derivation directly into account. Our experiments also once again reinforce the established wisdom that soft, rather than strict constraints, are a necessity when aiming to include new information to an already strong system without the of worsening performance through constraints that have not been directly tailored to the data through a proper learning approach. While lexicalized constraints on reordering have proven to have great potential, un-lexicalized soft bilingual constraints, which are more general and transcend the rule level have their own place in providing another agenda of improving translation which focusses more on the global coherence direction by directly putting soft alignmentinformed constraints on the combination of rules. Finally, while more research is necessary in this direction, there are strong reasons to believe that the right setup these approaches can be made to further reinforce each other. Acknowledgements This work is supported by The Netherlands Organization for Scientific Research (NWO) under grant nr. 612.066.929. The authors would like to thank Matt Post and Juri Ganitkevitch, for their with respect to the integration of Decoding the Joshua codebase.</abstract>
<date confidence="0.39371">19</date>
<title confidence="0.842544">References</title>
<author confidence="0.881513">Lrscore</author>
<abstract confidence="0.954475333333333">for evaluating lexical and reordering quality in mt. of the Joint Fifth Workshop on Machine Translation and pages 327–332. Pi-Chuan Chang, Michel Galley, and Christopher D. Manning. 2008. Optimizing chinese segmentation for machine translation performance. of the Third Workshop on Statistical pages 224–232.</abstract>
<note confidence="0.729837">Stanley F. Chen and Joshua T. Goodman. 1998.</note>
<title confidence="0.426656">An empirical study of smoothing techniques for</title>
<pubnum confidence="0.76714">language modeling. Technical Report TR-10-98,</pubnum>
<affiliation confidence="0.845061">Computer Science Group, Harvard University.</affiliation>
<note confidence="0.49040175">Chiang. 2005. A hierarchical phrasebased model for statistical machine translation. In of the 43rd Annual Meeting of the pages 263–270, June.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Miles Osborne</author>
</authors>
<title>Lrscore for evaluating lexical and reordering quality in mt.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>327--332</pages>
<contexts>
<context position="21540" citStr="Birch and Osborne, 2010" startWordPosition="3328" endWordPosition="3331">use MultEval’s implementation of statistical significance testing between systems, which is based on multiple optimizer runs and approximate randomization. Multeval (Clark et al., 2011) randomly swaps outputs between systems and estimates the probability that the observed score difference arose by chance. Differences that are statistically significant and correspond to improvement/worsening with respect to the baseline are marked with N/Hat the p &lt;_ .05 level and NN/HHat the p &lt;_ .01 level. We also report the Kendall Reordering Score (KRS), which is the reordering-only variant of the LRscore (Birch and Osborne, 2010) (without the optional interpolation with BLEU) and which is a sentence-level score. For the computation of statistical significance of this metric we use our own implementation of the sign test 13 (Dixon and Mood, 1946), as also described in (Koehn, 2010). In our experiments we repeated each experiment three times to counter unreliable conclusions due to optimizer variance. Scores are averages over three runs of tuning plus testing. Scores marked with N are significantly better than the baseline, those marked with H are significantly worse; according to the resampling test of Multeval (Clark </context>
</contexts>
<marker>Birch, Osborne, 2010</marker>
<rawString>Alexandra Birch and Miles Osborne. 2010. Lrscore for evaluating lexical and reordering quality in mt. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 327–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pi-Chuan Chang</author>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>Optimizing chinese word segmentation for machine translation performance.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>224--232</pages>
<contexts>
<context position="18095" citStr="Chang et al., 2008" startWordPosition="2818" endWordPosition="2821"> translated documents from the United Nations, similar in genre to the parliament domain. The Hong Kong Parallel Text in contrast contains a richer mix of domains, namely Hansards, Laws and News. For the dev and test set we use the MultipleTranslation Chinese datasets from LDC, part 1-48, which contain sentences from the News domain. We combined part 2 and 3 to form the dev set (1813 sentence pairs) and part 1 and 4 to form the test set (1912 sentence pairs). For both development and testing we use 4 references. The Chinese source side of all datasets is segmented using the Stanford Segmenter(Chang et al., 2008)9. The English target side of all datasets is tokenized using the Moses tokenization script. For these experiments both the baseline and our method use a language model trained on 5.4M sentences of domain specific10 news data taken from the “Xinhua” subcorpus of the English Gigaword corpus of LDC. 11 7Using a simple conversion script downloaded from http://www.mandarintools.com/zhcode.html 8LDC catalog numbers: LDC2002T01, DC2003T17, LDC2004T07 and LDC2004T07 9Downloaded from http://nlp.stanford.edu/software/segmenter.shtml 10For Chinese-English translation the different domain of the train da</context>
</contexts>
<marker>Chang, Galley, Manning, 2008</marker>
<rawString>Pi-Chuan Chang, Michel Galley, and Christopher D. Manning. 2008. Optimizing chinese word segmentation for machine translation performance. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 224–232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua T Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<institution>Computer Science Group, Harvard University.</institution>
<contexts>
<context position="14639" citStr="Chen and Goodman, 1998" startWordPosition="2286" endWordPosition="2289">9.68&apos; &apos; Hiero-1stCoarse 31.64 30.75 61.37 59.48&apos;&apos; 31.57 30.57 59.58&apos; &apos; 59.13&apos; &apos; Hiero-1st 31.74 30.79 61.94&apos; &apos; 60.22&apos;&apos; 31.77 30.62 60.13&apos; &apos; 59.89&apos; &apos; Table 2: Mean results bilingual labels with strict matching.4 a single labeled version per Hiero rule, which we call the “canonical labeled rule”. Following (Chiang, 2010), this canonical form is the most frequent labeled variant. 4 Experiments We evaluate our method on two language pairs: using German/Chinese as source and English as target. In all experiments we decode with a 4-gram language model smoothed with modified Knesser-Ney discounting (Chen and Goodman, 1998). The data used for training the language models differs per language pair, details are given in the next paragraphs. All data is lowercased as a last pre-processing step. In all experiments we use our own grammar extractor for the generation of all grammars, including the baseline Hiero grammars. This enables us to use the same features (as far as applicable given the grammar formalism) and assure true comparability of the grammars under comparison. German-English 4Statistical significance is dependent on variance of resampled scores, and hence sometimes different for same mean scores across </context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley F. Chen and Joshua T. Goodman. 1998. An empirical study of smoothing techniques for language modeling. Technical Report TR-10-98, Computer Science Group, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrasebased model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="4456" citStr="Chiang, 2005" startWordPosition="666" endWordPosition="667">ructure in Statistical Translation, pages 11–21, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics and 1st-order labels both as hard and soft labels. In experiments on German-English and ChineseEnglish we show that this extension of Hiero often significantly outperforms the unlabeled model while using no external data or monolingual labeling mechanisms. This suggests the viability of automatically inducing bilingual labels following the Markov labeling approach on operatorlabelled NDTs as proposed in this paper. 1 Hierarchical models and related work Hiero SCFGs (Chiang, 2005; Chiang, 2007) allow only up to two (pairs of) nonterminals on the righthand-side (RHS) of synchronous rules. The types of permissible Hiero rules are: X → hα, γi (1) X → hα X1 β, δ X1 ζi (2) X → hα X1 β X2 γ , δ X1 ζ X2 η i (3) X → hα X1 β X2 γ , δ X2 ζ X1 η i (4) Here α,β, γ, δ, ζ, η are terminal sequences, possibly empty. Equation 1 corresponds to a normal phrase pair, 2 to a rule with one gap and 3 and 4 to the monotone- and inverting rules respectively. Given an Hiero SCFG G, a source sentence s is translated into a target sentence t by synchronous derivations d, each is a finite sequenc</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrasebased model for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the ACL, pages 263–270, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>An introduction to synchronous grammars.</title>
<date>2006</date>
<contexts>
<context position="5139" citStr="Chiang, 2006" startWordPosition="810" endWordPosition="811">ghthand-side (RHS) of synchronous rules. The types of permissible Hiero rules are: X → hα, γi (1) X → hα X1 β, δ X1 ζi (2) X → hα X1 β X2 γ , δ X1 ζ X2 η i (3) X → hα X1 β X2 γ , δ X2 ζ X1 η i (4) Here α,β, γ, δ, ζ, η are terminal sequences, possibly empty. Equation 1 corresponds to a normal phrase pair, 2 to a rule with one gap and 3 and 4 to the monotone- and inverting rules respectively. Given an Hiero SCFG G, a source sentence s is translated into a target sentence t by synchronous derivations d, each is a finite sequence of wellformed substitutions of synchronous productions from G, see (Chiang, 2006). Existing phrasebased models score a derivation der with linear interpolation of a finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Hua</context>
</contexts>
<marker>Chiang, 2006</marker>
<rawString>David Chiang. 2006. An introduction to synchronous grammars.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<pages>228</pages>
<contexts>
<context position="1429" citStr="Chiang, 2007" startWordPosition="214" endWordPosition="215">ents in Hiero’s own training data. In this paper we take a Markovian view on synchronous top-down derivations over these factorizations which allows us to extract 0th- and 1st-order bilingual reordering labels. Using exactly the same training data as Hiero we show that the Markovian interpretation of word alignment factorization offers major benefits over the unlabeled version. We report extensive experiments with strict and soft bilingual labeled Hiero showing improved performance up to 1 BLEU points for ChineseEnglish and about 0.1 BLEU points for German-English. Phrase reordering in Hiero (Chiang, 2007) is modelled with synchronous rules consisting of phrase pairs with at most two nonterminal gaps, thereby embedding ITG permutations (Wu, 1997) in lexical context. It is by now recognized that Hiero’s reordering can be strengthened either by labeling (e.g., (Zollmann and Venugopal, 2006)) or by supplementing the grammar with extra-grammatical reordering models, e.g., (Xiao et al., 2011; Huck et al., 2013; Nguyen and Vogel, 2013). In this paper we concentrate on labeling approaches. Conceptually, labeling Hiero rules aims at introducing preference in the SCFG derivations for frequently occurrin</context>
<context position="4471" citStr="Chiang, 2007" startWordPosition="668" endWordPosition="669">tistical Translation, pages 11–21, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics and 1st-order labels both as hard and soft labels. In experiments on German-English and ChineseEnglish we show that this extension of Hiero often significantly outperforms the unlabeled model while using no external data or monolingual labeling mechanisms. This suggests the viability of automatically inducing bilingual labels following the Markov labeling approach on operatorlabelled NDTs as proposed in this paper. 1 Hierarchical models and related work Hiero SCFGs (Chiang, 2005; Chiang, 2007) allow only up to two (pairs of) nonterminals on the righthand-side (RHS) of synchronous rules. The types of permissible Hiero rules are: X → hα, γi (1) X → hα X1 β, δ X1 ζi (2) X → hα X1 β X2 γ , δ X1 ζ X2 η i (3) X → hα X1 β X2 γ , δ X2 ζ X1 η i (4) Here α,β, γ, δ, ζ, η are terminal sequences, possibly empty. Equation 1 corresponds to a normal phrase pair, 2 to a rule with one gap and 3 and 4 to the monotone- and inverting rules respectively. Given an Hiero SCFG G, a source sentence s is translated into a target sentence t by synchronous derivations d, each is a finite sequence of wellformed</context>
<context position="20020" citStr="Chiang, 2007" startWordPosition="3094" endWordPosition="3095">} Combining these dimensions gives 8 different reordering labeled systems per language pair. On top of that we use two baseline systems, namely Hiero and Syntax Augmented Machine Translation (SAMT) to measure these systems against. An overview of the naming of our reordering labeled systems is given in Table 1. Training and decoding details Our experiments use Joshua (Ganitkevitch et al., 2012) with Viterbi best derivation. Baseline experiments use normal decoding whereas soft labeling experiments use soft constraint decoding. For training we use standard Hiero grammar extraction constraints (Chiang, 2007) (phrase pairs with source spans up to 10 words; abstract rules are forbidden). During decoding maximum span 10 on the source side is maintained. Following common practice, we use relative frequency estimates for phrase probabilities, lexical probabilities and generative rule probability. We train our systems using (batch-kbest) Mira as borrowed by Joshua from the Moses codebase, allowing up to 30 tuning iterations. Following 17 standard practice, we tune on BLEU, and after tuning we use the configuration with the highest scores on the dev set with actual (corpus level) BLEU evaluation. We rep</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201– 228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Learning to translate with source and target syntax.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1443--1452</pages>
<contexts>
<context position="6678" citStr="Chiang, 2010" startWordPosition="1060" endWordPosition="1061">o et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes lower in the chart whose orientations are affected by them. This goes to show that phrase-orientation models are not mere labelings of Hiero. Soft syntactic constraints has been around for some time now (Zhou et al., 2008; Venugopal et al., 2009; Chiang, 2010). In (Zhou et al., 2008) Hiero is reinforced with a linguistically motivated prior. This prior is based on the level of syntactic homogeneity between pairs of non-terminals and the associated syntactic forests rooted at these nonterminals, whereby tree-kernels are applied to efficiently measure the amount of overlap between all pairs of sub-trees induced by the pairs of syntactic forests. Crucially, the syntactic prior encourages derivations that are more syntactically coherent but does not block derivations when they are not. In (Venugopal et al., 2009) the authors associate distributions ove</context>
<context position="10145" citStr="Chiang, 2010" startWordPosition="1570" endWordPosition="1571">rarchical Statistical Machine Translation (SMT) are typically adapted from external resources such as taggers and parsers. Like in our case, these labels are typically not fitted to the training data – with very few exceptions e.g., (Mylonakis and Sima’an, 2011; Mylonakis, 2012; Hanneman and Lavie, 2013). Unfortunately this means that the labels will either overfit or underfit, and when they are used as strict constraints on SCFG derivations they are likely to underperform. Experience with mismatch between syntactic labels and the data is abundant (Venugopal et al., 2009; Marton et al., 2012; Chiang, 2010), and using soft constraint decoding with suitable label substitution features has been shown to be an effective workaround solution. The intuition behind soft constraint decoding is that even though heuristic labels are not perfectly tailored to the data, they do provide useful information provided the model is “allowed to learn” to use them only in as far as they can improve the final evaluation metric (usually BLEU). 3We could also further coarsen the 1stlabels by removing entirely all sub-distinctions of binding-type for the binarizable cases, but that would make the labeling essentially e</context>
<context position="14336" citStr="Chiang, 2010" startWordPosition="2242" endWordPosition="2243">67.47 Hiero-1st 27.74&apos; 32.60&apos; &apos; 58.11 66.44 28.27 32.80&apos; &apos; 57.95 67.39 Chinese-English Hiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03 Hiero-0thITG+ 31.54 30.97&apos; &apos; 62.79&apos; &apos; 59.54&apos;&apos; 31.94&apos; &apos; 30.84&apos; &apos; 60.76&apos; &apos; 59.45&apos; &apos; Hiero-0th 31.66 30.95&apos; &apos; 62.20&apos; &apos; 60.00&apos;&apos; 31.90&apos; &apos; 30.79&apos; &apos; 60.11&apos; &apos; 59.68&apos; &apos; Hiero-1stCoarse 31.64 30.75 61.37 59.48&apos;&apos; 31.57 30.57 59.58&apos; &apos; 59.13&apos; &apos; Hiero-1st 31.74 30.79 61.94&apos; &apos; 60.22&apos;&apos; 31.77 30.62 60.13&apos; &apos; 59.89&apos; &apos; Table 2: Mean results bilingual labels with strict matching.4 a single labeled version per Hiero rule, which we call the “canonical labeled rule”. Following (Chiang, 2010), this canonical form is the most frequent labeled variant. 4 Experiments We evaluate our method on two language pairs: using German/Chinese as source and English as target. In all experiments we decode with a 4-gram language model smoothed with modified Knesser-Ney discounting (Chen and Goodman, 1998). The data used for training the language models differs per language pair, details are given in the next paragraphs. All data is lowercased as a last pre-processing step. In all experiments we use our own grammar extractor for the generation of all grammars, including the baseline Hiero grammars</context>
</contexts>
<marker>Chiang, 2010</marker>
<rawString>David Chiang. 2010. Learning to translate with source and target syntax. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1443–1452.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: Controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: HLTTechnologies: Short Papers -</booktitle>
<volume>2</volume>
<pages>176--181</pages>
<contexts>
<context position="21101" citStr="Clark et al., 2011" startWordPosition="3258" endWordPosition="3261"> BLEU, and after tuning we use the configuration with the highest scores on the dev set with actual (corpus level) BLEU evaluation. We report lowercase BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011) and TER (Snover et al., 2006) scores for the tuned test set and also for the tuned dev set, the latter mainly to observe any possible overfitting. We use Multeval version 0.5.1.12 for computing these metrics. We also use MultEval’s implementation of statistical significance testing between systems, which is based on multiple optimizer runs and approximate randomization. Multeval (Clark et al., 2011) randomly swaps outputs between systems and estimates the probability that the observed score difference arose by chance. Differences that are statistically significant and correspond to improvement/worsening with respect to the baseline are marked with N/Hat the p &lt;_ .05 level and NN/HHat the p &lt;_ .01 level. We also report the Kendall Reordering Score (KRS), which is the reordering-only variant of the LRscore (Birch and Osborne, 2010) (without the optional interpolation with BLEU) and which is a sentence-level score. For the computation of statistical significance of this metric we use our ow</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: HLTTechnologies: Short Papers - Volume 2, pages 176–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Alon Lavie</author>
</authors>
<title>Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>85--91</pages>
<contexts>
<context position="20698" citStr="Denkowski and Lavie, 2011" startWordPosition="3196" endWordPosition="3199">tract rules are forbidden). During decoding maximum span 10 on the source side is maintained. Following common practice, we use relative frequency estimates for phrase probabilities, lexical probabilities and generative rule probability. We train our systems using (batch-kbest) Mira as borrowed by Joshua from the Moses codebase, allowing up to 30 tuning iterations. Following 17 standard practice, we tune on BLEU, and after tuning we use the configuration with the highest scores on the dev set with actual (corpus level) BLEU evaluation. We report lowercase BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011) and TER (Snover et al., 2006) scores for the tuned test set and also for the tuned dev set, the latter mainly to observe any possible overfitting. We use Multeval version 0.5.1.12 for computing these metrics. We also use MultEval’s implementation of statistical significance testing between systems, which is based on multiple optimizer runs and approximate randomization. Multeval (Clark et al., 2011) randomly swaps outputs between systems and estimates the probability that the observed score difference arose by chance. Differences that are statistically significant and correspond to improvemen</context>
</contexts>
<marker>Denkowski, Lavie, 2011</marker>
<rawString>Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 85–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Dixon</author>
<author>A M Mood</author>
</authors>
<title>The statistical sign test.</title>
<date>1946</date>
<journal>Journal of the American Statistical Association,</journal>
<pages>557--566</pages>
<contexts>
<context position="21760" citStr="Dixon and Mood, 1946" startWordPosition="3363" endWordPosition="3366">s and estimates the probability that the observed score difference arose by chance. Differences that are statistically significant and correspond to improvement/worsening with respect to the baseline are marked with N/Hat the p &lt;_ .05 level and NN/HHat the p &lt;_ .01 level. We also report the Kendall Reordering Score (KRS), which is the reordering-only variant of the LRscore (Birch and Osborne, 2010) (without the optional interpolation with BLEU) and which is a sentence-level score. For the computation of statistical significance of this metric we use our own implementation of the sign test 13 (Dixon and Mood, 1946), as also described in (Koehn, 2010). In our experiments we repeated each experiment three times to counter unreliable conclusions due to optimizer variance. Scores are averages over three runs of tuning plus testing. Scores marked with N are significantly better than the baseline, those marked with H are significantly worse; according to the resampling test of Multeval (Clark et al., 2011). Preliminary experiment with strict matching Initial experiments concerned 0th-order reordering labels in a strict matching approach (no soft constraints). The results are shown in Table 2 for both language</context>
</contexts>
<marker>Dixon, Mood, 1946</marker>
<rawString>W. J. Dixon and A. M. Mood. 1946. The statistical sign test. Journal of the American Statistical Association, pages 557–566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Eisele</author>
<author>Yu Chen</author>
</authors>
<title>Multiun: A multilingual corpus from united nation documents.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>2868--2872</pages>
<contexts>
<context position="16021" citStr="Eisele and Chen, 2010" startWordPosition="2498" endWordPosition="2501"> development and test data. We used a maximum sentence length of 40 for filtering the training data. We employ 1M sentence pairs for training, 1K for development and 2K for testing (single reference per source sentence). Both source and target of all datasets are tokenized using the Moses(Hoang et al., 2007) tokenization script. For these experiments both the baseline and our method use a language model trained on the target side of the full original training set (approximately 1M sentences). Chinese-English The data for our Chinese-English experiments is derived from a combination of MultiUn(Eisele and Chen, 2010; Tiedemann, 2012)5 data and Hong Kong Parallel Text data from the Linguistic Data Consortium6. The Hong Kong Parallel Text data is in traditional Chinese and is thus first converted to simplified Chinese to be compatible 5Freely available and downloaded from http://opus.lingfil.uu.se/ 6The LDC catalog number of this dataset is LDC2004T08 16 System Name DEV TEST BLEU T METEOR T TER 1 KRS T BLEU T METEOR T TER 1 KRS T German-English Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44 SAMT 27.76 32.67 58.05 66.84• 28.32 32.88 57.70•• 67.63 Hiero-0thITG+-Sft 28.00• 32.76•• 57.90•• 66.17 28.48 3</context>
</contexts>
<marker>Eisele, Chen, 2010</marker>
<rawString>Andreas Eisele and Yu Chen. 2010. Multiun: A multilingual corpus from united nation documents. In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC 2010), pages 2868–2872.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Yuan Cao</author>
<author>Jonathan Weese</author>
<author>Matt Post</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Joshua 4.0: Packing, pro, and paraphrases.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>283--291</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="19804" citStr="Ganitkevitch et al., 2012" startWordPosition="3063" endWordPosition="3066">y. These dimensions are: • label granularity: granularity of the labeling {Coarse,Fine} • label order : the type/order of the labeling {0th, 1st} • matching type : the type of label matching performed during decoding {Strict,Soft} Combining these dimensions gives 8 different reordering labeled systems per language pair. On top of that we use two baseline systems, namely Hiero and Syntax Augmented Machine Translation (SAMT) to measure these systems against. An overview of the naming of our reordering labeled systems is given in Table 1. Training and decoding details Our experiments use Joshua (Ganitkevitch et al., 2012) with Viterbi best derivation. Baseline experiments use normal decoding whereas soft labeling experiments use soft constraint decoding. For training we use standard Hiero grammar extraction constraints (Chiang, 2007) (phrase pairs with source spans up to 10 words; abstract rules are forbidden). During decoding maximum span 10 on the source side is maintained. Following common practice, we use relative frequency estimates for phrase probabilities, lexical probabilities and generative rule probability. We train our systems using (batch-kbest) Mira as borrowed by Joshua from the Moses codebase, a</context>
</contexts>
<marker>Ganitkevitch, Cao, Weese, Post, Callison-Burch, 2012</marker>
<rawString>Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post, and Chris Callison-Burch. 2012. Joshua 4.0: Packing, pro, and paraphrases. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 283–291, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Hanneman</author>
<author>Alon Lavie</author>
</authors>
<title>Improving syntax-augmented machine translation by coarsening the label set.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>288--297</pages>
<contexts>
<context position="9837" citStr="Hanneman and Lavie, 2013" startWordPosition="1519" endWordPosition="1522"> inverted may not be informative. We therefore also form a set of coarse parent-relative labels (“1stCoarse”) by collapsing the label pairs Left/Right-Binding-Mono and Left/Right-Binding-Inverted into single labels One-Side-Binding-Mono and One-Side-BindingInv3. 3 Features for soft bilingual labeling Labels used in hierarchical Statistical Machine Translation (SMT) are typically adapted from external resources such as taggers and parsers. Like in our case, these labels are typically not fitted to the training data – with very few exceptions e.g., (Mylonakis and Sima’an, 2011; Mylonakis, 2012; Hanneman and Lavie, 2013). Unfortunately this means that the labels will either overfit or underfit, and when they are used as strict constraints on SCFG derivations they are likely to underperform. Experience with mismatch between syntactic labels and the data is abundant (Venugopal et al., 2009; Marton et al., 2012; Chiang, 2010), and using soft constraint decoding with suitable label substitution features has been shown to be an effective workaround solution. The intuition behind soft constraint decoding is that even though heuristic labels are not perfectly tailored to the data, they do provide useful information </context>
</contexts>
<marker>Hanneman, Lavie, 2013</marker>
<rawString>Greg Hanneman and Alon Lavie. 2013. Improving syntax-augmented machine translation by coarsening the label set. In HLT-NAACL, pages 288–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-burch</author>
<author>Richard Zens</author>
<author>Rwth Aachen</author>
<author>Alexandra Constantin</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Chris Dyer</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Ondrej Bojar</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics -</booktitle>
<volume>1</volume>
<pages>177--180</pages>
<contexts>
<context position="15709" citStr="Hoang et al., 2007" startWordPosition="2452" endWordPosition="2455">on. German-English 4Statistical significance is dependent on variance of resampled scores, and hence sometimes different for same mean scores across different systems. The data for our German-English experiments is derived from parliament proceedings sourced from the Europarl corpus (Koehn, 2005), with WMT-07 development and test data. We used a maximum sentence length of 40 for filtering the training data. We employ 1M sentence pairs for training, 1K for development and 2K for testing (single reference per source sentence). Both source and target of all datasets are tokenized using the Moses(Hoang et al., 2007) tokenization script. For these experiments both the baseline and our method use a language model trained on the target side of the full original training set (approximately 1M sentences). Chinese-English The data for our Chinese-English experiments is derived from a combination of MultiUn(Eisele and Chen, 2010; Tiedemann, 2012)5 data and Hong Kong Parallel Text data from the Linguistic Data Consortium6. The Hong Kong Parallel Text data is in traditional Chinese and is thus first converted to simplified Chinese to be compatible 5Freely available and downloaded from http://opus.lingfil.uu.se/ 6</context>
</contexts>
<marker>Hoang, Birch, Callison-burch, Zens, Aachen, Constantin, Federico, Bertoldi, Dyer, Cowan, Shen, Moran, Bojar, 2007</marker>
<rawString>Hieu Hoang, Alexandra Birch, Chris Callison-burch, Richard Zens, Rwth Aachen, Alexandra Constantin, Marcello Federico, Nicola Bertoldi, Chris Dyer, Brooke Cowan, Wade Shen, Christine Moran, and Ondrej Bojar. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, pages 177– 180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>A syntax-directed translator with extended domain of locality.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="5754" citStr="Huang et al., 2006" startWordPosition="910" endWordPosition="913">06). Existing phrasebased models score a derivation der with linear interpolation of a finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves d</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Liang Huang, Kevin Knight, and Aravind Joshi. 2006. A syntax-directed translator with extended domain of locality. In Proceedings of the Workshop on Computationally Hard Problems and Joint Inference in Speech and Language Processing, pages 1–8.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Matthias Huck</author>
</authors>
<location>Joern Wuebker, Felix Rietig, and</location>
<marker>Huck, </marker>
<rawString>Matthias Huck, Joern Wuebker, Felix Rietig, and</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hermann Ney</author>
</authors>
<title>A phrase orientation model for hierarchical machine translation.</title>
<date>2013</date>
<booktitle>In ACL 2013 Eighth Workshop on Statistical Machine Translation,</booktitle>
<pages>452--463</pages>
<marker>Ney, 2013</marker>
<rawString>Hermann Ney. 2013. A phrase orientation model for hierarchical machine translation. In ACL 2013 Eighth Workshop on Statistical Machine Translation, pages 452–463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics -</booktitle>
<volume>1</volume>
<pages>423--430</pages>
<contexts>
<context position="3270" citStr="Klein and Manning, 2003" startWordPosition="488" endWordPosition="492">with explicit phrase permutation operators also extracted from the original word alignment (Sima’an and Maillette de Buy Wenniger, 2013); Every node in the NDT is equipped with a node operator that specifies how the order of the target phrases (children of this node) is produced from the corresponding source phrases. Subsequently, we cluster the node operators in these enriched NDTs according to their complexity, e.g., monotone (straight), inverted, non-binary but one-to-one, and the more complex case of discontinuous (Maillette de Buy Wenniger and Sima’an, 2013). Inspired by work on parsing (Klein and Manning, 2003), we explore a vertical Markovian labeling approach: intuitively, 0th-order labels signify the reordering of the sub-phrases inside the phrase pair (Zhang et al., 2008), 1st-order labels signify reordering aspects of the direct context (an embedding, parent phrase pair) of the phrase pair, and so on. Like the phrase orientation models this labeling approach does not employ external resources (e.g., taggers, parsers) beyond the training data used by Hiero. We empirically explore this bucketing for 0th11 Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Tra</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, pages 423– 430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. of MT Summit.</booktitle>
<contexts>
<context position="15387" citStr="Koehn, 2005" startWordPosition="2400" endWordPosition="2401">ased as a last pre-processing step. In all experiments we use our own grammar extractor for the generation of all grammars, including the baseline Hiero grammars. This enables us to use the same features (as far as applicable given the grammar formalism) and assure true comparability of the grammars under comparison. German-English 4Statistical significance is dependent on variance of resampled scores, and hence sometimes different for same mean scores across different systems. The data for our German-English experiments is derived from parliament proceedings sourced from the Europarl corpus (Koehn, 2005), with WMT-07 development and test data. We used a maximum sentence length of 40 for filtering the training data. We employ 1M sentence pairs for training, 1K for development and 2K for testing (single reference per source sentence). Both source and target of all datasets are tokenized using the Moses(Hoang et al., 2007) tokenization script. For these experiments both the baseline and our method use a language model trained on the target side of the full original training set (approximately 1M sentences). Chinese-English The data for our Chinese-English experiments is derived from a combinatio</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proc. of MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2010</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="21796" citStr="Koehn, 2010" startWordPosition="3371" endWordPosition="3372">rved score difference arose by chance. Differences that are statistically significant and correspond to improvement/worsening with respect to the baseline are marked with N/Hat the p &lt;_ .05 level and NN/HHat the p &lt;_ .01 level. We also report the Kendall Reordering Score (KRS), which is the reordering-only variant of the LRscore (Birch and Osborne, 2010) (without the optional interpolation with BLEU) and which is a sentence-level score. For the computation of statistical significance of this metric we use our own implementation of the sign test 13 (Dixon and Mood, 1946), as also described in (Koehn, 2010). In our experiments we repeated each experiment three times to counter unreliable conclusions due to optimizer variance. Scores are averages over three runs of tuning plus testing. Scores marked with N are significantly better than the baseline, those marked with H are significantly worse; according to the resampling test of Multeval (Clark et al., 2011). Preliminary experiment with strict matching Initial experiments concerned 0th-order reordering labels in a strict matching approach (no soft constraints). The results are shown in Table 2 for both language pairs. The results for the Hiero an</context>
</contexts>
<marker>Koehn, 2010</marker>
<rawString>Philipp Koehn. 2010. Statistical Machine Translation. Cambridge University Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Treeto-string alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>609--616</pages>
<contexts>
<context position="5734" citStr="Liu et al., 2006" startWordPosition="906" endWordPosition="909">G, see (Chiang, 2006). Existing phrasebased models score a derivation der with linear interpolation of a finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decod</context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2006. Treeto-string alignment template for statistical machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 609–616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Maillette de Buy Wenniger</author>
<author>Khalil Sima’an</author>
</authors>
<title>Hierarchical alignment decomposition labels for hiero grammar rules.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<pages>pages</pages>
<marker>Wenniger, Sima’an, 2013</marker>
<rawString>Gideon Maillette de Buy Wenniger and Khalil Sima’an. 2013. Hierarchical alignment decomposition labels for hiero grammar rules. In Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 19–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>David Chiang</author>
<author>Philip Resnik</author>
</authors>
<title>Soft syntactic constraints for arabic—english hierarchical phrase-based translation.</title>
<date>2012</date>
<journal>Machine Translation,</journal>
<pages>26--1</pages>
<contexts>
<context position="10130" citStr="Marton et al., 2012" startWordPosition="1566" endWordPosition="1569">ng Labels used in hierarchical Statistical Machine Translation (SMT) are typically adapted from external resources such as taggers and parsers. Like in our case, these labels are typically not fitted to the training data – with very few exceptions e.g., (Mylonakis and Sima’an, 2011; Mylonakis, 2012; Hanneman and Lavie, 2013). Unfortunately this means that the labels will either overfit or underfit, and when they are used as strict constraints on SCFG derivations they are likely to underperform. Experience with mismatch between syntactic labels and the data is abundant (Venugopal et al., 2009; Marton et al., 2012; Chiang, 2010), and using soft constraint decoding with suitable label substitution features has been shown to be an effective workaround solution. The intuition behind soft constraint decoding is that even though heuristic labels are not perfectly tailored to the data, they do provide useful information provided the model is “allowed to learn” to use them only in as far as they can improve the final evaluation metric (usually BLEU). 3We could also further coarsen the 1stlabels by removing entirely all sub-distinctions of binding-type for the binarizable cases, but that would make the labelin</context>
</contexts>
<marker>Marton, Chiang, Resnik, 2012</marker>
<rawString>Yuval Marton, David Chiang, and Philip Resnik. 2012. Soft syntactic constraints for arabic—english hierarchical phrase-based translation. Machine Translation, 26(1-2):137–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
</authors>
<title>Forest-based translation rule extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="5791" citStr="Mi and Huang, 2008" startWordPosition="918" endWordPosition="921">e a derivation der with linear interpolation of a finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up </context>
</contexts>
<marker>Mi, Huang, 2008</marker>
<rawString>Haitao Mi and Liang Huang. 2008. Forest-based translation rule extraction. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
</authors>
<title>Forestbased translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL: HLT,</booktitle>
<contexts>
<context position="5771" citStr="Mi et al., 2008" startWordPosition="914" endWordPosition="917">based models score a derivation der with linear interpolation of a finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scori</context>
</contexts>
<marker>Mi, Huang, Liu, 2008</marker>
<rawString>Haitao Mi, Liang Huang, and Qun Liu. 2008. Forestbased translation. In Proceedings of ACL: HLT, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markos Mylonakis</author>
<author>Khalil Sima’an</author>
</authors>
<title>Learning hierarchical translation structure with linguistic annotations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>642--652</pages>
<marker>Mylonakis, Sima’an, 2011</marker>
<rawString>Markos Mylonakis and Khalil Sima’an. 2011. Learning hierarchical translation structure with linguistic annotations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 642–652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markos Mylonakis</author>
</authors>
<title>Learning the Latent Structure of Translation.</title>
<date>2012</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="9810" citStr="Mylonakis, 2012" startWordPosition="1517" endWordPosition="1518">n of monotone and inverted may not be informative. We therefore also form a set of coarse parent-relative labels (“1stCoarse”) by collapsing the label pairs Left/Right-Binding-Mono and Left/Right-Binding-Inverted into single labels One-Side-Binding-Mono and One-Side-BindingInv3. 3 Features for soft bilingual labeling Labels used in hierarchical Statistical Machine Translation (SMT) are typically adapted from external resources such as taggers and parsers. Like in our case, these labels are typically not fitted to the training data – with very few exceptions e.g., (Mylonakis and Sima’an, 2011; Mylonakis, 2012; Hanneman and Lavie, 2013). Unfortunately this means that the labels will either overfit or underfit, and when they are used as strict constraints on SCFG derivations they are likely to underperform. Experience with mismatch between syntactic labels and the data is abundant (Venugopal et al., 2009; Marton et al., 2012; Chiang, 2010), and using soft constraint decoding with suitable label substitution features has been shown to be an effective workaround solution. The intuition behind soft constraint decoding is that even though heuristic labels are not perfectly tailored to the data, they do </context>
</contexts>
<marker>Mylonakis, 2012</marker>
<rawString>Markos Mylonakis. 2012. Learning the Latent Structure of Translation. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ThuyLinh Nguyen</author>
<author>Stephan Vogel</author>
</authors>
<title>Integrating phrase-based reordering features into a chart-based decoder for machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1587--1596</pages>
<contexts>
<context position="1861" citStr="Nguyen and Vogel, 2013" startWordPosition="280" endWordPosition="283">ct and soft bilingual labeled Hiero showing improved performance up to 1 BLEU points for ChineseEnglish and about 0.1 BLEU points for German-English. Phrase reordering in Hiero (Chiang, 2007) is modelled with synchronous rules consisting of phrase pairs with at most two nonterminal gaps, thereby embedding ITG permutations (Wu, 1997) in lexical context. It is by now recognized that Hiero’s reordering can be strengthened either by labeling (e.g., (Zollmann and Venugopal, 2006)) or by supplementing the grammar with extra-grammatical reordering models, e.g., (Xiao et al., 2011; Huck et al., 2013; Nguyen and Vogel, 2013). In this paper we concentrate on labeling approaches. Conceptually, labeling Hiero rules aims at introducing preference in the SCFG derivations for frequently occurring lexicalized ordering constellations over rare ones which also affects lexical selection. In this paper, we present an approach for distilling phrase reordering labels directly from alignments (hence bilingual labels). To extract bilingual labels from word alignments we must first interpret the alignments as a hierarchy of phrases. Luckily, every word alignment factorizes into Normalized Decomposition Trees (NDTs) (Zhang et al.</context>
<context position="6240" citStr="Nguyen and Vogel, 2013" startWordPosition="989" endWordPosition="992">inimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes lower in the chart whose orientations are affected by them. This goes to show that phrase-orientation models are not mere labelings of Hiero. Soft syntactic constraints has been around for some time now (Zhou et al., 2008; Venugopal et al., 2009; Chiang, 2010). In (Zhou et al., 2008) Hiero is reinforced with a linguistically motivated prior. This prior is based on the level of syntactic homogeneity between pairs of non</context>
</contexts>
<marker>Nguyen, Vogel, 2013</marker>
<rawString>ThuyLinh Nguyen and Stephan Vogel. 2013. Integrating phrase-based reordering features into a chart-based decoder for machine translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1587–1596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics -</booktitle>
<volume>1</volume>
<pages>160--167</pages>
<contexts>
<context position="5640" citStr="Och, 2003" startWordPosition="892" endWordPosition="893">, each is a finite sequence of wellformed substitutions of synchronous productions from G, see (Chiang, 2006). Existing phrasebased models score a derivation der with linear interpolation of a finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013)</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, pages 160– 167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="20662" citStr="Papineni et al., 2002" startWordPosition="3191" endWordPosition="3194">source spans up to 10 words; abstract rules are forbidden). During decoding maximum span 10 on the source side is maintained. Following common practice, we use relative frequency estimates for phrase probabilities, lexical probabilities and generative rule probability. We train our systems using (batch-kbest) Mira as borrowed by Joshua from the Moses codebase, allowing up to 30 tuning iterations. Following 17 standard practice, we tune on BLEU, and after tuning we use the configuration with the highest scores on the dev set with actual (corpus level) BLEU evaluation. We report lowercase BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011) and TER (Snover et al., 2006) scores for the tuned test set and also for the tuned dev set, the latter mainly to observe any possible overfitting. We use Multeval version 0.5.1.12 for computing these metrics. We also use MultEval’s implementation of statistical significance testing between systems, which is based on multiple optimizer runs and approximate randomization. Multeval (Clark et al., 2011) randomly swaps outputs between systems and estimates the probability that the observed score difference arose by chance. Differences that are statistically sign</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalil Sima’an</author>
<author>Gideon Maillette de Buy Wenniger</author>
</authors>
<title>Hierarchical alignment trees: A recursive factorization of reordering in word alignments with empirical results.</title>
<date>2013</date>
<tech>Internal Report.</tech>
<marker>Sima’an, Wenniger, 2013</marker>
<rawString>Khalil Sima’an and Gideon Maillette de Buy Wenniger. 2013. Hierarchical alignment trees: A recursive factorization of reordering in word alignments with empirical results. Internal Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation. In</title>
<date>2006</date>
<booktitle>In Proceedings of Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="20728" citStr="Snover et al., 2006" startWordPosition="3202" endWordPosition="3205">ecoding maximum span 10 on the source side is maintained. Following common practice, we use relative frequency estimates for phrase probabilities, lexical probabilities and generative rule probability. We train our systems using (batch-kbest) Mira as borrowed by Joshua from the Moses codebase, allowing up to 30 tuning iterations. Following 17 standard practice, we tune on BLEU, and after tuning we use the configuration with the highest scores on the dev set with actual (corpus level) BLEU evaluation. We report lowercase BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011) and TER (Snover et al., 2006) scores for the tuned test set and also for the tuned dev set, the latter mainly to observe any possible overfitting. We use Multeval version 0.5.1.12 for computing these metrics. We also use MultEval’s implementation of statistical significance testing between systems, which is based on multiple optimizer runs and approximate randomization. Multeval (Clark et al., 2011) randomly swaps outputs between systems and estimates the probability that the observed score difference arose by chance. Differences that are statistically significant and correspond to improvement/worsening with respect to th</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In In Proceedings of Association for Machine Translation in the Americas, pages 223– 231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jrg Tiedemann</author>
</authors>
<title>Parallel data, tools and interfaces in opus.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>2868--2872</pages>
<contexts>
<context position="16039" citStr="Tiedemann, 2012" startWordPosition="2502" endWordPosition="2503">ata. We used a maximum sentence length of 40 for filtering the training data. We employ 1M sentence pairs for training, 1K for development and 2K for testing (single reference per source sentence). Both source and target of all datasets are tokenized using the Moses(Hoang et al., 2007) tokenization script. For these experiments both the baseline and our method use a language model trained on the target side of the full original training set (approximately 1M sentences). Chinese-English The data for our Chinese-English experiments is derived from a combination of MultiUn(Eisele and Chen, 2010; Tiedemann, 2012)5 data and Hong Kong Parallel Text data from the Linguistic Data Consortium6. The Hong Kong Parallel Text data is in traditional Chinese and is thus first converted to simplified Chinese to be compatible 5Freely available and downloaded from http://opus.lingfil.uu.se/ 6The LDC catalog number of this dataset is LDC2004T08 16 System Name DEV TEST BLEU T METEOR T TER 1 KRS T BLEU T METEOR T TER 1 KRS T German-English Hiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44 SAMT 27.76 32.67 58.05 66.84• 28.32 32.88 57.70•• 67.63 Hiero-0thITG+-Sft 28.00• 32.76•• 57.90•• 66.17 28.48 32.98 57.79•• 67.32</context>
</contexts>
<marker>Tiedemann, 2012</marker>
<rawString>Jrg Tiedemann. 2012. Parallel data, tools and interfaces in opus. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012), pages 2868–2872.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
</authors>
<title>A unigram orientation model for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL 2004: Short Papers,</booktitle>
<pages>101--104</pages>
<contexts>
<context position="6152" citStr="Tillmann, 2004" startWordPosition="976" endWordPosition="977">Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes lower in the chart whose orientations are affected by them. This goes to show that phrase-orientation models are not mere labelings of Hiero. Soft syntactic constraints has been around for some time now (Zhou et al., 2008; Venugopal et al., 2009; Chiang, 2010). In (Zhou et al., 2008) Hiero is reinforced with a linguistically motivat</context>
</contexts>
<marker>Tillmann, 2004</marker>
<rawString>Christoph Tillmann. 2004. A unigram orientation model for statistical machine translation. In Proceedings of HLT-NAACL 2004: Short Papers, pages 101–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Venugopal</author>
<author>Andreas Zollmann</author>
<author>Noah A Smith</author>
<author>Stephan Vogel</author>
</authors>
<title>Preference grammars: softening syntactic constraints to improve statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>236--244</pages>
<contexts>
<context position="6663" citStr="Venugopal et al., 2009" startWordPosition="1056" endWordPosition="1059">hrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes lower in the chart whose orientations are affected by them. This goes to show that phrase-orientation models are not mere labelings of Hiero. Soft syntactic constraints has been around for some time now (Zhou et al., 2008; Venugopal et al., 2009; Chiang, 2010). In (Zhou et al., 2008) Hiero is reinforced with a linguistically motivated prior. This prior is based on the level of syntactic homogeneity between pairs of non-terminals and the associated syntactic forests rooted at these nonterminals, whereby tree-kernels are applied to efficiently measure the amount of overlap between all pairs of sub-trees induced by the pairs of syntactic forests. Crucially, the syntactic prior encourages derivations that are more syntactically coherent but does not block derivations when they are not. In (Venugopal et al., 2009) the authors associate di</context>
<context position="10109" citStr="Venugopal et al., 2009" startWordPosition="1562" endWordPosition="1565">or soft bilingual labeling Labels used in hierarchical Statistical Machine Translation (SMT) are typically adapted from external resources such as taggers and parsers. Like in our case, these labels are typically not fitted to the training data – with very few exceptions e.g., (Mylonakis and Sima’an, 2011; Mylonakis, 2012; Hanneman and Lavie, 2013). Unfortunately this means that the labels will either overfit or underfit, and when they are used as strict constraints on SCFG derivations they are likely to underperform. Experience with mismatch between syntactic labels and the data is abundant (Venugopal et al., 2009; Marton et al., 2012; Chiang, 2010), and using soft constraint decoding with suitable label substitution features has been shown to be an effective workaround solution. The intuition behind soft constraint decoding is that even though heuristic labels are not perfectly tailored to the data, they do provide useful information provided the model is “allowed to learn” to use them only in as far as they can improve the final evaluation metric (usually BLEU). 3We could also further coarsen the 1stlabels by removing entirely all sub-distinctions of binding-type for the binarizable cases, but that w</context>
</contexts>
<marker>Venugopal, Zollmann, Smith, Vogel, 2009</marker>
<rawString>Ashish Venugopal, Andreas Zollmann, Noah A. Smith, and Stephan Vogel. 2009. Preference grammars: softening syntactic constraints to improve statistical machine translation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 236–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Hongsing Wong Hkust</author>
</authors>
<title>Machine translation with a stochastic grammatical channel.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics -</booktitle>
<volume>2</volume>
<pages>1408--1415</pages>
<contexts>
<context position="5842" citStr="Wu and Hkust, 1998" startWordPosition="926" endWordPosition="929">finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes lower in the chart whose</context>
</contexts>
<marker>Wu, Hkust, 1998</marker>
<rawString>Dekai Wu and Hongsing Wong Hkust. 1998. Machine translation with a stochastic grammatical channel. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 2, pages 1408–1415.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--377</pages>
<contexts>
<context position="1572" citStr="Wu, 1997" startWordPosition="236" endWordPosition="237">s us to extract 0th- and 1st-order bilingual reordering labels. Using exactly the same training data as Hiero we show that the Markovian interpretation of word alignment factorization offers major benefits over the unlabeled version. We report extensive experiments with strict and soft bilingual labeled Hiero showing improved performance up to 1 BLEU points for ChineseEnglish and about 0.1 BLEU points for German-English. Phrase reordering in Hiero (Chiang, 2007) is modelled with synchronous rules consisting of phrase pairs with at most two nonterminal gaps, thereby embedding ITG permutations (Wu, 1997) in lexical context. It is by now recognized that Hiero’s reordering can be strengthened either by labeling (e.g., (Zollmann and Venugopal, 2006)) or by supplementing the grammar with extra-grammatical reordering models, e.g., (Xiao et al., 2011; Huck et al., 2013; Nguyen and Vogel, 2013). In this paper we concentrate on labeling approaches. Conceptually, labeling Hiero rules aims at introducing preference in the SCFG derivations for frequently occurring lexicalized ordering constellations over rare ones which also affects lexical selection. In this paper, we present an approach for distilling</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23:377–404.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Xinyan Xiao</author>
</authors>
<title>Jinsong Su,</title>
<location>Yang Liu, Qun Liu, and</location>
<marker>Xiao, </marker>
<rawString>Xinyan Xiao, Jinsong Su, Yang Liu, Qun Liu, and</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shouxun Lin</author>
</authors>
<title>An orientation model for hierarchical phrase-based translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 International Conference on Asian Language Processing,</booktitle>
<pages>165--168</pages>
<marker>Lin, 2011</marker>
<rawString>Shouxun Lin. 2011. An orientation model for hierarchical phrase-based translation. In Proceedings of the 2011 International Conference on Asian Language Processing, pages 165–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
<author>David Chiang</author>
</authors>
<title>Extracting synchronous grammar rules from word-level alignments in linear time.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics -</booktitle>
<volume>1</volume>
<pages>1081--1088</pages>
<contexts>
<context position="2468" citStr="Zhang et al., 2008" startWordPosition="367" endWordPosition="370">Vogel, 2013). In this paper we concentrate on labeling approaches. Conceptually, labeling Hiero rules aims at introducing preference in the SCFG derivations for frequently occurring lexicalized ordering constellations over rare ones which also affects lexical selection. In this paper, we present an approach for distilling phrase reordering labels directly from alignments (hence bilingual labels). To extract bilingual labels from word alignments we must first interpret the alignments as a hierarchy of phrases. Luckily, every word alignment factorizes into Normalized Decomposition Trees (NDTs) (Zhang et al., 2008), showing explicitly how the word alignment recursively decomposes into phrase pairs. Zhang et al. (2008) employ NDTs for extracting Hiero grammars. In this work, we extend NDTs with explicit phrase permutation operators also extracted from the original word alignment (Sima’an and Maillette de Buy Wenniger, 2013); Every node in the NDT is equipped with a node operator that specifies how the order of the target phrases (children of this node) is produced from the corresponding source phrases. Subsequently, we cluster the node operators in these enriched NDTs according to their complexity, e.g.,</context>
</contexts>
<marker>Zhang, Gildea, Chiang, 2008</marker>
<rawString>Hao Zhang, Daniel Gildea, and David Chiang. 2008. Extracting synchronous grammar rules from word-level alignments in linear time. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, pages 1081–1088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bowen Zhou</author>
<author>Bing Xiang</author>
<author>Xiaodan Zhu</author>
<author>Yuqing Gao</author>
</authors>
<title>Prior derivation models for formally syntax-based translation using linguistically syntactic parsing and tree kernels.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2),</booktitle>
<pages>pages</pages>
<contexts>
<context position="6639" citStr="Zhou et al., 2008" startWordPosition="1052" endWordPosition="1055">o non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes lower in the chart whose orientations are affected by them. This goes to show that phrase-orientation models are not mere labelings of Hiero. Soft syntactic constraints has been around for some time now (Zhou et al., 2008; Venugopal et al., 2009; Chiang, 2010). In (Zhou et al., 2008) Hiero is reinforced with a linguistically motivated prior. This prior is based on the level of syntactic homogeneity between pairs of non-terminals and the associated syntactic forests rooted at these nonterminals, whereby tree-kernels are applied to efficiently measure the amount of overlap between all pairs of sub-trees induced by the pairs of syntactic forests. Crucially, the syntactic prior encourages derivations that are more syntactically coherent but does not block derivations when they are not. In (Venugopal et al., 2009) </context>
</contexts>
<marker>Zhou, Xiang, Zhu, Gao, 2008</marker>
<rawString>Bowen Zhou, Bing Xiang, Xiaodan Zhu, and Yuqing Gao. 2008. Prior derivation models for formally syntax-based translation using linguistically syntactic parsing and tree kernels. In Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollmann</author>
<author>Ashish Venugopal</author>
</authors>
<title>Syntax augmented machine translation via chart parsing.</title>
<date>2006</date>
<booktitle>In NAACL 2006 - Workshop on statistical machine translation,</booktitle>
<contexts>
<context position="1717" citStr="Zollmann and Venugopal, 2006" startWordPosition="257" endWordPosition="260">e Markovian interpretation of word alignment factorization offers major benefits over the unlabeled version. We report extensive experiments with strict and soft bilingual labeled Hiero showing improved performance up to 1 BLEU points for ChineseEnglish and about 0.1 BLEU points for German-English. Phrase reordering in Hiero (Chiang, 2007) is modelled with synchronous rules consisting of phrase pairs with at most two nonterminal gaps, thereby embedding ITG permutations (Wu, 1997) in lexical context. It is by now recognized that Hiero’s reordering can be strengthened either by labeling (e.g., (Zollmann and Venugopal, 2006)) or by supplementing the grammar with extra-grammatical reordering models, e.g., (Xiao et al., 2011; Huck et al., 2013; Nguyen and Vogel, 2013). In this paper we concentrate on labeling approaches. Conceptually, labeling Hiero rules aims at introducing preference in the SCFG derivations for frequently occurring lexicalized ordering constellations over rare ones which also affects lexical selection. In this paper, we present an approach for distilling phrase reordering labels directly from alignments (hence bilingual labels). To extract bilingual labels from word alignments we must first inter</context>
<context position="5821" citStr="Zollmann and Venugopal, 2006" startWordPosition="922" endWordPosition="925">ith linear interpolation of a finite set of feature functions ((D(d)) of the derivation d, mostly working with local feature functions φi of individual productions, the target side yield string t of d (target language model features) and other features (see experimental section): arg maxd∈G P(t, d |s) ≈ arg maxd∈G E1&apos;(d) |Ai X The parameters Ail are i_1 �i• P [Ail optimized on a held-out parallel corpus by direct error-minimization (Och, 2003). A range of (distantly) related work exploits syntax for Hiero models, e.g. (Liu et al., 2006; Huang et al., 2006; Mi et al., 2008; Mi and Huang, 2008; Zollmann and Venugopal, 2006; Wu and Hkust, 1998). In terms of labeling Hiero rules, SAMT (Zollmann and Venugopal, 2006; Mylonakis and Sima’an, 2011) exploits a “softer notion” of syntax by fitting the CCG-like syntactic labels to non-constituent phrases. The work of (Xiao et al., 2011) adds a lexicalized orientation model to Hiero, akin to (Tillmann, 2004) and achieves significant gains. The work of (Huck et al., 2013; Nguyen and Vogel, 2013) overcomes technical limitations of (Xiao et al., 2011), making necessary changes to the decoder, which involves delayed (re-)scoring at hypernodes up in the derivation of nodes low</context>
<context position="7687" citStr="Zollmann and Venugopal, 2006" startWordPosition="1200" endWordPosition="1203">ic forests. Crucially, the syntactic prior encourages derivations that are more syntactically coherent but does not block derivations when they are not. In (Venugopal et al., 2009) the authors associate distributions over compatible syntactic labelings with grammar rules, and combine these preference distributions during decoding, thus achieving a summation rather than competition between compatible label configurations. The latter approach requires significant changes to the decoder and comes at a considerable computational cost. An alternative approach (Chiang, 2010) uses labels similar to (Zollmann and Venugopal, 2006) together with boolean features for rule-label and substitutedlabel combinations; using discriminative training (MIRA) it is learned what combinations are associated with better translations. The labeling approach presented next differs from existing approaches. It is inspired by soft labeling but employs novel, non-linguistic bilingual labels. And it shares the bilingual intuition with phrase orientation models but it is based on a Markov approach for SCFG labeling, thereby remaining within the confines of Hiero SCFG, avoiding the need to make changes inside the decoder.1 1Soft constraint dec</context>
</contexts>
<marker>Zollmann, Venugopal, 2006</marker>
<rawString>Andreas Zollmann and Ashish Venugopal. 2006. Syntax augmented machine translation via chart parsing. In NAACL 2006 - Workshop on statistical machine translation, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>