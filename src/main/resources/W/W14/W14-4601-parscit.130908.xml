<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016171">
<title confidence="0.895079">
Developing an Automatic Part-of-Speech Tagger for Scottish Gaelic
</title>
<author confidence="0.726203">
Samuel Danso William Lamb
</author>
<affiliation confidence="0.650607">
Celtic and Scottish Studies Celtic and Scottish Studies
University of Edinburgh EH8 9LD University of Edinburgh EH8 9LD
</affiliation>
<email confidence="0.955151">
sdanso@staffmail.ed.ac.uk w.lamb@ed.ac.uk
</email>
<sectionHeader confidence="0.992866" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999901">
This paper describes an on-going project that seeks to develop the first automatic PoS tagger
for Scottish Gaelic. Adapting the PAROLE tagset for Irish, we manually re-tagged a pre-
existing 86k token corpus of Scottish Gaelic. A double-verified subset of 13.5k tokens was
used to instantiate eight statistical taggers and verify their accuracy, via a randomly assigned
hold-out sample. An accuracy level of 76.6% was achieved using a Brill bigram tagger. We
provide an overview of the project’s methodology, interim results and future directions.
</bodyText>
<sectionHeader confidence="0.999263" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999765142857143">
Part-of-speech (PoS) tagging is considered by some to be a solved problem (cf. Manning, 2011: 172).
Although this could be argued for languages and domains with decades of NLP work behind them,
developing accurate PoS taggers for highly inflectional or agglutinative languages is no trivial task
(Oravecz and Dienes, 2002: 710). Challenges are posed by the profusion of word-forms in these lan-
guages – leading to data sparseness – and their typically complex tagsets (ibid.). The complicated
morphology of the Celtic languages, of which Scottish Gaelic (ScG) is a member,1 led one linguist to
state, “There is hardly a language [family] in the world for which the traditional concept of ‘word’ is
so doubtful” (Ternes, 1982: 72; cf. Dorian, 1973: 414). As inauspicious as this may seem for our
aims, tagger accuracy levels of 95-97% have been achieved for other morphologically complex lan-
guages such as Polish (Acedański, 2010: 3), Irish (U’ Dhonnchadha and Van Genabith, 2006) and
Hungarian (Oravecz and Dienes, 2002: 710). In this paper, we describe our effort to build – to the best
of our knowledge – the first accurate, automatic tagger of ScG.
Irish is the closest linguistic relative to Gaelic in which substantial NLP work has been done, and U’
Dhonnchadha and Van Genabith’s work (2006; cf. U’ Dhonnchadha, 2009) provides a valuable refer-
ence point. For them, a rule-based method was the preferred option, as a tagged corpus of Irish was
unavailable (U’ Dhonnchadha, 2009: 42).2 They used finite-state transducers for the tokenisation and
morphological analyses, and context-sensitive Constraint Grammar rules to carry out PoS disambigua-
tion (2006: 2241). In our case, after consultation, we decided to adopt a statistical approach. We were
motivated by the availability of a pre-existing, hand-tagged corpus of Scottish Gaelic (see Lamb,
2008: 52-70), and our expectation that developing an accurate, rule-based tagger would take us beyond
our one-year timeframe.
</bodyText>
<sectionHeader confidence="0.991194" genericHeader="introduction">
2 Methodology
</sectionHeader>
<subsectionHeader confidence="0.977588">
2.1 Annotation
</subsectionHeader>
<bodyText confidence="0.999234333333333">
Using an adapted form of the PAROLE Irish tagset (U’ Dhonnchadha, 2009: 224), we manually re-
tagged the corpus of ScG mentioned above. Significant conversion was required, as the corpus had
been designed for a study of register variation (Lamb, 2008). Currently, 13.5k tokens have been final-
</bodyText>
<footnote confidence="0.866557285714286">
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/.
1 The Goidelic branch includes Scottish Gaelic, Irish and Manx Gaelic. Welsh, Breton and Cornish are part of the Brythonic
branch.
2 U’ Dhonnchadha (2009: 213; cf ibid: 42) states her future intention to induce a Brill tagger on a Gold-standard corpus of
Irish.
1
</footnote>
<note confidence="0.788894">
Proceedings of the First Celtic Language Technology Workshop, pages 1–5,
Dublin, Ireland, August 23 2014.
</note>
<bodyText confidence="0.9999204">
ised and used to train and evaluate various tagger algorithms, as described below. Our motivations for
adapting the Irish tagset were to facilitate comparisons between Irish and ScG corpora, and to follow
emergent de facto standards, as recommended in Leech (2005). Although this expedited progress,
some tokens could not be easily classified.
Like Irish (cf. U’ Dhonnchadha, 2009: 81), ScG morphology is generally regarded as complex, par-
ticularly in the nominal system. Various process can re-shape word-forms, resulting in data sparse-
ness; sparsity is a common issue in NLP work with morphologically-rich languages (Orvecz and
Dienes, 2002: 711). These processes include initial consonant mutation (e.g. c — ch); internal vowel
change (e.g. a — oi); palatalisation of final consonants (e.g. -at — -ait) and affixation. For example,
the singular noun cearc [‘hen’] declines for case and definiteness as cearc, chearc, circ, chirc, circe
and chirce. The adjective mall [‘slow’] can be found variably as mall, mhall, malla, mhalla, moill,
mhoill, moille and mhoille.3 To compound issues, as the language attrites, historically robust
distinctions are being levelled or inconsistently observed. Another obstacle was ambiguous function
words, such as a and a’; these can be tagged in various ways,4 depending on context. There were also
a small number of fused forms having multiple grammatical categories: e.g. cuimhneam [‘I know’],5
— cuimhne [‘knowledge’] + agam [‘at me’]. It was not possible, in all cases, to split these at the to-
kenisation stage and introducing further complexity to an already involved tagset seemed ill-advised.
Therefore, we determined to use concatenation tags (cf. Chungku et al., 2010: 105), e.g. cuimhneam
[‘knowledge at me’] &lt;Ncsfn+Pr1s&gt;. This tag is glossed as: Noun common singular feminine nomina-
tive + Pronoun prepositional 1st-person singular.
</bodyText>
<subsectionHeader confidence="0.994119">
2.2 Tokenisation
</subsectionHeader>
<bodyText confidence="0.99998925">
A full account of the automatic tokeniser is beyond the scope of this paper. What follows is a brief
description of our guiding principles and the manual tokenisation of the training corpus. As a rule, we
strove for a 1:1 correspondence between words/punctuation and tokens (1). However, some excep-
tions were necessary. As illustrated in (2) by the phrase mu dheireadh [‘at last’], multi-word expres-
sions were tokenised together when they performed an indivisible grammatical function6 and could not
be intersected by another word. Here, we took a slightly different approach from U’ Dhonnchadh
(2009: 71-72); our preference was for a low number of MWEs in order to avoid the need for a compli-
cated lexicon.7 In a few cases, we split words into two or more tokens if a failure to have done so
would have negatively impacted the pipeline further on (e.g. during lexicon extraction). In (3), this is
illustrated by the word dh’fhuirich [‘stayed’], which has been split into two tokens, separating the
morphophonemic particle dh’ from the verbal form. As described in U’ Dhonnchadha (2009: 70-71),
this obviates duplication in the lexicon (cf. m’ad1 [‘my hat’] — m’1 ad2).
</bodyText>
<equation confidence="0.998471666666667">
1) 1 WORD — 1 TOKEN
“1ñ2 cha3 robh4 e5 seo6,7”8 ars’9 ise10 — &amp;quot;1 ñ2 cha3 robh4 e5 seo6 ,7 &amp;quot;8 ars´9 ise10
2) &gt; 2 WORDS — 1 TOKEN
Bhˆsaich1 am2 fear3 mu4 dheireadh5 — Bhˆsaich1 am2 fear3 mu dheireadh4
3) 1 WORD —&gt;2 TOKENS
Dh’fhuirich1 e2 ann3 — Dh´1 fhuirich2 e3 ann4
</equation>
<footnote confidence="0.8042585">
3 See Lamb (2008: 197-280) for further details on Gaelic grammar. Many of the same issues are encountered in Irish (see U’
Dhonnchadha, 2009).
4 The word a, for instance, can be variably tagged as a 3rd person masc possessive, a relative PN, a verbal agreement marker,
the vocative particle, an interrogative pronoun, a simple preposition and a numerical counting particle.
5 NB: cuimhneam is a fused form consisting of a noun and a prepositional pronoun. Like Russian, Gaelic expresses
possession in a locative fashion (e.g. tha e agam [‘I have it’, lit. ‘it is at me’]; there is no verb of possession.
6 As defined by the tagset.
7 However, toponyms were tokenised as MWEs, e.g. Dun éideann ‘Edinburgh’ (cf. U’ Dhonnchadha, 2009: 72).
</footnote>
<page confidence="0.99126">
2
</page>
<bodyText confidence="0.999912">
More generally, the corpus was manually divided into clauses, with each clause on a separate line.
This was done to provide additional context for automatic tag disambiguation, with clause boundaries
used in lieu of ‘sentence boundaries’ for instantiating the taggers. Clauses are linguistically well-
defined structures, whilst sentences are not (Miller and Weiner, 1998: 71).
</bodyText>
<subsectionHeader confidence="0.980615">
2.3 Tagger Instantiation
</subsectionHeader>
<bodyText confidence="0.999923857142857">
The PoS tagging task can be formulated as follows: given a word wi, derived from a sequence of
words (wiÉwn), assign the best tag ti, derived from a set of tags, T={ti..tn}. After our 13.5k token
sample had been manually tagged and twice verified, we used it to instantiate two stochastic taggers –
bigram HMM (see Huang et al., 2009: 214) and trigram TnT (Brants, 2000: 224) – and a hybrid tagger
(Brill, 1992: 112), which combines a stochastic and rule-based method. We employed the principle of
ensemble learning (Dietterich, 2000: 1), whereby simple statistical PoS tagging algorithms can be use-
fully employed to improve the precision of more sophisticated algorithms. For comparative purposes,
we also included simple unigram, bigram and trigram taggers. Simple n-gram algorithms tend to as-
sign tags based on the most frequent tag sequence of the n-gram as observed in the training set.
On the surface, the HMM and TnT algorithms employ similar approaches to tagging, as both analyse
the sequential history of word–tag pairings in a given ‘sentence’ using Markov Model principles
(Ghahramani, 2001: 9). However, the approaches employed by HMM and TnT are somewhat differ-
ent. HMM is based on first-order Markov Model principles, whereas TnT tends to be based upon se-
cond-order ones. Additionally, TnT tends to employ additional features during training, such as capi-
talisation and suffixes (Brants, 2000: 224). The Brill tagger, on the other hand, is an example of
Transformational-Based Learning (Brill, 1992: 112). Like a stochastic tagger, it begins by pairing
words with their most likely tags, as observed in the training corpus. This can be done using uni-
grams, bigrams or trigrams. It then notes where tags are applied incorrectly and attempts to induce
corrective rules via various context-sensitive templates (ibid.: 113). Finally, it re-tags the corpus ac-
cording to learnt patterns. A typical template is ‘replace t1 with t2 in the context of C’. Some glossed
examples from the Gaelic corpus follow:
</bodyText>
<listItem confidence="0.803532">
1) Ug — Q-r if the tag of words i+1...i+2 is ‘V-s’ [token = a]
</listItem>
<bodyText confidence="0.6653905">
Change the tag for the agreement marker to one for a relative pronoun if one of the next two
words is tagged as a past-tense verb
</bodyText>
<listItem confidence="0.839316">
2) Tdsm — Tdsf if the tag of words i+1...i+2 is ‘Ncsfn’ [token = a’]
</listItem>
<bodyText confidence="0.9510175">
Change the tag for the singular, masculine definite article to one for the singular, feminine def-
inite article if one of the following two words is a singular, feminine noun in the nominative
</bodyText>
<listItem confidence="0.929627">
3) Sa — Tdsf if the tag of the following word is ‘Ncsfn’ [token = a’]
</listItem>
<bodyText confidence="0.99927025">
Change the tag for the aspectual particle to one for the singular, feminine definite article if the
following word is tagged as a singular, feminine noun in the nominative
One of the advantages of the Brill tagger over other stochastic approaches is its transparency. With a
knowledge of the tagset and target language, its output is easily understood. As seen in the above ex-
amples, it is capable of handling the problematic homographs discussed in §2.1.
Eight models, in total, were developed and assessed using the same training and testing set (see Ta-
ble 1). Since the Brill tagger requires the output of a stochastic tagger before applying inductive
methods, as described above, we employed the unigram algorithm as a base. Our ensemble strategy
used a backoff mechanism, implemented as part of the Natural Language Tool Kit (NLTK) libraries
(Bird, 2006: 70). Backoff creates a chain of PoS tagging algorithms that are executed in sequential
order, ensuring that if an initial tagger is unable to classify a given token, then that token is passed on
to the next tagging algorithm. Two ensemble-based models were developed: Brill (with bigram) and
Brill (with trigram). Thus, in addition to using the simple unigram model as an initial stochastic tag-
ger with Brill, we also employed bigram and trigram models. Brill (bigram) passes any untagged to-
ken to the unigram tagger, whereas the Brill (trigram), employs the bigram algorithm for untagged
tokens and then passes any untagged tokens onto the unigram algorithm. In all cases, these stochastic
</bodyText>
<page confidence="0.997383">
3
</page>
<bodyText confidence="0.999919">
stages are followed by the inductive of rules characterising the Brill algorithm. We used the default
parameters of all algorithms, apart from one in the Brill algorithm, which defines the number of rules
to be learned automatically from the training corpus. This was set to 150, as it optimised performance
with the training set (NB: it did not apply to the test set).
We employed the hold-out method to evaluate our models (cf. Acedański 2010). To achieve this, we
randomly divided the corpus sample into a 10% ‘hold-out’ set for evaluation (165 sentences, —986 to-
kens), and a 90% ‘training’ set for model development (1492 sentences, —12,560 tokens). We as-
sessed the performance of the models by calculating the percentage of correctly assigned PoS tags for
each against the manually assigned tags.
</bodyText>
<sectionHeader confidence="0.999825" genericHeader="background">
3 Results
</sectionHeader>
<bodyText confidence="0.969516">
The table below shows the preliminary results.
</bodyText>
<tableCaption confidence="0.999686">
Table 1: Preliminary performance comparison of 8 statistical taggers
</tableCaption>
<table confidence="0.922502">
Model Unigram Bigram Trigram HMM TnT BrillUNI BrillBI BrillTRI
Accuracy 66.1 52.1 23.6 74.6 76.1 75.6 76.6 75.2
</table>
<bodyText confidence="0.998572636363636">
As seen in Table 1, the most successful method, at present, is the Brill bigram model, which had a per-
formance level of 76.6%. This is to be expected given the granularity of the tagset, along with the re-
stricted training data; we expect accuracy to increase once we utilise the full corpus of —86k tokens.8
Unsurprisingly, due to sparsity issues, the least successful model was the simple trigram, at 23.6%.
The performance of the TnT model was somewhat better than HMM (HMM: 74.6% and TnT: 76.1%),
and also better than the Brill unigram model (TnT: 76.1% and BrillUNI: 75.6%). The Brill bigram mod-
el, which is ensemble-based, outperformed the TnT model by about 0.5% (BrillBI: 76.6% and TnT:
76.1%). There was, however, a drop in performance of about 1.4% between the Brill bigram (76.6 %)
and Brill trigram (75.2%). Overall, our top accuracy level is comparable to that reported in Dandapat
et al. (2007: 223) for their 10k sample (84.73%), although they experienced less sparsity as their tagset
had only 40 categories (ibid.: 221).
</bodyText>
<sectionHeader confidence="0.993822" genericHeader="discussions">
4 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999955769230769">
In this paper, we describe an on-going project that seeks to develop the first automatic tagger for ScG.
We employed supervised methods to develop and evaluate eight different PoS tagging models. De-
spite the promising results, more work is indicated. Data sparsity is the most likely explanation for the
relatively low performance across the models. This is exemplified by the 43% difference between the
performance of the simple trigram and unigram models. Considering the size of the our current train-
ing set (12.5k tokens) and the granular nature of the tagset (242 discrete categories), it seems unavoid-
able at present. The majority of tags had less than five instances in the training set, making it difficult
for the algorithms to generate useful patterns. We will address this problem soon by including the full
corpus, once it has been verified. Subsequently, we will carry out a fine-grained error analysis to de-
termine which PoS features require further development. To improve results, we may integrate a lim-
ited amount of morphological analysis, as well a lexical database that has been made available to us
(Bauer &amp; Robertson, 2014). Finally, we will be exploring a multi-phase feature disambiguation
scheme similar to that described in Acedański (2010: 5).
</bodyText>
<sectionHeader confidence="0.996513" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999939">
We would like to thank Prof Mirella Lapata (University of Edinburgh) for reading a draft of this paper
and providing helpful comments. Many thanks to project members Dr Sharon Arbuthnot for retagging
the corpus and helping to devise the tagset, and Ms Susanna Naismith for her work in verifying and
</bodyText>
<footnote confidence="0.6831535">
8 Since this paper was written, the Brill tagger has achieved 86.8% accuracy (cf 92.5% on word classes only), using an 80k
token training sample and 6,460 token test sample.
</footnote>
<page confidence="0.993211">
4
</page>
<bodyText confidence="0.997573">
correcting the corpus. Finally, our appreciation to the Carnegie Trust for the Universities of Scotland
and B˜rd na Gˆidhlig for their generous financial support.
</bodyText>
<sectionHeader confidence="0.990048" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999100704545454">
Szymon Acedański. 2010. A morphosyntactic Brill tagger for inflectional languages. Advances in Natural Lan-
guage Processing. Berlin: Springer Berlin Heidelberg, 3-14
Michael Bauer and William Robertson. 2014. Am Faclair Beag (On-line dictionary). Available at
www.faclair.com.
Steven Bird. 2006. NLTK: The natural language toolkit. Proceedings of the COLING/ACL on Interactive presen-
tation sessions. Association for Computational Linguistics, 69-72.
Thorsten Brants. 2000. TnT: a statistical part-of-speech tagger. Proceedings of the sixth conference on Applied
natural language processing. Association for Computational Linguistics, 224-231
Eric Brill. 1992. A simple rule-based part of speech tagger. Proceedings of the workshop on Speech and Natural
Language. Association for Computational Linguistics, 112-116
Chungku Chungku, Jurmey Rabgay, and Gertrud Faa§. 2010. Building NLP resources for Dzongkha: a tagset
and a tagged corpus. Paper presented at the Proceedings of the 8th workshop on Asian language resources,
103-110.
Sandipan Dandapat, Sudeshna Sarkar, and Anupam Basu. 2007. Automatic part-of-speech tagging for Bengali:
An approach for morphologically rich languages in a poor resource scenario. Proceedings of the 45th Annual
Meeting of the ACL on Interactive Poster and Demonstration Sessions, 221-224.
Thomas G. Dietterich. 2000. Ensemble methods in machine learning. Multiple Classifier Systems. Berlin:
Springer Berlin Heidelberg, 1-15.
Nancy Dorian. 1973. Grammatical change in a dying dialect. Language, 49:413-438.
Zoubin Ghahramani. 2001. An introduction to hidden Markov models and Bayesian networks. International
Journal of Pattern Recognition and Artificial Intelligence, 15(01):9-42.
Zhongqiang Huang, Vladimir Eidelman, and Mary Harper. 2009. Improving a simple bigram HMM part-of-
speech tagger by latent annotation and self-training. Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,
Companion Volume: Short Papers. Association for Computational Linguistics, 213-216
William Lamb. 2008. Scottish Gaelic Speech and Writing: Register Variation in an Endangered Language. Bel-
fast: Cl— Ollscoil na Banr’ona.
Geoffrey Leech. 2005. In Martin Wynne (Ed.), Developing Linguistic Corpora: a Guide to Good Practice. Ox-
ford: Oxbow Books, 17-29. Retrieved from http://ahds.ac.uk/linguistic-corpora [accessed 28 April 2014].
Christopher Manning. 2011. Part-of-speech tagging from 97% to 100%: Is it time for some linguistics? In A.
Gelbukh (Ed.), Computational Linguistics and Intelligent Text Processing, 12th International Conference,
CICLing 2011, Proceedings, Part I. Lecture Notes in Computer Science 6608. Berlin: Springer Berlin Hei-
delberg, 171-189
James E. Miller and Regina Weinert. 1998. Spontaneous Spoken Language: Syntax and Discourse. Oxford:
Clarendon Press.
Csaba Oravecz and Péter Dienes. 2002. Efficient stochastic part-of-speech tagging for Hungarian. The Proceed-
ings of the Third International Conference on Language Resources and Evaluation (Las Palmas), 710-717.
Elmer Ternes. 1982. The grammatical structure of the Celtic languages. In R. Driscoll (Ed.), The Celtic Con-
sciousness. Edinburgh: Canongate, 69-78.
Elaine U’ Dhonnchadha. 2009. Part-of-speech tagging and partial parsing for Irish using finite-state transducers
and Constraint Grammar. PhD thesis. Dublin City University, School of Computing.
Elaine U’ Dhonnchadha and Joseph van Genabith. 2006. A Part-of-Speech tagger for Irish using finite state mor-
phology and constraint grammar disambiguation. Proceedings of the 5th International Conference on Lan-
guage Resources and Evaluation (LREC 2006), 2241-2244.
</reference>
<page confidence="0.994235">
5
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.433576">
<title confidence="0.998038">Developing an Automatic Part-of-Speech Tagger for Scottish Gaelic</title>
<author confidence="0.998082">Samuel William</author>
<affiliation confidence="0.695645">Celtic and Scottish Celtic and Scottish University of Edinburgh EH8 University of Edinburgh EH8</affiliation>
<email confidence="0.976091">sdanso@staffmail.ed.ac.ukw.lamb@ed.ac.uk</email>
<abstract confidence="0.998546428571429">This paper describes an on-going project that seeks to develop the first automatic PoS tagger for Scottish Gaelic. Adapting the PAROLE tagset for Irish, we manually re-tagged a preexisting 86k token corpus of Scottish Gaelic. A double-verified subset of 13.5k tokens was used to instantiate eight statistical taggers and verify their accuracy, via a randomly assigned hold-out sample. An accuracy level of 76.6% was achieved using a Brill bigram tagger. We provide an overview of the project’s methodology, interim results and future directions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Szymon Acedański</author>
</authors>
<title>A morphosyntactic Brill tagger for inflectional languages.</title>
<date>2010</date>
<booktitle>Advances in Natural Language Processing.</booktitle>
<pages>3--14</pages>
<publisher>Springer</publisher>
<location>Berlin:</location>
<contexts>
<context position="1751" citStr="Acedański, 2010" startWordPosition="266" endWordPosition="267">nes, 2002: 710). Challenges are posed by the profusion of word-forms in these languages – leading to data sparseness – and their typically complex tagsets (ibid.). The complicated morphology of the Celtic languages, of which Scottish Gaelic (ScG) is a member,1 led one linguist to state, “There is hardly a language [family] in the world for which the traditional concept of ‘word’ is so doubtful” (Ternes, 1982: 72; cf. Dorian, 1973: 414). As inauspicious as this may seem for our aims, tagger accuracy levels of 95-97% have been achieved for other morphologically complex languages such as Polish (Acedański, 2010: 3), Irish (U’ Dhonnchadha and Van Genabith, 2006) and Hungarian (Oravecz and Dienes, 2002: 710). In this paper, we describe our effort to build – to the best of our knowledge – the first accurate, automatic tagger of ScG. Irish is the closest linguistic relative to Gaelic in which substantial NLP work has been done, and U’ Dhonnchadha and Van Genabith’s work (2006; cf. U’ Dhonnchadha, 2009) provides a valuable reference point. For them, a rule-based method was the preferred option, as a tagged corpus of Irish was unavailable (U’ Dhonnchadha, 2009: 42).2 They used finite-state transducers for</context>
<context position="12709" citStr="Acedański 2010" startWordPosition="2043" endWordPosition="2044">as the Brill (trigram), employs the bigram algorithm for untagged tokens and then passes any untagged tokens onto the unigram algorithm. In all cases, these stochastic 3 stages are followed by the inductive of rules characterising the Brill algorithm. We used the default parameters of all algorithms, apart from one in the Brill algorithm, which defines the number of rules to be learned automatically from the training corpus. This was set to 150, as it optimised performance with the training set (NB: it did not apply to the test set). We employed the hold-out method to evaluate our models (cf. Acedański 2010). To achieve this, we randomly divided the corpus sample into a 10% ‘hold-out’ set for evaluation (165 sentences, —986 tokens), and a 90% ‘training’ set for model development (1492 sentences, —12,560 tokens). We assessed the performance of the models by calculating the percentage of correctly assigned PoS tags for each against the manually assigned tags. 3 Results The table below shows the preliminary results. Table 1: Preliminary performance comparison of 8 statistical taggers Model Unigram Bigram Trigram HMM TnT BrillUNI BrillBI BrillTRI Accuracy 66.1 52.1 23.6 74.6 76.1 75.6 76.6 75.2 As se</context>
<context position="15635" citStr="Acedański (2010" startWordPosition="2519" endWordPosition="2520">ess than five instances in the training set, making it difficult for the algorithms to generate useful patterns. We will address this problem soon by including the full corpus, once it has been verified. Subsequently, we will carry out a fine-grained error analysis to determine which PoS features require further development. To improve results, we may integrate a limited amount of morphological analysis, as well a lexical database that has been made available to us (Bauer &amp; Robertson, 2014). Finally, we will be exploring a multi-phase feature disambiguation scheme similar to that described in Acedański (2010: 5). Acknowledgements We would like to thank Prof Mirella Lapata (University of Edinburgh) for reading a draft of this paper and providing helpful comments. Many thanks to project members Dr Sharon Arbuthnot for retagging the corpus and helping to devise the tagset, and Ms Susanna Naismith for her work in verifying and 8 Since this paper was written, the Brill tagger has achieved 86.8% accuracy (cf 92.5% on word classes only), using an 80k token training sample and 6,460 token test sample. 4 correcting the corpus. Finally, our appreciation to the Carnegie Trust for the Universities of Scotlan</context>
</contexts>
<marker>Acedański, 2010</marker>
<rawString>Szymon Acedański. 2010. A morphosyntactic Brill tagger for inflectional languages. Advances in Natural Language Processing. Berlin: Springer Berlin Heidelberg, 3-14</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Bauer</author>
<author>William Robertson</author>
</authors>
<title>Am Faclair Beag (On-line dictionary). Available at www.faclair.com.</title>
<date>2014</date>
<contexts>
<context position="15515" citStr="Bauer &amp; Robertson, 2014" startWordPosition="2500" endWordPosition="2503">ens) and the granular nature of the tagset (242 discrete categories), it seems unavoidable at present. The majority of tags had less than five instances in the training set, making it difficult for the algorithms to generate useful patterns. We will address this problem soon by including the full corpus, once it has been verified. Subsequently, we will carry out a fine-grained error analysis to determine which PoS features require further development. To improve results, we may integrate a limited amount of morphological analysis, as well a lexical database that has been made available to us (Bauer &amp; Robertson, 2014). Finally, we will be exploring a multi-phase feature disambiguation scheme similar to that described in Acedański (2010: 5). Acknowledgements We would like to thank Prof Mirella Lapata (University of Edinburgh) for reading a draft of this paper and providing helpful comments. Many thanks to project members Dr Sharon Arbuthnot for retagging the corpus and helping to devise the tagset, and Ms Susanna Naismith for her work in verifying and 8 Since this paper was written, the Brill tagger has achieved 86.8% accuracy (cf 92.5% on word classes only), using an 80k token training sample and 6,460 tok</context>
</contexts>
<marker>Bauer, Robertson, 2014</marker>
<rawString>Michael Bauer and William Robertson. 2014. Am Faclair Beag (On-line dictionary). Available at www.faclair.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
</authors>
<title>NLTK: The natural language toolkit.</title>
<date>2006</date>
<booktitle>Proceedings of the COLING/ACL on Interactive presentation sessions. Association for Computational Linguistics,</booktitle>
<pages>69--72</pages>
<contexts>
<context position="11569" citStr="Bird, 2006" startWordPosition="1855" endWordPosition="1856">s its transparency. With a knowledge of the tagset and target language, its output is easily understood. As seen in the above examples, it is capable of handling the problematic homographs discussed in §2.1. Eight models, in total, were developed and assessed using the same training and testing set (see Table 1). Since the Brill tagger requires the output of a stochastic tagger before applying inductive methods, as described above, we employed the unigram algorithm as a base. Our ensemble strategy used a backoff mechanism, implemented as part of the Natural Language Tool Kit (NLTK) libraries (Bird, 2006: 70). Backoff creates a chain of PoS tagging algorithms that are executed in sequential order, ensuring that if an initial tagger is unable to classify a given token, then that token is passed on to the next tagging algorithm. Two ensemble-based models were developed: Brill (with bigram) and Brill (with trigram). Thus, in addition to using the simple unigram model as an initial stochastic tagger with Brill, we also employed bigram and trigram models. Brill (bigram) passes any untagged token to the unigram tagger, whereas the Brill (trigram), employs the bigram algorithm for untagged tokens an</context>
</contexts>
<marker>Bird, 2006</marker>
<rawString>Steven Bird. 2006. NLTK: The natural language toolkit. Proceedings of the COLING/ACL on Interactive presentation sessions. Association for Computational Linguistics, 69-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT: a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>Proceedings of the sixth conference on Applied natural language processing. Association for Computational Linguistics,</booktitle>
<pages>224--231</pages>
<contexts>
<context position="8542" citStr="Brants, 2000" startWordPosition="1350" endWordPosition="1351">ag disambiguation, with clause boundaries used in lieu of ‘sentence boundaries’ for instantiating the taggers. Clauses are linguistically welldefined structures, whilst sentences are not (Miller and Weiner, 1998: 71). 2.3 Tagger Instantiation The PoS tagging task can be formulated as follows: given a word wi, derived from a sequence of words (wiÉwn), assign the best tag ti, derived from a set of tags, T={ti..tn}. After our 13.5k token sample had been manually tagged and twice verified, we used it to instantiate two stochastic taggers – bigram HMM (see Huang et al., 2009: 214) and trigram TnT (Brants, 2000: 224) – and a hybrid tagger (Brill, 1992: 112), which combines a stochastic and rule-based method. We employed the principle of ensemble learning (Dietterich, 2000: 1), whereby simple statistical PoS tagging algorithms can be usefully employed to improve the precision of more sophisticated algorithms. For comparative purposes, we also included simple unigram, bigram and trigram taggers. Simple n-gram algorithms tend to assign tags based on the most frequent tag sequence of the n-gram as observed in the training set. On the surface, the HMM and TnT algorithms employ similar approaches to taggi</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT: a statistical part-of-speech tagger. Proceedings of the sixth conference on Applied natural language processing. Association for Computational Linguistics, 224-231</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>Proceedings of the workshop on Speech and Natural Language. Association for Computational Linguistics,</booktitle>
<pages>112--116</pages>
<contexts>
<context position="8583" citStr="Brill, 1992" startWordPosition="1358" endWordPosition="1359">used in lieu of ‘sentence boundaries’ for instantiating the taggers. Clauses are linguistically welldefined structures, whilst sentences are not (Miller and Weiner, 1998: 71). 2.3 Tagger Instantiation The PoS tagging task can be formulated as follows: given a word wi, derived from a sequence of words (wiÉwn), assign the best tag ti, derived from a set of tags, T={ti..tn}. After our 13.5k token sample had been manually tagged and twice verified, we used it to instantiate two stochastic taggers – bigram HMM (see Huang et al., 2009: 214) and trigram TnT (Brants, 2000: 224) – and a hybrid tagger (Brill, 1992: 112), which combines a stochastic and rule-based method. We employed the principle of ensemble learning (Dietterich, 2000: 1), whereby simple statistical PoS tagging algorithms can be usefully employed to improve the precision of more sophisticated algorithms. For comparative purposes, we also included simple unigram, bigram and trigram taggers. Simple n-gram algorithms tend to assign tags based on the most frequent tag sequence of the n-gram as observed in the training set. On the surface, the HMM and TnT algorithms employ similar approaches to tagging, as both analyse the sequential histor</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Eric Brill. 1992. A simple rule-based part of speech tagger. Proceedings of the workshop on Speech and Natural Language. Association for Computational Linguistics, 112-116</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chungku Chungku</author>
<author>Jurmey Rabgay</author>
<author>Gertrud Faa§</author>
</authors>
<title>Building NLP resources for Dzongkha: a tagset and a tagged corpus.</title>
<date>2010</date>
<booktitle>Paper presented at the Proceedings of the 8th workshop on Asian language resources,</booktitle>
<pages>103--110</pages>
<marker>Chungku, Rabgay, Faa§, 2010</marker>
<rawString>Chungku Chungku, Jurmey Rabgay, and Gertrud Faa§. 2010. Building NLP resources for Dzongkha: a tagset and a tagged corpus. Paper presented at the Proceedings of the 8th workshop on Asian language resources, 103-110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandipan Dandapat</author>
<author>Sudeshna Sarkar</author>
<author>Anupam Basu</author>
</authors>
<title>Automatic part-of-speech tagging for Bengali: An approach for morphologically rich languages in a poor resource scenario.</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>221--224</pages>
<contexts>
<context position="14210" citStr="Dandapat et al. (2007" startWordPosition="2289" endWordPosition="2292">orpus of —86k tokens.8 Unsurprisingly, due to sparsity issues, the least successful model was the simple trigram, at 23.6%. The performance of the TnT model was somewhat better than HMM (HMM: 74.6% and TnT: 76.1%), and also better than the Brill unigram model (TnT: 76.1% and BrillUNI: 75.6%). The Brill bigram model, which is ensemble-based, outperformed the TnT model by about 0.5% (BrillBI: 76.6% and TnT: 76.1%). There was, however, a drop in performance of about 1.4% between the Brill bigram (76.6 %) and Brill trigram (75.2%). Overall, our top accuracy level is comparable to that reported in Dandapat et al. (2007: 223) for their 10k sample (84.73%), although they experienced less sparsity as their tagset had only 40 categories (ibid.: 221). 4 Discussion and Future Work In this paper, we describe an on-going project that seeks to develop the first automatic tagger for ScG. We employed supervised methods to develop and evaluate eight different PoS tagging models. Despite the promising results, more work is indicated. Data sparsity is the most likely explanation for the relatively low performance across the models. This is exemplified by the 43% difference between the performance of the simple trigram an</context>
</contexts>
<marker>Dandapat, Sarkar, Basu, 2007</marker>
<rawString>Sandipan Dandapat, Sudeshna Sarkar, and Anupam Basu. 2007. Automatic part-of-speech tagging for Bengali: An approach for morphologically rich languages in a poor resource scenario. Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, 221-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Ensemble methods in machine learning. Multiple Classifier Systems.</title>
<date>2000</date>
<pages>1--15</pages>
<publisher>Springer</publisher>
<location>Berlin:</location>
<contexts>
<context position="8706" citStr="Dietterich, 2000" startWordPosition="1375" endWordPosition="1376">, whilst sentences are not (Miller and Weiner, 1998: 71). 2.3 Tagger Instantiation The PoS tagging task can be formulated as follows: given a word wi, derived from a sequence of words (wiÉwn), assign the best tag ti, derived from a set of tags, T={ti..tn}. After our 13.5k token sample had been manually tagged and twice verified, we used it to instantiate two stochastic taggers – bigram HMM (see Huang et al., 2009: 214) and trigram TnT (Brants, 2000: 224) – and a hybrid tagger (Brill, 1992: 112), which combines a stochastic and rule-based method. We employed the principle of ensemble learning (Dietterich, 2000: 1), whereby simple statistical PoS tagging algorithms can be usefully employed to improve the precision of more sophisticated algorithms. For comparative purposes, we also included simple unigram, bigram and trigram taggers. Simple n-gram algorithms tend to assign tags based on the most frequent tag sequence of the n-gram as observed in the training set. On the surface, the HMM and TnT algorithms employ similar approaches to tagging, as both analyse the sequential history of word–tag pairings in a given ‘sentence’ using Markov Model principles (Ghahramani, 2001: 9). However, the approaches e</context>
</contexts>
<marker>Dietterich, 2000</marker>
<rawString>Thomas G. Dietterich. 2000. Ensemble methods in machine learning. Multiple Classifier Systems. Berlin: Springer Berlin Heidelberg, 1-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Dorian</author>
</authors>
<title>Grammatical change in a dying dialect.</title>
<date>1973</date>
<journal>Language,</journal>
<pages>49--413</pages>
<contexts>
<context position="1569" citStr="Dorian, 1973" startWordPosition="237" endWordPosition="238"> languages and domains with decades of NLP work behind them, developing accurate PoS taggers for highly inflectional or agglutinative languages is no trivial task (Oravecz and Dienes, 2002: 710). Challenges are posed by the profusion of word-forms in these languages – leading to data sparseness – and their typically complex tagsets (ibid.). The complicated morphology of the Celtic languages, of which Scottish Gaelic (ScG) is a member,1 led one linguist to state, “There is hardly a language [family] in the world for which the traditional concept of ‘word’ is so doubtful” (Ternes, 1982: 72; cf. Dorian, 1973: 414). As inauspicious as this may seem for our aims, tagger accuracy levels of 95-97% have been achieved for other morphologically complex languages such as Polish (Acedański, 2010: 3), Irish (U’ Dhonnchadha and Van Genabith, 2006) and Hungarian (Oravecz and Dienes, 2002: 710). In this paper, we describe our effort to build – to the best of our knowledge – the first accurate, automatic tagger of ScG. Irish is the closest linguistic relative to Gaelic in which substantial NLP work has been done, and U’ Dhonnchadha and Van Genabith’s work (2006; cf. U’ Dhonnchadha, 2009) provides a valuable re</context>
</contexts>
<marker>Dorian, 1973</marker>
<rawString>Nancy Dorian. 1973. Grammatical change in a dying dialect. Language, 49:413-438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zoubin Ghahramani</author>
</authors>
<title>An introduction to hidden Markov models and Bayesian networks.</title>
<date>2001</date>
<journal>International Journal of Pattern Recognition and Artificial Intelligence,</journal>
<pages>15--01</pages>
<contexts>
<context position="9275" citStr="Ghahramani, 2001" startWordPosition="1463" endWordPosition="1464">rinciple of ensemble learning (Dietterich, 2000: 1), whereby simple statistical PoS tagging algorithms can be usefully employed to improve the precision of more sophisticated algorithms. For comparative purposes, we also included simple unigram, bigram and trigram taggers. Simple n-gram algorithms tend to assign tags based on the most frequent tag sequence of the n-gram as observed in the training set. On the surface, the HMM and TnT algorithms employ similar approaches to tagging, as both analyse the sequential history of word–tag pairings in a given ‘sentence’ using Markov Model principles (Ghahramani, 2001: 9). However, the approaches employed by HMM and TnT are somewhat different. HMM is based on first-order Markov Model principles, whereas TnT tends to be based upon second-order ones. Additionally, TnT tends to employ additional features during training, such as capitalisation and suffixes (Brants, 2000: 224). The Brill tagger, on the other hand, is an example of Transformational-Based Learning (Brill, 1992: 112). Like a stochastic tagger, it begins by pairing words with their most likely tags, as observed in the training corpus. This can be done using unigrams, bigrams or trigrams. It then n</context>
</contexts>
<marker>Ghahramani, 2001</marker>
<rawString>Zoubin Ghahramani. 2001. An introduction to hidden Markov models and Bayesian networks. International Journal of Pattern Recognition and Artificial Intelligence, 15(01):9-42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongqiang Huang</author>
<author>Vladimir Eidelman</author>
<author>Mary Harper</author>
</authors>
<title>Improving a simple bigram HMM part-ofspeech tagger by latent annotation and self-training.</title>
<date>2009</date>
<booktitle>Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers. Association for Computational Linguistics,</booktitle>
<pages>213--216</pages>
<contexts>
<context position="8506" citStr="Huang et al., 2009" startWordPosition="1342" endWordPosition="1345">provide additional context for automatic tag disambiguation, with clause boundaries used in lieu of ‘sentence boundaries’ for instantiating the taggers. Clauses are linguistically welldefined structures, whilst sentences are not (Miller and Weiner, 1998: 71). 2.3 Tagger Instantiation The PoS tagging task can be formulated as follows: given a word wi, derived from a sequence of words (wiÉwn), assign the best tag ti, derived from a set of tags, T={ti..tn}. After our 13.5k token sample had been manually tagged and twice verified, we used it to instantiate two stochastic taggers – bigram HMM (see Huang et al., 2009: 214) and trigram TnT (Brants, 2000: 224) – and a hybrid tagger (Brill, 1992: 112), which combines a stochastic and rule-based method. We employed the principle of ensemble learning (Dietterich, 2000: 1), whereby simple statistical PoS tagging algorithms can be usefully employed to improve the precision of more sophisticated algorithms. For comparative purposes, we also included simple unigram, bigram and trigram taggers. Simple n-gram algorithms tend to assign tags based on the most frequent tag sequence of the n-gram as observed in the training set. On the surface, the HMM and TnT algorithm</context>
</contexts>
<marker>Huang, Eidelman, Harper, 2009</marker>
<rawString>Zhongqiang Huang, Vladimir Eidelman, and Mary Harper. 2009. Improving a simple bigram HMM part-ofspeech tagger by latent annotation and self-training. Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers. Association for Computational Linguistics, 213-216</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Lamb</author>
</authors>
<title>Scottish Gaelic Speech and Writing: Register Variation in an Endangered Language. Belfast: Cl— Ollscoil na Banr’ona.</title>
<date>2008</date>
<contexts>
<context position="2677" citStr="Lamb, 2008" startWordPosition="412" endWordPosition="413">ne, and U’ Dhonnchadha and Van Genabith’s work (2006; cf. U’ Dhonnchadha, 2009) provides a valuable reference point. For them, a rule-based method was the preferred option, as a tagged corpus of Irish was unavailable (U’ Dhonnchadha, 2009: 42).2 They used finite-state transducers for the tokenisation and morphological analyses, and context-sensitive Constraint Grammar rules to carry out PoS disambiguation (2006: 2241). In our case, after consultation, we decided to adopt a statistical approach. We were motivated by the availability of a pre-existing, hand-tagged corpus of Scottish Gaelic (see Lamb, 2008: 52-70), and our expectation that developing an accurate, rule-based tagger would take us beyond our one-year timeframe. 2 Methodology 2.1 Annotation Using an adapted form of the PAROLE Irish tagset (U’ Dhonnchadha, 2009: 224), we manually retagged the corpus of ScG mentioned above. Significant conversion was required, as the corpus had been designed for a study of register variation (Lamb, 2008). Currently, 13.5k tokens have been finalThis work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence </context>
<context position="7049" citStr="Lamb (2008" startWordPosition="1104" endWordPosition="1105">er on (e.g. during lexicon extraction). In (3), this is illustrated by the word dh’fhuirich [‘stayed’], which has been split into two tokens, separating the morphophonemic particle dh’ from the verbal form. As described in U’ Dhonnchadha (2009: 70-71), this obviates duplication in the lexicon (cf. m’ad1 [‘my hat’] — m’1 ad2). 1) 1 WORD — 1 TOKEN “1ñ2 cha3 robh4 e5 seo6,7”8 ars’9 ise10 — &amp;quot;1 ñ2 cha3 robh4 e5 seo6 ,7 &amp;quot;8 ars´9 ise10 2) &gt; 2 WORDS — 1 TOKEN Bhˆsaich1 am2 fear3 mu4 dheireadh5 — Bhˆsaich1 am2 fear3 mu dheireadh4 3) 1 WORD —&gt;2 TOKENS Dh’fhuirich1 e2 ann3 — Dh´1 fhuirich2 e3 ann4 3 See Lamb (2008: 197-280) for further details on Gaelic grammar. Many of the same issues are encountered in Irish (see U’ Dhonnchadha, 2009). 4 The word a, for instance, can be variably tagged as a 3rd person masc possessive, a relative PN, a verbal agreement marker, the vocative particle, an interrogative pronoun, a simple preposition and a numerical counting particle. 5 NB: cuimhneam is a fused form consisting of a noun and a prepositional pronoun. Like Russian, Gaelic expresses possession in a locative fashion (e.g. tha e agam [‘I have it’, lit. ‘it is at me’]; there is no verb of possession. 6 As defined</context>
</contexts>
<marker>Lamb, 2008</marker>
<rawString>William Lamb. 2008. Scottish Gaelic Speech and Writing: Register Variation in an Endangered Language. Belfast: Cl— Ollscoil na Banr’ona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
</authors>
<title>In Martin Wynne (Ed.), Developing Linguistic Corpora: a Guide to Good Practice.</title>
<date>2005</date>
<pages>17--29</pages>
<publisher>Oxbow Books,</publisher>
<location>Oxford:</location>
<note>Retrieved from http://ahds.ac.uk/linguistic-corpora [accessed 28</note>
<contexts>
<context position="3965" citStr="Leech (2005)" startWordPosition="606" endWordPosition="607">includes Scottish Gaelic, Irish and Manx Gaelic. Welsh, Breton and Cornish are part of the Brythonic branch. 2 U’ Dhonnchadha (2009: 213; cf ibid: 42) states her future intention to induce a Brill tagger on a Gold-standard corpus of Irish. 1 Proceedings of the First Celtic Language Technology Workshop, pages 1–5, Dublin, Ireland, August 23 2014. ised and used to train and evaluate various tagger algorithms, as described below. Our motivations for adapting the Irish tagset were to facilitate comparisons between Irish and ScG corpora, and to follow emergent de facto standards, as recommended in Leech (2005). Although this expedited progress, some tokens could not be easily classified. Like Irish (cf. U’ Dhonnchadha, 2009: 81), ScG morphology is generally regarded as complex, particularly in the nominal system. Various process can re-shape word-forms, resulting in data sparseness; sparsity is a common issue in NLP work with morphologically-rich languages (Orvecz and Dienes, 2002: 711). These processes include initial consonant mutation (e.g. c — ch); internal vowel change (e.g. a — oi); palatalisation of final consonants (e.g. -at — -ait) and affixation. For example, the singular noun cearc [‘hen</context>
</contexts>
<marker>Leech, 2005</marker>
<rawString>Geoffrey Leech. 2005. In Martin Wynne (Ed.), Developing Linguistic Corpora: a Guide to Good Practice. Oxford: Oxbow Books, 17-29. Retrieved from http://ahds.ac.uk/linguistic-corpora [accessed 28 April 2014].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
</authors>
<title>Part-of-speech tagging from 97% to 100%: Is it time for some linguistics?</title>
<date>2011</date>
<booktitle>In A. Gelbukh (Ed.), Computational Linguistics and Intelligent Text Processing, 12th International Conference, CICLing 2011, Proceedings, Part I. Lecture Notes in Computer Science 6608.</booktitle>
<pages>171--189</pages>
<publisher>Springer</publisher>
<location>Berlin:</location>
<contexts>
<context position="916" citStr="Manning, 2011" startWordPosition="132" endWordPosition="133"> that seeks to develop the first automatic PoS tagger for Scottish Gaelic. Adapting the PAROLE tagset for Irish, we manually re-tagged a preexisting 86k token corpus of Scottish Gaelic. A double-verified subset of 13.5k tokens was used to instantiate eight statistical taggers and verify their accuracy, via a randomly assigned hold-out sample. An accuracy level of 76.6% was achieved using a Brill bigram tagger. We provide an overview of the project’s methodology, interim results and future directions. 1 Introduction Part-of-speech (PoS) tagging is considered by some to be a solved problem (cf. Manning, 2011: 172). Although this could be argued for languages and domains with decades of NLP work behind them, developing accurate PoS taggers for highly inflectional or agglutinative languages is no trivial task (Oravecz and Dienes, 2002: 710). Challenges are posed by the profusion of word-forms in these languages – leading to data sparseness – and their typically complex tagsets (ibid.). The complicated morphology of the Celtic languages, of which Scottish Gaelic (ScG) is a member,1 led one linguist to state, “There is hardly a language [family] in the world for which the traditional concept of ‘word</context>
</contexts>
<marker>Manning, 2011</marker>
<rawString>Christopher Manning. 2011. Part-of-speech tagging from 97% to 100%: Is it time for some linguistics? In A. Gelbukh (Ed.), Computational Linguistics and Intelligent Text Processing, 12th International Conference, CICLing 2011, Proceedings, Part I. Lecture Notes in Computer Science 6608. Berlin: Springer Berlin Heidelberg, 171-189</rawString>
</citation>
<citation valid="true">
<authors>
<author>James E Miller</author>
<author>Regina Weinert</author>
</authors>
<title>Spontaneous Spoken Language: Syntax and Discourse.</title>
<date>1998</date>
<publisher>Press.</publisher>
<location>Oxford: Clarendon</location>
<marker>Miller, Weinert, 1998</marker>
<rawString>James E. Miller and Regina Weinert. 1998. Spontaneous Spoken Language: Syntax and Discourse. Oxford: Clarendon Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Csaba Oravecz</author>
<author>Péter Dienes</author>
</authors>
<title>Efficient stochastic part-of-speech tagging for Hungarian.</title>
<date>2002</date>
<booktitle>The Proceedings of the Third International Conference on Language Resources and Evaluation (Las Palmas),</booktitle>
<pages>710--717</pages>
<contexts>
<context position="1145" citStr="Oravecz and Dienes, 2002" startWordPosition="165" endWordPosition="168">k tokens was used to instantiate eight statistical taggers and verify their accuracy, via a randomly assigned hold-out sample. An accuracy level of 76.6% was achieved using a Brill bigram tagger. We provide an overview of the project’s methodology, interim results and future directions. 1 Introduction Part-of-speech (PoS) tagging is considered by some to be a solved problem (cf. Manning, 2011: 172). Although this could be argued for languages and domains with decades of NLP work behind them, developing accurate PoS taggers for highly inflectional or agglutinative languages is no trivial task (Oravecz and Dienes, 2002: 710). Challenges are posed by the profusion of word-forms in these languages – leading to data sparseness – and their typically complex tagsets (ibid.). The complicated morphology of the Celtic languages, of which Scottish Gaelic (ScG) is a member,1 led one linguist to state, “There is hardly a language [family] in the world for which the traditional concept of ‘word’ is so doubtful” (Ternes, 1982: 72; cf. Dorian, 1973: 414). As inauspicious as this may seem for our aims, tagger accuracy levels of 95-97% have been achieved for other morphologically complex languages such as Polish (Acedański</context>
</contexts>
<marker>Oravecz, Dienes, 2002</marker>
<rawString>Csaba Oravecz and Péter Dienes. 2002. Efficient stochastic part-of-speech tagging for Hungarian. The Proceedings of the Third International Conference on Language Resources and Evaluation (Las Palmas), 710-717.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elmer Ternes</author>
</authors>
<title>The grammatical structure of the Celtic languages. In</title>
<date>1982</date>
<pages>69--78</pages>
<location>Edinburgh: Canongate,</location>
<contexts>
<context position="1547" citStr="Ternes, 1982" startWordPosition="233" endWordPosition="234">is could be argued for languages and domains with decades of NLP work behind them, developing accurate PoS taggers for highly inflectional or agglutinative languages is no trivial task (Oravecz and Dienes, 2002: 710). Challenges are posed by the profusion of word-forms in these languages – leading to data sparseness – and their typically complex tagsets (ibid.). The complicated morphology of the Celtic languages, of which Scottish Gaelic (ScG) is a member,1 led one linguist to state, “There is hardly a language [family] in the world for which the traditional concept of ‘word’ is so doubtful” (Ternes, 1982: 72; cf. Dorian, 1973: 414). As inauspicious as this may seem for our aims, tagger accuracy levels of 95-97% have been achieved for other morphologically complex languages such as Polish (Acedański, 2010: 3), Irish (U’ Dhonnchadha and Van Genabith, 2006) and Hungarian (Oravecz and Dienes, 2002: 710). In this paper, we describe our effort to build – to the best of our knowledge – the first accurate, automatic tagger of ScG. Irish is the closest linguistic relative to Gaelic in which substantial NLP work has been done, and U’ Dhonnchadha and Van Genabith’s work (2006; cf. U’ Dhonnchadha, 2009) </context>
</contexts>
<marker>Ternes, 1982</marker>
<rawString>Elmer Ternes. 1982. The grammatical structure of the Celtic languages. In R. Driscoll (Ed.), The Celtic Consciousness. Edinburgh: Canongate, 69-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine U’ Dhonnchadha</author>
</authors>
<title>Part-of-speech tagging and partial parsing for Irish using finite-state transducers and Constraint Grammar. PhD thesis.</title>
<date>2009</date>
<institution>Dublin City University, School of Computing.</institution>
<contexts>
<context position="2146" citStr="Dhonnchadha, 2009" startWordPosition="333" endWordPosition="334">tful” (Ternes, 1982: 72; cf. Dorian, 1973: 414). As inauspicious as this may seem for our aims, tagger accuracy levels of 95-97% have been achieved for other morphologically complex languages such as Polish (Acedański, 2010: 3), Irish (U’ Dhonnchadha and Van Genabith, 2006) and Hungarian (Oravecz and Dienes, 2002: 710). In this paper, we describe our effort to build – to the best of our knowledge – the first accurate, automatic tagger of ScG. Irish is the closest linguistic relative to Gaelic in which substantial NLP work has been done, and U’ Dhonnchadha and Van Genabith’s work (2006; cf. U’ Dhonnchadha, 2009) provides a valuable reference point. For them, a rule-based method was the preferred option, as a tagged corpus of Irish was unavailable (U’ Dhonnchadha, 2009: 42).2 They used finite-state transducers for the tokenisation and morphological analyses, and context-sensitive Constraint Grammar rules to carry out PoS disambiguation (2006: 2241). In our case, after consultation, we decided to adopt a statistical approach. We were motivated by the availability of a pre-existing, hand-tagged corpus of Scottish Gaelic (see Lamb, 2008: 52-70), and our expectation that developing an accurate, rule-based</context>
<context position="3484" citStr="Dhonnchadha (2009" startWordPosition="530" endWordPosition="531">sh tagset (U’ Dhonnchadha, 2009: 224), we manually retagged the corpus of ScG mentioned above. Significant conversion was required, as the corpus had been designed for a study of register variation (Lamb, 2008). Currently, 13.5k tokens have been finalThis work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. 1 The Goidelic branch includes Scottish Gaelic, Irish and Manx Gaelic. Welsh, Breton and Cornish are part of the Brythonic branch. 2 U’ Dhonnchadha (2009: 213; cf ibid: 42) states her future intention to induce a Brill tagger on a Gold-standard corpus of Irish. 1 Proceedings of the First Celtic Language Technology Workshop, pages 1–5, Dublin, Ireland, August 23 2014. ised and used to train and evaluate various tagger algorithms, as described below. Our motivations for adapting the Irish tagset were to facilitate comparisons between Irish and ScG corpora, and to follow emergent de facto standards, as recommended in Leech (2005). Although this expedited progress, some tokens could not be easily classified. Like Irish (cf. U’ Dhonnchadha, 2009: 8</context>
<context position="6682" citStr="Dhonnchadha (2009" startWordPosition="1031" endWordPosition="1032">matical function6 and could not be intersected by another word. Here, we took a slightly different approach from U’ Dhonnchadh (2009: 71-72); our preference was for a low number of MWEs in order to avoid the need for a complicated lexicon.7 In a few cases, we split words into two or more tokens if a failure to have done so would have negatively impacted the pipeline further on (e.g. during lexicon extraction). In (3), this is illustrated by the word dh’fhuirich [‘stayed’], which has been split into two tokens, separating the morphophonemic particle dh’ from the verbal form. As described in U’ Dhonnchadha (2009: 70-71), this obviates duplication in the lexicon (cf. m’ad1 [‘my hat’] — m’1 ad2). 1) 1 WORD — 1 TOKEN “1ñ2 cha3 robh4 e5 seo6,7”8 ars’9 ise10 — &amp;quot;1 ñ2 cha3 robh4 e5 seo6 ,7 &amp;quot;8 ars´9 ise10 2) &gt; 2 WORDS — 1 TOKEN Bhˆsaich1 am2 fear3 mu4 dheireadh5 — Bhˆsaich1 am2 fear3 mu dheireadh4 3) 1 WORD —&gt;2 TOKENS Dh’fhuirich1 e2 ann3 — Dh´1 fhuirich2 e3 ann4 3 See Lamb (2008: 197-280) for further details on Gaelic grammar. Many of the same issues are encountered in Irish (see U’ Dhonnchadha, 2009). 4 The word a, for instance, can be variably tagged as a 3rd person masc possessive, a relative PN, a verba</context>
</contexts>
<marker>Dhonnchadha, 2009</marker>
<rawString>Elaine U’ Dhonnchadha. 2009. Part-of-speech tagging and partial parsing for Irish using finite-state transducers and Constraint Grammar. PhD thesis. Dublin City University, School of Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine U’ Dhonnchadha</author>
<author>Joseph van Genabith</author>
</authors>
<title>A Part-of-Speech tagger for Irish using finite state morphology and constraint grammar disambiguation.</title>
<date>2006</date>
<booktitle>Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>2241--2244</pages>
<marker>Dhonnchadha, van Genabith, 2006</marker>
<rawString>Elaine U’ Dhonnchadha and Joseph van Genabith. 2006. A Part-of-Speech tagger for Irish using finite state morphology and constraint grammar disambiguation. Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006), 2241-2244.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>