<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003833">
<title confidence="0.970171">
The Role of Adverbs in Sentiment Analysis
</title>
<author confidence="0.977049">
Eduard C. Dragut Christiane Fellbaum
</author>
<affiliation confidence="0.993327">
Computer and Information Sciences Dept. Department of Computer Science
Temple University Princeton University
</affiliation>
<email confidence="0.999278">
edragut@temple.edu fellbaum@princeton.edu
</email>
<sectionHeader confidence="0.997394" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999446">
Sentiment Analysis, an important area of
Natural Language Understanding, often
relies on the assumption that lexemes carry
inherent sentiment values, as reflected in
specialized resources. We examine and
measure the contribution that eight intensi-
fying adverbs make to the sentiment value
of sentences, as judged by human anno-
tators. Our results show, first, that the
intensifying adverbs are not themselves
sentiment-laden but strengthen the senti-
ment conveyed by words in their contexts
to different degrees. We consider the con-
sequences for appropriate modifications of
the representation of the adverbs in senti-
ment lexicons.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998175">
It was probably Chuck who coined the term “arm-
chair linguist” (Svartvik, 1991). Chuck Fillmore’s
deep commitment to the study of language — in
particular lexical semantics — on the basis of cor-
pus data served as a model that kept many of us
honest in our investigation of language. Today,
we are lucky to be able to work from our office
chairs while collecting data from a broad speaker
group by means of crowdsourcing. And Chuck’s
FrameNet taught us the importance of consider-
ing word meanings in their contexts. Our paper
presents work that tries to take this legacy to heart.
</bodyText>
<sectionHeader confidence="0.973473" genericHeader="method">
2 Sentiment Analysis
</sectionHeader>
<bodyText confidence="0.994998948717949">
Broadly speaking, sentiment analysis (SA) at-
tempts to automatically derive a writer’s “senti-
ment” about the topic of a text. “Sentiment” is
usually categorized into “positive,” “neutral” and
“negative,” where positive corresponds to satisfac-
tion or happiness and “negative” to dissatisfaction
or unhappiness. Some work in SA further dis-
tinguishes degrees of positive and negative senti-
ment. SA often refers to lexical resources where
words are annotated with a sentiment value. Sen-
tiWordNet (SWN) (Esuli and Sebastiani, 2006) as-
signs one of three sentiment values to each synset
in WordNet (Fellbaum, 1998). Opinion Finder
(OF) (Wilson et al., 2005) identifies the sentiment
of the writer. Other resources include Appraisal
Lexicon (AL) (Taboada and Grieve, 2004) and
Micro-WNOp (Cerini et al., 2007).
Much of this work relies on the assumption that
specific lexemes (unique mappings of word forms
and word meanings) carry an inherent sentiment
value. This seems intuitively correct for words like
enjoy (positive), pencil (neutral) and pain (nega-
tive).
Other words may not carry inherent sentiment
value yet, in context, contribute to that of the
words they co-occur with or modify. One such
class of words comprises what we call polarity
intensifiers. In this preliminary study, we ana-
lyze the contribution of adverbial intensifiers to
the sentiment value of the sentences in which they
occur.
Consider the adverb absolutely in two sam-
ple sentences from movie reviews:
S1 He and Leonora have absolutely no chemistry
on screen whatsoever.
S2 I was absolutely delighted by the simple story
and amazing animation.
The goal of this preliminary experimental study
is to seek answers to the following questions
</bodyText>
<page confidence="0.993531">
38
</page>
<affiliation confidence="0.639459">
Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929–2014), pages 38–41,
Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics
</affiliation>
<table confidence="0.980763333333333">
Adverbs OF AL SWN
absolutely Neu. – Neu.
awfully Neg. Neg. Neu.
enormously Neg. – Neu.
extremely Neg. – Pos.
horribly Neg. Neg. Neu.
incredibly Pos. Pos. Neu.
pretty Pos. Pos. Neu.
seriously Neg. – Neu.
</table>
<tableCaption confidence="0.9932905">
Table 1: Eight intensifying adverbs and their po-
larities in sentiment lexicons.
</tableCaption>
<listItem confidence="0.998966545454545">
1. Do the adverbs we investigate carry inherent
sentiment values, as postulated by some sen-
timent lexicons?
2. Which adverbs have the strongest sentiment
intensifying effect?
3. Do some adverbs have a stronger effect on
sentences with a negative polarity or on sen-
tences with a positive polarity?
4. Does the presence or absence of each adverb
affect the direction of the polarity of the sen-
tence?
</listItem>
<sectionHeader confidence="0.986239" genericHeader="method">
3 The Experiment
</sectionHeader>
<bodyText confidence="0.999957235294118">
We analyze whether human judgments show an ef-
fect on the sentiment ratings of sentences in the
presence or absence of selected adverbs, and how
strong the effect of each adverb is.
Let S1’ be the sentence S1 from which an ad-
verb like absolutely is removed. S2’ is de-
fined similarly. Three main observations can be
made: (1) the adverb appears in both positive and
negative sentiment-bearing sentences (S1 is nega-
tive and S2 is positive); (2) its removal from either
S1 or S2 does not change the overall polarity of the
sentence; (3) intuitively, S1 has a stronger negative
polarity value than S1’ and S2 has a stronger posi-
tive polarity value than S2’. We conduct a prelim-
inary study of polarity intensifier words and show
that they all have characteristics (1) - (3). We ex-
amine data with eight different adverbs (Table 1).
</bodyText>
<subsectionHeader confidence="0.99771">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.999902227272727">
We extracted sentences containing the target ad-
verbs from a corpus of 50,000 movie reviews
(Maas et al., 2011). Each sentence is extracted
from a review that is labeled either “positive” or
“negative” and correlated with a star rating. We
manually inspected the sentences and discarded
those where the target adverb was used in a modal
sense, as in Seriously, there was not one re-
spectable character in the entire script while re-
taining sentences like There is no doubt that Al-
fred Hitchcock was a seriously talented director.
For each adverb, we retained ten sentences from
positive and negative reviews each, for a total 160
sentences. We copied the original sentences, re-
moved the adverbs without making additional al-
terations. Our final dataset consisted of a total
of 320 sentences with 160 sentence pairs whose
members were identical except for the presence or
absence of the target adverbs. Below is an exam-
ple of a sentence pair, where the original sentence
with the adverbs was pre-classified by (Pang and
Lee, 2004) as carrying positive sentiment.
</bodyText>
<listItem confidence="0.9688345">
1. I was absolutely delighted by the simple story
and amazing animation.
2. I was delighted by the simple story and amaz-
ing animation.
</listItem>
<subsectionHeader confidence="0.999756">
3.2 Collecting Judgments via Crowdsourcing
</subsectionHeader>
<bodyText confidence="0.999975928571429">
We submitted single sentences (not pairs) to be
annotated with sentiment scores for crowdsourc-
ing, using Amazon Mechanical Turk (AMT). To
avoid any bias we shuffled the sentences and dis-
played them individually. We asked the Turkers
to select, for each sentence, one of five sentiment
scores: strong positive (2), positive (1), neutral (0),
negative (-1), strong negative (-2). Each sentence
was rated by five annotators. Altogether, twenty
annotators completed the task within eight hours.
Since the annotators did not all judge the same set
of sentences, we computed the agreement between
annotators as follows. For each annotator, his/her
agreement with the others is given be the follow-
</bodyText>
<equation confidence="0.96076925">
1∑
ing formula: psji,
|S(i)|
jES(i)
</equation>
<bodyText confidence="0.999981125">
where S(i) is the set of sentences annotated by
the ith Turker and psji is the percentage of Turkers
who have the same annotation with the ith Turker
for sentence j. |S(i) |is the cardinality of set S(i).
The agreement ranges from 0.52 to 0.8. Although
the annotation of some Turkers is close to that of
flipping a coin, all judgments were retained and
included in the results reported here.
</bodyText>
<subsectionHeader confidence="0.644586">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.9992445">
We report the main results. The polarity rating of
a sentence j is the (un-weighted) average rating
</bodyText>
<page confidence="0.996716">
39
</page>
<bodyText confidence="0.486250090909091">
Adverbs Avg. Pol. Change
absolutely
awfully
enormously
extremely
horribly
incredibly
pretty
seriously
Table 2: Effects of adverbs on sentiment ratings.
of the five annotators for the sentence, denoted αj
</bodyText>
<equation confidence="0.508546">
∑and αj _ psji. We use uniform weighting. A
i
</equation>
<bodyText confidence="0.910620285714286">
sentence j is classified into one of the five polarity
categories according to the following criteria:
strong positve if αj E [1.5, 2]
positive if αj E (1.5, 0.5]
neutral if αj E (0.5, −0.5)
negative if αj E [−0.5,−1.5)
strong negative if αj E [−0.5,−2]
</bodyText>
<subsectionHeader confidence="0.809393">
3.3.1 Do Adverbs Change Sentiment Rating?
</subsectionHeader>
<bodyText confidence="0.9999862">
We first examine the polarity intensifying effects
of the eight adverbs and determine their relative
intensifying effects. For each adverb we compute
the average polarity rating change between the
members of the 20 sentence pairs with and with-
out the target adverb. The second column of Table
2 shows the average polarity rating change for the
adverbs. All adverbs have polarity intensifying ef-
fect, which ranges from 0.2 to 0.6. Awfully and
seriously have the strongest effect.
</bodyText>
<sectionHeader confidence="0.5818955" genericHeader="method">
3.3.2 Change of Sentiment Rating in Positive
vs. Negative Contexts
</sectionHeader>
<bodyText confidence="0.999646538461539">
Next we ask whether the adverbs have a stronger
polarity intensifying effect on sentences with a
negative, positive or neutral ratings. We partition
the 20 sentences with/without each adverb into
the three polarity categories according to their av-
erage polarity ratings. A sentence j is negative
(positive) if αj G −0.5 (αj &gt; 0.5). Figure 1
shows the results. For six out of the eight adverbs,
the graph follows a V-shaped pattern, indicating
that the adverbs have stronger polarity influence
on sentences conveying opinionated, but not neu-
tral, statements. Pretty shows the weakest ef-
fect across, which makes intuitive sense, as this
</bodyText>
<figureCaption confidence="0.995562">
Figure 1: The polarity intensifying effects of ad-
verbs over the sentiment categories.
</figureCaption>
<bodyText confidence="0.995713714285714">
adverb seems to have a “softening/weakening” ef-
fect: consider “pretty good,” which one could
judge to be slightly less good than “good.” For ex-
ample, the sentence
He has a pretty strident rant about how impor-
tant it is.
received an average rating score of 0 with the
adverb present and -0.2 without it. The results
for awfully and extremely are surprising. A
closer look at the annotations revealed some pos-
sible unreliable ratings. For example, the sentence
The part of the movie set in Vietnam was
extremely inaccurate.
has average polarity score of 0 (i.e., neutral)
with the adverb and -0.8 without. Intuitively,
it seems that the first sentence conveys a strong
negative sentiment. Such data indicate the need
for further study. A more complex scheme for
computing the average polarity scores, such as
weighted by inter-annotator agreement, might pro-
duce better results.
</bodyText>
<subsectionHeader confidence="0.926266">
3.3.3 Can Adverbs Reverse Sentiment
Orientation?
</subsectionHeader>
<bodyText confidence="0.999279444444444">
We ask whether their presence can have the effect
of reversing the polarity of a sentence. We again
consider three sentiment categories: positive, neg-
ative and neutral. The third column in Table 2
shows for each adverb, how many sentences out
of the total of 20 were judged to have a reversed
polarity when the adverb was removed. Overall,
the polarities of only 13 out of 160 sentences (i.e.,
about 8%) change.
</bodyText>
<subsectionHeader confidence="0.9771385">
3.3.4 Do Adverbs Have an Inherent
Sentiment Value?
</subsectionHeader>
<bodyText confidence="0.992859">
Our target adverbs have inherent polarity as
claimed in some sentiment lexicons (see Table 1).
</bodyText>
<figure confidence="0.996661588235294">
Pol. Reversal
0.2
0.6
0.2
0.2
0.2
0.2
0.2
0.4
0/20
2/20
1/20
2/20
0/20
4/20
1/20
3/20
</figure>
<page confidence="0.993126">
40
</page>
<bodyText confidence="0.99997475">
If the polarity of a sentence does not change when
the adverbs is present or absent, we conclude that
the adverb has no inherent polarity but may merely
affect the intensity of the constituents that it mod-
ifies. These results, as displayed in Figure 1 indi-
cate that our target adverbs do not carry inherent
polarity. Instead, they modify the intensity of the
sentiment connoted by the context.
</bodyText>
<sectionHeader confidence="0.999836" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999992">
We examined the effect of eight intensifying ad-
verbs on the sentiment ratings of the sentences in
which they occur. Our study showed that, contrary
to their representation in some widely used senti-
ment lexicons, these adverbs do not carry an inher-
ent sentiment polarity, but merely alter the degree
of the polarity of the constituents they modify; cor-
rections of the corresponding entries in the senti-
ment resources seem warranted. Our results show
further that all adverbs strengthen the polarity of
the context to different degrees. If confirmed on a
larger data set, this indicates that the intensifying
force of different adverbs should be reflected in
lexical resources, perhaps along an ordered scale.
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="conclusions">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999939705882353">
Two recent surveys give a detailed account of the
SL acquisition techniques (Feldman, 2013; Liu,
2012). We give only an overview of the related
work here. SLs are acquired by one of three meth-
ods. Manual tagging is performed by human an-
notators: e.g., OF, and AL. Dictionary-based ac-
quisition relies on a set of seed words that is ex-
panded by using external resources, such as Word-
Net: e.g., (Dragut et al., 2010; Hassan and Radev,
2010; Mohammad et al., 2009; Dragut et al., 2012;
Takamura et al., 2005). In corpus-based acquisi-
tion a set of seed words is expanded by using a
large corpus of documents (Feng et al., 2013; Lu
et al., 2011; Yu et al., 2013; Wu and Wen, 2010).
To our knowledge, none of these works include
the polarity intensifiers that we introduce in this
paper.
</bodyText>
<sectionHeader confidence="0.999314" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999621052631579">
S. Cerini, V. Compagnoni, A. Demontis, M. For-
mentelli, and G. Gandini, 2007. Language resources
and linguistic theory: Typology, second language
acquisition, English linguistics.
Eduard C. Dragut, Clement T. Yu, A. Prasad Sistla, and
Weiyi Meng. 2010. Construction of a sentimental
word dictionary. In CIKM, pages 1761–1764.
Eduard C. Dragut, Hong Wang, Clement Yu, Prasad
Sistla, and Weiyi Meng. 2012. Polarity consistency
checking for sentiment dictionaries. In ACL.
A. Esuli and F. Sebastiani. 2006. Sentiwordnet: A
publicly available lexical resource for opinion min-
ing. In LREC.
Ronen Feldman. 2013. Techniques and applications
for sentiment analysis. CACM, 56(4):82–89, April.
C. Fellbaum. 1998. WordNet: An On-Line Lexical
Database and Some of its Applications. MIT Press.
Song Feng, Jun Sak Kang, Polina Kuznetsova, and
Yejin Choi. 2013. Connotation lexicon: A dash of
sentiment beneath the surface meaning. In ACL.
Ahmed Hassan and Dragomir Radev. 2010. Identify-
ing text polarity using random walks. In ACL.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies. Morgan &amp; Claypool Publishers.
Yue Lu, Malu Castellanos, Umeshwar Dayal, and
ChengXiang Zhai. 2011. Automatic construction of
a context-aware sentiment lexicon: an optimization
approach. In WWW, pages 347–356. ACM.
Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
Dan Huang, Andrew Y. Ng, and Christopher Potts.
2011. Learning word vectors for sentiment analysis.
In ACL, pages 142–150.
Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009. Generating high-coverage semantic orienta-
tion lexicons from overtly marked words and a the-
saurus. In EMNLP.
B. Pang and L. Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In ACL.
Jan Svartvik, editor. 1991. Directions in Corpus Lin-
guistics. Nobel Symposium 82, Mouton de Gruyter.
M. Taboada and J. Grieve. 2004. Analyzing appraisal
automatically. In AAAI Spring Symposium.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words us-
ing spin model. In ACL, pages 133–140.
T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recog-
nizing contextual polarity in phrase-level sentiment
analysis. In HLT/EMNLP.
Yunfang Wu and Miaomiao Wen. 2010. Disambiguat-
ing dynamic sentiment ambiguous adjectives. In
COLING, pages 1191–1199.
Hongliang Yu, Zhi-Hong Deng, and Shiyingxue Li.
2013. Identifying sentiment words using an
optimization-based model without seedwords. In
ACL.
</reference>
<page confidence="0.999445">
41
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.952632">
<title confidence="0.999924">The Role of Adverbs in Sentiment Analysis</title>
<author confidence="0.997206">Eduard C Dragut Christiane Fellbaum</author>
<affiliation confidence="0.993532">Computer and Information Sciences Dept. Department of Computer Science Temple University Princeton University</affiliation>
<email confidence="0.999513">edragut@temple.edufellbaum@princeton.edu</email>
<abstract confidence="0.998072176470588">Sentiment Analysis, an important area of Natural Language Understanding, often relies on the assumption that lexemes carry inherent sentiment values, as reflected in specialized resources. We examine and measure the contribution that eight intensifying adverbs make to the sentiment value of sentences, as judged by human annotators. Our results show, first, that the intensifying adverbs are not themselves sentiment-laden but strengthen the sentiment conveyed by words in their contexts to different degrees. We consider the consequences for appropriate modifications of the representation of the adverbs in sentiment lexicons.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Cerini</author>
<author>V Compagnoni</author>
<author>A Demontis</author>
<author>M Formentelli</author>
<author>G Gandini</author>
</authors>
<title>Language resources and linguistic theory: Typology, second language acquisition, English linguistics.</title>
<date>2007</date>
<contexts>
<context position="2285" citStr="Cerini et al., 2007" startWordPosition="345" endWordPosition="348">utral” and “negative,” where positive corresponds to satisfaction or happiness and “negative” to dissatisfaction or unhappiness. Some work in SA further distinguishes degrees of positive and negative sentiment. SA often refers to lexical resources where words are annotated with a sentiment value. SentiWordNet (SWN) (Esuli and Sebastiani, 2006) assigns one of three sentiment values to each synset in WordNet (Fellbaum, 1998). Opinion Finder (OF) (Wilson et al., 2005) identifies the sentiment of the writer. Other resources include Appraisal Lexicon (AL) (Taboada and Grieve, 2004) and Micro-WNOp (Cerini et al., 2007). Much of this work relies on the assumption that specific lexemes (unique mappings of word forms and word meanings) carry an inherent sentiment value. This seems intuitively correct for words like enjoy (positive), pencil (neutral) and pain (negative). Other words may not carry inherent sentiment value yet, in context, contribute to that of the words they co-occur with or modify. One such class of words comprises what we call polarity intensifiers. In this preliminary study, we analyze the contribution of adverbial intensifiers to the sentiment value of the sentences in which they occur. Cons</context>
</contexts>
<marker>Cerini, Compagnoni, Demontis, Formentelli, Gandini, 2007</marker>
<rawString>S. Cerini, V. Compagnoni, A. Demontis, M. Formentelli, and G. Gandini, 2007. Language resources and linguistic theory: Typology, second language acquisition, English linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard C Dragut</author>
<author>Clement T Yu</author>
<author>A Prasad Sistla</author>
<author>Weiyi Meng</author>
</authors>
<title>Construction of a sentimental word dictionary.</title>
<date>2010</date>
<booktitle>In CIKM,</booktitle>
<pages>1761--1764</pages>
<marker>Dragut, Yu, Sistla, Meng, 2010</marker>
<rawString>Eduard C. Dragut, Clement T. Yu, A. Prasad Sistla, and Weiyi Meng. 2010. Construction of a sentimental word dictionary. In CIKM, pages 1761–1764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard C Dragut</author>
<author>Hong Wang</author>
<author>Clement Yu</author>
<author>Prasad Sistla</author>
<author>Weiyi Meng</author>
</authors>
<title>Polarity consistency checking for sentiment dictionaries.</title>
<date>2012</date>
<booktitle>In ACL.</booktitle>
<marker>Dragut, Wang, Yu, Sistla, Meng, 2012</marker>
<rawString>Eduard C. Dragut, Hong Wang, Clement Yu, Prasad Sistla, and Weiyi Meng. 2012. Polarity consistency checking for sentiment dictionaries. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Esuli</author>
<author>F Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="2010" citStr="Esuli and Sebastiani, 2006" startWordPosition="302" endWordPosition="305">their contexts. Our paper presents work that tries to take this legacy to heart. 2 Sentiment Analysis Broadly speaking, sentiment analysis (SA) attempts to automatically derive a writer’s “sentiment” about the topic of a text. “Sentiment” is usually categorized into “positive,” “neutral” and “negative,” where positive corresponds to satisfaction or happiness and “negative” to dissatisfaction or unhappiness. Some work in SA further distinguishes degrees of positive and negative sentiment. SA often refers to lexical resources where words are annotated with a sentiment value. SentiWordNet (SWN) (Esuli and Sebastiani, 2006) assigns one of three sentiment values to each synset in WordNet (Fellbaum, 1998). Opinion Finder (OF) (Wilson et al., 2005) identifies the sentiment of the writer. Other resources include Appraisal Lexicon (AL) (Taboada and Grieve, 2004) and Micro-WNOp (Cerini et al., 2007). Much of this work relies on the assumption that specific lexemes (unique mappings of word forms and word meanings) carry an inherent sentiment value. This seems intuitively correct for words like enjoy (positive), pencil (neutral) and pain (negative). Other words may not carry inherent sentiment value yet, in context, con</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>A. Esuli and F. Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
</authors>
<title>Techniques and applications for sentiment analysis.</title>
<date>2013</date>
<journal>CACM,</journal>
<volume>56</volume>
<issue>4</issue>
<publisher>MIT Press.</publisher>
<contexts>
<context position="11993" citStr="Feldman, 2013" startWordPosition="1953" endWordPosition="1954">t lexicons, these adverbs do not carry an inherent sentiment polarity, but merely alter the degree of the polarity of the constituents they modify; corrections of the corresponding entries in the sentiment resources seem warranted. Our results show further that all adverbs strengthen the polarity of the context to different degrees. If confirmed on a larger data set, this indicates that the intensifying force of different adverbs should be reflected in lexical resources, perhaps along an ordered scale. 5 Related Work Two recent surveys give a detailed account of the SL acquisition techniques (Feldman, 2013; Liu, 2012). We give only an overview of the related work here. SLs are acquired by one of three methods. Manual tagging is performed by human annotators: e.g., OF, and AL. Dictionary-based acquisition relies on a set of seed words that is expanded by using external resources, such as WordNet: e.g., (Dragut et al., 2010; Hassan and Radev, 2010; Mohammad et al., 2009; Dragut et al., 2012; Takamura et al., 2005). In corpus-based acquisition a set of seed words is expanded by using a large corpus of documents (Feng et al., 2013; Lu et al., 2011; Yu et al., 2013; Wu and Wen, 2010). To our knowled</context>
</contexts>
<marker>Feldman, 2013</marker>
<rawString>Ronen Feldman. 2013. Techniques and applications for sentiment analysis. CACM, 56(4):82–89, April. C. Fellbaum. 1998. WordNet: An On-Line Lexical Database and Some of its Applications. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Jun Sak Kang</author>
<author>Polina Kuznetsova</author>
<author>Yejin Choi</author>
</authors>
<title>Connotation lexicon: A dash of sentiment beneath the surface meaning.</title>
<date>2013</date>
<booktitle>In ACL.</booktitle>
<marker>Feng, Kang, Kuznetsova, Choi, 2013</marker>
<rawString>Song Feng, Jun Sak Kang, Polina Kuznetsova, and Yejin Choi. 2013. Connotation lexicon: A dash of sentiment beneath the surface meaning. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Dragomir Radev</author>
</authors>
<title>Identifying text polarity using random walks.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<marker>Hassan, Radev, 2010</marker>
<rawString>Ahmed Hassan and Dragomir Radev. 2010. Identifying text polarity using random walks. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="12005" citStr="Liu, 2012" startWordPosition="1955" endWordPosition="1956">se adverbs do not carry an inherent sentiment polarity, but merely alter the degree of the polarity of the constituents they modify; corrections of the corresponding entries in the sentiment resources seem warranted. Our results show further that all adverbs strengthen the polarity of the context to different degrees. If confirmed on a larger data set, this indicates that the intensifying force of different adverbs should be reflected in lexical resources, perhaps along an ordered scale. 5 Related Work Two recent surveys give a detailed account of the SL acquisition techniques (Feldman, 2013; Liu, 2012). We give only an overview of the related work here. SLs are acquired by one of three methods. Manual tagging is performed by human annotators: e.g., OF, and AL. Dictionary-based acquisition relies on a set of seed words that is expanded by using external resources, such as WordNet: e.g., (Dragut et al., 2010; Hassan and Radev, 2010; Mohammad et al., 2009; Dragut et al., 2012; Takamura et al., 2005). In corpus-based acquisition a set of seed words is expanded by using a large corpus of documents (Feng et al., 2013; Lu et al., 2011; Yu et al., 2013; Wu and Wen, 2010). To our knowledge, none of </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Malu Castellanos</author>
<author>Umeshwar Dayal</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Automatic construction of a context-aware sentiment lexicon: an optimization approach.</title>
<date>2011</date>
<booktitle>In WWW,</booktitle>
<pages>347--356</pages>
<publisher>ACM.</publisher>
<marker>Lu, Castellanos, Dayal, Zhai, 2011</marker>
<rawString>Yue Lu, Malu Castellanos, Umeshwar Dayal, and ChengXiang Zhai. 2011. Automatic construction of a context-aware sentiment lexicon: an optimization approach. In WWW, pages 347–356. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew L Maas</author>
<author>Raymond E Daly</author>
<author>Peter T Pham</author>
<author>Dan Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Learning word vectors for sentiment analysis.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>142--150</pages>
<contexts>
<context position="5029" citStr="Maas et al., 2011" startWordPosition="803" endWordPosition="806">e adverb appears in both positive and negative sentiment-bearing sentences (S1 is negative and S2 is positive); (2) its removal from either S1 or S2 does not change the overall polarity of the sentence; (3) intuitively, S1 has a stronger negative polarity value than S1’ and S2 has a stronger positive polarity value than S2’. We conduct a preliminary study of polarity intensifier words and show that they all have characteristics (1) - (3). We examine data with eight different adverbs (Table 1). 3.1 Data We extracted sentences containing the target adverbs from a corpus of 50,000 movie reviews (Maas et al., 2011). Each sentence is extracted from a review that is labeled either “positive” or “negative” and correlated with a star rating. We manually inspected the sentences and discarded those where the target adverb was used in a modal sense, as in Seriously, there was not one respectable character in the entire script while retaining sentences like There is no doubt that Alfred Hitchcock was a seriously talented director. For each adverb, we retained ten sentences from positive and negative reviews each, for a total 160 sentences. We copied the original sentences, removed the adverbs without making add</context>
</contexts>
<marker>Maas, Daly, Pham, Huang, Ng, Potts, 2011</marker>
<rawString>Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In ACL, pages 142–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Cody Dunne</author>
<author>Bonnie Dorr</author>
</authors>
<title>Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.</title>
<date>2009</date>
<booktitle>In EMNLP.</booktitle>
<marker>Mohammad, Dunne, Dorr, 2009</marker>
<rawString>Saif Mohammad, Cody Dunne, and Bonnie Dorr. 2009. Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="5944" citStr="Pang and Lee, 2004" startWordPosition="956" endWordPosition="959"> entire script while retaining sentences like There is no doubt that Alfred Hitchcock was a seriously talented director. For each adverb, we retained ten sentences from positive and negative reviews each, for a total 160 sentences. We copied the original sentences, removed the adverbs without making additional alterations. Our final dataset consisted of a total of 320 sentences with 160 sentence pairs whose members were identical except for the presence or absence of the target adverbs. Below is an example of a sentence pair, where the original sentence with the adverbs was pre-classified by (Pang and Lee, 2004) as carrying positive sentiment. 1. I was absolutely delighted by the simple story and amazing animation. 2. I was delighted by the simple story and amazing animation. 3.2 Collecting Judgments via Crowdsourcing We submitted single sentences (not pairs) to be annotated with sentiment scores for crowdsourcing, using Amazon Mechanical Turk (AMT). To avoid any bias we shuffled the sentences and displayed them individually. We asked the Turkers to select, for each sentence, one of five sentiment scores: strong positive (2), positive (1), neutral (0), negative (-1), strong negative (-2). Each senten</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>B. Pang and L. Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In ACL.</rawString>
</citation>
<citation valid="true">
<date>1991</date>
<booktitle>Directions in Corpus Linguistics. Nobel Symposium 82, Mouton de Gruyter.</booktitle>
<editor>Jan Svartvik, editor.</editor>
<marker>1991</marker>
<rawString>Jan Svartvik, editor. 1991. Directions in Corpus Linguistics. Nobel Symposium 82, Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Taboada</author>
<author>J Grieve</author>
</authors>
<title>Analyzing appraisal automatically. In</title>
<date>2004</date>
<publisher>AAAI Spring Symposium.</publisher>
<contexts>
<context position="2248" citStr="Taboada and Grieve, 2004" startWordPosition="339" endWordPosition="342">s usually categorized into “positive,” “neutral” and “negative,” where positive corresponds to satisfaction or happiness and “negative” to dissatisfaction or unhappiness. Some work in SA further distinguishes degrees of positive and negative sentiment. SA often refers to lexical resources where words are annotated with a sentiment value. SentiWordNet (SWN) (Esuli and Sebastiani, 2006) assigns one of three sentiment values to each synset in WordNet (Fellbaum, 1998). Opinion Finder (OF) (Wilson et al., 2005) identifies the sentiment of the writer. Other resources include Appraisal Lexicon (AL) (Taboada and Grieve, 2004) and Micro-WNOp (Cerini et al., 2007). Much of this work relies on the assumption that specific lexemes (unique mappings of word forms and word meanings) carry an inherent sentiment value. This seems intuitively correct for words like enjoy (positive), pencil (neutral) and pain (negative). Other words may not carry inherent sentiment value yet, in context, contribute to that of the words they co-occur with or modify. One such class of words comprises what we call polarity intensifiers. In this preliminary study, we analyze the contribution of adverbial intensifiers to the sentiment value of th</context>
</contexts>
<marker>Taboada, Grieve, 2004</marker>
<rawString>M. Taboada and J. Grieve. 2004. Analyzing appraisal automatically. In AAAI Spring Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>133--140</pages>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In ACL, pages 133–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP.</booktitle>
<contexts>
<context position="2134" citStr="Wilson et al., 2005" startWordPosition="323" endWordPosition="326">nalysis (SA) attempts to automatically derive a writer’s “sentiment” about the topic of a text. “Sentiment” is usually categorized into “positive,” “neutral” and “negative,” where positive corresponds to satisfaction or happiness and “negative” to dissatisfaction or unhappiness. Some work in SA further distinguishes degrees of positive and negative sentiment. SA often refers to lexical resources where words are annotated with a sentiment value. SentiWordNet (SWN) (Esuli and Sebastiani, 2006) assigns one of three sentiment values to each synset in WordNet (Fellbaum, 1998). Opinion Finder (OF) (Wilson et al., 2005) identifies the sentiment of the writer. Other resources include Appraisal Lexicon (AL) (Taboada and Grieve, 2004) and Micro-WNOp (Cerini et al., 2007). Much of this work relies on the assumption that specific lexemes (unique mappings of word forms and word meanings) carry an inherent sentiment value. This seems intuitively correct for words like enjoy (positive), pencil (neutral) and pain (negative). Other words may not carry inherent sentiment value yet, in context, contribute to that of the words they co-occur with or modify. One such class of words comprises what we call polarity intensifi</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunfang Wu</author>
<author>Miaomiao Wen</author>
</authors>
<title>Disambiguating dynamic sentiment ambiguous adjectives.</title>
<date>2010</date>
<booktitle>In COLING,</booktitle>
<pages>1191--1199</pages>
<marker>Wu, Wen, 2010</marker>
<rawString>Yunfang Wu and Miaomiao Wen. 2010. Disambiguating dynamic sentiment ambiguous adjectives. In COLING, pages 1191–1199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongliang Yu</author>
<author>Zhi-Hong Deng</author>
<author>Shiyingxue Li</author>
</authors>
<title>Identifying sentiment words using an optimization-based model without seedwords.</title>
<date>2013</date>
<booktitle>In ACL.</booktitle>
<marker>Yu, Deng, Li, 2013</marker>
<rawString>Hongliang Yu, Zhi-Hong Deng, and Shiyingxue Li. 2013. Identifying sentiment words using an optimization-based model without seedwords. In ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>