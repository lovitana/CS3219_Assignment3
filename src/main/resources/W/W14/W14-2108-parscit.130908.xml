<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002942">
<title confidence="0.995294">
Automated argumentation mining to the rescue? Envisioning
argumentation and decision-making support for debates in open online
collaboration communities
</title>
<author confidence="0.993494">
Jodi Schneider∗
</author>
<affiliation confidence="0.944778">
INRIA Sophia Antipolis, France
</affiliation>
<email confidence="0.996313">
jodi.schneider@inria.fr
</email>
<sectionHeader confidence="0.993833" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954214285714">
Argumentation mining, a relatively new
area of discourse analysis, involves auto-
matically identifying and structuring argu-
ments. Following a basic introduction to
argumentation, we describe a new possible
domain for argumentation mining: debates
in open online collaboration communities.
Based on our experience with manual an-
notation of arguments in debates, we envi-
sion argumentation mining as the basis for
three kinds of support tools, for authoring
more persuasive arguments, finding weak-
nesses in others’ arguments, and summa-
rizing a debate’s overall conclusions.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999936777777778">
Argumentation mining, a relatively new area of
discourse analysis, involves automatically identi-
fying and structuring arguments. Following a ba-
sic introduction to argumentation, we describe on-
line debates as a future application area for argu-
mentation mining, describing how we have man-
ually identified and structured argumentation, and
how we envision argumentation mining being ap-
plied to support these debates in the future.
</bodyText>
<subsectionHeader confidence="0.995515">
1.1 What is an argument
</subsectionHeader>
<bodyText confidence="0.999777">
Informally, an argument is a communication pre-
senting reasons for accepting a conclusion. Unlike
proofs that lead step-by-step from premises with
logical justifications for a conclusion, arguments
are non-monotonic and can be disproven. Argu-
ments may use various approaches including gen-
eralization, analogy, inference, and prediction.
</bodyText>
<footnote confidence="0.8498778">
∗This work was carried out during the tenure of an
ERCIM “Alain Bensoussan” Fellowship Programme. The re-
search leading to these results has received funding from the
European Union Seventh Framework Programme (FP7/2007-
2013) under grant agreement no 246016.
</footnote>
<figureCaption confidence="0.999888">
Figure 1: The simplest possible argument.
</figureCaption>
<bodyText confidence="0.9999758">
The simplest possible argument connects two
Statements by means of an Inference Rule (Fig-
ure 1). Inference Rules are functions that input
one or more Statements (the premises) and return
one or more Statements (the conclusions).
</bodyText>
<subsectionHeader confidence="0.986851">
1.2 More complex arguments
</subsectionHeader>
<bodyText confidence="0.9688665">
Far more complex arguments can be formed. Ar-
bitrary numbers of arguments can be joined into
a larger and more complex argument. Useful ter-
minology is introduced by (Wyner et al., 2008),
who reserve the term argument to refer to the sim-
plest kind: non-decomposable arguments. They
distinguish cases which support a single conclu-
sion (see Figure 2) from debates which argue for
and against a single conclusion.
Figure 2: Cases support a single conclusion. Cases
may (a) use multiple, independent premises to
support a single conclusion; (b) draw an inter-
mediate conclusion, and use it as an additional
premise in order to support a final conclusion; or
(c) require two linked premises (both required as
input to the inference rule) to support a conclusion.
Figure 3 shows a simple debate, where two ar-
guments attack one another. There are three ways
</bodyText>
<figure confidence="0.9607883">
Sin
Inference Rule
Sout
(e) (b) (c)
1
3
2 1
2
3
1
</figure>
<page confidence="0.7570035">
2
59
</page>
<note confidence="0.347045">
Proceedings of the First Workshop on Argumentation Mining, pages 59–63,
Baltimore, Maryland USA, June 26, 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.992675">
Figure 3: Debates argue for and against a single
conclusion. This kind of attack is called a rebuttal.
</figureCaption>
<bodyText confidence="0.99931">
of attacking an argument: attacking a premise
(known as undermining), attacking a conclusion
(known as rebutting), and attacking an inference
(known as undercutting), following (Prakken,
2010).1
</bodyText>
<subsectionHeader confidence="0.910975">
1.3 Inference Rules
</subsectionHeader>
<bodyText confidence="0.999964181818182">
Argumentation schemes, e.g. (Walton et al., 2008)
are one way of expressing Inference Rules. These
are patterns for arguing which are stated ab-
stractly: to use an argumentation scheme, it must
be instantiated with details. To indicate possible
flaws in reasoning, associated with each scheme
there are critical questions pointing to the possible
counterarguments.
We next introduce an example from our own
work, where automated argumentation mining
could be used.
</bodyText>
<sectionHeader confidence="0.5143935" genericHeader="method">
2 Rationale-based debate in open online
communities
</sectionHeader>
<bodyText confidence="0.9932931">
One place where argumentation mining could be
applied is in rationale-based debate in open online
communities. The Web has enabled large-scale
collaboration, even among people who may never
meet face-to-face. A large number of participants
present their views and reasoning to make deci-
sions for open, online collaborative software and
knowledge development in Mozilla, Wikipedia,
OpenStreetMap, etc. In these groups, asyn-
chronous textual debates are the basis for decision
making. Participants argue for decisions based on
rationales, since the reasons for opinions, rather
than majority votes or aggregate sentiment, jus-
tify decisions. Thus large-scale decision support
in these communities should make evident not just
the overall tendency of the group (as in opinion
mining) but rather the arguments made, focusing
1Rebut and undercut are drawn from the well-known
work of (Pollock, 1994); Prakken credits undermining
to (Vreeswijk, 1993) and (Elvang-Gøransson et al., 1993).
especially on the rationales, or reasons given for a
preferred outcome.
In our work, we have analyzed a corpus of
debates, to understand how the English-language
version of Wikipedia makes decisions about which
articles to include and exclude from the encyclo-
pedia. We used two approaches to argumentation
theory to annotate asynchronous messages in each
debate, in iterative multiparty annotation experi-
ments (Schneider, 2014).
</bodyText>
<subsectionHeader confidence="0.999475">
2.1 Analysis using argumentation schemes
</subsectionHeader>
<bodyText confidence="0.999651259259259">
First, we used Walton’s argumentation schemes
(outlined in Ch. 9 of (Walton et al., 2008)) in or-
der to annotate the arguments, focusing on the in-
ternal reasoning of each message. First one per-
son (this author) annotated all the arguments found
in the corpus against Walton’s 60 schemes, find-
ing 1213 arguments in 741 messages (Schneider
et al., 2013). Then, we focused on the subset
of 14 argumentation schemes that appeared more
than 2% of the time, with iterative, multiparty
annotation. There was a sharp divide between
the two most prevalent argument types–Argument
from Evidence to Hypothesis (19%) and Argument
from Rules (17%)–and the remaining 12 types that
appeared from 2-4% of the time.
Besides these patterns, we found statistically
significant differences between how experts and
novices in the community argued in our corpus
of debates. Experts were more likely to use Ar-
gument from Precedent, while novices (who had
little experience in the debates and in the wider
Wikipedia community) were more likely to use
several argumentation schemes that the commu-
nity viewed as less sound bases for decision mak-
ing.2 These included Argumentation from Values,
Argumentation from Cause to Effect, and Argu-
ment from Analogy.
</bodyText>
<subsectionHeader confidence="0.999511">
2.2 Analysis using factors analysis
</subsectionHeader>
<bodyText confidence="0.997658333333333">
Second, we used a very different approach, based
on factors analysis (Ashley, 1991) and dimensions
theory (Bench-Capon and Rissland, 2001), which
</bodyText>
<footnote confidence="0.853603444444444">
2Our analysis of acceptability of arguments drew from
community documentation and took community responses
to messages into account. For instance, Argumentation from
Values might be countered by a messages saying “Whether
you personally like an article or its subject, is totally
irrelevant.” (This exchange appeared in our corpus in fact
http://en.wikipedia.org/wiki/Wikipedia:
Articles_for_deletion/Log/2011_January_
29.)
</footnote>
<page confidence="0.408226">
2
</page>
<figure confidence="0.92757625">
1
Attack
3
2
</figure>
<page confidence="0.97156">
60
</page>
<bodyText confidence="0.999972967741935">
have most commonly been used in case-based rea-
soning. We iteratively derived four factors im-
portant in the discussions: Notability, Sources,
Maintenance, and Bias (Schneider et al., 2012).
This was an easier annotation task, with stronger
inter-annotator agreement than for Walton’s ar-
gumentation schemes: factors analysis had Co-
hen’s kappa (Cohen, 1960) of .64-.82 depending
on the factor (Schneider et al., 2012), versus .48
for Walton’s argumentation schemes (Schneider et
al., 2013)). Factors provide a good way to orga-
nize the debate; filtering discussions based on each
factor can show the rationale topic by topic, which
supported decision making in a pilot user-based
evaluation (Schneider, 2014).
We can also identify the misunderstandings that
newcomers have about which factors are impor-
tant, and about what kind of support is neces-
sary to justify claims about whether a factor holds.
When an article is unacceptable because it lacks
reliable sources, it is not enough to counter that
someone will publish about this website when it
gets out of beta testing.3 This newcomer’s argu-
ment fails to convincingly establish that there are
reliable sources (because for Wikipedia, a reliable
source should be published, independent, and sub-
ject to full editorial control), and may make things
worse because it suggests that the sources are not
independent. Rather, a convincing counterargu-
ment would explicitly address how the most rel-
evant criteria are met.
</bodyText>
<sectionHeader confidence="0.8546285" genericHeader="method">
3 Envisioned applications of
argumentation mining
</sectionHeader>
<bodyText confidence="0.9999348">
The manual annotations described above, of ar-
gumentation schemes and of factors, suggest sev-
eral possibilities for automation. Scalable pro-
cesses for analyzing messages are needed since
Wikipedia has roughly 500 debates each week
about deleting borderline articles. Argumentation
mining could be the basis for several support tools,
helping participants write more persuasive argu-
ments, find weaknesses in others’ arguments, and
summarize the overall conclusions of the debate.
First consider how we might give participants
feedback about their arguments. From our re-
search, we know which argumentation schemes
are viewed as acceptable and persuasive within the
community. If real-time algorithms could identify
</bodyText>
<footnote confidence="0.8454065">
3This is a real argument from a newcomer from our cor-
pus, slightly reworded for clarity.
</footnote>
<bodyText confidence="0.999968735294118">
the argumentation schemes used in the main argu-
ment, authors could be given personalized feed-
back even before their message is posted to the
discussion. When the argumentation scheme used
in a draft message is not generally accepted, the
author could be warned that their message might
not be persuasive, and given personalized sugges-
tions. Thus debate participants might be nudged
into writing more persuasive arguments.
Next consider how we could help participants
find weaknesses in others’ arguments. Automat-
ically listing critical questions might benefit the
discussion. Critical questions point out the pos-
sible weaknesses of an argument, based on the ar-
gumentation scheme pattern it uses. Listing these
questions in concrete and contextualized form
(drawing on the premises, inference rules, and
conclusions to instantiate and contextualize them)
would encourage participants to consider the pos-
sible flaws in reasoning and might prompt partici-
pants to request answers within the debate. In the
authoring process, supplying the critical questions
associated with argumentation schemes might also
help the author (who could consider elaborating
before submitting a message).
Finally, we could envision argumentation min-
ing being used to summarize the debate. Macro-
argumentation, such as the factors analysis de-
scribed above, would be a natural choice for sum-
marization, as it has already proven useful for fil-
tering discussions. A more reasoning-intensive
approach would be to calculate consistent out-
comes (Wyner and van Engers, 2010), if debates
can be easily formalized.
</bodyText>
<subsectionHeader confidence="0.992735">
3.1 Challenges for argumentation mining
</subsectionHeader>
<bodyText confidence="0.999939909090909">
In previous work, argumentation schemes have
been classified in constrained domains, especially
in legal argumentation (Mochales and Moens,
2011) and by using (Feng, 2010; Feng and Hirst,
2011) the Araucaria corpus (Katzav et al., 2004).4
Each of our envisioned applications of argu-
mentation has certain requirements. Automati-
cally detecting the argumentation schemes used in
a message could be used for supporting authoring
and finding weaknesses of arguments, which focus
on the interior of each message. In order to ask the
</bodyText>
<footnote confidence="0.9358374">
4Further work is needed on argument scheme prevalence,
which seems to vary by domain. Only 3 of Feng’s 5 ‘most
common argumentation schemes’ appear in the top 14 most
common schemes in our corpus, excluding Argument from
Example and Argument from Cause to Effect.
</footnote>
<page confidence="0.998973">
61
</page>
<bodyText confidence="0.999953529411765">
appropriate critical questions, the premises, con-
clusions, and inference rules would first need to
be detected. To get at the point of each message,
the macro-level argumentation (for instance using
factors and dimensions) would be useful for sum-
marizing the debate, especially if we record ratio-
nales.
Another challenge is to create scaleable archi-
tectures for real-time or batch reprocessing of ar-
gumentation mining on the Web. In our scenar-
ios above, support for authoring arguments would
require real-time feedback (i.e. within minutes).
Slower batch processing would be useful for the
two other scenarios (support in challenging argu-
ments with critical questions; support for summa-
rizing debates) since Wikipedia’s debates are gen-
erally open for 7 days.
</bodyText>
<subsectionHeader confidence="0.993997">
3.2 Related scenarios
</subsectionHeader>
<bodyText confidence="0.999952263157895">
This is a single use case, but it represents a
wide array of related ones. Open source and
open knowledge projects are full of decision mak-
ing discussions available widely in textual form.
Rhetorical studies of them so far take place on
a qualitative, discursive level. Examples include
dissent and rhetorical devices in bug reporting (Ko
and Chilana, 2011) and how Python listservs
select enhancement proposals (Barcellini et al.,
2005). Interestingly, the role of a participant in the
Python community is related to the kinds of mes-
sage they quote (Syntheses, Disagreements, Pro-
posals, or Agreements), and Syntheses and Dis-
agreements are the most quoted. The organiza-
tional relevance of these open decision making
discussions in collaborative communities makes
them a promising target for support, and argumen-
tation mining technology is an appropriate tool to
deploy towards that end.
</bodyText>
<sectionHeader confidence="0.999587" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999983888888889">
This paper detailed how automated argumentation
mining could be leveraged to support open on-
line communities in making decisions through on-
line debates about rationale. We first gave a ba-
sic overview of argumentation structures, describ-
ing arguments as consisting of Statements, Infer-
ence Rules, and (possibly) Attacks. Then we de-
scribed our own work on manual identification
of argumentation schemes in Wikipedia informa-
tion quality debates. We envisioned three kinds
support tools that could be developed from auto-
mated argumentation mining in the future, for au-
thoring more persuasive arguments, finding weak-
nesses in others’ arguments, and summarizing a
debate’s overall conclusions. Open online com-
munities are a wide area of application where ar-
gumentation mining could help participants reason
collectively.
</bodyText>
<sectionHeader confidence="0.998452" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999449951219512">
Kevin D Ashley. 1991. Modeling Legal Arguments:
Reasoning with Cases and Hypotheticals. MIT
Press.
Flore Barcellini, Franc¸oise D´etienne, Jean-Marie
Burkhardt, and Warren Sack. 2005. A study of on-
line discussions in an open-source software commu-
nity. In Communities and Technologies 2005, pages
301–320. Springer.
Trevor J M Bench-Capon and Edwina L Rissland.
2001. Back to the future: Dimensions revisited. In
Proceedings of JURIX 2001, pages 41–52.
Jacob Cohen. 1960. A coefficient of agreement
for nominal scales. Educational and psychological
measurement, 20(1):37–46.
Morten Elvang-Gøransson, Paul J Krause, and John
Fox. 1993. Acceptability of arguments as ‘logi-
cal uncertainty’. In Symbolic and Quantitative Ap-
proaches to Reasoning and Uncertainty, pages 85–
90. Springer.
Vanessa Wei Feng and Graeme Hirst. 2011. Clas-
sifying arguments by scheme. In Proceedings
of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies–Volume 1, pages 987–996.
Vanessa Wei Feng. 2010. Classifying arguments by
scheme. Master’s thesis, University of Toronto.
Joel Katzav, Chris Reed, and Glenn Rowe. 2004. Ar-
gument Research Corpus. In Proceedings of the
2003 Conference on Practical Applications in Lan-
guage and Computers, pages 229–239. Peter Lang.
Andrew J Ko and Parmit K Chilana. 2011. Design,
discussion, and dissent in open bug reports. In Pro-
ceedings of the 2011 iConference, pages 106–113.
Raquel Mochales and Marie-Francine Moens. 2011.
Argumentation mining. Artificial Intelligence and
Law, 19(1):1–22.
John L Pollock. 1994. Justification and defeat. Artifi-
cialIntelligence, 67(2):377–407.
Henry Prakken. 2010. An abstract framework for ar-
gumentation with structured arguments. Argument
and Computation, 1(2):93–124.
</reference>
<page confidence="0.980827">
62
</page>
<reference confidence="0.99979053125">
Jodi Schneider, Alexandre Passant, and Stefan Decker.
2012. Deletion discussions in Wikipedia: Decision
factors and outcomes. In Proceedings of the Interna-
tional Symposium on Wikis and Open Collaboration,
pages 17:1–17:10.
Jodi Schneider, Krystian Samp, Alexandre Passant, and
Stefan Decker. 2013. Arguments about deletion:
How experience improves the acceptability of argu-
ments in ad-hoc online task groups. In Proceedings
of the ACM conference on Computer Supported Co-
operative Work, pages 1069–1080.
Jodi Schneider. 2014. Identifying, Annotating, and Fil-
tering Arguments and Opinions in Open Collabora-
tion Systems. Ph.D. dissertation, Digital Enterprise
Research Institute, National University of Ireland,
Galway. Corpus and supplementary material also
available online at http://purl.org/jsphd.
Gerard Vreeswijk. 1993. Studies in Defeasible Argu-
mentation. Ph.D. dissertation, Free University Am-
sterdam.
Douglas Walton, Chris Reed, and Fabrizio Macagno.
2008. Argumentation Schemes. Cambridge.
Adam Wyner and Tom van Engers. 2010. To-
wards web-based mass argumentation in natural lan-
guage. In Proceedings of Knowledge Engineering
and Knowledge Management 2010 Poster and Demo
Track.
Adam Z Wyner, Trevor J Bench-Capon, and Katie
Atkinson. 2008. Three senses of “Argument”.
In Computable Models of the Law: Languages,
Dialogues, Games, Ontologies, pages 146–161.
Springer-Verlag.
</reference>
<page confidence="0.999462">
63
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.682200">
<title confidence="0.855547333333333">Automated argumentation mining to the rescue? argumentation and decision-making support for debates in open collaboration communities</title>
<author confidence="0.796523">INRIA Sophia Antipolis</author>
<email confidence="0.971158">jodi.schneider@inria.fr</email>
<abstract confidence="0.97519175">Argumentation mining, a relatively new area of discourse analysis, involves automatically identifying and structuring argu-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kevin D Ashley</author>
</authors>
<title>Modeling Legal Arguments: Reasoning with Cases and Hypotheticals.</title>
<date>1991</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6859" citStr="Ashley, 1991" startWordPosition="1038" endWordPosition="1039">istically significant differences between how experts and novices in the community argued in our corpus of debates. Experts were more likely to use Argument from Precedent, while novices (who had little experience in the debates and in the wider Wikipedia community) were more likely to use several argumentation schemes that the community viewed as less sound bases for decision making.2 These included Argumentation from Values, Argumentation from Cause to Effect, and Argument from Analogy. 2.2 Analysis using factors analysis Second, we used a very different approach, based on factors analysis (Ashley, 1991) and dimensions theory (Bench-Capon and Rissland, 2001), which 2Our analysis of acceptability of arguments drew from community documentation and took community responses to messages into account. For instance, Argumentation from Values might be countered by a messages saying “Whether you personally like an article or its subject, is totally irrelevant.” (This exchange appeared in our corpus in fact http://en.wikipedia.org/wiki/Wikipedia: Articles_for_deletion/Log/2011_January_ 29.) 2 1 Attack 3 2 60 have most commonly been used in case-based reasoning. We iteratively derived four factors impor</context>
</contexts>
<marker>Ashley, 1991</marker>
<rawString>Kevin D Ashley. 1991. Modeling Legal Arguments: Reasoning with Cases and Hypotheticals. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Flore Barcellini</author>
<author>Franc¸oise D´etienne</author>
<author>Jean-Marie Burkhardt</author>
<author>Warren Sack</author>
</authors>
<title>A study of online discussions in an open-source software community.</title>
<date>2005</date>
<booktitle>In Communities and Technologies</booktitle>
<pages>301--320</pages>
<publisher>Springer.</publisher>
<marker>Barcellini, D´etienne, Burkhardt, Sack, 2005</marker>
<rawString>Flore Barcellini, Franc¸oise D´etienne, Jean-Marie Burkhardt, and Warren Sack. 2005. A study of online discussions in an open-source software community. In Communities and Technologies 2005, pages 301–320. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor J M Bench-Capon</author>
<author>Edwina L Rissland</author>
</authors>
<title>Back to the future: Dimensions revisited.</title>
<date>2001</date>
<booktitle>In Proceedings of JURIX</booktitle>
<pages>41--52</pages>
<contexts>
<context position="6914" citStr="Bench-Capon and Rissland, 2001" startWordPosition="1043" endWordPosition="1046">ween how experts and novices in the community argued in our corpus of debates. Experts were more likely to use Argument from Precedent, while novices (who had little experience in the debates and in the wider Wikipedia community) were more likely to use several argumentation schemes that the community viewed as less sound bases for decision making.2 These included Argumentation from Values, Argumentation from Cause to Effect, and Argument from Analogy. 2.2 Analysis using factors analysis Second, we used a very different approach, based on factors analysis (Ashley, 1991) and dimensions theory (Bench-Capon and Rissland, 2001), which 2Our analysis of acceptability of arguments drew from community documentation and took community responses to messages into account. For instance, Argumentation from Values might be countered by a messages saying “Whether you personally like an article or its subject, is totally irrelevant.” (This exchange appeared in our corpus in fact http://en.wikipedia.org/wiki/Wikipedia: Articles_for_deletion/Log/2011_January_ 29.) 2 1 Attack 3 2 60 have most commonly been used in case-based reasoning. We iteratively derived four factors important in the discussions: Notability, Sources, Maintenan</context>
</contexts>
<marker>Bench-Capon, Rissland, 2001</marker>
<rawString>Trevor J M Bench-Capon and Edwina L Rissland. 2001. Back to the future: Dimensions revisited. In Proceedings of JURIX 2001, pages 41–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and psychological measurement,</booktitle>
<pages>20--1</pages>
<contexts>
<context position="7718" citStr="Cohen, 1960" startWordPosition="1157" endWordPosition="1158">untered by a messages saying “Whether you personally like an article or its subject, is totally irrelevant.” (This exchange appeared in our corpus in fact http://en.wikipedia.org/wiki/Wikipedia: Articles_for_deletion/Log/2011_January_ 29.) 2 1 Attack 3 2 60 have most commonly been used in case-based reasoning. We iteratively derived four factors important in the discussions: Notability, Sources, Maintenance, and Bias (Schneider et al., 2012). This was an easier annotation task, with stronger inter-annotator agreement than for Walton’s argumentation schemes: factors analysis had Cohen’s kappa (Cohen, 1960) of .64-.82 depending on the factor (Schneider et al., 2012), versus .48 for Walton’s argumentation schemes (Schneider et al., 2013)). Factors provide a good way to organize the debate; filtering discussions based on each factor can show the rationale topic by topic, which supported decision making in a pilot user-based evaluation (Schneider, 2014). We can also identify the misunderstandings that newcomers have about which factors are important, and about what kind of support is necessary to justify claims about whether a factor holds. When an article is unacceptable because it lacks reliable </context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and psychological measurement, 20(1):37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morten Elvang-Gøransson</author>
<author>Paul J Krause</author>
<author>John Fox</author>
</authors>
<title>Acceptability of arguments as ‘logical uncertainty’.</title>
<date>1993</date>
<booktitle>In Symbolic and Quantitative Approaches to Reasoning and Uncertainty,</booktitle>
<pages>85--90</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5039" citStr="Elvang-Gøransson et al., 1993" startWordPosition="751" endWordPosition="754">velopment in Mozilla, Wikipedia, OpenStreetMap, etc. In these groups, asynchronous textual debates are the basis for decision making. Participants argue for decisions based on rationales, since the reasons for opinions, rather than majority votes or aggregate sentiment, justify decisions. Thus large-scale decision support in these communities should make evident not just the overall tendency of the group (as in opinion mining) but rather the arguments made, focusing 1Rebut and undercut are drawn from the well-known work of (Pollock, 1994); Prakken credits undermining to (Vreeswijk, 1993) and (Elvang-Gøransson et al., 1993). especially on the rationales, or reasons given for a preferred outcome. In our work, we have analyzed a corpus of debates, to understand how the English-language version of Wikipedia makes decisions about which articles to include and exclude from the encyclopedia. We used two approaches to argumentation theory to annotate asynchronous messages in each debate, in iterative multiparty annotation experiments (Schneider, 2014). 2.1 Analysis using argumentation schemes First, we used Walton’s argumentation schemes (outlined in Ch. 9 of (Walton et al., 2008)) in order to annotate the arguments, f</context>
</contexts>
<marker>Elvang-Gøransson, Krause, Fox, 1993</marker>
<rawString>Morten Elvang-Gøransson, Paul J Krause, and John Fox. 1993. Acceptability of arguments as ‘logical uncertainty’. In Symbolic and Quantitative Approaches to Reasoning and Uncertainty, pages 85– 90. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Wei Feng</author>
<author>Graeme Hirst</author>
</authors>
<title>Classifying arguments by scheme.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies–Volume</booktitle>
<volume>1</volume>
<pages>987--996</pages>
<contexts>
<context position="11490" citStr="Feng and Hirst, 2011" startWordPosition="1726" endWordPosition="1729"> could envision argumentation mining being used to summarize the debate. Macroargumentation, such as the factors analysis described above, would be a natural choice for summarization, as it has already proven useful for filtering discussions. A more reasoning-intensive approach would be to calculate consistent outcomes (Wyner and van Engers, 2010), if debates can be easily formalized. 3.1 Challenges for argumentation mining In previous work, argumentation schemes have been classified in constrained domains, especially in legal argumentation (Mochales and Moens, 2011) and by using (Feng, 2010; Feng and Hirst, 2011) the Araucaria corpus (Katzav et al., 2004).4 Each of our envisioned applications of argumentation has certain requirements. Automatically detecting the argumentation schemes used in a message could be used for supporting authoring and finding weaknesses of arguments, which focus on the interior of each message. In order to ask the 4Further work is needed on argument scheme prevalence, which seems to vary by domain. Only 3 of Feng’s 5 ‘most common argumentation schemes’ appear in the top 14 most common schemes in our corpus, excluding Argument from Example and Argument from Cause to Effect. 61</context>
</contexts>
<marker>Feng, Hirst, 2011</marker>
<rawString>Vanessa Wei Feng and Graeme Hirst. 2011. Classifying arguments by scheme. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies–Volume 1, pages 987–996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Wei Feng</author>
</authors>
<title>Classifying arguments by scheme. Master’s thesis,</title>
<date>2010</date>
<institution>University of Toronto.</institution>
<contexts>
<context position="11467" citStr="Feng, 2010" startWordPosition="1724" endWordPosition="1725"> Finally, we could envision argumentation mining being used to summarize the debate. Macroargumentation, such as the factors analysis described above, would be a natural choice for summarization, as it has already proven useful for filtering discussions. A more reasoning-intensive approach would be to calculate consistent outcomes (Wyner and van Engers, 2010), if debates can be easily formalized. 3.1 Challenges for argumentation mining In previous work, argumentation schemes have been classified in constrained domains, especially in legal argumentation (Mochales and Moens, 2011) and by using (Feng, 2010; Feng and Hirst, 2011) the Araucaria corpus (Katzav et al., 2004).4 Each of our envisioned applications of argumentation has certain requirements. Automatically detecting the argumentation schemes used in a message could be used for supporting authoring and finding weaknesses of arguments, which focus on the interior of each message. In order to ask the 4Further work is needed on argument scheme prevalence, which seems to vary by domain. Only 3 of Feng’s 5 ‘most common argumentation schemes’ appear in the top 14 most common schemes in our corpus, excluding Argument from Example and Argument f</context>
</contexts>
<marker>Feng, 2010</marker>
<rawString>Vanessa Wei Feng. 2010. Classifying arguments by scheme. Master’s thesis, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Katzav</author>
<author>Chris Reed</author>
<author>Glenn Rowe</author>
</authors>
<title>Argument Research Corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2003 Conference on Practical Applications in Language and Computers,</booktitle>
<pages>229--239</pages>
<publisher>Peter Lang.</publisher>
<contexts>
<context position="11533" citStr="Katzav et al., 2004" startWordPosition="1733" endWordPosition="1736">sed to summarize the debate. Macroargumentation, such as the factors analysis described above, would be a natural choice for summarization, as it has already proven useful for filtering discussions. A more reasoning-intensive approach would be to calculate consistent outcomes (Wyner and van Engers, 2010), if debates can be easily formalized. 3.1 Challenges for argumentation mining In previous work, argumentation schemes have been classified in constrained domains, especially in legal argumentation (Mochales and Moens, 2011) and by using (Feng, 2010; Feng and Hirst, 2011) the Araucaria corpus (Katzav et al., 2004).4 Each of our envisioned applications of argumentation has certain requirements. Automatically detecting the argumentation schemes used in a message could be used for supporting authoring and finding weaknesses of arguments, which focus on the interior of each message. In order to ask the 4Further work is needed on argument scheme prevalence, which seems to vary by domain. Only 3 of Feng’s 5 ‘most common argumentation schemes’ appear in the top 14 most common schemes in our corpus, excluding Argument from Example and Argument from Cause to Effect. 61 appropriate critical questions, the premis</context>
</contexts>
<marker>Katzav, Reed, Rowe, 2004</marker>
<rawString>Joel Katzav, Chris Reed, and Glenn Rowe. 2004. Argument Research Corpus. In Proceedings of the 2003 Conference on Practical Applications in Language and Computers, pages 229–239. Peter Lang.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew J Ko</author>
<author>Parmit K Chilana</author>
</authors>
<title>Design, discussion, and dissent in open bug reports.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 iConference,</booktitle>
<pages>106--113</pages>
<contexts>
<context position="13229" citStr="Ko and Chilana, 2011" startWordPosition="2002" endWordPosition="2005">k (i.e. within minutes). Slower batch processing would be useful for the two other scenarios (support in challenging arguments with critical questions; support for summarizing debates) since Wikipedia’s debates are generally open for 7 days. 3.2 Related scenarios This is a single use case, but it represents a wide array of related ones. Open source and open knowledge projects are full of decision making discussions available widely in textual form. Rhetorical studies of them so far take place on a qualitative, discursive level. Examples include dissent and rhetorical devices in bug reporting (Ko and Chilana, 2011) and how Python listservs select enhancement proposals (Barcellini et al., 2005). Interestingly, the role of a participant in the Python community is related to the kinds of message they quote (Syntheses, Disagreements, Proposals, or Agreements), and Syntheses and Disagreements are the most quoted. The organizational relevance of these open decision making discussions in collaborative communities makes them a promising target for support, and argumentation mining technology is an appropriate tool to deploy towards that end. 4 Conclusions This paper detailed how automated argumentation mining c</context>
</contexts>
<marker>Ko, Chilana, 2011</marker>
<rawString>Andrew J Ko and Parmit K Chilana. 2011. Design, discussion, and dissent in open bug reports. In Proceedings of the 2011 iConference, pages 106–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raquel Mochales</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Argumentation mining.</title>
<date>2011</date>
<journal>Artificial Intelligence and Law,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="11442" citStr="Mochales and Moens, 2011" startWordPosition="1717" endWordPosition="1720">laborating before submitting a message). Finally, we could envision argumentation mining being used to summarize the debate. Macroargumentation, such as the factors analysis described above, would be a natural choice for summarization, as it has already proven useful for filtering discussions. A more reasoning-intensive approach would be to calculate consistent outcomes (Wyner and van Engers, 2010), if debates can be easily formalized. 3.1 Challenges for argumentation mining In previous work, argumentation schemes have been classified in constrained domains, especially in legal argumentation (Mochales and Moens, 2011) and by using (Feng, 2010; Feng and Hirst, 2011) the Araucaria corpus (Katzav et al., 2004).4 Each of our envisioned applications of argumentation has certain requirements. Automatically detecting the argumentation schemes used in a message could be used for supporting authoring and finding weaknesses of arguments, which focus on the interior of each message. In order to ask the 4Further work is needed on argument scheme prevalence, which seems to vary by domain. Only 3 of Feng’s 5 ‘most common argumentation schemes’ appear in the top 14 most common schemes in our corpus, excluding Argument fr</context>
</contexts>
<marker>Mochales, Moens, 2011</marker>
<rawString>Raquel Mochales and Marie-Francine Moens. 2011. Argumentation mining. Artificial Intelligence and Law, 19(1):1–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John L Pollock</author>
</authors>
<title>Justification and defeat.</title>
<date>1994</date>
<journal>ArtificialIntelligence,</journal>
<volume>67</volume>
<issue>2</issue>
<contexts>
<context position="4953" citStr="Pollock, 1994" startWordPosition="742" endWordPosition="743">ake decisions for open, online collaborative software and knowledge development in Mozilla, Wikipedia, OpenStreetMap, etc. In these groups, asynchronous textual debates are the basis for decision making. Participants argue for decisions based on rationales, since the reasons for opinions, rather than majority votes or aggregate sentiment, justify decisions. Thus large-scale decision support in these communities should make evident not just the overall tendency of the group (as in opinion mining) but rather the arguments made, focusing 1Rebut and undercut are drawn from the well-known work of (Pollock, 1994); Prakken credits undermining to (Vreeswijk, 1993) and (Elvang-Gøransson et al., 1993). especially on the rationales, or reasons given for a preferred outcome. In our work, we have analyzed a corpus of debates, to understand how the English-language version of Wikipedia makes decisions about which articles to include and exclude from the encyclopedia. We used two approaches to argumentation theory to annotate asynchronous messages in each debate, in iterative multiparty annotation experiments (Schneider, 2014). 2.1 Analysis using argumentation schemes First, we used Walton’s argumentation sche</context>
</contexts>
<marker>Pollock, 1994</marker>
<rawString>John L Pollock. 1994. Justification and defeat. ArtificialIntelligence, 67(2):377–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Prakken</author>
</authors>
<title>An abstract framework for argumentation with structured arguments.</title>
<date>2010</date>
<journal>Argument and Computation,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="3522" citStr="Prakken, 2010" startWordPosition="530" endWordPosition="531">nclusion. Figure 3 shows a simple debate, where two arguments attack one another. There are three ways Sin Inference Rule Sout (e) (b) (c) 1 3 2 1 2 3 1 2 59 Proceedings of the First Workshop on Argumentation Mining, pages 59–63, Baltimore, Maryland USA, June 26, 2014. c�2014 Association for Computational Linguistics Figure 3: Debates argue for and against a single conclusion. This kind of attack is called a rebuttal. of attacking an argument: attacking a premise (known as undermining), attacking a conclusion (known as rebutting), and attacking an inference (known as undercutting), following (Prakken, 2010).1 1.3 Inference Rules Argumentation schemes, e.g. (Walton et al., 2008) are one way of expressing Inference Rules. These are patterns for arguing which are stated abstractly: to use an argumentation scheme, it must be instantiated with details. To indicate possible flaws in reasoning, associated with each scheme there are critical questions pointing to the possible counterarguments. We next introduce an example from our own work, where automated argumentation mining could be used. 2 Rationale-based debate in open online communities One place where argumentation mining could be applied is in r</context>
</contexts>
<marker>Prakken, 2010</marker>
<rawString>Henry Prakken. 2010. An abstract framework for argumentation with structured arguments. Argument and Computation, 1(2):93–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jodi Schneider</author>
<author>Alexandre Passant</author>
<author>Stefan Decker</author>
</authors>
<title>Deletion discussions in Wikipedia: Decision factors and outcomes.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Symposium on Wikis and Open Collaboration,</booktitle>
<pages>17--1</pages>
<contexts>
<context position="7551" citStr="Schneider et al., 2012" startWordPosition="1131" endWordPosition="1134">nalysis of acceptability of arguments drew from community documentation and took community responses to messages into account. For instance, Argumentation from Values might be countered by a messages saying “Whether you personally like an article or its subject, is totally irrelevant.” (This exchange appeared in our corpus in fact http://en.wikipedia.org/wiki/Wikipedia: Articles_for_deletion/Log/2011_January_ 29.) 2 1 Attack 3 2 60 have most commonly been used in case-based reasoning. We iteratively derived four factors important in the discussions: Notability, Sources, Maintenance, and Bias (Schneider et al., 2012). This was an easier annotation task, with stronger inter-annotator agreement than for Walton’s argumentation schemes: factors analysis had Cohen’s kappa (Cohen, 1960) of .64-.82 depending on the factor (Schneider et al., 2012), versus .48 for Walton’s argumentation schemes (Schneider et al., 2013)). Factors provide a good way to organize the debate; filtering discussions based on each factor can show the rationale topic by topic, which supported decision making in a pilot user-based evaluation (Schneider, 2014). We can also identify the misunderstandings that newcomers have about which factor</context>
</contexts>
<marker>Schneider, Passant, Decker, 2012</marker>
<rawString>Jodi Schneider, Alexandre Passant, and Stefan Decker. 2012. Deletion discussions in Wikipedia: Decision factors and outcomes. In Proceedings of the International Symposium on Wikis and Open Collaboration, pages 17:1–17:10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jodi Schneider</author>
<author>Krystian Samp</author>
<author>Alexandre Passant</author>
<author>Stefan Decker</author>
</authors>
<title>Arguments about deletion: How experience improves the acceptability of arguments in ad-hoc online task groups.</title>
<date>2013</date>
<booktitle>In Proceedings of the ACM conference on Computer Supported Cooperative Work,</booktitle>
<pages>1069--1080</pages>
<contexts>
<context position="5861" citStr="Schneider et al., 2013" startWordPosition="880" endWordPosition="883">s about which articles to include and exclude from the encyclopedia. We used two approaches to argumentation theory to annotate asynchronous messages in each debate, in iterative multiparty annotation experiments (Schneider, 2014). 2.1 Analysis using argumentation schemes First, we used Walton’s argumentation schemes (outlined in Ch. 9 of (Walton et al., 2008)) in order to annotate the arguments, focusing on the internal reasoning of each message. First one person (this author) annotated all the arguments found in the corpus against Walton’s 60 schemes, finding 1213 arguments in 741 messages (Schneider et al., 2013). Then, we focused on the subset of 14 argumentation schemes that appeared more than 2% of the time, with iterative, multiparty annotation. There was a sharp divide between the two most prevalent argument types–Argument from Evidence to Hypothesis (19%) and Argument from Rules (17%)–and the remaining 12 types that appeared from 2-4% of the time. Besides these patterns, we found statistically significant differences between how experts and novices in the community argued in our corpus of debates. Experts were more likely to use Argument from Precedent, while novices (who had little experience i</context>
<context position="7850" citStr="Schneider et al., 2013" startWordPosition="1175" endWordPosition="1178">ge appeared in our corpus in fact http://en.wikipedia.org/wiki/Wikipedia: Articles_for_deletion/Log/2011_January_ 29.) 2 1 Attack 3 2 60 have most commonly been used in case-based reasoning. We iteratively derived four factors important in the discussions: Notability, Sources, Maintenance, and Bias (Schneider et al., 2012). This was an easier annotation task, with stronger inter-annotator agreement than for Walton’s argumentation schemes: factors analysis had Cohen’s kappa (Cohen, 1960) of .64-.82 depending on the factor (Schneider et al., 2012), versus .48 for Walton’s argumentation schemes (Schneider et al., 2013)). Factors provide a good way to organize the debate; filtering discussions based on each factor can show the rationale topic by topic, which supported decision making in a pilot user-based evaluation (Schneider, 2014). We can also identify the misunderstandings that newcomers have about which factors are important, and about what kind of support is necessary to justify claims about whether a factor holds. When an article is unacceptable because it lacks reliable sources, it is not enough to counter that someone will publish about this website when it gets out of beta testing.3 This newcomer’s</context>
</contexts>
<marker>Schneider, Samp, Passant, Decker, 2013</marker>
<rawString>Jodi Schneider, Krystian Samp, Alexandre Passant, and Stefan Decker. 2013. Arguments about deletion: How experience improves the acceptability of arguments in ad-hoc online task groups. In Proceedings of the ACM conference on Computer Supported Cooperative Work, pages 1069–1080.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jodi Schneider</author>
</authors>
<title>Identifying, Annotating, and Filtering Arguments and Opinions in Open Collaboration Systems.</title>
<date>2014</date>
<institution>Digital Enterprise Research Institute, National University of Ireland, Galway. Corpus</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="5468" citStr="Schneider, 2014" startWordPosition="817" endWordPosition="818">he arguments made, focusing 1Rebut and undercut are drawn from the well-known work of (Pollock, 1994); Prakken credits undermining to (Vreeswijk, 1993) and (Elvang-Gøransson et al., 1993). especially on the rationales, or reasons given for a preferred outcome. In our work, we have analyzed a corpus of debates, to understand how the English-language version of Wikipedia makes decisions about which articles to include and exclude from the encyclopedia. We used two approaches to argumentation theory to annotate asynchronous messages in each debate, in iterative multiparty annotation experiments (Schneider, 2014). 2.1 Analysis using argumentation schemes First, we used Walton’s argumentation schemes (outlined in Ch. 9 of (Walton et al., 2008)) in order to annotate the arguments, focusing on the internal reasoning of each message. First one person (this author) annotated all the arguments found in the corpus against Walton’s 60 schemes, finding 1213 arguments in 741 messages (Schneider et al., 2013). Then, we focused on the subset of 14 argumentation schemes that appeared more than 2% of the time, with iterative, multiparty annotation. There was a sharp divide between the two most prevalent argument ty</context>
<context position="8068" citStr="Schneider, 2014" startWordPosition="1211" endWordPosition="1212">s important in the discussions: Notability, Sources, Maintenance, and Bias (Schneider et al., 2012). This was an easier annotation task, with stronger inter-annotator agreement than for Walton’s argumentation schemes: factors analysis had Cohen’s kappa (Cohen, 1960) of .64-.82 depending on the factor (Schneider et al., 2012), versus .48 for Walton’s argumentation schemes (Schneider et al., 2013)). Factors provide a good way to organize the debate; filtering discussions based on each factor can show the rationale topic by topic, which supported decision making in a pilot user-based evaluation (Schneider, 2014). We can also identify the misunderstandings that newcomers have about which factors are important, and about what kind of support is necessary to justify claims about whether a factor holds. When an article is unacceptable because it lacks reliable sources, it is not enough to counter that someone will publish about this website when it gets out of beta testing.3 This newcomer’s argument fails to convincingly establish that there are reliable sources (because for Wikipedia, a reliable source should be published, independent, and subject to full editorial control), and may make things worse be</context>
</contexts>
<marker>Schneider, 2014</marker>
<rawString>Jodi Schneider. 2014. Identifying, Annotating, and Filtering Arguments and Opinions in Open Collaboration Systems. Ph.D. dissertation, Digital Enterprise Research Institute, National University of Ireland, Galway. Corpus and supplementary material also available online at http://purl.org/jsphd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Vreeswijk</author>
</authors>
<title>Studies in Defeasible Argumentation.</title>
<date>1993</date>
<institution>Free University Amsterdam.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="5003" citStr="Vreeswijk, 1993" startWordPosition="748" endWordPosition="749">tware and knowledge development in Mozilla, Wikipedia, OpenStreetMap, etc. In these groups, asynchronous textual debates are the basis for decision making. Participants argue for decisions based on rationales, since the reasons for opinions, rather than majority votes or aggregate sentiment, justify decisions. Thus large-scale decision support in these communities should make evident not just the overall tendency of the group (as in opinion mining) but rather the arguments made, focusing 1Rebut and undercut are drawn from the well-known work of (Pollock, 1994); Prakken credits undermining to (Vreeswijk, 1993) and (Elvang-Gøransson et al., 1993). especially on the rationales, or reasons given for a preferred outcome. In our work, we have analyzed a corpus of debates, to understand how the English-language version of Wikipedia makes decisions about which articles to include and exclude from the encyclopedia. We used two approaches to argumentation theory to annotate asynchronous messages in each debate, in iterative multiparty annotation experiments (Schneider, 2014). 2.1 Analysis using argumentation schemes First, we used Walton’s argumentation schemes (outlined in Ch. 9 of (Walton et al., 2008)) i</context>
</contexts>
<marker>Vreeswijk, 1993</marker>
<rawString>Gerard Vreeswijk. 1993. Studies in Defeasible Argumentation. Ph.D. dissertation, Free University Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Walton</author>
<author>Chris Reed</author>
<author>Fabrizio Macagno</author>
</authors>
<title>Argumentation Schemes.</title>
<date>2008</date>
<location>Cambridge.</location>
<contexts>
<context position="3594" citStr="Walton et al., 2008" startWordPosition="538" endWordPosition="541">ck one another. There are three ways Sin Inference Rule Sout (e) (b) (c) 1 3 2 1 2 3 1 2 59 Proceedings of the First Workshop on Argumentation Mining, pages 59–63, Baltimore, Maryland USA, June 26, 2014. c�2014 Association for Computational Linguistics Figure 3: Debates argue for and against a single conclusion. This kind of attack is called a rebuttal. of attacking an argument: attacking a premise (known as undermining), attacking a conclusion (known as rebutting), and attacking an inference (known as undercutting), following (Prakken, 2010).1 1.3 Inference Rules Argumentation schemes, e.g. (Walton et al., 2008) are one way of expressing Inference Rules. These are patterns for arguing which are stated abstractly: to use an argumentation scheme, it must be instantiated with details. To indicate possible flaws in reasoning, associated with each scheme there are critical questions pointing to the possible counterarguments. We next introduce an example from our own work, where automated argumentation mining could be used. 2 Rationale-based debate in open online communities One place where argumentation mining could be applied is in rationale-based debate in open online communities. The Web has enabled la</context>
<context position="5600" citStr="Walton et al., 2008" startWordPosition="835" endWordPosition="838">ng to (Vreeswijk, 1993) and (Elvang-Gøransson et al., 1993). especially on the rationales, or reasons given for a preferred outcome. In our work, we have analyzed a corpus of debates, to understand how the English-language version of Wikipedia makes decisions about which articles to include and exclude from the encyclopedia. We used two approaches to argumentation theory to annotate asynchronous messages in each debate, in iterative multiparty annotation experiments (Schneider, 2014). 2.1 Analysis using argumentation schemes First, we used Walton’s argumentation schemes (outlined in Ch. 9 of (Walton et al., 2008)) in order to annotate the arguments, focusing on the internal reasoning of each message. First one person (this author) annotated all the arguments found in the corpus against Walton’s 60 schemes, finding 1213 arguments in 741 messages (Schneider et al., 2013). Then, we focused on the subset of 14 argumentation schemes that appeared more than 2% of the time, with iterative, multiparty annotation. There was a sharp divide between the two most prevalent argument types–Argument from Evidence to Hypothesis (19%) and Argument from Rules (17%)–and the remaining 12 types that appeared from 2-4% of t</context>
</contexts>
<marker>Walton, Reed, Macagno, 2008</marker>
<rawString>Douglas Walton, Chris Reed, and Fabrizio Macagno. 2008. Argumentation Schemes. Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Wyner</author>
<author>Tom van Engers</author>
</authors>
<title>Towards web-based mass argumentation in natural language.</title>
<date>2010</date>
<booktitle>In Proceedings of Knowledge Engineering and Knowledge Management 2010 Poster and Demo Track.</booktitle>
<marker>Wyner, van Engers, 2010</marker>
<rawString>Adam Wyner and Tom van Engers. 2010. Towards web-based mass argumentation in natural language. In Proceedings of Knowledge Engineering and Knowledge Management 2010 Poster and Demo Track.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Z Wyner</author>
<author>Trevor J Bench-Capon</author>
<author>Katie Atkinson</author>
</authors>
<title>Three senses of “Argument”.</title>
<date>2008</date>
<booktitle>In Computable Models of the Law: Languages, Dialogues, Games, Ontologies,</booktitle>
<pages>146--161</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="2347" citStr="Wyner et al., 2008" startWordPosition="337" endWordPosition="340">these results has received funding from the European Union Seventh Framework Programme (FP7/2007- 2013) under grant agreement no 246016. Figure 1: The simplest possible argument. The simplest possible argument connects two Statements by means of an Inference Rule (Figure 1). Inference Rules are functions that input one or more Statements (the premises) and return one or more Statements (the conclusions). 1.2 More complex arguments Far more complex arguments can be formed. Arbitrary numbers of arguments can be joined into a larger and more complex argument. Useful terminology is introduced by (Wyner et al., 2008), who reserve the term argument to refer to the simplest kind: non-decomposable arguments. They distinguish cases which support a single conclusion (see Figure 2) from debates which argue for and against a single conclusion. Figure 2: Cases support a single conclusion. Cases may (a) use multiple, independent premises to support a single conclusion; (b) draw an intermediate conclusion, and use it as an additional premise in order to support a final conclusion; or (c) require two linked premises (both required as input to the inference rule) to support a conclusion. Figure 3 shows a simple debat</context>
</contexts>
<marker>Wyner, Bench-Capon, Atkinson, 2008</marker>
<rawString>Adam Z Wyner, Trevor J Bench-Capon, and Katie Atkinson. 2008. Three senses of “Argument”. In Computable Models of the Law: Languages, Dialogues, Games, Ontologies, pages 146–161. Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>