<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001100">
<title confidence="0.997439">
Detecting Code-Switching in a Multilingual Alpine Heritage Corpus
</title>
<author confidence="0.999278">
Martin Volk and Simon Clematide
</author>
<affiliation confidence="0.997818">
University of Zurich
Institute of Computational Linguistics
</affiliation>
<email confidence="0.985397">
volk|siclemat@cl.uzh.ch
</email>
<sectionHeader confidence="0.993628" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999910631578948">
This paper describes experiments in de-
tecting and annotating code-switching in
a large multilingual diachronic corpus of
Swiss Alpine texts. The texts are in En-
glish, French, German, Italian, Romansh
and Swiss German. Because of the mul-
tilingual authors (mountaineers, scientists)
and the assumed multilingual readers, the
texts contain numerous code-switching
elements. When building and annotating
the corpus, we faced issues of language
identification on the sentence and sub-
sentential level. We present our strategy
for language identification and for the an-
notation of foreign language fragments
within sentences. We report 78% precision
on detecting a subset of code-switches
with correct language labels and 92% un-
labeled precision.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999654933333333">
In the Text+Berg project we have digitized the
yearbooks of the Swiss Alpine Club (SAC) from
its first edition in 1864 until today. They contain
articles about mountain expeditions, the flora and
fauna of the Alpes and other mountain regions,
glacier and climate observations, geology and his-
tory papers, book reviews, accident and security
reports, as well as the protocols of the annual
club gatherings. The texts are in the four official
languages of Switzerland French, German, Italian
and Romansh 1 plus a few in English and Swiss
German dialects.
Because of the multilinguality of the authors
and readers, many articles are mixed-language
texts with inter-sentential and intra-sentential
</bodyText>
<footnote confidence="0.936096">
1. Romansh is the 4th official language in Switzerland. It
is spoken by around 25,000 people in the mountainous South-
Eastern canton of Graub¨unden.
</footnote>
<bodyText confidence="0.9946799">
code-switching. This poses a challenge for auto-
matically processing the texts. When we apply
Part-of-Speech (PoS) tagging, named entity recog-
nition or parsing, our systems need to know the
language that they are dealing with. Therefore we
had used a language identifier from the start of the
project to mark the language of each sentence. We
report on our experiences with sentence-based lan-
guage identification in section 3. Figure 1 shows
an example of a French text with an English ap-
pendix title plus an English quote from this book.
Lately we discovered that our corpus also
contains many intra-sentential code-switches. For
example, we find sentences like
... und ich finde es &lt;cvery nice and de-
lightful» einen Vortrag halten zu d¨urfen.
(Die Alpen, 1925) (EN : ... and I find it
very nice and delightful to be allowed to
give a talk.)
where the German sentence contains an English
phrase in quotation marks. Obviously, a German
PoS tagger will produce nonsense tags for the En-
glish phrase as the words will be unknown to it.
PoS taggers are good at tagging single unknown
words based on the surrounding context, but most
taggers fail miserably when a sequence of two
or more words is unknown. The upper half of fi-
gure 2 shows the PoS tagger output for the above
example. The words very, nice, delightful are sen-
selessly tagged as proper names (NE), only and is
tagged as foreign word (FM).
Our goal is to detect all intra-sentential code-
switches and to annotate them as exemplified in
the lower half of figure 2. They shall be framed
with the TEI-conformant tag &lt;foreign&gt; which
also shall specify the language of the foreign lan-
guage segment. All tokens in the segment shall be
tagged as foreign words (e.g. FM in the German
STTS tag set, ET in the French Le Monde tag set
(Abeill´e et al., 2003)), and each lemma shall get
</bodyText>
<page confidence="0.989523">
24
</page>
<note confidence="0.8607255">
Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 24–33,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999437">
the special symbol @fn@ to set it apart from lem-
mas of the surrounding sentence. In this paper we
report on our experiments towards this goal and
suggest an algorithm for detecting code-switching.
We adopt a wide definition of code-switching.
We are interested in detecting all instances where
a text is in a dominant language and contains
words, phrases and sentences in another language.
Though our definition is broad, it is clearly more
restricted than others, as e.g. the definition by
Kracht and Klein (2014) which includes special
purpose codes like bank account numbers or shoe
sizes.
In this paper we will give an overview of the
language mix in the yearbooks of the Swiss Al-
pine Club over the 150 years, and we will illus-
trate how we identified inter-sentential and intra-
sentential code-switching. We will give a quanti-
tative overview of the number of code-switching
candidates that we automatically located.
</bodyText>
<sectionHeader confidence="0.938135" genericHeader="introduction">
2 The Text+Berg Corpus
</sectionHeader>
<bodyText confidence="0.999912376811594">
The Text+Berg corpus comprises the annual pu-
blications of the Swiss Alpine Club (SAC) from
its first edition in 1864 until 2013. From the start
until 1923 the official yearbook was called “Jahr-
buch des Schweizer Alpen-Club” (EN : yearbook
of the Swiss Alpine Club), and it typically consis-
ted of 500 to 700 pages. The articles of these first
60 years were mostly in German (with 86% of
the words), but some also in French (13% of the
words) and few in Italian and Romansh (Volk et
al., 2010).
Interestingly, the German articles contained
passages in French and sometimes other languages
(e.g. English, Swiss German, Latin) without trans-
lations, and vice versa. Obviously, the article au-
thors and yearbook editors assumed that the rea-
ders of the yearbook were polyglott at least in En-
glish, French, German and Latin during that time.
In fact, the members of the SAC in the 19th cen-
tury came from an academic elite. Mountain ex-
ploration was a past-time of the rich and educated.
Still, during that same time the French-speaking
sections of the Swiss Alpine Club published their
own yearbook in parallel to the official yearbook
and called it “Echo des Alpes”. It started shortly
after the official yearbook in the late 1860s and
continued until 1923. Each “Echo des Alpes” year-
book contained between 300 to 600 pages adding
up to a total of 22,582 pages with 7.4 million to-
kens, almost all in French with rare quotes in Ger-
man.
As of 1925 the official SAC yearbook and the
“Echo des Alpes” were merged into a new publi-
cation called “Die Alpen. Les Alpes. Le Alpi” (in
German, French, Italian) which has been publi-
shed ever since. Over the years it sometimes ap-
peared as quarterly and sometimes as monthly ma-
gazine. Today it appears 12 times per year in ma-
gazine format. For the sake of simplicity we conti-
nue to call each annual volume a yearbook.
The merger in 1925 resulted in a higher per-
centage of French texts in the new yearbook. For
example, the 1925 yearbook had around 143,000
words in German and 112,000 in French (56% to
44%). The ratio varied somewhat but was still at
64% to 36% in 1956.
From 1957 onwards, the SAC has published pa-
rallel (i.e. translated) French and German versions
of the yearbooks. At the start of this new era only
half of the articles were translated, the rest was
printed in the original language in identical ver-
sions in the two language copies.
Over the next decade the number of translations
increased and as of 1983 the yearbooks were com-
pletely translated between German and French.
Few Italian articles were still published verbatim
in both the French and German yearbooks. As of
2012 the SAC has launched an Italian language
version of its monthly magazine so that now it pro-
duces French, German and Italian parallel texts.
In its latest release the Text+Berg corpus (com-
prising the SAC yearbooks, the ALPEN maga-
zine and the Echo des Alpes) contains around
45.8 million tokens (after tokenization). French
and German account for around 22 million tokens
each, Italian accounts for 0.8 million tokens. The
remainder goes to English, Latin, Romansh and
Swiss German. The corpus is freely available for
research purposes upon request.
</bodyText>
<sectionHeader confidence="0.8233985" genericHeader="method">
3 Language Identification in the
Text+Berg Corpus
</sectionHeader>
<bodyText confidence="0.9995705">
We compiled the Text+Berg corpus by scanning
all SAC yearbooks from 1864 until 2000 (around
100,000+ pages). Afterwards we employed com-
mercial OCR software to convert the scan images
into electronic text. We developed and applied
techniques to automatically reduce the number of
OCR errors (Volk et al., 2011).
We obtained the yearbooks from 2001 to
</bodyText>
<page confidence="0.996523">
25
</page>
<bodyText confidence="0.988562222222222">
de la publication du Mount Everest 1938 2 de Tilman. L&apos;Appendix B, intitule: Antropolosy or
Zoology, with Particular Reference to the Abominable Snowman, reprend la question ab
ovo 3, en la soumettant, pp. 127-137, a tine enquate stricternent impartiale.
La conclusion de cette enqute est re&apos;sum6e dans les sept dernieres lignes de la page 137;
«I merely affirm that traces for which no adequate explanation is forthcoming have
been seen and will continue to be seen in various parts of the Himalaya, and until a worthier
claimant is found we may as well attribute them to the ,Abominable snowman&apos;, And I think
he would be a bold and in some ways an impious sceptic who, after balancing the evidence, does
not decide to give him the benefit of the doubt 4, &gt;?
</bodyText>
<sectionHeader confidence="0.305344" genericHeader="method">
Conclusion: Devant l&apos;opinion fortement document&amp; et motivee de Tilrnan, peut-etre
</sectionHeader>
<figureCaption confidence="0.774814333333333">
FIGURE 1 — Example of an English title and an English quote in a French text (Die Alpen, 1955)
FIGURE 2 - Example of an annotated German sentence with English segment, before and dim. code-
switchdetection(DieMpen, 1925)
</figureCaption>
<figure confidence="0.990133525">
&lt;w n=&amp;quot;23-16-21&amp;quot; lemmo=&amp;quot;und&amp;quot; pos=&amp;quot;KON&amp;quot;&gt;urd&lt;/w&gt;
&lt;w n=&amp;quot;23-16-22&amp;quot; lemma=&amp;quot;ich&amp;quot; pos=&amp;quot;PPER&amp;quot;&gt;ich&lt;A&gt;
&lt;w n=&amp;quot;23-16-23&amp;quot; lemma=&amp;quot;finden&amp;quot; pos=&amp;quot;VVFIN&amp;quot;&gt;finde&lt;/w&gt;
&lt;w n=&amp;quot;23-16-24&amp;quot; lemma=&amp;quot;es&amp;quot; pos=&amp;quot;PPER&amp;quot;&gt;es&lt;/w&gt;
&lt;w n=&amp;quot;23-16-25&amp;quot; lemma&amp;quot;.&amp;quot;
&lt;w n=&amp;quot;23-16-26&amp;quot; lemmo=&amp;quot;unk&amp;quot;
&lt;w n=&amp;quot;23-16-27&amp;quot; lemmo=&amp;quot;unk&amp;quot;
&lt;w n=&amp;quot;23-16-28&amp;quot; lemmo=&amp;quot;and&amp;quot;
&lt;w n=&amp;quot;23-16-29&amp;quot; lemmo=&amp;quot;unk&amp;quot;
pos=&amp;quot;$(&amp;quot;&gt;(«/w&gt;
pos=&amp;quot;NE&amp;quot;&gt;very&lt;/w&gt;
pos=&amp;quot;NP&gt;nice&lt;/w&gt;
pos=&amp;quot;FW&gt;and&lt;/w&gt;
pos=&amp;quot;NP&gt;delightful&lt;/w&gt;
&lt;w n=&amp;quot;23-16-30&amp;quot; lemma&amp;quot; D&apos; pos=&amp;quot;$(&amp;quot;&gt;m&lt;/w&gt;
&lt;w n=&amp;quot;23-16-31&amp;quot; lemmo=&amp;quot;ein&amp;quot; pos=&amp;quot;ART&amp;quot;,einen&lt;/w&gt;
&lt;w n=&amp;quot;23-16-32&amp;quot; lemmo=&amp;quot;Vortrag&amp;quot; pos=&amp;quot;NN&amp;quot;&gt;Vortrag&lt;/w&gt;
&lt;w n=&amp;quot;23-16-33&amp;quot; lemmo=&amp;quot;halten&amp;quot; pos=&amp;quot;VVINF&amp;quot;&gt;halten&lt;/w&gt;
&lt;w n=&amp;quot;23-16-34&amp;quot; lemma=&amp;quot;zu&amp;quot; pos=&amp;quot;171(ZU&amp;quot;&gt;zu&lt;A&gt;
&lt;w n=&amp;quot;23-16-35&amp;quot; lemma=&amp;quot;d6rfen&amp;quot; pos=&amp;quot;VMINF&amp;quot;&gt;darfen&lt;/w&gt;
&lt;w n=&amp;quot;23-16-36&amp;quot; lemma=&amp;quot;.&amp;quot; pos=&amp;quot;$.&amp;quot;&gt;.&lt;/w&gt;
after code switch detection
&lt;w n=&amp;quot;23-16-21&amp;quot; lemmo=&amp;quot;und&amp;quot; pos=&amp;quot;KON&amp;quot;&gt;und&lt;/w&gt;
&lt;w n=&amp;quot;23-16-22&amp;quot; lemmo=&amp;quot;ich&amp;quot; pos=&amp;quot;PPER&amp;quot;&gt;ich&lt;/w&gt;
&lt;w n=&amp;quot;23-16-23&amp;quot; lemmo=&amp;quot;finden&amp;quot; pos=&amp;quot;VVFIN&amp;quot;&gt;finde&lt;/w&gt;
&lt;w n=&amp;quot;23-16-24&amp;quot; lemmo=&amp;quot;es&amp;quot; pos=&amp;quot;PPER&amp;quot;&gt;es&lt;/w&gt;
&lt;foreign long=&amp;quot;en&amp;quot;›
&lt;w n=&amp;quot;23-16-25&amp;quot; lemma pos&amp;quot;$(&amp;quot;&gt;g&lt;/w&gt;
&lt;w n=&amp;quot;23-16-26&amp;quot; lemma=&amp;quot;ffnIP&amp;quot; pos=&amp;quot;FM&amp;quot;,very&lt;A&gt;
&lt;w n=&amp;quot;23-16-27&amp;quot; lemma=&amp;quot;ffnIP&amp;quot; pos=&amp;quot;FM&amp;quot;,nice&lt;A&gt;
&lt;w n=&amp;quot;23-16-28&amp;quot; lemma=&amp;quot;ffnIP&amp;quot; pos=&amp;quot;FM&amp;quot;,ord&lt;/w&gt;
&lt;w n=&amp;quot;23-16-29&amp;quot; lemma=&amp;quot;ffnIP&amp;quot; pos=&amp;quot;FM&amp;quot;&gt;delightful&lt;/w&gt;
&lt;w n=&amp;quot;23-16-30&amp;quot; lemma pos&amp;quot;$(&amp;quot;&gt;D&lt;/w&gt;
&lt;/foreign&gt;
&lt;w n=&amp;quot;23-16-31&amp;quot; lemmo=&amp;quot;ein&amp;quot; pos=&amp;quot;ART&amp;quot;&gt;einen&lt;/w&gt;
&lt;w n=&amp;quot;23-16-32&amp;quot; lemmo=&amp;quot;Vortrag&amp;quot; pos=&amp;quot;NN&amp;quot;&gt;Vortrag&lt;/w&gt;
&lt;w n=&amp;quot;23-16-33&amp;quot; lemmo=&amp;quot;halten&amp;quot; pos=&amp;quot;VVINF&amp;quot;&gt;holten&lt;/w&gt;
&lt;w n=&amp;quot;23-16-34&amp;quot; lemmo=&amp;quot;zu&amp;quot; pos=&amp;quot;PTIQU&amp;quot;&gt;zu&lt;/w&gt;
&lt;w n=&amp;quot;23-16-35&amp;quot; lemmo=&amp;quot;dUrfen&amp;quot; pos=&amp;quot;VMINF&amp;quot;&gt;dilrfen&lt;/w&gt;
&lt;w n=&amp;quot;23-16-36&amp;quot; lemmo=&amp;quot;.&amp;quot; pos=&amp;quot;$.&amp;quot;&gt;.&lt;/w&gt;
</figure>
<page confidence="0.980993">
26
</page>
<bodyText confidence="0.999887416666667">
2009 as PDF documents which we automatically
converted to text. The subsequent yearbooks from
2010 until 2013 we received as XML files from
the SAC.
We have turned the whole corpus into a uniform
XML format. For this, the OCR output texts as
well as the texts converted from PDF and XML
are structured and annotated by automatically mar-
king article boundaries, by tokenization, language
identification, Part-of-Speech tagging and lemma-
tization. Our processing pipeline also includes to-
ponym recognition and geo-coding of mountains,
glaciers, cabins, valleys, lakes and towns. Further-
more we recognize and co-reference person names
(Ebling et al., 2011), and we annotate temporal
expressions (date, time, duration and set) with a
variant of HeidelTime (Rettich, 2013). Finally we
analyze the parallel parts of our corpus and pro-
vide sentence alignment information that is com-
puted via BLEUalign (Sennrich and Volk, 2011).
In order to process our texts with language-
specific tools (e.g. PoS tagging and person name
recognition) we employed automatic language
identification on the sentence level. We used
Lingua-Ident 2 (developed by Michael Piotrowski)
to determine for each sentence in our corpus whe-
ther it is in English, French, German, Italian or Ro-
mansh. Lingua-Ident is a statistical language iden-
tifier based on letter n-gram frequencies. For long
sentences it reliably distinguishes between the lan-
guages. Unfortunately it often misclassifies short
sentences. Therefore we decided to use it only for
sentences with more than 40 characters. Shorter
sentences are assigned the language of the article.
This can be problematic for mixed language ar-
ticles. An alternative strategy would be to assign
the language of the previous sentence to short sen-
tences.
For sentences that Lingua-Ident judges as Ger-
man we run a second classifier that distinguishes
between Standard German and Swiss German dia-
lect text. Since there are no writing rules for Swiss
German dialects, they come in a variety of spel-
lings. We have compiled a list of typical Swiss
German words (e.g. Swiss-German : chli, chlii,
chlini, chline = German: klein, kleine = English:
small) that are not used in Standard German in or-
der to identify Swiss German sentences. 3
</bodyText>
<listItem confidence="0.930587">
2. http ://search.cpan.org/dist/Lingua-Ident/
3. We are aware that the Text+Berg corpus contains also
occasional sentences (or sentence fragments) in other Ger-
man dialects (e.g. Austrian German, Bavarian German) and
</listItem>
<bodyText confidence="0.999902588235294">
Based on the language tag of each sentence
we are able to investigate coarse-grained code-
switching. Whenever the language of a sentence
deviates from the language of the article, we have a
candidate for code-switching. For example, in the
yearbook 1867 we find a German text (describing
the activities of the club) with a French quote:
Der Berichterstatter bemerkt dar¨uber :
“On peut remarquer a` cette occasion
qu’il est rare que par un effort de l’es-
prit on puisse mettre du brouillard en
bouteille, et ... ” Die etwas ¨altere Sek-
tion Diablerets, deren Steuer Herr Au-
gust Bernus mit kundiger Hand ...
Most code-switching occurs with direct speech,
quotes and book titles. The communicative goal is
obviously to make the text more authentic.
</bodyText>
<sectionHeader confidence="0.9933" genericHeader="method">
4 Related Work on Detection of
</sectionHeader>
<subsectionHeader confidence="0.478913">
Code-Switching
</subsectionHeader>
<bodyText confidence="0.998722322580645">
Most previous work on automatically detecting
code-switching focused on the switches between
two known languages (whereas we have to deal
with a mix of 6 languages).
Solorio and Liu (2008) worked on real-time
prediction of code-switching points in Spanish-
English conversations. This means that the judge-
ment whether the current word is in a different lan-
guage than the language of the matrix clause can
only be based on the previous words. They use the
PoS tag and its probability plus the lemma as pro-
vided by both the Spanish and the English Tree-
Tagger as well as the position of the word in the
Beginning-Inside-Outside scheme as features for
making the decision. In order to keep the number
of experiments manageable they restricted their
history to one or two preceding words. As an inter-
esting experiment they generated code-switching
sentences Spanish-English based on their different
predictors and asked human judges to rate the na-
turalness of the resulting sentences. This helped
them to identify the most useful code-switching
predictor.
Vu et al. (2013) and Adel et al. (2013) consi-
der English-Mandarin code-switching in speech
recognition. They investigate recurrent neural net-
work language models and factored language mo-
dels to the task in an attempt to integrate syntac-
tic features. For the experiments they use SEAME,
in old German spellings. Since these varieties are rare in the
corpus, we do not deal with them explicitly.
</bodyText>
<page confidence="0.990553">
27
</page>
<bodyText confidence="0.99981758974359">
the South East Asia Mandarin-English speech cor-
pus compiled from Singaporean and Malaysian
speakers. It consists of spontaneous interviews
and conversations. The transcriptions were clea-
ned and each word was manually tagged as En-
glish, Mandarin or other. The data consists of an
intensive mix of the two languages with the ave-
rage duration of both English and Mandarin seg-
ments to be less than a second ( !). In order to as-
sign PoS tags to this mixed language corpus, the
authors applied two monolingual taggers and com-
bined the results.
Huang and Yates (2014) also work on the de-
tection of English-Chinese code-switching but not
on speech but rather on web forum texts produ-
ced by Chinese speakers living in the US. They
use statistical word alignment and a Chinese lan-
guage model to substitute English words in Chi-
nese sentences with suitable Chinese words. Pre-
paring the data in this way significantly improved
Machine Translation quality. Their approach is li-
mited to two known languages and to very short
code-switching phrases (typically only one word).
Tim Baldwin and his group (Hughes et al.,
2006) have surveyed the approaches to language
identification at the time. They found a number of
missing issues, such as language identification for
minority languages, open class language identifi-
cation (in contrast to identification within a fixed
set of languages), sparse training data, varying
encodings, and multilingual documents. Subse-
quently they (Lui and Baldwin, 2011) introduced a
system for language identification of 97 languages
trained on a mixture of corpora from different
domains. They claim that their system Langid is
particularly well suited for classifying short input
strings (as in Twitter messages). We therefore tes-
ted Langid in our experiments for code-switching
detection.
</bodyText>
<sectionHeader confidence="0.9757975" genericHeader="method">
5 Exploratory Experiments with the
SAC Yearbook 1925
</sectionHeader>
<bodyText confidence="0.999971333333333">
In order to assess the performance of Langid
for the detection of code-switching we performed
an exploratory experiment with the SAC yearbook
1925. We extracted all word sequences between
pairs of quotation marks where at least one token
had been assigned the “unknown” lemma by our
PoS tagger. The “unknown” lemma indicates that
this word sequence may come from a different lan-
guage.
The word sequence had to be at least 4 cha-
racters long, thus skipping single letters and ab-
breviations. In this way we obtained 333 word
sequences that are potential candidates for intra-
sentential code-switching. We then ran these word
sequences through the Langid language identifica-
tion system with the restriction that we expect the
word sequences only to be either English, French,
German, Italian or Latin (Romansh and Swiss Ger-
man are not included in Langid). For a given string
Langid delivers the most likely language together
with a confidence score.
We then compared the language predicted by
the Langid system with the (automatically) com-
puted language of the complete sentence. In 189
out of the 333 sentences the Langid output pre-
dicted a code-switch. We then manually graded all
Langid judgements and found that 225 language
judgements (67.5%) were correct. But only 89 of
the 189 predicted code-switches came with the
correct language. 40 of the 100 incorrect judge-
ments were actually code-switches but with a dif-
ferent language. The remaining ones should have
been classified with the same language as the sur-
rounding sentence and are thus no examples of
code-switching.
A closer inspection of the results revealed that
the book contained not only code-switches in the
expected 5 languages, but also into Romansh (6),
Spanish (4) and Swiss-German (13). Obviously all
of these were incorrectly classified. Most (8) of
the Swiss-German word sequences were classified
as German which could count as half correct, but
the others were misclassified as English (among
them a variant of the popular Swiss German fare-
well phrase uf Wiederluege spelled as uf’s Wieder-
luege).
The Langid system has a tendency to classify
word sequences as English. Many of the short, in-
correctly classified word sequences were judged
as English. It turns out that Langid judges even the
empty string as English with a score of 9.06. The-
refore all judgements with this score are dubious.
We found that 56 short word sequences were clas-
sified as English with this score, out of which 35
were erroneously judged as English. Only strings
with a length of 15 and more characters that are
classified as English should be trusted. All others
need to be discarded.
In general, if precision is the most important as-
pect, then Langid should only be used for strings
</bodyText>
<page confidence="0.998197">
28
</page>
<table confidence="0.990835">
SAC yearbooks candidates predicted code-sw correct wrong lang no code-sw
1868 to 1878 388 121 88 33 13
1926 to 1935 792 335 266 69 23
Total 1180 456 354 102 36
</table>
<tableCaption confidence="0.878631">
TABLE 1 – Recognition of code-switches in the Text+Berg corpus
</tableCaption>
<bodyText confidence="0.999962489361703">
with 20 or more characters. In our test set only 4
strings that were longer than 20 characters were
incorrectly classified within the selected language
set. Among the errors was the famous Latin phrase
conditio sine qua non (length: 21 characters inclu-
ding blanks) which Langid incorrectly classified
as Italian.
Another reason for the considerable number of
misclassifications can be repeated occurrences of
a word sequence. Our error count is a token-based
count and thus prone to misclassified recurring
phrases. In our experiment, Langid misclassified
the French book name Echo des Alpes as Italian.
Unfortunately this name occurs 18 times in our
test set and thus accounts for 18 errors. We suspect
that an -o at the end of a word is a strong indicator
for Italian. In a short string like Echo des Alpes (14
characters), this can make the difference.
Another interesting observation is that hyphens
speak for German. Our test set contains the hy-
phenated French string vesse-de-neige which Lan-
gid misclassifies as German with a clear margin
over French. When the same string is analyzed
without hyphens, then Langid correctly computes
a preference for French over German. A similar
observation comes from the Swiss German phrase
uf’s Wiederluege being classified as English when
spelled with the apostrophe (which is less frequent
in German than in English). Without the apos-
trophe Langid would count the string as German.
With short strings like this, special symbols have a
visible impact on the language identification.
We also observed that Langid is sensitive to
all-caps capitalization. For example, AUS DEM
LEBEN DER GEBIRGSMUNDARTEN (EN : The
Lives of Mountain Dialects) is misclassified as En-
glish (with the default score) while Aus dem Le-
ben der Gebirgsmundarten is correctly classified
as German.
Overall, we found that code-switching within
the same article rarely targets different languages.
For example, if the article is in German and
contains code-switches into English, then it hardly
ever contains code-switches into other languages.
In analogy to the one-sense-per-discourse hypo-
thesis we might call this the one-code-switch-
language-per-discourse hypothesis.
</bodyText>
<sectionHeader confidence="0.994055" genericHeader="method">
6 Detecting Intra-sentential
</sectionHeader>
<subsectionHeader confidence="0.529848">
Code-Switching
</subsectionHeader>
<bodyText confidence="0.999986131578947">
Based on exploratory studies and observations
we decided on the following algorithm for detec-
ting and annotating intra-sentential foreign lan-
guage segments in the Text+Berg corpus. We
search for sub-sentential token sequences (possi-
bly of length 1) that are framed by a pair of quota-
tion marks and that contain at least one “unknown”
lemma. There must be at least two tokens outside
of the quotation marks in the same sentence. As
a compromise we restrict our detection to strings
longer than 15 characters so that we get relati-
vely reliable language judgements by Langid. The
strings may consist of one token that is longer than
15 characters (e.g. Matterhornhochtourist) or a se-
quence of tokens whose sum of characters inclu-
ding blanks is more than 15. We feed these can-
didate strings to Langid for language identifica-
tion and compare the output language with the lan-
guage attribute of the surrounding sentence. If the
languages are different, then we regard the token
sequence as code-switch and mark it accordingly
in XML as shown in figure 2.
In order to determine the precision of this al-
gorithm, we checked 10 yearbooks from 1868 to
1878 (there was no yearbook in 1870) and from
1926 to 1935. The results are in table 1. From
the 1180 code-switch candidates that we compu-
ted based on the above restrictions, Langid predic-
ted 456 code-switches (39%). This means that in
39% of the cases Langid predicted a language that
was different from the language of the surrounding
sentence.
We manually evaluated all 456 predicted code-
switches and found that 354 of them (78%) were
correctly classified and labeled. These segments
were indeed in a different language than the sur-
rounding sentence and their language was cor-
rectly determined. For example, the French seg-
</bodyText>
<page confidence="0.997831">
29
</page>
<table confidence="0.999340857142857">
SAC yearbooks ≤ 15 characters
&gt; 15 characters
without unknowns
all sample: TN/FN all sample: TN/FP
1868 to 1878 322 20/1 404 15/8
1926 to 1935 1944 78/1 1136 54/23
Total 2266 (2%) 98/2 1540 (31%) 69/31
</table>
<tableCaption confidence="0.545376">
TABLE 2 – Estimation of the loss of recall due to the filtering approach based on a random sample of 100
quotations for each filtering category (TN : true negatives, FN : false negatives)
</tableCaption>
<bodyText confidence="0.994273666666667">
ment in the following German sentence is cor-
rectly detected and classified:
Anschliessend f¨uhrte Ambros dasselbe
Bergsteigertrio «dans des circonstances
tr`es d´efavorables» auf den Monte Rosa
... (Die Alpen, 1935) (EN : After-
wards Ambros led the same 3 mountai-
neers &lt;&lt;under very unfavorable condi-
tions» onto Monte Rosa.)
Out of the 102 segments whose language
was wrongly classified, only 36 were no code-
switches. For example, the Latin segment cum
grano salis africani is indeed a code-switch in
a German sentence although Langid incorrectly
classifies it as English. In fact, our evaluation sho-
wed that Langid is “reluctant” to classify strings as
Latin. Latin strings are often misclassified as En-
glish or Italian.
Overall this means that only 8% of the predicted
code-switches are no code-switches. Therefore we
can safely add the module for code-switch detec-
tion into our processing and annotation pipeline.
In order to estimate the recall of our quota-
tion filtering approach we manually evaluated a
sample of the quotations that our algorithm exclu-
ded. Table 2 presents the numbers for the two time
periods for two cases : first for sequences that are
longer than 15 characters and contain only known
lemmas, second for sequences that are shorter than
16 characters and contain at least one “unknown”
lemma. For both cases we checked 100 instances.
The evaluation for the quotations with more
than 15 characters but with all known lemmas (no
“unknown” lemma) shows only 2 false negatives.
Therefore, we can conclude safely that most of the
code-switches with more than 15 characters were
included in our candidate set.
Table 2 also shows that there were 1540 quota-
tions with 15 or less characters. The manual ins-
pection of 100 randomly selected quotations re-
vealed that 31 indeed include foreign material.
Some of these quotations are geographic names,
e.g. the valley Bergell (EN/IT : Val Bregaglia),
where it is difficult to decide whether this should
be regarded as a code-switch. For this evaluation,
we sticked to the principle that a foreign geogra-
phic name in quotation marks counts as a code-
switch. The number of missed code-switches is
high (31%). However, due to the limited preci-
sion of Langid (and other character-based lan-
guage identifiers) for short character sequences,
we still consider our length threshold appropriate.
A different approach to language identification is
needed to reliably classify these short quotes.
</bodyText>
<sectionHeader confidence="0.997143" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.99887084">
The correctly marked code-switches in our test
periods can be split by language of the matrix sen-
tence and the language of the sub-sentential seg-
ment (= the code-switch segment). Table 3 gives
an overview of the types of code-switches for the
two periods under investigation. We see clearly
that code-switches from German to English were
rare in the 19th century (8 out of 89 = 9%) but be-
came much more popular in the 1920s and 1930s
(61 out of 265 = 23%). This came at the cost of
French which lost ground from 54% (48 out of 89)
to 40% (106 out of 265).
One can only compare the code-switch num-
bers from German with the corresponding num-
bers from French after normalizing the numbers
in relation to the overall amount of text in Ger-
man and French. During the first period (1868 to
1878) we count roughly 200,000 tokens in French
and 1.4 million tokens in German, whereas in the
second period (1926 to 1935) we have around 1
million tokens in French and again 1.4 million
tokens in German. For the first period we find
87 code-switches (triggered by quotation marks)
in the 1.4 million German tokens compared to
189 code-switches in the second period. The num-
</bodyText>
<page confidence="0.995528">
30
</page>
<table confidence="0.994140395348837">
sent segm 1868 to 1926 to
lang lang 1878 1935
de en 8 61
de fr 48 106
de it 24 19
de la 7 3
fr de 2 35
fr en - 20
fr it - 11
fr la - 2
it de - 3
it en - 2
it fr - 3
Total 89 265
TABLE 3 – Correctly detected code-switches in the
Text+Berg corpus
correct Langid prediction
segm
lang en it fr la de Total
la 15 12 3 1 31
de 7 5 5 1 18
fr 7 3 10
it 6 6
es 3 1 2 6
rm 1 2 3
ru 1 1
id 1 1
Total 40 22 10 3 1 76
TABLE 5 – Confusion matrix for incorrectly labe-
led code-switches in the periods 1868 to 1878 and
1926 to 1935
sent segm 1868 to 1926 to
lang lang 1878 1935
de en 13 23
de fr 9 5
de it 8 12
de la 2 1
fr de - 7
fr en 1 10
fr it - 8
fr la - 1
it en - 2
Total 33 69
</table>
<tableCaption confidence="0.4149655">
TABLE 4 – Incorrectly labeled code-switches in
the Text+Berg corpus
</tableCaption>
<bodyText confidence="0.999726444444444">
ber of code-switches have clearly increased. For
French we observe the same trend with 2 code-
switches in 200’000 words in the first period com-
pared to 68 code-switches in the 1 million tokens
in the second period.
There is also a striking difference between
French and German with many more code-
switches in German than in French. For instance,
for German we find 135 code-switches per 1 mil-
lion tokens in the second period vs. 68 code-
switches per 1 million tokens for French.
One surprising finding were the code-switches
into Latin. We had not noticed them before, since
our corpus does not contain longer passages of La-
tin text. But this study shows that code-switches
into Latin persisted into the 1920s (3 out of Ger-
man and 2 out of French).
On the negative side (cf. table 4), misclassi-
fying segments as English is the most frequent
cause for a wrong language assignment in both
periods. Table 5 shows the confusion matrix which
contrasts the manually determined segment lan-
guage with the incorrect language predicted by
Langid. This confirms that Langid has a tendency
to classify short text segments as English. But
there are also a number of errors for Latin being
mistaken for Italian, and German being mistaken
for Italian or French.
As a general remark, it should be noted that an
n-gram-based language identifier has advantages
over a lexicon-based language identifier in the face
of OCR errors. In the yearbook 1926 we observed
the rare case of a whole English sentence having
been contracted to one token Ilovetobemothered.
Still, our code-switch detector recognizes this as
an English string. 4
</bodyText>
<sectionHeader confidence="0.998874" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.998606">
We have described our efforts in language iden-
tification in a multilingual corpus of Alpine texts.
As part of corpus annotation we have identified
the language of each corpus sentence amongst En-
glish, French, Standard German, Swiss German,
</bodyText>
<footnote confidence="0.823387">
4. The complete sentence is : Un long Anglais, avec le-
quel, dans le hall familial, je m’essaie a` ´echanger laborieu-
sement quelques impressions a` ce sujet, me dit : &lt;cI love to be
mothered.&gt;
</footnote>
<page confidence="0.999835">
31
</page>
<bodyText confidence="0.999871979166667">
Italian and Romansh. Furthermore we have de-
veloped an algorithm to identify intra-sentential
code-switching by analyzing sentence parts in
quotation marks that contain “unknown” lemmas.
We have shown that token sequences that
amount to 15 or more characters can be judged by
a state-of-the-art language identifier and will result
in 78% correctly labeled code-switches. Another
14% are code-switches but with a language dif-
ferent from the auto-assigned language. Only 8%
are not code-switches at all.
There are many ways to continue and extend
this research. We have not included language iden-
tification for Swiss German nor for Romansh in
the intra-sentential code-switch experiments re-
ported in this paper. We will train language models
for these two languages and add them to Langid
to check the impact on the recognition accuracy.
Since code-switches into Romansh are rare, and
since Romansh can easily be confused with Ita-
lian, it is questionable whether the addition of this
language model will have a positive influence.
We have used the “general-purpose” language
identifier Langid in these experiments. It will be
interesting to investigate language identifiers that
are optimized for short text fragments as discus-
sed by Vatanen et al. (2010). Given the relati-
vely high number of short quotations (31%) that
contain code-switches, recall could improve consi-
derably.
In this paper we have focused solely on code-
switching candidates that are triggered by pairs of
quotation marks. In order to increase the recall we
will certainly enlarge the set of triggers to other in-
dicators such as parentheses or commas. We have
briefly looked at parentheses as trigger symbols
and found them clearly less productive than quo-
tation marks. To also find code-switches that have
no overt marker remains the ultimate goal.
Finally, we will exploit the parallel parts of our
corpus. If a sentence in German contains a French
segment, then it is likely that this French segment
occurs verbatim in the parallel French sentence.
Based on sentence and word alignment we will
search for identical phrases in both language ver-
sions. We hope that this will lead to high accuracy
code-switch data that we can use as training mate-
rial for machine learning experiments.
</bodyText>
<sectionHeader confidence="0.996557" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998992">
We would like to thank Michi Amsler and
Don Tuggener for useful comments on literature
and tools for language identification and code-
switching, as well as Patricia Scheurer for com-
ments and suggestions on the language use in
the SAC corpus. This research was supported
by the Swiss National Science Foundation under
grant CRSII2 147653/1 through the project “MO-
DERN : Modelling discourse entities and relations
for coherent machine translation”.
</bodyText>
<sectionHeader confidence="0.999182" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993456136363636">
Anne Abeill´e, Lionel Cl´ement, and Francois Tousse-
nel. 2003. Building a Treebank for French. In Anne
Abeill´e, editor, Building and Using Parsed Corpora,
volume 20 of Text, Speech and Language Tech-
nology, chapter 10, pages 165–187. Kluwer, Dor-
drecht.
Heike Adel, Ngoc Thang Vu, and Tanja Schultz. 2013.
Combination of recurrent neural networks and fac-
tored language models for code-switching language
modeling. In Proceedings of the 51st Annual Mee-
ting of the Association for Computational Linguis-
tics (ACL), Sofia.
Sarah Ebling, Rico Sennrich, David Klaper, and Martin
Volk. 2011. Digging for names in the mountains :
Combined person name recognition and reference
resolution for German alpine texts. In Proceedings
of The 5th Language &amp; Technology Conference :
Human Language Technologies as a Challenge for
Computer Science and Linguistics, Poznan.
Fei Huang and Alexander Yates. 2014. Improving
word alignment using linguistic code switching data.
In Proceedings of the 14th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics, pages 1–9, G¨oteborg.
Baden Hughes, Timothy Baldwin, Steven Bird, Jeremy
Nicholson, and Andrew Mackinlay. 2006. Reconsi-
dering language identification for written language
resources. In Proceedings of LREC 2006, pages
485–488, Genoa.
Marcus Kracht and Udo Klein. 2014. The grammar
of code switching. Journal of Logic, Language and
Information, 23(3) :313–329.
Marco Lui and Timothy Baldwin. 2011. Cross-
domain feature selection for language identification.
In Proceedings of 5th International Joint Conference
on Natural Language Processing, pages 553–561,
Chiang Mai, Thailand. Asian Federation of Natural
Language Processing.
Katrin Rettich. 2013. Automatische Annotation
von deutschen und franz¨osischen temporalen Aus-
dr¨ucken im Text+Berg-Korpus. Master thesis, Uni-
versit¨at Z¨urich, Institut f¨ur Computerlinguistik.
Rico Sennrich and Martin Volk. 2011. Itera-
tive, MT-based sentence alignment of parallel texts.
</reference>
<page confidence="0.988009">
32
</page>
<reference confidence="0.999319275862069">
In Proceedings of The 18th International Nordic
Conference of Computational Linguistics (Noda-
lida), Riga.
Thamar Solorio and Yang Liu. 2008. Learning to pre-
dict code-switching points. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 973–981, Honolulu. Asso-
ciation for Computational Linguistics.
Tommi Vatanen, Jaakko J. V¨ayrynen, and Sami Vir-
pioja. 2010. Language identification of short text
segments with n-gram models. In Proceedings of
LREC, pages 3423–3430, Malta.
Martin Volk, Noah Bubenhofer, Adrian Althaus, Maya
Bangerter, Lenz Furrer, and Beni Ruef. 2010. Chal-
lenges in building a multilingual alpine heritage cor-
pus. In Proceedings of LREC, Valletta, Malta.
Martin Volk, Lenz Furrer, and Rico Sennrich. 2011.
Strategies for reducing and correcting OCR errors.
In C. Sporleder, A. van den Bosch, and K. Zerva-
nou, editors, Language Technology for Cultural He-
ritage : Selected Papers from the LaTeCH Work-
shop Series, Theory and Applications of Natural
Language Processing, pages 3–22. Springer-Verlag,
Berlin.
Ngoc Thang Vu, Heike Adel, and Tanja Schultz.
2013. An investigation of code-switching atti-
tude dependent language modeling. In Statistical
Language and Speech Processing, pages 297–308.
Springer.
</reference>
<page confidence="0.99937">
33
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.537553">
<title confidence="0.999626">Detecting Code-Switching in a Multilingual Alpine Heritage Corpus</title>
<author confidence="0.997823">Martin Volk</author>
<author confidence="0.997823">Simon</author>
<affiliation confidence="0.9981755">University of Institute of Computational</affiliation>
<email confidence="0.588248">volk|siclemat@cl.uzh.ch</email>
<abstract confidence="0.99555155">This paper describes experiments in detecting and annotating code-switching in a large multilingual diachronic corpus of Swiss Alpine texts. The texts are in English, French, German, Italian, Romansh and Swiss German. Because of the multilingual authors (mountaineers, scientists) and the assumed multilingual readers, the texts contain numerous code-switching elements. When building and annotating the corpus, we faced issues of language identification on the sentence and subsentential level. We present our strategy for language identification and for the annotation of foreign language fragments within sentences. We report 78% precision on detecting a subset of code-switches with correct language labels and 92% unlabeled precision.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Cl´ement</author>
<author>Francois Toussenel</author>
</authors>
<title>Building a Treebank for French.</title>
<date>2003</date>
<booktitle>Building and Using Parsed Corpora,</booktitle>
<volume>20</volume>
<pages>165--187</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>Anne Abeill´e, Lionel Cl´ement, and Francois Toussenel. 2003. Building a Treebank for French. In Anne Abeill´e, editor, Building and Using Parsed Corpora, volume 20 of Text, Speech and Language Technology, chapter 10, pages 165–187. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Adel</author>
<author>Ngoc Thang Vu</author>
<author>Tanja Schultz</author>
</authors>
<title>Combination of recurrent neural networks and factored language models for code-switching language modeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Sofia.</location>
<contexts>
<context position="15275" citStr="Adel et al. (2013)" startWordPosition="2389" endWordPosition="2392">robability plus the lemma as provided by both the Spanish and the English TreeTagger as well as the position of the word in the Beginning-Inside-Outside scheme as features for making the decision. In order to keep the number of experiments manageable they restricted their history to one or two preceding words. As an interesting experiment they generated code-switching sentences Spanish-English based on their different predictors and asked human judges to rate the naturalness of the resulting sentences. This helped them to identify the most useful code-switching predictor. Vu et al. (2013) and Adel et al. (2013) consider English-Mandarin code-switching in speech recognition. They investigate recurrent neural network language models and factored language models to the task in an attempt to integrate syntactic features. For the experiments they use SEAME, in old German spellings. Since these varieties are rare in the corpus, we do not deal with them explicitly. 27 the South East Asia Mandarin-English speech corpus compiled from Singaporean and Malaysian speakers. It consists of spontaneous interviews and conversations. The transcriptions were cleaned and each word was manually tagged as English, Mandar</context>
</contexts>
<marker>Adel, Vu, Schultz, 2013</marker>
<rawString>Heike Adel, Ngoc Thang Vu, and Tanja Schultz. 2013. Combination of recurrent neural networks and factored language models for code-switching language modeling. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), Sofia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah Ebling</author>
<author>Rico Sennrich</author>
<author>David Klaper</author>
<author>Martin Volk</author>
</authors>
<title>Digging for names in the mountains : Combined person name recognition and reference resolution for German alpine texts.</title>
<date>2011</date>
<booktitle>In Proceedings of The 5th Language &amp; Technology Conference : Human Language Technologies as a Challenge for Computer Science and Linguistics,</booktitle>
<location>Poznan.</location>
<contexts>
<context position="11596" citStr="Ebling et al., 2011" startWordPosition="1795" endWordPosition="1798">utomatically converted to text. The subsequent yearbooks from 2010 until 2013 we received as XML files from the SAC. We have turned the whole corpus into a uniform XML format. For this, the OCR output texts as well as the texts converted from PDF and XML are structured and annotated by automatically marking article boundaries, by tokenization, language identification, Part-of-Speech tagging and lemmatization. Our processing pipeline also includes toponym recognition and geo-coding of mountains, glaciers, cabins, valleys, lakes and towns. Furthermore we recognize and co-reference person names (Ebling et al., 2011), and we annotate temporal expressions (date, time, duration and set) with a variant of HeidelTime (Rettich, 2013). Finally we analyze the parallel parts of our corpus and provide sentence alignment information that is computed via BLEUalign (Sennrich and Volk, 2011). In order to process our texts with languagespecific tools (e.g. PoS tagging and person name recognition) we employed automatic language identification on the sentence level. We used Lingua-Ident 2 (developed by Michael Piotrowski) to determine for each sentence in our corpus whether it is in English, French, German, Italian or Ro</context>
</contexts>
<marker>Ebling, Sennrich, Klaper, Volk, 2011</marker>
<rawString>Sarah Ebling, Rico Sennrich, David Klaper, and Martin Volk. 2011. Digging for names in the mountains : Combined person name recognition and reference resolution for German alpine texts. In Proceedings of The 5th Language &amp; Technology Conference : Human Language Technologies as a Challenge for Computer Science and Linguistics, Poznan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Alexander Yates</author>
</authors>
<title>Improving word alignment using linguistic code switching data.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="16193" citStr="Huang and Yates (2014)" startWordPosition="2542" endWordPosition="2545">e rare in the corpus, we do not deal with them explicitly. 27 the South East Asia Mandarin-English speech corpus compiled from Singaporean and Malaysian speakers. It consists of spontaneous interviews and conversations. The transcriptions were cleaned and each word was manually tagged as English, Mandarin or other. The data consists of an intensive mix of the two languages with the average duration of both English and Mandarin segments to be less than a second ( !). In order to assign PoS tags to this mixed language corpus, the authors applied two monolingual taggers and combined the results. Huang and Yates (2014) also work on the detection of English-Chinese code-switching but not on speech but rather on web forum texts produced by Chinese speakers living in the US. They use statistical word alignment and a Chinese language model to substitute English words in Chinese sentences with suitable Chinese words. Preparing the data in this way significantly improved Machine Translation quality. Their approach is limited to two known languages and to very short code-switching phrases (typically only one word). Tim Baldwin and his group (Hughes et al., 2006) have surveyed the approaches to language identificat</context>
</contexts>
<marker>Huang, Yates, 2014</marker>
<rawString>Fei Huang and Alexander Yates. 2014. Improving word alignment using linguistic code switching data. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 1–9, G¨oteborg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baden Hughes</author>
<author>Timothy Baldwin</author>
<author>Steven Bird</author>
<author>Jeremy Nicholson</author>
<author>Andrew Mackinlay</author>
</authors>
<title>Reconsidering language identification for written language resources.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC</booktitle>
<pages>485--488</pages>
<location>Genoa.</location>
<contexts>
<context position="16740" citStr="Hughes et al., 2006" startWordPosition="2633" endWordPosition="2636"> two monolingual taggers and combined the results. Huang and Yates (2014) also work on the detection of English-Chinese code-switching but not on speech but rather on web forum texts produced by Chinese speakers living in the US. They use statistical word alignment and a Chinese language model to substitute English words in Chinese sentences with suitable Chinese words. Preparing the data in this way significantly improved Machine Translation quality. Their approach is limited to two known languages and to very short code-switching phrases (typically only one word). Tim Baldwin and his group (Hughes et al., 2006) have surveyed the approaches to language identification at the time. They found a number of missing issues, such as language identification for minority languages, open class language identification (in contrast to identification within a fixed set of languages), sparse training data, varying encodings, and multilingual documents. Subsequently they (Lui and Baldwin, 2011) introduced a system for language identification of 97 languages trained on a mixture of corpora from different domains. They claim that their system Langid is particularly well suited for classifying short input strings (as </context>
</contexts>
<marker>Hughes, Baldwin, Bird, Nicholson, Mackinlay, 2006</marker>
<rawString>Baden Hughes, Timothy Baldwin, Steven Bird, Jeremy Nicholson, and Andrew Mackinlay. 2006. Reconsidering language identification for written language resources. In Proceedings of LREC 2006, pages 485–488, Genoa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcus Kracht</author>
<author>Udo Klein</author>
</authors>
<title>The grammar of code switching.</title>
<date>2014</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>23</volume>
<issue>3</issue>
<pages>313--329</pages>
<contexts>
<context position="4310" citStr="Kracht and Klein (2014)" startWordPosition="690" endWordPosition="693">Code Switching, pages 24–33, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics the special symbol @fn@ to set it apart from lemmas of the surrounding sentence. In this paper we report on our experiments towards this goal and suggest an algorithm for detecting code-switching. We adopt a wide definition of code-switching. We are interested in detecting all instances where a text is in a dominant language and contains words, phrases and sentences in another language. Though our definition is broad, it is clearly more restricted than others, as e.g. the definition by Kracht and Klein (2014) which includes special purpose codes like bank account numbers or shoe sizes. In this paper we will give an overview of the language mix in the yearbooks of the Swiss Alpine Club over the 150 years, and we will illustrate how we identified inter-sentential and intrasentential code-switching. We will give a quantitative overview of the number of code-switching candidates that we automatically located. 2 The Text+Berg Corpus The Text+Berg corpus comprises the annual publications of the Swiss Alpine Club (SAC) from its first edition in 1864 until 2013. From the start until 1923 the official year</context>
</contexts>
<marker>Kracht, Klein, 2014</marker>
<rawString>Marcus Kracht and Udo Klein. 2014. The grammar of code switching. Journal of Logic, Language and Information, 23(3) :313–329.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>Crossdomain feature selection for language identification.</title>
<date>2011</date>
<journal>Chiang Mai, Thailand. Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>553--561</pages>
<contexts>
<context position="17115" citStr="Lui and Baldwin, 2011" startWordPosition="2687" endWordPosition="2690">Preparing the data in this way significantly improved Machine Translation quality. Their approach is limited to two known languages and to very short code-switching phrases (typically only one word). Tim Baldwin and his group (Hughes et al., 2006) have surveyed the approaches to language identification at the time. They found a number of missing issues, such as language identification for minority languages, open class language identification (in contrast to identification within a fixed set of languages), sparse training data, varying encodings, and multilingual documents. Subsequently they (Lui and Baldwin, 2011) introduced a system for language identification of 97 languages trained on a mixture of corpora from different domains. They claim that their system Langid is particularly well suited for classifying short input strings (as in Twitter messages). We therefore tested Langid in our experiments for code-switching detection. 5 Exploratory Experiments with the SAC Yearbook 1925 In order to assess the performance of Langid for the detection of code-switching we performed an exploratory experiment with the SAC yearbook 1925. We extracted all word sequences between pairs of quotation marks where at le</context>
</contexts>
<marker>Lui, Baldwin, 2011</marker>
<rawString>Marco Lui and Timothy Baldwin. 2011. Crossdomain feature selection for language identification. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 553–561, Chiang Mai, Thailand. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Rettich</author>
</authors>
<title>Automatische Annotation von deutschen und franz¨osischen temporalen Ausdr¨ucken im Text+Berg-Korpus. Master thesis,</title>
<date>2013</date>
<institution>Universit¨at Z¨urich, Institut f¨ur Computerlinguistik.</institution>
<contexts>
<context position="11710" citStr="Rettich, 2013" startWordPosition="1814" endWordPosition="1815">have turned the whole corpus into a uniform XML format. For this, the OCR output texts as well as the texts converted from PDF and XML are structured and annotated by automatically marking article boundaries, by tokenization, language identification, Part-of-Speech tagging and lemmatization. Our processing pipeline also includes toponym recognition and geo-coding of mountains, glaciers, cabins, valleys, lakes and towns. Furthermore we recognize and co-reference person names (Ebling et al., 2011), and we annotate temporal expressions (date, time, duration and set) with a variant of HeidelTime (Rettich, 2013). Finally we analyze the parallel parts of our corpus and provide sentence alignment information that is computed via BLEUalign (Sennrich and Volk, 2011). In order to process our texts with languagespecific tools (e.g. PoS tagging and person name recognition) we employed automatic language identification on the sentence level. We used Lingua-Ident 2 (developed by Michael Piotrowski) to determine for each sentence in our corpus whether it is in English, French, German, Italian or Romansh. Lingua-Ident is a statistical language identifier based on letter n-gram frequencies. For long sentences it</context>
</contexts>
<marker>Rettich, 2013</marker>
<rawString>Katrin Rettich. 2013. Automatische Annotation von deutschen und franz¨osischen temporalen Ausdr¨ucken im Text+Berg-Korpus. Master thesis, Universit¨at Z¨urich, Institut f¨ur Computerlinguistik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rico Sennrich</author>
<author>Martin Volk</author>
</authors>
<title>Iterative, MT-based sentence alignment of parallel texts.</title>
<date>2011</date>
<booktitle>In Proceedings of The 18th International Nordic Conference of Computational Linguistics (Nodalida),</booktitle>
<location>Riga.</location>
<contexts>
<context position="11863" citStr="Sennrich and Volk, 2011" startWordPosition="1837" endWordPosition="1840">ctured and annotated by automatically marking article boundaries, by tokenization, language identification, Part-of-Speech tagging and lemmatization. Our processing pipeline also includes toponym recognition and geo-coding of mountains, glaciers, cabins, valleys, lakes and towns. Furthermore we recognize and co-reference person names (Ebling et al., 2011), and we annotate temporal expressions (date, time, duration and set) with a variant of HeidelTime (Rettich, 2013). Finally we analyze the parallel parts of our corpus and provide sentence alignment information that is computed via BLEUalign (Sennrich and Volk, 2011). In order to process our texts with languagespecific tools (e.g. PoS tagging and person name recognition) we employed automatic language identification on the sentence level. We used Lingua-Ident 2 (developed by Michael Piotrowski) to determine for each sentence in our corpus whether it is in English, French, German, Italian or Romansh. Lingua-Ident is a statistical language identifier based on letter n-gram frequencies. For long sentences it reliably distinguishes between the languages. Unfortunately it often misclassifies short sentences. Therefore we decided to use it only for sentences wi</context>
</contexts>
<marker>Sennrich, Volk, 2011</marker>
<rawString>Rico Sennrich and Martin Volk. 2011. Iterative, MT-based sentence alignment of parallel texts. In Proceedings of The 18th International Nordic Conference of Computational Linguistics (Nodalida), Riga.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thamar Solorio</author>
<author>Yang Liu</author>
</authors>
<title>Learning to predict code-switching points.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>973--981</pages>
<institution>Honolulu. Association for Computational Linguistics.</institution>
<contexts>
<context position="14375" citStr="Solorio and Liu (2008)" startWordPosition="2240" endWordPosition="2243"> bemerkt dar¨uber : “On peut remarquer a` cette occasion qu’il est rare que par un effort de l’esprit on puisse mettre du brouillard en bouteille, et ... ” Die etwas ¨altere Sektion Diablerets, deren Steuer Herr August Bernus mit kundiger Hand ... Most code-switching occurs with direct speech, quotes and book titles. The communicative goal is obviously to make the text more authentic. 4 Related Work on Detection of Code-Switching Most previous work on automatically detecting code-switching focused on the switches between two known languages (whereas we have to deal with a mix of 6 languages). Solorio and Liu (2008) worked on real-time prediction of code-switching points in SpanishEnglish conversations. This means that the judgement whether the current word is in a different language than the language of the matrix clause can only be based on the previous words. They use the PoS tag and its probability plus the lemma as provided by both the Spanish and the English TreeTagger as well as the position of the word in the Beginning-Inside-Outside scheme as features for making the decision. In order to keep the number of experiments manageable they restricted their history to one or two preceding words. As an </context>
</contexts>
<marker>Solorio, Liu, 2008</marker>
<rawString>Thamar Solorio and Yang Liu. 2008. Learning to predict code-switching points. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 973–981, Honolulu. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tommi Vatanen</author>
<author>Jaakko J V¨ayrynen</author>
<author>Sami Virpioja</author>
</authors>
<title>Language identification of short text segments with n-gram models.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>3423--3430</pages>
<marker>Vatanen, V¨ayrynen, Virpioja, 2010</marker>
<rawString>Tommi Vatanen, Jaakko J. V¨ayrynen, and Sami Virpioja. 2010. Language identification of short text segments with n-gram models. In Proceedings of LREC, pages 3423–3430, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
<author>Noah Bubenhofer</author>
<author>Adrian Althaus</author>
<author>Maya Bangerter</author>
<author>Lenz Furrer</author>
<author>Beni Ruef</author>
</authors>
<title>Challenges in building a multilingual alpine heritage corpus.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Valletta,</location>
<contexts>
<context position="5229" citStr="Volk et al., 2010" startWordPosition="851" endWordPosition="854"> give a quantitative overview of the number of code-switching candidates that we automatically located. 2 The Text+Berg Corpus The Text+Berg corpus comprises the annual publications of the Swiss Alpine Club (SAC) from its first edition in 1864 until 2013. From the start until 1923 the official yearbook was called “Jahrbuch des Schweizer Alpen-Club” (EN : yearbook of the Swiss Alpine Club), and it typically consisted of 500 to 700 pages. The articles of these first 60 years were mostly in German (with 86% of the words), but some also in French (13% of the words) and few in Italian and Romansh (Volk et al., 2010). Interestingly, the German articles contained passages in French and sometimes other languages (e.g. English, Swiss German, Latin) without translations, and vice versa. Obviously, the article authors and yearbook editors assumed that the readers of the yearbook were polyglott at least in English, French, German and Latin during that time. In fact, the members of the SAC in the 19th century came from an academic elite. Mountain exploration was a past-time of the rich and educated. Still, during that same time the French-speaking sections of the Swiss Alpine Club published their own yearbook in</context>
</contexts>
<marker>Volk, Bubenhofer, Althaus, Bangerter, Furrer, Ruef, 2010</marker>
<rawString>Martin Volk, Noah Bubenhofer, Adrian Althaus, Maya Bangerter, Lenz Furrer, and Beni Ruef. 2010. Challenges in building a multilingual alpine heritage corpus. In Proceedings of LREC, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
<author>Lenz Furrer</author>
<author>Rico Sennrich</author>
</authors>
<title>Strategies for reducing and correcting OCR errors.</title>
<date>2011</date>
<booktitle>Language Technology for Cultural Heritage : Selected Papers from the LaTeCH Workshop Series, Theory and Applications of Natural Language Processing,</booktitle>
<pages>3--22</pages>
<editor>In C. Sporleder, A. van den Bosch, and K. Zervanou, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="8269" citStr="Volk et al., 2011" startWordPosition="1370" endWordPosition="1373">ens (after tokenization). French and German account for around 22 million tokens each, Italian accounts for 0.8 million tokens. The remainder goes to English, Latin, Romansh and Swiss German. The corpus is freely available for research purposes upon request. 3 Language Identification in the Text+Berg Corpus We compiled the Text+Berg corpus by scanning all SAC yearbooks from 1864 until 2000 (around 100,000+ pages). Afterwards we employed commercial OCR software to convert the scan images into electronic text. We developed and applied techniques to automatically reduce the number of OCR errors (Volk et al., 2011). We obtained the yearbooks from 2001 to 25 de la publication du Mount Everest 1938 2 de Tilman. L&apos;Appendix B, intitule: Antropolosy or Zoology, with Particular Reference to the Abominable Snowman, reprend la question ab ovo 3, en la soumettant, pp. 127-137, a tine enquate stricternent impartiale. La conclusion de cette enqute est re&apos;sum6e dans les sept dernieres lignes de la page 137; «I merely affirm that traces for which no adequate explanation is forthcoming have been seen and will continue to be seen in various parts of the Himalaya, and until a worthier claimant is found we may as well a</context>
</contexts>
<marker>Volk, Furrer, Sennrich, 2011</marker>
<rawString>Martin Volk, Lenz Furrer, and Rico Sennrich. 2011. Strategies for reducing and correcting OCR errors. In C. Sporleder, A. van den Bosch, and K. Zervanou, editors, Language Technology for Cultural Heritage : Selected Papers from the LaTeCH Workshop Series, Theory and Applications of Natural Language Processing, pages 3–22. Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ngoc Thang Vu</author>
<author>Heike Adel</author>
<author>Tanja Schultz</author>
</authors>
<title>An investigation of code-switching attitude dependent language modeling.</title>
<date>2013</date>
<booktitle>In Statistical Language and Speech Processing,</booktitle>
<pages>297--308</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="15252" citStr="Vu et al. (2013)" startWordPosition="2384" endWordPosition="2387">the PoS tag and its probability plus the lemma as provided by both the Spanish and the English TreeTagger as well as the position of the word in the Beginning-Inside-Outside scheme as features for making the decision. In order to keep the number of experiments manageable they restricted their history to one or two preceding words. As an interesting experiment they generated code-switching sentences Spanish-English based on their different predictors and asked human judges to rate the naturalness of the resulting sentences. This helped them to identify the most useful code-switching predictor. Vu et al. (2013) and Adel et al. (2013) consider English-Mandarin code-switching in speech recognition. They investigate recurrent neural network language models and factored language models to the task in an attempt to integrate syntactic features. For the experiments they use SEAME, in old German spellings. Since these varieties are rare in the corpus, we do not deal with them explicitly. 27 the South East Asia Mandarin-English speech corpus compiled from Singaporean and Malaysian speakers. It consists of spontaneous interviews and conversations. The transcriptions were cleaned and each word was manually ta</context>
</contexts>
<marker>Vu, Adel, Schultz, 2013</marker>
<rawString>Ngoc Thang Vu, Heike Adel, and Tanja Schultz. 2013. An investigation of code-switching attitude dependent language modeling. In Statistical Language and Speech Processing, pages 297–308. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>