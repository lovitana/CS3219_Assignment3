<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004973">
<title confidence="0.978969">
SPIED: Stanford Pattern-based Information Extraction and Diagnostics
</title>
<author confidence="0.997009">
Sonal Gupta Christopher D. Manning
</author>
<affiliation confidence="0.9860035">
Department of Computer Science
Stanford University
</affiliation>
<email confidence="0.993436">
{sonal, manning}@cs.stanford.edu
</email>
<sectionHeader confidence="0.993721" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999937148148148">
This paper aims to provide an effective
interface for progressive refinement of
pattern-based information extraction sys-
tems. Pattern-based information extrac-
tion (IE) systems have an advantage over
machine learning based systems that pat-
terns are easy to customize to cope with
errors and are interpretable by humans.
Building a pattern-based system is usually
an iterative process of trying different pa-
rameters and thresholds to learn patterns
and entities with high precision and recall.
Since patterns are interpretable to humans,
it is possible to identify sources of errors,
such as patterns responsible for extract-
ing incorrect entities and vice-versa, and
correct them. However, it involves time
consuming manual inspection of the ex-
tracted output. We present a light-weight
tool, SPIED, to aid IE system develop-
ers in learning entities using patterns with
bootstrapping, and visualizing the learned
entities and patterns with explanations.
SPIED is the first publicly available tool to
visualize diagnostic information of multi-
ple pattern learning systems to the best of
our knowledge.
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99986202">
Entity extraction using rules dominates commer-
cial industry, mainly because rules are effective,
interpretable by humans, and easy to customize to
cope with errors (Chiticariu et al., 2013). Rules,
which can be hand crafted or learned by a sys-
tem, are commonly created by looking at the con-
text around already known entities, such as surface
word patterns (Hearst, 1992) and dependency pat-
terns (Yangarber et al., 2000). Building a pattern-
based learning system is usually a repetitive pro-
cess, usually performed by the system developer,
of manually examining a system’s output to iden-
tify improvements or errors introduced by chang-
ing the entity or pattern extractor. Interpretabil-
ity of patterns makes it easier for humans to iden-
tify sources of errors by inspecting patterns that
extracted incorrect instances or instances that re-
sulted in learning of bad patterns. Parameters
range from window size of the context in surface
word patterns to thresholds for learning a candi-
date entity. At present, there is a lack of tools
helping a system developer to understand results
and to improve results iteratively.
Visualizing diagnostic information of a system
and contrasting it with another system can make
the iterative process easier and more efficient. For
example, consider a user trying to decide on the
context’s window size in surface words patterns.
And the user deliberates that part-of-speech (POS)
restriction of context words might be required for
a reduced window size to avoid extracting erro-
neous mentions.1 By comparing and contrasting
extractions of two systems with different parame-
ters, the user can investigate the cases in which the
POS restriction is required with smaller window
size, and whether the restriction causes the system
to miss some correct entities. In contrast, compar-
ing just accuracy of two systems does not allow
inspecting finer details of extractions that increase
or decrease accuracy and to make changes accord-
ingly.
In this paper, we present a pattern-based entity
learning and diagnostics tool, SPIED. It consists
of two components: 1. pattern-based entity learn-
ing using bootstrapping (SPIED-Learn), and 2. vi-
sualizing the output of one or two entity learning
systems (SPIED-Viz). SPIED-Viz is independent
of SPIED-Learn and can be used with any pattern-
based entity learner. For demonstration, we use
the output of SPIED-Learn as an input to SPIED-
</bodyText>
<footnote confidence="0.996795">
1A shorter context size usually extracts entities with
higher recall but lower precision.
</footnote>
<page confidence="0.989404">
38
</page>
<note confidence="0.303602">
Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 38–44,
</note>
<page confidence="0.322849">
Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics
</page>
<bodyText confidence="0.99978244">
Viz. SPIED-Viz has pattern-centric and entity-
centric views, which visualize learned patterns
and entities, respectively, and the explanations for
learning them. SPIED-Viz can also contrast two
systems by comparing the ranks of learned enti-
ties and patterns. In this paper, as a concrete ex-
ample, we learn and visualize drug-treatment (DT)
entities from unlabeled patient-generated medical
text, starting with seed dictionaries of entities for
multiple classes. The task was proposed and fur-
ther developed in Gupta and Manning (2014b)
and Gupta and Manning (2014a).
Our contributions in this paper are: 1. we
present a novel diagnostic tool for visual-
ization of output of multiple pattern-based
entity learning systems, and 2. we release the
code of an end-to-end pattern learning sys-
tem, which learns entities using patterns in a
bootstrapped system and visualizes its diag-
nostic output. The pattern learning code is
available at http://nlp.stanford.edu/
software/patternslearning.shtml.
The visualization code is available at
http://nlp.stanford.edu/software/
patternviz.shtml.
</bodyText>
<subsectionHeader confidence="0.505473">
2 Learning Patterns and Entities
</subsectionHeader>
<bodyText confidence="0.999925933333333">
Bootstrapped systems have been commonly used
to learn entities (Riloff, 1996; Collins and Singer,
1999). SPIED-Learn is based on the system de-
scribed in Gupta and Manning (2014a), which
builds upon the previous bootstrapped pattern-
learning work and proposed an improved mea-
sure to score patterns (Step 3 below). It learns
entities for given classes from unlabeled text by
bootstrapping from seed dictionaries. Patterns
are learned using labeled entities, and entities are
learned based on the extractions of learned pat-
terns. The process is iteratively performed until
no more patterns or entities can be learned. The
following steps give a short summary of the itera-
tive learning of entities belonging to a class DT:
</bodyText>
<listItem confidence="0.997434130434783">
1. Data labeling: The text is labeled using the
class dictionaries, starting with the seed dic-
tionaries in the first iteration. A phrase
matching a dictionary phrase is labeled with
the dictionary’s class.
2. Pattern generation: Patterns are generated us-
ing the context around the positively labeled
entities to create candidate patterns for DT.
3. Pattern learning: Candidate patterns are
scored using a pattern scoring measure and
the top ones are added to the list of learned
patterns for DT. The maximum number of
patterns learned is given as an input to the
system by the developer.
4. Entity learning: Learned patterns for the class
are applied to the text to extract candidate en-
tities. An entity scorer ranks the candidate
entities and adds the top entities to DT’s dic-
tionary. The maximum number of entities
learned is given as an input to the system by
the developer.
5. Repeat steps 1-4 for a given number of itera-
tions.
</listItem>
<bodyText confidence="0.999733909090909">
SPIED provides an option to use any of the pat-
tern scoring measures described in (Riloff, 1996;
Thelen and Riloff, 2002; Yangarber et al., 2002;
Lin et al., 2003; Gupta and Manning, 2014b). A
pattern is scored based on the positive, negative,
and unlabeled entities it extracts. The positive and
negative labels of entities are heuristically deter-
mined by the system using the dictionaries and the
iterative entity learning process. The oracle labels
of learned entities are not available to the learning
system. Note that an entity that the system consid-
ered positive might actually be incorrect, since the
seed dictionaries can be noisy and the system can
learn incorrect entities in the previous iterations,
and vice-versa. SPIED’s entity scorer is the same
as in Gupta and Manning (2014a).
Each candidate entity is scored using weights of
the patterns that extract it and other entity scoring
measures, such as TF-IDF. Thus, learning of each
entity can be explained by the learned patterns that
extract it, and learning of each pattern can be ex-
plained by all the entities it extracts.
</bodyText>
<sectionHeader confidence="0.976449" genericHeader="method">
3 Visualizing Diagnostic Information
</sectionHeader>
<bodyText confidence="0.9994418">
SPIED-Viz visualizes learned entities and patterns
from one or two entity learning systems, and the
diagnostic information associated with them. It
optionally uses the oracle labels of learned enti-
ties to color code them, and contrast their ranks
of correct/incorrect entities when comparing two
systems. The oracle labels are usually determined
by manually judging each learned entity as cor-
rect or incorrect. SPIED-Viz has two views: 1. a
pattern-centric view that visualizes patterns of one
</bodyText>
<page confidence="0.9938665">
39
40
</page>
<figureCaption confidence="0.999599">
Figure 1: Entity centric view of SPIED-Viz. The interface allows the user to drill down the results to diagnose extraction of correct and incorrect entities, and
</figureCaption>
<bodyText confidence="0.898079333333333">
An star sign for an
contrast the details of the two systems. The entities that are not learned by the other system are marked with either atrophy (correct entity), a thumbs down
entity indicates the
</bodyText>
<equation confidence="0.659317">
(incorrect entity), or a star icon (oracle label missing), for easy identification.
it og
tt
</equation>
<footnote confidence="0.628139888888889">
it of titis
d t h
ration. Green
olor indicates
the enity is
orrect and red
or indicates
the entity is
incorrect.
</footnote>
<page confidence="0.992781">
41
</page>
<figure confidence="0.99051505">
n exclamationwere
ignindicates that
less han half of
y
h correct label the
Greensystem color of
entity indicatesii
hat the entity was
List of patternspatter
vaslearnedatlearned each
iteration. Blue
List of entities
econsidered inict
hat the pattern
not learned by
the other negative
1 -I system - 11-
Listsystem of entities
onsidered as
ve, nega
</figure>
<figureCaption confidence="0.97162275">
Figure 2: Pattern centric view of SPIED-Viz.
Figure 3: When the user click on the compare icon for an entity, the explanations of the entity extraction
for both systems (if available) are displayed. This allows direct comparison of why the two systems
learned the entity.
</figureCaption>
<bodyText confidence="0.998826859375">
to two systems, and 2. an entity centric view that
mainly focuses on the entities learned. Figure 1
shows a screenshot of the entity-centric view of
SPIED-Viz. It displays following information:
Summary: A summary information of each sys-
tem at each iteration and overall. It shows
for each system the number of iterations, the
number of patterns learned, and the number
of correct and incorrect entities learned.
Learned Entities with provenance: It shows
ranked list of entities learned by each system,
along with an explanation of why the entity
was learned. The details shown include the
entity’s oracle label, its rank in the other sys-
tem, and the learned patterns that extracted
the entity. Such information can help the user
to identify and inspect the patterns responsi-
ble for learning an incorrect entity. The inter-
face also provides a link to search the entity
along with any user provided keywords (such
as domain of the problem) on Google.
System Comparison: SPIED-Viz can be used to
compare entities learned by two systems. It
marks entities that are learned by one system
but not by the other system, by either display-
ing a trophy sign (if the entity is correct), a
thumbs down sign (if the entity is incorrect),
or a star sign (if the oracle label is not pro-
vided).
The second view of SPIED-Viz is pattern-
centric. Figure 2 shows a screenshot of the pattern-
centric view. It displays the following informa-
tion.
Summary: A summary information of each sys-
tem including the number of iterations and
number of patterns learned at each iteration
and overall.
Learned Patterns with provenance: It shows
ranked list of patterns along with the entities
it extracts and their labels. Note that each pat-
tern is associated with a set of positive, neg-
ative and unlabeled entities, which were used
to determine its score.2 It also shows the per-
centage of unlabeled entities extracted by a
pattern that were eventually learned by the
system and assessed as correct by the oracle.
A smaller percentage means that the pattern
extracted many entities that were either never
learned or learned but were labeled as incor-
rect by the oracle.
Figure 3 shows an option in the entity-centric
view when hovering over an entity opens a win-
dow on the side that shows the diagnostic informa-
tion of the entity learned by the other system. This
direct comparison is to directly contrast learning
of an entity by both systems. For example, it can
help the user to inspect why an entity was learned
at an earlier rank than the other system.
An advantage of making the learning entities
component and the visualization component inde-
pendent is that a developer can use any pattern
scorer or entity scorer in the system without de-
pending on the visualization component to provide
that functionality.
</bodyText>
<footnote confidence="0.71840975">
2Note that positive, negative, and unlabeled labels are dif-
ferent from the oracle labels, correct and incorrect, for the
learned entities. The former refer to the entity labels consid-
ered by the system when learning the pattern, and they come
from the seed dictionaries and the learned entities. A positive
entity considered by the system can be labeled as incorrect
by the human assessor, in case the system made a mistake in
labeling data, and vice-versa.
</footnote>
<page confidence="0.999008">
42
</page>
<sectionHeader confidence="0.984209" genericHeader="method">
4 System Details
</sectionHeader>
<bodyText confidence="0.999731833333333">
SPIED-Learn uses TokensRegex (Chang and
Manning, 2014) to create and apply surface word
patterns to text. SPIED-Viz takes details of
learned entities and patterns as input in a JSON
format. It uses Javascript, angular, and jquery to
visualize the information in a web browser.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.993285548387097">
Most interactive IE systems focus on annotation
of text, labeling of entities, and manual writing
of rules. Some annotation and labeling tools are:
MITRE’s Callisto3, Knowtator4, SAPIENT (Li-
akata et al., 2009), brat5, Melita (Ciravegna et al.,
2002), and XConc Suite (Kim et al., 2008). Akbik
et al. (2013) interactively helps non-expert users
to manually write patterns over dependency trees.
GATE6 provides the JAPE language that recog-
nizes regular expressions over annotations. Other
systems focus on reducing manual effort for de-
veloping extractors (Brauer et al., 2011; Li et al.,
2011). In contrast, our tool focuses on visualizing
and comparing diagnostic information associated
with pattern learning systems.
WizIE (Li et al., 2012) is an integrated environ-
ment for annotating text and writing pattern ex-
tractors for information extraction. It also gener-
ates regular expressions around labeled mentions
and suggests patterns to users. It is most similar
to our tool as it displays an explanation of the re-
sults extracted by a pattern. However, it is focused
towards hand writing and selection of rules. In ad-
dition, it cannot be used to directly compare two
pattern learning systems.
What’s Wrong With My NLP?7 is a tool for
jointly visualizing various natural language pro-
cessing formats such as trees, graphs, and entities.
It can be used alongside our system to visualize
the patterns since we mainly focus on diagnostic
information.
</bodyText>
<sectionHeader confidence="0.989929" genericHeader="conclusions">
6 Future Work and Conclusion
</sectionHeader>
<bodyText confidence="0.99682075">
We plan to add a feature for a user to provide
the oracle label of a learned entity using the in-
terface. Currently, the oracle labels are assigned
offline. We also plan to extend SPIED to visualize
</bodyText>
<footnote confidence="0.9999422">
3http://callisto.mitre.org
4http://knowtator.sourceforge.net
5http://brat.nlplab.org
6http://gate.ac.uk
7https://code.google.com/p/whatswrong
</footnote>
<bodyText confidence="0.999597409090909">
diagnostic information of learned relations from a
pattern-based relation learning system. Another
avenue of future work is to evaluate SPIED-Viz
by studying its users and their interactions with
the system. In addition, we plan to improve the
visualization by summarizing the diagnostic infor-
mation, such as which parameters led to what mis-
takes, to make it easier to understand for systems
that extract large number of patterns and entities.
In conclusion, we present a novel diagnostic
tool for pattern-based entity learning that visual-
izes and compares output of one to two systems.
It is light-weight web browser based visualization.
The visualization can be used with any pattern-
based entity learner. We make the code of an end-
to-end system freely available for research pur-
pose. The system learns entities and patterns using
bootstrapping starting with seed dictionaries, and
visualizes the diagnostic output. We hope SPIED
will help other researchers and users to diagnose
errors and tune parameters in their pattern-based
entity learning system in an easy and efficient way.
</bodyText>
<sectionHeader confidence="0.997484" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.947886275862069">
Alan Akbik, Oresti Konomi, and Michail Melnikov.
2013. Propminer: A workflow for interactive infor-
mation extraction and exploration using dependency
trees. In ACL (Conference System Demonstrations),
pages 157–162.
Falk Brauer, Robert Rieger, Adrian Mocan, and Woj-
ciech M. Barczynski. 2011. Enabling information
extraction by inference of regular expressions from
sample entities. In CIKM, pages 1285–1294.
Angel X. Chang and Christopher D. Manning. 2014.
TokensRegex: Defining cascaded regular expres-
sions over tokens. In Stanford University Technical
Report.
Laura Chiticariu, Yunyao Li, and Frederick R. Reiss.
2013. Rule-based information extraction is dead!
long live rule-based information extraction systems!
In Proceedings of the Conference on Empirical
Methods in Natural Language Processing, EMNLP
’13, pages 827–832.
Fabio Ciravegna, Alexiei Dingli, Daniela Petrelli, and
Yorick Wilks. 2002. User-system cooperation
in document annotation based on information ex-
traction. In In Proceedings of the 13th Interna-
tional Conference on Knowledge Engineering and
Knowledge Management, EKAW02, pages 122–137.
Springer Verlag.
Michael Collins and Yoram Singer. 1999. Unsuper-
vised models for named entity classification. In Pro-
ceedings of the Joint SIGDAT Conference on Empir-
</reference>
<page confidence="0.998683">
43
</page>
<reference confidence="0.99924375">
ical Methods in Natural Language Processing and
Very Large Corpora, pages 100–110.
Sonal Gupta and Christopher D. Manning. 2014a. Im-
proved pattern learning for bootstrapped entity ex-
traction. In Proceedings of the Eighteenth Confer-
ence on Computational Natural Language Learning
(CoNLL).
Sonal Gupta and Christopher D. Manning. 2014b. In-
duced lexico-syntactic patterns improve information
extraction from online medical forums. Under Sub-
mission.
Marti A Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th International Conference on Computational
linguistics, COLING ’92, pages 539–545.
Jin-Dong Kim, Tomoko Ohta, and Jun ichi Tsujii.
2008. Corpus annotation for mining biomedical
events from literature. BMC Bioinformatics.
Yunyao Li, Vivian Chu, Sebastian Blohm, Huaiyu
Zhu, and Howard Ho. 2011. Facilitating pat-
tern discovery for relation extraction with semantic-
signature-based clustering. In Proceedings of the
20th ACM International Conference on Informa-
tion and Knowledge Management, CIKM ’11, pages
1415–1424.
Yunyao Li, Laura Chiticariu, Huahai Yang, Freder-
ick R. Reiss, and Arnaldo Carreno-fuentes. 2012.
Wizie: A best practices guided development envi-
ronment for information extraction. In Proceedings
of the ACL 2012 System Demonstrations, ACL ’12,
pages 109–114.
Maria Liakata, Claire Q, and Larisa N. Soldatova.
2009. Semantic annotation of papers: Interface &amp;
enrichment tool (sapient). In Proceedings of the
BioNLP 2009 Workshop, pages 193–200.
Winston Lin, Roman Yangarber, and Ralph Grishman.
2003. Bootstrapped learning of semantic classes
from positive and negative examples. In Proceed-
ings of the ICML 2003 Workshop on The Continuum
from Labeled to Unlabeled Data in Machine Learn-
ing and Data Mining.
Ellen Riloff. 1996. Automatically generating extrac-
tion patterns from untagged text. In Proceedings
of the 13th National Conference on Artificial Intelli-
gence, AAAI’96, pages 1044–1049.
Michael Thelen and Ellen Riloff. 2002. A bootstrap-
ping method for learning semantic lexicons using
extraction pattern contexts. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP ’02, pages 214–221.
Roman Yangarber, Ralph Grishman, and Pasi
Tapanainen. 2000. Automatic acquisition of
domain knowledge for information extraction. In
Proceedings of the 18th International Conference
on Computational Linguistics, COLING ’00, pages
940–946.
Roman Yangarber, Winston Lin, and Ralph Grishman.
2002. Unsupervised learning of generalized names.
In Proceedings of the 19th International Conference
on Computational Linguistics, COLING ’02.
</reference>
<page confidence="0.999289">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.990869">
<title confidence="0.997072">SPIED: Stanford Pattern-based Information Extraction and Diagnostics</title>
<author confidence="0.999562">Sonal Gupta Christopher D Manning</author>
<affiliation confidence="0.9998785">Department of Computer Stanford University</affiliation>
<abstract confidence="0.999795607142857">This paper aims to provide an effective interface for progressive refinement of pattern-based information extraction systems. Pattern-based information extraction (IE) systems have an advantage over machine learning based systems that patterns are easy to customize to cope with errors and are interpretable by humans. Building a pattern-based system is usually an iterative process of trying different parameters and thresholds to learn patterns and entities with high precision and recall. Since patterns are interpretable to humans, it is possible to identify sources of errors, such as patterns responsible for extracting incorrect entities and vice-versa, and correct them. However, it involves time consuming manual inspection of the extracted output. We present a light-weight tool, SPIED, to aid IE system developers in learning entities using patterns with bootstrapping, and visualizing the learned entities and patterns with explanations. SPIED is the first publicly available tool to visualize diagnostic information of multiple pattern learning systems to the best of our knowledge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan Akbik</author>
<author>Oresti Konomi</author>
<author>Michail Melnikov</author>
</authors>
<title>Propminer: A workflow for interactive information extraction and exploration using dependency trees.</title>
<date>2013</date>
<booktitle>In ACL (Conference System Demonstrations),</booktitle>
<pages>157--162</pages>
<contexts>
<context position="13421" citStr="Akbik et al. (2013)" startWordPosition="2141" endWordPosition="2144"> 42 4 System Details SPIED-Learn uses TokensRegex (Chang and Manning, 2014) to create and apply surface word patterns to text. SPIED-Viz takes details of learned entities and patterns as input in a JSON format. It uses Javascript, angular, and jquery to visualize the information in a web browser. 5 Related Work Most interactive IE systems focus on annotation of text, labeling of entities, and manual writing of rules. Some annotation and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write patterns over dependency trees. GATE6 provides the JAPE language that recognizes regular expressions over annotations. Other systems focus on reducing manual effort for developing extractors (Brauer et al., 2011; Li et al., 2011). In contrast, our tool focuses on visualizing and comparing diagnostic information associated with pattern learning systems. WizIE (Li et al., 2012) is an integrated environment for annotating text and writing pattern extractors for information extraction. It also generates regular expressions around labeled ment</context>
</contexts>
<marker>Akbik, Konomi, Melnikov, 2013</marker>
<rawString>Alan Akbik, Oresti Konomi, and Michail Melnikov. 2013. Propminer: A workflow for interactive information extraction and exploration using dependency trees. In ACL (Conference System Demonstrations), pages 157–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Falk Brauer</author>
<author>Robert Rieger</author>
<author>Adrian Mocan</author>
<author>Wojciech M Barczynski</author>
</authors>
<title>Enabling information extraction by inference of regular expressions from sample entities.</title>
<date>2011</date>
<booktitle>In CIKM,</booktitle>
<pages>1285--1294</pages>
<contexts>
<context position="13688" citStr="Brauer et al., 2011" startWordPosition="2179" endWordPosition="2182"> information in a web browser. 5 Related Work Most interactive IE systems focus on annotation of text, labeling of entities, and manual writing of rules. Some annotation and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write patterns over dependency trees. GATE6 provides the JAPE language that recognizes regular expressions over annotations. Other systems focus on reducing manual effort for developing extractors (Brauer et al., 2011; Li et al., 2011). In contrast, our tool focuses on visualizing and comparing diagnostic information associated with pattern learning systems. WizIE (Li et al., 2012) is an integrated environment for annotating text and writing pattern extractors for information extraction. It also generates regular expressions around labeled mentions and suggests patterns to users. It is most similar to our tool as it displays an explanation of the results extracted by a pattern. However, it is focused towards hand writing and selection of rules. In addition, it cannot be used to directly compare two pattern</context>
</contexts>
<marker>Brauer, Rieger, Mocan, Barczynski, 2011</marker>
<rawString>Falk Brauer, Robert Rieger, Adrian Mocan, and Wojciech M. Barczynski. 2011. Enabling information extraction by inference of regular expressions from sample entities. In CIKM, pages 1285–1294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel X Chang</author>
<author>Christopher D Manning</author>
</authors>
<title>TokensRegex: Defining cascaded regular expressions over tokens. In</title>
<date>2014</date>
<tech>Technical Report.</tech>
<institution>Stanford University</institution>
<contexts>
<context position="12877" citStr="Chang and Manning, 2014" startWordPosition="2052" endWordPosition="2055"> the system without depending on the visualization component to provide that functionality. 2Note that positive, negative, and unlabeled labels are different from the oracle labels, correct and incorrect, for the learned entities. The former refer to the entity labels considered by the system when learning the pattern, and they come from the seed dictionaries and the learned entities. A positive entity considered by the system can be labeled as incorrect by the human assessor, in case the system made a mistake in labeling data, and vice-versa. 42 4 System Details SPIED-Learn uses TokensRegex (Chang and Manning, 2014) to create and apply surface word patterns to text. SPIED-Viz takes details of learned entities and patterns as input in a JSON format. It uses Javascript, angular, and jquery to visualize the information in a web browser. 5 Related Work Most interactive IE systems focus on annotation of text, labeling of entities, and manual writing of rules. Some annotation and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write </context>
</contexts>
<marker>Chang, Manning, 2014</marker>
<rawString>Angel X. Chang and Christopher D. Manning. 2014. TokensRegex: Defining cascaded regular expressions over tokens. In Stanford University Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Chiticariu</author>
<author>Yunyao Li</author>
<author>Frederick R Reiss</author>
</authors>
<title>Rule-based information extraction is dead! long live rule-based information extraction systems!</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’13,</booktitle>
<pages>827--832</pages>
<contexts>
<context position="1497" citStr="Chiticariu et al., 2013" startWordPosition="211" endWordPosition="214">m. However, it involves time consuming manual inspection of the extracted output. We present a light-weight tool, SPIED, to aid IE system developers in learning entities using patterns with bootstrapping, and visualizing the learned entities and patterns with explanations. SPIED is the first publicly available tool to visualize diagnostic information of multiple pattern learning systems to the best of our knowledge. 1 Introduction Entity extraction using rules dominates commercial industry, mainly because rules are effective, interpretable by humans, and easy to customize to cope with errors (Chiticariu et al., 2013). Rules, which can be hand crafted or learned by a system, are commonly created by looking at the context around already known entities, such as surface word patterns (Hearst, 1992) and dependency patterns (Yangarber et al., 2000). Building a patternbased learning system is usually a repetitive process, usually performed by the system developer, of manually examining a system’s output to identify improvements or errors introduced by changing the entity or pattern extractor. Interpretability of patterns makes it easier for humans to identify sources of errors by inspecting patterns that extract</context>
</contexts>
<marker>Chiticariu, Li, Reiss, 2013</marker>
<rawString>Laura Chiticariu, Yunyao Li, and Frederick R. Reiss. 2013. Rule-based information extraction is dead! long live rule-based information extraction systems! In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’13, pages 827–832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Ciravegna</author>
<author>Alexiei Dingli</author>
<author>Daniela Petrelli</author>
<author>Yorick Wilks</author>
</authors>
<title>User-system cooperation in document annotation based on information extraction.</title>
<date>2002</date>
<booktitle>In In Proceedings of the 13th International Conference on Knowledge Engineering and Knowledge Management, EKAW02,</booktitle>
<pages>122--137</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="13364" citStr="Ciravegna et al., 2002" startWordPosition="2130" endWordPosition="2133">e the system made a mistake in labeling data, and vice-versa. 42 4 System Details SPIED-Learn uses TokensRegex (Chang and Manning, 2014) to create and apply surface word patterns to text. SPIED-Viz takes details of learned entities and patterns as input in a JSON format. It uses Javascript, angular, and jquery to visualize the information in a web browser. 5 Related Work Most interactive IE systems focus on annotation of text, labeling of entities, and manual writing of rules. Some annotation and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write patterns over dependency trees. GATE6 provides the JAPE language that recognizes regular expressions over annotations. Other systems focus on reducing manual effort for developing extractors (Brauer et al., 2011; Li et al., 2011). In contrast, our tool focuses on visualizing and comparing diagnostic information associated with pattern learning systems. WizIE (Li et al., 2012) is an integrated environment for annotating text and writing pattern extractors for information extraction. </context>
</contexts>
<marker>Ciravegna, Dingli, Petrelli, Wilks, 2002</marker>
<rawString>Fabio Ciravegna, Alexiei Dingli, Daniela Petrelli, and Yorick Wilks. 2002. User-system cooperation in document annotation based on information extraction. In In Proceedings of the 13th International Conference on Knowledge Engineering and Knowledge Management, EKAW02, pages 122–137. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Yoram Singer</author>
</authors>
<title>Unsupervised models for named entity classification.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>100--110</pages>
<contexts>
<context position="5205" citStr="Collins and Singer, 1999" startWordPosition="774" endWordPosition="777"> paper are: 1. we present a novel diagnostic tool for visualization of output of multiple pattern-based entity learning systems, and 2. we release the code of an end-to-end pattern learning system, which learns entities using patterns in a bootstrapped system and visualizes its diagnostic output. The pattern learning code is available at http://nlp.stanford.edu/ software/patternslearning.shtml. The visualization code is available at http://nlp.stanford.edu/software/ patternviz.shtml. 2 Learning Patterns and Entities Bootstrapped systems have been commonly used to learn entities (Riloff, 1996; Collins and Singer, 1999). SPIED-Learn is based on the system described in Gupta and Manning (2014a), which builds upon the previous bootstrapped patternlearning work and proposed an improved measure to score patterns (Step 3 below). It learns entities for given classes from unlabeled text by bootstrapping from seed dictionaries. Patterns are learned using labeled entities, and entities are learned based on the extractions of learned patterns. The process is iteratively performed until no more patterns or entities can be learned. The following steps give a short summary of the iterative learning of entities belonging </context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>Michael Collins and Yoram Singer. 1999. Unsupervised models for named entity classification. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 100–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonal Gupta</author>
<author>Christopher D Manning</author>
</authors>
<title>Improved pattern learning for bootstrapped entity extraction.</title>
<date>2014</date>
<booktitle>In Proceedings of the Eighteenth Conference on Computational Natural Language Learning (CoNLL).</booktitle>
<contexts>
<context position="4521" citStr="Gupta and Manning (2014" startWordPosition="680" endWordPosition="683"> Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics Viz. SPIED-Viz has pattern-centric and entitycentric views, which visualize learned patterns and entities, respectively, and the explanations for learning them. SPIED-Viz can also contrast two systems by comparing the ranks of learned entities and patterns. In this paper, as a concrete example, we learn and visualize drug-treatment (DT) entities from unlabeled patient-generated medical text, starting with seed dictionaries of entities for multiple classes. The task was proposed and further developed in Gupta and Manning (2014b) and Gupta and Manning (2014a). Our contributions in this paper are: 1. we present a novel diagnostic tool for visualization of output of multiple pattern-based entity learning systems, and 2. we release the code of an end-to-end pattern learning system, which learns entities using patterns in a bootstrapped system and visualizes its diagnostic output. The pattern learning code is available at http://nlp.stanford.edu/ software/patternslearning.shtml. The visualization code is available at http://nlp.stanford.edu/software/ patternviz.shtml. 2 Learning Patterns and Entities Bootstrapped system</context>
<context position="6938" citStr="Gupta and Manning, 2014" startWordPosition="1065" endWordPosition="1068"> The maximum number of patterns learned is given as an input to the system by the developer. 4. Entity learning: Learned patterns for the class are applied to the text to extract candidate entities. An entity scorer ranks the candidate entities and adds the top entities to DT’s dictionary. The maximum number of entities learned is given as an input to the system by the developer. 5. Repeat steps 1-4 for a given number of iterations. SPIED provides an option to use any of the pattern scoring measures described in (Riloff, 1996; Thelen and Riloff, 2002; Yangarber et al., 2002; Lin et al., 2003; Gupta and Manning, 2014b). A pattern is scored based on the positive, negative, and unlabeled entities it extracts. The positive and negative labels of entities are heuristically determined by the system using the dictionaries and the iterative entity learning process. The oracle labels of learned entities are not available to the learning system. Note that an entity that the system considered positive might actually be incorrect, since the seed dictionaries can be noisy and the system can learn incorrect entities in the previous iterations, and vice-versa. SPIED’s entity scorer is the same as in Gupta and Manning (</context>
</contexts>
<marker>Gupta, Manning, 2014</marker>
<rawString>Sonal Gupta and Christopher D. Manning. 2014a. Improved pattern learning for bootstrapped entity extraction. In Proceedings of the Eighteenth Conference on Computational Natural Language Learning (CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonal Gupta</author>
<author>Christopher D Manning</author>
</authors>
<title>Induced lexico-syntactic patterns improve information extraction from online medical forums. Under Submission.</title>
<date>2014</date>
<contexts>
<context position="4521" citStr="Gupta and Manning (2014" startWordPosition="680" endWordPosition="683"> Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics Viz. SPIED-Viz has pattern-centric and entitycentric views, which visualize learned patterns and entities, respectively, and the explanations for learning them. SPIED-Viz can also contrast two systems by comparing the ranks of learned entities and patterns. In this paper, as a concrete example, we learn and visualize drug-treatment (DT) entities from unlabeled patient-generated medical text, starting with seed dictionaries of entities for multiple classes. The task was proposed and further developed in Gupta and Manning (2014b) and Gupta and Manning (2014a). Our contributions in this paper are: 1. we present a novel diagnostic tool for visualization of output of multiple pattern-based entity learning systems, and 2. we release the code of an end-to-end pattern learning system, which learns entities using patterns in a bootstrapped system and visualizes its diagnostic output. The pattern learning code is available at http://nlp.stanford.edu/ software/patternslearning.shtml. The visualization code is available at http://nlp.stanford.edu/software/ patternviz.shtml. 2 Learning Patterns and Entities Bootstrapped system</context>
<context position="6938" citStr="Gupta and Manning, 2014" startWordPosition="1065" endWordPosition="1068"> The maximum number of patterns learned is given as an input to the system by the developer. 4. Entity learning: Learned patterns for the class are applied to the text to extract candidate entities. An entity scorer ranks the candidate entities and adds the top entities to DT’s dictionary. The maximum number of entities learned is given as an input to the system by the developer. 5. Repeat steps 1-4 for a given number of iterations. SPIED provides an option to use any of the pattern scoring measures described in (Riloff, 1996; Thelen and Riloff, 2002; Yangarber et al., 2002; Lin et al., 2003; Gupta and Manning, 2014b). A pattern is scored based on the positive, negative, and unlabeled entities it extracts. The positive and negative labels of entities are heuristically determined by the system using the dictionaries and the iterative entity learning process. The oracle labels of learned entities are not available to the learning system. Note that an entity that the system considered positive might actually be incorrect, since the seed dictionaries can be noisy and the system can learn incorrect entities in the previous iterations, and vice-versa. SPIED’s entity scorer is the same as in Gupta and Manning (</context>
</contexts>
<marker>Gupta, Manning, 2014</marker>
<rawString>Sonal Gupta and Christopher D. Manning. 2014b. Induced lexico-syntactic patterns improve information extraction from online medical forums. Under Submission.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational linguistics, COLING ’92,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="1678" citStr="Hearst, 1992" startWordPosition="245" endWordPosition="246">otstrapping, and visualizing the learned entities and patterns with explanations. SPIED is the first publicly available tool to visualize diagnostic information of multiple pattern learning systems to the best of our knowledge. 1 Introduction Entity extraction using rules dominates commercial industry, mainly because rules are effective, interpretable by humans, and easy to customize to cope with errors (Chiticariu et al., 2013). Rules, which can be hand crafted or learned by a system, are commonly created by looking at the context around already known entities, such as surface word patterns (Hearst, 1992) and dependency patterns (Yangarber et al., 2000). Building a patternbased learning system is usually a repetitive process, usually performed by the system developer, of manually examining a system’s output to identify improvements or errors introduced by changing the entity or pattern extractor. Interpretability of patterns makes it easier for humans to identify sources of errors by inspecting patterns that extracted incorrect instances or instances that resulted in learning of bad patterns. Parameters range from window size of the context in surface word patterns to thresholds for learning a</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th International Conference on Computational linguistics, COLING ’92, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Jun ichi Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics.</journal>
<contexts>
<context position="13400" citStr="Kim et al., 2008" startWordPosition="2137" endWordPosition="2140">ta, and vice-versa. 42 4 System Details SPIED-Learn uses TokensRegex (Chang and Manning, 2014) to create and apply surface word patterns to text. SPIED-Viz takes details of learned entities and patterns as input in a JSON format. It uses Javascript, angular, and jquery to visualize the information in a web browser. 5 Related Work Most interactive IE systems focus on annotation of text, labeling of entities, and manual writing of rules. Some annotation and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write patterns over dependency trees. GATE6 provides the JAPE language that recognizes regular expressions over annotations. Other systems focus on reducing manual effort for developing extractors (Brauer et al., 2011; Li et al., 2011). In contrast, our tool focuses on visualizing and comparing diagnostic information associated with pattern learning systems. WizIE (Li et al., 2012) is an integrated environment for annotating text and writing pattern extractors for information extraction. It also generates regular expression</context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Jun ichi Tsujii. 2008. Corpus annotation for mining biomedical events from literature. BMC Bioinformatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunyao Li</author>
<author>Vivian Chu</author>
<author>Sebastian Blohm</author>
<author>Huaiyu Zhu</author>
<author>Howard Ho</author>
</authors>
<title>Facilitating pattern discovery for relation extraction with semanticsignature-based clustering.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM ’11,</booktitle>
<pages>1415--1424</pages>
<contexts>
<context position="13706" citStr="Li et al., 2011" startWordPosition="2183" endWordPosition="2186"> browser. 5 Related Work Most interactive IE systems focus on annotation of text, labeling of entities, and manual writing of rules. Some annotation and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write patterns over dependency trees. GATE6 provides the JAPE language that recognizes regular expressions over annotations. Other systems focus on reducing manual effort for developing extractors (Brauer et al., 2011; Li et al., 2011). In contrast, our tool focuses on visualizing and comparing diagnostic information associated with pattern learning systems. WizIE (Li et al., 2012) is an integrated environment for annotating text and writing pattern extractors for information extraction. It also generates regular expressions around labeled mentions and suggests patterns to users. It is most similar to our tool as it displays an explanation of the results extracted by a pattern. However, it is focused towards hand writing and selection of rules. In addition, it cannot be used to directly compare two pattern learning systems.</context>
</contexts>
<marker>Li, Chu, Blohm, Zhu, Ho, 2011</marker>
<rawString>Yunyao Li, Vivian Chu, Sebastian Blohm, Huaiyu Zhu, and Howard Ho. 2011. Facilitating pattern discovery for relation extraction with semanticsignature-based clustering. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM ’11, pages 1415–1424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunyao Li</author>
<author>Laura Chiticariu</author>
<author>Huahai Yang</author>
<author>Frederick R Reiss</author>
<author>Arnaldo Carreno-fuentes</author>
</authors>
<title>Wizie: A best practices guided development environment for information extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations, ACL ’12,</booktitle>
<pages>109--114</pages>
<contexts>
<context position="13855" citStr="Li et al., 2012" startWordPosition="2204" endWordPosition="2207">and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write patterns over dependency trees. GATE6 provides the JAPE language that recognizes regular expressions over annotations. Other systems focus on reducing manual effort for developing extractors (Brauer et al., 2011; Li et al., 2011). In contrast, our tool focuses on visualizing and comparing diagnostic information associated with pattern learning systems. WizIE (Li et al., 2012) is an integrated environment for annotating text and writing pattern extractors for information extraction. It also generates regular expressions around labeled mentions and suggests patterns to users. It is most similar to our tool as it displays an explanation of the results extracted by a pattern. However, it is focused towards hand writing and selection of rules. In addition, it cannot be used to directly compare two pattern learning systems. What’s Wrong With My NLP?7 is a tool for jointly visualizing various natural language processing formats such as trees, graphs, and entities. It can</context>
</contexts>
<marker>Li, Chiticariu, Yang, Reiss, Carreno-fuentes, 2012</marker>
<rawString>Yunyao Li, Laura Chiticariu, Huahai Yang, Frederick R. Reiss, and Arnaldo Carreno-fuentes. 2012. Wizie: A best practices guided development environment for information extraction. In Proceedings of the ACL 2012 System Demonstrations, ACL ’12, pages 109–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Liakata</author>
<author>Q Claire</author>
<author>Larisa N Soldatova</author>
</authors>
<title>Semantic annotation of papers: Interface &amp; enrichment tool (sapient).</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop,</booktitle>
<pages>193--200</pages>
<contexts>
<context position="13324" citStr="Liakata et al., 2009" startWordPosition="2123" endWordPosition="2127">ncorrect by the human assessor, in case the system made a mistake in labeling data, and vice-versa. 42 4 System Details SPIED-Learn uses TokensRegex (Chang and Manning, 2014) to create and apply surface word patterns to text. SPIED-Viz takes details of learned entities and patterns as input in a JSON format. It uses Javascript, angular, and jquery to visualize the information in a web browser. 5 Related Work Most interactive IE systems focus on annotation of text, labeling of entities, and manual writing of rules. Some annotation and labeling tools are: MITRE’s Callisto3, Knowtator4, SAPIENT (Liakata et al., 2009), brat5, Melita (Ciravegna et al., 2002), and XConc Suite (Kim et al., 2008). Akbik et al. (2013) interactively helps non-expert users to manually write patterns over dependency trees. GATE6 provides the JAPE language that recognizes regular expressions over annotations. Other systems focus on reducing manual effort for developing extractors (Brauer et al., 2011; Li et al., 2011). In contrast, our tool focuses on visualizing and comparing diagnostic information associated with pattern learning systems. WizIE (Li et al., 2012) is an integrated environment for annotating text and writing pattern</context>
</contexts>
<marker>Liakata, Claire, Soldatova, 2009</marker>
<rawString>Maria Liakata, Claire Q, and Larisa N. Soldatova. 2009. Semantic annotation of papers: Interface &amp; enrichment tool (sapient). In Proceedings of the BioNLP 2009 Workshop, pages 193–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Winston Lin</author>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
</authors>
<title>Bootstrapped learning of semantic classes from positive and negative examples.</title>
<date>2003</date>
<booktitle>In Proceedings of the ICML 2003 Workshop on The Continuum from Labeled to Unlabeled Data in Machine Learning and Data Mining.</booktitle>
<contexts>
<context position="6913" citStr="Lin et al., 2003" startWordPosition="1061" endWordPosition="1064">d patterns for DT. The maximum number of patterns learned is given as an input to the system by the developer. 4. Entity learning: Learned patterns for the class are applied to the text to extract candidate entities. An entity scorer ranks the candidate entities and adds the top entities to DT’s dictionary. The maximum number of entities learned is given as an input to the system by the developer. 5. Repeat steps 1-4 for a given number of iterations. SPIED provides an option to use any of the pattern scoring measures described in (Riloff, 1996; Thelen and Riloff, 2002; Yangarber et al., 2002; Lin et al., 2003; Gupta and Manning, 2014b). A pattern is scored based on the positive, negative, and unlabeled entities it extracts. The positive and negative labels of entities are heuristically determined by the system using the dictionaries and the iterative entity learning process. The oracle labels of learned entities are not available to the learning system. Note that an entity that the system considered positive might actually be incorrect, since the seed dictionaries can be noisy and the system can learn incorrect entities in the previous iterations, and vice-versa. SPIED’s entity scorer is the same </context>
</contexts>
<marker>Lin, Yangarber, Grishman, 2003</marker>
<rawString>Winston Lin, Roman Yangarber, and Ralph Grishman. 2003. Bootstrapped learning of semantic classes from positive and negative examples. In Proceedings of the ICML 2003 Workshop on The Continuum from Labeled to Unlabeled Data in Machine Learning and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically generating extraction patterns from untagged text.</title>
<date>1996</date>
<booktitle>In Proceedings of the 13th National Conference on Artificial Intelligence, AAAI’96,</booktitle>
<pages>1044--1049</pages>
<contexts>
<context position="5178" citStr="Riloff, 1996" startWordPosition="772" endWordPosition="773">utions in this paper are: 1. we present a novel diagnostic tool for visualization of output of multiple pattern-based entity learning systems, and 2. we release the code of an end-to-end pattern learning system, which learns entities using patterns in a bootstrapped system and visualizes its diagnostic output. The pattern learning code is available at http://nlp.stanford.edu/ software/patternslearning.shtml. The visualization code is available at http://nlp.stanford.edu/software/ patternviz.shtml. 2 Learning Patterns and Entities Bootstrapped systems have been commonly used to learn entities (Riloff, 1996; Collins and Singer, 1999). SPIED-Learn is based on the system described in Gupta and Manning (2014a), which builds upon the previous bootstrapped patternlearning work and proposed an improved measure to score patterns (Step 3 below). It learns entities for given classes from unlabeled text by bootstrapping from seed dictionaries. Patterns are learned using labeled entities, and entities are learned based on the extractions of learned patterns. The process is iteratively performed until no more patterns or entities can be learned. The following steps give a short summary of the iterative lear</context>
<context position="6846" citStr="Riloff, 1996" startWordPosition="1051" endWordPosition="1052">coring measure and the top ones are added to the list of learned patterns for DT. The maximum number of patterns learned is given as an input to the system by the developer. 4. Entity learning: Learned patterns for the class are applied to the text to extract candidate entities. An entity scorer ranks the candidate entities and adds the top entities to DT’s dictionary. The maximum number of entities learned is given as an input to the system by the developer. 5. Repeat steps 1-4 for a given number of iterations. SPIED provides an option to use any of the pattern scoring measures described in (Riloff, 1996; Thelen and Riloff, 2002; Yangarber et al., 2002; Lin et al., 2003; Gupta and Manning, 2014b). A pattern is scored based on the positive, negative, and unlabeled entities it extracts. The positive and negative labels of entities are heuristically determined by the system using the dictionaries and the iterative entity learning process. The oracle labels of learned entities are not available to the learning system. Note that an entity that the system considered positive might actually be incorrect, since the seed dictionaries can be noisy and the system can learn incorrect entities in the prev</context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. Automatically generating extraction patterns from untagged text. In Proceedings of the 13th National Conference on Artificial Intelligence, AAAI’96, pages 1044–1049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Thelen</author>
<author>Ellen Riloff</author>
</authors>
<title>A bootstrapping method for learning semantic lexicons using extraction pattern contexts.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’02,</booktitle>
<pages>214--221</pages>
<contexts>
<context position="6871" citStr="Thelen and Riloff, 2002" startWordPosition="1053" endWordPosition="1056"> and the top ones are added to the list of learned patterns for DT. The maximum number of patterns learned is given as an input to the system by the developer. 4. Entity learning: Learned patterns for the class are applied to the text to extract candidate entities. An entity scorer ranks the candidate entities and adds the top entities to DT’s dictionary. The maximum number of entities learned is given as an input to the system by the developer. 5. Repeat steps 1-4 for a given number of iterations. SPIED provides an option to use any of the pattern scoring measures described in (Riloff, 1996; Thelen and Riloff, 2002; Yangarber et al., 2002; Lin et al., 2003; Gupta and Manning, 2014b). A pattern is scored based on the positive, negative, and unlabeled entities it extracts. The positive and negative labels of entities are heuristically determined by the system using the dictionaries and the iterative entity learning process. The oracle labels of learned entities are not available to the learning system. Note that an entity that the system considered positive might actually be incorrect, since the seed dictionaries can be noisy and the system can learn incorrect entities in the previous iterations, and vice</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>Michael Thelen and Ellen Riloff. 2002. A bootstrapping method for learning semantic lexicons using extraction pattern contexts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’02, pages 214–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
<author>Pasi Tapanainen</author>
</authors>
<title>Automatic acquisition of domain knowledge for information extraction.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics, COLING ’00,</booktitle>
<pages>940--946</pages>
<contexts>
<context position="1727" citStr="Yangarber et al., 2000" startWordPosition="251" endWordPosition="254">d entities and patterns with explanations. SPIED is the first publicly available tool to visualize diagnostic information of multiple pattern learning systems to the best of our knowledge. 1 Introduction Entity extraction using rules dominates commercial industry, mainly because rules are effective, interpretable by humans, and easy to customize to cope with errors (Chiticariu et al., 2013). Rules, which can be hand crafted or learned by a system, are commonly created by looking at the context around already known entities, such as surface word patterns (Hearst, 1992) and dependency patterns (Yangarber et al., 2000). Building a patternbased learning system is usually a repetitive process, usually performed by the system developer, of manually examining a system’s output to identify improvements or errors introduced by changing the entity or pattern extractor. Interpretability of patterns makes it easier for humans to identify sources of errors by inspecting patterns that extracted incorrect instances or instances that resulted in learning of bad patterns. Parameters range from window size of the context in surface word patterns to thresholds for learning a candidate entity. At present, there is a lack of</context>
</contexts>
<marker>Yangarber, Grishman, Tapanainen, 2000</marker>
<rawString>Roman Yangarber, Ralph Grishman, and Pasi Tapanainen. 2000. Automatic acquisition of domain knowledge for information extraction. In Proceedings of the 18th International Conference on Computational Linguistics, COLING ’00, pages 940–946.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Winston Lin</author>
<author>Ralph Grishman</author>
</authors>
<title>Unsupervised learning of generalized names.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics, COLING ’02.</booktitle>
<contexts>
<context position="6895" citStr="Yangarber et al., 2002" startWordPosition="1057" endWordPosition="1060">ed to the list of learned patterns for DT. The maximum number of patterns learned is given as an input to the system by the developer. 4. Entity learning: Learned patterns for the class are applied to the text to extract candidate entities. An entity scorer ranks the candidate entities and adds the top entities to DT’s dictionary. The maximum number of entities learned is given as an input to the system by the developer. 5. Repeat steps 1-4 for a given number of iterations. SPIED provides an option to use any of the pattern scoring measures described in (Riloff, 1996; Thelen and Riloff, 2002; Yangarber et al., 2002; Lin et al., 2003; Gupta and Manning, 2014b). A pattern is scored based on the positive, negative, and unlabeled entities it extracts. The positive and negative labels of entities are heuristically determined by the system using the dictionaries and the iterative entity learning process. The oracle labels of learned entities are not available to the learning system. Note that an entity that the system considered positive might actually be incorrect, since the seed dictionaries can be noisy and the system can learn incorrect entities in the previous iterations, and vice-versa. SPIED’s entity s</context>
</contexts>
<marker>Yangarber, Lin, Grishman, 2002</marker>
<rawString>Roman Yangarber, Winston Lin, and Ralph Grishman. 2002. Unsupervised learning of generalized names. In Proceedings of the 19th International Conference on Computational Linguistics, COLING ’02.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>