<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003378">
<title confidence="0.997773">
A Quantitative Insight into the Impact of Translation on Readability
</title>
<author confidence="0.993692">
Alina Maria Ciobanu, Liviu P. Dinu
</author>
<affiliation confidence="0.9944725">
Center for Computational Linguistics, University of Bucharest
Faculty of Mathematics and Computer Science, University of Bucharest
</affiliation>
<email confidence="0.988029">
alina.ciobanu@my.fmi.unibuc.ro, ldinu@fmi.unibuc.ro
</email>
<sectionHeader confidence="0.997318" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998800166666667">
In this paper we investigate the impact
of translation on readability. We propose
a quantitative analysis of several shallow,
lexical and morpho-syntactic features that
have been traditionally used for assessing
readability and have proven relevant for
this task. We conduct our experiments
on a parallel corpus of transcribed parlia-
mentary sessions and we investigate read-
ability metrics for the original segments of
text, written in the language of the speaker,
and their translations.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999875844444445">
Systems for automatic readability assessment have
been studied since the 1920s and have received an
increasing attention during the last decade. Early
research on readability assessment focused only
on shallow language properties, but nowadays na-
tural language processing technologies allow the
investigation of a wide range of factors which in-
fluence the ease which a text is read and under-
stood with. These factors correspond to differ-
ent levels of linguistic analysis, such as the le-
xical, morphological, semantic, syntactic or dis-
course levels. However, readability depends not
only on text properties, but also on characteristics
of the target readers. Aspects such as background
knowledge, age, level of literacy and motivation of
the expected audience should be considered when
developing a readability assessment system. Al-
though most readability metrics were initially de-
veloped for English, current research has shown a
growing interest in other languages, such as Ger-
man, French, Italian or Portuguese.
Readability assessment systems are relevant for
a wide variety of applications, both human- and
machine-oriented (Dell’Orletta et al., 2011). Se-
cond language learners and people with disabili-
ties or low literacy skills benefit from such sys-
tems, which provide assistance in selecting read-
ing material with an appropriate level of com-
plexity from a large collection of documents –
for example, the documents available on the web
(Collins-Thompson, 2011). Within the medical
domain, the investigation of the readability level
of medical texts helps developing well-suited ma-
terials to increase the level of information for pre-
venting diseases (Richwald et al., 1989) and to au-
tomatically adapt technical documents to various
levels of medical expertise (Elhadad and Sutaria,
2007). For natural language processing tasks such
as machine translation (Stymne et al., 2013), text
simplification (Aluisio et al., 2010), speech recog-
nition (Jones et al., 2005) or document summa-
rization (Radev and Fan, 2000), readability ap-
proaches are employed to assist the process and
to evaluate and quantify its performance and ef-
fectiveness.
</bodyText>
<sectionHeader confidence="0.757194" genericHeader="related work">
1.1 Related Work
</sectionHeader>
<bodyText confidence="0.999964368421053">
Most of the traditional readability approaches in-
vestigate shallow text properties to determine the
complexity of a text. These readability metrics are
based on assumptions which correlate surface fea-
tures with the linguistic factors which influence
readability. For example, the average number of
characters or syllables per word, the average num-
ber of words per sentence and the percentage of
words not occurring among the most frequent n
words in a language are correlated with the lexi-
cal, syntactic and, respectively, the semantic com-
plexity of the text. The Flesch-Kincaid measure
(Kincaid et al., 1975) employs the average number
of syllables per word and the average number of
words per sentence to assess readability, while the
Automated Readability Index (Smith and Senter,
1967) and the Coleman-Liau metric (Coleman and
Liau, 1975) measure word length based on charac-
ter count rather than syllable count; they are func-
</bodyText>
<page confidence="0.983901">
104
</page>
<note confidence="0.99412">
Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 104–113,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999972276923077">
tions of both the average number of characters per
word and the average number of words per sen-
tence. Gunning Fog (Gunning, 1952) and SMOG
(McLaughlin, 1969) account also for the percent-
age of polysyllabic words and the Dale-Chall for-
mula (Dale and Chall, 1995) relies on word fre-
quency lists to assess readability. The traditional
readability approaches are not computationally ex-
pensive, but they are only a coarse approximation
of the linguistic factors which influence readabil-
ity (Pitler and Nenkova, 2008). According to Si
and Callan (2001), the shallow features employed
by standard readability indices are based on as-
sumptions about writing style that may not apply
in all situations.
Along with the development of natural lan-
guages processing tools and machine learning
techniques, factors of increasing complexity, cor-
responding to various levels of linguistic analy-
sis, have been taken into account in the study of
readability assessment. Si and Callan (2001) and
Collins-Thompson and Callan (2004) use statisti-
cal language modeling and Petersen and Ostendorf
(2009) combine features from statistical language
models, syntactic parse trees and traditional met-
rics to estimate reading difficulty. Feng (2009) ex-
plores discourse level attributes, along with lexical
and syntactic features, and emphasizes the value of
the global semantic properties of the text for pre-
dicting text readability. Pitler and Nenkova (2008)
propose and analyze two perspectives for the task
of readability assessment: prediction and ranking.
Using various features, they reach the conclusion
that only discourse level features exhibit robust-
ness across the two tasks. Vajjala and Meurers
(2012) show that combining lexical and syntac-
tic features with features derived from second lan-
guage acquisition research leads to performance
improvements.
Although most readability approaches deve-
loped so far deal with English, the development
of adequate corpora for experiments and the study
of readability features tailored for other languages
have received increasing attention. For Italian,
Franchina and Vacca (1986) propose the Flesch-
Vacca formula, which is an adaptation of the
Flesch index (Flesch, 1946). Another metric de-
veloped for Italian is Gulpease (Lucisano and
Piemontese, 1988), which uses characters instead
of syllables to measure word length and thus re-
quires less resources. Dell’Orletta et al. (2011)
combine traditional, morpho-syntactic, lexical and
syntactic features for building a readability model
for Italian, while Tonelli et al. (2012) propose a
system for readability assessment for Italian in-
spired by the principles of Coh-Metrix (Graesser
et al., 2004). For French, Kandel and Moles
(1958) propose an adaptation of the Flesch for-
mula and Franc¸ois and Miltsakaki (2012) inves-
tigate a wide range of classic and non-classic fea-
tures to predict readability level using a dataset for
French as a foreign language. Readability assess-
ment was also studied for Spanish (Huerta, 1959)
and Portuguese (Aluisio et al., 2010) using fea-
tures derived from previous research on English.
</bodyText>
<subsectionHeader confidence="0.997263">
1.2 Readability of Translation
</subsectionHeader>
<bodyText confidence="0.999979303030303">
According to Sun (2012), the reception of a trans-
lated text is related to cross-cultural readability.
Translators need to understand the particularities
of both the source and the target language in order
to transfer the meaning of the text from one lan-
guage to another. This process can be challenging,
especially for languages with significant structure
differences, such as English and Chinese. The
three-step system of translation (analysis, trans-
fer and restructuring) presented by Nida and Taber
(1969) summarizes the process and emphasizes
the importance of a proper understanding of the
source and the target languages. While rendering
the source language text into the target language, it
is also important to maintain the style of the docu-
ment. Various genres of text might be translated
for different purposes, which influence the choice
of the translation strategy. For example, for politi-
cal speeches the purpose is to report exactly what
is communicated in a given text (Trosborg, 1997).
Parallel corpora are very useful in studying
the properties of translation and the relationships
between source language and target language.
Therefore, the corpus-based research has become
more and more popular in translation research.
Using the Europarl (Koehn, 2005) parallel cor-
pus, van Halteren (2008) investigates the auto-
matic identification of the source language of Eu-
ropean Parliament speeches, based on frequency
counts of word n-grams. Islam and Mehler (2012)
draw attention to the absence of adequate corpora
for studies on translation and propose a resource
suited for this purpose.
</bodyText>
<page confidence="0.999309">
105
</page>
<sectionHeader confidence="0.812011" genericHeader="method">
2 Our Approach and Methodology
</sectionHeader>
<bodyText confidence="0.999845724137931">
The problem that we address in this paper is
whether human translation has an impact on read-
ability. Given a text T1 in a source language
L1 and its translations in various target languages
L2,..., Ln, how does readability vary? Is the orig-
inal text in L1 easier to read and understand than
its translation in a target language Li? Which lan-
guage is closest to the source language, in terms
of readability? We investigate several shallow,
lexical and morpho-syntactic features that have
been widely used and have proven relevant for as-
sessing readability. We are interested in observ-
ing the differences between the feature values ob-
tained for the original texts and those obtained for
their translations. Although some of the metrics
(such as average word length) might be language-
specific, most of them are language-independent
and a comparison between them across languages
is justified. The 10 readability metrics that we ac-
count for are described in Section 3.2.
We run our experiments on Europarl (Koehn,
2005), a multilingual parallel corpus which is de-
scribed in detail in Section 3.1. We investigate 5
Romance languages (Romanian, French, Italian,
Spanish and Portuguese) and, in order to excerpt
an adequate dataset of parallel texts, we adopt a
strategy similar to that of van Halteren (2008):
given n languages L1,..., Ln, we apply the follow-
ing steps:
</bodyText>
<listItem confidence="0.9665033">
1. we select L1 as the source language
2. we excerpt the collection of segments of text
T1 for which L1 is the source language
3. we identify the translations T2, ..., Tn of T1 in
the target languages L2, ..., Ln
4. we compute the readability metrics for
T1, ..., Tn
5. we repeat steps 1 − 4 using each language
L2, ..., Ln as the source language, one at a
time
</listItem>
<bodyText confidence="0.999627">
We propose two approaches to quantify and
evaluate the variation in the readability feature val-
ues from the original texts to their translations: a
distance-based method and a multi-criteria tech-
nique based on rank aggregation.
</bodyText>
<sectionHeader confidence="0.994298" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.996872">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.9999174">
Europarl (Koehn, 2005) is a multilingual paral-
lel corpus extracted from the proceedings of the
European Parliament. Its main intended use is
as aid for statistical machine translation research
(Tiedemann, 2012). The corpus is tokenized and
aligned in 21 languages. The files contain annota-
tions for marking the document (&lt;chapter&gt;), the
speaker (&lt;speaker&gt;) and the paragraph (&lt;p&gt;).
Some documents have the attribute language for
the speaker tag, which indicates the language used
by the original speaker. Another way of annotating
the original language is by having the language ab-
breviation written between parentheses at the be-
ginning of each segment of text. However, there
are segments where the language is not marked in
either of the two ways. We account only for sen-
tences for which the original language could be
determined and we exclude all segments showing
inconsistent values.
We use the following strategy: because for the
Romance languages there are very few segments
of text for which the language attribute is consis-
tent across all versions, we take into account an at-
tribute L if all other Romance languages mention
it. For example, given a paragraph P in the Ro-
manian subcorpus, we assume that the source lan-
guage for this paragraph is Romanian if all other
four subcorpora (Italian, French, Spanish and Por-
tuguese) mark this paragraph P with the tag RO
for language. Thus, we obtain a collection of
segments of text for each subcorpus. We iden-
tify 4,988 paragraphs for which Romanian is the
source language, 13,093 for French, 7,485 for Ital-
ian, 5,959 for Spanish and 8,049 for Portuguese.
Because we need sets of approximately equal size
for comparison, we choose, for each language, a
subset equal with the size of the smallest subset,
i.e., we keep 4,988 paragraphs for each language.
Note that in this corpus paragraphs are aligned
across languages, but the number of sentences
may be different. For example, the sentence
“UE trebuie s˘a fie ambit¸ioas˘a in combaterea
schimb˘arilor climatice, iar rolul energiei nucle-
are s¸i energiilor regenerabile nu poate fi negli-
jat.”1, for which Romanian is the source language,
</bodyText>
<footnote confidence="0.712388">
1Translation into English: “The EU must be ambitious in
the battle against climate change, which means that the role
of nuclear power and renewable energy sources cannot be
discounted.”
</footnote>
<page confidence="0.995845">
106
</page>
<bodyText confidence="0.999870823529412">
is translated into French in two sentences: “L’UE
doit se montrer ambitieuse dans sa lutte contre
les changements climatiques.” and “L’´energie
nucl´eaire et les sources d’´energie renouvelables
ne peuvent donc pas ˆetre ´ecart´ees.”. Therefore, we
match paragraphs, rather than sentences, across
languages.
As a preprocessing step, we discard the tran-
scribers’ descriptions of the parliamentary ses-
sions (such as “Applause”, “The President in-
terrupted the speaker” or “The session was sus-
pended at 19.30 and resumed at 21.00”).
According to van Halteren (2008), translations
in the European Parliament are generally made by
native speakers of the target language. Transla-
tion is an inherent part of the political activity
(Sch¨affner and Bassnett, 2010) and has a high
influence on the way the political speeches are
perceived. The question posed by Sch¨affner and
Bassnett (2010) “What exactly happens in the
complex processes of recontextualisation across
linguistic, cultural and ideological boundaries?”
summarizes the complexity of the process of trans-
lating political documents. Political texts might
contain complex technical terms and elaborated
sentences. Therefore, the results of our experi-
ments are probably domain-specific and cannot be
generalized to other types of texts. Although par-
liamentary documents probably have a low read-
ability level, our investigation is not negatively in-
fluenced by the choice of corpus because we are
consistent across all experiments in terms of text
gender and we report results obtained solely by
comparison between source and target languages.
</bodyText>
<subsectionHeader confidence="0.987478">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.9999412">
We investigate several shallow, lexical and
morpho-syntactic features that were traditionally
used for assessing readability and have proven
high discriminative power within readability met-
rics.
</bodyText>
<subsectionHeader confidence="0.808636">
3.2.1 Shallow Features
</subsectionHeader>
<bodyText confidence="0.998963705882353">
Average number of words per sentence. The
average sentence length is one of the most widely
used metrics for determining readability level and
was employed in numerous readability formulas,
proving to be most meaningful in combined evi-
dence with average word frequency. Feng et al.
(2010) find the average sentence length to have
higher predictive power than all the other lexical
and syllable-based features they used.
Average number of characters per word. It
is generally considered that frequently occurring
words are usually short, so the average number
of characters per word was broadly used for mea-
suring readability in a robust manner. Many read-
ability formulas measure word length in syllables
rather than letters, but this requires additional re-
sources for syllabication.
</bodyText>
<subsectionHeader confidence="0.831863">
3.2.2 Lexical Features
</subsectionHeader>
<bodyText confidence="0.999767214285714">
Percentage of words from the basic lexicon.
Based on the assumption that more common
words are easier to understand, the percentage of
words not occurring among the most frequent n
in the language is a commonly used metric to ap-
proximate readability. To determine the percent-
age of words from the basic lexicon, we employ
the representative vocabularies for Romance lan-
guages proposed by Sala (1988).
Type/Token Ratio. The proportion between the
number of lexical types and the number of to-
kens indicates the range of use of vocabulary. The
higher the value of this feature, the higher the vari-
ability of the vocabulary used in the text.
</bodyText>
<subsectionHeader confidence="0.500977">
3.2.3 Morpho-Syntactic Features
</subsectionHeader>
<bodyText confidence="0.998049941176471">
Relative frequency of POS unigrams. The ra-
tio for 5 parts of speech (verbs, nouns, pronouns,
adjectives and adverbs), computed individually
on a per-token basis. This feature assumes that
the probability of a token is context-independent.
For lemmatization and part of speech tagging
we use the DexOnline2 machine-readable dictio-
nary for Romanian and the FreeLing3 (Padr´o and
Stanilovsky, 2012; Padr´o, 2011; Padr´o et al., 2010;
Atserias et al., 2006; Carreras et al., 2004) lan-
guage analysis tool suite for French, Italian, Span-
ish and Portuguese.
Lexical density. The proportion of content
words (verbs, nouns, adjectives and adverbs),
computed on a per-token basis. Grammatical fea-
tures were shown to be useful in readability pre-
diction (Heilman et al., 2007).
</bodyText>
<sectionHeader confidence="0.999868" genericHeader="evaluation">
4 Results Analysis
</sectionHeader>
<bodyText confidence="0.999621">
Our main purpose is to investigate the variabil-
ity of the feature values from the original texts to
their translations. In Table 1 we report the values
</bodyText>
<footnote confidence="0.999148">
2http://dexonline.ro
3http://nlp.lsi.upc.edu/freeling
</footnote>
<page confidence="0.996887">
107
</page>
<bodyText confidence="0.999825541666667">
obtained for 10 readability metrics computed for
the Europarl subcorpora for Romanian, French,
Italian, Spanish and Portuguese. The readability
metrics we computed lead to several immediate
remarks. We notice that, generally, when repre-
senting the values for a feature F on the real axis,
the values corresponding to the translations are not
placed on the same side of the value correspond-
ing to the original text. For example, considering
feature F3 (the percentage of words from the ba-
sic lexicon), and taking Romanian as the source
language, we observe that the value for the origi-
nal text is between Italian (on the left side) and the
other languages (on the right side).
In the absence of a widely-accepted readability
metric, such as the Flesch-Kincaid formula or the
Automated Readability Index, for all 5 Romance
languages, we choose two other ways to evalu-
ate the results obtained after applying the 10 read-
ability features: a distance-based evaluation and a
multi-criteria approach.
In order to compute distance measures reliably,
we normalize feature values using the following
formula:
</bodyText>
<equation confidence="0.693106">
fz = fi − fmin
</equation>
<bodyText confidence="0.9545576">
fmax − fmin ,
where fmin is the minimum value for feature F
and fmax is the maximum value for feature F. For
example, if F = F1 and the source language is Ro-
manian, then fmin = 26.2 and fmax = 29.0.
</bodyText>
<subsectionHeader confidence="0.973404">
4.1 Preliminaries
</subsectionHeader>
<bodyText confidence="0.999309333333333">
In this subsection we shortly describe the two tech-
niques used. The experimented reader can skip
this subsection.
</bodyText>
<subsubsectionHeader confidence="0.811716">
4.1.1 Rank Aggregation
</subsubsectionHeader>
<bodyText confidence="0.936114571428572">
Rank distance (Dinu and Dinu, 2005) is a met-
ric used for measuring the similarity between two
ranked lists. A ranking of a set of n objects can
be represented as a permutation of the integers
1, 2, ..., n. S is a set of ranking results, σ E S.
σ(i) represents the rank of object i in the ranking
result σ. The rank distance is computed as:
</bodyText>
<equation confidence="0.9860835">
A(σ, τ) = Xn |σ(i) − τ(i)|
i=1
</equation>
<bodyText confidence="0.9999589">
The ranks of the elements are given from bot-
tom up, i.e., from n to 1, in a Borda order. The
elements which do not occur in any of the rank-
ings receive the rank 0.
In a selection process, rankings are issued for
a common decision problem, therefore a ranking
that “combines” all the original (base) rankings is
required. One common-sense solution is finding a
ranking that is as close as possible to all the par-
ticular rankings.
Formally, given m partial rankings T =
τ1, τ2, ..., τm, over a universe U, the rank aggre-
gation problem requires a partial ranking that is
as close as possible to all these rankings to be de-
termined. In other words, it requires a means of
combining the rankings. There are many ways to
solve this problem, one of which is by trying to
find a ranking such that the sum of rank distances
between it and the given rankings is minimal. In
other words, find σ such that:
</bodyText>
<equation confidence="0.9283545">
A(σ, T) = X A(σ, τ)
T∈T
</equation>
<bodyText confidence="0.99248275">
is minimal. The set of all rankings that minimize
A(σ, T) is called the aggregations set and is de-
noted by agr(T).
Apart from many paradoxes of different aggre-
gation methods, this problem is NP-hard for most
non-trivial distances (e.g., for edit distance, see
(de la Higuera and Casacuberta, 2000)). Dinu
and Manea (2006) show that the rank aggregation
problem using rank distance, which minimizes the
sum A(σ, T) of the rank distances between the ag-
gregation and each given ranking, can be reduced
to solving |U |assignment problems, where U is
the universe of objects. Let n = #U. The time
complexity to obtain one such aggregation (there
may be more than one) is O(n4).
We then transform the aggregation problem in
a categorization problem as follows (Dinu and
Popescu, 2008): for a multiset L of rankings, we
determine all the aggregations of L and then we
apply voting on the set of agr(L).
</bodyText>
<subsectionHeader confidence="0.518054">
4.1.2 Cosine Distance
</subsectionHeader>
<bodyText confidence="0.9946222">
Cosine distance is a metric which computes the
angular cosine distance between two vectors of an
inner product space. Given two vectors of fea-
tures, A and B, the cosine distance is represented
as follows:
</bodyText>
<equation confidence="0.9989434">
Pn i=1 Ai × Bi
A(A, B) = 1 −
qPn )2
(Ai)2 × qPn
1 (Bi)2
</equation>
<bodyText confidence="0.960011">
When used in positive space, the cosine distance
ranges from 0 to 1.
</bodyText>
<page confidence="0.995014">
108
</page>
<table confidence="0.999956074074074">
Source Target F1 F2 F3 F4 Features F7 F8 F9 F10
Language Language F5 F6
RO 26.2 5.61 0.67 0.06 0.66 0.15 0.29 0.16 0.05 0.11
FR 29.0 5.06 0.79 0.03 0.59 0.13 0.35 0.06 0.04 0.06
RO IT 27.4 5.57 0.63 0.04 0.61 0.16 0.30 0.10 0.04 0.06
ES 28.3 5.18 0.81 0.04 0.53 0.15 0.24 0.09 0.03 0.03
PT 26.8 5.31 0.78 0.04 0.58 0.14 0.30 0.08 0.04 0.02
RO 24.6 5.35 0.70 0.06 0.64 0.17 0.26 0.14 0.06 0.13
FR 27.4 4.86 0.81 0.04 0.58 0.14 0.32 0.05 0.06 0.09
FR IT 25.7 5.46 0.65 0.05 0.61 0.17 0.28 0.09 0.05 0.07
ES 26.3 5.11 0.82 0.05 0.53 0.16 0.23 0.08 0.04 0.04
PT 25.1 5.21 0.80 0.05 0.58 0.16 0.29 0.07 0.05 0.02
RO 29.7 5.46 0.69 0.06 0.62 0.16 0.27 0.15 0.05 0.12
FR 32.4 5.00 0.80 0.04 0.58 0.14 0.33 0.06 0.05 0.08
IT IT 30.9 5.48 0.64 0.05 0.61 0.16 0.28 0.10 0.05 0.07
ES 31.8 5.15 0.82 0.04 0.53 0.16 0.23 0.09 0.04 0.03
PT 30.5 5.28 0.79 0.04 0.58 0.15 0.29 0.07 0.05 0.02
RO 27.6 5.33 0.70 0.06 0.64 0.17 0.26 0.14 0.06 0.13
FR 29.9 4.91 0.81 0.04 0.58 0.14 0.32 0.05 0.05 0.09
ES IT 27.9 5.45 0.66 0.05 0.60 0.17 0.28 0.09 0.05 0.08
ES 31.1 5.02 0.83 0.05 0.52 0.16 0.22 0.08 0.05 0.04
PT 28.2 5.17 0.81 0.05 0.57 0.16 0.28 0.07 0.05 0.02
RO 29.3 5.58 0.67 0.05 0.65 0.15 0.28 0.16 0.05 0.12
FR 32.8 5.04 0.80 0.03 0.58 0.13 0.34 0.06 0.04 0.07
PT IT 30.9 5.56 0.62 0.04 0.60 0.15 0.29 0.10 0.04 0.06
ES 32.5 5.15 0.81 0.03 0.53 0.15 0.24 0.09 0.03 0.03
PT 30.9 5.28 0.79 0.04 0.57 0.14 0.30 0.08 0.04 0.02
</table>
<tableCaption confidence="0.993508">
Table 1: Values for readability metrics applied on Europarl. The first column represents the source
</tableCaption>
<bodyText confidence="0.793694">
language (the language of the speaker). The second column represents the target language (the language
in which the text is written / translated). The features F1 - F10 are as follows:
</bodyText>
<listItem confidence="0.9991029">
• F1 - average number of words per sentence
• F2 - average number of characters per word
• F3 - percentage of words from the basic lexicon
• F4 - type / token ratio
• F5 - lexical density
• F6 - relative frequency of POS unigrams: verbs
• F7 - relative frequency of POS unigrams: nouns
• P8 - relative frequency of POS unigrams: adjectives
• F9 - relative frequency of POS unigrams: adverbs
• F10 - relative frequency of POS unigrams: pronouns
</listItem>
<page confidence="0.993138">
109
</page>
<table confidence="0.996339333333333">
RO FR IT ES PT
RO – 0.571 0.138 0.582 0.292
FR 0.513 – 0.505 0.491 0.328
IT 0.075 0.416 – 0.502 0.212
ES 0.531 0.423 0.545 – 0.256
PT 0.300 0.227 0.252 0.275 –
</table>
<tableCaption confidence="0.998454">
Table 2: Cosine distance between feature vectors.
</tableCaption>
<bodyText confidence="0.64916">
The first column represents the source language
and the first line represents the target language.
</bodyText>
<subsectionHeader confidence="0.744249">
4.2 Experiment Analysis: Original vs.
Translation
</subsectionHeader>
<bodyText confidence="0.999571272727273">
Our main goal is to determine a robust way to
evaluate the variation in readability from the origi-
nal texts to their translations, after applying the 10
readability features described in Section 3.2.
A natural approach is to use an evaluation
methodology based on a distance metric between
feature vectors to observe how close translations
are in various languages, with respect to readabil-
ity. The closer the distance is to 0, the more easily
can one language be translated into the other, in
terms of readability. Briefly, our first approach is
as follows: for each source language L in column
1 of Table 1, we consider the feature vector corre-
sponding to this language from column 2 and we
compute the cosine distance between this vector
and all the other 4 vectors remaining in column 2,
one for each target language. The obtained values
are reported in Table 2, on the line corresponding
to language L.
Table 2 provides not only information regard-
ing the closest language, but also the hierarchy of
languages in terms of readability. For example,
the closest language to Romanian is Italian, fol-
lowed by Portuguese, French and Spanish. Over-
all, the lowest distance between an original text
and its translation occurs when Italian is the source
language and Romanian the target language. The
highest distance is reported for translations from
Romanian into Spanish.
The second approach we use for investigating
the readability of translation is multi-criteria ag-
gregation: since the 10 monitored features can
be seen as individual classifiers for readability
(and in various papers they were used either in-
dividually or combined as representative features
for predicting readability), we experiment with a
multi-criteria aggregation of these metrics in order
to predict which language is closest to the source
language in terms of readability.
For segments of text having the source language
L, we consider each feature FZ, one at a time, and
we compute the absolute value of the difference
between the FZ value for the original text and the
FZ values for its translations. Then, we sort the
values in ascending order, thus obtaining for each
language L and feature FZ a ranking with 4 ele-
ments (one for each translation) determined as fol-
lows: the language having the lowest computed
absolute value is placed on the first position, the
language having the second to lowest computed
absolute value is placed on the second position,
and so on. Finally, we have, for each language L,
10 rankings (one for each feature) with 4 elements
(one for each translation), each ranking indicating
on the first position the target language which is
closest to the source language with regard to read-
ability measured by feature FZ. In case of equal
values for the computed absolute distance, we con-
sider all possible rankings.
Given these rankings, the task we propose is to
determine which target language is closest to the
source language in terms of readability. To solve
this requirement, we apply multi-criteria aggrega-
tion based on rank distance. For each language, we
aggregate the 10 corresponding rankings and de-
termine the closest language with respect to read-
ability across translation. The results we obtain for
Romance languages after the rank aggregation are
as follows: the closest translation language for Ro-
manian is Italian (followed by Portuguese, Span-
ish and French). Conversely, for Italian the closest
language is Romanian (followed by Portuguese,
French and Spanish). For French, Portuguese oc-
cupies the first position in the ranking (followed
by Spanish, Italian and Romanian). For Spanish,
Portuguese ranks first (followed by Italian, French
and Romanian), while for Portuguese, Italian is
the closest language (followed by French, Spanish
and Romanian).
The obtained results are very similar to those
computed by the cosine distance and reported in
Table 2. The only difference regarding the closest
language in terms of readability is that rank ag-
gregation reports Italian as being closest to Por-
tuguese, while the cosine distance reports French
instead. However, the differences between the
first two ranked languages for Portuguese, namely
French and Italian, are insignificant.
</bodyText>
<page confidence="0.988124">
110
</page>
<figure confidence="0.9995896875">
1.0
0.5
0.0
0.5
1.0
IT_ES
PT_ES
RO_ES
ES_ES
FR_ES
PT_RO
FR_RO
RO_RO
IT_IT
IT_PT
IT_RO
ES_RO
ES_FR
RO_FR
PT_FR
FR_FR
IT_FR
ES_IT ES_PT
PT_IT
FR_PT
FR_IT
RO_IT
PT_PT
RO_PT
original
translation
1.5 1.0 0.5 0.0 0.5 1.0
</figure>
<figureCaption confidence="0.997018">
Figure 1: PCA. Languages are annotated in the figure as follows: L1 L2, where L1 is the source language
and L2 is the target language.
</figureCaption>
<subsectionHeader confidence="0.984536">
4.3 PCA: Original vs. Translation
</subsectionHeader>
<bodyText confidence="0.999949733333333">
In Figure 1 we employ Principal Component Anal-
ysis (PCA) to perform linear data reduction in or-
der to obtain a better representation of the read-
ability feature vectors without losing much infor-
mation. We use the Modular toolkit for Data Pro-
cessing (MDP), a Python data processing frame-
work (Zito et al., 2008). We observe that clusters
tend to be formed based on the target language.
rather than based on the source language. While
for Romanian and Italian the original texts are to
some extent isolated from their translations, for
French, Spanish and Portuguese the original texts
are more integrated within the groups of transla-
tions. The most compact cluster corresponds to
Romanian as a target language.
</bodyText>
<sectionHeader confidence="0.996579" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.998584727272727">
In this paper we investigate the behaviour of vari-
ous readability metrics across parallel translations
of texts from a source language to target lan-
guages. We focus on Romance languages and we
propose two methods for the analysis of the clos-
est translation, in terms of readability. Given a text
in a source language, we determine which of its
translations in various target languages is closest
to the original text with regard to readability. In
our future works, we plan to extend our analysis to
more languages, in order to cover a wider variety
of linguistic families. We are mainly interested in
the 21 languages covered by Europarl. Moreover,
we intend to enrich the variety of the texts, be-
ginning with an analysis of translations of literary
works. As far as resources are available, we plan
to investigate other readability metrics as well and
to combine our findings with the views of human
experts. We believe our method can provide valu-
able information regarding the difficulty of trans-
lation from one language into another in terms of
readability.
</bodyText>
<sectionHeader confidence="0.997363" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999914714285714">
The authors thank the anonymous reviewers for
their helpful and constructive comments. The con-
tribution of the authors to this paper is equal. Re-
search supported by a grant of the Romanian Na-
tional Authority for Scientific Research, CNCS
UEFISCDI, project number PN-II-ID-PCE-2011-
3-0959.
</bodyText>
<sectionHeader confidence="0.999316" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9942369">
Sandra Aluisio, Lucia Specia, Caroline Gasperin, and
Carolina Scarton. 2010. Readability Assessment for
Text Simplification. In Proceedings of the NAACL
HLT 2010 Fifth Workshop on Innovative Use of NLP
for Building Educational Applications, IUNLPBEA
2010, pages 1–9.
Jordi Atserias, Bernardino Casas, Elisabet Comelles,
Meritxell Gonz´alez, Llu´ıs Padr´o, and Muntsa Padr´o.
2006. FreeLing 1.3: Syntactic and semantic services
in an open-source NLP library. In Proceedings of
</reference>
<page confidence="0.994077">
111
</page>
<reference confidence="0.998580205607477">
the 5th International Conference on Language Re-
sources and Evaluation, LREC 2006, pages 2281–
2286.
Xavier Carreras, Isaac Chao, Llu´ıs Padr´o, and Muntsa
Padr´o. 2004. FreeLing: An Open-Source Suite of
Language Analyzers. In Proceedings of the 4th In-
ternational Conference on Language Resources and
Evaluation, LREC 2004, pages 239–242.
Meri Coleman and T. L. Liau. 1975. A computer read-
ability formula designed for machine scoring. Jour-
nal of Applied Psychology, 60(2):283–284.
Kevyn Collins-Thompson and James P. Callan. 2004.
A Language Modeling Approach to Predicting
Reading Difficulty. In Proceedings of the Hu-
man Language Technology Conference of the North
American Chapter of the Association of Computa-
tional Linguistics, HLT-NAACL 2004, pages 193–
200.
Kevyn Collins-Thompson. 2011. Enriching Informa-
tion Retrieval with Reading Level Prediction. In SI-
GIR 2011 Workshop on Enriching Information Re-
trieval.
Edgar Dale and Jeanne Chall. 1995. Readability Re-
visited: The New Dale-Chall Readability Formula.
Brookline Books, Cambridge.
C. de la Higuera and F. Casacuberta. 2000. Topology
of Strings: Median String is NP-complete. Theoret-
ical Computer Science, 230(1-2):39–48.
Felice Dell’Orletta, Simonetta Montemagni, and Giu-
lia Venturi. 2011. READ–IT: Assessing Readabil-
ity of Italian Texts with a View to Text Simplifica-
tion. In Proceedings of the 2nd Workshop on Speech
and Language Processing for Assistive Technolo-
gies, SLPAT 2011, pages 73–83.
Anca Dinu and Liviu P. Dinu. 2005. On the Syllabic
Similarities of Romance Languages. In Proceed-
ings of the 6th International Conference on Compu-
tational Linguistics and Intelligent Text Processing,
CICLing 2005, pages 785–788.
Liviu P. Dinu and Florin Manea. 2006. An Efficient
Approach for the Rank Aggregation Problem. The-
oretical Computer Science, 359(1):455–461.
Liviu P. Dinu and Marius Popescu. 2008. A Multi-
Criteria Decision Method Based on Rank Distance.
Fundamenta Informaticae, 86(1-2):79–91.
Noemie Elhadad and Komal Sutaria. 2007. Mining a
Lexicon of Technical Terms and Lay Equivalents. In
Proceedings of the Workshop on BioNLP 2007: Bi-
ological, Translational, and Clinical Language Pro-
cessing, BioNLP 2007, pages 49–56.
Lijun Feng, Martin Jansche, Matt Huenerfauth, and
No´emie Elhadad. 2010. A Comparison of Fea-
tures for Automatic Readability Assessment. In
Proceedings of the 23rd International Conference on
Computational Linguistics: Posters, COLING 2010,
pages 276–284.
Lijun Feng. 2009. Automatic Readability Assessment
for People with Intellectual Disabilities. SIGAC-
CESSAccess. Comput., (93):84–91.
Rudolf Flesch. 1946. The Art ofplain talk. T. Harper.
Thomas Franc¸ois and Eleni Miltsakaki. 2012. Do NLP
and Machine Learning Improve Traditional Read-
ability Formulas? In Proceedings of the First Work-
shop on Predicting and Improving Text Readability
for Target Reader Populations, PITR 2012, pages
49–57.
Valerio Franchina and Roberto Vacca. 1986. Adapta-
tion of Flesch readability index on a bilingual text
written by the same author both in Italian and En-
glish languages. Linguaggi, 3:47–49.
Arthur C. Graesser, Danielle S. McNamara, Max M.
Louwerse, and Zhiqiang Cai. 2004. Coh-Metrix:
Analysis of text on cohesion and language. Behav-
ior Research Methods, Instruments, and Computers,
36(2):193–202.
Robert Gunning. 1952. The technique of clear writing.
McGraw-Hill; Fouth Printing edition.
Michael Heilman, Kevyn Collins-Thompson, Jamie
Callan, and Maxine Eskenazi. 2007. Combining
Lexical and Grammatical Features to Improve Read-
ability Measures for First and Second Language
Texts. In Proceedings of the Human Language Tech-
nology Conference of the North American Chap-
ter of the Association of Computational Linguistics,
HLT-NAACL 2007, pages 460–467.
F. Huerta. 1959. Medida sencillas de lecturabilidad.
Consigna, 214:29–32.
Zahurul Islam and Alexander Mehler. 2012. Cus-
tomization of the Europarl Corpus for Translation
Studies. In Proceedings of the 8th International
Conference on Language Resources and Evaluation,
LREC 2012, pages 2505–2510.
Douglas Jones, Edward Gibson, Wade Shen, Neil Gra-
noien, Martha Herzog, Douglas Reynolds, and Clif-
ford Weinstein. 2005. Measuring Human Readabil-
ity of Machine Generated Text: Three Case Stud-
ies in Speech Recognition and Machine Translation.
In Proceedings of the IEEE International Confer-
ence on Acoustics, Speech, and Signal Processing,
ICASSP 2005, pages 1009–1012.
L. Kandel and A. Moles. 1958. Application de l’indice
de Flesch a la langue franc¸aise. Cahiers Etudes de
Radio-Television, 19:253–274.
J. Peter Kincaid, Lieutenant Robert P. Fishburne Jr.,
Richard L. Rogers, and Brad S. Chissom. 1975.
Derivation of new readability formulas (Automated
Readability Index, Fog Count and Flesch Reading
</reference>
<page confidence="0.982729">
112
</page>
<reference confidence="0.999765197916667">
Ease formula) for Navy enlisted personnel. Re-
search Branch Report, Millington, TN: Chief of
Naval Training.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proceedings of
the 10th Machine Translation Summit, pages 79–86.
Pietro Lucisano and Maria Emanuela Piemontese.
1988. Gulpease. una formula per la predizione della
difficolt`a dei testi in lingua italiana. Scuola e Citt`a,
39:110–124.
G. Harry McLaughlin. 1969. Smog grading: A new
readability formula. Journal of Reading, 12(8):639–
646.
Eugene A. Nida and Charles R. Taber. 1969. The The-
ory and Practice of Translation. Leiden: E.J. Brill.
Llu´ıs Padr´o and Evgeny Stanilovsky. 2012. FreeLing
3.0: Towards Wider Multilinguality. In Proceed-
ings of the 8th International Conference on Lan-
guage Resources and Evaluation, LREC 2012, pages
2473–2479.
Llu´ıs Padr´o, Miquel Collado, Samuel Reese, Marina
Lloberes, and Irene Castell´on. 2010. FreeLing
2.1: Five Years of Open-source Language Process-
ing Tools. In Proceedings of the 7th International
Conference on Language Resources and Evaluation,
LREC 2010, pages 931–936.
Llu´ıs Padr´o. 2011. Analizadores Multiling¨ues en
FreeLing. Linguamatica, 3(2):13–20.
Sarah E. Petersen and Mari Ostendorf. 2009. A Ma-
chine Learning Approach to Reading Level Assess-
ment. Computer Speech and Language, 23(1):89–
106.
Emily Pitler and Ani Nenkova. 2008. Revisiting Read-
ability: A Unified Framework for Predicting Text
Quality. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP 2008, pages 186–195.
Dragomir R. Radev and Weiguo Fan. 2000. Auto-
matic Summarization of Search Engine Hit Lists. In
Proceedings of the ACL-2000 Workshop on Recent
Advances in Natural Language Processing and In-
formation Retrieval: Held in Conjunction with the
38th Annual Meeting of the Association for Compu-
tational Linguistics, RANLPIR 2000, pages 99–109.
Gary A. Richwald, Margarita Schneider-Mufnoz, and
R. Burciaga Valdez. 1989. Are Condom Instruc-
tions in Spanish Readable? Implications for AIDS
Prevention Activities for Hispanics. Hispanic Jour-
nal of Behavioral Sciences, 11(1):70–82.
Marius Sala. 1988. Vocabularul Reprezentativ al Lim-
bilor Romanice. Editura Academiei, Bucures¸ti.
Christina Sch¨affner and Susan Bassnett. 2010. Pol-
itics, Media and Translation - Exploring Syner-
gies. In Political Discourse, Media and Transla-
tion, pages 1–29. Newcastle upon Tyne: Cambridge
Scholars Publishing.
Luo Si and Jamie Callan. 2001. A Statistical Model
for Scientific Readability. In Proceedings of the
10th International Conference on Information and
Knowledge Management, CIKM 2001, pages 574–
576.
E.A. Smith and R.J. Senter. 1967. Automated read-
ability index. Wright-Patterson Air Force Base.
AMRL-TR-6620.
Sara Stymne, J¨org Tiedemann, Christian Hardmeier,
and Joakim Nivre. 2013. Statistical Machine Trans-
lation with Readability Constraints. In Proceedings
of the 19th Nordic Conference on Computational
Linguistics, NODALIDA 2013, pages 375–386.
Yifeng Sun. 2012. Translation and strategies for cross-
cultural communication. Chinese Translators Jour-
nal, 33(1):16–23.
J¨org Tiedemann. 2012. Parallel Data, Tools and Inter-
faces in OPUS. In Proceedings of the 8th Interna-
tional Conference on Language Resources and Eval-
uation, LREC 2012, pages 2214–2218.
Sara Tonelli, Ke Tran Manh, and Emanuele Pianta.
2012. Making Readability Indices Readable. In
Proceedings of the 1st Workshop on Predicting and
Improving Text Readability for Target Reader Popu-
lations, PITR 2012, pages 40–48.
Anna Trosborg, editor. 1997. Text Typology and Trans-
lation. Benjamins Translation Library.
Sowmya Vajjala and Detmar Meurers. 2012. On Im-
proving the Accuracy of Readability Classification
Using Insights from Second Language Acquisition.
In Proceedings of the 7th Workshop on Building Ed-
ucational Applications Using NLP, pages 163–173.
Hans van Halteren. 2008. Source Language Mark-
ers in EUROPARL Translations. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics, COLING 2008, pages 937–944.
Tiziano Zito, Niko Wilbert, Laurenz Wiskott, and
Pietro Berkes. 2008. Modular toolkit for Data
Processing (MDP): a Python data processing frame
work. Front. Neuroinform., 2(8).
</reference>
<page confidence="0.99932">
113
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.735653">
<title confidence="0.998427">A Quantitative Insight into the Impact of Translation on Readability</title>
<author confidence="0.973687">Alina Maria Ciobanu</author>
<author confidence="0.973687">P Liviu</author>
<affiliation confidence="0.924411">Center for Computational Linguistics, University of Faculty of Mathematics and Computer Science, University of</affiliation>
<email confidence="0.789764">alina.ciobanu@my.fmi.unibuc.ro,ldinu@fmi.unibuc.ro</email>
<abstract confidence="0.999551307692308">In this paper we investigate the impact of translation on readability. We propose a quantitative analysis of several shallow, lexical and morpho-syntactic features that have been traditionally used for assessing readability and have proven relevant for this task. We conduct our experiments on a parallel corpus of transcribed parliamentary sessions and we investigate readability metrics for the original segments of text, written in the language of the speaker, and their translations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sandra Aluisio</author>
<author>Lucia Specia</author>
<author>Caroline Gasperin</author>
<author>Carolina Scarton</author>
</authors>
<title>Readability Assessment for Text Simplification.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, IUNLPBEA</booktitle>
<pages>1--9</pages>
<contexts>
<context position="2724" citStr="Aluisio et al., 2010" startWordPosition="396" endWordPosition="399">g material with an appropriate level of complexity from a large collection of documents – for example, the documents available on the web (Collins-Thompson, 2011). Within the medical domain, the investigation of the readability level of medical texts helps developing well-suited materials to increase the level of information for preventing diseases (Richwald et al., 1989) and to automatically adapt technical documents to various levels of medical expertise (Elhadad and Sutaria, 2007). For natural language processing tasks such as machine translation (Stymne et al., 2013), text simplification (Aluisio et al., 2010), speech recognition (Jones et al., 2005) or document summarization (Radev and Fan, 2000), readability approaches are employed to assist the process and to evaluate and quantify its performance and effectiveness. 1.1 Related Work Most of the traditional readability approaches investigate shallow text properties to determine the complexity of a text. These readability metrics are based on assumptions which correlate surface features with the linguistic factors which influence readability. For example, the average number of characters or syllables per word, the average number of words per senten</context>
<context position="7144" citStr="Aluisio et al., 2010" startWordPosition="1070" endWordPosition="1073">ne traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investigate a wide range of classic and non-classic features to predict readability level using a dataset for French as a foreign language. Readability assessment was also studied for Spanish (Huerta, 1959) and Portuguese (Aluisio et al., 2010) using features derived from previous research on English. 1.2 Readability of Translation According to Sun (2012), the reception of a translated text is related to cross-cultural readability. Translators need to understand the particularities of both the source and the target language in order to transfer the meaning of the text from one language to another. This process can be challenging, especially for languages with significant structure differences, such as English and Chinese. The three-step system of translation (analysis, transfer and restructuring) presented by Nida and Taber (1969) s</context>
</contexts>
<marker>Aluisio, Specia, Gasperin, Scarton, 2010</marker>
<rawString>Sandra Aluisio, Lucia Specia, Caroline Gasperin, and Carolina Scarton. 2010. Readability Assessment for Text Simplification. In Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, IUNLPBEA 2010, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
<author>Bernardino Casas</author>
<author>Elisabet Comelles</author>
<author>Meritxell Gonz´alez</author>
<author>Llu´ıs Padr´o</author>
<author>Muntsa Padr´o</author>
</authors>
<title>FreeLing 1.3: Syntactic and semantic services in an open-source NLP library.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC</booktitle>
<pages>2281--2286</pages>
<marker>Atserias, Casas, Comelles, Gonz´alez, Padr´o, Padr´o, 2006</marker>
<rawString>Jordi Atserias, Bernardino Casas, Elisabet Comelles, Meritxell Gonz´alez, Llu´ıs Padr´o, and Muntsa Padr´o. 2006. FreeLing 1.3: Syntactic and semantic services in an open-source NLP library. In Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC 2006, pages 2281– 2286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Isaac Chao</author>
<author>Llu´ıs Padr´o</author>
<author>Muntsa Padr´o</author>
</authors>
<title>FreeLing: An Open-Source Suite of Language Analyzers.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation, LREC</booktitle>
<pages>239--242</pages>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>Xavier Carreras, Isaac Chao, Llu´ıs Padr´o, and Muntsa Padr´o. 2004. FreeLing: An Open-Source Suite of Language Analyzers. In Proceedings of the 4th International Conference on Language Resources and Evaluation, LREC 2004, pages 239–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Meri Coleman</author>
<author>T L Liau</author>
</authors>
<title>A computer readability formula designed for machine scoring.</title>
<date>1975</date>
<journal>Journal of Applied Psychology,</journal>
<volume>60</volume>
<issue>2</issue>
<contexts>
<context position="3796" citStr="Coleman and Liau, 1975" startWordPosition="564" endWordPosition="567">uistic factors which influence readability. For example, the average number of characters or syllables per word, the average number of words per sentence and the percentage of words not occurring among the most frequent n words in a language are correlated with the lexical, syntactic and, respectively, the semantic complexity of the text. The Flesch-Kincaid measure (Kincaid et al., 1975) employs the average number of syllables per word and the average number of words per sentence to assess readability, while the Automated Readability Index (Smith and Senter, 1967) and the Coleman-Liau metric (Coleman and Liau, 1975) measure word length based on character count rather than syllable count; they are func104 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 104–113, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters per word and the average number of words per sentence. Gunning Fog (Gunning, 1952) and SMOG (McLaughlin, 1969) account also for the percentage of polysyllabic words and the Dale-Chall formula (Dale and Chall, 1995) relies on word fre</context>
</contexts>
<marker>Coleman, Liau, 1975</marker>
<rawString>Meri Coleman and T. L. Liau. 1975. A computer readability formula designed for machine scoring. Journal of Applied Psychology, 60(2):283–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevyn Collins-Thompson</author>
<author>James P Callan</author>
</authors>
<title>A Language Modeling Approach to Predicting Reading Difficulty.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL</booktitle>
<pages>193--200</pages>
<contexts>
<context position="5125" citStr="Collins-Thompson and Callan (2004)" startWordPosition="769" endWordPosition="772">lly expensive, but they are only a coarse approximation of the linguistic factors which influence readability (Pitler and Nenkova, 2008). According to Si and Callan (2001), the shallow features employed by standard readability indices are based on assumptions about writing style that may not apply in all situations. Along with the development of natural languages processing tools and machine learning techniques, factors of increasing complexity, corresponding to various levels of linguistic analysis, have been taken into account in the study of readability assessment. Si and Callan (2001) and Collins-Thompson and Callan (2004) use statistical language modeling and Petersen and Ostendorf (2009) combine features from statistical language models, syntactic parse trees and traditional metrics to estimate reading difficulty. Feng (2009) explores discourse level attributes, along with lexical and syntactic features, and emphasizes the value of the global semantic properties of the text for predicting text readability. Pitler and Nenkova (2008) propose and analyze two perspectives for the task of readability assessment: prediction and ranking. Using various features, they reach the conclusion that only discourse level fea</context>
</contexts>
<marker>Collins-Thompson, Callan, 2004</marker>
<rawString>Kevyn Collins-Thompson and James P. Callan. 2004. A Language Modeling Approach to Predicting Reading Difficulty. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL 2004, pages 193– 200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevyn Collins-Thompson</author>
</authors>
<title>Enriching Information Retrieval with Reading Level Prediction.</title>
<date>2011</date>
<booktitle>In SIGIR 2011 Workshop on Enriching Information Retrieval.</booktitle>
<contexts>
<context position="2265" citStr="Collins-Thompson, 2011" startWordPosition="330" endWordPosition="331">readability metrics were initially developed for English, current research has shown a growing interest in other languages, such as German, French, Italian or Portuguese. Readability assessment systems are relevant for a wide variety of applications, both human- and machine-oriented (Dell’Orletta et al., 2011). Second language learners and people with disabilities or low literacy skills benefit from such systems, which provide assistance in selecting reading material with an appropriate level of complexity from a large collection of documents – for example, the documents available on the web (Collins-Thompson, 2011). Within the medical domain, the investigation of the readability level of medical texts helps developing well-suited materials to increase the level of information for preventing diseases (Richwald et al., 1989) and to automatically adapt technical documents to various levels of medical expertise (Elhadad and Sutaria, 2007). For natural language processing tasks such as machine translation (Stymne et al., 2013), text simplification (Aluisio et al., 2010), speech recognition (Jones et al., 2005) or document summarization (Radev and Fan, 2000), readability approaches are employed to assist the </context>
</contexts>
<marker>Collins-Thompson, 2011</marker>
<rawString>Kevyn Collins-Thompson. 2011. Enriching Information Retrieval with Reading Level Prediction. In SIGIR 2011 Workshop on Enriching Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edgar Dale</author>
<author>Jeanne Chall</author>
</authors>
<title>Readability Revisited: The New Dale-Chall Readability Formula. Brookline Books,</title>
<date>1995</date>
<location>Cambridge.</location>
<contexts>
<context position="4377" citStr="Dale and Chall, 1995" startWordPosition="656" endWordPosition="659">man-Liau metric (Coleman and Liau, 1975) measure word length based on character count rather than syllable count; they are func104 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 104–113, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters per word and the average number of words per sentence. Gunning Fog (Gunning, 1952) and SMOG (McLaughlin, 1969) account also for the percentage of polysyllabic words and the Dale-Chall formula (Dale and Chall, 1995) relies on word frequency lists to assess readability. The traditional readability approaches are not computationally expensive, but they are only a coarse approximation of the linguistic factors which influence readability (Pitler and Nenkova, 2008). According to Si and Callan (2001), the shallow features employed by standard readability indices are based on assumptions about writing style that may not apply in all situations. Along with the development of natural languages processing tools and machine learning techniques, factors of increasing complexity, corresponding to various levels of l</context>
</contexts>
<marker>Dale, Chall, 1995</marker>
<rawString>Edgar Dale and Jeanne Chall. 1995. Readability Revisited: The New Dale-Chall Readability Formula. Brookline Books, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C de la Higuera</author>
<author>F Casacuberta</author>
</authors>
<title>Topology of Strings: Median String is NP-complete.</title>
<date>2000</date>
<journal>Theoretical Computer Science,</journal>
<pages>230--1</pages>
<contexts>
<context position="20532" citStr="Higuera and Casacuberta, 2000" startWordPosition="3252" endWordPosition="3255">le to all these rankings to be determined. In other words, it requires a means of combining the rankings. There are many ways to solve this problem, one of which is by trying to find a ranking such that the sum of rank distances between it and the given rankings is minimal. In other words, find σ such that: A(σ, T) = X A(σ, τ) T∈T is minimal. The set of all rankings that minimize A(σ, T) is called the aggregations set and is denoted by agr(T). Apart from many paradoxes of different aggregation methods, this problem is NP-hard for most non-trivial distances (e.g., for edit distance, see (de la Higuera and Casacuberta, 2000)). Dinu and Manea (2006) show that the rank aggregation problem using rank distance, which minimizes the sum A(σ, T) of the rank distances between the aggregation and each given ranking, can be reduced to solving |U |assignment problems, where U is the universe of objects. Let n = #U. The time complexity to obtain one such aggregation (there may be more than one) is O(n4). We then transform the aggregation problem in a categorization problem as follows (Dinu and Popescu, 2008): for a multiset L of rankings, we determine all the aggregations of L and then we apply voting on the set of agr(L). 4</context>
</contexts>
<marker>Higuera, Casacuberta, 2000</marker>
<rawString>C. de la Higuera and F. Casacuberta. 2000. Topology of Strings: Median String is NP-complete. Theoretical Computer Science, 230(1-2):39–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Felice Dell’Orletta</author>
<author>Simonetta Montemagni</author>
<author>Giulia Venturi</author>
</authors>
<title>READ–IT: Assessing Readability of Italian Texts with a View to Text Simplification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, SLPAT</booktitle>
<pages>73--83</pages>
<marker>Dell’Orletta, Montemagni, Venturi, 2011</marker>
<rawString>Felice Dell’Orletta, Simonetta Montemagni, and Giulia Venturi. 2011. READ–IT: Assessing Readability of Italian Texts with a View to Text Simplification. In Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, SLPAT 2011, pages 73–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anca Dinu</author>
<author>Liviu P Dinu</author>
</authors>
<title>On the Syllabic Similarities of Romance Languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing</booktitle>
<pages>785--788</pages>
<contexts>
<context position="18980" citStr="Dinu and Dinu, 2005" startWordPosition="2957" endWordPosition="2960">btained after applying the 10 readability features: a distance-based evaluation and a multi-criteria approach. In order to compute distance measures reliably, we normalize feature values using the following formula: fz = fi − fmin fmax − fmin , where fmin is the minimum value for feature F and fmax is the maximum value for feature F. For example, if F = F1 and the source language is Romanian, then fmin = 26.2 and fmax = 29.0. 4.1 Preliminaries In this subsection we shortly describe the two techniques used. The experimented reader can skip this subsection. 4.1.1 Rank Aggregation Rank distance (Dinu and Dinu, 2005) is a metric used for measuring the similarity between two ranked lists. A ranking of a set of n objects can be represented as a permutation of the integers 1, 2, ..., n. S is a set of ranking results, σ E S. σ(i) represents the rank of object i in the ranking result σ. The rank distance is computed as: A(σ, τ) = Xn |σ(i) − τ(i)| i=1 The ranks of the elements are given from bottom up, i.e., from n to 1, in a Borda order. The elements which do not occur in any of the rankings receive the rank 0. In a selection process, rankings are issued for a common decision problem, therefore a ranking that </context>
</contexts>
<marker>Dinu, Dinu, 2005</marker>
<rawString>Anca Dinu and Liviu P. Dinu. 2005. On the Syllabic Similarities of Romance Languages. In Proceedings of the 6th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing 2005, pages 785–788.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liviu P Dinu</author>
<author>Florin Manea</author>
</authors>
<title>An Efficient Approach for the Rank Aggregation Problem.</title>
<date>2006</date>
<journal>Theoretical Computer Science,</journal>
<volume>359</volume>
<issue>1</issue>
<contexts>
<context position="20556" citStr="Dinu and Manea (2006)" startWordPosition="3256" endWordPosition="3259">termined. In other words, it requires a means of combining the rankings. There are many ways to solve this problem, one of which is by trying to find a ranking such that the sum of rank distances between it and the given rankings is minimal. In other words, find σ such that: A(σ, T) = X A(σ, τ) T∈T is minimal. The set of all rankings that minimize A(σ, T) is called the aggregations set and is denoted by agr(T). Apart from many paradoxes of different aggregation methods, this problem is NP-hard for most non-trivial distances (e.g., for edit distance, see (de la Higuera and Casacuberta, 2000)). Dinu and Manea (2006) show that the rank aggregation problem using rank distance, which minimizes the sum A(σ, T) of the rank distances between the aggregation and each given ranking, can be reduced to solving |U |assignment problems, where U is the universe of objects. Let n = #U. The time complexity to obtain one such aggregation (there may be more than one) is O(n4). We then transform the aggregation problem in a categorization problem as follows (Dinu and Popescu, 2008): for a multiset L of rankings, we determine all the aggregations of L and then we apply voting on the set of agr(L). 4.1.2 Cosine Distance Cos</context>
</contexts>
<marker>Dinu, Manea, 2006</marker>
<rawString>Liviu P. Dinu and Florin Manea. 2006. An Efficient Approach for the Rank Aggregation Problem. Theoretical Computer Science, 359(1):455–461.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liviu P Dinu</author>
<author>Marius Popescu</author>
</authors>
<title>A MultiCriteria Decision Method Based on Rank Distance. Fundamenta Informaticae,</title>
<date>2008</date>
<pages>86--1</pages>
<contexts>
<context position="21013" citStr="Dinu and Popescu, 2008" startWordPosition="3334" endWordPosition="3337">ggregation methods, this problem is NP-hard for most non-trivial distances (e.g., for edit distance, see (de la Higuera and Casacuberta, 2000)). Dinu and Manea (2006) show that the rank aggregation problem using rank distance, which minimizes the sum A(σ, T) of the rank distances between the aggregation and each given ranking, can be reduced to solving |U |assignment problems, where U is the universe of objects. Let n = #U. The time complexity to obtain one such aggregation (there may be more than one) is O(n4). We then transform the aggregation problem in a categorization problem as follows (Dinu and Popescu, 2008): for a multiset L of rankings, we determine all the aggregations of L and then we apply voting on the set of agr(L). 4.1.2 Cosine Distance Cosine distance is a metric which computes the angular cosine distance between two vectors of an inner product space. Given two vectors of features, A and B, the cosine distance is represented as follows: Pn i=1 Ai × Bi A(A, B) = 1 − qPn )2 (Ai)2 × qPn 1 (Bi)2 When used in positive space, the cosine distance ranges from 0 to 1. 108 Source Target F1 F2 F3 F4 Features F7 F8 F9 F10 Language Language F5 F6 RO 26.2 5.61 0.67 0.06 0.66 0.15 0.29 0.16 0.05 0.11 F</context>
</contexts>
<marker>Dinu, Popescu, 2008</marker>
<rawString>Liviu P. Dinu and Marius Popescu. 2008. A MultiCriteria Decision Method Based on Rank Distance. Fundamenta Informaticae, 86(1-2):79–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noemie Elhadad</author>
<author>Komal Sutaria</author>
</authors>
<title>Mining a Lexicon of Technical Terms and Lay Equivalents.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing, BioNLP</booktitle>
<pages>49--56</pages>
<contexts>
<context position="2591" citStr="Elhadad and Sutaria, 2007" startWordPosition="377" endWordPosition="380">guage learners and people with disabilities or low literacy skills benefit from such systems, which provide assistance in selecting reading material with an appropriate level of complexity from a large collection of documents – for example, the documents available on the web (Collins-Thompson, 2011). Within the medical domain, the investigation of the readability level of medical texts helps developing well-suited materials to increase the level of information for preventing diseases (Richwald et al., 1989) and to automatically adapt technical documents to various levels of medical expertise (Elhadad and Sutaria, 2007). For natural language processing tasks such as machine translation (Stymne et al., 2013), text simplification (Aluisio et al., 2010), speech recognition (Jones et al., 2005) or document summarization (Radev and Fan, 2000), readability approaches are employed to assist the process and to evaluate and quantify its performance and effectiveness. 1.1 Related Work Most of the traditional readability approaches investigate shallow text properties to determine the complexity of a text. These readability metrics are based on assumptions which correlate surface features with the linguistic factors whi</context>
</contexts>
<marker>Elhadad, Sutaria, 2007</marker>
<rawString>Noemie Elhadad and Komal Sutaria. 2007. Mining a Lexicon of Technical Terms and Lay Equivalents. In Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing, BioNLP 2007, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lijun Feng</author>
<author>Martin Jansche</author>
<author>Matt Huenerfauth</author>
<author>No´emie Elhadad</author>
</authors>
<title>A Comparison of Features for Automatic Readability Assessment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING</booktitle>
<pages>276--284</pages>
<contexts>
<context position="15295" citStr="Feng et al. (2010)" startWordPosition="2364" endWordPosition="2367">xt gender and we report results obtained solely by comparison between source and target languages. 3.2 Features We investigate several shallow, lexical and morpho-syntactic features that were traditionally used for assessing readability and have proven high discriminative power within readability metrics. 3.2.1 Shallow Features Average number of words per sentence. The average sentence length is one of the most widely used metrics for determining readability level and was employed in numerous readability formulas, proving to be most meaningful in combined evidence with average word frequency. Feng et al. (2010) find the average sentence length to have higher predictive power than all the other lexical and syllable-based features they used. Average number of characters per word. It is generally considered that frequently occurring words are usually short, so the average number of characters per word was broadly used for measuring readability in a robust manner. Many readability formulas measure word length in syllables rather than letters, but this requires additional resources for syllabication. 3.2.2 Lexical Features Percentage of words from the basic lexicon. Based on the assumption that more comm</context>
</contexts>
<marker>Feng, Jansche, Huenerfauth, Elhadad, 2010</marker>
<rawString>Lijun Feng, Martin Jansche, Matt Huenerfauth, and No´emie Elhadad. 2010. A Comparison of Features for Automatic Readability Assessment. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING 2010, pages 276–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lijun Feng</author>
</authors>
<title>Automatic Readability Assessment for People with Intellectual Disabilities.</title>
<date>2009</date>
<journal>SIGACCESSAccess. Comput.,</journal>
<pages>93--84</pages>
<contexts>
<context position="5334" citStr="Feng (2009)" startWordPosition="800" endWordPosition="801">es are based on assumptions about writing style that may not apply in all situations. Along with the development of natural languages processing tools and machine learning techniques, factors of increasing complexity, corresponding to various levels of linguistic analysis, have been taken into account in the study of readability assessment. Si and Callan (2001) and Collins-Thompson and Callan (2004) use statistical language modeling and Petersen and Ostendorf (2009) combine features from statistical language models, syntactic parse trees and traditional metrics to estimate reading difficulty. Feng (2009) explores discourse level attributes, along with lexical and syntactic features, and emphasizes the value of the global semantic properties of the text for predicting text readability. Pitler and Nenkova (2008) propose and analyze two perspectives for the task of readability assessment: prediction and ranking. Using various features, they reach the conclusion that only discourse level features exhibit robustness across the two tasks. Vajjala and Meurers (2012) show that combining lexical and syntactic features with features derived from second language acquisition research leads to performance</context>
</contexts>
<marker>Feng, 2009</marker>
<rawString>Lijun Feng. 2009. Automatic Readability Assessment for People with Intellectual Disabilities. SIGACCESSAccess. Comput., (93):84–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolf Flesch</author>
</authors>
<title>The Art ofplain</title>
<date>1946</date>
<contexts>
<context position="6307" citStr="Flesch, 1946" startWordPosition="943" endWordPosition="944">n that only discourse level features exhibit robustness across the two tasks. Vajjala and Meurers (2012) show that combining lexical and syntactic features with features derived from second language acquisition research leads to performance improvements. Although most readability approaches developed so far deal with English, the development of adequate corpora for experiments and the study of readability features tailored for other languages have received increasing attention. For Italian, Franchina and Vacca (1986) propose the FleschVacca formula, which is an adaptation of the Flesch index (Flesch, 1946). Another metric developed for Italian is Gulpease (Lucisano and Piemontese, 1988), which uses characters instead of syllables to measure word length and thus requires less resources. Dell’Orletta et al. (2011) combine traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investi</context>
</contexts>
<marker>Flesch, 1946</marker>
<rawString>Rudolf Flesch. 1946. The Art ofplain talk. T. Harper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Franc¸ois</author>
<author>Eleni Miltsakaki</author>
</authors>
<title>Do NLP and Machine Learning Improve Traditional Readability Formulas?</title>
<date>2012</date>
<booktitle>In Proceedings of the First Workshop on Predicting and Improving Text Readability for Target Reader Populations, PITR 2012,</booktitle>
<pages>49--57</pages>
<marker>Franc¸ois, Miltsakaki, 2012</marker>
<rawString>Thomas Franc¸ois and Eleni Miltsakaki. 2012. Do NLP and Machine Learning Improve Traditional Readability Formulas? In Proceedings of the First Workshop on Predicting and Improving Text Readability for Target Reader Populations, PITR 2012, pages 49–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valerio Franchina</author>
<author>Roberto Vacca</author>
</authors>
<title>Adaptation of Flesch readability index on a bilingual text written by the same author both in Italian and English languages.</title>
<date>1986</date>
<journal>Linguaggi,</journal>
<pages>3--47</pages>
<contexts>
<context position="6216" citStr="Franchina and Vacca (1986)" startWordPosition="926" endWordPosition="929">task of readability assessment: prediction and ranking. Using various features, they reach the conclusion that only discourse level features exhibit robustness across the two tasks. Vajjala and Meurers (2012) show that combining lexical and syntactic features with features derived from second language acquisition research leads to performance improvements. Although most readability approaches developed so far deal with English, the development of adequate corpora for experiments and the study of readability features tailored for other languages have received increasing attention. For Italian, Franchina and Vacca (1986) propose the FleschVacca formula, which is an adaptation of the Flesch index (Flesch, 1946). Another metric developed for Italian is Gulpease (Lucisano and Piemontese, 1988), which uses characters instead of syllables to measure word length and thus requires less resources. Dell’Orletta et al. (2011) combine traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (19</context>
</contexts>
<marker>Franchina, Vacca, 1986</marker>
<rawString>Valerio Franchina and Roberto Vacca. 1986. Adaptation of Flesch readability index on a bilingual text written by the same author both in Italian and English languages. Linguaggi, 3:47–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur C Graesser</author>
<author>Danielle S McNamara</author>
<author>Max M Louwerse</author>
<author>Zhiqiang Cai</author>
</authors>
<title>Coh-Metrix: Analysis of text on cohesion and language.</title>
<date>2004</date>
<journal>Behavior Research Methods, Instruments, and Computers,</journal>
<volume>36</volume>
<issue>2</issue>
<contexts>
<context position="6782" citStr="Graesser et al., 2004" startWordPosition="1011" endWordPosition="1014">asing attention. For Italian, Franchina and Vacca (1986) propose the FleschVacca formula, which is an adaptation of the Flesch index (Flesch, 1946). Another metric developed for Italian is Gulpease (Lucisano and Piemontese, 1988), which uses characters instead of syllables to measure word length and thus requires less resources. Dell’Orletta et al. (2011) combine traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investigate a wide range of classic and non-classic features to predict readability level using a dataset for French as a foreign language. Readability assessment was also studied for Spanish (Huerta, 1959) and Portuguese (Aluisio et al., 2010) using features derived from previous research on English. 1.2 Readability of Translation According to Sun (2012), the reception of a translated text is related to cross-cultural readability. Translators need to understand the particulari</context>
</contexts>
<marker>Graesser, McNamara, Louwerse, Cai, 2004</marker>
<rawString>Arthur C. Graesser, Danielle S. McNamara, Max M. Louwerse, and Zhiqiang Cai. 2004. Coh-Metrix: Analysis of text on cohesion and language. Behavior Research Methods, Instruments, and Computers, 36(2):193–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Gunning</author>
</authors>
<title>The technique of clear writing. McGraw-Hill; Fouth Printing edition.</title>
<date>1952</date>
<contexts>
<context position="4245" citStr="Gunning, 1952" startWordPosition="636" endWordPosition="637">mber of words per sentence to assess readability, while the Automated Readability Index (Smith and Senter, 1967) and the Coleman-Liau metric (Coleman and Liau, 1975) measure word length based on character count rather than syllable count; they are func104 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 104–113, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters per word and the average number of words per sentence. Gunning Fog (Gunning, 1952) and SMOG (McLaughlin, 1969) account also for the percentage of polysyllabic words and the Dale-Chall formula (Dale and Chall, 1995) relies on word frequency lists to assess readability. The traditional readability approaches are not computationally expensive, but they are only a coarse approximation of the linguistic factors which influence readability (Pitler and Nenkova, 2008). According to Si and Callan (2001), the shallow features employed by standard readability indices are based on assumptions about writing style that may not apply in all situations. Along with the development of natura</context>
</contexts>
<marker>Gunning, 1952</marker>
<rawString>Robert Gunning. 1952. The technique of clear writing. McGraw-Hill; Fouth Printing edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Kevyn Collins-Thompson</author>
<author>Jamie Callan</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Combining Lexical and Grammatical Features to Improve Readability Measures for First and Second Language Texts.</title>
<date>2007</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL</booktitle>
<pages>460--467</pages>
<contexts>
<context position="17247" citStr="Heilman et al., 2007" startWordPosition="2672" endWordPosition="2675">a per-token basis. This feature assumes that the probability of a token is context-independent. For lemmatization and part of speech tagging we use the DexOnline2 machine-readable dictionary for Romanian and the FreeLing3 (Padr´o and Stanilovsky, 2012; Padr´o, 2011; Padr´o et al., 2010; Atserias et al., 2006; Carreras et al., 2004) language analysis tool suite for French, Italian, Spanish and Portuguese. Lexical density. The proportion of content words (verbs, nouns, adjectives and adverbs), computed on a per-token basis. Grammatical features were shown to be useful in readability prediction (Heilman et al., 2007). 4 Results Analysis Our main purpose is to investigate the variability of the feature values from the original texts to their translations. In Table 1 we report the values 2http://dexonline.ro 3http://nlp.lsi.upc.edu/freeling 107 obtained for 10 readability metrics computed for the Europarl subcorpora for Romanian, French, Italian, Spanish and Portuguese. The readability metrics we computed lead to several immediate remarks. We notice that, generally, when representing the values for a feature F on the real axis, the values corresponding to the translations are not placed on the same side of </context>
</contexts>
<marker>Heilman, Collins-Thompson, Callan, Eskenazi, 2007</marker>
<rawString>Michael Heilman, Kevyn Collins-Thompson, Jamie Callan, and Maxine Eskenazi. 2007. Combining Lexical and Grammatical Features to Improve Readability Measures for First and Second Language Texts. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL 2007, pages 460–467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huerta</author>
</authors>
<title>Medida sencillas de lecturabilidad.</title>
<date>1959</date>
<journal>Consigna,</journal>
<pages>214--29</pages>
<contexts>
<context position="7106" citStr="Huerta, 1959" startWordPosition="1066" endWordPosition="1067">ll’Orletta et al. (2011) combine traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investigate a wide range of classic and non-classic features to predict readability level using a dataset for French as a foreign language. Readability assessment was also studied for Spanish (Huerta, 1959) and Portuguese (Aluisio et al., 2010) using features derived from previous research on English. 1.2 Readability of Translation According to Sun (2012), the reception of a translated text is related to cross-cultural readability. Translators need to understand the particularities of both the source and the target language in order to transfer the meaning of the text from one language to another. This process can be challenging, especially for languages with significant structure differences, such as English and Chinese. The three-step system of translation (analysis, transfer and restructuring</context>
</contexts>
<marker>Huerta, 1959</marker>
<rawString>F. Huerta. 1959. Medida sencillas de lecturabilidad. Consigna, 214:29–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zahurul Islam</author>
<author>Alexander Mehler</author>
</authors>
<title>Customization of the Europarl Corpus for Translation Studies.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012,</booktitle>
<pages>2505--2510</pages>
<contexts>
<context position="8707" citStr="Islam and Mehler (2012)" startWordPosition="1309" endWordPosition="1312">f the translation strategy. For example, for political speeches the purpose is to report exactly what is communicated in a given text (Trosborg, 1997). Parallel corpora are very useful in studying the properties of translation and the relationships between source language and target language. Therefore, the corpus-based research has become more and more popular in translation research. Using the Europarl (Koehn, 2005) parallel corpus, van Halteren (2008) investigates the automatic identification of the source language of European Parliament speeches, based on frequency counts of word n-grams. Islam and Mehler (2012) draw attention to the absence of adequate corpora for studies on translation and propose a resource suited for this purpose. 105 2 Our Approach and Methodology The problem that we address in this paper is whether human translation has an impact on readability. Given a text T1 in a source language L1 and its translations in various target languages L2,..., Ln, how does readability vary? Is the original text in L1 easier to read and understand than its translation in a target language Li? Which language is closest to the source language, in terms of readability? We investigate several shallow, </context>
</contexts>
<marker>Islam, Mehler, 2012</marker>
<rawString>Zahurul Islam and Alexander Mehler. 2012. Customization of the Europarl Corpus for Translation Studies. In Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012, pages 2505–2510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Jones</author>
<author>Edward Gibson</author>
<author>Wade Shen</author>
<author>Neil Granoien</author>
<author>Martha Herzog</author>
<author>Douglas Reynolds</author>
<author>Clifford Weinstein</author>
</authors>
<title>Measuring Human Readability of Machine Generated Text: Three Case Studies in Speech Recognition and Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP</booktitle>
<pages>1009--1012</pages>
<contexts>
<context position="2765" citStr="Jones et al., 2005" startWordPosition="403" endWordPosition="406">plexity from a large collection of documents – for example, the documents available on the web (Collins-Thompson, 2011). Within the medical domain, the investigation of the readability level of medical texts helps developing well-suited materials to increase the level of information for preventing diseases (Richwald et al., 1989) and to automatically adapt technical documents to various levels of medical expertise (Elhadad and Sutaria, 2007). For natural language processing tasks such as machine translation (Stymne et al., 2013), text simplification (Aluisio et al., 2010), speech recognition (Jones et al., 2005) or document summarization (Radev and Fan, 2000), readability approaches are employed to assist the process and to evaluate and quantify its performance and effectiveness. 1.1 Related Work Most of the traditional readability approaches investigate shallow text properties to determine the complexity of a text. These readability metrics are based on assumptions which correlate surface features with the linguistic factors which influence readability. For example, the average number of characters or syllables per word, the average number of words per sentence and the percentage of words not occurr</context>
</contexts>
<marker>Jones, Gibson, Shen, Granoien, Herzog, Reynolds, Weinstein, 2005</marker>
<rawString>Douglas Jones, Edward Gibson, Wade Shen, Neil Granoien, Martha Herzog, Douglas Reynolds, and Clifford Weinstein. 2005. Measuring Human Readability of Machine Generated Text: Three Case Studies in Speech Recognition and Machine Translation. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2005, pages 1009–1012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kandel</author>
<author>A Moles</author>
</authors>
<title>Application de l’indice de Flesch a la langue franc¸aise. Cahiers Etudes de Radio-Television,</title>
<date>1958</date>
<contexts>
<context position="6819" citStr="Kandel and Moles (1958)" startWordPosition="1017" endWordPosition="1020">ina and Vacca (1986) propose the FleschVacca formula, which is an adaptation of the Flesch index (Flesch, 1946). Another metric developed for Italian is Gulpease (Lucisano and Piemontese, 1988), which uses characters instead of syllables to measure word length and thus requires less resources. Dell’Orletta et al. (2011) combine traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investigate a wide range of classic and non-classic features to predict readability level using a dataset for French as a foreign language. Readability assessment was also studied for Spanish (Huerta, 1959) and Portuguese (Aluisio et al., 2010) using features derived from previous research on English. 1.2 Readability of Translation According to Sun (2012), the reception of a translated text is related to cross-cultural readability. Translators need to understand the particularities of both the source and the targe</context>
</contexts>
<marker>Kandel, Moles, 1958</marker>
<rawString>L. Kandel and A. Moles. 1958. Application de l’indice de Flesch a la langue franc¸aise. Cahiers Etudes de Radio-Television, 19:253–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peter Kincaid</author>
<author>Lieutenant Robert P Fishburne Jr</author>
<author>Richard L Rogers</author>
<author>Brad S Chissom</author>
</authors>
<title>Derivation of new readability formulas (Automated Readability Index, Fog Count and Flesch Reading Ease formula) for Navy enlisted personnel. Research Branch Report,</title>
<date>1975</date>
<institution>Chief of Naval Training.</institution>
<location>Millington, TN:</location>
<contexts>
<context position="3563" citStr="Kincaid et al., 1975" startWordPosition="528" endWordPosition="531">elated Work Most of the traditional readability approaches investigate shallow text properties to determine the complexity of a text. These readability metrics are based on assumptions which correlate surface features with the linguistic factors which influence readability. For example, the average number of characters or syllables per word, the average number of words per sentence and the percentage of words not occurring among the most frequent n words in a language are correlated with the lexical, syntactic and, respectively, the semantic complexity of the text. The Flesch-Kincaid measure (Kincaid et al., 1975) employs the average number of syllables per word and the average number of words per sentence to assess readability, while the Automated Readability Index (Smith and Senter, 1967) and the Coleman-Liau metric (Coleman and Liau, 1975) measure word length based on character count rather than syllable count; they are func104 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 104–113, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters </context>
</contexts>
<marker>Kincaid, Jr, Rogers, Chissom, 1975</marker>
<rawString>J. Peter Kincaid, Lieutenant Robert P. Fishburne Jr., Richard L. Rogers, and Brad S. Chissom. 1975. Derivation of new readability formulas (Automated Readability Index, Fog Count and Flesch Reading Ease formula) for Navy enlisted personnel. Research Branch Report, Millington, TN: Chief of Naval Training.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Machine Translation Summit,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="8505" citStr="Koehn, 2005" startWordPosition="1280" endWordPosition="1281">uage text into the target language, it is also important to maintain the style of the document. Various genres of text might be translated for different purposes, which influence the choice of the translation strategy. For example, for political speeches the purpose is to report exactly what is communicated in a given text (Trosborg, 1997). Parallel corpora are very useful in studying the properties of translation and the relationships between source language and target language. Therefore, the corpus-based research has become more and more popular in translation research. Using the Europarl (Koehn, 2005) parallel corpus, van Halteren (2008) investigates the automatic identification of the source language of European Parliament speeches, based on frequency counts of word n-grams. Islam and Mehler (2012) draw attention to the absence of adequate corpora for studies on translation and propose a resource suited for this purpose. 105 2 Our Approach and Methodology The problem that we address in this paper is whether human translation has an impact on readability. Given a text T1 in a source language L1 and its translations in various target languages L2,..., Ln, how does readability vary? Is the o</context>
<context position="9883" citStr="Koehn, 2005" startWordPosition="1505" endWordPosition="1506">ty? We investigate several shallow, lexical and morpho-syntactic features that have been widely used and have proven relevant for assessing readability. We are interested in observing the differences between the feature values obtained for the original texts and those obtained for their translations. Although some of the metrics (such as average word length) might be languagespecific, most of them are language-independent and a comparison between them across languages is justified. The 10 readability metrics that we account for are described in Section 3.2. We run our experiments on Europarl (Koehn, 2005), a multilingual parallel corpus which is described in detail in Section 3.1. We investigate 5 Romance languages (Romanian, French, Italian, Spanish and Portuguese) and, in order to excerpt an adequate dataset of parallel texts, we adopt a strategy similar to that of van Halteren (2008): given n languages L1,..., Ln, we apply the following steps: 1. we select L1 as the source language 2. we excerpt the collection of segments of text T1 for which L1 is the source language 3. we identify the translations T2, ..., Tn of T1 in the target languages L2, ..., Ln 4. we compute the readability metrics </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of the 10th Machine Translation Summit, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pietro Lucisano</author>
<author>Maria Emanuela Piemontese</author>
</authors>
<title>Gulpease. una formula per la predizione della difficolt`a dei testi in lingua italiana.</title>
<date>1988</date>
<booktitle>Scuola e Citt`a,</booktitle>
<pages>39--110</pages>
<contexts>
<context position="6389" citStr="Lucisano and Piemontese, 1988" startWordPosition="953" endWordPosition="956">e two tasks. Vajjala and Meurers (2012) show that combining lexical and syntactic features with features derived from second language acquisition research leads to performance improvements. Although most readability approaches developed so far deal with English, the development of adequate corpora for experiments and the study of readability features tailored for other languages have received increasing attention. For Italian, Franchina and Vacca (1986) propose the FleschVacca formula, which is an adaptation of the Flesch index (Flesch, 1946). Another metric developed for Italian is Gulpease (Lucisano and Piemontese, 1988), which uses characters instead of syllables to measure word length and thus requires less resources. Dell’Orletta et al. (2011) combine traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investigate a wide range of classic and non-classic features to predict readability level</context>
</contexts>
<marker>Lucisano, Piemontese, 1988</marker>
<rawString>Pietro Lucisano and Maria Emanuela Piemontese. 1988. Gulpease. una formula per la predizione della difficolt`a dei testi in lingua italiana. Scuola e Citt`a, 39:110–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Harry McLaughlin</author>
</authors>
<title>Smog grading: A new readability formula.</title>
<date>1969</date>
<journal>Journal of Reading,</journal>
<volume>12</volume>
<issue>8</issue>
<pages>646</pages>
<contexts>
<context position="4273" citStr="McLaughlin, 1969" startWordPosition="640" endWordPosition="641">e to assess readability, while the Automated Readability Index (Smith and Senter, 1967) and the Coleman-Liau metric (Coleman and Liau, 1975) measure word length based on character count rather than syllable count; they are func104 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 104–113, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters per word and the average number of words per sentence. Gunning Fog (Gunning, 1952) and SMOG (McLaughlin, 1969) account also for the percentage of polysyllabic words and the Dale-Chall formula (Dale and Chall, 1995) relies on word frequency lists to assess readability. The traditional readability approaches are not computationally expensive, but they are only a coarse approximation of the linguistic factors which influence readability (Pitler and Nenkova, 2008). According to Si and Callan (2001), the shallow features employed by standard readability indices are based on assumptions about writing style that may not apply in all situations. Along with the development of natural languages processing tools</context>
</contexts>
<marker>McLaughlin, 1969</marker>
<rawString>G. Harry McLaughlin. 1969. Smog grading: A new readability formula. Journal of Reading, 12(8):639– 646.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene A Nida</author>
<author>Charles R Taber</author>
</authors>
<title>The Theory and Practice of Translation.</title>
<date>1969</date>
<publisher>E.J. Brill.</publisher>
<location>Leiden:</location>
<contexts>
<context position="7742" citStr="Nida and Taber (1969)" startWordPosition="1161" endWordPosition="1164"> (Aluisio et al., 2010) using features derived from previous research on English. 1.2 Readability of Translation According to Sun (2012), the reception of a translated text is related to cross-cultural readability. Translators need to understand the particularities of both the source and the target language in order to transfer the meaning of the text from one language to another. This process can be challenging, especially for languages with significant structure differences, such as English and Chinese. The three-step system of translation (analysis, transfer and restructuring) presented by Nida and Taber (1969) summarizes the process and emphasizes the importance of a proper understanding of the source and the target languages. While rendering the source language text into the target language, it is also important to maintain the style of the document. Various genres of text might be translated for different purposes, which influence the choice of the translation strategy. For example, for political speeches the purpose is to report exactly what is communicated in a given text (Trosborg, 1997). Parallel corpora are very useful in studying the properties of translation and the relationships between s</context>
</contexts>
<marker>Nida, Taber, 1969</marker>
<rawString>Eugene A. Nida and Charles R. Taber. 1969. The Theory and Practice of Translation. Leiden: E.J. Brill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs Padr´o</author>
<author>Evgeny Stanilovsky</author>
</authors>
<title>FreeLing 3.0: Towards Wider Multilinguality.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012,</booktitle>
<pages>2473--2479</pages>
<marker>Padr´o, Stanilovsky, 2012</marker>
<rawString>Llu´ıs Padr´o and Evgeny Stanilovsky. 2012. FreeLing 3.0: Towards Wider Multilinguality. In Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012, pages 2473–2479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs Padr´o</author>
<author>Miquel Collado</author>
<author>Samuel Reese</author>
<author>Marina Lloberes</author>
<author>Irene Castell´on</author>
</authors>
<title>FreeLing 2.1: Five Years of Open-source Language Processing Tools.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation, LREC</booktitle>
<pages>931--936</pages>
<marker>Padr´o, Collado, Reese, Lloberes, Castell´on, 2010</marker>
<rawString>Llu´ıs Padr´o, Miquel Collado, Samuel Reese, Marina Lloberes, and Irene Castell´on. 2010. FreeLing 2.1: Five Years of Open-source Language Processing Tools. In Proceedings of the 7th International Conference on Language Resources and Evaluation, LREC 2010, pages 931–936.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs Padr´o</author>
</authors>
<title>Analizadores Multiling¨ues en FreeLing.</title>
<date>2011</date>
<journal>Linguamatica,</journal>
<volume>3</volume>
<issue>2</issue>
<marker>Padr´o, 2011</marker>
<rawString>Llu´ıs Padr´o. 2011. Analizadores Multiling¨ues en FreeLing. Linguamatica, 3(2):13–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah E Petersen</author>
<author>Mari Ostendorf</author>
</authors>
<title>A Machine Learning Approach to Reading Level Assessment.</title>
<date>2009</date>
<journal>Computer Speech and Language,</journal>
<volume>23</volume>
<issue>1</issue>
<pages>106</pages>
<contexts>
<context position="5193" citStr="Petersen and Ostendorf (2009)" startWordPosition="779" endWordPosition="782"> factors which influence readability (Pitler and Nenkova, 2008). According to Si and Callan (2001), the shallow features employed by standard readability indices are based on assumptions about writing style that may not apply in all situations. Along with the development of natural languages processing tools and machine learning techniques, factors of increasing complexity, corresponding to various levels of linguistic analysis, have been taken into account in the study of readability assessment. Si and Callan (2001) and Collins-Thompson and Callan (2004) use statistical language modeling and Petersen and Ostendorf (2009) combine features from statistical language models, syntactic parse trees and traditional metrics to estimate reading difficulty. Feng (2009) explores discourse level attributes, along with lexical and syntactic features, and emphasizes the value of the global semantic properties of the text for predicting text readability. Pitler and Nenkova (2008) propose and analyze two perspectives for the task of readability assessment: prediction and ranking. Using various features, they reach the conclusion that only discourse level features exhibit robustness across the two tasks. Vajjala and Meurers (</context>
</contexts>
<marker>Petersen, Ostendorf, 2009</marker>
<rawString>Sarah E. Petersen and Mari Ostendorf. 2009. A Machine Learning Approach to Reading Level Assessment. Computer Speech and Language, 23(1):89– 106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Revisiting Readability: A Unified Framework for Predicting Text Quality.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP</booktitle>
<pages>186--195</pages>
<contexts>
<context position="4627" citStr="Pitler and Nenkova, 2008" startWordPosition="693" endWordPosition="696"> EACL 2014, pages 104–113, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters per word and the average number of words per sentence. Gunning Fog (Gunning, 1952) and SMOG (McLaughlin, 1969) account also for the percentage of polysyllabic words and the Dale-Chall formula (Dale and Chall, 1995) relies on word frequency lists to assess readability. The traditional readability approaches are not computationally expensive, but they are only a coarse approximation of the linguistic factors which influence readability (Pitler and Nenkova, 2008). According to Si and Callan (2001), the shallow features employed by standard readability indices are based on assumptions about writing style that may not apply in all situations. Along with the development of natural languages processing tools and machine learning techniques, factors of increasing complexity, corresponding to various levels of linguistic analysis, have been taken into account in the study of readability assessment. Si and Callan (2001) and Collins-Thompson and Callan (2004) use statistical language modeling and Petersen and Ostendorf (2009) combine features from statistical</context>
</contexts>
<marker>Pitler, Nenkova, 2008</marker>
<rawString>Emily Pitler and Ani Nenkova. 2008. Revisiting Readability: A Unified Framework for Predicting Text Quality. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP 2008, pages 186–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Weiguo Fan</author>
</authors>
<title>Automatic Summarization of Search Engine Hit Lists.</title>
<date>2000</date>
<booktitle>In Proceedings of the ACL-2000 Workshop on Recent Advances in Natural Language Processing and Information Retrieval: Held in Conjunction with the 38th Annual Meeting of the Association for Computational Linguistics, RANLPIR</booktitle>
<pages>99--109</pages>
<contexts>
<context position="2813" citStr="Radev and Fan, 2000" startWordPosition="411" endWordPosition="414">for example, the documents available on the web (Collins-Thompson, 2011). Within the medical domain, the investigation of the readability level of medical texts helps developing well-suited materials to increase the level of information for preventing diseases (Richwald et al., 1989) and to automatically adapt technical documents to various levels of medical expertise (Elhadad and Sutaria, 2007). For natural language processing tasks such as machine translation (Stymne et al., 2013), text simplification (Aluisio et al., 2010), speech recognition (Jones et al., 2005) or document summarization (Radev and Fan, 2000), readability approaches are employed to assist the process and to evaluate and quantify its performance and effectiveness. 1.1 Related Work Most of the traditional readability approaches investigate shallow text properties to determine the complexity of a text. These readability metrics are based on assumptions which correlate surface features with the linguistic factors which influence readability. For example, the average number of characters or syllables per word, the average number of words per sentence and the percentage of words not occurring among the most frequent n words in a languag</context>
</contexts>
<marker>Radev, Fan, 2000</marker>
<rawString>Dragomir R. Radev and Weiguo Fan. 2000. Automatic Summarization of Search Engine Hit Lists. In Proceedings of the ACL-2000 Workshop on Recent Advances in Natural Language Processing and Information Retrieval: Held in Conjunction with the 38th Annual Meeting of the Association for Computational Linguistics, RANLPIR 2000, pages 99–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary A Richwald</author>
<author>Margarita Schneider-Mufnoz</author>
<author>R Burciaga Valdez</author>
</authors>
<title>Are Condom Instructions in Spanish Readable? Implications for AIDS Prevention Activities for Hispanics.</title>
<date>1989</date>
<journal>Hispanic Journal of Behavioral Sciences,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="2477" citStr="Richwald et al., 1989" startWordPosition="360" endWordPosition="363">t for a wide variety of applications, both human- and machine-oriented (Dell’Orletta et al., 2011). Second language learners and people with disabilities or low literacy skills benefit from such systems, which provide assistance in selecting reading material with an appropriate level of complexity from a large collection of documents – for example, the documents available on the web (Collins-Thompson, 2011). Within the medical domain, the investigation of the readability level of medical texts helps developing well-suited materials to increase the level of information for preventing diseases (Richwald et al., 1989) and to automatically adapt technical documents to various levels of medical expertise (Elhadad and Sutaria, 2007). For natural language processing tasks such as machine translation (Stymne et al., 2013), text simplification (Aluisio et al., 2010), speech recognition (Jones et al., 2005) or document summarization (Radev and Fan, 2000), readability approaches are employed to assist the process and to evaluate and quantify its performance and effectiveness. 1.1 Related Work Most of the traditional readability approaches investigate shallow text properties to determine the complexity of a text. T</context>
</contexts>
<marker>Richwald, Schneider-Mufnoz, Valdez, 1989</marker>
<rawString>Gary A. Richwald, Margarita Schneider-Mufnoz, and R. Burciaga Valdez. 1989. Are Condom Instructions in Spanish Readable? Implications for AIDS Prevention Activities for Hispanics. Hispanic Journal of Behavioral Sciences, 11(1):70–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Sala</author>
</authors>
<title>Vocabularul Reprezentativ al Limbilor Romanice. Editura Academiei,</title>
<date>1988</date>
<location>Bucures¸ti.</location>
<contexts>
<context position="16212" citStr="Sala (1988)" startWordPosition="2511" endWordPosition="2512">used for measuring readability in a robust manner. Many readability formulas measure word length in syllables rather than letters, but this requires additional resources for syllabication. 3.2.2 Lexical Features Percentage of words from the basic lexicon. Based on the assumption that more common words are easier to understand, the percentage of words not occurring among the most frequent n in the language is a commonly used metric to approximate readability. To determine the percentage of words from the basic lexicon, we employ the representative vocabularies for Romance languages proposed by Sala (1988). Type/Token Ratio. The proportion between the number of lexical types and the number of tokens indicates the range of use of vocabulary. The higher the value of this feature, the higher the variability of the vocabulary used in the text. 3.2.3 Morpho-Syntactic Features Relative frequency of POS unigrams. The ratio for 5 parts of speech (verbs, nouns, pronouns, adjectives and adverbs), computed individually on a per-token basis. This feature assumes that the probability of a token is context-independent. For lemmatization and part of speech tagging we use the DexOnline2 machine-readable dictio</context>
</contexts>
<marker>Sala, 1988</marker>
<rawString>Marius Sala. 1988. Vocabularul Reprezentativ al Limbilor Romanice. Editura Academiei, Bucures¸ti.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sch¨affner</author>
<author>Susan Bassnett</author>
</authors>
<title>Politics, Media and Translation - Exploring Synergies.</title>
<date>2010</date>
<booktitle>In Political Discourse, Media and Translation,</booktitle>
<pages>1--29</pages>
<marker>Sch¨affner, Bassnett, 2010</marker>
<rawString>Christina Sch¨affner and Susan Bassnett. 2010. Politics, Media and Translation - Exploring Synergies. In Political Discourse, Media and Translation, pages 1–29. Newcastle upon Tyne: Cambridge Scholars Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luo Si</author>
<author>Jamie Callan</author>
</authors>
<title>A Statistical Model for Scientific Readability.</title>
<date>2001</date>
<booktitle>In Proceedings of the 10th International Conference on Information and Knowledge Management, CIKM</booktitle>
<pages>574--576</pages>
<contexts>
<context position="4662" citStr="Si and Callan (2001)" startWordPosition="699" endWordPosition="702">weden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters per word and the average number of words per sentence. Gunning Fog (Gunning, 1952) and SMOG (McLaughlin, 1969) account also for the percentage of polysyllabic words and the Dale-Chall formula (Dale and Chall, 1995) relies on word frequency lists to assess readability. The traditional readability approaches are not computationally expensive, but they are only a coarse approximation of the linguistic factors which influence readability (Pitler and Nenkova, 2008). According to Si and Callan (2001), the shallow features employed by standard readability indices are based on assumptions about writing style that may not apply in all situations. Along with the development of natural languages processing tools and machine learning techniques, factors of increasing complexity, corresponding to various levels of linguistic analysis, have been taken into account in the study of readability assessment. Si and Callan (2001) and Collins-Thompson and Callan (2004) use statistical language modeling and Petersen and Ostendorf (2009) combine features from statistical language models, syntactic parse t</context>
</contexts>
<marker>Si, Callan, 2001</marker>
<rawString>Luo Si and Jamie Callan. 2001. A Statistical Model for Scientific Readability. In Proceedings of the 10th International Conference on Information and Knowledge Management, CIKM 2001, pages 574– 576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Smith</author>
<author>R J Senter</author>
</authors>
<title>Automated readability index. Wright-Patterson Air Force Base.</title>
<date>1967</date>
<pages>6620</pages>
<contexts>
<context position="3743" citStr="Smith and Senter, 1967" startWordPosition="556" endWordPosition="559">ptions which correlate surface features with the linguistic factors which influence readability. For example, the average number of characters or syllables per word, the average number of words per sentence and the percentage of words not occurring among the most frequent n words in a language are correlated with the lexical, syntactic and, respectively, the semantic complexity of the text. The Flesch-Kincaid measure (Kincaid et al., 1975) employs the average number of syllables per word and the average number of words per sentence to assess readability, while the Automated Readability Index (Smith and Senter, 1967) and the Coleman-Liau metric (Coleman and Liau, 1975) measure word length based on character count rather than syllable count; they are func104 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 104–113, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics tions of both the average number of characters per word and the average number of words per sentence. Gunning Fog (Gunning, 1952) and SMOG (McLaughlin, 1969) account also for the percentage of polysyllabic words and the Dale-Ch</context>
</contexts>
<marker>Smith, Senter, 1967</marker>
<rawString>E.A. Smith and R.J. Senter. 1967. Automated readability index. Wright-Patterson Air Force Base. AMRL-TR-6620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
<author>J¨org Tiedemann</author>
<author>Christian Hardmeier</author>
<author>Joakim Nivre</author>
</authors>
<title>Statistical Machine Translation with Readability Constraints.</title>
<date>2013</date>
<booktitle>In Proceedings of the 19th Nordic Conference on Computational Linguistics, NODALIDA</booktitle>
<pages>375--386</pages>
<contexts>
<context position="2680" citStr="Stymne et al., 2013" startWordPosition="390" endWordPosition="393">hich provide assistance in selecting reading material with an appropriate level of complexity from a large collection of documents – for example, the documents available on the web (Collins-Thompson, 2011). Within the medical domain, the investigation of the readability level of medical texts helps developing well-suited materials to increase the level of information for preventing diseases (Richwald et al., 1989) and to automatically adapt technical documents to various levels of medical expertise (Elhadad and Sutaria, 2007). For natural language processing tasks such as machine translation (Stymne et al., 2013), text simplification (Aluisio et al., 2010), speech recognition (Jones et al., 2005) or document summarization (Radev and Fan, 2000), readability approaches are employed to assist the process and to evaluate and quantify its performance and effectiveness. 1.1 Related Work Most of the traditional readability approaches investigate shallow text properties to determine the complexity of a text. These readability metrics are based on assumptions which correlate surface features with the linguistic factors which influence readability. For example, the average number of characters or syllables per </context>
</contexts>
<marker>Stymne, Tiedemann, Hardmeier, Nivre, 2013</marker>
<rawString>Sara Stymne, J¨org Tiedemann, Christian Hardmeier, and Joakim Nivre. 2013. Statistical Machine Translation with Readability Constraints. In Proceedings of the 19th Nordic Conference on Computational Linguistics, NODALIDA 2013, pages 375–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yifeng Sun</author>
</authors>
<title>Translation and strategies for crosscultural communication.</title>
<date>2012</date>
<journal>Chinese Translators Journal,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="7257" citStr="Sun (2012)" startWordPosition="1089" endWordPosition="1090"> et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investigate a wide range of classic and non-classic features to predict readability level using a dataset for French as a foreign language. Readability assessment was also studied for Spanish (Huerta, 1959) and Portuguese (Aluisio et al., 2010) using features derived from previous research on English. 1.2 Readability of Translation According to Sun (2012), the reception of a translated text is related to cross-cultural readability. Translators need to understand the particularities of both the source and the target language in order to transfer the meaning of the text from one language to another. This process can be challenging, especially for languages with significant structure differences, such as English and Chinese. The three-step system of translation (analysis, transfer and restructuring) presented by Nida and Taber (1969) summarizes the process and emphasizes the importance of a proper understanding of the source and the target langua</context>
</contexts>
<marker>Sun, 2012</marker>
<rawString>Yifeng Sun. 2012. Translation and strategies for crosscultural communication. Chinese Translators Journal, 33(1):16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Parallel Data, Tools and Interfaces in OPUS.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012,</booktitle>
<pages>2214--2218</pages>
<contexts>
<context position="11062" citStr="Tiedemann, 2012" startWordPosition="1706" endWordPosition="1707">. we compute the readability metrics for T1, ..., Tn 5. we repeat steps 1 − 4 using each language L2, ..., Ln as the source language, one at a time We propose two approaches to quantify and evaluate the variation in the readability feature values from the original texts to their translations: a distance-based method and a multi-criteria technique based on rank aggregation. 3 Experimental Setup 3.1 Data Europarl (Koehn, 2005) is a multilingual parallel corpus extracted from the proceedings of the European Parliament. Its main intended use is as aid for statistical machine translation research (Tiedemann, 2012). The corpus is tokenized and aligned in 21 languages. The files contain annotations for marking the document (&lt;chapter&gt;), the speaker (&lt;speaker&gt;) and the paragraph (&lt;p&gt;). Some documents have the attribute language for the speaker tag, which indicates the language used by the original speaker. Another way of annotating the original language is by having the language abbreviation written between parentheses at the beginning of each segment of text. However, there are segments where the language is not marked in either of the two ways. We account only for sentences for which the original languag</context>
</contexts>
<marker>Tiedemann, 2012</marker>
<rawString>J¨org Tiedemann. 2012. Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012, pages 2214–2218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Ke Tran Manh</author>
<author>Emanuele Pianta</author>
</authors>
<title>Making Readability Indices Readable.</title>
<date>2012</date>
<booktitle>In Proceedings of the 1st Workshop on Predicting and Improving Text Readability for Target Reader Populations, PITR 2012,</booktitle>
<pages>40--48</pages>
<contexts>
<context position="6661" citStr="Tonelli et al. (2012)" startWordPosition="992" endWordPosition="995"> adequate corpora for experiments and the study of readability features tailored for other languages have received increasing attention. For Italian, Franchina and Vacca (1986) propose the FleschVacca formula, which is an adaptation of the Flesch index (Flesch, 1946). Another metric developed for Italian is Gulpease (Lucisano and Piemontese, 1988), which uses characters instead of syllables to measure word length and thus requires less resources. Dell’Orletta et al. (2011) combine traditional, morpho-syntactic, lexical and syntactic features for building a readability model for Italian, while Tonelli et al. (2012) propose a system for readability assessment for Italian inspired by the principles of Coh-Metrix (Graesser et al., 2004). For French, Kandel and Moles (1958) propose an adaptation of the Flesch formula and Franc¸ois and Miltsakaki (2012) investigate a wide range of classic and non-classic features to predict readability level using a dataset for French as a foreign language. Readability assessment was also studied for Spanish (Huerta, 1959) and Portuguese (Aluisio et al., 2010) using features derived from previous research on English. 1.2 Readability of Translation According to Sun (2012), th</context>
</contexts>
<marker>Tonelli, Manh, Pianta, 2012</marker>
<rawString>Sara Tonelli, Ke Tran Manh, and Emanuele Pianta. 2012. Making Readability Indices Readable. In Proceedings of the 1st Workshop on Predicting and Improving Text Readability for Target Reader Populations, PITR 2012, pages 40–48.</rawString>
</citation>
<citation valid="true">
<date>1997</date>
<booktitle>Text Typology and Translation. Benjamins Translation Library.</booktitle>
<editor>Anna Trosborg, editor.</editor>
<marker>1997</marker>
<rawString>Anna Trosborg, editor. 1997. Text Typology and Translation. Benjamins Translation Library.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sowmya Vajjala</author>
<author>Detmar Meurers</author>
</authors>
<title>On Improving the Accuracy of Readability Classification Using Insights from Second Language Acquisition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 7th Workshop on Building Educational Applications Using NLP,</booktitle>
<pages>163--173</pages>
<contexts>
<context position="5798" citStr="Vajjala and Meurers (2012)" startWordPosition="867" endWordPosition="870"> and Ostendorf (2009) combine features from statistical language models, syntactic parse trees and traditional metrics to estimate reading difficulty. Feng (2009) explores discourse level attributes, along with lexical and syntactic features, and emphasizes the value of the global semantic properties of the text for predicting text readability. Pitler and Nenkova (2008) propose and analyze two perspectives for the task of readability assessment: prediction and ranking. Using various features, they reach the conclusion that only discourse level features exhibit robustness across the two tasks. Vajjala and Meurers (2012) show that combining lexical and syntactic features with features derived from second language acquisition research leads to performance improvements. Although most readability approaches developed so far deal with English, the development of adequate corpora for experiments and the study of readability features tailored for other languages have received increasing attention. For Italian, Franchina and Vacca (1986) propose the FleschVacca formula, which is an adaptation of the Flesch index (Flesch, 1946). Another metric developed for Italian is Gulpease (Lucisano and Piemontese, 1988), which u</context>
</contexts>
<marker>Vajjala, Meurers, 2012</marker>
<rawString>Sowmya Vajjala and Detmar Meurers. 2012. On Improving the Accuracy of Readability Classification Using Insights from Second Language Acquisition. In Proceedings of the 7th Workshop on Building Educational Applications Using NLP, pages 163–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans van Halteren</author>
</authors>
<title>Source Language Markers in EUROPARL Translations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics, COLING</booktitle>
<pages>937--944</pages>
<marker>van Halteren, 2008</marker>
<rawString>Hans van Halteren. 2008. Source Language Markers in EUROPARL Translations. In Proceedings of the 22nd International Conference on Computational Linguistics, COLING 2008, pages 937–944.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tiziano Zito</author>
<author>Niko Wilbert</author>
<author>Laurenz Wiskott</author>
<author>Pietro Berkes</author>
</authors>
<title>Modular toolkit for Data Processing (MDP): a Python data processing frame work.</title>
<date>2008</date>
<journal>Front. Neuroinform.,</journal>
<volume>2</volume>
<issue>8</issue>
<contexts>
<context position="28886" citStr="Zito et al., 2008" startWordPosition="4716" endWordPosition="4719">T_PT IT_RO ES_RO ES_FR RO_FR PT_FR FR_FR IT_FR ES_IT ES_PT PT_IT FR_PT FR_IT RO_IT PT_PT RO_PT original translation 1.5 1.0 0.5 0.0 0.5 1.0 Figure 1: PCA. Languages are annotated in the figure as follows: L1 L2, where L1 is the source language and L2 is the target language. 4.3 PCA: Original vs. Translation In Figure 1 we employ Principal Component Analysis (PCA) to perform linear data reduction in order to obtain a better representation of the readability feature vectors without losing much information. We use the Modular toolkit for Data Processing (MDP), a Python data processing framework (Zito et al., 2008). We observe that clusters tend to be formed based on the target language. rather than based on the source language. While for Romanian and Italian the original texts are to some extent isolated from their translations, for French, Spanish and Portuguese the original texts are more integrated within the groups of translations. The most compact cluster corresponds to Romanian as a target language. 5 Conclusions In this paper we investigate the behaviour of various readability metrics across parallel translations of texts from a source language to target languages. We focus on Romance languages </context>
</contexts>
<marker>Zito, Wilbert, Wiskott, Berkes, 2008</marker>
<rawString>Tiziano Zito, Niko Wilbert, Laurenz Wiskott, and Pietro Berkes. 2008. Modular toolkit for Data Processing (MDP): a Python data processing frame work. Front. Neuroinform., 2(8).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>