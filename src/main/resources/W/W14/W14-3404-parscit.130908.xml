<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.037782">
<title confidence="0.989348">
Automated Disease Normalization with Low Rank Approximations
</title>
<author confidence="0.997297">
Robert Leaman Zhiyong Lu
</author>
<affiliation confidence="0.9851815">
National Center for Biotechnology Information
National Library of Medicine
</affiliation>
<email confidence="0.991815">
{robert.leaman, zhiyong.lu}@nih.gov
</email>
<sectionHeader confidence="0.997323" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999950962962963">
While machine learning methods for
named entity recognition (mention-level
detection) have become common, ma-
chine learning methods have rarely been
applied to normalization (concept-level
identification). Recent research intro-
duced a machine learning method for
normalization based on pairwise learning
to rank. This method, DNorm, uses a lin-
ear model to score the similarity between
mentions and concept names, and has
several desirable properties, including
learning term variation directly from
training data. In this manuscript we em-
ploy a dimensionality reduction tech-
nique based on low-rank matrix approx-
imation, similar to latent semantic index-
ing. We compare the performance of the
low rank method to previous work, using
disease name normalization in the NCBI
Disease Corpus as the test case, and
demonstrate increased performance as
the matrix rank increases. We further
demonstrate a significant reduction in the
number of parameters to be learned and
discuss the implications of this result in
the context of algorithm scalability.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999910125">
The data necessary to answer a wide variety of
biomedical research questions is locked away in
narrative text. Automating the location (named
entity recognition) and identification (normaliza-
tion) of key biomedical entities (Doğan et al.,
2009; N6v6ol et al., 2011) such as diseases, pro-
teins and chemicals in narrative text may reduce
curation costs, enable significantly increased
scale and ultimately accelerate biomedical dis-
covery (Wei et al., 2012a).
Named entity recognition (NER) techniques
have typically focused on machine learning
methods such as conditional random fields
(CRFs), which have provided high performance
when coupled with a rich feature approach. The
utility of NER for biomedical end users is lim-
ited, however, since many applications require
each mention to be normalized, that is, identified
within a specified controlled vocabulary.
The normalization task has been highlighted in
the BioCreative challenges (Hirschman et al.,
2005; Lu et al., 2011; Morgan et al., 2008),
where a variety of methods have been explored
for normalizing gene names, including string
matching, pattern matching, and heuristic rules.
Similar methods have been applied to disease
names (Doğan &amp; Lu, 2012b; Kang et al., 2012;
N6v6ol et al., 2009) and species names (Gerner
et al., 2010; Wei et al., 2012b), and the MetaMap
program is used to locate and identify concepts
from the UMLS MetaThesaurus (Aronson, 2001;
Bodenreider, 2004).
Machine learning methods for NER have pro-
vided high performance, enhanced system adapt-
ability to new entity types, and abstracted many
details of specific rule patterns. While machine
learning methods for normalization have been
explored (Tsuruoka et al., 2007; Wermter et al.,
2009), these are far less common. This is partial-
ly due to the lack of appropriate training data,
and also partially due to the need for a general-
izable supporting framework.
Normalization is frequently decomposed into
the sub-tasks of candidate generation and disam-
biguation (Lu et al., 2011; Morgan et al., 2008).
During candidate generation, the set of concept
names is constrained to a set of possible matches
using the text of the mention. The primary diffi-
culty addressed in candidate generation is term
variation: the need to identify terms which are
semantically similar but textually distinct (e.g.
“nephropathy” and “kidney disease”). The dis-
ambiguation step then differentiates between the
different candidates to remove false positives,
typically using the context of the mention and the
article metadata.
</bodyText>
<page confidence="0.984591">
24
</page>
<bodyText confidence="0.980690953846154">
Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 24–28,
Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics
Recently, Leaman et al. (2013a) developed an
algorithm (DNorm) that directly addresses the
term variation problem with machine learning,
and used diseases – an important biomedical en-
tity – as the first case study. The algorithm learns
a similarity function between mentions and con-
cept names directly from training data using a
method based on pairwise learning to rank. The
method was shown to provide high performance
on the NCBI Disease Corpus (Doğan et al., 2014;
Doğan &amp; Lu, 2012a), and was also applied to
clinical notes in the ShARe / CLEF eHealth task
(Suominen et al., 2013), where it achieved the
highest normalization performance out of 17 in-
ternational teams (Leaman et al., 2013b). The
normalization step does not consider context, and
therefore must be combined with a disambigua-
tion method for tasks where disambiguation is
important. However, this method provides high
performance when paired with a conditional ran-
dom field system for NER, making the combina-
tion a step towards fully adaptable mention
recognition and normalization systems.
This manuscript adapts DNorm to use a di-
mensionality reduction technique based on low
rank matrix approximation. This may provide
several benefits. First, it may increase the scala-
bility of the method, since the number of pa-
rameters used by the original technique is pro-
portional to the square of the number of unique
tokens. Second, reducing the number of parame-
ters may, in turn, improve the stability of the
method and improve its generalization due to the
induction of a latent “concept space,” similar to
latent semantic indexing (Bai et al., 2010). Final-
ly, while the rich feature approach typically used
with conditional random fields allows it to par-
tially compensate for out-of-vocabulary effects,
DNorm ignores unknown tokens. This reduces
the ability of the model to generalize, due to the
zipfian distribution of text (Manning &amp; Schütze,
1999), and is especially problematic in text
which contains many misspellings, such as con-
sumer text. Using a richer feature space with
DNorm would not be feasible, however, unless
the parameter scalability problem is resolved.
In this article we expand the DNorm method
in a pilot study on feasibility of using low rank
approximation methods for disease name nor-
malization. To make this work comparable to the
previous work on DNorm, we again employed
the NCBI Disease Corpus (Doğan et al., 2014).
This corpus contains nearly 800 abstracts, split
into training, development, and test sets, as de-
scribed in Table 1. Each disease mention is anno-
tated for span and concept, using the MEDIC
vocabulary (Davis et al., 2012), which combines
MeSH® (Coletti &amp; Bleich, 2001) and OMIM®
(Amberger et al., 2011). The average number of
concepts for each name in the vocabulary is 5.72.
Disease names exhibit relatively low ambiguity,
with an average number of concepts per name of
1.01.
</bodyText>
<table confidence="0.99517">
Subset Abstracts Mentions Concepts
Training 593 5145 670
Development 100 787 176
Test 100 960 203
</table>
<tableCaption confidence="0.9839635">
Table 1. Descriptive statistics for the NCBI Disease
Corpus.
</tableCaption>
<sectionHeader confidence="0.994984" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.99460575">
DNorm uses the BANNER NER system
(Leaman &amp; Gonzalez, 2008) to locate disease
mentions, and then employs a ranking method to
normalize each mention found to the disease
concepts in the lexicon (Leaman et al., 2013a).
Briefly, we define to be the set of tokens from
both the disease mentions in the training data and
the concept names in the lexicon. We stem each
token in both disease mentions and concept
names (Porter, 1980), and then convert each to
TF-IDF vectors of dimensionality  ||, where the
document frequency for each token is taken to be
the number of names in the lexicon containing it
(Manning et al., 2008). All vectors are normal-
ized to unit length. We define a similarity score
between mention vector and name vector ,
( ), and each mention is normalized by
iterating through all concept names and returning
the disease concept corresponding to the one
with the highest score.
In previous work, ( ) T ,
where is a weight matrix and each entry
represents the correlation between token ap-
pearing in a mention and token appearing in a
concept name from the lexicon. In this work,
however, we set to be a low-rank approxima-
tion of the form T , where and
are both   ||matrices, being the rank
(number of linearly independent rows), and
  ||(Bai et al., 2010).
For efficiency, the low-rank scoring function
can be rewritten and evaluated as ( )
( ) T ( ) T , allowing the respective
and vectors to be calculated once and then
reused. This view provides an intuitive explana-
tion of the purpose of the and matrices: to
</bodyText>
<page confidence="0.99062">
25
</page>
<bodyText confidence="0.9998965">
convert the sparse, high-dimensional mention
and concept name vectors (m and n) into dense,
low dimensional vectors (as Um and Vn). Under
this interpretation, we found that performance
improved if each Um and Vn vector was renor-
malized to unit length.
This model retains many useful properties of
the original model, such as the ability to repre-
sent both positive and negative correlations be-
tween tokens, to represent both synonymy and
polysemy, and to allow the token distributions
between the mentions and the names to be differ-
ent. The new model also adds one important ad-
ditional property: the number of parameters is
linear in the number of unique tokens, potentially
enabling greater scalability.
</bodyText>
<subsectionHeader confidence="0.991369">
2.1 Model Training
</subsectionHeader>
<bodyText confidence="0.999916829268293">
Given any pair of disease names where one (n+)
is for c+ , the correct disease concept for
tion m, and the other, n-, is for c-, an incorrect
concept , we would like to update the weight ma-
trix W so that mTWn+ &gt; mTWn- . Following
Leaman et al. (2013a), we iterate through each
(m, c+, c-) tuple, selecting n+and n-as the name
for c+ and c-, respectively, with the highest sim-
ilarity score to m, using stochastic gradient de-
scent to make updates to W. With a dense weight
matrix W , the update rule is: if mTWn+ —
mTWn- &lt; 1, then W is updated as W +- W +
77(m(n+) T — m(n-) T), where 77 is the learning
rate, a parameter controlling the size of the
change to W. Under the low-rank approximation,
the update rules are: if mT Wn+ — mTWn- &lt; 1,
then U is updated as U+-U + 77V (n+ — n-) mT ,
and V is updated as V+-V + 77Um(n+ — n-) T ,
noting that the updates are applied simultaneous-
ly (Bai et al., 2010). Overfitting is avoided using
a holdout set, using the average of the ranks of
the correct concept as the performance measure-
ment, as in previous work.
We initialize U using values chosen randomly
from a normal distribution with mean 0 and
standard deviation 1. We found it useful to ini-
tialize V as UT, since this causes the representa-
tion for disease mentions and disease names to
initially be the same.
We employed an adaptive learning rate using
the schedule 77k = 770
r+k, where k is the itera-
tion, 770 is the initial learning rate, and i is the
discount (Finkel et al., 2008). We used an initial
learning rate of 770= 10-7. This is much lower
than reported by Leaman et al. (2013a), since we
found that higher values caused the training to
found that higher values caused the training to
diverge. We used a discount parameter of i = 5,
so that the learning rate is equal to one half the
initial rate after five iterations.
</bodyText>
<sectionHeader confidence="0.999955" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.999428333333333">
Our results were evaluated at the abstract level,
allowing comparison to the previous work on
DNorm (Leaman et al., 2013a). This evaluation
considers the set of disease concepts found in the
abstract, and ignores the exact location(s) where
each concept was found. A true positive consists
of the system returning a disease concept anno-
tated within the NCBI Disease Corpus, and the
number of false negatives and false positives are
defined similarly. We calculated the precision,
recall and F-measure as follows:
We list the micro-averaged results in Table 2.
</bodyText>
<table confidence="0.999779333333333">
Rank Precision Recall F-measure
50 0.648 0.671 0.659
100 0.673 0.685 0.679
250 0.697 0.697 0.697
500 0.702 0.700 0.701
(Full) 0.828 0.819 0.809
</table>
<tableCaption confidence="0.991504">
Table 2. Performance measurements for each
</tableCaption>
<bodyText confidence="0.954077666666667">
model on the NCBI Disease Test set. Full corre-
sponds with the full-rank matrix used in previous
work.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999978947368421">
There are two primary trends to note. First, the
performance of the low rank models is about
10%-15% lower than the full rank model. Sec-
ond, there is a clear trend towards higher preci-
sion and recall as the rank of the matrix increas-
es. This trend is reinforced in Figure 1, which
shows the learning curve for all models. These
describe the performance on the holdout set after
each iteration through the training data, and are
measured using the average rank of the correct
concept in the holdout set, which is dominated
by a small number of difficult cases.
Using the low rank approximation, the number
of parameters is equal to 2 x r x  |T|. Since r is
fixed and independent of  |T|, the number of pa-
rameters is now linear in the number of tokens,
effectively solving the parameter scalability
problem. Table 3 lists the number of parameters
for each of the models used in this study.
</bodyText>
<page confidence="0.997068">
26
</page>
<figureCaption confidence="0.993918">
Figure 1. Learning curves showing holdout per-
formance at each iteration through the training
data.
</figureCaption>
<table confidence="0.652780333333333">
Rank Parameters
50 1.8×106
100 3.7×106
250 9.1×106
500 1.8×107
(Full) 3.3×108
</table>
<tableCaption confidence="0.734970333333333">
Table 3. Number of model parameters for each
variant, showing the low rank methods using 1 to
2 orders of magnitude fewer parameters.
</tableCaption>
<bodyText confidence="0.999330166666666">
There are two trade-offs for this improvement
in scalability. First, there is a substantial perfor-
mance reduction, though this might be mitigated
somewhat in the future by using a richer feature
set – a possibility enabled by the use of the low
rank approximation. Second, training and infer-
ence times are significantly increased; training
the largest low-rank model ( r = 500) required
approximately 9 days, though the full-rank mod-
el trains in under an hour.
The view that the U and V matrices convert the
TF-IDF vectors to a lower dimensional space
suggests that the function of U and V is to pro-
vide word embeddings or word representations –
a vector space where each word vector encodes
its relationships with other words. This further
suggests that one way to provide higher perfor-
mance may be to take advantage of unsupervised
pre-training (Erhan et al., 2010). Instead of ini-
tializing U and V randomly, they could be initial-
ized using a set of word embeddings trained on a
large amount of biomedical text, such as with
neural network language models (Collobert &amp;
Weston, 2008; Mikolov et al., 2013).
</bodyText>
<sectionHeader confidence="0.993968" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999909764705882">
We performed a pilot study to determine whether
a low rank approximation may increase the
scalability of normalization using pairwise learn-
ing to rank. We showed that the reduction in the
number of parameters is substantial: it is now
linear to the number of tokens, rather than pro-
portional to the square of the number of tokens.
We further observed that the precision and recall
increase as the rank of the matrices is increased.
We believe that further performance increases
may be possible through the use of a richer fea-
ture set, unsupervised pre-training, or other di-
mensionality reduction techniques including fea-
ture selection or L1 regularization (Tibshirani,
1996). We also intend to apply the method to
additional entity types, using recently released
corpora such as CRAFT (Bada et al., 2012).
</bodyText>
<sectionHeader confidence="0.994348" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999459">
The authors would like to thank the anonymous
reviewers for their helpful suggestions. This re-
search was supported by the NIH Intramural Re-
search Program, National Library of Medicine.
</bodyText>
<sectionHeader confidence="0.992672" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992503739130435">
Amberger, J., Bocchini, C., &amp; Hamosh, A. (2011). A
new face and new challenges for Online
Mendelian Inheritance in Man (OMIM(R)). Hum
Mutat, 32(5), 564-567.
Aronson, A. R. (2001). Effective mapping of
biomedical text to the UMLS Metathesaurus: the
MetaMap program. In Proceedings of the AMIA
Symposium, 17-21.
Bada, M., Eckert, M., Evans, D., Garcia, K., Shipley,
K., Sitnikov, D., et al. (2012). Concept annotation
in the CRAFT corpus. BMC Bioinformatics, 13,
161.
Bai, B., Weston, J., Grangier, D., Collobert, R.,
Sadamasa, K., Qi, Y. J., et al. (2010). Learning to
rank with (a lot of) word features. Inform.
Retrieval, 13(3), 291-314.
Bodenreider, O. (2004). The Unified Medical
Language System (UMLS): integrating biomedical
terminology. Nucleic Acids Res, 32, D267-270.
Coletti, M. H., &amp; Bleich, H. L. (2001). Medical
subject headings used to search the biomedical
literature. J Am Med Inform Assoc, 8(4), 317-323.
Collobert, R., &amp; Weston, J. (2008). A unified
</reference>
<bodyText confidence="0.638363833333333">
architecture for natural language processing:
deep neural networks with multitask learning. In
Proceedings of the ICML, 160-167.
Davis, A. P., Wiegers, T. C., Rosenstein, M. C., &amp;
Mattingly, C. J. (2012). MEDIC: a practical
disease vocabulary used at the Comparative
</bodyText>
<figure confidence="0.999508294117647">
0 5 10
Average rank
100
90
80
40
70
60
50
30
20
50
100
250
500
Full
Iteration
</figure>
<page confidence="0.978909">
27
</page>
<reference confidence="0.997007909090909">
Toxicogenomics Database. Database, 2012,
bar065.
Doğan, R. I., Leaman, R., &amp; Lu, Z. (2014). NCBI
disease corpus: A resource for disease name
recognition and concept normalization. J Biomed
Inform, 47, 1-10.
Doğan, R. I., &amp; Lu, Z. (2012a). An improved corpus
of disease mentions in PubMed citations. In
Proceedings of the ACL 2012 Workshop on
BioNLP, 91-99.
Doğan, R. I., &amp; Lu, Z. (2012b). An Inference Method
for Disease Name Normalization. In Proceedings
of the AAAI 2012 Fall Symposium on Information
Retrieval and Knowledge Discovery in
Biomedical Text, 8-13.
Doğan, R. I., Murray, G. C., N6v6ol, A., &amp; Lu, Z.
(2009). Understanding PubMed user search
behavior through log analysis. Database (Oxford),
2009, bap018.
Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-
A., Vincent, P., &amp; Bengio, S. (2010). Why does
unsupervised pre-training help deep learning? J.
Machine Learning Res., 11, 625-660.
Finkel, J. R., Kleenman, A., &amp; Manning, C. D.
(2008). Efficient, Feature-based, Conditional
Random Field Parsing. In Proceedings of the 46th
Annual Meeting of the ACL, 959-967.
Gerner, M., Nenadic, G., &amp; Bergman, C. M. (2010).
LINNAEUS: a species name identification system
for biomedical literature. BMC Bioinformatics, 11,
85.
Hirschman, L., Colosimo, M., Morgan, A., &amp; Yeh, A.
(2005). Overview of BioCreAtIvE task 1B:
normalized gene lists. BMC Bioinformatics, 6
Suppl 1, S11.
Kang, N., Singh, B., Afzal, Z., van Mulligen, E. M.,
&amp; Kors, J. A. (2012). Using rule-based natural
language processing to improve disease
normalization in biomedical text. J. Am. Med.
Inform. Assoc., 20, 876-881.
Leaman, R., Doğan, R. I., &amp; Lu, Z. (2013a). DNorm:
Disease name normalization with pairwise
learning-to-rank. Bioinformatics, 29(22), 2909-
2917.
Leaman, R., &amp; Gonzalez, G. (2008). BANNER: an
executable survey of advances in biomedical
named entity recognition. Pac. Symp. Biocomput.,
652-663.
Leaman, R., Khare, R., &amp; Lu, Z. (2013b). NCBI at
2013 ShARe/CLEF eHealth Shared Task:
Disorder Normalization in Clinical Notes with
DNorm. In Working Notes of the Conference and
Labs of the Evaluation Forum Valencia, Spain.
Lu, Z., Kao, H. Y., Wei, C. H., Huang, M., Liu, J.,
Kuo, C. J., et al. (2011). The gene normalization
task in BioCreative III. BMC Bioinformatics, 12
Suppl 8, S2.
Manning, C., &amp; Schütze, H. (1999). Foundations of
Statistical Natural Language Processing:
Massachusetts Institute of Technology.
Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008).
Introduction to Information Retrieval: Cambridge
University Press.
Mikolov, T., Yih, W.-t., &amp; Zweig, G. (2013).
Linguistic Regularities in Continuous Space Word
Representations. In Proceedings of the 2013
Conference of the NAACL-HLT, 746-751.
Morgan, A. A., Lu, Z., Wang, X., Cohen, A. M.,
Fluck, J., Ruch, P., et al. (2008). Overview of
BioCreative II gene normalization. Genome Biol.,
9 Suppl 2, S3.
N6v6ol, A., Doğan, R. I., &amp; Lu, Z. (2011). Semi-
automatic semantic annotation of PubMed queries:
a study on quality, efficiency, satisfaction. J
Biomed Inform, 44(2), 310-318.
Névéol, A., Kim, W., Wilbur, W. J., &amp; Lu, Z. (2009).
Exploring two biomedical text genres for disease
recognition. In Proceedings of the ACL 2009
BioNLP Workshop, 144-152.
Porter, M. F. (1980). An algorithm for suffix
stripping. Program, 14, 130-137.
Suominen, H., Salanterä, S., Velupillai, S., Chapman,
W., Savova, G., Elhadad, N., et al. (2013).
Overview of the ShARe/CLEF eHealth Evaluation
Lab 2013. In P. Forner, H. Müller, R. Paredes, P.
Rosso &amp; B. Stein (Eds.), Information Access
Evaluation. Multilinguality, Multimodality, and
Visualization (Vol. 8138, pp. 212-231): Springer
Berlin Heidelberg.
Tibshirani, R. (1996). Regression shrinkage and
selection via the Lasso. Journal of the Royal
Statistical Society Series B-Methodological, 58(1),
267-288.
Tsuruoka, Y., McNaught, J., Tsujii, J., &amp; Ananiadou,
S. (2007). Learning string similarity measures for
gene/protein name dictionary look-up using
logistic regression. Bioinformatics, 23(20), 2768-
2774.
Wei, C. H., Harris, B. R., Li, D., Berardini, T. Z.,
Huala, E., Kao, H. Y., et al. (2012a). Accelerating
literature curation with text-mining tools: a case
study of using PubTator to curate genes in
PubMed abstracts. Database (Oxford), 2012,
bas041.
Wei, C. H., Kao, H. Y., &amp; Lu, Z. (2012b). SR4GN: a
species recognition software tool for gene
normalization. PLoS One, 7(6), e38460.
Wermter, J., Tomanek, K., &amp; Hahn, U. (2009). High-
performance gene name normalization with GeNo.
Bioinformatics, 25(6), 815-821.
</reference>
<page confidence="0.999071">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.914764">
<title confidence="0.999872">Automated Disease Normalization with Low Rank Approximations</title>
<author confidence="0.999842">Robert Leaman Zhiyong Lu</author>
<affiliation confidence="0.986844">National Center for Biotechnology National Library of Medicine</affiliation>
<email confidence="0.972432">robert.leaman@nih.gov</email>
<email confidence="0.972432">zhiyong.lu@nih.gov</email>
<abstract confidence="0.998626285714286">While machine learning methods for named entity recognition (mention-level detection) have become common, machine learning methods have rarely been applied to normalization (concept-level identification). Recent research introduced a machine learning method for normalization based on pairwise learning to rank. This method, DNorm, uses a linear model to score the similarity between mentions and concept names, and has several desirable properties, including learning term variation directly from training data. In this manuscript we employ a dimensionality reduction technique based on low-rank matrix approximation, similar to latent semantic indexing. We compare the performance of the low rank method to previous work, using disease name normalization in the NCBI Disease Corpus as the test case, and demonstrate increased performance as the matrix rank increases. We further demonstrate a significant reduction in the number of parameters to be learned and discuss the implications of this result in the context of algorithm scalability.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Amberger</author>
<author>C Bocchini</author>
<author>A Hamosh</author>
</authors>
<title>A new face and new challenges for Online Mendelian Inheritance in Man (OMIM(R)).</title>
<date>2011</date>
<journal>Hum Mutat,</journal>
<volume>32</volume>
<issue>5</issue>
<pages>564--567</pages>
<contexts>
<context position="6706" citStr="Amberger et al., 2011" startWordPosition="1029" endWordPosition="1032">ss the parameter scalability problem is resolved. In this article we expand the DNorm method in a pilot study on feasibility of using low rank approximation methods for disease name normalization. To make this work comparable to the previous work on DNorm, we again employed the NCBI Disease Corpus (Doğan et al., 2014). This corpus contains nearly 800 abstracts, split into training, development, and test sets, as described in Table 1. Each disease mention is annotated for span and concept, using the MEDIC vocabulary (Davis et al., 2012), which combines MeSH® (Coletti &amp; Bleich, 2001) and OMIM® (Amberger et al., 2011). The average number of concepts for each name in the vocabulary is 5.72. Disease names exhibit relatively low ambiguity, with an average number of concepts per name of 1.01. Subset Abstracts Mentions Concepts Training 593 5145 670 Development 100 787 176 Test 100 960 203 Table 1. Descriptive statistics for the NCBI Disease Corpus. 2 Methods DNorm uses the BANNER NER system (Leaman &amp; Gonzalez, 2008) to locate disease mentions, and then employs a ranking method to normalize each mention found to the disease concepts in the lexicon (Leaman et al., 2013a). Briefly, we define to be the set of toke</context>
</contexts>
<marker>Amberger, Bocchini, Hamosh, 2011</marker>
<rawString>Amberger, J., Bocchini, C., &amp; Hamosh, A. (2011). A new face and new challenges for Online Mendelian Inheritance in Man (OMIM(R)). Hum Mutat, 32(5), 564-567.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Aronson</author>
</authors>
<title>Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program.</title>
<date>2001</date>
<booktitle>In Proceedings of the AMIA Symposium,</booktitle>
<pages>17--21</pages>
<contexts>
<context position="2682" citStr="Aronson, 2001" startWordPosition="395" endWordPosition="396"> is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule patterns. While machine learning methods for normalization have been explored (Tsuruoka et al., 2007; Wermter et al., 2009), these are far less common. This is partially due to the lack of appropriate training data, and also partially due to the need for a generalizable supporting framework. Normalization is frequently decomposed into the sub-tasks of candidate generation and disambiguation (Lu et al., 2011; Morgan</context>
</contexts>
<marker>Aronson, 2001</marker>
<rawString>Aronson, A. R. (2001). Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. In Proceedings of the AMIA Symposium, 17-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bada</author>
<author>M Eckert</author>
<author>D Evans</author>
<author>K Garcia</author>
<author>K Shipley</author>
<author>D Sitnikov</author>
</authors>
<title>Concept annotation in the CRAFT corpus.</title>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<volume>13</volume>
<pages>161</pages>
<marker>Bada, Eckert, Evans, Garcia, Shipley, Sitnikov, 2012</marker>
<rawString>Bada, M., Eckert, M., Evans, D., Garcia, K., Shipley, K., Sitnikov, D., et al. (2012). Concept annotation in the CRAFT corpus. BMC Bioinformatics, 13, 161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bai</author>
<author>J Weston</author>
<author>D Grangier</author>
<author>R Collobert</author>
<author>K Sadamasa</author>
<author>Y J Qi</author>
</authors>
<title>Learning to rank with (a lot of) word features.</title>
<date>2010</date>
<journal>Inform. Retrieval,</journal>
<volume>13</volume>
<issue>3</issue>
<pages>291--314</pages>
<contexts>
<context position="5609" citStr="Bai et al., 2010" startWordPosition="852" endWordPosition="855"> fully adaptable mention recognition and normalization systems. This manuscript adapts DNorm to use a dimensionality reduction technique based on low rank matrix approximation. This may provide several benefits. First, it may increase the scalability of the method, since the number of parameters used by the original technique is proportional to the square of the number of unique tokens. Second, reducing the number of parameters may, in turn, improve the stability of the method and improve its generalization due to the induction of a latent “concept space,” similar to latent semantic indexing (Bai et al., 2010). Finally, while the rich feature approach typically used with conditional random fields allows it to partially compensate for out-of-vocabulary effects, DNorm ignores unknown tokens. This reduces the ability of the model to generalize, due to the zipfian distribution of text (Manning &amp; Schütze, 1999), and is especially problematic in text which contains many misspellings, such as consumer text. Using a richer feature space with DNorm would not be feasible, however, unless the parameter scalability problem is resolved. In this article we expand the DNorm method in a pilot study on feasibility </context>
<context position="8314" citStr="Bai et al., 2010" startWordPosition="1309" endWordPosition="1312"> to unit length. We define a similarity score between mention vector and name vector , ( ), and each mention is normalized by iterating through all concept names and returning the disease concept corresponding to the one with the highest score. In previous work, ( ) T , where is a weight matrix and each entry represents the correlation between token appearing in a mention and token appearing in a concept name from the lexicon. In this work, however, we set to be a low-rank approximation of the form T , where and are both ||matrices, being the rank (number of linearly independent rows), and ||(Bai et al., 2010). For efficiency, the low-rank scoring function can be rewritten and evaluated as ( ) ( ) T ( ) T , allowing the respective and vectors to be calculated once and then reused. This view provides an intuitive explanation of the purpose of the and matrices: to 25 convert the sparse, high-dimensional mention and concept name vectors (m and n) into dense, low dimensional vectors (as Um and Vn). Under this interpretation, we found that performance improved if each Um and Vn vector was renormalized to unit length. This model retains many useful properties of the original model, such as the ability to</context>
<context position="10199" citStr="Bai et al., 2010" startWordPosition="1662" endWordPosition="1665"> c-) tuple, selecting n+and n-as the name for c+ and c-, respectively, with the highest similarity score to m, using stochastic gradient descent to make updates to W. With a dense weight matrix W , the update rule is: if mTWn+ — mTWn- &lt; 1, then W is updated as W +- W + 77(m(n+) T — m(n-) T), where 77 is the learning rate, a parameter controlling the size of the change to W. Under the low-rank approximation, the update rules are: if mT Wn+ — mTWn- &lt; 1, then U is updated as U+-U + 77V (n+ — n-) mT , and V is updated as V+-V + 77Um(n+ — n-) T , noting that the updates are applied simultaneously (Bai et al., 2010). Overfitting is avoided using a holdout set, using the average of the ranks of the correct concept as the performance measurement, as in previous work. We initialize U using values chosen randomly from a normal distribution with mean 0 and standard deviation 1. We found it useful to initialize V as UT, since this causes the representation for disease mentions and disease names to initially be the same. We employed an adaptive learning rate using the schedule 77k = 770 r+k, where k is the iteration, 770 is the initial learning rate, and i is the discount (Finkel et al., 2008). We used an initi</context>
</contexts>
<marker>Bai, Weston, Grangier, Collobert, Sadamasa, Qi, 2010</marker>
<rawString>Bai, B., Weston, J., Grangier, D., Collobert, R., Sadamasa, K., Qi, Y. J., et al. (2010). Learning to rank with (a lot of) word features. Inform. Retrieval, 13(3), 291-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bodenreider</author>
</authors>
<title>The Unified Medical Language System (UMLS): integrating biomedical terminology.</title>
<date>2004</date>
<journal>Nucleic Acids Res,</journal>
<volume>32</volume>
<pages>267--270</pages>
<contexts>
<context position="2702" citStr="Bodenreider, 2004" startWordPosition="397" endWordPosition="398"> within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule patterns. While machine learning methods for normalization have been explored (Tsuruoka et al., 2007; Wermter et al., 2009), these are far less common. This is partially due to the lack of appropriate training data, and also partially due to the need for a generalizable supporting framework. Normalization is frequently decomposed into the sub-tasks of candidate generation and disambiguation (Lu et al., 2011; Morgan et al., 2008). Duri</context>
</contexts>
<marker>Bodenreider, 2004</marker>
<rawString>Bodenreider, O. (2004). The Unified Medical Language System (UMLS): integrating biomedical terminology. Nucleic Acids Res, 32, D267-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H Coletti</author>
<author>H L Bleich</author>
</authors>
<title>Medical subject headings used to search the biomedical literature.</title>
<date>2001</date>
<journal>J Am Med Inform Assoc,</journal>
<volume>8</volume>
<issue>4</issue>
<pages>317--323</pages>
<contexts>
<context position="6672" citStr="Coletti &amp; Bleich, 2001" startWordPosition="1023" endWordPosition="1026">ould not be feasible, however, unless the parameter scalability problem is resolved. In this article we expand the DNorm method in a pilot study on feasibility of using low rank approximation methods for disease name normalization. To make this work comparable to the previous work on DNorm, we again employed the NCBI Disease Corpus (Doğan et al., 2014). This corpus contains nearly 800 abstracts, split into training, development, and test sets, as described in Table 1. Each disease mention is annotated for span and concept, using the MEDIC vocabulary (Davis et al., 2012), which combines MeSH® (Coletti &amp; Bleich, 2001) and OMIM® (Amberger et al., 2011). The average number of concepts for each name in the vocabulary is 5.72. Disease names exhibit relatively low ambiguity, with an average number of concepts per name of 1.01. Subset Abstracts Mentions Concepts Training 593 5145 670 Development 100 787 176 Test 100 960 203 Table 1. Descriptive statistics for the NCBI Disease Corpus. 2 Methods DNorm uses the BANNER NER system (Leaman &amp; Gonzalez, 2008) to locate disease mentions, and then employs a ranking method to normalize each mention found to the disease concepts in the lexicon (Leaman et al., 2013a). Briefl</context>
</contexts>
<marker>Coletti, Bleich, 2001</marker>
<rawString>Coletti, M. H., &amp; Bleich, H. L. (2001). Medical subject headings used to search the biomedical literature. J Am Med Inform Assoc, 8(4), 317-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
<author>J Weston</author>
</authors>
<title>A unified Toxicogenomics Database. Database,</title>
<date>2008</date>
<pages>065</pages>
<contexts>
<context position="14284" citStr="Collobert &amp; Weston, 2008" startWordPosition="2368" endWordPosition="2371">. The view that the U and V matrices convert the TF-IDF vectors to a lower dimensional space suggests that the function of U and V is to provide word embeddings or word representations – a vector space where each word vector encodes its relationships with other words. This further suggests that one way to provide higher performance may be to take advantage of unsupervised pre-training (Erhan et al., 2010). Instead of initializing U and V randomly, they could be initialized using a set of word embeddings trained on a large amount of biomedical text, such as with neural network language models (Collobert &amp; Weston, 2008; Mikolov et al., 2013). 5 Conclusion We performed a pilot study to determine whether a low rank approximation may increase the scalability of normalization using pairwise learning to rank. We showed that the reduction in the number of parameters is substantial: it is now linear to the number of tokens, rather than proportional to the square of the number of tokens. We further observed that the precision and recall increase as the rank of the matrices is increased. We believe that further performance increases may be possible through the use of a richer feature set, unsupervised pre-training, </context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Collobert, R., &amp; Weston, J. (2008). A unified Toxicogenomics Database. Database, 2012, bar065.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R I Doğan</author>
<author>R Leaman</author>
<author>Z Lu</author>
</authors>
<title>NCBI disease corpus: A resource for disease name recognition and concept normalization.</title>
<date>2014</date>
<journal>J Biomed Inform,</journal>
<volume>47</volume>
<pages>1--10</pages>
<contexts>
<context position="4464" citStr="Doğan et al., 2014" startWordPosition="666" endWordPosition="669">cal Natural Language Processing (BioNLP 2014), pages 24–28, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics Recently, Leaman et al. (2013a) developed an algorithm (DNorm) that directly addresses the term variation problem with machine learning, and used diseases – an important biomedical entity – as the first case study. The algorithm learns a similarity function between mentions and concept names directly from training data using a method based on pairwise learning to rank. The method was shown to provide high performance on the NCBI Disease Corpus (Doğan et al., 2014; Doğan &amp; Lu, 2012a), and was also applied to clinical notes in the ShARe / CLEF eHealth task (Suominen et al., 2013), where it achieved the highest normalization performance out of 17 international teams (Leaman et al., 2013b). The normalization step does not consider context, and therefore must be combined with a disambiguation method for tasks where disambiguation is important. However, this method provides high performance when paired with a conditional random field system for NER, making the combination a step towards fully adaptable mention recognition and normalization systems. This man</context>
<context position="6403" citStr="Doğan et al., 2014" startWordPosition="979" endWordPosition="982"> tokens. This reduces the ability of the model to generalize, due to the zipfian distribution of text (Manning &amp; Schütze, 1999), and is especially problematic in text which contains many misspellings, such as consumer text. Using a richer feature space with DNorm would not be feasible, however, unless the parameter scalability problem is resolved. In this article we expand the DNorm method in a pilot study on feasibility of using low rank approximation methods for disease name normalization. To make this work comparable to the previous work on DNorm, we again employed the NCBI Disease Corpus (Doğan et al., 2014). This corpus contains nearly 800 abstracts, split into training, development, and test sets, as described in Table 1. Each disease mention is annotated for span and concept, using the MEDIC vocabulary (Davis et al., 2012), which combines MeSH® (Coletti &amp; Bleich, 2001) and OMIM® (Amberger et al., 2011). The average number of concepts for each name in the vocabulary is 5.72. Disease names exhibit relatively low ambiguity, with an average number of concepts per name of 1.01. Subset Abstracts Mentions Concepts Training 593 5145 670 Development 100 787 176 Test 100 960 203 Table 1. Descriptive sta</context>
</contexts>
<marker>Doğan, Leaman, Lu, 2014</marker>
<rawString>Doğan, R. I., Leaman, R., &amp; Lu, Z. (2014). NCBI disease corpus: A resource for disease name recognition and concept normalization. J Biomed Inform, 47, 1-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R I Doğan</author>
<author>Z Lu</author>
</authors>
<title>An improved corpus of disease mentions in PubMed citations.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 Workshop on BioNLP,</booktitle>
<pages>91--99</pages>
<contexts>
<context position="2473" citStr="Doğan &amp; Lu, 2012" startWordPosition="357" endWordPosition="360">which have provided high performance when coupled with a rich feature approach. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule patterns. While machine learning methods for normalization have been explored (Tsuruoka et al., 2007; Wermter et al., 2009), these are far less common. This is partially due to the lack of appropriate training</context>
<context position="4482" citStr="Doğan &amp; Lu, 2012" startWordPosition="670" endWordPosition="673"> Processing (BioNLP 2014), pages 24–28, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics Recently, Leaman et al. (2013a) developed an algorithm (DNorm) that directly addresses the term variation problem with machine learning, and used diseases – an important biomedical entity – as the first case study. The algorithm learns a similarity function between mentions and concept names directly from training data using a method based on pairwise learning to rank. The method was shown to provide high performance on the NCBI Disease Corpus (Doğan et al., 2014; Doğan &amp; Lu, 2012a), and was also applied to clinical notes in the ShARe / CLEF eHealth task (Suominen et al., 2013), where it achieved the highest normalization performance out of 17 international teams (Leaman et al., 2013b). The normalization step does not consider context, and therefore must be combined with a disambiguation method for tasks where disambiguation is important. However, this method provides high performance when paired with a conditional random field system for NER, making the combination a step towards fully adaptable mention recognition and normalization systems. This manuscript adapts DNo</context>
</contexts>
<marker>Doğan, Lu, 2012</marker>
<rawString>Doğan, R. I., &amp; Lu, Z. (2012a). An improved corpus of disease mentions in PubMed citations. In Proceedings of the ACL 2012 Workshop on BioNLP, 91-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R I Doğan</author>
<author>Z Lu</author>
</authors>
<title>An Inference Method for Disease Name Normalization.</title>
<date>2012</date>
<booktitle>In Proceedings of the AAAI 2012 Fall Symposium on Information Retrieval and Knowledge Discovery in Biomedical Text,</booktitle>
<pages>8--13</pages>
<contexts>
<context position="2473" citStr="Doğan &amp; Lu, 2012" startWordPosition="357" endWordPosition="360">which have provided high performance when coupled with a rich feature approach. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule patterns. While machine learning methods for normalization have been explored (Tsuruoka et al., 2007; Wermter et al., 2009), these are far less common. This is partially due to the lack of appropriate training</context>
<context position="4482" citStr="Doğan &amp; Lu, 2012" startWordPosition="670" endWordPosition="673"> Processing (BioNLP 2014), pages 24–28, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics Recently, Leaman et al. (2013a) developed an algorithm (DNorm) that directly addresses the term variation problem with machine learning, and used diseases – an important biomedical entity – as the first case study. The algorithm learns a similarity function between mentions and concept names directly from training data using a method based on pairwise learning to rank. The method was shown to provide high performance on the NCBI Disease Corpus (Doğan et al., 2014; Doğan &amp; Lu, 2012a), and was also applied to clinical notes in the ShARe / CLEF eHealth task (Suominen et al., 2013), where it achieved the highest normalization performance out of 17 international teams (Leaman et al., 2013b). The normalization step does not consider context, and therefore must be combined with a disambiguation method for tasks where disambiguation is important. However, this method provides high performance when paired with a conditional random field system for NER, making the combination a step towards fully adaptable mention recognition and normalization systems. This manuscript adapts DNo</context>
</contexts>
<marker>Doğan, Lu, 2012</marker>
<rawString>Doğan, R. I., &amp; Lu, Z. (2012b). An Inference Method for Disease Name Normalization. In Proceedings of the AAAI 2012 Fall Symposium on Information Retrieval and Knowledge Discovery in Biomedical Text, 8-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R I Doğan</author>
<author>G C Murray</author>
<author>A N6v6ol</author>
<author>Z Lu</author>
</authors>
<title>Understanding PubMed user search behavior through log analysis. Database</title>
<date>2009</date>
<pages>018</pages>
<location>(Oxford),</location>
<marker>Doğan, Murray, N6v6ol, Lu, 2009</marker>
<rawString>Doğan, R. I., Murray, G. C., N6v6ol, A., &amp; Lu, Z. (2009). Understanding PubMed user search behavior through log analysis. Database (Oxford), 2009, bap018.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Erhan</author>
<author>Y Bengio</author>
<author>A Courville</author>
<author>P-A Manzagol</author>
<author>P Vincent</author>
<author>S Bengio</author>
</authors>
<title>Why does unsupervised pre-training help deep learning?</title>
<date>2010</date>
<journal>J. Machine Learning Res.,</journal>
<volume>11</volume>
<pages>625--660</pages>
<contexts>
<context position="14068" citStr="Erhan et al., 2010" startWordPosition="2330" endWordPosition="2333">k approximation. Second, training and inference times are significantly increased; training the largest low-rank model ( r = 500) required approximately 9 days, though the full-rank model trains in under an hour. The view that the U and V matrices convert the TF-IDF vectors to a lower dimensional space suggests that the function of U and V is to provide word embeddings or word representations – a vector space where each word vector encodes its relationships with other words. This further suggests that one way to provide higher performance may be to take advantage of unsupervised pre-training (Erhan et al., 2010). Instead of initializing U and V randomly, they could be initialized using a set of word embeddings trained on a large amount of biomedical text, such as with neural network language models (Collobert &amp; Weston, 2008; Mikolov et al., 2013). 5 Conclusion We performed a pilot study to determine whether a low rank approximation may increase the scalability of normalization using pairwise learning to rank. We showed that the reduction in the number of parameters is substantial: it is now linear to the number of tokens, rather than proportional to the square of the number of tokens. We further obse</context>
</contexts>
<marker>Erhan, Bengio, Courville, Manzagol, Vincent, Bengio, 2010</marker>
<rawString>Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., &amp; Bengio, S. (2010). Why does unsupervised pre-training help deep learning? J. Machine Learning Res., 11, 625-660.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>A Kleenman</author>
<author>C D Manning</author>
</authors>
<title>Efficient, Feature-based, Conditional Random Field Parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the ACL,</booktitle>
<pages>959--967</pages>
<contexts>
<context position="10781" citStr="Finkel et al., 2008" startWordPosition="1767" endWordPosition="1770">lied simultaneously (Bai et al., 2010). Overfitting is avoided using a holdout set, using the average of the ranks of the correct concept as the performance measurement, as in previous work. We initialize U using values chosen randomly from a normal distribution with mean 0 and standard deviation 1. We found it useful to initialize V as UT, since this causes the representation for disease mentions and disease names to initially be the same. We employed an adaptive learning rate using the schedule 77k = 770 r+k, where k is the iteration, 770 is the initial learning rate, and i is the discount (Finkel et al., 2008). We used an initial learning rate of 770= 10-7. This is much lower than reported by Leaman et al. (2013a), since we found that higher values caused the training to found that higher values caused the training to diverge. We used a discount parameter of i = 5, so that the learning rate is equal to one half the initial rate after five iterations. 3 Results Our results were evaluated at the abstract level, allowing comparison to the previous work on DNorm (Leaman et al., 2013a). This evaluation considers the set of disease concepts found in the abstract, and ignores the exact location(s) where e</context>
</contexts>
<marker>Finkel, Kleenman, Manning, 2008</marker>
<rawString>Finkel, J. R., Kleenman, A., &amp; Manning, C. D. (2008). Efficient, Feature-based, Conditional Random Field Parsing. In Proceedings of the 46th Annual Meeting of the ACL, 959-967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gerner</author>
<author>G Nenadic</author>
<author>C M Bergman</author>
</authors>
<title>LINNAEUS: a species name identification system for biomedical literature.</title>
<date>2010</date>
<journal>BMC Bioinformatics,</journal>
<volume>11</volume>
<pages>85</pages>
<contexts>
<context position="2554" citStr="Gerner et al., 2010" startWordPosition="372" endWordPosition="375">. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule patterns. While machine learning methods for normalization have been explored (Tsuruoka et al., 2007; Wermter et al., 2009), these are far less common. This is partially due to the lack of appropriate training data, and also partially due to the need for a generalizable supporting framewor</context>
</contexts>
<marker>Gerner, Nenadic, Bergman, 2010</marker>
<rawString>Gerner, M., Nenadic, G., &amp; Bergman, C. M. (2010). LINNAEUS: a species name identification system for biomedical literature. BMC Bioinformatics, 11, 85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hirschman</author>
<author>M Colosimo</author>
<author>A Morgan</author>
<author>A Yeh</author>
</authors>
<title>Overview of BioCreAtIvE task 1B: normalized gene lists.</title>
<date>2005</date>
<journal>BMC Bioinformatics,</journal>
<volume>6</volume>
<pages>11</pages>
<contexts>
<context position="2224" citStr="Hirschman et al., 2005" startWordPosition="317" endWordPosition="320">uration costs, enable significantly increased scale and ultimately accelerate biomedical discovery (Wei et al., 2012a). Named entity recognition (NER) techniques have typically focused on machine learning methods such as conditional random fields (CRFs), which have provided high performance when coupled with a rich feature approach. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and a</context>
</contexts>
<marker>Hirschman, Colosimo, Morgan, Yeh, 2005</marker>
<rawString>Hirschman, L., Colosimo, M., Morgan, A., &amp; Yeh, A. (2005). Overview of BioCreAtIvE task 1B: normalized gene lists. BMC Bioinformatics, 6 Suppl 1, S11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kang</author>
<author>B Singh</author>
<author>Z Afzal</author>
<author>E M van Mulligen</author>
<author>J A Kors</author>
</authors>
<title>Using rule-based natural language processing to improve disease normalization in biomedical text.</title>
<date>2012</date>
<journal>J. Am. Med. Inform. Assoc.,</journal>
<volume>20</volume>
<pages>876--881</pages>
<marker>Kang, Singh, Afzal, van Mulligen, Kors, 2012</marker>
<rawString>Kang, N., Singh, B., Afzal, Z., van Mulligen, E. M., &amp; Kors, J. A. (2012). Using rule-based natural language processing to improve disease normalization in biomedical text. J. Am. Med. Inform. Assoc., 20, 876-881.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leaman</author>
<author>R I Doğan</author>
<author>Z Lu</author>
</authors>
<title>DNorm: Disease name normalization with pairwise learning-to-rank.</title>
<date>2013</date>
<journal>Bioinformatics,</journal>
<volume>29</volume>
<issue>22</issue>
<pages>2909--2917</pages>
<contexts>
<context position="4026" citStr="Leaman et al. (2013" startWordPosition="595" endWordPosition="598">ext of the mention. The primary difficulty addressed in candidate generation is term variation: the need to identify terms which are semantically similar but textually distinct (e.g. “nephropathy” and “kidney disease”). The disambiguation step then differentiates between the different candidates to remove false positives, typically using the context of the mention and the article metadata. 24 Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 24–28, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics Recently, Leaman et al. (2013a) developed an algorithm (DNorm) that directly addresses the term variation problem with machine learning, and used diseases – an important biomedical entity – as the first case study. The algorithm learns a similarity function between mentions and concept names directly from training data using a method based on pairwise learning to rank. The method was shown to provide high performance on the NCBI Disease Corpus (Doğan et al., 2014; Doğan &amp; Lu, 2012a), and was also applied to clinical notes in the ShARe / CLEF eHealth task (Suominen et al., 2013), where it achieved the highest normalization</context>
<context position="7262" citStr="Leaman et al., 2013" startWordPosition="1121" endWordPosition="1124">eSH® (Coletti &amp; Bleich, 2001) and OMIM® (Amberger et al., 2011). The average number of concepts for each name in the vocabulary is 5.72. Disease names exhibit relatively low ambiguity, with an average number of concepts per name of 1.01. Subset Abstracts Mentions Concepts Training 593 5145 670 Development 100 787 176 Test 100 960 203 Table 1. Descriptive statistics for the NCBI Disease Corpus. 2 Methods DNorm uses the BANNER NER system (Leaman &amp; Gonzalez, 2008) to locate disease mentions, and then employs a ranking method to normalize each mention found to the disease concepts in the lexicon (Leaman et al., 2013a). Briefly, we define to be the set of tokens from both the disease mentions in the training data and the concept names in the lexicon. We stem each token in both disease mentions and concept names (Porter, 1980), and then convert each to TF-IDF vectors of dimensionality ||, where the document frequency for each token is taken to be the number of names in the lexicon containing it (Manning et al., 2008). All vectors are normalized to unit length. We define a similarity score between mention vector and name vector , ( ), and each mention is normalized by iterating through all concept names and</context>
<context position="9547" citStr="Leaman et al. (2013" startWordPosition="1527" endWordPosition="1530">h positive and negative correlations between tokens, to represent both synonymy and polysemy, and to allow the token distributions between the mentions and the names to be different. The new model also adds one important additional property: the number of parameters is linear in the number of unique tokens, potentially enabling greater scalability. 2.1 Model Training Given any pair of disease names where one (n+) is for c+ , the correct disease concept for tion m, and the other, n-, is for c-, an incorrect concept , we would like to update the weight matrix W so that mTWn+ &gt; mTWn- . Following Leaman et al. (2013a), we iterate through each (m, c+, c-) tuple, selecting n+and n-as the name for c+ and c-, respectively, with the highest similarity score to m, using stochastic gradient descent to make updates to W. With a dense weight matrix W , the update rule is: if mTWn+ — mTWn- &lt; 1, then W is updated as W +- W + 77(m(n+) T — m(n-) T), where 77 is the learning rate, a parameter controlling the size of the change to W. Under the low-rank approximation, the update rules are: if mT Wn+ — mTWn- &lt; 1, then U is updated as U+-U + 77V (n+ — n-) mT , and V is updated as V+-V + 77Um(n+ — n-) T , noting that the u</context>
<context position="10885" citStr="Leaman et al. (2013" startWordPosition="1787" endWordPosition="1790">the ranks of the correct concept as the performance measurement, as in previous work. We initialize U using values chosen randomly from a normal distribution with mean 0 and standard deviation 1. We found it useful to initialize V as UT, since this causes the representation for disease mentions and disease names to initially be the same. We employed an adaptive learning rate using the schedule 77k = 770 r+k, where k is the iteration, 770 is the initial learning rate, and i is the discount (Finkel et al., 2008). We used an initial learning rate of 770= 10-7. This is much lower than reported by Leaman et al. (2013a), since we found that higher values caused the training to found that higher values caused the training to diverge. We used a discount parameter of i = 5, so that the learning rate is equal to one half the initial rate after five iterations. 3 Results Our results were evaluated at the abstract level, allowing comparison to the previous work on DNorm (Leaman et al., 2013a). This evaluation considers the set of disease concepts found in the abstract, and ignores the exact location(s) where each concept was found. A true positive consists of the system returning a disease concept annotated with</context>
</contexts>
<marker>Leaman, Doğan, Lu, 2013</marker>
<rawString>Leaman, R., Doğan, R. I., &amp; Lu, Z. (2013a). DNorm: Disease name normalization with pairwise learning-to-rank. Bioinformatics, 29(22), 2909-2917.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leaman</author>
<author>G Gonzalez</author>
</authors>
<title>BANNER: an executable survey of advances in biomedical named entity recognition.</title>
<date>2008</date>
<journal>Pac. Symp. Biocomput.,</journal>
<pages>652--663</pages>
<contexts>
<context position="7108" citStr="Leaman &amp; Gonzalez, 2008" startWordPosition="1095" endWordPosition="1098">d test sets, as described in Table 1. Each disease mention is annotated for span and concept, using the MEDIC vocabulary (Davis et al., 2012), which combines MeSH® (Coletti &amp; Bleich, 2001) and OMIM® (Amberger et al., 2011). The average number of concepts for each name in the vocabulary is 5.72. Disease names exhibit relatively low ambiguity, with an average number of concepts per name of 1.01. Subset Abstracts Mentions Concepts Training 593 5145 670 Development 100 787 176 Test 100 960 203 Table 1. Descriptive statistics for the NCBI Disease Corpus. 2 Methods DNorm uses the BANNER NER system (Leaman &amp; Gonzalez, 2008) to locate disease mentions, and then employs a ranking method to normalize each mention found to the disease concepts in the lexicon (Leaman et al., 2013a). Briefly, we define to be the set of tokens from both the disease mentions in the training data and the concept names in the lexicon. We stem each token in both disease mentions and concept names (Porter, 1980), and then convert each to TF-IDF vectors of dimensionality ||, where the document frequency for each token is taken to be the number of names in the lexicon containing it (Manning et al., 2008). All vectors are normalized to unit le</context>
</contexts>
<marker>Leaman, Gonzalez, 2008</marker>
<rawString>Leaman, R., &amp; Gonzalez, G. (2008). BANNER: an executable survey of advances in biomedical named entity recognition. Pac. Symp. Biocomput., 652-663.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leaman</author>
<author>R Khare</author>
<author>Z Lu</author>
</authors>
<title>NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder Normalization in Clinical Notes with DNorm.</title>
<date>2013</date>
<booktitle>In Working Notes of the Conference and Labs of the Evaluation Forum</booktitle>
<location>Valencia,</location>
<contexts>
<context position="4026" citStr="Leaman et al. (2013" startWordPosition="595" endWordPosition="598">ext of the mention. The primary difficulty addressed in candidate generation is term variation: the need to identify terms which are semantically similar but textually distinct (e.g. “nephropathy” and “kidney disease”). The disambiguation step then differentiates between the different candidates to remove false positives, typically using the context of the mention and the article metadata. 24 Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 24–28, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics Recently, Leaman et al. (2013a) developed an algorithm (DNorm) that directly addresses the term variation problem with machine learning, and used diseases – an important biomedical entity – as the first case study. The algorithm learns a similarity function between mentions and concept names directly from training data using a method based on pairwise learning to rank. The method was shown to provide high performance on the NCBI Disease Corpus (Doğan et al., 2014; Doğan &amp; Lu, 2012a), and was also applied to clinical notes in the ShARe / CLEF eHealth task (Suominen et al., 2013), where it achieved the highest normalization</context>
<context position="7262" citStr="Leaman et al., 2013" startWordPosition="1121" endWordPosition="1124">eSH® (Coletti &amp; Bleich, 2001) and OMIM® (Amberger et al., 2011). The average number of concepts for each name in the vocabulary is 5.72. Disease names exhibit relatively low ambiguity, with an average number of concepts per name of 1.01. Subset Abstracts Mentions Concepts Training 593 5145 670 Development 100 787 176 Test 100 960 203 Table 1. Descriptive statistics for the NCBI Disease Corpus. 2 Methods DNorm uses the BANNER NER system (Leaman &amp; Gonzalez, 2008) to locate disease mentions, and then employs a ranking method to normalize each mention found to the disease concepts in the lexicon (Leaman et al., 2013a). Briefly, we define to be the set of tokens from both the disease mentions in the training data and the concept names in the lexicon. We stem each token in both disease mentions and concept names (Porter, 1980), and then convert each to TF-IDF vectors of dimensionality ||, where the document frequency for each token is taken to be the number of names in the lexicon containing it (Manning et al., 2008). All vectors are normalized to unit length. We define a similarity score between mention vector and name vector , ( ), and each mention is normalized by iterating through all concept names and</context>
<context position="9547" citStr="Leaman et al. (2013" startWordPosition="1527" endWordPosition="1530">h positive and negative correlations between tokens, to represent both synonymy and polysemy, and to allow the token distributions between the mentions and the names to be different. The new model also adds one important additional property: the number of parameters is linear in the number of unique tokens, potentially enabling greater scalability. 2.1 Model Training Given any pair of disease names where one (n+) is for c+ , the correct disease concept for tion m, and the other, n-, is for c-, an incorrect concept , we would like to update the weight matrix W so that mTWn+ &gt; mTWn- . Following Leaman et al. (2013a), we iterate through each (m, c+, c-) tuple, selecting n+and n-as the name for c+ and c-, respectively, with the highest similarity score to m, using stochastic gradient descent to make updates to W. With a dense weight matrix W , the update rule is: if mTWn+ — mTWn- &lt; 1, then W is updated as W +- W + 77(m(n+) T — m(n-) T), where 77 is the learning rate, a parameter controlling the size of the change to W. Under the low-rank approximation, the update rules are: if mT Wn+ — mTWn- &lt; 1, then U is updated as U+-U + 77V (n+ — n-) mT , and V is updated as V+-V + 77Um(n+ — n-) T , noting that the u</context>
<context position="10885" citStr="Leaman et al. (2013" startWordPosition="1787" endWordPosition="1790">the ranks of the correct concept as the performance measurement, as in previous work. We initialize U using values chosen randomly from a normal distribution with mean 0 and standard deviation 1. We found it useful to initialize V as UT, since this causes the representation for disease mentions and disease names to initially be the same. We employed an adaptive learning rate using the schedule 77k = 770 r+k, where k is the iteration, 770 is the initial learning rate, and i is the discount (Finkel et al., 2008). We used an initial learning rate of 770= 10-7. This is much lower than reported by Leaman et al. (2013a), since we found that higher values caused the training to found that higher values caused the training to diverge. We used a discount parameter of i = 5, so that the learning rate is equal to one half the initial rate after five iterations. 3 Results Our results were evaluated at the abstract level, allowing comparison to the previous work on DNorm (Leaman et al., 2013a). This evaluation considers the set of disease concepts found in the abstract, and ignores the exact location(s) where each concept was found. A true positive consists of the system returning a disease concept annotated with</context>
</contexts>
<marker>Leaman, Khare, Lu, 2013</marker>
<rawString>Leaman, R., Khare, R., &amp; Lu, Z. (2013b). NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder Normalization in Clinical Notes with DNorm. In Working Notes of the Conference and Labs of the Evaluation Forum Valencia, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Lu</author>
<author>H Y Kao</author>
<author>C H Wei</author>
<author>M Huang</author>
<author>J Liu</author>
<author>C J Kuo</author>
</authors>
<title>The gene normalization task in BioCreative III.</title>
<date>2011</date>
<journal>BMC Bioinformatics,</journal>
<volume>12</volume>
<pages>2</pages>
<contexts>
<context position="2241" citStr="Lu et al., 2011" startWordPosition="321" endWordPosition="324">gnificantly increased scale and ultimately accelerate biomedical discovery (Wei et al., 2012a). Named entity recognition (NER) techniques have typically focused on machine learning methods such as conditional random fields (CRFs), which have provided high performance when coupled with a rich feature approach. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many de</context>
</contexts>
<marker>Lu, Kao, Wei, Huang, Liu, Kuo, 2011</marker>
<rawString>Lu, Z., Kao, H. Y., Wei, C. H., Huang, M., Liu, J., Kuo, C. J., et al. (2011). The gene normalization task in BioCreative III. BMC Bioinformatics, 12 Suppl 8, S2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>H Schütze</author>
</authors>
<date>1999</date>
<journal>Foundations of Statistical Natural Language</journal>
<institution>Processing: Massachusetts Institute of Technology.</institution>
<contexts>
<context position="5911" citStr="Manning &amp; Schütze, 1999" startWordPosition="898" endWordPosition="901">s used by the original technique is proportional to the square of the number of unique tokens. Second, reducing the number of parameters may, in turn, improve the stability of the method and improve its generalization due to the induction of a latent “concept space,” similar to latent semantic indexing (Bai et al., 2010). Finally, while the rich feature approach typically used with conditional random fields allows it to partially compensate for out-of-vocabulary effects, DNorm ignores unknown tokens. This reduces the ability of the model to generalize, due to the zipfian distribution of text (Manning &amp; Schütze, 1999), and is especially problematic in text which contains many misspellings, such as consumer text. Using a richer feature space with DNorm would not be feasible, however, unless the parameter scalability problem is resolved. In this article we expand the DNorm method in a pilot study on feasibility of using low rank approximation methods for disease name normalization. To make this work comparable to the previous work on DNorm, we again employed the NCBI Disease Corpus (Doğan et al., 2014). This corpus contains nearly 800 abstracts, split into training, development, and test sets, as described i</context>
</contexts>
<marker>Manning, Schütze, 1999</marker>
<rawString>Manning, C., &amp; Schütze, H. (1999). Foundations of Statistical Natural Language Processing: Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>P Raghavan</author>
<author>H Schütze</author>
</authors>
<title>Introduction to Information Retrieval:</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7669" citStr="Manning et al., 2008" startWordPosition="1193" endWordPosition="1196">s DNorm uses the BANNER NER system (Leaman &amp; Gonzalez, 2008) to locate disease mentions, and then employs a ranking method to normalize each mention found to the disease concepts in the lexicon (Leaman et al., 2013a). Briefly, we define to be the set of tokens from both the disease mentions in the training data and the concept names in the lexicon. We stem each token in both disease mentions and concept names (Porter, 1980), and then convert each to TF-IDF vectors of dimensionality ||, where the document frequency for each token is taken to be the number of names in the lexicon containing it (Manning et al., 2008). All vectors are normalized to unit length. We define a similarity score between mention vector and name vector , ( ), and each mention is normalized by iterating through all concept names and returning the disease concept corresponding to the one with the highest score. In previous work, ( ) T , where is a weight matrix and each entry represents the correlation between token appearing in a mention and token appearing in a concept name from the lexicon. In this work, however, we set to be a low-rank approximation of the form T , where and are both ||matrices, being the rank (number of linearl</context>
</contexts>
<marker>Manning, Raghavan, Schütze, 2008</marker>
<rawString>Manning, C. D., Raghavan, P., &amp; Schütze, H. (2008). Introduction to Information Retrieval: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mikolov</author>
<author>W-t Yih</author>
<author>G Zweig</author>
</authors>
<title>Linguistic Regularities in Continuous Space Word Representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the NAACL-HLT,</booktitle>
<pages>746--751</pages>
<contexts>
<context position="14307" citStr="Mikolov et al., 2013" startWordPosition="2372" endWordPosition="2375">V matrices convert the TF-IDF vectors to a lower dimensional space suggests that the function of U and V is to provide word embeddings or word representations – a vector space where each word vector encodes its relationships with other words. This further suggests that one way to provide higher performance may be to take advantage of unsupervised pre-training (Erhan et al., 2010). Instead of initializing U and V randomly, they could be initialized using a set of word embeddings trained on a large amount of biomedical text, such as with neural network language models (Collobert &amp; Weston, 2008; Mikolov et al., 2013). 5 Conclusion We performed a pilot study to determine whether a low rank approximation may increase the scalability of normalization using pairwise learning to rank. We showed that the reduction in the number of parameters is substantial: it is now linear to the number of tokens, rather than proportional to the square of the number of tokens. We further observed that the precision and recall increase as the rank of the matrices is increased. We believe that further performance increases may be possible through the use of a richer feature set, unsupervised pre-training, or other dimensionality</context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Mikolov, T., Yih, W.-t., &amp; Zweig, G. (2013). Linguistic Regularities in Continuous Space Word Representations. In Proceedings of the 2013 Conference of the NAACL-HLT, 746-751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A A Morgan</author>
<author>Z Lu</author>
<author>X Wang</author>
<author>A M Cohen</author>
<author>J Fluck</author>
<author>P Ruch</author>
</authors>
<title>Overview of BioCreative II gene normalization.</title>
<date>2008</date>
<journal>Genome Biol.,</journal>
<volume>9</volume>
<pages>3</pages>
<contexts>
<context position="2263" citStr="Morgan et al., 2008" startWordPosition="325" endWordPosition="328">ased scale and ultimately accelerate biomedical discovery (Wei et al., 2012a). Named entity recognition (NER) techniques have typically focused on machine learning methods such as conditional random fields (CRFs), which have provided high performance when coupled with a rich feature approach. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for normalizing gene names, including string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule</context>
</contexts>
<marker>Morgan, Lu, Wang, Cohen, Fluck, Ruch, 2008</marker>
<rawString>Morgan, A. A., Lu, Z., Wang, X., Cohen, A. M., Fluck, J., Ruch, P., et al. (2008). Overview of BioCreative II gene normalization. Genome Biol., 9 Suppl 2, S3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A N6v6ol</author>
<author>R I Doğan</author>
<author>Z Lu</author>
</authors>
<title>Semiautomatic semantic annotation of PubMed queries: a study on quality, efficiency, satisfaction.</title>
<date>2011</date>
<journal>J Biomed Inform,</journal>
<volume>44</volume>
<issue>2</issue>
<pages>310--318</pages>
<marker>N6v6ol, Doğan, Lu, 2011</marker>
<rawString>N6v6ol, A., Doğan, R. I., &amp; Lu, Z. (2011). Semiautomatic semantic annotation of PubMed queries: a study on quality, efficiency, satisfaction. J Biomed Inform, 44(2), 310-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Névéol</author>
<author>W Kim</author>
<author>W J Wilbur</author>
<author>Z Lu</author>
</authors>
<title>Exploring two biomedical text genres for disease recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL 2009 BioNLP Workshop,</booktitle>
<pages>144--152</pages>
<marker>Névéol, Kim, Wilbur, Lu, 2009</marker>
<rawString>Névéol, A., Kim, W., Wilbur, W. J., &amp; Lu, Z. (2009). Exploring two biomedical text genres for disease recognition. In Proceedings of the ACL 2009 BioNLP Workshop, 144-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<pages>130--137</pages>
<contexts>
<context position="7475" citStr="Porter, 1980" startWordPosition="1161" endWordPosition="1162"> per name of 1.01. Subset Abstracts Mentions Concepts Training 593 5145 670 Development 100 787 176 Test 100 960 203 Table 1. Descriptive statistics for the NCBI Disease Corpus. 2 Methods DNorm uses the BANNER NER system (Leaman &amp; Gonzalez, 2008) to locate disease mentions, and then employs a ranking method to normalize each mention found to the disease concepts in the lexicon (Leaman et al., 2013a). Briefly, we define to be the set of tokens from both the disease mentions in the training data and the concept names in the lexicon. We stem each token in both disease mentions and concept names (Porter, 1980), and then convert each to TF-IDF vectors of dimensionality ||, where the document frequency for each token is taken to be the number of names in the lexicon containing it (Manning et al., 2008). All vectors are normalized to unit length. We define a similarity score between mention vector and name vector , ( ), and each mention is normalized by iterating through all concept names and returning the disease concept corresponding to the one with the highest score. In previous work, ( ) T , where is a weight matrix and each entry represents the correlation between token appearing in a mention and</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14, 130-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Suominen</author>
<author>S Salanterä</author>
<author>S Velupillai</author>
<author>W Chapman</author>
<author>G Savova</author>
<author>N Elhadad</author>
</authors>
<title>Overview of the ShARe/CLEF eHealth Evaluation Lab 2013. In</title>
<date>2013</date>
<journal>Multilinguality, Multimodality, and Visualization</journal>
<volume>8138</volume>
<pages>212--231</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="4581" citStr="Suominen et al., 2013" startWordPosition="688" endWordPosition="691">ciation for Computational Linguistics Recently, Leaman et al. (2013a) developed an algorithm (DNorm) that directly addresses the term variation problem with machine learning, and used diseases – an important biomedical entity – as the first case study. The algorithm learns a similarity function between mentions and concept names directly from training data using a method based on pairwise learning to rank. The method was shown to provide high performance on the NCBI Disease Corpus (Doğan et al., 2014; Doğan &amp; Lu, 2012a), and was also applied to clinical notes in the ShARe / CLEF eHealth task (Suominen et al., 2013), where it achieved the highest normalization performance out of 17 international teams (Leaman et al., 2013b). The normalization step does not consider context, and therefore must be combined with a disambiguation method for tasks where disambiguation is important. However, this method provides high performance when paired with a conditional random field system for NER, making the combination a step towards fully adaptable mention recognition and normalization systems. This manuscript adapts DNorm to use a dimensionality reduction technique based on low rank matrix approximation. This may pro</context>
</contexts>
<marker>Suominen, Salanterä, Velupillai, Chapman, Savova, Elhadad, 2013</marker>
<rawString>Suominen, H., Salanterä, S., Velupillai, S., Chapman, W., Savova, G., Elhadad, N., et al. (2013). Overview of the ShARe/CLEF eHealth Evaluation Lab 2013. In P. Forner, H. Müller, R. Paredes, P. Rosso &amp; B. Stein (Eds.), Information Access Evaluation. Multilinguality, Multimodality, and Visualization (Vol. 8138, pp. 212-231): Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tibshirani</author>
</authors>
<title>Regression shrinkage and selection via the Lasso.</title>
<date>1996</date>
<journal>Journal of the Royal Statistical Society Series B-Methodological,</journal>
<volume>58</volume>
<issue>1</issue>
<pages>267--288</pages>
<marker>Tibshirani, 1996</marker>
<rawString>Tibshirani, R. (1996). Regression shrinkage and selection via the Lasso. Journal of the Royal Statistical Society Series B-Methodological, 58(1), 267-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>J McNaught</author>
<author>J Tsujii</author>
<author>S Ananiadou</author>
</authors>
<title>Learning string similarity measures for gene/protein name dictionary look-up using logistic regression.</title>
<date>2007</date>
<journal>Bioinformatics,</journal>
<volume>23</volume>
<issue>20</issue>
<pages>2768--2774</pages>
<contexts>
<context position="2964" citStr="Tsuruoka et al., 2007" startWordPosition="434" endWordPosition="437">uding string matching, pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule patterns. While machine learning methods for normalization have been explored (Tsuruoka et al., 2007; Wermter et al., 2009), these are far less common. This is partially due to the lack of appropriate training data, and also partially due to the need for a generalizable supporting framework. Normalization is frequently decomposed into the sub-tasks of candidate generation and disambiguation (Lu et al., 2011; Morgan et al., 2008). During candidate generation, the set of concept names is constrained to a set of possible matches using the text of the mention. The primary difficulty addressed in candidate generation is term variation: the need to identify terms which are semantically similar but</context>
</contexts>
<marker>Tsuruoka, McNaught, Tsujii, Ananiadou, 2007</marker>
<rawString>Tsuruoka, Y., McNaught, J., Tsujii, J., &amp; Ananiadou, S. (2007). Learning string similarity measures for gene/protein name dictionary look-up using logistic regression. Bioinformatics, 23(20), 2768-2774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Wei</author>
<author>B R Harris</author>
<author>D Li</author>
<author>T Z Berardini</author>
<author>E Huala</author>
<author>H Y Kao</author>
</authors>
<title>Accelerating literature curation with text-mining tools: a case study of using PubTator to curate genes in PubMed abstracts. Database</title>
<date>2012</date>
<pages>041</pages>
<location>(Oxford),</location>
<contexts>
<context position="1718" citStr="Wei et al., 2012" startWordPosition="244" endWordPosition="247">ignificant reduction in the number of parameters to be learned and discuss the implications of this result in the context of algorithm scalability. 1 Introduction The data necessary to answer a wide variety of biomedical research questions is locked away in narrative text. Automating the location (named entity recognition) and identification (normalization) of key biomedical entities (Doğan et al., 2009; N6v6ol et al., 2011) such as diseases, proteins and chemicals in narrative text may reduce curation costs, enable significantly increased scale and ultimately accelerate biomedical discovery (Wei et al., 2012a). Named entity recognition (NER) techniques have typically focused on machine learning methods such as conditional random fields (CRFs), which have provided high performance when coupled with a rich feature approach. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for nor</context>
</contexts>
<marker>Wei, Harris, Li, Berardini, Huala, Kao, 2012</marker>
<rawString>Wei, C. H., Harris, B. R., Li, D., Berardini, T. Z., Huala, E., Kao, H. Y., et al. (2012a). Accelerating literature curation with text-mining tools: a case study of using PubTator to curate genes in PubMed abstracts. Database (Oxford), 2012, bas041.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Wei</author>
<author>H Y Kao</author>
<author>Z Lu</author>
</authors>
<title>SR4GN: a species recognition software tool for gene normalization.</title>
<date>2012</date>
<journal>PLoS One,</journal>
<volume>7</volume>
<issue>6</issue>
<pages>38460</pages>
<contexts>
<context position="1718" citStr="Wei et al., 2012" startWordPosition="244" endWordPosition="247">ignificant reduction in the number of parameters to be learned and discuss the implications of this result in the context of algorithm scalability. 1 Introduction The data necessary to answer a wide variety of biomedical research questions is locked away in narrative text. Automating the location (named entity recognition) and identification (normalization) of key biomedical entities (Doğan et al., 2009; N6v6ol et al., 2011) such as diseases, proteins and chemicals in narrative text may reduce curation costs, enable significantly increased scale and ultimately accelerate biomedical discovery (Wei et al., 2012a). Named entity recognition (NER) techniques have typically focused on machine learning methods such as conditional random fields (CRFs), which have provided high performance when coupled with a rich feature approach. The utility of NER for biomedical end users is limited, however, since many applications require each mention to be normalized, that is, identified within a specified controlled vocabulary. The normalization task has been highlighted in the BioCreative challenges (Hirschman et al., 2005; Lu et al., 2011; Morgan et al., 2008), where a variety of methods have been explored for nor</context>
</contexts>
<marker>Wei, Kao, Lu, 2012</marker>
<rawString>Wei, C. H., Kao, H. Y., &amp; Lu, Z. (2012b). SR4GN: a species recognition software tool for gene normalization. PLoS One, 7(6), e38460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wermter</author>
<author>K Tomanek</author>
<author>U Hahn</author>
</authors>
<title>Highperformance gene name normalization with GeNo.</title>
<date>2009</date>
<journal>Bioinformatics,</journal>
<volume>25</volume>
<issue>6</issue>
<pages>815--821</pages>
<contexts>
<context position="2987" citStr="Wermter et al., 2009" startWordPosition="438" endWordPosition="441">pattern matching, and heuristic rules. Similar methods have been applied to disease names (Doğan &amp; Lu, 2012b; Kang et al., 2012; N6v6ol et al., 2009) and species names (Gerner et al., 2010; Wei et al., 2012b), and the MetaMap program is used to locate and identify concepts from the UMLS MetaThesaurus (Aronson, 2001; Bodenreider, 2004). Machine learning methods for NER have provided high performance, enhanced system adaptability to new entity types, and abstracted many details of specific rule patterns. While machine learning methods for normalization have been explored (Tsuruoka et al., 2007; Wermter et al., 2009), these are far less common. This is partially due to the lack of appropriate training data, and also partially due to the need for a generalizable supporting framework. Normalization is frequently decomposed into the sub-tasks of candidate generation and disambiguation (Lu et al., 2011; Morgan et al., 2008). During candidate generation, the set of concept names is constrained to a set of possible matches using the text of the mention. The primary difficulty addressed in candidate generation is term variation: the need to identify terms which are semantically similar but textually distinct (e.</context>
</contexts>
<marker>Wermter, Tomanek, Hahn, 2009</marker>
<rawString>Wermter, J., Tomanek, K., &amp; Hahn, U. (2009). Highperformance gene name normalization with GeNo. Bioinformatics, 25(6), 815-821.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>