<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.115727">
<title confidence="0.99285">
Agent-based modeling of language evolution
</title>
<author confidence="0.993587">
Torvald Lekvam Bj¨orn Gamb¨ack Lars Bungum
</author>
<affiliation confidence="0.9993455">
Department of Computer and Information Science, Sem Sælands vei 7–9
Norwegian University of Science and Technology, 7491 Trondheim, Norway
</affiliation>
<email confidence="0.981939">
torvald@lekvam.no {gamback,larsbun}@idi.ntnu.no
</email>
<sectionHeader confidence="0.993487" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999929533333333">
Agent-based models of language evolution
have received a lot of attention in the last
two decades. Researchers wish to under-
stand the origin of language, and aim to
compensate for the lacking empirical evi-
dence by utilizing methods from computer
science and artificial life. The paper looks
at the main theories of language evolution:
biological evolution, learning, and cultural
evolution. In particular, the Baldwin effect
in a naming game model is elaborated on
by describing a set of experimental simu-
lations. This is on-going work and ideas
for further investigating the social aspects
of language evolution are also discussed.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971526315789">
What is language? It is interesting how we can
take a train of thought and transfer this into an-
other person’s mind by pushing the air around us.
Human language, this complex medium that dis-
tinctly separates humans from animals, has baf-
fled scientists for centuries. While animals also
use language, even with a degree of syntax (Kako,
1999), spoken human language exhibits a vastly
more complex structure and spacious variation.
To understand how language works — how it
is used, its origin and fundamentals — our best
information sources are the languages alive (and
some extinct but documented ones). Depending on
definition, there are 6,000–8,000 languages world-
wide today, showing extensive diversity of syntax,
semantics, phonetics and morphology (Evans and
Levinson, 2009). Still, these represent perhaps
only 2% of all languages that have ever existed
(Pagel, 2000). As this is a rather small window, we
want to look back in time. But there is a problem
in linguistic history: our reconstruction techniques
can only take us back some 6,000 to 7,000 years.
Beyond this point, researchers can only speculate
on when and how human language evolved: either
as a slowly proceeding process starting millions
of years (Ma) ago, e.g., 7 Ma ago with the first
appearance of cognitive capacity or 2.5 Ma ago
with the first manufacture of stone implements; or
through some radical change taking place about
100 ka ago with the appearance of the modern hu-
mans or 50–60 ka ago when they started leaving
Africa (Klein, 2008; Tattersall, 2010).
The rest of this introduction covers some key
aspects of language evolution. Section 2 then fo-
cuses on computational models within the field,
while Section 3 describes a specific naming game
model. Finally, Section 4 discusses the results and
some ideas for future work.
</bodyText>
<subsectionHeader confidence="0.992073">
1.1 Theories of origin: the biological aspect
</subsectionHeader>
<bodyText confidence="0.997884347826087">
There are two main ideas in biological evolution
as to why humans developed the capacity to com-
municate through speech. The first states that lan-
guage (or more precisely the ability to bear the full
structure of language) came as an epiphenomenon,
a by-product (spandrel) of an unrelated mutation.
This theory assumes that a mental language fac-
ulty could not by itself evolve by natural selection;
there would simply be too many costly adaptations
for it to be possible. Thus there should exist an in-
nate capacity in the form of a universal grammar
(Chomsky, 1986), which can hold a finite number
of rules enabling us to carry any kind of language.
According to the second idea, language
emerged in a strictly adaptational process (Pinker
and Bloom, 1990). That is, that language evolu-
tion can be explained by natural selection, in the
same way as the evolution of other complex traits
like echolocation in bats or stereopsis in monkeys.
Both ideas — innate capacity vs natural selection
— have supporters, as well as standpoints that
hold both aspects as important, but at different lev-
els (Deacon, 2010; Christiansen and Kirby, 2003).
</bodyText>
<page confidence="0.993084">
49
</page>
<note confidence="0.5226755">
Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 49–54,
Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.956254">
1.2 Theories of origin: the cultural aspect
</subsectionHeader>
<bodyText confidence="0.9999718">
Biology aside, the forces behind the emergence of
human language are not strictly genetic (and do
not operate only on a phylogenetic time scale).
Kirby (2002) argues that, in addition to biological
evolution, there are two more complex adaptive
(dynamical) systems influencing natural language;
namely cultural evolution (on the glossogenetic
time scale) and learning (which operates on a in-
dividual level, on the ontogenetic time scale).
In addition, there is the interesting Darwinian
idea that cultural learning can guide biological
evolution, a process known as the Baldwin effect
(Baldwin, 1896; Simpson, 1953). This theory ar-
gues that culturally learned traits (e.g., a univer-
sal understanding of grammar or a defense mech-
anism against a predator) can assimilate into the
genetic makeup of a species. Teaching each mem-
ber in a population the same thing over and over
again comes with great cost (time, faulty learn-
ing, genetic complexity), and the overall popula-
tion saves a lot of energy if a learned trait would
become innate. On the other hand, there is a cost
of genetic assimilation as it can prohibit plastic-
ity in future generations and make individuals less
adaptive to unstable environments.
There has been much debate recently whether
language is a result of the Baldwin effect or not
(Evans and Levinson, 2009; Chater et al., 2009;
Baronchelli et al., 2012, e.g.), but questions, hypo-
theses, and simulations fly in both directions.
</bodyText>
<sectionHeader confidence="0.434066" genericHeader="method">
2 Language evolution and computation
</sectionHeader>
<bodyText confidence="0.999969289855073">
Since the 90s, there has been much work on sim-
ulation of language evolution in bottom-up sys-
tems with populations of autonomous agents. The
field is highly influenced by the work of Steels and
Kirby, respectively, and has been summarized and
reviewed both by themselves and others (Steels,
2011; Kirby, 2002; Gong and Shuai, 2013, e.g.).
Computational research in this field is limited
to modeling very simplified features of human
language in isolation, such as strategies for nam-
ing colors (Bleys and Steels, 2011; Puglisi et al.,
2008), different aspects of morphology (Dale and
Lupyan, 2012), and similar. This simplicity is im-
portant to keep in mind, since it is conceivable that
certain features of language can be highly influ-
enced by other features in real life.
A language game simulation (Steels, 1995) is
a model where artificial agents interact with each
other in turn in order to reach a cooperative goal;
to make up a shared language of some sort, all
while minimizing their cognitive effort. All agents
are to some degree given the cognitive ability to
bear language, but not given any prior knowledge
of how language should look like or how consen-
sus should unfold. No centralized anchors are in-
volved: a simulation is all self-organized.
Agents are chosen (mostly at random) as hearer
and speaker, and made to exchange an utterance
about a certain arbitrary concept or meaning in
their environment. If the agents use the same lan-
guage (i.e., the utterance is understood by both
parties), the conversation is a success. If the
speaker utters something unfamiliar to the hearer,
the conversation is termed a failure. If an agent
wants to express some concept without having any
utterances for it, the agent is assumed to have the
ability to make one up and add this to its memory.
While interpretation in real life is a complex af-
fair, it is mostly assumed that there is a fairly direct
connection between utterance and actual meaning
in language game models (emotions and social sit-
uations do not bias how language is interpreted).
A simple language game normally is charac-
terized by many synonyms spawning among the
agents. As agents commence spreading their own
utterances around, high-weighted words start to be
preferred. Consensus is reached when all agents
know the highest weighted word for each concept.
Commonly, the agents aim to reach a single co-
herent language, but the emergence of multilin-
gualism has also been simulated (Lipowska, 2011;
Roberts, 2012). Cultural evolution can be captured
by horizontal communication between individuals
in the same generation or vertical communication
from adults to children. The latter typically lets the
agents breed, age and die, with the iterated learn-
ing model (Smith et al., 2003) being popular.
A variety of language games exist, from sim-
ple naming games, where the agents’ only topic
concerns one specific object (Lipowska, 2011), to
more cognitive grounding games (Steels and Loet-
zsch, 2012). There have also been studies on some
more complex types of interaction, such as spa-
tial games (Spranger, 2013), factual description
games (van Trijp, 2012) and action games (Steels
and Spranger, 2009), where the agent communi-
cation is about objects in a physical environment,
about real-world events, and about motoric behav-
iors, respectively.
</bodyText>
<page confidence="0.991464">
50
</page>
<sectionHeader confidence="0.952102" genericHeader="method">
3 The Baldwin effect in a naming game
</sectionHeader>
<bodyText confidence="0.999986465346535">
Several researchers have created simulations to in-
vestigate the Baldwin effect, starting with Hinton
and Nowlan (1987). Cangelosi and Parisi (2002)
simulate agents who evolve a simple grammatical
language in order to survive in a world filled with
edible and poisonous mushrooms. Munroe and
Cangelosi (2002) used this model to pursue the
Baldwin effect, with partially blind agents initially
having to learn features of edible mushrooms, but
with the learned abilities getting more and more
assimilated into the genome over the generations.
Chater et al. (2009) argue that only stable parts of
language may assimilate into the genetic makeup,
while variation within the linguistic environment
is too unstable to be a target of natural selection.
Watanabe et al. (2008) use a similar model, but in
contrast state that genetic assimilation not neces-
sarily requires a stable linguistic environment.
Lipowska (2011) has pursued the Baldwin ef-
fect in a simple naming game model with the in-
tention of mixing up a language game in a simu-
lation that incorporates both learning, cultural and
biological evolution. The model places a set of
agents in a square lattice of a linear size L, where
every agent is allowed — by a given probability p
— to communicate with a random neighbor.
At each time step, a random agent is chosen and
p initially decides whether the agent is allowed to
communicate or will face a “population update”.
Every agent has an internal lexicon of N words
with associated weights (wj : 1 &lt; j &lt; N). When-
ever a chosen speaker is to utter a word, the agent
selects a word i from its lexicon with the probabil-
ity wi/ EN j=1 wj. If the lexicon is empty (N = 0),
a word is made up. A random neighbor in the lat-
tice is then chosen as the hearer. If both agents
know the uttered word, the dialog is deemed a
success, and if not, a failure. Upon success, both
agents increase the uttered word’s weight in their
lexica by a learning ability variable. Each agent k
is equipped with such a variable l (0 &lt; lk &lt; 1).
This learning ability is meant to, in its simplicity,
reflect the genetic assimilation.
Instead of engaging in communication, the cho-
sen agent is occasionally updated, by a probability
1 − p. Agents die or survive with a probability ps
which is given by an equation that takes into ac-
count age, knowledge (lexicon weights in respect
to the population’s average weights), and simula-
tion arguments. If the agent has a high-weighted
lexicon and is young of age, and therefore survives
at a given time step, the agent is allowed to breed
if there are empty spaces in its neighborhood.
All in all, each time step can terminate with
eight different scenarios: in addition to the two
communication scenarios (success or failure), the
scenario where the agent dies, as well as the one
where the agents lives but only has non-empty
neighbors (so that no change is possible), there are
four possibilities for breeding. If the agent breeds,
the off-spring either inherit the parent’s learning
ability or gain a new learning ability, with a proba-
bility pm. With the same mutation probability, the
off-spring also either gains a new word or inherits
the parent’s highest-weight word.
This model was implemented with the aim to
reproduce Lipowska’s results. She argues that her
model is fairly robust to both population size and
her given arguments; however, our experiments
do not support this: as the Baldwin effect unfold,
it does not follow the same abrupt course as in
Lipowska’s model. This could be due to some as-
sumptions that had to be made, since Lipowska
(2011), for instance, presents no details on how
age is calculated. We thus assume that every time
an agent is allowed to communicate, its age gets
incremented. Another possibility could be to in-
crement every agent’s age at every time step, so
that agents get older even if they do not commu-
nicate. Furthermore, the initial values for learn-
ability are not clearly stated. Lipowska uses sev-
eral different values in her analysis. We have used
0.5, which makes a decrease in learnability a part
of the evolutionary search space as well.
Simulations with parameters similar to those
used by Lipowska (2011) [iterations = 200, 000,
mutationchance = 0.01, L = 25, p = 0.4, l = 0.5],
produce results as in Figure 1, showing the highest
weighted word per agent after 50k and 150k time
steps, with each agent being a dot in a “heat map”;
black dots indicate dead agents (empty space).
The number of groups are reduced over time, and
their sizes grow, as more agents agree on a lex-
icon and as favorable mutations spread through
the population, (as indicated by agent learnability;
Figure 2). Even after 200k iterations, consensus is
not reached (which it was in Lipowska’s simula-
tion), but the agent population agrees on one word
if the simulation is allowed to run further. It is nat-
ural to assume that the difference lays in the details
of how age is calculated, as noted above.
</bodyText>
<page confidence="0.998694">
51
</page>
<figureCaption confidence="0.999859714285714">
Figure 1: Ca 16 different words dominate the pop-
ulation at iteration 50k and nine at iteration 150k.
Figure 3: Fraction of agents alive in the lattice and
average learnability in the population (s-shaped).
Figure 2: Mutations favoring learnability at itera-
tion 50k spread substantially by iteration 150k.
Figure 4: Average sum of weights in agent lexica.
</figureCaption>
<bodyText confidence="0.999959651162791">
Diverting from Lipowska’s parameters and
skewing towards faster turnover (higher mutation
rate, higher possibility of survival with richer lex-
icon/higher age, etc.), gives behavior similar to
hers, with faster and more abrupt genetic assim-
ilation, as shown Figure 3. The upper line in the
figure represents the fraction of agents alive in the
lattice. It is initially fully populated, but the popu-
lation decreases with time and balances at a point
where death and birth are equally tensioned.
Agents with higher learnability tend to live
longer, and the lower graph in Figure 3 shows the
average learnability in the population. It is roughly
sigmoid (S-shaped; cf. Lipowska’s experiment) as
a result of slow mutation rate in the first phase,
followed by a phase with rapid mutation rate (ca
100k–170k) as the learnability also gets inherited,
and decreasing rate towards the end when mu-
tations are more likely to ruin agent learnability
(when the learning ability l is at its upper limit).
As can be seen in Figure 4, the agents rapidly get
to a stable weighted lexicon before the Baldwin
effect shows itself around time step 100k.
As mentioned, Lipowska’s model did not reflect
the robustness argued in her paper: for other val-
ues of p, the number of empty spots in the popu-
lation lattice starts to diverge substantially, and for
some values all agents simply die. As population
sizes vary, the number of iterations must also be
adjusted to get similar results. If not, the agents
will not reach the same population turn-over as
for smaller population sizes since only one agent
may be updated per iteration. Lipowska (2011)
compensated with higher mutation rate on simu-
lations with different population sizes; however,
these could be two variables somewhat more inde-
pendent of each other. The model would have been
much more stable if it contained aspects of a typi-
cal genetic algorithm, where agents are allowed to
interact freely within generations. This way, the
model could be acting more upon natural selec-
tion (and in search of the Baldwin effect), instead
of relying on well-chosen parameters to work.
</bodyText>
<sectionHeader confidence="0.98767" genericHeader="discussions">
4 Discussion and future work
</sectionHeader>
<bodyText confidence="0.999672375">
Language is a complex adaptive system with nu-
merous variables to consider. Thus we must make
a number of assumptions when studying language
and its evolution, and can only investigate certain
aspects at a time through simplifications and ab-
stractions. As this paper has concentrated on the
agent-based models of the field, many studies re-
flecting such other aspects had to be left out.
In addition, there has lately been a lot of work
studying small adjustments to the agent-based
models, in order to make them more realistic by,
for example, having multiple hearers in a lan-
guage game conversations (Li et al., 2013), dif-
ferent topologies (Lei et al., 2010; Lipowska and
Lipowski, 2012), and more heterogeneous popula-
tions (Gong et al., 2006).
</bodyText>
<page confidence="0.996302">
52
</page>
<bodyText confidence="0.999970975609756">
In general, though, simulations on language
evolution tend to have relatively small and fixed
sizes (Baronchelli et al., 2006; Vogt, 2007) — and
few studies seem to take social dynamics (Gong et
al., 2008; Kalampokis et al., 2007) or geography
into account (Patriarca and Heinsalu, 2009).
Further work is still needed to make existing
models more realistic and to analyze relations be-
tween different models (e.g., by combining them).
Biological evolution could be studied with more
flexible (or plastic) neural networks. Cultural evo-
lution could be investigated under more realistic
geographical and demographical influence, while
learning could be analyzed even further in light of
social dynamics, as different linguistic phenom-
ena unfold. Quillinan (2006) presented a model
concerning how a network of social relationships
could evolve with language traits. This model
could be taken further in combination with exist-
ing language games or it could be used to show
how language responds to an exposure of continu-
ous change in a complex social network.
Notably, many present models have a rather
naive way of selecting cultural parents, and a
genetic algorithm for giving fitness to agents in
terms of having (assimilated) the best strategies
for learning (e.g., memory efficiency), social con-
ventions (e.g., emotions, popularity), and/or sim-
ple or more advanced grammar could be explored.
A particular path we aim to pursue is to study a
language game with a simple grammar under so-
cial influence (e.g., with populations in different
fixed and non-fixed graphs, with multiple hearers),
contained within a genetic algorithm. In such a
setting, the agents must come up with strategies
for spreading and learning new languages, and
need to develop fault-tolerant models for speaking
with close and distant neighbors. This could be a
robust model where a typical language game could
be examined, in respect to both biological and cul-
tural evolution, with a more realistic perspective.
</bodyText>
<sectionHeader confidence="0.989777" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.89638925">
We would like thank the three anonymous review-
ers for several very useful comments. Thanks also
to Keith Downing for providing feedback on work
underlying this article.
The third author is supported by a grant from the
Norwegian University of Science and Technology.
Part of this work was funded by the PRESEMT
project (EC grant number FP7-ICT-4-248307).
</bodyText>
<sectionHeader confidence="0.8797" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998431058823529">
James Mark Baldwin. 1896. A new factor in evolution.
The American Naturalist, 30(354):441–451.
Andrea Baronchelli, Maddalena Felici, Vittorio Loreto,
Emanuele Caglioti, and Luc Steels. 2006. Sharp
transition towards shared vocabularies in multi-
agent systems. Journal of Statistical Mechanics:
Theory and Experiment, 2006(06):P06014.
Andrea Baronchelli, Nick Chater, Romualdo Pastor-
Satorras, and Morten H. Christiansen. 2012. The
biological origin of linguistic diversity. PLoS ONE,
7(10):e48029.
Joris Bleys and Luc Steels. 2011. Linguistic selec-
tion of language strategies. In G. Kampis, I. Kar-
sai, and E. Szathm´ary, editors, Advances in Artificial
Life. Darwin Meets von Neumann, volume 2, pages
150–157. Springer.
Angelo Cangelosi and Domenico Parisi. 2002. Com-
puter simulation: A new scientific approach to the
study of language evolution. In Angelo Cangelosi
and Domenico Parisi, editors, Simulating the Evolu-
tion of Language, chapter 1, pages 3–28. Springer,
London.
Nick Chater, Florencia Reali, and Morten H Chris-
tiansen. 2009. Restrictions on biological adaptation
in language evolution. Proceedings of the National
Academy of Sciences, 106(4):1015–1020.
Noam Chomsky. 1986. Knowledge of language: Its
nature, origins, and use. Greenwood.
Morten H. Christiansen and Simon Kirby. 2003.
Language evolution: consensus and controversies.
TRENDS in Cognitive Sciences, 7(7):300–307.
Rick Dale and Gary Lupyan. 2012. Understanding
the origins of morphological diversity: the linguis-
tic niche hypothesis. Advances in Complex Systems,
15(03n04):1150017.
Terrence W. Deacon. 2010. A role for relaxed se-
lection in the evolution of the language capacity.
Proceedings of the National Academy of Sciences,
107(Supplement 2):9000–9006.
Nicholas Evans and Stephen C. Levinson. 2009. The
myth of language universals: Language diversity
and its importance for cognitive science. Behavioral
and Brain Sciences, 32(05):429–448.
Tao Gong and Lan Shuai. 2013. Computer simulation
as a scientific approach in evolutionary linguistics.
Language Sciences, 40:12–23.
Tao Gong, James W. Minett, and William S-Y Wang.
2006. Language origin and the effects of individ-
uals popularity. In Proceedings of the 2006 IEEE
Congress on Evolutionary Computation, pages 999–
1006, Vancouver, British Columbia, Jul. IEEE.
</reference>
<page confidence="0.994649">
53
</page>
<reference confidence="0.99970171">
Tao Gong, James W. Minett, and William S-Y Wang.
2008. Exploring social structure effect on language
evolution based on a computational model. Connec-
tion Science, 20(2-3):135–153.
Geoffrey E Hinton and Steven J Nowlan. 1987. How
learning can guide evolution. Complex systems,
1(3):495–502.
Edward Kako. 1999. Elements of syntax in the sys-
tems of three language-trained animals. Animal
Learning &amp; Behavior, 27(1):1–14.
Alkiviadis Kalampokis, Kosmas Kosmidis, and Panos
Argyrakis. 2007. Evolution of vocabulary on scale-
free and random networks. Physica A: Statistical
Mechanics and its Applications, 379(2):665 – 671.
Simon Kirby. 2002. Natural language from artificial
life. Artificial Life, 8(2):185–215.
Richard G. Klein. 2008. Out of Africa and the evo-
lution of human behavior. Evolutionary Anthropol-
ogy: Issues, News, and Reviews, 17(6):267–281.
Chuang Lei, Jianyuan Jia, Te Wu, and Long Wang.
2010. Coevolution with weights of names in struc-
tured language games. Physica A: Statistical Me-
chanics and its Applications, 389(24):5628–5634.
Bing Li, Guanrong Chen, and Tommy W.S. Chow.
2013. Naming game with multiple hearers. Com-
munications in Nonlinear Science and Numerical
Simulation, 18(5):1214–1228.
Dorota Lipowska and Adam Lipowski. 2012. Naming
game on adaptive weighted networks. Artificial Life,
18(3):311–323.
Dorota Lipowska. 2011. Naming game and compu-
tational modelling of language evolution. Compu-
tational Methods in Science and Technology, 17(1–
2):41–51.
Steve Munroe and Angelo Cangelosi. 2002. Learning
and the evolution of language: the role of cultural
variation and learning costs in the Baldwin effect.
Artificial Life, 8(4):311–339.
Mark Pagel. 2000. The history, rate and pattern of
world linguistic evolution. In Ch. Knight, J.R. Hur-
ford, and M. Studdert-Kennedy, editors, The Evo-
lutionary Emergence of Language: Social Func-
tion and the Origins of Linguistic Form, chapter 22,
pages 391–416. Cambridge University Press.
Marco Patriarca and Els Heinsalu. 2009. Influence
of geography on language competition. Physica A:
Statistical Mechanics and its Applications, 388(2–
3):174–186.
Steven Pinker and Paul Bloom. 1990. Natural lan-
guage and natural selection. Behavioral and Brain
Sciences, 13:707–784.
Andrea Puglisi, Andrea Baronchelli, and Vittorio
Loreto. 2008. Cultural route to the emergence of
linguistic categories. Proceedings of the National
Academy of Sciences, 105(23):7936–7940.
Justin Quillinan. 2006. Social networks and cultural
transmission. Master of Science Thesis, School
of Philosophy, Psychology and Language Sciences,
University of Edinburgh, Edinburgh, Scotland, Aug.
Sean Geraint Roberts. 2012. An evolutionary ap-
proach to bilingualism. Ph.D. thesis, School of Phi-
losophy, Psychology and Language Sciences, Uni-
versity of Edinburgh, Edinburgh, Scotland, Oct.
George Gaylord Simpson. 1953. The Baldwin effect.
Evolution, 7(2):110–117.
Kenny Smith, Simon Kirby, and Henry Brighton.
2003. Iterated learning: A framework for the emer-
gence of language. Artificial Life, 9(4):371–386.
Michael Spranger. 2013. Evolving grounded spa-
tial language strategies. KI-K¨unstliche Intelligenz,
27(2):1–10.
Luc Steels and Martin Loetzsch. 2012. The grounded
naming game. In L. Steels, editor, Experiments in
Cultural Language Evolution, pages 41–59. John
Benjamins.
Luc Steels and Michael Spranger. 2009. How ex-
perience of the body shapes language about space.
In Proceedings of the 21st International Joint Con-
ference on Artificial Intelligence, pages 14–19,
Pasadena, California, Jul. IJCAI.
Luc Steels. 1995. A self-organizing spatial vocabulary.
Artificial Life, 2(3):319–332.
Luc Steels. 2011. Modeling the cultural evolution of
language. Physics of Life Reviews, 8(4):339–356.
Ian Tattersall. 2010. Human evolution and cognition.
Theory in Biosciences, 129(2–3):193–201.
Remi van Trijp. 2012. The evolution of case systems
for marking event structure. In L. Steels, editor,
Experiments in Cultural Language Evolution, pages
169–205. John Benjamins.
Paul Vogt. 2007. Group size effects on the emer-
gence of compositional structures in language. In
F. Almeida e Costa, L.M. Rocha, E. Costa, I Har-
vey, and A. Coutinho, editors, Advances in Artifi-
cial Life: Proceedings of the 9th European Confer-
ence (ECAL 2007), pages 405–414, Lisbon, Portu-
gal, Sep. Springer.
Yusuke Watanabe, Reiji Suzuki, and Takaya Arita.
2008. Language evolution and the Baldwin effect.
Artificial Life and Robotics, 12(1-2):65–69.
</reference>
<page confidence="0.999024">
54
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.818711">
<title confidence="0.99849">Agent-based modeling of language evolution</title>
<author confidence="0.997623">Torvald Lekvam Bj¨orn Gamb¨ack Lars Bungum</author>
<affiliation confidence="0.958593">Department of Computer and Information Science, Sem Sælands vei 7–9</affiliation>
<address confidence="0.842637">Norwegian University of Science and Technology, 7491 Trondheim, Norway</address>
<abstract confidence="0.999158125">Agent-based models of language evolution have received a lot of attention in the last two decades. Researchers wish to understand the origin of language, and aim to compensate for the lacking empirical evidence by utilizing methods from computer science and artificial life. The paper looks at the main theories of language evolution: biological evolution, learning, and cultural evolution. In particular, the Baldwin effect in a naming game model is elaborated on by describing a set of experimental simulations. This is on-going work and ideas for further investigating the social aspects of language evolution are also discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>A new factor in evolution.</title>
<journal>The American Naturalist,</journal>
<volume>30</volume>
<issue>354</issue>
<marker></marker>
<rawString>James Mark Baldwin. 1896. A new factor in evolution. The American Naturalist, 30(354):441–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Baronchelli</author>
<author>Maddalena Felici</author>
<author>Vittorio Loreto</author>
<author>Emanuele Caglioti</author>
<author>Luc Steels</author>
</authors>
<title>Sharp transition towards shared vocabularies in multiagent systems.</title>
<date>2006</date>
<journal>Journal of Statistical Mechanics: Theory and Experiment,</journal>
<volume>2006</volume>
<issue>06</issue>
<contexts>
<context position="17316" citStr="Baronchelli et al., 2006" startWordPosition="2863" endWordPosition="2866">s. As this paper has concentrated on the agent-based models of the field, many studies reflecting such other aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution could be investigated under more realistic geographical and demographical influence, while learning could be analyzed even further in light of social dynamics, as different linguistic p</context>
</contexts>
<marker>Baronchelli, Felici, Loreto, Caglioti, Steels, 2006</marker>
<rawString>Andrea Baronchelli, Maddalena Felici, Vittorio Loreto, Emanuele Caglioti, and Luc Steels. 2006. Sharp transition towards shared vocabularies in multiagent systems. Journal of Statistical Mechanics: Theory and Experiment, 2006(06):P06014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Baronchelli</author>
<author>Nick Chater</author>
<author>Romualdo PastorSatorras</author>
<author>Morten H Christiansen</author>
</authors>
<title>The biological origin of linguistic diversity.</title>
<date>2012</date>
<journal>PLoS ONE,</journal>
<volume>7</volume>
<issue>10</issue>
<contexts>
<context position="5540" citStr="Baronchelli et al., 2012" startWordPosition="882" endWordPosition="885">tor) can assimilate into the genetic makeup of a species. Teaching each member in a population the same thing over and over again comes with great cost (time, faulty learning, genetic complexity), and the overall population saves a lot of energy if a learned trait would become innate. On the other hand, there is a cost of genetic assimilation as it can prohibit plasticity in future generations and make individuals less adaptive to unstable environments. There has been much debate recently whether language is a result of the Baldwin effect or not (Evans and Levinson, 2009; Chater et al., 2009; Baronchelli et al., 2012, e.g.), but questions, hypotheses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming co</context>
</contexts>
<marker>Baronchelli, Chater, PastorSatorras, Christiansen, 2012</marker>
<rawString>Andrea Baronchelli, Nick Chater, Romualdo PastorSatorras, and Morten H. Christiansen. 2012. The biological origin of linguistic diversity. PLoS ONE, 7(10):e48029.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joris Bleys</author>
<author>Luc Steels</author>
</authors>
<title>Linguistic selection of language strategies.</title>
<date>2011</date>
<booktitle>Advances in Artificial Life. Darwin Meets von Neumann,</booktitle>
<volume>2</volume>
<pages>150--157</pages>
<editor>In G. Kampis, I. Karsai, and E. Szathm´ary, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="6168" citStr="Bleys and Steels, 2011" startWordPosition="982" endWordPosition="985">), but questions, hypotheses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming colors (Bleys and Steels, 2011; Puglisi et al., 2008), different aspects of morphology (Dale and Lupyan, 2012), and similar. This simplicity is important to keep in mind, since it is conceivable that certain features of language can be highly influenced by other features in real life. A language game simulation (Steels, 1995) is a model where artificial agents interact with each other in turn in order to reach a cooperative goal; to make up a shared language of some sort, all while minimizing their cognitive effort. All agents are to some degree given the cognitive ability to bear language, but not given any prior knowledg</context>
</contexts>
<marker>Bleys, Steels, 2011</marker>
<rawString>Joris Bleys and Luc Steels. 2011. Linguistic selection of language strategies. In G. Kampis, I. Karsai, and E. Szathm´ary, editors, Advances in Artificial Life. Darwin Meets von Neumann, volume 2, pages 150–157. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angelo Cangelosi</author>
<author>Domenico Parisi</author>
</authors>
<title>Computer simulation: A new scientific approach to the study of language evolution.</title>
<date>2002</date>
<booktitle>In Angelo Cangelosi and Domenico Parisi, editors, Simulating the Evolution of Language, chapter 1,</booktitle>
<pages>3--28</pages>
<publisher>Springer,</publisher>
<location>London.</location>
<contexts>
<context position="9152" citStr="Cangelosi and Parisi (2002)" startWordPosition="1469" endWordPosition="1472">ecific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spranger, 2013), factual description games (van Trijp, 2012) and action games (Steels and Spranger, 2009), where the agent communication is about objects in a physical environment, about real-world events, and about motoric behaviors, respectively. 50 3 The Baldwin effect in a naming game Several researchers have created simulations to investigate the Baldwin effect, starting with Hinton and Nowlan (1987). Cangelosi and Parisi (2002) simulate agents who evolve a simple grammatical language in order to survive in a world filled with edible and poisonous mushrooms. Munroe and Cangelosi (2002) used this model to pursue the Baldwin effect, with partially blind agents initially having to learn features of edible mushrooms, but with the learned abilities getting more and more assimilated into the genome over the generations. Chater et al. (2009) argue that only stable parts of language may assimilate into the genetic makeup, while variation within the linguistic environment is too unstable to be a target of natural selection. W</context>
</contexts>
<marker>Cangelosi, Parisi, 2002</marker>
<rawString>Angelo Cangelosi and Domenico Parisi. 2002. Computer simulation: A new scientific approach to the study of language evolution. In Angelo Cangelosi and Domenico Parisi, editors, Simulating the Evolution of Language, chapter 1, pages 3–28. Springer, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nick Chater</author>
<author>Florencia Reali</author>
<author>Morten H Christiansen</author>
</authors>
<title>Restrictions on biological adaptation in language evolution.</title>
<date>2009</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>106</volume>
<issue>4</issue>
<contexts>
<context position="5514" citStr="Chater et al., 2009" startWordPosition="878" endWordPosition="881">anism against a predator) can assimilate into the genetic makeup of a species. Teaching each member in a population the same thing over and over again comes with great cost (time, faulty learning, genetic complexity), and the overall population saves a lot of energy if a learned trait would become innate. On the other hand, there is a cost of genetic assimilation as it can prohibit plasticity in future generations and make individuals less adaptive to unstable environments. There has been much debate recently whether language is a result of the Baldwin effect or not (Evans and Levinson, 2009; Chater et al., 2009; Baronchelli et al., 2012, e.g.), but questions, hypotheses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such a</context>
<context position="9566" citStr="Chater et al. (2009)" startWordPosition="1534" endWordPosition="1537">rs, respectively. 50 3 The Baldwin effect in a naming game Several researchers have created simulations to investigate the Baldwin effect, starting with Hinton and Nowlan (1987). Cangelosi and Parisi (2002) simulate agents who evolve a simple grammatical language in order to survive in a world filled with edible and poisonous mushrooms. Munroe and Cangelosi (2002) used this model to pursue the Baldwin effect, with partially blind agents initially having to learn features of edible mushrooms, but with the learned abilities getting more and more assimilated into the genome over the generations. Chater et al. (2009) argue that only stable parts of language may assimilate into the genetic makeup, while variation within the linguistic environment is too unstable to be a target of natural selection. Watanabe et al. (2008) use a similar model, but in contrast state that genetic assimilation not necessarily requires a stable linguistic environment. Lipowska (2011) has pursued the Baldwin effect in a simple naming game model with the intention of mixing up a language game in a simulation that incorporates both learning, cultural and biological evolution. The model places a set of agents in a square lattice of </context>
</contexts>
<marker>Chater, Reali, Christiansen, 2009</marker>
<rawString>Nick Chater, Florencia Reali, and Morten H Christiansen. 2009. Restrictions on biological adaptation in language evolution. Proceedings of the National Academy of Sciences, 106(4):1015–1020.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Knowledge of language: Its nature, origins, and use.</title>
<date>1986</date>
<location>Greenwood.</location>
<contexts>
<context position="3349" citStr="Chomsky, 1986" startWordPosition="532" endWordPosition="533">rk. 1.1 Theories of origin: the biological aspect There are two main ideas in biological evolution as to why humans developed the capacity to communicate through speech. The first states that language (or more precisely the ability to bear the full structure of language) came as an epiphenomenon, a by-product (spandrel) of an unrelated mutation. This theory assumes that a mental language faculty could not by itself evolve by natural selection; there would simply be too many costly adaptations for it to be possible. Thus there should exist an innate capacity in the form of a universal grammar (Chomsky, 1986), which can hold a finite number of rules enabling us to carry any kind of language. According to the second idea, language emerged in a strictly adaptational process (Pinker and Bloom, 1990). That is, that language evolution can be explained by natural selection, in the same way as the evolution of other complex traits like echolocation in bats or stereopsis in monkeys. Both ideas — innate capacity vs natural selection — have supporters, as well as standpoints that hold both aspects as important, but at different levels (Deacon, 2010; Christiansen and Kirby, 2003). 49 Proc. of 5th Workshop on</context>
</contexts>
<marker>Chomsky, 1986</marker>
<rawString>Noam Chomsky. 1986. Knowledge of language: Its nature, origins, and use. Greenwood.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morten H Christiansen</author>
<author>Simon Kirby</author>
</authors>
<title>Language evolution: consensus and controversies.</title>
<date>2003</date>
<journal>TRENDS in Cognitive Sciences,</journal>
<volume>7</volume>
<issue>7</issue>
<contexts>
<context position="3920" citStr="Christiansen and Kirby, 2003" startWordPosition="625" endWordPosition="628">apacity in the form of a universal grammar (Chomsky, 1986), which can hold a finite number of rules enabling us to carry any kind of language. According to the second idea, language emerged in a strictly adaptational process (Pinker and Bloom, 1990). That is, that language evolution can be explained by natural selection, in the same way as the evolution of other complex traits like echolocation in bats or stereopsis in monkeys. Both ideas — innate capacity vs natural selection — have supporters, as well as standpoints that hold both aspects as important, but at different levels (Deacon, 2010; Christiansen and Kirby, 2003). 49 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 49–54, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics 1.2 Theories of origin: the cultural aspect Biology aside, the forces behind the emergence of human language are not strictly genetic (and do not operate only on a phylogenetic time scale). Kirby (2002) argues that, in addition to biological evolution, there are two more complex adaptive (dynamical) systems influencing natural language; namely cultural evolution (on the glossogenetic time scale</context>
</contexts>
<marker>Christiansen, Kirby, 2003</marker>
<rawString>Morten H. Christiansen and Simon Kirby. 2003. Language evolution: consensus and controversies. TRENDS in Cognitive Sciences, 7(7):300–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rick Dale</author>
<author>Gary Lupyan</author>
</authors>
<title>Understanding the origins of morphological diversity: the linguistic niche hypothesis.</title>
<date>2012</date>
<booktitle>Advances in Complex Systems,</booktitle>
<pages>15--03</pages>
<contexts>
<context position="6248" citStr="Dale and Lupyan, 2012" startWordPosition="994" endWordPosition="997"> evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming colors (Bleys and Steels, 2011; Puglisi et al., 2008), different aspects of morphology (Dale and Lupyan, 2012), and similar. This simplicity is important to keep in mind, since it is conceivable that certain features of language can be highly influenced by other features in real life. A language game simulation (Steels, 1995) is a model where artificial agents interact with each other in turn in order to reach a cooperative goal; to make up a shared language of some sort, all while minimizing their cognitive effort. All agents are to some degree given the cognitive ability to bear language, but not given any prior knowledge of how language should look like or how consensus should unfold. No centralize</context>
</contexts>
<marker>Dale, Lupyan, 2012</marker>
<rawString>Rick Dale and Gary Lupyan. 2012. Understanding the origins of morphological diversity: the linguistic niche hypothesis. Advances in Complex Systems, 15(03n04):1150017.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terrence W Deacon</author>
</authors>
<title>A role for relaxed selection in the evolution of the language capacity.</title>
<date>2010</date>
<booktitle>Proceedings of the National Academy of Sciences, 107(Supplement</booktitle>
<pages>2--9000</pages>
<contexts>
<context position="3889" citStr="Deacon, 2010" startWordPosition="623" endWordPosition="624">st an innate capacity in the form of a universal grammar (Chomsky, 1986), which can hold a finite number of rules enabling us to carry any kind of language. According to the second idea, language emerged in a strictly adaptational process (Pinker and Bloom, 1990). That is, that language evolution can be explained by natural selection, in the same way as the evolution of other complex traits like echolocation in bats or stereopsis in monkeys. Both ideas — innate capacity vs natural selection — have supporters, as well as standpoints that hold both aspects as important, but at different levels (Deacon, 2010; Christiansen and Kirby, 2003). 49 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 49–54, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics 1.2 Theories of origin: the cultural aspect Biology aside, the forces behind the emergence of human language are not strictly genetic (and do not operate only on a phylogenetic time scale). Kirby (2002) argues that, in addition to biological evolution, there are two more complex adaptive (dynamical) systems influencing natural language; namely cultural evolution (</context>
</contexts>
<marker>Deacon, 2010</marker>
<rawString>Terrence W. Deacon. 2010. A role for relaxed selection in the evolution of the language capacity. Proceedings of the National Academy of Sciences, 107(Supplement 2):9000–9006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Evans</author>
<author>Stephen C Levinson</author>
</authors>
<title>The myth of language universals: Language diversity and its importance for cognitive science.</title>
<date>2009</date>
<journal>Behavioral and Brain Sciences,</journal>
<volume>32</volume>
<issue>05</issue>
<contexts>
<context position="1709" citStr="Evans and Levinson, 2009" startWordPosition="253" endWordPosition="256">nguage, this complex medium that distinctly separates humans from animals, has baffled scientists for centuries. While animals also use language, even with a degree of syntax (Kako, 1999), spoken human language exhibits a vastly more complex structure and spacious variation. To understand how language works — how it is used, its origin and fundamentals — our best information sources are the languages alive (and some extinct but documented ones). Depending on definition, there are 6,000–8,000 languages worldwide today, showing extensive diversity of syntax, semantics, phonetics and morphology (Evans and Levinson, 2009). Still, these represent perhaps only 2% of all languages that have ever existed (Pagel, 2000). As this is a rather small window, we want to look back in time. But there is a problem in linguistic history: our reconstruction techniques can only take us back some 6,000 to 7,000 years. Beyond this point, researchers can only speculate on when and how human language evolved: either as a slowly proceeding process starting millions of years (Ma) ago, e.g., 7 Ma ago with the first appearance of cognitive capacity or 2.5 Ma ago with the first manufacture of stone implements; or through some radical c</context>
<context position="5493" citStr="Evans and Levinson, 2009" startWordPosition="874" endWordPosition="877"> grammar or a defense mechanism against a predator) can assimilate into the genetic makeup of a species. Teaching each member in a population the same thing over and over again comes with great cost (time, faulty learning, genetic complexity), and the overall population saves a lot of energy if a learned trait would become innate. On the other hand, there is a cost of genetic assimilation as it can prohibit plasticity in future generations and make individuals less adaptive to unstable environments. There has been much debate recently whether language is a result of the Baldwin effect or not (Evans and Levinson, 2009; Chater et al., 2009; Baronchelli et al., 2012, e.g.), but questions, hypotheses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language</context>
</contexts>
<marker>Evans, Levinson, 2009</marker>
<rawString>Nicholas Evans and Stephen C. Levinson. 2009. The myth of language universals: Language diversity and its importance for cognitive science. Behavioral and Brain Sciences, 32(05):429–448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Gong</author>
<author>Lan Shuai</author>
</authors>
<title>Computer simulation as a scientific approach in evolutionary linguistics. Language Sciences,</title>
<date>2013</date>
<pages>40--12</pages>
<contexts>
<context position="5982" citStr="Gong and Shuai, 2013" startWordPosition="953" endWordPosition="956">vironments. There has been much debate recently whether language is a result of the Baldwin effect or not (Evans and Levinson, 2009; Chater et al., 2009; Baronchelli et al., 2012, e.g.), but questions, hypotheses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming colors (Bleys and Steels, 2011; Puglisi et al., 2008), different aspects of morphology (Dale and Lupyan, 2012), and similar. This simplicity is important to keep in mind, since it is conceivable that certain features of language can be highly influenced by other features in real life. A language game simulation (Steels, 1995) is a model where artificial agents interact with each other in turn in order to reach a cooperative goal; to make up</context>
</contexts>
<marker>Gong, Shuai, 2013</marker>
<rawString>Tao Gong and Lan Shuai. 2013. Computer simulation as a scientific approach in evolutionary linguistics. Language Sciences, 40:12–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Gong</author>
<author>James W Minett</author>
<author>William S-Y Wang</author>
</authors>
<title>Language origin and the effects of individuals popularity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 IEEE Congress on Evolutionary Computation,</booktitle>
<pages>999--1006</pages>
<publisher>IEEE.</publisher>
<location>Vancouver, British Columbia,</location>
<contexts>
<context position="17186" citStr="Gong et al., 2006" startWordPosition="2843" endWordPosition="2846">dying language and its evolution, and can only investigate certain aspects at a time through simplifications and abstractions. As this paper has concentrated on the agent-based models of the field, many studies reflecting such other aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution could be investigated under more realistic geographical</context>
</contexts>
<marker>Gong, Minett, Wang, 2006</marker>
<rawString>Tao Gong, James W. Minett, and William S-Y Wang. 2006. Language origin and the effects of individuals popularity. In Proceedings of the 2006 IEEE Congress on Evolutionary Computation, pages 999– 1006, Vancouver, British Columbia, Jul. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Gong</author>
<author>James W Minett</author>
<author>William S-Y Wang</author>
</authors>
<title>Exploring social structure effect on language evolution based on a computational model.</title>
<date>2008</date>
<journal>Connection Science,</journal>
<pages>20--2</pages>
<contexts>
<context position="17395" citStr="Gong et al., 2008" startWordPosition="2878" endWordPosition="2881"> reflecting such other aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution could be investigated under more realistic geographical and demographical influence, while learning could be analyzed even further in light of social dynamics, as different linguistic phenomena unfold. Quillinan (2006) presented a model concerning how a network of</context>
</contexts>
<marker>Gong, Minett, Wang, 2008</marker>
<rawString>Tao Gong, James W. Minett, and William S-Y Wang. 2008. Exploring social structure effect on language evolution based on a computational model. Connection Science, 20(2-3):135–153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey E Hinton</author>
<author>Steven J Nowlan</author>
</authors>
<title>How learning can guide evolution.</title>
<date>1987</date>
<journal>Complex systems,</journal>
<pages>1--3</pages>
<contexts>
<context position="9123" citStr="Hinton and Nowlan (1987)" startWordPosition="1465" endWordPosition="1468">only topic concerns one specific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spranger, 2013), factual description games (van Trijp, 2012) and action games (Steels and Spranger, 2009), where the agent communication is about objects in a physical environment, about real-world events, and about motoric behaviors, respectively. 50 3 The Baldwin effect in a naming game Several researchers have created simulations to investigate the Baldwin effect, starting with Hinton and Nowlan (1987). Cangelosi and Parisi (2002) simulate agents who evolve a simple grammatical language in order to survive in a world filled with edible and poisonous mushrooms. Munroe and Cangelosi (2002) used this model to pursue the Baldwin effect, with partially blind agents initially having to learn features of edible mushrooms, but with the learned abilities getting more and more assimilated into the genome over the generations. Chater et al. (2009) argue that only stable parts of language may assimilate into the genetic makeup, while variation within the linguistic environment is too unstable to be a t</context>
</contexts>
<marker>Hinton, Nowlan, 1987</marker>
<rawString>Geoffrey E Hinton and Steven J Nowlan. 1987. How learning can guide evolution. Complex systems, 1(3):495–502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Kako</author>
</authors>
<title>Elements of syntax in the systems of three language-trained animals.</title>
<date>1999</date>
<journal>Animal Learning &amp; Behavior,</journal>
<volume>27</volume>
<issue>1</issue>
<contexts>
<context position="1271" citStr="Kako, 1999" startWordPosition="191" endWordPosition="192">l evolution. In particular, the Baldwin effect in a naming game model is elaborated on by describing a set of experimental simulations. This is on-going work and ideas for further investigating the social aspects of language evolution are also discussed. 1 Introduction What is language? It is interesting how we can take a train of thought and transfer this into another person’s mind by pushing the air around us. Human language, this complex medium that distinctly separates humans from animals, has baffled scientists for centuries. While animals also use language, even with a degree of syntax (Kako, 1999), spoken human language exhibits a vastly more complex structure and spacious variation. To understand how language works — how it is used, its origin and fundamentals — our best information sources are the languages alive (and some extinct but documented ones). Depending on definition, there are 6,000–8,000 languages worldwide today, showing extensive diversity of syntax, semantics, phonetics and morphology (Evans and Levinson, 2009). Still, these represent perhaps only 2% of all languages that have ever existed (Pagel, 2000). As this is a rather small window, we want to look back in time. Bu</context>
</contexts>
<marker>Kako, 1999</marker>
<rawString>Edward Kako. 1999. Elements of syntax in the systems of three language-trained animals. Animal Learning &amp; Behavior, 27(1):1–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alkiviadis Kalampokis</author>
<author>Kosmas Kosmidis</author>
<author>Panos Argyrakis</author>
</authors>
<title>Evolution of vocabulary on scalefree and random networks.</title>
<date>2007</date>
<journal>Physica A: Statistical Mechanics and its Applications,</journal>
<volume>379</volume>
<issue>2</issue>
<pages>671</pages>
<contexts>
<context position="17421" citStr="Kalampokis et al., 2007" startWordPosition="2882" endWordPosition="2885">her aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution could be investigated under more realistic geographical and demographical influence, while learning could be analyzed even further in light of social dynamics, as different linguistic phenomena unfold. Quillinan (2006) presented a model concerning how a network of social relationships coul</context>
</contexts>
<marker>Kalampokis, Kosmidis, Argyrakis, 2007</marker>
<rawString>Alkiviadis Kalampokis, Kosmas Kosmidis, and Panos Argyrakis. 2007. Evolution of vocabulary on scalefree and random networks. Physica A: Statistical Mechanics and its Applications, 379(2):665 – 671.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Kirby</author>
</authors>
<title>Natural language from artificial life.</title>
<date>2002</date>
<journal>Artificial Life,</journal>
<volume>8</volume>
<issue>2</issue>
<contexts>
<context position="4325" citStr="Kirby (2002)" startWordPosition="688" endWordPosition="689"> monkeys. Both ideas — innate capacity vs natural selection — have supporters, as well as standpoints that hold both aspects as important, but at different levels (Deacon, 2010; Christiansen and Kirby, 2003). 49 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 49–54, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics 1.2 Theories of origin: the cultural aspect Biology aside, the forces behind the emergence of human language are not strictly genetic (and do not operate only on a phylogenetic time scale). Kirby (2002) argues that, in addition to biological evolution, there are two more complex adaptive (dynamical) systems influencing natural language; namely cultural evolution (on the glossogenetic time scale) and learning (which operates on a individual level, on the ontogenetic time scale). In addition, there is the interesting Darwinian idea that cultural learning can guide biological evolution, a process known as the Baldwin effect (Baldwin, 1896; Simpson, 1953). This theory argues that culturally learned traits (e.g., a universal understanding of grammar or a defense mechanism against a predator) can </context>
<context position="5960" citStr="Kirby, 2002" startWordPosition="951" endWordPosition="952">o unstable environments. There has been much debate recently whether language is a result of the Baldwin effect or not (Evans and Levinson, 2009; Chater et al., 2009; Baronchelli et al., 2012, e.g.), but questions, hypotheses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming colors (Bleys and Steels, 2011; Puglisi et al., 2008), different aspects of morphology (Dale and Lupyan, 2012), and similar. This simplicity is important to keep in mind, since it is conceivable that certain features of language can be highly influenced by other features in real life. A language game simulation (Steels, 1995) is a model where artificial agents interact with each other in turn in order to reach a cooper</context>
</contexts>
<marker>Kirby, 2002</marker>
<rawString>Simon Kirby. 2002. Natural language from artificial life. Artificial Life, 8(2):185–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard G Klein</author>
</authors>
<title>Out of Africa and the evolution of human behavior.</title>
<date>2008</date>
<journal>Evolutionary Anthropology: Issues, News, and Reviews,</journal>
<volume>17</volume>
<issue>6</issue>
<contexts>
<context position="2447" citStr="Klein, 2008" startWordPosition="383" endWordPosition="384">w, we want to look back in time. But there is a problem in linguistic history: our reconstruction techniques can only take us back some 6,000 to 7,000 years. Beyond this point, researchers can only speculate on when and how human language evolved: either as a slowly proceeding process starting millions of years (Ma) ago, e.g., 7 Ma ago with the first appearance of cognitive capacity or 2.5 Ma ago with the first manufacture of stone implements; or through some radical change taking place about 100 ka ago with the appearance of the modern humans or 50–60 ka ago when they started leaving Africa (Klein, 2008; Tattersall, 2010). The rest of this introduction covers some key aspects of language evolution. Section 2 then focuses on computational models within the field, while Section 3 describes a specific naming game model. Finally, Section 4 discusses the results and some ideas for future work. 1.1 Theories of origin: the biological aspect There are two main ideas in biological evolution as to why humans developed the capacity to communicate through speech. The first states that language (or more precisely the ability to bear the full structure of language) came as an epiphenomenon, a by-product (</context>
</contexts>
<marker>Klein, 2008</marker>
<rawString>Richard G. Klein. 2008. Out of Africa and the evolution of human behavior. Evolutionary Anthropology: Issues, News, and Reviews, 17(6):267–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chuang Lei</author>
<author>Jianyuan Jia</author>
<author>Te Wu</author>
<author>Long Wang</author>
</authors>
<title>Coevolution with weights of names in structured language games. Physica A: Statistical Mechanics and its Applications,</title>
<date>2010</date>
<pages>389--24</pages>
<contexts>
<context position="17100" citStr="Lei et al., 2010" startWordPosition="2830" endWordPosition="2833">h numerous variables to consider. Thus we must make a number of assumptions when studying language and its evolution, and can only investigate certain aspects at a time through simplifications and abstractions. As this paper has concentrated on the agent-based models of the field, many studies reflecting such other aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neura</context>
</contexts>
<marker>Lei, Jia, Wu, Wang, 2010</marker>
<rawString>Chuang Lei, Jianyuan Jia, Te Wu, and Long Wang. 2010. Coevolution with weights of names in structured language games. Physica A: Statistical Mechanics and its Applications, 389(24):5628–5634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Li</author>
<author>Guanrong Chen</author>
<author>Tommy W S Chow</author>
</authors>
<title>Naming game with multiple hearers.</title>
<date>2013</date>
<booktitle>Communications in Nonlinear Science and Numerical Simulation,</booktitle>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="17060" citStr="Li et al., 2013" startWordPosition="2823" endWordPosition="2826">anguage is a complex adaptive system with numerous variables to consider. Thus we must make a number of assumptions when studying language and its evolution, and can only investigate certain aspects at a time through simplifications and abstractions. As this paper has concentrated on the agent-based models of the field, many studies reflecting such other aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studi</context>
</contexts>
<marker>Li, Chen, Chow, 2013</marker>
<rawString>Bing Li, Guanrong Chen, and Tommy W.S. Chow. 2013. Naming game with multiple hearers. Communications in Nonlinear Science and Numerical Simulation, 18(5):1214–1228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dorota Lipowska</author>
<author>Adam Lipowski</author>
</authors>
<title>Naming game on adaptive weighted networks.</title>
<date>2012</date>
<journal>Artificial Life,</journal>
<volume>18</volume>
<issue>3</issue>
<contexts>
<context position="17130" citStr="Lipowska and Lipowski, 2012" startWordPosition="2834" endWordPosition="2837">es to consider. Thus we must make a number of assumptions when studying language and its evolution, and can only investigate certain aspects at a time through simplifications and abstractions. As this paper has concentrated on the agent-based models of the field, many studies reflecting such other aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution</context>
</contexts>
<marker>Lipowska, Lipowski, 2012</marker>
<rawString>Dorota Lipowska and Adam Lipowski. 2012. Naming game on adaptive weighted networks. Artificial Life, 18(3):311–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dorota Lipowska</author>
</authors>
<title>Naming game and computational modelling of language evolution.</title>
<date>2011</date>
<booktitle>Computational Methods in Science and Technology,</booktitle>
<volume>17</volume>
<issue>1</issue>
<pages>2--41</pages>
<contexts>
<context position="8119" citStr="Lipowska, 2011" startWordPosition="1311" endWordPosition="1312">t is mostly assumed that there is a fairly direct connection between utterance and actual meaning in language game models (emotions and social situations do not bias how language is interpreted). A simple language game normally is characterized by many synonyms spawning among the agents. As agents commence spreading their own utterances around, high-weighted words start to be preferred. Consensus is reached when all agents know the highest weighted word for each concept. Commonly, the agents aim to reach a single coherent language, but the emergence of multilingualism has also been simulated (Lipowska, 2011; Roberts, 2012). Cultural evolution can be captured by horizontal communication between individuals in the same generation or vertical communication from adults to children. The latter typically lets the agents breed, age and die, with the iterated learning model (Smith et al., 2003) being popular. A variety of language games exist, from simple naming games, where the agents’ only topic concerns one specific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spra</context>
<context position="9916" citStr="Lipowska (2011)" startWordPosition="1590" endWordPosition="1591">losi (2002) used this model to pursue the Baldwin effect, with partially blind agents initially having to learn features of edible mushrooms, but with the learned abilities getting more and more assimilated into the genome over the generations. Chater et al. (2009) argue that only stable parts of language may assimilate into the genetic makeup, while variation within the linguistic environment is too unstable to be a target of natural selection. Watanabe et al. (2008) use a similar model, but in contrast state that genetic assimilation not necessarily requires a stable linguistic environment. Lipowska (2011) has pursued the Baldwin effect in a simple naming game model with the intention of mixing up a language game in a simulation that incorporates both learning, cultural and biological evolution. The model places a set of agents in a square lattice of a linear size L, where every agent is allowed — by a given probability p — to communicate with a random neighbor. At each time step, a random agent is chosen and p initially decides whether the agent is allowed to communicate or will face a “population update”. Every agent has an internal lexicon of N words with associated weights (wj : 1 &lt; j &lt; N).</context>
<context position="12580" citStr="Lipowska (2011)" startWordPosition="2068" endWordPosition="2069">g either inherit the parent’s learning ability or gain a new learning ability, with a probability pm. With the same mutation probability, the off-spring also either gains a new word or inherits the parent’s highest-weight word. This model was implemented with the aim to reproduce Lipowska’s results. She argues that her model is fairly robust to both population size and her given arguments; however, our experiments do not support this: as the Baldwin effect unfold, it does not follow the same abrupt course as in Lipowska’s model. This could be due to some assumptions that had to be made, since Lipowska (2011), for instance, presents no details on how age is calculated. We thus assume that every time an agent is allowed to communicate, its age gets incremented. Another possibility could be to increment every agent’s age at every time step, so that agents get older even if they do not communicate. Furthermore, the initial values for learnability are not clearly stated. Lipowska uses several different values in her analysis. We have used 0.5, which makes a decrease in learnability a part of the evolutionary search space as well. Simulations with parameters similar to those used by Lipowska (2011) [it</context>
<context position="15928" citStr="Lipowska (2011)" startWordPosition="2637" endWordPosition="2638">gure 4, the agents rapidly get to a stable weighted lexicon before the Baldwin effect shows itself around time step 100k. As mentioned, Lipowska’s model did not reflect the robustness argued in her paper: for other values of p, the number of empty spots in the population lattice starts to diverge substantially, and for some values all agents simply die. As population sizes vary, the number of iterations must also be adjusted to get similar results. If not, the agents will not reach the same population turn-over as for smaller population sizes since only one agent may be updated per iteration. Lipowska (2011) compensated with higher mutation rate on simulations with different population sizes; however, these could be two variables somewhat more independent of each other. The model would have been much more stable if it contained aspects of a typical genetic algorithm, where agents are allowed to interact freely within generations. This way, the model could be acting more upon natural selection (and in search of the Baldwin effect), instead of relying on well-chosen parameters to work. 4 Discussion and future work Language is a complex adaptive system with numerous variables to consider. Thus we mu</context>
</contexts>
<marker>Lipowska, 2011</marker>
<rawString>Dorota Lipowska. 2011. Naming game and computational modelling of language evolution. Computational Methods in Science and Technology, 17(1– 2):41–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Munroe</author>
<author>Angelo Cangelosi</author>
</authors>
<title>Learning and the evolution of language: the role of cultural variation and learning costs in the Baldwin effect.</title>
<date>2002</date>
<journal>Artificial Life,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="9312" citStr="Munroe and Cangelosi (2002)" startWordPosition="1494" endWordPosition="1497">ction, such as spatial games (Spranger, 2013), factual description games (van Trijp, 2012) and action games (Steels and Spranger, 2009), where the agent communication is about objects in a physical environment, about real-world events, and about motoric behaviors, respectively. 50 3 The Baldwin effect in a naming game Several researchers have created simulations to investigate the Baldwin effect, starting with Hinton and Nowlan (1987). Cangelosi and Parisi (2002) simulate agents who evolve a simple grammatical language in order to survive in a world filled with edible and poisonous mushrooms. Munroe and Cangelosi (2002) used this model to pursue the Baldwin effect, with partially blind agents initially having to learn features of edible mushrooms, but with the learned abilities getting more and more assimilated into the genome over the generations. Chater et al. (2009) argue that only stable parts of language may assimilate into the genetic makeup, while variation within the linguistic environment is too unstable to be a target of natural selection. Watanabe et al. (2008) use a similar model, but in contrast state that genetic assimilation not necessarily requires a stable linguistic environment. Lipowska (2</context>
</contexts>
<marker>Munroe, Cangelosi, 2002</marker>
<rawString>Steve Munroe and Angelo Cangelosi. 2002. Learning and the evolution of language: the role of cultural variation and learning costs in the Baldwin effect. Artificial Life, 8(4):311–339.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Pagel</author>
</authors>
<title>The history, rate and pattern of world linguistic evolution.</title>
<date>2000</date>
<booktitle>The Evolutionary Emergence of Language: Social Function and the Origins of Linguistic Form, chapter 22,</booktitle>
<pages>391--416</pages>
<editor>In Ch. Knight, J.R. Hurford, and M. Studdert-Kennedy, editors,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1803" citStr="Pagel, 2000" startWordPosition="270" endWordPosition="271">ries. While animals also use language, even with a degree of syntax (Kako, 1999), spoken human language exhibits a vastly more complex structure and spacious variation. To understand how language works — how it is used, its origin and fundamentals — our best information sources are the languages alive (and some extinct but documented ones). Depending on definition, there are 6,000–8,000 languages worldwide today, showing extensive diversity of syntax, semantics, phonetics and morphology (Evans and Levinson, 2009). Still, these represent perhaps only 2% of all languages that have ever existed (Pagel, 2000). As this is a rather small window, we want to look back in time. But there is a problem in linguistic history: our reconstruction techniques can only take us back some 6,000 to 7,000 years. Beyond this point, researchers can only speculate on when and how human language evolved: either as a slowly proceeding process starting millions of years (Ma) ago, e.g., 7 Ma ago with the first appearance of cognitive capacity or 2.5 Ma ago with the first manufacture of stone implements; or through some radical change taking place about 100 ka ago with the appearance of the modern humans or 50–60 ka ago w</context>
</contexts>
<marker>Pagel, 2000</marker>
<rawString>Mark Pagel. 2000. The history, rate and pattern of world linguistic evolution. In Ch. Knight, J.R. Hurford, and M. Studdert-Kennedy, editors, The Evolutionary Emergence of Language: Social Function and the Origins of Linguistic Form, chapter 22, pages 391–416. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Patriarca</author>
<author>Els Heinsalu</author>
</authors>
<title>Influence of geography on language competition. Physica A: Statistical Mechanics and its Applications,</title>
<date>2009</date>
<volume>388</volume>
<issue>2</issue>
<pages>3--174</pages>
<contexts>
<context position="17478" citStr="Patriarca and Heinsalu, 2009" startWordPosition="2890" endWordPosition="2893">as lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution could be investigated under more realistic geographical and demographical influence, while learning could be analyzed even further in light of social dynamics, as different linguistic phenomena unfold. Quillinan (2006) presented a model concerning how a network of social relationships could evolve with language traits. This model could be taken </context>
</contexts>
<marker>Patriarca, Heinsalu, 2009</marker>
<rawString>Marco Patriarca and Els Heinsalu. 2009. Influence of geography on language competition. Physica A: Statistical Mechanics and its Applications, 388(2– 3):174–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Pinker</author>
<author>Paul Bloom</author>
</authors>
<title>Natural language and natural selection.</title>
<date>1990</date>
<booktitle>Behavioral and Brain Sciences,</booktitle>
<pages>13--707</pages>
<contexts>
<context position="3540" citStr="Pinker and Bloom, 1990" startWordPosition="562" endWordPosition="565">ates that language (or more precisely the ability to bear the full structure of language) came as an epiphenomenon, a by-product (spandrel) of an unrelated mutation. This theory assumes that a mental language faculty could not by itself evolve by natural selection; there would simply be too many costly adaptations for it to be possible. Thus there should exist an innate capacity in the form of a universal grammar (Chomsky, 1986), which can hold a finite number of rules enabling us to carry any kind of language. According to the second idea, language emerged in a strictly adaptational process (Pinker and Bloom, 1990). That is, that language evolution can be explained by natural selection, in the same way as the evolution of other complex traits like echolocation in bats or stereopsis in monkeys. Both ideas — innate capacity vs natural selection — have supporters, as well as standpoints that hold both aspects as important, but at different levels (Deacon, 2010; Christiansen and Kirby, 2003). 49 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 49–54, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics 1.2 Theories of o</context>
</contexts>
<marker>Pinker, Bloom, 1990</marker>
<rawString>Steven Pinker and Paul Bloom. 1990. Natural language and natural selection. Behavioral and Brain Sciences, 13:707–784.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Puglisi</author>
<author>Andrea Baronchelli</author>
<author>Vittorio Loreto</author>
</authors>
<title>Cultural route to the emergence of linguistic categories.</title>
<date>2008</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>105</volume>
<issue>23</issue>
<contexts>
<context position="6191" citStr="Puglisi et al., 2008" startWordPosition="986" endWordPosition="989">eses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming colors (Bleys and Steels, 2011; Puglisi et al., 2008), different aspects of morphology (Dale and Lupyan, 2012), and similar. This simplicity is important to keep in mind, since it is conceivable that certain features of language can be highly influenced by other features in real life. A language game simulation (Steels, 1995) is a model where artificial agents interact with each other in turn in order to reach a cooperative goal; to make up a shared language of some sort, all while minimizing their cognitive effort. All agents are to some degree given the cognitive ability to bear language, but not given any prior knowledge of how language shoul</context>
</contexts>
<marker>Puglisi, Baronchelli, Loreto, 2008</marker>
<rawString>Andrea Puglisi, Andrea Baronchelli, and Vittorio Loreto. 2008. Cultural route to the emergence of linguistic categories. Proceedings of the National Academy of Sciences, 105(23):7936–7940.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Quillinan</author>
</authors>
<title>Social networks and cultural transmission. Master of Science Thesis,</title>
<date>2006</date>
<institution>School of Philosophy, Psychology and Language Sciences, University of Edinburgh,</institution>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="17949" citStr="Quillinan (2006)" startWordPosition="2960" endWordPosition="2961">nd few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution could be investigated under more realistic geographical and demographical influence, while learning could be analyzed even further in light of social dynamics, as different linguistic phenomena unfold. Quillinan (2006) presented a model concerning how a network of social relationships could evolve with language traits. This model could be taken further in combination with existing language games or it could be used to show how language responds to an exposure of continuous change in a complex social network. Notably, many present models have a rather naive way of selecting cultural parents, and a genetic algorithm for giving fitness to agents in terms of having (assimilated) the best strategies for learning (e.g., memory efficiency), social conventions (e.g., emotions, popularity), and/or simple or more adv</context>
</contexts>
<marker>Quillinan, 2006</marker>
<rawString>Justin Quillinan. 2006. Social networks and cultural transmission. Master of Science Thesis, School of Philosophy, Psychology and Language Sciences, University of Edinburgh, Edinburgh, Scotland, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Geraint Roberts</author>
</authors>
<title>An evolutionary approach to bilingualism.</title>
<date>2012</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Philosophy, Psychology and Language Sciences, University of Edinburgh,</institution>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="8135" citStr="Roberts, 2012" startWordPosition="1313" endWordPosition="1314">med that there is a fairly direct connection between utterance and actual meaning in language game models (emotions and social situations do not bias how language is interpreted). A simple language game normally is characterized by many synonyms spawning among the agents. As agents commence spreading their own utterances around, high-weighted words start to be preferred. Consensus is reached when all agents know the highest weighted word for each concept. Commonly, the agents aim to reach a single coherent language, but the emergence of multilingualism has also been simulated (Lipowska, 2011; Roberts, 2012). Cultural evolution can be captured by horizontal communication between individuals in the same generation or vertical communication from adults to children. The latter typically lets the agents breed, age and die, with the iterated learning model (Smith et al., 2003) being popular. A variety of language games exist, from simple naming games, where the agents’ only topic concerns one specific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spranger, 2013), fac</context>
</contexts>
<marker>Roberts, 2012</marker>
<rawString>Sean Geraint Roberts. 2012. An evolutionary approach to bilingualism. Ph.D. thesis, School of Philosophy, Psychology and Language Sciences, University of Edinburgh, Edinburgh, Scotland, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Gaylord Simpson</author>
</authors>
<title>The Baldwin effect.</title>
<date>1953</date>
<journal>Evolution,</journal>
<volume>7</volume>
<issue>2</issue>
<contexts>
<context position="4782" citStr="Simpson, 1953" startWordPosition="754" endWordPosition="755">iology aside, the forces behind the emergence of human language are not strictly genetic (and do not operate only on a phylogenetic time scale). Kirby (2002) argues that, in addition to biological evolution, there are two more complex adaptive (dynamical) systems influencing natural language; namely cultural evolution (on the glossogenetic time scale) and learning (which operates on a individual level, on the ontogenetic time scale). In addition, there is the interesting Darwinian idea that cultural learning can guide biological evolution, a process known as the Baldwin effect (Baldwin, 1896; Simpson, 1953). This theory argues that culturally learned traits (e.g., a universal understanding of grammar or a defense mechanism against a predator) can assimilate into the genetic makeup of a species. Teaching each member in a population the same thing over and over again comes with great cost (time, faulty learning, genetic complexity), and the overall population saves a lot of energy if a learned trait would become innate. On the other hand, there is a cost of genetic assimilation as it can prohibit plasticity in future generations and make individuals less adaptive to unstable environments. There ha</context>
</contexts>
<marker>Simpson, 1953</marker>
<rawString>George Gaylord Simpson. 1953. The Baldwin effect. Evolution, 7(2):110–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenny Smith</author>
<author>Simon Kirby</author>
<author>Henry Brighton</author>
</authors>
<title>Iterated learning: A framework for the emergence of language.</title>
<date>2003</date>
<journal>Artificial Life,</journal>
<volume>9</volume>
<issue>4</issue>
<contexts>
<context position="8404" citStr="Smith et al., 2003" startWordPosition="1352" endWordPosition="1355"> agents. As agents commence spreading their own utterances around, high-weighted words start to be preferred. Consensus is reached when all agents know the highest weighted word for each concept. Commonly, the agents aim to reach a single coherent language, but the emergence of multilingualism has also been simulated (Lipowska, 2011; Roberts, 2012). Cultural evolution can be captured by horizontal communication between individuals in the same generation or vertical communication from adults to children. The latter typically lets the agents breed, age and die, with the iterated learning model (Smith et al., 2003) being popular. A variety of language games exist, from simple naming games, where the agents’ only topic concerns one specific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spranger, 2013), factual description games (van Trijp, 2012) and action games (Steels and Spranger, 2009), where the agent communication is about objects in a physical environment, about real-world events, and about motoric behaviors, respectively. 50 3 The Baldwin effect in a naming game</context>
</contexts>
<marker>Smith, Kirby, Brighton, 2003</marker>
<rawString>Kenny Smith, Simon Kirby, and Henry Brighton. 2003. Iterated learning: A framework for the emergence of language. Artificial Life, 9(4):371–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Spranger</author>
</authors>
<title>Evolving grounded spatial language strategies. KI-K¨unstliche Intelligenz,</title>
<date>2013</date>
<contexts>
<context position="8730" citStr="Spranger, 2013" startWordPosition="1407" endWordPosition="1408">2011; Roberts, 2012). Cultural evolution can be captured by horizontal communication between individuals in the same generation or vertical communication from adults to children. The latter typically lets the agents breed, age and die, with the iterated learning model (Smith et al., 2003) being popular. A variety of language games exist, from simple naming games, where the agents’ only topic concerns one specific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spranger, 2013), factual description games (van Trijp, 2012) and action games (Steels and Spranger, 2009), where the agent communication is about objects in a physical environment, about real-world events, and about motoric behaviors, respectively. 50 3 The Baldwin effect in a naming game Several researchers have created simulations to investigate the Baldwin effect, starting with Hinton and Nowlan (1987). Cangelosi and Parisi (2002) simulate agents who evolve a simple grammatical language in order to survive in a world filled with edible and poisonous mushrooms. Munroe and Cangelosi (2002) used this model t</context>
</contexts>
<marker>Spranger, 2013</marker>
<rawString>Michael Spranger. 2013. Evolving grounded spatial language strategies. KI-K¨unstliche Intelligenz, 27(2):1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luc Steels</author>
<author>Martin Loetzsch</author>
</authors>
<title>The grounded naming game.</title>
<date>2012</date>
<booktitle>Experiments in Cultural Language Evolution,</booktitle>
<pages>41--59</pages>
<editor>In L. Steels, editor,</editor>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="8618" citStr="Steels and Loetzsch, 2012" startWordPosition="1385" endWordPosition="1389">he agents aim to reach a single coherent language, but the emergence of multilingualism has also been simulated (Lipowska, 2011; Roberts, 2012). Cultural evolution can be captured by horizontal communication between individuals in the same generation or vertical communication from adults to children. The latter typically lets the agents breed, age and die, with the iterated learning model (Smith et al., 2003) being popular. A variety of language games exist, from simple naming games, where the agents’ only topic concerns one specific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spranger, 2013), factual description games (van Trijp, 2012) and action games (Steels and Spranger, 2009), where the agent communication is about objects in a physical environment, about real-world events, and about motoric behaviors, respectively. 50 3 The Baldwin effect in a naming game Several researchers have created simulations to investigate the Baldwin effect, starting with Hinton and Nowlan (1987). Cangelosi and Parisi (2002) simulate agents who evolve a simple grammatical language in order</context>
</contexts>
<marker>Steels, Loetzsch, 2012</marker>
<rawString>Luc Steels and Martin Loetzsch. 2012. The grounded naming game. In L. Steels, editor, Experiments in Cultural Language Evolution, pages 41–59. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luc Steels</author>
<author>Michael Spranger</author>
</authors>
<title>How experience of the body shapes language about space.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st International Joint Conference on Artificial Intelligence,</booktitle>
<pages>14--19</pages>
<publisher>IJCAI.</publisher>
<location>Pasadena, California,</location>
<contexts>
<context position="8820" citStr="Steels and Spranger, 2009" startWordPosition="1418" endWordPosition="1421">ation between individuals in the same generation or vertical communication from adults to children. The latter typically lets the agents breed, age and die, with the iterated learning model (Smith et al., 2003) being popular. A variety of language games exist, from simple naming games, where the agents’ only topic concerns one specific object (Lipowska, 2011), to more cognitive grounding games (Steels and Loetzsch, 2012). There have also been studies on some more complex types of interaction, such as spatial games (Spranger, 2013), factual description games (van Trijp, 2012) and action games (Steels and Spranger, 2009), where the agent communication is about objects in a physical environment, about real-world events, and about motoric behaviors, respectively. 50 3 The Baldwin effect in a naming game Several researchers have created simulations to investigate the Baldwin effect, starting with Hinton and Nowlan (1987). Cangelosi and Parisi (2002) simulate agents who evolve a simple grammatical language in order to survive in a world filled with edible and poisonous mushrooms. Munroe and Cangelosi (2002) used this model to pursue the Baldwin effect, with partially blind agents initially having to learn feature</context>
</contexts>
<marker>Steels, Spranger, 2009</marker>
<rawString>Luc Steels and Michael Spranger. 2009. How experience of the body shapes language about space. In Proceedings of the 21st International Joint Conference on Artificial Intelligence, pages 14–19, Pasadena, California, Jul. IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luc Steels</author>
</authors>
<title>A self-organizing spatial vocabulary.</title>
<date>1995</date>
<journal>Artificial Life,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="6465" citStr="Steels, 1995" startWordPosition="1033" endWordPosition="1034"> respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming colors (Bleys and Steels, 2011; Puglisi et al., 2008), different aspects of morphology (Dale and Lupyan, 2012), and similar. This simplicity is important to keep in mind, since it is conceivable that certain features of language can be highly influenced by other features in real life. A language game simulation (Steels, 1995) is a model where artificial agents interact with each other in turn in order to reach a cooperative goal; to make up a shared language of some sort, all while minimizing their cognitive effort. All agents are to some degree given the cognitive ability to bear language, but not given any prior knowledge of how language should look like or how consensus should unfold. No centralized anchors are involved: a simulation is all self-organized. Agents are chosen (mostly at random) as hearer and speaker, and made to exchange an utterance about a certain arbitrary concept or meaning in their environme</context>
</contexts>
<marker>Steels, 1995</marker>
<rawString>Luc Steels. 1995. A self-organizing spatial vocabulary. Artificial Life, 2(3):319–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luc Steels</author>
</authors>
<title>Modeling the cultural evolution of language.</title>
<date>2011</date>
<journal>Physics of Life Reviews,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="5947" citStr="Steels, 2011" startWordPosition="949" endWordPosition="950">ess adaptive to unstable environments. There has been much debate recently whether language is a result of the Baldwin effect or not (Evans and Levinson, 2009; Chater et al., 2009; Baronchelli et al., 2012, e.g.), but questions, hypotheses, and simulations fly in both directions. 2 Language evolution and computation Since the 90s, there has been much work on simulation of language evolution in bottom-up systems with populations of autonomous agents. The field is highly influenced by the work of Steels and Kirby, respectively, and has been summarized and reviewed both by themselves and others (Steels, 2011; Kirby, 2002; Gong and Shuai, 2013, e.g.). Computational research in this field is limited to modeling very simplified features of human language in isolation, such as strategies for naming colors (Bleys and Steels, 2011; Puglisi et al., 2008), different aspects of morphology (Dale and Lupyan, 2012), and similar. This simplicity is important to keep in mind, since it is conceivable that certain features of language can be highly influenced by other features in real life. A language game simulation (Steels, 1995) is a model where artificial agents interact with each other in turn in order to r</context>
</contexts>
<marker>Steels, 2011</marker>
<rawString>Luc Steels. 2011. Modeling the cultural evolution of language. Physics of Life Reviews, 8(4):339–356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Tattersall</author>
</authors>
<title>Human evolution and cognition. Theory in Biosciences,</title>
<date>2010</date>
<pages>129--2</pages>
<contexts>
<context position="2466" citStr="Tattersall, 2010" startWordPosition="385" endWordPosition="386"> look back in time. But there is a problem in linguistic history: our reconstruction techniques can only take us back some 6,000 to 7,000 years. Beyond this point, researchers can only speculate on when and how human language evolved: either as a slowly proceeding process starting millions of years (Ma) ago, e.g., 7 Ma ago with the first appearance of cognitive capacity or 2.5 Ma ago with the first manufacture of stone implements; or through some radical change taking place about 100 ka ago with the appearance of the modern humans or 50–60 ka ago when they started leaving Africa (Klein, 2008; Tattersall, 2010). The rest of this introduction covers some key aspects of language evolution. Section 2 then focuses on computational models within the field, while Section 3 describes a specific naming game model. Finally, Section 4 discusses the results and some ideas for future work. 1.1 Theories of origin: the biological aspect There are two main ideas in biological evolution as to why humans developed the capacity to communicate through speech. The first states that language (or more precisely the ability to bear the full structure of language) came as an epiphenomenon, a by-product (spandrel) of an unr</context>
</contexts>
<marker>Tattersall, 2010</marker>
<rawString>Ian Tattersall. 2010. Human evolution and cognition. Theory in Biosciences, 129(2–3):193–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi van Trijp</author>
</authors>
<title>The evolution of case systems for marking event structure. In</title>
<date>2012</date>
<booktitle>Experiments in Cultural Language Evolution,</booktitle>
<pages>169--205</pages>
<editor>L. Steels, editor,</editor>
<publisher>John Benjamins.</publisher>
<marker>van Trijp, 2012</marker>
<rawString>Remi van Trijp. 2012. The evolution of case systems for marking event structure. In L. Steels, editor, Experiments in Cultural Language Evolution, pages 169–205. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Vogt</author>
</authors>
<title>Group size effects on the emergence of compositional structures in language.</title>
<date>2007</date>
<booktitle>Advances in Artificial Life: Proceedings of the 9th European Conference (ECAL 2007),</booktitle>
<pages>405--414</pages>
<editor>In F. Almeida e Costa, L.M. Rocha, E. Costa, I Harvey, and A. Coutinho, editors,</editor>
<publisher>Springer.</publisher>
<location>Lisbon, Portugal,</location>
<contexts>
<context position="17329" citStr="Vogt, 2007" startWordPosition="2867" endWordPosition="2868">ntrated on the agent-based models of the field, many studies reflecting such other aspects had to be left out. In addition, there has lately been a lot of work studying small adjustments to the agent-based models, in order to make them more realistic by, for example, having multiple hearers in a language game conversations (Li et al., 2013), different topologies (Lei et al., 2010; Lipowska and Lipowski, 2012), and more heterogeneous populations (Gong et al., 2006). 52 In general, though, simulations on language evolution tend to have relatively small and fixed sizes (Baronchelli et al., 2006; Vogt, 2007) — and few studies seem to take social dynamics (Gong et al., 2008; Kalampokis et al., 2007) or geography into account (Patriarca and Heinsalu, 2009). Further work is still needed to make existing models more realistic and to analyze relations between different models (e.g., by combining them). Biological evolution could be studied with more flexible (or plastic) neural networks. Cultural evolution could be investigated under more realistic geographical and demographical influence, while learning could be analyzed even further in light of social dynamics, as different linguistic phenomena unfo</context>
</contexts>
<marker>Vogt, 2007</marker>
<rawString>Paul Vogt. 2007. Group size effects on the emergence of compositional structures in language. In F. Almeida e Costa, L.M. Rocha, E. Costa, I Harvey, and A. Coutinho, editors, Advances in Artificial Life: Proceedings of the 9th European Conference (ECAL 2007), pages 405–414, Lisbon, Portugal, Sep. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Watanabe</author>
<author>Reiji Suzuki</author>
<author>Takaya Arita</author>
</authors>
<title>Language evolution and the Baldwin effect.</title>
<date>2008</date>
<journal>Artificial Life and Robotics,</journal>
<pages>12--1</pages>
<contexts>
<context position="9773" citStr="Watanabe et al. (2008)" startWordPosition="1567" endWordPosition="1570">) simulate agents who evolve a simple grammatical language in order to survive in a world filled with edible and poisonous mushrooms. Munroe and Cangelosi (2002) used this model to pursue the Baldwin effect, with partially blind agents initially having to learn features of edible mushrooms, but with the learned abilities getting more and more assimilated into the genome over the generations. Chater et al. (2009) argue that only stable parts of language may assimilate into the genetic makeup, while variation within the linguistic environment is too unstable to be a target of natural selection. Watanabe et al. (2008) use a similar model, but in contrast state that genetic assimilation not necessarily requires a stable linguistic environment. Lipowska (2011) has pursued the Baldwin effect in a simple naming game model with the intention of mixing up a language game in a simulation that incorporates both learning, cultural and biological evolution. The model places a set of agents in a square lattice of a linear size L, where every agent is allowed — by a given probability p — to communicate with a random neighbor. At each time step, a random agent is chosen and p initially decides whether the agent is allo</context>
</contexts>
<marker>Watanabe, Suzuki, Arita, 2008</marker>
<rawString>Yusuke Watanabe, Reiji Suzuki, and Takaya Arita. 2008. Language evolution and the Baldwin effect. Artificial Life and Robotics, 12(1-2):65–69.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>