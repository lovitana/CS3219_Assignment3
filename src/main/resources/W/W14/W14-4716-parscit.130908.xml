<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000341">
<title confidence="0.997548">
A Computational Approach to Generate a Sensorial Lexicon
</title>
<author confidence="0.726054">
Serra Sinem Tekiroğlu
</author>
<affiliation confidence="0.534855">
FBK-Irst
</affiliation>
<address confidence="0.3812105">
Via Sommarive 18
Povo, I-38100 Trento
</address>
<email confidence="0.983249">
tekiroglu@fbk.eu
</email>
<note confidence="0.64086225">
Gözde Özbal
Trento RISE
Via Sommarive 18
Povo, I-38100 Trento
</note>
<email confidence="0.98162">
gozbalde@gmail.com
</email>
<author confidence="0.679874">
Carlo Strapparava
</author>
<affiliation confidence="0.497369">
FBK-Irst
</affiliation>
<address confidence="0.3607645">
Via Sommarive 18
Povo, I-38100 Trento
</address>
<email confidence="0.992062">
strappa@fbk.eu
</email>
<sectionHeader confidence="0.993705" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999965090909091">
While humans are capable of building connections between words and sensorial modalities by
using commonsense knowledge, it is not straightforward for machines to interpret sensorial in-
formation. To this end, a lexicon associating words with human senses, namely sight, hearing,
taste, smell and touch, would be crucial. Nonetheless, to the best of our knowledge, there is no
systematic attempt in the literature to build such a resource. In this paper, we propose a compu-
tational method based on bootstrapping and corpus statistics to automatically associate English
words with senses. To evaluate the quality of the resulting lexicon, we create a gold standard via
crowdsourcing and show that a simple classifier relying on the lexicon outperforms two base-
lines on a sensory classification task, both at word and sentence level. The results confirm the
soundness of the proposed approach for the construction of the lexicon and the usefulness of the
resource for computational applications.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.959578884615385">
The connection between our senses and the way we perceive the world has been an important philosophi-
cal topic for centuries. According to a classification that dates back to Aristotle (Johansen, 1997), senses
can be categorized as sight, hearing, taste, smell and touch. With the help of perception, we can process
the data coming from our sensory receptors and become aware of our environment. While interpreting
sensory data, we unconsciously use our existing knowledge, experience and understanding of the world
to create a private experience (Bernstein, 2010).
Language has a significant role as our main communication device to convert our private experiences
to shared representations of the environment that we perceive (Majid and Levinson, 2011). As a basic
example, giving a name to a color, such as red, provides a tool to describe a visual feature of an object.
In addition to the words which describe the direct sensorial features of objects, languages include many
other lexical items that are connected to sense modalities in various semantic roles. For instance, while
some words can be used to describe a perception activity (e.g., to smell, to gaze, to listen), others can
simply be physical phenomenons that can be perceived by sensory receptors (e.g., flower, fire, sugar).
Common usage of language can be very dense in terms of sensorial words. As an example, the sentence
“I tasted a delicious soup.” contains three sensorial words: to taste as a perception activity, delicious as
a perceived sensorial feature and soup as a physical phenomenon. While we, as humans, have the ability
to connect words with senses intuitively by using our commonsense knowledge, it is not straightforward
for machines to interpret sensorial information.
From a computational point of view, a sensorial lexicon could be useful for many scenarios. Rodriguez-
Esteban and Rzhetsky (2008) report that using words related to human senses in a piece of text could
clarify the meaning of an abstract concept by facilitating a more concrete imagination. Based on this
result, an existing text could be automatically modified with sensory words for various purposes such
as attracting attention or biasing the audience towards a specific concept. In addition, sensory words
can be utilized to affect private psychology by inducing a positive or negative sentiment (Majid and
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http:// creativecommons.org/licenses/by/4.0/
</bodyText>
<page confidence="0.956074">
114
</page>
<note confidence="0.927417666666667">
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 114–125,
Dublin, Ireland, August 23, 2014.
Levinson, 2011). As an example, de Araujo et al. (2005) show that the pleasantness level of the same
odor can be altered by labeling it as body odor or cheddar cheese. As another motivation, the readability
and understandability of text could also be enhanced by using sensory words (Rodriguez-Esteban and
Rzhetsky, 2008).
</note>
<bodyText confidence="0.99767852">
Yet another area which would benefit from such a resource is advertisement especially by using synaes-
thesia1, as it reinforces creative thinking and it is commonly exploited as an imagination boosting tool in
advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow”
where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and
hearing are merged.
There are various studies both in computational linguistics and cognitive science that build resources
associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981;
Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors
(Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our
knowledge, there is no attempt in the literature to build a resource that associates words with senses.
In this paper, we propose a computational method to automatically generate a sensorial lexicon2 that
associates words in English with senses. Our method consists of two main steps. First, we generate the
initial seed words for each sense category with the help of a bootstrapping approach. Then, we exploit a
corpus based probabilistic technique to create the final lexicon. We evaluate this resource with the help
of a gold standard that we obtain by using the crowdsourcing service provided by CrowdFlower3.
The sensorial lexicon embodies 22,684 English lemmas together with their part-of-speech (POS) in-
formation that have been linked to one or more of the five senses. Each entry in this lexicon consists of a
lemma-POS pair and a score for each sense that indicates the degree of association. For instance, the verb
stink has the highest score for smell as expected while the scores for the other four senses are very low.
The noun tree, which is a concrete object and might be perceived by multiple senses, has high scores for
sight, touch and smell.
The rest of the paper is organized as follows. We first review previous work relevant to this task in
Section 2. Then in Section 3, we describe the proposed approach in detail. In Section 4, we explain the
annotation process that we conducted and the evaluation strategy that we adopted. Finally, in Section 4,
we draw our conclusions and outline possible future directions.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9997628125">
Since to the best of our knowledge there is no attempt in the literature to automatically associate words
with human senses, in this section we will summarize the most relevant studies that focused on linking
words with various other cognitive features.
There are several studies dealing with word-emotion associations. WordNet Affect Lexicon (Strap-
parava and Valitutti, 2004) maps WordNet (Fellbaum, 1998) synsets to various cognitive features (e.g.,
emotion, mood, behaviour). This resource is created by using a small set of synsets as seeds and expand-
ing them with the help of semantic and lexical relations among these synsets. Yang et al. (2007) propose
a collocation model with emoticons instead of seed words while creating an emotion lexicon from a cor-
pus. Perrie et al. (2013) build a word-emotion association lexicon by using subsets of a human-annotated
lexicon as seed sets. The authors use frequencies, counts, or unique seed words extracted from an n-
gram corpus to create lexicons in different sizes. They propose that larger lexicons with less accurate
generation method perform better than the smaller human annotated lexicons. While a major drawback
of manually generated lexicons is that they require a great deal of human labor, crowdsourcing services
provide an easier procedure for manual annotations. Mohammad and Turney (2010) generate an emotion
lexicon by using the crowdsourcing service provided by Amazon Mechanical Turk4 and it covers 14,200
term-emotion associations.
</bodyText>
<footnote confidence="0.9995706">
1American Heritage Dictionary (http://ahdictionary.com/) defines synaesthesia in linguistics as the description of one
kind of sense impression by using words that normally describe another.
2The sensorial lexicon is publicly available, upon request to the authors.
3http://www.crowdflower.com/
4http://www.mturk.com/mturk
</footnote>
<page confidence="0.9988">
115
</page>
<bodyText confidence="0.999963611111111">
Regarding the sentiment orientations and subjectivity levels of words, Sentiwordnet (Esuli and Sebas-
tiani, 2006) is constructed as an extension to WordNet and it provides sentiments in synset level. Positive,
negative and neutral values are assigned to synsets by using ternary classifiers and synset glosses. An-
other study that has been inspirational for the design of our approach is Banea et al. (2008). The authors
generate a subjectivity lexicon starting with a set of seed words and then using a similarity measure among
the seeds and the candidate words.
Concerning the association between colors and words, Mohammad (2011) builds a color-word asso-
ciation lexicon by organizing a crowdsourcing task on Amazon Mechanical Turk. Instead, Özbal et al.
(2011) aim to automate this process and propose three computational methods based on image analysis,
language models and latent semantic analysis (LSA) (Landauer and Dumais, 1997). The authors com-
pare these methods against a gold standard obtained by the crowdsourcing service of Amazon Mechanical
Turk. The best performance is obtained by using image features while LSA performs slightly better than
the baseline.
Finally, there have been efforts in the literature about the association of words with their abstractness-
concreteness and imageability levels. MRC Psycholinguistic Database (Coltheart, 1981) includes
abstractness-concreteness and imageability ratings of a small set of words determined according to psy-
cholinguistic experiments. Turney et al. (2011) propose to use LSA similarities of words with a set of
seed words to automatically calculate the abstractness and concreteness degrees of words.
</bodyText>
<sectionHeader confidence="0.936733" genericHeader="method">
3 Automatically Associating Senses with Words
</sectionHeader>
<bodyText confidence="0.99998425">
We adopt a two phased computational approach to construct a large sensorial lexicon. First, we employ a
bootstrapping strategy to generate a sufficient number of sensory seed words from a small set of manually
selected seed words. In the second phase, we perform a corpus based probabilistic method to estimate
the association scores to build a larger lexicon.
</bodyText>
<subsectionHeader confidence="0.999876">
3.1 Selecting Seed Words
</subsectionHeader>
<bodyText confidence="0.999996133333333">
The first phase of the lexicon construction process aims to collect sensorial seed words, which are directly
related to senses (e.g., sound, tasty and sightedness). To achieve that, we utilized a lexical database called
FrameNet (Baker et al., 1998), which is built upon semantic frames of concepts in English and lexical
units (i.e., words) that evoke these frames. The basic idea behind this resource is that meanings of words
can be understood on the basis of a semantic frame. A semantic frame consists of semantic roles called
frame elements, which are manually annotated in more than 170,000 sentences. We have considered
FrameNet to be especially suitable for the collection of sensorial seed words since it includes semantic
roles and syntactic features of sensational and perceptional concepts.
In order to determine the seed lemma-POS pairs in FrameNet, we first manually determined 31
frames that we found to be highly connected to senses such as Hear, Color, Temperature and Percep-
tion_experience. Then, we conducted an annotation task and asked 3 annotators to determine which
senses the lemma-POS pairs evoking the collected frames are associated with. At the end of this task, we
collected all the pairs (i.e., 277) with 100% agreement to constitute our initial seed set. This set contains
277 lemma-POS pairs associated with a specific sense such as the verb click with hearing, the noun glitter
with sight and aromatic with smell.
</bodyText>
<subsectionHeader confidence="0.999339">
3.2 Seed Expansion via Bootstrapping
</subsectionHeader>
<bodyText confidence="0.999984875">
In this step, we aim to extend the seed list that we obtained from FrameNet with the help of a bootstrapping
approach. To achieve that, we adopt a similar approach to Dias et al. (2014), who propose a repetitive
semantic expansion model to automatically build temporal associations of synsets in WordNet. Figure 1
provides an overview of the bootstrapping process. At each iteration, we first expand the seed list by
using semantic relations provided by WordNet. We then evaluate the accuracy of the new seed list for
sense classification by means of cross-validation against WordNet glosses. For each sense, we continue
iterating until the cross-validation accuracy becomes stable or starts to decrease. The following sections
explain the whole process in detail.
</bodyText>
<page confidence="0.986133">
116
</page>
<figure confidence="0.999821">
FrameNet
WordNet
MapNet
SVM Cross-
validation
Synset Set
Expansion
Break-Point
Detection
Sense
Seed
Synsets
</figure>
<figureCaption confidence="0.999961">
Figure 1: Bootstrapping procedure to expand the seed list.
</figureCaption>
<subsectionHeader confidence="0.586006">
Extending the Seed List with WordNet
</subsectionHeader>
<bodyText confidence="0.999972642857143">
While the initial sensory seed list obtained from FrameNet contains only 277 lemma-POS pairs, we extend
this list by utilizing the semantic relations provided by WordNet. To achieve that, we first map each
lemma-POS pair in the seed list to WordNet synsets with the help of MapNet (Tonelli and Pighin, 2009),
which is a resource providing direct mapping between WordNet synsets and FrameNet lexical units. Then,
we add to the list the synsets that are in WordNet relations direct antonymy, similarity, derived-from,
derivationally-related, pertains-to, attribute and also-see with the already existing seeds. For instance,
we add the synset containing the verb laugh for the synset of the verb cry with the relation direct antonymy,
or the synset containing the adjective chilly for the synset of the adjective cold with the relation similarity.
We prefer to use these relations as they might allow us to preserve the semantic information as much as
possible during the extension process. It is worth mentioning that these relations were also found to be
appropriate for preserving the affective connotation by Valitutti et al. (2004). Additionally, we use the
relations hyponym and hyponym-instance to enrich the seed set with semantically more specific synsets.
For instance, for the noun seed smell, we expand the list with the hyponyms of its synset such as the
nouns bouquet, fragrance, fragrancy, redolence and sweetness.
</bodyText>
<subsectionHeader confidence="0.783707">
Cross-validation for Sensorial Model
</subsectionHeader>
<bodyText confidence="0.999925421052632">
After obtaining new synsets with the help of WordNet relations in each bootstrapping cycle, we build a
five-class sense classifier over the seed synsets defined by their glosses provided in WordNet. Similarly
to Dias et al. (2014), we assume that the sense information of sensorial synsets is preserved in their
definitions. Accordingly, we employ a support vector machine (SVM) (Boser et al., 1992; Vapnik, 1998)
model with second degree polynomial kernel by representing the gloss of each synset as a vector of
lemmas weighted by their counts. For each synset, its gloss is lemmatized by using Stanford Core NLP5
and cleaned from the stop words. After each iteration cycle, we perform a 10-fold cross-validation in the
updated seed list to detect the accuracy of the new sensorial model. For each sense class, we continue
iterating and thereby expanding the seed list until the classifier accuracy steadily drops.
Table 1 lists the precision (P), recall (R) and F1 values obtained for each sense after each iteration until
the bootstrapping mechanism stops. While the iteration number is provided in the first column, the values
under the last column group present the micro-average of the resulting multi-class classifier. The change
in the performance values of each class in each iteration reveal that the number of iterations required to
obtain the seed lists varies for each sense. For instance, the F1 value of touch continues to increase until
the fourth cycle whereas hearing records a sharp decrease after the first iteration.
After the bootstrapping process, we create the final lexicon by repeating the expansion for each class
until the optimal number of iterations is reached. The last row of Table 1, labeled as Final, demonstrates
the accuracy of the classifier trained and tested on the final lexicon, i.e., using the seeds selected after
iteration 2 for Sight, iteration 1 for Hearing, iteration 3 for Taste and Smell and iteration 4 for Touch.
</bodyText>
<footnote confidence="0.953266">
5http://nlp.stanford.edu/software/corenlp.shtml
</footnote>
<page confidence="0.986506">
117
</page>
<table confidence="0.99967025">
It# P Sight F1 P Hearing P Taste F1 P Smell P Touch Micro-average
R R F1 R R F1 R F1 P R F1
1 .873 .506 .640 .893 .607 .723 .716 .983 .828 .900 .273 .419 .759 .320 .451 .780 .754 .729
2 .666 .890 .762 .829 .414 .552 .869 .929 .898 .746 .473 .579 .714 .439 .543 .791 .787 .772
3 .643 .878 .742 .863 .390 .538 .891 .909 .900 .667 .525 .588 .720 .482 .578 .796 .786 .776
4 .641 .869 .738 .832 .400 .540 .866 .888 .877 .704 .500 .585 .736 .477 .579 .784 .774 .765
5 .640 .869 .737 .832 .400 .540 .866 .888 .877 .704 .500 .585 .738 .474 .578 .784 .774 .764
Final .805 .827 .816 .840 .408 .549 .814 .942 .873 .685 .534 .600 .760 .582 .659 .800 .802 .790
</table>
<tableCaption confidence="0.999917">
Table 1: Bootstrapping cycles with validation results.
</tableCaption>
<bodyText confidence="0.9995112">
According to F1 measurements of each iteration, while hearing and taste have a lower value for the final
model, sight, smell and touch have higher results. It should also be noted that the micro-average of the F1
values of the final model shows an increase when compared to the third iteration which has the highest
avarage F1 value among the iterations. At the end of this step we have a seed synset list consisting of
2572 synsets yielding the highest performance when used to learn a sensorial model.
</bodyText>
<subsectionHeader confidence="0.996193">
3.3 Sensorial Lexicon Construction Using Corpus Statistics
</subsectionHeader>
<bodyText confidence="0.999987625">
After generating the seed lists consisting of synsets for each sense category with the help of a set of
WordNet relations and a bootstrapping process, we use corpus statistics to create our final sensorial lex-
icon. More specifically, we exploit a probabilistic approach based on the co-occurence of the seeds and
the candidate lexical entries. Since working on the synset level would raise the data sparsity problem in
synset tagged corpora such as SemCor (Miller et al., 1993) and we need a corpus that provides sufficient
statistical information, we migrate from synset level to lexical level. Accordingly, we treat each POS
role of the same lemmas as a distinct seed and extract 4287 lemma-POS pairs from 2572 synsets. In this
section, we explain the steps to construct our final sensorial lexicon in detail.
</bodyText>
<subsectionHeader confidence="0.474319">
Corpus and Candidate Words
</subsectionHeader>
<bodyText confidence="0.9998982">
As a corpus, we use a subset of English GigaWord 5th Edition released by Linguistic Data Consortium
(LDC)6. This resource is a collection of almost 10 million English newswire documents collected in recent
years, whose content sums up to nearly 5 billion words. The richly annotated GigaWord data comprises
automatic parses obtained with the Stanford parser (Klein and Manning, 2003) so that we easily have
access to the lemma and POS information of each word in the resource. For the scope of this study, we
work on a randomly chosen subset that contains 79800 sentences and we define a co-occurrence event as
the co-existence of a candidate word and a seed word within a window of 9 words (the candidate word,
4 words to its left and 4 words to its right). In this manner, we analyze the cooccurrence of each unique
lemma-POS pair in the corpus with the sense seeds. We eliminate the candidates which have less than 5
cooccurences with the sense categories.
</bodyText>
<subsectionHeader confidence="0.969453">
Normalized Pointwise Mutual Information
</subsectionHeader>
<bodyText confidence="0.9969185">
For the cooccurrence analysis of the candidate words and seeds, we use pointwise mutual information
(PMI), which is simply a measure of association between the probability of the co-occurence of two
events and their individual probabilities when they are assumed to be independent (Church and Hanks,
1990) and it is calculated as:
</bodyText>
<equation confidence="0.9101645">
PMI (x,y) = log p(x,y) (1)
[p(x)p(y)
</equation>
<bodyText confidence="0.99287375">
To calculate the PMI value of a candidate word and a specific sense, we considerp(x) as the probability
of the candidate word to occur in the corpus. Therefore,p(x) is calculated as p(x) = c(x)/N, where c(x)
is the total count of the occurences of the candidate word x in the corpus and N is the total cooccurrence
count of all words in the corpus. Similarly, we calculate p(y) as the total occurrence count of all the
</bodyText>
<footnote confidence="0.899193">
6http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2011T07
</footnote>
<page confidence="0.961106">
118
</page>
<table confidence="0.999418666666667">
majority class 3 4 5 6 7 8 9 10
word 0 0.98 3.84 9.96 11.63 16.66 34.41 12.42
sentence 0.58 2.35 7.07 10.91 13.27 15.63 21.23 16.51
</table>
<tableCaption confidence="0.999305">
Table 2: Percentage of words and sentences in each majority class.
</tableCaption>
<bodyText confidence="0.9988842">
seeds for the sense considered (y). p(y) can thus be formulated as c(y)/N. p(x,y) is the probability of the
cooccurence of a candidate word x with a sense event y.
A major shortcoming of PMI is its sensitivity for low frequency data (Bouma, 2009). As one possible
solution, the author introduces Normalized Pointwise Mutual Information (NPMI), which normalizes the
PMI values to the range (-1, +1) with the following formula:
</bodyText>
<equation confidence="0.999849333333333">
PMI(x, y)
NPMI(x, y) = (2)
− log p(x, y)
</equation>
<bodyText confidence="0.999616333333333">
We calculated NPMI values for each candidate word and five sense events in the corpus. The sensorial
lexicon covers 22,684 lemma-POS pairs and a score for each sense class that denotes their association
degrees.
</bodyText>
<sectionHeader confidence="0.999436" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9999388">
To evaluate the performance of the sensorial classification and the quality of the lexicon, we first created
a gold standard with the help of a crowdsourcing task. Then, we compared the decisions coming from the
lexicon against the gold standard. In this section, we explain the annotation process that we conducted
and the evaluation technique that we adopted in detail. We also provide a brief discussion about the
obtained results.
</bodyText>
<subsectionHeader confidence="0.999192">
4.1 Crowdsourcing to Build a Gold Standard
</subsectionHeader>
<bodyText confidence="0.99999244">
The evaluation phase of the sensorial lexicon requires a gold standard data to be able to conduct a mean-
ingful assessment. Since to our best knowledge there is no resource with sensory associations of words
or sentences, we designed our own annotation task using the crowdsourcing service CrowdFlower. For
the annotation task, we first compiled a collection of sentences to be annotated. Then, we designed two
questions that the annotators were expected to answer for a given sentence. While the first question is
related to the sense association of a whole sentence, the second asks the annotators the sense associations
of the words in the same sentence to collect a fine-grained gold standard.
We collected a dataset of 340 sentences consisting of 300 advertisement slogans from 11 advertisement
categories (e.g., fashion, food, electronics) and 40 story sentences from a story corpus. We collected the
slogans from various online resources such as http://slogans.wikia.com/wiki and http://www.
adslogans.co.uk/. The story corpus is generated as part of a dissertation research (Alm, 2008) and it
provides stories as a collection of sentences.
In both resources, we first determined the candidate sentences which had at least five tokens and con-
tained at least one adjective, verb or noun. In addition, we replaced the brand names in the advertisement
slogans with X to prevent any bias. For instance, the name of a well-known restaurant in a slogan might
cause a bias towards taste. Finally, the slogans used in the annotation task were chosen randomly among
the candidate sentences by considering a balanced number of slogans from each category. Similarly, 40
story sentences were selected randomly among the candidate story sentences. To give a more concrete
idea, for our dataset we obtained an advertisement slogan such as “X&apos;s Sugar Frosted Flakes They&apos;re
Great!” or a story sentence such as “The ground is frozen, and besides the snow has covered everything.”
In the crowdsourcing task we designed, the annotators were required to answer 2 questions for a given
sentence. In the first question, they were asked to detect the human senses conveyed or directly described
by a given sentence. To exemplify these cases, we provided two examples such as “I saw the cat” that
directly mentions the action of seeing and “The sun was shining on the blue water.” that conveys the sense
of sight by using visual descriptions or elements like “blue” or “shine” which are notable for their visual
</bodyText>
<page confidence="0.997572">
119
</page>
<table confidence="0.997185692307692">
Category Si He Ta Sm To
personal care 49.36 10.75 0.00 13.29 26.58
travel 58.18 0.00 29.09 0.00 12.72
fashion 43.47 0.00 0.00 26.08 30.43
beauty 84.56 0.00 0.00 0.00 15.43
computing 32.25 59.13 0.00 0.00 8.60
food 0.00 5.46 94.53 0.00 0.00
beverages 22.68 0.00 59.79 0.00 17.52
communications 25.00 67.50 0.00 0.00 0.075
electronics 45.94 54.05 0.00 0.00 0.00
education 28.57 42.85 0.00 0.00 28.57
transport 61.81 38.18 0.00 0.00 0.00
story 58.37 20.81 0.00 7.23 13.57
</table>
<tableCaption confidence="0.999921">
Table 3: The categories of the annotated data and their sense association percentages.
</tableCaption>
<bodyText confidence="0.999955454545455">
properties. The annotators were able to select more than one sense for each sentence and together with
the five senses we provided another option as None which should be selected when an annotator could
not associate a sentence with any sense. The second question was devoted do determining word-sense
associations. Here, the annotators were expected to associate the words in each sentence with at least
one sense. Again, annotators could choose None for every word that they could not confidently associate
with a sense.
The reliability of the annotators was evaluated on the basis of 20 control sentences which were highly
associated with a specific sense and which included at least one sensorial word. For instance, for the con-
trol sentence “The skin you love to touch”, we only considered as reliable the annotators who associated
the sentence with touch and the word touch with the sense touch7. Similarly, for the slogan “The most
colourful name in cosmetics.”, an annotator was expected to associate the sentence with at least the sense
sight and the word colorful to at least the sense sight. The raters who scored at least 70% accuracy on
average on the control questions for the two tasks were considered to be reliable. Each unit was annotated
by at least 10 reliable raters.
Similarly to Mohammad (2011) and Özbal et al. (2011), we calculated the majority class of each anno-
tated item to measure the agreement among the annotators. Table 2 demonstrates the observed agreement
at both word and sentence level. Since 10 annotators participated in the task, the annotations with a ma-
jority class greater than 5 can be considered as reliable (Özbal et al., 2011). Indeed, for 85.10% of the
word annotations the absolute majority agreed on the same decision, while 77.58% of the annotations in
the sentence level have majority class greater than 5. The high agreement observed among the annotators
in both cases confirms the quality of the resulting gold standard data.
In Table 3, we present the results of the annotation task by providing the association percentage of each
category with each sense, namely sight (Si), hear (He), taste (Ta), smell (Sm) and touch (To). As demon-
strated in the table, while the sense of sight can be observed in almost every advertisement category and
in story, smell and taste are very rare. We observe that the story sentences invoke all sensorial modali-
ties except taste, although the percentage of sentences annotated with smell is relatively low. Similarly,
personal care category has an association with four of the senses while the other categories have either
very low or no association with some of the sense classes. Indeed, the perceived sensorial effects in the
sentences vary according to the category such that the slogans in the travel category are highly associated
with sight whereas the communication category is highly associated with hearing. While the connection
of the food and beverages categories with taste is very high as expected, they have no association with the
sense of smell. This kind of analysis could be useful for copywriters to decide which sensory modalities
to invoke while creating a slogan for a specific product category.
</bodyText>
<footnote confidence="0.945892">
7If the annotators gave additional answers to the expected ones, we considered their answers as correct.
</footnote>
<page confidence="0.991271">
120
</page>
<subsectionHeader confidence="0.920927">
4.2 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.999980857142857">
Based on the annotation results of our crowdsourcing task, we propose an evaluation technique consider-
ing that a lemma-POS or a sentence might be associated with more than one sensory modalities. Similar to
the evaluation framework defined by Özbal et al. (2011), we adapt the evaluation measures of SemEval-
2007 English Lexical Substitution Task (McCarthy and Navigli, 2007), where a system generates one or
more possible substitutions for a target word in a sentence preserving its meaning.
For a given lemma-POS or a sentence, which we will name as item in the rest of the section, we allow
our system to provide as many sensorial associations as it determines using a specific lexicon. While
evaluating a sense-item association of a method, a best and an oot score are calculated by considering
the number of the annotators who associate that sense with the given item, the number of the annotators
who associate any sense with the given item and the number of the senses the system gives as an answer
for that item. More specifically, best scoring provides a credit for the best answer for a given item by
dividing it to the number of the answers of the system. oot scoring, on the other hand, considers only a
certain number of system answers for a given item and does not divide the credit to the total number of
the answers. Unlike the lexical substitution task, a limited set of labels (i.e., 5 sense labels and none) are
allowed for the sensorial annotation of sentences or lemma-POS pairs. For this reason, we reformulate
out-of-ten (oot) scoring used by McCarthy and Navigli (2007) as out-of-two.
In Equation 3, best score for a given item i from the set of items I, which consists of the items annotated
with a specific sense by a majority of 5 annotators, is formulated where Hi is the multiset of gold standard
sense associations for item i and Si is the set of sense associations provided by the system. oot scoring,
as formulated in Equation 4, accepts up to 2 sense associations s from the answers of system Si for a
given item i and the credit is not divided by the number of the answers of the system.
</bodyText>
<equation confidence="0.9367505">
EBESi freq (s E Hi)
best (i) = (3)
JHiJ - JSiJ
t (i) =
EBESi freq (s E Hi)
oo
(4)
JHiJ
</equation>
<bodyText confidence="0.9998435">
As formulated in Equation 5, to calculate the precision of an item-sense association task with a specific
method, the sum of the scores (i.e., best or oot) for each item is divided by the number of items A, for
which the method can provide an answer. In recall, the denominator is the number of the items in the
gold standard for which an answer is given by the annotators.
</bodyText>
<equation confidence="0.89775525">
P = EiEA scorei
R = EiEZ scorei
(5)
JAJ JIJ
</equation>
<subsectionHeader confidence="0.997147">
4.3 Evaluation Method
</subsectionHeader>
<bodyText confidence="0.999866285714286">
For the evaluation, we compare the accuracy of a simple classifier based on the sensorial lexicon against
two baselines on a sense classification task, both at word and sentence level. To achieve that, we use
the gold standard that we obtain from the crowdsourcing task and the evaluation measures best and oot.
The lexicon-based classifier simply assigns to each word in a sentence the sense values found in the
lexicon. The first baseline simply assigns a random float value, which is in the range of (-1,1), to each
sense association of each lemma-POS pair in the sensorial lexicon. The second baseline instead builds
the associations by using a Latent Semantic Analysis space generated from the British National Corpus8
(BNC), which is a very large (over 100 million words) corpus of modern English. More specifically,
this baseline calculates the LSA similarities between each candidate lemma-POS pair and sense class
by taking the cosine similarity between the vector of the target lemma-POS pair and the average of the
vectors of the related sensory word (i.e., see, hear, touch, taste, and smell) for each possible POS tag.
For instance, to get the association score of a lemma-POS pair with the sense sight, we first average the
vectors of see (noun) and see (verb) before calculating its cosine similarity with the target lemma-POS
pair.
</bodyText>
<footnote confidence="0.977425">
8http://www.hcu.ox.ac.uk/bnc/
</footnote>
<page confidence="0.996543">
121
</page>
<bodyText confidence="0.999988105263158">
For the first experiment, i.e., word-sense association, we automatically associate the lemma-POS pairs
obtained from the annotated dataset with senses by using i) the sensorial lexicon, ii) the random baseline,
iii) the LSA baseline. To achieve that, we lemmatize and POS tag each sentence in the dataset by using
Stanford Core NLP. In the end, for each method and target word, we obtain a list of senses sorted according
to their sensorial association values in decreasing order. It is worth noting that we only consider the non-
negative sensorial associations for the sensorial lexicon and the random baseline, and the associations
above the value of 0.4 which we empirically set as the threshold for the LSA baseline. For instance,
the sensorial lexicon associates the noun wine with [smell, taste, sight]. In this experiment, best scoring
considers the associated senses as the best answer, smell, taste, sight according to the previous example,
and calculates a score with respect to the best answer in the gold standard and the number of the senses
in this answer. Instead, oot scoring takes the first two answers, smell and taste according to the previous
example, and assigns the score accordingly.
To determine the senses associated with a sentence for the second experiment, we use a method similar
to the one proposed by Turney (2002). For each sense, we simply calculate the average score of the
lemma-POS pairs in a sentence. We set a threshold value of 0 to decide whether a sentence is associated
with a given sense. In this manner, we obtain a sorted list of average sensory scores for each sentence
according to the three methods. For instance, the classifier based on the sensorial lexicon associates the
sentence Smash it to pieces, love it to bits. with [touch, taste]. For the best score, only touch would be
considered, whereas oot would consider both touch and taste.
</bodyText>
<subsectionHeader confidence="0.998246">
4.4 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.999972">
In Table 4, we list the F1 values that we obtained with the classifier using the sensorial lexicon and the
two baselines (Random and LSA) according to both best and oot measures. In addition, we provide
the performance of the sensorial lexicon in two preliminary steps, before bootstrapping (BB) and after
bootstrapping (AB) to observe the incremental progress of the lexicon construction method. As can be
observed from the table, the best performance for both experiments is achieved by the sensorial lexicon
when compared against the baselines.
While in the first experiment the lexicon generated after the bootstrapping step (AB) provides a very
similar performance to the final lexicon according to the best measure, it can only build sense associations
for 69 lemmas out of 153 appearing in the gold standard. Instead, the final lexicon attempts to resolve
129 lemma-sense associations and results in a better recall value. Additionally, AB yields a very high
precision as expected, since it is created by a controlled semantical expansion from manually annotated
sensorial words. The LSA baseline slightly improves the random baseline according to both best and oot
measures and it also outperforms BB for oot. BB lexicon includes only 573 lemmas which are collected
from 277 synsets and we can not obtain 2 sense association scores for oot in this lexicon since each lemma
is associated with only one sense with a value of 1.
Concerning the sentence classification experiment, the classifier using the sensorial lexicon yields the
highest performance in both measures. The very high F1 value obtained with the oot scoring indicates that
the right answer for a sentence is included in the first two decisions in many cases. The low performance
of the LSA baseline might be arising due to its tendency to link the sentences with the sense of touch (i.e.,
215 sentences out of 320 gold standard data). It would be interesting to see the impact of using another
corpus to build the LSA space and constituting the sense vectors differently.
After the manual analysis of the sensorial lexicon and gold standard data, we observe that the sensorial
classification task could be nontrivial. For instance, a story sentence “He went to sleep again and snored
until the windows shook.” has been most frequently annotated as hearing. While the sensorial lexicon
classifier associates this sentence with touch as the best answer, it can provide the correct association
hearing as the second best answer. To find out the best sensorial association for a sentence, a classification
method which exploits various aspects of sensorial elements in a sentence, such as the number of sensorial
words or their dependencies, could be a better approach than using only the average sensorial values.
Based on our observations in the error cases, the advertisement slogan “100% pure squeezed sunshine”
is associated with touch as the best answer by both the sensorial lexicon and LSA baseline while it is most
frequently annotated as sight in the gold standard. This slogan is an example usage of synaesthesia and
</bodyText>
<page confidence="0.988479">
122
</page>
<table confidence="0.999057714285714">
Model Lemma Sentence
best oot best oot
Random 21.10 37.59 21.10 37.59
LSA 26.35 37.60 31.01 37.63
Lexicon-BB 45.22 45.22 49.60 51.12
Lexicon-AB 55.85 55.85 59.89 63.21
Sensorial Lexicon 55.86 80.13 69.76 80.73
</table>
<tableCaption confidence="0.99987">
Table 4: Evaluation results.
</tableCaption>
<bodyText confidence="0.9988968">
metaphors in advertising language. To clarify, a product from the category of beverages, which might be
assumed to have a taste association, is described by a metaphorical substitution of a taste-related noun,
most probably the name of a fruit, with a sight-related noun; sunshine. This metaphorical substitution,
then used as the object of a touch-related verb, to squeeze, produces a synaesthetic expression with touch
and sight.
</bodyText>
<sectionHeader confidence="0.999303" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999713380952381">
In this paper we have presented a computational method to build a lexicon that associates words with
senses by employing a two-step strategy. First, we collected seed words by using a bootstrapping ap-
proach based on a set of WordNet relations. Then, we performed a corpus based statistical analysis to
produce the final lexicon. The resulting sensorial lexicon consists of 22,684 lemma-POS pairs and their
association degrees with five sensory modalities. To our best knowledge, this is the first systematic at-
tempt to build a sensorial lexicon and we believe that our contribution constitutes a valid starting point
for the community to consider sensorial information conveyed by text as a feature for various tasks and
applications. The results that we obtain by comparing our lexicon against the gold standard are promis-
ing even though not conclusive. The results confirm the soundness of the proposed approach for the
construction of the lexicon and the usefulness of the resource for text classification and possibly other
computational applications.
As future work, we would like to explore the effect of using different kinds of WordNet relations dur-
ing the bootstrapping phase. It would also be interesting to experiment with relations provided by other
resources such as ConceptNet (Liu and Singh, 2004), which is a semantic network containing common
sense, cultural and scientific knowledge. We would also like to use the sensorial lexicon for various
applicative scenarios such as slanting existing text towards a specific sense with text modification. We
believe that our resource could be extremely useful for automatic content personalization according to
user profiles. As an example, one can imagine a system that automatically replaces hearing based ex-
pressions with sight based ones in pieces of texts for a hearing-impaired person. Finally, we plan to
investigate the impact of using sensory information for metaphor detection and interpretation based on
our observations during the evaluation.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998775">
We would like to thank Daniele Pighin for his insightful comments and valuable suggestions.
This work was partially supported by the PerTe project (Trento RISE).
</bodyText>
<sectionHeader confidence="0.998952" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990811">
Ebba Cecilia Ovesdotter Alm. 2008. Affect in Text and Speech. Ph.D. thesis, University of Illinois at Urbana-
Champaign.
Collin F Baker, Charles J Fillmore, and John B Lowe. 1998. The berkeley framenet project. pages 86--90.
Association for Computational Linguistics.
</reference>
<page confidence="0.986774">
123
</page>
<reference confidence="0.999329895833334">
Carmen Banea, Rada Mihalcea, and Janyce Wiebe. 2008. A bootstrapping method for building subjectivity lexi-
cons for languages with scarce resources. In LREC.
D. Bernstein. 2010. Essentials of Psychology. PSY 113 General Psychology Series. Cengage Learning.
Bernhard E. Boser, Isabelle Guyon, and Vladimir Vapnik. 1992. A Training Algorithm for Optimal Margin Clas-
sifiers. In Proceedings of the 5th Annual Workshop on Computational learning theory.
Gerlof Bouma. 2009. Normalized (pointwise) mutual information in collocation extraction. Proceedings of GSCL,
pages 31--40.
Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography.
Comput. Linguist., 16(1):22--29, March.
Max Coltheart. 1981. The mrc psycholinguistic database. The Quarterly Journal of Experimental Psychology,
33(4):497--505.
Ivan E de Araujo, Edmund T Rolls, Maria Inés Velazco, Christian Margot, and Isabelle Cayeux. 2005. Cognitive
modulation of olfactory processing. Neuron, 46(4):671--679.
Gaël Harry Dias, Mohammed Hasanuzzaman, Stéphane Ferrari, and Yann Mathet. 2014. Tempowordnet for
sentence time tagging. In Proceedings of the Companion Publication of the 23rd International Conference
on World Wide Web Companion, WWW Companion &apos;14, pages 833--838, Republic and Canton of Geneva,
Switzerland. International World Wide Web Conferences Steering Committee.
Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion
mining. In Proceedings ofLREC, volume 6, pages 417--422.
Christiane Fellbaum, editor. 1998. WordNet An Electronic Lexical Database. The MIT Press, Cambridge, MA ;
London.
Thomas Kjeller Johansen. 1997. Aristotle on the Sense-organs. Cambridge University Press.
Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In IN PROCEEDINGS OF THE
41ST ANNUAL MEETING OF THE ASSOCIATIONFOR COMPUTATIONAL LINGUISTICS, pages 423--430.
Thomas K Landauer and Susan T Dumais. 1997. A solution to plato&apos;s problem: The latent semantic analysis theory
of acquisition, induction, and representation of knowledge. Psychological review, 104(2):211.
H. Liu and P. Singh. 2004. Conceptnet - a practical commonsense reasoning tool-kit. BT Technology Journal,
22(4):211--226, October.
Asifa Majid and Stephen C Levinson. 2011. The senses in language and culture. The Senses and Society, 6(1):5--
18.
Diana McCarthy and Roberto Navigli. 2007. Semeval-2007 task 10: English lexical substitution task. In Proceed-
ings of the 4th International Workshop on Semantic Evaluations, pages 48--53. Association for Computational
Linguistics.
George A. Miller, Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A semantic concordance. In
Proceedings of the workshop on Human Language Technology, HLT &apos;93, pages 303--308, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Saif M Mohammad and Peter D Turney. 2010. Emotions evoked by common words and phrases: Using mechan-
ical turk to create an emotion lexicon. In Proceedings of the NAACL HLT 2010 Workshop on Computational
Approaches to Analysis and Generation of Emotion in Text, pages 26--34. Association for Computational Lin-
guistics.
Saif Mohammad. 2011. Colourful language: Measuring word-colour associations. In Proceedings of the 2nd
Workshop on Cognitive Modeling and Computational Linguistics, pages 97--106. Association for Computational
Linguistics.
Gözde Özbal, Carlo Strapparava, Rada Mihalcea, and Daniele Pighin. 2011. A comparison of unsupervised meth-
ods to associate colors with words. In Affective Computing and Intelligent Interaction, pages 42--51. Springer.
Jessica Perrie, Aminul Islam, Evangelos Milios, and Vlado Keselj. 2013. Using google n-grams to expand word-
emotion association lexicon. In Computational Linguistics and Intelligent Text Processing, pages 137--148.
Springer.
</reference>
<page confidence="0.982858">
124
</page>
<reference confidence="0.99948595">
Mario Pricken. 2008. Creative Advertising Ideas and Techniques from the World&apos;s Best Campaigns. Thames &amp;
Hudson, 2,d edition.
R. Rodriguez-Esteban and A. Rzhetsky. 2008. Six senses in the literature. The bleak sensory landscape of biomed-
ical texts. EMBO reports, 9(3):212--215, March.
C. Strapparava and A. Valitutti. 2004. WordNet-Affect: an affective extension of WordNet. In Proceedings of
LREC, volume 4, pages 1083--1086.
Sara Tonelli and Daniele Pighin. 2009. New features for framenet - wordnet mapping. In Proceedings of the
Thirteenth Conference on Computational Natural Language Learning (CoNLL&apos;09), Boulder, CO, USA.
Peter D Turney, Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identification
through concrete and abstract context. In Proceedings of the 2011 Conference on the Empirical Methods in
Natural Language Processing, pages 680--690.
Peter D Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification
of reviews. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 417-
-424. Association for Computational Linguistics.
Alessandro Valitutti, Carlo Strapparava, and Oliviero Stock. 2004. Developing affective lexical resources. Psych-
Nology Journal, 2(1):61--83.
Vladimir N. Vapnik. 1998. Statistical Learning Theory. Wiley-Interscience.
Changhua Yang, Kevin Hsin-Yih Lin, and Hsin-Hsi Chen. 2007. Building emotion lexicon from weblog corpora.
In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages
133--136. Association for Computational Linguistics.
</reference>
<page confidence="0.998488">
125
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.039185">
<title confidence="0.998737">A Computational Approach to Generate a Sensorial Lexicon</title>
<author confidence="0.793514">Serra Sinem Via Sommarive</author>
<address confidence="0.74403">Povo, I-38100</address>
<email confidence="0.8726745">tekiroglu@fbk.euGözde</email>
<affiliation confidence="0.444982">Trento Via Sommarive</affiliation>
<address confidence="0.775824">Povo, I-38100</address>
<email confidence="0.999389">gozbalde@gmail.com</email>
<author confidence="0.780342">Carlo Via Sommarive</author>
<address confidence="0.783779">Povo, I-38100</address>
<email confidence="0.991966">strappa@fbk.eu</email>
<abstract confidence="0.998976583333333">While humans are capable of building connections between words and sensorial modalities by using commonsense knowledge, it is not straightforward for machines to interpret sensorial information. To this end, a lexicon associating words with human senses, namely sight, hearing, taste, smell and touch, would be crucial. Nonetheless, to the best of our knowledge, there is no systematic attempt in the literature to build such a resource. In this paper, we propose a computational method based on bootstrapping and corpus statistics to automatically associate English words with senses. To evaluate the quality of the resulting lexicon, we create a gold standard via crowdsourcing and show that a simple classifier relying on the lexicon outperforms two baselines on a sensory classification task, both at word and sentence level. The results confirm the soundness of the proposed approach for the construction of the lexicon and the usefulness of the resource for computational applications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ebba Cecilia Ovesdotter Alm</author>
</authors>
<date>2008</date>
<booktitle>Affect in Text and Speech. Ph.D. thesis,</booktitle>
<institution>University of Illinois at UrbanaChampaign.</institution>
<contexts>
<context position="23048" citStr="Alm, 2008" startWordPosition="3656" endWordPosition="3657">ce. While the first question is related to the sense association of a whole sentence, the second asks the annotators the sense associations of the words in the same sentence to collect a fine-grained gold standard. We collected a dataset of 340 sentences consisting of 300 advertisement slogans from 11 advertisement categories (e.g., fashion, food, electronics) and 40 story sentences from a story corpus. We collected the slogans from various online resources such as http://slogans.wikia.com/wiki and http://www. adslogans.co.uk/. The story corpus is generated as part of a dissertation research (Alm, 2008) and it provides stories as a collection of sentences. In both resources, we first determined the candidate sentences which had at least five tokens and contained at least one adjective, verb or noun. In addition, we replaced the brand names in the advertisement slogans with X to prevent any bias. For instance, the name of a well-known restaurant in a slogan might cause a bias towards taste. Finally, the slogans used in the annotation task were chosen randomly among the candidate sentences by considering a balanced number of slogans from each category. Similarly, 40 story sentences were select</context>
</contexts>
<marker>Alm, 2008</marker>
<rawString>Ebba Cecilia Ovesdotter Alm. 2008. Affect in Text and Speech. Ph.D. thesis, University of Illinois at UrbanaChampaign.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley framenet project.</title>
<date>1998</date>
<pages>86--90</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="10931" citStr="Baker et al., 1998" startWordPosition="1673" endWordPosition="1676">hased computational approach to construct a large sensorial lexicon. First, we employ a bootstrapping strategy to generate a sufficient number of sensory seed words from a small set of manually selected seed words. In the second phase, we perform a corpus based probabilistic method to estimate the association scores to build a larger lexicon. 3.1 Selecting Seed Words The first phase of the lexicon construction process aims to collect sensorial seed words, which are directly related to senses (e.g., sound, tasty and sightedness). To achieve that, we utilized a lexical database called FrameNet (Baker et al., 1998), which is built upon semantic frames of concepts in English and lexical units (i.e., words) that evoke these frames. The basic idea behind this resource is that meanings of words can be understood on the basis of a semantic frame. A semantic frame consists of semantic roles called frame elements, which are manually annotated in more than 170,000 sentences. We have considered FrameNet to be especially suitable for the collection of sensorial seed words since it includes semantic roles and syntactic features of sensational and perceptional concepts. In order to determine the seed lemma-POS pair</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F Baker, Charles J Fillmore, and John B Lowe. 1998. The berkeley framenet project. pages 86--90. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
<author>Janyce Wiebe</author>
</authors>
<title>A bootstrapping method for building subjectivity lexicons for languages with scarce resources.</title>
<date>2008</date>
<booktitle>In LREC. D. Bernstein. 2010. Essentials of Psychology. PSY 113 General Psychology Series. Cengage Learning.</booktitle>
<contexts>
<context position="8990" citStr="Banea et al. (2008)" startWordPosition="1381" endWordPosition="1384">f one kind of sense impression by using words that normally describe another. 2The sensorial lexicon is publicly available, upon request to the authors. 3http://www.crowdflower.com/ 4http://www.mturk.com/mturk 115 Regarding the sentiment orientations and subjectivity levels of words, Sentiwordnet (Esuli and Sebastiani, 2006) is constructed as an extension to WordNet and it provides sentiments in synset level. Positive, negative and neutral values are assigned to synsets by using ternary classifiers and synset glosses. Another study that has been inspirational for the design of our approach is Banea et al. (2008). The authors generate a subjectivity lexicon starting with a set of seed words and then using a similarity measure among the seeds and the candidate words. Concerning the association between colors and words, Mohammad (2011) builds a color-word association lexicon by organizing a crowdsourcing task on Amazon Mechanical Turk. Instead, Özbal et al. (2011) aim to automate this process and propose three computational methods based on image analysis, language models and latent semantic analysis (LSA) (Landauer and Dumais, 1997). The authors compare these methods against a gold standard obtained by</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, 2008</marker>
<rawString>Carmen Banea, Rada Mihalcea, and Janyce Wiebe. 2008. A bootstrapping method for building subjectivity lexicons for languages with scarce resources. In LREC. D. Bernstein. 2010. Essentials of Psychology. PSY 113 General Psychology Series. Cengage Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard E Boser</author>
<author>Isabelle Guyon</author>
<author>Vladimir Vapnik</author>
</authors>
<title>A Training Algorithm for Optimal Margin Classifiers.</title>
<date>1992</date>
<booktitle>In Proceedings of the 5th Annual Workshop on Computational learning theory.</booktitle>
<contexts>
<context position="15001" citStr="Boser et al., 1992" startWordPosition="2313" endWordPosition="2316"> specific synsets. For instance, for the noun seed smell, we expand the list with the hyponyms of its synset such as the nouns bouquet, fragrance, fragrancy, redolence and sweetness. Cross-validation for Sensorial Model After obtaining new synsets with the help of WordNet relations in each bootstrapping cycle, we build a five-class sense classifier over the seed synsets defined by their glosses provided in WordNet. Similarly to Dias et al. (2014), we assume that the sense information of sensorial synsets is preserved in their definitions. Accordingly, we employ a support vector machine (SVM) (Boser et al., 1992; Vapnik, 1998) model with second degree polynomial kernel by representing the gloss of each synset as a vector of lemmas weighted by their counts. For each synset, its gloss is lemmatized by using Stanford Core NLP5 and cleaned from the stop words. After each iteration cycle, we perform a 10-fold cross-validation in the updated seed list to detect the accuracy of the new sensorial model. For each sense class, we continue iterating and thereby expanding the seed list until the classifier accuracy steadily drops. Table 1 lists the precision (P), recall (R) and F1 values obtained for each sense </context>
</contexts>
<marker>Boser, Guyon, Vapnik, 1992</marker>
<rawString>Bernhard E. Boser, Isabelle Guyon, and Vladimir Vapnik. 1992. A Training Algorithm for Optimal Margin Classifiers. In Proceedings of the 5th Annual Workshop on Computational learning theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerlof Bouma</author>
</authors>
<title>Normalized (pointwise) mutual information in collocation extraction.</title>
<date>2009</date>
<booktitle>Proceedings of GSCL,</booktitle>
<pages>31--40</pages>
<contexts>
<context position="21032" citStr="Bouma, 2009" startWordPosition="3339" endWordPosition="3340">words in the corpus. Similarly, we calculate p(y) as the total occurrence count of all the 6http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2011T07 118 majority class 3 4 5 6 7 8 9 10 word 0 0.98 3.84 9.96 11.63 16.66 34.41 12.42 sentence 0.58 2.35 7.07 10.91 13.27 15.63 21.23 16.51 Table 2: Percentage of words and sentences in each majority class. seeds for the sense considered (y). p(y) can thus be formulated as c(y)/N. p(x,y) is the probability of the cooccurence of a candidate word x with a sense event y. A major shortcoming of PMI is its sensitivity for low frequency data (Bouma, 2009). As one possible solution, the author introduces Normalized Pointwise Mutual Information (NPMI), which normalizes the PMI values to the range (-1, +1) with the following formula: PMI(x, y) NPMI(x, y) = (2) − log p(x, y) We calculated NPMI values for each candidate word and five sense events in the corpus. The sensorial lexicon covers 22,684 lemma-POS pairs and a score for each sense class that denotes their association degrees. 4 Evaluation To evaluate the performance of the sensorial classification and the quality of the lexicon, we first created a gold standard with the help of a crowdsourc</context>
</contexts>
<marker>Bouma, 2009</marker>
<rawString>Gerlof Bouma. 2009. Normalized (pointwise) mutual information in collocation extraction. Proceedings of GSCL, pages 31--40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Comput. Linguist.,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="20029" citStr="Church and Hanks, 1990" startWordPosition="3164" endWordPosition="3167"> 9 words (the candidate word, 4 words to its left and 4 words to its right). In this manner, we analyze the cooccurrence of each unique lemma-POS pair in the corpus with the sense seeds. We eliminate the candidates which have less than 5 cooccurences with the sense categories. Normalized Pointwise Mutual Information For the cooccurrence analysis of the candidate words and seeds, we use pointwise mutual information (PMI), which is simply a measure of association between the probability of the co-occurence of two events and their individual probabilities when they are assumed to be independent (Church and Hanks, 1990) and it is calculated as: PMI (x,y) = log p(x,y) (1) [p(x)p(y) To calculate the PMI value of a candidate word and a specific sense, we considerp(x) as the probability of the candidate word to occur in the corpus. Therefore,p(x) is calculated as p(x) = c(x)/N, where c(x) is the total count of the occurences of the candidate word x in the corpus and N is the total cooccurrence count of all words in the corpus. Similarly, we calculate p(y) as the total occurrence count of all the 6http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2011T07 118 majority class 3 4 5 6 7 8 9 10 word 0 0.9</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Comput. Linguist., 16(1):22--29, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Coltheart</author>
</authors>
<title>The mrc psycholinguistic database.</title>
<date>1981</date>
<journal>The Quarterly Journal of Experimental Psychology,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="5006" citStr="Coltheart, 1981" startWordPosition="763" endWordPosition="764"> would benefit from such a resource is advertisement especially by using synaesthesia1, as it reinforces creative thinking and it is commonly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981; Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors (Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our knowledge, there is no attempt in the literature to build a resource that associates words with senses. In this paper, we propose a computational method to automatically generate a sensorial lexicon2 that associates words in English with senses. Our method consists of two main steps. First, we generate the initial seed words for each sense category with the help of a bootstrapping approach. The</context>
<context position="9945" citStr="Coltheart, 1981" startWordPosition="1524" endWordPosition="1525">bal et al. (2011) aim to automate this process and propose three computational methods based on image analysis, language models and latent semantic analysis (LSA) (Landauer and Dumais, 1997). The authors compare these methods against a gold standard obtained by the crowdsourcing service of Amazon Mechanical Turk. The best performance is obtained by using image features while LSA performs slightly better than the baseline. Finally, there have been efforts in the literature about the association of words with their abstractnessconcreteness and imageability levels. MRC Psycholinguistic Database (Coltheart, 1981) includes abstractness-concreteness and imageability ratings of a small set of words determined according to psycholinguistic experiments. Turney et al. (2011) propose to use LSA similarities of words with a set of seed words to automatically calculate the abstractness and concreteness degrees of words. 3 Automatically Associating Senses with Words We adopt a two phased computational approach to construct a large sensorial lexicon. First, we employ a bootstrapping strategy to generate a sufficient number of sensory seed words from a small set of manually selected seed words. In the second phas</context>
</contexts>
<marker>Coltheart, 1981</marker>
<rawString>Max Coltheart. 1981. The mrc psycholinguistic database. The Quarterly Journal of Experimental Psychology, 33(4):497--505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan E de Araujo</author>
<author>Edmund T Rolls</author>
<author>Maria Inés Velazco</author>
<author>Christian Margot</author>
<author>Isabelle Cayeux</author>
</authors>
<title>Cognitive modulation of olfactory processing.</title>
<date>2005</date>
<journal>Neuron,</journal>
<volume>46</volume>
<issue>4</issue>
<marker>de Araujo, Rolls, Velazco, Margot, Cayeux, 2005</marker>
<rawString>Ivan E de Araujo, Edmund T Rolls, Maria Inés Velazco, Christian Margot, and Isabelle Cayeux. 2005. Cognitive modulation of olfactory processing. Neuron, 46(4):671--679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gaël Harry Dias</author>
<author>Mohammed Hasanuzzaman</author>
<author>Stéphane Ferrari</author>
<author>Yann Mathet</author>
</authors>
<title>Tempowordnet for sentence time tagging.</title>
<date>2014</date>
<booktitle>In Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web Companion, WWW Companion &apos;14,</booktitle>
<pages>833--838</pages>
<institution>Republic and Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee.</institution>
<contexts>
<context position="12352" citStr="Dias et al. (2014)" startWordPosition="1906" endWordPosition="1909">asked 3 annotators to determine which senses the lemma-POS pairs evoking the collected frames are associated with. At the end of this task, we collected all the pairs (i.e., 277) with 100% agreement to constitute our initial seed set. This set contains 277 lemma-POS pairs associated with a specific sense such as the verb click with hearing, the noun glitter with sight and aromatic with smell. 3.2 Seed Expansion via Bootstrapping In this step, we aim to extend the seed list that we obtained from FrameNet with the help of a bootstrapping approach. To achieve that, we adopt a similar approach to Dias et al. (2014), who propose a repetitive semantic expansion model to automatically build temporal associations of synsets in WordNet. Figure 1 provides an overview of the bootstrapping process. At each iteration, we first expand the seed list by using semantic relations provided by WordNet. We then evaluate the accuracy of the new seed list for sense classification by means of cross-validation against WordNet glosses. For each sense, we continue iterating until the cross-validation accuracy becomes stable or starts to decrease. The following sections explain the whole process in detail. 116 FrameNet WordNet</context>
<context position="14833" citStr="Dias et al. (2014)" startWordPosition="2287" endWordPosition="2290">ving the affective connotation by Valitutti et al. (2004). Additionally, we use the relations hyponym and hyponym-instance to enrich the seed set with semantically more specific synsets. For instance, for the noun seed smell, we expand the list with the hyponyms of its synset such as the nouns bouquet, fragrance, fragrancy, redolence and sweetness. Cross-validation for Sensorial Model After obtaining new synsets with the help of WordNet relations in each bootstrapping cycle, we build a five-class sense classifier over the seed synsets defined by their glosses provided in WordNet. Similarly to Dias et al. (2014), we assume that the sense information of sensorial synsets is preserved in their definitions. Accordingly, we employ a support vector machine (SVM) (Boser et al., 1992; Vapnik, 1998) model with second degree polynomial kernel by representing the gloss of each synset as a vector of lemmas weighted by their counts. For each synset, its gloss is lemmatized by using Stanford Core NLP5 and cleaned from the stop words. After each iteration cycle, we perform a 10-fold cross-validation in the updated seed list to detect the accuracy of the new sensorial model. For each sense class, we continue iterat</context>
</contexts>
<marker>Dias, Hasanuzzaman, Ferrari, Mathet, 2014</marker>
<rawString>Gaël Harry Dias, Mohammed Hasanuzzaman, Stéphane Ferrari, and Yann Mathet. 2014. Tempowordnet for sentence time tagging. In Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web Companion, WWW Companion &apos;14, pages 833--838, Republic and Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings ofLREC,</booktitle>
<volume>6</volume>
<pages>417--422</pages>
<contexts>
<context position="8697" citStr="Esuli and Sebastiani, 2006" startWordPosition="1332" endWordPosition="1336"> annotations. Mohammad and Turney (2010) generate an emotion lexicon by using the crowdsourcing service provided by Amazon Mechanical Turk4 and it covers 14,200 term-emotion associations. 1American Heritage Dictionary (http://ahdictionary.com/) defines synaesthesia in linguistics as the description of one kind of sense impression by using words that normally describe another. 2The sensorial lexicon is publicly available, upon request to the authors. 3http://www.crowdflower.com/ 4http://www.mturk.com/mturk 115 Regarding the sentiment orientations and subjectivity levels of words, Sentiwordnet (Esuli and Sebastiani, 2006) is constructed as an extension to WordNet and it provides sentiments in synset level. Positive, negative and neutral values are assigned to synsets by using ternary classifiers and synset glosses. Another study that has been inspirational for the design of our approach is Banea et al. (2008). The authors generate a subjectivity lexicon starting with a set of seed words and then using a similarity measure among the seeds and the candidate words. Concerning the association between colors and words, Mohammad (2011) builds a color-word association lexicon by organizing a crowdsourcing task on Ama</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings ofLREC, volume 6, pages 417--422.</rawString>
</citation>
<citation valid="true">
<title>WordNet An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA ; London.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet An Electronic Lexical Database. The MIT Press, Cambridge, MA ; London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Kjeller Johansen</author>
</authors>
<title>Aristotle on the Sense-organs.</title>
<date>1997</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1520" citStr="Johansen, 1997" startWordPosition="226" endWordPosition="227">luate the quality of the resulting lexicon, we create a gold standard via crowdsourcing and show that a simple classifier relying on the lexicon outperforms two baselines on a sensory classification task, both at word and sentence level. The results confirm the soundness of the proposed approach for the construction of the lexicon and the usefulness of the resource for computational applications. 1 Introduction The connection between our senses and the way we perceive the world has been an important philosophical topic for centuries. According to a classification that dates back to Aristotle (Johansen, 1997), senses can be categorized as sight, hearing, taste, smell and touch. With the help of perception, we can process the data coming from our sensory receptors and become aware of our environment. While interpreting sensory data, we unconsciously use our existing knowledge, experience and understanding of the world to create a private experience (Bernstein, 2010). Language has a significant role as our main communication device to convert our private experiences to shared representations of the environment that we perceive (Majid and Levinson, 2011). As a basic example, giving a name to a color,</context>
</contexts>
<marker>Johansen, 1997</marker>
<rawString>Thomas Kjeller Johansen. 1997. Aristotle on the Sense-organs. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In IN PROCEEDINGS OF THE 41ST ANNUAL MEETING OF THE ASSOCIATIONFOR COMPUTATIONAL LINGUISTICS,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="19107" citStr="Klein and Manning, 2003" startWordPosition="3008" endWordPosition="3011">cordingly, we treat each POS role of the same lemmas as a distinct seed and extract 4287 lemma-POS pairs from 2572 synsets. In this section, we explain the steps to construct our final sensorial lexicon in detail. Corpus and Candidate Words As a corpus, we use a subset of English GigaWord 5th Edition released by Linguistic Data Consortium (LDC)6. This resource is a collection of almost 10 million English newswire documents collected in recent years, whose content sums up to nearly 5 billion words. The richly annotated GigaWord data comprises automatic parses obtained with the Stanford parser (Klein and Manning, 2003) so that we easily have access to the lemma and POS information of each word in the resource. For the scope of this study, we work on a randomly chosen subset that contains 79800 sentences and we define a co-occurrence event as the co-existence of a candidate word and a seed word within a window of 9 words (the candidate word, 4 words to its left and 4 words to its right). In this manner, we analyze the cooccurrence of each unique lemma-POS pair in the corpus with the sense seeds. We eliminate the candidates which have less than 5 cooccurences with the sense categories. Normalized Pointwise Mu</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In IN PROCEEDINGS OF THE 41ST ANNUAL MEETING OF THE ASSOCIATIONFOR COMPUTATIONAL LINGUISTICS, pages 423--430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dumais</author>
</authors>
<title>A solution to plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="9519" citStr="Landauer and Dumais, 1997" startWordPosition="1461" endWordPosition="1464">. Another study that has been inspirational for the design of our approach is Banea et al. (2008). The authors generate a subjectivity lexicon starting with a set of seed words and then using a similarity measure among the seeds and the candidate words. Concerning the association between colors and words, Mohammad (2011) builds a color-word association lexicon by organizing a crowdsourcing task on Amazon Mechanical Turk. Instead, Özbal et al. (2011) aim to automate this process and propose three computational methods based on image analysis, language models and latent semantic analysis (LSA) (Landauer and Dumais, 1997). The authors compare these methods against a gold standard obtained by the crowdsourcing service of Amazon Mechanical Turk. The best performance is obtained by using image features while LSA performs slightly better than the baseline. Finally, there have been efforts in the literature about the association of words with their abstractnessconcreteness and imageability levels. MRC Psycholinguistic Database (Coltheart, 1981) includes abstractness-concreteness and imageability ratings of a small set of words determined according to psycholinguistic experiments. Turney et al. (2011) propose to use</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas K Landauer and Susan T Dumais. 1997. A solution to plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review, 104(2):211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>P Singh</author>
</authors>
<title>Conceptnet - a practical commonsense reasoning tool-kit.</title>
<date>2004</date>
<journal>BT Technology Journal,</journal>
<volume>22</volume>
<issue>4</issue>
<contexts>
<context position="39389" citStr="Liu and Singh, 2004" startWordPosition="6360" endWordPosition="6363">eature for various tasks and applications. The results that we obtain by comparing our lexicon against the gold standard are promising even though not conclusive. The results confirm the soundness of the proposed approach for the construction of the lexicon and the usefulness of the resource for text classification and possibly other computational applications. As future work, we would like to explore the effect of using different kinds of WordNet relations during the bootstrapping phase. It would also be interesting to experiment with relations provided by other resources such as ConceptNet (Liu and Singh, 2004), which is a semantic network containing common sense, cultural and scientific knowledge. We would also like to use the sensorial lexicon for various applicative scenarios such as slanting existing text towards a specific sense with text modification. We believe that our resource could be extremely useful for automatic content personalization according to user profiles. As an example, one can imagine a system that automatically replaces hearing based expressions with sight based ones in pieces of texts for a hearing-impaired person. Finally, we plan to investigate the impact of using sensory i</context>
</contexts>
<marker>Liu, Singh, 2004</marker>
<rawString>H. Liu and P. Singh. 2004. Conceptnet - a practical commonsense reasoning tool-kit. BT Technology Journal, 22(4):211--226, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asifa Majid</author>
<author>Stephen C Levinson</author>
</authors>
<date>2011</date>
<booktitle>The senses in language and culture. The Senses and Society,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="2073" citStr="Majid and Levinson, 2011" startWordPosition="307" endWordPosition="310">ording to a classification that dates back to Aristotle (Johansen, 1997), senses can be categorized as sight, hearing, taste, smell and touch. With the help of perception, we can process the data coming from our sensory receptors and become aware of our environment. While interpreting sensory data, we unconsciously use our existing knowledge, experience and understanding of the world to create a private experience (Bernstein, 2010). Language has a significant role as our main communication device to convert our private experiences to shared representations of the environment that we perceive (Majid and Levinson, 2011). As a basic example, giving a name to a color, such as red, provides a tool to describe a visual feature of an object. In addition to the words which describe the direct sensorial features of objects, languages include many other lexical items that are connected to sense modalities in various semantic roles. For instance, while some words can be used to describe a perception activity (e.g., to smell, to gaze, to listen), others can simply be physical phenomenons that can be perceived by sensory receptors (e.g., flower, fire, sugar). Common usage of language can be very dense in terms of senso</context>
</contexts>
<marker>Majid, Levinson, 2011</marker>
<rawString>Asifa Majid and Stephen C Levinson. 2011. The senses in language and culture. The Senses and Society, 6(1):5--18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>Semeval-2007 task 10: English lexical substitution task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>48--53</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="28724" citStr="McCarthy and Navigli, 2007" startWordPosition="4587" endWordPosition="4590">l for copywriters to decide which sensory modalities to invoke while creating a slogan for a specific product category. 7If the annotators gave additional answers to the expected ones, we considered their answers as correct. 120 4.2 Evaluation Measures Based on the annotation results of our crowdsourcing task, we propose an evaluation technique considering that a lemma-POS or a sentence might be associated with more than one sensory modalities. Similar to the evaluation framework defined by Özbal et al. (2011), we adapt the evaluation measures of SemEval2007 English Lexical Substitution Task (McCarthy and Navigli, 2007), where a system generates one or more possible substitutions for a target word in a sentence preserving its meaning. For a given lemma-POS or a sentence, which we will name as item in the rest of the section, we allow our system to provide as many sensorial associations as it determines using a specific lexicon. While evaluating a sense-item association of a method, a best and an oot score are calculated by considering the number of the annotators who associate that sense with the given item, the number of the annotators who associate any sense with the given item and the number of the senses</context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007. Semeval-2007 task 10: English lexical substitution task. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 48--53. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross T Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the workshop on Human Language Technology, HLT &apos;93,</booktitle>
<pages>303--308</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="18362" citStr="Miller et al., 1993" startWordPosition="2889" endWordPosition="2892">2572 synsets yielding the highest performance when used to learn a sensorial model. 3.3 Sensorial Lexicon Construction Using Corpus Statistics After generating the seed lists consisting of synsets for each sense category with the help of a set of WordNet relations and a bootstrapping process, we use corpus statistics to create our final sensorial lexicon. More specifically, we exploit a probabilistic approach based on the co-occurence of the seeds and the candidate lexical entries. Since working on the synset level would raise the data sparsity problem in synset tagged corpora such as SemCor (Miller et al., 1993) and we need a corpus that provides sufficient statistical information, we migrate from synset level to lexical level. Accordingly, we treat each POS role of the same lemmas as a distinct seed and extract 4287 lemma-POS pairs from 2572 synsets. In this section, we explain the steps to construct our final sensorial lexicon in detail. Corpus and Candidate Words As a corpus, we use a subset of English GigaWord 5th Edition released by Linguistic Data Consortium (LDC)6. This resource is a collection of almost 10 million English newswire documents collected in recent years, whose content sums up to </context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A semantic concordance. In Proceedings of the workshop on Human Language Technology, HLT &apos;93, pages 303--308, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,</booktitle>
<pages>26--34</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5099" citStr="Mohammad and Turney, 2010" startWordPosition="774" endWordPosition="777">sia1, as it reinforces creative thinking and it is commonly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981; Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors (Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our knowledge, there is no attempt in the literature to build a resource that associates words with senses. In this paper, we propose a computational method to automatically generate a sensorial lexicon2 that associates words in English with senses. Our method consists of two main steps. First, we generate the initial seed words for each sense category with the help of a bootstrapping approach. Then, we exploit a corpus based probabilistic technique to create the final lexicon. We evaluate</context>
<context position="8110" citStr="Mohammad and Turney (2010)" startWordPosition="1260" endWordPosition="1263">reating an emotion lexicon from a corpus. Perrie et al. (2013) build a word-emotion association lexicon by using subsets of a human-annotated lexicon as seed sets. The authors use frequencies, counts, or unique seed words extracted from an ngram corpus to create lexicons in different sizes. They propose that larger lexicons with less accurate generation method perform better than the smaller human annotated lexicons. While a major drawback of manually generated lexicons is that they require a great deal of human labor, crowdsourcing services provide an easier procedure for manual annotations. Mohammad and Turney (2010) generate an emotion lexicon by using the crowdsourcing service provided by Amazon Mechanical Turk4 and it covers 14,200 term-emotion associations. 1American Heritage Dictionary (http://ahdictionary.com/) defines synaesthesia in linguistics as the description of one kind of sense impression by using words that normally describe another. 2The sensorial lexicon is publicly available, upon request to the authors. 3http://www.crowdflower.com/ 4http://www.mturk.com/mturk 115 Regarding the sentiment orientations and subjectivity levels of words, Sentiwordnet (Esuli and Sebastiani, 2006) is construct</context>
</contexts>
<marker>Mohammad, Turney, 2010</marker>
<rawString>Saif M Mohammad and Peter D Turney. 2010. Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 26--34. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
</authors>
<title>Colourful language: Measuring word-colour associations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics,</booktitle>
<pages>97--106</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="5144" citStr="Mohammad, 2011" startWordPosition="783" endWordPosition="784">nly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981; Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors (Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our knowledge, there is no attempt in the literature to build a resource that associates words with senses. In this paper, we propose a computational method to automatically generate a sensorial lexicon2 that associates words in English with senses. Our method consists of two main steps. First, we generate the initial seed words for each sense category with the help of a bootstrapping approach. Then, we exploit a corpus based probabilistic technique to create the final lexicon. We evaluate this resource with the help of a gold standa</context>
<context position="9215" citStr="Mohammad (2011)" startWordPosition="1418" endWordPosition="1419">entiment orientations and subjectivity levels of words, Sentiwordnet (Esuli and Sebastiani, 2006) is constructed as an extension to WordNet and it provides sentiments in synset level. Positive, negative and neutral values are assigned to synsets by using ternary classifiers and synset glosses. Another study that has been inspirational for the design of our approach is Banea et al. (2008). The authors generate a subjectivity lexicon starting with a set of seed words and then using a similarity measure among the seeds and the candidate words. Concerning the association between colors and words, Mohammad (2011) builds a color-word association lexicon by organizing a crowdsourcing task on Amazon Mechanical Turk. Instead, Özbal et al. (2011) aim to automate this process and propose three computational methods based on image analysis, language models and latent semantic analysis (LSA) (Landauer and Dumais, 1997). The authors compare these methods against a gold standard obtained by the crowdsourcing service of Amazon Mechanical Turk. The best performance is obtained by using image features while LSA performs slightly better than the baseline. Finally, there have been efforts in the literature about the</context>
<context position="26328" citStr="Mohammad (2011)" startWordPosition="4202" endWordPosition="4203">ord. For instance, for the control sentence “The skin you love to touch”, we only considered as reliable the annotators who associated the sentence with touch and the word touch with the sense touch7. Similarly, for the slogan “The most colourful name in cosmetics.”, an annotator was expected to associate the sentence with at least the sense sight and the word colorful to at least the sense sight. The raters who scored at least 70% accuracy on average on the control questions for the two tasks were considered to be reliable. Each unit was annotated by at least 10 reliable raters. Similarly to Mohammad (2011) and Özbal et al. (2011), we calculated the majority class of each annotated item to measure the agreement among the annotators. Table 2 demonstrates the observed agreement at both word and sentence level. Since 10 annotators participated in the task, the annotations with a majority class greater than 5 can be considered as reliable (Özbal et al., 2011). Indeed, for 85.10% of the word annotations the absolute majority agreed on the same decision, while 77.58% of the annotations in the sentence level have majority class greater than 5. The high agreement observed among the annotators in both ca</context>
</contexts>
<marker>Mohammad, 2011</marker>
<rawString>Saif Mohammad. 2011. Colourful language: Measuring word-colour associations. In Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics, pages 97--106. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gözde Özbal</author>
<author>Carlo Strapparava</author>
<author>Rada Mihalcea</author>
<author>Daniele Pighin</author>
</authors>
<title>A comparison of unsupervised methods to associate colors with words.</title>
<date>2011</date>
<booktitle>In Affective Computing and Intelligent Interaction,</booktitle>
<pages>42--51</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5127" citStr="Özbal et al., 2011" startWordPosition="779" endWordPosition="782">king and it is commonly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981; Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors (Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our knowledge, there is no attempt in the literature to build a resource that associates words with senses. In this paper, we propose a computational method to automatically generate a sensorial lexicon2 that associates words in English with senses. Our method consists of two main steps. First, we generate the initial seed words for each sense category with the help of a bootstrapping approach. Then, we exploit a corpus based probabilistic technique to create the final lexicon. We evaluate this resource with the help</context>
<context position="9346" citStr="Özbal et al. (2011)" startWordPosition="1436" endWordPosition="1439">n to WordNet and it provides sentiments in synset level. Positive, negative and neutral values are assigned to synsets by using ternary classifiers and synset glosses. Another study that has been inspirational for the design of our approach is Banea et al. (2008). The authors generate a subjectivity lexicon starting with a set of seed words and then using a similarity measure among the seeds and the candidate words. Concerning the association between colors and words, Mohammad (2011) builds a color-word association lexicon by organizing a crowdsourcing task on Amazon Mechanical Turk. Instead, Özbal et al. (2011) aim to automate this process and propose three computational methods based on image analysis, language models and latent semantic analysis (LSA) (Landauer and Dumais, 1997). The authors compare these methods against a gold standard obtained by the crowdsourcing service of Amazon Mechanical Turk. The best performance is obtained by using image features while LSA performs slightly better than the baseline. Finally, there have been efforts in the literature about the association of words with their abstractnessconcreteness and imageability levels. MRC Psycholinguistic Database (Coltheart, 1981) </context>
<context position="26352" citStr="Özbal et al. (2011)" startWordPosition="4205" endWordPosition="4208">or the control sentence “The skin you love to touch”, we only considered as reliable the annotators who associated the sentence with touch and the word touch with the sense touch7. Similarly, for the slogan “The most colourful name in cosmetics.”, an annotator was expected to associate the sentence with at least the sense sight and the word colorful to at least the sense sight. The raters who scored at least 70% accuracy on average on the control questions for the two tasks were considered to be reliable. Each unit was annotated by at least 10 reliable raters. Similarly to Mohammad (2011) and Özbal et al. (2011), we calculated the majority class of each annotated item to measure the agreement among the annotators. Table 2 demonstrates the observed agreement at both word and sentence level. Since 10 annotators participated in the task, the annotations with a majority class greater than 5 can be considered as reliable (Özbal et al., 2011). Indeed, for 85.10% of the word annotations the absolute majority agreed on the same decision, while 77.58% of the annotations in the sentence level have majority class greater than 5. The high agreement observed among the annotators in both cases confirms the quality</context>
<context position="28612" citStr="Özbal et al. (2011)" startWordPosition="4571" endWordPosition="4574">high as expected, they have no association with the sense of smell. This kind of analysis could be useful for copywriters to decide which sensory modalities to invoke while creating a slogan for a specific product category. 7If the annotators gave additional answers to the expected ones, we considered their answers as correct. 120 4.2 Evaluation Measures Based on the annotation results of our crowdsourcing task, we propose an evaluation technique considering that a lemma-POS or a sentence might be associated with more than one sensory modalities. Similar to the evaluation framework defined by Özbal et al. (2011), we adapt the evaluation measures of SemEval2007 English Lexical Substitution Task (McCarthy and Navigli, 2007), where a system generates one or more possible substitutions for a target word in a sentence preserving its meaning. For a given lemma-POS or a sentence, which we will name as item in the rest of the section, we allow our system to provide as many sensorial associations as it determines using a specific lexicon. While evaluating a sense-item association of a method, a best and an oot score are calculated by considering the number of the annotators who associate that sense with the g</context>
</contexts>
<marker>Özbal, Strapparava, Mihalcea, Pighin, 2011</marker>
<rawString>Gözde Özbal, Carlo Strapparava, Rada Mihalcea, and Daniele Pighin. 2011. A comparison of unsupervised methods to associate colors with words. In Affective Computing and Intelligent Interaction, pages 42--51. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jessica Perrie</author>
</authors>
<title>Aminul Islam, Evangelos Milios, and Vlado Keselj.</title>
<date>2013</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>137--148</pages>
<publisher>Springer.</publisher>
<marker>Perrie, 2013</marker>
<rawString>Jessica Perrie, Aminul Islam, Evangelos Milios, and Vlado Keselj. 2013. Using google n-grams to expand wordemotion association lexicon. In Computational Linguistics and Intelligent Text Processing, pages 137--148. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mario Pricken</author>
</authors>
<title>Creative Advertising Ideas and Techniques from the World&apos;s Best Campaigns. Thames &amp; Hudson, 2,d edition.</title>
<date>2008</date>
<contexts>
<context position="4615" citStr="Pricken, 2008" startWordPosition="704" endWordPosition="705">s 114–125, Dublin, Ireland, August 23, 2014. Levinson, 2011). As an example, de Araujo et al. (2005) show that the pleasantness level of the same odor can be altered by labeling it as body odor or cheddar cheese. As another motivation, the readability and understandability of text could also be enhanced by using sensory words (Rodriguez-Esteban and Rzhetsky, 2008). Yet another area which would benefit from such a resource is advertisement especially by using synaesthesia1, as it reinforces creative thinking and it is commonly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981; Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors (Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our knowle</context>
</contexts>
<marker>Pricken, 2008</marker>
<rawString>Mario Pricken. 2008. Creative Advertising Ideas and Techniques from the World&apos;s Best Campaigns. Thames &amp; Hudson, 2,d edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rodriguez-Esteban</author>
<author>A Rzhetsky</author>
</authors>
<title>Six senses in the literature. The bleak sensory landscape of biomedical texts.</title>
<date>2008</date>
<journal>EMBO reports,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="4367" citStr="Rodriguez-Esteban and Rzhetsky, 2008" startWordPosition="665" endWordPosition="668">ons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http:// creativecommons.org/licenses/by/4.0/ 114 Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 114–125, Dublin, Ireland, August 23, 2014. Levinson, 2011). As an example, de Araujo et al. (2005) show that the pleasantness level of the same odor can be altered by labeling it as body odor or cheddar cheese. As another motivation, the readability and understandability of text could also be enhanced by using sensory words (Rodriguez-Esteban and Rzhetsky, 2008). Yet another area which would benefit from such a resource is advertisement especially by using synaesthesia1, as it reinforces creative thinking and it is commonly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abs</context>
</contexts>
<marker>Rodriguez-Esteban, Rzhetsky, 2008</marker>
<rawString>R. Rodriguez-Esteban and A. Rzhetsky. 2008. Six senses in the literature. The bleak sensory landscape of biomedical texts. EMBO reports, 9(3):212--215, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Strapparava</author>
<author>A Valitutti</author>
</authors>
<title>WordNet-Affect: an affective extension of WordNet.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>4</volume>
<pages>1083--1086</pages>
<contexts>
<context position="5071" citStr="Strapparava and Valitutti, 2004" startWordPosition="770" endWordPosition="773">ent especially by using synaesthesia1, as it reinforces creative thinking and it is commonly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981; Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors (Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our knowledge, there is no attempt in the literature to build a resource that associates words with senses. In this paper, we propose a computational method to automatically generate a sensorial lexicon2 that associates words in English with senses. Our method consists of two main steps. First, we generate the initial seed words for each sense category with the help of a bootstrapping approach. Then, we exploit a corpus based probabilistic technique to create th</context>
<context position="7136" citStr="Strapparava and Valitutti, 2004" startWordPosition="1106" endWordPosition="1110"> describe the proposed approach in detail. In Section 4, we explain the annotation process that we conducted and the evaluation strategy that we adopted. Finally, in Section 4, we draw our conclusions and outline possible future directions. 2 Related Work Since to the best of our knowledge there is no attempt in the literature to automatically associate words with human senses, in this section we will summarize the most relevant studies that focused on linking words with various other cognitive features. There are several studies dealing with word-emotion associations. WordNet Affect Lexicon (Strapparava and Valitutti, 2004) maps WordNet (Fellbaum, 1998) synsets to various cognitive features (e.g., emotion, mood, behaviour). This resource is created by using a small set of synsets as seeds and expanding them with the help of semantic and lexical relations among these synsets. Yang et al. (2007) propose a collocation model with emoticons instead of seed words while creating an emotion lexicon from a corpus. Perrie et al. (2013) build a word-emotion association lexicon by using subsets of a human-annotated lexicon as seed sets. The authors use frequencies, counts, or unique seed words extracted from an ngram corpus</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>C. Strapparava and A. Valitutti. 2004. WordNet-Affect: an affective extension of WordNet. In Proceedings of LREC, volume 4, pages 1083--1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Daniele Pighin</author>
</authors>
<title>New features for framenet - wordnet mapping.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL&apos;09),</booktitle>
<location>Boulder, CO, USA.</location>
<contexts>
<context position="13445" citStr="Tonelli and Pighin, 2009" startWordPosition="2073" endWordPosition="2076">tion accuracy becomes stable or starts to decrease. The following sections explain the whole process in detail. 116 FrameNet WordNet MapNet SVM Crossvalidation Synset Set Expansion Break-Point Detection Sense Seed Synsets Figure 1: Bootstrapping procedure to expand the seed list. Extending the Seed List with WordNet While the initial sensory seed list obtained from FrameNet contains only 277 lemma-POS pairs, we extend this list by utilizing the semantic relations provided by WordNet. To achieve that, we first map each lemma-POS pair in the seed list to WordNet synsets with the help of MapNet (Tonelli and Pighin, 2009), which is a resource providing direct mapping between WordNet synsets and FrameNet lexical units. Then, we add to the list the synsets that are in WordNet relations direct antonymy, similarity, derived-from, derivationally-related, pertains-to, attribute and also-see with the already existing seeds. For instance, we add the synset containing the verb laugh for the synset of the verb cry with the relation direct antonymy, or the synset containing the adjective chilly for the synset of the adjective cold with the relation similarity. We prefer to use these relations as they might allow us to pr</context>
</contexts>
<marker>Tonelli, Pighin, 2009</marker>
<rawString>Sara Tonelli and Daniele Pighin. 2009. New features for framenet - wordnet mapping. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL&apos;09), Boulder, CO, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Yair Neuman</author>
<author>Dan Assaf</author>
<author>Yohai Cohen</author>
</authors>
<title>Literal and metaphorical sense identification through concrete and abstract context.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on the Empirical Methods in Natural Language Processing,</booktitle>
<pages>680--690</pages>
<contexts>
<context position="5028" citStr="Turney et al., 2011" startWordPosition="765" endWordPosition="768">om such a resource is advertisement especially by using synaesthesia1, as it reinforces creative thinking and it is commonly exploited as an imagination boosting tool in advertisement slogans (Pricken, 2008). As an example, we can consider the slogans “Taste the rainbow” where the sense of sight is combined with the sense of taste or “Hear the big picture” where sight and hearing are merged. There are various studies both in computational linguistics and cognitive science that build resources associating words with several cognitive features such as abstractness-concreteness (Coltheart, 1981; Turney et al., 2011), emotions (Strapparava and Valitutti, 2004; Mohammad and Turney, 2010), colors (Özbal et al., 2011; Mohammad, 2011) and imageability (Coltheart, 1981). However, to the best of our knowledge, there is no attempt in the literature to build a resource that associates words with senses. In this paper, we propose a computational method to automatically generate a sensorial lexicon2 that associates words in English with senses. Our method consists of two main steps. First, we generate the initial seed words for each sense category with the help of a bootstrapping approach. Then, we exploit a corpus</context>
<context position="10104" citStr="Turney et al. (2011)" startWordPosition="1543" endWordPosition="1546">s (LSA) (Landauer and Dumais, 1997). The authors compare these methods against a gold standard obtained by the crowdsourcing service of Amazon Mechanical Turk. The best performance is obtained by using image features while LSA performs slightly better than the baseline. Finally, there have been efforts in the literature about the association of words with their abstractnessconcreteness and imageability levels. MRC Psycholinguistic Database (Coltheart, 1981) includes abstractness-concreteness and imageability ratings of a small set of words determined according to psycholinguistic experiments. Turney et al. (2011) propose to use LSA similarities of words with a set of seed words to automatically calculate the abstractness and concreteness degrees of words. 3 Automatically Associating Senses with Words We adopt a two phased computational approach to construct a large sensorial lexicon. First, we employ a bootstrapping strategy to generate a sufficient number of sensory seed words from a small set of manually selected seed words. In the second phase, we perform a corpus based probabilistic method to estimate the association scores to build a larger lexicon. 3.1 Selecting Seed Words The first phase of the</context>
</contexts>
<marker>Turney, Neuman, Assaf, Cohen, 2011</marker>
<rawString>Peter D Turney, Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identification through concrete and abstract context. In Proceedings of the 2011 Conference on the Empirical Methods in Natural Language Processing, pages 680--690.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th annual meeting on association for computational linguistics,</booktitle>
<pages>417--424</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="33724" citStr="Turney (2002)" startWordPosition="5450" endWordPosition="5451">e, the sensorial lexicon associates the noun wine with [smell, taste, sight]. In this experiment, best scoring considers the associated senses as the best answer, smell, taste, sight according to the previous example, and calculates a score with respect to the best answer in the gold standard and the number of the senses in this answer. Instead, oot scoring takes the first two answers, smell and taste according to the previous example, and assigns the score accordingly. To determine the senses associated with a sentence for the second experiment, we use a method similar to the one proposed by Turney (2002). For each sense, we simply calculate the average score of the lemma-POS pairs in a sentence. We set a threshold value of 0 to decide whether a sentence is associated with a given sense. In this manner, we obtain a sorted list of average sensory scores for each sentence according to the three methods. For instance, the classifier based on the sensorial lexicon associates the sentence Smash it to pieces, love it to bits. with [touch, taste]. For the best score, only touch would be considered, whereas oot would consider both touch and taste. 4.4 Evaluation Results In Table 4, we list the F1 valu</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 417--424. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Valitutti</author>
<author>Carlo Strapparava</author>
<author>Oliviero Stock</author>
</authors>
<title>Developing affective lexical resources.</title>
<date>2004</date>
<journal>PsychNology Journal,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="14272" citStr="Valitutti et al. (2004)" startWordPosition="2201" endWordPosition="2204">rom, derivationally-related, pertains-to, attribute and also-see with the already existing seeds. For instance, we add the synset containing the verb laugh for the synset of the verb cry with the relation direct antonymy, or the synset containing the adjective chilly for the synset of the adjective cold with the relation similarity. We prefer to use these relations as they might allow us to preserve the semantic information as much as possible during the extension process. It is worth mentioning that these relations were also found to be appropriate for preserving the affective connotation by Valitutti et al. (2004). Additionally, we use the relations hyponym and hyponym-instance to enrich the seed set with semantically more specific synsets. For instance, for the noun seed smell, we expand the list with the hyponyms of its synset such as the nouns bouquet, fragrance, fragrancy, redolence and sweetness. Cross-validation for Sensorial Model After obtaining new synsets with the help of WordNet relations in each bootstrapping cycle, we build a five-class sense classifier over the seed synsets defined by their glosses provided in WordNet. Similarly to Dias et al. (2014), we assume that the sense information </context>
</contexts>
<marker>Valitutti, Strapparava, Stock, 2004</marker>
<rawString>Alessandro Valitutti, Carlo Strapparava, and Oliviero Stock. 2004. Developing affective lexical resources. PsychNology Journal, 2(1):61--83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>Wiley-Interscience.</publisher>
<contexts>
<context position="15016" citStr="Vapnik, 1998" startWordPosition="2317" endWordPosition="2318">or instance, for the noun seed smell, we expand the list with the hyponyms of its synset such as the nouns bouquet, fragrance, fragrancy, redolence and sweetness. Cross-validation for Sensorial Model After obtaining new synsets with the help of WordNet relations in each bootstrapping cycle, we build a five-class sense classifier over the seed synsets defined by their glosses provided in WordNet. Similarly to Dias et al. (2014), we assume that the sense information of sensorial synsets is preserved in their definitions. Accordingly, we employ a support vector machine (SVM) (Boser et al., 1992; Vapnik, 1998) model with second degree polynomial kernel by representing the gloss of each synset as a vector of lemmas weighted by their counts. For each synset, its gloss is lemmatized by using Stanford Core NLP5 and cleaned from the stop words. After each iteration cycle, we perform a 10-fold cross-validation in the updated seed list to detect the accuracy of the new sensorial model. For each sense class, we continue iterating and thereby expanding the seed list until the classifier accuracy steadily drops. Table 1 lists the precision (P), recall (R) and F1 values obtained for each sense after each iter</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. Wiley-Interscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changhua Yang</author>
<author>Kevin Hsin-Yih Lin</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Building emotion lexicon from weblog corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>133--136</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7411" citStr="Yang et al. (2007)" startWordPosition="1152" endWordPosition="1155">e there is no attempt in the literature to automatically associate words with human senses, in this section we will summarize the most relevant studies that focused on linking words with various other cognitive features. There are several studies dealing with word-emotion associations. WordNet Affect Lexicon (Strapparava and Valitutti, 2004) maps WordNet (Fellbaum, 1998) synsets to various cognitive features (e.g., emotion, mood, behaviour). This resource is created by using a small set of synsets as seeds and expanding them with the help of semantic and lexical relations among these synsets. Yang et al. (2007) propose a collocation model with emoticons instead of seed words while creating an emotion lexicon from a corpus. Perrie et al. (2013) build a word-emotion association lexicon by using subsets of a human-annotated lexicon as seed sets. The authors use frequencies, counts, or unique seed words extracted from an ngram corpus to create lexicons in different sizes. They propose that larger lexicons with less accurate generation method perform better than the smaller human annotated lexicons. While a major drawback of manually generated lexicons is that they require a great deal of human labor, cr</context>
</contexts>
<marker>Yang, Lin, Chen, 2007</marker>
<rawString>Changhua Yang, Kevin Hsin-Yih Lin, and Hsin-Hsi Chen. 2007. Building emotion lexicon from weblog corpora. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 133--136. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>