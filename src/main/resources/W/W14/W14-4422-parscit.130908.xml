<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002004">
<title confidence="0.978472">
Multi-adaptive Natural Language Generation using Principal Component
Regression
</title>
<author confidence="0.990058">
Dimitra Gkatzia, Helen Hastie, and Oliver Lemon
</author>
<affiliation confidence="0.974009">
School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh
</affiliation>
<email confidence="0.987768">
{dg106, h.hastie, o.lemon}@hw.ac.uk
</email>
<sectionHeader confidence="0.993692" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99995275">
We present FeedbackGen, a system that
uses a multi-adaptive approach to Natu-
ral Language Generation. With the term
‘multi-adaptive’, we refer to a system
that is able to adapt its content to dif-
ferent user groups simultaneously, in our
case adapting to both lecturers and stu-
dents. We present a novel approach to
student feedback generation, which simul-
taneously takes into account the prefer-
ences of lecturers and students when de-
termining the content to be conveyed in
a feedback summary. In this framework,
we utilise knowledge derived from rat-
ings on feedback summaries by extract-
ing the most relevant features using Prin-
cipal Component Regression (PCR) anal-
ysis. We then model a reward function
that is used for training a Reinforcement
Learning agent. Our results with stu-
dents suggest that, from the students’ per-
spective, such an approach can generate
more preferable summaries than a purely
lecturer-adapted approach.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999850965517241">
Summarisation of time-series data refers to the
task of automatically generating reports from at-
tributes whose values change over time. Content
selection is the task of choosing what to say, i.e.
what information is to be included in a report (Re-
iter and Dale, 2000). We consider the task of auto-
matically generating feedback summaries for stu-
dents describing their performance during the lab
of a computer science module over the semester.
Various factors can influence students’ learn-
ing such as difficulty of the material (Person et
al., 1995), workload (Craig et al., 2004), atten-
dance in lectures (Ames, 1992), etc. These fac-
tors change over time and can be interdependent.
In addition, different stakeholders often have con-
flicting goals, needs and preferences, for example
managers with employees, or doctors with patients
and relatives, or novice and expert users. In our
data, for instance, lecturers tend to comment on
the hours that the student studied, whereas the stu-
dents disprefer this content. In our previous work,
we showed that lecturers and students have dif-
ferent perceptions regarding what constitutes good
feedback (Gkatzia et al., 2013). Here, we present a
novel approach to generation by adapting its con-
tent to two user groups simultaneously. Producing
the same summary for two groups is important as
it allows for shared context and meaningful further
discussion and reduces development time.
</bodyText>
<sectionHeader confidence="0.999691" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999636136363636">
Previous work on NLG systems that address more
than one user group employs different versions of
a system for each different user group (Gatt et al.,
2009; Hunter et al., 2011; Mahamood and Reiter,
2011), makes use of User Models (Janarthanam
and Lemon, 2010; Thompson et al., 2004; Zuker-
man and Litman, 2001) or personalises the output
to individual users using rules (Reiter et al., 1999).
Our proposed system adapts the output to the pref-
erences of more than one user type1, lecturers and
students, but instead of developing many different
systems or using User Models that describe differ-
ent users, it attempts to model the middle ground
between the preferences.
In order to identify the users’ preferences, we
apply Principal Components Regression (PCR
(Jolliffe, 1982)) analysis to two datasets that con-
tain lecturers’ and students’ ratings and identify
the most important variables from the principal
components, which are then included in a reward
function. This hand-crafted reward function is
used for training an RL agent for summarisation
</bodyText>
<footnote confidence="0.995981">
1Our approach is different to multi-objective optimisa-
tion.
</footnote>
<page confidence="0.885314">
138
</page>
<bodyText confidence="0.3431835">
Proceedings of the 8th International Natural Language Generation Conference, pages 138–142,
Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics
</bodyText>
<figure confidence="0.875462285714286">
factors week 2 week 3 ... week 10
marks 5 4 ... 5
hours studied 1 2 ... 3
... ... ... ... ...
Raw Data
Trends from Data
factors trend
</figure>
<listItem confidence="0.999025888888889">
(1) marks trend other
(2) hours studied trend increasing
(3) understandability trend decreasing
(4) difficulty trend decreasing
(5) deadlines trend increasing
(6) health issues trend other
(7) personal issues trend decreasing
(8) lectures attended trend other
(9) revision trend decreasing
</listItem>
<sectionHeader confidence="0.530373" genericHeader="method">
Summary
</sectionHeader>
<bodyText confidence="0.988030783783784">
Your overall performance was excellent
during the semester. Keep up the good
work and maybe try some more challeng-
ing exercises. Your attendance was vary-
ing over the semester. Have a think about
how to use time in lectures to improve your
understanding of the material. You spent 2
hours studying the lecture material on
average. You should dedicate more time
to study. You seem to find the material
easier to understand compared to the
beginning of the semester. Keep up the
good work! You revised part of the learn-
ing material. Have a think whether revis-
ing has improved your performance.
Table 1: The table on the top left shows an example of the time-series data. The table on the bottom left
shows an example of described trends. The box on the right presents a target summary.
of time-series data. Our previous work showed
that when comparing RL and supervised learning
in the context of student feedback generation, stu-
dents preferred the output generated by the RL
system (Gkatzia et al., 2014a). Therefore, here, we
used RL rather than a supervised learning method.
The work described here builds on work reported
in (Gkatzia et al., 2014b), which uses as a reward
function the average of the Lecturer-adapted and
Student-adapted reward functions. However, that
method seems to cancel out the preferences of the
two groups whereas PCR is able to identify rele-
vant content for both groups.
In the next section, we describe the data used,
and the methodology for the multi-adaptive NLG,
as well as two alternative systems. In Section 4,
we describe the comparison of these three systems
in a subjective evaluation and present the results in
Section 5. A discussion follows in Section 6 and
finally, future work is discussed in Section 7.
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.999778583333333">
Reinforcement Learning is a machine learning
technique that defines how an agent learns to take
optimal sequences of actions so as to maximize a
cumulative reward (Sutton and Barto, 1998). In
our framework, the task of summarisation of time-
series data is modelled as a Markov Decision Pro-
cess, where the decisions on content selection cor-
respond to a sequence of actions (see Section 3.2).
Temporal Difference (TD) learning (Sutton and
Barto, 1990) is used for training three agents in
a simulated environment to learn to make optimal
content selection decisions:
</bodyText>
<listItem confidence="0.999786">
1. by adapting to both groups simultaneously,
2. by adapting to lecturers,
3. by adapting to students.
</listItem>
<subsectionHeader confidence="0.999335">
3.1 The Data
</subsectionHeader>
<bodyText confidence="0.999974333333333">
For this study, the dataset described in (Gkatzia et
al., 2013) was used. Table 1 presents an exam-
ple of this dataset that describes a student’s learn-
ing factors and an aligned feedback summary pro-
vided by a lecturer. The dataset is composed of
37 similar instances. Each instance consists of
time-series information about the student’s learn-
ing routine and the selected templates that lec-
turers used to provide feedback to this particu-
lar student. A template is a quadruple consist-
ing of an id, a factor (bottom left of Ta-
ble 1), a reference type (trend, week, aver-
age, other) and surface text. For instance,
a template can be (1, marks, trend, “Your marks
were &lt;trend&gt;over the semester”). The lexical
choice for &lt;trend&gt;(i.e. increasing or decreasing)
depends on the values of time-series data. There
is a direct mapping between the values of factor
</bodyText>
<page confidence="0.995477">
139
</page>
<bodyText confidence="0.9983315">
and reference type and the surface text. The time-
series factors are listed in Table 1.
</bodyText>
<subsectionHeader confidence="0.99951">
3.2 Actions and states
</subsectionHeader>
<bodyText confidence="0.999728125">
The state consists of the time-series data and the
number of factors which have so far been selected
to be talked about (the change of the value of this
variable consequently introduces a state change).
In order to explore the state space the agent se-
lects a time-series factor (e.g. marks, deadlines
etc.) and then decides whether to talk about it or
not, until all factors have been considered.
</bodyText>
<subsectionHeader confidence="0.997674">
3.3 Reward function
</subsectionHeader>
<bodyText confidence="0.822483">
The reward function is the following cumulative
multivariate function:
</bodyText>
<equation confidence="0.846427666666667">
Reward = a + ∑n bi * xi + c * length
i=1
where X = {x1, x2, ..., xn} describes the cho-
</equation>
<bodyText confidence="0.999638818181818">
sen combinations of the factor trends observed in
the time-series data and a particular template (i.e.
the way of mentioning a factor). a, b and c are the
correlation coefficients and length describes the
number of factors selected to be conveyed in the
feedback summary. The value of xi is given by
the function:
{ 1, the combination of a factor trend
and a template type is included
0, if not.
The coefficients represent the level of preference
for a factor to be selected and the way it is con-
veyed in the summary. In the training phase, the
agent selects a factor and then decides whether to
talk about it or not. If the agent decides to refer
to a factor, the selection of the template is then
performed in a deterministic way, i.e. it selects the
template that results in higher reward.
Each rated summary is transformed into a vec-
tor of 91 binary features. Each feature describes
both (1) the trend of a factor (e.g. marks increas-
ing, see also Table 1) and (2) the way that this
factor could be conveyed in the summary (e.g.
one possible way is referring to average, another
possible way is referring to increasing/decreasing
trend). If both conditions are met, the value of
the feature is 1, otherwise 0. The 91 binary fea-
tures describe all the different possible combina-
tions. For both the Lecturer-adapted and Student-
adapted systems, the reward function is derived
from a linear regression analysis of the provided
dataset, similarly to Walker et al. (1997) and
Rieser et al. (2010).
</bodyText>
<subsectionHeader confidence="0.964018">
3.3.1 Multi-adaptive Reward Function
</subsectionHeader>
<bodyText confidence="0.998670571428572">
In order to derive a reward function that finds a
balance between the two above mentioned sys-
tems, we use PCR to reduce the dimensionality
of the data and thus reduce the introduced noise.
Through PCR we are able to reduce the number
of features and identify components of factors that
are deemed important to both parties to be used in
the reward function.
PCR is a method that combines Principal Com-
ponent Analysis (PCA) (Jolliffe, 1986) with lin-
ear regression. PCA is a technique for reducing
the dataset dimensionality while keeping as much
of the variance as possible. In PCR, PCA is ini-
tially performed to identify the principal compo-
nents, in our case, the factors that contribute the
most to the variance. Then, regression is applied
to these principal components to obtain a vector
of estimated coefficients. Finally, this vector is
transformed back into the general linear regres-
sion equation. After performing this analysis on
both datasets (students and lecturers), we choose
the most important (i.e. the ones that contribute
the most to the variance) commoncomponents or
features resulting in 18 features which were used
in the reward function. We then design a hand-
crafted reward function taking into account this
PCR analysis. The five most important features
are shown in Table 2.
</bodyText>
<listItem confidence="0.677477333333333">
factor trend way it is mentioned
(1) marks stable average
(2) hours studied decreasing trend
(3) health issues decreasing weeks
(4) lectures attended stable average
(5) personal issues increasing trend
</listItem>
<tableCaption confidence="0.863412">
Table 2: The top 5 features out of the 18 selected
through PCR analysis.
</tableCaption>
<sectionHeader confidence="0.99733" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999834090909091">
FeedbackGen is evaluated with real users against
two alternative systems: one that adapts to lectur-
ers’ preferences and one that adapts to students’
preferences. The output of the three systems is
ranked by 30 computer science students from a va-
riety of years of study. Time-series data of three
students are presented on graphs to each partici-
pant, along with three feedback summaries (each
one generated by a different system), in random
order, and they are asked to rank them in terms of
preference.
</bodyText>
<equation confidence="0.773323">
xi =
</equation>
<page confidence="0.969985">
140
</page>
<bodyText confidence="0.998086722222222">
Student-adapted {Ranking: 1st*} FeedbackGen {Ranking: 2nd*} Lecturer-adapted {Ranking: 3rd*}
You did well at weeks 2, 3, 6, 8, 9 and 10, Your overall performance was Your overall performance was very
but not at weeks 4, 5 and 7. Have a think very good during the semester. good during the semester. Keep up the
about how you were working well and Keep up the good work and maybe good work and maybe try some more
try to apply it to the other labs. Your at- try some more challenging exer- challenging exercises. You found the
tendance was varying over the semester. cises. You found the lab exer- lab exercises not very challenging. You
Have a think about how to use time in lec- cises not very challenging. You could try out some more advanced mate-
tures to improve your understanding of could try out some more advanced rial and exercises. You dedicated more
the material. You found the lab exercises material and exercises. You dedi- time studying the lecture material in the
not very challenging. You could try out cated more time studying the lec- beginning of the semester compared to
some more advanced material and exer- ture material in the beginning of the end of the semester. Have a think
cises. You dedicated more time study- the semester compared to the end about what is preventing you from study-
ing the lecture material in the beginning of the semester. Have a think about ing. You have had other deadlines during
of the semester compared to the end of what is preventing you from study- weeks 6 and 8. You may want to plan
the semester. Have a think about what ing. You have had other dead- your studying and work ahead. You did
is preventing you from studying. Revis- lines during weeks 6 and 8. You not face any health problems during the
ing material during the semester will im- may want to plan your studying and semester. You did not face any personal
prove your performance in the lab. work ahead. issues during the semester.
</bodyText>
<tableCaption confidence="0.626075">
Table 3: The table presents example outputs from the three different systems in order of highest ranked
</tableCaption>
<bodyText confidence="0.882709">
(bold signifies the chosen template content, * denotes significance with p &lt;0.05 after comparing each
system with each other using Mann Whitney U test).
</bodyText>
<sectionHeader confidence="0.999843" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.999841846153846">
Table 3 shows three summaries that have been
generated by the different systems. As we can see
from Table 3, students significantly prefer the out-
put of the system that is trained for their prefer-
ences. In contrast, students significantly dispre-
fer the system that is trained for lecturers’ pref-
erences. Finally, they rank as second the system
that captures the preferences of both lecturers and
students, which shows that it might be feasible to
find middle ground between the preferences of two
user groups. Significance testing is done using
a Mann Whitney U test (p &lt;0.05), performing a
pair-wise comparison.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999969466666667">
The weights derived from the linear regression
analysis vary from the Lecturer-adapted func-
tion to the Student-adapted function. For in-
stance, the lecturers’ most preferred content is
hours studied. This, however, does not factor
heavily into the student’s reward function, apart
from the case where hours studied are de-
creasing or remain stable (see also Table 2).
Students like reading about
personal issues when the number of issues
they faced was increasing over the semester. On
the other hand, lecturers find it useful to give
advice to all students who faced personal issues
during the semester, hencepersonal issues
are included in the top 18 features (Table 2).
Moreover, students seem to mostly prefer a feed-
back summary that mentions the understandability
of the material when it increases, which is positive
feedback.
As reflected in Table 2, the analysis of PCR
showed that both groups found it useful to refer
to the average of marks when they remain stable.
In addition, both groups found understandability
when it increases useful, for a variety of reasons,
for example lecturers might find it useful to en-
courage students whereas students might prefer to
receive positive feedback. Both groups also agree
on hours studied as described earlier. On the
other hand, both groups find mentioning the stu-
dents’ difficulty when it decreases as positive.
</bodyText>
<sectionHeader confidence="0.999575" genericHeader="discussions">
7 Future Work
</sectionHeader>
<bodyText confidence="0.999987833333333">
In the future, we plan to evaluate our methodol-
ogy with lecturers and a larger sample of students
across different disciplines. Moreover, we aim to
port our methodology to a different domain, and
try to find the middle ground between the pref-
erences of novices and expert users when sum-
marising medical data while providing first aid.
Finally, we want to compare the methodology pre-
sented here to a multi-objective optimisation ap-
proach (Fonseca and Flemming, 1993), where the
preferences of each user group will be modelled as
two different optimisation functions.
</bodyText>
<sectionHeader confidence="0.996502" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.988935">
The research leading to this work has re-
ceived funding from the EC’s FP7 programme:
(FP7/2011-14) under grant agreement no. 248765
(Help4Mood).
</bodyText>
<page confidence="0.994826">
141
</page>
<bodyText confidence="0.7635296">
Natalie K. Person, Roger J. Kreuz, Rolf A. Zwaan, and
Arthur C. Graesser. 1995. Pragmatics and peda-
gogy: Conversational rules and politeness strategies
may inhibit effective tutoring. Journal of Cognition
and Instruction, 13(2):161-188.
</bodyText>
<sectionHeader confidence="0.741407" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.920918333333333">
Carole Ames. 1992. Classrooms: Goals, structures,
and student motivation. Journal of Educational Psy-
chology, 84(3):p261–71.
</bodyText>
<reference confidence="0.996951536585366">
Scotty D. Craig, Arthur C. Graesser, Jeremiah Sullins,
and Barry Gholson. 2004. Affect and learning: an
exploratory look into the role of affect in learning
with autotutor.
Carlos Fonseca and Peter Flemming. 1993. Genetic
algorithms for multiobjective optimization: Formu-
lation, discussion and generalization. In 5th Inter-
national Conference on Genetic Algorithms.
Albert Gatt, Francois Portet, Ehud Reiter, James
Hunter, Saad Mahamood, Wendy Moncur, and So-
mayajulu Sripada. 2009. From data to text in the
neonatal intensive care unit: Using NLG technology
for decision support and information management.
AI Communications, 22: 153-186.
Dimitra Gkatzia, Helen Hastie, Srinivasan Ja-
narthanam, and Oliver Lemon. 2013. Generating
student feedback from time-series data using Rein-
forcement Learning. In 14th European Workshop in
Natural Language Generation (ENLG).
Dimitra Gkatzia, Helen Hastie, and Oliver Lemon.
2014a. Comparing multi-label classification with
reinforcement learning for summarisation of time-
series data. In 52nd Annual Meeting of the Associa-
tion for Computational Linguistics (ACL).
Dimitra Gkatzia, Helen Hastie, and Oliver Lemon.
2014b. Finding Middle Ground? Multi-objective
Natural Language Generation from Time-series
data. In 14th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL).
Jim Hunter, Yvonne Freer, Albert Gatt, Yaji Sripada,
Cindy Sykes, and D Westwater. 2011. Bt-nurse:
Computer generation of natural language shift sum-
maries from complex heterogeneous medical data.
American Medical Informatics Association, 18:621-
624.
Srinivasan Janarthanam and Oliver Lemon. 2010.
Adaptive referring expression generation in spoken
dialogue systems: Evaluation with real users. In
11th Annual Meeting of the Special Interest Group
on Discourse and Dialogue (SIGDIAL).
Ian T. Jolliffe. 1982. A note on the use of principal
components in regression. Journal of the Royal Sta-
tistical Society, Series C: 31(3):300–303.
Ian Jolliffe. 1986. Principal Component Analysis.
Springer-Verlag.
Saad Mahamood and Ehud Reiter. 2011. Generating
Affective Natural Language for Parents of Neona-
tal Infants. In 13th European Workshop in Natural
Language Generation (ENLG).
Ehud Reiter and Robert Dale. 2000. Building natu-
ral language generation systems. Cambridge Uni-
versity Press.
Ehud Reiter, Roma Robertson, and Liesl Osman. 1999.
Types of knowledge required to personalise smoking
cessation letters. Artificial Intelligence in Medicine:
Proceedings of the Joint European Conference on
Artificial Intelligence in Medicine and Medical De-
cision Making.
Verena Rieser, Oliver Lemon, and Xingkun Liu. 2010.
Optimising information presentation for spoken dia-
logue systems. In 48th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL).
Richard Sutton and Andrew Barto. 1990. Time deriva-
tive models of pavlovian reinforcement. Learning
and Computational Neuroscience: Foundations of
Adaptive Networks, pages 497–537.
Richart Sutton and Andrew Barto. 1998. Reinforce-
ment learning. MIT Press.
Cynthia A. Thompson, Mehmet H. Goker, and Pat Lan-
gley. 2004. A personalised system for conversa-
tional recommendations. Journal of Artificial Intel-
ligence Research, 21(1).
Marilyn Walker, Diane J Litman, Candace Kamm, and
Alicia Abella. 1997. PARADISE: A framework
for evaluating spoken dialogue agents. In 8th con-
ference on European chapter of the Association for
Computational Linguistics (EACL).
Ingrid Zukerman and Diane Litman. 2001. Natu-
ral language processing and user modeling: Syner-
gies and limitations. In User Modeling and User-
Adapted Interaction, 11(1-2).
</reference>
<page confidence="0.997725">
142
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.872449">
<title confidence="0.9991585">Multi-adaptive Natural Language Generation using Principal Component Regression</title>
<author confidence="0.998603">Dimitra Gkatzia</author>
<author confidence="0.998603">Helen Hastie</author>
<author confidence="0.998603">Oliver Lemon</author>
<affiliation confidence="0.999993">School of Mathematical and Computer Sciences, Heriot-Watt University,</affiliation>
<email confidence="0.965507">h.hastie,</email>
<abstract confidence="0.99619364">We present FeedbackGen, a system that uses a multi-adaptive approach to Natural Language Generation. With the term ‘multi-adaptive’, we refer to a system that is able to adapt its content to different user groups simultaneously, in our case adapting to both lecturers and students. We present a novel approach to student feedback generation, which simultaneously takes into account the preferences of lecturers and students when determining the content to be conveyed in a feedback summary. In this framework, we utilise knowledge derived from ratings on feedback summaries by extracting the most relevant features using Principal Component Regression (PCR) analysis. We then model a reward function that is used for training a Reinforcement Learning agent. Our results with students suggest that, from the students’ perspective, such an approach can generate more preferable summaries than a purely lecturer-adapted approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Scotty D Craig</author>
<author>Arthur C Graesser</author>
<author>Jeremiah Sullins</author>
<author>Barry Gholson</author>
</authors>
<title>Affect and learning: an exploratory look into the role of affect in learning with autotutor.</title>
<date>2004</date>
<contexts>
<context position="1772" citStr="Craig et al., 2004" startWordPosition="269" endWordPosition="272">lecturer-adapted approach. 1 Introduction Summarisation of time-series data refers to the task of automatically generating reports from attributes whose values change over time. Content selection is the task of choosing what to say, i.e. what information is to be included in a report (Reiter and Dale, 2000). We consider the task of automatically generating feedback summaries for students describing their performance during the lab of a computer science module over the semester. Various factors can influence students’ learning such as difficulty of the material (Person et al., 1995), workload (Craig et al., 2004), attendance in lectures (Ames, 1992), etc. These factors change over time and can be interdependent. In addition, different stakeholders often have conflicting goals, needs and preferences, for example managers with employees, or doctors with patients and relatives, or novice and expert users. In our data, for instance, lecturers tend to comment on the hours that the student studied, whereas the students disprefer this content. In our previous work, we showed that lecturers and students have different perceptions regarding what constitutes good feedback (Gkatzia et al., 2013). Here, we presen</context>
</contexts>
<marker>Craig, Graesser, Sullins, Gholson, 2004</marker>
<rawString>Scotty D. Craig, Arthur C. Graesser, Jeremiah Sullins, and Barry Gholson. 2004. Affect and learning: an exploratory look into the role of affect in learning with autotutor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Fonseca</author>
<author>Peter Flemming</author>
</authors>
<title>Genetic algorithms for multiobjective optimization: Formulation, discussion and generalization.</title>
<date>1993</date>
<booktitle>In 5th International Conference on Genetic Algorithms.</booktitle>
<contexts>
<context position="16654" citStr="Fonseca and Flemming, 1993" startWordPosition="2758" endWordPosition="2761">agree on hours studied as described earlier. On the other hand, both groups find mentioning the students’ difficulty when it decreases as positive. 7 Future Work In the future, we plan to evaluate our methodology with lecturers and a larger sample of students across different disciplines. Moreover, we aim to port our methodology to a different domain, and try to find the middle ground between the preferences of novices and expert users when summarising medical data while providing first aid. Finally, we want to compare the methodology presented here to a multi-objective optimisation approach (Fonseca and Flemming, 1993), where the preferences of each user group will be modelled as two different optimisation functions. Acknowledgements The research leading to this work has received funding from the EC’s FP7 programme: (FP7/2011-14) under grant agreement no. 248765 (Help4Mood). 141 Natalie K. Person, Roger J. Kreuz, Rolf A. Zwaan, and Arthur C. Graesser. 1995. Pragmatics and pedagogy: Conversational rules and politeness strategies may inhibit effective tutoring. Journal of Cognition and Instruction, 13(2):161-188. References Carole Ames. 1992. Classrooms: Goals, structures, and student motivation. Journal of E</context>
</contexts>
<marker>Fonseca, Flemming, 1993</marker>
<rawString>Carlos Fonseca and Peter Flemming. 1993. Genetic algorithms for multiobjective optimization: Formulation, discussion and generalization. In 5th International Conference on Genetic Algorithms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert Gatt</author>
<author>Francois Portet</author>
<author>Ehud Reiter</author>
<author>James Hunter</author>
<author>Saad Mahamood</author>
<author>Wendy Moncur</author>
<author>Somayajulu Sripada</author>
</authors>
<title>From data to text in the neonatal intensive care unit: Using NLG technology for decision support and information management.</title>
<date>2009</date>
<journal>AI Communications,</journal>
<volume>22</volume>
<pages>153--186</pages>
<contexts>
<context position="2784" citStr="Gatt et al., 2009" startWordPosition="431" endWordPosition="434"> the students disprefer this content. In our previous work, we showed that lecturers and students have different perceptions regarding what constitutes good feedback (Gkatzia et al., 2013). Here, we present a novel approach to generation by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (</context>
</contexts>
<marker>Gatt, Portet, Reiter, Hunter, Mahamood, Moncur, Sripada, 2009</marker>
<rawString>Albert Gatt, Francois Portet, Ehud Reiter, James Hunter, Saad Mahamood, Wendy Moncur, and Somayajulu Sripada. 2009. From data to text in the neonatal intensive care unit: Using NLG technology for decision support and information management. AI Communications, 22: 153-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitra Gkatzia</author>
<author>Helen Hastie</author>
<author>Srinivasan Janarthanam</author>
<author>Oliver Lemon</author>
</authors>
<title>Generating student feedback from time-series data using Reinforcement Learning.</title>
<date>2013</date>
<booktitle>In 14th European Workshop in Natural Language Generation (ENLG).</booktitle>
<contexts>
<context position="2355" citStr="Gkatzia et al., 2013" startWordPosition="360" endWordPosition="363">, 1995), workload (Craig et al., 2004), attendance in lectures (Ames, 1992), etc. These factors change over time and can be interdependent. In addition, different stakeholders often have conflicting goals, needs and preferences, for example managers with employees, or doctors with patients and relatives, or novice and expert users. In our data, for instance, lecturers tend to comment on the hours that the student studied, whereas the students disprefer this content. In our previous work, we showed that lecturers and students have different perceptions regarding what constitutes good feedback (Gkatzia et al., 2013). Here, we present a novel approach to generation by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises</context>
<context position="6865" citStr="Gkatzia et al., 2013" startWordPosition="1094" endWordPosition="1097">ns so as to maximize a cumulative reward (Sutton and Barto, 1998). In our framework, the task of summarisation of timeseries data is modelled as a Markov Decision Process, where the decisions on content selection correspond to a sequence of actions (see Section 3.2). Temporal Difference (TD) learning (Sutton and Barto, 1990) is used for training three agents in a simulated environment to learn to make optimal content selection decisions: 1. by adapting to both groups simultaneously, 2. by adapting to lecturers, 3. by adapting to students. 3.1 The Data For this study, the dataset described in (Gkatzia et al., 2013) was used. Table 1 presents an example of this dataset that describes a student’s learning factors and an aligned feedback summary provided by a lecturer. The dataset is composed of 37 similar instances. Each instance consists of time-series information about the student’s learning routine and the selected templates that lecturers used to provide feedback to this particular student. A template is a quadruple consisting of an id, a factor (bottom left of Table 1), a reference type (trend, week, average, other) and surface text. For instance, a template can be (1, marks, trend, “Your marks were </context>
</contexts>
<marker>Gkatzia, Hastie, Janarthanam, Lemon, 2013</marker>
<rawString>Dimitra Gkatzia, Helen Hastie, Srinivasan Janarthanam, and Oliver Lemon. 2013. Generating student feedback from time-series data using Reinforcement Learning. In 14th European Workshop in Natural Language Generation (ENLG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitra Gkatzia</author>
<author>Helen Hastie</author>
<author>Oliver Lemon</author>
</authors>
<title>Comparing multi-label classification with reinforcement learning for summarisation of timeseries data.</title>
<date>2014</date>
<booktitle>In 52nd Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="5364" citStr="Gkatzia et al., 2014" startWordPosition="847" endWordPosition="850"> find the material easier to understand compared to the beginning of the semester. Keep up the good work! You revised part of the learning material. Have a think whether revising has improved your performance. Table 1: The table on the top left shows an example of the time-series data. The table on the bottom left shows an example of described trends. The box on the right presents a target summary. of time-series data. Our previous work showed that when comparing RL and supervised learning in the context of student feedback generation, students preferred the output generated by the RL system (Gkatzia et al., 2014a). Therefore, here, we used RL rather than a supervised learning method. The work described here builds on work reported in (Gkatzia et al., 2014b), which uses as a reward function the average of the Lecturer-adapted and Student-adapted reward functions. However, that method seems to cancel out the preferences of the two groups whereas PCR is able to identify relevant content for both groups. In the next section, we describe the data used, and the methodology for the multi-adaptive NLG, as well as two alternative systems. In Section 4, we describe the comparison of these three systems in a su</context>
</contexts>
<marker>Gkatzia, Hastie, Lemon, 2014</marker>
<rawString>Dimitra Gkatzia, Helen Hastie, and Oliver Lemon. 2014a. Comparing multi-label classification with reinforcement learning for summarisation of timeseries data. In 52nd Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitra Gkatzia</author>
<author>Helen Hastie</author>
<author>Oliver Lemon</author>
</authors>
<title>Finding Middle Ground? Multi-objective Natural Language Generation from Time-series data.</title>
<date>2014</date>
<booktitle>In 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="5364" citStr="Gkatzia et al., 2014" startWordPosition="847" endWordPosition="850"> find the material easier to understand compared to the beginning of the semester. Keep up the good work! You revised part of the learning material. Have a think whether revising has improved your performance. Table 1: The table on the top left shows an example of the time-series data. The table on the bottom left shows an example of described trends. The box on the right presents a target summary. of time-series data. Our previous work showed that when comparing RL and supervised learning in the context of student feedback generation, students preferred the output generated by the RL system (Gkatzia et al., 2014a). Therefore, here, we used RL rather than a supervised learning method. The work described here builds on work reported in (Gkatzia et al., 2014b), which uses as a reward function the average of the Lecturer-adapted and Student-adapted reward functions. However, that method seems to cancel out the preferences of the two groups whereas PCR is able to identify relevant content for both groups. In the next section, we describe the data used, and the methodology for the multi-adaptive NLG, as well as two alternative systems. In Section 4, we describe the comparison of these three systems in a su</context>
</contexts>
<marker>Gkatzia, Hastie, Lemon, 2014</marker>
<rawString>Dimitra Gkatzia, Helen Hastie, and Oliver Lemon. 2014b. Finding Middle Ground? Multi-objective Natural Language Generation from Time-series data. In 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jim Hunter</author>
<author>Yvonne Freer</author>
<author>Albert Gatt</author>
<author>Yaji Sripada</author>
<author>Cindy Sykes</author>
<author>D Westwater</author>
</authors>
<title>Bt-nurse: Computer generation of natural language shift summaries from complex heterogeneous medical data.</title>
<date>2011</date>
<journal>American Medical Informatics Association,</journal>
<pages>18--621</pages>
<contexts>
<context position="2805" citStr="Hunter et al., 2011" startWordPosition="435" endWordPosition="438">efer this content. In our previous work, we showed that lecturers and students have different perceptions regarding what constitutes good feedback (Gkatzia et al., 2013). Here, we present a novel approach to generation by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (PCR (Jolliffe, 1982))</context>
</contexts>
<marker>Hunter, Freer, Gatt, Sripada, Sykes, Westwater, 2011</marker>
<rawString>Jim Hunter, Yvonne Freer, Albert Gatt, Yaji Sripada, Cindy Sykes, and D Westwater. 2011. Bt-nurse: Computer generation of natural language shift summaries from complex heterogeneous medical data. American Medical Informatics Association, 18:621-624.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivasan Janarthanam</author>
<author>Oliver Lemon</author>
</authors>
<title>Adaptive referring expression generation in spoken dialogue systems: Evaluation with real users.</title>
<date>2010</date>
<booktitle>In 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL).</booktitle>
<contexts>
<context position="2888" citStr="Janarthanam and Lemon, 2010" startWordPosition="448" endWordPosition="451">nts have different perceptions regarding what constitutes good feedback (Gkatzia et al., 2013). Here, we present a novel approach to generation by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (PCR (Jolliffe, 1982)) analysis to two datasets that contain lecturers’ and students’ ratings and identif</context>
</contexts>
<marker>Janarthanam, Lemon, 2010</marker>
<rawString>Srinivasan Janarthanam and Oliver Lemon. 2010. Adaptive referring expression generation in spoken dialogue systems: Evaluation with real users. In 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian T Jolliffe</author>
</authors>
<title>A note on the use of principal components in regression.</title>
<date>1982</date>
<journal>Journal of the Royal Statistical Society, Series C:</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="3404" citStr="Jolliffe, 1982" startWordPosition="532" endWordPosition="533">ter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (PCR (Jolliffe, 1982)) analysis to two datasets that contain lecturers’ and students’ ratings and identify the most important variables from the principal components, which are then included in a reward function. This hand-crafted reward function is used for training an RL agent for summarisation 1Our approach is different to multi-objective optimisation. 138 Proceedings of the 8th International Natural Language Generation Conference, pages 138–142, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics factors week 2 week 3 ... week 10 marks 5 4 ... 5 hours studied 1 2 ... 3</context>
</contexts>
<marker>Jolliffe, 1982</marker>
<rawString>Ian T. Jolliffe. 1982. A note on the use of principal components in regression. Journal of the Royal Statistical Society, Series C: 31(3):300–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Jolliffe</author>
</authors>
<title>Principal Component Analysis.</title>
<date>1986</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="10311" citStr="Jolliffe, 1986" startWordPosition="1698" endWordPosition="1699">function is derived from a linear regression analysis of the provided dataset, similarly to Walker et al. (1997) and Rieser et al. (2010). 3.3.1 Multi-adaptive Reward Function In order to derive a reward function that finds a balance between the two above mentioned systems, we use PCR to reduce the dimensionality of the data and thus reduce the introduced noise. Through PCR we are able to reduce the number of features and identify components of factors that are deemed important to both parties to be used in the reward function. PCR is a method that combines Principal Component Analysis (PCA) (Jolliffe, 1986) with linear regression. PCA is a technique for reducing the dataset dimensionality while keeping as much of the variance as possible. In PCR, PCA is initially performed to identify the principal components, in our case, the factors that contribute the most to the variance. Then, regression is applied to these principal components to obtain a vector of estimated coefficients. Finally, this vector is transformed back into the general linear regression equation. After performing this analysis on both datasets (students and lecturers), we choose the most important (i.e. the ones that contribute t</context>
</contexts>
<marker>Jolliffe, 1986</marker>
<rawString>Ian Jolliffe. 1986. Principal Component Analysis. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saad Mahamood</author>
<author>Ehud Reiter</author>
</authors>
<title>Generating Affective Natural Language for Parents of Neonatal Infants.</title>
<date>2011</date>
<booktitle>In 13th European Workshop in Natural Language Generation (ENLG).</booktitle>
<contexts>
<context position="2833" citStr="Mahamood and Reiter, 2011" startWordPosition="439" endWordPosition="442"> our previous work, we showed that lecturers and students have different perceptions regarding what constitutes good feedback (Gkatzia et al., 2013). Here, we present a novel approach to generation by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (PCR (Jolliffe, 1982)) analysis to two datasets th</context>
</contexts>
<marker>Mahamood, Reiter, 2011</marker>
<rawString>Saad Mahamood and Ehud Reiter. 2011. Generating Affective Natural Language for Parents of Neonatal Infants. In 13th European Workshop in Natural Language Generation (ENLG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building natural language generation systems.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1461" citStr="Reiter and Dale, 2000" startWordPosition="219" endWordPosition="223">g the most relevant features using Principal Component Regression (PCR) analysis. We then model a reward function that is used for training a Reinforcement Learning agent. Our results with students suggest that, from the students’ perspective, such an approach can generate more preferable summaries than a purely lecturer-adapted approach. 1 Introduction Summarisation of time-series data refers to the task of automatically generating reports from attributes whose values change over time. Content selection is the task of choosing what to say, i.e. what information is to be included in a report (Reiter and Dale, 2000). We consider the task of automatically generating feedback summaries for students describing their performance during the lab of a computer science module over the semester. Various factors can influence students’ learning such as difficulty of the material (Person et al., 1995), workload (Craig et al., 2004), attendance in lectures (Ames, 1992), etc. These factors change over time and can be interdependent. In addition, different stakeholders often have conflicting goals, needs and preferences, for example managers with employees, or doctors with patients and relatives, or novice and expert </context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Ehud Reiter and Robert Dale. 2000. Building natural language generation systems. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Roma Robertson</author>
<author>Liesl Osman</author>
</authors>
<title>Types of knowledge required to personalise smoking cessation letters.</title>
<date>1999</date>
<booktitle>Artificial Intelligence in Medicine: Proceedings of the Joint European Conference on Artificial Intelligence in Medicine and Medical Decision Making.</booktitle>
<contexts>
<context position="3020" citStr="Reiter et al., 1999" startWordPosition="470" endWordPosition="473">tion by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (PCR (Jolliffe, 1982)) analysis to two datasets that contain lecturers’ and students’ ratings and identify the most important variables from the principal components, which are then included in a reward function. This hand-crafted reward</context>
</contexts>
<marker>Reiter, Robertson, Osman, 1999</marker>
<rawString>Ehud Reiter, Roma Robertson, and Liesl Osman. 1999. Types of knowledge required to personalise smoking cessation letters. Artificial Intelligence in Medicine: Proceedings of the Joint European Conference on Artificial Intelligence in Medicine and Medical Decision Making.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Verena Rieser</author>
<author>Oliver Lemon</author>
<author>Xingkun Liu</author>
</authors>
<title>Optimising information presentation for spoken dialogue systems.</title>
<date>2010</date>
<booktitle>In 48th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="9833" citStr="Rieser et al. (2010)" startWordPosition="1615" endWordPosition="1618">ture describes both (1) the trend of a factor (e.g. marks increasing, see also Table 1) and (2) the way that this factor could be conveyed in the summary (e.g. one possible way is referring to average, another possible way is referring to increasing/decreasing trend). If both conditions are met, the value of the feature is 1, otherwise 0. The 91 binary features describe all the different possible combinations. For both the Lecturer-adapted and Studentadapted systems, the reward function is derived from a linear regression analysis of the provided dataset, similarly to Walker et al. (1997) and Rieser et al. (2010). 3.3.1 Multi-adaptive Reward Function In order to derive a reward function that finds a balance between the two above mentioned systems, we use PCR to reduce the dimensionality of the data and thus reduce the introduced noise. Through PCR we are able to reduce the number of features and identify components of factors that are deemed important to both parties to be used in the reward function. PCR is a method that combines Principal Component Analysis (PCA) (Jolliffe, 1986) with linear regression. PCA is a technique for reducing the dataset dimensionality while keeping as much of the variance </context>
</contexts>
<marker>Rieser, Lemon, Liu, 2010</marker>
<rawString>Verena Rieser, Oliver Lemon, and Xingkun Liu. 2010. Optimising information presentation for spoken dialogue systems. In 48th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sutton</author>
<author>Andrew Barto</author>
</authors>
<title>Time derivative models of pavlovian reinforcement. Learning and Computational Neuroscience: Foundations of Adaptive Networks,</title>
<date>1990</date>
<pages>497--537</pages>
<contexts>
<context position="6570" citStr="Sutton and Barto, 1990" startWordPosition="1045" endWordPosition="1048">e systems in a subjective evaluation and present the results in Section 5. A discussion follows in Section 6 and finally, future work is discussed in Section 7. 3 Methodology Reinforcement Learning is a machine learning technique that defines how an agent learns to take optimal sequences of actions so as to maximize a cumulative reward (Sutton and Barto, 1998). In our framework, the task of summarisation of timeseries data is modelled as a Markov Decision Process, where the decisions on content selection correspond to a sequence of actions (see Section 3.2). Temporal Difference (TD) learning (Sutton and Barto, 1990) is used for training three agents in a simulated environment to learn to make optimal content selection decisions: 1. by adapting to both groups simultaneously, 2. by adapting to lecturers, 3. by adapting to students. 3.1 The Data For this study, the dataset described in (Gkatzia et al., 2013) was used. Table 1 presents an example of this dataset that describes a student’s learning factors and an aligned feedback summary provided by a lecturer. The dataset is composed of 37 similar instances. Each instance consists of time-series information about the student’s learning routine and the select</context>
</contexts>
<marker>Sutton, Barto, 1990</marker>
<rawString>Richard Sutton and Andrew Barto. 1990. Time derivative models of pavlovian reinforcement. Learning and Computational Neuroscience: Foundations of Adaptive Networks, pages 497–537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richart Sutton</author>
<author>Andrew Barto</author>
</authors>
<title>Reinforcement learning.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6309" citStr="Sutton and Barto, 1998" startWordPosition="1002" endWordPosition="1005">o groups whereas PCR is able to identify relevant content for both groups. In the next section, we describe the data used, and the methodology for the multi-adaptive NLG, as well as two alternative systems. In Section 4, we describe the comparison of these three systems in a subjective evaluation and present the results in Section 5. A discussion follows in Section 6 and finally, future work is discussed in Section 7. 3 Methodology Reinforcement Learning is a machine learning technique that defines how an agent learns to take optimal sequences of actions so as to maximize a cumulative reward (Sutton and Barto, 1998). In our framework, the task of summarisation of timeseries data is modelled as a Markov Decision Process, where the decisions on content selection correspond to a sequence of actions (see Section 3.2). Temporal Difference (TD) learning (Sutton and Barto, 1990) is used for training three agents in a simulated environment to learn to make optimal content selection decisions: 1. by adapting to both groups simultaneously, 2. by adapting to lecturers, 3. by adapting to students. 3.1 The Data For this study, the dataset described in (Gkatzia et al., 2013) was used. Table 1 presents an example of th</context>
</contexts>
<marker>Sutton, Barto, 1998</marker>
<rawString>Richart Sutton and Andrew Barto. 1998. Reinforcement learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia A Thompson</author>
<author>Mehmet H Goker</author>
<author>Pat Langley</author>
</authors>
<title>A personalised system for conversational recommendations.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>21</volume>
<issue>1</issue>
<contexts>
<context position="2911" citStr="Thompson et al., 2004" startWordPosition="452" endWordPosition="455">s regarding what constitutes good feedback (Gkatzia et al., 2013). Here, we present a novel approach to generation by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (PCR (Jolliffe, 1982)) analysis to two datasets that contain lecturers’ and students’ ratings and identify the most important va</context>
</contexts>
<marker>Thompson, Goker, Langley, 2004</marker>
<rawString>Cynthia A. Thompson, Mehmet H. Goker, and Pat Langley. 2004. A personalised system for conversational recommendations. Journal of Artificial Intelligence Research, 21(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Diane J Litman</author>
<author>Candace Kamm</author>
<author>Alicia Abella</author>
</authors>
<title>PARADISE: A framework for evaluating spoken dialogue agents.</title>
<date>1997</date>
<booktitle>In 8th conference on European chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="9808" citStr="Walker et al. (1997)" startWordPosition="1610" endWordPosition="1613">binary features. Each feature describes both (1) the trend of a factor (e.g. marks increasing, see also Table 1) and (2) the way that this factor could be conveyed in the summary (e.g. one possible way is referring to average, another possible way is referring to increasing/decreasing trend). If both conditions are met, the value of the feature is 1, otherwise 0. The 91 binary features describe all the different possible combinations. For both the Lecturer-adapted and Studentadapted systems, the reward function is derived from a linear regression analysis of the provided dataset, similarly to Walker et al. (1997) and Rieser et al. (2010). 3.3.1 Multi-adaptive Reward Function In order to derive a reward function that finds a balance between the two above mentioned systems, we use PCR to reduce the dimensionality of the data and thus reduce the introduced noise. Through PCR we are able to reduce the number of features and identify components of factors that are deemed important to both parties to be used in the reward function. PCR is a method that combines Principal Component Analysis (PCA) (Jolliffe, 1986) with linear regression. PCA is a technique for reducing the dataset dimensionality while keeping</context>
</contexts>
<marker>Walker, Litman, Kamm, Abella, 1997</marker>
<rawString>Marilyn Walker, Diane J Litman, Candace Kamm, and Alicia Abella. 1997. PARADISE: A framework for evaluating spoken dialogue agents. In 8th conference on European chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingrid Zukerman</author>
<author>Diane Litman</author>
</authors>
<title>Natural language processing and user modeling: Synergies and limitations.</title>
<date>2001</date>
<booktitle>In User Modeling and UserAdapted Interaction,</booktitle>
<pages>11--1</pages>
<contexts>
<context position="2939" citStr="Zukerman and Litman, 2001" startWordPosition="456" endWordPosition="460">tutes good feedback (Gkatzia et al., 2013). Here, we present a novel approach to generation by adapting its content to two user groups simultaneously. Producing the same summary for two groups is important as it allows for shared context and meaningful further discussion and reduces development time. 2 Related Work Previous work on NLG systems that address more than one user group employs different versions of a system for each different user group (Gatt et al., 2009; Hunter et al., 2011; Mahamood and Reiter, 2011), makes use of User Models (Janarthanam and Lemon, 2010; Thompson et al., 2004; Zukerman and Litman, 2001) or personalises the output to individual users using rules (Reiter et al., 1999). Our proposed system adapts the output to the preferences of more than one user type1, lecturers and students, but instead of developing many different systems or using User Models that describe different users, it attempts to model the middle ground between the preferences. In order to identify the users’ preferences, we apply Principal Components Regression (PCR (Jolliffe, 1982)) analysis to two datasets that contain lecturers’ and students’ ratings and identify the most important variables from the principal c</context>
</contexts>
<marker>Zukerman, Litman, 2001</marker>
<rawString>Ingrid Zukerman and Diane Litman. 2001. Natural language processing and user modeling: Synergies and limitations. In User Modeling and UserAdapted Interaction, 11(1-2).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>