<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000916">
<title confidence="0.9863295">
FlowGraph2Text: Automatic Sentence Skeleton Compilation
for Procedural Text Generation
</title>
<author confidence="0.761524">
t&apos;Shinsuke Mori t2Hirokuni Maeta &apos;Tetsuro Sasada 2Koichiro Yoshino
&apos;Atsushi Hashimoto &apos;Takuya Funatomi 2Yoko Yamakata
</author>
<affiliation confidence="0.947188666666667">
&apos;Academic Center for Computing and Media Studies, Kyoto University
2Graduate School of Informatics, Kyoto University
&apos;Graduate School of Law, Kyoto University
</affiliation>
<address confidence="0.816351">
Yoshida Honmachi, Sakyo-ku, Kyoto, Japan
</address>
<email confidence="0.999464">
†forest@i.kyoto-u.ac.jp
</email>
<sectionHeader confidence="0.995701" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9988162">
In this paper we describe a method for
generating a procedural text given its
flow graph representation. Our main
idea is to automatically collect sen-
tence skeletons from real texts by re-
placing the important word sequences
with their type labels to form a skeleton
pool. The experimental results showed
that our method is feasible and has a
potential to generate natural sentences.
</bodyText>
<sectionHeader confidence="0.997909" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993788">
Along with computers penetrating in our daily
life, the needs for the natural language gener-
ation (NLG) technology are increasing more
and more. If computers understand both the
meaning of a procedural text and the progres-
sion status, they can suggest us what to do
next. In such situation they can show sen-
tences describing the next instruction on a dis-
play or speak it.
On this background we propose a method
for generating instruction texts from a flow
graph representation for a series of procedures.
Among various genres of procedural texts, we
choose cooking recipes, because they are one of
the most familiar procedural texts for the pub-
lic. In addition, a computerized help system
proposed by Hashimoto et al. (2008) called
smart kitchen is becoming more and more re-
alistic. Thus we try to generate cooking pro-
cedural texts from a formal representation for
a series of preparation instructions of a dish.
As the formal representation, we adopt the
flow graph representation (Hamada et al.,
2000; Mori et al., 2014), in which the vertices
and the arcs correspond to important objects
</bodyText>
<note confidence="0.4742465">
*His current affiliation is Cybozu Inc., Koraku 1-4-
14, Bunkyo, Tokyo, Japan.
</note>
<bodyText confidence="0.998721818181818">
or actions in cooking and relationships among
them, respectively. We use the flow graphs as
the input and the text parts as the references
for evaluation.
Our generation method first automatically
compiles a set of templates, which we call the
skeleton pool, from a huge number of real pro-
cedural sentences. Then it decomposes the in-
put flow graph into a sequence of subtrees that
are suitable for a sentence. Finally it converts
subtrees into natural language sentences.
</bodyText>
<sectionHeader confidence="0.979114" genericHeader="method">
2 Recipe Flow Graph Corpus
</sectionHeader>
<bodyText confidence="0.999319863636364">
The input of our LNG system is the mean-
ing representation (Mori et al., 2014) for cook-
ing instructions in a recipe. A recipe con-
sists of three parts: a title, an ingredient list,
and sentences describing cooking instructions
(see Figure 1). The meaning of the instruc-
tion sentences is represented by a directed
acyclic graph (DAG) with a root (the final
dish) as shown in Figure 2. Its vertices have
a pair of an important word sequence in the
recipe and its type called a recipe named en-
tity (NE)&apos;. And its arcs denote relationships
between them. The arcs are also classified into
some types. In this paper, however, we do
not use arc types for text generation, because
we want our system to be capable of generat-
ing sentences from flow graphs output by an
automatic video recognition system2 or those
drawn by internet users.
Each vertex of a flow graph has an NE com-
posed of a word sequence in the text and its
type such as food, tool, action, etc. Table 3
</bodyText>
<footnote confidence="0.759776857142857">
&apos;Although the label set contains verb phrases, they
are called named entities.
2By computer vision techniques such as (Regneri et
al., 2013) we may be able to figure out what action
a person takes on what objects. But it is difficult to
distinguish the direct object and the indirect object,
for example.
</footnote>
<page confidence="0.925555">
118
</page>
<bodyText confidence="0.686145">
Proceedings of the 8th International Natural Language Generation Conference, pages 118–122,
Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics
</bodyText>
<equation confidence="0.903008">
1. 両手鍋で油を熱する。
(In a Dutch oven, heat oil.)
セロリと青ねぎとニンニクを加える。
(Add celery, green onions, and garlic.)
1分ほど炒める。
(Cook for about 1 minute.)
</equation>
<listItem confidence="0.930838333333333">
2. ブイヨンと水とマカロニと胡椒を加え
パスタが柔らかくなるまで煮る。
(Add broth, water, macaroni, and pepper,
and simmer until the pasta is tender.)
3. 刻んだセージをまぶす。
(Sprinkle the snipped sage.)
</listItem>
<figureCaption confidence="0.694598">
Figure 1: A recipe example. The sentences are
one of the ideal outputs of our problem. They
are also used as the reference in evaluation.
</figureCaption>
<bodyText confidence="0.9790619">
lists all of the type labels along with the aver-
age numbers of occurrences in a recipe text
and examples. The word sequences of ver-
bal NEs do not include their inflectional end-
ings. From the definition we can say that the
content words are included in the flow graph
representation. Thus an NLG system has to
decide their order and generate the function
words (including inflectional endings for verbs)
to connect them to form a sentence.
</bodyText>
<sectionHeader confidence="0.988785" genericHeader="method">
3 Recipe Text Generation
</sectionHeader>
<bodyText confidence="0.9998972">
The problem in this paper is generating a pro-
cedural text for cooking (ex. Figure 1) from a
recipe flow graph (ex. Figure 2).
Our method is decomposed into two mod-
ules. In this section, we explain them in detail.
</bodyText>
<subsectionHeader confidence="0.997051">
3.1 Skeleton Pool Compilation
</subsectionHeader>
<bodyText confidence="0.9997258">
Before the run time, we first prepare a skele-
ton pool. A skeleton pool is a collection of
skeleton sentences, or skeletons for short, and
a skeleton is a sentence in which NEs have
been replaced with NE tags. The skeletons
are similar to the so-called templates and the
main difference is that the skeletons are auto-
matically converted from real sentences. The
following is the process to prepare a skeleton
pool.
</bodyText>
<listItem confidence="0.99867575">
1. Crawl cooking procedural sentences from
recipe sites.
2. Segment sentences into words by a word
segmenter KyTea (Neubig et al., 2011).
Then recognize recipe NEs by an NE rec-
ognizer PWNER (Mori et al., 2012).
3. Replace the NE instances in the sentences
with NE tags.
</listItem>
<figureCaption confidence="0.9500525">
Figure 2: The flow graph of the example
recipe.
</figureCaption>
<tableCaption confidence="0.974032">
Table 3: Named entity tags with average fre-
quence per recipe.
</tableCaption>
<table confidence="0.960993">
NE tag Meaning Freq.
F Food 11.87
T Tool 3.83
D Duration 0.67
Q Quantity 0.79
Ac Action by the chef 13.83
Af Action by foods 2.04
Sf State of foods 3.02
St State of tools 0.30
</table>
<bodyText confidence="0.996655">
We store skeletons with a key which is the se-
quence of the NE tags in the order of their
occurrence.
</bodyText>
<subsectionHeader confidence="0.998199">
3.2 Sentence Planning
</subsectionHeader>
<bodyText confidence="0.9997895">
Our sentence planner produces a sequence of
subtrees each of which corresponds to a sen-
tence. There are two conditions.
Cond. 1 Each subtree has an Ac as its root.
Cond. 2 Every vertex is included in at least
one subtree.
As a strategy for enumerating subtrees given a
flow graph, we choose the following algorithm.
</bodyText>
<listItem confidence="0.926928111111111">
1. search for an Ac vertex by the depth first
search (DFS),
2. each time it finds an Ac, return the largest
subtree which has an Ac as its root and
contains only unvisited vertices.
3. set the visited-mark to the vertices con-
tained in the returned subtree,
4. go back to 1 unless all the vertices are
marked as visited.
</listItem>
<bodyText confidence="0.9930525">
In DFS, we choose a child vertex randomly
because a recipe flow graph is unordered.
</bodyText>
<page confidence="0.999168">
119
</page>
<tableCaption confidence="0.999624">
Table 1: Corpus specifications.
</tableCaption>
<table confidence="0.983511363636364">
Usage #Recipes #Sent. #NEs #Words #Char.
Test 40 245 1,352 4,005 7,509
NER training 360 2,813 12,101 51,847 97,911
Skeleton pool 100,000 713,524 ∗3,919,964 ∗11,988,344 22,826,496
The numbers with asterisc are estimated values on the NLP result.
Table 2: Statistical results of various skeleton pool sizes.
No. of sentences used for 2,769 11,077 44,308 177,235 708,940
skeleton pool compilation (1/256) (1/64) (1/16) (1/4) (1/1)
No. of uncovered subtrees 52 27 17 9 4
Average no. of skeletons 37.4 124.3 450.2 1598.1 5483.3
BLEU 11.19 11.25 12.86 13.12 13.76
</table>
<subsectionHeader confidence="0.978407">
3.3 Sentence Generation
</subsectionHeader>
<bodyText confidence="0.9876075">
Given a subtree sequence, our text realizer
generates a sentence by the following steps.
</bodyText>
<listItem confidence="0.9905902">
1. Collect skeletons from the pool whose NE
key matches the NE tag sequence speci-
fied by the subtree3.
2. Select the skeleton that maximize a scor-
ing function among collected ones. As the
first trial we use the frequency of skeletons
in the pool as the scoring function.
3. Replace each NE in the skeleton with the
word sequence of the corresponding NE in
the subtree.
</listItem>
<sectionHeader confidence="0.982477" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999915333333333">
We conducted experiments generating texts
from flow graphs. In this section, we report
the coverage and the sentence quality.
</bodyText>
<subsectionHeader confidence="0.978331">
4.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999996444444444">
The recipe flow graph corpus (Mori et al.,
2014) contains 200 recipes. We randomly se-
lected 40 flow graphs as the test data from
which we generate texts. The other 160 recipes
were used to train the NE recognizer PWNER
(Mori et al., 2012) with 200 more recipes that
we annotated with NE tags. To compile the
skeleton pool we crawled 100,000 recipes con-
taining 713,524 sentences (see Table 1).
</bodyText>
<subsectionHeader confidence="0.97718">
4.2 Skeleton Pool Coverage
</subsectionHeader>
<bodyText confidence="0.912632708333333">
First we counted the numbers of the skeletons
that matches with a subtree (Step 1 in Subsec-
tion 3.3) for all the subtrees in the test set by
3This part is language dependent. Since Japanese is
SOV language, the instance of Ac is placed at the last
of the sentence to be generated. Languages of other
types like English may need some rules to change the
NE tag order specified by the subtree into the proper
sentence element order.
changing the number of the recipe sentences
used for the skeleton pool compilation.
Table 2 shows the numbers of subtrees that
do not have any matching skeleton in the pool
(uncovered subtrees) and the average number
of skeletons in the pool for a subtree. From
the results shown in the table we can say that
when we use 100,000 recipes for the skeleton
compilation, our method can generate a sen-
tence for 98.4% subtrees. And the table says
that we can halve the number of uncovered
subtrees by using about four times more sen-
tences. The average number of the skeletons
says that we have enough skeletons in average
to try more sophisticated scoring functions.
</bodyText>
<subsectionHeader confidence="0.991964">
4.3 Text Quality
</subsectionHeader>
<bodyText confidence="0.99986794117647">
To measure the quality of generated texts, we
first calculated the BLEU (N = 4) (Papineni
et al., 2002) with taking the original recipe
texts as the references. The unit in our case
is a sequence of sentences for a dish. Table 2
shows the average BLEU for all the test set.
The result says that the more sentences we use
for the skeleton pool compilation, the better
the generated sentences become.
The absolute BLEU score, however, does
not tell much about the quality of generated
texts. As it is well known, we can sometimes
change the instruction order in dish prepa-
ration. Therefore we conducted a subjective
evaluation in addition. We asked four evalu-
ators to read 10 texts generated from 10 flow
graphs and answer the following questions.
</bodyText>
<listItem confidence="0.884184">
Q1. How many ungrammatical two-word se-
quences does the text contain?
Q2. How many ambiguous wordings do you
find in the text?
</listItem>
<bodyText confidence="0.9988935">
Then we show the evaluators the original
recipe text and asked the following question.
</bodyText>
<page confidence="0.998086">
120
</page>
<tableCaption confidence="0.999554">
Table 4: Result of text quality survey on 10 recipe texts.
</tableCaption>
<table confidence="0.999765785714286">
BLEU Q1 Evaluator 1 Q1 Evaluator 2 Q1 Evaluator 3 Q1 Evaluator 4
Q2 Q3 Q2 Q3 Q2 Q3 Q2 Q3
6.50 13 2 4 11 0 3 12 0 2 7 1 2
7.99 7 2 2 5 2 2 7 1 1 4 2 2
10.09 18 2 4 15 2 1 17 4 1 11 4 2
11.60 24 1 4 13 2 4 18 2 4 13 1 2
13.35 6 1 4 6 0 4 7 1 5 4 1 2
14.70 16 1 4 12 2 4 12 0 3 6 2 2
16.76 9 2 3 6 1 3 7 1 3 5 3 2
19.65 8 2 5 6 1 1 4 1 4 4 2 4
22.85 18 1 4 15 2 5 12 2 2 7 3 2
31.35 5 1 5 5 0 4 5 1 3 5 1 4
Ave. 12.4 1.5 3.9 9.4 1.2 3.1 10.1 1.3 2.8 6.6 2.0 2.4
PCC −0.30 −0.46 +0.57 −0.24 −0.24 +0.36 −0.46 −0.04 +0.26 −0.29 −0.04 +0.70
</table>
<bodyText confidence="0.975649">
PPC stands for Pearson correlation coefficient.
Q3. Will the dish be the same as the origi-
nal recipe when you cook according to the
generated text? Choose the one among 5:
completely, 4: almost, 3: partly, 2: differ-
ent, or 1: unexecutable.
Table 4 shows the result. The generated texts
contain 14.5 sentences in average. The an-
swers to Q1 tell that there are many grammat-
ical errors. We need some mechanism that se-
lects more appropriate skeletons. The number
of ambiguous wordings, however, is very low.
The reason is that the important words are
given along with the subtrees. The average of
the answer to Q3 is 3.05. This result says that
the dish will be partly the same as the original
recipe. There is a room for improvement.
Finally, let us take a look at the correlation
of the result of three Qs with BLEU. The num-
bers of grammatical errors, i.e. the answers
to Q1, has a stronger correlation with BLEU
than those of Q2 asking the semantic quality.
These are consistent with the intuition. The
answer to Q3, asking overall text quality, has
the strongest correlation with BLEU on aver-
age among all the questions. Therefore we can
say that for the time being the objective eval-
uation by BLEU is sufficient to measure the
performance of various improvements.
</bodyText>
<sectionHeader confidence="0.999961" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999841272727273">
Our method can be seen a member of
template-based text generation systems (Re-
iter, 1995). Contrary to the ordinary
template-based approach, our method first au-
tomatically compiles a set of templates, which
we call skeleton pool, by running an NE tagger
on the real texts. This allows us to cope with
the coverage problem with keeping the advan-
tage of the template-based approach, ability
to prevent from generating incomprehensible
sentence structures. The main contribution of
this paper is to use an accurate NE tagger to
convert sentences into skeletons, to show the
coverages of the skeleton pool, and to evaluate
the method in a realistic situation.
Among many applications of our method, a
concrete one is the smart kitchen (Hashimoto
et al., 2008), a computerized cooking help sys-
tem which watches over the chef by the com-
puter vision (CV) technologies etc. and sug-
gests the chef the next action to be taken or
a good way of doing it in a casual manner. In
this application, the text generation module
make a sentence from a subtree specified by
the process supervision module.
There are some other interesting applica-
tions: a help system for internet users to write
good sentences, machine translation of a recipe
in a different language represented as a flow
graph, or automatic recipe generation from
a cooking video based on CV and NLP re-
searches such as (Regneri et al., 2013; Ya-
makata et al., 2013; Yu and Siskind, 2013).
</bodyText>
<sectionHeader confidence="0.999479" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999861285714286">
In this paper, we explained and evaluated our
method for generating a procedural text from
a flow graph representation. The experimental
results showed that our method is feasible es-
pecially when we have huge number of real sen-
tences and that some more sophistications are
possible to generate more natural sentences.
</bodyText>
<page confidence="0.99741">
121
</page>
<sectionHeader confidence="0.99613" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.972640666666667">
This work was supported by JSPS Grants-
in-Aid for Scientific Research Grant Numbers
26280084, 24240030, and 26280039.
</bodyText>
<sectionHeader confidence="0.95896" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999685519230769">
Reiko Hamada, Ichiro Ide, Shuichi Sakai, and Hide-
hiko Tanaka. 2000. Structural analysis of cook-
ing preparation steps in japanese. In Proceedings
of the fifth international workshop on Informa-
tion retrieval with Asian languages, number 8 in
IRAL ’00, pages 157–164.
Atsushi Hashimoto, Naoyuki Mori, Takuya Fu-
natomi, Yoko Yamakata, Koh Kakusho, and
Michihiko Minoh. 2008. Smart kitchen: A user
centric cooking support system. In Proceedings
of the 12th Information Processing and Manage-
ment of Uncertainty in Knowledge-Based Sys-
tems, pages 848–854.
Shinsuke Mori, Tetsuro Sasada, Yoko Yamakata,
and Koichiro Yoshino. 2012. A machine learn-
ing approach to recipe text processing. In Pro-
ceedings of Cooking with Computer workshop.
Shinsuke Mori, Hirokuni Maeta, Yoko Yamakata,
and Tetsuro Sasada. 2014. Flow graph cor-
pus from recipe texts. In Proceedings of the
Nineth International Conference on Language
Resources and Evaluation.
Graham Neubig, Yosuke Nakata, and Shinsuke
Mori. 2011. Pointwise prediction for robust,
adaptable japanese morphological analysis. In
Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. Bleu: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics, pages
311–318.
Michaela Regneri, Marcus Rohrbach, Dominikus
Wetzel, Stefan Thater, Bernt Schiele, and Man-
fred Pinkal. 2013. Grounding action descrip-
tions in videos. Transactions of the Association
for Computational Linguistics, 1(Mar):25–36.
Ehud Reiter. 1995. Nlg vs. templates. In Pro-
ceedings of the the Fifth European Workshop on
Natural Language Generation, pages 147–151.
Yoko Yamakata, Shinji Imahori, Yuichi Sugiyama,
Shinsuke Mori, and Katsumi Tanaka. 2013.
Feature extraction and summarization of recipes
using flow graph. In Proceedings of the 5th In-
ternational Conference on Social Informatics,
LNCS 8238, pages 241–254.
Haonan Yu and Jeffrey Mark Siskind. 2013.
Grounded language learning from video de-
scribed with sentences. In Proceedings of the
51st Annual Meeting of the Association for
Computational Linguistics.
</reference>
<page confidence="0.997473">
122
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.289568">
<title confidence="0.990049">FlowGraph2Text: Automatic Sentence Skeleton for Procedural Text Generation</title>
<author confidence="0.829956">Mori Maeta Sasada Hashimoto Funatomi</author>
<affiliation confidence="0.980243333333333">Center for Computing and Media Studies, Kyoto School of Informatics, Kyoto School of Law, Kyoto</affiliation>
<address confidence="0.47058">Yoshida Honmachi, Sakyo-ku, Kyoto,</address>
<abstract confidence="0.997705272727273">In this paper we describe a method for generating a procedural text given its flow graph representation. Our main idea is to automatically collect sentence skeletons from real texts by replacing the important word sequences with their type labels to form a skeleton pool. The experimental results showed that our method is feasible and has a potential to generate natural sentences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Reiko Hamada</author>
<author>Ichiro Ide</author>
<author>Shuichi Sakai</author>
<author>Hidehiko Tanaka</author>
</authors>
<title>Structural analysis of cooking preparation steps in japanese.</title>
<date>2000</date>
<booktitle>In Proceedings of the fifth international workshop on Information retrieval with Asian languages, number 8 in IRAL ’00,</booktitle>
<pages>157--164</pages>
<contexts>
<context position="1838" citStr="Hamada et al., 2000" startWordPosition="280" endWordPosition="283">kground we propose a method for generating instruction texts from a flow graph representation for a series of procedures. Among various genres of procedural texts, we choose cooking recipes, because they are one of the most familiar procedural texts for the public. In addition, a computerized help system proposed by Hashimoto et al. (2008) called smart kitchen is becoming more and more realistic. Thus we try to generate cooking procedural texts from a formal representation for a series of preparation instructions of a dish. As the formal representation, we adopt the flow graph representation (Hamada et al., 2000; Mori et al., 2014), in which the vertices and the arcs correspond to important objects *His current affiliation is Cybozu Inc., Koraku 1-4- 14, Bunkyo, Tokyo, Japan. or actions in cooking and relationships among them, respectively. We use the flow graphs as the input and the text parts as the references for evaluation. Our generation method first automatically compiles a set of templates, which we call the skeleton pool, from a huge number of real procedural sentences. Then it decomposes the input flow graph into a sequence of subtrees that are suitable for a sentence. Finally it converts su</context>
</contexts>
<marker>Hamada, Ide, Sakai, Tanaka, 2000</marker>
<rawString>Reiko Hamada, Ichiro Ide, Shuichi Sakai, and Hidehiko Tanaka. 2000. Structural analysis of cooking preparation steps in japanese. In Proceedings of the fifth international workshop on Information retrieval with Asian languages, number 8 in IRAL ’00, pages 157–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Hashimoto</author>
<author>Naoyuki Mori</author>
<author>Takuya Funatomi</author>
<author>Yoko Yamakata</author>
<author>Koh Kakusho</author>
<author>Michihiko Minoh</author>
</authors>
<title>Smart kitchen: A user centric cooking support system.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Information Processing and Management of Uncertainty in Knowledge-Based Systems,</booktitle>
<pages>848--854</pages>
<contexts>
<context position="1560" citStr="Hashimoto et al. (2008)" startWordPosition="234" endWordPosition="237">G) technology are increasing more and more. If computers understand both the meaning of a procedural text and the progression status, they can suggest us what to do next. In such situation they can show sentences describing the next instruction on a display or speak it. On this background we propose a method for generating instruction texts from a flow graph representation for a series of procedures. Among various genres of procedural texts, we choose cooking recipes, because they are one of the most familiar procedural texts for the public. In addition, a computerized help system proposed by Hashimoto et al. (2008) called smart kitchen is becoming more and more realistic. Thus we try to generate cooking procedural texts from a formal representation for a series of preparation instructions of a dish. As the formal representation, we adopt the flow graph representation (Hamada et al., 2000; Mori et al., 2014), in which the vertices and the arcs correspond to important objects *His current affiliation is Cybozu Inc., Koraku 1-4- 14, Bunkyo, Tokyo, Japan. or actions in cooking and relationships among them, respectively. We use the flow graphs as the input and the text parts as the references for evaluation.</context>
<context position="13277" citStr="Hashimoto et al., 2008" startWordPosition="2341" endWordPosition="2344">pproach, our method first automatically compiles a set of templates, which we call skeleton pool, by running an NE tagger on the real texts. This allows us to cope with the coverage problem with keeping the advantage of the template-based approach, ability to prevent from generating incomprehensible sentence structures. The main contribution of this paper is to use an accurate NE tagger to convert sentences into skeletons, to show the coverages of the skeleton pool, and to evaluate the method in a realistic situation. Among many applications of our method, a concrete one is the smart kitchen (Hashimoto et al., 2008), a computerized cooking help system which watches over the chef by the computer vision (CV) technologies etc. and suggests the chef the next action to be taken or a good way of doing it in a casual manner. In this application, the text generation module make a sentence from a subtree specified by the process supervision module. There are some other interesting applications: a help system for internet users to write good sentences, machine translation of a recipe in a different language represented as a flow graph, or automatic recipe generation from a cooking video based on CV and NLP researc</context>
</contexts>
<marker>Hashimoto, Mori, Funatomi, Yamakata, Kakusho, Minoh, 2008</marker>
<rawString>Atsushi Hashimoto, Naoyuki Mori, Takuya Funatomi, Yoko Yamakata, Koh Kakusho, and Michihiko Minoh. 2008. Smart kitchen: A user centric cooking support system. In Proceedings of the 12th Information Processing and Management of Uncertainty in Knowledge-Based Systems, pages 848–854.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shinsuke Mori</author>
<author>Tetsuro Sasada</author>
<author>Yoko Yamakata</author>
<author>Koichiro Yoshino</author>
</authors>
<title>A machine learning approach to recipe text processing.</title>
<date>2012</date>
<booktitle>In Proceedings of Cooking with Computer workshop.</booktitle>
<contexts>
<context position="5726" citStr="Mori et al., 2012" startWordPosition="941" endWordPosition="944">e the run time, we first prepare a skeleton pool. A skeleton pool is a collection of skeleton sentences, or skeletons for short, and a skeleton is a sentence in which NEs have been replaced with NE tags. The skeletons are similar to the so-called templates and the main difference is that the skeletons are automatically converted from real sentences. The following is the process to prepare a skeleton pool. 1. Crawl cooking procedural sentences from recipe sites. 2. Segment sentences into words by a word segmenter KyTea (Neubig et al., 2011). Then recognize recipe NEs by an NE recognizer PWNER (Mori et al., 2012). 3. Replace the NE instances in the sentences with NE tags. Figure 2: The flow graph of the example recipe. Table 3: Named entity tags with average frequence per recipe. NE tag Meaning Freq. F Food 11.87 T Tool 3.83 D Duration 0.67 Q Quantity 0.79 Ac Action by the chef 13.83 Af Action by foods 2.04 Sf State of foods 3.02 St State of tools 0.30 We store skeletons with a key which is the sequence of the NE tags in the order of their occurrence. 3.2 Sentence Planning Our sentence planner produces a sequence of subtrees each of which corresponds to a sentence. There are two conditions. Cond. 1 Ea</context>
<context position="8395" citStr="Mori et al., 2012" startWordPosition="1410" endWordPosition="1413">tion among collected ones. As the first trial we use the frequency of skeletons in the pool as the scoring function. 3. Replace each NE in the skeleton with the word sequence of the corresponding NE in the subtree. 4 Evaluation We conducted experiments generating texts from flow graphs. In this section, we report the coverage and the sentence quality. 4.1 Experimental Settings The recipe flow graph corpus (Mori et al., 2014) contains 200 recipes. We randomly selected 40 flow graphs as the test data from which we generate texts. The other 160 recipes were used to train the NE recognizer PWNER (Mori et al., 2012) with 200 more recipes that we annotated with NE tags. To compile the skeleton pool we crawled 100,000 recipes containing 713,524 sentences (see Table 1). 4.2 Skeleton Pool Coverage First we counted the numbers of the skeletons that matches with a subtree (Step 1 in Subsection 3.3) for all the subtrees in the test set by 3This part is language dependent. Since Japanese is SOV language, the instance of Ac is placed at the last of the sentence to be generated. Languages of other types like English may need some rules to change the NE tag order specified by the subtree into the proper sentence el</context>
</contexts>
<marker>Mori, Sasada, Yamakata, Yoshino, 2012</marker>
<rawString>Shinsuke Mori, Tetsuro Sasada, Yoko Yamakata, and Koichiro Yoshino. 2012. A machine learning approach to recipe text processing. In Proceedings of Cooking with Computer workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shinsuke Mori</author>
<author>Hirokuni Maeta</author>
<author>Yoko Yamakata</author>
<author>Tetsuro Sasada</author>
</authors>
<title>Flow graph corpus from recipe texts.</title>
<date>2014</date>
<booktitle>In Proceedings of the Nineth International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="1858" citStr="Mori et al., 2014" startWordPosition="284" endWordPosition="287">method for generating instruction texts from a flow graph representation for a series of procedures. Among various genres of procedural texts, we choose cooking recipes, because they are one of the most familiar procedural texts for the public. In addition, a computerized help system proposed by Hashimoto et al. (2008) called smart kitchen is becoming more and more realistic. Thus we try to generate cooking procedural texts from a formal representation for a series of preparation instructions of a dish. As the formal representation, we adopt the flow graph representation (Hamada et al., 2000; Mori et al., 2014), in which the vertices and the arcs correspond to important objects *His current affiliation is Cybozu Inc., Koraku 1-4- 14, Bunkyo, Tokyo, Japan. or actions in cooking and relationships among them, respectively. We use the flow graphs as the input and the text parts as the references for evaluation. Our generation method first automatically compiles a set of templates, which we call the skeleton pool, from a huge number of real procedural sentences. Then it decomposes the input flow graph into a sequence of subtrees that are suitable for a sentence. Finally it converts subtrees into natural </context>
<context position="8205" citStr="Mori et al., 2014" startWordPosition="1375" endWordPosition="1378"> a sentence by the following steps. 1. Collect skeletons from the pool whose NE key matches the NE tag sequence specified by the subtree3. 2. Select the skeleton that maximize a scoring function among collected ones. As the first trial we use the frequency of skeletons in the pool as the scoring function. 3. Replace each NE in the skeleton with the word sequence of the corresponding NE in the subtree. 4 Evaluation We conducted experiments generating texts from flow graphs. In this section, we report the coverage and the sentence quality. 4.1 Experimental Settings The recipe flow graph corpus (Mori et al., 2014) contains 200 recipes. We randomly selected 40 flow graphs as the test data from which we generate texts. The other 160 recipes were used to train the NE recognizer PWNER (Mori et al., 2012) with 200 more recipes that we annotated with NE tags. To compile the skeleton pool we crawled 100,000 recipes containing 713,524 sentences (see Table 1). 4.2 Skeleton Pool Coverage First we counted the numbers of the skeletons that matches with a subtree (Step 1 in Subsection 3.3) for all the subtrees in the test set by 3This part is language dependent. Since Japanese is SOV language, the instance of Ac is</context>
</contexts>
<marker>Mori, Maeta, Yamakata, Sasada, 2014</marker>
<rawString>Shinsuke Mori, Hirokuni Maeta, Yoko Yamakata, and Tetsuro Sasada. 2014. Flow graph corpus from recipe texts. In Proceedings of the Nineth International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Yosuke Nakata</author>
<author>Shinsuke Mori</author>
</authors>
<title>Pointwise prediction for robust, adaptable japanese morphological analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5653" citStr="Neubig et al., 2011" startWordPosition="927" endWordPosition="930">his section, we explain them in detail. 3.1 Skeleton Pool Compilation Before the run time, we first prepare a skeleton pool. A skeleton pool is a collection of skeleton sentences, or skeletons for short, and a skeleton is a sentence in which NEs have been replaced with NE tags. The skeletons are similar to the so-called templates and the main difference is that the skeletons are automatically converted from real sentences. The following is the process to prepare a skeleton pool. 1. Crawl cooking procedural sentences from recipe sites. 2. Segment sentences into words by a word segmenter KyTea (Neubig et al., 2011). Then recognize recipe NEs by an NE recognizer PWNER (Mori et al., 2012). 3. Replace the NE instances in the sentences with NE tags. Figure 2: The flow graph of the example recipe. Table 3: Named entity tags with average frequence per recipe. NE tag Meaning Freq. F Food 11.87 T Tool 3.83 D Duration 0.67 Q Quantity 0.79 Ac Action by the chef 13.83 Af Action by foods 2.04 Sf State of foods 3.02 St State of tools 0.30 We store skeletons with a key which is the sequence of the NE tags in the order of their occurrence. 3.2 Sentence Planning Our sentence planner produces a sequence of subtrees each</context>
</contexts>
<marker>Neubig, Nakata, Mori, 2011</marker>
<rawString>Graham Neubig, Yosuke Nakata, and Shinsuke Mori. 2011. Pointwise prediction for robust, adaptable japanese morphological analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="9789" citStr="Papineni et al., 2002" startWordPosition="1656" endWordPosition="1659">n in the pool (uncovered subtrees) and the average number of skeletons in the pool for a subtree. From the results shown in the table we can say that when we use 100,000 recipes for the skeleton compilation, our method can generate a sentence for 98.4% subtrees. And the table says that we can halve the number of uncovered subtrees by using about four times more sentences. The average number of the skeletons says that we have enough skeletons in average to try more sophisticated scoring functions. 4.3 Text Quality To measure the quality of generated texts, we first calculated the BLEU (N = 4) (Papineni et al., 2002) with taking the original recipe texts as the references. The unit in our case is a sequence of sentences for a dish. Table 2 shows the average BLEU for all the test set. The result says that the more sentences we use for the skeleton pool compilation, the better the generated sentences become. The absolute BLEU score, however, does not tell much about the quality of generated texts. As it is well known, we can sometimes change the instruction order in dish preparation. Therefore we conducted a subjective evaluation in addition. We asked four evaluators to read 10 texts generated from 10 flow </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michaela Regneri</author>
<author>Marcus Rohrbach</author>
<author>Dominikus Wetzel</author>
<author>Stefan Thater</author>
<author>Bernt Schiele</author>
<author>Manfred Pinkal</author>
</authors>
<title>Grounding action descriptions in videos. Transactions of the Association for Computational Linguistics,</title>
<date>2013</date>
<contexts>
<context position="3605" citStr="Regneri et al., 2013" startWordPosition="588" endWordPosition="591"> named entity (NE)&apos;. And its arcs denote relationships between them. The arcs are also classified into some types. In this paper, however, we do not use arc types for text generation, because we want our system to be capable of generating sentences from flow graphs output by an automatic video recognition system2 or those drawn by internet users. Each vertex of a flow graph has an NE composed of a word sequence in the text and its type such as food, tool, action, etc. Table 3 &apos;Although the label set contains verb phrases, they are called named entities. 2By computer vision techniques such as (Regneri et al., 2013) we may be able to figure out what action a person takes on what objects. But it is difficult to distinguish the direct object and the indirect object, for example. 118 Proceedings of the 8th International Natural Language Generation Conference, pages 118–122, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics 1. 両手鍋で油を熱する。 (In a Dutch oven, heat oil.) セロリと青ねぎとニンニクを加える。 (Add celery, green onions, and garlic.) 1分ほど炒める。 (Cook for about 1 minute.) 2. ブイヨンと水とマカロニと胡椒を加え パスタが柔らかくなるまで煮る。 (Add broth, water, macaroni, and pepper, and simmer until the pasta is </context>
</contexts>
<marker>Regneri, Rohrbach, Wetzel, Thater, Schiele, Pinkal, 2013</marker>
<rawString>Michaela Regneri, Marcus Rohrbach, Dominikus Wetzel, Stefan Thater, Bernt Schiele, and Manfred Pinkal. 2013. Grounding action descriptions in videos. Transactions of the Association for Computational Linguistics, 1(Mar):25–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>Nlg vs. templates.</title>
<date>1995</date>
<booktitle>In Proceedings of the the Fifth European Workshop on Natural Language Generation,</booktitle>
<pages>147--151</pages>
<contexts>
<context position="12611" citStr="Reiter, 1995" startWordPosition="2234" endWordPosition="2236">ook at the correlation of the result of three Qs with BLEU. The numbers of grammatical errors, i.e. the answers to Q1, has a stronger correlation with BLEU than those of Q2 asking the semantic quality. These are consistent with the intuition. The answer to Q3, asking overall text quality, has the strongest correlation with BLEU on average among all the questions. Therefore we can say that for the time being the objective evaluation by BLEU is sufficient to measure the performance of various improvements. 5 Related Work Our method can be seen a member of template-based text generation systems (Reiter, 1995). Contrary to the ordinary template-based approach, our method first automatically compiles a set of templates, which we call skeleton pool, by running an NE tagger on the real texts. This allows us to cope with the coverage problem with keeping the advantage of the template-based approach, ability to prevent from generating incomprehensible sentence structures. The main contribution of this paper is to use an accurate NE tagger to convert sentences into skeletons, to show the coverages of the skeleton pool, and to evaluate the method in a realistic situation. Among many applications of our me</context>
</contexts>
<marker>Reiter, 1995</marker>
<rawString>Ehud Reiter. 1995. Nlg vs. templates. In Proceedings of the the Fifth European Workshop on Natural Language Generation, pages 147–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoko Yamakata</author>
<author>Shinji Imahori</author>
<author>Yuichi Sugiyama</author>
<author>Shinsuke Mori</author>
<author>Katsumi Tanaka</author>
</authors>
<title>Feature extraction and summarization of recipes using flow graph.</title>
<date>2013</date>
<booktitle>In Proceedings of the 5th International Conference on Social Informatics, LNCS 8238,</booktitle>
<pages>241--254</pages>
<marker>Yamakata, Imahori, Sugiyama, Mori, Tanaka, 2013</marker>
<rawString>Yoko Yamakata, Shinji Imahori, Yuichi Sugiyama, Shinsuke Mori, and Katsumi Tanaka. 2013. Feature extraction and summarization of recipes using flow graph. In Proceedings of the 5th International Conference on Social Informatics, LNCS 8238, pages 241–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haonan Yu</author>
<author>Jeffrey Mark Siskind</author>
</authors>
<title>Grounded language learning from video described with sentences.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Yu, Siskind, 2013</marker>
<rawString>Haonan Yu and Jeffrey Mark Siskind. 2013. Grounded language learning from video described with sentences. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>