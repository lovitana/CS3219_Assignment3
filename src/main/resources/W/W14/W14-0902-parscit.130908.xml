<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004351">
<title confidence="0.967001">
Computational analysis to explore authors’ depiction of characters
</title>
<author confidence="0.998225">
Joseph Bullard
</author>
<affiliation confidence="0.999017">
Dept. of Computer Science
Rochester Institute of Technology
</affiliation>
<email confidence="0.981841">
jtb4478@cs.rit.edu
</email>
<author confidence="0.976987">
Cecilia Ovesdotter Alm
</author>
<affiliation confidence="0.9936225">
Dept. of English
Rochester Institute of Technology
</affiliation>
<email confidence="0.994354">
coagla@rit.edu
</email>
<sectionHeader confidence="0.993797" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954409090909">
This study involves automatically identi-
fying the sociolinguistic characteristics of
fictional characters in plays by analyz-
ing their written “speech”. We discuss
three binary classification problems: pre-
dicting the characters’ gender (male vs.
female), age (young vs. old), and socio-
economic standing (upper-middle class vs.
lower class). The text corpus used is
an annotated collection of August Strind-
berg and Henrik Ibsen plays, translated
into English, which are in the public do-
main. These playwrights were chosen for
their known attention to relevant socio-
economic issues in their work. Linguis-
tic and textual cues are extracted from the
characters’ lines (turns) for modeling pur-
poses. We report on the dataset as well
as the performance and important features
when predicting each of the sociolinguis-
tic characteristics, comparing intra- and
inter-author testing.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999874561403509">
A speech community has sociolinguistic proper-
ties. Social variables influencing verbal inter-
action include, for example, geographical back-
ground, gender, age, ethnicity, and class. Writ-
ers and playwrights, in turn, use their knowledge
of social verbal markers to generate credible and
compelling characters. The focus of this study is
the creation of an annotated dataset and computa-
tional model for predicting the social-biographical
aspects of fictional characters based on features
of their written “speech” in dramatic plays. The
plays used here are authored by August Strind-
berg and Henrik Ibsen, two Scandinavian play-
wrights known for creating characters and stories
that acted as social commentary and were contro-
versial when they were first written. These authors
are also recognized for their contributions in shap-
ing modern drama. Their attention to social issues
makes these plays and characters highly relevant
in constructing such a model to shed light on how
these authors’ translated texts portray social vari-
ables. Interlocutors’ social attributes (such as their
gender, age, social class, and ethnicity) are known
to correlate with language behavior, and they tap
into dimensions of language behavior that are of
central interest to the humanities. For instance,
anecdotal evidence suggests that large-scale cor-
pus analysis can show how society collectively as-
cribes certain roles to male versus female referents
in text (cf. Lindquist, 2009).
Studying these authors and texts from the point
of view of corpus-oriented computational soci-
olinguistics can also help us examine the authors’
differences in production, descriptively. This is
useful as a complementary approach to the more
traditional close reading methodology common in
literary research, through which their texts are
usually approached. On a broader scale, the study
can contribute valuable insights to a theory of lin-
guistic text criticism. These authors are part of a
global literary canon, and their plays are arguably
more often performed in translation than in their
Scandinavian originals. Accordingly, we focus on
analyzing texts translated into English.
We focus on sociolinguistic characteristics that
are assigned to each character and that can be
described as translating into three binary classifi-
cation problems: predicting the characters’ gen-
der (male vs. female), age (young vs. old), and
socioeconomic standing or class (upper-middle
class vs. lower class). The text corpus is
annotated by assigning each of the characters
that match specified criteria a value in each of
the characteristics. We do this at the charac-
ter level, joining all dialogic lines of a charac-
ter into one instance. The work was accom-
plished through the use of computational tools
</bodyText>
<page confidence="0.992738">
11
</page>
<note confidence="0.793056">
Proceedings of the 3rd Workshop on Computational Linguistics for Literature (CLfL) @ EACL 2014, pages 11–16,
Gothenburg, Sweden, April 27, 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999244">
for natural language processing, including Python
(http://www.python.org/), the Natural Language
Toolkit (http://www.nltk.org/) for part of the pre-
processing, and the scikit-learn machine
learning library for the computational modeling.
Translated texts that reside in the public do-
main were collected from the Gutenberg Archive
(http://www.gutenburg.org/wiki/Main Page/).
</bodyText>
<sectionHeader confidence="0.993425" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999978085365854">
A pilot study by Hota et al. (2006) on automatic
gender identification in Shakespeare’s texts, as
well as a few primarily gender-oriented studies
surveyed in Garera and Yarowsky (2009), have set
the stage for further inquiry. The latter study ex-
panded on previous work by exploring three at-
tributes: gender, age, and native/non-native speak-
ers. There have been previous avenues of re-
search into categorizing speakers based on differ-
ent individual sociolinguistic factors. However,
not many studies have attempted this categoriza-
tion with fictional characters. Literary texts are
complex, reflecting authors’ decision-making and
creative processes. From the perspective of digi-
tal humanities, such a focus complements compu-
tational sociolinguistic modeling of contemporary
user-generated text types (such as emails, or blogs
(Rosenthal and McKeown, 2011)). As Lindquist
(2009) points out, social data for interlocutors is
less often attached to openly available linguistic
corpora, and interest is strong in developing cor-
pus methods to help explore social language be-
havior (see Lindquist (2009) and Baker (2010)).
Previous investigation into social dimensions of
language has established strong links between lan-
guage and social attributes of speech communi-
ties (for an overview, see Mesthrie et al. (2009)).
However, such inquiry has generally had a firm
foundation in field-based research and has usually
focused on one or just a few linguistic variables
(such as how the pronunciation of certain sounds
aligns with social stratification (Labov, 1972)).
Moreover, previous scholarship has chiefly fo-
cused on the spoken rather than the written mode.
Garera and Yarowsky (2009) and Boulis and Os-
tendorf (2005) take into account the interlocutors’
speech for analysis. In contrast, we experiment
with the challenge of using only sociolinguisti-
cally relevant knowledge coded in the text of char-
acters’ lines. Thus, our approach is more simi-
lar to Hota et al.’s (2006) work on Shakespeare.
The characters’ lines do not include the metadata
needed for considering spoken features, since usu-
ally these are added at the discretion of the per-
former. This may make our problem more chal-
lenging, since some of these indicators may be
reliable for identifying gender, such as backchan-
nel responses and affirmations from females, and
assertively “holding the floor” with filled pauses
from males (Boulis and Ostendorf, 2005). More-
over, there are prosodic features that clearly dif-
fer between males and females due to physical
characteristics (e.g. Fo, predominant for pitch per-
ception). We do not take advantage of acous-
tic/prosodic cues in this work. Our text is also
artificial discourse, as opposed to natural speech;
therefore these characters’ lines may rather ex-
press how writers choose to convey sociolinguistic
attributes of their characters.
In terms of features, we have explored observa-
tions from previous studies. For instance, com-
mon lexical items have been shown successful,
with males tending to use more obscenities, espe-
cially when talking to other males (Boulis and Os-
tendorf, 2005), and females tending to use more
third-person pronouns. Phrases also tended to be
more useful than unigrams, though whether the
commonly-used words tend to be content-bearing
remains a question according to Boulis and Os-
tendorf (2005). Tackling another form of text,
Kao and Jurafksy (2012) examined the statisti-
cal properties of 20th century acknowledged ver-
sus amateur poets in terms of style and content
substance, finding, for example, that lexical afflu-
ence and properties coherent with imagism, as an
aesthetic theorized ideal, distinguished contempo-
rary professionals’ poetics, while sound phenom-
ena played a lesser role, and amateurs preferred
the use of more explicit negative vocabulary than
professionals. In our study, we focus on data col-
lection, corpus analysis, and exploratory experi-
mentation with classification algorithms.
</bodyText>
<sectionHeader confidence="0.997305" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999972625">
The texts used were freely available transcriptions
from the Gutenberg Archive. English transla-
tions of public-domain plays by August Strindberg
and Henrik Ibsen were collected from the archive,
from various translators and years of release. As
noted above, these plays are often performed in
English, and we assume that the translations will
convey relevant linguistic cues, as influenced by
</bodyText>
<page confidence="0.995646">
12
</page>
<table confidence="0.9978785">
Strindberg Ibsen Total
# of plays 11 12 23
# of characters 65 93 158
# of lines 6555 12306 18861
</table>
<tableCaption confidence="0.9964405">
Table 1: Distribution of plays, characters, and
lines between Strindberg and Ibsen in the dataset.
</tableCaption>
<table confidence="0.999316">
Character Gender Age Class
Christine Female Young Upper
Jean Male Young Lower
Miss Julia Female Young Lower
</table>
<tableCaption confidence="0.999719">
Table 2: Example annotations from Miss Julia.
</tableCaption>
<bodyText confidence="0.99999146875">
authors, as well as translators. We assume that
the translators intended to replicate as closely as
possible the voice of the original author, as this is
generally the function of literary translation, but
we recognize the potential for loss of information.
The texts were minimally pre-processed (such
as removing licensing and introduction text), leav-
ing only the written lines-to-be-spoken of the char-
acters. Each character’s lines were automatically
extracted and aggregated using a Python script.
Characters should have a significant number of
lines (equal to or greater than fifteen in his or her
respective play) to be considered.1 We also record
metadata per character, such as the play title, the
play translator, and the URL of the original play
text on Gutenberg. The basic characteristics of the
resulting dataset are shown in Table 1.
In terms of annotation, characters from each
play were annotated by a third party and assigned
characteristics primarily according to the plot de-
scriptions on Wikipedia of their respective plays of
origin. The characteristics considered were gen-
der (male vs. female), age (young vs. old), and so-
cioeconomic standing or class (upper-middle class
vs. lower class). For example, for age, characters
with children are considered old, and those chil-
dren are considered young. A childless character
whose peers have children or who has experienced
life-changing events typically associated with age
(e.g. widows/widowers) is also old, unless sepa-
rately noted otherwise. The gender annotations
were validated by a project-independent person
</bodyText>
<footnote confidence="0.992696166666667">
1The only exception to this rule is Mrs. X from Strind-
berg’s The Stronger. She has only 11 separate “lines”, but
also has the only speaking part for the entire play, which is a
single act of substantial length. We also note that while an ad
hoc threshold for lines was used, future work could explore
principled ways to set it.
</footnote>
<table confidence="0.99941625">
Attribute Annotation Strindberg Ibsen
Gender Male / Female 42 / 23 61 / 32
Age Old / Young 46 / 19 61 / 32
Class Upper / Lower 57 / 8 83 / 10
</table>
<tableCaption confidence="0.99456">
Table 3: Character attribute distributions for gen-
</tableCaption>
<bodyText confidence="0.968481636363636">
der, age, and class for each author.
in Scandinavia (Swedish native speaker) based on
her knowledge of Scandinavian naming conven-
tions. Example character annotations for Strind-
berg’s well-known naturalistic play Miss Julia (or
Miss Julie) are shown in Table 2. As seen in Table
3, the imbalance of class labels presents the great-
est problem for our model. Baselines of 88% and
89% upper class for Strindberg and Ibsen, respec-
tively, indicate that there may be less information
to be extracted for class.
</bodyText>
<sectionHeader confidence="0.998687" genericHeader="method">
4 Models
</sectionHeader>
<bodyText confidence="0.999836857142857">
Here we describe the design and performance of
computational models for predicting a character’s
gender, age, and class for Strindberg and Ibsen,
yielding six models in total. Logistic regression,
implemented in Python with the scikit-learn
machine learning library (Pedregosa et al., 2011),
is used for all classification models.
</bodyText>
<subsectionHeader confidence="0.991488">
4.1 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.9999728">
Many features were examined, some inspired
by previous analyses in the literature, such as
type-token ratio, subordinate clauses, and wh-
questions, as well as some exploratory features,
such as honorific terms of address. A full list
of the features examined is shown in Table 4.
All features were automatically extracted using
Python. We use honorifics here to mean com-
mon formal terms of address during the time pe-
riod (sir, madam, lord, Mr., Mrs., etc.). It seems
intuitive that such terms may be used differently
based on class or possibly age (e.g. lower class
using more higher terms of address when speaking
to their superiors). We use family words to mean
anything that indicates a familial relationship (fa-
ther, daughter, nephew, etc.). The use of such
words may be affected by gender roles (Hota et al.,
2006). Part-of-speech tagging was accomplished
using the Natural Language Toolkit (NLTK) (Bird
et al., 2009).
</bodyText>
<page confidence="0.998493">
13
</page>
<tableCaption confidence="0.4692415">
Linguistic features
Table 4: List of linguistic features examined for
</tableCaption>
<bodyText confidence="0.9980405">
the models. All features, with the exception of the
last three in the right column, were measured once
as raw counts and once as the fraction of the over-
all words for a given character.
</bodyText>
<subsectionHeader confidence="0.817257">
4.2 Cross-Author Validation
</subsectionHeader>
<bodyText confidence="0.999987451612903">
We compared translations of Strindberg and Ib-
sen’s use of language to convey sociolinguistic
attributes. This was done for each of the three
attributes of interest (gender, age, and class) by
training one model for each author, then using it to
classify the other author’s characters. We accom-
plish this by defining a cross-author validation
procedure, a variation of the standard k-fold cross-
validation procedure in which the trained model in
each fold is used to predict both its own test set
and the test set of the other author. This proce-
dure is explained visually in Figure 1. The pro-
cedure is especially interesting as these two au-
thors were contemporaries and dealt with topics of
social commentary in their works, although from
their own perspectives.
The results of cross-author validation are shown
in Table 5 as a matrix where the row is the au-
thor used for training, the column is the author
used for testing, and the value inside a cell is
the average accuracy over all iterations of cross-
author validation. Majority class baselines are also
shown. As expected, the models for each author’s
texts were better at predicting themselves than the
other author, with a couple of exceptions. For
age, the Strindberg-trained model was still able to
improve on Ibsen’s baseline, but not vice versa.
One possible explanation could be that common
features between their depictions of age might be
more useful for one author than the other. An-
other interesting exception is in the class models
</bodyText>
<figure confidence="0.947115">
Train
Test S
Test I
Train
</figure>
<figureCaption confidence="0.962831333333333">
Figure 1: Example of one fold of cross-author
validation for Strindberg (S) and Ibsen (I). Ar-
rows indicate testing. Each author has its own 5-
fold cross-validation, but in each fold, the trained
model is tested on both its own test set and the test
set of the other author.
</figureCaption>
<table confidence="0.890752">
Gender Age Class
S I S I S I
Strindberg (S) 68 60 74 70 89 90
Ibsen (I) 61 67 70 74 91 90
Baseline 65 66 71 66 88 89
</table>
<tableCaption confidence="0.825297">
Table 5: Results of cross-author validation (see
</tableCaption>
<figureCaption confidence="0.5915538">
Figure 1). Rows are the author used for training,
columns are the author used for testing, and the
value in the cell is the average accuracy over 500
iterations of 5-fold cross-validation. Accuracies
above majority class baselines are shown in bold.
</figureCaption>
<bodyText confidence="0.999576285714286">
for both authors, which performed slightly above
high baselines for the opposite authors as well as
their own. While class improvements are recog-
nizably marginal (and not claimed to be signifi-
cant), these results might indicate that the two au-
thors’ translated texts are using similar character-
istics to convey social class of their characters. It is
important to note that the baselines for class were
extremely high, making prediction of this attribute
more difficult. At least in the intra-author testing,
the gender and age models were generally able to
improve accuracy over their respective baselines
more so than the class models, with age being the
best overall.
</bodyText>
<subsectionHeader confidence="0.999923">
4.3 Comparison of Useful Features
</subsectionHeader>
<bodyText confidence="0.9999825">
Since the experimentation used a linear model
(logistic regression), we can inspect the coeffi-
cients/weights of a trained classifier to determine
which features contributed particularly to the clas-
sification. The absolute value of a coefficient in-
dicates how influential its feature is, and the sign
(+/-) of the coefficient indicates which class the
feature is associated with. During cross-author
</bodyText>
<figure confidence="0.696844045454545">
Family words
Honorifics
Pronouns 1st
Pronouns 2nd
Pronouns 3rd
Pronouns all
Wh- questions
Type-token ratio
Determiners
Adjectives
Prepositions
For/with
Modals
Personal pronouns
Nouns singular
Nouns plural
Verbs past
Verbs past part.
Verbs sing. pres. non-3rd
Mean line length
Number of lines
% short lines (≤5 words)
</figure>
<page confidence="0.750421">
14
</page>
<table confidence="0.9996934">
Strindberg Ibsen
Gender Pronouns 3rd Female Pronouns 3rd Female
Honorifics Female Family words Female
Determiners Male Modals Male
Age Nouns singular Old Family words Young
Family words Young Verbs sing. pres. non-3rd Young
Modals Young Prepositions Old
Class For/with Lower For/with Lower
Verbs past part. Upper Honorifics Lower
Honorifics Lower Nouns singular Lower
</table>
<tableCaption confidence="0.7571394">
Table 6: Most useful features for gender, age, and class for each author, determined by examining the
coefficients of classifiers that performed above baseline during cross-author testing. The pairs in the
table consist of a linguistic feature and the label indicated by more frequent use of that feature (e.g. for
Strindberg, third-person pronoun usage contributed to predicting gender, with greater usage indicating a
female character). Features marked in bold are shared between authors for a given attribute.
</tableCaption>
<bodyText confidence="0.999801826086956">
validation, if the trained classifier for a given fold
performed above the baseline of its own test set,
then we record its three most heavily weighted fea-
tures. At the end, we have a tally of which fea-
tures most often appeared in the top three features
for such better-performing classifiers. We can use
this to compare which features were more consis-
tently involved for each author and attribute pair,
as shown in Table 6.
Some of the useful features are more intuitive
than others. For example, as mentioned in an
earlier section, it seems reasonable that family
words may relate to depictions of gender roles
of the time period in which the plays were writ-
ten, with women being expected to take on so-
cial roles more confined to the home. This ap-
pears to be true for Ibsen, but not for Strindberg.
We also see family words suggesting young char-
acters for both authors’ texts. It seems intuitive
that authors may have chosen to depict children as
spending more time around family members, in-
cluding using family terminology as terms of ad-
dress. The use of honorifics is also as predicted
earlier in the paper: lower class characters use
more higher terms of address, presumably when
interacting with their superiors. Another inter-
esting result is the frequency of third-person pro-
nouns being the most useful predictor of gender,
indicating female characters for both authors. Pos-
sibly, women may have spoken more about other
people than men did in these texts.
Some other results are not as easy to explain.
For example, the use of the prepositions for and
with was consistently the most useful predictor of
lower class characters (which could explain why
the models performed comparably on opposite au-
thors in Table 5). An interesting result was the
more frequent use of singular, present tense, non-
third person verbs among young characters in the
Ibsen texts. This suggests that young characters
used more verbs centered around I and you in the
present tense. One possible explanation is that
children were depicted as being more involved in
their own personal world, speaking less about peo-
ple they were not directly interacting with in a
given moment.
</bodyText>
<sectionHeader confidence="0.998904" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999995666666667">
We have presented a dataset of translated plays by
August Strindberg and Henrik Ibsen, along with
computational models for predicting the sociolin-
guistic attributes of gender, age, and social class
of characters using the aggregation of their tex-
tual lines-to-be-spoken. We compared the per-
formance and important features of the models in
both intra- and inter-author testing using a cross-
author validation procedure, finding that models
generally performed above challenging baselines
for their own authors, but less so for the other,
as one would expect. The exception was the so-
cial class variable, which was consistently slightly
above baseline regardless of the author used for
testing. While this could indicate that the trans-
lated Strindberg and Ibsen texts conveyed social
class using similar linguistic cues, this remains a
topic for future exploration, given the class im-
balance for that attribute. We also examine some
indicative features for each attribute and author
pair, identifying similarities and differences be-
</bodyText>
<page confidence="0.99244">
15
</page>
<bodyText confidence="0.99997485">
tween the depictions in each set of texts. This anal-
ysis supported the trends seen in the cross-author
testing.
Future work would include exploring other au-
thors and literary genres, or extending the scope
to non-literary domains. When expanding this
initial work to larger datasets, there is an op-
portunity to better understand the intricacies of
performance through other metrics (e.g. preci-
sion, recall). There is certainly much opportu-
nity to expand sociolinguistic features on fictional
texts and to explore other potentially simpler or
more advanced modeling frameworks. Alterna-
tives for assigning annotation of sociolinguistic
variables, such as socioeconomic standing, also
deserve further attention. Additionally, it would
be interesting to verify the preservation of linguis-
tic/sociolinguistic cues in translation by repeating
this work using different translations of the same
texts.
</bodyText>
<sectionHeader confidence="0.996038" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99998925">
We thank the Swedish Institute (http://eng.si.se)
for partially supporting this work. We also thank
the reviewers for valuable comments that were
considered in the revision of this paper.
</bodyText>
<sectionHeader confidence="0.999247" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999688958333334">
Paul Baker. 2010. Sociolinguistics and Corpus Lin-
guistics. Edinburgh University Press, Edinburgh.
Steven Bird, Ewan Klein, and Edward Loper. 2009.
Natural Language Processing with Python – An-
alyzing Text with the Natural Language Toolkit.
O’Reilly Media, Sebastopol.
Constantinos Boulis and Mari Ostendorf. 2005. A
quantitative analysis of lexical differences between
genders in telephone conversations. In Proceedings
of the 43rd Annual Meeting of the ACL, pages 435–
442, Ann Arbor, MI, USA, June.
Nikesh Garera and David Yarowsky. 2009. Modeling
latent biographic attributes in conversational genres.
In Proceedings of the 47th Annual Meeting of the
ACL and 4th IJCNLP of the AFNLP, pages 719–718,
Suntec, Singapore, August.
Sobhan Raj Hota, Shlomo Argamon, and Rebecca
Chung. 2006. Gender in Shakespeare: Automatic
stylistics gender character classification using syn-
tactic, lexical and lemma features. In Digital Hu-
manities and Computer Science (DHCS 2006).
Justine Kao and Dan Jurafsky. 2012. A computational
analysis of style, affect, and imagery in contempo-
rary poetry. In Workshop on Computational Linguis-
tics for Literature, pages 8–17, Montr´eal, Canada,
June 8.
William Labov. 1972. Sociolinguistic Patterns. Uni-
versity of Pennsylvania Press, Philadelphia, PA.
Hans Lindquist. 2009. Corpus Linguistics and the De-
scription of English. Edinburgh University Press,
Edinburgh.
Rajend Mesthrie, Joan Swann, Anna Deumert, and
William Leap. 2009. Introducing Sociolinguistics
(2nd ed.). Jon Benjamins, Amsterdam.
Fabian Pedregosa, Gael Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, Jake Vanderplas, Alexan-
dre Passos, David Cournapeau, Matthieu Brucher,
Matthieu Perrot, and Edouard Duchesnay. 2011.
Scikit-learn: Machine learning in Python. Journal
of Machine Learning Research, 12:2825–2830.
Sara Rosenthal and Kathleen McKeown. 2011. Age
prediction in blogs: A study of style, content, and
online behavior in pre- and post-social media gen-
erations. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 763–772, Portland, Oregon, June 19-24.
</reference>
<page confidence="0.998688">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.839721">
<title confidence="0.9639">Computational analysis to explore authors’ depiction of characters</title>
<author confidence="0.980081">Joseph</author>
<affiliation confidence="0.993801">Dept. of Computer Rochester Institute of</affiliation>
<email confidence="0.985045">jtb4478@cs.rit.edu</email>
<author confidence="0.978719">Cecilia Ovesdotter</author>
<affiliation confidence="0.975546">Dept. of Rochester Institute of</affiliation>
<email confidence="0.997979">coagla@rit.edu</email>
<abstract confidence="0.997986565217391">This study involves automatically identifying the sociolinguistic characteristics of fictional characters in plays by analyzing their written “speech”. We discuss three binary classification problems: predicting the characters’ gender (male vs. female), age (young vs. old), and socioeconomic standing (upper-middle class vs. lower class). The text corpus used is an annotated collection of August Strindberg and Henrik Ibsen plays, translated into English, which are in the public domain. These playwrights were chosen for their known attention to relevant socioeconomic issues in their work. Linguistic and textual cues are extracted from the characters’ lines (turns) for modeling purposes. We report on the dataset as well as the performance and important features when predicting each of the sociolinguistic characteristics, comparing intraand inter-author testing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Paul Baker</author>
</authors>
<title>Sociolinguistics and Corpus Linguistics.</title>
<date>2010</date>
<publisher>Edinburgh University Press,</publisher>
<location>Edinburgh.</location>
<contexts>
<context position="5597" citStr="Baker (2010)" startWordPosition="822" endWordPosition="823">ve attempted this categorization with fictional characters. Literary texts are complex, reflecting authors’ decision-making and creative processes. From the perspective of digital humanities, such a focus complements computational sociolinguistic modeling of contemporary user-generated text types (such as emails, or blogs (Rosenthal and McKeown, 2011)). As Lindquist (2009) points out, social data for interlocutors is less often attached to openly available linguistic corpora, and interest is strong in developing corpus methods to help explore social language behavior (see Lindquist (2009) and Baker (2010)). Previous investigation into social dimensions of language has established strong links between language and social attributes of speech communities (for an overview, see Mesthrie et al. (2009)). However, such inquiry has generally had a firm foundation in field-based research and has usually focused on one or just a few linguistic variables (such as how the pronunciation of certain sounds aligns with social stratification (Labov, 1972)). Moreover, previous scholarship has chiefly focused on the spoken rather than the written mode. Garera and Yarowsky (2009) and Boulis and Ostendorf (2005) t</context>
</contexts>
<marker>Baker, 2010</marker>
<rawString>Paul Baker. 2010. Sociolinguistics and Corpus Linguistics. Edinburgh University Press, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit. O’Reilly</booktitle>
<location>Media, Sebastopol.</location>
<contexts>
<context position="13060" citStr="Bird et al., 2009" startWordPosition="2011" endWordPosition="2014">tically extracted using Python. We use honorifics here to mean common formal terms of address during the time period (sir, madam, lord, Mr., Mrs., etc.). It seems intuitive that such terms may be used differently based on class or possibly age (e.g. lower class using more higher terms of address when speaking to their superiors). We use family words to mean anything that indicates a familial relationship (father, daughter, nephew, etc.). The use of such words may be affected by gender roles (Hota et al., 2006). Part-of-speech tagging was accomplished using the Natural Language Toolkit (NLTK) (Bird et al., 2009). 13 Linguistic features Table 4: List of linguistic features examined for the models. All features, with the exception of the last three in the right column, were measured once as raw counts and once as the fraction of the overall words for a given character. 4.2 Cross-Author Validation We compared translations of Strindberg and Ibsen’s use of language to convey sociolinguistic attributes. This was done for each of the three attributes of interest (gender, age, and class) by training one model for each author, then using it to classify the other author’s characters. We accomplish this by defi</context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit. O’Reilly Media, Sebastopol.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantinos Boulis</author>
<author>Mari Ostendorf</author>
</authors>
<title>A quantitative analysis of lexical differences between genders in telephone conversations.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>435--442</pages>
<location>Ann Arbor, MI, USA,</location>
<contexts>
<context position="6195" citStr="Boulis and Ostendorf (2005)" startWordPosition="911" endWordPosition="915">quist (2009) and Baker (2010)). Previous investigation into social dimensions of language has established strong links between language and social attributes of speech communities (for an overview, see Mesthrie et al. (2009)). However, such inquiry has generally had a firm foundation in field-based research and has usually focused on one or just a few linguistic variables (such as how the pronunciation of certain sounds aligns with social stratification (Labov, 1972)). Moreover, previous scholarship has chiefly focused on the spoken rather than the written mode. Garera and Yarowsky (2009) and Boulis and Ostendorf (2005) take into account the interlocutors’ speech for analysis. In contrast, we experiment with the challenge of using only sociolinguistically relevant knowledge coded in the text of characters’ lines. Thus, our approach is more similar to Hota et al.’s (2006) work on Shakespeare. The characters’ lines do not include the metadata needed for considering spoken features, since usually these are added at the discretion of the performer. This may make our problem more challenging, since some of these indicators may be reliable for identifying gender, such as backchannel responses and affirmations from</context>
<context position="7575" citStr="Boulis and Ostendorf, 2005" startWordPosition="1131" endWordPosition="1135">rly differ between males and females due to physical characteristics (e.g. Fo, predominant for pitch perception). We do not take advantage of acoustic/prosodic cues in this work. Our text is also artificial discourse, as opposed to natural speech; therefore these characters’ lines may rather express how writers choose to convey sociolinguistic attributes of their characters. In terms of features, we have explored observations from previous studies. For instance, common lexical items have been shown successful, with males tending to use more obscenities, especially when talking to other males (Boulis and Ostendorf, 2005), and females tending to use more third-person pronouns. Phrases also tended to be more useful than unigrams, though whether the commonly-used words tend to be content-bearing remains a question according to Boulis and Ostendorf (2005). Tackling another form of text, Kao and Jurafksy (2012) examined the statistical properties of 20th century acknowledged versus amateur poets in terms of style and content substance, finding, for example, that lexical affluence and properties coherent with imagism, as an aesthetic theorized ideal, distinguished contemporary professionals’ poetics, while sound ph</context>
</contexts>
<marker>Boulis, Ostendorf, 2005</marker>
<rawString>Constantinos Boulis and Mari Ostendorf. 2005. A quantitative analysis of lexical differences between genders in telephone conversations. In Proceedings of the 43rd Annual Meeting of the ACL, pages 435– 442, Ann Arbor, MI, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikesh Garera</author>
<author>David Yarowsky</author>
</authors>
<title>Modeling latent biographic attributes in conversational genres.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the ACL and 4th IJCNLP of the AFNLP,</booktitle>
<pages>719--718</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="4669" citStr="Garera and Yarowsky (2009)" startWordPosition="685" endWordPosition="688">14. c�2014 Association for Computational Linguistics for natural language processing, including Python (http://www.python.org/), the Natural Language Toolkit (http://www.nltk.org/) for part of the preprocessing, and the scikit-learn machine learning library for the computational modeling. Translated texts that reside in the public domain were collected from the Gutenberg Archive (http://www.gutenburg.org/wiki/Main Page/). 2 Previous Work A pilot study by Hota et al. (2006) on automatic gender identification in Shakespeare’s texts, as well as a few primarily gender-oriented studies surveyed in Garera and Yarowsky (2009), have set the stage for further inquiry. The latter study expanded on previous work by exploring three attributes: gender, age, and native/non-native speakers. There have been previous avenues of research into categorizing speakers based on different individual sociolinguistic factors. However, not many studies have attempted this categorization with fictional characters. Literary texts are complex, reflecting authors’ decision-making and creative processes. From the perspective of digital humanities, such a focus complements computational sociolinguistic modeling of contemporary user-generat</context>
<context position="6163" citStr="Garera and Yarowsky (2009)" startWordPosition="906" endWordPosition="909">ial language behavior (see Lindquist (2009) and Baker (2010)). Previous investigation into social dimensions of language has established strong links between language and social attributes of speech communities (for an overview, see Mesthrie et al. (2009)). However, such inquiry has generally had a firm foundation in field-based research and has usually focused on one or just a few linguistic variables (such as how the pronunciation of certain sounds aligns with social stratification (Labov, 1972)). Moreover, previous scholarship has chiefly focused on the spoken rather than the written mode. Garera and Yarowsky (2009) and Boulis and Ostendorf (2005) take into account the interlocutors’ speech for analysis. In contrast, we experiment with the challenge of using only sociolinguistically relevant knowledge coded in the text of characters’ lines. Thus, our approach is more similar to Hota et al.’s (2006) work on Shakespeare. The characters’ lines do not include the metadata needed for considering spoken features, since usually these are added at the discretion of the performer. This may make our problem more challenging, since some of these indicators may be reliable for identifying gender, such as backchannel</context>
</contexts>
<marker>Garera, Yarowsky, 2009</marker>
<rawString>Nikesh Garera and David Yarowsky. 2009. Modeling latent biographic attributes in conversational genres. In Proceedings of the 47th Annual Meeting of the ACL and 4th IJCNLP of the AFNLP, pages 719–718, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sobhan Raj Hota</author>
<author>Shlomo Argamon</author>
<author>Rebecca Chung</author>
</authors>
<title>Gender in Shakespeare: Automatic stylistics gender character classification using syntactic, lexical and lemma features.</title>
<date>2006</date>
<booktitle>In Digital Humanities and Computer Science (DHCS</booktitle>
<contexts>
<context position="4520" citStr="Hota et al. (2006)" startWordPosition="664" endWordPosition="667">Proceedings of the 3rd Workshop on Computational Linguistics for Literature (CLfL) @ EACL 2014, pages 11–16, Gothenburg, Sweden, April 27, 2014. c�2014 Association for Computational Linguistics for natural language processing, including Python (http://www.python.org/), the Natural Language Toolkit (http://www.nltk.org/) for part of the preprocessing, and the scikit-learn machine learning library for the computational modeling. Translated texts that reside in the public domain were collected from the Gutenberg Archive (http://www.gutenburg.org/wiki/Main Page/). 2 Previous Work A pilot study by Hota et al. (2006) on automatic gender identification in Shakespeare’s texts, as well as a few primarily gender-oriented studies surveyed in Garera and Yarowsky (2009), have set the stage for further inquiry. The latter study expanded on previous work by exploring three attributes: gender, age, and native/non-native speakers. There have been previous avenues of research into categorizing speakers based on different individual sociolinguistic factors. However, not many studies have attempted this categorization with fictional characters. Literary texts are complex, reflecting authors’ decision-making and creativ</context>
<context position="12957" citStr="Hota et al., 2006" startWordPosition="1997" endWordPosition="2000">ic terms of address. A full list of the features examined is shown in Table 4. All features were automatically extracted using Python. We use honorifics here to mean common formal terms of address during the time period (sir, madam, lord, Mr., Mrs., etc.). It seems intuitive that such terms may be used differently based on class or possibly age (e.g. lower class using more higher terms of address when speaking to their superiors). We use family words to mean anything that indicates a familial relationship (father, daughter, nephew, etc.). The use of such words may be affected by gender roles (Hota et al., 2006). Part-of-speech tagging was accomplished using the Natural Language Toolkit (NLTK) (Bird et al., 2009). 13 Linguistic features Table 4: List of linguistic features examined for the models. All features, with the exception of the last three in the right column, were measured once as raw counts and once as the fraction of the overall words for a given character. 4.2 Cross-Author Validation We compared translations of Strindberg and Ibsen’s use of language to convey sociolinguistic attributes. This was done for each of the three attributes of interest (gender, age, and class) by training one mod</context>
</contexts>
<marker>Hota, Argamon, Chung, 2006</marker>
<rawString>Sobhan Raj Hota, Shlomo Argamon, and Rebecca Chung. 2006. Gender in Shakespeare: Automatic stylistics gender character classification using syntactic, lexical and lemma features. In Digital Humanities and Computer Science (DHCS 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine Kao</author>
<author>Dan Jurafsky</author>
</authors>
<title>A computational analysis of style, affect, and imagery in contemporary poetry.</title>
<date>2012</date>
<booktitle>In Workshop on Computational Linguistics for Literature,</booktitle>
<pages>8--17</pages>
<location>Montr´eal, Canada,</location>
<marker>Kao, Jurafsky, 2012</marker>
<rawString>Justine Kao and Dan Jurafsky. 2012. A computational analysis of style, affect, and imagery in contemporary poetry. In Workshop on Computational Linguistics for Literature, pages 8–17, Montr´eal, Canada, June 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Labov</author>
</authors>
<title>Sociolinguistic Patterns.</title>
<date>1972</date>
<publisher>University of Pennsylvania Press,</publisher>
<location>Philadelphia, PA.</location>
<contexts>
<context position="6039" citStr="Labov, 1972" startWordPosition="889" endWordPosition="890">o openly available linguistic corpora, and interest is strong in developing corpus methods to help explore social language behavior (see Lindquist (2009) and Baker (2010)). Previous investigation into social dimensions of language has established strong links between language and social attributes of speech communities (for an overview, see Mesthrie et al. (2009)). However, such inquiry has generally had a firm foundation in field-based research and has usually focused on one or just a few linguistic variables (such as how the pronunciation of certain sounds aligns with social stratification (Labov, 1972)). Moreover, previous scholarship has chiefly focused on the spoken rather than the written mode. Garera and Yarowsky (2009) and Boulis and Ostendorf (2005) take into account the interlocutors’ speech for analysis. In contrast, we experiment with the challenge of using only sociolinguistically relevant knowledge coded in the text of characters’ lines. Thus, our approach is more similar to Hota et al.’s (2006) work on Shakespeare. The characters’ lines do not include the metadata needed for considering spoken features, since usually these are added at the discretion of the performer. This may m</context>
</contexts>
<marker>Labov, 1972</marker>
<rawString>William Labov. 1972. Sociolinguistic Patterns. University of Pennsylvania Press, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Lindquist</author>
</authors>
<title>Corpus Linguistics and the Description of English.</title>
<date>2009</date>
<publisher>Edinburgh University Press,</publisher>
<location>Edinburgh.</location>
<contexts>
<context position="2606" citStr="Lindquist, 2009" startWordPosition="383" endWordPosition="384">eir attention to social issues makes these plays and characters highly relevant in constructing such a model to shed light on how these authors’ translated texts portray social variables. Interlocutors’ social attributes (such as their gender, age, social class, and ethnicity) are known to correlate with language behavior, and they tap into dimensions of language behavior that are of central interest to the humanities. For instance, anecdotal evidence suggests that large-scale corpus analysis can show how society collectively ascribes certain roles to male versus female referents in text (cf. Lindquist, 2009). Studying these authors and texts from the point of view of corpus-oriented computational sociolinguistics can also help us examine the authors’ differences in production, descriptively. This is useful as a complementary approach to the more traditional close reading methodology common in literary research, through which their texts are usually approached. On a broader scale, the study can contribute valuable insights to a theory of linguistic text criticism. These authors are part of a global literary canon, and their plays are arguably more often performed in translation than in their Scand</context>
<context position="5360" citStr="Lindquist (2009)" startWordPosition="785" endWordPosition="786">ious work by exploring three attributes: gender, age, and native/non-native speakers. There have been previous avenues of research into categorizing speakers based on different individual sociolinguistic factors. However, not many studies have attempted this categorization with fictional characters. Literary texts are complex, reflecting authors’ decision-making and creative processes. From the perspective of digital humanities, such a focus complements computational sociolinguistic modeling of contemporary user-generated text types (such as emails, or blogs (Rosenthal and McKeown, 2011)). As Lindquist (2009) points out, social data for interlocutors is less often attached to openly available linguistic corpora, and interest is strong in developing corpus methods to help explore social language behavior (see Lindquist (2009) and Baker (2010)). Previous investigation into social dimensions of language has established strong links between language and social attributes of speech communities (for an overview, see Mesthrie et al. (2009)). However, such inquiry has generally had a firm foundation in field-based research and has usually focused on one or just a few linguistic variables (such as how the </context>
</contexts>
<marker>Lindquist, 2009</marker>
<rawString>Hans Lindquist. 2009. Corpus Linguistics and the Description of English. Edinburgh University Press, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajend Mesthrie</author>
<author>Joan Swann</author>
<author>Anna Deumert</author>
<author>William Leap</author>
</authors>
<date>2009</date>
<booktitle>Introducing Sociolinguistics (2nd ed.). Jon Benjamins,</booktitle>
<location>Amsterdam.</location>
<contexts>
<context position="5792" citStr="Mesthrie et al. (2009)" startWordPosition="849" endWordPosition="852">ities, such a focus complements computational sociolinguistic modeling of contemporary user-generated text types (such as emails, or blogs (Rosenthal and McKeown, 2011)). As Lindquist (2009) points out, social data for interlocutors is less often attached to openly available linguistic corpora, and interest is strong in developing corpus methods to help explore social language behavior (see Lindquist (2009) and Baker (2010)). Previous investigation into social dimensions of language has established strong links between language and social attributes of speech communities (for an overview, see Mesthrie et al. (2009)). However, such inquiry has generally had a firm foundation in field-based research and has usually focused on one or just a few linguistic variables (such as how the pronunciation of certain sounds aligns with social stratification (Labov, 1972)). Moreover, previous scholarship has chiefly focused on the spoken rather than the written mode. Garera and Yarowsky (2009) and Boulis and Ostendorf (2005) take into account the interlocutors’ speech for analysis. In contrast, we experiment with the challenge of using only sociolinguistically relevant knowledge coded in the text of characters’ lines.</context>
</contexts>
<marker>Mesthrie, Swann, Deumert, Leap, 2009</marker>
<rawString>Rajend Mesthrie, Joan Swann, Anna Deumert, and William Leap. 2009. Introducing Sociolinguistics (2nd ed.). Jon Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian Pedregosa</author>
<author>Gael Varoquaux</author>
<author>Alexandre Gramfort</author>
<author>Vincent Michel</author>
<author>Bertrand Thirion</author>
<author>Olivier Grisel</author>
<author>Mathieu Blondel</author>
<author>Peter Prettenhofer</author>
</authors>
<title>Scikit-learn: Machine learning in Python.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2825</pages>
<location>Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David</location>
<contexts>
<context position="12075" citStr="Pedregosa et al., 2011" startWordPosition="1851" endWordPosition="1854">’s well-known naturalistic play Miss Julia (or Miss Julie) are shown in Table 2. As seen in Table 3, the imbalance of class labels presents the greatest problem for our model. Baselines of 88% and 89% upper class for Strindberg and Ibsen, respectively, indicate that there may be less information to be extracted for class. 4 Models Here we describe the design and performance of computational models for predicting a character’s gender, age, and class for Strindberg and Ibsen, yielding six models in total. Logistic regression, implemented in Python with the scikit-learn machine learning library (Pedregosa et al., 2011), is used for all classification models. 4.1 Feature Extraction Many features were examined, some inspired by previous analyses in the literature, such as type-token ratio, subordinate clauses, and whquestions, as well as some exploratory features, such as honorific terms of address. A full list of the features examined is shown in Table 4. All features were automatically extracted using Python. We use honorifics here to mean common formal terms of address during the time period (sir, madam, lord, Mr., Mrs., etc.). It seems intuitive that such terms may be used differently based on class or po</context>
</contexts>
<marker>Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, 2011</marker>
<rawString>Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and Edouard Duchesnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Kathleen McKeown</author>
</authors>
<title>Age prediction in blogs: A study of style, content, and online behavior in pre- and post-social media generations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>763--772</pages>
<location>Portland, Oregon,</location>
<contexts>
<context position="5338" citStr="Rosenthal and McKeown, 2011" startWordPosition="780" endWordPosition="783"> The latter study expanded on previous work by exploring three attributes: gender, age, and native/non-native speakers. There have been previous avenues of research into categorizing speakers based on different individual sociolinguistic factors. However, not many studies have attempted this categorization with fictional characters. Literary texts are complex, reflecting authors’ decision-making and creative processes. From the perspective of digital humanities, such a focus complements computational sociolinguistic modeling of contemporary user-generated text types (such as emails, or blogs (Rosenthal and McKeown, 2011)). As Lindquist (2009) points out, social data for interlocutors is less often attached to openly available linguistic corpora, and interest is strong in developing corpus methods to help explore social language behavior (see Lindquist (2009) and Baker (2010)). Previous investigation into social dimensions of language has established strong links between language and social attributes of speech communities (for an overview, see Mesthrie et al. (2009)). However, such inquiry has generally had a firm foundation in field-based research and has usually focused on one or just a few linguistic varia</context>
</contexts>
<marker>Rosenthal, McKeown, 2011</marker>
<rawString>Sara Rosenthal and Kathleen McKeown. 2011. Age prediction in blogs: A study of style, content, and online behavior in pre- and post-social media generations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 763–772, Portland, Oregon, June 19-24.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>