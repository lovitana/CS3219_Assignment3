<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9964445">
Interaction Quality Estimation in Spoken Dialogue Systems Using
Hybrid-HMMs
</title>
<author confidence="0.988752">
Stefan Ultes
</author>
<affiliation confidence="0.966934">
Ulm University
</affiliation>
<address confidence="0.6299435">
Albert-Einstein-Allee 43
89081 Ulm, Germany
</address>
<email confidence="0.820506">
stefan.ultes@uni-ulm.de
</email>
<author confidence="0.972659">
Wolfgang Minker
</author>
<affiliation confidence="0.94976">
Ulm University
</affiliation>
<address confidence="0.632452">
Albert-Einstein-Allee 43
89081 Ulm, Germany
</address>
<email confidence="0.853483">
wolfgang.minker@uni-ulm.de
</email>
<sectionHeader confidence="0.989851" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9983026">
Research trends on SDS evaluation are
recently focusing on objective assess-
ment methods. Most existing methods,
which derive quality for each system-
user-exchange, do not consider tempo-
ral dependencies on the quality of pre-
vious exchanges. In this work, we in-
vestigate an approach for determining In-
teraction Quality for human-machine dia-
logue based on methods modeling the se-
quential characteristics using HMM mod-
eling. Our approach significantly outper-
forms conventional approaches by up to
4.5% relative improvement based on Un-
weighted Average Recall metrics.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999874409836066">
Spoken Dialogue Systems (SDSs) play a key role
in achieving natural human-machine interaction.
One reason is that speech is one major chan-
nel of natural human communication. Assess-
ing the quality of such SDSs has been discussed
frequently in recent years. The basic principles
which all approaches underlie have been analyzed
by M¨oller et al. (2009) creating a taxonomy for
quality of human-machine interaction, i.e., Qual-
ity of Service (QoS) and Quality of Experience
(QoE). Quality of Service describes objective cri-
teria like total number of turns. The recent shift of
interest in dialogue assessment methods towards
subjective criteria is described as Quality of Expe-
rience, putting the user in the spotlight of dialogue
assessment. For QoE, M¨oller et al. (2009) iden-
tified several aspects contributing to a good user
experience, e.g., usability or acceptability. These
aspects can be combined under the term user sat-
isfaction, describing the degree by which the user
is satisfied with the system’s performance. By as-
sessing QoE, the hope of the research community
is to better measure the human-like quality of an
SDS. While this information may be used during
the design process, enabling automatically derived
user satisfaction within the dialogue management
allows for adaption of the ongoing dialogue (Ultes
et al., 2012b).
First work on deriving subjective metrics au-
tomatically has been performed by Walker et
al. (1997) resulting in the PARADISE framework,
which is the current quasi-standard in this field.
Briefly explained, a linear dependency is assumed
between dialogue parameters and user satisfaction
to estimate qualitative performance on the dia-
logue level.
Measuring the performance of complete dia-
logues does not allow for adapting to the user dur-
ing the dialogue (Ultes et al., 2012b). Hence,
performance measures which provide a measure-
ment for each system-user-exchange1 are of inter-
est. Approaches based on Hidden Markov Models
(HMMs) are widely used for sequence modeling.
Therefore, Engelbrecht et al. (2009) used these
models for predicting the dialogue quality on the
exchange level. Similar to this, we presented work
on estimating Interaction Quality using HMMs
and Conditioned HMMs (Ultes et al., 2012a). In
this contribution, we investigate an approach for
recognizing the dialogue quality using a hybrid
Markovian model. Here, hybrid means combin-
ing statistical approaches such as Support Vector
Machines with Hidden Markov Models by model-
ing the observation probability of the HMMs us-
ing classification. While this is the first time hy-
brid approaches are used for estimating Interaction
Quality, they are well-known and have been used
before for other classification tasks (e.g. (Valstar
and Pantic, 2007; Onaran et al., 2011)).
This paper is outlined as follows: Related work
on subjective quality measurement on the ex-
</bodyText>
<footnote confidence="0.934155">
1A system-user-exchange consists of a system dialogue
turn followed by a user dialogue turn
</footnote>
<page confidence="0.908087">
208
</page>
<note confidence="0.7426815">
Proceedings of the SIGDIAL 2014 Conference, pages 208–217,
Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997582">
change level is presented in Section 2. All experi-
ments in this work are based on the Interaction
Quality metric of the LEGO corpus described in
Section 3. We motivate for introducing time de-
pendency and present our own approach on rec-
ognizing Interaction Quality using a Markovian
model presented in Section 4 and briefly present
the classification algorithms used for the experi-
ments in Section 5. Experiments are presented in
Section 6 and their results discussion in Section 7.
</bodyText>
<sectionHeader confidence="0.97578" genericHeader="introduction">
2 Significant Related Work
</sectionHeader>
<bodyText confidence="0.999927973684211">
Much research on predicting subjective quality
measures on an exchange level has been per-
formed hitherto. However, most of this body of
work lacks of either taking account of the sequen-
tial structure of the dialogue or resulting in insuf-
ficient performance.
Engelbrecht et al. (2009) presented an approach
using Hidden Markov Models (HMMs) to model
the SDS as a process evolving over time. Perfor-
mance ratings on a 5 point scale (“bad”, “poor”,
“fair”, “good”, “excellent”) have been applied by
the users of the SDS during the dialogue. The in-
teraction was halted while the user rated. A HMM
was created consisting of 5 states (one for each
rating) and a 6-dimensional input vector. While
Engelbrecht et al. (2009) relied on only 6 input
variables, we will pursue an approach with 29 in-
put variables. Moreover, we will investigate dia-
logues of a real world dialogue system annotated
with quality labels by expert annotators.
Higashinaka et al. (2010) proposed a model for
predicting turn-wise ratings for human-human di-
alogues. Ratings ranging from 1 to 7 were applied
by two expert annotators labeling for smooth-
ness, closeness, and willingness. They achieved
an UAR2 of only 0.2-0.24 which is only slightly
above the random baseline of 0.14.
Hara et al. (2010) derived turn level ratings from
overall ratings of the dialogue which were applied
by the users after the interaction on a five point
scale within an online questionnaire. Using n-
grams to model the dialogue by calculating n-gram
occurrence frequencies for each satisfaction value
showed that results for distinguishing between six
classes at any point in the dialogue to be hardly
above chance.
A more robust measure for user satisfaction has
been presented by Schmitt et al. (2011) within
</bodyText>
<footnote confidence="0.968219">
2Unweighted Average Recall, see Section 6
</footnote>
<figureCaption confidence="0.9755795">
Figure 1: A dialogue may be separated into a se-
quence of system-user-exchanges where each ex-
change ei consists of a system turn si followed by
a user turn ui.
</figureCaption>
<bodyText confidence="0.999083363636364">
their work about Interaction Quality (IQ) for Spo-
ken Dialogue Systems. In contrast to user satis-
faction, the labels were applied by expert annota-
tors after the dialogue at the exchange level. Auto-
matically derived parameters were used as features
for creating a statistical model using static fea-
ture vectors. Schmitt et al. (2011) performed IQ
recognition on the LEGO corpus (see Section 3)
using linear SVMs. They achieved an UAR2 of
0.58 based on 10-fold cross-validation which is
clearly above the random baseline of 0.2. Ultes
et al. (2012a) put an emphasis on the sequential
character of the IQ measure by applying a Hid-
den Markov Models (HMMs) and a Conditioned
Hidden Markov Models (CHMMs). Both have
been applied using 6-fold cross validation and a
reduced feature set of the LEGO corpus achieving
an UAR2 of 0.44 for HMMs and 0.39 for CHMMs.
While Ultes et al. (2012a) used generic Gaussian
Mixture Models to model the observation proba-
bilities, we use confidence distributions of static
classification algorithms.
</bodyText>
<sectionHeader confidence="0.995517" genericHeader="method">
3 The LEGO Corpus
</sectionHeader>
<bodyText confidence="0.999115733333333">
For Interaction Quality (IQ) estimation, we use the
LEGO corpus published by Schmitt et al. (2012).
Interaction Quality is defined similarly to user sat-
isfaction: While the latter represents the true dis-
position of the user, IQ is the disposition of the
user assumed by an expert annotator. Here, ex-
pert annotators are people who listen to recorded
dialogues after the interactions and rate them by
assuming the point of view of the actual person
performing the dialogue. These experts are sup-
posed to have some experience with dialogue sys-
tems. In this work, expert annotators were “ad-
vanced students of computer science and engineer-
ing” (Schmitt et al., 2011), i.e., grad students.
The LEGO corpus is based on 200 calls to
</bodyText>
<page confidence="0.999065">
209
</page>
<figureCaption confidence="0.953784">
Figure 2: The three different modeling levels representing the interaction at exchange e,,,: The most
</figureCaption>
<bodyText confidence="0.98183522">
detailed exchange level, comprising parameters of the current exchange; the window level, capturing
important parameters from the previous n dialog steps (here n = 3); the dialog level, measuring overall
performance values from the entire previous interaction.
the “Let’s Go Bus Information System” of the
Carnegie Mellon University in Pittsburgh (Raux et
al., 2006) recorded in 2006. Labels for IQ have
been assigned by three expert annotators to 200
calls consisting of 4,885 system-user-exchanges
(see Figure 1) in total with an inter-annotator
agreement of κ = 0.54. This may be considered
as a moderate agreement (cf. Landis and Koch’s
Kappa Benchmark Scale (1977)) which is quite
good considering the difficulty of the task that re-
quired to rate each exchange. For instance, if one
annotator reduces the IQ value only one exchange
earlier than another annotator, both already dis-
agree on two exchanges. The final label was as-
signed to each exchange by using the median of
all three individual ratings.
IQ was labeled on a scale from 1 (extremely un-
satisfied) to 5 (satisfied) considering the complete
dialogue up to the current exchange. Thus, each
exchange has been rated without regarding any up-
coming user utterance. As the users are expected
to be satisfied at the beginning, each dialogue’s
initial rating is 5. In order to ensure consistent la-
beling, the expert annotators had to follow labeling
guidelines (Schmitt et al., 2012).
An example of an annotated dialogue is shown
in Table 5. It starts off with a good IQ until the
system provides some results and then falls drasti-
cally as the user input does not correspond to what
the system expects. Thus, the system remains in a
loop until the user reacts appropriately.
Parameters used as input variables for the IQ
model have been derived from the dialogue system
modules automatically for each exchange. Fur-
thermore, parameters on three levels have been
created: the exchange level, the dialogue level,
and the window level (see Figure 2). As parame-
ters like ASRCONFIDENCE (confidence of speech
recognition) or UTTERANCE (word sequence rec-
ognized by speech recognition) can directly be
acquired from the dialogue modules they consti-
tute the exchange level. Counts, sums, means,
and frequencies of exchange level parameters from
multiple exchanges are computed to constitute the
dialogue level (all exchanges up to the current
one) and the window level (the three previous ex-
changes).
</bodyText>
<sectionHeader confidence="0.987467" genericHeader="method">
4 Hybrid-HMM
</sectionHeader>
<bodyText confidence="0.999955322580645">
As Schmitt et al. (2011) model the sequential
character of the data only indirectly by design-
ing special features, our approach applies Marko-
vian modeling to directly model temporal de-
pendencies. Temporal dependencies on previous
system-user-exchanges are not taken into account
by Schmitt et al.; only parameters derived from
the current exchange are used. However, we found
out that Interaction Quality is highly dependent on
the IQ value of the previous exchange. Adding
the parameter IQp... describing the previous IQ
value to the input vector to the IQ model consist-
ing of several parameters results in an extended in-
put vector. Calculating the Information Gain Ra-
tio (IGR) of each parameter of the extended input
vector shows that IQp... achieves the highest IGR
value of 1.0. In other words, IQp... represents the
parameter which contains the most information for
the classification task.
While performing IQ recognition on the ex-
tended features set using the annotated IQ values
results in an UAR of 0.82, rather using the esti-
mated IQ value results in an UAR of only 0.43.
Consequently, other configurations have to be in-
vestigated. Here, Markovian approaches offer a
self-contained concept of using these temporal de-
pendencies. However, Ultes et al. (2012a) showed
that applying neither a classical HMM nor a con-
ditioned HMM yields results outperforming static
approaches.
Therefore, in this Section we present a Hybrid-
</bodyText>
<page confidence="0.988389">
210
</page>
<bodyText confidence="0.988341307692308">
HMM approach, which is based on the classical
HMM and takes advantage of good performing
existing static classification approaches. The clas-
sical HMM, specifically used for time-sequential
data, consists of a set of states 5 with transition
probability matrix A and initial probability vec-
tor π over a set of observations B (also called vo-
cabulary) and an observation function bqt depen-
dent on the state qt. For calculating the proba-
bility p(qtjOt, λ) of seeing observation sequence
Ot = (o1, o2, ... , ot) while being in state qt at
time t given the HMM λ, the Forward Algorithm
is used:
</bodyText>
<equation confidence="0.999745666666667">
p(qt = sjjOt, λ) = αt(j)
� |S |αt−1(i)aijbj(ot) . (1)
i=1
</equation>
<bodyText confidence="0.999983545454546">
Here, aij describes the transition probability of
transitioning from state si to state sj. To find
a suitable model λ, the HMM must be trained,
for example, by using the Baum-Welch algorithm.
Usually, the observation function bqt is modeled
with Gaussian mixture models (GMMs). For more
information on general HMMs, please refer to Ra-
biner et al. (1989).
For determining the most likely class ˆwt at time
t, where each state j E 5 is associated with one
class w, the following equation is used:
</bodyText>
<equation confidence="0.8292515">
ˆwt = arg max αt(j) . (2)
j
</equation>
<bodyText confidence="0.9999745625">
For applying an HMM while exploiting exist-
ing statistical classification approaches, the obser-
vation function bj(ot) is modeled by using con-
fidence score distributions of statistical classifiers,
e.g., a Support Vector Machine in accordance with
Schmitt et al. (2011) (see Section 5). Furthermore,
the transition function aij is computed by taking
the frequencies of the state transitions contained
in the given corpus. Therefore, an ergodic HMM
is used comprising five states with each represent-
ing one of the five IQ scores.
Moreover, in SDSs, a system action act is per-
formed at the end of each system turn. This can
be utilized by adding an additional dependency on
this action to the state transition function aij. By
augmenting Equation 1, this results in
</bodyText>
<equation confidence="0.973996">
αt(j) = � |S |αt−1(i)aij,actbj(ot) . (3)
i=1
</equation>
<bodyText confidence="0.999852666666667">
This refinement models differences in state tran-
sitions evoked by different system actions, e.g.,
a different transition probability is expected if a
WAIT action is performed compared to a CONFIR-
MATION. Equation 3 is equal to the belief up-
date equation known from the Partially Observ-
able Markov Decision Process formalism (Kael-
bling et al., 1998).
Therefore, two versions of the Hybrid-HMM
are evaluated: an action-independent version as in
Equation 1 and an action-dependent version as in
Equation 3.
</bodyText>
<sectionHeader confidence="0.987653" genericHeader="method">
5 Classifier Types
</sectionHeader>
<bodyText confidence="0.999573">
For modeling the observation probability bj(ot)of
the hybrid HMM, multiple classification schemes
have been applied to investigate the influence of
observation distributions with different character-
istics on the overall performance.
In general, classification means estimating a
class wˆ to the given observation o by comparing
the class-wise probabilities p(wjo). In this work,
this probability may be used to model the observa-
tion probability bj(o) of the HMM by the posterior
probability
</bodyText>
<equation confidence="0.8799885">
p(wjo) = bj(o) (4)
for j = w.
</equation>
<bodyText confidence="0.999950875">
As not all classification algorithms provide a
posterior probability, it may be replaced by the
confidence distribution. A general description of
the classification algorithms used in this work are
described in the following Section along with a
motivation for the feature subset of the LEGO cor-
pus used for estimating the Interaction Quality in
this work.
</bodyText>
<subsectionHeader confidence="0.997117">
5.1 Support Vector Machine
</subsectionHeader>
<bodyText confidence="0.9967795">
For a two class problem, a Support Vector Ma-
chine (SVM) (Vapnik, 1995) is based on the con-
cept of linear discrimination with maximum mar-
gin by defining a hyperplane separating the two
classes. The estimated class wˆ for observation vec-
tor o� is based on the sign of the decision function
</bodyText>
<equation confidence="0.986713666666667">
N
k(o) = αiziK(mi, 01 + b , (5)
i=1
</equation>
<bodyText confidence="0.999304">
where mi represent support vectors defining the
hyper plane (together with b), zi the known class
�mi belongs to, αi the weight of mi, and K(·, ·) a
</bodyText>
<page confidence="0.992338">
211
</page>
<bodyText confidence="0.977979">
kernel function. The kernel function is defined as
</bodyText>
<equation confidence="0.934723">
K(~m, ~m�) = (ϕ(~m), ϕ(~m�)) , (6)
</equation>
<bodyText confidence="0.999968363636364">
where ϕ(~m) represents a transformation function
mapping m~ into a space Φ of different dimension-
ality and (·, ·) defines a scalar product in Φ. By
using the kernel function, the linear discrimina-
tion may happen in a space of high dimensional-
ity without explicitly transforming the observation
vectors into said space.
The SVM implementation which is used in this
contribution is libSVM (Chang and Lin, 2011). As
this algorithm does not provide class probabilities
directly, the respective confidence scores are used.
</bodyText>
<subsectionHeader confidence="0.979589">
5.2 Naive Bayes
</subsectionHeader>
<bodyText confidence="0.99997280952381">
For deriving the posterior probability, the Naive
Bayes classifier may be used. It calculates the pos-
terior probability P(ω|o) of having class ω when
seeing the n-dimensional observation vector o~ by
applying Bayes rule (Duda et al., 2001):
In general, observations, i.e., elements of the
observation vector, may be correlated with each
other and introducing independence assumptions
between these elements does usually not reflect
the true state of the world. However, correlations
are often not very high thus simplifying the Bayes
problem has proved to result in reasonable perfor-
mance. This is utilized by the Naive Bayes classi-
fier by assuming said independence thus calculat-
ing
three steps: First, rules are grown by adding at-
tributes to the rule. Second, the rules are pruned.
If the resulting rule set is not of sufficient perfor-
mance, all training examples which are covered by
the generated rules are removed from the example
set and a new rule is created.
</bodyText>
<subsectionHeader confidence="0.980701">
5.4 Feature selection
</subsectionHeader>
<bodyText confidence="0.996697421052631">
As stated previously, all experiments are based on
the LEGO corpus presented in Section 3. In order
to keep the presented results comparable to pre-
vious work based on HMM and CHMM (Ultes et
al., 2012a), a reduced parameter set is used. Pa-
rameters with constant values for most exchanges
have been excluded. These would result in rows
of zeros during computation of the covariance ma-
trices of the feature vectors, which are needed for
HMM and CHMM classification. A row of ze-
ros in the covariance matrix will make it non-
invertible, which will cause errors during the com-
putation of the emission probabilities.
Therefore, a feature set consisting of 29 inter-
action parameters is used for both defining a base-
line and for evaluating the Hybrid-HMM. The set
consists of the following parameters (for an expla-
nation of the features, please refer to (Schmitt et
al., 2012)):
</bodyText>
<table confidence="0.937568222222222">
Exchange Level ASRRECOGNITIONSTATUS, ACTIVITY-
TYPE, ASRCONFIDENCE, ROLEINDEX, ROLENAME,
UTD, REPROMPT?, BARGED-IN?, DD, WPST,
WPUT
Dialogue Level MEANASRCONFIDENCE, #ASRREJEC-
TIONS, #TIMEOUTS ASRREJ, #BARGEINS, %ASR-
REJECTIONS, %TIMEOUTS ASRREJ, %BARGEINS,
#REPROMPTS,
%REPROMPTS, #SYSTEMQUESTIONS
</table>
<equation confidence="0.992289571428571">
P(ω|~o) = p(~o|ω) · P(ω)
p(~o)
. (7)
Window Level #TIMEOUTS ASRREJ, #ASRREJEC-
n TIONS, #BARGEINS, %BARGEINS, #SYSTEMQUES-
p(~o|ω) = p(oZ|ω) . (8) TIONS, MEANASRCONFIDENCE, #ASRSUCCESS,
Z=1 #RE-PROMPT
</equation>
<subsectionHeader confidence="0.979786">
5.3 Rule Induction
</subsectionHeader>
<bodyText confidence="0.996339117647059">
The classification algorithm Rule Induction or
Rule Learner is based on the idea of defining rules
to assign classes ωˆ to observation vectors ~o. In this
work, the algorithm RIPPER (Repeated Incremen-
tal Pruning to Produce Error Reduction) (Cohen,
1995) is used where each rule consists of conjunc-
tions of An = v, where An is a nominal attribute,
or A, &gt; θ, A, &lt; θ, where A, is a continuous at-
tribute. Each part of the observation vector o~ is re-
flected by one of the attributes. The basic process
of the algorithm for generating rules is divided into
For act in Equation 3, the exchange level pa-
rameter ACTIVITYTYPE is used which may take
one out of the four values “Announcement”, “Con-
firmation”, “Question”, or “wait”. Their distribu-
tion within the LEGO corpus is depicted in Fig-
ure 3.
</bodyText>
<sectionHeader confidence="0.988282" genericHeader="method">
6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.522472">
All experiments are conducted using 6-fold cross-
validation3. This includes the baseline approach
</bodyText>
<footnote confidence="0.998588">
3Six folds have been selected as a reasonable trade-off be-
tween validity and computation time.
</footnote>
<page confidence="0.996142">
212
</page>
<figureCaption confidence="0.9393695">
Figure 3: Distribution of the four values for act
in Equation 3 in the LEGO corpus. While “wait”
occurs rarely, the other three main actions occur at
roughly the same frequency.
</figureCaption>
<bodyText confidence="0.999079882352941">
(also producing the observation probabilities of
the Hybrid-HMM approach) and the evaluation of
the Hybrid-HMM. For the latter, two phases of
cross-validation were applied.
Interaction Quality estimation is done by
using three commonly used evaluation met-
rics: Unweighted Average Recall (UAR), Co-
hen’s Kappa (Cohen, 1960) and Spearman’s
Rho (Spearman, 1904). These are also selected
as the same metrics have been used in Schmitt et
al. (2011) as well.
Recall in general is defined as the rate of cor-
rectly classified samples belonging to one class.
The recall in UAR for multi-class classification
problems with N classes recalli is computed for
each class i and then averaged over all class-wise
recalls:
</bodyText>
<equation confidence="0.603467">
recalli . (9)
</equation>
<bodyText confidence="0.999847">
Cohen’s Kappa measures the relative agree-
ment between two corresponding sets of ratings.
In our case, we compute the number of label
agreements corrected by the chance level of agree-
ment divided by the maximum proportion of times
the labelers could agree. However, Cohen’s
weighted Kappa is applied as ordinal scores are
compared (Cohen, 1968). A weighting factor w is
introduced reducing the discount of disagreements
the smaller the difference is between two ratings:
</bodyText>
<equation confidence="0.978519333333333">
|r1 − r2|
w =.(10)
 |rmax − rmin
</equation>
<bodyText confidence="0.896515714285714">
Here, r1 and r2 denote the rating pair and rmax
and rmin the maximum and minimum ratings pos-
sible.
Table 1: Results for IQ recognition of the statis-
tical classifiers: UAR, κ and ρ for linear SVM,
Bayes classification and Rule Induction. σ2 repre-
sents the variances of the confidence scores.
</bodyText>
<table confidence="0.9951775">
UAR κ ρ σ2
SVM (linear) .495 .611 .774 .020
Bayes .467 .541 .716 .127
Rule Induction .596 .678 .790 .131
</table>
<bodyText confidence="0.9544186">
Correlation between two variables describes the
degree by which one variable can be expressed by
the other. Spearman’s Rho is a non-parametric
method assuming a monotonic function between
the two variables (Spearman, 1904).
</bodyText>
<subsectionHeader confidence="0.946396">
6.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999979931034483">
As baseline, we adapted the approach of Schmitt
et al. (2011). While they focused only on an SVM
with linear kernel, we investigate three different
static classification approaches. Different clas-
sifiers will produce different confidence distribu-
tions. These distributions will have different char-
acteristics which is of special interest for evaluat-
ing the Hybrid-HMM as will be discussed in Sec-
tion 7. The confidence characteristics are repre-
sented by the variance of the confidence scores
σ2. This variance is used as indicator for how cer-
tain the classifier is about its results. If one IQ
value has a high confidence while all others have
low confidence, the classifier is considered to be
very certain. This also results in a high variance.
Vice versa, if all IQ values have almost equal con-
fidence indicates high uncertainty. This will result
in a low variance.
The classification algorithms, which have been
selected arbitrarily, are SVM with linear kernel,
Naive Bayes, and Rule Induction (see Section 5).
The results in Table 1 show that an SVM with lin-
ear kernel (as used by Schmitt et al. (2011)) per-
forms second best with an UAR of 0.495 after
Rule Induction with an UAR of 0.596. The re-
sults of the SVM differ from the results obtained
by Schmitt et al. (UAR of 0.58) as we used a re-
duced feature set while they used all available fea-
tures.
</bodyText>
<subsectionHeader confidence="0.99845">
6.2 Hybrid-HMM
</subsectionHeader>
<bodyText confidence="0.99995875">
For evaluating the Hybrid-HMM on Interaction
Quality recognition, three aspects are of inter-
est. Most prominent is whether the presented ap-
proaches outperform the baseline, i.e., the clas-
</bodyText>
<equation confidence="0.970546">
1
UAR = N
N
i=1
</equation>
<page confidence="0.990959">
213
</page>
<figure confidence="0.894772">
‐
‐
</figure>
<figureCaption confidence="0.874040333333333">
Figure 4: Relative difference of UAR in percent between the baseline performance and the Hybrid-
HMM for the action-independent (AI), action-dependent (AD) and handcrafted (HC) transition matrix.
Differences marked with an * are significant (Wilcoxon test (Wilcoxon, 1945), α &lt; 0.05).
</figureCaption>
<bodyText confidence="0.494457">
‐
</bodyText>
<tableCaption confidence="0.895232">
Table 2: Results for the Hybrid-HMM approach:
UAR, κ and p for the action-independent (AI) and
action-dependent (AD) versions.
</tableCaption>
<table confidence="0.9993625">
‐ AI κ AI AD
UAR AD ρ
AI AD
SVM (linear) .477 .484 .599 .598 .770 .771
Bayes .486 .489 .563 .564 .737 .741
Rule Induction .608 .609 .712 .714 .826 .824
</table>
<bodyText confidence="0.999705384615385">
sifier which produces the observation probabili-
ties. Moreover, performance values of action-
dependent approaches and action-independent ap-
proaches are compared. In addition, the results are
analyzed with respect to the characteristic of the
confidence distribution.
For producing the confidence scores represent-
ing the observation probabilities, the statistical
classification algorithms presented in Section 6.1
are used. The initial distribution 7 for each HMM
was chosen in accordance with the annotation
guidelines of the LEGO corpus starting each di-
alogue with an IQ score of 5 resulting in
</bodyText>
<equation confidence="0.9994265">
75 = P(IQ = 5) = 1.0
74 = 73 = 72 = 71 = P(IQ =�5) = 0.0 .
</equation>
<bodyText confidence="0.9681262">
Results of the experiments with action-dependent
(AD) and action-independent (AI) transition func-
tion may be seen in Table 2. Again, Rule Induction
performed best with Naive Bayes on the second
and SVM on the third place.
</bodyText>
<sectionHeader confidence="0.998295" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.99966146875">
While previous work on applying the HMM and
CHMM for IQ recognition could not outperform
the baseline (Ultes et al., 2012a), Hybrid-HMM
experiments show a significant improvement in
UAR, Cohen’s κ and Spearman’s p for Naive
Bayes and Rule Induction. While performance
declines for the linear SVM, this difference has
shown to be not significant.
The relative difference of the Hybrid-HMM
compared to the respective baseline approaches
using an action-dependent and an action-
independent transition matrix is depicted in
Figure 4. Improvement for the Bayes method was
the highest significantly increasing UAR by up to
4.5% relative to the baseline. However, adding
action-dependency to the Hybrid-HMM does not
show any effect. This may be a result of using
ACTIVITYTYPE instead of the actual action.
However, using the actual action would result in
the need for more data as it contains 45 different
values. Significance for all results has been
calculated using the Wilcoxon test (Wilcoxon,
1945) by pair-wise comparison of the estimated
IQ values of all exchanges. All results except for
the decline in SVM performance are significant
with α &lt; 0.05.
Correlating the confidence variances shown in
Table 1 with the improvements of the Hybrid-
HMM reveals that for methods with a high
variance—and therefore with a greater certainty
about the classification result—, an improvement
could be accomplished. However, the perfor-
</bodyText>
<page confidence="0.999338">
214
</page>
<tableCaption confidence="0.963008666666667">
Table 3: Results of Hybrid-HMM with hand-
crafted transition matrix of the action-independent
version.
</tableCaption>
<table confidence="0.837838285714286">
UAR κ ρ
SVM (linear)
Bayes
Rule Induction
.506 .642 .797
.487 .563 .734
.608 .712 .825
</table>
<tableCaption confidence="0.99084">
Table 4: Handcrafted transition matrix based on
empirical data.
</tableCaption>
<figure confidence="0.965017470588235">
PPPPPP
to
1
2
3
4
5
1 2 3 4 5
0.7 0.3 0 0 0
0.25 0.5 0.25 0 0
0 0.25 0.5 0.25 0
0 0 0.25 0.5 0.25
0 0 0 0.3 0.7
from
by users (without guidelines), achieving
a Spear-
man’s p of 0.66 (α &lt; 0.01) (Ultes et al., 2013).
</figure>
<sectionHeader confidence="0.980162" genericHeader="method">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.99046132">
As previously publi
shed, approaches for recogniz-
ing the Interaction Quality of Spoken Dialogue
215 Systems are based on static classification without
temporal dependency on previous values, a Hy-
brid Hidden Markov Model approach has been in-
vestigated based on three static classifiers. The
Hybrid-HMM achieved a relative improvement up
Finally, it is notable that rule induction outper-
derstan
ding the problem of estimating Interaction
Quality better, especially since rule-based recog-
nition methods allow easy interpretation.
its results.
Further research should be conducted investi-
gating the question how the presented approach as
well as the Interaction Quality paradigm in general
will generalize for different dialogue domains. As
IQ is designed to be domain independent, it may
for Cognitive Technical
which is funded by the German
“Companion-Technology
Systems”
Re-
search Foundation (DFG).
</bodyText>
<sectionHeader confidence="0.737558" genericHeader="method">
nces
SVM: Alibrary for support
</sectionHeader>
<reference confidence="0.611726571428571">
vector machines. ACM
Transactions on Intelligent Systems and Technology,
2:27:1–27:27.
Apri
37–46,
l.
Jacob Cohen. 1968. Weighted kappa: Nominal scale
</reference>
<bodyText confidence="0.968818096774194">
agreement provision for scaled disagreement or par-
tial credit. Psychological bulletin, 70(4):213.
mance declined for classification approaches with
a low confidence variance, which can be seen as a
sign for uncertain classification results.
While the results for Hybrid-HMM are encour-
aging, creating a simple handcrafted transition
matrix for the action-independent version shown
in Table 4 achieved even more promising results
as performance for all classifier types could be im-
proved significantly compared to the baseline (see
Table 3). The handcrafted matrix was created in a
way to smooth the resulting estimates as only tran-
sitions from one IQ rating to its neighbors have a
probability greater than zero. Drastic changes in
the estimated IQ value compared to the previous
exchange are thus less likely. The exact values
have been derived empirically. By applying this
handcrafted transition matrix, even SVM perfor-
mance with linear kernel could be improved sig-
nificantly by 2.2% in UAR (see Figure 4) com-
pared to the baseline.
For creating the Interaction Quality scores, an-
notation guidelines were used resulting in certain
characteristics of IQ. Therefore, it may be as-
sumed that the effect of exploiting the dependency
on previous states is just a reflection of the guide-
lines. While this might be true, applying a Hy-
brid HMM for IQ recognition is reasonable as, de-
spite the guidelines, the IQ metric itself is strongly
related to user satisfaction, i.e., ratings applied
</bodyText>
<sectionHeader confidence="0.998005" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.7932295">
This work was supported by the Transregional
Collaborative Research Centre SFB/TRR 62
</bodyText>
<sectionHeader confidence="0.981777" genericHeader="method">
Refere
</sectionHeader>
<reference confidence="0.995000166666667">
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
Jacob Cohen. 1960. A coefficient of agreement for
nominal scales. In Educational and Psychological
Measurement, volume 20, pages
William W. Cohen. 1995. Fast effective rule induc-
tion. In Pro
</reference>
<bodyText confidence="0.971388666666667">
ceedings of the 12th International Con-
to 4.5% and a maximum of 0.61 UAR. Analyz-
ing the experiments revealed that, while an im-
provement could be achieved with the Hybrid-
HMM approach, handcrafting a transition model
achieved even better results as performance for all
analyzed classifier types could be improved signif-
icantly. Furthermore, applying the Hybrid-HMM
approach only yields improved performance if the
basic classifier itself has a high confidence about
be expected that the Hybrid-HMM will be appli-
cable for different dialogue domains as well.
formed SVM approaches in the baseline by 10 per-
centage points. While this contribution does not
focus on this, analyzing the model may help in un-
</bodyText>
<reference confidence="0.995027754716981">
ference on Machine Learning, pages 115–123. Mor-
gan Kaufmann, July.
Richard O. Duda, Peter E. Hart, and David G. Stork.
2001. Pattern Classification (2nd Edition). Wiley-
Interscience, 2 edition, November.
Klaus-Peter Engelbrecht, Florian G¨odde, Felix Har-
tard, Hamed Ketabdar, and Sebastian M¨oller. 2009.
Modeling user satisfaction with hidden markov
model. In SIGDIAL ’09: Proceedings of the SIG-
DIAL 2009 Conference, pages 170–177, Morris-
town, NJ, USA. ACL.
Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.
2010. Estimation method of user satisfaction us-
ing n-gram-based dialog history model for spo-
ken dialog system. In Proceedings of the Seventh
conference on International Language Resources
and Evaluation (LREC’10), Valletta, Malta, May.
ELRA.
Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010. Issues in pre-
dicting user satisfaction transitions in dialogues: In-
dividual differences, evaluation criteria, and predic-
tion models. In Spoken Dialogue Systems for Am-
bient Environments, volume 6392 of Lecture Notes
in Computer Science, pages 48–60. Springer Berlin
/ Heidelberg.
L. P. Kaelbling, M. L. Littman, and A. R. Cassandra.
1998. Planning and acting in partially observable
stochastic domains. Artificial Intelligence, 101(1-
2):99–134.
J. R. Landis and G. G. Koch. 1977. The measurement
of observer agreement for categorical data. Biomet-
rics, 33(1):159–174, March.
Sebastian M¨oller, Klaus-Peter Engelbrecht, C. K¨uhnel,
I. Wechsung, and B. Weiss. 2009. A taxonomy of
quality of service and quality of experience of mul-
timodal human-machine interaction. In Quality of
Multimedia Experience, 2009. QoMEx 2009. Inter-
national Workshop on, pages 7–12, July.
Ibrahim Onaran, N Firat Ince, A Enis Cetin, and Aviva
Abosch. 2011. A hybrid svm/hmm based system for
the state detection of individual finger movements
from multichannel ecog signals. In Neural Engi-
neering (NER), 2011 5th International IEEE/EMBS
Conference on, pages 457–460. IEEE.
Lawrence R. Rabiner. 1989. A tutorial on hidden
Markov models and selected applications in speech
recognition. Morgan Kaufmann Publishers Inc., San
Francisco, CA, USA.
Antoine Raux, Dan Bohus, Brian Langner, Alan W.
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year
of letˆas go! experience. In Proc. of the Interna-
tional Conference on Speech and Language Process-
ing (ICSLP), September.
Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011. Modeling and predicting quality in
spoken human-computer interaction. In Proceed-
ings of the SIGDIAL 2011 Conference, Portland,
Oregon, USA, June. Association for Computational
Linguistics.
Alexander Schmitt, Stefan Ultes, and Wolfgang
Minker. 2012. A parameterized and annotated cor-
pus of the cmu let’s go bus information system. In
International Conference on Language Resources
and Evaluation (LREC).
Charles Edward Spearman. 1904. The proof and mea-
surement of association between two things. Ameri-
can Journal of Psychology, 15:88–103.
Stefan Ultes, Robert ElChabb, and Wolfgang Minker.
2012a. Application and evaluation of a condi-
tioned hidden markov model for estimating inter-
action quality of spoken dialogue systems. In Pro-
ceedings of the 4th International Workshop on Spo-
ken Language Dialog System (IWSDS), pages 141–
150. Springer, November.
Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2012b. Towards quality-adaptive spoken
dialogue management. In NAACL-HLT Workshop
on Future directions and needs in the Spoken Dialog
Community: Tools and Data (SDCTD 2012), pages
49–52, Montr´eal, Canada, June. ACL.
Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2013. On quality ratings for spoken dia-
logue systems – experts vs. users. In Proceedings of
the 2013 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 569–
578. ACL, June.
Michel F. Valstar and Maja Pantic. 2007. Combined
support vector machines and hidden markov mod-
els for modeling facial action temporal dynamics.
In Human-Computer Interaction, volume 4796 of
Lecture Notes in Computer Science, pages 118–127.
Springer Berlin Heidelberg.
Vladimir N. Vapnik. 1995. The nature of statistical
learning theory. Springer-Verlag New York, Inc.,
New York, NY, USA.
Marilyn Walker, Diane Litman, Candace A. Kamm,
and Alicia Abella. 1997. Paradise: a framework
for evaluating spoken dialogue agents. In Proceed-
ings of the eighth conference on European chap-
ter of the Association for Computational Linguistics,
pages 271–280, Morristown, NJ, USA. ACL.
Frank Wilcoxon. 1945. Individual comparisons by
ranking methods. Biometrics bulletin, 1(6):80–83.
</reference>
<page confidence="0.999661">
216
</page>
<sectionHeader confidence="0.990036" genericHeader="method">
Appendix
</sectionHeader>
<bodyText confidence="0.94940975">
Table 5: Example of a dialogue annotated with Interaction Quality for each system-user-exchange. As
the system fails to interact properly with the user in the end, the IQ value drops down to one. Utterance
represents either the system utterance or the recognized user utterance. (CallID 2061123000 of the
LEGO corpus.)
</bodyText>
<figure confidence="0.938057289473684">
Utterance IQ
S: Welcome to the CMU Let’s Go bus information system.
U: 5
S: To get help at any time, just say Help or press zero.
U: 5
S: What can I do for you?
U: PENN AT BUTLER TIME IS IT IS THE CENTRE AT HIGHLAND FROM RUNS THE 61A EIGHT THIRTY 61B CAN’T OAKLAND 5
S: Leaving from OAKLAND. Is this correct?
U: OAKLAND 4
S: Leaving from OAKLAND. Is this correct?
U: YES 4
S: Right
U: - 4
S: Where do you want to go?
U: SQUIRREL HILL OF FIFTH AVENUE 4
S: Going to FIFTH AVENUE. Is this correct?
U: YES 5
S: Alright
U: - 5
S: When do you wanna travel?
U: SUNDAY 4
S: At what time do you wanna travel?
U: AT FIVE FOUR VERY ABOUT ELEVEN O’CLOCK 4
S: Leaving at 11 a.m. . Is this correct?
U: YES 5
S: Right
U: - 5
S: Hold on. Let me check that for you.
U: - 5
S: OAKLAND and FIFTH AVENUE are both the same stop. Please provide a different start or end point.
U: - 3
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: 61A 2
S: You can say start a new query, or goodbye.
U: FIVEDUQUESNE 1
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: LAST THE NEXT 1
S: You can say start a new query, or goodbye.
</figure>
<table confidence="0.603929444444444">
U: START WH 1
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: THE 1
S: You can say start a new query, or goodbye.
U: THANK YOU QUERY ELEVEN BACK 1
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: GOODBYE 1
S: Thank you for using the cmu Let’s Go Bus Information System. Goodbye.
U: - 1
</table>
<page confidence="0.993863">
217
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.271111">
<title confidence="0.999094">Interaction Quality Estimation in Spoken Dialogue Systems Hybrid-HMMs</title>
<author confidence="0.992614">Stefan</author>
<affiliation confidence="0.910748">Ulm Albert-Einstein-Allee</affiliation>
<address confidence="0.99484">89081 Ulm,</address>
<email confidence="0.998764">stefan.ultes@uni-ulm.de</email>
<author confidence="0.656182">Wolfgang</author>
<affiliation confidence="0.8194175">Ulm Albert-Einstein-Allee</affiliation>
<address confidence="0.992166">89081 Ulm,</address>
<email confidence="0.999376">wolfgang.minker@uni-ulm.de</email>
<abstract confidence="0.9728803125">Research trends on SDS evaluation are recently focusing on objective assessment methods. Most existing methods, which derive quality for each systemuser-exchange, do not consider temporal dependencies on the quality of previous exchanges. In this work, we investigate an approach for determining Interaction Quality for human-machine dialogue based on methods modeling the sequential characteristics using HMM modeling. Our approach significantly outperforms conventional approaches by up to 4.5% relative improvement based on Unweighted Average Recall metrics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>vector machines</author>
</authors>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<pages>2--27</pages>
<marker>machines, </marker>
<rawString>vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27. l.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>Weighted kappa: Nominal scale Chih-Chung Chang and Chih-Jen Lin.</title>
<date>1968</date>
<booktitle>In Educational and Psychological Measurement,</booktitle>
<volume>20</volume>
<pages>pages</pages>
<contexts>
<context position="21316" citStr="Cohen, 1968" startWordPosition="3431" endWordPosition="3432"> Recall in general is defined as the rate of correctly classified samples belonging to one class. The recall in UAR for multi-class classification problems with N classes recalli is computed for each class i and then averaged over all class-wise recalls: recalli . (9) Cohen’s Kappa measures the relative agreement between two corresponding sets of ratings. In our case, we compute the number of label agreements corrected by the chance level of agreement divided by the maximum proportion of times the labelers could agree. However, Cohen’s weighted Kappa is applied as ordinal scores are compared (Cohen, 1968). A weighting factor w is introduced reducing the discount of disagreements the smaller the difference is between two ratings: |r1 − r2| w =.(10) |rmax − rmin Here, r1 and r2 denote the rating pair and rmax and rmin the maximum and minimum ratings possible. Table 1: Results for IQ recognition of the statistical classifiers: UAR, κ and ρ for linear SVM, Bayes classification and Rule Induction. σ2 represents the variances of the confidence scores. UAR κ ρ σ2 SVM (linear) .495 .611 .774 .020 Bayes .467 .541 .716 .127 Rule Induction .596 .678 .790 .131 Correlation between two variables describes t</context>
</contexts>
<marker>Cohen, 1968</marker>
<rawString>Jacob Cohen. 1968. Weighted kappa: Nominal scale Chih-Chung Chang and Chih-Jen Lin. 2011. LIBJacob Cohen. 1960. A coefficient of agreement for nominal scales. In Educational and Psychological Measurement, volume 20, pages</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
</authors>
<title>Fast effective rule induction.</title>
<date>1995</date>
<booktitle>In Pro ference on Machine Learning,</booktitle>
<pages>115--123</pages>
<publisher>Morgan Kaufmann,</publisher>
<contexts>
<context position="19317" citStr="Cohen, 1995" startWordPosition="3097" endWordPosition="3098">CONFIDENCE, #ASRREJECTIONS, #TIMEOUTS ASRREJ, #BARGEINS, %ASRREJECTIONS, %TIMEOUTS ASRREJ, %BARGEINS, #REPROMPTS, %REPROMPTS, #SYSTEMQUESTIONS P(ω|~o) = p(~o|ω) · P(ω) p(~o) . (7) Window Level #TIMEOUTS ASRREJ, #ASRREJECn TIONS, #BARGEINS, %BARGEINS, #SYSTEMQUESp(~o|ω) = p(oZ|ω) . (8) TIONS, MEANASRCONFIDENCE, #ASRSUCCESS, Z=1 #RE-PROMPT 5.3 Rule Induction The classification algorithm Rule Induction or Rule Learner is based on the idea of defining rules to assign classes ωˆ to observation vectors ~o. In this work, the algorithm RIPPER (Repeated Incremental Pruning to Produce Error Reduction) (Cohen, 1995) is used where each rule consists of conjunctions of An = v, where An is a nominal attribute, or A, &gt; θ, A, &lt; θ, where A, is a continuous attribute. Each part of the observation vector o~ is reflected by one of the attributes. The basic process of the algorithm for generating rules is divided into For act in Equation 3, the exchange level parameter ACTIVITYTYPE is used which may take one out of the four values “Announcement”, “Confirmation”, “Question”, or “wait”. Their distribution within the LEGO corpus is depicted in Figure 3. 6 Experiments and Results All experiments are conducted using 6-</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>William W. Cohen. 1995. Fast effective rule induction. In Pro ference on Machine Learning, pages 115–123. Morgan Kaufmann, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard O Duda</author>
<author>Peter E Hart</author>
<author>David G Stork</author>
</authors>
<date>2001</date>
<booktitle>Pattern Classification (2nd Edition). WileyInterscience,</booktitle>
<volume>2</volume>
<pages>edition,</pages>
<contexts>
<context position="16934" citStr="Duda et al., 2001" startWordPosition="2723" endWordPosition="2726">he kernel function, the linear discrimination may happen in a space of high dimensionality without explicitly transforming the observation vectors into said space. The SVM implementation which is used in this contribution is libSVM (Chang and Lin, 2011). As this algorithm does not provide class probabilities directly, the respective confidence scores are used. 5.2 Naive Bayes For deriving the posterior probability, the Naive Bayes classifier may be used. It calculates the posterior probability P(ω|o) of having class ω when seeing the n-dimensional observation vector o~ by applying Bayes rule (Duda et al., 2001): In general, observations, i.e., elements of the observation vector, may be correlated with each other and introducing independence assumptions between these elements does usually not reflect the true state of the world. However, correlations are often not very high thus simplifying the Bayes problem has proved to result in reasonable performance. This is utilized by the Naive Bayes classifier by assuming said independence thus calculating three steps: First, rules are grown by adding attributes to the rule. Second, the rules are pruned. If the resulting rule set is not of sufficient performa</context>
</contexts>
<marker>Duda, Hart, Stork, 2001</marker>
<rawString>Richard O. Duda, Peter E. Hart, and David G. Stork. 2001. Pattern Classification (2nd Edition). WileyInterscience, 2 edition, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus-Peter Engelbrecht</author>
<author>Florian G¨odde</author>
<author>Felix Hartard</author>
<author>Hamed Ketabdar</author>
<author>Sebastian M¨oller</author>
</authors>
<title>Modeling user satisfaction with hidden markov model.</title>
<date>2009</date>
<booktitle>In SIGDIAL ’09: Proceedings of the SIGDIAL 2009 Conference,</booktitle>
<pages>170--177</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ, USA.</location>
<marker>Engelbrecht, G¨odde, Hartard, Ketabdar, M¨oller, 2009</marker>
<rawString>Klaus-Peter Engelbrecht, Florian G¨odde, Felix Hartard, Hamed Ketabdar, and Sebastian M¨oller. 2009. Modeling user satisfaction with hidden markov model. In SIGDIAL ’09: Proceedings of the SIGDIAL 2009 Conference, pages 170–177, Morristown, NJ, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunao Hara</author>
<author>Norihide Kitaoka</author>
<author>Kazuya Takeda</author>
</authors>
<title>Estimation method of user satisfaction using n-gram-based dialog history model for spoken dialog system.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<publisher>ELRA.</publisher>
<location>Valletta, Malta,</location>
<contexts>
<context position="5733" citStr="Hara et al. (2010)" startWordPosition="883" endWordPosition="886">ing) and a 6-dimensional input vector. While Engelbrecht et al. (2009) relied on only 6 input variables, we will pursue an approach with 29 input variables. Moreover, we will investigate dialogues of a real world dialogue system annotated with quality labels by expert annotators. Higashinaka et al. (2010) proposed a model for predicting turn-wise ratings for human-human dialogues. Ratings ranging from 1 to 7 were applied by two expert annotators labeling for smoothness, closeness, and willingness. They achieved an UAR2 of only 0.2-0.24 which is only slightly above the random baseline of 0.14. Hara et al. (2010) derived turn level ratings from overall ratings of the dialogue which were applied by the users after the interaction on a five point scale within an online questionnaire. Using ngrams to model the dialogue by calculating n-gram occurrence frequencies for each satisfaction value showed that results for distinguishing between six classes at any point in the dialogue to be hardly above chance. A more robust measure for user satisfaction has been presented by Schmitt et al. (2011) within 2Unweighted Average Recall, see Section 6 Figure 1: A dialogue may be separated into a sequence of system-use</context>
</contexts>
<marker>Hara, Kitaoka, Takeda, 2010</marker>
<rawString>Sunao Hara, Norihide Kitaoka, and Kazuya Takeda. 2010. Estimation method of user satisfaction using n-gram-based dialog history model for spoken dialog system. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta, May. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Yasuhiro Minami</author>
<author>Kohji Dohsaka</author>
<author>Toyomi Meguro</author>
</authors>
<title>Issues in predicting user satisfaction transitions in dialogues: Individual differences, evaluation criteria, and prediction models.</title>
<date>2010</date>
<booktitle>In Spoken Dialogue Systems for Ambient Environments,</booktitle>
<volume>6392</volume>
<pages>48--60</pages>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="5421" citStr="Higashinaka et al. (2010)" startWordPosition="832" endWordPosition="835"> Models (HMMs) to model the SDS as a process evolving over time. Performance ratings on a 5 point scale (“bad”, “poor”, “fair”, “good”, “excellent”) have been applied by the users of the SDS during the dialogue. The interaction was halted while the user rated. A HMM was created consisting of 5 states (one for each rating) and a 6-dimensional input vector. While Engelbrecht et al. (2009) relied on only 6 input variables, we will pursue an approach with 29 input variables. Moreover, we will investigate dialogues of a real world dialogue system annotated with quality labels by expert annotators. Higashinaka et al. (2010) proposed a model for predicting turn-wise ratings for human-human dialogues. Ratings ranging from 1 to 7 were applied by two expert annotators labeling for smoothness, closeness, and willingness. They achieved an UAR2 of only 0.2-0.24 which is only slightly above the random baseline of 0.14. Hara et al. (2010) derived turn level ratings from overall ratings of the dialogue which were applied by the users after the interaction on a five point scale within an online questionnaire. Using ngrams to model the dialogue by calculating n-gram occurrence frequencies for each satisfaction value showed </context>
</contexts>
<marker>Higashinaka, Minami, Dohsaka, Meguro, 2010</marker>
<rawString>Ryuichiro Higashinaka, Yasuhiro Minami, Kohji Dohsaka, and Toyomi Meguro. 2010. Issues in predicting user satisfaction transitions in dialogues: Individual differences, evaluation criteria, and prediction models. In Spoken Dialogue Systems for Ambient Environments, volume 6392 of Lecture Notes in Computer Science, pages 48–60. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L P Kaelbling</author>
<author>M L Littman</author>
<author>A R Cassandra</author>
</authors>
<title>Planning and acting in partially observable stochastic domains.</title>
<date>1998</date>
<journal>Artificial Intelligence,</journal>
<pages>101--1</pages>
<contexts>
<context position="14518" citStr="Kaelbling et al., 1998" startWordPosition="2328" endWordPosition="2332">over, in SDSs, a system action act is performed at the end of each system turn. This can be utilized by adding an additional dependency on this action to the state transition function aij. By augmenting Equation 1, this results in αt(j) = � |S |αt−1(i)aij,actbj(ot) . (3) i=1 This refinement models differences in state transitions evoked by different system actions, e.g., a different transition probability is expected if a WAIT action is performed compared to a CONFIRMATION. Equation 3 is equal to the belief update equation known from the Partially Observable Markov Decision Process formalism (Kaelbling et al., 1998). Therefore, two versions of the Hybrid-HMM are evaluated: an action-independent version as in Equation 1 and an action-dependent version as in Equation 3. 5 Classifier Types For modeling the observation probability bj(ot)of the hybrid HMM, multiple classification schemes have been applied to investigate the influence of observation distributions with different characteristics on the overall performance. In general, classification means estimating a class wˆ to the given observation o by comparing the class-wise probabilities p(wjo). In this work, this probability may be used to model the obse</context>
</contexts>
<marker>Kaelbling, Littman, Cassandra, 1998</marker>
<rawString>L. P. Kaelbling, M. L. Littman, and A. R. Cassandra. 1998. Planning and acting in partially observable stochastic domains. Artificial Intelligence, 101(1-2):99–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Landis</author>
<author>G G Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>Biometrics,</journal>
<volume>33</volume>
<issue>1</issue>
<marker>Landis, Koch, 1977</marker>
<rawString>J. R. Landis and G. G. Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, 33(1):159–174, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian M¨oller</author>
<author>Klaus-Peter Engelbrecht</author>
<author>C K¨uhnel</author>
<author>I Wechsung</author>
<author>B Weiss</author>
</authors>
<title>A taxonomy of quality of service and quality of experience of multimodal human-machine interaction.</title>
<date>2009</date>
<booktitle>In Quality of Multimedia Experience,</booktitle>
<pages>7--12</pages>
<marker>M¨oller, Engelbrecht, K¨uhnel, Wechsung, Weiss, 2009</marker>
<rawString>Sebastian M¨oller, Klaus-Peter Engelbrecht, C. K¨uhnel, I. Wechsung, and B. Weiss. 2009. A taxonomy of quality of service and quality of experience of multimodal human-machine interaction. In Quality of Multimedia Experience, 2009. QoMEx 2009. International Workshop on, pages 7–12, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ibrahim Onaran</author>
<author>N Firat Ince</author>
<author>A Enis Cetin</author>
<author>Aviva Abosch</author>
</authors>
<title>A hybrid svm/hmm based system for the state detection of individual finger movements from multichannel ecog signals.</title>
<date>2011</date>
<booktitle>In Neural Engineering (NER), 2011 5th International IEEE/EMBS Conference on,</booktitle>
<pages>457--460</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="3625" citStr="Onaran et al., 2011" startWordPosition="541" endWordPosition="544">d work on estimating Interaction Quality using HMMs and Conditioned HMMs (Ultes et al., 2012a). In this contribution, we investigate an approach for recognizing the dialogue quality using a hybrid Markovian model. Here, hybrid means combining statistical approaches such as Support Vector Machines with Hidden Markov Models by modeling the observation probability of the HMMs using classification. While this is the first time hybrid approaches are used for estimating Interaction Quality, they are well-known and have been used before for other classification tasks (e.g. (Valstar and Pantic, 2007; Onaran et al., 2011)). This paper is outlined as follows: Related work on subjective quality measurement on the ex1A system-user-exchange consists of a system dialogue turn followed by a user dialogue turn 208 Proceedings of the SIGDIAL 2014 Conference, pages 208–217, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics change level is presented in Section 2. All experiments in this work are based on the Interaction Quality metric of the LEGO corpus described in Section 3. We motivate for introducing time dependency and present our own approach on recognizing Interaction Quality</context>
</contexts>
<marker>Onaran, Ince, Cetin, Abosch, 2011</marker>
<rawString>Ibrahim Onaran, N Firat Ince, A Enis Cetin, and Aviva Abosch. 2011. A hybrid svm/hmm based system for the state detection of individual finger movements from multichannel ecog signals. In Neural Engineering (NER), 2011 5th International IEEE/EMBS Conference on, pages 457–460. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence R Rabiner</author>
</authors>
<title>A tutorial on hidden Markov models and selected applications in speech recognition.</title>
<date>1989</date>
<publisher>Morgan Kaufmann Publishers Inc.,</publisher>
<location>San Francisco, CA, USA.</location>
<marker>Rabiner, 1989</marker>
<rawString>Lawrence R. Rabiner. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Raux</author>
<author>Dan Bohus</author>
<author>Brian Langner</author>
<author>Alan W Black</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Doing research on a deployed spoken dialogue system: One year of letˆas go! experience.</title>
<date>2006</date>
<booktitle>In Proc. of the International Conference on Speech and Language Processing (ICSLP),</booktitle>
<contexts>
<context position="8665" citStr="Raux et al., 2006" startWordPosition="1362" endWordPosition="1365">ere “advanced students of computer science and engineering” (Schmitt et al., 2011), i.e., grad students. The LEGO corpus is based on 200 calls to 209 Figure 2: The three different modeling levels representing the interaction at exchange e,,,: The most detailed exchange level, comprising parameters of the current exchange; the window level, capturing important parameters from the previous n dialog steps (here n = 3); the dialog level, measuring overall performance values from the entire previous interaction. the “Let’s Go Bus Information System” of the Carnegie Mellon University in Pittsburgh (Raux et al., 2006) recorded in 2006. Labels for IQ have been assigned by three expert annotators to 200 calls consisting of 4,885 system-user-exchanges (see Figure 1) in total with an inter-annotator agreement of κ = 0.54. This may be considered as a moderate agreement (cf. Landis and Koch’s Kappa Benchmark Scale (1977)) which is quite good considering the difficulty of the task that required to rate each exchange. For instance, if one annotator reduces the IQ value only one exchange earlier than another annotator, both already disagree on two exchanges. The final label was assigned to each exchange by using th</context>
</contexts>
<marker>Raux, Bohus, Langner, Black, Eskenazi, 2006</marker>
<rawString>Antoine Raux, Dan Bohus, Brian Langner, Alan W. Black, and Maxine Eskenazi. 2006. Doing research on a deployed spoken dialogue system: One year of letˆas go! experience. In Proc. of the International Conference on Speech and Language Processing (ICSLP), September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Schmitt</author>
<author>Benjamin Schatz</author>
<author>Wolfgang Minker</author>
</authors>
<title>Modeling and predicting quality in spoken human-computer interaction.</title>
<date>2011</date>
<booktitle>In Proceedings of the SIGDIAL 2011 Conference,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="6216" citStr="Schmitt et al. (2011)" startWordPosition="961" endWordPosition="964">ness, and willingness. They achieved an UAR2 of only 0.2-0.24 which is only slightly above the random baseline of 0.14. Hara et al. (2010) derived turn level ratings from overall ratings of the dialogue which were applied by the users after the interaction on a five point scale within an online questionnaire. Using ngrams to model the dialogue by calculating n-gram occurrence frequencies for each satisfaction value showed that results for distinguishing between six classes at any point in the dialogue to be hardly above chance. A more robust measure for user satisfaction has been presented by Schmitt et al. (2011) within 2Unweighted Average Recall, see Section 6 Figure 1: A dialogue may be separated into a sequence of system-user-exchanges where each exchange ei consists of a system turn si followed by a user turn ui. their work about Interaction Quality (IQ) for Spoken Dialogue Systems. In contrast to user satisfaction, the labels were applied by expert annotators after the dialogue at the exchange level. Automatically derived parameters were used as features for creating a statistical model using static feature vectors. Schmitt et al. (2011) performed IQ recognition on the LEGO corpus (see Section 3)</context>
<context position="8129" citStr="Schmitt et al., 2011" startWordPosition="1280" endWordPosition="1283"> we use the LEGO corpus published by Schmitt et al. (2012). Interaction Quality is defined similarly to user satisfaction: While the latter represents the true disposition of the user, IQ is the disposition of the user assumed by an expert annotator. Here, expert annotators are people who listen to recorded dialogues after the interactions and rate them by assuming the point of view of the actual person performing the dialogue. These experts are supposed to have some experience with dialogue systems. In this work, expert annotators were “advanced students of computer science and engineering” (Schmitt et al., 2011), i.e., grad students. The LEGO corpus is based on 200 calls to 209 Figure 2: The three different modeling levels representing the interaction at exchange e,,,: The most detailed exchange level, comprising parameters of the current exchange; the window level, capturing important parameters from the previous n dialog steps (here n = 3); the dialog level, measuring overall performance values from the entire previous interaction. the “Let’s Go Bus Information System” of the Carnegie Mellon University in Pittsburgh (Raux et al., 2006) recorded in 2006. Labels for IQ have been assigned by three exp</context>
<context position="10785" citStr="Schmitt et al. (2011)" startWordPosition="1711" endWordPosition="1714">ge. Furthermore, parameters on three levels have been created: the exchange level, the dialogue level, and the window level (see Figure 2). As parameters like ASRCONFIDENCE (confidence of speech recognition) or UTTERANCE (word sequence recognized by speech recognition) can directly be acquired from the dialogue modules they constitute the exchange level. Counts, sums, means, and frequencies of exchange level parameters from multiple exchanges are computed to constitute the dialogue level (all exchanges up to the current one) and the window level (the three previous exchanges). 4 Hybrid-HMM As Schmitt et al. (2011) model the sequential character of the data only indirectly by designing special features, our approach applies Markovian modeling to directly model temporal dependencies. Temporal dependencies on previous system-user-exchanges are not taken into account by Schmitt et al.; only parameters derived from the current exchange are used. However, we found out that Interaction Quality is highly dependent on the IQ value of the previous exchange. Adding the parameter IQp... describing the previous IQ value to the input vector to the IQ model consisting of several parameters results in an extended inpu</context>
<context position="13631" citStr="Schmitt et al. (2011)" startWordPosition="2181" endWordPosition="2184"> Baum-Welch algorithm. Usually, the observation function bqt is modeled with Gaussian mixture models (GMMs). For more information on general HMMs, please refer to Rabiner et al. (1989). For determining the most likely class ˆwt at time t, where each state j E 5 is associated with one class w, the following equation is used: ˆwt = arg max αt(j) . (2) j For applying an HMM while exploiting existing statistical classification approaches, the observation function bj(ot) is modeled by using confidence score distributions of statistical classifiers, e.g., a Support Vector Machine in accordance with Schmitt et al. (2011) (see Section 5). Furthermore, the transition function aij is computed by taking the frequencies of the state transitions contained in the given corpus. Therefore, an ergodic HMM is used comprising five states with each representing one of the five IQ scores. Moreover, in SDSs, a system action act is performed at the end of each system turn. This can be utilized by adding an additional dependency on this action to the state transition function aij. By augmenting Equation 1, this results in αt(j) = � |S |αt−1(i)aij,actbj(ot) . (3) i=1 This refinement models differences in state transitions evok</context>
<context position="20695" citStr="Schmitt et al. (2011)" startWordPosition="3327" endWordPosition="3330"> Figure 3: Distribution of the four values for act in Equation 3 in the LEGO corpus. While “wait” occurs rarely, the other three main actions occur at roughly the same frequency. (also producing the observation probabilities of the Hybrid-HMM approach) and the evaluation of the Hybrid-HMM. For the latter, two phases of cross-validation were applied. Interaction Quality estimation is done by using three commonly used evaluation metrics: Unweighted Average Recall (UAR), Cohen’s Kappa (Cohen, 1960) and Spearman’s Rho (Spearman, 1904). These are also selected as the same metrics have been used in Schmitt et al. (2011) as well. Recall in general is defined as the rate of correctly classified samples belonging to one class. The recall in UAR for multi-class classification problems with N classes recalli is computed for each class i and then averaged over all class-wise recalls: recalli . (9) Cohen’s Kappa measures the relative agreement between two corresponding sets of ratings. In our case, we compute the number of label agreements corrected by the chance level of agreement divided by the maximum proportion of times the labelers could agree. However, Cohen’s weighted Kappa is applied as ordinal scores are c</context>
<context position="22169" citStr="Schmitt et al. (2011)" startWordPosition="3574" endWordPosition="3577">minimum ratings possible. Table 1: Results for IQ recognition of the statistical classifiers: UAR, κ and ρ for linear SVM, Bayes classification and Rule Induction. σ2 represents the variances of the confidence scores. UAR κ ρ σ2 SVM (linear) .495 .611 .774 .020 Bayes .467 .541 .716 .127 Rule Induction .596 .678 .790 .131 Correlation between two variables describes the degree by which one variable can be expressed by the other. Spearman’s Rho is a non-parametric method assuming a monotonic function between the two variables (Spearman, 1904). 6.1 Baseline As baseline, we adapted the approach of Schmitt et al. (2011). While they focused only on an SVM with linear kernel, we investigate three different static classification approaches. Different classifiers will produce different confidence distributions. These distributions will have different characteristics which is of special interest for evaluating the Hybrid-HMM as will be discussed in Section 7. The confidence characteristics are represented by the variance of the confidence scores σ2. This variance is used as indicator for how certain the classifier is about its results. If one IQ value has a high confidence while all others have low confidence, th</context>
</contexts>
<marker>Schmitt, Schatz, Minker, 2011</marker>
<rawString>Alexander Schmitt, Benjamin Schatz, and Wolfgang Minker. 2011. Modeling and predicting quality in spoken human-computer interaction. In Proceedings of the SIGDIAL 2011 Conference, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Schmitt</author>
<author>Stefan Ultes</author>
<author>Wolfgang Minker</author>
</authors>
<title>A parameterized and annotated corpus of the cmu let’s go bus information system.</title>
<date>2012</date>
<booktitle>In International Conference on Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="7566" citStr="Schmitt et al. (2012)" startWordPosition="1186" endWordPosition="1189"> 0.2. Ultes et al. (2012a) put an emphasis on the sequential character of the IQ measure by applying a Hidden Markov Models (HMMs) and a Conditioned Hidden Markov Models (CHMMs). Both have been applied using 6-fold cross validation and a reduced feature set of the LEGO corpus achieving an UAR2 of 0.44 for HMMs and 0.39 for CHMMs. While Ultes et al. (2012a) used generic Gaussian Mixture Models to model the observation probabilities, we use confidence distributions of static classification algorithms. 3 The LEGO Corpus For Interaction Quality (IQ) estimation, we use the LEGO corpus published by Schmitt et al. (2012). Interaction Quality is defined similarly to user satisfaction: While the latter represents the true disposition of the user, IQ is the disposition of the user assumed by an expert annotator. Here, expert annotators are people who listen to recorded dialogues after the interactions and rate them by assuming the point of view of the actual person performing the dialogue. These experts are supposed to have some experience with dialogue systems. In this work, expert annotators were “advanced students of computer science and engineering” (Schmitt et al., 2011), i.e., grad students. The LEGO corpu</context>
<context position="9740" citStr="Schmitt et al., 2012" startWordPosition="1541" endWordPosition="1544">nly one exchange earlier than another annotator, both already disagree on two exchanges. The final label was assigned to each exchange by using the median of all three individual ratings. IQ was labeled on a scale from 1 (extremely unsatisfied) to 5 (satisfied) considering the complete dialogue up to the current exchange. Thus, each exchange has been rated without regarding any upcoming user utterance. As the users are expected to be satisfied at the beginning, each dialogue’s initial rating is 5. In order to ensure consistent labeling, the expert annotators had to follow labeling guidelines (Schmitt et al., 2012). An example of an annotated dialogue is shown in Table 5. It starts off with a good IQ until the system provides some results and then falls drastically as the user input does not correspond to what the system expects. Thus, the system remains in a loop until the user reacts appropriately. Parameters used as input variables for the IQ model have been derived from the dialogue system modules automatically for each exchange. Furthermore, parameters on three levels have been created: the exchange level, the dialogue level, and the window level (see Figure 2). As parameters like ASRCONFIDENCE (co</context>
<context position="18550" citStr="Schmitt et al., 2012" startWordPosition="2994" endWordPosition="2997">s with constant values for most exchanges have been excluded. These would result in rows of zeros during computation of the covariance matrices of the feature vectors, which are needed for HMM and CHMM classification. A row of zeros in the covariance matrix will make it noninvertible, which will cause errors during the computation of the emission probabilities. Therefore, a feature set consisting of 29 interaction parameters is used for both defining a baseline and for evaluating the Hybrid-HMM. The set consists of the following parameters (for an explanation of the features, please refer to (Schmitt et al., 2012)): Exchange Level ASRRECOGNITIONSTATUS, ACTIVITYTYPE, ASRCONFIDENCE, ROLEINDEX, ROLENAME, UTD, REPROMPT?, BARGED-IN?, DD, WPST, WPUT Dialogue Level MEANASRCONFIDENCE, #ASRREJECTIONS, #TIMEOUTS ASRREJ, #BARGEINS, %ASRREJECTIONS, %TIMEOUTS ASRREJ, %BARGEINS, #REPROMPTS, %REPROMPTS, #SYSTEMQUESTIONS P(ω|~o) = p(~o|ω) · P(ω) p(~o) . (7) Window Level #TIMEOUTS ASRREJ, #ASRREJECn TIONS, #BARGEINS, %BARGEINS, #SYSTEMQUESp(~o|ω) = p(oZ|ω) . (8) TIONS, MEANASRCONFIDENCE, #ASRSUCCESS, Z=1 #RE-PROMPT 5.3 Rule Induction The classification algorithm Rule Induction or Rule Learner is based on the idea of de</context>
</contexts>
<marker>Schmitt, Ultes, Minker, 2012</marker>
<rawString>Alexander Schmitt, Stefan Ultes, and Wolfgang Minker. 2012. A parameterized and annotated corpus of the cmu let’s go bus information system. In International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Edward Spearman</author>
</authors>
<title>The proof and measurement of association between two things.</title>
<date>1904</date>
<journal>American Journal of Psychology,</journal>
<pages>15--88</pages>
<contexts>
<context position="20610" citStr="Spearman, 1904" startWordPosition="3313" endWordPosition="3314">n selected as a reasonable trade-off between validity and computation time. 212 Figure 3: Distribution of the four values for act in Equation 3 in the LEGO corpus. While “wait” occurs rarely, the other three main actions occur at roughly the same frequency. (also producing the observation probabilities of the Hybrid-HMM approach) and the evaluation of the Hybrid-HMM. For the latter, two phases of cross-validation were applied. Interaction Quality estimation is done by using three commonly used evaluation metrics: Unweighted Average Recall (UAR), Cohen’s Kappa (Cohen, 1960) and Spearman’s Rho (Spearman, 1904). These are also selected as the same metrics have been used in Schmitt et al. (2011) as well. Recall in general is defined as the rate of correctly classified samples belonging to one class. The recall in UAR for multi-class classification problems with N classes recalli is computed for each class i and then averaged over all class-wise recalls: recalli . (9) Cohen’s Kappa measures the relative agreement between two corresponding sets of ratings. In our case, we compute the number of label agreements corrected by the chance level of agreement divided by the maximum proportion of times the lab</context>
<context position="22093" citStr="Spearman, 1904" startWordPosition="3563" endWordPosition="3564">e, r1 and r2 denote the rating pair and rmax and rmin the maximum and minimum ratings possible. Table 1: Results for IQ recognition of the statistical classifiers: UAR, κ and ρ for linear SVM, Bayes classification and Rule Induction. σ2 represents the variances of the confidence scores. UAR κ ρ σ2 SVM (linear) .495 .611 .774 .020 Bayes .467 .541 .716 .127 Rule Induction .596 .678 .790 .131 Correlation between two variables describes the degree by which one variable can be expressed by the other. Spearman’s Rho is a non-parametric method assuming a monotonic function between the two variables (Spearman, 1904). 6.1 Baseline As baseline, we adapted the approach of Schmitt et al. (2011). While they focused only on an SVM with linear kernel, we investigate three different static classification approaches. Different classifiers will produce different confidence distributions. These distributions will have different characteristics which is of special interest for evaluating the Hybrid-HMM as will be discussed in Section 7. The confidence characteristics are represented by the variance of the confidence scores σ2. This variance is used as indicator for how certain the classifier is about its results. If</context>
</contexts>
<marker>Spearman, 1904</marker>
<rawString>Charles Edward Spearman. 1904. The proof and measurement of association between two things. American Journal of Psychology, 15:88–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Ultes</author>
<author>Robert ElChabb</author>
<author>Wolfgang Minker</author>
</authors>
<title>Application and evaluation of a conditioned hidden markov model for estimating interaction quality of spoken dialogue systems.</title>
<date>2012</date>
<booktitle>In Proceedings of the 4th International Workshop on Spoken Language Dialog System (IWSDS),</booktitle>
<pages>141--150</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="2191" citStr="Ultes et al., 2012" startWordPosition="322" endWordPosition="325"> of dialogue assessment. For QoE, M¨oller et al. (2009) identified several aspects contributing to a good user experience, e.g., usability or acceptability. These aspects can be combined under the term user satisfaction, describing the degree by which the user is satisfied with the system’s performance. By assessing QoE, the hope of the research community is to better measure the human-like quality of an SDS. While this information may be used during the design process, enabling automatically derived user satisfaction within the dialogue management allows for adaption of the ongoing dialogue (Ultes et al., 2012b). First work on deriving subjective metrics automatically has been performed by Walker et al. (1997) resulting in the PARADISE framework, which is the current quasi-standard in this field. Briefly explained, a linear dependency is assumed between dialogue parameters and user satisfaction to estimate qualitative performance on the dialogue level. Measuring the performance of complete dialogues does not allow for adapting to the user during the dialogue (Ultes et al., 2012b). Hence, performance measures which provide a measurement for each system-user-exchange1 are of interest. Approaches base</context>
<context position="6969" citStr="Ultes et al. (2012" startWordPosition="1088" endWordPosition="1091">each exchange ei consists of a system turn si followed by a user turn ui. their work about Interaction Quality (IQ) for Spoken Dialogue Systems. In contrast to user satisfaction, the labels were applied by expert annotators after the dialogue at the exchange level. Automatically derived parameters were used as features for creating a statistical model using static feature vectors. Schmitt et al. (2011) performed IQ recognition on the LEGO corpus (see Section 3) using linear SVMs. They achieved an UAR2 of 0.58 based on 10-fold cross-validation which is clearly above the random baseline of 0.2. Ultes et al. (2012a) put an emphasis on the sequential character of the IQ measure by applying a Hidden Markov Models (HMMs) and a Conditioned Hidden Markov Models (CHMMs). Both have been applied using 6-fold cross validation and a reduced feature set of the LEGO corpus achieving an UAR2 of 0.44 for HMMs and 0.39 for CHMMs. While Ultes et al. (2012a) used generic Gaussian Mixture Models to model the observation probabilities, we use confidence distributions of static classification algorithms. 3 The LEGO Corpus For Interaction Quality (IQ) estimation, we use the LEGO corpus published by Schmitt et al. (2012). I</context>
<context position="12026" citStr="Ultes et al. (2012" startWordPosition="1909" endWordPosition="1912">he Information Gain Ratio (IGR) of each parameter of the extended input vector shows that IQp... achieves the highest IGR value of 1.0. In other words, IQp... represents the parameter which contains the most information for the classification task. While performing IQ recognition on the extended features set using the annotated IQ values results in an UAR of 0.82, rather using the estimated IQ value results in an UAR of only 0.43. Consequently, other configurations have to be investigated. Here, Markovian approaches offer a self-contained concept of using these temporal dependencies. However, Ultes et al. (2012a) showed that applying neither a classical HMM nor a conditioned HMM yields results outperforming static approaches. Therefore, in this Section we present a Hybrid210 HMM approach, which is based on the classical HMM and takes advantage of good performing existing static classification approaches. The classical HMM, specifically used for time-sequential data, consists of a set of states 5 with transition probability matrix A and initial probability vector π over a set of observations B (also called vocabulary) and an observation function bqt dependent on the state qt. For calculating the prob</context>
<context position="17883" citStr="Ultes et al., 2012" startWordPosition="2881" endWordPosition="2884">onable performance. This is utilized by the Naive Bayes classifier by assuming said independence thus calculating three steps: First, rules are grown by adding attributes to the rule. Second, the rules are pruned. If the resulting rule set is not of sufficient performance, all training examples which are covered by the generated rules are removed from the example set and a new rule is created. 5.4 Feature selection As stated previously, all experiments are based on the LEGO corpus presented in Section 3. In order to keep the presented results comparable to previous work based on HMM and CHMM (Ultes et al., 2012a), a reduced parameter set is used. Parameters with constant values for most exchanges have been excluded. These would result in rows of zeros during computation of the covariance matrices of the feature vectors, which are needed for HMM and CHMM classification. A row of zeros in the covariance matrix will make it noninvertible, which will cause errors during the computation of the emission probabilities. Therefore, a feature set consisting of 29 interaction parameters is used for both defining a baseline and for evaluating the Hybrid-HMM. The set consists of the following parameters (for an </context>
<context position="25262" citStr="Ultes et al., 2012" startWordPosition="4094" endWordPosition="4097">nted in Section 6.1 are used. The initial distribution 7 for each HMM was chosen in accordance with the annotation guidelines of the LEGO corpus starting each dialogue with an IQ score of 5 resulting in 75 = P(IQ = 5) = 1.0 74 = 73 = 72 = 71 = P(IQ =�5) = 0.0 . Results of the experiments with action-dependent (AD) and action-independent (AI) transition function may be seen in Table 2. Again, Rule Induction performed best with Naive Bayes on the second and SVM on the third place. 7 Discussion While previous work on applying the HMM and CHMM for IQ recognition could not outperform the baseline (Ultes et al., 2012a), Hybrid-HMM experiments show a significant improvement in UAR, Cohen’s κ and Spearman’s p for Naive Bayes and Rule Induction. While performance declines for the linear SVM, this difference has shown to be not significant. The relative difference of the Hybrid-HMM compared to the respective baseline approaches using an action-dependent and an actionindependent transition matrix is depicted in Figure 4. Improvement for the Bayes method was the highest significantly increasing UAR by up to 4.5% relative to the baseline. However, adding action-dependency to the Hybrid-HMM does not show any effe</context>
</contexts>
<marker>Ultes, ElChabb, Minker, 2012</marker>
<rawString>Stefan Ultes, Robert ElChabb, and Wolfgang Minker. 2012a. Application and evaluation of a conditioned hidden markov model for estimating interaction quality of spoken dialogue systems. In Proceedings of the 4th International Workshop on Spoken Language Dialog System (IWSDS), pages 141– 150. Springer, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Ultes</author>
<author>Alexander Schmitt</author>
<author>Wolfgang Minker</author>
</authors>
<title>Towards quality-adaptive spoken dialogue management.</title>
<date>2012</date>
<booktitle>In NAACL-HLT Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data (SDCTD 2012),</booktitle>
<pages>49--52</pages>
<publisher>ACL.</publisher>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="2191" citStr="Ultes et al., 2012" startWordPosition="322" endWordPosition="325"> of dialogue assessment. For QoE, M¨oller et al. (2009) identified several aspects contributing to a good user experience, e.g., usability or acceptability. These aspects can be combined under the term user satisfaction, describing the degree by which the user is satisfied with the system’s performance. By assessing QoE, the hope of the research community is to better measure the human-like quality of an SDS. While this information may be used during the design process, enabling automatically derived user satisfaction within the dialogue management allows for adaption of the ongoing dialogue (Ultes et al., 2012b). First work on deriving subjective metrics automatically has been performed by Walker et al. (1997) resulting in the PARADISE framework, which is the current quasi-standard in this field. Briefly explained, a linear dependency is assumed between dialogue parameters and user satisfaction to estimate qualitative performance on the dialogue level. Measuring the performance of complete dialogues does not allow for adapting to the user during the dialogue (Ultes et al., 2012b). Hence, performance measures which provide a measurement for each system-user-exchange1 are of interest. Approaches base</context>
<context position="6969" citStr="Ultes et al. (2012" startWordPosition="1088" endWordPosition="1091">each exchange ei consists of a system turn si followed by a user turn ui. their work about Interaction Quality (IQ) for Spoken Dialogue Systems. In contrast to user satisfaction, the labels were applied by expert annotators after the dialogue at the exchange level. Automatically derived parameters were used as features for creating a statistical model using static feature vectors. Schmitt et al. (2011) performed IQ recognition on the LEGO corpus (see Section 3) using linear SVMs. They achieved an UAR2 of 0.58 based on 10-fold cross-validation which is clearly above the random baseline of 0.2. Ultes et al. (2012a) put an emphasis on the sequential character of the IQ measure by applying a Hidden Markov Models (HMMs) and a Conditioned Hidden Markov Models (CHMMs). Both have been applied using 6-fold cross validation and a reduced feature set of the LEGO corpus achieving an UAR2 of 0.44 for HMMs and 0.39 for CHMMs. While Ultes et al. (2012a) used generic Gaussian Mixture Models to model the observation probabilities, we use confidence distributions of static classification algorithms. 3 The LEGO Corpus For Interaction Quality (IQ) estimation, we use the LEGO corpus published by Schmitt et al. (2012). I</context>
<context position="12026" citStr="Ultes et al. (2012" startWordPosition="1909" endWordPosition="1912">he Information Gain Ratio (IGR) of each parameter of the extended input vector shows that IQp... achieves the highest IGR value of 1.0. In other words, IQp... represents the parameter which contains the most information for the classification task. While performing IQ recognition on the extended features set using the annotated IQ values results in an UAR of 0.82, rather using the estimated IQ value results in an UAR of only 0.43. Consequently, other configurations have to be investigated. Here, Markovian approaches offer a self-contained concept of using these temporal dependencies. However, Ultes et al. (2012a) showed that applying neither a classical HMM nor a conditioned HMM yields results outperforming static approaches. Therefore, in this Section we present a Hybrid210 HMM approach, which is based on the classical HMM and takes advantage of good performing existing static classification approaches. The classical HMM, specifically used for time-sequential data, consists of a set of states 5 with transition probability matrix A and initial probability vector π over a set of observations B (also called vocabulary) and an observation function bqt dependent on the state qt. For calculating the prob</context>
<context position="17883" citStr="Ultes et al., 2012" startWordPosition="2881" endWordPosition="2884">onable performance. This is utilized by the Naive Bayes classifier by assuming said independence thus calculating three steps: First, rules are grown by adding attributes to the rule. Second, the rules are pruned. If the resulting rule set is not of sufficient performance, all training examples which are covered by the generated rules are removed from the example set and a new rule is created. 5.4 Feature selection As stated previously, all experiments are based on the LEGO corpus presented in Section 3. In order to keep the presented results comparable to previous work based on HMM and CHMM (Ultes et al., 2012a), a reduced parameter set is used. Parameters with constant values for most exchanges have been excluded. These would result in rows of zeros during computation of the covariance matrices of the feature vectors, which are needed for HMM and CHMM classification. A row of zeros in the covariance matrix will make it noninvertible, which will cause errors during the computation of the emission probabilities. Therefore, a feature set consisting of 29 interaction parameters is used for both defining a baseline and for evaluating the Hybrid-HMM. The set consists of the following parameters (for an </context>
<context position="25262" citStr="Ultes et al., 2012" startWordPosition="4094" endWordPosition="4097">nted in Section 6.1 are used. The initial distribution 7 for each HMM was chosen in accordance with the annotation guidelines of the LEGO corpus starting each dialogue with an IQ score of 5 resulting in 75 = P(IQ = 5) = 1.0 74 = 73 = 72 = 71 = P(IQ =�5) = 0.0 . Results of the experiments with action-dependent (AD) and action-independent (AI) transition function may be seen in Table 2. Again, Rule Induction performed best with Naive Bayes on the second and SVM on the third place. 7 Discussion While previous work on applying the HMM and CHMM for IQ recognition could not outperform the baseline (Ultes et al., 2012a), Hybrid-HMM experiments show a significant improvement in UAR, Cohen’s κ and Spearman’s p for Naive Bayes and Rule Induction. While performance declines for the linear SVM, this difference has shown to be not significant. The relative difference of the Hybrid-HMM compared to the respective baseline approaches using an action-dependent and an actionindependent transition matrix is depicted in Figure 4. Improvement for the Bayes method was the highest significantly increasing UAR by up to 4.5% relative to the baseline. However, adding action-dependency to the Hybrid-HMM does not show any effe</context>
</contexts>
<marker>Ultes, Schmitt, Minker, 2012</marker>
<rawString>Stefan Ultes, Alexander Schmitt, and Wolfgang Minker. 2012b. Towards quality-adaptive spoken dialogue management. In NAACL-HLT Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data (SDCTD 2012), pages 49–52, Montr´eal, Canada, June. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Ultes</author>
<author>Alexander Schmitt</author>
<author>Wolfgang Minker</author>
</authors>
<title>On quality ratings for spoken dialogue systems – experts vs. users.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>569--578</pages>
<publisher>ACL,</publisher>
<contexts>
<context position="27028" citStr="Ultes et al., 2013" startWordPosition="4392" endWordPosition="4395">with a high variance—and therefore with a greater certainty about the classification result—, an improvement could be accomplished. However, the perfor214 Table 3: Results of Hybrid-HMM with handcrafted transition matrix of the action-independent version. UAR κ ρ SVM (linear) Bayes Rule Induction .506 .642 .797 .487 .563 .734 .608 .712 .825 Table 4: Handcrafted transition matrix based on empirical data. PPPPPP to 1 2 3 4 5 1 2 3 4 5 0.7 0.3 0 0 0 0.25 0.5 0.25 0 0 0 0.25 0.5 0.25 0 0 0 0.25 0.5 0.25 0 0 0 0.3 0.7 from by users (without guidelines), achieving a Spearman’s p of 0.66 (α &lt; 0.01) (Ultes et al., 2013). 8 Conclusions As previously publi shed, approaches for recognizing the Interaction Quality of Spoken Dialogue 215 Systems are based on static classification without temporal dependency on previous values, a Hybrid Hidden Markov Model approach has been investigated based on three static classifiers. The Hybrid-HMM achieved a relative improvement up Finally, it is notable that rule induction outperderstan ding the problem of estimating Interaction Quality better, especially since rule-based recognition methods allow easy interpretation. its results. Further research should be conducted investi</context>
</contexts>
<marker>Ultes, Schmitt, Minker, 2013</marker>
<rawString>Stefan Ultes, Alexander Schmitt, and Wolfgang Minker. 2013. On quality ratings for spoken dialogue systems – experts vs. users. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 569– 578. ACL, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel F Valstar</author>
<author>Maja Pantic</author>
</authors>
<title>Combined support vector machines and hidden markov models for modeling facial action temporal dynamics.</title>
<date>2007</date>
<booktitle>In Human-Computer Interaction,</booktitle>
<volume>4796</volume>
<pages>118--127</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="3603" citStr="Valstar and Pantic, 2007" startWordPosition="537" endWordPosition="540">milar to this, we presented work on estimating Interaction Quality using HMMs and Conditioned HMMs (Ultes et al., 2012a). In this contribution, we investigate an approach for recognizing the dialogue quality using a hybrid Markovian model. Here, hybrid means combining statistical approaches such as Support Vector Machines with Hidden Markov Models by modeling the observation probability of the HMMs using classification. While this is the first time hybrid approaches are used for estimating Interaction Quality, they are well-known and have been used before for other classification tasks (e.g. (Valstar and Pantic, 2007; Onaran et al., 2011)). This paper is outlined as follows: Related work on subjective quality measurement on the ex1A system-user-exchange consists of a system dialogue turn followed by a user dialogue turn 208 Proceedings of the SIGDIAL 2014 Conference, pages 208–217, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics change level is presented in Section 2. All experiments in this work are based on the Interaction Quality metric of the LEGO corpus described in Section 3. We motivate for introducing time dependency and present our own approach on recognizi</context>
</contexts>
<marker>Valstar, Pantic, 2007</marker>
<rawString>Michel F. Valstar and Maja Pantic. 2007. Combined support vector machines and hidden markov models for modeling facial action temporal dynamics. In Human-Computer Interaction, volume 4796 of Lecture Notes in Computer Science, pages 118–127. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The nature of statistical learning theory.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York,</location>
<contexts>
<context position="15668" citStr="Vapnik, 1995" startWordPosition="2509" endWordPosition="2510">). In this work, this probability may be used to model the observation probability bj(o) of the HMM by the posterior probability p(wjo) = bj(o) (4) for j = w. As not all classification algorithms provide a posterior probability, it may be replaced by the confidence distribution. A general description of the classification algorithms used in this work are described in the following Section along with a motivation for the feature subset of the LEGO corpus used for estimating the Interaction Quality in this work. 5.1 Support Vector Machine For a two class problem, a Support Vector Machine (SVM) (Vapnik, 1995) is based on the concept of linear discrimination with maximum margin by defining a hyperplane separating the two classes. The estimated class wˆ for observation vector o� is based on the sign of the decision function N k(o) = αiziK(mi, 01 + b , (5) i=1 where mi represent support vectors defining the hyper plane (together with b), zi the known class �mi belongs to, αi the weight of mi, and K(·, ·) a 211 kernel function. The kernel function is defined as K(~m, ~m�) = (ϕ(~m), ϕ(~m�)) , (6) where ϕ(~m) represents a transformation function mapping m~ into a space Φ of different dimensionality and </context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir N. Vapnik. 1995. The nature of statistical learning theory. Springer-Verlag New York, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Diane Litman</author>
<author>Candace A Kamm</author>
<author>Alicia Abella</author>
</authors>
<title>Paradise: a framework for evaluating spoken dialogue agents.</title>
<date>1997</date>
<booktitle>In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>271--280</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2293" citStr="Walker et al. (1997)" startWordPosition="338" endWordPosition="341"> good user experience, e.g., usability or acceptability. These aspects can be combined under the term user satisfaction, describing the degree by which the user is satisfied with the system’s performance. By assessing QoE, the hope of the research community is to better measure the human-like quality of an SDS. While this information may be used during the design process, enabling automatically derived user satisfaction within the dialogue management allows for adaption of the ongoing dialogue (Ultes et al., 2012b). First work on deriving subjective metrics automatically has been performed by Walker et al. (1997) resulting in the PARADISE framework, which is the current quasi-standard in this field. Briefly explained, a linear dependency is assumed between dialogue parameters and user satisfaction to estimate qualitative performance on the dialogue level. Measuring the performance of complete dialogues does not allow for adapting to the user during the dialogue (Ultes et al., 2012b). Hence, performance measures which provide a measurement for each system-user-exchange1 are of interest. Approaches based on Hidden Markov Models (HMMs) are widely used for sequence modeling. Therefore, Engelbrecht et al. </context>
</contexts>
<marker>Walker, Litman, Kamm, Abella, 1997</marker>
<rawString>Marilyn Walker, Diane Litman, Candace A. Kamm, and Alicia Abella. 1997. Paradise: a framework for evaluating spoken dialogue agents. In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics, pages 271–280, Morristown, NJ, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Wilcoxon</author>
</authors>
<title>Individual comparisons by ranking methods.</title>
<date>1945</date>
<journal>Biometrics bulletin,</journal>
<volume>1</volume>
<issue>6</issue>
<contexts>
<context position="23958" citStr="Wilcoxon, 1945" startWordPosition="3875" endWordPosition="3876">ults obtained by Schmitt et al. (UAR of 0.58) as we used a reduced feature set while they used all available features. 6.2 Hybrid-HMM For evaluating the Hybrid-HMM on Interaction Quality recognition, three aspects are of interest. Most prominent is whether the presented approaches outperform the baseline, i.e., the clas1 UAR = N N i=1 213 ‐ ‐ Figure 4: Relative difference of UAR in percent between the baseline performance and the HybridHMM for the action-independent (AI), action-dependent (AD) and handcrafted (HC) transition matrix. Differences marked with an * are significant (Wilcoxon test (Wilcoxon, 1945), α &lt; 0.05). ‐ Table 2: Results for the Hybrid-HMM approach: UAR, κ and p for the action-independent (AI) and action-dependent (AD) versions. ‐ AI κ AI AD UAR AD ρ AI AD SVM (linear) .477 .484 .599 .598 .770 .771 Bayes .486 .489 .563 .564 .737 .741 Rule Induction .608 .609 .712 .714 .826 .824 sifier which produces the observation probabilities. Moreover, performance values of actiondependent approaches and action-independent approaches are compared. In addition, the results are analyzed with respect to the characteristic of the confidence distribution. For producing the confidence scores repre</context>
<context position="26136" citStr="Wilcoxon, 1945" startWordPosition="4231" endWordPosition="4232">rid-HMM compared to the respective baseline approaches using an action-dependent and an actionindependent transition matrix is depicted in Figure 4. Improvement for the Bayes method was the highest significantly increasing UAR by up to 4.5% relative to the baseline. However, adding action-dependency to the Hybrid-HMM does not show any effect. This may be a result of using ACTIVITYTYPE instead of the actual action. However, using the actual action would result in the need for more data as it contains 45 different values. Significance for all results has been calculated using the Wilcoxon test (Wilcoxon, 1945) by pair-wise comparison of the estimated IQ values of all exchanges. All results except for the decline in SVM performance are significant with α &lt; 0.05. Correlating the confidence variances shown in Table 1 with the improvements of the HybridHMM reveals that for methods with a high variance—and therefore with a greater certainty about the classification result—, an improvement could be accomplished. However, the perfor214 Table 3: Results of Hybrid-HMM with handcrafted transition matrix of the action-independent version. UAR κ ρ SVM (linear) Bayes Rule Induction .506 .642 .797 .487 .563 .734</context>
</contexts>
<marker>Wilcoxon, 1945</marker>
<rawString>Frank Wilcoxon. 1945. Individual comparisons by ranking methods. Biometrics bulletin, 1(6):80–83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>