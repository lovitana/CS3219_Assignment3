<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002907">
<title confidence="0.997953">
Two-Stage Stochastic Natural Language Generation for Email Synthesis
by Modeling Sender Style and Topic Structure
</title>
<author confidence="0.995394">
Yun-Nung Chen and Alexander I. Rudnicky
</author>
<affiliation confidence="0.8327925">
School of Computer Science, Carnegie Mellon University
5000 Forbes Ave., Pittsburgh, PA 15213-3891, USA
</affiliation>
<email confidence="0.993629">
{yvchen, air}@cs.cmu.edu
</email>
<sectionHeader confidence="0.997257" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947411764706">
This paper describes a two-stage pro-
cess for stochastic generation of email, in
which the first stage structures the emails
according to sender style and topic struc-
ture (high-level generation), and the sec-
ond stage synthesizes text content based
on the particulars of an email element
and the goals of a given communication
(surface-level realization). Synthesized
emails were rated in a preliminary experi-
ment. The results indicate that sender style
can be detected. In addition we found
that stochastic generation performs better
if applied at the word level than at an
original-sentence level (“template-based”)
in terms of email coherence, sentence flu-
ency, naturalness, and preference.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955576271186">
This paper focuses on generating language for the
email domain, with the goal of producing mails
that reflect sender style and the intent of the com-
munication. Such a process might be used for the
generation of common messages (for example a
request for a meeting without direct intervention
from the sender). It can also be used in situations
where naturalistic email is needed for other ap-
plications. For instance, our email generator was
developed to provide emails to be used as part of
synthetic evidence of insider threats for purposes
of training, prototyping, and evaluating anomaly
detectors (Hershkop et al., 2011).
There are two approaches to natural language
generation (NLG), one focuses on generating text
using templates or rules (linguistic) methods, the
another uses corpus-based statistical techniques.
Oh and Rudnicky (2002) showed that stochastic
generation benefits from two factors: 1) it takes
advantage of the practical language of a domain
expert instead of the developer and 2) it restates
the problem in terms of classification and label-
ing, where expertise is not required for developing
a rule-based generation system. They found that
naive listeners found such utterances as accept-
able as human-generated utterances. Belz (2005)
also proposed a probabilistic NLG approach to
make systems more robust and components more
reusable, reducing manual corpus analysis.
However, most work usually focused on well-
structured documents such as news and Wikipedia,
while email messages differ from them, which
reflect senders’ style and are more spontaneous.
Lampert et al. (2009) segmented email messages
into zones, including sender zones, quoted con-
versation zones, and boilerplate zones. This paper
only models the text in the sender zone, new con-
tent from the current sender. In the present work,
we investigate the use of stochastic techniques for
generation of a different class of communications
and whether global structures can be convincingly
created in the email domain.
A lot of NLG systems are applied in dialogue
systems, some of which focus on topic model-
ing (Sauper and Barzilay, 2009; Barzilay and Lap-
ata, 2008; Barzilay and Lee, 2004), proposing al-
gorithms to balance local fit of information and
global coherence. However, they seldom con-
sider to model the speaker’s characteristics. Gill
et al. (2012) considered sentiment such as open-
ness and neuroticism to specify characters for di-
alogue generation. In stead of modeling authors’
attitudes, this paper proposes the first approach of
synthesizing emails by modeling their writing pat-
terns. Specifically we investigate whether stochas-
tic techniques can be used to acceptably model
longer texts and individual speaker characteristics
in the emails, both of which may require higher
cohesion to be acceptable.
</bodyText>
<sectionHeader confidence="0.812772" genericHeader="introduction">
2 Overview of Framework
</sectionHeader>
<bodyText confidence="0.999328555555556">
Our proposed NLG approach has three steps: pre-
processing training data, modeling sender style
and topic structure for email organization, fol-
lowed by surface realization, shown in Figure 1.
In preprocessing, we segment sentences for
each email, and label email structural elements.
This is used to create a structural label sequence
for each email, and then used to model sender
style and topic structure for email organization
(1st stage in the figure). Content slots are also
annotated for surface realization (2nd stage in the
figure). Details are in Section 3.
From the annotated corpus, we build sender-
specific and topic-specific structure language
models based on structural label sequences, and
use a mixture sender-topic-specific model to
stochastically generate email structure in the first
stage. The process is detailed in Section 4.
</bodyText>
<page confidence="0.978648">
152
</page>
<bodyText confidence="0.3900315">
Proceedings of the 8th International Natural Language Generation Conference, pages 152–156,
Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics
</bodyText>
<figure confidence="0.999435607843137">
Input to NLG
Training Data Preprocessing
Slot-Value Pairs
Email
Document
Archive
Structural Label
Annotation
Slot
Annotation
Sender Topic
Structural
Label
Sequences
Emails w/
Slots
1st Stage: Modeling Sender Style and Topic Structure for Email Organization
2nd Stage: Surface Realization
Building
Structure
LM
Building
Content
LM
Generating
Text Content
Sender-Specific
Model
Topic-Specific
Model
Email Candidates
Hi [Person]
Today’s ...
Predicting
Mixture
Models
Scoring
Email
Candidates
Generating
Email
Structures
Filling
Slots
Generated Structural
Label Sequences
&lt;greeting&gt;
&lt;inform&gt;
Hi Peter
Today’s ...
Synthesized Emails
</figure>
<figureCaption confidence="0.999996">
Figure 1: The proposed framework of two-stage NLG component.
</figureCaption>
<bodyText confidence="0.999628555555556">
In the second stage, we build a content lan-
guage model for each structural element and then
stochastically generate sentences using the se-
quence generated in the first stage. To ensure that
required slot-value pairs occur in the text, candi-
dates emails are filtered to retain only those texts
that contain the desired content slots. These slots
are then filled to produce the final result. Section 5
explains the process.
</bodyText>
<sectionHeader confidence="0.960701" genericHeader="method">
3 Training Data Preprocessing
</sectionHeader>
<bodyText confidence="0.9998445">
To model sender style and topic structure, we an-
notate the data with defined structural labels in
Section 3.1, and data with slots to model text con-
tent of language in Section 3.2.
</bodyText>
<subsectionHeader confidence="0.999444">
3.1 Structural Label Annotation
</subsectionHeader>
<bodyText confidence="0.899719">
Based on examination of the corpus, we defined
10 email structure elements:
</bodyText>
<listItem confidence="0.999338761904762">
1. greeting: a friendly expression or respectful
phrase, typically at the start of an email.
2. inform: to give or impart knowledge of a fact
or circumstance.
3. request: the act of asking for something to be
given or done, especially as a favor or cour-
tesy.
4. suggestion: to mention or introduce (an idea,
proposition, plan, etc.) for consideration or
possible action.
5. question: an interrogative sentence in an
form, requesting information in reply.
6. answer: a reply or response to a question, etc.
7. regard: to have or show respect or concern
for, usually at the end of an email.
8. acknowledgement: to show or express appre-
ciation or gratitude.
9. sorry: express regret, compunction, sympa-
thy, pity, etc.
10. signature: a sender’s name usually at the end
of the email.
</listItem>
<bodyText confidence="0.6291486">
We perform sentence segmentation using punc-
tuation and line-breaks and then manually tag each
sentence with a structure label. We exclude the
header of emails for labeling. Figure 2 shows an
example email with structural labels.
</bodyText>
<figureCaption confidence="0.996544">
Figure 2: The email with structural labels.
</figureCaption>
<subsectionHeader confidence="0.997333">
3.2 Slot Annotation
</subsectionHeader>
<bodyText confidence="0.999965833333333">
The input to NLG may contain the information
that needs to be included in the synthesized emails.
Tokens in the corpus text corresponding to slots
are replaced by slot (or concept) tokens prior to
building content language models. Slots are clas-
sified into general class and topic class below.
</bodyText>
<subsectionHeader confidence="0.485073">
3.2.1 General Class
</subsectionHeader>
<bodyText confidence="0.999686666666667">
We use existing named entity recognition (NER)
tools for identifying general classes. Finkel et al.
(2005) used CRF to label sequences of words in
text that are names of things, such as person, or-
ganization, etc. There are three models trained on
different data, which are a 4-class model trained
for CoNLL1, a 7-class model trained for MUC,
and a 3-class model trained on both data sets for
the intersection of those class sets below.
</bodyText>
<listItem confidence="0.928937333333333">
• 4-class: location, person, organization, misc
• 7-class: location, person, organization, time,
money, percent, date
</listItem>
<bodyText confidence="0.99953">
Considering that 3-class model performs higher
accuracy and 7-class model provides better cover-
age, we take the union of outputs produced by 3-
class and 7-class models and use the labels output
by 3-class model if the two models give different
results, since the 3-class model is trained on both
data sets and provides better accuracy.
</bodyText>
<footnote confidence="0.980018">
1http://www.cnts.ua.ac.be/conll2003/
ner/
</footnote>
<table confidence="0.932044375">
suggestion
content
signature
inform
header
request
Shukaly resigned and left.
But I assume the invitation will be extended to all of their groups so that
whoever they want can attend.
I would actually prefer that the presentation is actually circulated to the
groups on Friday rather than presented as we will wait forever on
getting an offsite together.
How about circulating the presentation and then letting them refer all
questions to Rahil - see how much interest you get.
One on ones are much better and I think this is how Rahil should
proceed.
We need to get in front of customers in the next couple of weeks.
Let&apos;s aim to get a least three customers this quarter.
From: Kitchen, Louise
Sent: Thursday, April 05, 2001 11:15 AM
To: Beck, Sally
Cc: Piper, Greg; Jafry, Rahil
Subject: Re: Costs
Louise
</table>
<page confidence="0.997499">
153
</page>
<subsectionHeader confidence="0.520335">
3.2.2 Topic Class
</subsectionHeader>
<bodyText confidence="0.99997925">
Many named entities cannot be recognized by a
general NER, because they are topic-specific in-
formation. Accordingly we define additional enti-
ties that are part of the email domain.
</bodyText>
<sectionHeader confidence="0.720822" genericHeader="method">
4 Modeling Sender Style and Topic
Structure for Email Organization
</sectionHeader>
<bodyText confidence="0.999764">
Given a target sender and topic focus specified in
system input, email structures can be generated by
predicted sender-topic-specific mixture models.
</bodyText>
<subsectionHeader confidence="0.999739">
4.1 Building Structure Language Models
</subsectionHeader>
<bodyText confidence="0.991852125">
Based on the annotation of structural labels, each
email can be expressed as a structural label se-
quence. Then we can train a sender-specific and
a topic-specific structure model using the emails
from each sender and the emails related to each
topic respectively. Here the structure models are
n-gram models with Good-Turing smoothing (n =
3) (Good, 1953).
</bodyText>
<subsectionHeader confidence="0.998646">
4.2 Predicting Mixture Models
</subsectionHeader>
<bodyText confidence="0.996298">
Using sender-specific and topic-specific structure
models, we predict sender-topic-specific mixture
models by interpolation:
</bodyText>
<equation confidence="0.999241">
Pi,j(l) = αPis(l) + (1 − α)Pjt (l), (1)
</equation>
<bodyText confidence="0.9999231">
where Pi,j(l) is the estimated probability that the
structural label l occurs from the sender i and for
the topic j, Pis(l) is the probability of the struc-
tural label l from the sender i (regardless of top-
ics), Pjt (l) is the probability of the structural label
l related to the topic j (regardless of senders), and
α is the interpolation weight, balancing between
sender style and topic focus. Figure 3 illustrates
the mixture models combined by sender-specific
and topic-specific models.
</bodyText>
<subsectionHeader confidence="0.999067">
4.3 Generating Email Structure
</subsectionHeader>
<bodyText confidence="0.999978833333333">
We generate structural label sequences randomly
according to the distribution from sender-topic-
specific models. To generate the structural label
sequences from the sender i and related to the
topic j, the probability of the structural label lk
using n-gram language model is
</bodyText>
<equation confidence="0.996409">
Pi,j(lk) = Pi,j(lk  |lk−1, lk−2, ..., lk−(n−1)). (2)
</equation>
<bodyText confidence="0.9999896">
Since we use smoothed trigrams, we may gen-
erate unseen trigrams based on back-off methods,
resulting in some undesirable randomness. We
therefore exclude unreasonable emails that don’t
follow two simple rules.
</bodyText>
<listItem confidence="0.82446325">
1. The structural label “greeting” only occurs at
the beginning of the email.
2. The structural label “signature” only occurs
at the end of the email.
</listItem>
<sectionHeader confidence="0.953772" genericHeader="method">
5 Surface Realization
</sectionHeader>
<bodyText confidence="0.999738">
Our surface realizer has four elements: building
language models, generating text content, scoring
email candidates, and filling slots.
</bodyText>
<subsectionHeader confidence="0.996719">
5.1 Building Content Language Models
</subsectionHeader>
<bodyText confidence="0.999995210526316">
After replacing the tokens with slots, for each
structural label, we train an unsmoothed n-gram
language model using all sentences with that struc-
tural label. We make a simplifying assumption
that the usage of within-sentence language can be
treated as independent across senders; generating
the text content only considers the structural la-
bels. We use 5-gram to balance variability in gen-
erated sentences while minimizing nonsense sen-
tences.
Given a structural label, we use the content lan-
guage model probability directly to predict the
next word. The most likely sentence is W∗ =
arg max P(W  |l), where W is a word sequence
and l is a structural label. However, in order to
introduce more variation, we do not look for the
most likely sentence but generate each word ran-
domly according to the distribution similar to Sec-
tion 4.3 and illustrated below.
</bodyText>
<subsectionHeader confidence="0.999459">
5.2 Generating Text Content
</subsectionHeader>
<bodyText confidence="0.999990285714286">
The input to surface realization is the generated
structural label sequence. We use the correspond-
ing content language model trained for the given
structural label to generate word sequences ran-
domly according to the distribution from the lan-
guage model. The probability of a word wi using
the n-gram language model is
</bodyText>
<equation confidence="0.996352">
P(wi) = P(wi  |wi−1, wi−2, ..., wi−(n−1), l),
(3)
</equation>
<bodyText confidence="0.999768333333333">
where l is the input structural label. Since we build
separate models for different structural labels, (3)
can be written as
</bodyText>
<equation confidence="0.997013">
P(wi) = P(wi  |wi−1, wi−2, ..., wi−(n−1)) (4)
</equation>
<bodyText confidence="0.9990955">
using the model for l.
Using unsmoothed 5-grams will not generate
any unseen 5-grams (or smaller n-grams at the be-
ginning and end of a sentence). This precludes
generation of nonsense sentences within the 5-
word window. Given a generated structural label
sequence, we can generate multiple sentences to
create a synthesized email.
</bodyText>
<figure confidence="0.963517333333333">
sender-specific model
topic-specific model
mixture model
</figure>
<figureCaption confidence="0.999538">
Figure 3: The visualization of the mixture model.
</figureCaption>
<page confidence="0.999112">
154
</page>
<subsectionHeader confidence="0.999433">
5.3 Scoring Email Candidates
</subsectionHeader>
<bodyText confidence="0.999912">
The input to NLG contains the required informa-
tion that needs to be in the output email, as de-
scribed in Section 3.2. For each synthesized email,
we penalize it if the email 1) contains slots for
which there is no provided valid value, or 2) does
not have the required slots.
The content generation engine stochastically
generates an email candidate and scores it. If the
email has a zero penalty it is passed on.
</bodyText>
<subsectionHeader confidence="0.999462">
5.4 Filling Slots
</subsectionHeader>
<bodyText confidence="0.99993025">
The last step is to fill slots with the appropriate
values. For example, the sentence “Tomorrow’s
[meeting] is at [location].” could become “Tomor-
row’s speech seminar is at Gates building.”
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99365">
6.1 Setup
</subsectionHeader>
<bodyText confidence="0.9997793">
The corpus used for our experiments is the Enron
Email Dataset2, which contains a total of about
0.5M messages. We selected the data related to
daily business for our use, including data from
about 150 users. We randomly picked 3 senders,
ones who wrote many emails, and defined addi-
tional 3 topic classes (meeting, discussion, issue)
as topic-specific entities for the task. Each sender-
specific model (across topics) or topic-specific
model (across senders) is trained on 30 emails.
</bodyText>
<subsectionHeader confidence="0.999827">
6.2 Evaluation of Sender Style Modeling
</subsectionHeader>
<bodyText confidence="0.9999795">
To evaluate the performance of sender style, 7 sub-
jects were given 5 real emails from each sender
and then 9 synthesized emails. They were asked
to rate each synthesized email for each sender on
a scale of 1 (highly confident that the email is not
from the sender) to 5 (highly confident that the
email is from that sender).
With α = 0.75 in (1) for predicting mix-
ture models (higher weight for sender-specific
model), average normalized scores the corre-
sponding senders receives account for 45%; this
is above chance (which would be 33%). This sug-
gests that sender style can be noticed by subjects,
although the effect is weak, and we are in the pro-
cess of designing a larger evaluation. In a follow-
up questionnaire, subjects indicated that their rat-
ings were based on greeting usage, politeness, the
length of email and other characteristics.
</bodyText>
<subsectionHeader confidence="0.999751">
6.3 Evaluation of Surface Realization
</subsectionHeader>
<bodyText confidence="0.997800428571429">
We conduct a comparative evaluation of two dif-
ferent generation algorithms, template-based gen-
eration and stochastic generation, on the same
email structures. The average number of sen-
tences in synthesized emails is 3.8, because our
data is about daily business and has relatively short
emails. Given a structural label, template-based
</bodyText>
<footnote confidence="0.830996">
2https://www.cs.cmu.edu/˜enron/
</footnote>
<bodyText confidence="0.999004807692308">
generation consisted of randomly selecting an in-
tact whole sentence with the target structural label.
This could be termed sentence-level NLG, while
stochastic generation is word-level NLG.
We presented 30 pairs of (sentence-, word-)
synthesized emails, and 7 subjects were asked to
compare the overall coherence of an email, its sen-
tence fluency and naturalness; then select their
preference. Table 1 shows subjects’ preference
according to the rating criteria. The word-based
stochastic generation outperforms or performs as
well as the template-based algorithm for all cri-
teria, where a t-test on an email as a random vari-
able shows no significant improvement but p-value
is close to 0.05 (p = 0.051). Subjects indicated
that emails from word-based stochastic genera-
tion are more natural; word-level generation is less
likely to produce an unusual sentences from the
real data; word-level generation produces more
conventional sentences. Some subjects noted that
neither email seemed human-written, perhaps an
artifact of our experimental design. Nevertheless,
we believe that this stochastic approach would re-
quire less effort compared to most rule-based or
template-based systems in terms of knowledge en-
gineering.
</bodyText>
<table confidence="0.999232166666667">
Template Stochastic No Diff.
Coherence 36.19 38.57 25.24
Fluency 28.10 40.48 31.43
Naturalness 35.71 45.71 18.57
Preference 36.67 42.86 20.48
Overall 34.17 41.90 23.93
</table>
<tableCaption confidence="0.999758">
Table 1: Generation algorithm comparison (%).
</tableCaption>
<sectionHeader confidence="0.996077" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99998675">
This paper presents a two-stage stochastic NLG
for synthesizing emails: first a structure is gener-
ated, and then text is generated for each structure
element, where sender style and topic structure
can be modeled. Subjects appear to notice sender
style and can also tell the difference between tem-
plates using original sentences and stochastically
generated sentences. We believe that this tech-
nique can be used to create realistic emails and that
email generation could be carried out using mix-
tures containing additional models based on other
characteristics. The current study shows that email
can be synthesized using a small corpus of labeled
data; however these models could be used to boot-
strap the labeling of a larger corpus which in turn
could be used to create more robust models.
</bodyText>
<sectionHeader confidence="0.999334" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.994966">
The authors wish to thank Brian Lindauer and Kurt
Wallnau from the Software Engineering Institute
of Carnegie Mellon University for their guidance,
advice, and help.
</bodyText>
<page confidence="0.99876">
155
</page>
<sectionHeader confidence="0.998343" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999870263157895">
Regina Barzilay and Mirella Lapata. 2008. Modeling lo-
cal coherence: An entity-based approach. Computational
Linguistics, 34(1):1–34.
Regina Barzilay and Lillian Lee. 2004. Catching the drift:
Probabilistic content models, with applications to genera-
tion and summarization. In HLT-NAACL, pages 113–120.
Anja Belz. 2005. Corpus-driven generation of weather fore-
casts. In Proc. 3rd Corpus Linguistics Conference.
Jenny Rose Finkel, Trond Grenager, and Christopher Man-
ning. 2005. Incorporating non-local information into in-
formation extraction systems by gibbs sampling. In Proc.
of ACL, pages 363–370.
Alastair J Gill, Carsten Brockmann, and Jon Oberlander.
2012. Perceptions of alignment and personality in gener-
ated dialogue. In Proceedings of the Seventh International
Natural Language Generation Conference, pages 40–48.
Association for Computational Linguistics.
Irving J Good. 1953. The population frequencies of species
and the estimation of population parameters. Biometrika,
40(3-4):237–264.
Shlomo Hershkop, Salvatore J Stolfo, Angelos D Keromytis,
and Hugh Thompson. 2011. Anomaly detection at multi-
ple scales (ADAMS).
Andrew Lampert, Robert Dale, and C´ecile Paris. 2009. Seg-
menting email message text into zones. In Proceedings
of the 2009 Conference on Empirical Methods in Natural
Language Processing, volume 2, pages 919–928. Associ-
ation for Computational Linguistics.
Alice H Oh and Alexander I Rudnicky. 2002. Stochastic nat-
ural language generation for spoken dialog systems. Com-
puter Speech &amp; Language, 16(3):387–407.
Christina Sauper and Regina Barzilay. 2009. Automati-
cally generating wikipedia articles: A structure-aware ap-
proach. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing of the
AFNLP: Volume 1-Volume 1, pages 208–216. Association
for Computational Linguistics.
</reference>
<page confidence="0.998786">
156
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.464632">
<title confidence="0.999903">Two-Stage Stochastic Natural Language Generation for Email</title>
<author confidence="0.7843595">by Modeling Sender Style</author>
<author confidence="0.7843595">Topic Structure Yun-Nung Chen</author>
<author confidence="0.7843595">I Alexander</author>
<affiliation confidence="0.999558">School of Computer Science, Carnegie Mellon</affiliation>
<address confidence="0.999622">5000 Forbes Ave., Pittsburgh, PA 15213-3891,</address>
<abstract confidence="0.989590277777778">This paper describes a two-stage process for stochastic generation of email, in which the first stage structures the emails according to sender style and topic structure (high-level generation), and the second stage synthesizes text content based on the particulars of an email element and the goals of a given communication (surface-level realization). Synthesized emails were rated in a preliminary experiment. The results indicate that sender style can be detected. In addition we found that stochastic generation performs better if applied at the word level than at an original-sentence level (“template-based”) in terms of email coherence, sentence fluency, naturalness, and preference.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="3146" citStr="Barzilay and Lapata, 2008" startWordPosition="477" endWordPosition="481"> which reflect senders’ style and are more spontaneous. Lampert et al. (2009) segmented email messages into zones, including sender zones, quoted conversation zones, and boilerplate zones. This paper only models the text in the sender zone, new content from the current sender. In the present work, we investigate the use of stochastic techniques for generation of a different class of communications and whether global structures can be convincingly created in the email domain. A lot of NLG systems are applied in dialogue systems, some of which focus on topic modeling (Sauper and Barzilay, 2009; Barzilay and Lapata, 2008; Barzilay and Lee, 2004), proposing algorithms to balance local fit of information and global coherence. However, they seldom consider to model the speaker’s characteristics. Gill et al. (2012) considered sentiment such as openness and neuroticism to specify characters for dialogue generation. In stead of modeling authors’ attitudes, this paper proposes the first approach of synthesizing emails by modeling their writing patterns. Specifically we investigate whether stochastic techniques can be used to acceptably model longer texts and individual speaker characteristics in the emails, both of </context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computational Linguistics, 34(1):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization.</title>
<date>2004</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="3171" citStr="Barzilay and Lee, 2004" startWordPosition="482" endWordPosition="485">le and are more spontaneous. Lampert et al. (2009) segmented email messages into zones, including sender zones, quoted conversation zones, and boilerplate zones. This paper only models the text in the sender zone, new content from the current sender. In the present work, we investigate the use of stochastic techniques for generation of a different class of communications and whether global structures can be convincingly created in the email domain. A lot of NLG systems are applied in dialogue systems, some of which focus on topic modeling (Sauper and Barzilay, 2009; Barzilay and Lapata, 2008; Barzilay and Lee, 2004), proposing algorithms to balance local fit of information and global coherence. However, they seldom consider to model the speaker’s characteristics. Gill et al. (2012) considered sentiment such as openness and neuroticism to specify characters for dialogue generation. In stead of modeling authors’ attitudes, this paper proposes the first approach of synthesizing emails by modeling their writing patterns. Specifically we investigate whether stochastic techniques can be used to acceptably model longer texts and individual speaker characteristics in the emails, both of which may require higher </context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In HLT-NAACL, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
</authors>
<title>Corpus-driven generation of weather forecasts.</title>
<date>2005</date>
<booktitle>In Proc. 3rd Corpus Linguistics Conference.</booktitle>
<contexts>
<context position="2257" citStr="Belz (2005)" startWordPosition="339" endWordPosition="340">hes to natural language generation (NLG), one focuses on generating text using templates or rules (linguistic) methods, the another uses corpus-based statistical techniques. Oh and Rudnicky (2002) showed that stochastic generation benefits from two factors: 1) it takes advantage of the practical language of a domain expert instead of the developer and 2) it restates the problem in terms of classification and labeling, where expertise is not required for developing a rule-based generation system. They found that naive listeners found such utterances as acceptable as human-generated utterances. Belz (2005) also proposed a probabilistic NLG approach to make systems more robust and components more reusable, reducing manual corpus analysis. However, most work usually focused on wellstructured documents such as news and Wikipedia, while email messages differ from them, which reflect senders’ style and are more spontaneous. Lampert et al. (2009) segmented email messages into zones, including sender zones, quoted conversation zones, and boilerplate zones. This paper only models the text in the sender zone, new content from the current sender. In the present work, we investigate the use of stochastic </context>
</contexts>
<marker>Belz, 2005</marker>
<rawString>Anja Belz. 2005. Corpus-driven generation of weather forecasts. In Proc. 3rd Corpus Linguistics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="7779" citStr="Finkel et al. (2005)" startWordPosition="1192" endWordPosition="1195"> sentence with a structure label. We exclude the header of emails for labeling. Figure 2 shows an example email with structural labels. Figure 2: The email with structural labels. 3.2 Slot Annotation The input to NLG may contain the information that needs to be included in the synthesized emails. Tokens in the corpus text corresponding to slots are replaced by slot (or concept) tokens prior to building content language models. Slots are classified into general class and topic class below. 3.2.1 General Class We use existing named entity recognition (NER) tools for identifying general classes. Finkel et al. (2005) used CRF to label sequences of words in text that are names of things, such as person, organization, etc. There are three models trained on different data, which are a 4-class model trained for CoNLL1, a 7-class model trained for MUC, and a 3-class model trained on both data sets for the intersection of those class sets below. • 4-class: location, person, organization, misc • 7-class: location, person, organization, time, money, percent, date Considering that 3-class model performs higher accuracy and 7-class model provides better coverage, we take the union of outputs produced by 3- class an</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proc. of ACL, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alastair J Gill</author>
<author>Carsten Brockmann</author>
<author>Jon Oberlander</author>
</authors>
<title>Perceptions of alignment and personality in generated dialogue.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh International Natural Language Generation Conference,</booktitle>
<pages>40--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3340" citStr="Gill et al. (2012)" startWordPosition="508" endWordPosition="511">nly models the text in the sender zone, new content from the current sender. In the present work, we investigate the use of stochastic techniques for generation of a different class of communications and whether global structures can be convincingly created in the email domain. A lot of NLG systems are applied in dialogue systems, some of which focus on topic modeling (Sauper and Barzilay, 2009; Barzilay and Lapata, 2008; Barzilay and Lee, 2004), proposing algorithms to balance local fit of information and global coherence. However, they seldom consider to model the speaker’s characteristics. Gill et al. (2012) considered sentiment such as openness and neuroticism to specify characters for dialogue generation. In stead of modeling authors’ attitudes, this paper proposes the first approach of synthesizing emails by modeling their writing patterns. Specifically we investigate whether stochastic techniques can be used to acceptably model longer texts and individual speaker characteristics in the emails, both of which may require higher cohesion to be acceptable. 2 Overview of Framework Our proposed NLG approach has three steps: preprocessing training data, modeling sender style and topic structure for </context>
</contexts>
<marker>Gill, Brockmann, Oberlander, 2012</marker>
<rawString>Alastair J Gill, Carsten Brockmann, and Jon Oberlander. 2012. Perceptions of alignment and personality in generated dialogue. In Proceedings of the Seventh International Natural Language Generation Conference, pages 40–48. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irving J Good</author>
</authors>
<title>The population frequencies of species and the estimation of population parameters.</title>
<date>1953</date>
<journal>Biometrika,</journal>
<pages>40--3</pages>
<contexts>
<context position="10227" citStr="Good, 1953" startWordPosition="1593" endWordPosition="1594">4 Modeling Sender Style and Topic Structure for Email Organization Given a target sender and topic focus specified in system input, email structures can be generated by predicted sender-topic-specific mixture models. 4.1 Building Structure Language Models Based on the annotation of structural labels, each email can be expressed as a structural label sequence. Then we can train a sender-specific and a topic-specific structure model using the emails from each sender and the emails related to each topic respectively. Here the structure models are n-gram models with Good-Turing smoothing (n = 3) (Good, 1953). 4.2 Predicting Mixture Models Using sender-specific and topic-specific structure models, we predict sender-topic-specific mixture models by interpolation: Pi,j(l) = αPis(l) + (1 − α)Pjt (l), (1) where Pi,j(l) is the estimated probability that the structural label l occurs from the sender i and for the topic j, Pis(l) is the probability of the structural label l from the sender i (regardless of topics), Pjt (l) is the probability of the structural label l related to the topic j (regardless of senders), and α is the interpolation weight, balancing between sender style and topic focus. Figure 3</context>
</contexts>
<marker>Good, 1953</marker>
<rawString>Irving J Good. 1953. The population frequencies of species and the estimation of population parameters. Biometrika, 40(3-4):237–264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shlomo Hershkop</author>
<author>Salvatore J Stolfo</author>
<author>Angelos D Keromytis</author>
<author>Hugh Thompson</author>
</authors>
<title>Anomaly detection at multiple scales (ADAMS).</title>
<date>2011</date>
<contexts>
<context position="1623" citStr="Hershkop et al., 2011" startWordPosition="243" endWordPosition="246">is paper focuses on generating language for the email domain, with the goal of producing mails that reflect sender style and the intent of the communication. Such a process might be used for the generation of common messages (for example a request for a meeting without direct intervention from the sender). It can also be used in situations where naturalistic email is needed for other applications. For instance, our email generator was developed to provide emails to be used as part of synthetic evidence of insider threats for purposes of training, prototyping, and evaluating anomaly detectors (Hershkop et al., 2011). There are two approaches to natural language generation (NLG), one focuses on generating text using templates or rules (linguistic) methods, the another uses corpus-based statistical techniques. Oh and Rudnicky (2002) showed that stochastic generation benefits from two factors: 1) it takes advantage of the practical language of a domain expert instead of the developer and 2) it restates the problem in terms of classification and labeling, where expertise is not required for developing a rule-based generation system. They found that naive listeners found such utterances as acceptable as human</context>
</contexts>
<marker>Hershkop, Stolfo, Keromytis, Thompson, 2011</marker>
<rawString>Shlomo Hershkop, Salvatore J Stolfo, Angelos D Keromytis, and Hugh Thompson. 2011. Anomaly detection at multiple scales (ADAMS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Lampert</author>
<author>Robert Dale</author>
<author>C´ecile Paris</author>
</authors>
<title>Segmenting email message text into zones.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<volume>2</volume>
<pages>919--928</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2598" citStr="Lampert et al. (2009)" startWordPosition="388" endWordPosition="391">d of the developer and 2) it restates the problem in terms of classification and labeling, where expertise is not required for developing a rule-based generation system. They found that naive listeners found such utterances as acceptable as human-generated utterances. Belz (2005) also proposed a probabilistic NLG approach to make systems more robust and components more reusable, reducing manual corpus analysis. However, most work usually focused on wellstructured documents such as news and Wikipedia, while email messages differ from them, which reflect senders’ style and are more spontaneous. Lampert et al. (2009) segmented email messages into zones, including sender zones, quoted conversation zones, and boilerplate zones. This paper only models the text in the sender zone, new content from the current sender. In the present work, we investigate the use of stochastic techniques for generation of a different class of communications and whether global structures can be convincingly created in the email domain. A lot of NLG systems are applied in dialogue systems, some of which focus on topic modeling (Sauper and Barzilay, 2009; Barzilay and Lapata, 2008; Barzilay and Lee, 2004), proposing algorithms to b</context>
</contexts>
<marker>Lampert, Dale, Paris, 2009</marker>
<rawString>Andrew Lampert, Robert Dale, and C´ecile Paris. 2009. Segmenting email message text into zones. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, volume 2, pages 919–928. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alice H Oh</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Stochastic natural language generation for spoken dialog systems.</title>
<date>2002</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>16</volume>
<issue>3</issue>
<contexts>
<context position="1842" citStr="Oh and Rudnicky (2002)" startWordPosition="273" endWordPosition="276">sages (for example a request for a meeting without direct intervention from the sender). It can also be used in situations where naturalistic email is needed for other applications. For instance, our email generator was developed to provide emails to be used as part of synthetic evidence of insider threats for purposes of training, prototyping, and evaluating anomaly detectors (Hershkop et al., 2011). There are two approaches to natural language generation (NLG), one focuses on generating text using templates or rules (linguistic) methods, the another uses corpus-based statistical techniques. Oh and Rudnicky (2002) showed that stochastic generation benefits from two factors: 1) it takes advantage of the practical language of a domain expert instead of the developer and 2) it restates the problem in terms of classification and labeling, where expertise is not required for developing a rule-based generation system. They found that naive listeners found such utterances as acceptable as human-generated utterances. Belz (2005) also proposed a probabilistic NLG approach to make systems more robust and components more reusable, reducing manual corpus analysis. However, most work usually focused on wellstructur</context>
</contexts>
<marker>Oh, Rudnicky, 2002</marker>
<rawString>Alice H Oh and Alexander I Rudnicky. 2002. Stochastic natural language generation for spoken dialog systems. Computer Speech &amp; Language, 16(3):387–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sauper</author>
<author>Regina Barzilay</author>
</authors>
<title>Automatically generating wikipedia articles: A structure-aware approach.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>1</volume>
<pages>208--216</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3119" citStr="Sauper and Barzilay, 2009" startWordPosition="473" endWordPosition="476"> messages differ from them, which reflect senders’ style and are more spontaneous. Lampert et al. (2009) segmented email messages into zones, including sender zones, quoted conversation zones, and boilerplate zones. This paper only models the text in the sender zone, new content from the current sender. In the present work, we investigate the use of stochastic techniques for generation of a different class of communications and whether global structures can be convincingly created in the email domain. A lot of NLG systems are applied in dialogue systems, some of which focus on topic modeling (Sauper and Barzilay, 2009; Barzilay and Lapata, 2008; Barzilay and Lee, 2004), proposing algorithms to balance local fit of information and global coherence. However, they seldom consider to model the speaker’s characteristics. Gill et al. (2012) considered sentiment such as openness and neuroticism to specify characters for dialogue generation. In stead of modeling authors’ attitudes, this paper proposes the first approach of synthesizing emails by modeling their writing patterns. Specifically we investigate whether stochastic techniques can be used to acceptably model longer texts and individual speaker characterist</context>
</contexts>
<marker>Sauper, Barzilay, 2009</marker>
<rawString>Christina Sauper and Regina Barzilay. 2009. Automatically generating wikipedia articles: A structure-aware approach. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1, pages 208–216. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>