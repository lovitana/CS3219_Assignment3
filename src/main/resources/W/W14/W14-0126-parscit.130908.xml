<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015872">
<title confidence="0.986843">
Do not do processing, when you can look up: Towards a Discrimina-
tion Net for WSD
</title>
<author confidence="0.960973">
Diptesh Kanojia
</author>
<affiliation confidence="0.909034">
IIT Bombay
</affiliation>
<email confidence="0.989834">
dipteshkanojia@gmail.com
</email>
<author confidence="0.964406">
Raj Dabre
</author>
<affiliation confidence="0.904272">
IIT Bombay
</affiliation>
<email confidence="0.989089">
prajdabre@gmail.com
</email>
<author confidence="0.884428">
Pushpak Bhattacharyya
</author>
<affiliation confidence="0.841064">
IIT Bombay
</affiliation>
<email confidence="0.984137">
pb@cse.iitb.ac.in
</email>
<author confidence="0.941044">
Siddhartha Gunti
</author>
<affiliation confidence="0.885964">
IIT Bombay
</affiliation>
<email confidence="0.983834">
siddhartha.gunti191@gmail.com
</email>
<author confidence="0.954882">
Manish Shrivastava
</author>
<affiliation confidence="0.930162">
IIT Bombay
</affiliation>
<email confidence="0.979608">
mani.shrivastava@gmail.com
</email>
<sectionHeader confidence="0.995354" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999639210526316">
The task of Word Sense Disambiguation
(WSD) incorporates in its definition the role of
‘context’. We present our work on the devel-
opment of a tool which allows for automatic
acquisition and ranking of ‘context clues’ for
WSD. These clue words are extracted from the
contexts of words appearing in a large mono-
lingual corpus. These mined collection of con-
textual clues form a discrimination net in the
sense that for targeted WSD, navigation of the
net leads to the correct sense of a word given
its context. Utilizing this resource we intend
to develop efficient and light weight WSD
based on look up and navigation of memory-
resident knowledge base, thereby avoiding
heavy computation which often prevents in-
corporation of any serious WSD in MT and
search. The need for large quantities of sense
marked data too can be reduced.
</bodyText>
<sectionHeader confidence="0.999069" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998993447368421">
Word Sense Disambiguation (WSD) is formally
defined as the task of computationally identify-
ing senses of a word in a context. Chatterjee et
al. (2011) showed that contextual evidence is the
predominant parameter for human (and hence
machine) sense disambiguation process.
Joshi et al. (2013) had conducted experiments
on eye tracking for sense disambiguation in
which they studied the cognitive aspects of hu-
man sense disambiguation. They demonstrated
that annotators do not focus on sentential struc-
ture but look for specific words that help identify
the domain of the word and narrow down the
number of senses.
Kanojia et al. (2012) had developed a basic
WordNet navigation and clue selection tool,
“Sense Discrimination Tool”, which we have
studied and improved upon. We realized that this
tool can be improved to include many useful
functionalities, the most important being auto-
mated clue word acquisition using word context
(see section 2) and clue ranking based on the rel-
ative importance of a clue word. Thus, to utilize
context efficiently we have developed a tool
which can help mark clues for each word sense
along with providing weights indicating their
importance. It can also automatically generate
clue word suggestions from large monolingual
corpus; leading to the development of a new re-
source for context based WSD. This tool will
later evolve into a memory resident knowledge
base whose look up and navigation can perform
high quality, light weight WSD. This would
avoid the need for sense marked data which it is
expensive to create. Such a static WSD system
will essentially amount to look up and navigation
to discriminate amongst word senses, thereby
avoiding expensive computation.
</bodyText>
<sectionHeader confidence="0.953145" genericHeader="method">
2 Clue Marker Tool1
</sectionHeader>
<bodyText confidence="0.998997571428571">
“Sense Discrimination Tool” developed by Ka-
nojia et al. (2012) provided simple functionality
of allowing lexicographers to traverse WordNet
senses and annotate them with clues which were
added manually during this process.
The Clue Marker Tool which we present here
has embedded within it a number of functionali-
</bodyText>
<footnote confidence="0.9383415">
1http://www.cfilt.iitb.ac.in/~diptesh/admin/l
ogin.php
</footnote>
<bodyText confidence="0.999316666666667">
ties which transcend beyond mere marking
words with clues. It is language independent and
we plan to expand it to many other languages
later. For now we describe our work on Hindi.
Refer to snapshots attached for each subsection.
The tool allows for the following actions:
</bodyText>
<subsectionHeader confidence="0.992951">
2.1 Centralized User Management
</subsectionHeader>
<bodyText confidence="0.99992475">
In order to track what work was done by which
lexicographer we created a registration/login
mechanism (Snapshot 1). This ensures that no
one can tamper with the data and also determines
how much work was done by a particular person.
After the first registration the request is sent to
the admin who can regulate the tool usage by the
person.
</bodyText>
<subsectionHeader confidence="0.96738">
2.2 Phonetic Typing and Devanagari Key-
board
</subsectionHeader>
<bodyText confidence="0.9998978">
We integrated the Google Transliterate API into
our tool which simplifies the task of data entry.
For people who find the phonetic typing difficult
we have also incorporated a visual Devanagari
keyboard.
</bodyText>
<subsectionHeader confidence="0.999097">
2.3 WordIet Synsets Iavigation
</subsectionHeader>
<bodyText confidence="0.999869230769231">
Wordnets have emerged as crucial resources for
Natural Language Processing (NLP). They are
lexical structures composed of synsets and se-
mantic relations (Fellbaum, 1998). Our tool al-
lows one to navigate through the complete Hindi
WordNet (Narayan et al., 2002). One can pro-
ceed in a sequential manner by viewing previous
or next synsets. If one wishes to view any arbi-
trary synset they can just type its ‘id’ in a search
box and get redirected to it. One can also search
for a word and the tool will display all the
synsets that contain that word and the user can
select any one.
</bodyText>
<subsectionHeader confidence="0.998309">
2.4 Add Clues
</subsectionHeader>
<bodyText confidence="0.999898818181818">
Synset words, Gloss and Example are possible
clue sources. We have provided a mechanism so
that if a user selects any text on the page, it can
be added to the clues box with a “add”/“add to
clues” button (Snapshot 2). After the lexicogra-
pher is sure, she can “submit” the clues to make
sure they are finally added to the database. Add-
ing clues only from synset words, gloss or exam-
ple can be quite restrictive and thus we incorpo-
rated a corpus search mechanism known as the
concordancer search.
</bodyText>
<subsectionHeader confidence="0.972073">
2.5 Concordancer Search
</subsectionHeader>
<bodyText confidence="0.9997741875">
The concordancer is a tool in which, given a cor-
pus and any word to be searched, it returns a set
of sentences which contain the word (Snapshot
3). We provided mechanisms to control the num-
ber of sentences to be displayed for lexicogra-
pher’s convenience. Any word from the sentenc-
es returned by the concordancer search results
can also be added to the clue word list by the
“add to clues” button. The corpus we used, ini-
tially, consisted of around 0.22 million sentences
from tourism, health and BBC news corpus2. We
then considered incorporating 0.45 million lines
of Wikipedia corpus and 0.97 million lines of
crawled news data. Thus we collated a total of
approximately 1.4 million lines of monolingual
corpus for Hindi.
</bodyText>
<subsectionHeader confidence="0.933354">
2.6 Generate Clues automatically
</subsectionHeader>
<bodyText confidence="0.999916666666667">
Even with the above concordancer, the lexicog-
raphers still have to go through a large number of
sentences to decide on the clue words. The pri-
mary feature of this tool is being able to generate
clues automatically from concordancer sentences
(Snapshot 4). To alleviate this problem we de-
veloped a mechanism to automatically generate
candidate clue words. The lexicographer can
click on the “search for possible clues” button to
get a set of words which the tool proposes to be
prominent clues. The procedure to generate the
clue words is given below:
</bodyText>
<listItem confidence="0.9646270625">
1. Select N sentences (N=10 for the results
reported here) from the concordancer
search results by using the first word of
the synset as a search term.
2. Run the Hindi part of speech CRF tagger3
on these sentences.
3. Select the nouns and verbs from the
tagged words.
4. Remove stop words, noise and duplicates.
We select nouns and verbs because the lexicog-
raphers determined that they are the best candi-
dates for clues. These are, however, not ordered
by relative importance, which was the objective
of developing the tool. We thus made investiga-
tions on the association between the clue words
and the synset words leading to some interesting
</listItem>
<footnote confidence="0.978494666666667">
2 www.cfilt.iitb.ac.in/wsd/annotated_corpus/
3http://www.cfilt.iitb.ac.in/tools/POS_tagger
.zip
</footnote>
<table confidence="0.999859266666667">
S. No. Word Clues
अपराध अपराधी (aparddhi - criminal), दण्ड(daṇḍa - penalty), सजा(sajd - punishment),
(aparddha) हत्या(hatyd - killing), साधुजी(sddhuji - sage), चौंका(cauṅkd - surprised),
(crime) बंगले(bangle - bungalow), लौटा(lautd - return),घटनाक्रम(ghatndkrama – develop-
ment), सोकर(sokar - slept)
पुष्पपत आनंद(dnanda - joy), वनस्पति(vanaspati - flora), स्पर्श(sparśa - touch),
(puṣpita) ष्थिरता(sthiratd - stability), सखी(sakhī - girlfriend), सम्पकश (samparka - contact),
(flowering) श (śdnti – silence, peace), पवन(pavana - wind), समतववि (samanvita - incorpo-
rated)
अनाि अनाथों (andtho - orphans), अनाथालय(andthdlaya - orphanage), मां-बाप(maa-baap -
(andtha) parents), बताती(batdti - inform), मारती(mdrti – to hit), चलाना(caldnd – to operate),
(orphan) मैनेजर(mainējara - manager), असहाय(asahdya - helpless), खोकर(khokar - lose)
अपमान (apamdna) जनक(janak - originator), सहन(sahan – to endure), मरना(marnd – to die),
(insult, affront) समझ(samajh - understanding), कहे(kahe - said), भूखों(bhukho - hungry),
परीष्ित(parikshita - tested), सूचनाओां(sucanao - information), मुुँह(mun h - mouth)
</table>
<tableCaption confidence="0.999139">
Table 1: Clues after PMI ranking
</tableCaption>
<bodyText confidence="0.9716278">
p(target, clue word)
results and insights which are given in the next
section.
For each word in the list returned, we calcu-
lated a score and sorted the list based on this
score. The result is a reordered list of clues pre-
sented to the lexicographers who reject the
wrong ones. Since the best clues are at the top
the lexicographers found their task much simpler
than before.
</bodyText>
<sectionHeader confidence="0.998011" genericHeader="method">
3 Clue Words Ranking
</sectionHeader>
<bodyText confidence="0.99985125">
We considered a set of 80 synsets and studied
them to form an idea of the basis of ranking the
clue words. We used Hindi Synsets for our study.
For each synset:
</bodyText>
<listItem confidence="0.987613428571429">
1. Generate the set of possible/candidate
clue words by corpus searching, POS tag-
ging and filtering as described in section
2.6.
2. For each clue word generate scores
3. Sort list of scored clues in descending or-
der and consider top 10 clues.
</listItem>
<bodyText confidence="0.999820285714286">
Scoring techniques which include the co-
occurrence factor between two words seemed
intuitive since they would rate the clues statisti-
cally. We studied some prominent scoring mech-
anisms such as contingency table measure and
PMI given by Terra et al. (2003) amongst which
PMI fared better.
</bodyText>
<subsectionHeader confidence="0.998391">
3.1 Pointwise Mutual Information
</subsectionHeader>
<bodyText confidence="0.941507">
PMI, a concept from information theory, is in-
dicative of the degree of association between two
words, in this case: the current synset member
and the potential clue word. The formulae used
are:
(target, clue word) = lo g2 p (target) *p ( clue word)
</bodyText>
<figure confidence="0.9669735">
... (3.1)
#(number of sentences containing x and y)
... (3.2)
#(number of sentences containing x )
... (3.3)
For words that are independent, then PMI is 0.
</figure>
<subsectionHeader confidence="0.991358">
3.2 Results with PMI
</subsectionHeader>
<bodyText confidence="0.999955888888889">
We present in Table 1 above, four synsets for
which there were strong clues after PMI based
ranking. The clues in bold are relevant ones.
Over the complete set of 80 words studied, an
average of 5 relevant clue words occurred in the
top 10 after PMI ranking. This situation freed the
lexicographers from looking for clue words
manually, by reading sentences from the con-
cordancer search.
</bodyText>
<sectionHeader confidence="0.964988" genericHeader="method">
4 Synset reinforced clue ranking
</sectionHeader>
<bodyText confidence="0.999982416666667">
In PMI based ranking, we would only consider
the first word of a synset to retrieve clues which
led the tool to produce the same set of clues for
all synsets which had this word as the first word.
We solved this problem by reinforcing the clues
using other members of the given synset. We
also use a different metric for clue word selection
and ranking.
This modified clue acquisition mechanism, in-
stead of using just the first word of the synset,
uses the first three words of the synset. Using
more members of the same synset helps in high-
</bodyText>
<equation confidence="0.986513">
(x,y) = #(number of sentences)
(x) =
</equation>
<table confidence="0.974979038461539">
#(number of sentences)
S. No. Word senses Top overlapped clues
1. जन्मा काल(kaal - time), मृत्यु(mrityu - death), रूप(roop – form, shape), आज(aaj - today),
(janma) दुष्नया(duniya - world), युग(yuga - era)
(born)
जन्मा प्रयोगशाला(prayogshalaa - laboratory), कारण(kaaran - reason), अनुसांधान(anusandhaan -
(janma) research), अध्ययन(adhyyan - study), भाषा(bhashaa - language), तकक(tarka - argu-
(originate) ment)
2 आष्दवासी अभाव(abhaav - scarcity), कारण(kaaran - reason), प्रदेश(Pradesh - territory),
(aadivaasi) ष्शिा(shiksha - education), जनजाष्त(janjaati – tribe, folk), भाषाांतरण(bhashaantaran -
(tribe) translation), ष्ववाद(vivaada - debate), अवथिापन(avasthaapan – habitation, abode)
आष्दवासी जनसांख्या(janasankhya - population), राज्य(rajya - state), सीमाओां(seemaon - borders),
(aadivaasi) सांथकृष्त(sanskriti - culture), आकलनों(aakalanon - estimations)
(domicile)
यूरोपीय,यूरोपी सांघ(sangha - union), रूप(roop - form), देशों(deshon - countries), शष्ि(shakti - power),
(yuropiya, yuropi) ष्वश्व(vishwa - world)
(related to Europe)
यूरोपी,यूरोपीय भाषा(bhasha - language), लोगों(logon - people), पररवार(parivaar - family)
(yuropi , yuropiya)
(European citizen)
जल्दी काम(kaam - work), कारण(kaaran - reason), लोग(log - people), अष्भनय(abhinaya - act-
(jaldi) ing), ष्वषय(vishaya - topic), नुकसान(nuksaan - loss)
(rapidity)
जल्दी, सवेरे (early morning)र(der
(jaldi, savere) थनान(snaana - bath), सुबह(subaha - morning), ष्दन(din - day), दूध(doodh - milk),
- delay), व्रत(vrata – fast, fasting)
</table>
<tableCaption confidence="0.997562">
Table 2: Overlapped clues
</tableCaption>
<bodyText confidence="0.992652227272727">
lighting those clues which are more important for
a given synset.
As before, we retrieve the sets of candidate
clue words for each of the 3 synset words and
then perform further processing. Instead of just
top 10 clues we now consider as many as possi-
ble to ensure coverage. We find clue word over-
laps between the three different sets of clues ob-
tained. Those candidate clues which are present
in more than one set are obviously good indica-
tors of sense and are given a higher ranking. This
added metric counters polysemy, even when first
synset word is same for different senses, since
having clues which are generated from members
of the given synset would help greatly in disam-
biguating using the overlapping clues. Such clue
overlaps would be able to help us distinguish
between fine grained word senses and eliminate
the unrelated sense, thus improving our accuracy.
Table 2 presents such cases where clue overlaps
are able to distinguish specifically between the
different senses for the same word.
</bodyText>
<sectionHeader confidence="0.99845" genericHeader="method">
5 Error Analysis
</sectionHeader>
<bodyText confidence="0.999849">
For every wrong clue generated we studied the
sentences from the concordancer which lead to
its coming up. We believe that these wrong clues
appear due to the following reasons:
</bodyText>
<subsubsectionHeader confidence="0.689788">
5.1.1 Chance co-occurrence
</subsubsectionHeader>
<bodyText confidence="0.99993975">
Consider for अनाथ (anātha) (orphan) the clue
word मैनेजर (manager). Here अनाथ mostly oc-
curred with अनाथालय (orphanage) (a strong clue)
which has an association with मैनेजर; but मैनेजर
can occur with any organization like banks,
companies and so on. Similarly, Proper nouns
can also occur by chance without giving any in-
formation about the senses.
</bodyText>
<subsectionHeader confidence="0.928584">
5.1.2 Lack of Context
</subsectionHeader>
<bodyText confidence="0.999937">
Retrieval of relevant clue words is greatly affect-
ed by the sentences that are chosen to get the
context. Currently, we are using 10 sentences
from the concordancer output to get a list of po-
tential clues. Using more sentences can help in
some cases by providing more relevant clues. We
have refrained from increasing this number to
avoid runtime computation time. We expect to
reduce pre-processing time to enable us to in-
clude more sentences.
</bodyText>
<subsectionHeader confidence="0.779147">
5.1.3 Absence of word in corpus
</subsectionHeader>
<bodyText confidence="0.999909222222222">
The tool cannot provide any clues if the word is
not present in the monolingual corpus. This can
happen for two reasons: if the word is rare or if
the word is not matched by the concordancer due
to corpus tokenization errors. We realized that
1.4 million domain specific sentences can be re-
strictive. We are currently in the process of col-
lecting more, clean and good quality, corpus
from the web.
</bodyText>
<sectionHeader confidence="0.995428" genericHeader="method">
6 Discrimination Net
</sectionHeader>
<bodyText confidence="0.999987307692308">
The tool is expected to produce a structured net
(Figure 1) with the synset words (green) con-
nected to the clues (yellow), as neighbors, with
weighted edges given by the scoring mechanism,
which for now is PMI. Using wordnet sematic
relations, relevant clues can be brought closer to
the sense that they indicate. This structured net
will be further augmented by inclusion of seman-
tic relations from WordNet to result in a Dis-
crimination Net. To disambiguate a word using
this net, we will calculate a score for all the sens-
es of the word and select the sense with highest
score based on its clues.
</bodyText>
<subsectionHeader confidence="0.999717">
6.1 Scoring mechanism and sample
</subsectionHeader>
<bodyText confidence="0.999723555555556">
The score for a particular possible sense will be
progressively calculated by traversing from clue
words of the given synset in the net, while mov-
ing towards the sense word. We are in the pro-
cess of developing a more efficient scoring
mechanism than PMI which will help us in as-
signing relevant weightage to edges in the dis-
crimination net and improve the potential clue
score.
</bodyText>
<figureCaption confidence="0.998967">
Figure 1: Discrimination Net Sample
</figureCaption>
<sectionHeader confidence="0.996898" genericHeader="conclusions">
7 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.99999295">
We have described the Clue Marker Tool for
word senses which allows lexicographers to se-
lect relevant clues from a set of ranked candidate
clues to disambiguate the sense of the word un-
der consideration. This tool, in addition to being
a wordnet browser, is also a corpus browser by
way of concordancer based searching. In order to
generate high quality clues, we applied PMI
based clue ranking and observed its efficacy. The
tool is language independent, since by adding
synsets of another language to the database and
the POS tagger, the clue gathering process can be
adapted for the new language. In future we plan
to study better measures for clue ranking based
on established statistical methods, along with
augmenting the corpus to get improvements in
generated clues. Finally, we plan to devise effi-
cient and light weight WSD methods that will
use the discrimination net, hopefully, bringing
about a newer understanding of WSD.
</bodyText>
<sectionHeader confidence="0.999439" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993600807692308">
Pushpak Bhattacharyya, Debasri Chakrabarty, Dipak
Narayan and Prabhakar Pande. 2002. An Experi-
ence in Building the Indo WordNet- a WordNet for
Hindi, International Conference on Global Word-
Net (GWC 02), Mysore, India.
Pushpak Bhattacharyya, Arindam Chatterjee, Salil
Joshi, Diptesh Kanojia and Akhlesh Meena. 2011.
A Study of Human Sense annotation process: Man
v/s Machine. Global WordNet Conference, Matsue,
Japan.
Pushpak Bhattacharyya, Arindam Chatterjee, Salil
Joshi and Diptesh Kanojia. 2012. Discrimination
Net for Hindi. COLING, Mumbai, India.
Pushpak Bhattacharyya, Salil Joshi and Diptesh Ka-
nojia. 2013. More than meets the eye: Study of
Human Cognition in Sense Annotation. NAACL
HLT 2013, Atlanta, USA.
Charles Clarke and Egidio Terra. 2003. Frequency
Estimates for Statistical Word Similarity Measures.
NAACL HLT 2003, Edmonton, Canada.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. Cambridge, MA: MIT Press.
Snapshot 1: Clue Marker tool user management
Snapshot 2: Clue Marker tool home / Data entry
Snapshot 3: Clue marker tool concordancer pane
Snapshot 4: Clue marker tool automated clue search
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.208392">
<title confidence="0.9843195">not do processing, when you can look up: Towards a tion Net for WSD</title>
<author confidence="0.632172">Diptesh</author>
<affiliation confidence="0.875918">IIT Bombay</affiliation>
<email confidence="0.998967">dipteshkanojia@gmail.com</email>
<author confidence="0.982526">Raj</author>
<affiliation confidence="0.98958">IIT Bombay</affiliation>
<email confidence="0.99915">prajdabre@gmail.com</email>
<author confidence="0.876563">Pushpak</author>
<affiliation confidence="0.870921">IIT Bombay</affiliation>
<email confidence="0.765209">pb@cse.iitb.ac.in</email>
<author confidence="0.784253">Siddhartha</author>
<affiliation confidence="0.986221">IIT Bombay</affiliation>
<email confidence="0.997696">siddhartha.gunti191@gmail.com</email>
<author confidence="0.77238">Manish</author>
<affiliation confidence="0.982525">IIT Bombay</affiliation>
<email confidence="0.999627">mani.shrivastava@gmail.com</email>
<abstract confidence="0.99846935">The task of Word Sense Disambiguation (WSD) incorporates in its definition the role of We present our work on the opment of a tool which allows for automatic and ranking ‘context clues’ for WSD. These clue words are extracted from the contexts of words appearing in a large monolingual corpus. These mined collection of conclues form a net the sense that for targeted WSD, navigation of the net leads to the correct sense of a word given its context. Utilizing this resource we intend to develop efficient and light weight WSD based on look up and navigation of memoryresident knowledge base, thereby avoiding heavy computation which often prevents incorporation of any serious WSD in MT and search. The need for large quantities of sense marked data too can be reduced.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pushpak Bhattacharyya</author>
<author>Debasri Chakrabarty</author>
<author>Dipak Narayan</author>
<author>Prabhakar Pande</author>
</authors>
<title>An Experience in Building the Indo WordNet- a WordNet for</title>
<date>2002</date>
<booktitle>Hindi, International Conference on Global WordNet (GWC 02),</booktitle>
<location>Mysore, India.</location>
<marker>Bhattacharyya, Chakrabarty, Narayan, Pande, 2002</marker>
<rawString>Pushpak Bhattacharyya, Debasri Chakrabarty, Dipak Narayan and Prabhakar Pande. 2002. An Experience in Building the Indo WordNet- a WordNet for Hindi, International Conference on Global WordNet (GWC 02), Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Arindam Chatterjee, Salil Joshi, Diptesh Kanojia and Akhlesh Meena.</title>
<date>2011</date>
<location>Matsue, Japan.</location>
<marker>Bhattacharyya, 2011</marker>
<rawString>Pushpak Bhattacharyya, Arindam Chatterjee, Salil Joshi, Diptesh Kanojia and Akhlesh Meena. 2011. A Study of Human Sense annotation process: Man v/s Machine. Global WordNet Conference, Matsue, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Arindam Chatterjee, Salil Joshi and Diptesh Kanojia.</title>
<date>2012</date>
<location>COLING, Mumbai, India.</location>
<marker>Bhattacharyya, 2012</marker>
<rawString>Pushpak Bhattacharyya, Arindam Chatterjee, Salil Joshi and Diptesh Kanojia. 2012. Discrimination Net for Hindi. COLING, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pushpak Bhattacharyya</author>
<author>Salil Joshi</author>
<author>Diptesh Kanojia</author>
</authors>
<title>More than meets the eye: Study of Human Cognition</title>
<date>2013</date>
<booktitle>in Sense Annotation. NAACL HLT 2013,</booktitle>
<location>Atlanta, USA.</location>
<marker>Bhattacharyya, Joshi, Kanojia, 2013</marker>
<rawString>Pushpak Bhattacharyya, Salil Joshi and Diptesh Kanojia. 2013. More than meets the eye: Study of Human Cognition in Sense Annotation. NAACL HLT 2013, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Clarke</author>
<author>Egidio Terra</author>
</authors>
<title>Frequency Estimates for Statistical Word Similarity Measures. NAACL HLT</title>
<date>2003</date>
<location>Edmonton, Canada.</location>
<marker>Clarke, Terra, 2003</marker>
<rawString>Charles Clarke and Egidio Terra. 2003. Frequency Estimates for Statistical Word Similarity Measures. NAACL HLT 2003, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="4380" citStr="Fellbaum, 1998" startWordPosition="687" endWordPosition="688">determines how much work was done by a particular person. After the first registration the request is sent to the admin who can regulate the tool usage by the person. 2.2 Phonetic Typing and Devanagari Keyboard We integrated the Google Transliterate API into our tool which simplifies the task of data entry. For people who find the phonetic typing difficult we have also incorporated a visual Devanagari keyboard. 2.3 WordIet Synsets Iavigation Wordnets have emerged as crucial resources for Natural Language Processing (NLP). They are lexical structures composed of synsets and semantic relations (Fellbaum, 1998). Our tool allows one to navigate through the complete Hindi WordNet (Narayan et al., 2002). One can proceed in a sequential manner by viewing previous or next synsets. If one wishes to view any arbitrary synset they can just type its ‘id’ in a search box and get redirected to it. One can also search for a word and the tool will display all the synsets that contain that word and the user can select any one. 2.4 Add Clues Synset words, Gloss and Example are possible clue sources. We have provided a mechanism so that if a user selects any text on the page, it can be added to the clues box with a</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. Cambridge, MA: MIT Press. Snapshot 1: Clue Marker tool user management Snapshot 2: Clue Marker tool home / Data entry Snapshot 3: Clue marker tool concordancer pane Snapshot 4: Clue marker tool automated clue search</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>