<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.332418">
<title confidence="0.978745">
Applying UMLS for Distantly Supervised Relation Detection
</title>
<author confidence="0.983572">
Roland Roller and Mark Stevenson
</author>
<affiliation confidence="0.980864">
University of Sheffield
</affiliation>
<address confidence="0.786922">
Regent Court, 211 Portobello
S1 4DP Sheffield, UK
</address>
<email confidence="0.999073">
{R.Roller,M.Stevenson}@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.997391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998653">
This paper describes first results using
the Unified Medical Language System
(UMLS) for distantly supervised relation
extraction. UMLS is a large knowledge
base which contains information about
millions of medical concepts and relations
between them. Our approach is evaluated
using existing relation extraction data sets
that contain relations that are similar to
some of those in UMLS.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999957913043478">
Distant supervision has proved to be a popular ap-
proach to relation extraction (Craven and Kum-
lien, 1999; Mintz et al., 2009; Hoffmann et al.,
2010; Nguyen and Moschitti, 2011). It has the
advantage that it does not require manually anno-
tated training data. Distant supervision avoids this
by using information from a knowledge base to
automatically identify instances of a relation from
text and use them in order to generate training data
for a relation extraction system.
Distant supervision has already been applied
to the biomedical domain (Craven and Kumlien,
1999; Thomas et al., 2011). Craven and Kum-
lien (1999) were the first to apply distant supervi-
sion and used the Yeast Protein Database (YPD) to
detect sentences containing subcellar-localization
relations. Thomas et al. (2011) trained a clas-
sifier for protein-protein interactions (PPI) using
the knowledge base IntAct and evaluated their ap-
proach on different PPI corpora.
There have also been recent applications of dis-
tant supervision outside the biomedical domain.
The use of Freebase to train a classifier, e.g.
(Mintz et al., 2009; Riedel et al., 2010), has proved
popular. Other, such as Hoffmann et al. (2010),
use Wikipedia info-boxes as the knowledge base.
Applications of distant supervision face several
challenges. The main problem is ensuring the
quality of the automatically identified training in-
stances identified by the self-annotation. The use
of instances that have been incorrectly labelled as
positive can lower performance (Takamatsu et al.,
2012). Another problem arises when positive ex-
amples are included in the set of negative train-
ing instances, which can occur when information
is missing from the knowledge base (Min et al.,
2013; Ritter et al., 2013; Xu et al., 2013).
Evaluation of relation extraction systems that
use distant supervision represents a further chal-
lenge. In the ideal case an annotated evaluation set
is available. Others, such as Ritter et al. (2013) and
Hoffmann et al. (2011), use Freebase as knowl-
edge base and evaluate their classifier on an an-
notated New York Times corpus. However, if no
evaluation set is available leave-out can be used
where the data identified using distant supervision
used for both training and testing (Hoffmann et al.,
2010).
This paper makes use of the Unified Medical
Language System (UMLS) as a knowledge source
for distant supervision. It is widely used for
biomedical language processing and readily avail-
able. The advantage of UMLS is that it contains
information about a wide range of different types
of relations and therefore has the potential to gen-
erate a large number of relation classifiers. To our
knowledge, it has not been used as a knowledge
source to train relation extraction systems.
Evaluating such as wide range of relation clas-
sifiers is not straightforward due to the lack of
gold-standard data. As an alternative approach we
make use of existing annotated data sets and iden-
tify ones which contain relations that are similar to
those included in UMLS.
The next section provides a short description of
UMLS. We then describe how we acquire existing
data sets to evaluate certain relations. In section 4
we present our first results using UMLS for distant
supervision.
</bodyText>
<page confidence="0.977365">
80
</page>
<note confidence="0.891269">
Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 80–84,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.937576" genericHeader="method">
2 Unified Medical Language System
</sectionHeader>
<bodyText confidence="0.999993941176471">
The Unified Medical Language System1 is a set
of files and software which combines different
biomedical vocabularies, knowledge bases and
standards. The Metathesaurus is a database within
UMLS which contains several million biomedical
and health related names and concepts and rela-
tionships among them. All different names of a
concept are unified by the Concept Unique Identi-
fiers (CUI). MRREL is a subset of the Metathe-
saurus and involves different relationships be-
tween different medical concepts defined by a pair
of CUIs. Many of them are child-parent rela-
tionships, express a synonymy or are vaguely de-
fined as broader or narrower relation. Other re-
lations are more specific, such as has location or
drug contraindicated for. This work focuses on
more specific types of relations.
</bodyText>
<sectionHeader confidence="0.95606" genericHeader="method">
3 Acquiring Evaluation Data Sets
</sectionHeader>
<bodyText confidence="0.999959034482759">
We examined a number of relation extraction data
sets in order to identify ones that could be used to
evaluate our system. The aim is to find a data set
that is annotated with relations that are similar to
some of those found in the UMLS. If an appropri-
ate relation can be identified then a relation extrac-
tion system can be trained using information from
the UMLS and evaluated using the data set.
To determine whether a data set is suitable we
used MetaMap (Aronson and Lang, 2010) to iden-
tify the CUIs for each related item. We then com-
pared each pair against the MRREL table to deter-
mine whether it is included as a relation. To in-
crease coverage we also included parent and child
nodes in the mapping process.
Table 1 shows the mappings obtained for two
of the data sets: the DDI 2011 data set (Segura-
Bedmar et al., 2011) and the data set described by
Rosario and Hearst (2004).
The DDI data set contains information about
drug-drug interactions and includes a single re-
lation (DDI). The relations it contained were
mapped onto 701 CUI pairs. 266 (37.9%) of these
mappings could be matched to the MRREL rela-
tion has contraindicated drug. Many of the CUI
pairs could also be mapped to the isa relationship
in MRREL, but this is a very general relationship
and the matches are caused by the large number of
these in UMLS rather than it being a reasonable
</bodyText>
<footnote confidence="0.905303">
1https://www.nlm.nih.gov/research/umls/
</footnote>
<bodyText confidence="0.9979925">
match for the DDI relation.
The data set described by Rosario and Hearst
(2004) focuses on different relationships between
treatments and diseases. The two most com-
mon relations TREAT FOR DIS (TREAT), denot-
ing the treatment for a particular disease, and PRE-
VENT (PREV), which indicates that a treatment
can be used to prevent a disease. The MRREL
isa relationship also matches many of these re-
lations, again due to its prevalence in MRREL.
Other MRREL relations (may be prevented by
and may be treated by) match fewer CUI pairs but
seem to be better matches for the TREAT and
PREV relations.
</bodyText>
<table confidence="0.9833935">
Relation MRREL
DDI (701) has contraindicated drug (266),
isa (185), may treat (57),
has contraindication (51)
PREV (41) isa (11), may be prevented by (5)
TREAT (741) isa (172), may be treated by (118)
</table>
<tableCaption confidence="0.999903">
Table 1: Relation mapping to MRREL
</tableCaption>
<bodyText confidence="0.999987076923077">
It is important to note that it is not always possi-
ble to find a CUI mapping for each entity and the
mapping process means that the mapping cannot
be guaranteed to be correct in all cases. High cov-
erage does not necessarily mean that a corpus is
very similar to a certain MRREL relation, just that
many of the CUI pairs which have been mapped
to the related entities in the corpus occur often to-
gether in a certain MRREL relation. However, in
the absence of any other suitable evaluation data
we assume that high coverage is an indicator that
the relations are strongly similar and use these two
data sets for evaluation.
</bodyText>
<sectionHeader confidence="0.992393" genericHeader="method">
4 Distant Supervision using UMLS
</sectionHeader>
<bodyText confidence="0.999959142857143">
In this section we carry out two different dis-
tant supervised experiments using UMLS. The
first experiment will be evaluated on a subset
of the DDI 2011 training data set using the
MRREL relation has contraindicated drug and
has contraindication. The second experiment
uses the MRREL relations may be treated by and
may be prevented by and are evaluated on the
Rosario &amp; Hearst data set.
We use 7,500,000 Medline abstracts annotated
with CUIs using MetaMap (choosing the best
mapping as annotation) as a corpus for distant su-
pervision. Our information extraction platform
based on a system developed for the BioNLP
</bodyText>
<page confidence="0.993478">
81
</page>
<bodyText confidence="0.9991945">
Shared Task 2013 (Roller and Stevenson, 2013).
In contrast to our previous work, our classification
process relies on the Shallow Linguistic Kernel
(Giuliano et al., 2006) in combination with Lib-
SVM (Chang and Lin, 2011) taking the kernel as
input.
</bodyText>
<subsectionHeader confidence="0.995176">
4.1 Experiment 1: DDI 2011
</subsectionHeader>
<bodyText confidence="0.999668583333333">
The DDI 2011 data set was split into training and
test sets for the experiments. Table 2 presents
results that place the distant supervision perfor-
mance in context. The naive classification ap-
proach predicts all candidate pairs as positive. The
supervised approach is trained on the training set,
using the same kernel method as our distant su-
pervised experiments and evaluated on the test set.
This represents the performance that can be ob-
tained using manually labelled training data and
can be considered as an upper bound for distant
supervision.
</bodyText>
<table confidence="0.998883">
Method Prec. / Recall / F1
naive 0.098 / 1.000 / 0.178
supervised 0.428 / 0.702 / 0.532
</table>
<tableCaption confidence="0.993265">
Table 2: DDI 2011 baseline results
</tableCaption>
<bodyText confidence="0.999701647058824">
The distant supervision approach requires pairs
of positive and negative CUI to be identified.
These pairs are used to identify positive and nega-
tive examples of the target relation from a corpus.
Pairs which occur in our target MRREL relation
are used as positive CUI pairs. Negative pairs are
generated by selecting pairs of CUIs that are occur
in any other MRREL relation.
Sentences containing these CUI pairs are iden-
tified in the subset of the MetaMapped Medline.
In the basic setup (basic), sentences containing a
positive pair will be considered as a positive train-
ing example. There are many cases where just the
occurrence of a positive MRREL pair does not ex-
press the target relation. In an effort to remove
this noisy data we apply some simple heuristics.
The first discards all training instances with more
than five words (5w) between the two entities, an
approach similar to one applied by Takamatsu et
al. (2012). The second discards positive sentences
containing a comma between the related entities
(com). We found that commas often indicate a sen-
tence containing a list of items (e.g. genes or dis-
eases) and that these sentences do not form good
training examples due to the multiple relations that
are possible when there are several items. Finally
we also apply a combination of both techniques
(5w+com).
1000 positive examples were generated using
each approach and used for training. Although it
would be possible to generate more examples for
some approaches, for example basic, applying the
combination of techniques (5w+com) significantly
reduces the number of instances available.
</bodyText>
<table confidence="0.9963825">
Method has contraindication has contraindicated
(P./R./F1) drug (P./R./F1)
basic 0.146 / 0.371 / 0.210 0.158 / 0.598 / 0.250
5w 0.109 / 0.641 / 0.187 0.207 / 0.487 / 0.290
com 0.212 / 0.560 / 0.308 0.177 / 0.498 / 0.261
5w+com 0.207 / 0.487 / 0.291 0.214 / 0.471 / 0.294
</table>
<tableCaption confidence="0.999976">
Table 3: Evaluation with DDI 2011
</tableCaption>
<bodyText confidence="0.998751321428571">
Table 3 presents results of the experiments.
The results show that all applied techniques for
both MRREL relations outperform the naive ap-
proach. The best results in terms of F1 score
for the has contraindication MRREL relation
are obtained using the com selection technique.
Applying just 5w leads to worse results than
using the basic approach. The situation for
has contraindicated drug is different. The classi-
fier provides for all techniques a better F1 score
than the basic approach. The best results are
achieved by using 5w+com. It is interesting to see,
that both MRREL relations provide similar aver-
age classification results, even if both relations are
different from the target relation and cover com-
pletely different CUI pairs. It is also interest-
ing that the MRREL relation has contraindication
has a lower coverage to the DDI relation than
has contraindicated drug, but provides slightly
better results overall. A problem with the distant
supervised classification of these two MRREL re-
lations is their low occurrence in our Medline sub-
set. Using more training data will often lead to
better results. In our case, if we apply the com-
bined selection technique, there are fewer positive
training instances than are available to the super-
vised approach, making it difficult to outperform
the supervised approach.
</bodyText>
<subsectionHeader confidence="0.989415">
4.2 Experiment 2: Rosario &amp; Hearst
</subsectionHeader>
<bodyText confidence="0.999975">
The second experiment addresses the prob-
lem of detecting the MRREL relations
may be prevented by and may be treated by.
Parts of the Rosario &amp; Hearst data set are used
to evaluate this relation. This data set differs
in structure from the DDI data set. Instead of
</bodyText>
<page confidence="0.99706">
82
</page>
<bodyText confidence="0.999916321428571">
annotating the entities in the sentence according
to its relation, the annotations in the data set
indicate whether a certain relation occurs in the
sentence. This data set does not contain any
negative examples. If a sentence contains two
entities, it will always describe a certain relation.
A supervised classifier is created by dividing the
data set into training and test sets. The test set
contains 253 different sentences (221 describe
a TREAT relation, 15 a PREV relation and 17
involve other relationships). Positive and negative
CUI pairs are selected in a different way to the
previous experiment. The two most frequent
relations in the data set are TREAT and PREV.
A classifier for a particular relation is trained
using sentences annotated with the corresponding
MRREL relation as positive instances. Negative
instances are identified using the other relation.
For example, the classifier for the TREAT relation
is trained using positive examples identified
using may be treated by with negative examples
generated using may be treated by.
Table 4 shows the baseline results on the data
set using a naive and a supervised approach on the
two original relations TREAT and PREV. Perfor-
mance of the naive approach for TREAT is very
high since the majority of sentences in the data set
are annotated with that relation.
</bodyText>
<table confidence="0.997499">
Data Set Method Prec. / Recall / F1
TREAT naive 0.874 / 1.000 / 0.933
supervised 0.944 / 0.923 / 0.934
naive 0.059 / 1.000 / 0.112
PREY supervised 0.909 / 0.667 / 0.769
</table>
<tableCaption confidence="0.999657">
Table 4: Rosario &amp; Hearst baseline results
</tableCaption>
<bodyText confidence="0.999569769230769">
Table 5 shows the results for the various dis-
tant supervision approaches. Again, 1000 positive
training examples were used to train the classifier.
Since the F-Score of the naive and the supervised
approaches of TREAT are very high, it is difficult
to compete with the may be treated by distant su-
pervised classifier. However, considering that just
15.9% of the TREAT instance pairs of the train-
ing set match the MRREL may be treated by re-
lation, the results are promising. Furthermore, the
precision of all may be treated by distant super-
vised experiments outperform the naive approach.
The best results are achieved using com as selec-
tion technique.
The experiments using the PREV relation for
evaluation are more interesting. Due to its low
occurrence in the test set it is more difficult to
detect this relation. The distant supervised clas-
sifier trained with the may be prevented by rela-
tion easily outperforms the naive approach. The
best overall F1 scoer results are achieved using
the 5w technique. As expected the distant super-
vised results are outperformed by the supervised
approach. However, the recall for all distantly su-
pervised approaches are at least as high as those
obtained using the supervised approach.
</bodyText>
<table confidence="0.991120857142857">
Method may be treated by may be prevented by
evaluated on TREAT evaluated on PREY
(P./R./F1) (P./R./F1)
basic 0.926 / 0.733 / 0.818 0.286 / 0.667 / 0.400
5w 0.925 / 0.783 / 0.848 0.407 / 0.733 / 0.524
com 0.928 / 0.819 / 0.870 0.222 / 0.800 / 0.348
5w+com 0.924 / 0.769 / 0.840 0.361 / 0.867 / 0.510
</table>
<tableCaption confidence="0.9493045">
Table 5: Evaluation with Rosario &amp; Hearst data
set
</tableCaption>
<sectionHeader confidence="0.973589" genericHeader="conclusions">
5 Conclusion and Discussion
</sectionHeader>
<bodyText confidence="0.999254045454546">
In this paper we presented first results using
UMLS to train a distant supervised relational clas-
sifier. Evaluation was carried out using existing
evaluation data sets since no resources directly an-
notated with UMLS relations were available. We
showed that using a distantly supervised classifier
trained on MRREL relations similar to those found
in the evaluation data set provides promising re-
sults.
Overall, our system works with some compo-
nents which should be improved to achieve better
results. First, we rely on a cheap and fast anno-
tation using MetaMap, which might produce an-
notation errors. In addition, the use of noisy dis-
tant supervised training data decreases the classi-
fication quality. An improvement of the selection
process and an improvement of the classification
method, such as Chowdhury and Lavelli (2013),
could lead to better classification results. In future
we would also like to make further use of existing
data sets with similar relations to those of interest
to evaluate distant supervision approaches.
</bodyText>
<sectionHeader confidence="0.997751" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999723">
The authors are grateful to the Engineering
and Physical Sciences Research Council for
supporting the work described in this paper
(EP/J008427/1).
</bodyText>
<page confidence="0.998506">
83
</page>
<sectionHeader confidence="0.994371" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999479445454545">
A. Aronson and F. Lang. 2010. An overview of
MetaMap: historical perspective and recent ad-
vances. Journal of the American Medical Associ-
ation, 17(3):229–236.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technology,
2:27:1–27:27.
Md. Faisal Mahbub Chowdhury and Alberto Lavelli.
2013. Fbk-irst : A multi-phase kernel based ap-
proach for drug-drug interaction detection and clas-
sification that exploits linguistic information. In
Second Joint Conference on Lexical and Computa-
tional Semantics (*SEM), Volume 2: Proceedings
of the Seventh International Workshop on Seman-
tic Evaluation (SemEval 2013), pages 351–355, At-
lanta, Georgia, USA, June. Association for Compu-
tational Linguistics.
Mark Craven and Johan Kumlien. 1999. Constructing
biological knowledge bases by extracting informa-
tion from text sources. In In Proceedings of the Sev-
enth International Conference on Intelligent Systems
for Molecular Biology (ISMB), pages 77–86. AAAI
Press.
Claudio Giuliano, Alberto Lavelli, and Lorenza Ro-
mano. 2006. Exploiting shallow linguistic infor-
mation for relation extraction from biomedical liter-
ature. In In Proc. EACL 2006.
Raphael Hoffmann, Congle Zhang, and Daniel S.
Weld. 2010. Learning 5000 relational extractors. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, ACL ’10,
pages 286–295, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Raphael Hoffmann, Congle Zhang, Xiao Ling,
Luke Zettlemoyer, and Daniel S. Weld. 2011.
Knowledge-based weak supervision for information
extraction of overlapping relations. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics, ACL ’11, pages 541–
550.
Bonan Min, Ralph Grishman, Li Wan, Chang Wang,
and David Gondek. 2013. Distant supervision for
relation extraction with an incomplete knowledge
base. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 777–782, Atlanta, Georgia, June.
Association for Computational Linguistics.
Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 2 - Volume 2, ACL ’09, pages 1003–1011,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Truc-Vien T. Nguyen and Alessandro Moschitti. 2011.
End-to-end relation extraction using distant super-
vision from external semantic repositories. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies: short papers - Volume 2, HLT
’11, pages 277–282, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Proceedings of the European
Conference on Machine Learning and Knowledge
Discovery in Databases (ECML PKDD ’10).
Alan Ritter, Luke Zettlemoyer, Mausam, and Oren Et-
zioni. 2013. Modeling missing data in distant su-
pervision for information extraction. In Association
for Computational Linguistics Vol. 1 (TACL).
Roland Roller and Mark Stevenson. 2013. Identi-
fication of genia events using multiple classifiers.
In Proceedings of BioNLP Shared Task 2013 Work-
shop, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Barbara Rosario and Marti A. Hearst. 2004. Classi-
fying semantic relations in bioscience texts. In Pro-
ceedings of the 42nd Annual Meeting on Association
for Computational Linguistics, ACL ’04, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Isabel Segura-Bedmar, Paloma Martnez, and Daniel
Snchez-Cisneros. 2011. The 1st ddi extraction-
2011 challenge task: Extraction of drug-drug inter-
actions from biomedical texts. In Proceedings of
DDI Extraction-2011 challenge task., pages 1–9.
Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.
2012. Reducing wrong labels in distant supervi-
sion for relation extraction. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics: Long Papers - Volume 1, ACL
’12, pages 721–729, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Philippe Thomas, Ill´es Solt, Roman Klinger, and Ulf
Leser. 2011. Learning protein protein interaction
extraction using distant supervision. In Proceedings
of Robust Unsupervised and Semi-Supervised Meth-
ods in Natural Language Processing, pages 34–41.
Wei Xu, Raphael Hoffmann, Le Zhao, and Ralph Gr-
ishman. 2013. Filling knowledge base gaps for dis-
tant supervision of relation extraction. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Pa-
pers), pages 665–670, Sofia, Bulgaria, August. As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.999245">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.697396">
<title confidence="0.999865">Applying UMLS for Distantly Supervised Relation Detection</title>
<author confidence="0.977376">Roller</author>
<affiliation confidence="0.992436">University of</affiliation>
<address confidence="0.80005">Regent Court, 211 S1 4DP Sheffield,</address>
<abstract confidence="0.998291454545455">This paper describes first results using the Unified Medical Language System (UMLS) for distantly supervised relation extraction. UMLS is a large knowledge base which contains information about millions of medical concepts and relations between them. Our approach is evaluated using existing relation extraction data sets that contain relations that are similar to some of those in UMLS.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Aronson</author>
<author>F Lang</author>
</authors>
<title>An overview of MetaMap: historical perspective and recent advances.</title>
<date>2010</date>
<journal>Journal of the American Medical Association,</journal>
<volume>17</volume>
<issue>3</issue>
<contexts>
<context position="5405" citStr="Aronson and Lang, 2010" startWordPosition="855" endWordPosition="858">, such as has location or drug contraindicated for. This work focuses on more specific types of relations. 3 Acquiring Evaluation Data Sets We examined a number of relation extraction data sets in order to identify ones that could be used to evaluate our system. The aim is to find a data set that is annotated with relations that are similar to some of those found in the UMLS. If an appropriate relation can be identified then a relation extraction system can be trained using information from the UMLS and evaluated using the data set. To determine whether a data set is suitable we used MetaMap (Aronson and Lang, 2010) to identify the CUIs for each related item. We then compared each pair against the MRREL table to determine whether it is included as a relation. To increase coverage we also included parent and child nodes in the mapping process. Table 1 shows the mappings obtained for two of the data sets: the DDI 2011 data set (SeguraBedmar et al., 2011) and the data set described by Rosario and Hearst (2004). The DDI data set contains information about drug-drug interactions and includes a single relation (DDI). The relations it contained were mapped onto 701 CUI pairs. 266 (37.9%) of these mappings could</context>
</contexts>
<marker>Aronson, Lang, 2010</marker>
<rawString>A. Aronson and F. Lang. 2010. An overview of MetaMap: historical perspective and recent advances. Journal of the American Medical Association, 17(3):229–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<pages>2--27</pages>
<contexts>
<context position="8641" citStr="Chang and Lin, 2011" startWordPosition="1413" endWordPosition="1416">ug and has contraindication. The second experiment uses the MRREL relations may be treated by and may be prevented by and are evaluated on the Rosario &amp; Hearst data set. We use 7,500,000 Medline abstracts annotated with CUIs using MetaMap (choosing the best mapping as annotation) as a corpus for distant supervision. Our information extraction platform based on a system developed for the BioNLP 81 Shared Task 2013 (Roller and Stevenson, 2013). In contrast to our previous work, our classification process relies on the Shallow Linguistic Kernel (Giuliano et al., 2006) in combination with LibSVM (Chang and Lin, 2011) taking the kernel as input. 4.1 Experiment 1: DDI 2011 The DDI 2011 data set was split into training and test sets for the experiments. Table 2 presents results that place the distant supervision performance in context. The naive classification approach predicts all candidate pairs as positive. The supervised approach is trained on the training set, using the same kernel method as our distant supervised experiments and evaluated on the test set. This represents the performance that can be obtained using manually labelled training data and can be considered as an upper bound for distant superv</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Faisal Mahbub Chowdhury</author>
<author>Alberto Lavelli</author>
</authors>
<title>Fbk-irst : A multi-phase kernel based approach for drug-drug interaction detection and classification that exploits linguistic information.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>351--355</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<marker>Chowdhury, Lavelli, 2013</marker>
<rawString>Md. Faisal Mahbub Chowdhury and Alberto Lavelli. 2013. Fbk-irst : A multi-phase kernel based approach for drug-drug interaction detection and classification that exploits linguistic information. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 351–355, Atlanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources. In</title>
<date>1999</date>
<booktitle>In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology (ISMB),</booktitle>
<pages>77--86</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="719" citStr="Craven and Kumlien, 1999" startWordPosition="97" endWordPosition="101">ersity of Sheffield Regent Court, 211 Portobello S1 4DP Sheffield, UK {R.Roller,M.Stevenson}@dcs.shef.ac.uk Abstract This paper describes first results using the Unified Medical Language System (UMLS) for distantly supervised relation extraction. UMLS is a large knowledge base which contains information about millions of medical concepts and relations between them. Our approach is evaluated using existing relation extraction data sets that contain relations that are similar to some of those in UMLS. 1 Introduction Distant supervision has proved to be a popular approach to relation extraction (Craven and Kumlien, 1999; Mintz et al., 2009; Hoffmann et al., 2010; Nguyen and Moschitti, 2011). It has the advantage that it does not require manually annotated training data. Distant supervision avoids this by using information from a knowledge base to automatically identify instances of a relation from text and use them in order to generate training data for a relation extraction system. Distant supervision has already been applied to the biomedical domain (Craven and Kumlien, 1999; Thomas et al., 2011). Craven and Kumlien (1999) were the first to apply distant supervision and used the Yeast Protein Database (YPD</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology (ISMB), pages 77–86. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Giuliano</author>
<author>Alberto Lavelli</author>
<author>Lorenza Romano</author>
</authors>
<title>Exploiting shallow linguistic information for relation extraction from biomedical literature. In</title>
<date>2006</date>
<booktitle>In Proc. EACL</booktitle>
<contexts>
<context position="8592" citStr="Giuliano et al., 2006" startWordPosition="1404" endWordPosition="1407">set using the MRREL relation has contraindicated drug and has contraindication. The second experiment uses the MRREL relations may be treated by and may be prevented by and are evaluated on the Rosario &amp; Hearst data set. We use 7,500,000 Medline abstracts annotated with CUIs using MetaMap (choosing the best mapping as annotation) as a corpus for distant supervision. Our information extraction platform based on a system developed for the BioNLP 81 Shared Task 2013 (Roller and Stevenson, 2013). In contrast to our previous work, our classification process relies on the Shallow Linguistic Kernel (Giuliano et al., 2006) in combination with LibSVM (Chang and Lin, 2011) taking the kernel as input. 4.1 Experiment 1: DDI 2011 The DDI 2011 data set was split into training and test sets for the experiments. Table 2 presents results that place the distant supervision performance in context. The naive classification approach predicts all candidate pairs as positive. The supervised approach is trained on the training set, using the same kernel method as our distant supervised experiments and evaluated on the test set. This represents the performance that can be obtained using manually labelled training data and can b</context>
</contexts>
<marker>Giuliano, Lavelli, Romano, 2006</marker>
<rawString>Claudio Giuliano, Alberto Lavelli, and Lorenza Romano. 2006. Exploiting shallow linguistic information for relation extraction from biomedical literature. In In Proc. EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Daniel S Weld</author>
</authors>
<title>Learning 5000 relational extractors.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>286--295</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="762" citStr="Hoffmann et al., 2010" startWordPosition="106" endWordPosition="109">lo S1 4DP Sheffield, UK {R.Roller,M.Stevenson}@dcs.shef.ac.uk Abstract This paper describes first results using the Unified Medical Language System (UMLS) for distantly supervised relation extraction. UMLS is a large knowledge base which contains information about millions of medical concepts and relations between them. Our approach is evaluated using existing relation extraction data sets that contain relations that are similar to some of those in UMLS. 1 Introduction Distant supervision has proved to be a popular approach to relation extraction (Craven and Kumlien, 1999; Mintz et al., 2009; Hoffmann et al., 2010; Nguyen and Moschitti, 2011). It has the advantage that it does not require manually annotated training data. Distant supervision avoids this by using information from a knowledge base to automatically identify instances of a relation from text and use them in order to generate training data for a relation extraction system. Distant supervision has already been applied to the biomedical domain (Craven and Kumlien, 1999; Thomas et al., 2011). Craven and Kumlien (1999) were the first to apply distant supervision and used the Yeast Protein Database (YPD) to detect sentences containing subcellar-</context>
<context position="2883" citStr="Hoffmann et al., 2010" startWordPosition="441" endWordPosition="444">an occur when information is missing from the knowledge base (Min et al., 2013; Ritter et al., 2013; Xu et al., 2013). Evaluation of relation extraction systems that use distant supervision represents a further challenge. In the ideal case an annotated evaluation set is available. Others, such as Ritter et al. (2013) and Hoffmann et al. (2011), use Freebase as knowledge base and evaluate their classifier on an annotated New York Times corpus. However, if no evaluation set is available leave-out can be used where the data identified using distant supervision used for both training and testing (Hoffmann et al., 2010). This paper makes use of the Unified Medical Language System (UMLS) as a knowledge source for distant supervision. It is widely used for biomedical language processing and readily available. The advantage of UMLS is that it contains information about a wide range of different types of relations and therefore has the potential to generate a large number of relation classifiers. To our knowledge, it has not been used as a knowledge source to train relation extraction systems. Evaluating such as wide range of relation classifiers is not straightforward due to the lack of gold-standard data. As a</context>
</contexts>
<marker>Hoffmann, Zhang, Weld, 2010</marker>
<rawString>Raphael Hoffmann, Congle Zhang, and Daniel S. Weld. 2010. Learning 5000 relational extractors. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 286–295, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledge-based weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, ACL ’11,</booktitle>
<pages>541--550</pages>
<contexts>
<context position="2606" citStr="Hoffmann et al. (2011)" startWordPosition="395" endWordPosition="398">ining instances identified by the self-annotation. The use of instances that have been incorrectly labelled as positive can lower performance (Takamatsu et al., 2012). Another problem arises when positive examples are included in the set of negative training instances, which can occur when information is missing from the knowledge base (Min et al., 2013; Ritter et al., 2013; Xu et al., 2013). Evaluation of relation extraction systems that use distant supervision represents a further challenge. In the ideal case an annotated evaluation set is available. Others, such as Ritter et al. (2013) and Hoffmann et al. (2011), use Freebase as knowledge base and evaluate their classifier on an annotated New York Times corpus. However, if no evaluation set is available leave-out can be used where the data identified using distant supervision used for both training and testing (Hoffmann et al., 2010). This paper makes use of the Unified Medical Language System (UMLS) as a knowledge source for distant supervision. It is widely used for biomedical language processing and readily available. The advantage of UMLS is that it contains information about a wide range of different types of relations and therefore has the pote</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, ACL ’11, pages 541– 550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonan Min</author>
<author>Ralph Grishman</author>
<author>Li Wan</author>
<author>Chang Wang</author>
<author>David Gondek</author>
</authors>
<title>Distant supervision for relation extraction with an incomplete knowledge base.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>777--782</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="2339" citStr="Min et al., 2013" startWordPosition="351" endWordPosition="354">l et al., 2010), has proved popular. Other, such as Hoffmann et al. (2010), use Wikipedia info-boxes as the knowledge base. Applications of distant supervision face several challenges. The main problem is ensuring the quality of the automatically identified training instances identified by the self-annotation. The use of instances that have been incorrectly labelled as positive can lower performance (Takamatsu et al., 2012). Another problem arises when positive examples are included in the set of negative training instances, which can occur when information is missing from the knowledge base (Min et al., 2013; Ritter et al., 2013; Xu et al., 2013). Evaluation of relation extraction systems that use distant supervision represents a further challenge. In the ideal case an annotated evaluation set is available. Others, such as Ritter et al. (2013) and Hoffmann et al. (2011), use Freebase as knowledge base and evaluate their classifier on an annotated New York Times corpus. However, if no evaluation set is available leave-out can be used where the data identified using distant supervision used for both training and testing (Hoffmann et al., 2010). This paper makes use of the Unified Medical Language S</context>
</contexts>
<marker>Min, Grishman, Wan, Wang, Gondek, 2013</marker>
<rawString>Bonan Min, Ralph Grishman, Li Wan, Chang Wang, and David Gondek. 2013. Distant supervision for relation extraction with an incomplete knowledge base. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 777–782, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<contexts>
<context position="739" citStr="Mintz et al., 2009" startWordPosition="102" endWordPosition="105"> Court, 211 Portobello S1 4DP Sheffield, UK {R.Roller,M.Stevenson}@dcs.shef.ac.uk Abstract This paper describes first results using the Unified Medical Language System (UMLS) for distantly supervised relation extraction. UMLS is a large knowledge base which contains information about millions of medical concepts and relations between them. Our approach is evaluated using existing relation extraction data sets that contain relations that are similar to some of those in UMLS. 1 Introduction Distant supervision has proved to be a popular approach to relation extraction (Craven and Kumlien, 1999; Mintz et al., 2009; Hoffmann et al., 2010; Nguyen and Moschitti, 2011). It has the advantage that it does not require manually annotated training data. Distant supervision avoids this by using information from a knowledge base to automatically identify instances of a relation from text and use them in order to generate training data for a relation extraction system. Distant supervision has already been applied to the biomedical domain (Craven and Kumlien, 1999; Thomas et al., 2011). Craven and Kumlien (1999) were the first to apply distant supervision and used the Yeast Protein Database (YPD) to detect sentence</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2, ACL ’09, pages 1003–1011,</rawString>
</citation>
<citation valid="false">
<authors>
<author>PA Stroudsburg</author>
</authors>
<institution>USA. Association for Computational Linguistics.</institution>
<marker>Stroudsburg, </marker>
<rawString>Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Truc-Vien T Nguyen</author>
<author>Alessandro Moschitti</author>
</authors>
<title>End-to-end relation extraction using distant supervision from external semantic repositories.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>277--282</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="791" citStr="Nguyen and Moschitti, 2011" startWordPosition="110" endWordPosition="113"> {R.Roller,M.Stevenson}@dcs.shef.ac.uk Abstract This paper describes first results using the Unified Medical Language System (UMLS) for distantly supervised relation extraction. UMLS is a large knowledge base which contains information about millions of medical concepts and relations between them. Our approach is evaluated using existing relation extraction data sets that contain relations that are similar to some of those in UMLS. 1 Introduction Distant supervision has proved to be a popular approach to relation extraction (Craven and Kumlien, 1999; Mintz et al., 2009; Hoffmann et al., 2010; Nguyen and Moschitti, 2011). It has the advantage that it does not require manually annotated training data. Distant supervision avoids this by using information from a knowledge base to automatically identify instances of a relation from text and use them in order to generate training data for a relation extraction system. Distant supervision has already been applied to the biomedical domain (Craven and Kumlien, 1999; Thomas et al., 2011). Craven and Kumlien (1999) were the first to apply distant supervision and used the Yeast Protein Database (YPD) to detect sentences containing subcellar-localization relations. Thoma</context>
</contexts>
<marker>Nguyen, Moschitti, 2011</marker>
<rawString>Truc-Vien T. Nguyen and Alessandro Moschitti. 2011. End-to-end relation extraction using distant supervision from external semantic repositories. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 277–282, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD ’10).</booktitle>
<contexts>
<context position="1738" citStr="Riedel et al., 2010" startWordPosition="259" endWordPosition="262">ady been applied to the biomedical domain (Craven and Kumlien, 1999; Thomas et al., 2011). Craven and Kumlien (1999) were the first to apply distant supervision and used the Yeast Protein Database (YPD) to detect sentences containing subcellar-localization relations. Thomas et al. (2011) trained a classifier for protein-protein interactions (PPI) using the knowledge base IntAct and evaluated their approach on different PPI corpora. There have also been recent applications of distant supervision outside the biomedical domain. The use of Freebase to train a classifier, e.g. (Mintz et al., 2009; Riedel et al., 2010), has proved popular. Other, such as Hoffmann et al. (2010), use Wikipedia info-boxes as the knowledge base. Applications of distant supervision face several challenges. The main problem is ensuring the quality of the automatically identified training instances identified by the self-annotation. The use of instances that have been incorrectly labelled as positive can lower performance (Takamatsu et al., 2012). Another problem arises when positive examples are included in the set of negative training instances, which can occur when information is missing from the knowledge base (Min et al., 201</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD ’10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Luke Zettlemoyer</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Modeling missing data in distant supervision for information extraction.</title>
<date>2013</date>
<booktitle>In Association for Computational Linguistics</booktitle>
<volume>1</volume>
<contexts>
<context position="2360" citStr="Ritter et al., 2013" startWordPosition="355" endWordPosition="358">as proved popular. Other, such as Hoffmann et al. (2010), use Wikipedia info-boxes as the knowledge base. Applications of distant supervision face several challenges. The main problem is ensuring the quality of the automatically identified training instances identified by the self-annotation. The use of instances that have been incorrectly labelled as positive can lower performance (Takamatsu et al., 2012). Another problem arises when positive examples are included in the set of negative training instances, which can occur when information is missing from the knowledge base (Min et al., 2013; Ritter et al., 2013; Xu et al., 2013). Evaluation of relation extraction systems that use distant supervision represents a further challenge. In the ideal case an annotated evaluation set is available. Others, such as Ritter et al. (2013) and Hoffmann et al. (2011), use Freebase as knowledge base and evaluate their classifier on an annotated New York Times corpus. However, if no evaluation set is available leave-out can be used where the data identified using distant supervision used for both training and testing (Hoffmann et al., 2010). This paper makes use of the Unified Medical Language System (UMLS) as a kno</context>
</contexts>
<marker>Ritter, Zettlemoyer, Mausam, Etzioni, 2013</marker>
<rawString>Alan Ritter, Luke Zettlemoyer, Mausam, and Oren Etzioni. 2013. Modeling missing data in distant supervision for information extraction. In Association for Computational Linguistics Vol. 1 (TACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roland Roller</author>
<author>Mark Stevenson</author>
</authors>
<title>Identification of genia events using multiple classifiers.</title>
<date>2013</date>
<booktitle>In Proceedings of BioNLP Shared Task 2013 Workshop,</booktitle>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="8466" citStr="Roller and Stevenson, 2013" startWordPosition="1385" endWordPosition="1388">ferent distant supervised experiments using UMLS. The first experiment will be evaluated on a subset of the DDI 2011 training data set using the MRREL relation has contraindicated drug and has contraindication. The second experiment uses the MRREL relations may be treated by and may be prevented by and are evaluated on the Rosario &amp; Hearst data set. We use 7,500,000 Medline abstracts annotated with CUIs using MetaMap (choosing the best mapping as annotation) as a corpus for distant supervision. Our information extraction platform based on a system developed for the BioNLP 81 Shared Task 2013 (Roller and Stevenson, 2013). In contrast to our previous work, our classification process relies on the Shallow Linguistic Kernel (Giuliano et al., 2006) in combination with LibSVM (Chang and Lin, 2011) taking the kernel as input. 4.1 Experiment 1: DDI 2011 The DDI 2011 data set was split into training and test sets for the experiments. Table 2 presents results that place the distant supervision performance in context. The naive classification approach predicts all candidate pairs as positive. The supervised approach is trained on the training set, using the same kernel method as our distant supervised experiments and e</context>
</contexts>
<marker>Roller, Stevenson, 2013</marker>
<rawString>Roland Roller and Mark Stevenson. 2013. Identification of genia events using multiple classifiers. In Proceedings of BioNLP Shared Task 2013 Workshop, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti A Hearst</author>
</authors>
<title>Classifying semantic relations in bioscience texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5804" citStr="Rosario and Hearst (2004)" startWordPosition="931" endWordPosition="934">relation can be identified then a relation extraction system can be trained using information from the UMLS and evaluated using the data set. To determine whether a data set is suitable we used MetaMap (Aronson and Lang, 2010) to identify the CUIs for each related item. We then compared each pair against the MRREL table to determine whether it is included as a relation. To increase coverage we also included parent and child nodes in the mapping process. Table 1 shows the mappings obtained for two of the data sets: the DDI 2011 data set (SeguraBedmar et al., 2011) and the data set described by Rosario and Hearst (2004). The DDI data set contains information about drug-drug interactions and includes a single relation (DDI). The relations it contained were mapped onto 701 CUI pairs. 266 (37.9%) of these mappings could be matched to the MRREL relation has contraindicated drug. Many of the CUI pairs could also be mapped to the isa relationship in MRREL, but this is a very general relationship and the matches are caused by the large number of these in UMLS rather than it being a reasonable 1https://www.nlm.nih.gov/research/umls/ match for the DDI relation. The data set described by Rosario and Hearst (2004) focu</context>
</contexts>
<marker>Rosario, Hearst, 2004</marker>
<rawString>Barbara Rosario and Marti A. Hearst. 2004. Classifying semantic relations in bioscience texts. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabel Segura-Bedmar</author>
<author>Paloma Martnez</author>
<author>Daniel Snchez-Cisneros</author>
</authors>
<title>The 1st ddi extraction2011 challenge task: Extraction of drug-drug interactions from biomedical texts.</title>
<date>2011</date>
<booktitle>In Proceedings of DDI Extraction-2011 challenge task.,</booktitle>
<pages>1--9</pages>
<marker>Segura-Bedmar, Martnez, Snchez-Cisneros, 2011</marker>
<rawString>Isabel Segura-Bedmar, Paloma Martnez, and Daniel Snchez-Cisneros. 2011. The 1st ddi extraction2011 challenge task: Extraction of drug-drug interactions from biomedical texts. In Proceedings of DDI Extraction-2011 challenge task., pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shingo Takamatsu</author>
<author>Issei Sato</author>
<author>Hiroshi Nakagawa</author>
</authors>
<title>Reducing wrong labels in distant supervision for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12,</booktitle>
<pages>721--729</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2150" citStr="Takamatsu et al., 2012" startWordPosition="319" endWordPosition="322"> on different PPI corpora. There have also been recent applications of distant supervision outside the biomedical domain. The use of Freebase to train a classifier, e.g. (Mintz et al., 2009; Riedel et al., 2010), has proved popular. Other, such as Hoffmann et al. (2010), use Wikipedia info-boxes as the knowledge base. Applications of distant supervision face several challenges. The main problem is ensuring the quality of the automatically identified training instances identified by the self-annotation. The use of instances that have been incorrectly labelled as positive can lower performance (Takamatsu et al., 2012). Another problem arises when positive examples are included in the set of negative training instances, which can occur when information is missing from the knowledge base (Min et al., 2013; Ritter et al., 2013; Xu et al., 2013). Evaluation of relation extraction systems that use distant supervision represents a further challenge. In the ideal case an annotated evaluation set is available. Others, such as Ritter et al. (2013) and Hoffmann et al. (2011), use Freebase as knowledge base and evaluate their classifier on an annotated New York Times corpus. However, if no evaluation set is available</context>
<context position="10298" citStr="Takamatsu et al. (2012)" startWordPosition="1694" endWordPosition="1697"> by selecting pairs of CUIs that are occur in any other MRREL relation. Sentences containing these CUI pairs are identified in the subset of the MetaMapped Medline. In the basic setup (basic), sentences containing a positive pair will be considered as a positive training example. There are many cases where just the occurrence of a positive MRREL pair does not express the target relation. In an effort to remove this noisy data we apply some simple heuristics. The first discards all training instances with more than five words (5w) between the two entities, an approach similar to one applied by Takamatsu et al. (2012). The second discards positive sentences containing a comma between the related entities (com). We found that commas often indicate a sentence containing a list of items (e.g. genes or diseases) and that these sentences do not form good training examples due to the multiple relations that are possible when there are several items. Finally we also apply a combination of both techniques (5w+com). 1000 positive examples were generated using each approach and used for training. Although it would be possible to generate more examples for some approaches, for example basic, applying the combination </context>
</contexts>
<marker>Takamatsu, Sato, Nakagawa, 2012</marker>
<rawString>Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. 2012. Reducing wrong labels in distant supervision for relation extraction. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12, pages 721–729, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Thomas</author>
<author>Ill´es Solt</author>
<author>Roman Klinger</author>
<author>Ulf Leser</author>
</authors>
<title>Learning protein protein interaction extraction using distant supervision.</title>
<date>2011</date>
<booktitle>In Proceedings of Robust Unsupervised and Semi-Supervised Methods in Natural Language Processing,</booktitle>
<pages>34--41</pages>
<contexts>
<context position="1207" citStr="Thomas et al., 2011" startWordPosition="176" endWordPosition="179">ose in UMLS. 1 Introduction Distant supervision has proved to be a popular approach to relation extraction (Craven and Kumlien, 1999; Mintz et al., 2009; Hoffmann et al., 2010; Nguyen and Moschitti, 2011). It has the advantage that it does not require manually annotated training data. Distant supervision avoids this by using information from a knowledge base to automatically identify instances of a relation from text and use them in order to generate training data for a relation extraction system. Distant supervision has already been applied to the biomedical domain (Craven and Kumlien, 1999; Thomas et al., 2011). Craven and Kumlien (1999) were the first to apply distant supervision and used the Yeast Protein Database (YPD) to detect sentences containing subcellar-localization relations. Thomas et al. (2011) trained a classifier for protein-protein interactions (PPI) using the knowledge base IntAct and evaluated their approach on different PPI corpora. There have also been recent applications of distant supervision outside the biomedical domain. The use of Freebase to train a classifier, e.g. (Mintz et al., 2009; Riedel et al., 2010), has proved popular. Other, such as Hoffmann et al. (2010), use Wiki</context>
</contexts>
<marker>Thomas, Solt, Klinger, Leser, 2011</marker>
<rawString>Philippe Thomas, Ill´es Solt, Roman Klinger, and Ulf Leser. 2011. Learning protein protein interaction extraction using distant supervision. In Proceedings of Robust Unsupervised and Semi-Supervised Methods in Natural Language Processing, pages 34–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Xu</author>
<author>Raphael Hoffmann</author>
<author>Le Zhao</author>
<author>Ralph Grishman</author>
</authors>
<title>Filling knowledge base gaps for distant supervision of relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>665--670</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<marker>Xu, Hoffmann, Le Zhao, Grishman, 2013</marker>
<rawString>Wei Xu, Raphael Hoffmann, Le Zhao, and Ralph Grishman. 2013. Filling knowledge base gaps for distant supervision of relation extraction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 665–670, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>