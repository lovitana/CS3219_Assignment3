<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.975344">
Using Ellipsis Detection and Word Similarity for Transformation of
Spoken Language into Grammatically Valid Sentences
</title>
<author confidence="0.958732">
Manuel Giuliani Thomas Marschall Amy Isard
</author>
<affiliation confidence="0.892484">
fortiss GmbH fortiss GmbH University of Edinburgh
</affiliation>
<address confidence="0.477746">
Munich, Germany Munich, Germany Edinburgh, UK
</address>
<email confidence="0.992764">
giuliani@fortiss.org marschat@in.tum.de amyi@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.993739" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999951954545455">
When humans speak they often use gram-
matically incorrect sentences, which is a
problem for grammar-based language pro-
cessing methods, since they expect in-
put that is valid for the grammar. We
present two methods to transform spoken
language into grammatically correct sen-
tences. The first is an algorithm for au-
tomatic ellipsis detection, which finds el-
lipses in spoken sentences and searches
in a combinatory categorial grammar for
suitable words to fill the ellipses. The sec-
ond method is an algorithm that computes
the semantic similarity of two words us-
ing WordNet, which we use to find alter-
natives to words that are unknown to the
grammar. In an evaluation, we show that
the usage of these two methods leads to
an increase of 38.64% more parseable sen-
tences on a test set of spoken sentences
that were collected during a human-robot
interaction experiment.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999810428571428">
Computer systems that are designed to interact
verbally with humans need to be able to recog-
nise and understand human speech. In this pa-
per we use as an example the robot bartender
JAMES (Joint Action for Multimodal Embodied
Social Systems),1 shown in Figure 1. The robot
is able to take drink orders from customers and to
serve drinks. It is equipped with automatic speech
recognition, to understand what the human is say-
ing, and it has a grammar, to parse and process the
spoken utterances.
The JAMES robot grammar was initially very
restricted, and therefore during grammar devel-
opment as well as during the user studies that
</bodyText>
<footnote confidence="0.964409">
1http://www.james-project.eu
</footnote>
<figureCaption confidence="0.8473375">
Figure 1: The robot bartender of the JAMES
project interacting with a customer.
</figureCaption>
<bodyText confidence="0.99987">
we conducted (Foster et al., 2012; Giuliani et al.,
2013; Keizer et al., 2013), we experienced situa-
tions in which the robot was not able to process
the spoken input by humans, because they spoke
sentences with grammatical structures that could
not be parsed by the grammar, they used words
that were not part of the grammar, or they left out
words. We had for example cases where humans
approached the robot and used a sentence with an
ellipsis (“I want Coke”, but the grammar expected
a determiner in front of “Coke”) or a sentence with
a word that was unknown to the grammar (“I need
a water”, but “need” was not part of the gram-
mar’s word list). In these cases, the robot was un-
able to process and to respond to the spoken ut-
terance by the human. Of course, these shortcom-
ings can be overcome by extending the grammar,
but even with a much more sophisticated grammar
there will always be instances of unexpected lan-
guage, and we believe that our approach can be
very useful in extending the coverage of a gram-
mar during testing or user studies.
Therefore, we present an approach to transform
unparseable spoken language into sentences that a
given grammar can parse. For ellipsis detection,
</bodyText>
<page confidence="0.984555">
243
</page>
<note confidence="0.7315255">
Proceedings of the SIGDIAL 2014 Conference, pages 243–250,
Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.998734272727273">
we present in Section 3.1 a novel algorithm that
searches for ellipses in a sentence and computes
candidate words to fill the ellipsis with words from
a grammar. In Section 3.2, we show how we use
WordNet (Miller, 1995) to find replacements for
words that are not in the robot’s grammar. In Sec-
tion 4 we evaluate our approach with a test set
of 211 spoken utterances that were recorded in
a human-robot interaction (HRI) experiment, and
the grammar for processing used in the same ex-
periment.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999959">
The work described in this paper draws on re-
search and techniques from three main areas: the
automatic detection of ellipses in sentences, cal-
culation of semantic similarity between two words
using WordNet, and spoken language processing.
This section provides a summary of relevant work
in these areas.
</bodyText>
<subsectionHeader confidence="0.965749">
2.1 Ellipsis Detection
</subsectionHeader>
<bodyText confidence="0.999827923076923">
There is a wide range of research in ellipsis de-
tection in written language, where different types
of ellipses are widely defined, such as gapping,
stripping or verb phrase ellipsis (Lappin, 1996).
For example, an ellipsis occurs when a redundant
word is left out of succeeding sentences, such as
the words “want to have” in the sentence “I want
to have a water, and my friend a juice”, which are
omitted in the second part of the sentence.
The detection of verb phrase ellipses (VPE)
is a subfield of ellipsis detection that has re-
ceived much attention. For VPE detection, re-
searchers have used machine learning algorithms
which were trained on grammar-parsed corpora,
for example in the works of Hardt (1997), Nielsen
(2004a), Nielsen (2004b), and Smith and Rauchas
(2006). Other approaches for ellipsis detection
rely on symbolic processing of sentences, which is
similar to our work. Haddar and Hamadou (1998)
present a method for ellipsis detection in the Ara-
bic language, which is based on an augmented
transition network grammar. Egg and Erk (2001)
present a general approach for ellipsis detection
and resolution that uses a language for partial de-
scription of λ-terms called Constraint Language
for Lambda Structures.
</bodyText>
<subsectionHeader confidence="0.9970235">
2.2 WordNet-based Semantic Similarity
Calculation
</subsectionHeader>
<bodyText confidence="0.992157875">
WordNet is used in many varied natural language
processing applications, such as word sense dis-
ambiguation, determining the structure of texts,
text summarisation and annotation, information
extraction and retrieval, automatic indexing, lexi-
cal selection, and the automatic correction of word
errors in text. In our work, we use WordNet
to find similar or synonym words. In previous
work, researchers have proposed several methods
to generally compute the semantic relatedness of
two words using WordNet. Budanitsky and Hirst
(2006) review methods to determine semantic re-
latedness. Newer examples for WordNet-based
calculation of semantic similarity are the works
by Qin et al. (2009), Cai et al. (2010), Liu et al.
(2012), and Wagh and Kolhe (2012).
</bodyText>
<subsectionHeader confidence="0.999537">
2.3 Spoken Language Processing
</subsectionHeader>
<bodyText confidence="0.99994064516129">
Our work addresses the processing of spoken lan-
guage, which differs from the processing of writ-
ten language in that spoken language is more of-
ten elliptical and grammatically incorrect. Previ-
ous work in this area has attempted to address this
issue at different levels of processing. Issar and
Ward (1993) presented the CMU speech process-
ing system that supports recognition for grammat-
ically ill-formed sentences. Lavie (1996) presents
GLR*, a grammar-based parser for spoken lan-
guage, which ignores unparseable words and sen-
tence parts and instead looks for the maximal sub-
set of an input sentence that is covered by the
grammar.
Other researchers in this area have designed
grammar-based approaches for incremental spo-
ken language processing: Brick and Scheutz
(2007) present RISE, the robotic incremental se-
mantic engine. RISE is able to process syntactic
and semantic information incrementally and to in-
tegrate this information with perceptual and lin-
guistic information. Kruijff et al. (2007) present
an approach for incremental processing of situ-
ated dialogue in human-robot interaction, which
maintains parallel interpretations of the current di-
alogue that are pruned by making use of the con-
text information. Schlangen and Skantze (2009)
describe a “general, abstract model of incremental
dialogue processing”, where their goal is to pro-
vide principles for designing new systems for in-
cremental speech processing.
</bodyText>
<page confidence="0.998773">
244
</page>
<sectionHeader confidence="0.997405" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999936727272727">
Our goal in this paper is to transform spoken utter-
ances which cannot be parsed by our grammar into
grammar-valid sentences. During this process, we
have to make sure that the changes to the input
sentence do not change its meaning. In this sec-
tion, we show how we implement ellipsis detec-
tion and semantic similarity computation in order
to achieve this goal. We present our ellipsis detec-
tion algorithm in Section 3.1. Section 3.2 explains
our implementation of WordNet-based word simi-
larity computation.
</bodyText>
<subsectionHeader confidence="0.999501">
3.1 Ellipsis Detection Algorithm
</subsectionHeader>
<bodyText confidence="0.999888648648649">
We use the OpenCCG parser (White, 2006), which
is based on Combinatory Categorial Grammar
(Kruijff and Baldridge, 2004; Steedman, 2000), to
parse the output of our speech recognition system.
We use the properties of CCGs to solve a prob-
lem that often occurs during parsing of spoken lan-
guage. In our evaluation (Section 4) we use a test
set (Section 4.1) of spoken sentences that was col-
lected during one of our human-robot interaction
studies (Foster et al., 2012) and the CCG (Sec-
tion 4.2) that was used in the same study. In the
test set, we found that speakers leave out words.
For example, one speaker said I want water to
order a drink. The grammar used in the experi-
ment assumed that every noun is specified by an
article; the grammar was only able to parse the
sentence I want a water. Just to remind you,
of course this particular example could have been
solved by rewriting the grammar, but at the time
of running the experiment it was not possible to
us to change the grammar. Furthermore, we argue
that there will always be examples of the above
described situation where experiment participants
use grammatical structures or words that cannot be
processed by the used grammar. Thus, we present
an algorithm that automatically finds ellipses in
sentences and suggests words from the grammar
that could be used to fill the ellipses.
To illustrate our approach, we will use the ex-
ample sentence give me a water. Example (1)
shows the words of the example sentence with
their assigned categories from the used CCG, and
Example (2) shows the parsed sentence. In the ex-
amples, we use the category symbols s for sen-
tence, n for noun, and np for noun phrase. In Ex-
ample (2) the symbol &gt; denotes the used CCG for-
ward application combinator.
</bodyText>
<listItem confidence="0.944202666666667">
(1) CCG lexicon entries
a. give:=s/np/np
b. me := np
c. a:=np/n
d. water := n
(2) Full parse of an example sentence
</listItem>
<figure confidence="0.6809914">
give me a water
s/np/np np np/n n
np
s/np
s
</figure>
<bodyText confidence="0.985813078947368">
The algorithm consists of two parts: (i) search
for ellipses in the sentence and selection of the
most relevant ellipsis, and (ii) computation of the
category for the word that will fill the chosen el-
lipsis.
(i) Ellipsis Search
In order to find the ellipsis in the sentence, our al-
gorithm assumes that to the left and to the right of
the ellipsis, the spoken utterance consists of sen-
tence parts that the grammar can parse. In our ex-
ample, these sentence parts would be I want to the
left of the ellipsis and water to the right. In order
to automatically find the sentence part to the right,
we use the following algorithm, which we present
in Listing 1 in a Java-style pseudo code: The al-
gorithm uses the method tokenize() to split up the
string that contains the utterance into an array of
single words. It then iterates through the array and
builds a new sentence of the words in the array,
using the method buildString(). This sentence is
then processed by the parser. If the parser finds
a parse for the sentence, the algorithm returns the
result. Otherwise it cuts off the first word of the
sentence and repeats the procedure. This way, the
algorithm searches for a parseable sentence part
for the given utterance from the left to the right un-
til it either finds the right-most parseable sentence
part or there are no more words to parse. In order
to find the left-most parseable sentence part, we
implemented a method findParseReverse(), which
parses sentence parts from right to left.
One has to consider that our method for ellip-
sis detection can falsely identify ellipses in cer-
tain sentence constellations. For example, if the
word like in the sentence I would like a water
is left out and given to our ellipsis detection al-
gorithm, it would falsely find an ellipsis between
I and would, and another ellipsis between would
</bodyText>
<page confidence="0.993108">
245
</page>
<figure confidence="0.638286769230769">
Listing 1: Ellipsis detection algorithm.
Result findParse ( String utterance) {
words[] = tokenize (utterance);
for ( i = 0; i &lt; words. length ; i ++) {
String sentence = buildString (words[
i ] , words . length) ;
Result parse = parse(sentence);
i f ( parse != null) {
return parse;
}
}
return null;
}
</figure>
<bodyText confidence="0.983473394736842">
and a. The reason for the detection of the first
ellipsis is that the categories for I and would can-
not be combined together. would and like have to
be parsed first to an auxiliary verb-verb construct.
This construct can then be combined with the pro-
noun I. To overcome this problem, we first com-
pute the category for each found ellipsis. Then we
find a word for the ellipsis with the simplest cate-
gory, which is either an atomic category or a func-
tional category with fewer functors than the other
found categories, add it to the original input sen-
tence, and parse the output sentence. If the output
sentence cannot be parsed, we repeat the step with
the next found ellipsis.
(ii) Ellipsis Category Computation
After the algorithm has determined the ellipsis in
an utterance, it computes the category of the word
that will fill the ellipsis. The goal here is to find a
category which the grammar needs to combine the
sentence parts to the left and right of the ellipsis.
For example, the left part of our example utterance
I want has the category s/np and the right part wa-
ter has the category n. Hence, the category for the
missing word needs to be np/n, because it takes
the category of the right sentence part as argument
and produces the category np, which is the argu-
ment of the category of the left sentence part.
Figure 2 shows the processing sequence dia-
gram of our algorithm for computing the category
of an ellipsis. In the diagram, left and right stand
for the categories of the sentence parts that are to
the left and right of the ellipsis. The predicates
symbolise functions: isEmpty(category) checks
if a category is empty, atom(category) checks
if a category is atomic, compl(category) checks
if a category is complex and has a slash oper-
ator that faces toward the ellipsis. The predi-
cate arg(category) returns the argument of a com-
</bodyText>
<figureCaption confidence="0.969408">
Figure 2: Processing sequence of the category
computation algorithm.
</figureCaption>
<bodyText confidence="0.99815475">
plex category. Rectangular boxes symbolise steps
where the algorithm builds the result category for
the missing word. The algorithm determines the
category with the following rules:
</bodyText>
<listItem confidence="0.9549725625">
• if the categories to the left or to the right of
the ellipsis are empty, the ellipsis category is
s/right or s\left, respectively,
• if the categories to the right and to the left of
the ellipsis are atomic, the ellipsis category is
s/right\left,
• if the categories to the right and to the left
of the ellipsis are both complex and have a
slash operator facing toward the ellipsis, the
ellipsis category is s/right\left,
• if the category to the left of the ellipsis is
atomic and to the right of the ellipsis is com-
plex, the ellipsis category is left\arg(right),
• if the category to the right of the ellipsis is
atomic and to the left of the ellipsis is com-
plex, the ellipsis category is arg(left)\right.
</listItem>
<bodyText confidence="0.999695333333333">
After the computation of the ellipsis category,
we use the OpenCCG grammar to select words to
fill the ellipsis. This step is straightforward, be-
cause the grammar maintains a separate word list
with corresponding categories. Here, we benefit
from the usage of a categorial grammar, as the
usage of a top-down grammar formalism would
have meant a more complicated computation in
this step.
</bodyText>
<subsectionHeader confidence="0.998521">
3.2 WordNet-based Word Substitution
</subsectionHeader>
<bodyText confidence="0.9904485">
Spoken language is versatile and there are many
ways to express one’s intentions by using differ-
</bodyText>
<figure confidence="0.98512736">
arg(left) / right
left \ arg(right)
false
isEmpty(left) isEmpty(right)
atom(right)
compl(left)
s / right
true
true
false
atom(left)
compl(right)
s \ left
true
true
false
false
s / right \ left
compl(left)
compl(right)
atom(left)
atom(right)
true
true
false
</figure>
<page confidence="0.997235">
246
</page>
<bodyText confidence="0.999936805555556">
ent expressions. Thus, in grammar-based spo-
ken language processing it often happens that sen-
tences cannot be parsed because of words that
are not in the grammar. To overcome this prob-
lem, we use WordNet (Miller, 1995) to find se-
mantically equivalent replacements for unknown
words. WordNet arranges words in sets of syn-
onyms called synsets which are connected to other
synsets by a variety of relations, which differ for
each word category. The most relevant relations
for our work are: for nouns and verbs hyperonyms
(e.g., drink is a hyperonym of juice) and hyponyms
(e.g., juice is a hyponym of drink), and for adjec-
tives we use the similar to relation.
Our implementation of word substitution exe-
cutes two steps if a word is unknown to the gram-
mar: (1) look-up of synonyms for the unknown
words. The unknown word can be substituted with
a semantically similar word directly, if the synset
of the unknown word contains a word, which is
known to the grammar. (2) Computation of simi-
lar words in the WordNet hyperonym/hyponym hi-
erarchy. If the synset of the unknown word does
not contain a substitution, we compute if one of
the hyperonyms of the unknown word has a hy-
ponym which is known to the grammar. Here, one
has to be careful not to move too far away from
the meaning of the unknown word in the Word-
Net tree, in order not to change the meaning of
the originally spoken sentence. Also, the compu-
tation of the similar word should not take too much
time. Therefore, in our implementation, we only
substitute an unknown word with one of its hyper-
onym/hyponym neighbours when the substitution
candidate is a direct hyponym of the direct hyper-
onym of the unknown word.
</bodyText>
<sectionHeader confidence="0.998855" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999430615384615">
The goal of this evaluation is to measure how
many spoken sentences that our grammar cannot
parse can be processed after the transformation of
the sentences with our methods. In Section 4.1
we present the test set of spoken sentences that we
used in the evaluation. In Section 4.2 we give de-
tails of the used grammar. As mentioned above,
both, the test set as well as the grammar, were
taken from the human-robot interaction study re-
ported by Foster et al. (2012). Section 4.3 sum-
marises the details of the evaluation procedure. Fi-
nally, we present the evaluation results in Section
4.4 and discuss their meaning in Section 4.5.
</bodyText>
<subsectionHeader confidence="0.999565">
4.1 Test Set
</subsectionHeader>
<bodyText confidence="0.9998316">
As test set for the evaluation, we used the spo-
ken utterances from the participants of the human-
robot interaction experiment reported by Foster et
al. (2012). In the experiment, 31 participants were
asked to order a drink from the robot bartender
shown in Figure 1. The experiment consisted of
three parts: in the first part, participants had to or-
der drinks on their own, in the second and third
part, participants were accompanied by a confed-
erate in order to have a multi-party interaction with
the robot. The spoken utterances in the test set
were annotated by hand from video recordings of
the 93 drink order sequences. Please refer to (Fos-
ter et al., 2012) for a detailed description of the
experiment.
Table 1 shows an overview of the test set. In
total, it contains 211 unique utterances; the exper-
iment participants spoke 531 sentences of which
some sentences were said repeatedly. We di-
vided the test set into the following speech acts
(Searle, 1965): Ordering (“I would like a juice
please.”), Question (“What do you have?”), Greet-
ing (“Hello there.”), Polite expression (“Thank
you.”), Confirmation (“Yes.”), Other (“I am
thirsty.”).
</bodyText>
<subsectionHeader confidence="0.900036">
4.2 Grammar
</subsectionHeader>
<bodyText confidence="0.999995909090909">
The grammar that we used in this evaluation was
also used in the robot bartender experiment (Fos-
ter et al., 2012). This grammar is limited in its
scope, because the domain of the experiment—the
robot hands out drinks to customers—was limited
as well. Overall, the lexicon of the grammar con-
tains 92 words, which are divided into the follow-
ing part of speech classes: 42 verbs, 11 nouns, 10
greetings, 6 pronouns, 5 prepositions, 4 adverbs, 4
determiners, 3 quantifiers, 3 confirmations, 2 rela-
tive pronouns, 1 conjunction, 1 polite expression.
</bodyText>
<subsectionHeader confidence="0.997074">
4.3 Procedure
</subsectionHeader>
<bodyText confidence="0.9984633">
For the evaluation, we implemented a programme
that takes our test set and automatically parses
each sentence with four different settings, which
are also presented in Table 1: (1) parsing with
the grammar only, (2) application of ellipsis de-
tection and word filling before parsing, (3) appli-
cation of WordNet similarity substitution before
parsing, (4) application of a combination of both
methods before parsing. Please note that for al-
ternative (4) the sequence in which the methods
</bodyText>
<page confidence="0.993297">
247
</page>
<table confidence="0.99925675">
Speech act No. utt (1) CCG (2) Ell. det. (3) WordNet (4) Ell. + WordNet
Ordering 143 34 16 - 1
Question 19 1 - - -
Greeting 18 4 1 - -
Polite expression 14 1 - - -
Confirmation 5 4 - - -
Other 12 - - - -
Total 211 44 17 - 1
</table>
<tableCaption confidence="0.73317775">
Table 1: Overview for test set and evaluation. Column No. utt contains the number of test utterances
per speech act. Column (1) CCG shows the number of utterances that were directly parsed by the
grammar. Columns (2) Ell. det., (3) WordNet, and (4) Ell. + WordNet show how many utterances were
additionally parsed using the ellipsis detection, WordNet substitution, and combination of both modules.
</tableCaption>
<bodyText confidence="0.9978866">
are applied to a given sentence can make a differ-
ence to the parsing result. In this evaluation, we
used both possible sequences: first ellipsis detec-
tion followed by WordNet substitution method or
vice versa.
</bodyText>
<subsectionHeader confidence="0.737281">
4.4 Results
</subsectionHeader>
<bodyText confidence="0.999964666666667">
Table 1 shows the result of the evaluation proce-
dure. The grammar parses 44 sentences of the
211 test set sentences correctly. By using the el-
lipsis detection algorithm, 17 additional sentences
are parsed. The usage of the WordNet substitution
algorithm yields no additionally parsed sentences.
The combination of both methods (in this case,
first ellipsis detection, then WordNet substitution)
leads to the correct parse of one additional sen-
tence. None of the transformed sentences changed
its meaning when compared to the original sen-
tence.
</bodyText>
<subsectionHeader confidence="0.938601">
4.5 Discussion
</subsectionHeader>
<bodyText confidence="0.999511909090909">
The evaluation results show that the application
of our ellipsis detection algorithm leads to an in-
crease of successfully parsed sentences of 38.64%.
In the class of ordering sentences, which was the
most relevant for the human-robot interaction ex-
periment from which we used the evaluation test
set, the number of successfully parsed sentences
increases by 47.06%. Compared to this, the us-
age of WordNet substitution alone does not lead to
an increase in parseable sentences. The one case
in which the combination of ellipsis detection and
WordNet substitution transformed an unparseable
sentence into a grammatically valid sentence is in-
teresting: here, the experiment participant said “I
need Coke.” to order a drink from the robot. This
sentence contained the word “need”, which was
not in the grammar. WordNet has the synonym
“want” in the synset for the word “need”. How-
ever, the sentence “I want Coke.” was also not
parseable, because the grammar expected an arti-
cle in front of every noun. The ellipsis detection
algorithm was able to find the missing article in the
sentence and filled it with an article “a” from the
grammar, leading to a parseable sentence “I want
a Coke.”.
Although we see an increase in parsed sen-
tences, 150 sentences of the test set were not trans-
formed by our approach. Therefore, we made an
analysis for the remaining utterances to find the
main causes for this weak performance. We found
that the following reasons cause problems for the
grammar (with number of cases in brackets behind
each reason):
</bodyText>
<listItem confidence="0.530263263157895">
• Word missing in grammar (81). The partic-
ipant used a word that was not in the gram-
mar. For example, users ordered drinks by
saying “One water, please.” , but the gram-
mar did not contain “one” as an article. This
result shows that the WordNet similarity sub-
stitution has the potential to lead to a large
increase in parseable sentences. However as
mentioned above, there is a risk of changing
the meaning of a sentence too much when al-
lowing the replacement of words which are
only vaguely similar to the unknown word.
• Sentence structure (25). Some participants
said sentences that were either grammatically
incorrect or had a sentence structure that was
not encoded in the grammar. For example
one participant tried to order a juice by saying
“Juice for me.”. Additionally, some partici-
pants asked questions (“Do you have coke?”).
</listItem>
<page confidence="0.995116">
248
</page>
<bodyText confidence="0.9998894">
For the latter, please note that it was not part
of the HRI experiment, from which we use
the test set, that the experiment participants
should be allowed to ask questions to the
robot.
</bodyText>
<listItem confidence="0.514494333333333">
• Unnecessary fill words (22). Some experi-
ment participants used unnecessary fill words
that did not add meaning to the sentence, for
example one participant said “Oh come on, I
only need water” to order a drink.
• Sentence not related to domain (22). Some
</listItem>
<bodyText confidence="0.798881555555556">
participants said sentences that were contrary
to the given experiment instructions. For ex-
ample, some participants asked questions to
the robot (“How old are you?”) and to the ex-
perimenter (“Do I need to focus on the cam-
era?”), or complained about the robot’s per-
formance (“You are not quite responsive right
now.”). Clearly, these sentences were out of
the scope of the grammar.
</bodyText>
<sectionHeader confidence="0.998477" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99999634">
We presented two methods for transforming spo-
ken language into grammatically correct sen-
tences. The first of these two approaches is an
ellipsis detection, which automatically detects el-
lipses in sentences and looks up words in a gram-
mar that can fill the ellipsis. Our ellipsis de-
tection algorithm is based on the properties of
the combinatory categorial grammar, which as-
signs categories to each word in the grammar
and thus enables the algorithm to find suitable fill
words by calculating the category of the ellipsis.
The second approach for sentence transformation
was a WordNet-based word similarity computa-
tion and substitution. Here, we used the synsets of
WordNet to substitute words that are unknown to a
given grammar with synonyms for these words. In
an evaluation we showed that the usage of ellip-
sis detection leads to an increase of successfully
parsed sentences of up to 47.06% for some speech
acts. The usage of the WordNet similarity substi-
tution does not increase the number of parsed sen-
tences, although our analysis of the test set shows
that unknown words are the most common reason
that sentences cannot be parsed.
Our approach was specifically implemented to
help circumventing problems during development
and usage of grammars for spoken language pro-
cessing in human-robot interaction experiments,
and the example grammar was a very restricted
one. However, we believe that our method can
also be helpful with more extensive grammars, and
for developers of dialogue systems in other ar-
eas, such as telephone-based information systems
or offline versions of automatic smartphone assis-
tants like Apple’s Siri.
In the future, we will refine our methodology.
In particular, the WordNet similarity substitution
is too rigid in its current form. Here, we plan
to loosen some of the constraints that we ap-
plied to our algorithm. We will systematically test
how far away from a word one can look for suit-
able substitutes in the WordNet hierarchy, with-
out losing the meaning of a sentence. Further-
more, we plan to add a dialogue history to our
approach, which will provide an additional source
of information—besides the grammar—to the el-
lipsis detection method. Finally, we plan to work
with stop word lists to filter unnecessary fill words
from the input sentences, since these proved also
to be a reason for sentences to be unparseable.
</bodyText>
<sectionHeader confidence="0.994729" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999458333333333">
This research was supported by the European
Commission through the project JAMES (FP7-
270435-STREP).
</bodyText>
<sectionHeader confidence="0.99284" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.966110954545455">
Timothy Brick and Matthias Scheutz. 2007. Incre-
mental natural language processing for hri. In Pro-
ceedings of the ACM/IEEE International Confer-
ence on Human-Robot Interaction, pages 263–270.
ACM New York, NY, USA.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating wordnet-based measures of lexical semantic
relatedness. Computational Linguistics, 32(1):13–
47.
Songmei Cai, Zhao Lu, and Junzhong Gu. 2010. An
effective measure of semantic similarity. In Ad-
vances in Wireless Networks and Information Sys-
tems, pages 9–17. Springer.
Markus Egg and Katrin Erk. 2001. A compositional
account of vp ellipsis. Technology, 3:5.
Mary Ellen Foster, Andre Gaschler, Manuel Giuliani,
Amy Isard, Maria Pateraki, and Ronald P. A. Pet-
rick. 2012. Two people walk into a bar: Dynamic
multi-party social interaction with a robot agent. In
Proceedings of the 14th ACM International Confer-
ence on Multimodal Interaction (ICMI 2012), Octo-
ber.
</reference>
<page confidence="0.982112">
249
</page>
<reference confidence="0.999910133333333">
Manuel Giuliani, Ronald P.A. Petrick, Mary Ellen Fos-
ter, Andre Gaschler, Amy Isard, Maria Pateraki, and
Markos Sigalas. 2013. Comparing task-based and
socially intelligent behaviour in a robot bartender. In
Proceedings of the 15th International Conference on
Multimodal Interfaces (ICMI 2013), Sydney, Aus-
tralia, December.
Kais Haddar and A Ben Hamadou. 1998. An ellip-
sis detection method based on a clause parser for
the arabic language. In Proceedings of the Interna-
tional Florida Artificial Intelligence Research Soci-
ety FLAIRS98, pages 270–274.
Daniel Hardt. 1997. An empirical approach to vp el-
lipsis. Computational Linguistics, 23(4):525–541.
Sunil Issar and Wayne Ward. 1993. Cmu’s robust spo-
ken language understanding system. In Proceedings
of the Third European Conference on Speech Com-
munication and Technology (Eurospeech 1993).
Simon Keizer, Mary Ellen Foster, Oliver Lemon, An-
dre Gaschler, and Manuel Giuliani. 2013. Training
and evaluation of an MDP model for social multi-
user human-robot interaction. In Proceedings of the
SIGDIAL 2013 Conference, pages 223–232, Metz,
France, August.
Geert-Jan M. Kruijff and Jason Baldridge. 2004. Gen-
eralizing dimensionality in combinatory categorial
grammar. In Proceedings of the 20th International
Conference on Computational Linguistics (COLING
2004), Geneva, Switzerland, August.
Geert-Jan M. Kruijff, Pierre Lison, Trevor Benjamin,
Henrik Jacobsson, and Nick Hawes. 2007. In-
cremental, multi-level processing for comprehend-
ing situated dialogue in human-robot interaction. In
Luis Seabra Lopes, Tony Belpaeme, and Stephen J.
Cowley, editors, Symposium on Language and
Robots (LangRo 2007), Aveiro, Portugal, December.
Shalom Lappin. 1996. The interpretation of ellipsis.
The Handbook of Contemporary Semantic Theory,
397:399.
Alon Lavie. 1996. GLR*: A Robust Grammar-
Focused Parser for Spontaneously Spoken Lan-
guage. Ph.D. thesis, Carnegie Mellon University.
Hongzhe Liu, Hong Bao, and De Xu. 2012. Concept
vector for semantic similarity and relatedness based
on wordnet structure. Journal of Systems and Soft-
ware, 85(2):370–381.
George A. Miller. 1995. Wordnet: A lexical
database for english. Communications of the ACM,
38(11):39–41.
Leif Arda Nielsen. 2004a. Verb phrase ellipsis detec-
tion using automatically parsed text. In Proceedings
of the 20th International Conference on Computa-
tional Linguistics, page 1093. Association for Com-
putational Linguistics.
Leif Arda Nielsen. 2004b. Verb phrase ellipsis detec-
tion using machine learning techniques. Amsterdam
Studies in the Theory and History of Linguistic Sci-
ence, page 317.
Peng Qin, Zhao Lu, Yu Yan, and Fang Wu. 2009. A
new measure of word semantic similarity based on
wordnet hierarchy and dag theory. In Proceedings
of the International Conference on Web Information
Systems and Mining2009 (WISM 2009), pages 181–
185. IEEE.
David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue pro-
cessing. In Proceedings of the 12th Conference of
the European Chapter of the Association for Com-
putational Linguistics (EACL-09).
John R. Searle. 1965. What is a speech act? In
Robert J. Stainton, editor, Perspectives in the Phi-
losophy of Language: A Concise Anthology, pages
253–268.
Lindsey Smith and Sarah Rauchas. 2006. A machine-
learning approach for the treatment of vp ellipsis.
In Proceedings of the Seventeenth Annual Sympo-
sium of the Pattern Recognition Association of South
Africa, November.
Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, MA, USA.
Kishor Wagh and Satish Kolhe. 2012. A new approach
for measuring semantic similarity in ontology and
its application in information retrieval. In Multi-
disciplinary Trends in Artificial Intelligence, pages
122–132. Springer.
Michael White. 2006. CCG chart realization from dis-
junctive inputs. In Proceedings of the Fourth Inter-
national Natural Language Generation Conference,
pages 12–19, Sydney, Australia, July. Association
for Computational Linguistics.
</reference>
<page confidence="0.997143">
250
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.642222">
<title confidence="0.9998305">Using Ellipsis Detection and Word Similarity for Transformation of Spoken Language into Grammatically Valid Sentences</title>
<author confidence="0.999893">Manuel Giuliani Thomas Marschall Amy Isard</author>
<affiliation confidence="0.998702">fortiss GmbH fortiss GmbH University of Edinburgh</affiliation>
<address confidence="0.664992">Munich, Germany Munich, Germany Edinburgh,</address>
<email confidence="0.991495">giuliani@fortiss.orgmarschat@in.tum.deamyi@inf.ed.ac.uk</email>
<abstract confidence="0.998799086956522">When humans speak they often use grammatically incorrect sentences, which is a problem for grammar-based language processing methods, since they expect input that is valid for the grammar. We present two methods to transform spoken language into grammatically correct sentences. The first is an algorithm for automatic ellipsis detection, which finds ellipses in spoken sentences and searches in a combinatory categorial grammar for suitable words to fill the ellipses. The second method is an algorithm that computes the semantic similarity of two words using WordNet, which we use to find alternatives to words that are unknown to the grammar. In an evaluation, we show that the usage of these two methods leads to an increase of 38.64% more parseable sentences on a test set of spoken sentences that were collected during a human-robot interaction experiment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Brick</author>
<author>Matthias Scheutz</author>
</authors>
<title>Incremental natural language processing for hri.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction,</booktitle>
<pages>263--270</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6951" citStr="Brick and Scheutz (2007)" startWordPosition="1121" endWordPosition="1124">elliptical and grammatically incorrect. Previous work in this area has attempted to address this issue at different levels of processing. Issar and Ward (1993) presented the CMU speech processing system that supports recognition for grammatically ill-formed sentences. Lavie (1996) presents GLR*, a grammar-based parser for spoken language, which ignores unparseable words and sentence parts and instead looks for the maximal subset of an input sentence that is covered by the grammar. Other researchers in this area have designed grammar-based approaches for incremental spoken language processing: Brick and Scheutz (2007) present RISE, the robotic incremental semantic engine. RISE is able to process syntactic and semantic information incrementally and to integrate this information with perceptual and linguistic information. Kruijff et al. (2007) present an approach for incremental processing of situated dialogue in human-robot interaction, which maintains parallel interpretations of the current dialogue that are pruned by making use of the context information. Schlangen and Skantze (2009) describe a “general, abstract model of incremental dialogue processing”, where their goal is to provide principles for desi</context>
</contexts>
<marker>Brick, Scheutz, 2007</marker>
<rawString>Timothy Brick and Matthias Scheutz. 2007. Incremental natural language processing for hri. In Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction, pages 263–270. ACM New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating wordnet-based measures of lexical semantic relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<pages>47</pages>
<contexts>
<context position="5930" citStr="Budanitsky and Hirst (2006)" startWordPosition="959" endWordPosition="962">d Constraint Language for Lambda Structures. 2.2 WordNet-based Semantic Similarity Calculation WordNet is used in many varied natural language processing applications, such as word sense disambiguation, determining the structure of texts, text summarisation and annotation, information extraction and retrieval, automatic indexing, lexical selection, and the automatic correction of word errors in text. In our work, we use WordNet to find similar or synonym words. In previous work, researchers have proposed several methods to generally compute the semantic relatedness of two words using WordNet. Budanitsky and Hirst (2006) review methods to determine semantic relatedness. Newer examples for WordNet-based calculation of semantic similarity are the works by Qin et al. (2009), Cai et al. (2010), Liu et al. (2012), and Wagh and Kolhe (2012). 2.3 Spoken Language Processing Our work addresses the processing of spoken language, which differs from the processing of written language in that spoken language is more often elliptical and grammatically incorrect. Previous work in this area has attempted to address this issue at different levels of processing. Issar and Ward (1993) presented the CMU speech processing system </context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating wordnet-based measures of lexical semantic relatedness. Computational Linguistics, 32(1):13– 47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Songmei Cai</author>
<author>Zhao Lu</author>
<author>Junzhong Gu</author>
</authors>
<title>An effective measure of semantic similarity.</title>
<date>2010</date>
<booktitle>In Advances in Wireless Networks and Information Systems,</booktitle>
<pages>9--17</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6102" citStr="Cai et al. (2010)" startWordPosition="986" endWordPosition="989">ense disambiguation, determining the structure of texts, text summarisation and annotation, information extraction and retrieval, automatic indexing, lexical selection, and the automatic correction of word errors in text. In our work, we use WordNet to find similar or synonym words. In previous work, researchers have proposed several methods to generally compute the semantic relatedness of two words using WordNet. Budanitsky and Hirst (2006) review methods to determine semantic relatedness. Newer examples for WordNet-based calculation of semantic similarity are the works by Qin et al. (2009), Cai et al. (2010), Liu et al. (2012), and Wagh and Kolhe (2012). 2.3 Spoken Language Processing Our work addresses the processing of spoken language, which differs from the processing of written language in that spoken language is more often elliptical and grammatically incorrect. Previous work in this area has attempted to address this issue at different levels of processing. Issar and Ward (1993) presented the CMU speech processing system that supports recognition for grammatically ill-formed sentences. Lavie (1996) presents GLR*, a grammar-based parser for spoken language, which ignores unparseable words an</context>
</contexts>
<marker>Cai, Lu, Gu, 2010</marker>
<rawString>Songmei Cai, Zhao Lu, and Junzhong Gu. 2010. An effective measure of semantic similarity. In Advances in Wireless Networks and Information Systems, pages 9–17. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Egg</author>
<author>Katrin Erk</author>
</authors>
<title>A compositional account of vp ellipsis.</title>
<date>2001</date>
<journal>Technology,</journal>
<volume>3</volume>
<contexts>
<context position="5176" citStr="Egg and Erk (2001)" startWordPosition="851" endWordPosition="854">ce. The detection of verb phrase ellipses (VPE) is a subfield of ellipsis detection that has received much attention. For VPE detection, researchers have used machine learning algorithms which were trained on grammar-parsed corpora, for example in the works of Hardt (1997), Nielsen (2004a), Nielsen (2004b), and Smith and Rauchas (2006). Other approaches for ellipsis detection rely on symbolic processing of sentences, which is similar to our work. Haddar and Hamadou (1998) present a method for ellipsis detection in the Arabic language, which is based on an augmented transition network grammar. Egg and Erk (2001) present a general approach for ellipsis detection and resolution that uses a language for partial description of λ-terms called Constraint Language for Lambda Structures. 2.2 WordNet-based Semantic Similarity Calculation WordNet is used in many varied natural language processing applications, such as word sense disambiguation, determining the structure of texts, text summarisation and annotation, information extraction and retrieval, automatic indexing, lexical selection, and the automatic correction of word errors in text. In our work, we use WordNet to find similar or synonym words. In prev</context>
</contexts>
<marker>Egg, Erk, 2001</marker>
<rawString>Markus Egg and Katrin Erk. 2001. A compositional account of vp ellipsis. Technology, 3:5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Ellen Foster</author>
<author>Andre Gaschler</author>
<author>Manuel Giuliani</author>
<author>Amy Isard</author>
<author>Maria Pateraki</author>
<author>Ronald P A Petrick</author>
</authors>
<title>Two people walk into a bar: Dynamic multi-party social interaction with a robot agent.</title>
<date>2012</date>
<booktitle>In Proceedings of the 14th ACM International Conference on Multimodal Interaction (ICMI</booktitle>
<contexts>
<context position="1973" citStr="Foster et al., 2012" startWordPosition="309" endWordPosition="312"> example the robot bartender JAMES (Joint Action for Multimodal Embodied Social Systems),1 shown in Figure 1. The robot is able to take drink orders from customers and to serve drinks. It is equipped with automatic speech recognition, to understand what the human is saying, and it has a grammar, to parse and process the spoken utterances. The JAMES robot grammar was initially very restricted, and therefore during grammar development as well as during the user studies that 1http://www.james-project.eu Figure 1: The robot bartender of the JAMES project interacting with a customer. we conducted (Foster et al., 2012; Giuliani et al., 2013; Keizer et al., 2013), we experienced situations in which the robot was not able to process the spoken input by humans, because they spoke sentences with grammatical structures that could not be parsed by the grammar, they used words that were not part of the grammar, or they left out words. We had for example cases where humans approached the robot and used a sentence with an ellipsis (“I want Coke”, but the grammar expected a determiner in front of “Coke”) or a sentence with a word that was unknown to the grammar (“I need a water”, but “need” was not part of the gramm</context>
<context position="8624" citStr="Foster et al., 2012" startWordPosition="1388" endWordPosition="1391">detection algorithm in Section 3.1. Section 3.2 explains our implementation of WordNet-based word similarity computation. 3.1 Ellipsis Detection Algorithm We use the OpenCCG parser (White, 2006), which is based on Combinatory Categorial Grammar (Kruijff and Baldridge, 2004; Steedman, 2000), to parse the output of our speech recognition system. We use the properties of CCGs to solve a problem that often occurs during parsing of spoken language. In our evaluation (Section 4) we use a test set (Section 4.1) of spoken sentences that was collected during one of our human-robot interaction studies (Foster et al., 2012) and the CCG (Section 4.2) that was used in the same study. In the test set, we found that speakers leave out words. For example, one speaker said I want water to order a drink. The grammar used in the experiment assumed that every noun is specified by an article; the grammar was only able to parse the sentence I want a water. Just to remind you, of course this particular example could have been solved by rewriting the grammar, but at the time of running the experiment it was not possible to us to change the grammar. Furthermore, we argue that there will always be examples of the above describ</context>
<context position="17943" citStr="Foster et al. (2012)" startWordPosition="3030" endWordPosition="3033">d with one of its hyperonym/hyponym neighbours when the substitution candidate is a direct hyponym of the direct hyperonym of the unknown word. 4 Evaluation The goal of this evaluation is to measure how many spoken sentences that our grammar cannot parse can be processed after the transformation of the sentences with our methods. In Section 4.1 we present the test set of spoken sentences that we used in the evaluation. In Section 4.2 we give details of the used grammar. As mentioned above, both, the test set as well as the grammar, were taken from the human-robot interaction study reported by Foster et al. (2012). Section 4.3 summarises the details of the evaluation procedure. Finally, we present the evaluation results in Section 4.4 and discuss their meaning in Section 4.5. 4.1 Test Set As test set for the evaluation, we used the spoken utterances from the participants of the humanrobot interaction experiment reported by Foster et al. (2012). In the experiment, 31 participants were asked to order a drink from the robot bartender shown in Figure 1. The experiment consisted of three parts: in the first part, participants had to order drinks on their own, in the second and third part, participants were </context>
<context position="19393" citStr="Foster et al., 2012" startWordPosition="3274" endWordPosition="3278"> al., 2012) for a detailed description of the experiment. Table 1 shows an overview of the test set. In total, it contains 211 unique utterances; the experiment participants spoke 531 sentences of which some sentences were said repeatedly. We divided the test set into the following speech acts (Searle, 1965): Ordering (“I would like a juice please.”), Question (“What do you have?”), Greeting (“Hello there.”), Polite expression (“Thank you.”), Confirmation (“Yes.”), Other (“I am thirsty.”). 4.2 Grammar The grammar that we used in this evaluation was also used in the robot bartender experiment (Foster et al., 2012). This grammar is limited in its scope, because the domain of the experiment—the robot hands out drinks to customers—was limited as well. Overall, the lexicon of the grammar contains 92 words, which are divided into the following part of speech classes: 42 verbs, 11 nouns, 10 greetings, 6 pronouns, 5 prepositions, 4 adverbs, 4 determiners, 3 quantifiers, 3 confirmations, 2 relative pronouns, 1 conjunction, 1 polite expression. 4.3 Procedure For the evaluation, we implemented a programme that takes our test set and automatically parses each sentence with four different settings, which are also </context>
</contexts>
<marker>Foster, Gaschler, Giuliani, Isard, Pateraki, Petrick, 2012</marker>
<rawString>Mary Ellen Foster, Andre Gaschler, Manuel Giuliani, Amy Isard, Maria Pateraki, and Ronald P. A. Petrick. 2012. Two people walk into a bar: Dynamic multi-party social interaction with a robot agent. In Proceedings of the 14th ACM International Conference on Multimodal Interaction (ICMI 2012), October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuel Giuliani</author>
<author>Ronald P A Petrick</author>
<author>Mary Ellen Foster</author>
<author>Andre Gaschler</author>
<author>Amy Isard</author>
<author>Maria Pateraki</author>
<author>Markos Sigalas</author>
</authors>
<title>Comparing task-based and socially intelligent behaviour in a robot bartender.</title>
<date>2013</date>
<booktitle>In Proceedings of the 15th International Conference on Multimodal Interfaces (ICMI 2013),</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="1996" citStr="Giuliani et al., 2013" startWordPosition="313" endWordPosition="316">rtender JAMES (Joint Action for Multimodal Embodied Social Systems),1 shown in Figure 1. The robot is able to take drink orders from customers and to serve drinks. It is equipped with automatic speech recognition, to understand what the human is saying, and it has a grammar, to parse and process the spoken utterances. The JAMES robot grammar was initially very restricted, and therefore during grammar development as well as during the user studies that 1http://www.james-project.eu Figure 1: The robot bartender of the JAMES project interacting with a customer. we conducted (Foster et al., 2012; Giuliani et al., 2013; Keizer et al., 2013), we experienced situations in which the robot was not able to process the spoken input by humans, because they spoke sentences with grammatical structures that could not be parsed by the grammar, they used words that were not part of the grammar, or they left out words. We had for example cases where humans approached the robot and used a sentence with an ellipsis (“I want Coke”, but the grammar expected a determiner in front of “Coke”) or a sentence with a word that was unknown to the grammar (“I need a water”, but “need” was not part of the grammar’s word list). In the</context>
</contexts>
<marker>Giuliani, Petrick, Foster, Gaschler, Isard, Pateraki, Sigalas, 2013</marker>
<rawString>Manuel Giuliani, Ronald P.A. Petrick, Mary Ellen Foster, Andre Gaschler, Amy Isard, Maria Pateraki, and Markos Sigalas. 2013. Comparing task-based and socially intelligent behaviour in a robot bartender. In Proceedings of the 15th International Conference on Multimodal Interfaces (ICMI 2013), Sydney, Australia, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kais Haddar</author>
<author>A Ben Hamadou</author>
</authors>
<title>An ellipsis detection method based on a clause parser for the arabic language.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Florida Artificial Intelligence Research Society FLAIRS98,</booktitle>
<pages>270--274</pages>
<contexts>
<context position="5034" citStr="Haddar and Hamadou (1998)" startWordPosition="827" endWordPosition="830"> such as the words “want to have” in the sentence “I want to have a water, and my friend a juice”, which are omitted in the second part of the sentence. The detection of verb phrase ellipses (VPE) is a subfield of ellipsis detection that has received much attention. For VPE detection, researchers have used machine learning algorithms which were trained on grammar-parsed corpora, for example in the works of Hardt (1997), Nielsen (2004a), Nielsen (2004b), and Smith and Rauchas (2006). Other approaches for ellipsis detection rely on symbolic processing of sentences, which is similar to our work. Haddar and Hamadou (1998) present a method for ellipsis detection in the Arabic language, which is based on an augmented transition network grammar. Egg and Erk (2001) present a general approach for ellipsis detection and resolution that uses a language for partial description of λ-terms called Constraint Language for Lambda Structures. 2.2 WordNet-based Semantic Similarity Calculation WordNet is used in many varied natural language processing applications, such as word sense disambiguation, determining the structure of texts, text summarisation and annotation, information extraction and retrieval, automatic indexing,</context>
</contexts>
<marker>Haddar, Hamadou, 1998</marker>
<rawString>Kais Haddar and A Ben Hamadou. 1998. An ellipsis detection method based on a clause parser for the arabic language. In Proceedings of the International Florida Artificial Intelligence Research Society FLAIRS98, pages 270–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Hardt</author>
</authors>
<title>An empirical approach to vp ellipsis.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>4</issue>
<contexts>
<context position="4831" citStr="Hardt (1997)" startWordPosition="799" endWordPosition="800"> of ellipses are widely defined, such as gapping, stripping or verb phrase ellipsis (Lappin, 1996). For example, an ellipsis occurs when a redundant word is left out of succeeding sentences, such as the words “want to have” in the sentence “I want to have a water, and my friend a juice”, which are omitted in the second part of the sentence. The detection of verb phrase ellipses (VPE) is a subfield of ellipsis detection that has received much attention. For VPE detection, researchers have used machine learning algorithms which were trained on grammar-parsed corpora, for example in the works of Hardt (1997), Nielsen (2004a), Nielsen (2004b), and Smith and Rauchas (2006). Other approaches for ellipsis detection rely on symbolic processing of sentences, which is similar to our work. Haddar and Hamadou (1998) present a method for ellipsis detection in the Arabic language, which is based on an augmented transition network grammar. Egg and Erk (2001) present a general approach for ellipsis detection and resolution that uses a language for partial description of λ-terms called Constraint Language for Lambda Structures. 2.2 WordNet-based Semantic Similarity Calculation WordNet is used in many varied na</context>
</contexts>
<marker>Hardt, 1997</marker>
<rawString>Daniel Hardt. 1997. An empirical approach to vp ellipsis. Computational Linguistics, 23(4):525–541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunil Issar</author>
<author>Wayne Ward</author>
</authors>
<title>Cmu’s robust spoken language understanding system.</title>
<date>1993</date>
<booktitle>In Proceedings of the Third European Conference on Speech Communication and Technology (Eurospeech</booktitle>
<contexts>
<context position="6486" citStr="Issar and Ward (1993)" startWordPosition="1050" endWordPosition="1053">latedness of two words using WordNet. Budanitsky and Hirst (2006) review methods to determine semantic relatedness. Newer examples for WordNet-based calculation of semantic similarity are the works by Qin et al. (2009), Cai et al. (2010), Liu et al. (2012), and Wagh and Kolhe (2012). 2.3 Spoken Language Processing Our work addresses the processing of spoken language, which differs from the processing of written language in that spoken language is more often elliptical and grammatically incorrect. Previous work in this area has attempted to address this issue at different levels of processing. Issar and Ward (1993) presented the CMU speech processing system that supports recognition for grammatically ill-formed sentences. Lavie (1996) presents GLR*, a grammar-based parser for spoken language, which ignores unparseable words and sentence parts and instead looks for the maximal subset of an input sentence that is covered by the grammar. Other researchers in this area have designed grammar-based approaches for incremental spoken language processing: Brick and Scheutz (2007) present RISE, the robotic incremental semantic engine. RISE is able to process syntactic and semantic information incrementally and to</context>
</contexts>
<marker>Issar, Ward, 1993</marker>
<rawString>Sunil Issar and Wayne Ward. 1993. Cmu’s robust spoken language understanding system. In Proceedings of the Third European Conference on Speech Communication and Technology (Eurospeech 1993).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Keizer</author>
<author>Mary Ellen Foster</author>
<author>Oliver Lemon</author>
<author>Andre Gaschler</author>
<author>Manuel Giuliani</author>
</authors>
<title>Training and evaluation of an MDP model for social multiuser human-robot interaction.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<pages>223--232</pages>
<location>Metz, France,</location>
<contexts>
<context position="2018" citStr="Keizer et al., 2013" startWordPosition="317" endWordPosition="320">tion for Multimodal Embodied Social Systems),1 shown in Figure 1. The robot is able to take drink orders from customers and to serve drinks. It is equipped with automatic speech recognition, to understand what the human is saying, and it has a grammar, to parse and process the spoken utterances. The JAMES robot grammar was initially very restricted, and therefore during grammar development as well as during the user studies that 1http://www.james-project.eu Figure 1: The robot bartender of the JAMES project interacting with a customer. we conducted (Foster et al., 2012; Giuliani et al., 2013; Keizer et al., 2013), we experienced situations in which the robot was not able to process the spoken input by humans, because they spoke sentences with grammatical structures that could not be parsed by the grammar, they used words that were not part of the grammar, or they left out words. We had for example cases where humans approached the robot and used a sentence with an ellipsis (“I want Coke”, but the grammar expected a determiner in front of “Coke”) or a sentence with a word that was unknown to the grammar (“I need a water”, but “need” was not part of the grammar’s word list). In these cases, the robot wa</context>
</contexts>
<marker>Keizer, Foster, Lemon, Gaschler, Giuliani, 2013</marker>
<rawString>Simon Keizer, Mary Ellen Foster, Oliver Lemon, Andre Gaschler, and Manuel Giuliani. 2013. Training and evaluation of an MDP model for social multiuser human-robot interaction. In Proceedings of the SIGDIAL 2013 Conference, pages 223–232, Metz, France, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert-Jan M Kruijff</author>
<author>Jason Baldridge</author>
</authors>
<title>Generalizing dimensionality in combinatory categorial grammar.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="8277" citStr="Kruijff and Baldridge, 2004" startWordPosition="1327" endWordPosition="1330">ansform spoken utterances which cannot be parsed by our grammar into grammar-valid sentences. During this process, we have to make sure that the changes to the input sentence do not change its meaning. In this section, we show how we implement ellipsis detection and semantic similarity computation in order to achieve this goal. We present our ellipsis detection algorithm in Section 3.1. Section 3.2 explains our implementation of WordNet-based word similarity computation. 3.1 Ellipsis Detection Algorithm We use the OpenCCG parser (White, 2006), which is based on Combinatory Categorial Grammar (Kruijff and Baldridge, 2004; Steedman, 2000), to parse the output of our speech recognition system. We use the properties of CCGs to solve a problem that often occurs during parsing of spoken language. In our evaluation (Section 4) we use a test set (Section 4.1) of spoken sentences that was collected during one of our human-robot interaction studies (Foster et al., 2012) and the CCG (Section 4.2) that was used in the same study. In the test set, we found that speakers leave out words. For example, one speaker said I want water to order a drink. The grammar used in the experiment assumed that every noun is specified by </context>
</contexts>
<marker>Kruijff, Baldridge, 2004</marker>
<rawString>Geert-Jan M. Kruijff and Jason Baldridge. 2004. Generalizing dimensionality in combinatory categorial grammar. In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004), Geneva, Switzerland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert-Jan M Kruijff</author>
<author>Pierre Lison</author>
<author>Trevor Benjamin</author>
<author>Henrik Jacobsson</author>
<author>Nick Hawes</author>
</authors>
<title>Incremental, multi-level processing for comprehending situated dialogue in human-robot interaction.</title>
<date>2007</date>
<booktitle>Symposium on Language and Robots (LangRo 2007),</booktitle>
<editor>In Luis Seabra Lopes, Tony Belpaeme, and Stephen J. Cowley, editors,</editor>
<location>Aveiro, Portugal,</location>
<contexts>
<context position="7179" citStr="Kruijff et al. (2007)" startWordPosition="1155" endWordPosition="1158">r grammatically ill-formed sentences. Lavie (1996) presents GLR*, a grammar-based parser for spoken language, which ignores unparseable words and sentence parts and instead looks for the maximal subset of an input sentence that is covered by the grammar. Other researchers in this area have designed grammar-based approaches for incremental spoken language processing: Brick and Scheutz (2007) present RISE, the robotic incremental semantic engine. RISE is able to process syntactic and semantic information incrementally and to integrate this information with perceptual and linguistic information. Kruijff et al. (2007) present an approach for incremental processing of situated dialogue in human-robot interaction, which maintains parallel interpretations of the current dialogue that are pruned by making use of the context information. Schlangen and Skantze (2009) describe a “general, abstract model of incremental dialogue processing”, where their goal is to provide principles for designing new systems for incremental speech processing. 244 3 Approach Our goal in this paper is to transform spoken utterances which cannot be parsed by our grammar into grammar-valid sentences. During this process, we have to mak</context>
</contexts>
<marker>Kruijff, Lison, Benjamin, Jacobsson, Hawes, 2007</marker>
<rawString>Geert-Jan M. Kruijff, Pierre Lison, Trevor Benjamin, Henrik Jacobsson, and Nick Hawes. 2007. Incremental, multi-level processing for comprehending situated dialogue in human-robot interaction. In Luis Seabra Lopes, Tony Belpaeme, and Stephen J. Cowley, editors, Symposium on Language and Robots (LangRo 2007), Aveiro, Portugal, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
</authors>
<title>The interpretation of ellipsis.</title>
<date>1996</date>
<booktitle>The Handbook of Contemporary Semantic Theory,</booktitle>
<pages>397--399</pages>
<contexts>
<context position="4317" citStr="Lappin, 1996" startWordPosition="710" endWordPosition="711">I) experiment, and the grammar for processing used in the same experiment. 2 Related Work The work described in this paper draws on research and techniques from three main areas: the automatic detection of ellipses in sentences, calculation of semantic similarity between two words using WordNet, and spoken language processing. This section provides a summary of relevant work in these areas. 2.1 Ellipsis Detection There is a wide range of research in ellipsis detection in written language, where different types of ellipses are widely defined, such as gapping, stripping or verb phrase ellipsis (Lappin, 1996). For example, an ellipsis occurs when a redundant word is left out of succeeding sentences, such as the words “want to have” in the sentence “I want to have a water, and my friend a juice”, which are omitted in the second part of the sentence. The detection of verb phrase ellipses (VPE) is a subfield of ellipsis detection that has received much attention. For VPE detection, researchers have used machine learning algorithms which were trained on grammar-parsed corpora, for example in the works of Hardt (1997), Nielsen (2004a), Nielsen (2004b), and Smith and Rauchas (2006). Other approaches for</context>
</contexts>
<marker>Lappin, 1996</marker>
<rawString>Shalom Lappin. 1996. The interpretation of ellipsis. The Handbook of Contemporary Semantic Theory, 397:399.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
</authors>
<title>GLR*: A Robust GrammarFocused Parser for Spontaneously Spoken Language.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="6608" citStr="Lavie (1996)" startWordPosition="1069" endWordPosition="1070">for WordNet-based calculation of semantic similarity are the works by Qin et al. (2009), Cai et al. (2010), Liu et al. (2012), and Wagh and Kolhe (2012). 2.3 Spoken Language Processing Our work addresses the processing of spoken language, which differs from the processing of written language in that spoken language is more often elliptical and grammatically incorrect. Previous work in this area has attempted to address this issue at different levels of processing. Issar and Ward (1993) presented the CMU speech processing system that supports recognition for grammatically ill-formed sentences. Lavie (1996) presents GLR*, a grammar-based parser for spoken language, which ignores unparseable words and sentence parts and instead looks for the maximal subset of an input sentence that is covered by the grammar. Other researchers in this area have designed grammar-based approaches for incremental spoken language processing: Brick and Scheutz (2007) present RISE, the robotic incremental semantic engine. RISE is able to process syntactic and semantic information incrementally and to integrate this information with perceptual and linguistic information. Kruijff et al. (2007) present an approach for incr</context>
</contexts>
<marker>Lavie, 1996</marker>
<rawString>Alon Lavie. 1996. GLR*: A Robust GrammarFocused Parser for Spontaneously Spoken Language. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongzhe Liu</author>
<author>Hong Bao</author>
<author>De Xu</author>
</authors>
<title>Concept vector for semantic similarity and relatedness based on wordnet structure.</title>
<date>2012</date>
<journal>Journal of Systems and Software,</journal>
<volume>85</volume>
<issue>2</issue>
<marker>Liu, Bao, De Xu, 2012</marker>
<rawString>Hongzhe Liu, Hong Bao, and De Xu. 2012. Concept vector for semantic similarity and relatedness based on wordnet structure. Journal of Systems and Software, 85(2):370–381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="3505" citStr="Miller, 1995" startWordPosition="576" endWordPosition="577">proach can be very useful in extending the coverage of a grammar during testing or user studies. Therefore, we present an approach to transform unparseable spoken language into sentences that a given grammar can parse. For ellipsis detection, 243 Proceedings of the SIGDIAL 2014 Conference, pages 243–250, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics we present in Section 3.1 a novel algorithm that searches for ellipses in a sentence and computes candidate words to fill the ellipsis with words from a grammar. In Section 3.2, we show how we use WordNet (Miller, 1995) to find replacements for words that are not in the robot’s grammar. In Section 4 we evaluate our approach with a test set of 211 spoken utterances that were recorded in a human-robot interaction (HRI) experiment, and the grammar for processing used in the same experiment. 2 Related Work The work described in this paper draws on research and techniques from three main areas: the automatic detection of ellipses in sentences, calculation of semantic similarity between two words using WordNet, and spoken language processing. This section provides a summary of relevant work in these areas. 2.1 Ell</context>
<context position="16013" citStr="Miller, 1995" startWordPosition="2689" endWordPosition="2690">p. 3.2 WordNet-based Word Substitution Spoken language is versatile and there are many ways to express one’s intentions by using differarg(left) / right left \ arg(right) false isEmpty(left) isEmpty(right) atom(right) compl(left) s / right true true false atom(left) compl(right) s \ left true true false false s / right \ left compl(left) compl(right) atom(left) atom(right) true true false 246 ent expressions. Thus, in grammar-based spoken language processing it often happens that sentences cannot be parsed because of words that are not in the grammar. To overcome this problem, we use WordNet (Miller, 1995) to find semantically equivalent replacements for unknown words. WordNet arranges words in sets of synonyms called synsets which are connected to other synsets by a variety of relations, which differ for each word category. The most relevant relations for our work are: for nouns and verbs hyperonyms (e.g., drink is a hyperonym of juice) and hyponyms (e.g., juice is a hyponym of drink), and for adjectives we use the similar to relation. Our implementation of word substitution executes two steps if a word is unknown to the grammar: (1) look-up of synonyms for the unknown words. The unknown word </context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: A lexical database for english. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leif Arda Nielsen</author>
</authors>
<title>Verb phrase ellipsis detection using automatically parsed text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>1093</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="4846" citStr="Nielsen (2004" startWordPosition="801" endWordPosition="802">re widely defined, such as gapping, stripping or verb phrase ellipsis (Lappin, 1996). For example, an ellipsis occurs when a redundant word is left out of succeeding sentences, such as the words “want to have” in the sentence “I want to have a water, and my friend a juice”, which are omitted in the second part of the sentence. The detection of verb phrase ellipses (VPE) is a subfield of ellipsis detection that has received much attention. For VPE detection, researchers have used machine learning algorithms which were trained on grammar-parsed corpora, for example in the works of Hardt (1997), Nielsen (2004a), Nielsen (2004b), and Smith and Rauchas (2006). Other approaches for ellipsis detection rely on symbolic processing of sentences, which is similar to our work. Haddar and Hamadou (1998) present a method for ellipsis detection in the Arabic language, which is based on an augmented transition network grammar. Egg and Erk (2001) present a general approach for ellipsis detection and resolution that uses a language for partial description of λ-terms called Constraint Language for Lambda Structures. 2.2 WordNet-based Semantic Similarity Calculation WordNet is used in many varied natural language </context>
</contexts>
<marker>Nielsen, 2004</marker>
<rawString>Leif Arda Nielsen. 2004a. Verb phrase ellipsis detection using automatically parsed text. In Proceedings of the 20th International Conference on Computational Linguistics, page 1093. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leif Arda Nielsen</author>
</authors>
<title>Verb phrase ellipsis detection using machine learning techniques.</title>
<date>2004</date>
<booktitle>Amsterdam Studies in the Theory and History of Linguistic Science,</booktitle>
<pages>317</pages>
<contexts>
<context position="4846" citStr="Nielsen (2004" startWordPosition="801" endWordPosition="802">re widely defined, such as gapping, stripping or verb phrase ellipsis (Lappin, 1996). For example, an ellipsis occurs when a redundant word is left out of succeeding sentences, such as the words “want to have” in the sentence “I want to have a water, and my friend a juice”, which are omitted in the second part of the sentence. The detection of verb phrase ellipses (VPE) is a subfield of ellipsis detection that has received much attention. For VPE detection, researchers have used machine learning algorithms which were trained on grammar-parsed corpora, for example in the works of Hardt (1997), Nielsen (2004a), Nielsen (2004b), and Smith and Rauchas (2006). Other approaches for ellipsis detection rely on symbolic processing of sentences, which is similar to our work. Haddar and Hamadou (1998) present a method for ellipsis detection in the Arabic language, which is based on an augmented transition network grammar. Egg and Erk (2001) present a general approach for ellipsis detection and resolution that uses a language for partial description of λ-terms called Constraint Language for Lambda Structures. 2.2 WordNet-based Semantic Similarity Calculation WordNet is used in many varied natural language </context>
</contexts>
<marker>Nielsen, 2004</marker>
<rawString>Leif Arda Nielsen. 2004b. Verb phrase ellipsis detection using machine learning techniques. Amsterdam Studies in the Theory and History of Linguistic Science, page 317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Qin</author>
<author>Zhao Lu</author>
<author>Yu Yan</author>
<author>Fang Wu</author>
</authors>
<title>A new measure of word semantic similarity based on wordnet hierarchy and dag theory.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference on Web Information Systems and Mining2009 (WISM</booktitle>
<pages>181--185</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6083" citStr="Qin et al. (2009)" startWordPosition="982" endWordPosition="985">ons, such as word sense disambiguation, determining the structure of texts, text summarisation and annotation, information extraction and retrieval, automatic indexing, lexical selection, and the automatic correction of word errors in text. In our work, we use WordNet to find similar or synonym words. In previous work, researchers have proposed several methods to generally compute the semantic relatedness of two words using WordNet. Budanitsky and Hirst (2006) review methods to determine semantic relatedness. Newer examples for WordNet-based calculation of semantic similarity are the works by Qin et al. (2009), Cai et al. (2010), Liu et al. (2012), and Wagh and Kolhe (2012). 2.3 Spoken Language Processing Our work addresses the processing of spoken language, which differs from the processing of written language in that spoken language is more often elliptical and grammatically incorrect. Previous work in this area has attempted to address this issue at different levels of processing. Issar and Ward (1993) presented the CMU speech processing system that supports recognition for grammatically ill-formed sentences. Lavie (1996) presents GLR*, a grammar-based parser for spoken language, which ignores u</context>
</contexts>
<marker>Qin, Lu, Yan, Wu, 2009</marker>
<rawString>Peng Qin, Zhao Lu, Yu Yan, and Fang Wu. 2009. A new measure of word semantic similarity based on wordnet hierarchy and dag theory. In Proceedings of the International Conference on Web Information Systems and Mining2009 (WISM 2009), pages 181– 185. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Schlangen</author>
<author>Gabriel Skantze</author>
</authors>
<title>A general, abstract model of incremental dialogue processing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09).</booktitle>
<contexts>
<context position="7427" citStr="Schlangen and Skantze (2009)" startWordPosition="1192" endWordPosition="1195"> the grammar. Other researchers in this area have designed grammar-based approaches for incremental spoken language processing: Brick and Scheutz (2007) present RISE, the robotic incremental semantic engine. RISE is able to process syntactic and semantic information incrementally and to integrate this information with perceptual and linguistic information. Kruijff et al. (2007) present an approach for incremental processing of situated dialogue in human-robot interaction, which maintains parallel interpretations of the current dialogue that are pruned by making use of the context information. Schlangen and Skantze (2009) describe a “general, abstract model of incremental dialogue processing”, where their goal is to provide principles for designing new systems for incremental speech processing. 244 3 Approach Our goal in this paper is to transform spoken utterances which cannot be parsed by our grammar into grammar-valid sentences. During this process, we have to make sure that the changes to the input sentence do not change its meaning. In this section, we show how we implement ellipsis detection and semantic similarity computation in order to achieve this goal. We present our ellipsis detection algorithm in </context>
</contexts>
<marker>Schlangen, Skantze, 2009</marker>
<rawString>David Schlangen and Gabriel Skantze. 2009. A general, abstract model of incremental dialogue processing. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Searle</author>
</authors>
<title>What is a speech act? In</title>
<date>1965</date>
<booktitle>Perspectives in the Philosophy of Language: A Concise Anthology,</booktitle>
<pages>253--268</pages>
<editor>Robert J. Stainton, editor,</editor>
<contexts>
<context position="19082" citStr="Searle, 1965" startWordPosition="3228" endWordPosition="3229">rder drinks on their own, in the second and third part, participants were accompanied by a confederate in order to have a multi-party interaction with the robot. The spoken utterances in the test set were annotated by hand from video recordings of the 93 drink order sequences. Please refer to (Foster et al., 2012) for a detailed description of the experiment. Table 1 shows an overview of the test set. In total, it contains 211 unique utterances; the experiment participants spoke 531 sentences of which some sentences were said repeatedly. We divided the test set into the following speech acts (Searle, 1965): Ordering (“I would like a juice please.”), Question (“What do you have?”), Greeting (“Hello there.”), Polite expression (“Thank you.”), Confirmation (“Yes.”), Other (“I am thirsty.”). 4.2 Grammar The grammar that we used in this evaluation was also used in the robot bartender experiment (Foster et al., 2012). This grammar is limited in its scope, because the domain of the experiment—the robot hands out drinks to customers—was limited as well. Overall, the lexicon of the grammar contains 92 words, which are divided into the following part of speech classes: 42 verbs, 11 nouns, 10 greetings, 6</context>
</contexts>
<marker>Searle, 1965</marker>
<rawString>John R. Searle. 1965. What is a speech act? In Robert J. Stainton, editor, Perspectives in the Philosophy of Language: A Concise Anthology, pages 253–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lindsey Smith</author>
<author>Sarah Rauchas</author>
</authors>
<title>A machinelearning approach for the treatment of vp ellipsis.</title>
<date>2006</date>
<booktitle>In Proceedings of the Seventeenth Annual Symposium of the Pattern Recognition Association of South Africa,</booktitle>
<contexts>
<context position="4895" citStr="Smith and Rauchas (2006)" startWordPosition="806" endWordPosition="809">ripping or verb phrase ellipsis (Lappin, 1996). For example, an ellipsis occurs when a redundant word is left out of succeeding sentences, such as the words “want to have” in the sentence “I want to have a water, and my friend a juice”, which are omitted in the second part of the sentence. The detection of verb phrase ellipses (VPE) is a subfield of ellipsis detection that has received much attention. For VPE detection, researchers have used machine learning algorithms which were trained on grammar-parsed corpora, for example in the works of Hardt (1997), Nielsen (2004a), Nielsen (2004b), and Smith and Rauchas (2006). Other approaches for ellipsis detection rely on symbolic processing of sentences, which is similar to our work. Haddar and Hamadou (1998) present a method for ellipsis detection in the Arabic language, which is based on an augmented transition network grammar. Egg and Erk (2001) present a general approach for ellipsis detection and resolution that uses a language for partial description of λ-terms called Constraint Language for Lambda Structures. 2.2 WordNet-based Semantic Similarity Calculation WordNet is used in many varied natural language processing applications, such as word sense disam</context>
</contexts>
<marker>Smith, Rauchas, 2006</marker>
<rawString>Lindsey Smith and Sarah Rauchas. 2006. A machinelearning approach for the treatment of vp ellipsis. In Proceedings of the Seventeenth Annual Symposium of the Pattern Recognition Association of South Africa, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="8294" citStr="Steedman, 2000" startWordPosition="1331" endWordPosition="1332">ch cannot be parsed by our grammar into grammar-valid sentences. During this process, we have to make sure that the changes to the input sentence do not change its meaning. In this section, we show how we implement ellipsis detection and semantic similarity computation in order to achieve this goal. We present our ellipsis detection algorithm in Section 3.1. Section 3.2 explains our implementation of WordNet-based word similarity computation. 3.1 Ellipsis Detection Algorithm We use the OpenCCG parser (White, 2006), which is based on Combinatory Categorial Grammar (Kruijff and Baldridge, 2004; Steedman, 2000), to parse the output of our speech recognition system. We use the properties of CCGs to solve a problem that often occurs during parsing of spoken language. In our evaluation (Section 4) we use a test set (Section 4.1) of spoken sentences that was collected during one of our human-robot interaction studies (Foster et al., 2012) and the CCG (Section 4.2) that was used in the same study. In the test set, we found that speakers leave out words. For example, one speaker said I want water to order a drink. The grammar used in the experiment assumed that every noun is specified by an article; the g</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishor Wagh</author>
<author>Satish Kolhe</author>
</authors>
<title>A new approach for measuring semantic similarity in ontology and its application in information retrieval.</title>
<date>2012</date>
<booktitle>In Multidisciplinary Trends in Artificial Intelligence,</booktitle>
<pages>122--132</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6148" citStr="Wagh and Kolhe (2012)" startWordPosition="995" endWordPosition="998">ture of texts, text summarisation and annotation, information extraction and retrieval, automatic indexing, lexical selection, and the automatic correction of word errors in text. In our work, we use WordNet to find similar or synonym words. In previous work, researchers have proposed several methods to generally compute the semantic relatedness of two words using WordNet. Budanitsky and Hirst (2006) review methods to determine semantic relatedness. Newer examples for WordNet-based calculation of semantic similarity are the works by Qin et al. (2009), Cai et al. (2010), Liu et al. (2012), and Wagh and Kolhe (2012). 2.3 Spoken Language Processing Our work addresses the processing of spoken language, which differs from the processing of written language in that spoken language is more often elliptical and grammatically incorrect. Previous work in this area has attempted to address this issue at different levels of processing. Issar and Ward (1993) presented the CMU speech processing system that supports recognition for grammatically ill-formed sentences. Lavie (1996) presents GLR*, a grammar-based parser for spoken language, which ignores unparseable words and sentence parts and instead looks for the max</context>
</contexts>
<marker>Wagh, Kolhe, 2012</marker>
<rawString>Kishor Wagh and Satish Kolhe. 2012. A new approach for measuring semantic similarity in ontology and its application in information retrieval. In Multidisciplinary Trends in Artificial Intelligence, pages 122–132. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>CCG chart realization from disjunctive inputs.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fourth International Natural Language Generation Conference,</booktitle>
<pages>12--19</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="8198" citStr="White, 2006" startWordPosition="1318" endWordPosition="1319">peech processing. 244 3 Approach Our goal in this paper is to transform spoken utterances which cannot be parsed by our grammar into grammar-valid sentences. During this process, we have to make sure that the changes to the input sentence do not change its meaning. In this section, we show how we implement ellipsis detection and semantic similarity computation in order to achieve this goal. We present our ellipsis detection algorithm in Section 3.1. Section 3.2 explains our implementation of WordNet-based word similarity computation. 3.1 Ellipsis Detection Algorithm We use the OpenCCG parser (White, 2006), which is based on Combinatory Categorial Grammar (Kruijff and Baldridge, 2004; Steedman, 2000), to parse the output of our speech recognition system. We use the properties of CCGs to solve a problem that often occurs during parsing of spoken language. In our evaluation (Section 4) we use a test set (Section 4.1) of spoken sentences that was collected during one of our human-robot interaction studies (Foster et al., 2012) and the CCG (Section 4.2) that was used in the same study. In the test set, we found that speakers leave out words. For example, one speaker said I want water to order a dri</context>
</contexts>
<marker>White, 2006</marker>
<rawString>Michael White. 2006. CCG chart realization from disjunctive inputs. In Proceedings of the Fourth International Natural Language Generation Conference, pages 12–19, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>