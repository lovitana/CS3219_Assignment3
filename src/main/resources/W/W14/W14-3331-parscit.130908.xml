<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000061">
<title confidence="0.996909">
Combining Domain Adaptation Approaches for Medical Text Transla-
tion
</title>
<author confidence="0.979265">
Longyue Wang, Yi Lu, Derek F. Wong, Lidia S. Chao, Yiming Wang, Francisco Oliveira
</author>
<affiliation confidence="0.980714">
Natural Language Processing &amp; Portuguese-Chinese Machine Translation Laboratory,
Department of Computer and Information Science,
University of Macau, Macau, China
</affiliation>
<email confidence="0.974577">
vincentwang0229@hotmail.com,
{mb25435, derekfw, lidiasc, mb25433, olifran}@umac.mo
</email>
<sectionHeader confidence="0.995235" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999016875">
This paper explores a number of simple
and effective techniques to adapt statisti-
cal machine translation (SMT) systems in
the medical domain. Comparative exper-
iments are conducted on large corpora for
six language pairs. We not only compare
each adapted system with the baseline,
but also combine them to further improve
the domain-specific systems. Finally, we
attend the WMT2014 medical summary
sentence translation constrained task and
our systems achieve the best BLEU
scores for Czech-English, English-
German, French-English language pairs
and the second best BLEU scores for re-
minding pairs.
</bodyText>
<sectionHeader confidence="0.998218" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999966297297297">
This paper presents the experiments conducted
by the NLP2CT Laboratory at the University of
Macau for WMT2014 medical sentence transla-
tion task on six language pairs: Czech-English
(cs-en), French-English (fr-en), German-English
(de-en) and the reverse direction pairs, i.e., en-cs,
en-fr and en-de.
By comparing the medical text with common
text, we discovered some interesting phenomena
in medical genre. We apply domain-specific
techniques in data pre-processing, language
model adaptation, translation model adaptation,
numeric and hyphenated words translation.
Compared to the baseline systems (detailed in
Section 2 &amp; 3), the results of each method show
reasonable gains. We combine individual ap-
proach to further improve the performance of our
systems. To validate the robustness and lan-
guage-independency of individual and combined
systems, we conduct experiments on the official
training data (detailed in Section 3) in all six lan-
guage pairs. We anticipate the numeric compari-
son (BLEU scores) on these individual and com-
bined domain adaptation approaches that could
be valuable for others on building a real-life do-
main-specific system.
The reminder of this paper is organized as fol-
lows. In Section 2, we detail the configurations
of our experiments as well as the baseline sys-
tems. Section 3 presents the specific pre-
processing for medical data. In Section 4 and 5,
we describe the language model (LM) and trans-
lation model (TM) adaptation, respectively. Be-
sides, the techniques for numeric and hyphenated
words translation are reported in Section 6 and 7.
Finally, the performance of design systems and
the official results are reported in Section 8.
</bodyText>
<sectionHeader confidence="0.998515" genericHeader="introduction">
2. Experimental Setup
</sectionHeader>
<bodyText confidence="0.999873">
All available training data from both WMT2014
standard translation task1 (general-domain data)
and medical translation task2 (in-domain data)
are used in this study. The official medical sum-
mary development sets (dev) are used for tuning
and evaluating all the comparative systems. The
official medical summary test sets (test) are only
used in our final submitted systems.
The experiments were carried out with the
Moses 1.03 (Koehn et al., 2007). The translation
and the re-ordering model utilizes the “grow-
diag-final” symmetrized word-to-word align-
ments created with MGIZA++4 (Och and Ney,
</bodyText>
<footnote confidence="0.99887975">
1 http://www.statmt.org/wmt14/translation-task.html.
2 http://www.statmt.org/wmt14/medical-task/.
3 http://www.statmt.org/moses/.
4 http://www.kyloo.net/software/doku.php/mgiza:overview.
</footnote>
<page confidence="0.961771">
254
</page>
<bodyText confidence="0.8692503">
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 254–259,
Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics
2003; Gao and Vogel, 2008) and the training
scripts from Moses. A 5-gram LM was trained
using the SRILM toolkit5 (Stolcke et al., 2002),
exploiting improved modified Kneser-Ney
smoothing, and quantizing both probabilities and
back-off weights. For the log-linear model train-
ing, we take the minimum-error-rate training
(MERT) method as described in (Och, 2003).
</bodyText>
<sectionHeader confidence="0.775024" genericHeader="method">
3. Task Oriented Pre-processing
</sectionHeader>
<bodyText confidence="0.999943365853659">
A careful pre-processing on training data is sig-
nificant for building a real-life SMT system. In
addition to the general data preparing steps used
for constructing the baseline system, we intro-
duce some extra steps to pre-process the training
data.
The first step is to remove the duplicate sen-
tences. In data-driven methods, the more fre-
quent a term occurs, the higher probability it bi-
ases. Duplicate data may lead to unpredicted be-
havior during the decoding. Therefore, we keep
only the distinct sentences in monolingual cor-
pus. By taking into account multiple translations
in parallel corpus, we remove the duplicate sen-
tence pairs. The second concern in pre-
processing is symbol normalization. Due to the
nature of medical genre, symbols such as num-
bers and punctuations are commonly-used to pre-
sent chemical formula, measuring unit, terminol-
ogy and expression. Fig. 1 shows the examples
of this case. These symbols are more frequent in
medical article than that in the common texts.
Besides, the punctuations of apostrophe and sin-
gle quotation are interchangeably used in French
text, e.g. “l’effet de l&apos;inhibition”. We unify it by
replacing with the apostrophe. In addition, we
observe that some monolingual training subsets
(e.g., Gene Regulation Event Corpus) contain
sentences of more than 3,000 words in length. To
avoid the long sentences from harming the true-
case model, we split them into sentences with a
sentence splitter6 (Rune et al., 2007) that is opti-
mized for biomedical texts. On the other hand,
we consider the target system is intended for
summary translation, the sentences tend to be
short in length. For instance, the average sen-
tence lengths in development sets of cs, fr, de
and en are around 15, 21, 17 and 18, respective-
ly. We remove sentence pairs which are more
than 80 words at length. In order to that our ex-
periments are reproducible, we give the detailed
</bodyText>
<footnote confidence="0.950308">
5 http://www.speech.sri.com/projects/srilm/.
6 http://www.nactem.ac.uk/y-matsu/geniass/.
</footnote>
<bodyText confidence="0.9472285">
statistics of task oriented pre-processed training
data in Table 2.
</bodyText>
<figure confidence="0.99145">
1,25-OH
47 to 80%
10-20 ml/kg
A&amp;E department
Infective endocarditis (IE)
</figure>
<figureCaption confidence="0.99853">
Figure 1. Examples of the segments with sym-
bols in medical texts.
</figureCaption>
<bodyText confidence="0.99986136">
To validate the effectiveness of the pre-
processing, we compare the SMT systems
trained on original data 7 (Baseline1) and task-
oriented-processed data (Baseline2), respective-
ly. Table 1 shows the results of the baseline sys-
tems. We found all the Baseline2 systems outper-
form the Baseline1 models, showing that the sys-
tems can benefit from using the processed data.
For cs-en and en-cs pairs, the BLEU scores im-
prove quite a lot. For other language pairs, the
translation quality improves slightly.
By analyzing the Baseline2 results (in Table 1)
and the statistics of training corpora (in Table 2),
we can further elaborate and explain the results.
The en-cs system performs poorly, because of
the short average length of training sentences, as
well as the limited size of in-domain parallel and
monolingual corpora. On the other hand, the fr-
en system achieves the best translation score, as
we have sufficient training data. The translation
quality of cs-en, en-fr, fr-en and de-en pairs is
much higher than those in the other pairs. Hence,
Baseline2 will be used in the subsequent compar-
isons with the proposed systems described in
Section 4, 5, 6 and 7.
</bodyText>
<table confidence="0.950647571428571">
Lang. Pair Baseline1 Baseline2 Diff.
en-cs 12.92 17.57 +4.65
cs-en 20.85 31.29 +10.44
en-fr 38.31 38.36 +0.05
fr-en 44.27 44.36 +0.09
en-de 17.81 18.01 +0.20
de-en 32.34 32.50 +0.16
</table>
<tableCaption confidence="0.684943666666667">
Table 1: BLEU scores of two baseline systems
trained on original and processed corpora for
different language pairs.
</tableCaption>
<sectionHeader confidence="0.977965" genericHeader="method">
4. Language Model Adaptation
</sectionHeader>
<bodyText confidence="0.999854666666667">
The use of LMs (trained on large data) during
decoding is aided by more efficient storage and
inference (Heafield, 2011). Therefore, we not
</bodyText>
<footnote confidence="0.6480105">
7 Data are processed according to Moses baseline tutorial:
http://www.statmt.org/moses/?n=Moses.Baseline.
</footnote>
<page confidence="0.989726">
255
</page>
<table confidence="0.999936304347826">
Data Set Lang. Sent. Words Vocab. Ave. Len.
In-domain cs/en 1,770,421 9,373,482/ 134,998/ 5.29/
Parallel Data 10,605,222 156,402 5.99
de/en 3,894,099 52,211,730/ 1,146,262/ 13.41/
58,544,608 487,850 15.03
fr/en 4,579,533 77,866,237/ 495,856/ 17.00/
68,429,649 556,587 14.94
General-domain cs/en 12,426,374 180,349,215/ 1,614,023/ 14.51/
Parallel Data 183,841,805 1,661,830 14.79
de/en 4,421,961 106,001,775/ 1,912,953/ 23.97/
112,294,414 919,046 25.39
fr/en 36,342,530 1,131,027,766/ 3,149,336/ 31.12/
953,644,980 3,324,481 26.24
In-domain cs 106,548 1,779,677 150,672 16.70
Mono. Data
fr 1,424,539 53,839,928 644,484 37.79
de 2,222,502 53,840,304 1,415,202 24.23
en 7,802,610 199430649 1,709,594 25.56
General-domain cs 33,408,340 567,174,266 3,431,946 16.98
Mono. Data
fr 30,850,165 780,965,861 2,142,470 25.31
de 84,633,641 1,548,187,668 10,726,992 18.29
en 85,254,788 2,033,096,800 4,488,816 23.85
</table>
<tableCaption confidence="0.999541">
Table 2: Statistics summary of corpora after pre-processing.
</tableCaption>
<bodyText confidence="0.967840375">
only use the in-domain training data, but also the
selected pseudo in-domain data8 from general-
domain corpus to enhance the LMs (Toral, 2013;
Rubino et al., 2013; Duh et al., 2013). Firstly,
each sentence s in general-domain monolingual
corpus is scored using the cross-entropy differ-
ence method in (Moore and Lewis, 2010), which
is calculated as follows:
</bodyText>
<equation confidence="0.999108">
score(s) = HI (s) - HG (s) (1)
</equation>
<bodyText confidence="0.999957052631579">
where H(s) is the length-normalized cross-
entropy. I and G are the in-domain and general-
domain corpora, respectively. G is a random sub-
set (same size as the I) of the general-domain
corpus. Then top N percentages of ranked data
sentences are selected as a pseudo in-domain
subset to train an additional LM. Finally, we lin-
early interpolate the additional LM with in-
domain LM.
We use the top N% of ranked results, where
N={0, 25, 50, 75, 100} percentages of sentences
out of the general corpus. Table 3 shows the ab-
solute BLEU points for Baseline2 (N=0), while
the LM adapted systems are listed with values
relative to the Baseline2. The results indicate that
LM adaptation can gain a reasonable improve-
ment if the LMs are trained on more relevant
data for each pair, instead of using the whole
training data. For different systems, their BLEU
</bodyText>
<note confidence="0.6746015">
8 Axelrod et al. (2011) names the selected data as pseudo in-
domain data. We adopt both terminologies in this paper.
</note>
<bodyText confidence="0.999253076923077">
scores peak at different values of N. It gives the
best results for cs-en, en-fr and de-en pairs when
N=25, en-cs and en-de pairs when N=50, and fr-
en pair when N=75. Among them, en-cs and en-
fr achieve the highest BLEU scores. The reason
is that their original monolingual (in-domain)
data for training the LMs are not sufficient.
When introducing the extra pseudo in-domain
data, the systems improve the translation quality
by around 2 BLEU points. While for cs-en, fr-en
and de-en pairs, the gains are small. However, it
can still achieve a significant improvement of
0.60 up to 1.12 BLEU points.
</bodyText>
<table confidence="0.99957">
Lang. I=0 I=25 I=50 I=75 I=100
en-cs 17.57 +1.66 +2.08 +1.72 +2.04
cs-en 31.29 +0.94 +0.60 +0.66 +0.47
en-fr 38.36 +1.82 +1.66 +1.60 +0.08
fr-en 44.36 +0.91 +1.09 +1.12 +0.92
en-de 18.01 +0.57 +1.02 -4.48 -4.54
de-en 32.50 +0.60 +0.50 +0.56 +0.38
</table>
<tableCaption confidence="0.999001">
Table 3: BLEU scores of LM adapted systems.
</tableCaption>
<sectionHeader confidence="0.990199" genericHeader="method">
5. Translation Model Adaptation
</sectionHeader>
<bodyText confidence="0.999822428571428">
As shown in Table 2, general-domain parallel
corpora are around 1 to 7 times larger than the
in-domain ones. We suspect if general-domain
corpus is broad enough to cover some in-domain
sentences. To observe the domain-specificity of
general-domain corpus, we firstly evaluate sys-
tems trained on general-domain corpora. In Ta-
</bodyText>
<page confidence="0.989949">
256
</page>
<bodyText confidence="0.999950875">
ble 4, we show the BLEU scores of general-
domain systems9 on translating the medical sen-
tences. The BLEU scores of the compared sys-
tems are relative to the Baseline2 and the size of
the used general-domain corpus is relative to the
corresponding in-domain one. For en-cs, cs-en,
en-fr and fr-en pairs, the general-domain parallel
corpora we used are 6 times larger than the orig-
inal ones and we obtain the improved BLEU
scores by 1.72 up to 3.96 points. While for en-de
and de-en pairs, the performance drops sharply
due to the limited training corpus we used.
Hence we can draw a conclusion: the general-
domain corpus is able to aid the domain-specific
translation task if the general-domain data is
large and broad enough in content.
</bodyText>
<table confidence="0.998550428571429">
Lang. Pair BLEU Diff. Corpus
en-cs 21.53 +3.96 +601.89%
cs-en 33.01 +1.72
en-fr 41.57 +3.21 +693.59%
fr-en 47.33 +2.97
en-de 16.54 -1.47 +13.63%
de-en 27.35 -5.15
</table>
<tableCaption confidence="0.914528">
Table 4: The BLEU scores of systems trained on
general-domain corpora.
</tableCaption>
<bodyText confidence="0.999856">
Taking into account the performance of gen-
eral-domain system, we explore various data se-
lection methods to derive the pseudo in-domain
sentence pairs from general-domain parallel cor-
pus for enhancing the TMs (Wang et al., 2013;
Wang et al., 2014). Firstly, sentence pair in cor-
responding general-domain corpora is scored by
the modified Moore-Lewis (Axelrod et al.,
2011), which is calculated as follows:
</bodyText>
<equation confidence="0.98949">
� HI-src (s) - HG-src (s)�
score(s) =
+ [HI-tgt (s) - HG-tgt (s)] (2)
</equation>
<bodyText confidence="0.98269446875">
which is similar to Eq. (1) and the only differ-
ence is that it considers the both the source (src)
and target (tgt) sides of parallel corpora. Then
top I percentage of ranked sentence pairs are
selected as a pseudo in-domain subset to train an
individual translation model. The additional
model is log-linearly interpolated with the in-
domain model (Baseline2) using the multi-
decoding method described in (Koehn and
Schroeder, 2007).
Similar to LM adaptation, we use the top I%
of ranked results, where I={0, 25, 50, 75, 100}
percentages of sentences out of the general cor-
9 General-domain systems are trained only on genera-
domain training corpora (i.e., parallel, monolingual).
pus. Table 5 shows the absolute BLEU points for
Baseline2 (I=0), while for the TM adapted sys-
tems we show the values relative to the Base-
line2. For different systems, their BLEU peak at
different I. For en-fr and en-de pairs, it gives the
best translation results at I=25. Regarding cs-en
and fr-en pairs, the optimal performance is
peaked at I=50. While the best results for de-en
and en-cs pairs are I=75 and I=100 respective-
ly. Besides, performance of TM adapted system
heavily depends on the size and (domain) broad-
ness of the general-domain data. For example,
the improvements of en-de and de-en systems are
slight due to the small general-domain corpora.
While the quality of other systems improve about
3 BLEU points, because of their large and broad
general-domain corpora.
</bodyText>
<table confidence="0.995766">
Lang. I=0 I=25 I=50 I=75 I=100
en-cs 17.57 +0.84 +1.53 +1.74 +2.55
cs-en 31.29 +2.03 +3.12 +3.12 +2.24
en-fr 38.36 +3.87 +3.66 +3.53 +2.88
fr-en 44.36 +1.29 +3.36 +1.84 +1.65
en-de 18.01 +0.02 -0.13 -0.07 0
de-en 32.50 -0.12 +0.06 +0.31 +0.24
</table>
<tableCaption confidence="0.997777">
Table 5: BLEU scores of TM adapted systems.
</tableCaption>
<sectionHeader confidence="0.956559" genericHeader="method">
6. Numeric Adaptation
</sectionHeader>
<bodyText confidence="0.999805285714286">
As stated in Section 3, numeric occurs frequently
in medical texts. However, numeric expression in
dates, time, measuring unit, chemical formula are
often sparse, which may lead to OOV problems
in phrasal translation and reordering. Replacing
the sparse numbers with placeholders may pro-
duce more reliable statistics for the MT models.
Moses has support using placeholders in train-
ing and decoding. Firstly, we replace all the
numbers in monolingual and parallel training
corpus with a common symbol (a sample phrase
is illustrated in Fig. 2). Models are then trained
on these processed data. We use the XML
markup translation method for decoding.
</bodyText>
<figure confidence="0.4668525">
Original: Vitamin D 1,25-OH
Replaced: Vitamin D @num@, @num@-OH
</figure>
<figureCaption confidence="0.999778">
Figure 2. Examples of placeholders.
</figureCaption>
<bodyText confidence="0.9995775">
Table 6 shows the results on this number ad-
aptation approach as well as the improvements
compared to the Baseline2. The method im-
proves the Baseline2 systems by 0.23 to 0.40
BLEU scores. Although the scores increase
slightly, we still believe this adaptation method is
significant for medical domain. The WMT2014
medical task only focuses on the summary of
</bodyText>
<page confidence="0.990254">
257
</page>
<bodyText confidence="0.9981274">
medical text, which may contain fewer chemical
expression in compared with the full article. As
the used of numerical instances increases, place-
holder may play a more important role in domain
adaptation.
</bodyText>
<table confidence="0.999329857142857">
Lang. Pair BLEU (Dev) Diff.
en-cs 17.80 +0.23
cs-en 31.52 +0.23
en-fr 38.72 +0.36
fr-en 44.69 +0.33
en-de 18.41 +0.40
de-en 32.88 +0.38
</table>
<tableCaption confidence="0.980162">
Table 6: BLEU scores of numeric adapted sys-
tems.
</tableCaption>
<sectionHeader confidence="0.694853" genericHeader="method">
7. Hyphenated Word Adaptation
</sectionHeader>
<bodyText confidence="0.999910764705883">
Medical texts prefer a kind of compound words,
hyphenated words, which is composed of more
than one word. For instance, “slow-growing” and
“easy-to-use” are composed of words and linked
with hyphens. These hyphenated words occur
quite frequently in medical texts. We analyze the
development sets of cs, fr, en and de respective-
ly, and observe that there are approximately
3.2%, 11.6%, 12.4% and 19.2% of sentences that
contain one or more hyphenated words. The high
ratio of such compound words results in Out-Of-
Vocabulary words (OOV) 10 , and harms the
phrasal translation and reordering. However, a
number of those hyphenated words still have
chance to be translated, although it is not precise-
ly, when they are tokenized into individual
words.
</bodyText>
<sectionHeader confidence="0.455192" genericHeader="method">
Algorithm: Alternative-translation Method
</sectionHeader>
<bodyText confidence="0.806961">
Input:
</bodyText>
<listItem confidence="0.9991994">
1. A sentence, s, with M hyphenated words
2. Translation lexicon
Run:
1. For i = 1, 2, ..., M
2. Split the ith hyphenated word (Ci) into
Pi
3. Translate Pi into Ti
4. If (Ti are not OOVs):
5. Put alternative translation Ti in XML
6. Else: keep Ci unchanged
</listItem>
<sectionHeader confidence="0.346587" genericHeader="method">
Output:
</sectionHeader>
<bodyText confidence="0.5666125">
Sentence, s’, embedded with alternative
translations for all Ti.
</bodyText>
<subsectionHeader confidence="0.352252">
End
</subsectionHeader>
<tableCaption confidence="0.997136">
Table 7: Alternative-translation algorithm.
</tableCaption>
<page confidence="0.631372">
10 Default tokenizer does not handle the hyphenated words.
</page>
<bodyText confidence="0.9993715">
To resolve this problem, we present an alter-
native-translation method in decoding. Table 7
shows the proposed algorithm.
In the implementation, we apply XML markup
to record the translation (terminology) for each
compound word. During the decoding, a hyphen-
ated word delimited with markup will be re-
placed with its corresponding translation. Table 8
shows the BLEU scores of adapted systems ap-
plied to hyphenated translation. This method is
effective for most language pairs. While the
translation systems for en-cs and cs-en do not
benefit from this adaptation, because the hy-
phenated words ratio in the en and cs dev are
asymmetric. Thus, we only apply this method for
en-fr, fr-en, de-en and en-de pairs.
</bodyText>
<table confidence="0.998867571428571">
Lang. Pair BLEU (Dev) Diff.
en-cs 16.84 -0.73
cs-en 31.23 -0.06
en-fr 39.12 +0.76
fr-en 45.02 +0.66
en-de 18.64 +0.63
de-en 33.01 +0.51
</table>
<tableCaption confidence="0.9892475">
Table 8: BLEU scores of hyphenated word
adapted systems.
</tableCaption>
<sectionHeader confidence="0.88314" genericHeader="conclusions">
3. Final Results and Conclusions
</sectionHeader>
<bodyText confidence="0.968292125">
According to the performance of each individual
domain adaptation approach, we combined the
corresponding models for each language pair. In
Table 10, we show the BLEU scores and its in-
crements (compared to the Baseline2) of com-
bined systems in the second column. The official
test set is converted into the recased and deto-
kenized SGML format. The official results of our
submissions are given in the last column of Table
9.
Lang. BLEU of Com- Official
Pair bined systems BLEU
en-cs 23.66 (+6.09) 22.60
cs-en 38.05 (+6.76) 37.60
en-fr 42.30 (+3.94) 41.20
fr-en 48.25 (+3.89) 47.10
en-de 21.14 (+3.13) 20.90
de-en 36.03 (+3.53) 35.70
Table 9: BLEU scores of the submitted systems
for the medical translation task.
This paper presents a set of experiments con-
ducted on all available training data for six lan-
guage pairs. We explored various domain adap-
tation approaches for adapting medical transla-
</bodyText>
<page confidence="0.989563">
258
</page>
<bodyText confidence="0.9999524">
tion systems. Compared with other methods, lan-
guage model adaptation and translation model
adaptation are more effective. Other adapted
techniques are still necessary and important for
building a real-life system. Although all individ-
ual methods are not fully additive, combining
them together can further boost the performance
of the overall domain-specific system. We be-
lieve these empirical approaches could be valua-
ble for SMT development.
</bodyText>
<sectionHeader confidence="0.997385" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999838444444444">
The authors are grateful to the Science and
Technology Development Fund of Macau and
the Research Committee of the University of
Macau for the funding support for their research,
under the Reference nos. MYRG076 (Y1-L2)-
FST13-WF and MYRG070 (Y1-L2)-FST12-CS.
The authors also wish to thank the colleagues in
CNGL, Dublin City University (DCU) for their
helpful suggestion and guidance on related work.
</bodyText>
<sectionHeader confidence="0.983498" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999926214285714">
Amittai Axelrod, Xiaodong He, and Jianfeng Gao.
2011. Domain adaptation via pseudo in-domain da-
ta selection. In Proceedings of EMNLP, pages 355-
362.
K. Duh, G. Neubig, K. Sudoh, H. Tsukada. 2013. Ad-
aptation data selection using neural language mod-
els: Experiments in machine translation. In Pro-
ceedings of the Annual Meeting of the Association
for Computational Linguistics, pages, 678–683.
Qin Gao and Stephan Vogel. 2008. Parallel imple-
mentations of word alignment tool. Software Engi-
neering, Testing, and Quality Assurance for Natu-
ral Language Processing, pages 49-57.
Kenneth Heafield. 2011. KenLM: Faster and smaller
language model queries. In Proceedings of the
Sixth Workshop on Statistical Machine Transla-
tion, pages 187-197.
Philipp Koehn and Josh Schroeder. 2007. Experi-
ments in domain adaptation for statistical machine
translation. In Proceedings of the 2nd ACL Work-
shop on Statistical Machine Translation, pages
224-227.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Ber-
toldi, Brooke Cowan, Wade Shen, Christine Moran
et al. 2007. Moses: open source toolkit for statisti-
cal machine translation. In Proceedings of ACL,
pages 177-180.
Robert C. Moore and William Lewis. 2010. Intelli-
gent selection of language model training data. In
Proceedings of ACL: Short Papers, pages 220-224.
Sætre Rune, Kazuhiro Yoshida, Akane Yakushiji,
Yusuke Miyao, Yuichiro Matsubayashi and Tomo-
ko Ohta. 2007. AKANE system: protein-protein in-
teraction pairs in BioCreAtIvE2 challenge, PPI-IPS
subtask. In Proceedings of the Second BioCreative
Challenge Evaluation Workshop, pages 209-212.
Raphael Rubino, Antonio Toral, Santiago Cortés
Vaíllo, Jun Xie, Xiaofeng Wu, Stephen Doherty,
and Qun Liu. 2013. The CNGL-DCU-Prompsit
translation systems for WMT13. In Proceedings of
the Eighth Workshop on Statistical Machine Trans-
lation, pages 213-218.
Andreas Stolcke and others. 2002. SRILM-An exten-
sible language modeling toolkit. In Proceedings of
the International Conference on Spoken Language
Processing, pages 901-904.
Antonio Toral. 2013. Hybrid selection of language
model training data using linguistic information
and perplexity. In ACL Workshop on Hybrid Ma-
chine Approaches to Translation.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment
models. Computational Linguistics, 29:19-51.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 160-167.
Longyue Wang, Derek F. Wong, Lidia S. Chao, Yi
Lu, and Junwen Xing. 2014 “A Systematic Com-
parison of Data Selection Criteria for SMT Domain
Adaptation,” The Scientific World Journal, vol.
2014, Article ID 745485, 10 pages.
Longyue Wang, Derek F. Wong, Lidia S. Chao, Yi
Lu, Junwen Xing. 2013. iCPE: A Hybrid Data Se-
lection Model for SMT Domain Adaptation. Chi-
nese Computational Linguistics and Natural Lan-
guage Processing Based on Naturally Annotated
Big Data. Springer Berlin Heidelberg. pages, 280-
290.
</reference>
<page confidence="0.998529">
259
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.455798">
<title confidence="0.980559">Domain Adaptation Approaches for Medical Text Translation</title>
<author confidence="0.976335">Longyue Wang</author>
<author confidence="0.976335">Yi Lu</author>
<author confidence="0.976335">Derek F Wong</author>
<author confidence="0.976335">Lidia S Chao</author>
<author confidence="0.976335">Yiming Wang</author>
<author confidence="0.976335">Francisco</author>
<affiliation confidence="0.965430666666667">Natural Language Processing &amp; Portuguese-Chinese Machine Translation Department of Computer and Information University of Macau, Macau, China</affiliation>
<email confidence="0.7481965">vincentwang0229@hotmail.com,{mb25435,derekfw,lidiasc,mb25433,olifran}@umac.mo</email>
<abstract confidence="0.99844994117647">This paper explores a number of simple and effective techniques to adapt statistical machine translation (SMT) systems in the medical domain. Comparative experiments are conducted on large corpora for six language pairs. We not only compare each adapted system with the baseline, but also combine them to further improve the domain-specific systems. Finally, we attend the WMT2014 medical summary sentence translation constrained task and our systems achieve the best BLEU scores for Czech-English, English- German, French-English language pairs and the second best BLEU scores for reminding pairs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amittai Axelrod</author>
<author>Xiaodong He</author>
<author>Jianfeng Gao</author>
</authors>
<title>Domain adaptation via pseudo in-domain data selection.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>355--362</pages>
<contexts>
<context position="10197" citStr="Axelrod et al. (2011)" startWordPosition="1535" endWordPosition="1538">ected as a pseudo in-domain subset to train an additional LM. Finally, we linearly interpolate the additional LM with indomain LM. We use the top N% of ranked results, where N={0, 25, 50, 75, 100} percentages of sentences out of the general corpus. Table 3 shows the absolute BLEU points for Baseline2 (N=0), while the LM adapted systems are listed with values relative to the Baseline2. The results indicate that LM adaptation can gain a reasonable improvement if the LMs are trained on more relevant data for each pair, instead of using the whole training data. For different systems, their BLEU 8 Axelrod et al. (2011) names the selected data as pseudo indomain data. We adopt both terminologies in this paper. scores peak at different values of N. It gives the best results for cs-en, en-fr and de-en pairs when N=25, en-cs and en-de pairs when N=50, and fren pair when N=75. Among them, en-cs and enfr achieve the highest BLEU scores. The reason is that their original monolingual (in-domain) data for training the LMs are not sufficient. When introducing the extra pseudo in-domain data, the systems improve the translation quality by around 2 BLEU points. While for cs-en, fr-en and de-en pairs, the gains are smal</context>
<context position="12878" citStr="Axelrod et al., 2011" startWordPosition="1981" endWordPosition="1984">ugh in content. Lang. Pair BLEU Diff. Corpus en-cs 21.53 +3.96 +601.89% cs-en 33.01 +1.72 en-fr 41.57 +3.21 +693.59% fr-en 47.33 +2.97 en-de 16.54 -1.47 +13.63% de-en 27.35 -5.15 Table 4: The BLEU scores of systems trained on general-domain corpora. Taking into account the performance of general-domain system, we explore various data selection methods to derive the pseudo in-domain sentence pairs from general-domain parallel corpus for enhancing the TMs (Wang et al., 2013; Wang et al., 2014). Firstly, sentence pair in corresponding general-domain corpora is scored by the modified Moore-Lewis (Axelrod et al., 2011), which is calculated as follows: � HI-src (s) - HG-src (s)� score(s) = + [HI-tgt (s) - HG-tgt (s)] (2) which is similar to Eq. (1) and the only difference is that it considers the both the source (src) and target (tgt) sides of parallel corpora. Then top I percentage of ranked sentence pairs are selected as a pseudo in-domain subset to train an individual translation model. The additional model is log-linearly interpolated with the indomain model (Baseline2) using the multidecoding method described in (Koehn and Schroeder, 2007). Similar to LM adaptation, we use the top I% of ranked results, </context>
</contexts>
<marker>Axelrod, He, Gao, 2011</marker>
<rawString>Amittai Axelrod, Xiaodong He, and Jianfeng Gao. 2011. Domain adaptation via pseudo in-domain data selection. In Proceedings of EMNLP, pages 355-362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Duh</author>
<author>G Neubig</author>
<author>K Sudoh</author>
<author>H Tsukada</author>
</authors>
<title>Adaptation data selection using neural language models: Experiments in machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>678--683</pages>
<contexts>
<context position="9125" citStr="Duh et al., 2013" startWordPosition="1349" endWordPosition="1352">.24 In-domain cs 106,548 1,779,677 150,672 16.70 Mono. Data fr 1,424,539 53,839,928 644,484 37.79 de 2,222,502 53,840,304 1,415,202 24.23 en 7,802,610 199430649 1,709,594 25.56 General-domain cs 33,408,340 567,174,266 3,431,946 16.98 Mono. Data fr 30,850,165 780,965,861 2,142,470 25.31 de 84,633,641 1,548,187,668 10,726,992 18.29 en 85,254,788 2,033,096,800 4,488,816 23.85 Table 2: Statistics summary of corpora after pre-processing. only use the in-domain training data, but also the selected pseudo in-domain data8 from generaldomain corpus to enhance the LMs (Toral, 2013; Rubino et al., 2013; Duh et al., 2013). Firstly, each sentence s in general-domain monolingual corpus is scored using the cross-entropy difference method in (Moore and Lewis, 2010), which is calculated as follows: score(s) = HI (s) - HG (s) (1) where H(s) is the length-normalized crossentropy. I and G are the in-domain and generaldomain corpora, respectively. G is a random subset (same size as the I) of the general-domain corpus. Then top N percentages of ranked data sentences are selected as a pseudo in-domain subset to train an additional LM. Finally, we linearly interpolate the additional LM with indomain LM. We use the top N% </context>
</contexts>
<marker>Duh, Neubig, Sudoh, Tsukada, 2013</marker>
<rawString>K. Duh, G. Neubig, K. Sudoh, H. Tsukada. 2013. Adaptation data selection using neural language models: Experiments in machine translation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages, 678–683.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<contexts>
<context position="3693" citStr="Gao and Vogel, 2008" startWordPosition="520" endWordPosition="523">stems. The experiments were carried out with the Moses 1.03 (Koehn et al., 2007). The translation and the re-ordering model utilizes the “growdiag-final” symmetrized word-to-word alignments created with MGIZA++4 (Och and Ney, 1 http://www.statmt.org/wmt14/translation-task.html. 2 http://www.statmt.org/wmt14/medical-task/. 3 http://www.statmt.org/moses/. 4 http://www.kyloo.net/software/doku.php/mgiza:overview. 254 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 254–259, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics 2003; Gao and Vogel, 2008) and the training scripts from Moses. A 5-gram LM was trained using the SRILM toolkit5 (Stolcke et al., 2002), exploiting improved modified Kneser-Ney smoothing, and quantizing both probabilities and back-off weights. For the log-linear model training, we take the minimum-error-rate training (MERT) method as described in (Och, 2003). 3. Task Oriented Pre-processing A careful pre-processing on training data is significant for building a real-life SMT system. In addition to the general data preparing steps used for constructing the baseline system, we introduce some extra steps to pre-process th</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and smaller language model queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>187--197</pages>
<contexts>
<context position="7852" citStr="Heafield, 2011" startWordPosition="1190" endWordPosition="1191">s much higher than those in the other pairs. Hence, Baseline2 will be used in the subsequent comparisons with the proposed systems described in Section 4, 5, 6 and 7. Lang. Pair Baseline1 Baseline2 Diff. en-cs 12.92 17.57 +4.65 cs-en 20.85 31.29 +10.44 en-fr 38.31 38.36 +0.05 fr-en 44.27 44.36 +0.09 en-de 17.81 18.01 +0.20 de-en 32.34 32.50 +0.16 Table 1: BLEU scores of two baseline systems trained on original and processed corpora for different language pairs. 4. Language Model Adaptation The use of LMs (trained on large data) during decoding is aided by more efficient storage and inference (Heafield, 2011). Therefore, we not 7 Data are processed according to Moses baseline tutorial: http://www.statmt.org/moses/?n=Moses.Baseline. 255 Data Set Lang. Sent. Words Vocab. Ave. Len. In-domain cs/en 1,770,421 9,373,482/ 134,998/ 5.29/ Parallel Data 10,605,222 156,402 5.99 de/en 3,894,099 52,211,730/ 1,146,262/ 13.41/ 58,544,608 487,850 15.03 fr/en 4,579,533 77,866,237/ 495,856/ 17.00/ 68,429,649 556,587 14.94 General-domain cs/en 12,426,374 180,349,215/ 1,614,023/ 14.51/ Parallel Data 183,841,805 1,661,830 14.79 de/en 4,421,961 106,001,775/ 1,912,953/ 23.97/ 112,294,414 919,046 25.39 fr/en 36,342,530 1</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187-197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2nd ACL Workshop on Statistical Machine Translation,</booktitle>
<pages>224--227</pages>
<contexts>
<context position="13413" citStr="Koehn and Schroeder, 2007" startWordPosition="2072" endWordPosition="2075">ponding general-domain corpora is scored by the modified Moore-Lewis (Axelrod et al., 2011), which is calculated as follows: � HI-src (s) - HG-src (s)� score(s) = + [HI-tgt (s) - HG-tgt (s)] (2) which is similar to Eq. (1) and the only difference is that it considers the both the source (src) and target (tgt) sides of parallel corpora. Then top I percentage of ranked sentence pairs are selected as a pseudo in-domain subset to train an individual translation model. The additional model is log-linearly interpolated with the indomain model (Baseline2) using the multidecoding method described in (Koehn and Schroeder, 2007). Similar to LM adaptation, we use the top I% of ranked results, where I={0, 25, 50, 75, 100} percentages of sentences out of the general cor9 General-domain systems are trained only on generadomain training corpora (i.e., parallel, monolingual). pus. Table 5 shows the absolute BLEU points for Baseline2 (I=0), while for the TM adapted systems we show the values relative to the Baseline2. For different systems, their BLEU peak at different I. For en-fr and en-de pairs, it gives the best translation results at I=25. Regarding cs-en and fr-en pairs, the optimal performance is peaked at I=50. Whil</context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the 2nd ACL Workshop on Statistical Machine Translation, pages 224-227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="3153" citStr="Koehn et al., 2007" startWordPosition="464" endWordPosition="467">ted words translation are reported in Section 6 and 7. Finally, the performance of design systems and the official results are reported in Section 8. 2. Experimental Setup All available training data from both WMT2014 standard translation task1 (general-domain data) and medical translation task2 (in-domain data) are used in this study. The official medical summary development sets (dev) are used for tuning and evaluating all the comparative systems. The official medical summary test sets (test) are only used in our final submitted systems. The experiments were carried out with the Moses 1.03 (Koehn et al., 2007). The translation and the re-ordering model utilizes the “growdiag-final” symmetrized word-to-word alignments created with MGIZA++4 (Och and Ney, 1 http://www.statmt.org/wmt14/translation-task.html. 2 http://www.statmt.org/wmt14/medical-task/. 3 http://www.statmt.org/moses/. 4 http://www.kyloo.net/software/doku.php/mgiza:overview. 254 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 254–259, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics 2003; Gao and Vogel, 2008) and the training scripts from Moses. A 5-gram LM was traine</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran et al. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of ACL, pages 177-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
<author>William Lewis</author>
</authors>
<title>Intelligent selection of language model training data.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL: Short Papers,</booktitle>
<pages>220--224</pages>
<contexts>
<context position="9267" citStr="Moore and Lewis, 2010" startWordPosition="1370" endWordPosition="1373"> en 7,802,610 199430649 1,709,594 25.56 General-domain cs 33,408,340 567,174,266 3,431,946 16.98 Mono. Data fr 30,850,165 780,965,861 2,142,470 25.31 de 84,633,641 1,548,187,668 10,726,992 18.29 en 85,254,788 2,033,096,800 4,488,816 23.85 Table 2: Statistics summary of corpora after pre-processing. only use the in-domain training data, but also the selected pseudo in-domain data8 from generaldomain corpus to enhance the LMs (Toral, 2013; Rubino et al., 2013; Duh et al., 2013). Firstly, each sentence s in general-domain monolingual corpus is scored using the cross-entropy difference method in (Moore and Lewis, 2010), which is calculated as follows: score(s) = HI (s) - HG (s) (1) where H(s) is the length-normalized crossentropy. I and G are the in-domain and generaldomain corpora, respectively. G is a random subset (same size as the I) of the general-domain corpus. Then top N percentages of ranked data sentences are selected as a pseudo in-domain subset to train an additional LM. Finally, we linearly interpolate the additional LM with indomain LM. We use the top N% of ranked results, where N={0, 25, 50, 75, 100} percentages of sentences out of the general corpus. Table 3 shows the absolute BLEU points for</context>
</contexts>
<marker>Moore, Lewis, 2010</marker>
<rawString>Robert C. Moore and William Lewis. 2010. Intelligent selection of language model training data. In Proceedings of ACL: Short Papers, pages 220-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sætre Rune</author>
</authors>
<title>Kazuhiro Yoshida, Akane Yakushiji, Yusuke Miyao, Yuichiro Matsubayashi and Tomoko Ohta.</title>
<date>2007</date>
<booktitle>in BioCreAtIvE2 challenge, PPI-IPS subtask. In Proceedings of the Second BioCreative Challenge Evaluation Workshop,</booktitle>
<pages>209--212</pages>
<marker>Rune, 2007</marker>
<rawString>Sætre Rune, Kazuhiro Yoshida, Akane Yakushiji, Yusuke Miyao, Yuichiro Matsubayashi and Tomoko Ohta. 2007. AKANE system: protein-protein interaction pairs in BioCreAtIvE2 challenge, PPI-IPS subtask. In Proceedings of the Second BioCreative Challenge Evaluation Workshop, pages 209-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Rubino</author>
</authors>
<title>Antonio Toral, Santiago Cortés Vaíllo,</title>
<date></date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<pages>213--218</pages>
<marker>Rubino, </marker>
<rawString>Raphael Rubino, Antonio Toral, Santiago Cortés Vaíllo, Jun Xie, Xiaofeng Wu, Stephen Doherty, and Qun Liu. 2013. The CNGL-DCU-Prompsit translation systems for WMT13. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 213-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>others</author>
</authors>
<title>SRILM-An extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<marker>Stolcke, others, 2002</marker>
<rawString>Andreas Stolcke and others. 2002. SRILM-An extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing, pages 901-904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Toral</author>
</authors>
<title>Hybrid selection of language model training data using linguistic information and perplexity.</title>
<date>2013</date>
<booktitle>In ACL Workshop on Hybrid Machine Approaches to Translation.</booktitle>
<contexts>
<context position="9085" citStr="Toral, 2013" startWordPosition="1343" endWordPosition="1344">6/ 31.12/ 953,644,980 3,324,481 26.24 In-domain cs 106,548 1,779,677 150,672 16.70 Mono. Data fr 1,424,539 53,839,928 644,484 37.79 de 2,222,502 53,840,304 1,415,202 24.23 en 7,802,610 199430649 1,709,594 25.56 General-domain cs 33,408,340 567,174,266 3,431,946 16.98 Mono. Data fr 30,850,165 780,965,861 2,142,470 25.31 de 84,633,641 1,548,187,668 10,726,992 18.29 en 85,254,788 2,033,096,800 4,488,816 23.85 Table 2: Statistics summary of corpora after pre-processing. only use the in-domain training data, but also the selected pseudo in-domain data8 from generaldomain corpus to enhance the LMs (Toral, 2013; Rubino et al., 2013; Duh et al., 2013). Firstly, each sentence s in general-domain monolingual corpus is scored using the cross-entropy difference method in (Moore and Lewis, 2010), which is calculated as follows: score(s) = HI (s) - HG (s) (1) where H(s) is the length-normalized crossentropy. I and G are the in-domain and generaldomain corpora, respectively. G is a random subset (same size as the I) of the general-domain corpus. Then top N percentages of ranked data sentences are selected as a pseudo in-domain subset to train an additional LM. Finally, we linearly interpolate the additional</context>
</contexts>
<marker>Toral, 2013</marker>
<rawString>Antonio Toral. 2013. Hybrid selection of language model training data using linguistic information and perplexity. In ACL Workshop on Hybrid Machine Approaches to Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<pages>29--19</pages>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29:19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="4027" citStr="Och, 2003" startWordPosition="571" endWordPosition="572">org/moses/. 4 http://www.kyloo.net/software/doku.php/mgiza:overview. 254 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 254–259, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics 2003; Gao and Vogel, 2008) and the training scripts from Moses. A 5-gram LM was trained using the SRILM toolkit5 (Stolcke et al., 2002), exploiting improved modified Kneser-Ney smoothing, and quantizing both probabilities and back-off weights. For the log-linear model training, we take the minimum-error-rate training (MERT) method as described in (Och, 2003). 3. Task Oriented Pre-processing A careful pre-processing on training data is significant for building a real-life SMT system. In addition to the general data preparing steps used for constructing the baseline system, we introduce some extra steps to pre-process the training data. The first step is to remove the duplicate sentences. In data-driven methods, the more frequent a term occurs, the higher probability it biases. Duplicate data may lead to unpredicted behavior during the decoding. Therefore, we keep only the distinct sentences in monolingual corpus. By taking into account multiple tr</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longyue Wang</author>
<author>Derek F Wong</author>
<author>Lidia S Chao</author>
<author>Yi Lu</author>
<author>Junwen Xing</author>
</authors>
<date>2014</date>
<journal>A Systematic Comparison of Data Selection Criteria for SMT Domain Adaptation,” The Scientific World Journal,</journal>
<volume>vol.</volume>
<pages>pages.</pages>
<contexts>
<context position="12753" citStr="Wang et al., 2014" startWordPosition="1963" endWordPosition="1966">generaldomain corpus is able to aid the domain-specific translation task if the general-domain data is large and broad enough in content. Lang. Pair BLEU Diff. Corpus en-cs 21.53 +3.96 +601.89% cs-en 33.01 +1.72 en-fr 41.57 +3.21 +693.59% fr-en 47.33 +2.97 en-de 16.54 -1.47 +13.63% de-en 27.35 -5.15 Table 4: The BLEU scores of systems trained on general-domain corpora. Taking into account the performance of general-domain system, we explore various data selection methods to derive the pseudo in-domain sentence pairs from general-domain parallel corpus for enhancing the TMs (Wang et al., 2013; Wang et al., 2014). Firstly, sentence pair in corresponding general-domain corpora is scored by the modified Moore-Lewis (Axelrod et al., 2011), which is calculated as follows: � HI-src (s) - HG-src (s)� score(s) = + [HI-tgt (s) - HG-tgt (s)] (2) which is similar to Eq. (1) and the only difference is that it considers the both the source (src) and target (tgt) sides of parallel corpora. Then top I percentage of ranked sentence pairs are selected as a pseudo in-domain subset to train an individual translation model. The additional model is log-linearly interpolated with the indomain model (Baseline2) using the m</context>
</contexts>
<marker>Wang, Wong, Chao, Lu, Xing, 2014</marker>
<rawString>Longyue Wang, Derek F. Wong, Lidia S. Chao, Yi Lu, and Junwen Xing. 2014 “A Systematic Comparison of Data Selection Criteria for SMT Domain Adaptation,” The Scientific World Journal, vol. 2014, Article ID 745485, 10 pages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longyue Wang</author>
<author>Derek F Wong</author>
<author>Lidia S Chao</author>
<author>Yi Lu</author>
<author>Junwen Xing</author>
</authors>
<title>iCPE: A Hybrid Data Selection Model for SMT Domain Adaptation. Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data.</title>
<date>2013</date>
<pages>280--290</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="12733" citStr="Wang et al., 2013" startWordPosition="1959" endWordPosition="1962"> a conclusion: the generaldomain corpus is able to aid the domain-specific translation task if the general-domain data is large and broad enough in content. Lang. Pair BLEU Diff. Corpus en-cs 21.53 +3.96 +601.89% cs-en 33.01 +1.72 en-fr 41.57 +3.21 +693.59% fr-en 47.33 +2.97 en-de 16.54 -1.47 +13.63% de-en 27.35 -5.15 Table 4: The BLEU scores of systems trained on general-domain corpora. Taking into account the performance of general-domain system, we explore various data selection methods to derive the pseudo in-domain sentence pairs from general-domain parallel corpus for enhancing the TMs (Wang et al., 2013; Wang et al., 2014). Firstly, sentence pair in corresponding general-domain corpora is scored by the modified Moore-Lewis (Axelrod et al., 2011), which is calculated as follows: � HI-src (s) - HG-src (s)� score(s) = + [HI-tgt (s) - HG-tgt (s)] (2) which is similar to Eq. (1) and the only difference is that it considers the both the source (src) and target (tgt) sides of parallel corpora. Then top I percentage of ranked sentence pairs are selected as a pseudo in-domain subset to train an individual translation model. The additional model is log-linearly interpolated with the indomain model (Ba</context>
</contexts>
<marker>Wang, Wong, Chao, Lu, Xing, 2013</marker>
<rawString>Longyue Wang, Derek F. Wong, Lidia S. Chao, Yi Lu, Junwen Xing. 2013. iCPE: A Hybrid Data Selection Model for SMT Domain Adaptation. Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. Springer Berlin Heidelberg. pages, 280-290.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>