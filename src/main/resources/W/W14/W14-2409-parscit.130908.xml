<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002661">
<title confidence="0.973415">
Low-Dimensional Embeddings of Logic
</title>
<author confidence="0.992578">
Tim Rockt¨aschel§ Matko Bosnjak§ Sameer Singh† Sebastian Riedel§
</author>
<affiliation confidence="0.9871845">
§Department of Computer Science, University College London, UK
†Computer Science &amp; Engineering, University of Washington, Seattle
</affiliation>
<email confidence="0.997928">
{t.rocktaschel,m.bosnjak,s.riedel}@cs.ucl.ac.uk, sameer@cs.washington.edu
</email>
<sectionHeader confidence="0.997393" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999896">
Many machine reading approaches, from
shallow information extraction to deep
semantic parsing, map natural language
to symbolic representations of meaning.
Representations such as first-order logic
capture the richness of natural language
and support complex reasoning, but often
fail in practice due to their reliance on log-
ical background knowledge and the diffi-
culty of scaling up inference. In contrast,
low-dimensional embeddings (i.e. distri-
butional representations) are efficient and
enable generalization, but it is unclear how
reasoning with embeddings could support
the full power of symbolic representations
such as first-order logic. In this proof-of-
concept paper we address this by learning
embeddings that simulate the behavior of
first-order logic.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999959113207547">
Much of the work in machine reading follows an
approach that is, at its heart, symbolic: language
is transformed, possibly in a probabilistic way,
into a symbolic world model such as a relational
database or a knowledge base of first-order for-
mulae. For example, a statistical relation extractor
reads texts and populates relational tables (Mintz
et al., 2009). Likewise, a semantic parser can
turn sentences into complex first-order logic state-
ments (Zettlemoyer and Collins, 2005).
Several properties make symbolic representa-
tions of knowledge attractive as a target of ma-
chine reading. They support a range of well under-
stood symbolic reasoning processes, capture se-
mantic concepts such as determiners, negations
and tense, can be interpreted, edited and curated
by humans to inject prior knowledge. However, on
practical applications fully symbolic approaches
have often shown low recall (e.g. Bos and Markert,
2005) as they are affected by the limited coverage
of ontologies such as WordNet. Moreover, due to
their deterministic nature they often cannot cope
with noise and uncertainty inherent to real world
data, and inference with such representations is
difficult to scale up.
Embedding-based approaches address some of
the concerns above. Here relational worlds are de-
scribed using low-dimensional embeddings of en-
tities and relations based on relational evidence in
knowledge bases (Bordes et al., 2011) or surface-
form relationships mentioned in text (Riedel et al.,
2013). To overcome the generalization bottleneck,
these approaches learn to embed similar entities
and relations as vectors close in distance. Subse-
quently, unseen facts can be inferred by simple and
efficient linear algebra operations (e.g. dot prod-
ucts).
The core argument against embeddings is their
supposed inability to capture deeper semantics,
and more complex patterns of reasoning such
as those enabled by first-order logic (Lewis and
Steedman, 2013). Here we argue that this does
not need to be true. We present an approach that
enables us to learn low-dimensional embeddings
such that the model behaves as if it follows a com-
plex first-order reasoning process—but still oper-
ates in terms of simple vector and matrix repre-
sentations. In this view, machine reading becomes
the process of taking (inherently symbolic) knowl-
edge in language and injecting this knowledge into
a sub-symbolic distributional world model. For
example, one could envision a semantic parser that
turns a sentence into a first-order logic statement,
</bodyText>
<page confidence="0.992798">
45
</page>
<note confidence="0.423115">
Proceedings of the ACL 2014 Workshop on Semantic Parsing, pages 45–49,
Baltimore, Maryland USA, June 26 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.98715">
Figure 1: Information extraction (IE) and semantic
</figureCaption>
<bodyText confidence="0.952484166666667">
parsing (SP) extract factual and more general log-
ical statements from text, respectively. Humans
can manually curate this knowledge. Instead of
reasoning with this knowledge directly (A) we in-
ject it into low dimensional representations of en-
tities and relations (B). Linear algebra operations
manipulate embeddings to derive truth vectors (C),
which can be discretized or thresholded to retrieve
truth values (D).
just to then inject this statement into the embed-
dings of relations and entities mentioned in the
sentence.
</bodyText>
<sectionHeader confidence="0.98772" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999326675675676">
Figure 1 shows our problem setup. We as-
sume a domain of a set of entities, such as
SMITH and CAMBRIDGE, and relations among
these (e.g. profAt(·, ·)). We start from a
knowledge base of observed logical statements,
e.g., profAt(SMITH, CAMBRIDGE) or Vx, y :
profAt(x, y) ==�- worksFor(x, y). These state-
ments can be extracted from text through informa-
tion extraction (for factual statements), be the out-
put from a semantic parsing (for first-order state-
ments) or come from human curators or external
knowledge bases.
The task at hand is to predict the truth
value of unseen statements, for example
worksFor(SMITH, CAMBRIDGE). Assuming we
have the corresponding formulae, logical infer-
ence can be used to arrive at this statement (arrow
A in Figure 1). However, in practice the relevant
background knowledge is usually missing. By
contrast, a range of work (e.g. Bordes et al., 2011;
Riedel et al., 2013) has successfully predicted
unseen factual statements by learning entity and
relation embeddings that recover the observed
facts and generalize to unseen facts through
dimensionality reduction (B). Inference in these
approaches amounts to a series of algebraic
operations on the learned embeddings that returns
a numeric representation of the degree of truth
(C), which can be thresholded to arrive back at a
true or false statement (D) if needed.
Our goal in this view is to generalize (B) to al-
low richer logical statements to be recovered by
low-dimensional embeddings. To this end we first
describe how richer logical statements can be em-
bedded at full dimension where the number of di-
mensions equals to the number of entities in the
domain.
</bodyText>
<subsectionHeader confidence="0.972733">
2.1 Tensor Calculus
</subsectionHeader>
<bodyText confidence="0.999975625">
Grefenstette (2013) presents an isomorphism be-
tween statements in predicate logic and expres-
sions in tensor calculus. Let [·] denote this map-
ping from a logical expression F to an expression
in tensor algebra. Here, logical statements evaluat-
ing to true or false are mapped to [true] :=
T = [1 0]T and [false] := 1 = [0 1]T re-
spectively.
Entities are represented by logical constants and
mapped to one-hot vectors where each component
represents a unique entity. For example, let k = 3
be the number of entities in a domain, then SMITH
maybe mapped to [SMITH] = [1 0 0]T. Unary
predicates are represented as 2xk matrices, whose
columns are composed of T and 1 vectors. For
example, for a isProfessor predicate we may get
</bodyText>
<equation confidence="0.974641333333333">
1 0 1 �
.
0 1 0
</equation>
<bodyText confidence="0.977414545454545">
In this paper we treat binary relations as unary
predicates over constants (X, Y) that correspond to
pairs of entities X and Y in the domain.1
The application of a unary predicate to a con-
stant is realized through matrix-vector multiplica-
tion. For example, for profAt and the entity pair
(X, Y) we get
[profAt((X, Y))] = [profAt] [(X, Y)] .
In Grefenstette’s calculus, binary boolean oper-
ators are mapped to mode 3 tensors. For example,
for the implication operator holds:
</bodyText>
<equation confidence="0.953634333333333">
� 1 0
[ =� ] :=
0 1
</equation>
<bodyText confidence="0.9840225">
Let A and B be two logical statements that,
when evaluated in tensor algebra, yield a vector
</bodyText>
<footnote confidence="0.790427">
1This simplifies our exposition and approach, and it can
be shown that both representations are logically equivalent.
</footnote>
<figure confidence="0.993946105263158">
IE
SP
Curate
Evidence
Logic Embedded Logic
worksFor(A), profAt(A)
profAt(B) ...
profAt(x) =&gt; worksFor(x)
Logical Inference A C Algebra
worksFor(B)
D
B
worksFor
worksFor(B)
profAt
[isProfessor] =
�
1 1 .
0 0
</figure>
<page confidence="0.998081">
46
</page>
<bodyText confidence="0.933312333333333">
in {&gt;,⊥}. The application of a binary operator
to statements A and B is realized via two con-
secutive tensor-vector products in their respective
modes (see Kolda and Bader (2009) for details),
e.g.,
[A =⇒ B] := [ =⇒ ] ×1 [A] ×2 [B] .
</bodyText>
<sectionHeader confidence="0.991734" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.999905333333333">
Grefenstette’s mapping to tensors exactly recov-
ers the behavior of predicate logic. However, it
also inherits the lack of generalization that comes
with a purely symbolic representation. To over-
come this problem we propose an alternate map-
ping. We retain the representation of truth val-
ues and boolean operators as the 2 × 1 and the
2 × 2 × 2 sized tensors respectively. However,
instead of mapping entities and predicates to one-
hot representations, we estimate low-dimensional
embeddings that recover the behavior of their one-
hot counterparts when plugged into a set of tensor-
logic statements.
In the following we first present a general learn-
ing objective that encourages low-dimensional
embeddings to behave like one-hot representa-
tions. Then we show how this objective can be
optimized for facts and implications.
</bodyText>
<subsectionHeader confidence="0.984474">
3.1 Objective
</subsectionHeader>
<bodyText confidence="0.986056384615385">
Let N be the set of all relation embeddings and
q3 be the set of all entity pair embeddings. Given
a knowledge base (KB) of logical formulae K
which we assume to hold, the objective is
F∈K
That is, we prefer embeddings for which the given
formulae evaluate to the vector representation for
truth. The same can be done for negative data by
working with ⊥, but we omit details for brevity.
To optimize this function we require the gradi-
ents of k[F] − &gt;k2 terms. Below we discuss these
for two types of formulae: ground atoms and first-
order formulae.
</bodyText>
<subsectionHeader confidence="0.999499">
3.2 Ground Atoms
</subsectionHeader>
<bodyText confidence="0.99515425">
The KB may contain ground atoms (i.e. facts) of
the form F = R(p) for a pair of entities p and a
relation R. These atoms correspond to observed
cells in an entity-pair-relation matrix, and inject-
ing these facts into the embedding roughly corre-
sponds to matrix factorization for link prediction
or relation extraction (Riedel et al., 2013).
Let ˆηF := ([F] − &gt;) / k[F] − &gt;k2, then it is
easy to show that the gradients with respect to re-
lation embedding [R] and entity pair embedding
[p] are
∂/∂ [p] = [R] ˆηF and ∂/∂ [R] = ˆηF ⊗ [p] .
</bodyText>
<subsectionHeader confidence="0.984389">
3.3 First-order Formulae
</subsectionHeader>
<bodyText confidence="0.999892545454545">
Crucially, and in contrast to matrix factorization,
we can inject more expressive logical formulae
than just ground atoms. For example, the KB
K may contain a universally quantified first-order
rule such as ∀x : R1(x) =⇒ R2(x). Assum-
ing a finite domain, this statement can be unrolled
into a conjunction of propositional statements of
the form F = R1(p) =⇒ R2(p), one for each
pair p. We can directly inject these propositional
statements into the embeddings, and their gradi-
ents are straightfoward to derive. For example,
</bodyText>
<equation confidence="0.455606">
∂/∂ [R1] = (([ =⇒ ] ×2 [R2(p)]) ˆηF) ⊗ [p] .
</equation>
<subsectionHeader confidence="0.995228">
3.4 Learning and Inference
</subsectionHeader>
<bodyText confidence="0.9534655">
We learn embeddings for entity pairs and relations
by minimizing objective 1 using stochastic gradi-
ent descent (SGD). To infer the (two-dimensional)
truth value (C in Figure 1) of a formula F in em-
bedded logic we evaluate [F]. An easier to intpret
one-dimensional representation can be derived by
(h[F], [1 −1]Ti + 1) /2,
followed by truncation to the interval [0, 1]. Other
ways of projecting [F] to IR, such as using cosine
similarity to &gt;, are possible as well.
</bodyText>
<sectionHeader confidence="0.999737" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.996197">
We perform experiments on synthetic data defined
over 7 entity pairs and 6 relations. We fix the em-
bedding size k to 4 and train the model for 100
epochs using SGD with `2-regularization on the
values of the embeddings. The learning rate and
the regularization parameter are set to 0.05.
The left part of Table 1 shows the observed
(bold) and inferred truth values for a set of fac-
tual staments of the form R(p), mapped to IR as
discussed above. Due to the generalization ob-
tained by low-dimensional embeddings, the model
infers that, for example, SMITH is an employee
at CAMBRIDGE and DAVIES lives in LONDON.
However, we would like the model to also capture
that every professor works for his or her university
[P]∈ , [n]∈. 1: k [F] − &gt; k2 . (1)
</bodyText>
<page confidence="0.997909">
47
</page>
<table confidence="0.999406">
profAt worksFor With Factual Constraints livesIn bornIn profAt With Factual and First-Order Constraints bornIn
employeeAt registeredIn worksFor employeeAt registeredIn livesIn
1.00 1.00 1.00 0.00 0.18 0.01 0.98 0.98 0.95 0.03 0.00 0.04
1.00 1.00 0.98 0.00 0.20 0.00 0.98 0.96 0.95 0.05 0.00 0.06
0.98 T 0.00 T 0.64 0.75 0.07 0.72 0.92 T 0.97 T 0.89 0.04 0.04 0.05
1 0.02 1.00 0.08 0.00 0.93 0.02 1 0.05 0.91 0.02 0.05 0.87 0.06
1 0.00 0.97 0.02 1 0.01 0.95 0.06 1 0.01 0.90 0.00 1 0.07 0.92 0.07
0.00 0.00 0.00 0.99 T 0.50 1.00 0.01 0.00 0.00 0.98 T 0.98 0.97
0.00 0.00 0.00 1.00 T 0.48 1.00 0.00 0.00 0.00 0.97 T 1.00 0.96
</table>
<bodyText confidence="0.551247142857143">
hJONES, UWASHi
hTAYLOR, UCLi
hSMITH, CAMBRIDGEi
hWILLIAMS, OXFORDi
hBROWN, CAMBRIDGEi
hDAVIES, LONDONi
hEVANS, PARISi
</bodyText>
<tableCaption confidence="0.893639666666667">
Table 1: Reconstructed matrix without (left) and with (right) the first-order constraints profAt =⇒
worksFor and registeredIn =⇒ livesIn. Predictions for training cells of factual constraints [R(p)] =
&gt; are shown in bold, and true and false test cells are denoted by T and 1 respectively.
</tableCaption>
<bodyText confidence="0.985650214285714">
and that, when somebody is registered in a city, he
or she also lives in that city.
When including such first-order constraints
(right part of Table 1), the model’s predictions
improve concerning different aspects. First, the
model gets the implication right, demonstrating
that the low-dimensional embeddings encode first-
order knowledge. Second, this implication transi-
tively improves the predictions on other columns
(e.g. SMITH is an employee at CAMBRIDGE).
Third, the implication works indeed in an asym-
metric way, e.g., the model does not predict that
WILLIAMS is a professor at OXFORD just because
she is working there.
</bodyText>
<sectionHeader confidence="0.999923" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999978352941176">
The idea of bringing together distributional se-
mantics and formal logic is not new. Lewis and
Steedman (2013) improve the generalization per-
formance of a semantic parser via the use of dis-
tributional representations. However, their target
representation language is still symbolic, and it is
unclear how this approach can cope with noise and
uncertainty in data.
Another line of work (Clark and Pulman, 2007;
Mitchell and Lapata, 2008; Coecke et al., 2010;
Socher et al., 2012; Hermann and Blunsom, 2013)
uses symbolic representations to guide the com-
position of distributional representations. Read-
ing a sentence or logical formula there amounts
to compositionally mapping it to a k-dimensional
vector that then can be used for downstream tasks.
We propose a very different approach: Reading a
sentence amounts to updating the involved entity
pair and relation embeddings such that the sen-
tence evaluates to true. Afterwards we cannot use
the embeddings to calculate sentence similarities,
but to answer relational questions about the world.
Similar to our work, Bowman (2014) provides
further evidence that distributed representations
can indeed capture logical reasoning. Although
Bowman demonstrates this on natural logic ex-
pressions without capturing factual statements,
one can think of ways to include the latter in
his framework as well. However, the ap-
proach presented here can conceptually inject
complex nested logical statements into embed-
dings, whereas it is not obvious how this can be
achieved in the neural-network based multi-class
classification framework proposed by Bowman.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99993828">
We have argued that low dimensional embeddings
of entities and relations may be tuned to simu-
late the behavior of logic and hence combine the
advantages of distributional representations with
those of their symbolic counterparts. As a first
step into this direction we have presented an ob-
jective that encourages embeddings to be consis-
tent with a given logical knowledge base that in-
cludes facts and first-order rules. On a small syn-
thetic dataset we optimize this objective with SGD
to learn low-dimensional embeddings that indeed
follow the behavior of the knowledge base.
Clearly we have only scratched the surface
here. Besides only using toy data and logical for-
mulae of very limited expressiveness, there are
fundamental questions we have yet to address.
For example, even if the embeddings could en-
able perfect logical reasoning, how do we pro-
vide provenance or proofs of answers? More-
over, in practice a machine reader (e.g. a semantic
parser) incrementally gathers logical statements
from text— how could we incrementally inject this
knowledge into embeddings without retraining the
whole model? Finally, what are the theoretical
limits of embedding logic in vector spaces?
</bodyText>
<page confidence="0.998861">
48
</page>
<sectionHeader confidence="0.999214" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999990454545454">
We would like to thank Giorgos Spithourakis,
Thore Graepel, Karl Moritz Hermann and Ed-
ward Grefenstette for helpful discussions, and An-
dreas Vlachos for comments on the manuscript.
This work was supported by Microsoft Research
through its PhD Scholarship Programme. This
work was supported in part by the TerraSwarm Re-
search Center, one of six centers supported by the
STARnet phase of the Focus Center Research Pro-
gram (FCRP) a Semiconductor Research Corpora-
tion program sponsored by MARCO and DARPA.
</bodyText>
<sectionHeader confidence="0.999433" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999801865384616">
Antoine Bordes, Jason Weston, Ronan Collobert,
and Yoshua Bengio. 2011. Learning structured
embeddings of knowledge bases. In AAAI.
Johan Bos and Katja Markert. 2005. Recognis-
ing textual entailment with logical inference. In
Proc. of HLT/EMNLP, pages 628–635.
Samuel R Bowman. 2014. Can recursive neural
tensor networks learn logical reasoning? In
ICLR’14.
Stephen Clark and Stephen Pulman. 2007. Com-
bining symbolic and distributional models of
meaning. In AAAI Spring Symposium: Quan-
tum Interaction, pages 52–55.
Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen
Clark. 2010. Mathematical foundations for a
compositional distributional model of meaning.
CoRR, abs/1003.4394.
Edward Grefenstette. 2013. Towards a formal dis-
tributional semantics: Simulating logical calculi
with tensors. In Proc. of *SEM, pages 1–10.
Karl Moritz Hermann and Phil Blunsom. 2013.
The role of syntax in vector space models of
compositional semantics. In Proc. of ACL,
pages 894–904.
Tamara G Kolda and Brett W Bader. 2009. Tensor
decompositions and applications. SIAM review,
51(3):455–500.
Mike Lewis and Mark Steedman. 2013. Combined
distributional and logical semantics. In TACL,
volume 1, pages 179–192.
Mike Mintz, Steven Bills, Rion Snow, and Daniel
Jurafsky. 2009. Distant supervision for rela-
tion extraction without labeled data. In Proc.
ofACL-IJCNLP, pages 1003–1011.
Jeff Mitchell and Mirella Lapata. 2008. Vector-
based models of semantic composition. In Proc.
of ACL, pages 236–244.
Sebastian Riedel, Limin Yao, Andrew McCallum,
and Benjamin M Marlin. 2013. Relation ex-
traction with matrix factorization and universal
schemas. In Proc. of NAACL-HLT, pages 74–
84.
Richard Socher, Brody Huval, Christopher D
Manning, and Andrew Y Ng. 2012. Seman-
tic compositionality through recursive matrix-
vector spaces. In Proc. of EMNLP, pages 1201–
1211.
Luke S Zettlemoyer and Michael Collins. 2005.
Learning to map sentences to logical form:
Structured classification with probabilistic cat-
egorial grammars. In Proc. of UAI, pages 658–
666.
</reference>
<page confidence="0.999542">
49
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.225249">
<title confidence="0.39903">Low-Dimensional Embeddings of Logic of Computer Science, University College London, UK</title>
<author confidence="0.329395">Science</author>
<author confidence="0.329395">University of Washington Engineering</author>
<author confidence="0.329395">Seattle</author>
<abstract confidence="0.9988345">Many machine reading approaches, from shallow information extraction to deep semantic parsing, map natural language to symbolic representations of meaning. Representations such as first-order logic capture the richness of natural language and support complex reasoning, but often fail in practice due to their reliance on logical background knowledge and the difficulty of scaling up inference. In contrast, embeddings distributional representations) are efficient and enable generalization, but it is unclear how reasoning with embeddings could support the full power of symbolic representations such as first-order logic. In this proof-ofconcept paper we address this by learning embeddings that simulate the behavior of first-order logic.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Jason Weston</author>
<author>Ronan Collobert</author>
<author>Yoshua Bengio</author>
</authors>
<title>Learning structured embeddings of knowledge bases.</title>
<date>2011</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="2507" citStr="Bordes et al., 2011" startWordPosition="353" endWordPosition="356">owledge. However, on practical applications fully symbolic approaches have often shown low recall (e.g. Bos and Markert, 2005) as they are affected by the limited coverage of ontologies such as WordNet. Moreover, due to their deterministic nature they often cannot cope with noise and uncertainty inherent to real world data, and inference with such representations is difficult to scale up. Embedding-based approaches address some of the concerns above. Here relational worlds are described using low-dimensional embeddings of entities and relations based on relational evidence in knowledge bases (Bordes et al., 2011) or surfaceform relationships mentioned in text (Riedel et al., 2013). To overcome the generalization bottleneck, these approaches learn to embed similar entities and relations as vectors close in distance. Subsequently, unseen facts can be inferred by simple and efficient linear algebra operations (e.g. dot products). The core argument against embeddings is their supposed inability to capture deeper semantics, and more complex patterns of reasoning such as those enabled by first-order logic (Lewis and Steedman, 2013). Here we argue that this does not need to be true. We present an approach th</context>
<context position="5232" citStr="Bordes et al., 2011" startWordPosition="781" endWordPosition="784">At(x, y) ==�- worksFor(x, y). These statements can be extracted from text through information extraction (for factual statements), be the output from a semantic parsing (for first-order statements) or come from human curators or external knowledge bases. The task at hand is to predict the truth value of unseen statements, for example worksFor(SMITH, CAMBRIDGE). Assuming we have the corresponding formulae, logical inference can be used to arrive at this statement (arrow A in Figure 1). However, in practice the relevant background knowledge is usually missing. By contrast, a range of work (e.g. Bordes et al., 2011; Riedel et al., 2013) has successfully predicted unseen factual statements by learning entity and relation embeddings that recover the observed facts and generalize to unseen facts through dimensionality reduction (B). Inference in these approaches amounts to a series of algebraic operations on the learned embeddings that returns a numeric representation of the degree of truth (C), which can be thresholded to arrive back at a true or false statement (D) if needed. Our goal in this view is to generalize (B) to allow richer logical statements to be recovered by low-dimensional embeddings. To th</context>
</contexts>
<marker>Bordes, Weston, Collobert, Bengio, 2011</marker>
<rawString>Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embeddings of knowledge bases. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>Recognising textual entailment with logical inference.</title>
<date>2005</date>
<booktitle>In Proc. of HLT/EMNLP,</booktitle>
<pages>628--635</pages>
<contexts>
<context position="2013" citStr="Bos and Markert, 2005" startWordPosition="278" endWordPosition="281">ads texts and populates relational tables (Mintz et al., 2009). Likewise, a semantic parser can turn sentences into complex first-order logic statements (Zettlemoyer and Collins, 2005). Several properties make symbolic representations of knowledge attractive as a target of machine reading. They support a range of well understood symbolic reasoning processes, capture semantic concepts such as determiners, negations and tense, can be interpreted, edited and curated by humans to inject prior knowledge. However, on practical applications fully symbolic approaches have often shown low recall (e.g. Bos and Markert, 2005) as they are affected by the limited coverage of ontologies such as WordNet. Moreover, due to their deterministic nature they often cannot cope with noise and uncertainty inherent to real world data, and inference with such representations is difficult to scale up. Embedding-based approaches address some of the concerns above. Here relational worlds are described using low-dimensional embeddings of entities and relations based on relational evidence in knowledge bases (Bordes et al., 2011) or surfaceform relationships mentioned in text (Riedel et al., 2013). To overcome the generalization bott</context>
</contexts>
<marker>Bos, Markert, 2005</marker>
<rawString>Johan Bos and Katja Markert. 2005. Recognising textual entailment with logical inference. In Proc. of HLT/EMNLP, pages 628–635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel R Bowman</author>
</authors>
<title>Can recursive neural tensor networks learn logical reasoning?</title>
<date>2014</date>
<booktitle>In ICLR’14.</booktitle>
<contexts>
<context position="14443" citStr="Bowman (2014)" startWordPosition="2364" endWordPosition="2365">et al., 2012; Hermann and Blunsom, 2013) uses symbolic representations to guide the composition of distributional representations. Reading a sentence or logical formula there amounts to compositionally mapping it to a k-dimensional vector that then can be used for downstream tasks. We propose a very different approach: Reading a sentence amounts to updating the involved entity pair and relation embeddings such that the sentence evaluates to true. Afterwards we cannot use the embeddings to calculate sentence similarities, but to answer relational questions about the world. Similar to our work, Bowman (2014) provides further evidence that distributed representations can indeed capture logical reasoning. Although Bowman demonstrates this on natural logic expressions without capturing factual statements, one can think of ways to include the latter in his framework as well. However, the approach presented here can conceptually inject complex nested logical statements into embeddings, whereas it is not obvious how this can be achieved in the neural-network based multi-class classification framework proposed by Bowman. 6 Conclusion We have argued that low dimensional embeddings of entities and relatio</context>
</contexts>
<marker>Bowman, 2014</marker>
<rawString>Samuel R Bowman. 2014. Can recursive neural tensor networks learn logical reasoning? In ICLR’14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>Stephen Pulman</author>
</authors>
<title>Combining symbolic and distributional models of meaning.</title>
<date>2007</date>
<booktitle>In AAAI Spring Symposium: Quantum Interaction,</booktitle>
<pages>52--55</pages>
<contexts>
<context position="13773" citStr="Clark and Pulman, 2007" startWordPosition="2259" endWordPosition="2262">MITH is an employee at CAMBRIDGE). Third, the implication works indeed in an asymmetric way, e.g., the model does not predict that WILLIAMS is a professor at OXFORD just because she is working there. 5 Related Work The idea of bringing together distributional semantics and formal logic is not new. Lewis and Steedman (2013) improve the generalization performance of a semantic parser via the use of distributional representations. However, their target representation language is still symbolic, and it is unclear how this approach can cope with noise and uncertainty in data. Another line of work (Clark and Pulman, 2007; Mitchell and Lapata, 2008; Coecke et al., 2010; Socher et al., 2012; Hermann and Blunsom, 2013) uses symbolic representations to guide the composition of distributional representations. Reading a sentence or logical formula there amounts to compositionally mapping it to a k-dimensional vector that then can be used for downstream tasks. We propose a very different approach: Reading a sentence amounts to updating the involved entity pair and relation embeddings such that the sentence evaluates to true. Afterwards we cannot use the embeddings to calculate sentence similarities, but to answer re</context>
</contexts>
<marker>Clark, Pulman, 2007</marker>
<rawString>Stephen Clark and Stephen Pulman. 2007. Combining symbolic and distributional models of meaning. In AAAI Spring Symposium: Quantum Interaction, pages 52–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coecke</author>
<author>Mehrnoosh Sadrzadeh</author>
<author>Stephen Clark</author>
</authors>
<title>Mathematical foundations for a compositional distributional model of meaning.</title>
<date>2010</date>
<journal>CoRR,</journal>
<pages>1003--4394</pages>
<contexts>
<context position="13821" citStr="Coecke et al., 2010" startWordPosition="2267" endWordPosition="2270">cation works indeed in an asymmetric way, e.g., the model does not predict that WILLIAMS is a professor at OXFORD just because she is working there. 5 Related Work The idea of bringing together distributional semantics and formal logic is not new. Lewis and Steedman (2013) improve the generalization performance of a semantic parser via the use of distributional representations. However, their target representation language is still symbolic, and it is unclear how this approach can cope with noise and uncertainty in data. Another line of work (Clark and Pulman, 2007; Mitchell and Lapata, 2008; Coecke et al., 2010; Socher et al., 2012; Hermann and Blunsom, 2013) uses symbolic representations to guide the composition of distributional representations. Reading a sentence or logical formula there amounts to compositionally mapping it to a k-dimensional vector that then can be used for downstream tasks. We propose a very different approach: Reading a sentence amounts to updating the involved entity pair and relation embeddings such that the sentence evaluates to true. Afterwards we cannot use the embeddings to calculate sentence similarities, but to answer relational questions about the world. Similar to o</context>
</contexts>
<marker>Coecke, Sadrzadeh, Clark, 2010</marker>
<rawString>Bob Coecke, Mehrnoosh Sadrzadeh, and Stephen Clark. 2010. Mathematical foundations for a compositional distributional model of meaning. CoRR, abs/1003.4394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Grefenstette</author>
</authors>
<title>Towards a formal distributional semantics: Simulating logical calculi with tensors.</title>
<date>2013</date>
<booktitle>In Proc. of *SEM,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="6039" citStr="Grefenstette (2013)" startWordPosition="913" endWordPosition="914">h dimensionality reduction (B). Inference in these approaches amounts to a series of algebraic operations on the learned embeddings that returns a numeric representation of the degree of truth (C), which can be thresholded to arrive back at a true or false statement (D) if needed. Our goal in this view is to generalize (B) to allow richer logical statements to be recovered by low-dimensional embeddings. To this end we first describe how richer logical statements can be embedded at full dimension where the number of dimensions equals to the number of entities in the domain. 2.1 Tensor Calculus Grefenstette (2013) presents an isomorphism between statements in predicate logic and expressions in tensor calculus. Let [·] denote this mapping from a logical expression F to an expression in tensor algebra. Here, logical statements evaluating to true or false are mapped to [true] := T = [1 0]T and [false] := 1 = [0 1]T respectively. Entities are represented by logical constants and mapped to one-hot vectors where each component represents a unique entity. For example, let k = 3 be the number of entities in a domain, then SMITH maybe mapped to [SMITH] = [1 0 0]T. Unary predicates are represented as 2xk matrice</context>
</contexts>
<marker>Grefenstette, 2013</marker>
<rawString>Edward Grefenstette. 2013. Towards a formal distributional semantics: Simulating logical calculi with tensors. In Proc. of *SEM, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Moritz Hermann</author>
<author>Phil Blunsom</author>
</authors>
<title>The role of syntax in vector space models of compositional semantics.</title>
<date>2013</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>894--904</pages>
<contexts>
<context position="13870" citStr="Hermann and Blunsom, 2013" startWordPosition="2275" endWordPosition="2278">e.g., the model does not predict that WILLIAMS is a professor at OXFORD just because she is working there. 5 Related Work The idea of bringing together distributional semantics and formal logic is not new. Lewis and Steedman (2013) improve the generalization performance of a semantic parser via the use of distributional representations. However, their target representation language is still symbolic, and it is unclear how this approach can cope with noise and uncertainty in data. Another line of work (Clark and Pulman, 2007; Mitchell and Lapata, 2008; Coecke et al., 2010; Socher et al., 2012; Hermann and Blunsom, 2013) uses symbolic representations to guide the composition of distributional representations. Reading a sentence or logical formula there amounts to compositionally mapping it to a k-dimensional vector that then can be used for downstream tasks. We propose a very different approach: Reading a sentence amounts to updating the involved entity pair and relation embeddings such that the sentence evaluates to true. Afterwards we cannot use the embeddings to calculate sentence similarities, but to answer relational questions about the world. Similar to our work, Bowman (2014) provides further evidence </context>
</contexts>
<marker>Hermann, Blunsom, 2013</marker>
<rawString>Karl Moritz Hermann and Phil Blunsom. 2013. The role of syntax in vector space models of compositional semantics. In Proc. of ACL, pages 894–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tamara G Kolda</author>
<author>Brett W Bader</author>
</authors>
<title>Tensor decompositions and applications.</title>
<date>2009</date>
<journal>SIAM review,</journal>
<volume>51</volume>
<issue>3</issue>
<contexts>
<context position="7848" citStr="Kolda and Bader (2009)" startWordPosition="1233" endWordPosition="1236">ds: � 1 0 [ =� ] := 0 1 Let A and B be two logical statements that, when evaluated in tensor algebra, yield a vector 1This simplifies our exposition and approach, and it can be shown that both representations are logically equivalent. IE SP Curate Evidence Logic Embedded Logic worksFor(A), profAt(A) profAt(B) ... profAt(x) =&gt; worksFor(x) Logical Inference A C Algebra worksFor(B) D B worksFor worksFor(B) profAt [isProfessor] = � 1 1 . 0 0 46 in {&gt;,⊥}. The application of a binary operator to statements A and B is realized via two consecutive tensor-vector products in their respective modes (see Kolda and Bader (2009) for details), e.g., [A =⇒ B] := [ =⇒ ] ×1 [A] ×2 [B] . 3 Method Grefenstette’s mapping to tensors exactly recovers the behavior of predicate logic. However, it also inherits the lack of generalization that comes with a purely symbolic representation. To overcome this problem we propose an alternate mapping. We retain the representation of truth values and boolean operators as the 2 × 1 and the 2 × 2 × 2 sized tensors respectively. However, instead of mapping entities and predicates to onehot representations, we estimate low-dimensional embeddings that recover the behavior of their onehot coun</context>
</contexts>
<marker>Kolda, Bader, 2009</marker>
<rawString>Tamara G Kolda and Brett W Bader. 2009. Tensor decompositions and applications. SIAM review, 51(3):455–500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>Combined distributional and logical semantics.</title>
<date>2013</date>
<booktitle>In TACL,</booktitle>
<volume>1</volume>
<pages>179--192</pages>
<contexts>
<context position="3030" citStr="Lewis and Steedman, 2013" startWordPosition="431" endWordPosition="434">ddings of entities and relations based on relational evidence in knowledge bases (Bordes et al., 2011) or surfaceform relationships mentioned in text (Riedel et al., 2013). To overcome the generalization bottleneck, these approaches learn to embed similar entities and relations as vectors close in distance. Subsequently, unseen facts can be inferred by simple and efficient linear algebra operations (e.g. dot products). The core argument against embeddings is their supposed inability to capture deeper semantics, and more complex patterns of reasoning such as those enabled by first-order logic (Lewis and Steedman, 2013). Here we argue that this does not need to be true. We present an approach that enables us to learn low-dimensional embeddings such that the model behaves as if it follows a complex first-order reasoning process—but still operates in terms of simple vector and matrix representations. In this view, machine reading becomes the process of taking (inherently symbolic) knowledge in language and injecting this knowledge into a sub-symbolic distributional world model. For example, one could envision a semantic parser that turns a sentence into a first-order logic statement, 45 Proceedings of the ACL </context>
<context position="13475" citStr="Lewis and Steedman (2013)" startWordPosition="2212" endWordPosition="2215">ts (right part of Table 1), the model’s predictions improve concerning different aspects. First, the model gets the implication right, demonstrating that the low-dimensional embeddings encode firstorder knowledge. Second, this implication transitively improves the predictions on other columns (e.g. SMITH is an employee at CAMBRIDGE). Third, the implication works indeed in an asymmetric way, e.g., the model does not predict that WILLIAMS is a professor at OXFORD just because she is working there. 5 Related Work The idea of bringing together distributional semantics and formal logic is not new. Lewis and Steedman (2013) improve the generalization performance of a semantic parser via the use of distributional representations. However, their target representation language is still symbolic, and it is unclear how this approach can cope with noise and uncertainty in data. Another line of work (Clark and Pulman, 2007; Mitchell and Lapata, 2008; Coecke et al., 2010; Socher et al., 2012; Hermann and Blunsom, 2013) uses symbolic representations to guide the composition of distributional representations. Reading a sentence or logical formula there amounts to compositionally mapping it to a k-dimensional vector that t</context>
</contexts>
<marker>Lewis, Steedman, 2013</marker>
<rawString>Mike Lewis and Mark Steedman. 2013. Combined distributional and logical semantics. In TACL, volume 1, pages 179–192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data. In</title>
<date>2009</date>
<booktitle>Proc. ofACL-IJCNLP,</booktitle>
<pages>1003--1011</pages>
<contexts>
<context position="1453" citStr="Mintz et al., 2009" startWordPosition="195" endWordPosition="198"> is unclear how reasoning with embeddings could support the full power of symbolic representations such as first-order logic. In this proof-ofconcept paper we address this by learning embeddings that simulate the behavior of first-order logic. 1 Introduction Much of the work in machine reading follows an approach that is, at its heart, symbolic: language is transformed, possibly in a probabilistic way, into a symbolic world model such as a relational database or a knowledge base of first-order formulae. For example, a statistical relation extractor reads texts and populates relational tables (Mintz et al., 2009). Likewise, a semantic parser can turn sentences into complex first-order logic statements (Zettlemoyer and Collins, 2005). Several properties make symbolic representations of knowledge attractive as a target of machine reading. They support a range of well understood symbolic reasoning processes, capture semantic concepts such as determiners, negations and tense, can be interpreted, edited and curated by humans to inject prior knowledge. However, on practical applications fully symbolic approaches have often shown low recall (e.g. Bos and Markert, 2005) as they are affected by the limited cov</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proc. ofACL-IJCNLP, pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Vectorbased models of semantic composition.</title>
<date>2008</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>236--244</pages>
<contexts>
<context position="13800" citStr="Mitchell and Lapata, 2008" startWordPosition="2263" endWordPosition="2266">AMBRIDGE). Third, the implication works indeed in an asymmetric way, e.g., the model does not predict that WILLIAMS is a professor at OXFORD just because she is working there. 5 Related Work The idea of bringing together distributional semantics and formal logic is not new. Lewis and Steedman (2013) improve the generalization performance of a semantic parser via the use of distributional representations. However, their target representation language is still symbolic, and it is unclear how this approach can cope with noise and uncertainty in data. Another line of work (Clark and Pulman, 2007; Mitchell and Lapata, 2008; Coecke et al., 2010; Socher et al., 2012; Hermann and Blunsom, 2013) uses symbolic representations to guide the composition of distributional representations. Reading a sentence or logical formula there amounts to compositionally mapping it to a k-dimensional vector that then can be used for downstream tasks. We propose a very different approach: Reading a sentence amounts to updating the involved entity pair and relation embeddings such that the sentence evaluates to true. Afterwards we cannot use the embeddings to calculate sentence similarities, but to answer relational questions about th</context>
</contexts>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2008. Vectorbased models of semantic composition. In Proc. of ACL, pages 236–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
<author>Benjamin M Marlin</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In Proc. of NAACL-HLT,</booktitle>
<pages>74--84</pages>
<contexts>
<context position="2576" citStr="Riedel et al., 2013" startWordPosition="364" endWordPosition="367"> have often shown low recall (e.g. Bos and Markert, 2005) as they are affected by the limited coverage of ontologies such as WordNet. Moreover, due to their deterministic nature they often cannot cope with noise and uncertainty inherent to real world data, and inference with such representations is difficult to scale up. Embedding-based approaches address some of the concerns above. Here relational worlds are described using low-dimensional embeddings of entities and relations based on relational evidence in knowledge bases (Bordes et al., 2011) or surfaceform relationships mentioned in text (Riedel et al., 2013). To overcome the generalization bottleneck, these approaches learn to embed similar entities and relations as vectors close in distance. Subsequently, unseen facts can be inferred by simple and efficient linear algebra operations (e.g. dot products). The core argument against embeddings is their supposed inability to capture deeper semantics, and more complex patterns of reasoning such as those enabled by first-order logic (Lewis and Steedman, 2013). Here we argue that this does not need to be true. We present an approach that enables us to learn low-dimensional embeddings such that the model</context>
<context position="5254" citStr="Riedel et al., 2013" startWordPosition="785" endWordPosition="788">r(x, y). These statements can be extracted from text through information extraction (for factual statements), be the output from a semantic parsing (for first-order statements) or come from human curators or external knowledge bases. The task at hand is to predict the truth value of unseen statements, for example worksFor(SMITH, CAMBRIDGE). Assuming we have the corresponding formulae, logical inference can be used to arrive at this statement (arrow A in Figure 1). However, in practice the relevant background knowledge is usually missing. By contrast, a range of work (e.g. Bordes et al., 2011; Riedel et al., 2013) has successfully predicted unseen factual statements by learning entity and relation embeddings that recover the observed facts and generalize to unseen facts through dimensionality reduction (B). Inference in these approaches amounts to a series of algebraic operations on the learned embeddings that returns a numeric representation of the degree of truth (C), which can be thresholded to arrive back at a true or false statement (D) if needed. Our goal in this view is to generalize (B) to allow richer logical statements to be recovered by low-dimensional embeddings. To this end we first descri</context>
<context position="9648" citStr="Riedel et al., 2013" startWordPosition="1545" endWordPosition="1548">on for truth. The same can be done for negative data by working with ⊥, but we omit details for brevity. To optimize this function we require the gradients of k[F] − &gt;k2 terms. Below we discuss these for two types of formulae: ground atoms and firstorder formulae. 3.2 Ground Atoms The KB may contain ground atoms (i.e. facts) of the form F = R(p) for a pair of entities p and a relation R. These atoms correspond to observed cells in an entity-pair-relation matrix, and injecting these facts into the embedding roughly corresponds to matrix factorization for link prediction or relation extraction (Riedel et al., 2013). Let ˆηF := ([F] − &gt;) / k[F] − &gt;k2, then it is easy to show that the gradients with respect to relation embedding [R] and entity pair embedding [p] are ∂/∂ [p] = [R] ˆηF and ∂/∂ [R] = ˆηF ⊗ [p] . 3.3 First-order Formulae Crucially, and in contrast to matrix factorization, we can inject more expressive logical formulae than just ground atoms. For example, the KB K may contain a universally quantified first-order rule such as ∀x : R1(x) =⇒ R2(x). Assuming a finite domain, this statement can be unrolled into a conjunction of propositional statements of the form F = R1(p) =⇒ R2(p), one for each p</context>
</contexts>
<marker>Riedel, Yao, McCallum, Marlin, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In Proc. of NAACL-HLT, pages 74– 84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrixvector spaces.</title>
<date>2012</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>1201--1211</pages>
<contexts>
<context position="13842" citStr="Socher et al., 2012" startWordPosition="2271" endWordPosition="2274">n an asymmetric way, e.g., the model does not predict that WILLIAMS is a professor at OXFORD just because she is working there. 5 Related Work The idea of bringing together distributional semantics and formal logic is not new. Lewis and Steedman (2013) improve the generalization performance of a semantic parser via the use of distributional representations. However, their target representation language is still symbolic, and it is unclear how this approach can cope with noise and uncertainty in data. Another line of work (Clark and Pulman, 2007; Mitchell and Lapata, 2008; Coecke et al., 2010; Socher et al., 2012; Hermann and Blunsom, 2013) uses symbolic representations to guide the composition of distributional representations. Reading a sentence or logical formula there amounts to compositionally mapping it to a k-dimensional vector that then can be used for downstream tasks. We propose a very different approach: Reading a sentence amounts to updating the involved entity pair and relation embeddings such that the sentence evaluates to true. Afterwards we cannot use the embeddings to calculate sentence similarities, but to answer relational questions about the world. Similar to our work, Bowman (2014</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D Manning, and Andrew Y Ng. 2012. Semantic compositionality through recursive matrixvector spaces. In Proc. of EMNLP, pages 1201– 1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In Proc. of UAI,</booktitle>
<pages>658--666</pages>
<contexts>
<context position="1575" citStr="Zettlemoyer and Collins, 2005" startWordPosition="212" endWordPosition="215">t-order logic. In this proof-ofconcept paper we address this by learning embeddings that simulate the behavior of first-order logic. 1 Introduction Much of the work in machine reading follows an approach that is, at its heart, symbolic: language is transformed, possibly in a probabilistic way, into a symbolic world model such as a relational database or a knowledge base of first-order formulae. For example, a statistical relation extractor reads texts and populates relational tables (Mintz et al., 2009). Likewise, a semantic parser can turn sentences into complex first-order logic statements (Zettlemoyer and Collins, 2005). Several properties make symbolic representations of knowledge attractive as a target of machine reading. They support a range of well understood symbolic reasoning processes, capture semantic concepts such as determiners, negations and tense, can be interpreted, edited and curated by humans to inject prior knowledge. However, on practical applications fully symbolic approaches have often shown low recall (e.g. Bos and Markert, 2005) as they are affected by the limited coverage of ontologies such as WordNet. Moreover, due to their deterministic nature they often cannot cope with noise and unc</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>Luke S Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proc. of UAI, pages 658– 666.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>