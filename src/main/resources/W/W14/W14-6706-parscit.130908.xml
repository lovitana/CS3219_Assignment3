<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<note confidence="0.891582">
21�me Traitement Automatique des Langues Naturelles, Marseille, 2014 [RLTLN-O.6]
</note>
<title confidence="0.504001">
Stocker des Mots ne Garantit nullement leur Acces.
</title>
<author confidence="0.867702">
Michael Zock1 Didier Schwab2
</author>
<address confidence="0.689897">
(1) CNRS, Aix Marseille Universite
(2) Univ. Grenoble Alpes
</address>
<email confidence="0.918697">
michael.zock@lif.univ-marseille.fr, didier.schwab@imag.fr
</email>
<bodyText confidence="0.999423975">
Résumé. L’objectif de ce papier est double : (a) montrer que le stockage ou la memorisation d’une forme lexicale
ne garantit nullement son acces ou sa disponibilite, et (b) decrire les etapes necessaires pour construire une ressource
susceptible d’aider les redacteurs ˆ trouver le mot bloque sur le bout de leur langue (ou de leur plume).
Pour verifier le premier point, nous avons realise une petite experience en comparant deux ressources pour voir si elles
nous permettaient de trouver le terme recherché (mot cible) et si l’acces etait facile. Les ressources en question sont
WordNet, ou plutTMt une version etendue, eXtended WordNet (xWN) et Wikipedia (WP), converti par nous en une
ressource lexicale, nommee WordFinder (WF). Il s’avere que cette derniere ressource permet generalement ˆ trouver
assez rapidement le terme recherché, alors que xWN y echoue souvent, ou lorsqu’il y parvient, l’element en question se
trouve assez loin dans la liste des candidats. Ceci para”t surprenant dans la mesure oa les deux ressources ‘possedent’ le
meme vocabulaire. Cependant la situation devient vite assez claire lorsqu’on regarde les liens entre les mots (l’index ou
l’organisation lexicale) des deux ressources. Contrairement ˆ WN, WF contient beaucoup de liens syntagmatiques
(café-noir ; cafe-Bresil ; café-Starbucks,...), permettant de ce fait d’acceder au mot cible par un bien plus grand nombre
de mots source.
Ayant montre que ‘stockage’ n’implique pas forcement ‘acces’ ou disponibilite, nous presentons ensuite une feuille de
route, esquissant les elements ˆ elaborer pour construire une ressource susceptible d’aider des redacteurs ˆ trouver le
mot bloque sur le bout de la langue. La construction de notre future ressource est basee sur les raisonnement suivants.
L’acces lexical consiste essentiellement ˆ localiser un element parmi l’ensemble des formes lexicales stockees dans la
ressource lexicale (dictionnaire). Comme il est deraisonnable de chercher le mot cible parmi l’ensemble des formes
stockees, nous proposons de decomposer ce processus en deux etapes. Dans un premier temps nous essayons de reduire
l&apos;espace initial ˆ un ensemble plus petit. A cette fin on presentera tous les mots directement associes au(x) mot(s) source
(l’entree), mot(s) disponible(s), et mot(s) auquel(s) on pense spontanement en cherchant la cible. Dans un deuxieme
temps on essayera de guider l’utilisateur en lui presentant une version structuree des mots obtenus lors de la phase
precedente. Pour atteindre ce dernier objectif il faut donc structurer la liste des mots, ce qui veut dire, qu’il faut former
des groupes (clusters) auxquels on donne des noms (arbre categoriel). Le defi ici est de nommer ces groupes, parce que
c&apos;est sur cette base (le nom de ces categories) que l&apos;utilisateur decidera dans quelle direction aller pour chercher le mot
dans un ‘paquet’ particulier.
Abstract. Dealing with word access in language production we pursue here two goals: (a) provide evidence that
&apos;storage&apos; does not imply &apos;access&apos; (or, accessibility) ; (b) describe the steps to be carried out to build a resource allowing
for interactive word finding.
In order to show evidence for the first claim we compared two resources, an extended version of WordNet (xWN) and
WordFinder (WF), a lexical resource based on Wikipedia (WP). One of the goals was to see their respective
performance with respect to word access. It appears that our resource (WF) generally finds quicker and more often the
target word than xWN. This seems surprising at first sight as both resources &apos;have&apos; the same vocabulary. Yet this is not
surprising any more if one takes a look at the information on which the organization of the two resources is based. WN
lacks syntagmatic links, hence it will not perform well when the relationship between the input and the target is
encyclopedic knowledge (coffee-Brazil ; elephant-grey).
In order to build the resource required to support wordfinding we started from the following assumptions. Word access
is basically finding a specific item (target word) within the lexicon. Put differently, the task is to reduce the entire set (of
words contained in the lexicon) to one, the target. Since it is unreasonable to search in the entire lexicon, we suggest a
two-step method. The goal of the first is to reduce the initial search space to a smaller set, while the goal of the second
</bodyText>
<page confidence="0.946763">
312
</page>
<note confidence="0.683788">
MICHAEL ZOCK &amp; DIDIER SCHWAB [RLTLN-O.6]
</note>
<bodyText confidence="0.986892666666667">
is to support navigation by presenting the words identified in step-1 in a clustered and labeled form (categorial tree).
The challenge here is to name the clusters, as it is on this basis that the user decides on the direction to go in order to
search further for a given word.
</bodyText>
<keyword confidence="0.953588">
Mots-cles : Acces lexical, WordNet, Wikip6dia, WordFinder, groupement par cat6gorie, navigation assist6e.
Keywords: Lexical access, WordNet, Wikipedia, WordFinder, categorial tree, clustering, navigational aid.
</keyword>
<sectionHeader confidence="0.999719" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999968944444445">
Tout le monde admettra que poss6der un grand vocabulaire est un atout important. Reste ˆ savoir ce qu’il faut entendre
par le terme ‘poss6der’. Pour nous cela signifie trois choses : avoir stock/ des signes au sens Saussurien (des couples
sens/mot-forme), savoir s’en servir en effectuant les bons choix entre des alternatives (synonymes) tout en respectant
les contraintes de la langue (collocations), et (c) savoir trouver (r6cup6rer) ˆ volont6 le sens (compr6hension) ou la
forme des lemmes (production). C’est surtout ce dernier aspect qui nous int6resse ici, la r6cup6ration des formes
(lemmes) exprimant un certain sens. Concernant l’acces lexical la m6moire humaine semble bien plus fragile que celle
des machines. Ce qui a 6t6 stock6 dans la m6moire d’une machine nous semble accessible ce qui est loin d’être le cas
pour le cerveau humain, comme cela a 6t6 maintes fois montr6 via le ph6nomene du mot sur le bout de la langue
(Brown et McNeill, 1966, Brown, 1991). Il nous arrive parfois de ne pas trouver un terme, alors que nous l’avions
appris et nous en sommes servi il n’y a pas bien longtemps. Le mot en question a donc bel et bien 6t6 stock6 (donc,
m6moris6), mais pour des raisons diverses, pas toujours identifiables, il est (momentan6ment) inaccessible. Bien qu’une
grande partie du mot est accessible (notamment le sens), la forme du mot reste bloqu6e sur le bout de la langue (Brown,
1991). Ceci dit, contrairement ˆ ce qu’on pourrait croire, un probleme d’apparence identique peut 6galement toucher les
machines. Ce n’est pas parce qu’une information (par exemple, un mot) a 6t6 stock6e, qu’elle est toujours accessible et
c’est que nous allons montrer par la suite.
Dans la deuxieme partie nous allons pr6senter l’6bauche d’une feuille de route (ou, d’un programme de recherche),
pr6cisant la nature du probleme et montrant quels 6l6ments doivent etre 6labor6s pour aider les etres humains ˆ d6passer
ce probleme, c’est-ˆ-dire, trouver effectivement le mot recherch6.
</bodyText>
<sectionHeader confidence="0.55853" genericHeader="keywords">
2 L&apos;acces lexical automatique via une ressource externe
</sectionHeader>
<subsectionHeader confidence="0.99858">
2.1 Comparaison de deux ressources
</subsectionHeader>
<bodyText confidence="0.999709333333333">
Comme d6jà dit, le fait d’avoir stock6 des mots ne garantit nullement leur acces. Pour v6rifier cette affirmation nous
avons r6alis6 une petite exp6rience, en comparant deux ressources : une version 6tendue de WordNet (WN), eXtended
WN (Mihalcea et Moldavan, 2001) et Wikipedia (WP), que nous avons converti en une ressource lexicale, nomm6e
WordFinder (voir 2.2). Notre but n&apos;6tait pas tant de v6rifier la qualit6 de WN ou d&apos;une de ses extensions que de montrer
que (a) le stockage ne garantissait pas l&apos;acces, et que (b) l&apos;acces d6pendait de plusieurs facteurs qualitatifs, notamment,
celui de la ressource dans laquelle s&apos;effectue la recherche, de l&apos;indice, et du type de la requete. Ayant deux ressources
aux caract6ristiques diff6rentes, notre objectif 6tait de v6rifier leur efficacit6 relative par rapport ˆ l&apos;acces lexical. Pour
des raisons purement pratiques (limitation du temps de traitement), nous avons seulement pris en compte les voisins
directs (c&apos;est-ˆ-dire, les mots ˆ une distance de 1). Par cons6quent, nous avons d6fini une fonction nomm6e voisinage
direct (d6sormais fvd), qui, une fois appliqu6e ˆ une fenetre donn6e (phrase / paragraphe)1, produit toutes ses
cooccurrences. Bien sur, ce qui vaut pour les associations directes (notre cas ici), vaut 6galement pour les mots li6s
indirectement (distance &gt; 1), c&apos;est-ˆ-dire, des associations m6di6es.
</bodyText>
<subsubsectionHeader confidence="0.679711">
2.1.1 L&apos;usage de WordNet comme un corpus
</subsubsectionHeader>
<bodyText confidence="0.806154">
Un des objectifs de WN 6tait de construire une ressource ressemblant au dictionnaire mental (r6seau associatif),
permettant un fonctionnement analogue ˆ celui du cerveau humain (propagation d’activation).
La structure de WN est assez diff6rente de celle des dictionnaires conventionnels, qui eux sont organis6s par ordre
alphab6tique. Aussi, plutTMt que de multiplier le nombre de dictionnaires, un pour chaque utilisation ou chaque t‰che
</bodyText>
<footnote confidence="0.88093">
1 La taille optimale est une question empirique. Elle peut varier selon le type de texte, encyclop6die texte brut.
</footnote>
<page confidence="0.998885">
313
</page>
<note confidence="0.639951">
STOCKER DES MOTS NE GARANTIT NULLEMENT LEUR ACCES [RLTLN-O.6]
</note>
<bodyText confidence="0.998712833333333">
(trouver une d6finition, un synonyme, un antonyme,É), WN a 6t6 construit comme une ressource unique, permettant
l&apos;acces par des chemins multiples et par le biais de diff6rents type de liens. Comme ce travail est tres connu, nous ne le
d6crirons pas plus en d6tail ici (Miller, 1990).
Si WN est une ressource lexicale, il peut 6galement etre vu comme un corpus. Ceci peut s&apos;av6rer tres utile, si l&apos;on veut le
comparer avec d&apos;autres corpus — comme, par exemple, Wikipedia2 qui est une encyclop6die multilingue, collaborative
et libre — ou si l&apos;on veut faire usage d&apos;une partie sp6cifique de la base, par exemple, les gloses. Puisque les gloses
correspondent sch6matiquement ˆ la signification d&apos;un mot (d6finition), leurs 6l6ments (sac de mots) peuvent etre
utilis6s pour acc6der au mot dont ils d6finissent le sens (entr6e lexicale, lemme).
WN a eu un grand impact dans la communaut6 TAL od il est fortement utilis63. Ceci a conduit ˆ la cr6ation de
nombreuses extensions. Comme d6jà mentionn6, nous en utilisons l&apos;une d&apos;elles, Extended WN (Mihalcea et Moldovan,
2001), ce qui nous 6pargne la peine d&apos;avoir ˆ faire face aux problemes inh6rents ˆ l&apos;analyse de textes brut :
segmentation, r6solution d&apos;ambiguYt6s lexicales, lemmatisation,...
</bodyText>
<figure confidence="0.965080615384615">
eXtended
WordNet
Filtrage
POS + fr6quences
WordNet
2.1
social: JJ
insect: NN
live: VB
organized: JJ
colonies: NN
social insect living social:JJ insect:NN live:VB
in organized colonies in:IN organized:JJ colony:NN
</figure>
<figureCaption confidence="0.993469">
FIGURE 1: WordNet comme corpus (l&apos;exemple etant &amp;quot;ants&amp;quot; (fourmis)).
</figureCaption>
<bodyText confidence="0.999968416666667">
Deux problemes demeurent cependant : la taille du corpus (environ 144 000 entr6es) et le manque de connaissances
encyclop6diques, c’est-ˆ-dire les associations syntagmatiques, faiblesses, qui, pris ensemble, peuvent entraver l&apos;acces
lexical. En effet, les concepts fonctionnellement li6s comme d”ner-table-repas ou pecher-filet-poisson, devraient
s&apos;6voquer r6ciproquement, alors que ce n&apos;est souvent pas le cas. Ce probleme, connu depuis longtemps par les auteurs de
WN est nomm6 probleme de tennis (Fellbaum, 1998). Des mots jouant ensemble un rTMle dans un domaine ou dans une
t‰che ne sont pas forc6ment stock6s ensemble. Ainsi, balle de tennis, raquette et arbitre apparaissent dans diff6rentes
branches de l&apos;arborescence, alors qu&apos;ils sont tous susceptibles d&apos;être n6cessaires lorsqu&apos;on parle du sujet qui les r6unit, un
match de tennis. De maniere analogue, instrument et utilise_pour, apparaissent dans diff6rentes parties de la ressource,
alors qu&apos;ils sont (quasi-)synonymes. Malgr6 tout, il faut noter que de r6els efforts ont 6t6 faits pour surmonter ces
problemes. Par exemple, des informations peuvent etre trouv6es dans les gloses (dans le cas de utilisee_pour et
instrument), et des mots th6matiquement li6s peuvent d6sormais etre consult6s dans une certaine mesure (Boyd-Graber
et al. 2006).
</bodyText>
<subsubsectionHeader confidence="0.746451">
2.1.2 L&apos;usage de Wikipidia comme corpus
</subsubsectionHeader>
<bodyText confidence="0.999966285714286">
Afin de comparer WP et WN, nous avons utilis6 la version anglaise, qui, au moment de la r6daction de ce papier (mars
2013) contenait 3.550.567 entr6es. WP a exactement des propri6t6s oppos6es ˆ WN4. Bien qu&apos;il contienne de
nombreuses associations syntagmatiques, ce n&apos;est que du texte brut. Ainsi, des problemes tels que la segmentation du
texte ou la lemmatisation doivent etre abord6s. Pour 6viter cela, nous avons utilis6 DBpedia (Bizer et al., 2009), une
version texte brut de WP. L&apos;utilisation d&apos;un lemmatiseur5 nous a permis d&apos;annoter les 6l6ments majeurs du paragraphe et
de filtrer tous les mots hors de propos, pour ne garder que les plus importants (noms, adjectifs, verbes et adverbes). Ces
derniers ont ensuite 6t6 utilis6s pour la construction de notre base de donn6es.
</bodyText>
<footnote confidence="0.9927224">
2 http://www.wikipedia.org/
3 Voir Fontenelle (2012) sur l&apos;impact des r6seaux s6mantiques ˆ la WordNet sur la lexicographie contemporaine.
4 Ces deux ressources ont 6t6 align6es, par exemple, dans BABELNET (Navigli et Ponzetto 2010).
5 Dans cette exp6rience, nous avons utilis6 notre propre lemmatiseur bas6 sur le dictionnaire anglais DELA
(http://infolingu.univ-mlv.fr/DonneesLinguistiques/Dictionnaires/ telechargement.html)
</footnote>
<page confidence="0.994532">
314
</page>
<figure confidence="0.99979785">
MICHAEL ZOCK &amp; DIDIER SCHWAB [RLTLN-O.6]
Filtrage
mots vides +
PoS + fr6quences
Ants N
are V
social J
insects N
of P
the D
family N
Formicidae N
ant
be
social
insect
of
the
family
formicidae
Ants are social
insects of the
family Formicidae
PoS 8tiquetage
Ants
are
social
insects
of
the
family
Formicidae
N ant
V be
J social
N insect
P of
D the
N family
N formicidae
</figure>
<figureCaption confidence="0.75058">
FIGURE 2: Wikipedia comme corpus
</figureCaption>
<subsubsectionHeader confidence="0.965095">
2.1.3 Exploitation et comparaison des ressources
</subsubsectionHeader>
<bodyText confidence="0.999963071428571">
Construire la ressource necessite le traitement d&apos;un corpus et la construction d&apos;une base de donnees. Ë cette fin, nous
avons utilise un corpus en appliquant notre fonction de voisinage fvd ˆ une fenetre predetermin�e : un paragraphe dans le
cas des encyclopedies. Le resultat (c’est-ˆ-dire les cooccurrences) est stocke dans la base de donnees, avec leurs poids,
(c’est-ˆ-dire le nombre de fois que deux termes apparaissent ensemble) et le type de lien. Comme mentionne plus haut,
ce genre d&apos;information est necessaire plus tard pour le classement des termes et la navigation.
Les cooccurrences sont stockees sous forme de triplets (MS, MCP, NBocc), od MS et MCP designent respectivement le mot
source (c&apos;est-ˆ-dire, le mot declencheur ou mot requite) et le mot cible potentiel, terme obtenu en reponse ˆ la requite
(association directe), tandis que NBocc (nombre d’occurrences), represente le poids, c’est-ˆ-dire le nombre de fois que
deux termes apparaissent ensemble dans le corpus, la portee des cooccurrences etant le paragraphe. Bien sur, il y a
d&apos;autres fagons de determiner le poids (par exemple, des informations partagees), et surtout, d&apos;autres facteurs peuvent
avoir influer sur l&apos;accessibilite d&apos;un terme, par exemple, la recence. Aussi, les mots produits suite ˆ une requete (MS), ne
sont que des mots cible potentiels. Ils peuvent etre la cible, sans l&apos;itre necessairement. Ils peuvent etre des termes
intermediaires entre la source et la cible (association indirecte) ou etre un terme associe au MS, sans etre le mot
recherché pour autant (la cible). Il s&apos;agit simplement d&apos;un terme associe.
</bodyText>
<subsectionHeader confidence="0.998693">
2.2 Utilisation
</subsectionHeader>
<bodyText confidence="0.950858142857143">
Pour montrer les qualites relatives d&apos;une requete, nous avons developpe WordFinder, un site web en Java (bientTMt
disponible sur nos pages d&apos;accueil respectives). L&apos;utilisateur communique au programme via cette interface les mots
source. Le programme calcule alors les mots les plus probables d&apos;être la cible, puis il transmet cette liste apres avoir
mise ˆ jour la page. L&apos;utilisateur peut alors choisir de rajouter des mots ˆ sa requete en l&apos;ajoutant dans le champ prevu ˆ
cet effet ou en cliquant sur les termes de la liste. Par exemple, si les entrées sont recolte, vin, raisin, le systeme va
afficher tous les mots co-occurrents (associations directes, figure 3). Bien sur, si nous utilisons plusieurs corpus, comme
c&apos;est le cas ici, nous devons afficher les resultats pour chacun d&apos;eux.
La sortie est une liste ordonnee de mots, l&apos;ordre etant fonction du score global : le nombre de cooccurrences entre les MS
et le mot associe, appele le mot cible potentiel (MCP). Par exemple, si le MS bouquet apparaissait cinq fois avec vin et
huit fois avec recolter, nous obtiendrions un score ou poids global de 13 : ((vin-5, recolte-8), bouquet, 13). Les poids
peuvent etre utilises pour classer les mots en terme d&apos;ordre (de priorite) et pour choisir les mots ˆ presenter. Ceci peut
devenir necessaire pour peu que la liste soit longue.
Welcome to the WORDFINDER webpage
send
</bodyText>
<sectionHeader confidence="0.8842695" genericHeader="introduction">
Input
Output
</sectionHeader>
<bodyText confidence="0.865314666666667">
harvest, wine, grape
(found, related words): 23 hits
Beaujolais, regions, area, quality, between, vintage, well,
usually, vineyards, south, various, year, growing, early,
cru, low, north, following, aging, generally, time,
potentially, very
</bodyText>
<figureCaption confidence="0.342903">
FIGURE 3: Sorties produites en reponse aux entrées &apos;recolte, vin, raisin&apos;
</figureCaption>
<page confidence="0.931237">
315
</page>
<table confidence="0.97527755">
STOCKER DES MOTS NE GARANTIT NULLEMENT LEUR ACCES [RLTLN-O.6]
2.2.1 Exemples de requites et comparaison des deux ressources
La figure 4a ci-dessous montre les resultats produits respectivement par WN et par WP pour les entrées vin, recolte ou
leur combinaison : vin + recolte.
Entrées : Sorties de WordNet Sorties de Wikipedia
wine 488 candidats : 3045 candidats :
grape, sweet, serve, france, name, lord characteristics, christian,
small, fruit, dry, bottle, produce, grape, France, ... vintage (81 &apos;me position
red, bread, hold...
), ...
harvest 30 candidats : 4583 candidats :
month, fish, grape, revolutio- agriculture, spirituality, liberate, produc-
nary, calendar, festival, butter- tion, producing, ..., vintage (112 gme
fish, dollar, person, make, wine,
first,...
position), ...
wine + harvest 6 candidats : 353 candidats :
make, grape, fish, someone, grape, France, vintage ( 3 &apos; position ),
commemorate, person
...
</table>
<tableCaption confidence="0.390502">
FIGURE 4a: Comparaison de deux corpus pour trois entrées diff6rentes
</tableCaption>
<bodyText confidence="0.998781333333333">
Notre objectif etait de trouver le terme vintage (vendange). Les resultats montrent que recolte est un meilleur terme de
requete que vin (488 vs 30 candidats) et que leur combinaison est meilleure que chacun des deux termes seul (6
candidats). Ce qui est plus interessant est le fait qu&apos;aucun de ces termes ne correspond au mot cible, bien que celui-ci
soit dans WN, ce qui etaye notre hypothese que le stockage d&apos;un terme ne garantit nullement son acces (voir egalement
Sinopalnikova &amp; Smrz, 2006, Tulving &amp; Pearlstone, 1966).
Les choses peuvent beaucoup changer lorsque nous construisons notre index sur la base d&apos;autres informations, par
exemple, sur la base d&apos;informations encyclopediques, comme celles contenues dans WP. Dans ce cas, le terme vin
evoque beaucoup plus de mots que WN (3045 au lieu de 488, avec vendange dans la position 81). Pour &apos;recolte&apos; nous
obtenons 4583 reponses au lieu de 30, vendange arrivant en position 112. La combinaison des deux produit 353
reponses, propulsant le mot cible ˆ la 3&apos; position, donc, tres proche de la tete de la liste.
Nous esperons que cet exemple suffit pour convaincre le lecteur de l&apos;interet qu&apos;il y a ˆ utiliser des corpus equilibre, c&apos;est-
ˆ-dire, des textes riches, mais heterogenes, pour construire l&apos;index gr‰ce auquel l&apos;usager peut naviguer dans la ressource
pour trouver le mot qu&apos;il a sur le bout de la langue, mot qu&apos;il conna”t sans pouvoir l&apos;activer (completement) pour autant.
On notera, que ce probleme n&apos;est pas sans rappeler le declin progressif d&apos;une fonction cerebrale nomme degradation
gracieuse, phenomene pris en compte par des architectures connexionistes (Bechtel et Abrahamsen, 1991).
</bodyText>
<subsubsectionHeader confidence="0.929849">
2.2.2 Analyse de cet ichec relatif
</subsubsectionHeader>
<bodyText confidence="0.999947">
On peut se demander pourquoi nous n&apos;avons pas reussi ˆ acceder aux informations dans WN, alors qu&apos;elles y etaient, et
pourquoi WP a fait tellement mieux. Nous croyons que l&apos;echec relatif de WN est principalement du ˆ deux facteurs : la
taille du corpus (114000 mots au lieu de 3 550 000 dans le cas de WP), et le nombre de liens syntagmatiques, qui tous
les deux sont assez faibles par rapport ˆ WP. Ce dernier point a déjà ete souligne par G. Miller, lorsqu’il ecrit :
&amp;quot;WordNet provides a good account of paradigmatic associations, but contains very few syntagmatic links. .... If we
knew how to add to each noun a distinctive representation of the contexts in which it is used... WordNet would be much
more useful.&amp;quot; (Miller, in Fellbaum, 1998: 33-34). C’est precisement ce que nous comptons faire (voir section 3).
ƒvidemment, comme WP est une encyclopedie, elle contient beaucoup plus de liens syntagmatiques que WN. Par
vocation, WP contient beaucoup plus d&apos;informations generales que WN concernant chacun des mots. Autrement dit, la
taille de WN n&apos;est pas un argument affaiblissant notre conclusion. Ceci dit, nous pouvons echouer ˆ trouver l&apos;objet
recherché, meme dans un tres grand corpus. La reussite dependant de la qualite de la ressource (couverture, adequation),
de la qualite de la requete, ou des deux. De plus, comme déjà mentionne, le point faible ne reside pas tant dans la
quantite de donnees, que dans la qualite de l&apos;index (la rarete relative des liens).
Afin d&apos;être juste envers WN, il faut admettre que, si nous avions construit notre ressource differemment, par exemple,
en incluant dans la liste tous les termes lies, non seulement les mots directement evoques (mots cibles potentielles),
mais aussi tous les mots contenant le mot-source (wine, i.e. vin) dans leur definition (Bordeaux, Retsina, Tokai), nous
aurions surement obtenu le terme vendange, puisque le mot vin est contenu dans sa definition (vintage : a season&apos;s yield
</bodyText>
<page confidence="0.998144">
316
</page>
<sectionHeader confidence="0.428792" genericHeader="method">
MICHAEL ZOCK &amp; DIDIER SCHWAB [RLTLN-O.6]
</sectionHeader>
<bodyText confidence="0.999916285714286">
of wine from a vineyard). On peut aussi remarquer que le succes peut varier assez considerablement, en fonction des
termes choisis (mots cibles). Comme le montre le tableau ci-dessous, WN obtient des meilleures performances que WP
pour les termes ball, racket et tennis. Ceci dit, WP suit de pres, tout en contenant beaucoup d&apos;autres mots susceptibles
d&apos;induire le mot cible, les termes player, racket, et court, etant classes respectivement 12, 18 et 20. N&apos;etant pas une
encyclopedie, WN ne possede pas la plupart d&apos;entre eux. En revanche, ce qui est plus surprenant, et probablement un
fait assez local et exceptionnel, il contient des informations tres specifiques et de nature encyclopedique, ˆ savoir, le
nom de deux grandes anciennes championnes de tennis : Monica Seles et Steffi Graf.
</bodyText>
<figureCaption confidence="0.666574071428572">
Entrées : Sorties de WordNet Sorties de Wikipedia
ball 346 candidats : 4891 candidats :
game, racket, player, court, sport, league, football, hand, food, foot,
volley, wimbledon, cham- win, run, game, ..., tennis (position
pionships, inflammation, ...,
tennis (15 &apos;me), ...
27), ...
racket 114 candidats : 2543 candidats :
break, headquarter, gangster, death, kill, illegal, business, corrupt, ...,
lieutenant, rival, kill, die, tennis (position 72), ...
ambush, tennis (38 &amp;quot;), ...
ball + racket 11 candidats : 528 candidats :
game, tennis, (2 &apos;me ), ... sport, strike, tennis (3 &amp;quot; position), ...
FIGURE 4b : Comparaison de differentes entrées dans deux corpus
</figureCaption>
<bodyText confidence="0.964799545454545">
Dernier point, contrairement ˆ ce que l’on pourrait croire en apprenant que WN a ete congu en s’appuyant sur des
donnees psycholinguistiques, WN n’a pas ete congu en vue d’une consultation. Voici les mots de son concepteur:
&amp;quot;WordNet is an online lexical database designed for use under program control.&amp;quot; (Miller, 1995, p. 39).
C’est pour combler cette lacune que nous allons esquisser dans le reste de cet article, une feuille de route afin de
construire un dictionnaire destine aux producteurs de langue (redacteurs, locuteurs).
3 Une feuille de route pour construire la carte semantique permettant ˆ
l’explorateur de s’orienter dans l’espace lexical
Chercher un mot dans un dictionnaire sans bon index est un peu comme s&apos;orienter sur une ”le deserte sans carte
convenable. Autrement dit, il faut construire une carte permettant ˆ l’utilisateur de s’orienter dans cet espace lexical.
Nous allons esquisser ci-dessous la construction de cette ressource, mais d’abord nous allons essayer de clarifier ce
qu’il faut entendre par ‘acces lexical’, terme qui semble a priori evident. Et pourtant,...
</bodyText>
<subsectionHeader confidence="0.99894">
3.1 Premisses et fonctionnement de la recherche lexicale
</subsectionHeader>
<bodyText confidence="0.999907375">
Tous les mots du dictionnaire sont lies entre eux par des associations. Ces liens sont soit directs (associations
immediates, voisins directs), soit plus ou moins indirects : associations mediatisees (les voisins de voisins, des
voisins,...). Aussi, si ‘jaune’ evoque ‘canari’ ou ‘citron’ on dira que ‘jaune-canari’ et ‘jaune-citron’ sont lies
directement, l’un pouvant evoquer l’autre. Ceci dit, cette information serait insuffisante si la cible etait le mot exprimant
la saveur du fruit mentionne. Mais comme le mot ‘citron’ evoque entre autre la notion d’acidite, on trouvera le terme
recherché ˆ l’etape suivante, puisque ‘jaune’ (mot source) et ‘acide’ (mot cible) sont lies indirectement via le mot fruit
(citron).
Le dictionnaire est donc un graphe connexe ce qui a pour consequence que tous les mots sont accessibles ˆ partir de
n’importe quel mot. Le nombre d’etapes dependra de la distance entre le mot source (Ms), mot ne vous venant pas ˆ
l’esprit, et le mot cible (Mc), mot representant le but de la recherche. Chercher un mot consiste donc ˆ entrer le reseau ˆ
un endroit quelconque en fournissant le mot source et de suivre les liens jusqu’au mot cible (mot bloque sur le bout de
la langue). Si ce dernier est un voisin direct, le systeme l’affiche immediatement, et le probleme est resolu. Dans le cas
contraire, l’utilisateur peut continuer en changeant de Mc. Celui-ci peut etre un des termes obtenues suite au Mc initial,
soit un tout autre mot.
L’association (ou, l’index creee ˆ partir d’associations) est donc l’une des bases de notre methode de recherche. Elle a
pour vocation de reveler le mot cible (voisin direct), soit de nous guider vers un mot plus proche (voisin indirect). Dans
</bodyText>
<page confidence="0.996566">
317
</page>
<note confidence="0.829688">
STOCKER DES MOTS NE GARANTIT NULLEMENT LEUR ACCES [RLTLN-O.6]
</note>
<bodyText confidence="0.999895785714286">
tous les cas, cette methode nous permettra de reduire l’espace de recherche. L’etape suivante consiste ˆ grouper et ˆ
nommer les grappes de mots obtenus suite ˆ l’entree, le Ms. L’objectif de ce travail est d’aider l’utilisateur ˆ naviguer
dans une liste de mots (desormais) structures.
Pour resumer : comme lancer une recherche dans l’integralite d’une ressource (dictionnaire) pour trouver un mot (Mc)
parai&amp;quot;t deraisonnable, nous proposons de diviser ce processus en deux etapes. Lors de la première, on reduit l’espace
initial, en ramenant l’ensemble des mots stockes dans la ressource aux voisins directs de l’entree (Mc), liste qu’on
structure ensuite en formant des groupes (clusters) auxquels on donne des noms. Aussi l’utilisateur pourrait-il naviguer
dans un arbre categoriel plutTMt que dans une liste plate, ce qui devrait considerablement accelerer la recherche.
La difficulte de cette deuxieme etape consiste essentiellement ˆ trouver des noms adequats aux groupes formes.
Idealement ces noms devraient correspondre ˆ ceux que la majorite des gens donneraient ˆ ces groupes, car, c’est via
ces noms ou categories qu’ils vont decider dans quelle direction orienter leurs efforts pour chercher le mot dans un
groupe plutTMt que dans un autre. Le figure 5 ci-dessous resume notre objectif, notre raisonnement et notre methode.
Ceci dit, beaucoup de details restent ˆ etre clarifier : quels corpus utiliser, quel algorithme developper pour grouper et
nommer ces listes de mots.
</bodyText>
<subsectionHeader confidence="0.999632">
3.2 L’acc6s lexical : un processus en deux 6tapes
</subsectionHeader>
<bodyText confidence="0.999974125">
D’abord que faut-il entendre par ‘acces lexical’ (en mode production) ? Cela peut vouloir dire plusieurs choses. Pour ce
qui nous concerne ici cela signifie « trouver un element specifique (mot cible) parmi l’ensemble des mots stockes dans
la ressource (le dictionnaire) ». Ceci peut vouloir dire pour un etre humain, trouver un terme parmi, environ 50.000
autres (son dictionnaire mental). La t‰che consiste donc ˆ reduire l&apos;ensemble des candidats (ensemble de mots contenus
dans le dictionnaire) ˆ un seul, le mot cible. Comme il est hors question d’effectuer une recherche dans l&apos;ensemble du
dictionnaire, nous proposons de proceder en plusieurs etapes, plus precisement, deux. L&apos;objectif de la première est de
reduire l&apos;espace de recherche initial (50.000) ˆ un ensemble plus petit (par exemple, 100-150 mots), alors que l&apos;objectif
de la seconde est d’aider l’explorateur (l’etre humain naviguant dans ce sous-ensemble) ˆ naviguer. Ë cette fin on lui
presente les mots identifies ˆ l&apos;etape 1 dans des ensembles etiquetes (arbre categoriel). Il y a donc deux aspects
importants dans cette deuxieme phase : grouper les mots et donner aux groupes des noms utilisables (meaningful) par
l’utilisateur. Ë cet egard, utiliser « plus general » parai&amp;quot;t plus pertinent qu’utiliser ‘hyperonyme’, parce que
comprehensible par un plus grand nombre d’utilisateurs.
Il convient de noter que les locuteurs dans l&apos;etat du mot sur le bout de la langue (MBL) savent toujours quelque chose ˆ
propos du mot cible (Brown et McNeill, 1966). C&apos;est precisement de cette information que nous allons nous servir. Ce
sera l’entree, la première prise de contact avec le dictionnaire. ƒtant donn�e une entrée, le systeme affichera alors tous
les mots directement lies (mots ˆ une distance de 1, c&apos;est ˆ dire, toutes les associations directes).6 Ce genre
d’informations peut etre glane dans une ressource comme le Edinburgh Association Thesaurus (EAT) (Kiss et al.
1973).7 Comme ceci produira toutefois une liste trop longue pour permettre de trouver rapidement le terme recherché,
nous proposons de regrouper les mots par familles, et de donner aux groupes des noms afin de faciliter la navigation.
Comme on le voit, cette deuxieme etape est cruciale, car sans elle l’utilisateur serait noye sous une enorme liste de mots
non-structures. La figure 5 resume l’ensemble des operations.
Notez que pour afficher correctement l&apos;espace de recherche, c&apos;est-ˆ-dire l’ensemble de mots parmi lesquels chercher le
mot cible (etape 1), il faut, dans un premier temps, lever toute incertitude sur l’entree (desambiguYsation) afin d’eviter
au maximum le bruit. Ne sachant pas quel sens est celui souhaite par l’utilisateur, le systeme risque d’afficher
l’ensemble des associations possibles : « souris :animal » vs. « souris : dispositif informatique ». Il s’agit d’un
desagrement que l’on aimerait eviter.
Notez egalement, que pour construire le guide en question, deux elements doivent etre construits (ou utilises) : (1) un
reseau lexical base sur la notion d’association et (2) une methode permettant de grouper les mots donnes en reponse ˆ
l’entree. Ces groupes se verront attribuer un nom parlant pour que l’utilisateur de cette ressource puisse comprendre ce
qui les reunit. Si la première etape commence ˆ poser moins de problemes ˆ l’heure actuelle, la construction
automatique de l’arbre categoriel en question est loin d’être resolu, et ceci malgre la tres grande litterature consacree au
probleme de la categorisation (Zhang et al., 2012, Bieman, 2012 ; Everitt et al. 2011).
</bodyText>
<footnote confidence="0.9690875">
6 Si l’utilisateur fournit plusieurs termes en entrée, le systeme affichera l’intersection des termes associ6s.
7 http://www.eat.rl.ac.uk
</footnote>
<page confidence="0.995491">
318
</page>
<figure confidence="0.719024166666667">
[RLTLN-O.6]
21�me Traitement Automatique des Langues Naturelles, Marseille, 2014
TEA 39 0.39
CUP 7 0.07
BLACK 5 0.05
BREAK 4 0.04
ESPRESSO 40.0.4
POT 3 0.03
CREAM 2 0.02
HOUSE 2 0.02
MILK 2 0.02
CAPPUCINO 20.02
</figure>
<figureCaption confidence="0.96989919047619">
STRONG 2 0.02
SUGAR 2 0.02
TIME 2 0.02
BAR 1 0.01
BEAN 1 0.01
BEVERAGE 1 0.01
BISCUITS 1 0.01
BITTER 1 0.01
DARK 1 0.01
DESERT 1 0.01
DRINK 1 0.01
FRENCH 1 0.01
GROUND 1 0.01
INSTANT 1 0.01
MACHINE 1 0.01
MOCHA 1 0.01
MORNING 1 0.01
MUD 1 0.01
NEGRO 1 0.01
SMELL 1 0.01
TABLE 1 0.01
</figureCaption>
<figure confidence="0.999305686567164">
.
.
.
.
.
mot cible :
mocha
39.788
.
.
.
.
.
60.000
1 1er 6l6ment :
abacus
dernier 6l6ment
de la liste :
zephyr
Dictionnaire hypoth6tique
contenant 60.000 mots
A: Dictionnaire integral B: Première reduction C : Arbre categoriel D : Unite lexicale
choisie
Etape-1: ing6nieur
Cr66er +/ou utiliser
r6seau associatif
Etape-1: utilisateur
(E.A.T, collocations
extraits d’un corpus)
Fournir l’entr6e
par exemple, ‘caf6’
termes directement associ6s
ˆ l’entr6e : ‘caf6’
1° via calcul (proximit6 s6mantique)
2° via une resource
3° via une combination
de resources (WordNet,
Roget, Entit6s Nomm6es, É)
Etape-2: ing6nieur
Groupement + 6tiquetage
categories potentielles (noeuds),
pour grouper les mots donn6es
en r6ponse ˆ l’entr6e (B):
espace de recherche
instances
lexicales
Cat-1
Exemples de categories:
- espece de, couleur, gout,
- utilis6_pour/avec
- qualit6, origine, lieu
Espace de
recherche indexé
instances
lexicales
Cat-3
Cat-2
Cat-4
instances
lexicales
2° D6cider de l’action suivante :
arreter ici ou continuer.
1° naviguer dans l’arbre + d6terminer
s’il contient la cible ou un terme
(plus ou moins) directement li6.
Etape-2: utilisateur
Navigation + choice
</figure>
<figureCaption confidence="0.87883575">
Etant donn6 une entr6e le systeme affiche
tous les mots directement associ6s, i.e. voisins
directes (graph), ordonn6s ou pas selon un
critere donn6e (p.ex. le poids)
</figureCaption>
<bodyText confidence="0.952147333333333">
Arbre conqu pour assister la navigation. Les feuilles contiennent
les mots-cibles potentiels (voir: ‘espace r6duit/ 1ere r6duction’)
et les noeuds les cat6gories permettant ˆ l’utilisateur de r6duire
l’espace de recherche et par lˆ le temps requis pour trouver
6ventuellement le mot recherch6.
FIGURE 5 : L’acces lexical comme un dialogue en deux etape
</bodyText>
<page confidence="0.816449">
319
</page>
<note confidence="0.630317">
21�me Traitement Automatique des Langues Naturelles, Marseille, 2014 [RLTLN-O.6]
</note>
<sectionHeader confidence="0.988707" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999935571428572">
L’objectif de ce papier etait d’attirer l’attention sur le fait que d’avoir stocke un mot ne signifiait nullement pouvoir y
acceder. Pour le permettre, nous nous avons esquisse une feuille de route precisant (1) la nature du dialogue entre
l’utilisateur et la machine et (2) les elements ˆ mettre en place afin de permettre une navigation par association. La suite
consistera donc ˆ mener des experiences concretes pour voir quel type de ressource (corpus ou autre) nous fournira la
meilleure carte (etape-1) et quelle methode nous permettra de presenter ce resultat sous forme d’un arbre dont les naeuds
sont des categories comprehensibles par l’etre humain, tout en nommant de maniere comprehensible et non-ambigüe la
classe dont les elements font partie (etape-2).
</bodyText>
<sectionHeader confidence="0.999205" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999330684210527">
BECHTEL, W. &amp; ABRAHAMSEN, A. (1991). Connectionism and the mind: A introduction to parallel processing in
networks. Oxford: Basil Blackwell. Traduction frangaise par J. Proust. Le connexionnisme et l&apos;esprit:
Introduction au traitement parallele par reseaux, Paris: Editions la Decouverte, 1993.
BIEMANN, C. (2012). Structure Discovery in Natural Language. Theory and Applications of Natural
Language Processing. Springer Berlin / Heidelberg.
BIZER, C., LEHMANN J., KOBILAROV G., AUER S., BECKER C., CYGANIAK R. &amp; HELLMANN S. (2009).
DBpedia – A Crystallization Point for the Web of Data. Journal of Web Semantics: Science, Services and
Agents on the World Wide Web, Issue 7, 154–165.
BOYD-GRABER, J., FELLBAUM, C., OSHERSON, D. &amp; SCHAPIRE, R. (2006). Adding dense, weighted
connections to WordNet. Proceedings of the Third Global WordNet Meeting, Jeju Island, Korea. pp. 29-
35
BROWN, A. (1991). A review of the tip of the tongue experience. Psychological Bulletin, 10, 204-223
BROWN, R. &amp; MC NEILL, D. (1966). The tip of the tongue phenomenon. Journal of Verbal Learning and
Verbal Behavior, 5, 325-337
EVERITT, B.S., LANDAU, S., LEESE, M. et STAHL, D. (2011). Cluster Analysis: 5th Edition, John Wiley &amp;
Sons, Ltd
FELLBAUM, C. (ed.) (1998). WordNet: An Electronic Lexical Database and some of its Applications.
Cambridge, MA: MIT Press.
KISS, G., ARMSTRONG, C., MILROY, R. &amp; PIPER, J. (1973). An associative thesaurus of English and its
computer analysis. In: A. Aitken, R. Beiley and N. Hamilton-Smith (eds.). The Computer and Literary
Studies. Edinburgh: University Press.
MIHALCEA, R &amp; MOLDAVAN, D. (2001). Extended WordNet: progress report. In NAACL 2001 - Workshop
on WordNet and Other Lexical Resources, Pittsburgh, USA.
MILLER, G.A. (ed.). (1990). WordNet: An On-Line Lexical Database. International Journal of
Lexicography, 3(4).
MILLER G. A. (1995). WordNet : A lexical database for english. Communications of the ACM, 38 (11), 39–
41.
NAVIGLI, R. &amp; PONZETTO, S.P. (2010). BabelNet: Building a very large multilingual semantic network.
Actes du 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Suede, pages
216-225.
SINOPALNIKOVA, A. &amp; SMRZ, P. (2006). Knowing a word vs. accessing a word: WordNet and word
association norms as interfaces to electronic dictionaries. In Proceedings of the Third International
WordNet Conference, pages 265–272, Korea.
TULVING, E. &amp; PEARLSTONE, Z. (1966). Availability versus accessibility of information in memory for
words. Journal of Verbal Learning and Verbal Behavior, 5, 381-391
ZHANG, Z., GENTILE A.L. &amp; CIRAVEGNA, F. (2012). Recent Advances in Methods of Lexical Semantic
Relatedness – a Survey . In the Journal of Natural Language Engineering, 19(4), 411-479, Cambridge
Universtiy Press.
</reference>
<page confidence="0.998242">
320
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.177329">
<note confidence="0.7621">Traitement Automatique des Langues Naturelles, Marseille, 2014</note>
<abstract confidence="0.972164529411765">Stocker des Mots ne Garantit nullement leur Acces. Didier (1) CNRS, Aix Marseille (2) Univ. Grenoble Alpes didier.schwab@imag.fr de ce papier est double : (a) montrer que le stockage ou la memorisation d’une forme lexicale ne garantit nullement son acces ou sa disponibilite, et (b) decrire les etapes necessaires pour construire une ressource susceptible d’aider les redacteurs ˆ trouver le mot bloque sur le bout de leur langue (ou de leur plume). Pour verifier le premier point, nous avons realise une petite experience en comparant deux ressources pour voir si elles nous permettaient de trouver le terme recherché (mot cible) et si l’acces etait facile. Les ressources en question sont WordNet, ou plutTMt une version etendue, eXtended WordNet (xWN) et Wikipedia (WP), converti par nous en une ressource lexicale, nommee WordFinder (WF). Il s’avere que cette derniere ressource permet generalement ˆ trouver assez rapidement le terme recherché, alors que xWN y echoue souvent, ou lorsqu’il y parvient, l’element en question se trouve assez loin dans la liste des candidats. Ceci para”t surprenant dans la mesure oa les deux ressources ‘possedent’ le meme vocabulaire. Cependant la situation devient vite assez claire lorsqu’on regarde les liens entre les mots (l’index ou l’organisation lexicale) des deux ressources. Contrairement ˆ WN, WF contient beaucoup de liens syntagmatiques (café-noir ; cafe-Bresil ; café-Starbucks,...), permettant de ce fait d’acceder au mot cible par un bien plus grand nombre de mots source. Ayant montre que ‘stockage’ n’implique pas forcement ‘acces’ ou disponibilite, nous presentons ensuite une feuille de route, esquissant les elements ˆ elaborer pour construire une ressource susceptible d’aider des redacteurs ˆ trouver le mot bloque sur le bout de la langue. La construction de notre future ressource est basee sur les raisonnement suivants. L’acces lexical consiste essentiellement ˆ localiser un element parmi l’ensemble des formes lexicales stockees dans la ressource lexicale (dictionnaire). Comme il est deraisonnable de chercher le mot cible parmi l’ensemble des formes stockees, nous proposons de decomposer ce processus en deux etapes. Dans un premier temps nous essayons de reduire l&apos;espace initial ˆ un ensemble plus petit. A cette fin on presentera tous les mots directement associes au(x) mot(s) source (l’entree), mot(s) disponible(s), et mot(s) auquel(s) on pense spontanement en cherchant la cible. Dans un deuxieme temps on essayera de guider l’utilisateur en lui presentant une version structuree des mots obtenus lors de la phase precedente. Pour atteindre ce dernier objectif il faut donc structurer la liste des mots, ce qui veut dire, qu’il faut former des groupes (clusters) auxquels on donne des noms (arbre categoriel). Le defi ici est de nommer ces groupes, parce que c&apos;est sur cette base (le nom de ces categories) que l&apos;utilisateur decidera dans quelle direction aller pour chercher le mot dans un ‘paquet’ particulier. with word access in language production we pursue here two goals: (a) provide evidence that &apos;storage&apos; does not imply &apos;access&apos; (or, accessibility) ; (b) describe the steps to be carried out to build a resource allowing for interactive word finding. In order to show evidence for the first claim we compared two resources, an extended version of WordNet (xWN) and WordFinder (WF), a lexical resource based on Wikipedia (WP). One of the goals was to see their respective performance with respect to word access. It appears that our resource (WF) generally finds quicker and more often the target word than xWN. This seems surprising at first sight as both resources &apos;have&apos; the same vocabulary. Yet this is not surprising any more if one takes a look at the information on which the organization of the two resources is based. WN lacks syntagmatic links, hence it will not perform well when the relationship between the input and the target is encyclopedic knowledge (coffee-Brazil ; elephant-grey). In order to build the resource required to support wordfinding we started from the following assumptions. Word access is basically finding a specific item (target word) within the lexicon. Put differently, the task is to reduce the entire set (of words contained in the lexicon) to one, the target. Since it is unreasonable to search in the entire lexicon, we suggest a two-step method. The goal of the first is to reduce the initial search space to a smaller set, while the goal of the second 312 [RLTLN-O.6] is to support navigation by presenting the words identified in step-1 in a clustered and labeled form (categorial tree). The challenge here is to name the clusters, as it is on this basis that the user decides on the direction to go in order to search further for a given word. : lexical, WordNet, Wikip6dia, WordFinder, groupement par cat6gorie, navigation assist6e.</abstract>
<intro confidence="0.500305">access, WordNet, Wikipedia, WordFinder, categorial tree, clustering, navigational aid.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W BECHTEL</author>
<author>A ABRAHAMSEN</author>
</authors>
<title>Connectionism and the mind: A introduction to parallel processing in networks. Oxford: Basil Blackwell. Traduction frangaise par</title>
<date>1991</date>
<marker>BECHTEL, ABRAHAMSEN, 1991</marker>
<rawString>BECHTEL, W. &amp; ABRAHAMSEN, A. (1991). Connectionism and the mind: A introduction to parallel processing in networks. Oxford: Basil Blackwell. Traduction frangaise par J. Proust. Le connexionnisme et l&apos;esprit: Introduction au traitement parallele par reseaux, Paris: Editions la Decouverte, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C BIEMANN</author>
</authors>
<date>2012</date>
<booktitle>Structure Discovery in Natural Language. Theory and Applications of Natural Language Processing.</booktitle>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<marker>BIEMANN, 2012</marker>
<rawString>BIEMANN, C. (2012). Structure Discovery in Natural Language. Theory and Applications of Natural Language Processing. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C BIZER</author>
<author>J LEHMANN</author>
<author>G KOBILAROV</author>
<author>S AUER</author>
<author>C BECKER</author>
<author>R CYGANIAK</author>
<author>S HELLMANN</author>
</authors>
<title>DBpedia – A Crystallization Point for the Web of Data.</title>
<date>2009</date>
<journal>Journal of Web Semantics: Science, Services and Agents on the World Wide Web, Issue</journal>
<volume>7</volume>
<pages>154--165</pages>
<marker>BIZER, LEHMANN, KOBILAROV, AUER, BECKER, CYGANIAK, HELLMANN, 2009</marker>
<rawString>BIZER, C., LEHMANN J., KOBILAROV G., AUER S., BECKER C., CYGANIAK R. &amp; HELLMANN S. (2009). DBpedia – A Crystallization Point for the Web of Data. Journal of Web Semantics: Science, Services and Agents on the World Wide Web, Issue 7, 154–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J BOYD-GRABER</author>
<author>C FELLBAUM</author>
<author>D OSHERSON</author>
<author>R SCHAPIRE</author>
</authors>
<title>Adding dense, weighted connections to WordNet.</title>
<date>2006</date>
<booktitle>Proceedings of the Third Global WordNet Meeting, Jeju Island,</booktitle>
<pages>29--35</pages>
<marker>BOYD-GRABER, FELLBAUM, OSHERSON, SCHAPIRE, 2006</marker>
<rawString>BOYD-GRABER, J., FELLBAUM, C., OSHERSON, D. &amp; SCHAPIRE, R. (2006). Adding dense, weighted connections to WordNet. Proceedings of the Third Global WordNet Meeting, Jeju Island, Korea. pp. 29-35</rawString>
</citation>
<citation valid="true">
<authors>
<author>A BROWN</author>
</authors>
<title>A review of the tip of the tongue experience.</title>
<date>1991</date>
<journal>Psychological Bulletin,</journal>
<volume>10</volume>
<pages>204--223</pages>
<marker>BROWN, 1991</marker>
<rawString>BROWN, A. (1991). A review of the tip of the tongue experience. Psychological Bulletin, 10, 204-223</rawString>
</citation>
<citation valid="true">
<authors>
<author>R BROWN</author>
<author>MC NEILL</author>
<author>D</author>
</authors>
<title>The tip of the tongue phenomenon.</title>
<date>1966</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>5</volume>
<pages>325--337</pages>
<marker>BROWN, NEILL, D, 1966</marker>
<rawString>BROWN, R. &amp; MC NEILL, D. (1966). The tip of the tongue phenomenon. Journal of Verbal Learning and Verbal Behavior, 5, 325-337</rawString>
</citation>
<citation valid="true">
<authors>
<author>B S EVERITT</author>
<author>S LANDAU</author>
<author>M et STAHL LEESE</author>
<author>D</author>
</authors>
<date>2011</date>
<booktitle>Cluster Analysis: 5th Edition,</booktitle>
<publisher>John Wiley &amp; Sons, Ltd</publisher>
<marker>EVERITT, LANDAU, LEESE, D, 2011</marker>
<rawString>EVERITT, B.S., LANDAU, S., LEESE, M. et STAHL, D. (2011). Cluster Analysis: 5th Edition, John Wiley &amp; Sons, Ltd</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database and some of its Applications.</title>
<date>1998</date>
<editor>FELLBAUM, C. (ed.)</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>1998</marker>
<rawString>FELLBAUM, C. (ed.) (1998). WordNet: An Electronic Lexical Database and some of its Applications. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<title>An associative thesaurus of English and its computer analysis.</title>
<date>1973</date>
<booktitle>The Computer and Literary Studies.</booktitle>
<editor>KISS, G., ARMSTRONG, C., MILROY, R. &amp; PIPER, J.</editor>
<publisher>University Press.</publisher>
<location>Edinburgh:</location>
<marker>1973</marker>
<rawString>KISS, G., ARMSTRONG, C., MILROY, R. &amp; PIPER, J. (1973). An associative thesaurus of English and its computer analysis. In: A. Aitken, R. Beiley and N. Hamilton-Smith (eds.). The Computer and Literary Studies. Edinburgh: University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R MIHALCEA</author>
<author>D MOLDAVAN</author>
</authors>
<title>Extended WordNet: progress report.</title>
<date>2001</date>
<booktitle>In NAACL 2001 - Workshop on WordNet and Other Lexical Resources,</booktitle>
<location>Pittsburgh, USA.</location>
<marker>MIHALCEA, MOLDAVAN, 2001</marker>
<rawString>MIHALCEA, R &amp; MOLDAVAN, D. (2001). Extended WordNet: progress report. In NAACL 2001 - Workshop on WordNet and Other Lexical Resources, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A MILLER</author>
</authors>
<title>WordNet: An On-Line Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<marker>MILLER, 1990</marker>
<rawString>MILLER, G.A. (ed.). (1990). WordNet: An On-Line Lexical Database. International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A MILLER</author>
</authors>
<title>WordNet : A lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<pages>41</pages>
<marker>MILLER, 1995</marker>
<rawString>MILLER G. A. (1995). WordNet : A lexical database for english. Communications of the ACM, 38 (11), 39– 41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R NAVIGLI</author>
<author>S P PONZETTO</author>
</authors>
<title>BabelNet: Building a very large multilingual semantic network.</title>
<date>2010</date>
<booktitle>Actes du 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>216--225</pages>
<location>Uppsala, Suede,</location>
<marker>NAVIGLI, PONZETTO, 2010</marker>
<rawString>NAVIGLI, R. &amp; PONZETTO, S.P. (2010). BabelNet: Building a very large multilingual semantic network. Actes du 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Suede, pages 216-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A SINOPALNIKOVA</author>
<author>P SMRZ</author>
</authors>
<title>Knowing a word vs. accessing a word: WordNet and word association norms as interfaces to electronic dictionaries.</title>
<date>2006</date>
<booktitle>In Proceedings of the Third International WordNet Conference,</booktitle>
<pages>265--272</pages>
<marker>SINOPALNIKOVA, SMRZ, 2006</marker>
<rawString>SINOPALNIKOVA, A. &amp; SMRZ, P. (2006). Knowing a word vs. accessing a word: WordNet and word association norms as interfaces to electronic dictionaries. In Proceedings of the Third International WordNet Conference, pages 265–272, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E TULVING</author>
<author>Z PEARLSTONE</author>
</authors>
<title>Availability versus accessibility of information in memory for words.</title>
<date>1966</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>5</volume>
<pages>381--391</pages>
<marker>TULVING, PEARLSTONE, 1966</marker>
<rawString>TULVING, E. &amp; PEARLSTONE, Z. (1966). Availability versus accessibility of information in memory for words. Journal of Verbal Learning and Verbal Behavior, 5, 381-391</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z ZHANG</author>
<author>A L GENTILE</author>
<author>F CIRAVEGNA</author>
</authors>
<title>Recent Advances in Methods of Lexical Semantic Relatedness – a Survey .</title>
<date>2012</date>
<journal>In the Journal of Natural Language Engineering,</journal>
<volume>19</volume>
<issue>4</issue>
<pages>411--479</pages>
<publisher>Universtiy Press.</publisher>
<location>Cambridge</location>
<marker>ZHANG, GENTILE, CIRAVEGNA, 2012</marker>
<rawString>ZHANG, Z., GENTILE A.L. &amp; CIRAVEGNA, F. (2012). Recent Advances in Methods of Lexical Semantic Relatedness – a Survey . In the Journal of Natural Language Engineering, 19(4), 411-479, Cambridge Universtiy Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>