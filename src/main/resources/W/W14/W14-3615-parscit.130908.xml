<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001279">
<title confidence="0.995408">
Arabic Spelling Correction using Supervised Learning
</title>
<author confidence="0.978342">
Youssef Hassan
</author>
<affiliation confidence="0.9718295">
Dept Computer Engineering
Cairo University
</affiliation>
<address confidence="0.812247">
Giza, Egypt
</address>
<email confidence="0.993016">
youssefhassan13@gmail.com
</email>
<author confidence="0.872421">
Mohamed Aly
</author>
<affiliation confidence="0.922229">
Dept Computer Engineering
Cairo University
</affiliation>
<address confidence="0.80931">
Giza, Egypt
</address>
<email confidence="0.996541">
mohamed@mohamedaly.info
</email>
<author confidence="0.923244">
Amir Atiya
</author>
<affiliation confidence="0.950114">
Dept Computer Engineering
Cairo University
</affiliation>
<address confidence="0.813204">
Giza, Egypt
</address>
<email confidence="0.998889">
amir@alumni.caltech.edu
</email>
<sectionHeader confidence="0.997393" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980090909091">
In this work, we address the problem
of spelling correction in the Arabic lan-
guage utilizing the new corpus provided
by QALB (Qatar Arabic Language Bank)
project which is an annotated corpus of
sentences with errors and their corrections.
The corpus contains edit, add before, split,
merge, add after, move and other error
types. We are concerned with the first four
error types as they contribute more than
90% of the spelling errors in the corpus.
The proposed system has many models to
address each error type on its own and then
integrating all the models to provide an
efficient and robust system that achieves
an overall recall of 0.59, precision of 0.58
and F1 score of 0.58 including all the error
types on the development set. Our system
participated in the QALB 2014 shared task
”Automatic Arabic Error Correction” and
achieved an F1 score of 0.6, earning the
sixth place out of nine participants.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978955555555">
The Arabic language is a highly inflected natural
language that has an enormous number of possi-
ble words (Othman et al., 2003). And although it
is the native language of over 300 million people,
it suffers from the lack of useful resources as op-
posed to other languages, specially English and
until now there are no systems that cover the wide
range of possible spelling errors. Fortunately the
QALB corpus (Zaghouani et al., 2014) will help
enrich the resources for Arabic language generally
and the spelling correction specifically by provid-
ing an annotated corpus with corrected sentences
from user comments, native student essays, non-
native data and machine translation data. In this
work, we are trying to use this corpus to build an
error correction system that can cover a range of
spelling errors.
This paper is a system description paper that is
submitted in the EMNLP 2014 conference shared
task ”Automatic Arabic Error Correction” (Mohit
et al., 2014) in the Arabic NLP workshop. The
challenges that faced us while working on this sys-
tem was the shortage of contribution in the area
of spelling correction in the Arabic language. But
hopefully the papers and the work in this shared
task specifically and in the workshop generally
will enrich this area and flourish it.
Our system targets four types of spelling errors,
edit errors, add before errors, merge errors and
split errors. For each error type, A model is built
to correct erroneous words detected by the error
detection technique. Edit errors and add before
errors are corrected using classifiers with contex-
tual features, while the merge and split errors are
corrected by inserting or omitting a space between
words and choosing the best candidate based on
the language model score of each candidate.
The rest of this paper is structured as follows.
In section 2, we give a brief background on re-
lated work in spelling correction. In section 3, we
introduce our system for spelling correction with
the description of the efficient models used in the
system. In section 4, we list some experimental re-
sults on the development set. In section 5, we give
some concluding remarks.
</bodyText>
<sectionHeader confidence="0.99989" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999916222222222">
The work in the field of spelling correction in the
Arabic language is not yet mature and no sys-
tem achieved a great error correction efficiency.
Even Microsoft Word, the most widely used Ara-
bic spelling correction system, does not achieve
good results. Our work was inspired by a num-
ber of papers. (Shaalan et al., 2012) addressed
the problem of Arabic Word Generation for spell
checking and they produced an open source and
</bodyText>
<page confidence="0.965334">
121
</page>
<bodyText confidence="0.971889710526316">
Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 121–126,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
large coverage word list for Arabic containing 9
million fully inflected surface words and applied
language models and Noisy Channel Model and
knowledge-based rules for error correction. This
word list is used in our work besides using lan-
guage models and Noisy Channel Model.
(Shaalan et al., 2010) proposed another sys-
tem for cases in which the candidate genera-
tion using edit algorithm only was not enough,
in which candidates were generated based on
transformation rules and errors are detected using
BAMA (Buckwalter Arabic Morphological Ana-
lyzer)(Buckwalter, 2002).
(Khalifa et al., 2011) proposed a system for text
segmentation. The system discriminates between
waw wasl and waw fasl, and depending on this
it can predict if the sentence to be segmented at
this position or not, they claim that they achieved
97.95% accuracy. The features used in this work
inspired us with the add before errors correction.
(Schaback, 2007) proposed a system for the En-
glish spelling correction, that is addressing the edit
errors on various levels: on the phonetic level us-
ing Soundex algorithm, on the character level us-
ing edit algorithm with one operation away, on the
word level using bigram language model, on the
syntactic level using collocation model to deter-
mine how fit the candidate is in this position and
on the semantic level using co-occurrence model
to determine how likely a candidate occurs within
the given context, using all the models output of
candidate word as features and using SVM model
to classify the candidates, they claim reaching re-
call ranging from 90% for first candidate and 97%
for all five candidates presented and outperform-
ing MS Word, Aspell, Hunspell, FST and Google.
</bodyText>
<sectionHeader confidence="0.969529" genericHeader="method">
3 Proposed System
</sectionHeader>
<bodyText confidence="0.999984666666667">
We propose a system for detecting and correct-
ing various spelling errors, including edit, split,
merge, and add before errors. The system consists
of two steps: error detection and error correction.
Each word is tested for correctness. If the word
is deemed incorrect, it is passed to the correction
step, otherwise it remains unchanged. The correc-
tion step contains specific handling for each type
of error, as detailed in subsection 3.3.
</bodyText>
<subsectionHeader confidence="0.99121">
3.1 Resources
</subsectionHeader>
<bodyText confidence="0.997106452380953">
Dictionary: Arabic wordlist for spell checking1
is a free dictionary containing 9 million Ara-
bic words. The words are automatically generated
from the AraComLex2 open-source finite state
transducer.
The dictionary is used in the generation
of candidates and using a special version of
MADAMIRA3 (Pasha et al., 2014) created for the
QALB shared task using a morphological database
based on BAMA 1.2.14 (Buckwalter, 2002). Fea-
tures are extracted for each word of the dictionary
to help in the proposed system in order that each
candidate has features just like the words in the
corpus.
Stoplist: Using stop words list available on
sourceforge.net5. This is used in the collocation
algorithm described later.
Language Model: We use SRILM (Stolcke,
2002) to build a language model using the Ajdir
Corpora6 as a corpus with the vocabulary from
the dictionary stated above. We train a language
model containing unigrams, bigrams, and trigrams
using modified Kneser-Ney smoothing (James,
2000).
QALB Corpus: QALB shared task offers a
new corpus for spelling correction. The corpus
contains a large dataset of manually corrected Ara-
bic sentences. Using this corpus, we were able
to implement a spelling correction system that
targets the most frequently occurring error types
which are (a) edit errors where a word is replaced
by another word, (b) add before errors where
a word was removed, (c) merge errors where a
space was inserted mistakenly and finally (d) split
errors where a space was removed mistakenly.
The corpus provided also has three other error
types but they occur much less frequently happen
which are (e) add after errors which is like the
add before but the token removed should be put af-
ter the word, (f) move errors where a word should
be moved to other place within the sentence and
(g) other errors where any other error that does
</bodyText>
<footnote confidence="0.9042164">
1http://sourceforge.net/projects/
arabic-wordlist/
2http://aracomlex.sourceforge.net/
3MADAMIRA-release-20140702-1.0
4AraMorph 1.2.1 - http://sourceforge.net/
projects/aramorph/
5http://sourceforge.net/projects/
arabicstopwords/
6http://aracorpus.e3rab.com/
argistestsrv.nmsu.edu/AraCorpus/
</footnote>
<page confidence="0.993374">
122
</page>
<bodyText confidence="0.877083">
not lie in the six others is labeled by it.
</bodyText>
<subsectionHeader confidence="0.966181">
3.2 Error Detection
</subsectionHeader>
<bodyText confidence="0.999983125">
The training set, development set and test set pro-
vided by QALB project come with the ”columns
file” and contains very helpful features generated
by MADAMIRA. Using the Buckwalter morpho-
logical analysis (Buckwalter, 2002) feature, we
determine if a word is correct or not. If the word
has no analysis, we consider the word as incorrect
and pass it through the correction process.
</bodyText>
<subsectionHeader confidence="0.999003">
3.3 Edit Errors Correction
</subsectionHeader>
<bodyText confidence="0.999028594594595">
The edit errors has the highest portion of total er-
rors in the corpus. It amounts to more than 55% of
the total errors. To correct this type of errors, we
train a classifier with features like the error model
probability, collocation and co-occurrence as fol-
lows:
Undiacriticized word preprocessed: Utilizing
the MADAMIRA features of each word, the undi-
acriticized word fixes some errors like hamzas, the
pair of haa and taa marboutah and the pair of yaa
and alif maqsoura.
We apply some preprocessing on the undiacrit-
icized word to make it more useful and fix the is-
sues associated with it. For example we remove
the incorrect redundant characters from the word
e.g (È@@@Ag. QË@ → ÈAg. QË@, AlrjAAAAl → AlrjAl).
We also replace the Roman punctuation marks by
the Arabic ones e.g (? → ?).
Language Model: For each candidate, A un-
igram, bigram and trigram values from the lan-
guage model trained are retrieved. In addition to a
feature that is the product of the unigram, bigram
and trigram values.
Likelihood Model: The likelihood model is
trained by iterating over the training sentences
counting the occurrences of each edit with the
characters being edited and the type of edit. The
output of this is called a confusion matrix.
The candidate score is based on the Noisy
Channel Model (Kernighan et al., 1990) which is
the multiplication of probabilty of the proposed
edit using the confusion matrix trained which is
called the error model, and the language model
score of that word. The language model used is
unigram, bigram and trigram with equal weights.
Add-1 smoothing is used for both models in the
counts.
</bodyText>
<subsubsectionHeader confidence="0.66742">
Score = p(x|w).p(w)
</subsubsectionHeader>
<bodyText confidence="0.999565375">
where x is the wrong word and w is the candidate
correction.
For substitution edit candidates, we give higher
score for substitution of a character that is close on
the keyboard or the substitution pair belongs to the
same group of letter groups (Shaalan et al., 2012)
by multiplying the score by a constant greater than
one.
</bodyText>
<equation confidence="0.636049833333333">
� �
,(h. ,h ,p) ,(H. , H~ , H~ , à ,ø
) ,(@ , @,@� ,@)
,( , � ) ,(• , �•) ,(€ , !€) ,(P ,J) ,(X , �)
.(ø �¨)
,ø) ,(ð , ð) ,(è , ~è) ,( ¬ � , �†) ,(¨ ,
</equation>
<bodyText confidence="0.99489458974359">
(|, &lt; , &gt;, A), (y, n, v, t, b), (x, H, j), (*, d), (z, r),
($, s), (D, S), (Z, T), (g, E), (q, f), (p h), (&amp;, w),
(Y, y)
For each candidate, the likelihood score is com-
puted and added to the feature vector of the candi-
date.
Collocation: The collocation model targets the
likelihood of the candidate inside the sentence.
This is done using the lemma of the word and the
POS tags of words in the sentence.
We use the algorithm in (Schaback, 2007) for
training the collocation model. Specifically, by re-
trieving the 5,000 most occurring lemmas in the
training corpus and put it in list L. For each lemma
in L, three lists are created, each record in the list
is a sequence of three POS tags around the target
lemma. For training, we shift a window of three
POS tags over the training sentence. If a lemma
belongs to L, we add the surrounding POS tags to
the equivalent list of the target lemma depending
on the position of the target lemma within the three
POS tags.
Given a misspelled word in a sentence, for each
candidate correction, if it is in the L list, we count
the number of occurrences of the surrounding POS
tags in each list of the three depending on the po-
sition of of the candidate.
The three likelihoods are stored in the feature
vector of the candidate in addition to the product
of them.
Co-occurrence: Co-occurrence is used to mea-
sure how likely a word fits inside a context. Where
L is the same list of most frequent lemmata from
collocation.
We use the co-occurrence algorithm in (Sch-
aback, 2007). Before training the model, we trans-
form each word of our training sentence into its
lemma form and remove stop-words. For exam-
ple, consider the original text:
</bodyText>
<page confidence="0.972275">
123
</page>
<equation confidence="0.62331425">
�
Aî �@ AÖß. ;LJ
ËAmÌ @ LñºmÌ @ð PAÒª&apos;B@ á~
K. �†Q�¯B �IJ�k
</equation>
<bodyText confidence="0.964527934782609">
Hyv l&gt;frq byn AlAstEmAr wAlHkwmp
AlHAlyp bmA &gt;nhA
After removing stop-words and replacing the
remaining words by their lemma form we end up
with:
úÍAg �éÓñºk PAÒª�Jƒ@ ~†Q ¯@
�
&gt;frq AstEmAr Hkwmp HAly
which forms C.
From that C, we get all lemmata that appear in
the radius of 10 words around the target lemma
b where b belongs to L. We count the number of
occurrences of each lemma in that context C.
By using the above model, three distances are
calculated for target lemma b: d1, the ratio of ac-
tually found context words in C and possibly find-
able context words. This describes how similar the
trained context and the given context are for can-
didate b; d2 considers how significant the found
context lemmata are by summing the normalized
frequencies of the context lemmata. As a third fea-
ture; d3(b) that simply measures how big the vec-
tor space model for lemma b is.
For each candidate, the model is applied and the
three distances are calculated and added to the fea-
ture vector of that candidate.
The Classifier: After generating the candidate
corrections within 1 and 2 edit operations (insert,
delete, replace and transpose) distance measured
by Levenshtein distance (Levenshtein, 1966), we
run them through a Naive-Bayes classifier using
python NLTK’s implementation to find out which
one is the most likely to be the correction for the
incorrect word.
The classifier is trained using the training set
provided by QALB project. For each edit correc-
tion in the training set, all candidates are gener-
ated for the incorrect word and a feature vector
(as shown in table1) is calculated using the tech-
niques aforementioned. If the candidate is the cor-
rect one, the label for the training feature vector is
correct else it is incorrect.
Then using the trained classifier, the same is
done on the development set or the test set where
we replace the incorrect word with the word sug-
gested by the classifier.
</bodyText>
<subsectionHeader confidence="0.98472">
3.4 Add before Errors Correction
</subsectionHeader>
<bodyText confidence="0.993084">
The add before errors are mostly punctuation er-
rors. A classifier is trained on the QALB training
</bodyText>
<tableCaption confidence="0.97077">
Table 1: The feature set used by the edit errors
classifier.
</tableCaption>
<table confidence="0.999324666666667">
Feature name
Likelihood model probability
unigram probability
previous bigram probability
next bigram probability
trigram probability
language model product
collocation left
collocation right
collocation mid
collocation product
cooccurrence distance 1
cooccurrence distance 2
cooccurrence distance 3
previous gender
previous number
next gender
next number
</table>
<bodyText confidence="0.999771454545454">
corpus. A classifier is implemented with contex-
tual features C. C is a 4-gram around the token be-
ing investigated. Each word of these four has the
two features: The token itself and Part-of-speech
tag and for the next word only pregloss because
if the word’s pregloss is ”and” it is more prob-
able that a new sentence began. Those features
are available thanks to MADAMIRA features pro-
vided with the corpus and the generated for dictio-
nary words.
The classifier is trained on the QALB training
set. We iterate over all the training sentences word
by word and getting the aforementioned features
(as shown in table 2) and label the training with
the added before token if there was a matching add
before correction for this word or the label will be
an empty string.
For applying the model, the same is done on the
QALB development sentences after removing all
punctuations as they are probably not correct and
the output of the classifier is either empty or sug-
gested token to add before current word.
</bodyText>
<subsectionHeader confidence="0.984999">
3.5 Merge Errors Correction
</subsectionHeader>
<bodyText confidence="0.9999355">
The merge errors occurs due to the insertion of
a space between two words by mistake. The ap-
proach is simply trying to attach every word with
its successor word and checking if it is a valid
</bodyText>
<page confidence="0.996245">
124
</page>
<bodyText confidence="0.870554">
posed 17057 correction resulting in the final sys-
tem recall of 0.5919, precision of 0.5781 and F1
score of 0.5849. Details are shown in Table 3.
</bodyText>
<tableCaption confidence="0.8364">
Table 2: The feature set used by the add before
errors classifier.
</tableCaption>
<table confidence="0.6221787">
Feature name
before previous word
before previous word POS tag
previous word
previous word POS tag
next word
next word POS tag
next word pregloss
after next word
after next POS tag
</table>
<bodyText confidence="0.9426315">
Arabic word and rank it with the language model
score.
</bodyText>
<subsectionHeader confidence="0.996997">
3.6 Split Errors Correction
</subsectionHeader>
<bodyText confidence="0.999976833333333">
The split errors occurs due to the deletion of a
space between two words. The approach is sim-
ply getting all the valid partitions of the word and
try to correct both partitions and give them a rank
using the language model score. The partition is at
least two characters long.
</bodyText>
<sectionHeader confidence="0.992715" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999967181818182">
In order to know the contribution of each error
type models to the overall system performance, we
adopted an incremental approach of the models.
We implemented the system using python7 and
NLTK8 (Loper and Bird, 2002) toolkit. The mod-
els are trained on the QALB corpus training set
and the results are obtained by applying the trained
models on the development set. Our goal was to
achieve high recall but without losing too much
precision. The models were evaluated using M2
scorer (Dahlmeier and Ng, 2012).
First, we start with only the preprocessed un-
diacriticized word, then we added our edit error
classifier. Adding the add before classifier was a
great addition to the system as the system was able
to increase the number of corrected errors signif-
icantly, notably the add before classifier proposed
too many incorrect suggestions that decreased the
precision. Then we added the merging correction
technique. Finally we added the split error cor-
rection technique. The system corrects 9860 errors
versus 16659 golden error corrections and pro-
</bodyText>
<footnote confidence="0.9997035">
7https://www.python.org/
8http://www.nltk.org/
</footnote>
<tableCaption confidence="0.930279666666667">
Table 3: The incremental results after adding each
error type model and applying them on the devel-
opment set.
</tableCaption>
<table confidence="0.999817833333333">
Model name Recall Precision F1 score
Undiacriticized 0.32 0.833 0.4715
+ Edit 0.3515 0.7930 0.5723
+ Add before 0.5476 0.5658 0.5567
+ Merge 0.5855 0.5816 0.5836
+ Split 0.5919 0.5781 0.5849
</table>
<bodyText confidence="0.949333222222222">
We tried other combinations of the models by
removing one or more of the components to get the
best results possible. Noting that all the systems
results are using the undiacriticized word. Details
are shown in Table 4
Table 4: The results of some combinations of the
models and applying them on the development set.
The models are abbreviated as Edit E, Merge M,
Split S, and Add before A.
</bodyText>
<table confidence="0.993195461538462">
Model name Precision Recall F1 score
M Only 0.8441 0.3724 0.5167
S Only 0.7838 0.338 0.5167
A Only 0.6008 0.4887 0.539
E Only 0.8143 0.3472 0.4868
M &amp; S 0.8121 0.3814 0.5191
E &amp; S 0.62 0.3542 0.4508
M &amp; E 0.6184 0.5403 0.5767
S &amp; M &amp; A 0.6114 0.5396 0.5733
M &amp; E &amp; A 0.6186 0.5404 0.5768
E &amp; S &amp; A 0.5955 0.507 0.5477
E &amp; S &amp; M 0.6477 0.3969 0.4922
E &amp; S &amp; M &amp; A 0.5919 0.5781 0.5849
</table>
<sectionHeader confidence="0.996103" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999864066666667">
We propose an all-in-one system for error detec-
tion and correction. The system addresses four
types of spelling errors (edit, add before, merge
and split errors). The system achieved promis-
ing results by successfully getting corrections for
about 60% of the spelling errors in the develop-
ment set. Also, There is still a big room for im-
provements in all types of error correction models.
We are planning to improve the current system
by incorporating more intelligent techniques and
models for split and merge. Also, the add before
classifier needs much work to improve the cov-
erage as the errors are mostly missing punctua-
tion marks. For the edit classifier, real-word errors
need to be addressed.
</bodyText>
<page confidence="0.998119">
125
</page>
<sectionHeader confidence="0.996051" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998106453333333">
Tim Buckwalter. 2002. Buckwalter arabic morpholog-
ical analyzer version 1.0. November.
Daniel Dahlmeier and Hwee Tou Ng. 2012. Bet-
ter evaluation for grammatical error correction. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ’12, pages 568–572, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Frankie James. 2000. Modified kneser-ney smoothing
of n-gram models. RIACS.
Mark D. Kernighan, Kenneth W. Church, and
William A. Gale. 1990. A spelling correction pro-
gram based on a noisy channel model. In Proceed-
ings of the 13th Conference on Computational Lin-
guistics - Volume 2, COLING ’90, pages 205–210,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Iraky Khalifa, Zakareya Al Feki, and Abdelfatah
Farawila. 2011. Arabic discourse segmentation
based on rhetorical methods.
VI Levenshtein. 1966. Binary Codes Capable of Cor-
recting Deletions, Insertions and Reversals. vol-
ume 10, page 707.
Edward Loper and Steven Bird. 2002. NLTK: The
Natural Language Toolkit.
Behrang Mohit, Alla Rozovskaya, Nizar Habash, Wa-
jdi Zaghouani, and Ossama Obeid. 2014. The First
QALB Shared Task on Automatic Text Correction
for Arabic. In Proceedings of EMNLP Workshop on
Arabic Natural Language Processing, Doha, Qatar,
October.
Eman Othman, Khaled Shaalan, and Ahmed Rafea.
2003. A chart parser for analyzing modern standard
arabic sentence. In To appear in In proceedings of
the MT Summit IX Workshop on Machine Transla-
tion for Semitic Languages: Issues and Approaches,
Louisiana, U.S.A.
Pasha, Arfath, Mohamed Al-Badrashiny, Mona Diab,
Ahmed El Kholy, Ramy Eskander, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan M. Roth.
2014. Madamira: A fast, comprehensive tool for
morphological analysis and disambiguation of ara-
bic. In In Proceedings of the Language Resources
and Evaluation Conference (LREC), Reykjavik, Ice-
land.
Johannes Schaback. 2007. Multi-level feature extrac-
tion for spelling correction. Hyderabad, India.
K. Shaalan, R. Aref, and A Fahmy. 2010. An approach
for analyzing and correcting spelling errors for non-
native arabic learners. In Informatics and Systems
(INFOS), 2010 The 7th International Conference on,
pages 1–7, March.
Khaled Shaalan, Mohammed Attia, Pavel Pecina,
Younes Samih, and Josef van Genabith. 2012. Ara-
bic word generation and modelling for spell check-
ing. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Thierry Declerck, Mehmet Uur
Doan, Bente Maegaard, Joseph Mariani, Asuncion
Moreno, Jan Odijk, and Stelios Piperidis, editors,
Proceedings of the Eight International Conference
on Language Resources and Evaluation (LREC’12),
Istanbul, Turkey, may. European Language Re-
sources Association (ELRA).
A. Stolcke. 2002. Srilm – an extensible language mod-
eling toolkit. In Proc. Intl. Conf. on Spoken Lan-
guage Processing, Denver,U.S.A.
Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-
sama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura
Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014.
Large scale arabic error annotation: Guidelines and
framework. In Proceedings of the Ninth Interna-
tional Conference on Language Resources and Eval-
uation (LREC’14), Reykjavik, Iceland, May. Euro-
pean Language Resources Association (ELRA).
</reference>
<page confidence="0.998523">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.198390">
<title confidence="0.997925">Arabic Spelling Correction using Supervised Learning</title>
<author confidence="0.971263">Youssef</author>
<affiliation confidence="0.853766">Dept Computer Cairo</affiliation>
<address confidence="0.945613">Giza, Egypt</address>
<email confidence="0.998027">youssefhassan13@gmail.com</email>
<author confidence="0.875092">Mohamed</author>
<affiliation confidence="0.850504">Dept Computer Cairo</affiliation>
<address confidence="0.971939">Giza, Egypt</address>
<email confidence="0.96357">mohamed@mohamedaly.info</email>
<author confidence="0.807274">Amir</author>
<affiliation confidence="0.8493555">Dept Computer Cairo</affiliation>
<address confidence="0.970119">Giza, Egypt</address>
<email confidence="0.999722">amir@alumni.caltech.edu</email>
<abstract confidence="0.998338347826087">In this work, we address the problem of spelling correction in the Arabic language utilizing the new corpus provided by QALB (Qatar Arabic Language Bank) project which is an annotated corpus of sentences with errors and their corrections. The corpus contains edit, add before, split, merge, add after, move and other error types. We are concerned with the first four error types as they contribute more than 90% of the spelling errors in the corpus. The proposed system has many models to address each error type on its own and then integrating all the models to provide an efficient and robust system that achieves an overall recall of 0.59, precision of 0.58 and F1 score of 0.58 including all the error types on the development set. Our system participated in the QALB 2014 shared task ”Automatic Arabic Error Correction” and achieved an F1 score of 0.6, earning the sixth place out of nine participants.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter arabic morphological analyzer version 1.0.</title>
<date>2002</date>
<contexts>
<context position="4606" citStr="Buckwalter, 2002" startWordPosition="741" endWordPosition="743">2014 Association for Computational Linguistics large coverage word list for Arabic containing 9 million fully inflected surface words and applied language models and Noisy Channel Model and knowledge-based rules for error correction. This word list is used in our work besides using language models and Noisy Channel Model. (Shaalan et al., 2010) proposed another system for cases in which the candidate generation using edit algorithm only was not enough, in which candidates were generated based on transformation rules and errors are detected using BAMA (Buckwalter Arabic Morphological Analyzer)(Buckwalter, 2002). (Khalifa et al., 2011) proposed a system for text segmentation. The system discriminates between waw wasl and waw fasl, and depending on this it can predict if the sentence to be segmented at this position or not, they claim that they achieved 97.95% accuracy. The features used in this work inspired us with the add before errors correction. (Schaback, 2007) proposed a system for the English spelling correction, that is addressing the edit errors on various levels: on the phonetic level using Soundex algorithm, on the character level using edit algorithm with one operation away, on the word l</context>
<context position="6627" citStr="Buckwalter, 2002" startWordPosition="1071" endWordPosition="1072">d incorrect, it is passed to the correction step, otherwise it remains unchanged. The correction step contains specific handling for each type of error, as detailed in subsection 3.3. 3.1 Resources Dictionary: Arabic wordlist for spell checking1 is a free dictionary containing 9 million Arabic words. The words are automatically generated from the AraComLex2 open-source finite state transducer. The dictionary is used in the generation of candidates and using a special version of MADAMIRA3 (Pasha et al., 2014) created for the QALB shared task using a morphological database based on BAMA 1.2.14 (Buckwalter, 2002). Features are extracted for each word of the dictionary to help in the proposed system in order that each candidate has features just like the words in the corpus. Stoplist: Using stop words list available on sourceforge.net5. This is used in the collocation algorithm described later. Language Model: We use SRILM (Stolcke, 2002) to build a language model using the Ajdir Corpora6 as a corpus with the vocabulary from the dictionary stated above. We train a language model containing unigrams, bigrams, and trigrams using modified Kneser-Ney smoothing (James, 2000). QALB Corpus: QALB shared task o</context>
<context position="8635" citStr="Buckwalter, 2002" startWordPosition="1372" endWordPosition="1373">rors where any other error that does 1http://sourceforge.net/projects/ arabic-wordlist/ 2http://aracomlex.sourceforge.net/ 3MADAMIRA-release-20140702-1.0 4AraMorph 1.2.1 - http://sourceforge.net/ projects/aramorph/ 5http://sourceforge.net/projects/ arabicstopwords/ 6http://aracorpus.e3rab.com/ argistestsrv.nmsu.edu/AraCorpus/ 122 not lie in the six others is labeled by it. 3.2 Error Detection The training set, development set and test set provided by QALB project come with the ”columns file” and contains very helpful features generated by MADAMIRA. Using the Buckwalter morphological analysis (Buckwalter, 2002) feature, we determine if a word is correct or not. If the word has no analysis, we consider the word as incorrect and pass it through the correction process. 3.3 Edit Errors Correction The edit errors has the highest portion of total errors in the corpus. It amounts to more than 55% of the total errors. To correct this type of errors, we train a classifier with features like the error model probability, collocation and co-occurrence as follows: Undiacriticized word preprocessed: Utilizing the MADAMIRA features of each word, the undiacriticized word fixes some errors like hamzas, the pair of h</context>
</contexts>
<marker>Buckwalter, 2002</marker>
<rawString>Tim Buckwalter. 2002. Buckwalter arabic morphological analyzer version 1.0. November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Better evaluation for grammatical error correction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12,</booktitle>
<pages>568--572</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="17635" citStr="Dahlmeier and Ng, 2012" startWordPosition="2966" endWordPosition="2969">e them a rank using the language model score. The partition is at least two characters long. 4 Experimental Results In order to know the contribution of each error type models to the overall system performance, we adopted an incremental approach of the models. We implemented the system using python7 and NLTK8 (Loper and Bird, 2002) toolkit. The models are trained on the QALB corpus training set and the results are obtained by applying the trained models on the development set. Our goal was to achieve high recall but without losing too much precision. The models were evaluated using M2 scorer (Dahlmeier and Ng, 2012). First, we start with only the preprocessed undiacriticized word, then we added our edit error classifier. Adding the add before classifier was a great addition to the system as the system was able to increase the number of corrected errors significantly, notably the add before classifier proposed too many incorrect suggestions that decreased the precision. Then we added the merging correction technique. Finally we added the split error correction technique. The system corrects 9860 errors versus 16659 golden error corrections and pro7https://www.python.org/ 8http://www.nltk.org/ Table 3: The</context>
</contexts>
<marker>Dahlmeier, Ng, 2012</marker>
<rawString>Daniel Dahlmeier and Hwee Tou Ng. 2012. Better evaluation for grammatical error correction. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12, pages 568–572, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frankie James</author>
</authors>
<title>Modified kneser-ney smoothing of n-gram models.</title>
<date>2000</date>
<publisher>RIACS.</publisher>
<contexts>
<context position="7194" citStr="James, 2000" startWordPosition="1161" endWordPosition="1162">abase based on BAMA 1.2.14 (Buckwalter, 2002). Features are extracted for each word of the dictionary to help in the proposed system in order that each candidate has features just like the words in the corpus. Stoplist: Using stop words list available on sourceforge.net5. This is used in the collocation algorithm described later. Language Model: We use SRILM (Stolcke, 2002) to build a language model using the Ajdir Corpora6 as a corpus with the vocabulary from the dictionary stated above. We train a language model containing unigrams, bigrams, and trigrams using modified Kneser-Ney smoothing (James, 2000). QALB Corpus: QALB shared task offers a new corpus for spelling correction. The corpus contains a large dataset of manually corrected Arabic sentences. Using this corpus, we were able to implement a spelling correction system that targets the most frequently occurring error types which are (a) edit errors where a word is replaced by another word, (b) add before errors where a word was removed, (c) merge errors where a space was inserted mistakenly and finally (d) split errors where a space was removed mistakenly. The corpus provided also has three other error types but they occur much less fr</context>
</contexts>
<marker>James, 2000</marker>
<rawString>Frankie James. 2000. Modified kneser-ney smoothing of n-gram models. RIACS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark D Kernighan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>A spelling correction program based on a noisy channel model.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th Conference on Computational Linguistics - Volume 2, COLING ’90,</booktitle>
<pages>205--210</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10131" citStr="Kernighan et al., 1990" startWordPosition="1629" endWordPosition="1632">QË@, AlrjAAAAl → AlrjAl). We also replace the Roman punctuation marks by the Arabic ones e.g (? → ?). Language Model: For each candidate, A unigram, bigram and trigram values from the language model trained are retrieved. In addition to a feature that is the product of the unigram, bigram and trigram values. Likelihood Model: The likelihood model is trained by iterating over the training sentences counting the occurrences of each edit with the characters being edited and the type of edit. The output of this is called a confusion matrix. The candidate score is based on the Noisy Channel Model (Kernighan et al., 1990) which is the multiplication of probabilty of the proposed edit using the confusion matrix trained which is called the error model, and the language model score of that word. The language model used is unigram, bigram and trigram with equal weights. Add-1 smoothing is used for both models in the counts. Score = p(x|w).p(w) where x is the wrong word and w is the candidate correction. For substitution edit candidates, we give higher score for substitution of a character that is close on the keyboard or the substitution pair belongs to the same group of letter groups (Shaalan et al., 2012) by mul</context>
</contexts>
<marker>Kernighan, Church, Gale, 1990</marker>
<rawString>Mark D. Kernighan, Kenneth W. Church, and William A. Gale. 1990. A spelling correction program based on a noisy channel model. In Proceedings of the 13th Conference on Computational Linguistics - Volume 2, COLING ’90, pages 205–210, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iraky Khalifa</author>
</authors>
<title>Zakareya Al Feki, and Abdelfatah Farawila.</title>
<date>2011</date>
<marker>Khalifa, 2011</marker>
<rawString>Iraky Khalifa, Zakareya Al Feki, and Abdelfatah Farawila. 2011. Arabic discourse segmentation based on rhetorical methods.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Levenshtein</author>
</authors>
<title>Binary Codes Capable of Correcting Deletions, Insertions and Reversals.</title>
<date>1966</date>
<volume>10</volume>
<pages>707</pages>
<contexts>
<context position="13864" citStr="Levenshtein, 1966" startWordPosition="2324" endWordPosition="2325">ribes how similar the trained context and the given context are for candidate b; d2 considers how significant the found context lemmata are by summing the normalized frequencies of the context lemmata. As a third feature; d3(b) that simply measures how big the vector space model for lemma b is. For each candidate, the model is applied and the three distances are calculated and added to the feature vector of that candidate. The Classifier: After generating the candidate corrections within 1 and 2 edit operations (insert, delete, replace and transpose) distance measured by Levenshtein distance (Levenshtein, 1966), we run them through a Naive-Bayes classifier using python NLTK’s implementation to find out which one is the most likely to be the correction for the incorrect word. The classifier is trained using the training set provided by QALB project. For each edit correction in the training set, all candidates are generated for the incorrect word and a feature vector (as shown in table1) is calculated using the techniques aforementioned. If the candidate is the correct one, the label for the training feature vector is correct else it is incorrect. Then using the trained classifier, the same is done on</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>VI Levenshtein. 1966. Binary Codes Capable of Correcting Deletions, Insertions and Reversals. volume 10, page 707.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Steven Bird</author>
</authors>
<date>2002</date>
<journal>NLTK: The Natural Language Toolkit.</journal>
<contexts>
<context position="17345" citStr="Loper and Bird, 2002" startWordPosition="2916" endWordPosition="2919">d after next POS tag Arabic word and rank it with the language model score. 3.6 Split Errors Correction The split errors occurs due to the deletion of a space between two words. The approach is simply getting all the valid partitions of the word and try to correct both partitions and give them a rank using the language model score. The partition is at least two characters long. 4 Experimental Results In order to know the contribution of each error type models to the overall system performance, we adopted an incremental approach of the models. We implemented the system using python7 and NLTK8 (Loper and Bird, 2002) toolkit. The models are trained on the QALB corpus training set and the results are obtained by applying the trained models on the development set. Our goal was to achieve high recall but without losing too much precision. The models were evaluated using M2 scorer (Dahlmeier and Ng, 2012). First, we start with only the preprocessed undiacriticized word, then we added our edit error classifier. Adding the add before classifier was a great addition to the system as the system was able to increase the number of corrected errors significantly, notably the add before classifier proposed too many i</context>
</contexts>
<marker>Loper, Bird, 2002</marker>
<rawString>Edward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Mohit</author>
<author>Alla Rozovskaya</author>
<author>Nizar Habash</author>
<author>Wajdi Zaghouani</author>
<author>Ossama Obeid</author>
</authors>
<title>The First QALB Shared Task on Automatic Text Correction for Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP Workshop on Arabic Natural Language Processing,</booktitle>
<location>Doha, Qatar,</location>
<contexts>
<context position="2224" citStr="Mohit et al., 2014" startWordPosition="349" endWordPosition="352"> range of possible spelling errors. Fortunately the QALB corpus (Zaghouani et al., 2014) will help enrich the resources for Arabic language generally and the spelling correction specifically by providing an annotated corpus with corrected sentences from user comments, native student essays, nonnative data and machine translation data. In this work, we are trying to use this corpus to build an error correction system that can cover a range of spelling errors. This paper is a system description paper that is submitted in the EMNLP 2014 conference shared task ”Automatic Arabic Error Correction” (Mohit et al., 2014) in the Arabic NLP workshop. The challenges that faced us while working on this system was the shortage of contribution in the area of spelling correction in the Arabic language. But hopefully the papers and the work in this shared task specifically and in the workshop generally will enrich this area and flourish it. Our system targets four types of spelling errors, edit errors, add before errors, merge errors and split errors. For each error type, A model is built to correct erroneous words detected by the error detection technique. Edit errors and add before errors are corrected using classi</context>
</contexts>
<marker>Mohit, Rozovskaya, Habash, Zaghouani, Obeid, 2014</marker>
<rawString>Behrang Mohit, Alla Rozovskaya, Nizar Habash, Wajdi Zaghouani, and Ossama Obeid. 2014. The First QALB Shared Task on Automatic Text Correction for Arabic. In Proceedings of EMNLP Workshop on Arabic Natural Language Processing, Doha, Qatar, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eman Othman</author>
<author>Khaled Shaalan</author>
<author>Ahmed Rafea</author>
</authors>
<title>A chart parser for analyzing modern standard arabic sentence. In To appear in</title>
<date>2003</date>
<booktitle>In proceedings of the MT Summit IX Workshop on Machine Translation for Semitic Languages: Issues and Approaches,</booktitle>
<location>Louisiana, U.S.A.</location>
<contexts>
<context position="1388" citStr="Othman et al., 2003" startWordPosition="212" endWordPosition="215">rrors in the corpus. The proposed system has many models to address each error type on its own and then integrating all the models to provide an efficient and robust system that achieves an overall recall of 0.59, precision of 0.58 and F1 score of 0.58 including all the error types on the development set. Our system participated in the QALB 2014 shared task ”Automatic Arabic Error Correction” and achieved an F1 score of 0.6, earning the sixth place out of nine participants. 1 Introduction The Arabic language is a highly inflected natural language that has an enormous number of possible words (Othman et al., 2003). And although it is the native language of over 300 million people, it suffers from the lack of useful resources as opposed to other languages, specially English and until now there are no systems that cover the wide range of possible spelling errors. Fortunately the QALB corpus (Zaghouani et al., 2014) will help enrich the resources for Arabic language generally and the spelling correction specifically by providing an annotated corpus with corrected sentences from user comments, native student essays, nonnative data and machine translation data. In this work, we are trying to use this corpus</context>
</contexts>
<marker>Othman, Shaalan, Rafea, 2003</marker>
<rawString>Eman Othman, Khaled Shaalan, and Ahmed Rafea. 2003. A chart parser for analyzing modern standard arabic sentence. In To appear in In proceedings of the MT Summit IX Workshop on Machine Translation for Semitic Languages: Issues and Approaches, Louisiana, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arfath Pasha</author>
<author>Mohamed Al-Badrashiny</author>
<author>Mona Diab</author>
<author>Ahmed El Kholy</author>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Manoj Pooleery</author>
<author>Owen Rambow</author>
<author>Ryan M Roth</author>
</authors>
<title>Madamira: A fast, comprehensive tool for morphological analysis and disambiguation of arabic. In</title>
<date>2014</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik,</booktitle>
<marker>Pasha, Al-Badrashiny, Diab, El Kholy, Eskander, Habash, Pooleery, Rambow, Roth, 2014</marker>
<rawString>Pasha, Arfath, Mohamed Al-Badrashiny, Mona Diab, Ahmed El Kholy, Ramy Eskander, Nizar Habash, Manoj Pooleery, Owen Rambow, and Ryan M. Roth. 2014. Madamira: A fast, comprehensive tool for morphological analysis and disambiguation of arabic. In In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Schaback</author>
</authors>
<title>Multi-level feature extraction for spelling correction.</title>
<date>2007</date>
<location>Hyderabad, India.</location>
<contexts>
<context position="4967" citStr="Schaback, 2007" startWordPosition="802" endWordPosition="803"> system for cases in which the candidate generation using edit algorithm only was not enough, in which candidates were generated based on transformation rules and errors are detected using BAMA (Buckwalter Arabic Morphological Analyzer)(Buckwalter, 2002). (Khalifa et al., 2011) proposed a system for text segmentation. The system discriminates between waw wasl and waw fasl, and depending on this it can predict if the sentence to be segmented at this position or not, they claim that they achieved 97.95% accuracy. The features used in this work inspired us with the add before errors correction. (Schaback, 2007) proposed a system for the English spelling correction, that is addressing the edit errors on various levels: on the phonetic level using Soundex algorithm, on the character level using edit algorithm with one operation away, on the word level using bigram language model, on the syntactic level using collocation model to determine how fit the candidate is in this position and on the semantic level using co-occurrence model to determine how likely a candidate occurs within the given context, using all the models output of candidate word as features and using SVM model to classify the candidates</context>
<context position="11377" citStr="Schaback, 2007" startWordPosition="1880" endWordPosition="1881">t greater than one. � � ,(h. ,h ,p) ,(H. , H~ , H~ , à ,ø ) ,(@ , @,@� ,@) ,( , � ) ,(• , �•) ,(€ , !€) ,(P ,J) ,(X , �) .(ø �¨) ,ø) ,(ð , ð) ,(è , ~è) ,( ¬ � , �†) ,(¨ , (|, &lt; , &gt;, A), (y, n, v, t, b), (x, H, j), (*, d), (z, r), ($, s), (D, S), (Z, T), (g, E), (q, f), (p h), (&amp;, w), (Y, y) For each candidate, the likelihood score is computed and added to the feature vector of the candidate. Collocation: The collocation model targets the likelihood of the candidate inside the sentence. This is done using the lemma of the word and the POS tags of words in the sentence. We use the algorithm in (Schaback, 2007) for training the collocation model. Specifically, by retrieving the 5,000 most occurring lemmas in the training corpus and put it in list L. For each lemma in L, three lists are created, each record in the list is a sequence of three POS tags around the target lemma. For training, we shift a window of three POS tags over the training sentence. If a lemma belongs to L, we add the surrounding POS tags to the equivalent list of the target lemma depending on the position of the target lemma within the three POS tags. Given a misspelled word in a sentence, for each candidate correction, if it is i</context>
</contexts>
<marker>Schaback, 2007</marker>
<rawString>Johannes Schaback. 2007. Multi-level feature extraction for spelling correction. Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Shaalan</author>
<author>R Aref</author>
<author>A Fahmy</author>
</authors>
<title>An approach for analyzing and correcting spelling errors for nonnative arabic learners.</title>
<date>2010</date>
<booktitle>In Informatics and Systems (INFOS), 2010 The 7th International Conference on,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="4335" citStr="Shaalan et al., 2010" startWordPosition="700" endWordPosition="703">of papers. (Shaalan et al., 2012) addressed the problem of Arabic Word Generation for spell checking and they produced an open source and 121 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 121–126, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics large coverage word list for Arabic containing 9 million fully inflected surface words and applied language models and Noisy Channel Model and knowledge-based rules for error correction. This word list is used in our work besides using language models and Noisy Channel Model. (Shaalan et al., 2010) proposed another system for cases in which the candidate generation using edit algorithm only was not enough, in which candidates were generated based on transformation rules and errors are detected using BAMA (Buckwalter Arabic Morphological Analyzer)(Buckwalter, 2002). (Khalifa et al., 2011) proposed a system for text segmentation. The system discriminates between waw wasl and waw fasl, and depending on this it can predict if the sentence to be segmented at this position or not, they claim that they achieved 97.95% accuracy. The features used in this work inspired us with the add before err</context>
</contexts>
<marker>Shaalan, Aref, Fahmy, 2010</marker>
<rawString>K. Shaalan, R. Aref, and A Fahmy. 2010. An approach for analyzing and correcting spelling errors for nonnative arabic learners. In Informatics and Systems (INFOS), 2010 The 7th International Conference on, pages 1–7, March.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Khaled Shaalan</author>
<author>Mohammed Attia</author>
<author>Pavel Pecina</author>
<author>Younes Samih</author>
<author>Josef van Genabith</author>
</authors>
<title>Arabic word generation and modelling for spell checking.</title>
<date>2012</date>
<booktitle>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Uur Doan, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors,</editor>
<location>Istanbul, Turkey,</location>
<marker>Shaalan, Attia, Pecina, Samih, van Genabith, 2012</marker>
<rawString>Khaled Shaalan, Mohammed Attia, Pavel Pecina, Younes Samih, and Josef van Genabith. 2012. Arabic word generation and modelling for spell checking. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Uur Doan, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>Srilm – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. Intl. Conf. on Spoken Language Processing,</booktitle>
<location>Denver,U.S.A.</location>
<contexts>
<context position="6958" citStr="Stolcke, 2002" startWordPosition="1125" endWordPosition="1126">rated from the AraComLex2 open-source finite state transducer. The dictionary is used in the generation of candidates and using a special version of MADAMIRA3 (Pasha et al., 2014) created for the QALB shared task using a morphological database based on BAMA 1.2.14 (Buckwalter, 2002). Features are extracted for each word of the dictionary to help in the proposed system in order that each candidate has features just like the words in the corpus. Stoplist: Using stop words list available on sourceforge.net5. This is used in the collocation algorithm described later. Language Model: We use SRILM (Stolcke, 2002) to build a language model using the Ajdir Corpora6 as a corpus with the vocabulary from the dictionary stated above. We train a language model containing unigrams, bigrams, and trigrams using modified Kneser-Ney smoothing (James, 2000). QALB Corpus: QALB shared task offers a new corpus for spelling correction. The corpus contains a large dataset of manually corrected Arabic sentences. Using this corpus, we were able to implement a spelling correction system that targets the most frequently occurring error types which are (a) edit errors where a word is replaced by another word, (b) add before</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. Srilm – an extensible language modeling toolkit. In Proc. Intl. Conf. on Spoken Language Processing, Denver,U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wajdi Zaghouani</author>
<author>Behrang Mohit</author>
<author>Nizar Habash</author>
<author>Ossama Obeid</author>
<author>Nadi Tomeh</author>
<author>Alla Rozovskaya</author>
<author>Noura Farra</author>
<author>Sarah Alkuhlani</author>
<author>Kemal Oflazer</author>
</authors>
<title>Large scale arabic error annotation: Guidelines and framework.</title>
<date>2014</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<location>Reykjavik, Iceland,</location>
<contexts>
<context position="1693" citStr="Zaghouani et al., 2014" startWordPosition="264" endWordPosition="267">set. Our system participated in the QALB 2014 shared task ”Automatic Arabic Error Correction” and achieved an F1 score of 0.6, earning the sixth place out of nine participants. 1 Introduction The Arabic language is a highly inflected natural language that has an enormous number of possible words (Othman et al., 2003). And although it is the native language of over 300 million people, it suffers from the lack of useful resources as opposed to other languages, specially English and until now there are no systems that cover the wide range of possible spelling errors. Fortunately the QALB corpus (Zaghouani et al., 2014) will help enrich the resources for Arabic language generally and the spelling correction specifically by providing an annotated corpus with corrected sentences from user comments, native student essays, nonnative data and machine translation data. In this work, we are trying to use this corpus to build an error correction system that can cover a range of spelling errors. This paper is a system description paper that is submitted in the EMNLP 2014 conference shared task ”Automatic Arabic Error Correction” (Mohit et al., 2014) in the Arabic NLP workshop. The challenges that faced us while worki</context>
</contexts>
<marker>Zaghouani, Mohit, Habash, Obeid, Tomeh, Rozovskaya, Farra, Alkuhlani, Oflazer, 2014</marker>
<rawString>Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014. Large scale arabic error annotation: Guidelines and framework. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland, May. European Language Resources Association (ELRA).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>