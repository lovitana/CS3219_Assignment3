<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000093">
<title confidence="0.999117">
A Rule-Based Approach to Aspect Extraction from Product Reviews
</title>
<author confidence="0.995317">
Soujanya Poria Erik Cambria
</author>
<affiliation confidence="0.998246">
Dept of Computing Science &amp; Maths School of Computer Engineering
University of Stirling Nanyang Technological University
</affiliation>
<email confidence="0.996022">
soujanya.poria@cs.stir.ac.uk cambria@ntu.edu.sg
</email>
<author confidence="0.998654">
Lun-Wei Ku Chen Gui Alexander Gelbukh
</author>
<affiliation confidence="0.999312">
Institute of Information Science SenticNet Center for Computing Research
</affiliation>
<email confidence="0.7137225">
Academia Sinica chen@sentic.net National Polytechnic Institute
lwku@iis.sinica.edu.tw gelbukh@cic.ipn.mx
</email>
<sectionHeader confidence="0.995572" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998916">
Sentiment analysis is a rapidly growing research field that has attracted both academia and in-
dustry because of the challenging research problems it poses and the potential benefits it can
provide in many real life applications. Aspect-based opinion mining, in particular, is one of the
fundamental challenges within this research field. In this work, we aim to solve the problem of
aspect extraction from product reviews by proposing a novel rule-based approach that exploits
common-sense knowledge and sentence dependency trees to detect both explicit and implicit as-
pects. Two popular review datasets were used for evaluating the system against state-of-the-art
aspect extraction techniques, obtaining higher detection accuracy for both datasets.
</bodyText>
<sectionHeader confidence="0.998997" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.951058363636363">
In opinion mining, different levels of granularity analysis have been proposed, each one having its own
advantages and disadvantages. Aspect-based opinion mining (Hu and Liu, 2004; Ding et al., 2008)
focuses on the extraction of aspects (or product features) from opinionated text and on the inference of
polarity values associated with these. For example, a sentence like “I love the touchscreen of my phone
but the battery life is so short” contains two aspects or opinion targets, namely touchscreen and battery
life. In this case, applying a sentence level polarity detection technique would mistakenly result in a
polarity value close to neutral, since the two opinions expressed by the users are opposite. Hence, aspect
extraction is necessary to first deconstruct sentences into product features and then assign a separate
polarity value to each of these features.
There are two types of aspects defined in aspect-based opinion mining: explicit and implicit. Explicit
aspects are concepts that explicitly denote targets in the opinionated sentence. For instance, in the above
example, touchscreen and battery life are explicit aspects as they are explicitly mentioned in the sentence.
On the other hand, an aspect can also be expressed indirectly through an implicit aspect clue (IAC), e.g.,
in the sentence “This camera is sleek and very affordable”, which implicitly provides a positive opinion
about the aspects appearance and price of the entity camera.
Explicit aspect extraction has been widely researched and there exists several approaches for this
task. Still, limited work has been done in extracting implicit aspects. This task is very difficult yet very
important because the phenomenon of implicit aspects is present in nearly every opinionated document.
For example, the following document extracted from the corpus (Hu and Liu, 2004) uses only implicit
aspects:
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0
</bodyText>
<page confidence="0.978431">
28
</page>
<note confidence="0.9890055">
Proceedings of the Second Workshop on Natural Language Processing for Social Media (SocialNLP), pages 28–37,
Dublin, Ireland, August 24 2014.
</note>
<bodyText confidence="0.999516181818182">
This is the best phone one could have. It has all the features one would need in a cellphone: It
is lightweight, sleek and attractive. I found it very user-friendly and easy to manipulate; very
convenient to scroll in menu etc.
Here, the word “lightweight” refers to the weight of the phone; the words “sleek” and “attractive” to
its appearance; the compound “user-friendly” to its interface; the phrase “easy to manipulate” to its
functionality; finally, the phrase “to scroll in menu” can be interpreted as a reference to the interface
of the phone or its menu. Even though the aspects appearance, weight and interface do not appear
in the sentence, the context contains clues that permit us to infer them. Namely, the words “sleek,”
“lightweight,” and “user-friendly” that do occur in the context suggest these aspects.
In contrast to the task of identification of explicit aspects, the general scheme for identification of
implicit aspects, a task called implicit aspect extraction, typically involves two steps:
</bodyText>
<listItem confidence="0.996673">
1. Identify IACs (e.g., “sleek”) in the opinionated document.
2. Map them to the corresponding aspects (e.g., appearance).
</listItem>
<bodyText confidence="0.999159416666667">
In this paper, we propose a novel approach to detect explicit aspects and IACs from opinionated
documents. We also map IACs to their respective aspect categories. IACs are either single words,
such as “sleek,” or multi-word expressions, such as “easy to manipulate” as in the above example. Each
IAC can be represented by a different part-of-speech (POS): in the example “This MP3 player is really
expensive,” the IAC “expensive” suggesting the aspect price is an adjective; in “This camera looks
great,” the IAC “look” suggesting appearance is a verb; in “I hate this phone. It only lasted less than six
months!”, the IAC “lasted” suggesting durability of the phone is a verb. In the following examples, IACs
are nouns or noun phrases: “Even if I had paid full price I would have considered this phone a good deal,”
“Not to mention the sleekness of this phone”, “The player keeps giving random errors”, “This phone is a
piece of crap.”
In different contexts, the same implicit aspect can be implied by different IACs, as shown below for
the implicit aspect price:
</bodyText>
<listItem confidence="0.999939166666667">
• This mp3 player is very affordable.
• This mp3 player also costs a lot less than the ipod.
• This mp3 player is quite cheap.
• This mp3 is inexpensive.
• I bought this mp3 for almost nothing!
• This mp3 player has been fairly innovative and reasonably priced.
</listItem>
<bodyText confidence="0.996824461538461">
A common approach for IAC identification is to assume that sentiments or polarity words are good
candidates for IACs: for example, in “This MP3 player is really expensive,” the word “expensive”,
which bears negative polarity, is also the IAC for the aspect price. However, this is not always true.
For example, in “This camera looks great,” the word “looks” implies the appearance of the phone,
while polarity is conveyed through the word “great.” In “I hate this phone. It only lasted less than six
months!”, the word “lasted” is the IAC for durability of the phone, while polarity is indicated by “hate.”
Furthermore, the second sentence of this example could appear without the first one: “This phone only
lasted less than six months” and still constitute a negative opinion of the phone’s durability, but not
expressed by any specific word.
This phenomenon is known in opinion mining as desirable fact: communicating fact that by common-
sense are good or bad, which indirectly implies polarity. For example, the objective fact “The camera can
hold lots of pictures” does not contain any sentiment or polarity word yet gives a positive opinion about
the camera’s memory capacity (IAC “hold”), because it is desirable for a camera to hold many pictures.
</bodyText>
<page confidence="0.99761">
29
</page>
<bodyText confidence="0.999583111111111">
In this paper, we present a rule-based approach that exploits common-sense knowledge and sentence
dependency trees to detect both implicit and explicit aspects. In particular, the approach draws lessons
from recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a)
and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependency
structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity
associated with them. The paper is organized as follows: Section 2 presents the literature in aspect ex-
traction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed
methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental
evaluation; finally, Section 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999696206896552">
Aspect extraction from opinionated text was first studied by Hu and Liu (Hu and Liu, 2004), who also
introduced the distinction between explicit and implicit aspects. However, the authors only dealt with
explicit aspects by adopting a set of rules based on statistical observations. Hu and Liu’s method was im-
proved by Popescu and Etzioni (Popescu and Etzioni, 2005) and by Blair-Goldensonh (Blair-Goldensohn
et al., 2008). Popescu and Etzioni assumed the product class to be known as priori. Their algorithm
detects whether a noun or noun phrase is a product feature or not by computing PMI between the noun
phrase and the product class. Scaffidi et al. (Scaffidi et al., 2007) presented a method that uses a language
model to identify product features. They assumed that product features are more frequent in product re-
views than in general natural language text. However, their method seems to be very inaccurate in terms
of precision as the retrieved aspects extracted by their method were very noisy.
Aspect extraction can be seen as a general information extraction problem, for which techniques based
on sequential labeling are generally used. The most popular methods in this context, in particular, are
Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and
Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit
aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a
custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and
Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects.
As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu
and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity
classification. However, their system is not described in detail and is not publicly available. To the
best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one
or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IACs
(which were assumed to be sentiment words) to their corresponding explicit aspects. The method exploits
the mutual reinforcement relationship between an explicit aspect and a sentiment word forming a co-
occurring pair in a sentence. Hai (Zhen et al., 2011) proposed a two-phase co-occurrence association
rule mining approach to match implicit aspects (which were also assumed to be sentiment words) with
explicit aspects. Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extract
explicit aspects and mapped implicit features by using a set of sentiment words and by clustering explicit
feature-word pairs.
</bodyText>
<sectionHeader confidence="0.997121" genericHeader="method">
3 Method
</sectionHeader>
<subsectionHeader confidence="0.998604">
3.1 Corpus for aspect extraction
</subsectionHeader>
<bodyText confidence="0.9998416">
In order to evaluate the explicit aspect extraction algorithm, we use the corpus provided by (Hu and
Liu, 2004) and the Semeval 2014 dataset1 (Table 1). As for the implicit aspect extraction algorithm and
lexicon, we use the corpus developed by Cruz-Garcia et al. (Cruz-Garcia et al., 2014), who manually
labeled each IAC and their corresponding aspects in a well-known corpus for opinion mining (Hu and
Liu, 2004). The corpus is publicly available for research purposes.2
</bodyText>
<footnote confidence="0.996054666666667">
1http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools
2Available from www.gelbukh.com/resources/implicit-aspect-extraction-corpus, visited on
March 19, 2014.
</footnote>
<page confidence="0.99838">
30
</page>
<tableCaption confidence="0.999715">
Table 1: Description of Semeval 2014 dataset
</tableCaption>
<table confidence="0.963201">
Sentences Containing n aspect terms
Domain Name n = 0 n &gt; 1 n &gt; 2 total(n &gt; 0)
Restaurants 1,732 2,212 881 3,944
Laptops 1,883 2,065 456 3,948
</table>
<subsectionHeader confidence="0.999911">
3.2 Pre-Processing
</subsectionHeader>
<bodyText confidence="0.9995542">
Pre-processing is a key step for aspect parsing. The pre-processing module of the proposed framework
consists of two major steps: firstly, the sentence dependency tree is obtained through Stanford Depen-
dency Parser3; secondly, dependency structure elements are processed by means of Stanford Lemmatizer
for each sentence. It is important to build the dependency tree before lemmatization as swapping the two
steps results in several imprecisions caused by the lower grammatical accuracy of lemmatized sentences.
</bodyText>
<subsectionHeader confidence="0.973582">
3.3 Aspect Parser
3.3.1 Implicit aspect lexicon
</subsectionHeader>
<bodyText confidence="0.9997908">
We use the implicit aspect corpus developed by Cruz-Garcia et al. (Cruz-Garcia et al., 2014), where
IACs are indicated and manually labeled by their corresponding aspect categories. For our task, we
extracted the sentences having implicit aspects and then extracted IACs for each of them, along with
their corresponding labeled categories. For example, in “The car is expensive” the IAC is expensive and
it is labeled by the category price. Below is the list of the aspect categories extracted from the corpus:
</bodyText>
<listItem confidence="0.999963222222222">
• functionality
• weight
• price
• appearance
• behavior
• performance
• quality
• service
• size
</listItem>
<bodyText confidence="0.9986586">
For each IAC under every aspect category, synonyms and antonyms were obtained from WordNet (Fell-
baum, 1998) and stored under the same aspect category. For example, expensive and its antonym inex-
pensive both have the same category price. Semantics extracted from SenticNet (Cambria et al., 2014b)
have also been exploited to enlarge the set of conceptually related IACs. Thus, a lexicon of 1,128 IACs
categorized into the above categories was built.
</bodyText>
<subsectionHeader confidence="0.848208">
3.3.2 Opinion Lexicon
</subsectionHeader>
<bodyText confidence="0.997234666666667">
We use SenticNet 3 as a concept-level opinion lexicon. The common-sense knowledge base contains
30,000 multi-word expressions labeled by their polarity scores. The proposed aspect parser is based on
two general rules:
</bodyText>
<listItem confidence="0.9996815">
• Rules for the sentences having subject verb.
• Rules for the sentences which do not have subject verb.
</listItem>
<footnote confidence="0.970658">
3http://nlp.stanford.edu:8080/parser
</footnote>
<page confidence="0.999782">
31
</page>
<bodyText confidence="0.969876">
A dependency relation is a binary relation characterized by the following features:
</bodyText>
<listItem confidence="0.982901">
• The type of the relation that specifies the nature of the (syntactic) link between the two elements in
the relation.
• The head of the relation: this is the element that is the pivot of the relation. Core syntactic and
semantics properties (e.g., agreement) are inherited from the head.
• The dependent is the element that depends on the head and which usually inherits some of its
characteristics (e.g., number, gender in the case of agreement).
</listItem>
<bodyText confidence="0.999542571428571">
Most of the times, the active token is considered in a relation if it acts as the head of the relation, although
there are exceptions. Once the active token has been identified as the trigger for a rule, there are several
ways to compute its contribution, depending on how the dependency relation and the properties of the
tokens match with the rules. The preferred way is not to consider the contribution of the token alone,
but in combination with the other elements in the dependency relation. First of all, Stanford parser is
used to obtain the dependency parse structure of each sentence. Then, hand-crafted dependency rules are
employed on the parse trees to extract aspects.
</bodyText>
<subsectionHeader confidence="0.760197">
3.3.3 Subject Noun Rule
</subsectionHeader>
<bodyText confidence="0.999799">
Trigger: when the active token is found to be the syntactic subject of a token. Behavior: if an active
token h is in a subject noun relationship with a word t then:
</bodyText>
<listItem confidence="0.98925828">
1. if t has any adverbial or adjective modifier and the modifier exists in SenticNet, then t is extracted
as an aspect.
2. if the sentence does not have auxiliary verb, i.e., is, was, would, should, could, then:
• if the verb t is modified by an adjective or an adverb or it is in adverbial clause modifier relation
with another token, then both h and t are extracted as aspects. In (1), battery is in a subject
relation with lasts and lasts is modified by the adjective modifier little, hence both the aspects
last and battery are extracted.
(1) The battery lasts little.
• if t has any direct object relation with a token n and the POS of the token is Noun and n is not
in SenticNet, then n is extracted as an aspect. In (2), like is in direct object relation with lens
so the aspect lens is extracted.
(2) I like the lens of this camera.
• if t has any direct object relation with a token n and the POS of the token n is Noun and n exists
in SenticNet, then the token n extracted as aspect term. In the dependency parse tree of the
sentence, if another token n1 is connected to n using any dependency relation and the POS of
n1 is Noun, then n1 is extracted as an aspect. In (3), like is in direct object relation with beauty
which is connected to screen via a preposition relation. So the aspects screen and beauty are
extracted.
(3) I like the beauty of the screen.
• if t is in open clausal complement relation with a token t1, then the aspect t-t1 is extracted if t-t1
exists in the opinion lexicon. If t1 is connected with a token t2 whose POS is Noun, then t2 is
extracted as an aspect. In (4), like and comment is in clausal complement relation and comment
is connected to camera using a preposition relation. Here, the POS of camera is Noun and,
hence, camera is extracted as an aspect.
(4) I would like to comment on the camera of this phone.
</listItem>
<page confidence="0.941047">
32
</page>
<listItem confidence="0.756502615384615">
3. A copula is the relation between the complement of a copular verb and the copular verb. If the
token t is in copula relation with a copular verb and the copular verb exists in the implicit aspect
lexicon, then t is extract as aspect term. In (5), expensive is extracted as an aspect.
(5) The car is expensive.
4. If the token t is in copula relation with a copular verb and the POS of h is Noun, then h is extracted
as an explicit aspect. In (6), camera is extracted as an aspect.
(6) The camera is nice.
5. If the token t is in copula relation with a copular verb and the copular verb is connected to a token
t1 using any dependency relation and t1 is a verb, then both t1 and t are extracted as implicit aspect
terms, as long as they exist in the implicit aspect lexicon. In (7), lightweight is in copula relation
with is and lightweight is connected to the word carry by open clausal complement relation. Here,
both lightweight and carry are extracted as aspects.
(7) The phone is very lightweight to carry.
</listItem>
<subsectionHeader confidence="0.779865">
3.3.4 Sentences which do not have subject noun relation in their parse tree
</subsectionHeader>
<bodyText confidence="0.991643">
For sentences that do not have noun subject relation in their parse trees, aspects are extracted using the
following rules:
</bodyText>
<listItem confidence="0.9194331">
1. if an adjective or adverb h is in infinitival or open clausal complement relation with a token t and h
exists in the implicit aspect lexicon, then h is extracted as an aspect. In (8), big is extracted as an
aspect as it is connected to hold using a clausal complement relation.
(8) Very big to hold.
2. if a token h is connected to a noun t using a prepositional relation, then both h and t are extracted as
aspects. In (9) sleekness is extracted as an aspect.
(9) Love the sleekness of the player.
3. if a token h is in a direct object relation with a token t, t is extracted as aspect. In (10), mention is in
a direct object relation with price, hence price is extracted as an aspect.
(10) Not to mention the price of the phone.
</listItem>
<subsectionHeader confidence="0.601953">
3.3.5 Additional Rules
</subsectionHeader>
<listItem confidence="0.965509555555555">
• For each aspect term extracted above, if an aspect term h is in co-ordination or conjunct relation
with another token t, then t is also extracted as an aspect. In (11), amazing is firstly extracted as an
aspect term. As amazing is in conjunct relation with easy, then use is also extracted as an aspect.
(11) The camera is amazing and easy to use.
• A noun compound modifier of an NP is any noun that serves to modify the head noun. If t is
extracted as an aspect and t has noun compound modifier h, then the aspect h-t is extracted and t
is removed from the aspect list. In (12), as chicken and casserole are in noun compound modifier
relation, only chicken casserole is extracted as an aspect.
(12) We ordered the chicken casserole, but what we got were a few small pieces of chicken, all
</listItem>
<bodyText confidence="0.531562">
dark meat and on the bone.
</bodyText>
<page confidence="0.998056">
33
</page>
<sectionHeader confidence="0.399871" genericHeader="method">
4 Novelty of the proposed work
</sectionHeader>
<bodyText confidence="0.9993543">
First of all, the proposed method is fully unsupervised and depends on the accuracy of the dependency
parser and the opinion lexicon, rather then a training corpus and supervised learning accuracy. Only
(Qiu et al., 2011) follow an unsupervised learning approach but the proposed method uses an enhanced
set of rules and opinion lexicon. The proposed method also outperforms (Qiu et al., 2011) on the same
dataset they used. Implicit aspects extracted through the proposed method differ from implicit aspect
expressions defined by Liu (Liu, 2012) as “aspect expressions that are not nouns or noun phrases” in that
implicit aspects extracted by the proposed algorithm semantically refer to the values of the pre-defined
aspects, irrespective of their own surface POS. Below are listed some examples where the implicit aspect
terms are either noun or noun phrases.
In (13), the IAC deal is extracted.
</bodyText>
<listItem confidence="0.8107934">
(13) Even if I had paid full price I would have considered this phone a good deal.
In (14), sleekness is extracted as an IAC.
(14) Not to mention the sleekness of this phone.
In (15), the IAC errors is extracted by the algorithm.
(15) The player keeps giving random errors.
</listItem>
<bodyText confidence="0.66769">
In (16), piece of crap is a noun phrase and is extracted as an IAC by the proposed algorithm.
(16) This phone is apiece of crap.
A demo of the developed aspect parser is freely available at http://sentic.net/demo.
</bodyText>
<tableCaption confidence="0.997994">
Table 2: Results on the DVD-player review dataset provided by (Hu and Liu, 2004)
</tableCaption>
<table confidence="0.9943412">
Algorithm Precision Recall
Hu and Liu 75.00% 82.00%
Popescu and Etzioni 89.00% 80.00%
Dependency propagation method 87.00% 81.00%
Proposed approach 89.25% 91.25%
</table>
<tableCaption confidence="0.998707">
Table 3: Results on the Canon G3 review dataset provided by (Hu and Liu, 2004)
</tableCaption>
<table confidence="0.9977388">
Algorithm Precision Recall
Hu and Liu 71.00% 79.00%
Popescu and Etzioni 87.00% 74.00%
Dependency propagation method 90.00% 81.00%
Proposed approach 90.15% 92.25%
</table>
<tableCaption confidence="0.999262">
Table 4: Results on the Jukebox review dataset provided by (Hu and Liu, 2004)
</tableCaption>
<table confidence="0.7039286">
Algorithm Precision Recall
Hu and Liu 72.00% 76.00%
Popescu and Etzioni 89.00% 74.00%
Dependency propagation method 90.00% 86.00%
Proposed approach 92.25% 94.15%
</table>
<page confidence="0.98258">
34
</page>
<tableCaption confidence="0.999482">
Table 5: Results on the Nikon Coolpix review dataset provided by (Hu and Liu, 2004)
</tableCaption>
<table confidence="0.9938924">
Algorithm Precision Recall
Hu and Liu 69.00% 82.00%
Popescu and Etzioni 86.00% 80.00%
Dependency propagation method 81.00% 84.00%
Proposed approach 82.15% 86.15%
</table>
<tableCaption confidence="0.995001">
Table 6: Results on the Nokia-6610 review dataset provided by (Hu and Liu, 2004)
</tableCaption>
<table confidence="0.789263">
Algorithm Precision Recall
Hu and Liu 74.00% 80.00%
Popescu and Etzioni 90.00% 78.00%
Dependency propagation method 92.00% 86.00%
Proposed approach 93.25% 93.32%
</table>
<sectionHeader confidence="0.998887" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.992885">
5.1 Experiment on the dataset provided by (Hu and Liu, 2004)
</subsectionHeader>
<bodyText confidence="0.999840428571429">
Experimental evaluation was carried out on the dataset derived from (Hu and Liu, 2004). As discussed
in Section 3, the proposed method is able to extract both explicit and implicit aspects. To the best of our
knowledge, there is no state-of-the-art benchmark to evaluate implicit aspect extraction.
We compare the proposed framework with those in Hu and Liu (Hu and Liu, 2004), Qiu et al. (Qiu et
al., 2011), and Popescu and Etzioni (Popescu and Etzioni, 2005) (which only carried out explicit aspect
extraction). Table 2, Table 3, Table 4, Table 5 and Table 6 show that the proposed framework outperforms
all existing methods in terms of both precision and recall.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999991285714286">
We have illustrated a method for extracting both explicit and implicit aspects from opinionated text.
The proposed framework only leverages on common-sense knowledge and on the dependency structure
of sentences and, hence, is unsupervised. As future work, we aim to discover more rules for aspect
extraction. Another key future effort is to combine existing rules for complex aspect extraction. To
obtain the aspect categories of IACs, we have developed an aspect knowledge base using WordNet and
SenticNet. We will focus on extending the scalability of such knowledge base and on making it as much
noise-free as possible.
</bodyText>
<subsectionHeader confidence="0.997316">
6.1 Experiment on Semeval 2014 dataset
</subsectionHeader>
<bodyText confidence="0.999105">
We also carried out experiments on Semeval 2014 aspect based sentiment analysis data obtained from
http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools. Re-
sults are shown in Table 7. We cannot perform a comparative evaluation of such experimental results as
there is no state-of-art approach yet which used this dataset for the same kind of experiment. Overall,
results show high accuracy.
</bodyText>
<tableCaption confidence="0.9947">
Table 7: Results on the Semeval 2014 dataset
</tableCaption>
<table confidence="0.557995">
Domain Precision Recall
Laptop 82.15% 84.32%
Restaurants 85.21% 88.15%
</table>
<page confidence="0.997804">
35
</page>
<sectionHeader confidence="0.989845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999674869565217">
Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDonald, Tyler Neylon, George A. Reis, and Jeff Reynar. 2008.
Building a sentiment summarizer for local service reviews. In Proceedings of WWW-2008 workshop on NLP in
the Information Explosion Era, page 14.
Erik Cambria, Thomas Mazzocco, Amir Hussain, and Chris Eckl. 2011. Sentic medoids: Organizing affective
common sense knowledge in a multi-dimensional vector space. In D Liu, H Zhang, M Polycarpou, C Alippi,
and H He, editors, Advances in Neural Networks, volume 6677 of Lecture Notes in Computer Science, pages
601–610, Berlin. Springer-Verlag.
Erik Cambria, Paolo Gastaldo, Federica Bisio, and Rodolfo Zunino. 2014a. An ELM-based model for affective
analogical reasoning. Neurocomputing.
Erik Cambria, Daniel Olsher, and Dheeraj Rajagopal. 2014b. SenticNet 3: A common and common-sense knowl-
edge base for cognition-driven sentiment analysis. AAAI, pages 1515–1521.
Yejin Choi and Claire Cardie. 2010. Hierarchical sequential learning for extracting opinions and their attributes. In
Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL-2010), pages 268–274.
Ivan Cruz-Garcia, Alexander Gelbukh, and Grigori Sidorov. 2014. Implicit aspect indicator extraction for aspect-
based opinion mining. submitted.
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In
Proceedings of First ACM International Conference on Web Search and Data Mining (WSDM-2008), pages
231–240, Stanford University, Stanford, California, USA, Feb.
Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication).
The MIT Press.
Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the ACM
SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, pages 168–177, Aug.
Sheng Huang, Xinlan Liu, Xueping Peng, and Zhendong Niu. 2012. Fine-grained product features extraction and
categorization in reviews opinion mining. In Proceedings of the IEEE 12th International Conference on Data
Mining Workshops, pages 680–686.
Wei Jin and Hung Hay Ho. 2009. A novel lexicalized HMM-based learning framework for web opinion mining.
In Proceedings of International Conference on Machine Learning (ICML-2009), pages 465–472.
John Lafferty, Andrew McCallum, and Fernando C.N. Pereira. 2001. Conditional random fields: probabilistic
models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on
Machine Learning, pages 282–289. Morgan Kaufmann Publishers.
Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, and Hao Yu. 2010. Structure-aware
review mining and summarization. In Proceedings of the 23rd International Conference on Computational
Linguistics (COLING-2010), pages 653–661.
Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool Publishers.
Jakob Niklas and Iryna Gurevych. 2010. Extracting opinion targets in a single and cross-domain setting with con-
ditional random fields. In Proceedings of Conference on Empirical Methods in Natural Language Processing
(EMNLP-2010), pages 1035–1045.
Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceed-
ings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2005), pages 3–28.
Soujanya Poria, Erik Cambria, Gregoire Winterstein, and Guang-Bin Huang. 2014. Sentic patterns: Dependency-
based rules for concept-level sentiment analysis. Knowledge-Based Systems.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through
double propagation. Computational linguistics, 37(1):9–27.
Christopher Scaffidi, Kevin Bierhoff, Eric Chang, Mikhael Felker, Herman Ng, and Chun Jin. 2007. Red opal:
product-feature scoring from reviews. In Proceedings of the 8th ACM conference on Electronic commerce,
pages 182–191. ACM.
</reference>
<page confidence="0.974986">
36
</page>
<reference confidence="0.999496785714286">
Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su. 2008. Hidden
sentiment association in chinese web opinion mining. In Proceedings of International Conference on World
Wide Web (WWW-2008), pages 959–968.
Rui Xia, Chengqing Zong, Xuelei Hu, and Erik Cambria. 2013. Feature ensemble plus sample selection: A
comprehensive approach to domain adaptation for sentiment classification. IEEE Intelligent Systems, 28(3):10–
18.
Lingwei Zeng and Fang Li. 2013. A classification-based approach for implicit feature identification. In Chinese
Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 12th
China National Conference, CCL 2013 and First International Symposium, NLP-NABD 2013, Suzhou, China,
October 10–12, 2013, Proceedings, volume 8202 of Lecture Notes in Computer Science, pages 190–202.
Hai Zhen, Kuiyu Chang, and Jung-jae Kim. 2011. Implicit feature identification via co-occurrence association rule
mining. In Computational Linguistics and Intelligent Text Processing. 12th International Conference, CICLing
2011, Tokyo, Japan, February 20–26, 2011. Proceedings, Part I, volume 6608 of Lecture Notes in Computer
Science, pages 393–404.
</reference>
<page confidence="0.999608">
37
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.378206">
<title confidence="0.99985">A Rule-Based Approach to Aspect Extraction from Product Reviews</title>
<author confidence="0.995178">Soujanya Poria Erik Cambria</author>
<affiliation confidence="0.999912">Dept of Computing Science &amp; Maths School of Computer Engineering University of Stirling Nanyang Technological University</affiliation>
<email confidence="0.6142">soujanya.poria@cs.stir.ac.ukcambria@ntu.edu.sg</email>
<author confidence="0.995203">Lun-Wei Ku Chen Gui Alexander Gelbukh</author>
<affiliation confidence="0.98585">Institute of Information Science SenticNet Center for Computing Research Sinica Polytechnic Institute</affiliation>
<email confidence="0.642226">lwku@iis.sinica.edu.twgelbukh@cic.ipn.mx</email>
<abstract confidence="0.998682555555555">Sentiment analysis is a rapidly growing research field that has attracted both academia and industry because of the challenging research problems it poses and the potential benefits it can provide in many real life applications. Aspect-based opinion mining, in particular, is one of the fundamental challenges within this research field. In this work, we aim to solve the problem of aspect extraction from product reviews by proposing a novel rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both explicit and implicit aspects. Two popular review datasets were used for evaluating the system against state-of-the-art aspect extraction techniques, obtaining higher detection accuracy for both datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
<author>Tyler Neylon</author>
<author>George A Reis</author>
<author>Jeff Reynar</author>
</authors>
<title>Building a sentiment summarizer for local service reviews.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era,</booktitle>
<pages>14</pages>
<contexts>
<context position="8537" citStr="Blair-Goldensohn et al., 2008" startWordPosition="1320" endWordPosition="1323"> discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes the paper. 2 Related Work Aspect extraction from opinionated text was first studied by Hu and Liu (Hu and Liu, 2004), who also introduced the distinction between explicit and implicit aspects. However, the authors only dealt with explicit aspects by adopting a set of rules based on statistical observations. Hu and Liu’s method was improved by Popescu and Etzioni (Popescu and Etzioni, 2005) and by Blair-Goldensonh (Blair-Goldensohn et al., 2008). Popescu and Etzioni assumed the product class to be known as priori. Their algorithm detects whether a noun or noun phrase is a product feature or not by computing PMI between the noun phrase and the product class. Scaffidi et al. (Scaffidi et al., 2007) presented a method that uses a language model to identify product features. They assumed that product features are more frequent in product reviews than in general natural language text. However, their method seems to be very inaccurate in terms of precision as the retrieved aspects extracted by their method were very noisy. Aspect extractio</context>
</contexts>
<marker>Blair-Goldensohn, Hannan, McDonald, Neylon, Reis, Reynar, 2008</marker>
<rawString>Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDonald, Tyler Neylon, George A. Reis, and Jeff Reynar. 2008. Building a sentiment summarizer for local service reviews. In Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era, page 14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Cambria</author>
<author>Thomas Mazzocco</author>
<author>Amir Hussain</author>
<author>Chris Eckl</author>
</authors>
<title>Sentic medoids: Organizing affective common sense knowledge in a multi-dimensional vector space. In</title>
<date>2011</date>
<booktitle>Advances in Neural Networks,</booktitle>
<volume>6677</volume>
<pages>601--610</pages>
<editor>D Liu, H Zhang, M Polycarpou, C Alippi, and H He, editors,</editor>
<publisher>Springer-Verlag.</publisher>
<location>Berlin.</location>
<contexts>
<context position="7491" citStr="Cambria et al., 2011" startWordPosition="1158" endWordPosition="1161">icating fact that by commonsense are good or bad, which indirectly implies polarity. For example, the objective fact “The camera can hold lots of pictures” does not contain any sentiment or polarity word yet gives a positive opinion about the camera’s memory capacity (IAC “hold”), because it is desirable for a camera to hold many pictures. 29 In this paper, we present a rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both implicit and explicit aspects. In particular, the approach draws lessons from recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a) and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependency structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity associated with them. The paper is organized as follows: Section 2 presents the literature in aspect extraction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes th</context>
</contexts>
<marker>Cambria, Mazzocco, Hussain, Eckl, 2011</marker>
<rawString>Erik Cambria, Thomas Mazzocco, Amir Hussain, and Chris Eckl. 2011. Sentic medoids: Organizing affective common sense knowledge in a multi-dimensional vector space. In D Liu, H Zhang, M Polycarpou, C Alippi, and H He, editors, Advances in Neural Networks, volume 6677 of Lecture Notes in Computer Science, pages 601–610, Berlin. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Cambria</author>
<author>Paolo Gastaldo</author>
<author>Federica Bisio</author>
<author>Rodolfo Zunino</author>
</authors>
<title>An ELM-based model for affective analogical reasoning.</title>
<date>2014</date>
<journal>Neurocomputing.</journal>
<contexts>
<context position="7513" citStr="Cambria et al., 2014" startWordPosition="1162" endWordPosition="1165">ommonsense are good or bad, which indirectly implies polarity. For example, the objective fact “The camera can hold lots of pictures” does not contain any sentiment or polarity word yet gives a positive opinion about the camera’s memory capacity (IAC “hold”), because it is desirable for a camera to hold many pictures. 29 In this paper, we present a rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both implicit and explicit aspects. In particular, the approach draws lessons from recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a) and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependency structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity associated with them. The paper is organized as follows: Section 2 presents the literature in aspect extraction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes the paper. 2 Related Wor</context>
<context position="13330" citStr="Cambria et al., 2014" startWordPosition="2077" endWordPosition="2080"> them, along with their corresponding labeled categories. For example, in “The car is expensive” the IAC is expensive and it is labeled by the category price. Below is the list of the aspect categories extracted from the corpus: • functionality • weight • price • appearance • behavior • performance • quality • service • size For each IAC under every aspect category, synonyms and antonyms were obtained from WordNet (Fellbaum, 1998) and stored under the same aspect category. For example, expensive and its antonym inexpensive both have the same category price. Semantics extracted from SenticNet (Cambria et al., 2014b) have also been exploited to enlarge the set of conceptually related IACs. Thus, a lexicon of 1,128 IACs categorized into the above categories was built. 3.3.2 Opinion Lexicon We use SenticNet 3 as a concept-level opinion lexicon. The common-sense knowledge base contains 30,000 multi-word expressions labeled by their polarity scores. The proposed aspect parser is based on two general rules: • Rules for the sentences having subject verb. • Rules for the sentences which do not have subject verb. 3http://nlp.stanford.edu:8080/parser 31 A dependency relation is a binary relation characterized by</context>
</contexts>
<marker>Cambria, Gastaldo, Bisio, Zunino, 2014</marker>
<rawString>Erik Cambria, Paolo Gastaldo, Federica Bisio, and Rodolfo Zunino. 2014a. An ELM-based model for affective analogical reasoning. Neurocomputing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Cambria</author>
<author>Daniel Olsher</author>
<author>Dheeraj Rajagopal</author>
</authors>
<title>SenticNet 3: A common and common-sense knowledge base for cognition-driven sentiment analysis.</title>
<date>2014</date>
<pages>1515--1521</pages>
<publisher>AAAI,</publisher>
<contexts>
<context position="7513" citStr="Cambria et al., 2014" startWordPosition="1162" endWordPosition="1165">ommonsense are good or bad, which indirectly implies polarity. For example, the objective fact “The camera can hold lots of pictures” does not contain any sentiment or polarity word yet gives a positive opinion about the camera’s memory capacity (IAC “hold”), because it is desirable for a camera to hold many pictures. 29 In this paper, we present a rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both implicit and explicit aspects. In particular, the approach draws lessons from recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a) and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependency structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity associated with them. The paper is organized as follows: Section 2 presents the literature in aspect extraction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes the paper. 2 Related Wor</context>
<context position="13330" citStr="Cambria et al., 2014" startWordPosition="2077" endWordPosition="2080"> them, along with their corresponding labeled categories. For example, in “The car is expensive” the IAC is expensive and it is labeled by the category price. Below is the list of the aspect categories extracted from the corpus: • functionality • weight • price • appearance • behavior • performance • quality • service • size For each IAC under every aspect category, synonyms and antonyms were obtained from WordNet (Fellbaum, 1998) and stored under the same aspect category. For example, expensive and its antonym inexpensive both have the same category price. Semantics extracted from SenticNet (Cambria et al., 2014b) have also been exploited to enlarge the set of conceptually related IACs. Thus, a lexicon of 1,128 IACs categorized into the above categories was built. 3.3.2 Opinion Lexicon We use SenticNet 3 as a concept-level opinion lexicon. The common-sense knowledge base contains 30,000 multi-word expressions labeled by their polarity scores. The proposed aspect parser is based on two general rules: • Rules for the sentences having subject verb. • Rules for the sentences which do not have subject verb. 3http://nlp.stanford.edu:8080/parser 31 A dependency relation is a binary relation characterized by</context>
</contexts>
<marker>Cambria, Olsher, Rajagopal, 2014</marker>
<rawString>Erik Cambria, Daniel Olsher, and Dheeraj Rajagopal. 2014b. SenticNet 3: A common and common-sense knowledge base for cognition-driven sentiment analysis. AAAI, pages 1515–1521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Hierarchical sequential learning for extracting opinions and their attributes.</title>
<date>2010</date>
<booktitle>In Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL-2010),</booktitle>
<pages>268--274</pages>
<contexts>
<context position="9740" citStr="Choi and Cardie, 2010" startWordPosition="1519" endWordPosition="1522">y. Aspect extraction can be seen as a general information extraction problem, for which techniques based on sequential labeling are generally used. The most popular methods in this context, in particular, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity classification. However, their system is not described in detail and is not publicly available. To the best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IA</context>
</contexts>
<marker>Choi, Cardie, 2010</marker>
<rawString>Yejin Choi and Claire Cardie. 2010. Hierarchical sequential learning for extracting opinions and their attributes. In Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL-2010), pages 268–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Cruz-Garcia</author>
<author>Alexander Gelbukh</author>
<author>Grigori Sidorov</author>
</authors>
<title>Implicit aspect indicator extraction for aspectbased opinion mining.</title>
<date>2014</date>
<note>submitted.</note>
<contexts>
<context position="11304" citStr="Cruz-Garcia et al., 2014" startWordPosition="1774" endWordPosition="1777">licit aspects (which were also assumed to be sentiment words) with explicit aspects. Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extract explicit aspects and mapped implicit features by using a set of sentiment words and by clustering explicit feature-word pairs. 3 Method 3.1 Corpus for aspect extraction In order to evaluate the explicit aspect extraction algorithm, we use the corpus provided by (Hu and Liu, 2004) and the Semeval 2014 dataset1 (Table 1). As for the implicit aspect extraction algorithm and lexicon, we use the corpus developed by Cruz-Garcia et al. (Cruz-Garcia et al., 2014), who manually labeled each IAC and their corresponding aspects in a well-known corpus for opinion mining (Hu and Liu, 2004). The corpus is publicly available for research purposes.2 1http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools 2Available from www.gelbukh.com/resources/implicit-aspect-extraction-corpus, visited on March 19, 2014. 30 Table 1: Description of Semeval 2014 dataset Sentences Containing n aspect terms Domain Name n = 0 n &gt; 1 n &gt; 2 total(n &gt; 0) Restaurants 1,732 2,212 881 3,944 Laptops 1,883 2,065 456 3,948 3.2 Pre-Processing Pre-processing is a key step for asp</context>
</contexts>
<marker>Cruz-Garcia, Gelbukh, Sidorov, 2014</marker>
<rawString>Ivan Cruz-Garcia, Alexander Gelbukh, and Grigori Sidorov. 2014. Implicit aspect indicator extraction for aspectbased opinion mining. submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of First ACM International Conference on Web Search and Data Mining (WSDM-2008),</booktitle>
<pages>231--240</pages>
<institution>Stanford University,</institution>
<location>Stanford, California, USA,</location>
<contexts>
<context position="1450" citStr="Ding et al., 2008" startWordPosition="193" endWordPosition="196">work, we aim to solve the problem of aspect extraction from product reviews by proposing a novel rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both explicit and implicit aspects. Two popular review datasets were used for evaluating the system against state-of-the-art aspect extraction techniques, obtaining higher detection accuracy for both datasets. 1 Introduction In opinion mining, different levels of granularity analysis have been proposed, each one having its own advantages and disadvantages. Aspect-based opinion mining (Hu and Liu, 2004; Ding et al., 2008) focuses on the extraction of aspects (or product features) from opinionated text and on the inference of polarity values associated with these. For example, a sentence like “I love the touchscreen of my phone but the battery life is so short” contains two aspects or opinion targets, namely touchscreen and battery life. In this case, applying a sentence level polarity detection technique would mistakenly result in a polarity value close to neutral, since the two opinions expressed by the users are opposite. Hence, aspect extraction is necessary to first deconstruct sentences into product featu</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In Proceedings of First ACM International Conference on Web Search and Data Mining (WSDM-2008), pages 231–240, Stanford University, Stanford, California, USA, Feb.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database (Language, Speech, and Communication).</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="13144" citStr="Fellbaum, 1998" startWordPosition="2049" endWordPosition="2051">ACs are indicated and manually labeled by their corresponding aspect categories. For our task, we extracted the sentences having implicit aspects and then extracted IACs for each of them, along with their corresponding labeled categories. For example, in “The car is expensive” the IAC is expensive and it is labeled by the category price. Below is the list of the aspect categories extracted from the corpus: • functionality • weight • price • appearance • behavior • performance • quality • service • size For each IAC under every aspect category, synonyms and antonyms were obtained from WordNet (Fellbaum, 1998) and stored under the same aspect category. For example, expensive and its antonym inexpensive both have the same category price. Semantics extracted from SenticNet (Cambria et al., 2014b) have also been exploited to enlarge the set of conceptually related IACs. Thus, a lexicon of 1,128 IACs categorized into the above categories was built. 3.3.2 Opinion Lexicon We use SenticNet 3 as a concept-level opinion lexicon. The common-sense knowledge base contains 30,000 multi-word expressions labeled by their polarity scores. The proposed aspect parser is based on two general rules: • Rules for the se</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="1430" citStr="Hu and Liu, 2004" startWordPosition="189" endWordPosition="192">ch field. In this work, we aim to solve the problem of aspect extraction from product reviews by proposing a novel rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both explicit and implicit aspects. Two popular review datasets were used for evaluating the system against state-of-the-art aspect extraction techniques, obtaining higher detection accuracy for both datasets. 1 Introduction In opinion mining, different levels of granularity analysis have been proposed, each one having its own advantages and disadvantages. Aspect-based opinion mining (Hu and Liu, 2004; Ding et al., 2008) focuses on the extraction of aspects (or product features) from opinionated text and on the inference of polarity values associated with these. For example, a sentence like “I love the touchscreen of my phone but the battery life is so short” contains two aspects or opinion targets, namely touchscreen and battery life. In this case, applying a sentence level polarity detection technique would mistakenly result in a polarity value close to neutral, since the two opinions expressed by the users are opposite. Hence, aspect extraction is necessary to first deconstruct sentence</context>
<context position="3106" citStr="Hu and Liu, 2004" startWordPosition="449" endWordPosition="452">ssed indirectly through an implicit aspect clue (IAC), e.g., in the sentence “This camera is sleek and very affordable”, which implicitly provides a positive opinion about the aspects appearance and price of the entity camera. Explicit aspect extraction has been widely researched and there exists several approaches for this task. Still, limited work has been done in extracting implicit aspects. This task is very difficult yet very important because the phenomenon of implicit aspects is present in nearly every opinionated document. For example, the following document extracted from the corpus (Hu and Liu, 2004) uses only implicit aspects: This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0 28 Proceedings of the Second Workshop on Natural Language Processing for Social Media (SocialNLP), pages 28–37, Dublin, Ireland, August 24 2014. This is the best phone one could have. It has all the features one would need in a cellphone: It is lightweight, sleek and attractive. I found it very user-friendly and easy to manipulate; very convenient to scroll </context>
<context position="8205" citStr="Hu and Liu, 2004" startWordPosition="1270" endWordPosition="1273">14) to first obtain the dependency structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity associated with them. The paper is organized as follows: Section 2 presents the literature in aspect extraction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes the paper. 2 Related Work Aspect extraction from opinionated text was first studied by Hu and Liu (Hu and Liu, 2004), who also introduced the distinction between explicit and implicit aspects. However, the authors only dealt with explicit aspects by adopting a set of rules based on statistical observations. Hu and Liu’s method was improved by Popescu and Etzioni (Popescu and Etzioni, 2005) and by Blair-Goldensonh (Blair-Goldensohn et al., 2008). Popescu and Etzioni assumed the product class to be known as priori. Their algorithm detects whether a noun or noun phrase is a product feature or not by computing PMI between the noun phrase and the product class. Scaffidi et al. (Scaffidi et al., 2007) presented a</context>
<context position="11125" citStr="Hu and Liu, 2004" startWordPosition="1745" endWordPosition="1748">ect and a sentiment word forming a cooccurring pair in a sentence. Hai (Zhen et al., 2011) proposed a two-phase co-occurrence association rule mining approach to match implicit aspects (which were also assumed to be sentiment words) with explicit aspects. Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extract explicit aspects and mapped implicit features by using a set of sentiment words and by clustering explicit feature-word pairs. 3 Method 3.1 Corpus for aspect extraction In order to evaluate the explicit aspect extraction algorithm, we use the corpus provided by (Hu and Liu, 2004) and the Semeval 2014 dataset1 (Table 1). As for the implicit aspect extraction algorithm and lexicon, we use the corpus developed by Cruz-Garcia et al. (Cruz-Garcia et al., 2014), who manually labeled each IAC and their corresponding aspects in a well-known corpus for opinion mining (Hu and Liu, 2004). The corpus is publicly available for research purposes.2 1http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools 2Available from www.gelbukh.com/resources/implicit-aspect-extraction-corpus, visited on March 19, 2014. 30 Table 1: Description of Semeval 2014 dataset Sentences Containin</context>
<context position="21425" citStr="Hu and Liu, 2004" startWordPosition="3535" endWordPosition="3538">oun phrases. In (13), the IAC deal is extracted. (13) Even if I had paid full price I would have considered this phone a good deal. In (14), sleekness is extracted as an IAC. (14) Not to mention the sleekness of this phone. In (15), the IAC errors is extracted by the algorithm. (15) The player keeps giving random errors. In (16), piece of crap is a noun phrase and is extracted as an IAC by the proposed algorithm. (16) This phone is apiece of crap. A demo of the developed aspect parser is freely available at http://sentic.net/demo. Table 2: Results on the DVD-player review dataset provided by (Hu and Liu, 2004) Algorithm Precision Recall Hu and Liu 75.00% 82.00% Popescu and Etzioni 89.00% 80.00% Dependency propagation method 87.00% 81.00% Proposed approach 89.25% 91.25% Table 3: Results on the Canon G3 review dataset provided by (Hu and Liu, 2004) Algorithm Precision Recall Hu and Liu 71.00% 79.00% Popescu and Etzioni 87.00% 74.00% Dependency propagation method 90.00% 81.00% Proposed approach 90.15% 92.25% Table 4: Results on the Jukebox review dataset provided by (Hu and Liu, 2004) Algorithm Precision Recall Hu and Liu 72.00% 76.00% Popescu and Etzioni 89.00% 74.00% Dependency propagation method 90</context>
<context position="22647" citStr="Hu and Liu, 2004" startWordPosition="3719" endWordPosition="3722">86.00% Proposed approach 92.25% 94.15% 34 Table 5: Results on the Nikon Coolpix review dataset provided by (Hu and Liu, 2004) Algorithm Precision Recall Hu and Liu 69.00% 82.00% Popescu and Etzioni 86.00% 80.00% Dependency propagation method 81.00% 84.00% Proposed approach 82.15% 86.15% Table 6: Results on the Nokia-6610 review dataset provided by (Hu and Liu, 2004) Algorithm Precision Recall Hu and Liu 74.00% 80.00% Popescu and Etzioni 90.00% 78.00% Dependency propagation method 92.00% 86.00% Proposed approach 93.25% 93.32% 5 Experiments and Results 5.1 Experiment on the dataset provided by (Hu and Liu, 2004) Experimental evaluation was carried out on the dataset derived from (Hu and Liu, 2004). As discussed in Section 3, the proposed method is able to extract both explicit and implicit aspects. To the best of our knowledge, there is no state-of-the-art benchmark to evaluate implicit aspect extraction. We compare the proposed framework with those in Hu and Liu (Hu and Liu, 2004), Qiu et al. (Qiu et al., 2011), and Popescu and Etzioni (Popescu and Etzioni, 2005) (which only carried out explicit aspect extraction). Table 2, Table 3, Table 4, Table 5 and Table 6 show that the proposed framework outpe</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, pages 168–177, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheng Huang</author>
<author>Xinlan Liu</author>
<author>Xueping Peng</author>
<author>Zhendong Niu</author>
</authors>
<title>Fine-grained product features extraction and categorization in reviews opinion mining.</title>
<date>2012</date>
<booktitle>In Proceedings of the IEEE 12th International Conference on Data Mining Workshops,</booktitle>
<pages>680--686</pages>
<contexts>
<context position="9778" citStr="Huang et al., 2012" startWordPosition="1527" endWordPosition="1530">eral information extraction problem, for which techniques based on sequential labeling are generally used. The most popular methods in this context, in particular, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity classification. However, their system is not described in detail and is not publicly available. To the best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IACs (which were assumed to be sentiment</context>
</contexts>
<marker>Huang, Liu, Peng, Niu, 2012</marker>
<rawString>Sheng Huang, Xinlan Liu, Xueping Peng, and Zhendong Niu. 2012. Fine-grained product features extraction and categorization in reviews opinion mining. In Proceedings of the IEEE 12th International Conference on Data Mining Workshops, pages 680–686.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
</authors>
<title>A novel lexicalized HMM-based learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of International Conference on Machine Learning (ICML-2009),</booktitle>
<pages>465--472</pages>
<contexts>
<context position="9444" citStr="Jin and Ho, 2009" startWordPosition="1469" endWordPosition="1472">nguage model to identify product features. They assumed that product features are more frequent in product reviews than in general natural language text. However, their method seems to be very inaccurate in terms of precision as the retrieved aspects extracted by their method were very noisy. Aspect extraction can be seen as a general information extraction problem, for which techniques based on sequential labeling are generally used. The most popular methods in this context, in particular, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity classif</context>
</contexts>
<marker>Jin, Ho, 2009</marker>
<rawString>Wei Jin and Hung Hay Ho. 2009. A novel lexicalized HMM-based learning framework for web opinion mining. In Proceedings of International Conference on Machine Learning (ICML-2009), pages 465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers.</publisher>
<contexts>
<context position="9413" citStr="Lafferty et al., 2001" startWordPosition="1462" endWordPosition="1465">7) presented a method that uses a language model to identify product features. They assumed that product features are more frequent in product reviews than in general natural language text. However, their method seems to be very inaccurate in terms of precision as the retrieved aspects extracted by their method were very noisy. Aspect extraction can be seen as a general information extraction problem, for which techniques based on sequential labeling are generally used. The most popular methods in this context, in particular, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspe</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando C.N. Pereira. 2001. Conditional random fields: probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning, pages 282–289. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Chao Han</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
<author>Ying-Ju Xia</author>
<author>Shu Zhang</author>
<author>Hao Yu</author>
</authors>
<title>Structure-aware review mining and summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING-2010),</booktitle>
<pages>653--661</pages>
<contexts>
<context position="9699" citStr="Li et al., 2010" startWordPosition="1512" endWordPosition="1515">cted by their method were very noisy. Aspect extraction can be seen as a general information extraction problem, for which techniques based on sequential labeling are generally used. The most popular methods in this context, in particular, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity classification. However, their system is not described in detail and is not publicly available. To the best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one or another way, of what we term IAC. Su (Su et al., 200</context>
</contexts>
<marker>Li, Han, Huang, Zhu, Xia, Zhang, Yu, 2010</marker>
<rawString>Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, and Hao Yu. 2010. Structure-aware review mining and summarization. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING-2010), pages 653–661.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="20504" citStr="Liu, 2012" startWordPosition="3377" endWordPosition="3378">ll dark meat and on the bone. 33 4 Novelty of the proposed work First of all, the proposed method is fully unsupervised and depends on the accuracy of the dependency parser and the opinion lexicon, rather then a training corpus and supervised learning accuracy. Only (Qiu et al., 2011) follow an unsupervised learning approach but the proposed method uses an enhanced set of rules and opinion lexicon. The proposed method also outperforms (Qiu et al., 2011) on the same dataset they used. Implicit aspects extracted through the proposed method differ from implicit aspect expressions defined by Liu (Liu, 2012) as “aspect expressions that are not nouns or noun phrases” in that implicit aspects extracted by the proposed algorithm semantically refer to the values of the pre-defined aspects, irrespective of their own surface POS. Below are listed some examples where the implicit aspect terms are either noun or noun phrases. In (13), the IAC deal is extracted. (13) Even if I had paid full price I would have considered this phone a good deal. In (14), sleekness is extracted as an IAC. (14) Not to mention the sleekness of this phone. In (15), the IAC errors is extracted by the algorithm. (15) The player k</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Niklas</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2010),</booktitle>
<pages>1035--1045</pages>
<contexts>
<context position="9583" citStr="Niklas and Gurevych, 2010" startWordPosition="1490" endWordPosition="1493"> natural language text. However, their method seems to be very inaccurate in terms of precision as the retrieved aspects extracted by their method were very noisy. Aspect extraction can be seen as a general information extraction problem, for which techniques based on sequential labeling are generally used. The most popular methods in this context, in particular, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity classification. However, their system is not described in detail and is not publicly available. To the best of our knowledge, all existing methods</context>
</contexts>
<marker>Niklas, Gurevych, 2010</marker>
<rawString>Jakob Niklas and Iryna Gurevych. 2010. Extracting opinion targets in a single and cross-domain setting with conditional random fields. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2010), pages 1035–1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2005),</booktitle>
<pages>3--28</pages>
<contexts>
<context position="8481" citStr="Popescu and Etzioni, 2005" startWordPosition="1313" endWordPosition="1316">xplains the features used for the labeler; Section 4 discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes the paper. 2 Related Work Aspect extraction from opinionated text was first studied by Hu and Liu (Hu and Liu, 2004), who also introduced the distinction between explicit and implicit aspects. However, the authors only dealt with explicit aspects by adopting a set of rules based on statistical observations. Hu and Liu’s method was improved by Popescu and Etzioni (Popescu and Etzioni, 2005) and by Blair-Goldensonh (Blair-Goldensohn et al., 2008). Popescu and Etzioni assumed the product class to be known as priori. Their algorithm detects whether a noun or noun phrase is a product feature or not by computing PMI between the noun phrase and the product class. Scaffidi et al. (Scaffidi et al., 2007) presented a method that uses a language model to identify product features. They assumed that product features are more frequent in product reviews than in general natural language text. However, their method seems to be very inaccurate in terms of precision as the retrieved aspects ext</context>
<context position="9945" citStr="Popescu and Etzioni, 2005" startWordPosition="1553" endWordPosition="1556">ar, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity classification. However, their system is not described in detail and is not publicly available. To the best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IACs (which were assumed to be sentiment words) to their corresponding explicit aspects. The method exploits the mutual reinforcement relationship between an explicit aspect and a sentiment word forming a co</context>
<context position="23108" citStr="Popescu and Etzioni, 2005" startWordPosition="3796" endWordPosition="3799">0% Dependency propagation method 92.00% 86.00% Proposed approach 93.25% 93.32% 5 Experiments and Results 5.1 Experiment on the dataset provided by (Hu and Liu, 2004) Experimental evaluation was carried out on the dataset derived from (Hu and Liu, 2004). As discussed in Section 3, the proposed method is able to extract both explicit and implicit aspects. To the best of our knowledge, there is no state-of-the-art benchmark to evaluate implicit aspect extraction. We compare the proposed framework with those in Hu and Liu (Hu and Liu, 2004), Qiu et al. (Qiu et al., 2011), and Popescu and Etzioni (Popescu and Etzioni, 2005) (which only carried out explicit aspect extraction). Table 2, Table 3, Table 4, Table 5 and Table 6 show that the proposed framework outperforms all existing methods in terms of both precision and recall. 6 Conclusion We have illustrated a method for extracting both explicit and implicit aspects from opinionated text. The proposed framework only leverages on common-sense knowledge and on the dependency structure of sentences and, hence, is unsupervised. As future work, we aim to discover more rules for aspect extraction. Another key future effort is to combine existing rules for complex aspec</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2005), pages 3–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soujanya Poria</author>
<author>Erik Cambria</author>
<author>Gregoire Winterstein</author>
<author>Guang-Bin Huang</author>
</authors>
<title>Sentic patterns: Dependencybased rules for concept-level sentiment analysis. Knowledge-Based Systems.</title>
<date>2014</date>
<contexts>
<context position="7591" citStr="Poria et al., 2014" startWordPosition="1174" endWordPosition="1177"> objective fact “The camera can hold lots of pictures” does not contain any sentiment or polarity word yet gives a positive opinion about the camera’s memory capacity (IAC “hold”), because it is desirable for a camera to hold many pictures. 29 In this paper, we present a rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both implicit and explicit aspects. In particular, the approach draws lessons from recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a) and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependency structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity associated with them. The paper is organized as follows: Section 2 presents the literature in aspect extraction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes the paper. 2 Related Work Aspect extraction from opinionated text was first studied by Hu and Liu (Hu </context>
</contexts>
<marker>Poria, Cambria, Winterstein, Huang, 2014</marker>
<rawString>Soujanya Poria, Erik Cambria, Gregoire Winterstein, and Guang-Bin Huang. 2014. Sentic patterns: Dependencybased rules for concept-level sentiment analysis. Knowledge-Based Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation.</title>
<date>2011</date>
<journal>Computational linguistics,</journal>
<pages>37--1</pages>
<contexts>
<context position="20179" citStr="Qiu et al., 2011" startWordPosition="3325" endWordPosition="3328"> aspect and t has noun compound modifier h, then the aspect h-t is extracted and t is removed from the aspect list. In (12), as chicken and casserole are in noun compound modifier relation, only chicken casserole is extracted as an aspect. (12) We ordered the chicken casserole, but what we got were a few small pieces of chicken, all dark meat and on the bone. 33 4 Novelty of the proposed work First of all, the proposed method is fully unsupervised and depends on the accuracy of the dependency parser and the opinion lexicon, rather then a training corpus and supervised learning accuracy. Only (Qiu et al., 2011) follow an unsupervised learning approach but the proposed method uses an enhanced set of rules and opinion lexicon. The proposed method also outperforms (Qiu et al., 2011) on the same dataset they used. Implicit aspects extracted through the proposed method differ from implicit aspect expressions defined by Liu (Liu, 2012) as “aspect expressions that are not nouns or noun phrases” in that implicit aspects extracted by the proposed algorithm semantically refer to the values of the pre-defined aspects, irrespective of their own surface POS. Below are listed some examples where the implicit aspe</context>
<context position="23055" citStr="Qiu et al., 2011" startWordPosition="3788" endWordPosition="3791">4.00% 80.00% Popescu and Etzioni 90.00% 78.00% Dependency propagation method 92.00% 86.00% Proposed approach 93.25% 93.32% 5 Experiments and Results 5.1 Experiment on the dataset provided by (Hu and Liu, 2004) Experimental evaluation was carried out on the dataset derived from (Hu and Liu, 2004). As discussed in Section 3, the proposed method is able to extract both explicit and implicit aspects. To the best of our knowledge, there is no state-of-the-art benchmark to evaluate implicit aspect extraction. We compare the proposed framework with those in Hu and Liu (Hu and Liu, 2004), Qiu et al. (Qiu et al., 2011), and Popescu and Etzioni (Popescu and Etzioni, 2005) (which only carried out explicit aspect extraction). Table 2, Table 3, Table 4, Table 5 and Table 6 show that the proposed framework outperforms all existing methods in terms of both precision and recall. 6 Conclusion We have illustrated a method for extracting both explicit and implicit aspects from opinionated text. The proposed framework only leverages on common-sense knowledge and on the dependency structure of sentences and, hence, is unsupervised. As future work, we aim to discover more rules for aspect extraction. Another key future </context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational linguistics, 37(1):9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Scaffidi</author>
<author>Kevin Bierhoff</author>
<author>Eric Chang</author>
<author>Mikhael Felker</author>
<author>Herman Ng</author>
<author>Chun Jin</author>
</authors>
<title>Red opal: product-feature scoring from reviews.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th ACM conference on Electronic commerce,</booktitle>
<pages>182--191</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="8793" citStr="Scaffidi et al., 2007" startWordPosition="1365" endWordPosition="1368">d by Hu and Liu (Hu and Liu, 2004), who also introduced the distinction between explicit and implicit aspects. However, the authors only dealt with explicit aspects by adopting a set of rules based on statistical observations. Hu and Liu’s method was improved by Popescu and Etzioni (Popescu and Etzioni, 2005) and by Blair-Goldensonh (Blair-Goldensohn et al., 2008). Popescu and Etzioni assumed the product class to be known as priori. Their algorithm detects whether a noun or noun phrase is a product feature or not by computing PMI between the noun phrase and the product class. Scaffidi et al. (Scaffidi et al., 2007) presented a method that uses a language model to identify product features. They assumed that product features are more frequent in product reviews than in general natural language text. However, their method seems to be very inaccurate in terms of precision as the retrieved aspects extracted by their method were very noisy. Aspect extraction can be seen as a general information extraction problem, for which techniques based on sequential labeling are generally used. The most popular methods in this context, in particular, are Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (La</context>
</contexts>
<marker>Scaffidi, Bierhoff, Chang, Felker, Ng, Jin, 2007</marker>
<rawString>Christopher Scaffidi, Kevin Bierhoff, Eric Chang, Mikhael Felker, Herman Ng, and Chun Jin. 2007. Red opal: product-feature scoring from reviews. In Proceedings of the 8th ACM conference on Electronic commerce, pages 182–191. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Su</author>
<author>Xinying Xu</author>
<author>Honglei Guo</author>
<author>Zhili Guo</author>
<author>Xian Wu</author>
<author>Xiaoxun Zhang</author>
<author>Bin Swen</author>
<author>Zhong Su</author>
</authors>
<title>Hidden sentiment association in chinese web opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of International Conference on World Wide Web (WWW-2008),</booktitle>
<pages>959--968</pages>
<contexts>
<context position="10301" citStr="Su et al., 2008" startWordPosition="1616" endWordPosition="1619"> et al., 2010), Choi and Cardie (Choi and Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects. As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity classification. However, their system is not described in detail and is not publicly available. To the best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IACs (which were assumed to be sentiment words) to their corresponding explicit aspects. The method exploits the mutual reinforcement relationship between an explicit aspect and a sentiment word forming a cooccurring pair in a sentence. Hai (Zhen et al., 2011) proposed a two-phase co-occurrence association rule mining approach to match implicit aspects (which were also assumed to be sentiment words) with explicit aspects. Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extract explicit aspects and mapped implicit features by using a</context>
</contexts>
<marker>Su, Xu, Guo, Guo, Wu, Zhang, Swen, Su, 2008</marker>
<rawString>Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su. 2008. Hidden sentiment association in chinese web opinion mining. In Proceedings of International Conference on World Wide Web (WWW-2008), pages 959–968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Xia</author>
<author>Chengqing Zong</author>
<author>Xuelei Hu</author>
<author>Erik Cambria</author>
</authors>
<title>Feature ensemble plus sample selection: A comprehensive approach to domain adaptation for sentiment classification.</title>
<date>2013</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>18</pages>
<contexts>
<context position="7570" citStr="Xia et al., 2013" startWordPosition="1170" endWordPosition="1173">. For example, the objective fact “The camera can hold lots of pictures” does not contain any sentiment or polarity word yet gives a positive opinion about the camera’s memory capacity (IAC “hold”), because it is desirable for a camera to hold many pictures. 29 In this paper, we present a rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both implicit and explicit aspects. In particular, the approach draws lessons from recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a) and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependency structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity associated with them. The paper is organized as follows: Section 2 presents the literature in aspect extraction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental evaluation; finally, Section 6 concludes the paper. 2 Related Work Aspect extraction from opinionated text was first studi</context>
</contexts>
<marker>Xia, Zong, Hu, Cambria, 2013</marker>
<rawString>Rui Xia, Chengqing Zong, Xuelei Hu, and Erik Cambria. 2013. Feature ensemble plus sample selection: A comprehensive approach to domain adaptation for sentiment classification. IEEE Intelligent Systems, 28(3):10– 18.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lingwei Zeng</author>
<author>Fang Li</author>
</authors>
<title>A classification-based approach for implicit feature identification.</title>
<date>2013</date>
<booktitle>In Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 12th China National Conference, CCL 2013 and First International Symposium, NLP-NABD 2013,</booktitle>
<volume>8202</volume>
<pages>190--202</pages>
<location>Suzhou, China,</location>
<contexts>
<context position="10804" citStr="Zeng and Li, 2013" startWordPosition="1694" endWordPosition="1697">r implicit aspect extraction are based on the use, in one or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IACs (which were assumed to be sentiment words) to their corresponding explicit aspects. The method exploits the mutual reinforcement relationship between an explicit aspect and a sentiment word forming a cooccurring pair in a sentence. Hai (Zhen et al., 2011) proposed a two-phase co-occurrence association rule mining approach to match implicit aspects (which were also assumed to be sentiment words) with explicit aspects. Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extract explicit aspects and mapped implicit features by using a set of sentiment words and by clustering explicit feature-word pairs. 3 Method 3.1 Corpus for aspect extraction In order to evaluate the explicit aspect extraction algorithm, we use the corpus provided by (Hu and Liu, 2004) and the Semeval 2014 dataset1 (Table 1). As for the implicit aspect extraction algorithm and lexicon, we use the corpus developed by Cruz-Garcia et al. (Cruz-Garcia et al., 2014), who manually labeled each IAC and their corresponding aspects in a well-known corpus for opinion m</context>
</contexts>
<marker>Zeng, Li, 2013</marker>
<rawString>Lingwei Zeng and Fang Li. 2013. A classification-based approach for implicit feature identification. In Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 12th China National Conference, CCL 2013 and First International Symposium, NLP-NABD 2013, Suzhou, China, October 10–12, 2013, Proceedings, volume 8202 of Lecture Notes in Computer Science, pages 190–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhen</author>
<author>Kuiyu Chang</author>
<author>Jung-jae Kim</author>
</authors>
<title>Implicit feature identification via co-occurrence association rule mining.</title>
<date>2011</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing. 12th International Conference, CICLing 2011,</booktitle>
<volume>6608</volume>
<pages>393--404</pages>
<location>Tokyo, Japan,</location>
<contexts>
<context position="10598" citStr="Zhen et al., 2011" startWordPosition="1663" endWordPosition="1666">e extraction of this type of aspects to improve polarity classification. However, their system is not described in detail and is not publicly available. To the best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IACs (which were assumed to be sentiment words) to their corresponding explicit aspects. The method exploits the mutual reinforcement relationship between an explicit aspect and a sentiment word forming a cooccurring pair in a sentence. Hai (Zhen et al., 2011) proposed a two-phase co-occurrence association rule mining approach to match implicit aspects (which were also assumed to be sentiment words) with explicit aspects. Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extract explicit aspects and mapped implicit features by using a set of sentiment words and by clustering explicit feature-word pairs. 3 Method 3.1 Corpus for aspect extraction In order to evaluate the explicit aspect extraction algorithm, we use the corpus provided by (Hu and Liu, 2004) and the Semeval 2014 dataset1 (Table 1). As for the implicit aspect extr</context>
</contexts>
<marker>Zhen, Chang, Kim, 2011</marker>
<rawString>Hai Zhen, Kuiyu Chang, and Jung-jae Kim. 2011. Implicit feature identification via co-occurrence association rule mining. In Computational Linguistics and Intelligent Text Processing. 12th International Conference, CICLing 2011, Tokyo, Japan, February 20–26, 2011. Proceedings, Part I, volume 6608 of Lecture Notes in Computer Science, pages 393–404.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>