<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.050109">
<title confidence="0.981296">
Assessing Violence Risk in Threatening Communications
</title>
<author confidence="0.989723">
Kimberly Glasgow
</author>
<affiliation confidence="0.9956608">
Johns Hopkins University
Applied Physics Laboratory,
and
College of Information Studies,
University of Maryland
</affiliation>
<email confidence="0.992745">
kimberly.glasgow@jhuapl.edu
</email>
<author confidence="0.967868">
Ronald Schouten
</author>
<affiliation confidence="0.8953765">
Harvard Medical School,
and
Department of Psychiatry,
Massachusetts General Hospital
</affiliation>
<email confidence="0.997409">
rschouten@mgh.harvard.edu
</email>
<sectionHeader confidence="0.998591" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999855583333333">
Violence risk assessment is an important
and challenging task undertaken by men-
tal health professionals and others, in both
clinical and nonclinical settings. To date,
computational linguistic techniques have
not been used in the risk assessment pro-
cess. However they could contribute to the
current threat assessment process by al-
lowing for early detection of elevated risk,
identification of risk factors for violence,
monitoring of violent intent, and determi-
nation of threat level. We analyzed a sam-
ple of communications to judges that were
referred to security personnel for evalua-
tion as constituting potential threats. We
categorized them along multiple dimen-
sions including evidence of mental illness,
presence and nature of any threat, and
level of threat. While neither word count-
based or topic models were able to effec-
tively predict elevated risk, we found top-
ics indicative of persecutory beliefs, para-
noid ideation, and other symptoms of Axis
I and Axis II disorders.
</bodyText>
<sectionHeader confidence="0.999628" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977148148148">
Mental health professionals are called upon to as-
sess the risk of violence in many different settings,
from the determination of the need for hospital-
ization or increased treatment to consultations for
the criminal justice system (Skeem and Monahan,
2011). These assessments include examination of
the verbal content of a subject’s communications,
primarily for the purpose of detecting symptoms
of thought disorder or evidence of impending vio-
lent behavior. Language technology is rarely uti-
lized in these efforts, yet it could be a valuable tool
for detecting evidence of illness and increased vi-
olence risk in verbal and written communications.
We analyzed a unique data set of threatening
communications sent to judges. Examination of
these written communications indicate that, for
this sample, explicit threats are rare, but evidence
of mental illness is common. We applied two types
of computational methods to the communications
in the sample—topic models, and a simple compu-
tational text analysis method: LIWC (Pennebaker
et al., 2001). The results point towards a useful
role for such methods in the analysis of threaten-
ing communications, as well as limitations. Ad-
vances in language technology methods, as well as
the availability of more data, may both be needed
to make substantial progress.
</bodyText>
<sectionHeader confidence="0.9186625" genericHeader="introduction">
2 Violence Risk Assessment and Mental
Health Professionals
</sectionHeader>
<bodyText confidence="0.999901545454545">
Assessment of the risk of violence is a task that
belongs to a diverse group of mental health profes-
sionals (MHPs): those who provide clinical care,
forensic MHPs specializing in mental health is-
sues related to the legal system, and those who en-
gage in the even more specialized field of threat
assessment. Other disciplines involved in threat
assessment include law enforcement, security pro-
fessionals, and intelligence analysts.
Violence risk assessment is a routine aspect of
the work of mental health professionals treating
</bodyText>
<page confidence="0.988162">
38
</page>
<bodyText confidence="0.928230769230769">
Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 38–45,
Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics
people with mental illness. While violence against
others on the part of people with diagnoses of
mental illness is far less prevalent than is popularly
thought, the increased risk attributable to these ill-
nesses is barely statistically significant (Steadman
et al., 1998; Swanson et al., 1990). This increased
risk is largely attributable to a small group of in-
dividuals who have a history of childhood or adult
antisocial behavior in combination with substance
use disorders and psychotic illness (Elbogen and
Johnson, 2009).
</bodyText>
<subsectionHeader confidence="0.984668">
2.1 Methods and Practice of Violence Risk
Assessment
</subsectionHeader>
<bodyText confidence="0.999971585714286">
Treating clinicians are responsible for evaluating
their patients to determine if they pose a risk of
violence and adjusting treatment accordingly, or
arranging for hospitalization, as needed. The risk
of violence, as evidenced by threats or attempts to
harm self or others, are two of the bases for hos-
pitalizing people with mental illness against their
will. This assessment primarily relies upon infor-
mation obtained through interviewing and observ-
ing the patient, as well as information from col-
lateral sources when it is available. The patient’s
language is taken into account largely as a part
of the mental status examination, in which atten-
tion is paid to the content and form of the patient’s
thoughts, which are characteristically disrupted in
certain illnesses. Clinicians look at many factors
to determine if someone poses a risk of violence,
but a patient’s written communications is typically
not one of them.
MHPs who practice in the field of forensic men-
tal health do so as an even larger component of
their work. Many are routinely asked to assess the
risk of violence in both the civil and criminal jus-
tice systems. In the civil justice system, for exam-
ple, they may be called upon as expert witnesses
in civil commitment proceedings or as consultants
on such matters. In the criminal justice system,
they may be asked to assess the risk of violence
in conjunction with the issuance of restraining or-
ders, determination of conditions of bail and pro-
bation, and sentencing. While judges make the ul-
timate decisions, they generally rely highly upon
the clinical judgment of MHPs with regard to di-
agnosis and assessment of the risk of violence.
In recent years, a number of tools have been in-
troduced to assist in the assessment of violence
risk, such at the HCR-20 (Webster et al., 1982),
COVR (Monahan et al., 2006), and VRAG (Quin-
sey et al., 1998). None of these instruments con-
sider linguistic factors. They utilize actuarial de-
terminations of violence risk. These instruments
do not provide strict cutoff scores that differen-
tiate between nonviolent and violent individuals.
Rather, they serve as adjunct tools to clinical judg-
ment. As a result, the current best practice in vio-
lence risk assessment consists of structured clini-
cal judgment, a process in which actuarial risk as-
sessments are combined with clinical judgment to
reach a determination regarding a specific individ-
ual’s risk.
Whereas treating clinicians primarily rely upon
examination of the patient in assessing the risk
of violence, forensic MHPs are expected to go
beyond the clinical examination and incorporate
information from a variety of collateral sources,
such as medical and mental health records, psy-
chological testing, legal documents, police re-
ports, and criminal histories in order to increase
the objectivity and “scientific” basis of their opin-
ion. As in clinical care, language is an important
part of the mental status examination. More de-
tailed review of the evaluee’s communications is
more common in forensic work, as it may provide
insight into the writer’s emotional state, motiva-
tion, and intention, as well as thought processes.
The content, syntax, and grammar of communica-
tions, as well as the page layout, variations in font
size, use of color, and graphics may all be consid-
ered in assessing for presence of a mental disorder
and indications of violence risk.
</bodyText>
<subsectionHeader confidence="0.998719">
2.2 Threat Assessment
</subsectionHeader>
<bodyText confidence="0.9999680625">
Threat assessment is a discipline that relates to, yet
is separate from, clinical violence risk assessment.
Meloy, et al. distinguish between the two fields,
noting that violence risk assessment is consulta-
tive in nature, and generally aimed at assisting le-
gal decision-making and managing a particular in-
dividual over the long term. They note that threat
assessment is operational, rather than consultative,
in nature and is aimed at protecting victims by de-
termining the level of risk that they face at a given
moment in time (Meloy and Hoffmann, 2013).
Although the emphasis is different, both take into
account the likelihood that a given individual will
act in a violent fashion. Threat assessment goes
beyond the determination of risk of physical vio-
lence and extends to insider threats such as sabo-
</bodyText>
<page confidence="0.998883">
39
</page>
<bodyText confidence="0.999889083333333">
tage, espionage, hacking, harassment, and attacks
on reputation. Language assumes an even greater
role in the analysis of threat than it does in vio-
lence risk assessment.
The Risk Assessment Guideline Elements for
Violence (RAGE-V) produced by the Association
of Threat Assessment Professionals lists a wide
range of behaviors and risk factors to be consid-
ered in assessing the threat of violence. It contains
no reference to the analysis of written materials or
communications, other than suicide notes. (Avail-
able at www.atapworldwide.org).
</bodyText>
<sectionHeader confidence="0.973097" genericHeader="method">
3 The Language of Threat
</sectionHeader>
<bodyText confidence="0.99870565625">
Analysis of language is an important aspect of
threat assessment and has traditionally been uti-
lized in much the same manner as in forensic eval-
uations. That is, it has largely involved ad hoc,
impressionistic assessments of communications.
Efforts towards a more methodical approach to
linguistic analysis of threatening communications
have been made. However, many of these still rely
primarily on human judgment of content. Smith
and Shuy describe closely examining language as
evidence for clues to race, ethnicity, or gender
of a perpetrator, for identifying false allegations,
and for related law enforcement tasks (Smith and
Shuy, 2002). Scalora describes analyzing threat-
ening language towards members of Congress in
terms of several thematic areas relating to presence
and types of demands (such as policy changes or
personal favors) (Scalora et al., 2003), and Cal-
houn (Calhoun, 1998) examines threatening or in-
appropriate communications and assaults against
federal judicial officials based upon factors such
as the directness or immediacy of the threat.
In other related work, efforts to predict case
outcomes for a set of 96 FBI cases involving
threatening communications have incorporated in-
terviews and automated text processing (Smith,
2008) Computational methods have also been ap-
plied to the communications of terrorist or radi-
cal religious extremist groups to detect aggressive
or violent intent, using function word categories
(Pennebaker et al., 2008) or frame analysis (San-
filippo, 2010).
</bodyText>
<sectionHeader confidence="0.997948" genericHeader="method">
4 Data
</sectionHeader>
<bodyText confidence="0.999913722222222">
Our data consisted of 60 documents that were
sent to judges in a major metropolitan area in the
United States. These documents were genuine,
natural, purposeful communications from a sender
to at least one judge or court official. They were
perceived as threatening, and referred to court se-
curity officers for risk assessment. These refer-
rals were usually made by judges, though Dis-
trict Attorneys and Clerks of the Court can also
report threats to court security. The documents
represented all cases that contained written mate-
rial (not just verbal threats) from the two largest
districts within the purview of the office responsi-
ble for trial court security for this region. Judges
may refer a potentially threatening communication
based on a perceived risk of harm to self, or to the
security of the courtroom.
All documents were in English. All documents
underwent optical character recognition (OCR),
and the output of the OCR process was reviewed
to correct errors in the text. Handwritten portions
of documents were manually transcribed.
Each document was manually annotated for the
presence of atypical formatting or text features,
(e.g., the inclusion of magazine cut-out words or
images, or the use of unusual bolding or italics,
centering, or large point size in text), or presence
of handwritten comments in addition to the text.
These documents include legal documents, letters,
faxes, cards, and other printed materials, as well
as hard copies of emails.
Documents were also coded for indications of
psychotic symptoms, Axis I mental disorders such
as mania, depression, anxiety and psychotic disor-
ders, or Axis II disorders such as personality dis-
orders, developmental disabilities or autism spec-
trum disorders, utilizing the multi-axial diagnos-
tic scheme contained in the Diagnostic and Statis-
tical Manual of Mental Disorders (DSM-IV-TR)
(American Psychiatric Association, 2000). Psy-
chotic symptoms are characteristic of a number of
Axis I disorders, but were coded separately due
to their special significance in the conveyance and
determination of violence risk. Where indications
of one of these types of disorders were present, the
strength of the evidence was rated as significant, or
very compelling. Forty-eight of the 60 documents
showed significant or very compelling indications
of at least one of these disorders.
A high, medium, or low judgment for risk of vi-
olence was made in the manner common in threat
assessment practice, i.e., an overall impression
based upon the intensity of emotion conveyed, the
presence of paranoid ideation directed toward the
</bodyText>
<page confidence="0.990241">
40
</page>
<table confidence="0.998895">
Indications of Mental Illness Psychotic Axis I Disorder Axis II Disorder
Absent 34 24 29
Present 26(7,19) 36(15,21) 31(3,28)
</table>
<tableCaption confidence="0.998364">
Table 1: Indications of mental illness appeared in most of the threatening communications. When indi-
</tableCaption>
<bodyText confidence="0.98337262962963">
cations were present, these were shown as counts of total number of document, and further broken down
into counts of (very compelling, significant).
recipient, and specificity and nature of any threat.
This annotation was performed by one of the au-
thors, who is a board-certified forensic psychiatrist
with over 20 years’ experience in both violence
risk assessment and clinical practice.
The presence of an actual threat in the doc-
ument, and the nature of that threat, were also
recorded. Interestingly, while all documents were
referred out of concern for the personal safety of
at least one judge or court official, in or outside
the courtroom, only a minority of the documents
threatened violence. Just three of the 60 docu-
ments made clear threats of violence, while an-
other five contained vague or ambiguous threats.
Fewer than half (26) contained threats of any kind,
and most of these were threats to take legal ac-
tion. Other documents expressed threats to repu-
tation – they purported to “expose” or embarrass
the judge in some way. Some threatened to file
an ethics complaint. Other threats were more fan-
ciful and clearly outside the power of the author
to effect. For example, they threatened to report
the judge to a non-existent “people’s committee,”
or threatened punishment from God. Some docu-
ments contained more than one threat.
</bodyText>
<table confidence="0.999173571428572">
Type of Threat No. of Documents
None 34
Violence 8 (3 clear, 5 vague)
Legal Action 16
Ethics Complaint 4
Reputation 8
Other 2
</table>
<tableCaption confidence="0.929131">
Table 2: Actual threats of violence are uncommon.
Most communications do not contain a threat.
</tableCaption>
<bodyText confidence="0.998352333333333">
Based on application of the standard threat as-
sessment methods described above to each docu-
ment, the perceived risk was rated low for two-
thirds of the documents (41), moderate for 18, and
high for only one document. These methods con-
sisted of examining each document in isolation.
Where two or more communications were avail-
able from a single sender, the documents were ex-
amined individually, with an effort to isolate each
document from its companions, in order to main-
tain a focus on language used in the document it-
self, and enable clearer comparison with the auto-
mated methods used later.
In the actual practice of threat assessment, if
multiple documents were attributed to a single
sender, and the case was not referred for assess-
ment until after multiple documents had been re-
ceived, the documents would be assessed together
as a pattern of communications. Our approach
more closely parallels the situation faced in as-
sessing anonymous threatening communications,
where knowledge of personal, historical, or clin-
ical factors of the sender is not available. As-
sessment in these circumstances must rely more
heavily on linguistic factors of the communica-
tions (Simons and Tunkel, 2013).
The fact that a single assessor reviewed all the
documents is a limitation of the current study,
which can be addressed in future work.
This research was approved as exempt by the
Partners Institutional Review Board, with the pro-
visions that the confidentiality of materials and the
privacy of individuals be protected.
</bodyText>
<sectionHeader confidence="0.999212" genericHeader="method">
5 Methods
</sectionHeader>
<bodyText confidence="0.999965333333333">
The potential for computational text analytic
methods to contribute to violence risk assessment
and threat assessment has been noted (Meloy and
Hoffmann, 2013). We apply two such methods,
LIWC and topic models, to our sample of threat-
ening communications.
Word count-based methods, such as LIWC
(Linguistic Inquiry and Word Count) are widely
used. LIWC’s central premise is that words peo-
ple use reveal their psychological or emotional
state, and may provide insight into their percep-
tions and intentions. LIWC has been applied to
assessing text for a range of psychological phe-
nomena (Pennebaker et al., 2001), and recently
has been used for detecting indications of decep-
</bodyText>
<page confidence="0.998719">
41
</page>
<bodyText confidence="0.999513666666667">
tion, and of aggression and hostility in the com-
munications of terrorist groups (Pennebaker et al.,
2008; Chung and Pennebaker, 2011).
LIWC is organized into a set of dozens of cat-
egories that contain words and word stems. These
may be grammatical categories such as preposi-
tions or pronouns, or they may be more psycho-
logically informed categories such as “anger” (at-
tack, battle, angry, enemy, violent, etc.). LIWC
calculates the percentage of words in a document
that belong in each of its categories.
We also employ topic models, which are prob-
abilistic models for illuminating an underlying se-
mantic or thematic structure within a set of doc-
uments (Blei and Lafferty, 2009). As an unsu-
pervised method, a topic model is not based on
some predetermined set of associated words, as is
LIWC, with its dozens of categories for function
words, emotion words, and so on. Instead the top-
ics emerge based on the statistical properties of the
documents themselves. This is a consequence of
documents that are about different things typically
using different words with different frequencies.
When the most frequent words in a topic co-
here, it is relatively simple to infer what the topic
is “about.” For example, applying topic model-
ing to over twenty years of the Yale Law Journal
yielded topics appear to relate to various areas of
the law, such as labor (labor, workers, employees,
union, employer) and contract law (contract, lia-
bilities, parties, contracts, party, creditors) (Blei,
2012).
To help avoid overtraining the model, location
names were removed from the documents. Names
of individuals were replaced with tokens for last
name (LN), male first name (MFN), female first
name (FFN), or middle initial (MI). References to
famous historical figures (e.g., Abraham Lincoln,
Hitler, Winston Churchill) were not altered.
We run a Latent Dirichlet Allocation topic
model (Blei, Ng, and Jordan 2003) using MAL-
LET (McCallum, 2002) (McCallum 2002) on the
set of threatening communications. In addition
to ignoring the standard English stopwords in our
documents, we also ignore a small set of ex-
tremely common words in the documents (district,
court, judge), the “LN” (last name) token, and the
months of the year.
Despite the relatively small size of our doc-
ument corpus, a number of intriguing topics
emerge. We observe topics relating to corruption,
misconduct and ethics, conspiracy or other delu-
sional beliefs, and family and community relation-
ships.
</bodyText>
<sectionHeader confidence="0.998369" genericHeader="method">
6 Findings
</sectionHeader>
<subsectionHeader confidence="0.667081">
Expressions of Anger and Negative Emotion
</subsectionHeader>
<bodyText confidence="0.999327955555556">
and Violence Risk Expression of anger and
negative emotions has long been considered a fac-
tor in violence risk assessment and threat assess-
ment. It has been observed that acts of targeted
violence commonly arise from a grievance on the
part of the perpetrator, such as a perceived injus-
tice (Calhoun and Weston, 2003). Chung and
Pennebaker also find significantly elevated rates of
anger words in the language of Al Qaeda leaders
compared to controls (Pennebaker et al., 2008). In
our threatening communications to judges, how-
ever, we do not observe a comparable effect with
respect to perceived violence risk. Words reflect-
ing anger, death, or negative emotions are not used
more frequently in documents that indicate ele-
vated risk. Nor do they vary significantly across
documents reflecting Axis I, Axis II, or psychotic
symptoms.
This may reflect a limitation of any tool such
as LIWC that uses word lists to capture emo-
tion. The expressive capacity of natural lan-
guage is much greater. For example, one threaten-
ing communication that contained no terms from
LIWC’s anger, death, or negative emotion cate-
gories, called others “animals” and “CRIMINAL
TRASH!”, who would be “held accountable” for
their actions.
Themes Induced through Topic Modeling Un-
surprisingly, given that these threatening com-
munications were sent to judges, often by liti-
gants, terms referencing the judicial system appear
prominently in many topics. A closer look reveals
themes relating to claims of judicial misconduct or
ethical violations, conspiracies and fundamentally
sinful or evil acts (“malum in se”). Such topics are
suggestive of symptoms such as persecutory be-
liefs, paranoid ideation, hyperreligiosity, and hy-
permorality that can be found in both Axis I and
Axis II disorders. Tellingly, these themes emerged
from the corpus, not from an a-priori categoriza-
tion of terms.
Not all topics show potential links to detectable
psychopathology. Another topic relates to family
and emotional attachment, and may be indicative
of child custody or child welfare issues. Topics
</bodyText>
<page confidence="0.998047">
42
</page>
<table confidence="0.99896025">
Risk Level Number of Documents Anger Death Negative Emotion
Elevated 19 1.22 (1.02) 0.21 (0.40) 2.42 (1.35)
Low 41 1.06 (0.74) 0.20 (0.40) 2.50 (1.45)
All 60 1.11 (0.83) 0.20 (0.40) 2.47 (1.45)
</table>
<tableCaption confidence="0.993257666666667">
Table 3: Threatening communications judged to show an elevated risk cannot be distinguished from low
risk documents, based on LIWC categories of anger, death, or negative emotion. Means and standard
deviations based on LIWC scores are reported.
</tableCaption>
<bodyText confidence="0.83177">
from this 10-topic LDA include
</bodyText>
<listItem confidence="0.984453">
• Relationships, family, and community: love
children years told thing drug wife fam-
ily conviction make date person community
felony simply letter dss
• Conspiracy and injustice: criminal filed or-
der attorney trial conspiracy federal jus-
tice conduct made constitutional dr se abuse
malum
• Misconduct, ethics: judicial complaints ap-
pointed justice case attorneys federal com-
mission attorney misconduct ethical conduct
complaint respect integrity.
</listItem>
<bodyText confidence="0.999921384615385">
Efforts to build predictive models for identify-
ing documents containing indications of Axis I,
Axis II, or psychotic symptoms based solely on
topic distributions were not entirely successful.
For example, a logistic regression model using
features based on a 10-topic LDA outperformed
chance on a test set at predicting presence of Axis I
symptoms, achieving excellent recall, but low pre-
cision. This may have been due to the small size
of the document collection. Additionally, the over-
lap of symptoms between Axis I and Axis II may
have lead to topics that do not effectively distin-
guish between them.
</bodyText>
<sectionHeader confidence="0.997741" genericHeader="evaluation">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999967396226416">
It is not surprising that judges can be the object of
considerable ire and attention directed at them by
disappointed litigants, family members, or others
who have concerns about legal and social issues.
They sit at the apex of a system that resolves inter-
personal conflicts and administers justice, but with
no shortage of disappointed parties.
Because of the important role they play in our
society, judges are normally accorded consider-
able respect and deference. The majority of dis-
appointed litigants use socially acceptable means
of redressing their grievances, e.g. appealing the
decision, seeking other legal remedies, or more
rarely, filing complaints of judicial misconduct.
Others express their disagreement and disappoint-
ment in a more direct fashion, either by choice or
because they cannot restrain themselves from do-
ing so, in some cases by communicating implied
or direct threats to judges. In doing so, they cross
the boundary of respect for judges and the legal
system that prevents the majority of litigants from
personalizing and pursuing their grievances.
Some such communications are referred by
their recipients to a protective service responsi-
ble for the court in question. The ensuing threat
assessment process yields a determination of the
level and type of violence risk, and the need for
any protective measures. The majority of the com-
munications referred for examination are deter-
mined to represent low risk of violence. Others,
however, are considered to represent significant
risk of harm and to require actions to eliminate or
diminish the threat.
Since the office responsible for court security
has not yet cataloged its threatening communica-
tions, we cannot ensure that this sample is per-
fectly representative of all threatening communi-
cations received by the courts. Plans to imple-
ment such a database are under development. In
addition, we do not have a sample of communica-
tions to judges that the recipients themselves did
not find sufficiently threatening to refer for assess-
ment, nor do we know the prevalence of such com-
munications.
This pilot study represents an attempt to use
computational linguistic analysis to explore what
aspects of written communications to judges re-
sult in the perception of threat and the determina-
tion of risk level. We analyzed a sample of doc-
uments referred by their recipients as potentially
threatening. In this sample we found evidence of
direct or implied threat of violence in a small mi-
nority of examples. An expert rater categorized
</bodyText>
<page confidence="0.99925">
43
</page>
<bodyText confidence="0.979575952380952">
only one communication as indicating a high level
of threat. Evidence of mental illness on the part of
the senders was found in the majority of examples
(80 percent).
Possible explanations for the disparity between
the universal perceptions of threat by recipients
and expert assessment of threat may include a
combination of the following:
1. The very act of sending an argumentative or
hostile communication to a judge represents
a breach of normative behavior, and suggests
that the sender may have difficulty control-
ling hostile impulses and maintaining appro-
priate boundaries.
2. The popular belief that mental illness is as-
sociated with a high risk of violence may
increase the likelihood that communications
containing evidence of psychotic beliefs and
other forms of disordered thinking, but no ev-
idence of threat, get referred by court person-
nel for further investigation.
</bodyText>
<listItem confidence="0.972947">
3. Over-assessment of mental illness by the ex-
pert rater, in spite of efforts to be conservative
in those ratings.
4. Under-assessment of violence risk by the ex-
</listItem>
<bodyText confidence="0.998027636363637">
pert rater, however it should be noted that
documents spanned a period from 1995 to
2013 and there have been no episodes of
violence against judges in that jurisdiction
to date. Whether that represents the true
level of actual risk or the successful efforts
of court security personnel in managing the
threat cannot be determined.
The purpose of the current pilot study was to
explore if language technology could be used to
identify those aspects of a communication that
render it threatening to its recipients or correlate
with expert assessment of the level of violence
threat they present. We applied these tools to a
relatively small group of 60 written communica-
tions sent to judges. A single forensic psychia-
trist, experienced in threat and violence risk as-
sessment, rated each document individually for the
study factors. The results were promising, yet not
dispositive, with regard to the ability of language
technology to identify those factors that render a
communication “threatening,” are predictive of in-
creased risk, or indicative of mental illness.
The next steps for this work include examina-
tion of a larger number of communications re-
ferred for assessment of possible increased risk
of violence. Communications addressed to other
public figures, as well as organizations and their
personnel, can be analyzed and compared to those
received by judges. Progress on automating the
extraction of text features that were manually an-
notated, including distinctive orthographic fea-
tures (contextually inappropriate use of capitaliza-
tion and emphasis), and number and titles of recip-
ients would be valuable. In addition, it will be im-
portant to have the presence of indicators of men-
tal illness and level of risk, rated independently by
multiple experts in the field of threat assessment
in a two part process. First, the documents will
be rated in the absence of any contextual infor-
mation. Second, evaluators will be provided with
additional information regarding the individual’s
background and asked to rerate the communica-
tions.
</bodyText>
<sectionHeader confidence="0.99866" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999966826086956">
Mental health professionals are asked to assess
the risk of violence on a regular basis and in a
wide variety of settings. The accuracy and reli-
ability of this complex and challenging task in-
creases with the amount of information available
to the evaluator. To date, those charged with con-
ducting these assessments have not utilized auto-
mated approaches for linguistic analysis to inform
their assessments. The results of this pilot study
suggest that such analysis may be a useful addi-
tion to the traditional tools currently used in vio-
lence threat assessment. The availability of such
a tool could increase the accuracy and objectiv-
ity of currently applied threat assessment methods.
However, more data is needed to train and build
models, and fully test their utility. Supervised ma-
chine learning approaches, or more sophisticated
topic models, may be needed to tackle the com-
plexities of supporting violence risk assessment
through language technology.
Acknowledgments We thank the anonymous
reviewers and Jordan Boyd-Graber for their in-
sightful comments.
</bodyText>
<sectionHeader confidence="0.999198" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.935831">
American Psychiatric Association. 2000. Diagnostic
</reference>
<page confidence="0.981891">
44
</page>
<reference confidence="0.998910583333333">
and statistical manual of mental disorders: DSM-
IV-TR R�. American Psychiatric Pub.
David M. Blei and John D. Lafferty. 2009. Topic mod-
els. Text mining: classification, clustering, and ap-
plications, 10:71.
David M Blei. 2012. Probabilistic topic models. Com-
munications of the ACM, 55(4):77–84.
F Calhoun and S Weston. 2003. Contemporary threat
management. San Diego, CA: Specialized Training
Services.
Frederick S Calhoun. 1998. Hunters and howlers:
Threats and violence against federal judicial offi-
cials in the United States, 1789-1993. Number 80.
US Department of Justice, US Marshals Service.
Cindy K Chung and James W Pennebaker. 2011. Us-
ing computerized text analysis to assess threatening
communications and behavior. Threatening commu-
nications and behavior: Perspectives on the pursuit
ofpublic figures, page 332.
E. B. Elbogen and S. C. Johnson. 2009. The intricate
link between violence and mental disorder: Results
from the national epidemiologic survey on alcohol
and related conditions. Archives of General Psychi-
atry, 66(2):152–161, February.
Andrew Kachites McCallum. 2002. Mallet: A ma-
chine learning for language toolkit.
J. Reid Meloy and Jens Hoffmann. 2013. International
Handbook of Threat Assessment. Oxford University
Press.
John Monahan, Henry J Steadman, Paul S Appelbaum,
Thomas Grisso, Edward P Mulvey, Loren H Roth,
Pamela Clark Robbins, Stephen Banks, and Eric Sil-
ver. 2006. The classification of violence risk. Be-
havioral sciences &amp; the law, 24(6):721–730.
James W Pennebaker, Martha E Francis, and Roger J
Booth. 2001. Linguistic inquiry and word count:
LIWC 2001. Mahway: Lawrence Erlbaum Asso-
ciates, page 71.
James W Pennebaker, Cindy K Chung, et al. 2008.
Computerized text analysis of al-qaeda transcripts.
A content analysis reader, pages 453–465.
Vernon L. Quinsey, Grant T. Harris, Marnie E. Rice,
and Catherine A. Cormier. 1998. Violent offenders:
Appraising and managing risk. American Psycho-
logical Association.
Antonio P. Sanfilippo. 2010. Content Analysis for
Proactive Protective Intelligence. Pacific Northwest
National Laboratory.
Mario J Scalora, Jerome V Baumgartner, Mary A
Hatch Maillette, Christmas N Covell, Russell E
Palarea, Jason A Krebs, David O Washington,
William Zimmerman, and David Callaway. 2003.
Risk factors for approach behavior toward the US
congress. Journal of threat assessment, 2(2):3555.
Andr´e Simons and Ronald Tunkel. 2013. The as-
sessment of anonymous threatening communica-
tions. International Handbook of Threat Assess-
ment, pages 195–213.
Jennifer L Skeem and John Monahan. 2011. Current
directions in violence risk assessment. Current Di-
rections in Psychological Science, 20(1):38–42.
S Smith and R Shuy. 2002. Forensic psycholinguis-
tics: using language analysis for identifying and as-
sessing offenders. FBI Law Enforcement Bulletin,
71(4):1621.
S Smith. 2008. From violent words to violent deeds:
assessing risk from FBI threatening communication
cases. Stalking, Threatening, and Attacking Public
Figures: a psychological and behavioral analysis,
page 435455.
H. J. Steadman, E.P. Mulvey, J. Monahan, and et al.
1998. Violence by people discharged from acute
psychiatric inpatient facilities and by others in the
same neighborhoods. Archives of General Psychia-
try, 55(5):393–401, May.
Jeffrey Swanson, Charles Holzer, Vijay Ganju, and
Robert Jono. 1990. Violence and psychiatric dis-
order in the community: evidence from the epi-
demiologic catchment area surveys. Hospital &amp;
community psychiatry, 41(7):761–770, July. PMID:
2142118.
Christopher D Webster, Kevin S Douglas, Derek Eaves,
and Stephen D Hart. 1982. Assessing risk for vio-
lence, version 2 (hcr-20). Sigma, 1993:1997.
</reference>
<page confidence="0.99939">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.439067">
<title confidence="0.999683">Assessing Violence Risk in Threatening Communications</title>
<author confidence="0.959144">Kimberly Johns Hopkins</author>
<affiliation confidence="0.99905">Applied Physics College of Information University of</affiliation>
<email confidence="0.998246">kimberly.glasgow@jhuapl.edu</email>
<author confidence="0.945192">Ronald</author>
<affiliation confidence="0.885194333333333">Harvard Medical Department of Massachusetts General</affiliation>
<email confidence="0.999611">rschouten@mgh.harvard.edu</email>
<abstract confidence="0.9895502">Violence risk assessment is an important and challenging task undertaken by mental health professionals and others, in both clinical and nonclinical settings. To date, computational linguistic techniques have not been used in the risk assessment process. However they could contribute to the current threat assessment process by allowing for early detection of elevated risk, identification of risk factors for violence, monitoring of violent intent, and determination of threat level. We analyzed a sample of communications to judges that were referred to security personnel for evaluation as constituting potential threats. We categorized them along multiple dimensions including evidence of mental illness, presence and nature of any threat, and level of threat. While neither word countbased or topic models were able to effectively predict elevated risk, we found topics indicative of persecutory beliefs, paranoid ideation, and other symptoms of Axis I and Axis II disorders.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>American Psychiatric Association</author>
</authors>
<title>Diagnostic and statistical manual of mental disorders: DSMIV-TR R�. American Psychiatric Pub.</title>
<date>2000</date>
<contexts>
<context position="12215" citStr="Association, 2000" startWordPosition="1901" endWordPosition="1902">xt), or presence of handwritten comments in addition to the text. These documents include legal documents, letters, faxes, cards, and other printed materials, as well as hard copies of emails. Documents were also coded for indications of psychotic symptoms, Axis I mental disorders such as mania, depression, anxiety and psychotic disorders, or Axis II disorders such as personality disorders, developmental disabilities or autism spectrum disorders, utilizing the multi-axial diagnostic scheme contained in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV-TR) (American Psychiatric Association, 2000). Psychotic symptoms are characteristic of a number of Axis I disorders, but were coded separately due to their special significance in the conveyance and determination of violence risk. Where indications of one of these types of disorders were present, the strength of the evidence was rated as significant, or very compelling. Forty-eight of the 60 documents showed significant or very compelling indications of at least one of these disorders. A high, medium, or low judgment for risk of violence was made in the manner common in threat assessment practice, i.e., an overall impression based upon </context>
</contexts>
<marker>Association, 2000</marker>
<rawString>American Psychiatric Association. 2000. Diagnostic and statistical manual of mental disorders: DSMIV-TR R�. American Psychiatric Pub.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>John D Lafferty</author>
</authors>
<title>Topic models. Text mining: classification, clustering, and applications,</title>
<date>2009</date>
<pages>10--71</pages>
<contexts>
<context position="17573" citStr="Blei and Lafferty, 2009" startWordPosition="2774" endWordPosition="2777">tions of terrorist groups (Pennebaker et al., 2008; Chung and Pennebaker, 2011). LIWC is organized into a set of dozens of categories that contain words and word stems. These may be grammatical categories such as prepositions or pronouns, or they may be more psychologically informed categories such as “anger” (attack, battle, angry, enemy, violent, etc.). LIWC calculates the percentage of words in a document that belong in each of its categories. We also employ topic models, which are probabilistic models for illuminating an underlying semantic or thematic structure within a set of documents (Blei and Lafferty, 2009). As an unsupervised method, a topic model is not based on some predetermined set of associated words, as is LIWC, with its dozens of categories for function words, emotion words, and so on. Instead the topics emerge based on the statistical properties of the documents themselves. This is a consequence of documents that are about different things typically using different words with different frequencies. When the most frequent words in a topic cohere, it is relatively simple to infer what the topic is “about.” For example, applying topic modeling to over twenty years of the Yale Law Journal y</context>
</contexts>
<marker>Blei, Lafferty, 2009</marker>
<rawString>David M. Blei and John D. Lafferty. 2009. Topic models. Text mining: classification, clustering, and applications, 10:71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
</authors>
<title>Probabilistic topic models.</title>
<date>2012</date>
<journal>Communications of the ACM,</journal>
<volume>55</volume>
<issue>4</issue>
<contexts>
<context position="18383" citStr="Blei, 2012" startWordPosition="2909" endWordPosition="2910">the topics emerge based on the statistical properties of the documents themselves. This is a consequence of documents that are about different things typically using different words with different frequencies. When the most frequent words in a topic cohere, it is relatively simple to infer what the topic is “about.” For example, applying topic modeling to over twenty years of the Yale Law Journal yielded topics appear to relate to various areas of the law, such as labor (labor, workers, employees, union, employer) and contract law (contract, liabilities, parties, contracts, party, creditors) (Blei, 2012). To help avoid overtraining the model, location names were removed from the documents. Names of individuals were replaced with tokens for last name (LN), male first name (MFN), female first name (FFN), or middle initial (MI). References to famous historical figures (e.g., Abraham Lincoln, Hitler, Winston Churchill) were not altered. We run a Latent Dirichlet Allocation topic model (Blei, Ng, and Jordan 2003) using MALLET (McCallum, 2002) (McCallum 2002) on the set of threatening communications. In addition to ignoring the standard English stopwords in our documents, we also ignore a small set</context>
</contexts>
<marker>Blei, 2012</marker>
<rawString>David M Blei. 2012. Probabilistic topic models. Communications of the ACM, 55(4):77–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Calhoun</author>
<author>S Weston</author>
</authors>
<title>Contemporary threat management. San Diego, CA: Specialized Training Services.</title>
<date>2003</date>
<contexts>
<context position="19720" citStr="Calhoun and Weston, 2003" startWordPosition="3121" endWordPosition="3124"> of the year. Despite the relatively small size of our document corpus, a number of intriguing topics emerge. We observe topics relating to corruption, misconduct and ethics, conspiracy or other delusional beliefs, and family and community relationships. 6 Findings Expressions of Anger and Negative Emotion and Violence Risk Expression of anger and negative emotions has long been considered a factor in violence risk assessment and threat assessment. It has been observed that acts of targeted violence commonly arise from a grievance on the part of the perpetrator, such as a perceived injustice (Calhoun and Weston, 2003). Chung and Pennebaker also find significantly elevated rates of anger words in the language of Al Qaeda leaders compared to controls (Pennebaker et al., 2008). In our threatening communications to judges, however, we do not observe a comparable effect with respect to perceived violence risk. Words reflecting anger, death, or negative emotions are not used more frequently in documents that indicate elevated risk. Nor do they vary significantly across documents reflecting Axis I, Axis II, or psychotic symptoms. This may reflect a limitation of any tool such as LIWC that uses word lists to captu</context>
</contexts>
<marker>Calhoun, Weston, 2003</marker>
<rawString>F Calhoun and S Weston. 2003. Contemporary threat management. San Diego, CA: Specialized Training Services.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick S Calhoun</author>
</authors>
<title>Hunters and howlers: Threats and violence against federal judicial officials in the United States,</title>
<date>1998</date>
<institution>US Department of Justice, US Marshals Service.</institution>
<contexts>
<context position="9696" citStr="Calhoun, 1998" startWordPosition="1513" endWordPosition="1514">ach to linguistic analysis of threatening communications have been made. However, many of these still rely primarily on human judgment of content. Smith and Shuy describe closely examining language as evidence for clues to race, ethnicity, or gender of a perpetrator, for identifying false allegations, and for related law enforcement tasks (Smith and Shuy, 2002). Scalora describes analyzing threatening language towards members of Congress in terms of several thematic areas relating to presence and types of demands (such as policy changes or personal favors) (Scalora et al., 2003), and Calhoun (Calhoun, 1998) examines threatening or inappropriate communications and assaults against federal judicial officials based upon factors such as the directness or immediacy of the threat. In other related work, efforts to predict case outcomes for a set of 96 FBI cases involving threatening communications have incorporated interviews and automated text processing (Smith, 2008) Computational methods have also been applied to the communications of terrorist or radical religious extremist groups to detect aggressive or violent intent, using function word categories (Pennebaker et al., 2008) or frame analysis (Sa</context>
</contexts>
<marker>Calhoun, 1998</marker>
<rawString>Frederick S Calhoun. 1998. Hunters and howlers: Threats and violence against federal judicial officials in the United States, 1789-1993. Number 80. US Department of Justice, US Marshals Service.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cindy K Chung</author>
<author>James W Pennebaker</author>
</authors>
<title>Using computerized text analysis to assess threatening communications and behavior. Threatening communications and behavior: Perspectives on the pursuit ofpublic figures,</title>
<date>2011</date>
<pages>332</pages>
<contexts>
<context position="17028" citStr="Chung and Pennebaker, 2011" startWordPosition="2682" endWordPosition="2685">hods, LIWC and topic models, to our sample of threatening communications. Word count-based methods, such as LIWC (Linguistic Inquiry and Word Count) are widely used. LIWC’s central premise is that words people use reveal their psychological or emotional state, and may provide insight into their perceptions and intentions. LIWC has been applied to assessing text for a range of psychological phenomena (Pennebaker et al., 2001), and recently has been used for detecting indications of decep41 tion, and of aggression and hostility in the communications of terrorist groups (Pennebaker et al., 2008; Chung and Pennebaker, 2011). LIWC is organized into a set of dozens of categories that contain words and word stems. These may be grammatical categories such as prepositions or pronouns, or they may be more psychologically informed categories such as “anger” (attack, battle, angry, enemy, violent, etc.). LIWC calculates the percentage of words in a document that belong in each of its categories. We also employ topic models, which are probabilistic models for illuminating an underlying semantic or thematic structure within a set of documents (Blei and Lafferty, 2009). As an unsupervised method, a topic model is not based</context>
</contexts>
<marker>Chung, Pennebaker, 2011</marker>
<rawString>Cindy K Chung and James W Pennebaker. 2011. Using computerized text analysis to assess threatening communications and behavior. Threatening communications and behavior: Perspectives on the pursuit ofpublic figures, page 332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E B Elbogen</author>
<author>S C Johnson</author>
</authors>
<title>The intricate link between violence and mental disorder: Results from the national epidemiologic survey on alcohol and related conditions.</title>
<date>2009</date>
<journal>Archives of General Psychiatry,</journal>
<volume>66</volume>
<issue>2</issue>
<contexts>
<context position="3975" citStr="Elbogen and Johnson, 2009" startWordPosition="592" endWordPosition="595">ges 38–45, Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics people with mental illness. While violence against others on the part of people with diagnoses of mental illness is far less prevalent than is popularly thought, the increased risk attributable to these illnesses is barely statistically significant (Steadman et al., 1998; Swanson et al., 1990). This increased risk is largely attributable to a small group of individuals who have a history of childhood or adult antisocial behavior in combination with substance use disorders and psychotic illness (Elbogen and Johnson, 2009). 2.1 Methods and Practice of Violence Risk Assessment Treating clinicians are responsible for evaluating their patients to determine if they pose a risk of violence and adjusting treatment accordingly, or arranging for hospitalization, as needed. The risk of violence, as evidenced by threats or attempts to harm self or others, are two of the bases for hospitalizing people with mental illness against their will. This assessment primarily relies upon information obtained through interviewing and observing the patient, as well as information from collateral sources when it is available. The pati</context>
</contexts>
<marker>Elbogen, Johnson, 2009</marker>
<rawString>E. B. Elbogen and S. C. Johnson. 2009. The intricate link between violence and mental disorder: Results from the national epidemiologic survey on alcohol and related conditions. Archives of General Psychiatry, 66(2):152–161, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<contexts>
<context position="18825" citStr="McCallum, 2002" startWordPosition="2977" endWordPosition="2978">ious areas of the law, such as labor (labor, workers, employees, union, employer) and contract law (contract, liabilities, parties, contracts, party, creditors) (Blei, 2012). To help avoid overtraining the model, location names were removed from the documents. Names of individuals were replaced with tokens for last name (LN), male first name (MFN), female first name (FFN), or middle initial (MI). References to famous historical figures (e.g., Abraham Lincoln, Hitler, Winston Churchill) were not altered. We run a Latent Dirichlet Allocation topic model (Blei, Ng, and Jordan 2003) using MALLET (McCallum, 2002) (McCallum 2002) on the set of threatening communications. In addition to ignoring the standard English stopwords in our documents, we also ignore a small set of extremely common words in the documents (district, court, judge), the “LN” (last name) token, and the months of the year. Despite the relatively small size of our document corpus, a number of intriguing topics emerge. We observe topics relating to corruption, misconduct and ethics, conspiracy or other delusional beliefs, and family and community relationships. 6 Findings Expressions of Anger and Negative Emotion and Violence Risk Expr</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reid Meloy</author>
<author>Jens Hoffmann</author>
</authors>
<date>2013</date>
<booktitle>International Handbook of Threat Assessment.</booktitle>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="7980" citStr="Meloy and Hoffmann, 2013" startWordPosition="1245" endWordPosition="1248">ental disorder and indications of violence risk. 2.2 Threat Assessment Threat assessment is a discipline that relates to, yet is separate from, clinical violence risk assessment. Meloy, et al. distinguish between the two fields, noting that violence risk assessment is consultative in nature, and generally aimed at assisting legal decision-making and managing a particular individual over the long term. They note that threat assessment is operational, rather than consultative, in nature and is aimed at protecting victims by determining the level of risk that they face at a given moment in time (Meloy and Hoffmann, 2013). Although the emphasis is different, both take into account the likelihood that a given individual will act in a violent fashion. Threat assessment goes beyond the determination of risk of physical violence and extends to insider threats such as sabo39 tage, espionage, hacking, harassment, and attacks on reputation. Language assumes an even greater role in the analysis of threat than it does in violence risk assessment. The Risk Assessment Guideline Elements for Violence (RAGE-V) produced by the Association of Threat Assessment Professionals lists a wide range of behaviors and risk factors to</context>
<context position="16378" citStr="Meloy and Hoffmann, 2013" startWordPosition="2577" endWordPosition="2580">ilable. Assessment in these circumstances must rely more heavily on linguistic factors of the communications (Simons and Tunkel, 2013). The fact that a single assessor reviewed all the documents is a limitation of the current study, which can be addressed in future work. This research was approved as exempt by the Partners Institutional Review Board, with the provisions that the confidentiality of materials and the privacy of individuals be protected. 5 Methods The potential for computational text analytic methods to contribute to violence risk assessment and threat assessment has been noted (Meloy and Hoffmann, 2013). We apply two such methods, LIWC and topic models, to our sample of threatening communications. Word count-based methods, such as LIWC (Linguistic Inquiry and Word Count) are widely used. LIWC’s central premise is that words people use reveal their psychological or emotional state, and may provide insight into their perceptions and intentions. LIWC has been applied to assessing text for a range of psychological phenomena (Pennebaker et al., 2001), and recently has been used for detecting indications of decep41 tion, and of aggression and hostility in the communications of terrorist groups (Pe</context>
</contexts>
<marker>Meloy, Hoffmann, 2013</marker>
<rawString>J. Reid Meloy and Jens Hoffmann. 2013. International Handbook of Threat Assessment. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Monahan</author>
<author>Henry J Steadman</author>
<author>Paul S Appelbaum</author>
<author>Thomas Grisso</author>
<author>Edward P Mulvey</author>
<author>Loren H Roth</author>
<author>Pamela Clark Robbins</author>
<author>Stephen Banks</author>
<author>Eric Silver</author>
</authors>
<title>The classification of violence risk.</title>
<date>2006</date>
<booktitle>Behavioral sciences &amp; the law,</booktitle>
<pages>24--6</pages>
<contexts>
<context position="5862" citStr="Monahan et al., 2006" startWordPosition="908" endWordPosition="911">itnesses in civil commitment proceedings or as consultants on such matters. In the criminal justice system, they may be asked to assess the risk of violence in conjunction with the issuance of restraining orders, determination of conditions of bail and probation, and sentencing. While judges make the ultimate decisions, they generally rely highly upon the clinical judgment of MHPs with regard to diagnosis and assessment of the risk of violence. In recent years, a number of tools have been introduced to assist in the assessment of violence risk, such at the HCR-20 (Webster et al., 1982), COVR (Monahan et al., 2006), and VRAG (Quinsey et al., 1998). None of these instruments consider linguistic factors. They utilize actuarial determinations of violence risk. These instruments do not provide strict cutoff scores that differentiate between nonviolent and violent individuals. Rather, they serve as adjunct tools to clinical judgment. As a result, the current best practice in violence risk assessment consists of structured clinical judgment, a process in which actuarial risk assessments are combined with clinical judgment to reach a determination regarding a specific individual’s risk. Whereas treating clinic</context>
</contexts>
<marker>Monahan, Steadman, Appelbaum, Grisso, Mulvey, Roth, Robbins, Banks, Silver, 2006</marker>
<rawString>John Monahan, Henry J Steadman, Paul S Appelbaum, Thomas Grisso, Edward P Mulvey, Loren H Roth, Pamela Clark Robbins, Stephen Banks, and Eric Silver. 2006. The classification of violence risk. Behavioral sciences &amp; the law, 24(6):721–730.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Martha E Francis</author>
<author>Roger J Booth</author>
</authors>
<title>Linguistic inquiry and word count: LIWC</title>
<date>2001</date>
<pages>71</pages>
<contexts>
<context position="2388" citStr="Pennebaker et al., 2001" startWordPosition="349" endWordPosition="352">vidence of impending violent behavior. Language technology is rarely utilized in these efforts, yet it could be a valuable tool for detecting evidence of illness and increased violence risk in verbal and written communications. We analyzed a unique data set of threatening communications sent to judges. Examination of these written communications indicate that, for this sample, explicit threats are rare, but evidence of mental illness is common. We applied two types of computational methods to the communications in the sample—topic models, and a simple computational text analysis method: LIWC (Pennebaker et al., 2001). The results point towards a useful role for such methods in the analysis of threatening communications, as well as limitations. Advances in language technology methods, as well as the availability of more data, may both be needed to make substantial progress. 2 Violence Risk Assessment and Mental Health Professionals Assessment of the risk of violence is a task that belongs to a diverse group of mental health professionals (MHPs): those who provide clinical care, forensic MHPs specializing in mental health issues related to the legal system, and those who engage in the even more specialized </context>
<context position="16829" citStr="Pennebaker et al., 2001" startWordPosition="2650" endWordPosition="2653">ed. 5 Methods The potential for computational text analytic methods to contribute to violence risk assessment and threat assessment has been noted (Meloy and Hoffmann, 2013). We apply two such methods, LIWC and topic models, to our sample of threatening communications. Word count-based methods, such as LIWC (Linguistic Inquiry and Word Count) are widely used. LIWC’s central premise is that words people use reveal their psychological or emotional state, and may provide insight into their perceptions and intentions. LIWC has been applied to assessing text for a range of psychological phenomena (Pennebaker et al., 2001), and recently has been used for detecting indications of decep41 tion, and of aggression and hostility in the communications of terrorist groups (Pennebaker et al., 2008; Chung and Pennebaker, 2011). LIWC is organized into a set of dozens of categories that contain words and word stems. These may be grammatical categories such as prepositions or pronouns, or they may be more psychologically informed categories such as “anger” (attack, battle, angry, enemy, violent, etc.). LIWC calculates the percentage of words in a document that belong in each of its categories. We also employ topic models, </context>
</contexts>
<marker>Pennebaker, Francis, Booth, 2001</marker>
<rawString>James W Pennebaker, Martha E Francis, and Roger J Booth. 2001. Linguistic inquiry and word count: LIWC 2001. Mahway: Lawrence Erlbaum Associates, page 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Cindy K Chung</author>
</authors>
<title>Computerized text analysis of al-qaeda transcripts. A content analysis reader,</title>
<date>2008</date>
<pages>453--465</pages>
<marker>Pennebaker, Chung, 2008</marker>
<rawString>James W Pennebaker, Cindy K Chung, et al. 2008. Computerized text analysis of al-qaeda transcripts. A content analysis reader, pages 453–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vernon L Quinsey</author>
<author>Grant T Harris</author>
<author>Marnie E Rice</author>
<author>Catherine A Cormier</author>
</authors>
<title>Violent offenders: Appraising and managing risk.</title>
<date>1998</date>
<publisher>American Psychological Association.</publisher>
<contexts>
<context position="5895" citStr="Quinsey et al., 1998" startWordPosition="914" endWordPosition="918">eedings or as consultants on such matters. In the criminal justice system, they may be asked to assess the risk of violence in conjunction with the issuance of restraining orders, determination of conditions of bail and probation, and sentencing. While judges make the ultimate decisions, they generally rely highly upon the clinical judgment of MHPs with regard to diagnosis and assessment of the risk of violence. In recent years, a number of tools have been introduced to assist in the assessment of violence risk, such at the HCR-20 (Webster et al., 1982), COVR (Monahan et al., 2006), and VRAG (Quinsey et al., 1998). None of these instruments consider linguistic factors. They utilize actuarial determinations of violence risk. These instruments do not provide strict cutoff scores that differentiate between nonviolent and violent individuals. Rather, they serve as adjunct tools to clinical judgment. As a result, the current best practice in violence risk assessment consists of structured clinical judgment, a process in which actuarial risk assessments are combined with clinical judgment to reach a determination regarding a specific individual’s risk. Whereas treating clinicians primarily rely upon examinat</context>
</contexts>
<marker>Quinsey, Harris, Rice, Cormier, 1998</marker>
<rawString>Vernon L. Quinsey, Grant T. Harris, Marnie E. Rice, and Catherine A. Cormier. 1998. Violent offenders: Appraising and managing risk. American Psychological Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio P Sanfilippo</author>
</authors>
<title>Content Analysis for Proactive Protective Intelligence.</title>
<date>2010</date>
<institution>Pacific Northwest National Laboratory.</institution>
<contexts>
<context position="10311" citStr="Sanfilippo, 2010" startWordPosition="1603" endWordPosition="1605">8) examines threatening or inappropriate communications and assaults against federal judicial officials based upon factors such as the directness or immediacy of the threat. In other related work, efforts to predict case outcomes for a set of 96 FBI cases involving threatening communications have incorporated interviews and automated text processing (Smith, 2008) Computational methods have also been applied to the communications of terrorist or radical religious extremist groups to detect aggressive or violent intent, using function word categories (Pennebaker et al., 2008) or frame analysis (Sanfilippo, 2010). 4 Data Our data consisted of 60 documents that were sent to judges in a major metropolitan area in the United States. These documents were genuine, natural, purposeful communications from a sender to at least one judge or court official. They were perceived as threatening, and referred to court security officers for risk assessment. These referrals were usually made by judges, though District Attorneys and Clerks of the Court can also report threats to court security. The documents represented all cases that contained written material (not just verbal threats) from the two largest districts </context>
</contexts>
<marker>Sanfilippo, 2010</marker>
<rawString>Antonio P. Sanfilippo. 2010. Content Analysis for Proactive Protective Intelligence. Pacific Northwest National Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mario J Scalora</author>
<author>Jerome V Baumgartner</author>
<author>Mary A Hatch Maillette</author>
<author>Christmas N Covell</author>
<author>Russell E Palarea</author>
<author>Jason A Krebs</author>
<author>David O Washington</author>
<author>William Zimmerman</author>
<author>David Callaway</author>
</authors>
<title>Risk factors for approach behavior toward the US congress.</title>
<date>2003</date>
<journal>Journal of threat assessment,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="9667" citStr="Scalora et al., 2003" startWordPosition="1506" endWordPosition="1509">orts towards a more methodical approach to linguistic analysis of threatening communications have been made. However, many of these still rely primarily on human judgment of content. Smith and Shuy describe closely examining language as evidence for clues to race, ethnicity, or gender of a perpetrator, for identifying false allegations, and for related law enforcement tasks (Smith and Shuy, 2002). Scalora describes analyzing threatening language towards members of Congress in terms of several thematic areas relating to presence and types of demands (such as policy changes or personal favors) (Scalora et al., 2003), and Calhoun (Calhoun, 1998) examines threatening or inappropriate communications and assaults against federal judicial officials based upon factors such as the directness or immediacy of the threat. In other related work, efforts to predict case outcomes for a set of 96 FBI cases involving threatening communications have incorporated interviews and automated text processing (Smith, 2008) Computational methods have also been applied to the communications of terrorist or radical religious extremist groups to detect aggressive or violent intent, using function word categories (Pennebaker et al.</context>
</contexts>
<marker>Scalora, Baumgartner, Maillette, Covell, Palarea, Krebs, Washington, Zimmerman, Callaway, 2003</marker>
<rawString>Mario J Scalora, Jerome V Baumgartner, Mary A Hatch Maillette, Christmas N Covell, Russell E Palarea, Jason A Krebs, David O Washington, William Zimmerman, and David Callaway. 2003. Risk factors for approach behavior toward the US congress. Journal of threat assessment, 2(2):3555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e Simons</author>
<author>Ronald Tunkel</author>
</authors>
<title>The assessment of anonymous threatening communications. International Handbook of Threat Assessment,</title>
<date>2013</date>
<pages>195--213</pages>
<contexts>
<context position="15887" citStr="Simons and Tunkel, 2013" startWordPosition="2500" endWordPosition="2503">omated methods used later. In the actual practice of threat assessment, if multiple documents were attributed to a single sender, and the case was not referred for assessment until after multiple documents had been received, the documents would be assessed together as a pattern of communications. Our approach more closely parallels the situation faced in assessing anonymous threatening communications, where knowledge of personal, historical, or clinical factors of the sender is not available. Assessment in these circumstances must rely more heavily on linguistic factors of the communications (Simons and Tunkel, 2013). The fact that a single assessor reviewed all the documents is a limitation of the current study, which can be addressed in future work. This research was approved as exempt by the Partners Institutional Review Board, with the provisions that the confidentiality of materials and the privacy of individuals be protected. 5 Methods The potential for computational text analytic methods to contribute to violence risk assessment and threat assessment has been noted (Meloy and Hoffmann, 2013). We apply two such methods, LIWC and topic models, to our sample of threatening communications. Word count-b</context>
</contexts>
<marker>Simons, Tunkel, 2013</marker>
<rawString>Andr´e Simons and Ronald Tunkel. 2013. The assessment of anonymous threatening communications. International Handbook of Threat Assessment, pages 195–213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer L Skeem</author>
<author>John Monahan</author>
</authors>
<title>Current directions in violence risk assessment.</title>
<date>2011</date>
<booktitle>Current Directions in Psychological Science,</booktitle>
<pages>20--1</pages>
<contexts>
<context position="1599" citStr="Skeem and Monahan, 2011" startWordPosition="229" endWordPosition="232"> categorized them along multiple dimensions including evidence of mental illness, presence and nature of any threat, and level of threat. While neither word countbased or topic models were able to effectively predict elevated risk, we found topics indicative of persecutory beliefs, paranoid ideation, and other symptoms of Axis I and Axis II disorders. 1 Introduction Mental health professionals are called upon to assess the risk of violence in many different settings, from the determination of the need for hospitalization or increased treatment to consultations for the criminal justice system (Skeem and Monahan, 2011). These assessments include examination of the verbal content of a subject’s communications, primarily for the purpose of detecting symptoms of thought disorder or evidence of impending violent behavior. Language technology is rarely utilized in these efforts, yet it could be a valuable tool for detecting evidence of illness and increased violence risk in verbal and written communications. We analyzed a unique data set of threatening communications sent to judges. Examination of these written communications indicate that, for this sample, explicit threats are rare, but evidence of mental illne</context>
</contexts>
<marker>Skeem, Monahan, 2011</marker>
<rawString>Jennifer L Skeem and John Monahan. 2011. Current directions in violence risk assessment. Current Directions in Psychological Science, 20(1):38–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Smith</author>
<author>R Shuy</author>
</authors>
<title>Forensic psycholinguistics: using language analysis for identifying and assessing offenders.</title>
<date>2002</date>
<journal>FBI Law Enforcement Bulletin,</journal>
<volume>71</volume>
<issue>4</issue>
<contexts>
<context position="9445" citStr="Smith and Shuy, 2002" startWordPosition="1472" endWordPosition="1475">s an important aspect of threat assessment and has traditionally been utilized in much the same manner as in forensic evaluations. That is, it has largely involved ad hoc, impressionistic assessments of communications. Efforts towards a more methodical approach to linguistic analysis of threatening communications have been made. However, many of these still rely primarily on human judgment of content. Smith and Shuy describe closely examining language as evidence for clues to race, ethnicity, or gender of a perpetrator, for identifying false allegations, and for related law enforcement tasks (Smith and Shuy, 2002). Scalora describes analyzing threatening language towards members of Congress in terms of several thematic areas relating to presence and types of demands (such as policy changes or personal favors) (Scalora et al., 2003), and Calhoun (Calhoun, 1998) examines threatening or inappropriate communications and assaults against federal judicial officials based upon factors such as the directness or immediacy of the threat. In other related work, efforts to predict case outcomes for a set of 96 FBI cases involving threatening communications have incorporated interviews and automated text processing</context>
</contexts>
<marker>Smith, Shuy, 2002</marker>
<rawString>S Smith and R Shuy. 2002. Forensic psycholinguistics: using language analysis for identifying and assessing offenders. FBI Law Enforcement Bulletin, 71(4):1621.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Smith</author>
</authors>
<title>From violent words to violent deeds: assessing risk from FBI threatening communication cases. Stalking, Threatening, and Attacking Public Figures: a psychological and behavioral analysis,</title>
<date>2008</date>
<pages>435455</pages>
<contexts>
<context position="10059" citStr="Smith, 2008" startWordPosition="1566" endWordPosition="1567">Scalora describes analyzing threatening language towards members of Congress in terms of several thematic areas relating to presence and types of demands (such as policy changes or personal favors) (Scalora et al., 2003), and Calhoun (Calhoun, 1998) examines threatening or inappropriate communications and assaults against federal judicial officials based upon factors such as the directness or immediacy of the threat. In other related work, efforts to predict case outcomes for a set of 96 FBI cases involving threatening communications have incorporated interviews and automated text processing (Smith, 2008) Computational methods have also been applied to the communications of terrorist or radical religious extremist groups to detect aggressive or violent intent, using function word categories (Pennebaker et al., 2008) or frame analysis (Sanfilippo, 2010). 4 Data Our data consisted of 60 documents that were sent to judges in a major metropolitan area in the United States. These documents were genuine, natural, purposeful communications from a sender to at least one judge or court official. They were perceived as threatening, and referred to court security officers for risk assessment. These refer</context>
</contexts>
<marker>Smith, 2008</marker>
<rawString>S Smith. 2008. From violent words to violent deeds: assessing risk from FBI threatening communication cases. Stalking, Threatening, and Attacking Public Figures: a psychological and behavioral analysis, page 435455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Steadman</author>
<author>E P Mulvey</author>
<author>J Monahan</author>
</authors>
<title>Violence by people discharged from acute psychiatric inpatient facilities and by others in the same neighborhoods.</title>
<date>1998</date>
<journal>Archives of General Psychiatry,</journal>
<volume>55</volume>
<issue>5</issue>
<contexts>
<context position="3720" citStr="Steadman et al., 1998" startWordPosition="552" endWordPosition="555">rofessionals, and intelligence analysts. Violence risk assessment is a routine aspect of the work of mental health professionals treating 38 Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 38–45, Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics people with mental illness. While violence against others on the part of people with diagnoses of mental illness is far less prevalent than is popularly thought, the increased risk attributable to these illnesses is barely statistically significant (Steadman et al., 1998; Swanson et al., 1990). This increased risk is largely attributable to a small group of individuals who have a history of childhood or adult antisocial behavior in combination with substance use disorders and psychotic illness (Elbogen and Johnson, 2009). 2.1 Methods and Practice of Violence Risk Assessment Treating clinicians are responsible for evaluating their patients to determine if they pose a risk of violence and adjusting treatment accordingly, or arranging for hospitalization, as needed. The risk of violence, as evidenced by threats or attempts to harm self or others, are two of the </context>
</contexts>
<marker>Steadman, Mulvey, Monahan, 1998</marker>
<rawString>H. J. Steadman, E.P. Mulvey, J. Monahan, and et al. 1998. Violence by people discharged from acute psychiatric inpatient facilities and by others in the same neighborhoods. Archives of General Psychiatry, 55(5):393–401, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Swanson</author>
<author>Charles Holzer</author>
<author>Vijay Ganju</author>
<author>Robert Jono</author>
</authors>
<title>Violence and psychiatric disorder in the community: evidence from the epidemiologic catchment area surveys.</title>
<date>1990</date>
<booktitle>Hospital &amp; community psychiatry,</booktitle>
<tech>PMID:</tech>
<volume>41</volume>
<issue>7</issue>
<pages>2142118</pages>
<contexts>
<context position="3743" citStr="Swanson et al., 1990" startWordPosition="556" endWordPosition="559">ligence analysts. Violence risk assessment is a routine aspect of the work of mental health professionals treating 38 Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 38–45, Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics people with mental illness. While violence against others on the part of people with diagnoses of mental illness is far less prevalent than is popularly thought, the increased risk attributable to these illnesses is barely statistically significant (Steadman et al., 1998; Swanson et al., 1990). This increased risk is largely attributable to a small group of individuals who have a history of childhood or adult antisocial behavior in combination with substance use disorders and psychotic illness (Elbogen and Johnson, 2009). 2.1 Methods and Practice of Violence Risk Assessment Treating clinicians are responsible for evaluating their patients to determine if they pose a risk of violence and adjusting treatment accordingly, or arranging for hospitalization, as needed. The risk of violence, as evidenced by threats or attempts to harm self or others, are two of the bases for hospitalizing</context>
</contexts>
<marker>Swanson, Holzer, Ganju, Jono, 1990</marker>
<rawString>Jeffrey Swanson, Charles Holzer, Vijay Ganju, and Robert Jono. 1990. Violence and psychiatric disorder in the community: evidence from the epidemiologic catchment area surveys. Hospital &amp; community psychiatry, 41(7):761–770, July. PMID: 2142118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Webster</author>
<author>Kevin S Douglas</author>
<author>Derek Eaves</author>
<author>Stephen D Hart</author>
</authors>
<title>Assessing risk for violence, version 2 (hcr-20).</title>
<date>1982</date>
<location>Sigma,</location>
<contexts>
<context position="5833" citStr="Webster et al., 1982" startWordPosition="903" endWordPosition="906">ay be called upon as expert witnesses in civil commitment proceedings or as consultants on such matters. In the criminal justice system, they may be asked to assess the risk of violence in conjunction with the issuance of restraining orders, determination of conditions of bail and probation, and sentencing. While judges make the ultimate decisions, they generally rely highly upon the clinical judgment of MHPs with regard to diagnosis and assessment of the risk of violence. In recent years, a number of tools have been introduced to assist in the assessment of violence risk, such at the HCR-20 (Webster et al., 1982), COVR (Monahan et al., 2006), and VRAG (Quinsey et al., 1998). None of these instruments consider linguistic factors. They utilize actuarial determinations of violence risk. These instruments do not provide strict cutoff scores that differentiate between nonviolent and violent individuals. Rather, they serve as adjunct tools to clinical judgment. As a result, the current best practice in violence risk assessment consists of structured clinical judgment, a process in which actuarial risk assessments are combined with clinical judgment to reach a determination regarding a specific individual’s </context>
</contexts>
<marker>Webster, Douglas, Eaves, Hart, 1982</marker>
<rawString>Christopher D Webster, Kevin S Douglas, Derek Eaves, and Stephen D Hart. 1982. Assessing risk for violence, version 2 (hcr-20). Sigma, 1993:1997.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>