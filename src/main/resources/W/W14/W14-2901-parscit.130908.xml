<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001500">
<title confidence="0.957616">
Augmenting FrameNet Via PPDB
</title>
<author confidence="0.948613">
Pushpendre Rastogi&apos; and Benjamin Van Durme&apos;,2
</author>
<affiliation confidence="0.962441333333333">
&apos;Center for Language and Speech Processing
2Human Language Technology Center of Excellence
Johns Hopkins University
</affiliation>
<email confidence="0.998678">
pushpendre@jhu.edu, vandurme@cs.jhu.edu
</email>
<sectionHeader confidence="0.9939" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999868">
FrameNet is a lexico-semantic dataset that
embodies the theory of frame semantics.
Like other semantic databases, FrameNet
is incomplete. We augment it via the para-
phrase database, PPDB, and gain a three-
fold increase in coverage at 65% precision.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992944481481481">
Frame semantics describes the meaning of a word
in relation to real world events and entities. In
frame semantics the primary unit of lexical analy-
sis is the frame and the lexical unit. A frame aims
to capture the most salient properties of a con-
cept, situation or event. For example, the frame
representing the concept of Abandonment con-
tains eight attributes:1 Agent, Theme, Place,
Time, Manner, Duration, Explanation
and Depictive. A lexical unit is a tuple of three
elements: the lemma of a word, its POS tag and
the associated frame.
FrameNet is large lexico-semantic dataset that
contains manually annotated information includ-
ing frame descriptions, frame-frame relations and
frame annotated sentences. It has been used build
to frame semantic parsers, which are systems that
can analyze a sentence and annotate its words with
the frames that they evoke and the correspond-
ing frame elements. The task of frame seman-
tic parsing was introduced by Gildea and Jurafsky
(2002) and later it matured into a community-wide
shared task (Baker et al., 2007), with CMU’s SE-
MAFOR system being the current state-of-the-art
parser (Das et al., 2013).
Common to rich, manually constructed seman-
tic resources, the coverage of FrameNet across its
</bodyText>
<footnote confidence="0.34585">
1An attribute of a frame is also called a Frame Element.
</footnote>
<bodyText confidence="0.999973263157895">
targetted language (English) is incomplete. State-
of-the-art frame semantic parsers thus employ var-
ious heuristics to identify the frame evoked by
out-of-vocabulary items (OOVs) at test-time.2 For
instance, an OOV if present in WordNet might
be aligned to frame(s) assigned to in-vocabulary
items in shared synsets (see the work by Ferr´andez
et al. (2010) and the related works section therein).
In this work we take a different approach and
attempt to directly increase the coverage of the
FrameNet corpus by automatically expanding the
collection of training examples via PPDB, The
Paraphrase Database (Ganitkevitch et al., 2013).
In Section 2 we analyze FrameNet and com-
ment on the sparsity in its different parts. In Sec-
tion 3 we describe PPDB, and how it was used to
augment FrameNet. We present our evaluation ex-
periments and results in the latter half of the sec-
tion followed by conclusions.
</bodyText>
<sectionHeader confidence="0.972581" genericHeader="method">
2 FrameNet Coverage
</sectionHeader>
<bodyText confidence="0.998683615384615">
FrameNet is a rich semantic resource, yet cur-
rently lacks complete coverage of the language.
In the following we give examples of this incom-
pleteness, in particular the OOV issue that we will
focus on in latter sections.
Frames A frame represents an event, a situ-
ation or a real life concept; FrameNet version
1.5 contains 1,019 such frames. These thou-
sand frames do not cover all possible situa-
tions that we might encounter. For example,
FrameNet does not have a frame for the activity
of Programming even though it has frames for
Creating, Text Creation, etc. The situa-
</bodyText>
<footnote confidence="0.82830775">
2For example the Abandonment frame lacks jettison as
one of its lexical units, and further, that word is not listed
as a lexical unit in FrameNet v1.5, making jettison an OOV.
1
</footnote>
<note confidence="0.560549">
Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 1–5,
</note>
<page confidence="0.354995">
Baltimore, Maryland, USA, June 22-27, 2014. c�2014 Association for Computational Linguistics
</page>
<bodyText confidence="0.994016297297297">
tion of writing a computer program is stereotypi-
cal and attributes that a reader might associate with
such an activity are: agent (who wrote the pro-
gram), language (the programming language
used) and function (the program’s purpose).
Further, FrameNet’s granularity is at times un-
even. For example, the Explosion frame
and the Become Triggered frames do not
have agentive attributes, instead there exist
separate frames Detonate Explosive and
Triggering which have the attributes Agent
and Actor respectively. This suggests a pattern
that events which are frequently described without
an agent are assigned their own frames. However,
there is no Burial frame which focuses on the
event corresponding to frame of Burying, which
itself focuses on the Actor.
This difference in granularity could be resolved
by either making distinctions more evenly fine-
grained: trying to automatically inducing new
frames; or by making things more evenly-coarse
grained: automatically merging existing frames
that are deemed similar. Researchers have ex-
plored methods for automatically learning frames
and on learning collocations of frames to their
syntactic dependent phrases. Recent examples in-
clude using either a Bayesian topic model to learn
clusters of words (O’ Connor, 2012; Materna,
2012), or attempting to learn symbolic concepts
and attributes from dictionary definitions of words
(Orfan and Allen, 2013).
Frame-Frame Relations FrameNet encodes
certain types of correlations between situations
and events by adding defeasible typed-relations
between frames encoding pairwise dependencies.
There are eight types of frame-frame rela-
tions: Inherits from, Perspective on,
</bodyText>
<subsectionHeader confidence="0.825316">
Precedes, Subframe of, See also,
</subsectionHeader>
<bodyText confidence="0.987779306451613">
Uses, Is Inchoative of, and
Is Causative of.3 For example the frame
Being Born is related to Death through the
relation Is Preceded By. Such common-
sense knowledge of event-event relationships
would be of significant utility to general AI,
however it is a large space to fill: with 1,019
frames and 8 binary relations there is a large
upper bound on the number of total possible
3Five frame-frame relations also have an antonym
relation: Is Used by, Is Inherited by,
Is Perspectivized in, Has Subframe(s),
Is Preceded by, however an antonym relation does not
add any extra information over its corresponding relation.
relation pairs, even if not considering the pre-
vious issue of incomplete frame coverage. For
example, the Experience bodily harm and
Hostile encounter frames are not related
through the Is Causative Of relation, even
though it is reasonable to expect that a hostile
encounter would result in bodily harm.4 Though
researchers have used FrameNet relations for
tasks such as recognizing textual entailment
(RTE) (Aharon et al., 2010) and for text under-
standing (Fillmore and Baker, 2001), to the best
of our knowledge there has been no work on
automatically extending frame-frame relations.
Frame Annotated Sentences FrameNet con-
tains annotated sentences providing examples of:
lexical units, frames those lexical units evoked,
and frame elements present in the sentence (along
with additional information). These annotated
sentences can be divided into two types based on
whether all the frame evoking words were marked
as targets or not.
The first type, which we call lexicographic,
contains sentences with a single target per sen-
tence. The second type, called fulltext, contains
sentences that have been annotated more com-
pletely and they contain multiple targets per sen-
tence. There are 4,026 fulltext sentences con-
taining 23,921 targets. This data has proved to
be useful for lexico-semantic tasks like RTE and
paraphrasing e.g. (Aharon et al., 2010; Coyne
and Rambow, 2009). As compared to Prop-
Bank (Palmer et al., 2005), which annotated all
predicates occurring within a collection of pre-
existing documents, FrameNet provides examples,
but not a corpus that allows for directly estimating
relative frequencies.
Frame-Lemma Mappings As said earlier, lexi-
cal units are tuples of the lemma form of a word,
its POS-tag and its associated frame. One compo-
nent of FrameNet is its information about which
words/lemmas prompt a particular frame. An an-
notated word that evokes a frame in a sentence
is referred to as a Target. There are two areas
where these mappings could be incomplete: (1)
lemmas contained within FrameNet may have al-
ternate senses such that they should be placed
in more Frames (or related: a currently missing
frame might then give rise to another sense of
</bodyText>
<footnote confidence="0.807623666666667">
4Reasonable highlights the issue that we would opti-
mally like to know things that are even just possible/not-too-
unlikely, even if not strictly entailed.
</footnote>
<page confidence="0.988652">
2
</page>
<bodyText confidence="0.99991575">
such a lemma); and (2) lemmas from the language
may not be in FrameNet in any form. Most re-
search on mitigating this limitation involves map-
ping FrameNet’s frames to WordNet’s synsets.5
Fossati et al. (2013) explored the feasibility of
crowdsourcing FrameNet coverage, using the dis-
tributed manual labor of Mechanical Turk to com-
plete the lemma coverage.
</bodyText>
<sectionHeader confidence="0.987901" genericHeader="method">
3 Augmenting FrameNet with PPDB
</sectionHeader>
<bodyText confidence="0.999901586206897">
In order to expand the coverage of FrameNet, we
performed an initial study on the use of a new
broad-coverage lexical-semantic resource, PPDB,
to first add new lemmas as potential triggers for
a frame, and then automatically rewrite existing
example sentences with these new triggers. The
eventual goal of would be to enable any existing
FrameNet semantic parser to simply retrain on this
expanded dataset, rather than needing to encode
methods for dynamic OOV-resolution at test-time
(such as employed by SEMAFOR).
PPDB Ganitkevitch et al. (2013) released a large
collection of lexical, phrasal and syntactic para-
phrases6 collectively called PPDB. We used the
lexical rules in PPDB to find potential paraphrases
of target words of frame annotated sentences. A
lexical rule in PPDB looks like the following:
p(e|f)=2.832, p(f|e)=1.551, ...
This rule conveys that the log-probability that
help would be paraphrased by the word assist is
-2.832 but the log probability of assist being para-
phrased as help is -1.551.7 Ganitkevitch et al.
(2013) released quality-sorted subsets of the full
(large) collection, varying in size from S to XXXL
by applying thresholds over a linear combination
of the feature values to prune away low quality
paraphrases. They verified that the average human
judgement score of randomly sampled paraphrases
from smaller sized collections was higher than the
</bodyText>
<footnote confidence="0.9532235">
5It is worth noting that substituting a larger automatically
derived WordNet (as derived in Snow et al. (2004)) could im-
prove the recall of some of the methods which automatically
learn a mapping from FrameNet frames to WordNet synsets.
6Lexical: Two words with the same meaning; phrasal:
two strings of words with the same meaning; syntactic:
strings of surface words and non-terminal categories that have
the same meaning. These strings are templates with the non-
terminals serving the role of constraints over what can go in
the blanks.
7See complete list at http://github.com/
jweese/thrax/wiki/Feature-functions.
</footnote>
<bodyText confidence="0.999907333333333">
average human judgement score of a random sam-
ple from a larger collection.
Approach We used the lexical rules sans fea-
tures along with a 5-gram Kneser-Ney smoothed
language model trained using KenLM (Heafield
et al., 2013) on the raw English sequence of An-
notated Gigaword (Napoles et al., 2012) to para-
phrase the fulltext frame annotated sentences of
FrameNet. We used a combination of the WordNet
morphological analyzer and Morpha8 for lemma-
tization and Morphg9 for generation.
Evaluation We present our evaluation of the
quantity and quality of generated paraphrases in
this section. Note that we did not use syntac-
tic reordering to generate the paraphrases. Also
we paraphrased the frame evoking targets individ-
ually i.e. we did not consider combinations of
paraphrases of individual targets to be a new para-
phrase of a sentence and we ignored those frame
evoking targets that contained multiple words.10
With the above mentioned constraints we
conducted the following experiments with dif-
ferent sizes of PPDB. In Experiment 1 we
generated a set of candidate paraphrases for
every target word in a sentence by directly
querying that word and its dictionary form in
PPDB. In Experiment 2 we first enlarged the set
of lexical units mapped to a frame by merging
lexical units of frames that were related to the
target word’s frame through either of the fol-
lowing relations: Is Perspectivized In,
Is Inherited By, Has Subframe (s).
For example, if frame A has a subframe B then
lexical units mapped to A can evoke B. We then
queried PPDB to gather paraphrases for all the
lexical units collected so far. This experiment
simulates the situation where a frame has been
mapped to a set of words, e.g. synsets in WordNet,
so that every word in that larger set is a paraphrase
of any word that evokes a frame. This procedure
increases the average number of paraphrases
mapped to a frame and we present those averages
in Table 1.
For both these experiments we also calculated
the incremental benefit of PPDB over WordNet by
</bodyText>
<footnote confidence="0.998287428571429">
8http://ilexir.co.uk/applications/
rasp/download
9http://cl.naist.jp/˜eric-n/
ubuntu-nlp/pool/hardy/english/morph_
0.0.20030918-2nlp1˜0hardy1.tar.gz
10Among fulltext sentences less than 3% of targets con-
tained multiple tokens.
</footnote>
<page confidence="0.995151">
3
</page>
<table confidence="0.628072">
Database Lexical Unit/Frame
Framenet 20.24
PPDB S 23.15
PPDB M 32.00
PPDB L 74.08
PPDB XL 214.99
</table>
<tableCaption confidence="0.9972965">
Table 1: Average count of lexical units per frame for differ-
ent sizes of PPDB in experiment 2.
</tableCaption>
<table confidence="0.99701">
The General Assembly should set aside money for a
new state health lab , millions of doses of antiviral
drugs and a fund to help meet basic needs after a disas-
ter , a legislative panel recommended Thursday .
1: The General Assembly should set aside cash ...
2: The General Assembly should set aside fund ...
1: The General Assembly should set aside dough ...
3: The General Assembly should set aside silver ...
</table>
<tableCaption confidence="0.9880045">
Table 2: Examples and their judgements, with the last being
debatable.
</tableCaption>
<bodyText confidence="0.9848698">
filtering out paraphrases that could have been re-
trieved as synonyms11 from WordNet v3.0. The
results of these experiments are in Table 3.
To evaluate the quality of our additional output
over WordNet we assigned one of the following
labels to 25 paraphrase sets generated at the end of
Experiment 1b12: 1, the paraphrase (a) invoked the
correct frame and (b) was grammatical; or 2, only
(a) held; or 3, (a) did not hold. Table 4 presents
aggregates over the labels.
</bodyText>
<table confidence="0.9619332">
PPDB 1a 1b 2a 2b
S 4,582 2,574 1,064,926 1,022,533
M 15,459 9,752 1,314,169 1,263,087
L 73,763 55,517 2,417,760 2,347,656
XL 340,406 283,126 – –
</table>
<tableCaption confidence="0.9356342">
Table 3: The total number of paraphrases generated for the
23,226 input targets versus different sizes of PPDB. The para-
phrase count excludes the input. Column 1a and 2a represent
unfiltered paraphrases as opposed to 1b and 2b where they
have been filtered using WordNet v3.0.
</tableCaption>
<sectionHeader confidence="0.990151" genericHeader="method">
4 Discussion And Conclusion
</sectionHeader>
<bodyText confidence="0.999628833333333">
We presented initial experiments on using PPDB
to automatically expand FrameNet through para-
phrastic re-writing. We found that over a sample
of 25 target words the top three paraphrases pro-
duced by PPDB XL evoked the correct frame and
were grammatical 65% of the time.13 However,
</bodyText>
<footnote confidence="0.973931625">
11Two lemmas that appear in the same synset at least once
are synonyms in our experiments.
12Experiment 2 generated significantly more candidates;
here we consider only the potential scope of expansion and
rely on Experiment 1 to gauge the likely paraphrase quality.
13We have released the generated corpus as well as the
manual annotations at cs.jhu.edu/˜prastog3/res/
fnppdb.html
</footnote>
<table confidence="0.999928444444445">
PPDB Size 1 2 3 %(1+2) %(1)
S 0 0 0 – –
M 6 1 2 77.77 66.67
L 27 15 11 86.25 50.94
L rank 3 23 12 7 83.33 54.76
XL 110 85 50 79.60 44.89
XL rank 3 47 16 9 87.5 65.27
XL rank 5 69 28 13 88.18 62.72
XL rank 10 105 52 32 83.07 55.55
</table>
<tableCaption confidence="0.811757428571428">
Table 4: Average quality of all paraphrases for 25 ran-
dom sentences. Rows marked A rank B convey that we used
PPDB of size A and kept only the top B sentences after sorting
them by their language model score. Column %(1) indicates
the percentage of output which was grammatical and evoked
the correct frame. Column%(1+2) represents the output that
evoked the correct frame.
</tableCaption>
<bodyText confidence="0.999694783783784">
work remains in recognizing the contexts in which
a paraphrase is appropriately applied, and in im-
proving the quality of PPDB itself.
Upon error analysis, we found two major rea-
sons for ungrammaticality of lexical paraphrases.
First: within FrameNet some sentences will have
a single token annotated as trigger, when in fact it
is part of a multi-word expression. For example, it
was grammatically infelicitous to replace part by
portion in the expression part of the answer. The
other major source of error was the inaccuracy in
PPDB itself. We found that for a large number of
cases when PPDB XL did not have a high number
of paraphrases the paraphrases were wrong (e.g.,
PPDB XL had only 2 paraphrases for the words
lab and millions.)
Going forward we aim to increase the precision
of our paraphrases and our ability to recognize
their appropriate contexts for application. Fur-
ther, we wish to augment additional resources in
a similar way, for example PropBank or the ACE
corpus (Walker et al., 2006). We should be able
to increase the precision by using the paraphrase
probability features of a PPDB rule and by using
better language models with lower perplexity than
n-grams e.g. recurrent neural net based language
models. Improving the accuracy of PPDB, espe-
cially in the large settings, would be another fo-
cus area. Also, we would use Amazon Mechani-
cal Turk to evaluate the quality of a larger set of
paraphrases to make our evaluation robust and so
that we can evaluate the efficacy of our second ex-
periment.
Acknowledgments This material is based on re-
search sponsored by the NSF under grant IIS-
1249516 and DARPA under agreement number
FA8750-13-2-0017.
</bodyText>
<page confidence="0.996866">
4
</page>
<sectionHeader confidence="0.99022" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999866471428571">
Roni Ben Aharon, Idan Szpektor, and Ido Dagan.
2010. Generating entailment rules from framenet.
In Proceedings of the ACL 2010 Conference Short
Papers, pages 241–246.
Collin Baker, Michael Ellsworth, and Katrin Erk.
2007. Semeval’07 task 19: frame semantic structure
extraction. In Proceedings of the 4th International
Workshop on Semantic Evaluations, pages 99–104.
ACL.
Bob Coyne and Owen Rambow. 2009. Lexpar: A
freely available english paraphrase lexicon automat-
ically extracted from framenet. 2012 IEEE Sixth
International Conference on Semantic Computing,
pages 53–58.
Dipanjan Das, Desai Chen, Andr´e F. T. Martins,
Nathan Schneider, and Noah A. Smith. 2013.
Frame-semantic parsing. Computational Linguis-
tics, 40(1):9–56.
Oscar Ferr´andez, Michael Ellsworth, Rafael Munoz,
and Collin F Baker. 2010. Aligning framenet
and wordnet based on semantic neighborhoods. In
LREC, volume 10, pages 310–314.
Charles J Fillmore and Collin F Baker. 2001. Frame
semantics for text understanding. In Proceedings
of WordNet and Other Lexical Resources Workshop,
NAACL.
Marco Fossati, Claudio Giuliano, and Sara Tonelli.
2013. Outsourcing framenet to the crowd. In Pro-
ceedings of the 51st Annual Meeting of the ACL,
pages 742–747.
Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Proceedings of NAACL-HLT, pages
758–764, Atlanta, Georgia, June. ACL.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational linguis-
tics, 28(3):245–288.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the ACL,
Sofia, Bulgaria.
Jiˇr´ı Materna. 2012. Lda-frames: An unsupervised ap-
proach to generating semantic frames. In Compu-
tational Linguistics and Intelligent Text Processing,
volume 7181 of Lecture Notes in Computer Science,
pages 376–387. Springer Berlin Heidelberg.
Courtney Napoles, Matthew Gormley, and Benjamin
Van Durme. 2012. Annotated gigaword. In Pro-
ceedings of the Joint Workshop on Automatic Knowl-
edge Base Construction and Web-scale Knowledge
Extraction, pages 95–100. ACL.
Brendan O’ Connor. 2012. Learning frames from text
with an unsupervised latent variable model. In Tech-
nical Report. Carnegie Mellon University.
Jansen Orfan and James Allen. 2013. Toward learning
high-level semantic frames from definitions. In Pro-
ceedings of the Second Annual Conference on Ad-
vances in Cognitive Systems, volume 125.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.
Rion Snow, Daniel Jurafsky, and Andrew Y Ng. 2004.
Learning syntactic patterns for automatic hypernym
discovery. In NIPS, volume 17, pages 1297–1304.
Christopher Walker, Stephanie Strassel, Julie Medero,
and Kazuaki Maeda. 2006. Ace 2005 multilin-
gual training corpus. Linguistic Data Consortium,
Philadelphia.
</reference>
<page confidence="0.994329">
5
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.594836">
<title confidence="0.999553">Augmenting FrameNet Via PPDB</title>
<author confidence="0.904301">Van</author>
<title confidence="0.7919135">for Language and Speech Language Technology Center of</title>
<author confidence="0.825285">Johns Hopkins</author>
<email confidence="0.999803">pushpendre@jhu.edu,vandurme@cs.jhu.edu</email>
<abstract confidence="0.989552">FrameNet is a lexico-semantic dataset that embodies the theory of frame semantics. Like other semantic databases, FrameNet is incomplete. We augment it via the paraphrase database, PPDB, and gain a threefold increase in coverage at 65% precision.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roni Ben Aharon</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Generating entailment rules from framenet.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>241--246</pages>
<contexts>
<context position="6408" citStr="Aharon et al., 2010" startWordPosition="998" endWordPosition="1001">relation: Is Used by, Is Inherited by, Is Perspectivized in, Has Subframe(s), Is Preceded by, however an antonym relation does not add any extra information over its corresponding relation. relation pairs, even if not considering the previous issue of incomplete frame coverage. For example, the Experience bodily harm and Hostile encounter frames are not related through the Is Causative Of relation, even though it is reasonable to expect that a hostile encounter would result in bodily harm.4 Though researchers have used FrameNet relations for tasks such as recognizing textual entailment (RTE) (Aharon et al., 2010) and for text understanding (Fillmore and Baker, 2001), to the best of our knowledge there has been no work on automatically extending frame-frame relations. Frame Annotated Sentences FrameNet contains annotated sentences providing examples of: lexical units, frames those lexical units evoked, and frame elements present in the sentence (along with additional information). These annotated sentences can be divided into two types based on whether all the frame evoking words were marked as targets or not. The first type, which we call lexicographic, contains sentences with a single target per sent</context>
</contexts>
<marker>Aharon, Szpektor, Dagan, 2010</marker>
<rawString>Roni Ben Aharon, Idan Szpektor, and Ido Dagan. 2010. Generating entailment rules from framenet. In Proceedings of the ACL 2010 Conference Short Papers, pages 241–246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin Baker</author>
<author>Michael Ellsworth</author>
<author>Katrin Erk</author>
</authors>
<title>Semeval’07 task 19: frame semantic structure extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>99--104</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1555" citStr="Baker et al., 2007" startWordPosition="237" endWordPosition="240"> A lexical unit is a tuple of three elements: the lemma of a word, its POS tag and the associated frame. FrameNet is large lexico-semantic dataset that contains manually annotated information including frame descriptions, frame-frame relations and frame annotated sentences. It has been used build to frame semantic parsers, which are systems that can analyze a sentence and annotate its words with the frames that they evoke and the corresponding frame elements. The task of frame semantic parsing was introduced by Gildea and Jurafsky (2002) and later it matured into a community-wide shared task (Baker et al., 2007), with CMU’s SEMAFOR system being the current state-of-the-art parser (Das et al., 2013). Common to rich, manually constructed semantic resources, the coverage of FrameNet across its 1An attribute of a frame is also called a Frame Element. targetted language (English) is incomplete. Stateof-the-art frame semantic parsers thus employ various heuristics to identify the frame evoked by out-of-vocabulary items (OOVs) at test-time.2 For instance, an OOV if present in WordNet might be aligned to frame(s) assigned to in-vocabulary items in shared synsets (see the work by Ferr´andez et al. (2010) and </context>
</contexts>
<marker>Baker, Ellsworth, Erk, 2007</marker>
<rawString>Collin Baker, Michael Ellsworth, and Katrin Erk. 2007. Semeval’07 task 19: frame semantic structure extraction. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 99–104. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coyne</author>
<author>Owen Rambow</author>
</authors>
<title>Lexpar: A freely available english paraphrase lexicon automatically extracted from framenet.</title>
<date>2009</date>
<booktitle>IEEE Sixth International Conference on Semantic Computing,</booktitle>
<pages>53--58</pages>
<contexts>
<context position="7354" citStr="Coyne and Rambow, 2009" startWordPosition="1145" endWordPosition="1148">n the sentence (along with additional information). These annotated sentences can be divided into two types based on whether all the frame evoking words were marked as targets or not. The first type, which we call lexicographic, contains sentences with a single target per sentence. The second type, called fulltext, contains sentences that have been annotated more completely and they contain multiple targets per sentence. There are 4,026 fulltext sentences containing 23,921 targets. This data has proved to be useful for lexico-semantic tasks like RTE and paraphrasing e.g. (Aharon et al., 2010; Coyne and Rambow, 2009). As compared to PropBank (Palmer et al., 2005), which annotated all predicates occurring within a collection of preexisting documents, FrameNet provides examples, but not a corpus that allows for directly estimating relative frequencies. Frame-Lemma Mappings As said earlier, lexical units are tuples of the lemma form of a word, its POS-tag and its associated frame. One component of FrameNet is its information about which words/lemmas prompt a particular frame. An annotated word that evokes a frame in a sentence is referred to as a Target. There are two areas where these mappings could be inco</context>
</contexts>
<marker>Coyne, Rambow, 2009</marker>
<rawString>Bob Coyne and Owen Rambow. 2009. Lexpar: A freely available english paraphrase lexicon automatically extracted from framenet. 2012 IEEE Sixth International Conference on Semantic Computing, pages 53–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Desai Chen</author>
<author>Andr´e F T Martins</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Frame-semantic parsing.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>40</volume>
<issue>1</issue>
<contexts>
<context position="1643" citStr="Das et al., 2013" startWordPosition="251" endWordPosition="254">ociated frame. FrameNet is large lexico-semantic dataset that contains manually annotated information including frame descriptions, frame-frame relations and frame annotated sentences. It has been used build to frame semantic parsers, which are systems that can analyze a sentence and annotate its words with the frames that they evoke and the corresponding frame elements. The task of frame semantic parsing was introduced by Gildea and Jurafsky (2002) and later it matured into a community-wide shared task (Baker et al., 2007), with CMU’s SEMAFOR system being the current state-of-the-art parser (Das et al., 2013). Common to rich, manually constructed semantic resources, the coverage of FrameNet across its 1An attribute of a frame is also called a Frame Element. targetted language (English) is incomplete. Stateof-the-art frame semantic parsers thus employ various heuristics to identify the frame evoked by out-of-vocabulary items (OOVs) at test-time.2 For instance, an OOV if present in WordNet might be aligned to frame(s) assigned to in-vocabulary items in shared synsets (see the work by Ferr´andez et al. (2010) and the related works section therein). In this work we take a different approach and attemp</context>
</contexts>
<marker>Das, Chen, Martins, Schneider, Smith, 2013</marker>
<rawString>Dipanjan Das, Desai Chen, Andr´e F. T. Martins, Nathan Schneider, and Noah A. Smith. 2013. Frame-semantic parsing. Computational Linguistics, 40(1):9–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Ferr´andez</author>
<author>Michael Ellsworth</author>
<author>Rafael Munoz</author>
<author>Collin F Baker</author>
</authors>
<title>Aligning framenet and wordnet based on semantic neighborhoods.</title>
<date>2010</date>
<booktitle>In LREC,</booktitle>
<volume>10</volume>
<pages>310--314</pages>
<marker>Ferr´andez, Ellsworth, Munoz, Baker, 2010</marker>
<rawString>Oscar Ferr´andez, Michael Ellsworth, Rafael Munoz, and Collin F Baker. 2010. Aligning framenet and wordnet based on semantic neighborhoods. In LREC, volume 10, pages 310–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Collin F Baker</author>
</authors>
<title>Frame semantics for text understanding.</title>
<date>2001</date>
<booktitle>In Proceedings of WordNet and Other Lexical Resources Workshop,</booktitle>
<location>NAACL.</location>
<contexts>
<context position="6462" citStr="Fillmore and Baker, 2001" startWordPosition="1007" endWordPosition="1010">tivized in, Has Subframe(s), Is Preceded by, however an antonym relation does not add any extra information over its corresponding relation. relation pairs, even if not considering the previous issue of incomplete frame coverage. For example, the Experience bodily harm and Hostile encounter frames are not related through the Is Causative Of relation, even though it is reasonable to expect that a hostile encounter would result in bodily harm.4 Though researchers have used FrameNet relations for tasks such as recognizing textual entailment (RTE) (Aharon et al., 2010) and for text understanding (Fillmore and Baker, 2001), to the best of our knowledge there has been no work on automatically extending frame-frame relations. Frame Annotated Sentences FrameNet contains annotated sentences providing examples of: lexical units, frames those lexical units evoked, and frame elements present in the sentence (along with additional information). These annotated sentences can be divided into two types based on whether all the frame evoking words were marked as targets or not. The first type, which we call lexicographic, contains sentences with a single target per sentence. The second type, called fulltext, contains sente</context>
</contexts>
<marker>Fillmore, Baker, 2001</marker>
<rawString>Charles J Fillmore and Collin F Baker. 2001. Frame semantics for text understanding. In Proceedings of WordNet and Other Lexical Resources Workshop, NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Fossati</author>
<author>Claudio Giuliano</author>
<author>Sara Tonelli</author>
</authors>
<title>Outsourcing framenet to the crowd.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the ACL,</booktitle>
<pages>742--747</pages>
<contexts>
<context position="8514" citStr="Fossati et al. (2013)" startWordPosition="1339" endWordPosition="1342">arget. There are two areas where these mappings could be incomplete: (1) lemmas contained within FrameNet may have alternate senses such that they should be placed in more Frames (or related: a currently missing frame might then give rise to another sense of 4Reasonable highlights the issue that we would optimally like to know things that are even just possible/not-toounlikely, even if not strictly entailed. 2 such a lemma); and (2) lemmas from the language may not be in FrameNet in any form. Most research on mitigating this limitation involves mapping FrameNet’s frames to WordNet’s synsets.5 Fossati et al. (2013) explored the feasibility of crowdsourcing FrameNet coverage, using the distributed manual labor of Mechanical Turk to complete the lemma coverage. 3 Augmenting FrameNet with PPDB In order to expand the coverage of FrameNet, we performed an initial study on the use of a new broad-coverage lexical-semantic resource, PPDB, to first add new lemmas as potential triggers for a frame, and then automatically rewrite existing example sentences with these new triggers. The eventual goal of would be to enable any existing FrameNet semantic parser to simply retrain on this expanded dataset, rather than n</context>
</contexts>
<marker>Fossati, Giuliano, Tonelli, 2013</marker>
<rawString>Marco Fossati, Claudio Giuliano, and Sara Tonelli. 2013. Outsourcing framenet to the crowd. In Proceedings of the 51st Annual Meeting of the ACL, pages 742–747.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Benjamin Van Durme</author>
<author>Chris Callison-Burch</author>
</authors>
<title>PPDB: The paraphrase database.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>758--764</pages>
<publisher>ACL.</publisher>
<location>Atlanta, Georgia,</location>
<marker>Ganitkevitch, Van Durme, Callison-Burch, 2013</marker>
<rawString>Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. 2013. PPDB: The paraphrase database. In Proceedings of NAACL-HLT, pages 758–764, Atlanta, Georgia, June. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational linguistics,</journal>
<pages>28--3</pages>
<contexts>
<context position="1479" citStr="Gildea and Jurafsky (2002)" startWordPosition="224" endWordPosition="227">ttributes:1 Agent, Theme, Place, Time, Manner, Duration, Explanation and Depictive. A lexical unit is a tuple of three elements: the lemma of a word, its POS tag and the associated frame. FrameNet is large lexico-semantic dataset that contains manually annotated information including frame descriptions, frame-frame relations and frame annotated sentences. It has been used build to frame semantic parsers, which are systems that can analyze a sentence and annotate its words with the frames that they evoke and the corresponding frame elements. The task of frame semantic parsing was introduced by Gildea and Jurafsky (2002) and later it matured into a community-wide shared task (Baker et al., 2007), with CMU’s SEMAFOR system being the current state-of-the-art parser (Das et al., 2013). Common to rich, manually constructed semantic resources, the coverage of FrameNet across its 1An attribute of a frame is also called a Frame Element. targetted language (English) is incomplete. Stateof-the-art frame semantic parsers thus employ various heuristics to identify the frame evoked by out-of-vocabulary items (OOVs) at test-time.2 For instance, an OOV if present in WordNet might be aligned to frame(s) assigned to in-vocab</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Ivan Pouzyrevsky</author>
<author>Jonathan H Clark</author>
<author>Philipp Koehn</author>
</authors>
<title>Scalable modified Kneser-Ney language model estimation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the ACL,</booktitle>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="10916" citStr="Heafield et al., 2013" startWordPosition="1713" endWordPosition="1716">to WordNet synsets. 6Lexical: Two words with the same meaning; phrasal: two strings of words with the same meaning; syntactic: strings of surface words and non-terminal categories that have the same meaning. These strings are templates with the nonterminals serving the role of constraints over what can go in the blanks. 7See complete list at http://github.com/ jweese/thrax/wiki/Feature-functions. average human judgement score of a random sample from a larger collection. Approach We used the lexical rules sans features along with a 5-gram Kneser-Ney smoothed language model trained using KenLM (Heafield et al., 2013) on the raw English sequence of Annotated Gigaword (Napoles et al., 2012) to paraphrase the fulltext frame annotated sentences of FrameNet. We used a combination of the WordNet morphological analyzer and Morpha8 for lemmatization and Morphg9 for generation. Evaluation We present our evaluation of the quantity and quality of generated paraphrases in this section. Note that we did not use syntactic reordering to generate the paraphrases. Also we paraphrased the frame evoking targets individually i.e. we did not consider combinations of paraphrases of individual targets to be a new paraphrase of </context>
</contexts>
<marker>Heafield, Pouzyrevsky, Clark, Koehn, 2013</marker>
<rawString>Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013. Scalable modified Kneser-Ney language model estimation. In Proceedings of the 51st Annual Meeting of the ACL, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiˇr´ı Materna</author>
</authors>
<title>Lda-frames: An unsupervised approach to generating semantic frames.</title>
<date>2012</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<volume>7181</volume>
<pages>376--387</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="4946" citStr="Materna, 2012" startWordPosition="776" endWordPosition="777">ocuses on the event corresponding to frame of Burying, which itself focuses on the Actor. This difference in granularity could be resolved by either making distinctions more evenly finegrained: trying to automatically inducing new frames; or by making things more evenly-coarse grained: automatically merging existing frames that are deemed similar. Researchers have explored methods for automatically learning frames and on learning collocations of frames to their syntactic dependent phrases. Recent examples include using either a Bayesian topic model to learn clusters of words (O’ Connor, 2012; Materna, 2012), or attempting to learn symbolic concepts and attributes from dictionary definitions of words (Orfan and Allen, 2013). Frame-Frame Relations FrameNet encodes certain types of correlations between situations and events by adding defeasible typed-relations between frames encoding pairwise dependencies. There are eight types of frame-frame relations: Inherits from, Perspective on, Precedes, Subframe of, See also, Uses, Is Inchoative of, and Is Causative of.3 For example the frame Being Born is related to Death through the relation Is Preceded By. Such commonsense knowledge of event-event relatio</context>
</contexts>
<marker>Materna, 2012</marker>
<rawString>Jiˇr´ı Materna. 2012. Lda-frames: An unsupervised approach to generating semantic frames. In Computational Linguistics and Intelligent Text Processing, volume 7181 of Lecture Notes in Computer Science, pages 376–387. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Napoles</author>
<author>Matthew Gormley</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Annotated gigaword.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction,</booktitle>
<pages>95--100</pages>
<publisher>ACL.</publisher>
<marker>Napoles, Gormley, Van Durme, 2012</marker>
<rawString>Courtney Napoles, Matthew Gormley, and Benjamin Van Durme. 2012. Annotated gigaword. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pages 95–100. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’ Connor</author>
</authors>
<title>Learning frames from text with an unsupervised latent variable model.</title>
<date>2012</date>
<booktitle>In Technical Report.</booktitle>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="4930" citStr="Connor, 2012" startWordPosition="774" endWordPosition="775"> frame which focuses on the event corresponding to frame of Burying, which itself focuses on the Actor. This difference in granularity could be resolved by either making distinctions more evenly finegrained: trying to automatically inducing new frames; or by making things more evenly-coarse grained: automatically merging existing frames that are deemed similar. Researchers have explored methods for automatically learning frames and on learning collocations of frames to their syntactic dependent phrases. Recent examples include using either a Bayesian topic model to learn clusters of words (O’ Connor, 2012; Materna, 2012), or attempting to learn symbolic concepts and attributes from dictionary definitions of words (Orfan and Allen, 2013). Frame-Frame Relations FrameNet encodes certain types of correlations between situations and events by adding defeasible typed-relations between frames encoding pairwise dependencies. There are eight types of frame-frame relations: Inherits from, Perspective on, Precedes, Subframe of, See also, Uses, Is Inchoative of, and Is Causative of.3 For example the frame Being Born is related to Death through the relation Is Preceded By. Such commonsense knowledge of eve</context>
</contexts>
<marker>Connor, 2012</marker>
<rawString>Brendan O’ Connor. 2012. Learning frames from text with an unsupervised latent variable model. In Technical Report. Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jansen Orfan</author>
<author>James Allen</author>
</authors>
<title>Toward learning high-level semantic frames from definitions.</title>
<date>2013</date>
<booktitle>In Proceedings of the Second Annual Conference on Advances in Cognitive Systems,</booktitle>
<volume>volume</volume>
<pages>125</pages>
<contexts>
<context position="5064" citStr="Orfan and Allen, 2013" startWordPosition="791" endWordPosition="794">ranularity could be resolved by either making distinctions more evenly finegrained: trying to automatically inducing new frames; or by making things more evenly-coarse grained: automatically merging existing frames that are deemed similar. Researchers have explored methods for automatically learning frames and on learning collocations of frames to their syntactic dependent phrases. Recent examples include using either a Bayesian topic model to learn clusters of words (O’ Connor, 2012; Materna, 2012), or attempting to learn symbolic concepts and attributes from dictionary definitions of words (Orfan and Allen, 2013). Frame-Frame Relations FrameNet encodes certain types of correlations between situations and events by adding defeasible typed-relations between frames encoding pairwise dependencies. There are eight types of frame-frame relations: Inherits from, Perspective on, Precedes, Subframe of, See also, Uses, Is Inchoative of, and Is Causative of.3 For example the frame Being Born is related to Death through the relation Is Preceded By. Such commonsense knowledge of event-event relationships would be of significant utility to general AI, however it is a large space to fill: with 1,019 frames and 8 bin</context>
</contexts>
<marker>Orfan, Allen, 2013</marker>
<rawString>Jansen Orfan and James Allen. 2013. Toward learning high-level semantic frames from definitions. In Proceedings of the Second Annual Conference on Advances in Cognitive Systems, volume 125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="7401" citStr="Palmer et al., 2005" startWordPosition="1154" endWordPosition="1157">. These annotated sentences can be divided into two types based on whether all the frame evoking words were marked as targets or not. The first type, which we call lexicographic, contains sentences with a single target per sentence. The second type, called fulltext, contains sentences that have been annotated more completely and they contain multiple targets per sentence. There are 4,026 fulltext sentences containing 23,921 targets. This data has proved to be useful for lexico-semantic tasks like RTE and paraphrasing e.g. (Aharon et al., 2010; Coyne and Rambow, 2009). As compared to PropBank (Palmer et al., 2005), which annotated all predicates occurring within a collection of preexisting documents, FrameNet provides examples, but not a corpus that allows for directly estimating relative frequencies. Frame-Lemma Mappings As said earlier, lexical units are tuples of the lemma form of a word, its POS-tag and its associated frame. One component of FrameNet is its information about which words/lemmas prompt a particular frame. An annotated word that evokes a frame in a sentence is referred to as a Target. There are two areas where these mappings could be incomplete: (1) lemmas contained within FrameNet ma</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning syntactic patterns for automatic hypernym discovery.</title>
<date>2004</date>
<booktitle>In NIPS,</booktitle>
<volume>17</volume>
<pages>1297--1304</pages>
<contexts>
<context position="10187" citStr="Snow et al. (2004)" startWordPosition="1600" endWordPosition="1603">ability that help would be paraphrased by the word assist is -2.832 but the log probability of assist being paraphrased as help is -1.551.7 Ganitkevitch et al. (2013) released quality-sorted subsets of the full (large) collection, varying in size from S to XXXL by applying thresholds over a linear combination of the feature values to prune away low quality paraphrases. They verified that the average human judgement score of randomly sampled paraphrases from smaller sized collections was higher than the 5It is worth noting that substituting a larger automatically derived WordNet (as derived in Snow et al. (2004)) could improve the recall of some of the methods which automatically learn a mapping from FrameNet frames to WordNet synsets. 6Lexical: Two words with the same meaning; phrasal: two strings of words with the same meaning; syntactic: strings of surface words and non-terminal categories that have the same meaning. These strings are templates with the nonterminals serving the role of constraints over what can go in the blanks. 7See complete list at http://github.com/ jweese/thrax/wiki/Feature-functions. average human judgement score of a random sample from a larger collection. Approach We used t</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2004</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y Ng. 2004. Learning syntactic patterns for automatic hypernym discovery. In NIPS, volume 17, pages 1297–1304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Walker</author>
<author>Stephanie Strassel</author>
<author>Julie Medero</author>
<author>Kazuaki Maeda</author>
</authors>
<title>multilingual training corpus. Linguistic Data Consortium,</title>
<date>2006</date>
<journal>Ace</journal>
<contexts>
<context position="16802" citStr="Walker et al., 2006" startWordPosition="2713" endWordPosition="2716">grammatically infelicitous to replace part by portion in the expression part of the answer. The other major source of error was the inaccuracy in PPDB itself. We found that for a large number of cases when PPDB XL did not have a high number of paraphrases the paraphrases were wrong (e.g., PPDB XL had only 2 paraphrases for the words lab and millions.) Going forward we aim to increase the precision of our paraphrases and our ability to recognize their appropriate contexts for application. Further, we wish to augment additional resources in a similar way, for example PropBank or the ACE corpus (Walker et al., 2006). We should be able to increase the precision by using the paraphrase probability features of a PPDB rule and by using better language models with lower perplexity than n-grams e.g. recurrent neural net based language models. Improving the accuracy of PPDB, especially in the large settings, would be another focus area. Also, we would use Amazon Mechanical Turk to evaluate the quality of a larger set of paraphrases to make our evaluation robust and so that we can evaluate the efficacy of our second experiment. Acknowledgments This material is based on research sponsored by the NSF under grant I</context>
</contexts>
<marker>Walker, Strassel, Medero, Maeda, 2006</marker>
<rawString>Christopher Walker, Stephanie Strassel, Julie Medero, and Kazuaki Maeda. 2006. Ace 2005 multilingual training corpus. Linguistic Data Consortium,</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>