<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000100">
<title confidence="0.990574">
Structuring Operative Notes using Active Learning
</title>
<author confidence="0.948638">
Kirk Roberts∗
</author>
<affiliation confidence="0.8103975">
National Library of Medicine
National Institutes of Health
</affiliation>
<address confidence="0.462847">
Bethesda, MD 20894
</address>
<email confidence="0.98688">
kirk.roberts@nih.gov
</email>
<author confidence="0.986793">
Sanda M. Harabagiu
</author>
<affiliation confidence="0.9897995">
Human Language Technology Research Institute
University of Texas at Dallas
</affiliation>
<address confidence="0.792728">
Richardson, TX 75080
</address>
<email confidence="0.997591">
sanda@hlt.utdallas.edu
</email>
<author confidence="0.98356">
Michael A. Skinner
</author>
<affiliation confidence="0.88748">
University of Texas Southwestern Medical Center
Children’s Medical Center of Dallas
</affiliation>
<address confidence="0.815462">
Dallas, TX 75235
</address>
<email confidence="0.996866">
michael.skinner@childrens.com
</email>
<sectionHeader confidence="0.998585" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999969727272727">
We present an active learning method for
placing the event mentions in an operative
note into a pre-specified event structure.
Event mentions are first classified into ac-
tion, peripheral action, observation, and
report events. The actions are further clas-
sified into their appropriate location within
the event structure. We examine how uti-
lizing active learning significantly reduces
the time needed to completely annotate a
corpus of 2,820 appendectomy notes.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99119462962963">
Operative reports are written or dictated after ev-
ery surgical procedure. They describe the course
of the operation as well as any abnormal find-
ings in the surgical process. Template-based and
structured methods exist for recording the opera-
tive note (DeOrio, 2002), and in many cases have
been shown to increase the completeness of sur-
gical information (Park et al., 2010; Gur et al.,
2011; Donahoe et al., 2012). The use of natural
language, however, is still preferred for its expres-
sive power. This unstructured information is typi-
cally the only vehicle for conveying important de-
tails of the procedure, including the surgical in-
struments, incision techniques, and laparoscopic
methods employed.
The ability to represent and extract the infor-
mation found within operative notes would enable
∗ Most of this work was performed while KR was at the
University of Texas at Dallas.
powerful post-hoc reasoning methods about surgi-
cal procedures. First, the completeness problem
may be alleviated by indicating gaps in the sur-
gical narrative. Second, deep semantic similarity
methods could be used to discover comparable op-
erations across surgeons and institutions. Third,
given information on the typical course and find-
ings of a procedure, abnormal aspects of an oper-
ation could be identified and investigated. Finally,
other secondary use applications would be enabled
to study the most effective instruments and tech-
niques across large amounts of surgical data.
In this paper, we present an initial method for
aligning the event mentions within an operative
note to the overall event structure for a procedure.
A surgeon with experience in a particular proce-
dure first describes the overall event structure. A
supervised method enhanced by active learning is
then employed to rapidly build an information ex-
traction model to classify event mentions into the
event structure. This active learning paradigm al-
lows for rapid prototyping while also taking ad-
vantage of the sub-language characteristics of op-
erative notes and the common structure of opera-
tive notes reporting the same type of procedure. A
further goal of this method is to aid in the eval-
uation of unsupervised techniques that can auto-
matically discover the event structure solely from
the narratives. This would enable all the objectives
outlined above for leveraging the unstructured in-
formation within operative notes.
This paper presents a first attempt at this ac-
tive learning paradigm for structuring appendec-
tomy reports. We intentionally chose a well-
understood and relatively simple procedure to en-
</bodyText>
<page confidence="0.991808">
68
</page>
<note confidence="0.7875095">
Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 68–76,
Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999909615384615">
sure a straight-forward, largely linear event struc-
ture where a large amount of data would be eas-
ily available. Section 3 describes a generic frame-
work for surgical event structures and the particu-
lar structure chosen for appendectomies. Section 4
details the data used in this study. Section 5 de-
scribes the active learning experiment for filling in
this event structure for operative notes. Section 6
reports the results of this experiment. Section 7
analyzes the method and proposes avenues for fur-
ther research. First, however, we outline the small
amount of previous work in natural language pro-
cessing on operative notes.
</bodyText>
<sectionHeader confidence="0.998946" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999789338028169">
An early tool for processing operative notes was
proposed by Lamiell et al. (1993). They develop
an auditing tool to help enforce completeness in
operative notes. A syntactic parser converts sen-
tences in an operative note into a graph structure
that can be queried to ensure the necessary surgical
elements are present in the narrative. For appen-
dectomies, they could determine whether answers
were specified for questions such as “What was
the appendix abnormality?” and “Was cautery or
drains used?”. Unlike what we propose, they did
not attempt to understand the narrative structure of
the operative note, only ensure that a small num-
ber of important elements were present. Unfortu-
nately, they only tested their rule-based system on
four notes, so it is difficult to evaluate the robust-
ness and generalizability of their method.
More recently, Wang et al. (2014) proposed a
machine learning (ML) method to extract patient-
specific values from operative notes written in
Chinese. They specifically extract tumor-related
information from patients with hepatic carcinoma,
such as the size/location of the tumor, and whether
the tumor boundary is clear. In many ways this is
similar in purpose to Lamiell et al. (1993) in the
sense that there are operation-specific attributes to
extract. However, while the auditing function pri-
marily requires knowing whether particular items
were stated, their method extracts the particular
values for these items. Furthermore, they em-
ploy an ML-based conditional random field (CRF)
trained and tested on 114 operative notes. The pri-
mary difference between the purpose of these two
methods and the purpose of our method lies in the
attempt to model all the events that characterize a
surgery. Both the work of Lamiell et al. (1993)
and Wang et al. (2014) can be used for complete-
ness testing, and Wang et al. (2014) can be used
to find similar patients. The lack of understand-
ing of the event structure, however, prevents these
methods from identifying similar surgical methods
or unexpected surgical techniques, or from accom-
plishing many other secondary use objectives.
In a more similar vein to our own approach,
Wang et al. (2012) studies actions (a subset of
event mentions) within an operative note. They
note that various lexico-syntactic constructions
can be used to specify an action (e.g., incised, the
incision was carried, made an incision). Like our
approach, they observed sentences can be catego-
rized into actions, perceptions/reports, and other
(though we make this distinction at the event men-
tion level). They adapted the Stanford Parser
(Klein and Manning, 2003) with the Specialist
Lexicon (Browne et al., 1993) similar to Huang
et al. (2005). They do not, however, propose any
automatic system for recognizing and categoriz-
ing actions. Instead, they concentrate on evalu-
ating existing resources. They find that many re-
sources, such as UMLS (Lindberg et al., 1993) and
FrameNet (Baker et al., 1998) have poor coverage
of surgical actions, while Specialist and WordNet
(Fellbaum, 1998) have good coverage.
A notable limitation of their work is that they
only studied actions at the sentence level, look-
ing at the main verb of the independent clause.
We have found in our study that multiple actions
can occur within a sentence, and we thus study ac-
tions at the event mention level. Wang et al. (2012)
noted this shortcoming and provide the following
illustrative examples:
</bodyText>
<listItem confidence="0.9511582">
• The patient was taken to the operating room
where general anesthesia was administered.
• After the successful induction of spinal anes-
thesia, she was placed supine on the operat-
ing table.
</listItem>
<bodyText confidence="0.999965818181818">
The second event mention in the first sentence
(administered) and the first event mention in the
second sentence (induction) are ignored in Wang
et al. (2012)’s study. Despite the fact that they
are stated in dependent clauses, these mentions
may be more semantically important to the narra-
tive than the mentions in the independent clauses.
This is because a grammatical relation does not
necessarily imply event prominence. In a further
study, Wang et al. (2013) work toward the creation
of an automatic extraction system by annotating
</bodyText>
<page confidence="0.998654">
69
</page>
<bodyText confidence="0.982399">
PropBank (Palmer et al., 2005) style predicate-
argument structures on thirty common surgical ac-
tions.
</bodyText>
<sectionHeader confidence="0.87667" genericHeader="method">
3 Event Structures in Operative Notes
</sectionHeader>
<bodyText confidence="0.999889909090909">
Since operations are considered to be one of the
riskier forms of clinical treatment, surgeons fol-
low strict procedures that are highly structured and
require significant training and oversight. Thus,
a surgeon’s description of a particular operation
should be highly similar with a different descrip-
tion of the same type of operation, even if writ-
ten by a different surgeon at a different hospital.
For instance, the two examples below were writ-
ten by two different surgeons to describe the event
of controlling the blood supply to the appendix:
</bodyText>
<listItem confidence="0.9913895">
• The 35 mm vascular Endo stapler device was
fired across the mesoappendix...
• The meso appendix was divided with electro-
cautery...
</listItem>
<bodyText confidence="0.999966756756757">
In these two examples, the surgeons use different
lexical forms (fired vs. divided), syntactic forms
(mesoappendix to the right or left of the EVENT),
different semantic predicate-argument structures
(INSTRUMENT-EVENT-ANATOMICALOBJECT
vs. ANATOMICALOBJECT-EVENT-METHOD),
and even different surgical techniques (stapling or
cautery). Still, these examples describe the same
step in the operation and thus can be mapped to
the same location in the event structure.
In order to recognize the event structure in op-
erative notes, we start by specifying an event
structure to a particular operation (e.g., mastec-
tomy, appendectomy, heart transplant) and create
a ground-truth structure based on expert knowl-
edge. Our goal is then to normalize the event men-
tions within a operative note to the specific surgi-
cal actions in the event structure. While the lex-
ical, syntactic, and predicate-argument structures
vary greatly across the surgeons in our data, many
event descriptions are highly consistent within
notes written by the same surgeon. This is es-
pecially true of events with little linguistic vari-
ability, typically largely procedural but necessary
events that are not the focus of the surgeon’s de-
scription of the operation. An example of low-
variability is the event of placing the patient on
the operating table, as opposed to the event of ma-
nipulating the appendix to prepare it for removal.
Additionally, while there is considerable lexical
variation in how an event is mentioned, the ter-
minology for event mentions is fairly limited, re-
sulting in reasonable similarity between surgeons
(e.g., the verbal description used for the dividing
of the mesoappendix is typically one of the fol-
lowing mentions: fire, staple, divide, separate, re-
move).
</bodyText>
<subsectionHeader confidence="0.999816">
3.1 Event Structure Representation
</subsectionHeader>
<bodyText confidence="0.999954222222222">
Operative notes contain event mentions of many
different event classes. Some classes correspond
to actions performed by the surgeon, while oth-
ers describe findings, provide reasonings, or dis-
cuss interactions with patients or assistants. These
distinctions are necessary to recognizing the event
structure of an operation, in which we are primar-
ily concerned with surgical actions. We consider
the following event types:
</bodyText>
<listItem confidence="0.950914678571429">
• ACTION: the primary types of events in an
operation. These typically involve physi-
cal actions taken by the surgeon (e.g., cre-
ating/closing an incision, dividing tissue), or
procedural events (e.g., anesthesia, transfer
to recovery). With limited exceptions, AC-
TIONs occur in a strict order and the ith AC-
TION can be interpreted as enabling the (i +
1)th ACTION.
• P ACTION: the peripheral actions that are
optional, do not occur within a specific place
in the chain of ACTIONs, and are not consid-
ered integral to the event structure. Examples
include stopping unexpected bleeding and re-
moving benign cysts un-connected with the
operation.
• OBSERVATION: an event that denotes the
act of observing a given state. OBSERVA-
TIONs may lead to ACTION (e.g., the ap-
pendix is perforated and therefore needs to
be removed) or P ACTIONs (e.g., a cyst is
found). They may also be elaborations to pro-
vide more details about the surgical method
being used.
• REPORT: an event that denotes a verbal in-
teraction between the surgeon and a patient,
guardian, or assistant (such as obtaining con-
sent for an operation).
</listItem>
<bodyText confidence="0.999976833333333">
The primary class of events that we are interested
in here are ACTIONs. Abstractly, one can view a
type of operation as a directed graph with specified
start and end states. The nodes denote the events,
while the edges denote enablements. An instance
of an operation then can be represented as some
</bodyText>
<page confidence="0.994437">
70
</page>
<figureCaption confidence="0.798656">
Figure 1: Graphical representation of a surgical
procedure with ACTIONs A, B, C, D, E, and F,
OBSERVATION O, and P ACTION G. (a) strict
</figureCaption>
<bodyText confidence="0.945275263157895">
surgical graph (only actions), (b) surgical graph
with an observation invoking an action, (c) surgi-
cal graph with an observation invoking a periph-
eral action.
path between the start and end nodes.
In its simplest form, a surgical graph is com-
posed entirely of ACTION nodes (see Figure 1(a)).
It is possible to add expected OBSERVATIONs
that might trigger a different ACTION path (Fig-
ure 1(b)). Finally, P ACTIONs can be represented
as optional nodes in the surgical graph, which may
or may not be triggered by OBSERVATIONs (Fig-
ure 1(c)). This graphical model is simply a con-
ceptual aid to help design the action types. The
model currently plays no role in the automatic
classification. For the remainder of this section
we focus on a relatively limited surgical proce-
dure that can be interpreted as a linear chain of
ACTIONs.
</bodyText>
<subsectionHeader confidence="0.999769">
3.2 Appendectomy Representation
</subsectionHeader>
<bodyText confidence="0.998120833333333">
Acute appendicitis is a common condition requir-
ing surgical management, and is typically treated
by removing the appendix, either laparoscopically
or by using an open technique. Appendectomies
are the most commonly performed urgent surgi-
cal procedure in the United States. The procedure
is relatively straight-forward, and the steps of the
procedure exhibit little variation between differ-
ent surgeons. The third author (MS), a surgeon
with more than 20 years of experience in pedi-
atric surgery, provided the following primary AC-
TIONs:
</bodyText>
<listItem confidence="0.99989352631579">
• APP01: transfer patient to operating room
• APP02: place patient on table
• APP03: anesthesia
• APP04: prep
• APP05: drape
• APP06: umbilical incision
• APP07: insert camera/telescope
• APP08: insert other working ports
• APP09: identify appendix
• APP10: dissect appendix away from other
structures
• APP11: divide blood supply
• APP12: divide appendix from cecum
• APP13: place appendix in a bag
• APP14: remove bag from body
• APP15: close incisions
• APP16: wake up patient
• APP17: transfer patient to post-anesthesia
care unit
</listItem>
<bodyText confidence="0.9857086">
In the laparoscopic setting, each of these actions is
a necessary part of the operation, and most should
be recorded in the operative note. Additionally,
any number of P ACTION, OBSERVATION, and
REPORT events may be interspersed.
</bodyText>
<sectionHeader confidence="0.998093" genericHeader="method">
4 Data
</sectionHeader>
<bodyText confidence="0.9999512">
In accordance with generally accepted medical
practice and to comply with requirements of The
Joint Commission, a detailed report of any surgical
procedure is placed in the medical record within
24 hours of the procedure. These notes include the
preoperative diagnosis, the post-operative diagno-
sis, the procedure name, names of surgeon(s) and
assistants, anesthetic method, operative findings,
complications (if any), estimated blood loss, and a
detailed report of the conduct of the procedure. To
ensure accuracy and completeness, such notes are
typically dictated and transcribed shortly after the
procedure by the operating surgeon or one of the
assistants.
To obtain the procedure notes for this study,
The Children’s Medical Center (CMC) of Dal-
las electronic medical record (EMR) was queried
for operative notes whose procedure contained the
word “appendectomy” (CPT codes 44970, 44950,
44960) for a preoperative diagnosis of “acute ap-
pendicitis” (ICD9 codes 541, 540.0, 540.1). At
the time of record acquisition, the CMC EMR had
been in operation for about 3 years, and 2,820
notes were obtained, having been completed by 12
pediatric surgeons. In this set, there were 2,757
</bodyText>
<page confidence="0.994353">
71
</page>
<table confidence="0.999974357142857">
Surgeon Notes Events Words
surgeon, 8 291 2,305
surgeon2 311 16,379 134,748
surgeon3 143 6,897 57,797
surgeon4 400 8,940 62,644
surgeons 391 15,246 114,684
surgeons 307 9,880 77,982
surgeon7 397 10,908 74,458
surgeons 34 2,401 20,391
surgeons 2 100 973
surgeon,0 355 9,987 89,085
surgeon,, 380 14,211 135,215
surgeon,2 92 2,417 19,364
Total 2,820 97,657 789,646
</table>
<tableCaption confidence="0.999908">
Table 1: Overview of corpus by surgeon.
</tableCaption>
<bodyText confidence="0.999970583333333">
laparoscopic appendectomies and 63 open proce-
dures. The records were then processed automat-
ically to remove any identifying information such
as names, hospital record numbers, and dates. For
the purposes of this investigation, only the sur-
geon’s name and the detailed procedure note were
collected for further study. Owing to the complete
anonymity of the records, the study received an ex-
emption from the University of Texas Southwest-
ern Medical Center and CMC Institutional Review
Boards. Table 1 contains statistics about the distri-
bution of notes by surgeon in our dataset.
</bodyText>
<sectionHeader confidence="0.996034" genericHeader="method">
5 Active Learning Framework
</sectionHeader>
<bodyText confidence="0.999873666666667">
Active learning is becoming a more and more
popular framework for natural language annota-
tion in the biomedical domain (Hahn et al., 2012;
Figueroa et al., 2012; Chen et al., 2013a; Chen et
al., 2013b). In an active learning setting, instead of
performing manual annotation separate from auto-
matic system development, an existing ML classi-
fier is employed to help choose which examples
to annotate. Thus, human annotators can focus on
examples that would prove difficult for a classifier,
which can dramatically reduce overall annotation
time. However, active learning is not without pit-
falls, notably sampling bias (Dasgupta and Hsu,
2008), re-usability (Tomanek et al., 2007), and
class imbalance (Tomanek and Hahn, 2009). In
our work, the purpose of utilizing an active learn-
ing framework is to produce a fully-annotated cor-
pus of labeled event mentions in as small a period
of time as possible. To some extent, the goal of
full-annotation alleviates some of the active learn-
ing issues discussed above (re-usability and class
imbalance), but sampling bias could still lead to
significantly longer annotation time.
Our goal is to (1) distinguish event mentions in
one of the four classes introduced in Section 3.1
(event type annotation), and (2) further classify ac-
tions into their appropriate location in the event
structure (on this data, appendectomy type anno-
tation). While most active learning methods are
used with the intention of only manually labeling
a sub-set of the data, our goal is to annotate every
event mention so that we may ultimately evaluate
unsupervised techniques on this data. Our active
learning experiment thus proceeds in two paral-
lel tracks: (i) a traditional active learning process
where the highest-utility unlabeled event mentions
are classified by a human annotator, and (ii) a
batch annotation process where extremely simi-
lar, “easy” examples are annotated in large groups.
Due to small intra-surgeon language variation, and
relatively small inter-surgeon variation due to the
limited terminology, this second process allows us
to annotate large numbers of unlabeled examples
at a time. The batch labeling largely annotates un-
labeled examples that would not be selected by the
primary active learning module because they are
too similar to the already-labeled examples. After
a sufficient amount of time being spent in tradi-
tional active learning, the batch labeling is used
to annotate until the batches produced are insuf-
ficiently similar and/or wrong classifications are
made. After a sufficent number of annotations are
made with the active learning method, the choice
of when to use the active learning or batch anno-
tation method is left to the discretion of the anno-
tator. This back-and-forth is then repeated itera-
tively until all the examples are annotated.
For both the active learning and batch labeling
processes, we use a multi-class support vector ma-
chine (SVM) using a simple set of features:
</bodyText>
<listItem confidence="0.974533166666667">
F1. Event mention’s lexical form (e.g., identified)
F2. Event mention’s lemma (identify)
F3. Previous words (3-the, 2-appendix, 1-was)
F4. Next words (1-and, 2-found, 3-to, 4-be,
5-ruptured)
F5. Whether the event is a gerund (false)
</listItem>
<bodyText confidence="0.960101428571429">
Features F3 and F4 were constrained to only return
words within the sentence.
To sample event mentions for the active learner,
we combine several sampling techniques to ensure
a diversity of samples to label. This meta-sampler
chooses from 4 different samplers with differing
probability p:
</bodyText>
<listItem confidence="0.9364055">
1. UNIFORM: Choose (uniformly) an unlabeled
instance (p = 0.1). Formally, let L be the
</listItem>
<page confidence="0.995931">
72
</page>
<bodyText confidence="0.993365">
set of manually labeled instances. Then, the
probability of selecting an event ei is:
</bodyText>
<equation confidence="0.963275">
PU(ei) ∝ S(ei ∈/ L)
</equation>
<bodyText confidence="0.9343908">
Where S(x) is the delta function that returns
1 if the condition x is true, and 0 otherwise.
Thus, an unlabeled event has an equal prob-
ability of being selected as every other unla-
beled event.
</bodyText>
<listItem confidence="0.89019575">
2. JACCARD: Choose an unlabeled instance bi-
ased toward those whose word context is least
similar to the labeled instances using Jac-
card similarity (p = 0.2). This sampler pro-
motes diversity to help prevent sampling bias.
Let Wi be the words in ei’s sentence. Then
the probability of selecting an event with the
JACCARD sampler is:
</listItem>
<equation confidence="0.901033">
α
PJ(ei) ∝ S(ei ∈/L) emEL K I 1 WZnWj
WZ U W� / J
</equation>
<bodyText confidence="0.866421">
Here, α is a parameter to give more weight to
dissimilar sentences (we set α = 2).
</bodyText>
<listItem confidence="0.883502571428571">
3. CLASSIFIER: Choose an unlabeled instance
biased toward those the SVM assigned low
confidence values (p = 0.65). Formally, let
fc(ei) be the confidence assigned by the clas-
sifier to event ei. Then, the probability of se-
lecting an event with the CLASSIFIER sam-
pler is:
</listItem>
<equation confidence="0.906155">
PC(ei) ∝ S(ei ∈/ L)(1 − fc(ei))
</equation>
<bodyText confidence="0.996798428571428">
The SVM we use provides confidence values
largely in the range (-1, 1), but for some very
confident examples this value can be larger.
We therefore constrain the raw confidence
value fr(ei) and place it within the range [0,
1] to achieve the modified confidence fc(ei)
above:
</bodyText>
<equation confidence="0.6555675">
max(min(fr(ei),1), −1) + 1
2
</equation>
<bodyText confidence="0.998850333333333">
In this way, fc(ei) can be guaranteed to be
within [0, 1] and can thus be interpreted as a
probability.
</bodyText>
<listItem confidence="0.989360833333333">
4. MISCLASSIFIED: Choose (uniformly) a la-
beled instance that the SVM mis-classifies
during cross-validation (p = 0.05). Let f(ei)
be the classifier’s guess and L(ei) be the
manual label for event ei. Then the proba-
bility of selecting an event is:
</listItem>
<equation confidence="0.493597">
PM(ei) ∝ S(ei ∈ L)S(f(ei) =6 L(ei))
</equation>
<table confidence="0.99870225">
Event Type Precision Recall Fl
ACTION 0.79 0.90 0.84
NOT EVENT 0.75 0.82 0.79
OBSERVATION 0.71 0.57 0.63
P ACTION 0.66 0.40 0.50
REPORT 1.00 0.58 0.73
Active Learning Accuracy: 76.4%
Batch Annotation Accuracy: 99.5%
</table>
<tableCaption confidence="0.988263">
Table 2: Classification results for event types. Ex-
</tableCaption>
<bodyText confidence="0.94968">
cept when specified, results are for data annotated
using the active learning method, while the batch
annotation results include all data.
The first annotation was made using the UNIFORM
sampler. For every new annotation, the meta-
sampler chooses one of the above sampling meth-
ods according to the above p values, and that sam-
pler selects an example to annotate. For each se-
lected sample, it is first assigned an event type. If it
is assigned as an ACTION, the annotator further as-
signs its appropriate action type. The CLASSIFIER
and MISCLASSIFIED samplers alternate between
the event type and action type classifiers. These
four samplers were chosen to balance the tra-
ditional active learning approach (CLASSIFIER),
while trying to prevent classifier bias (UNIFORM
and JACCARD), while also allowing mis-labeled
data to be corrected (MISCLASSIFIED). An eval-
uation of the utility of the individual samplers is
beyond the scope of this work.
</bodyText>
<sectionHeader confidence="0.999831" genericHeader="method">
6 Results
</sectionHeader>
<bodyText confidence="0.9997743">
For event type annotation, two annotators single-
annotated 1,014 events with one of five event types
(ACTION, P ACTION, OBSERVATION, REPORT,
and NOT EVENT). The classifier’s accuracy on
this data was 75.9% (see Table 2 for a breakdown
by event type). However, the examples were cho-
sen because they were very different from the cur-
rent labeled set, and thus we would expect them to
be more difficult than a random sampling. When
one includes the examples annotated using batch
labeling, the overall accuracy is 99.5%.
For action type annotation, the same two anno-
tators labeled 626 ACTIONs with one of the 17 ac-
tion types (APP01–APP17). The classifier’s accu-
racy on this data was again a relatively low 72.2%
(see Table 3 for a breakdown by action type).
However, again, these examples were expected to
be difficult for the classifier. When one includes
the examples annotated using batch labeling, the
overall accuracy is 99.4%.
</bodyText>
<equation confidence="0.940152">
fc(ei) =
</equation>
<page confidence="0.995269">
73
</page>
<table confidence="0.9999496">
Action Type Precision Recall Fl
APP01 0.91 0.77 0.83
APP02 1.00 0.67 0.80
APP03 1.00 0.67 0.80
APP04 0.95 0.95 0.95
APP05 1.00 1.00 1.00
APP06 0.79 0.72 0.76
APP07 0.58 0.58 0.58
APP08 0.65 0.75 0.70
APP09 0.82 0.93 0.87
APP10 0.63 0.73 0.68
APP11 0.50 0.50 0.50
APP12 0.61 0.56 0.58
APP13 0.94 0.94 0.94
APP14 0.71 0.73 0.72
APP15 0.84 0.79 0.82
APP16 0.93 0.81 0.87
APP17 0.84 0.89 0.86
Active Learning Accuracy: 71.4%
Batch Annotation Accuracy: 99.4%
</table>
<tableCaption confidence="0.999414">
Table 3: Classification results for action types.
</tableCaption>
<sectionHeader confidence="0.994196" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.998827464285714">
The total time allotted for annotation was approxi-
mately 12 hours, split between two annotators (the
first author and a computer science graduate stu-
dent). Prior to annotation, both annotators were
given a detailed description of an appendectomy,
including a video of a procedure to help asso-
ciate the actual surgical actions with the narrative
description. After annotation, 1,042 event types
were annotated using the active learning method,
90,335 event types were annotated using the batch
method, and 6,279 remained un-annotated. Sim-
ilarly, 658 action types were annotated using the
active learning method, 35,799 action types were
annotated using the batch method, and 21,151 re-
mained un-annotated. A greater proportion of ac-
tions remained un-annotated due to the lower clas-
sifier confidence associated with the task. Event
and action types were annotated in unison, but we
estimate during the active learning process it took
about 25 seconds to annotate each event (both the
event type and the action type if classified as an
ACTION). The batch process enabled the annota-
tion of an average of 3 event mentions per second.
This rapid annotation was made possible by
the repetitive nature of operative notes, especially
within an individual surgeon’s notes. For exam-
ple, the following statements were repeated over
100 times in our corpus:
</bodyText>
<listItem confidence="0.9982032">
• General anesthesia was induced.
• A Foley catheter was placed under sterile
conditions.
• The appendix was identified and seemed to
be acutely inflamed.
</listItem>
<bodyText confidence="0.999987607843137">
The first example was used by an individual sur-
geon in 95% of his/her notes, and only used three
times by a different surgeon. In the second exam-
ple, the sentence is used in 77% of the surgeon’s
notes while only used once by another surgeon.
The phrase “Foley catheter was placed”, however,
was used 133 times by other surgeons. In the con-
text of an appendectomy, this action is unambigu-
ous, and so only a few annotations are needed to
recognize the hundreds of actual occurrences in
the data. Similarly, with the third example, the
phrase “the appendix was identified” was used in
over 600 operative notes by 10 of the 12 surgeons.
After a few manual annotations to achieve suffi-
cient classification confidence, the batch process
can identify duplicate or near-duplicate events that
can be annotated at once, greatly reducing the time
needed to achieve full annotation.
Unfortunately, the most predictable parts of a
surgeon’s language are typically the least inter-
esting from the perspective of understanding the
critical points in the narrative. As shown in the
examples above, the highest levels of redundancy
are found in the most routine aspects of the op-
eration. The batch annotation, therefore, is quite
biased and the 99% accuracies it achieves cannot
be expected to hold up once the data is fully an-
notated. Conversely, the active learning process
specifically chooses examples that are different
from the current labeled set and thus are more dif-
ficult to classify. Active learning is more likely to
sample from the “long tail” than the most frequent
events and actions, so the performance on the cho-
sen sample is certainly a lower bound on the per-
formance of a completely annotated data set. If
one assumes the remaining un-annotated data will
be of similar difficulty to the data sampled by the
active learner, one could project an overall event
type accuracy of 97% and an overall action type
accuracy of 89%. This furthermore assumes no
improvements are made to the machine learning
method based on this completed data.
One way to estimate the potential bias in batch
annotation is by observing the differences in the
distributions of the two data sets. Figure 2 shows
the total numbers of action types for both the
active learning and batch annotation portions of
the data. For the most part, the distributions
are similar. APP08 (insert other working ports),
APP10 (dissect appendix away from other struc-
tures), APP11 (divide blood supply), APP12 (di-
</bodyText>
<page confidence="0.997573">
74
</page>
<figureCaption confidence="0.9490245">
Figure 2: Frequencies of action types in the active learning (AL) portion of the data set (left vertical axis)
and the batch annotation (BA) portion of the data set (right vertical axis).
</figureCaption>
<bodyText confidence="0.969227590909091">
vide appendix from cecum), and APP14 (remove
bag from body) are the most under-represented in
the batch annotation data. This confirms our hy-
pothesis that some of the most interesting events
have the greatest diversity in expression.
In Section 2 we noted that a limitation of the an-
notation method of Wang et al. (2012) was that a
sentence could only have one action. We largely
overcame this problem by associating a single sur-
gical action with an event mention. This has one
notable limitation, however, as occasionally a sin-
gle event mention corresponds to more than one
action. In our data, APP11 and APP12 are com-
monly expressed together:
• Next, the mesoappendix and appendix is
stapledAPP11/APP12 and then the appendix is
placedAPP13 in an endobag.
Here, a coordination (“mesoappendix and ap-
pendix”) is used to associate two events (the sta-
pling of the mesoappendix and the stapling of
the appendix) with the same event mention. In
the event extraction literature, this is a well-
understood occurrence, as for instance TimeML
(Pustejovsky et al., 2003) can represent more than
one event with a single event mention. In practice,
however, few automatic TimeML systems handle
such phenomena. Despite this, for our purpose the
annotation structure should likely be amended so
that we can account for all the important actions
in the operative note. This way, gaps in our event
structure will correspond to actual gaps in the nar-
rative (e.g., dividing the blood supply is a critical
step in an appendectomy and therefore needs to fit
within the event structure).
Finally, the data in our experiment comes from
a relatively simple procedure (an appendectomy).
It is unclear how well this method would general-
ize to more complex operations. Most likely, the
difficulty will lie in actions that are highly ambigu-
ous, such as if more than one incision is made.
In this case, richer semantic information will be
necessary, such as the spatial argument that indi-
cates where a particular event occurs (Roberts et
al., 2012).
</bodyText>
<sectionHeader confidence="0.999262" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999985133333333">
With the increasing availability of electronic oper-
ative notes, there is a corresponding need for deep
analysis methods to understand the note’s narra-
tive structure to enable applications for improving
patient care. In this paper, we have presented a
method for recognizing how event mentions in an
operative note fit into the event structure of the ac-
tual operation. We have proposed a generic frame-
work for event structures in surgical notes with a
specific event structure for appendectomy opera-
tions. We have described a corpus of 2,820 opera-
tive notes of appendectomies performed by 12 sur-
geons at a single institution. With the ultimate goal
of fully annotating this data set, which contains al-
most 100,000 event mentions, we have shown how
an active learning method combined with a batch
annotation process can quickly annotate the ma-
jority of the corpus. The method is not without
its weaknesses, however, and further annotation is
likely necessary.
Beyond finishing the annotation process, our ul-
timate goal is to develop unsupervised methods
for structuring operative notes. This would en-
able expanding to new surgical procedures without
human intervention while also leveraging the in-
creasing availability of this information. We have
shown in this work how operative notes have lin-
guistic characteristics that result in parallel struc-
tures. It is our goal to leverage these characteris-
tics in developing unsupervised methods.
</bodyText>
<page confidence="0.998376">
75
</page>
<sectionHeader confidence="0.999546" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9991445">
The authors would like to thank Sanya Peshwani
for her help in annotating the data.
</bodyText>
<sectionHeader confidence="0.998474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999823145631068">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proceed-
ings ofACL/COLING.
Allen C. Browne, Alexa T. McCray, and Suresh Srini-
vasan. 1993. The SPECIALIST Lexicon. Tech-
nical Report NLM-LHC-93-01, National Library of
Medicine.
Yukun Chen, Hongxin Cao, Qiaozhu Mei, Kai Zheng,
and Hua Xu. 2013a. Applying active learning to su-
pervised word sense disambiguation in MEDLINE.
JAm Med Inform Assoc, 20:1001–1006.
Yukun Chen, Robert Carroll, Eugenia R. McPeek Hinz,
Anushi Shah, Anne E. Eyler, Joshua C. Denny, ,
and Hua Xu. 2013b. Applying active learning
to high-throughput phenotyping algorithms for elec-
tronic health records data. JAm Med Inform Assoc,
20:e253–e259.
Sanjoy Dasgupta and Daniel Hsu. 2008. Hierarchical
Sampling for Active Learning. In Proceedings of the
International Conference on Maching Learning.
J.K. DeOrio. 2002. Surgical templates for orthopedic
operative reports. Orthopedics, 25(6):639–642.
Laura Donahoe, Sean Bennett, Walley Temple, Andrea
Hilchie-Pye, Kelly Dabbs, Ethel MacIntosh, and Ge-
off Porter. 2012. Completeness of dictated oper-
ative reports in breast cancer–the case for synoptic
reporting. JSurg Oncol, 106(1):79–83.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
Rosa L. Figueroa, Qing Zeng-Treitler, Long H. Ngo,
Sergey Goryachev, and Eduardo P. Wiechmann.
2012. Active learning for clinical text classification:
is it better than random sampling? JAm Med Inform
Assoc, 19:809–816.
I. Gur, D. Gur, and J.A. Recabaren. 2011. The com-
puterized synoptic operative report: A novel tool in
surgical residency education. Arch Surg, pages 71–
74.
Udo Hahn, Elena Beisswanger, Ekaterina Buyko, and
Erik Faessler. 2012. Active Learning-Based Corpus
Annotation – The PATHOJEN Experience. In Pro-
ceedings of the AMIA Symposium, pages 301–310.
Yang Huang, Henry J Lowe, Dan Klein, and Rus-
sell J Cucina. 2005. Improved Identification of
Noun Phrases in Clinical Radiology Reports Using
a High-Performance Statistical Natural Language
Parser Augmented with the UMLS Specialist Lex-
icon. J Am Med Inform Assoc, 12:275–285.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In Proceedings of ACL,
pages 423–430.
James M Lamiell, Zbigniew M Wojcik, and John
Isaacks. 1993. Computer Auditing of Surgical Op-
erative Reports Written in English. In Proc Annu
Symp ComputAppl Med Care, pages 269–273.
Donald A.B. Lindberg, Betsy L. Humphreys, and
Alexa T. McCray. 1993. The Unified Medical Lan-
guage System. Methods of Information in Medicine,
32(4):281–291.
Martha Palmer, Paul Kingsbury, and Daniel Gildea.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71–106.
Jason Park, Venu G. Pillarisetty, Murray F. Brennan,
and et al. 2010. Electronic Synoptic Operative Re-
porting: Assessing the Reliability and Completeness
of Synoptic Reports for Pancreatic Resection. JAm
Coll Surgeons, 211(3):308–315.
James Pustejovsky, Jos´e Castano, Robert Ingria, Roser
Sauri, Robert Gaizauskas, Andrea Setzer, Graham
Katz, and Dragomir Radev. 2003. TimeML: Ro-
bust Specification of Event and Temporal Expres-
sions in Text. In Proceedings of the Fifth Interna-
tional Workshop on Computational Semantics.
Kirk Roberts, Bryan Rink, Sanda M. Harabagiu,
Richard H. Scheuermann, Seth Toomay, Travis
Browning, Teresa Bosler, and Ronald Peshock.
2012. A Machine Learning Approach for Identi-
fying Anatomical Locations of Actionable Findings
in Radiology Reports. In Proceedings of the AMIA
Symposium.
Katrin Tomanek and Udo Hahn. 2009. Reducing Class
Imbalance during Active Learning for Named Entity
Annotation. In Proceedings of KCAP.
Katrin Tomanek, Joachim Wermter, and Udo Hahn.
2007. An Approach to Text Corpus Construc-
tion which Cuts Annotation Costs and Maintains
Reusability of Annotated Data. In Proceedings of
EMNLP/CoNLL, pages 486–495.
Yan Wang, Serguei Pakhomov, Nora E. Burkart,
James O. Ryan, and Genevieve B. Melton. 2012.
A Study of Actions in Operative Notes. In Proceed-
ings of the AMIA Symposium, pages 1431–1440.
Yan Wang, Serguei Pakhomov, and Genevieve B
Melton. 2013. Predicate Argument Structure
Frames for Modeling Information in Operative
Notes. In Studies in Health Technology and Infor-
matics (MEDINFO), pages 783–787.
Hui Wang, Weide Zhang, Qiang Zeng, Zuofeng Li,
Kaiyan Feng, and Lei Liu. 2014. Extracting impor-
tant information from Chinese Operation Notes with
natural language processing methods. J Biomed In-
form.
</reference>
<page confidence="0.99176">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.085354">
<title confidence="0.99371">Structuring Operative Notes using Active Learning</title>
<affiliation confidence="0.66132">National Library of National Institutes of Health</affiliation>
<address confidence="0.944285">Bethesda, MD</address>
<email confidence="0.982779">kirk.roberts@nih.gov</email>
<affiliation confidence="0.80936025">Sanda M. Human Language Technology Research University of Texas at Richardson, TX</affiliation>
<email confidence="0.998941">sanda@hlt.utdallas.edu</email>
<author confidence="0.987576">A Michael</author>
<affiliation confidence="0.834612">University of Texas Southwestern Medical Children’s Medical Center of Dallas, TX</affiliation>
<email confidence="0.999068">michael.skinner@childrens.com</email>
<abstract confidence="0.999379333333333">We present an active learning method for placing the event mentions in an operative note into a pre-specified event structure. Event mentions are first classified into action, peripheral action, observation, and report events. The actions are further classified into their appropriate location within the event structure. We examine how utilizing active learning significantly reduces the time needed to completely annotate a corpus of 2,820 appendectomy notes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings ofACL/COLING.</booktitle>
<contexts>
<context position="7299" citStr="Baker et al., 1998" startWordPosition="1133" endWordPosition="1136"> incised, the incision was carried, made an incision). Like our approach, they observed sentences can be categorized into actions, perceptions/reports, and other (though we make this distinction at the event mention level). They adapted the Stanford Parser (Klein and Manning, 2003) with the Specialist Lexicon (Browne et al., 1993) similar to Huang et al. (2005). They do not, however, propose any automatic system for recognizing and categorizing actions. Instead, they concentrate on evaluating existing resources. They find that many resources, such as UMLS (Lindberg et al., 1993) and FrameNet (Baker et al., 1998) have poor coverage of surgical actions, while Specialist and WordNet (Fellbaum, 1998) have good coverage. A notable limitation of their work is that they only studied actions at the sentence level, looking at the main verb of the independent clause. We have found in our study that multiple actions can occur within a sentence, and we thus study actions at the event mention level. Wang et al. (2012) noted this shortcoming and provide the following illustrative examples: • The patient was taken to the operating room where general anesthesia was administered. • After the successful induction of s</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings ofACL/COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allen C Browne</author>
<author>Alexa T McCray</author>
<author>Suresh Srinivasan</author>
</authors>
<title>The SPECIALIST Lexicon.</title>
<date>1993</date>
<tech>Technical Report NLM-LHC-93-01,</tech>
<institution>National Library of Medicine.</institution>
<contexts>
<context position="7012" citStr="Browne et al., 1993" startWordPosition="1086" endWordPosition="1089">, or from accomplishing many other secondary use objectives. In a more similar vein to our own approach, Wang et al. (2012) studies actions (a subset of event mentions) within an operative note. They note that various lexico-syntactic constructions can be used to specify an action (e.g., incised, the incision was carried, made an incision). Like our approach, they observed sentences can be categorized into actions, perceptions/reports, and other (though we make this distinction at the event mention level). They adapted the Stanford Parser (Klein and Manning, 2003) with the Specialist Lexicon (Browne et al., 1993) similar to Huang et al. (2005). They do not, however, propose any automatic system for recognizing and categorizing actions. Instead, they concentrate on evaluating existing resources. They find that many resources, such as UMLS (Lindberg et al., 1993) and FrameNet (Baker et al., 1998) have poor coverage of surgical actions, while Specialist and WordNet (Fellbaum, 1998) have good coverage. A notable limitation of their work is that they only studied actions at the sentence level, looking at the main verb of the independent clause. We have found in our study that multiple actions can occur wit</context>
</contexts>
<marker>Browne, McCray, Srinivasan, 1993</marker>
<rawString>Allen C. Browne, Alexa T. McCray, and Suresh Srinivasan. 1993. The SPECIALIST Lexicon. Technical Report NLM-LHC-93-01, National Library of Medicine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yukun Chen</author>
<author>Hongxin Cao</author>
<author>Qiaozhu Mei</author>
<author>Kai Zheng</author>
<author>Hua Xu</author>
</authors>
<title>Applying active learning to supervised word sense disambiguation in MEDLINE. JAm Med Inform Assoc,</title>
<date>2013</date>
<pages>20--1001</pages>
<contexts>
<context position="17603" citStr="Chen et al., 2013" startWordPosition="2788" endWordPosition="2791">umbers, and dates. For the purposes of this investigation, only the surgeon’s name and the detailed procedure note were collected for further study. Owing to the complete anonymity of the records, the study received an exemption from the University of Texas Southwestern Medical Center and CMC Institutional Review Boards. Table 1 contains statistics about the distribution of notes by surgeon in our dataset. 5 Active Learning Framework Active learning is becoming a more and more popular framework for natural language annotation in the biomedical domain (Hahn et al., 2012; Figueroa et al., 2012; Chen et al., 2013a; Chen et al., 2013b). In an active learning setting, instead of performing manual annotation separate from automatic system development, an existing ML classifier is employed to help choose which examples to annotate. Thus, human annotators can focus on examples that would prove difficult for a classifier, which can dramatically reduce overall annotation time. However, active learning is not without pitfalls, notably sampling bias (Dasgupta and Hsu, 2008), re-usability (Tomanek et al., 2007), and class imbalance (Tomanek and Hahn, 2009). In our work, the purpose of utilizing an active learni</context>
</contexts>
<marker>Chen, Cao, Mei, Zheng, Xu, 2013</marker>
<rawString>Yukun Chen, Hongxin Cao, Qiaozhu Mei, Kai Zheng, and Hua Xu. 2013a. Applying active learning to supervised word sense disambiguation in MEDLINE. JAm Med Inform Assoc, 20:1001–1006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yukun Chen</author>
<author>Robert Carroll</author>
<author>Eugenia R McPeek Hinz</author>
<author>Anushi Shah</author>
<author>Anne E Eyler</author>
<author>Joshua C Denny</author>
</authors>
<title>Applying active learning to high-throughput phenotyping algorithms for electronic health records data. JAm Med Inform Assoc,</title>
<date>2013</date>
<contexts>
<context position="17603" citStr="Chen et al., 2013" startWordPosition="2788" endWordPosition="2791">umbers, and dates. For the purposes of this investigation, only the surgeon’s name and the detailed procedure note were collected for further study. Owing to the complete anonymity of the records, the study received an exemption from the University of Texas Southwestern Medical Center and CMC Institutional Review Boards. Table 1 contains statistics about the distribution of notes by surgeon in our dataset. 5 Active Learning Framework Active learning is becoming a more and more popular framework for natural language annotation in the biomedical domain (Hahn et al., 2012; Figueroa et al., 2012; Chen et al., 2013a; Chen et al., 2013b). In an active learning setting, instead of performing manual annotation separate from automatic system development, an existing ML classifier is employed to help choose which examples to annotate. Thus, human annotators can focus on examples that would prove difficult for a classifier, which can dramatically reduce overall annotation time. However, active learning is not without pitfalls, notably sampling bias (Dasgupta and Hsu, 2008), re-usability (Tomanek et al., 2007), and class imbalance (Tomanek and Hahn, 2009). In our work, the purpose of utilizing an active learni</context>
</contexts>
<marker>Chen, Carroll, Hinz, Shah, Eyler, Denny, 2013</marker>
<rawString>Yukun Chen, Robert Carroll, Eugenia R. McPeek Hinz, Anushi Shah, Anne E. Eyler, Joshua C. Denny, , and Hua Xu. 2013b. Applying active learning to high-throughput phenotyping algorithms for electronic health records data. JAm Med Inform Assoc, 20:e253–e259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanjoy Dasgupta</author>
<author>Daniel Hsu</author>
</authors>
<title>Hierarchical Sampling for Active Learning.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Maching Learning.</booktitle>
<contexts>
<context position="18064" citStr="Dasgupta and Hsu, 2008" startWordPosition="2858" endWordPosition="2861">s becoming a more and more popular framework for natural language annotation in the biomedical domain (Hahn et al., 2012; Figueroa et al., 2012; Chen et al., 2013a; Chen et al., 2013b). In an active learning setting, instead of performing manual annotation separate from automatic system development, an existing ML classifier is employed to help choose which examples to annotate. Thus, human annotators can focus on examples that would prove difficult for a classifier, which can dramatically reduce overall annotation time. However, active learning is not without pitfalls, notably sampling bias (Dasgupta and Hsu, 2008), re-usability (Tomanek et al., 2007), and class imbalance (Tomanek and Hahn, 2009). In our work, the purpose of utilizing an active learning framework is to produce a fully-annotated corpus of labeled event mentions in as small a period of time as possible. To some extent, the goal of full-annotation alleviates some of the active learning issues discussed above (re-usability and class imbalance), but sampling bias could still lead to significantly longer annotation time. Our goal is to (1) distinguish event mentions in one of the four classes introduced in Section 3.1 (event type annotation),</context>
</contexts>
<marker>Dasgupta, Hsu, 2008</marker>
<rawString>Sanjoy Dasgupta and Daniel Hsu. 2008. Hierarchical Sampling for Active Learning. In Proceedings of the International Conference on Maching Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J K DeOrio</author>
</authors>
<title>Surgical templates for orthopedic operative reports.</title>
<date>2002</date>
<journal>Orthopedics,</journal>
<volume>25</volume>
<issue>6</issue>
<contexts>
<context position="1202" citStr="DeOrio, 2002" startWordPosition="167" endWordPosition="168">ent mentions are first classified into action, peripheral action, observation, and report events. The actions are further classified into their appropriate location within the event structure. We examine how utilizing active learning significantly reduces the time needed to completely annotate a corpus of 2,820 appendectomy notes. 1 Introduction Operative reports are written or dictated after every surgical procedure. They describe the course of the operation as well as any abnormal findings in the surgical process. Template-based and structured methods exist for recording the operative note (DeOrio, 2002), and in many cases have been shown to increase the completeness of surgical information (Park et al., 2010; Gur et al., 2011; Donahoe et al., 2012). The use of natural language, however, is still preferred for its expressive power. This unstructured information is typically the only vehicle for conveying important details of the procedure, including the surgical instruments, incision techniques, and laparoscopic methods employed. The ability to represent and extract the information found within operative notes would enable ∗ Most of this work was performed while KR was at the University of Te</context>
</contexts>
<marker>DeOrio, 2002</marker>
<rawString>J.K. DeOrio. 2002. Surgical templates for orthopedic operative reports. Orthopedics, 25(6):639–642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Donahoe</author>
<author>Sean Bennett</author>
<author>Walley Temple</author>
<author>Andrea Hilchie-Pye</author>
<author>Kelly Dabbs</author>
<author>Ethel MacIntosh</author>
<author>Geoff Porter</author>
</authors>
<title>Completeness of dictated operative reports in breast cancer–the case for synoptic reporting. JSurg</title>
<date>2012</date>
<journal>Oncol,</journal>
<volume>106</volume>
<issue>1</issue>
<contexts>
<context position="1350" citStr="Donahoe et al., 2012" startWordPosition="192" endWordPosition="195">eir appropriate location within the event structure. We examine how utilizing active learning significantly reduces the time needed to completely annotate a corpus of 2,820 appendectomy notes. 1 Introduction Operative reports are written or dictated after every surgical procedure. They describe the course of the operation as well as any abnormal findings in the surgical process. Template-based and structured methods exist for recording the operative note (DeOrio, 2002), and in many cases have been shown to increase the completeness of surgical information (Park et al., 2010; Gur et al., 2011; Donahoe et al., 2012). The use of natural language, however, is still preferred for its expressive power. This unstructured information is typically the only vehicle for conveying important details of the procedure, including the surgical instruments, incision techniques, and laparoscopic methods employed. The ability to represent and extract the information found within operative notes would enable ∗ Most of this work was performed while KR was at the University of Texas at Dallas. powerful post-hoc reasoning methods about surgical procedures. First, the completeness problem may be alleviated by indicating gaps i</context>
</contexts>
<marker>Donahoe, Bennett, Temple, Hilchie-Pye, Dabbs, MacIntosh, Porter, 2012</marker>
<rawString>Laura Donahoe, Sean Bennett, Walley Temple, Andrea Hilchie-Pye, Kelly Dabbs, Ethel MacIntosh, and Geoff Porter. 2012. Completeness of dictated operative reports in breast cancer–the case for synoptic reporting. JSurg Oncol, 106(1):79–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7385" citStr="Fellbaum, 1998" startWordPosition="1147" endWordPosition="1148">ntences can be categorized into actions, perceptions/reports, and other (though we make this distinction at the event mention level). They adapted the Stanford Parser (Klein and Manning, 2003) with the Specialist Lexicon (Browne et al., 1993) similar to Huang et al. (2005). They do not, however, propose any automatic system for recognizing and categorizing actions. Instead, they concentrate on evaluating existing resources. They find that many resources, such as UMLS (Lindberg et al., 1993) and FrameNet (Baker et al., 1998) have poor coverage of surgical actions, while Specialist and WordNet (Fellbaum, 1998) have good coverage. A notable limitation of their work is that they only studied actions at the sentence level, looking at the main verb of the independent clause. We have found in our study that multiple actions can occur within a sentence, and we thus study actions at the event mention level. Wang et al. (2012) noted this shortcoming and provide the following illustrative examples: • The patient was taken to the operating room where general anesthesia was administered. • After the successful induction of spinal anesthesia, she was placed supine on the operating table. The second event menti</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosa L Figueroa</author>
<author>Qing Zeng-Treitler</author>
<author>Long H Ngo</author>
<author>Sergey Goryachev</author>
<author>Eduardo P Wiechmann</author>
</authors>
<title>Active learning for clinical text classification: is it better than random sampling? JAm Med Inform Assoc,</title>
<date>2012</date>
<contexts>
<context position="17584" citStr="Figueroa et al., 2012" startWordPosition="2784" endWordPosition="2787">ames, hospital record numbers, and dates. For the purposes of this investigation, only the surgeon’s name and the detailed procedure note were collected for further study. Owing to the complete anonymity of the records, the study received an exemption from the University of Texas Southwestern Medical Center and CMC Institutional Review Boards. Table 1 contains statistics about the distribution of notes by surgeon in our dataset. 5 Active Learning Framework Active learning is becoming a more and more popular framework for natural language annotation in the biomedical domain (Hahn et al., 2012; Figueroa et al., 2012; Chen et al., 2013a; Chen et al., 2013b). In an active learning setting, instead of performing manual annotation separate from automatic system development, an existing ML classifier is employed to help choose which examples to annotate. Thus, human annotators can focus on examples that would prove difficult for a classifier, which can dramatically reduce overall annotation time. However, active learning is not without pitfalls, notably sampling bias (Dasgupta and Hsu, 2008), re-usability (Tomanek et al., 2007), and class imbalance (Tomanek and Hahn, 2009). In our work, the purpose of utilizi</context>
</contexts>
<marker>Figueroa, Zeng-Treitler, Ngo, Goryachev, Wiechmann, 2012</marker>
<rawString>Rosa L. Figueroa, Qing Zeng-Treitler, Long H. Ngo, Sergey Goryachev, and Eduardo P. Wiechmann. 2012. Active learning for clinical text classification: is it better than random sampling? JAm Med Inform Assoc, 19:809–816.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Gur</author>
<author>D Gur</author>
<author>J A Recabaren</author>
</authors>
<title>The computerized synoptic operative report: A novel tool in surgical residency education. Arch Surg,</title>
<date>2011</date>
<pages>71--74</pages>
<contexts>
<context position="1327" citStr="Gur et al., 2011" startWordPosition="188" endWordPosition="191">classified into their appropriate location within the event structure. We examine how utilizing active learning significantly reduces the time needed to completely annotate a corpus of 2,820 appendectomy notes. 1 Introduction Operative reports are written or dictated after every surgical procedure. They describe the course of the operation as well as any abnormal findings in the surgical process. Template-based and structured methods exist for recording the operative note (DeOrio, 2002), and in many cases have been shown to increase the completeness of surgical information (Park et al., 2010; Gur et al., 2011; Donahoe et al., 2012). The use of natural language, however, is still preferred for its expressive power. This unstructured information is typically the only vehicle for conveying important details of the procedure, including the surgical instruments, incision techniques, and laparoscopic methods employed. The ability to represent and extract the information found within operative notes would enable ∗ Most of this work was performed while KR was at the University of Texas at Dallas. powerful post-hoc reasoning methods about surgical procedures. First, the completeness problem may be alleviat</context>
</contexts>
<marker>Gur, Gur, Recabaren, 2011</marker>
<rawString>I. Gur, D. Gur, and J.A. Recabaren. 2011. The computerized synoptic operative report: A novel tool in surgical residency education. Arch Surg, pages 71– 74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Elena Beisswanger</author>
<author>Ekaterina Buyko</author>
<author>Erik Faessler</author>
</authors>
<title>Active Learning-Based Corpus Annotation – The PATHOJEN Experience.</title>
<date>2012</date>
<booktitle>In Proceedings of the AMIA Symposium,</booktitle>
<pages>301--310</pages>
<contexts>
<context position="17561" citStr="Hahn et al., 2012" startWordPosition="2780" endWordPosition="2783">formation such as names, hospital record numbers, and dates. For the purposes of this investigation, only the surgeon’s name and the detailed procedure note were collected for further study. Owing to the complete anonymity of the records, the study received an exemption from the University of Texas Southwestern Medical Center and CMC Institutional Review Boards. Table 1 contains statistics about the distribution of notes by surgeon in our dataset. 5 Active Learning Framework Active learning is becoming a more and more popular framework for natural language annotation in the biomedical domain (Hahn et al., 2012; Figueroa et al., 2012; Chen et al., 2013a; Chen et al., 2013b). In an active learning setting, instead of performing manual annotation separate from automatic system development, an existing ML classifier is employed to help choose which examples to annotate. Thus, human annotators can focus on examples that would prove difficult for a classifier, which can dramatically reduce overall annotation time. However, active learning is not without pitfalls, notably sampling bias (Dasgupta and Hsu, 2008), re-usability (Tomanek et al., 2007), and class imbalance (Tomanek and Hahn, 2009). In our work,</context>
</contexts>
<marker>Hahn, Beisswanger, Buyko, Faessler, 2012</marker>
<rawString>Udo Hahn, Elena Beisswanger, Ekaterina Buyko, and Erik Faessler. 2012. Active Learning-Based Corpus Annotation – The PATHOJEN Experience. In Proceedings of the AMIA Symposium, pages 301–310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Huang</author>
<author>Henry J Lowe</author>
<author>Dan Klein</author>
<author>Russell J Cucina</author>
</authors>
<title>Improved Identification of Noun Phrases in Clinical Radiology Reports Using a High-Performance Statistical Natural Language Parser Augmented with the UMLS Specialist Lexicon.</title>
<date>2005</date>
<journal>J Am Med Inform Assoc,</journal>
<pages>12--275</pages>
<contexts>
<context position="7043" citStr="Huang et al. (2005)" startWordPosition="1092" endWordPosition="1095">er secondary use objectives. In a more similar vein to our own approach, Wang et al. (2012) studies actions (a subset of event mentions) within an operative note. They note that various lexico-syntactic constructions can be used to specify an action (e.g., incised, the incision was carried, made an incision). Like our approach, they observed sentences can be categorized into actions, perceptions/reports, and other (though we make this distinction at the event mention level). They adapted the Stanford Parser (Klein and Manning, 2003) with the Specialist Lexicon (Browne et al., 1993) similar to Huang et al. (2005). They do not, however, propose any automatic system for recognizing and categorizing actions. Instead, they concentrate on evaluating existing resources. They find that many resources, such as UMLS (Lindberg et al., 1993) and FrameNet (Baker et al., 1998) have poor coverage of surgical actions, while Specialist and WordNet (Fellbaum, 1998) have good coverage. A notable limitation of their work is that they only studied actions at the sentence level, looking at the main verb of the independent clause. We have found in our study that multiple actions can occur within a sentence, and we thus stu</context>
</contexts>
<marker>Huang, Lowe, Klein, Cucina, 2005</marker>
<rawString>Yang Huang, Henry J Lowe, Dan Klein, and Russell J Cucina. 2005. Improved Identification of Noun Phrases in Clinical Radiology Reports Using a High-Performance Statistical Natural Language Parser Augmented with the UMLS Specialist Lexicon. J Am Med Inform Assoc, 12:275–285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="6962" citStr="Klein and Manning, 2003" startWordPosition="1078" endWordPosition="1081">lar surgical methods or unexpected surgical techniques, or from accomplishing many other secondary use objectives. In a more similar vein to our own approach, Wang et al. (2012) studies actions (a subset of event mentions) within an operative note. They note that various lexico-syntactic constructions can be used to specify an action (e.g., incised, the incision was carried, made an incision). Like our approach, they observed sentences can be categorized into actions, perceptions/reports, and other (though we make this distinction at the event mention level). They adapted the Stanford Parser (Klein and Manning, 2003) with the Specialist Lexicon (Browne et al., 1993) similar to Huang et al. (2005). They do not, however, propose any automatic system for recognizing and categorizing actions. Instead, they concentrate on evaluating existing resources. They find that many resources, such as UMLS (Lindberg et al., 1993) and FrameNet (Baker et al., 1998) have poor coverage of surgical actions, while Specialist and WordNet (Fellbaum, 1998) have good coverage. A notable limitation of their work is that they only studied actions at the sentence level, looking at the main verb of the independent clause. We have foun</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate Unlexicalized Parsing. In Proceedings of ACL, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James M Lamiell</author>
<author>Zbigniew M Wojcik</author>
<author>John Isaacks</author>
</authors>
<title>Computer Auditing of Surgical Operative Reports Written in English.</title>
<date>1993</date>
<booktitle>In Proc Annu Symp ComputAppl Med Care,</booktitle>
<pages>269--273</pages>
<contexts>
<context position="4428" citStr="Lamiell et al. (1993)" startWordPosition="674" endWordPosition="677">lable. Section 3 describes a generic framework for surgical event structures and the particular structure chosen for appendectomies. Section 4 details the data used in this study. Section 5 describes the active learning experiment for filling in this event structure for operative notes. Section 6 reports the results of this experiment. Section 7 analyzes the method and proposes avenues for further research. First, however, we outline the small amount of previous work in natural language processing on operative notes. 2 Previous Work An early tool for processing operative notes was proposed by Lamiell et al. (1993). They develop an auditing tool to help enforce completeness in operative notes. A syntactic parser converts sentences in an operative note into a graph structure that can be queried to ensure the necessary surgical elements are present in the narrative. For appendectomies, they could determine whether answers were specified for questions such as “What was the appendix abnormality?” and “Was cautery or drains used?”. Unlike what we propose, they did not attempt to understand the narrative structure of the operative note, only ensure that a small number of important elements were present. Unfor</context>
<context position="6112" citStr="Lamiell et al. (1993)" startWordPosition="942" endWordPosition="945">clear. In many ways this is similar in purpose to Lamiell et al. (1993) in the sense that there are operation-specific attributes to extract. However, while the auditing function primarily requires knowing whether particular items were stated, their method extracts the particular values for these items. Furthermore, they employ an ML-based conditional random field (CRF) trained and tested on 114 operative notes. The primary difference between the purpose of these two methods and the purpose of our method lies in the attempt to model all the events that characterize a surgery. Both the work of Lamiell et al. (1993) and Wang et al. (2014) can be used for completeness testing, and Wang et al. (2014) can be used to find similar patients. The lack of understanding of the event structure, however, prevents these methods from identifying similar surgical methods or unexpected surgical techniques, or from accomplishing many other secondary use objectives. In a more similar vein to our own approach, Wang et al. (2012) studies actions (a subset of event mentions) within an operative note. They note that various lexico-syntactic constructions can be used to specify an action (e.g., incised, the incision was carri</context>
</contexts>
<marker>Lamiell, Wojcik, Isaacks, 1993</marker>
<rawString>James M Lamiell, Zbigniew M Wojcik, and John Isaacks. 1993. Computer Auditing of Surgical Operative Reports Written in English. In Proc Annu Symp ComputAppl Med Care, pages 269–273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald A B Lindberg</author>
<author>Betsy L Humphreys</author>
<author>Alexa T McCray</author>
</authors>
<title>The Unified Medical Language System.</title>
<date>1993</date>
<journal>Methods of Information in Medicine,</journal>
<volume>32</volume>
<issue>4</issue>
<contexts>
<context position="7265" citStr="Lindberg et al., 1993" startWordPosition="1127" endWordPosition="1130">n be used to specify an action (e.g., incised, the incision was carried, made an incision). Like our approach, they observed sentences can be categorized into actions, perceptions/reports, and other (though we make this distinction at the event mention level). They adapted the Stanford Parser (Klein and Manning, 2003) with the Specialist Lexicon (Browne et al., 1993) similar to Huang et al. (2005). They do not, however, propose any automatic system for recognizing and categorizing actions. Instead, they concentrate on evaluating existing resources. They find that many resources, such as UMLS (Lindberg et al., 1993) and FrameNet (Baker et al., 1998) have poor coverage of surgical actions, while Specialist and WordNet (Fellbaum, 1998) have good coverage. A notable limitation of their work is that they only studied actions at the sentence level, looking at the main verb of the independent clause. We have found in our study that multiple actions can occur within a sentence, and we thus study actions at the event mention level. Wang et al. (2012) noted this shortcoming and provide the following illustrative examples: • The patient was taken to the operating room where general anesthesia was administered. • A</context>
</contexts>
<marker>Lindberg, Humphreys, McCray, 1993</marker>
<rawString>Donald A.B. Lindberg, Betsy L. Humphreys, and Alexa T. McCray. 1993. The Unified Medical Language System. Methods of Information in Medicine, 32(4):281–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Paul Kingsbury</author>
<author>Daniel Gildea</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="8533" citStr="Palmer et al., 2005" startWordPosition="1336" endWordPosition="1339">ia, she was placed supine on the operating table. The second event mention in the first sentence (administered) and the first event mention in the second sentence (induction) are ignored in Wang et al. (2012)’s study. Despite the fact that they are stated in dependent clauses, these mentions may be more semantically important to the narrative than the mentions in the independent clauses. This is because a grammatical relation does not necessarily imply event prominence. In a further study, Wang et al. (2013) work toward the creation of an automatic extraction system by annotating 69 PropBank (Palmer et al., 2005) style predicateargument structures on thirty common surgical actions. 3 Event Structures in Operative Notes Since operations are considered to be one of the riskier forms of clinical treatment, surgeons follow strict procedures that are highly structured and require significant training and oversight. Thus, a surgeon’s description of a particular operation should be highly similar with a different description of the same type of operation, even if written by a different surgeon at a different hospital. For instance, the two examples below were written by two different surgeons to describe the</context>
</contexts>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>Martha Palmer, Paul Kingsbury, and Daniel Gildea. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Park</author>
<author>Venu G Pillarisetty</author>
<author>Murray F Brennan</author>
</authors>
<title>Electronic Synoptic Operative Reporting: Assessing the Reliability and Completeness of Synoptic Reports for Pancreatic Resection.</title>
<date>2010</date>
<journal>JAm Coll Surgeons,</journal>
<volume>211</volume>
<issue>3</issue>
<contexts>
<context position="1309" citStr="Park et al., 2010" startWordPosition="184" endWordPosition="187">ctions are further classified into their appropriate location within the event structure. We examine how utilizing active learning significantly reduces the time needed to completely annotate a corpus of 2,820 appendectomy notes. 1 Introduction Operative reports are written or dictated after every surgical procedure. They describe the course of the operation as well as any abnormal findings in the surgical process. Template-based and structured methods exist for recording the operative note (DeOrio, 2002), and in many cases have been shown to increase the completeness of surgical information (Park et al., 2010; Gur et al., 2011; Donahoe et al., 2012). The use of natural language, however, is still preferred for its expressive power. This unstructured information is typically the only vehicle for conveying important details of the procedure, including the surgical instruments, incision techniques, and laparoscopic methods employed. The ability to represent and extract the information found within operative notes would enable ∗ Most of this work was performed while KR was at the University of Texas at Dallas. powerful post-hoc reasoning methods about surgical procedures. First, the completeness probl</context>
</contexts>
<marker>Park, Pillarisetty, Brennan, 2010</marker>
<rawString>Jason Park, Venu G. Pillarisetty, Murray F. Brennan, and et al. 2010. Electronic Synoptic Operative Reporting: Assessing the Reliability and Completeness of Synoptic Reports for Pancreatic Resection. JAm Coll Surgeons, 211(3):308–315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e Castano</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
<author>Dragomir Radev</author>
</authors>
<title>TimeML: Robust Specification of Event and Temporal Expressions in Text.</title>
<date>2003</date>
<booktitle>In Proceedings of the Fifth International Workshop on Computational Semantics.</booktitle>
<contexts>
<context position="30629" citStr="Pustejovsky et al., 2003" startWordPosition="4942" endWordPosition="4945"> action with an event mention. This has one notable limitation, however, as occasionally a single event mention corresponds to more than one action. In our data, APP11 and APP12 are commonly expressed together: • Next, the mesoappendix and appendix is stapledAPP11/APP12 and then the appendix is placedAPP13 in an endobag. Here, a coordination (“mesoappendix and appendix”) is used to associate two events (the stapling of the mesoappendix and the stapling of the appendix) with the same event mention. In the event extraction literature, this is a wellunderstood occurrence, as for instance TimeML (Pustejovsky et al., 2003) can represent more than one event with a single event mention. In practice, however, few automatic TimeML systems handle such phenomena. Despite this, for our purpose the annotation structure should likely be amended so that we can account for all the important actions in the operative note. This way, gaps in our event structure will correspond to actual gaps in the narrative (e.g., dividing the blood supply is a critical step in an appendectomy and therefore needs to fit within the event structure). Finally, the data in our experiment comes from a relatively simple procedure (an appendectomy</context>
</contexts>
<marker>Pustejovsky, Castano, Ingria, Sauri, Gaizauskas, Setzer, Katz, Radev, 2003</marker>
<rawString>James Pustejovsky, Jos´e Castano, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, Graham Katz, and Dragomir Radev. 2003. TimeML: Robust Specification of Event and Temporal Expressions in Text. In Proceedings of the Fifth International Workshop on Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kirk Roberts</author>
<author>Bryan Rink</author>
<author>Sanda M Harabagiu</author>
<author>Richard H Scheuermann</author>
<author>Seth Toomay</author>
<author>Travis Browning</author>
<author>Teresa Bosler</author>
<author>Ronald Peshock</author>
</authors>
<title>A Machine Learning Approach for Identifying Anatomical Locations of Actionable Findings in Radiology Reports.</title>
<date>2012</date>
<booktitle>In Proceedings of the AMIA Symposium.</booktitle>
<contexts>
<context position="31589" citStr="Roberts et al., 2012" startWordPosition="5102" endWordPosition="5105">rrespond to actual gaps in the narrative (e.g., dividing the blood supply is a critical step in an appendectomy and therefore needs to fit within the event structure). Finally, the data in our experiment comes from a relatively simple procedure (an appendectomy). It is unclear how well this method would generalize to more complex operations. Most likely, the difficulty will lie in actions that are highly ambiguous, such as if more than one incision is made. In this case, richer semantic information will be necessary, such as the spatial argument that indicates where a particular event occurs (Roberts et al., 2012). 8 Conclusion With the increasing availability of electronic operative notes, there is a corresponding need for deep analysis methods to understand the note’s narrative structure to enable applications for improving patient care. In this paper, we have presented a method for recognizing how event mentions in an operative note fit into the event structure of the actual operation. We have proposed a generic framework for event structures in surgical notes with a specific event structure for appendectomy operations. We have described a corpus of 2,820 operative notes of appendectomies performed </context>
</contexts>
<marker>Roberts, Rink, Harabagiu, Scheuermann, Toomay, Browning, Bosler, Peshock, 2012</marker>
<rawString>Kirk Roberts, Bryan Rink, Sanda M. Harabagiu, Richard H. Scheuermann, Seth Toomay, Travis Browning, Teresa Bosler, and Ronald Peshock. 2012. A Machine Learning Approach for Identifying Anatomical Locations of Actionable Findings in Radiology Reports. In Proceedings of the AMIA Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Tomanek</author>
<author>Udo Hahn</author>
</authors>
<title>Reducing Class Imbalance during Active Learning for Named Entity Annotation.</title>
<date>2009</date>
<booktitle>In Proceedings of KCAP.</booktitle>
<contexts>
<context position="18147" citStr="Tomanek and Hahn, 2009" startWordPosition="2870" endWordPosition="2873"> biomedical domain (Hahn et al., 2012; Figueroa et al., 2012; Chen et al., 2013a; Chen et al., 2013b). In an active learning setting, instead of performing manual annotation separate from automatic system development, an existing ML classifier is employed to help choose which examples to annotate. Thus, human annotators can focus on examples that would prove difficult for a classifier, which can dramatically reduce overall annotation time. However, active learning is not without pitfalls, notably sampling bias (Dasgupta and Hsu, 2008), re-usability (Tomanek et al., 2007), and class imbalance (Tomanek and Hahn, 2009). In our work, the purpose of utilizing an active learning framework is to produce a fully-annotated corpus of labeled event mentions in as small a period of time as possible. To some extent, the goal of full-annotation alleviates some of the active learning issues discussed above (re-usability and class imbalance), but sampling bias could still lead to significantly longer annotation time. Our goal is to (1) distinguish event mentions in one of the four classes introduced in Section 3.1 (event type annotation), and (2) further classify actions into their appropriate location in the event stru</context>
</contexts>
<marker>Tomanek, Hahn, 2009</marker>
<rawString>Katrin Tomanek and Udo Hahn. 2009. Reducing Class Imbalance during Active Learning for Named Entity Annotation. In Proceedings of KCAP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Tomanek</author>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<title>An Approach to Text Corpus Construction which Cuts Annotation Costs and Maintains Reusability of Annotated Data.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP/CoNLL,</booktitle>
<pages>486--495</pages>
<contexts>
<context position="18101" citStr="Tomanek et al., 2007" startWordPosition="2863" endWordPosition="2866">ework for natural language annotation in the biomedical domain (Hahn et al., 2012; Figueroa et al., 2012; Chen et al., 2013a; Chen et al., 2013b). In an active learning setting, instead of performing manual annotation separate from automatic system development, an existing ML classifier is employed to help choose which examples to annotate. Thus, human annotators can focus on examples that would prove difficult for a classifier, which can dramatically reduce overall annotation time. However, active learning is not without pitfalls, notably sampling bias (Dasgupta and Hsu, 2008), re-usability (Tomanek et al., 2007), and class imbalance (Tomanek and Hahn, 2009). In our work, the purpose of utilizing an active learning framework is to produce a fully-annotated corpus of labeled event mentions in as small a period of time as possible. To some extent, the goal of full-annotation alleviates some of the active learning issues discussed above (re-usability and class imbalance), but sampling bias could still lead to significantly longer annotation time. Our goal is to (1) distinguish event mentions in one of the four classes introduced in Section 3.1 (event type annotation), and (2) further classify actions int</context>
</contexts>
<marker>Tomanek, Wermter, Hahn, 2007</marker>
<rawString>Katrin Tomanek, Joachim Wermter, and Udo Hahn. 2007. An Approach to Text Corpus Construction which Cuts Annotation Costs and Maintains Reusability of Annotated Data. In Proceedings of EMNLP/CoNLL, pages 486–495.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Wang</author>
<author>Serguei Pakhomov</author>
<author>Nora E Burkart</author>
<author>James O Ryan</author>
<author>Genevieve B Melton</author>
</authors>
<title>A Study of Actions in Operative Notes.</title>
<date>2012</date>
<booktitle>In Proceedings of the AMIA Symposium,</booktitle>
<pages>1431--1440</pages>
<contexts>
<context position="6515" citStr="Wang et al. (2012)" startWordPosition="1010" endWordPosition="1013">ve notes. The primary difference between the purpose of these two methods and the purpose of our method lies in the attempt to model all the events that characterize a surgery. Both the work of Lamiell et al. (1993) and Wang et al. (2014) can be used for completeness testing, and Wang et al. (2014) can be used to find similar patients. The lack of understanding of the event structure, however, prevents these methods from identifying similar surgical methods or unexpected surgical techniques, or from accomplishing many other secondary use objectives. In a more similar vein to our own approach, Wang et al. (2012) studies actions (a subset of event mentions) within an operative note. They note that various lexico-syntactic constructions can be used to specify an action (e.g., incised, the incision was carried, made an incision). Like our approach, they observed sentences can be categorized into actions, perceptions/reports, and other (though we make this distinction at the event mention level). They adapted the Stanford Parser (Klein and Manning, 2003) with the Specialist Lexicon (Browne et al., 1993) similar to Huang et al. (2005). They do not, however, propose any automatic system for recognizing and</context>
<context position="8121" citStr="Wang et al. (2012)" startWordPosition="1270" endWordPosition="1273">ng at the main verb of the independent clause. We have found in our study that multiple actions can occur within a sentence, and we thus study actions at the event mention level. Wang et al. (2012) noted this shortcoming and provide the following illustrative examples: • The patient was taken to the operating room where general anesthesia was administered. • After the successful induction of spinal anesthesia, she was placed supine on the operating table. The second event mention in the first sentence (administered) and the first event mention in the second sentence (induction) are ignored in Wang et al. (2012)’s study. Despite the fact that they are stated in dependent clauses, these mentions may be more semantically important to the narrative than the mentions in the independent clauses. This is because a grammatical relation does not necessarily imply event prominence. In a further study, Wang et al. (2013) work toward the creation of an automatic extraction system by annotating 69 PropBank (Palmer et al., 2005) style predicateargument structures on thirty common surgical actions. 3 Event Structures in Operative Notes Since operations are considered to be one of the riskier forms of clinical trea</context>
<context position="29890" citStr="Wang et al. (2012)" startWordPosition="4821" endWordPosition="4824">working ports), APP10 (dissect appendix away from other structures), APP11 (divide blood supply), APP12 (di74 Figure 2: Frequencies of action types in the active learning (AL) portion of the data set (left vertical axis) and the batch annotation (BA) portion of the data set (right vertical axis). vide appendix from cecum), and APP14 (remove bag from body) are the most under-represented in the batch annotation data. This confirms our hypothesis that some of the most interesting events have the greatest diversity in expression. In Section 2 we noted that a limitation of the annotation method of Wang et al. (2012) was that a sentence could only have one action. We largely overcame this problem by associating a single surgical action with an event mention. This has one notable limitation, however, as occasionally a single event mention corresponds to more than one action. In our data, APP11 and APP12 are commonly expressed together: • Next, the mesoappendix and appendix is stapledAPP11/APP12 and then the appendix is placedAPP13 in an endobag. Here, a coordination (“mesoappendix and appendix”) is used to associate two events (the stapling of the mesoappendix and the stapling of the appendix) with the sam</context>
</contexts>
<marker>Wang, Pakhomov, Burkart, Ryan, Melton, 2012</marker>
<rawString>Yan Wang, Serguei Pakhomov, Nora E. Burkart, James O. Ryan, and Genevieve B. Melton. 2012. A Study of Actions in Operative Notes. In Proceedings of the AMIA Symposium, pages 1431–1440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Wang</author>
<author>Serguei Pakhomov</author>
<author>Genevieve B Melton</author>
</authors>
<title>Predicate Argument Structure Frames for Modeling Information in Operative Notes.</title>
<date>2013</date>
<booktitle>In Studies in Health Technology and Informatics (MEDINFO),</booktitle>
<pages>783--787</pages>
<contexts>
<context position="8426" citStr="Wang et al. (2013)" startWordPosition="1319" endWordPosition="1322">ating room where general anesthesia was administered. • After the successful induction of spinal anesthesia, she was placed supine on the operating table. The second event mention in the first sentence (administered) and the first event mention in the second sentence (induction) are ignored in Wang et al. (2012)’s study. Despite the fact that they are stated in dependent clauses, these mentions may be more semantically important to the narrative than the mentions in the independent clauses. This is because a grammatical relation does not necessarily imply event prominence. In a further study, Wang et al. (2013) work toward the creation of an automatic extraction system by annotating 69 PropBank (Palmer et al., 2005) style predicateargument structures on thirty common surgical actions. 3 Event Structures in Operative Notes Since operations are considered to be one of the riskier forms of clinical treatment, surgeons follow strict procedures that are highly structured and require significant training and oversight. Thus, a surgeon’s description of a particular operation should be highly similar with a different description of the same type of operation, even if written by a different surgeon at a diff</context>
</contexts>
<marker>Wang, Pakhomov, Melton, 2013</marker>
<rawString>Yan Wang, Serguei Pakhomov, and Genevieve B Melton. 2013. Predicate Argument Structure Frames for Modeling Information in Operative Notes. In Studies in Health Technology and Informatics (MEDINFO), pages 783–787.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Wang</author>
<author>Weide Zhang</author>
<author>Qiang Zeng</author>
<author>Zuofeng Li</author>
<author>Kaiyan Feng</author>
<author>Lei Liu</author>
</authors>
<title>Extracting important information from Chinese Operation Notes with natural language processing methods.</title>
<date>2014</date>
<journal>J Biomed Inform.</journal>
<contexts>
<context position="5211" citStr="Wang et al. (2014)" startWordPosition="800" endWordPosition="803">at can be queried to ensure the necessary surgical elements are present in the narrative. For appendectomies, they could determine whether answers were specified for questions such as “What was the appendix abnormality?” and “Was cautery or drains used?”. Unlike what we propose, they did not attempt to understand the narrative structure of the operative note, only ensure that a small number of important elements were present. Unfortunately, they only tested their rule-based system on four notes, so it is difficult to evaluate the robustness and generalizability of their method. More recently, Wang et al. (2014) proposed a machine learning (ML) method to extract patientspecific values from operative notes written in Chinese. They specifically extract tumor-related information from patients with hepatic carcinoma, such as the size/location of the tumor, and whether the tumor boundary is clear. In many ways this is similar in purpose to Lamiell et al. (1993) in the sense that there are operation-specific attributes to extract. However, while the auditing function primarily requires knowing whether particular items were stated, their method extracts the particular values for these items. Furthermore, th</context>
</contexts>
<marker>Wang, Zhang, Zeng, Li, Feng, Liu, 2014</marker>
<rawString>Hui Wang, Weide Zhang, Qiang Zeng, Zuofeng Li, Kaiyan Feng, and Lei Liu. 2014. Extracting important information from Chinese Operation Notes with natural language processing methods. J Biomed Inform.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>