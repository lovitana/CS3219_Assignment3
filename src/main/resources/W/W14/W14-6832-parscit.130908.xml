<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000380">
<title confidence="0.993894">
Chinese Spell Checking Based on Noisy Channel Model
</title>
<author confidence="0.99717">
Hsun-wen Chiu Jian-cheng Wu Jason S. Chang
</author>
<affiliation confidence="0.987648">
Department of Institute of Information Systems and Applications
National Tsing Hua University
</affiliation>
<email confidence="0.993297">
chiuhsunwen@gmail.com wujc86@gmail.com jason.jschang@gmail.com
</email>
<sectionHeader confidence="0.993762" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99993376">
Chinese spell checking is an important
component of many NLP applications, in-
cluding word processors, search engines,
and automatic essay rating. Compared
to English, Chinese has no word bound-
aries and there are various Chinese in-
put methods that cause different kinds of
typos, so it is more difficult to develop
spell checkers for Chinese. In this paper,
we introduce a novel method for correct-
ing Chinese typographical errors based on
sound or shape similarity. In our approach,
similar characters are automatically gener-
ated using Web corpora, and potential ty-
pos in a given sentence are then corrected
using a channel model and a character-
based language model in the noisy channel
model. In the training phase, we estimate
the channel probabilities for each charac-
ter based on ngrams in Web corpus. At
run-time, the system generates correction
candidates for each character in the given
sentence and selects the appropriate cor-
rection using the channel model and the
language model.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998328396226415">
Spell checking is a necessary task for text process-
ing of every written language, which involves au-
tomatically detecting and correcting typographical
errors. However, compared to spell checkers for
alphabetical languages (e.g., English or French),
Chinese spell checkers are more difficult to de-
velop because there are no word boundaries in
Chinese writing system and errors may be caused
by various Chinese input methods. In this the-
sis, we define typos as Chinese characters that are
misused due to sound or shape similarity. Liu et
al. (2011) show that people tend to unintention-
ally generate typos due to sound similarity (e.g.,
**,š (suo ding) instead of Vš (suo ding)) or
shape similarity (e.g., *M š (xiao ding) instead
of Vš (suo ding)). On the other hand, some ty-
pos found on the Web (e.g., forums or blogs) are
used deliberately for the purpose of speed typing
or just for fun. Therefore, spell checking is an im-
portant component for many applications, includ-
ing computer-aided writing, search engines, and
social media text normalization.
Very little work has been done on the task of
Chinese spell checking. The methods proposed
in the literature can be classified into two types:
rule-based methods and statistical methods. Rule-
based methods use knowledge resources, for ex-
ample, dictionaries, confusion sets, and segmenta-
tion systems. Simple rule-based methods, how-
ever, have their limitations. The following sen-
tence is a snippet collected from students’ written
essays which is correct.
�ffifI%r,FcARt Lt, fflrJ]r?�ART,
, ffl������������@š„
î °(wei she me ni yao ru ci di yong
gong ne ?ru guo wo bu yong gong
na yi hou wo jiang gan bu shang zi ji suo
ding de mu biao °)
Unfortunately, based on simple rules the two char-
acters @ (suo) and š (ding) are likely to be re-
garded as typos of the dictionary word Vš (suo
ding) with identical pronunciation.
The data-driven, statistical spell checking ap-
proach appears to be more robust and perform bet-
ter. Statistical methods typically use a large corpus
to create a language model to validate the correc-
tion hypotheses. Intuitively, by using PE@š„
î (zi ji suo ding de mu biao), the three charac-
ters @š„ (suo ding de) are a trigram with high
probability in a monolingual corpus, we may de-
termine the @š (suo ding) is not a typo after all.
Table 1 shows the frequency and probability of @
š„ (suo ding de) and Vš„ (suo ding de).
</bodyText>
<page confidence="0.970159">
202
</page>
<note confidence="0.989647">
Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 202–209,
Wuhan, China, 20-21 October 2014
</note>
<table confidence="0.874959666666667">
Trigrams Freq. LM prob.(log)
@š„ (suo ding de) 5 -0.70
–š„ (suo ding de) 2 -1.49
</table>
<tableCaption confidence="0.9447355">
Table 1: Example trigrams with corresponding
frequency and probability.
</tableCaption>
<bodyText confidence="0.998650666666667">
In this thesis, we propose a model using sta-
tistical approaches and model generates the most
appropriate corrections in a given sentence. In
the training phase, we automatically generate the
channel model (confusion set). We use a Chinese
spell checker to correct instances in the training
data and estimate the channel probability of a typo
condition on a correct character, then re-estimate
the probability, and iterate until convergence.
At run-time, the checker corrects typos using a
noisy channel model. Consider the following sen-
tence.
</bodyText>
<equation confidence="0.507021">
�À1��‚1i(ŸaP?‚AR
</equation>
<bodyText confidence="0.97735416">
�(Ÿ��å������êñ–
š„î °(wei she me ni yao ru ci di
yong gong ne ?ru guo wo bu yong gong
&apos; na yi hou wo jiang gan bu shang zi ji
suo ding de mu biao °)
The checker generates correction candidates by
the replacements of each character and confusable
characters with channel probabilities in a beam
search algorithm, then calculates the probability of
correction hypotheses according to the language
model and the channel model. Three correction
candidates are shown in Table 2. Finally, the
checker returns the correction with the highest
score, e.g., the follow sentence:
�À1I/Jr, ?‚A�
�(Ÿ��å������êñ@
š„î °(wei she me ni yao ru ci di
yong gong ne ?ru guo wo bu yong gong
&apos; na yi hou wo jiang gan bu shang zi ji
suo ding de mu biao °)
The rest of the paper is organized as follows.
We describe the proposed model for automatically
correcting the spelling typos in section 2. Sec-
tion 3 presents the experimental data. We con-
clude in Section 4.
</bodyText>
<sectionHeader confidence="0.960027" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.9767795">
Using fixed rule to correct typos in a given Chinese
sentence (e.g., êñ–š„î (zi ji suo ding de
</bodyText>
<figure confidence="0.532660142857143">
Hypotheses
�À1��‚1i(ŸaP?‚ART(Ÿ&apos;
�å������êñ@š„î��
�À1��‚1i(ŸaP�‚A��(Ÿ�
�å������êñ�š„î��
�À1��‚1i(ŸaP?‚ART(Ÿ&apos;
�å������êñ–š„î��
</figure>
<tableCaption confidence="0.8140385">
Table 2: The three correction candidates of the
given sentence.
</tableCaption>
<bodyText confidence="0.999381935483871">
mu biao)) does not work very well. Previous work
typically corrects typos based on a set of detection
rules. Unfortunately, the detection rules depend on
a lot of resources, and can be at times unreliable.
Typo positions usually are detected using heuristic
rules based on Chinese dictionary, word segmen-
tation and the frequency of the ngram. However,
Chinese dictionary, and word segmentation have
their limitations. For example, the segmentation
result of the sentence ”êñ–š„î ” is ”ê
ñ/–š/„/î ”, the two characters – and š
may or may not be considered as a word, depend
on the segmentation system. To avoid the limita-
tions of rule-based method, a promising approach
for Chinese spell checking is to train a noisy chan-
nel model based on unannotated data, which con-
taining many information.
In the rest of this section, we describe our
solution to the problem of Chinese spell check-
ing. We describe the process of training the
channel model in Section 2.1. More specifi-
cally, we describe the method for limiting con-
fusable characters in Section 2.1.1, and the use
of ngrams in Section 2.1.2. We will also de-
scribe an Expectation-Maximization (EM) algo-
rithms for estimating channel probabilities in Sec-
tion 2.1.3. This algorithm relies on a set of con-
fusable characters and ngrams. Finally in Sec-
tion 2.2, we describe how to correct typos using
the trained noisy channel model at run-time by
combining channel model and language model.
</bodyText>
<subsectionHeader confidence="0.954575">
2.1 Training Channel Model
</subsectionHeader>
<bodyText confidence="0.997840666666667">
We attempt to learn to develop a channel model
from the ngrams of Web corpus for correcting Chi-
nese spell typos.
</bodyText>
<page confidence="0.998649">
203
</page>
<table confidence="0.998595428571428">
Type Sound Shape
Full MMIPIÜ��.R
������� �������
������— �������
°3¢¬®Šš �������
��”˜ ��
Limited �Ü–
</table>
<tableCaption confidence="0.997675">
Table 3: The full confusion set and the limited
confusion set of –.
</tableCaption>
<subsectionHeader confidence="0.978151">
2.1.1 Limiting Confusable Characters
</subsectionHeader>
<bodyText confidence="0.999986454545455">
In the first stage of training the channel model, we
limit the confusable characters based on the sound
and shape similar characters, which containing un-
likely confusable characters (as the full confusion
set). For example, the full confusion set of –
(suo) is shown in Table 3. Liu et al. (2011) ana-
lyzed erroneous Chinese character and found that
more than 70% of typos were related to the phono-
logically similar characters, about 50% are visu-
ally similar, and almost 30% are both phonologi-
cally and visually similar. The goal of this method
is to reduce the sizes of the confusion sets and im-
prove the accuracy.
The input to this stage is a set of confusable
characters. These confusable characters consti-
tutes the full confusion set. We generate potential
confusable characters by reducing some unlikely
confusable relations and expanding the confusable
characters slightly.
The output of this stage is confusion sets that
can be used to correct ngrams for training channel
model. Limited confusion set of – (suo), auto-
matically generated from the full confusion set is
shown in Table 3. We can see that the limited con-
fusion set minimize the confusable characters and
select more likely characters. The limited confu-
sion set is used to accurately correct ngrams and
reduce the computational complexity.
Our method for limiting confusable characters
can generate many characters, potentially includ-
ing a significant number of characters that are not
useful in correcting typos. We also remove some
loosely similarly relations and expand the confus-
able characters slightly. For example, we remove
all relations based on non-identical phonologically
similarity. After that, we add the similarly sound-
ing characters based on nasal consonant in Chi-
nese phonetics (e.g., ”Li , L” (en, eng) and ”moi
, *_” (an, ang)), and retroflex consonant (e.g.,
”!a , lP” (shi, si) and ”T , fi” (chi, chi)). We
also modify the shape similarity by comparing the
characters in Cangjie codes (AM) to filter out
confusable characters with low similarity. We re-
tain character pairs differing from each other by
at most one symbol in Cangjie codes that tend to
be highly similar in shape. For example, the code
of 0 (zheng) and A (wei) are highly similar in
shape, and their corresponding codes ”ffAW±
�k” and ”ff�WW�k”, differ only in one place.
Note that we do not attempt to estimate the
channel probabilities of typos of a character at this
point. In contrast, we only use sound or shape
similarity to limit confusable characters, leading
to more effective confusion set as the basis for sub-
sequent probability estimation.
</bodyText>
<subsectionHeader confidence="0.834168">
2.1.2 Retrieving Ngrams
</subsectionHeader>
<bodyText confidence="0.999991413793103">
In the second stage of the training phase, we re-
trieve ngrams (e.g., FJTi5V-FI )W, (suo ding mu biao))
possibly containing a typo characters (e.g., PJTf
(suo)) that can be corrected using the confusable
characters (e.g., FJTi (suo), – (suo), or t, (suo)).
Because estimating channel probabilities need a
parallel corpus with typos annotated, we use an
existing Chinese spell checker CSC to correct ty-
pos in the ngrams. We use ngrams generated based
on collocates of high frequency words containing
the confusable character. The procedure for re-
trieving and correcting ngrams consist of a number
of steps, namely, generating collocates for words
containing a specific character, filtering these col-
locates by frequency, producing the ngrams for the
remaining collocates, and correcting these ngrams
using CSC. Each step is described below in detail.
For this stage of the learning process, we use a
collection of (Word, Collocate) pairs (e.g., (P )W,,
–5V-) ((mu biao, suo ding)), (lku[fi, –5V-) ((ban
mian, suo ding))). We generate the word from the
corpus using word frequency and find correspond-
ing collocates using Dice coefficient, which is a
statistic association value used for comparing the
relation of words and collocates. The collocates of
each word are sorted according to the Dice coeffi-
cient. We retain at most K collocates per word to
reduce the computational cost. We compute Dice
coefficient using the following equation:
</bodyText>
<equation confidence="0.999659333333333">
2 · freq(w) · freq(c)
Dice(w, c) = (1)
freq(w) + freq(c)
</equation>
<bodyText confidence="0.994686">
where freq(w) is the frequency of the word, and
freq(c) is the frequency of the collocate. Take –
</bodyText>
<page confidence="0.988648">
204
</page>
<table confidence="0.9999059375">
Words Collocates Dice
–š lkX f�1 .025
M .021
fl1&apos; q .004
î~ .004
1 .004
E“ .002
96A .001
.. .001
Words Collocates Dice
~– LB .019
_Rtbl .017
5� .015
�Æ .007
2a .002
�� .001
</table>
<tableCaption confidence="0.99689">
Table 4: Two sample collocates of –š and �–.
</tableCaption>
<table confidence="0.996935555555555">
Typos Texts Count
@ V&apos; @ š îO 86
1W @ š îO 83
AN @ š îO 44
RfI @ š „ î 42
&amp;quot;&amp;quot;š�c 66
6
&amp;quot; š 93
&amp;quot; šn fi� 40
</table>
<tableCaption confidence="0.8235215">
Table 5: Sample texts of typo @ and &amp;quot; of – from
the corpus.
</tableCaption>
<bodyText confidence="0.999454416666667">
(suo) for instance, the words (e.g., –š (suo ding)
and �– (feng suo)) and their corresponding col-
locates of words are shown in Table 4. The word
–š (suo ding) has the highest Dice coefficient of
0.025 with the collocate fkfffi (ban mian), while
�– (feng suo)) has the highest Dice coefficient
of 0.019 with the collocate MLB (chong chu).
For each (Word, Collocate) pair, we generate all
possible potential ngrams N containing Word and
Collocate. This stage of the learning process op-
erates over a corpus of ngram words. The sample
texts of the typos (@, &amp;quot;, and ) of – found in a
</bodyText>
<table confidence="0.99706625">
Words Collocates Characters Instances
–š îO @ î @š
~– 5W &amp;quot; 5WJ�&amp;quot;
�– )HE Jpf&apos;r*
</table>
<tableCaption confidence="0.7629735">
Table 6: A sample of instances containing charac-
ter – and potentially confusable characters.
</tableCaption>
<bodyText confidence="0.99954575">
corpus is shown in Table 5. We find the ngrams in
the corpus with identical collocates and Word con-
taining confusable characters (e.g., (@š, î~)).
Sample instances of character – is shown in Ta-
ble 6. In this sample, we can find that – may be
misused as confusable characters (e.g., @, &amp;quot;, )
in the corpus with such information in the ngrams,
we can generate typo pairs (e.g., [@, –], [&amp;quot;, –],
[, –]). Finally, we correct the typos in these
ngrams by using existing Chinese spell checker (In
Section 2.1.3). With the typos and corrections, we
can estimate the channel probabilities.
</bodyText>
<subsectionHeader confidence="0.996024">
2.1.3 Correcting Ngrams and Training
Channel Model
</subsectionHeader>
<bodyText confidence="0.982359885714286">
In the third and final stage of training, we correct
the ngrams and train the channel model for sup-
porting correction candidates. Figure ?? shows the
algorithm for correcting ngrams using a Chinese
spell checker and estimating the channel proba-
bilities related to typo pairs. The procedure is
repeated for all ngrams obtained in the previous
stage until the channel probabilities converge.
We are given a set of ngrams as training data
(described in Section 2.1.2). Recall that our goal
is to estimate the channel model for each charac-
ter, in the form of [original, correction, log chan-
nel probability] (e.g., [@, –, -4.284] and [&amp;quot;, –,
-5.264]). In order to generate a parallel corpus, we
need to provide representative ngrams to the train-
ing algorithm. The training set is created by re-
trieving the ngrams from Words of each character
and the corresponding Collocates in the corpus.
We apply a previously developed Chinese spell
checker(CSC) to correct ngrams. In this checker,
we adopt the confusion set limited in Stage (1) to
reduce the unlikely confusable characters and im-
prove the accuracy for generating typo pairs. We
combine the global error probability (GP) and lo-
cal error probability (LP) to reliably estimate the
channel probabilities (CP) using following equa-
tion:
CP(O, C) = WGL ·GP +(1−WGL)·LP(O, C)
(2)
where O is original character, C is corrected char-
acter, and WGL is a weight for probability. The
global error probability is a prior probability cal-
culated from a development data set, which can
instead the detection and avoid data sparse. The
global error probability calculated by the follow-
</bodyText>
<page confidence="0.997187">
205
</page>
<table confidence="0.999529285714286">
Ngrams Corrections Typo Pairs
F1 @5V_ F1 @5V_ [FI, F1], [ , ]
5WIft, 5W�– [@, @], [5, 5V_]
)aM&apos;Mc )aMM– [5, 5], [W, W]
[�, 1�], [&amp;quot;, –]
[)a, )a], [M, M]
[om, &apos;r], [c, –]
</table>
<tableCaption confidence="0.9493545">
Table 7: A sample of the typo pairs for –.
ing equation.
</tableCaption>
<equation confidence="0.996703">
count(nochange)
count(char)
GP(Devedata) = (3)
count(typos)
count(char)
</equation>
<bodyText confidence="0.999927285714286">
where count(nochange) is the count of corrected
characters, count(typos) is the count of typos, and
count(char) is the count of characters. The Deve-
data is the development data.
We use the Expectation-maximization algo-
rithm to estimate the local error probabilities re-
lated to the confusion set. We initialize the confu-
sion set with uniformed probability in the E-step
and re-estimate the probability of each character in
M-step until the local error probability converge.
For each of the potentially confused ngram (e.g.,
@5V-F1f0i (suo ding mu biao), we attempt to find
typos and corrections using CSC (Step (1)) and
produce the typo pairs (Step (2)). The typo pairs
are in the form of [Original, Correction]. The
frequency is the count of how many times of the
ngram occurs in the corpus. We estimate the local
error probability based on nochange pair (e.g., [@,
@] ([suo, suo])), and correction pair (e.g., [@, –]
([suo, suo])). In Table 7, we show a sample of the
typo pairs in the ngrams of the character – (suo).
Then we calculate the global error probability
using the development data (Step (3)). In Step (4),
the typo pairs are sorted according to the Original.
For each [Original, Correction] pair, we calculate
the local error probability of the Original condi-
tioned on Correction (Step (5a)). The probability
is calculated as follows:
</bodyText>
<equation confidence="0.93482">
count(O, CO)
LP(CO, O) = (4)
count(O)
</equation>
<bodyText confidence="0.87421225">
As shown in Table 8, the total count of @ (suo) is
6799532 + 529 + 235 = 6800296, the count of (&amp;quot;,
@) is 235, and the LocalErrorProbability(&amp;quot;—@)
is calculated as follows:
</bodyText>
<table confidence="0.9956274">
Original Correction Frequency
@ @ 6,799,532
@ E 529
@ &amp;quot; 235
Total Frequency 6,800,296
</table>
<tableCaption confidence="0.977975">
Table 8: Sample of the typo pairs with frequency.
</tableCaption>
<table confidence="0.999835333333333">
Original Correction Freq. LPlog
@ @ 6799532 -0.0001
@ E 529 -9.4614
@ &amp;quot; 235 -10.2728
@ c 1 -15.7324
@ – 1 -15.7324
</table>
<tableCaption confidence="0.932343">
Table 9: The result of the local error probability
with smoothing.
</tableCaption>
<equation confidence="0.996871">
LocalErrorProbability(&amp;quot;—@) = Count(&amp;quot;,
@)) / Count(@) = 235/6800296 =0.0000346
</equation>
<bodyText confidence="0.999945521739131">
However, we can not estimate that @ (suo) as
a typo of c (suo), if CSC does not find [@, c]
([suo, suo]). In that case, we use smoothing al-
gorithm to solve this problem. If a confusable
character does not has a certain typo pair, we use
add-one smoothing algorithm to deal with the un-
seen problem. For example, confusable characters
(e.g., c, –) of @ (suo) are not found in the cor-
pus, so we add count one for them. Table 9 shows
a confusion set of @ (suo) and the corresponding
smoothed local error probability.
We combine the global error probability and
the local error probability to estimate the chan-
nel probabilities in Step (5b), and save the Orig-
inal, Correction, and their channel probability in
the channel model in Step (5c). Steps (1) through
(5) are repeated to re-estimate the local error prob-
ability until the probabilities converge. The output
of this stage of training is a channel model with
reliable probabilities, automatically estimated us-
ing the confusable characters and ngrams based on
collocates. A samples of the channel model for @
(suo) is shown in Table 10.
</bodyText>
<subsectionHeader confidence="0.999716">
2.2 Run-time Typo Correction
</subsectionHeader>
<bodyText confidence="0.998063857142857">
Once the channel model is automatically trained
for each character, we store the model as a con-
fusion set. We then correct a given sentence us-
ing the procedure shown in Figure ?? with the
character-based language model and the channel
model.
For each character in the given sentence of n
</bodyText>
<page confidence="0.995968">
206
</page>
<table confidence="0.999772166666667">
Original Correction Freq. CPlog
@ @ 6799532 -0.1416
@ �t 529 -2.2111
@ 235 -4.4357
@ 1 -10.4947
@ M 1 -10.4947
</table>
<tableCaption confidence="0.95214">
Table 10: A sample of the channel model for @
(suo).
</tableCaption>
<table confidence="0.997795777777778">
Originals Corrections Ngrams Score
P P () 0.0
ñ ñ (,P) -2.6049
M @ (P,ñ) -2.6756
š š (ñ,@) -5.1145
„ „ (@,š) -6.3698
î î (š,„) -5.1627
(„,î) -5.7875
(î,) -10.2282
</table>
<tableCaption confidence="0.999599">
Table 11: A sample of the hypotheses.
</tableCaption>
<bodyText confidence="0.999532133333333">
characters (e.g., PñMš„îM (zi ji suo ding
de mu biao)), we correct typos as follows. In Step
(1), the system initializes n stacks for the channel
model, [Character, Ngram, Score]. In Step (2), the
system replaces each character with the confus-
able characters (e.g., @, , ,M (suo, suo, suo,
suo)) in the channel model as the correction can-
didates. For each confusable characters, we cre-
ate new hypotheses with a score, character ngram
state, character, and correction candidates. In or-
der to reduce computational complexity, we use
beam search algorithm to replace each and calcu-
late the score of sentences. The score in a hypoth-
esis is calculated based on the channel model and
the language model as follows.
</bodyText>
<equation confidence="0.999858">
S(hypothesis) = log(LPWLC · CP(1−WLC)) (5)
= WLC · log(LP) + (1 − WLC) · log(CP) (6)
</equation>
<bodyText confidence="0.999306454545455">
where LP is language model probability, CP is
channel probability, and WLC is a weight param-
eter in channel model and language model. A
sample hypothesis is shown in Table 11. In Step
(3), the new hypothesis are stored in the stack and
combined with the existing hypothesis in Step (4).
If the stack has too many hypotheses, we prune the
stack down to a fixed size in Step (5).
Finally in Step (6), we compare the score of all
the hypotheses in the last stack, and output the cor-
rection candidate with the highest score as output.
</bodyText>
<table confidence="0.8962052">
Sentences
Given G0��������Ç����
Corrected G0��������Ç����
Given ������0„���˜�
Corrected ������0„���˜�
</table>
<tableCaption confidence="0.833521">
Table 12: A sample of the given sentences and cor-
rections.
</tableCaption>
<bodyText confidence="0.997851125">
When there is no correction candidates with the
highest score (e.g., score(Pñ@š„î ) = -
10.2282), we output the given sentence. Table 12
shows three input sentences and the corresponding
corrected sentences output. For example, A (jing)
is corrected as A (jing), because A (jing) is the
most appropriate for the context of G0% *
(yu dao ni jing shi).
</bodyText>
<sectionHeader confidence="0.988563" genericHeader="method">
3 Experiment Setting
</sectionHeader>
<bodyText confidence="0.999972357142857">
Our systems were designed to provide wide cov-
erage spell checking for Chinese texts. As such,
we trained our systems using the confusion set, a
compiled corpus, Web-scale ngrams, and an ex-
isting Chinese spell checker. These resources are
used for different purposes: the confusion sets
provide the correction candidates; the compiled
corpus provide the training data for the language
model; Web-scale ngrams and the existing Chi-
nese spell checker are used for training the chan-
nel model. We evaluate our systems on the sen-
tence level. In this section, we present the details
of data sources used in training(Section 3.1 to Sec-
tion 3.4).
</bodyText>
<subsectionHeader confidence="0.999807">
3.1 Confusion Set
</subsectionHeader>
<bodyText confidence="0.999981533333333">
The confusion sets we used are the same as in Liu
et al. (2011) and provided for SIGHAN 7 Bake-
off 2013: Chinese Spelling Check Shared Task.
The confusion sets represent sound similarity and
shape similarity between a typo and potential cor-
rections.
There four categories of phonological similarity
between two characters: identical sound and tone
(II), identical sound but different tone (ID), sim-
ilar sound and identical tone (SI), similar sound
and different tone (SD), and identical radical and
number of strokes (RS). A sample of sound-related
confusion sets from SIGHAN 7 Bake-off 2013.
In this sample, the confusion sets of ò (yi), Ç
(yong), and WA (hu) contain a lot of unlikely con-
</bodyText>
<page confidence="0.991533">
207
</page>
<table confidence="0.994689833333333">
N-gram Types Google Chinese 5-gram
Unigram 1,616,150
Bigram 281,107,315
Trigram 1,024,642,142
Fourgram 1,348,990,533
Fivegram 1,256,043,325
</table>
<tableCaption confidence="0.9960345">
Table 13: The information of n-grams in Google
Chinese 5-gram.
</tableCaption>
<table confidence="0.999113">
N-gram Types Traditional Chinese 5-gram
Unigram 527,694
Bigram 102,092,428
Trigram 237,599,483
Fourgram 201,500,549
Fivegram 126,959,922
</table>
<tableCaption confidence="0.9785405">
Table 14: The information of n-grams in Tradi-
tional Chinese 5-gram.
</tableCaption>
<bodyText confidence="0.999572076923077">
fusable characters. Examples of unlikely pairs in-
clude E (yi) and 0 (yi) in ID, A (yong) and f
(wen) in SI, WA (hu) and fN (fu) in SD. The shape-
related confusion sets of E (yi), A (yong), and WA
(hu). The confusion sets also contain loosely sim-
ilarly relations, for instance, E (yi) and R (quan)
are not very similar visually.
In our work, we expand the sets slightly and also
remove some unlikely confusable characters in or-
der to improve the performance. We modify the
confusion set using the pronunciation and Cangjie
codes (AM). The process is described in detail
in Section 2.1.1.
</bodyText>
<subsectionHeader confidence="0.996332">
3.2 Google Chinese Web 5-gram
</subsectionHeader>
<bodyText confidence="0.999991578947368">
In 2010, Google published a Chinese Web 5-gram
dataset based on public webpages through Lin-
guistics Data Consortium (LDC).1 Chinese Web
5-gram consists of Chinese word n-grams and
their observed frequency counts generated from
approximately 883 billion word tokens of text in
publicly accessible Web pages. The Google Chi-
nese Web 5-gram contains 30 GB (gzip com-
pressed) of text files with n-grams ranging from
unigrams (single words) to fivegrams. In this
work, we used only the traditional Chinese 5-
grams. Table 13 and Table 14 show the informa-
tion of 5-grams in Google Chinese Web 5-gram
and traditional Chinese Web 5-gram. We use the
traditional Chinese Web 5-gram to retrieve ngrams
(at most ten Words) in the training phase for esti-
mate channel model probabilities. The advantage
of using the Web ngram is that unlike a compiled
corpus, it contains many typos.
</bodyText>
<subsectionHeader confidence="0.997873">
3.3 Existing Chinese Spell Checker
</subsectionHeader>
<bodyText confidence="0.990267666666667">
We use an existing Chinese spell checker (CSC)
we previously developed in 2013 (Chiu et al.,
2013) with the training data described in (Wu et
</bodyText>
<footnote confidence="0.9606815">
1https://catalog.ldc.upenn.edu/
LDC2010T06
</footnote>
<bodyText confidence="0.999310052631579">
al., 2013). This CSC is based on a novel method
for detecting and correcting Chinese typographical
typos. The approach involves word segmentation,
detection rules, and phrase-based machine transla-
tion. The error detection module detects typos by
segmenting words and checking word and phrase
frequency based on compiled and Web corpora.
The phonological or morphological typographical
typos found then are corrected by running a de-
coder based on the statistical machine translation
model. The language model is trained using the
word-based corpus using the SRILM (Stolcke et
al., 2011) toolkit. The translation model is trained
using the frequency of the word containing typos
and the corrected word. The results show that
the proposed system achieves high accuracy in er-
ror detecting and correcting. We use this Chinese
spell checker to train the channel model and as a
system to compared with the proposed method.
</bodyText>
<subsectionHeader confidence="0.900325">
3.4 Sinica Corpus
</subsectionHeader>
<bodyText confidence="0.990729833333333">
”Academia Sinica Balanced Corpus of Modern
Chinese”, or ”Sinica Corpus”, is the first bal-
anced Chinese corpus with part-of-speech tags.
The size of the corpus we used is about 5 mil-
lion words. The corpus is segmented according
to the word segmentation standard proposed by
the ROC Computational Linguistic Society. Each
segmented word is manually tagged with a part
of speech. Texts in the corpus are collected from
different areas: Literature, Life, Society, Science,
Philosophy, and Art. Table 15 shows the informa-
tion about numbers of word, character, article, and
percentage by area. We use Sinica Corpus (ignor-
ing word segmentation) to train a character-based
n-gram language model running the SRILM (Stol-
cke et al., 2011) toolkit. The sizes of the ngrams
of the character-based language model is shown in
Table 16
</bodyText>
<page confidence="0.988383">
208
</page>
<table confidence="0.800158666666667">
Areas Word Token Character Article
Literature 777,050 1,169,801 1,385
Life 858,750 1,398,791 2,301
Society 1,610,997 2,711,720 3,246
Science 629,838 1,054,738 994
Philosophy 439,955 673,080 695
Art 474,340 781,415 518
Others 101,394 160,306 89
Total Count 4,892,324 7,949,851 9228
</table>
<tableCaption confidence="0.999209">
Table 15: The information of the word, character,
article, and percentage in the area of sinica corpus.
</tableCaption>
<table confidence="0.590757333333333">
Ngram Types Ngram Count
Unigram 17,201
Bigram 741,739
Trigram 859,442
Fourgram 791,846
Fivegram 588,200
</table>
<tableCaption confidence="0.888024">
Table 16: The information of n-grams in
character-based language model.
</tableCaption>
<sectionHeader confidence="0.997794" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999981774193549">
Many avenues exist for future research and im-
provement of our system. For example, confusion
sets can be automatically generated using Web-
based character n-grams to improve correction
performance. Part of speech tagging can be per-
formed to provide more information for the noisy
channel model. Named entities can be recognized
in order to avoid false alarms. A supervised statis-
tical classifier can be used to model channel proba-
bility more accurately. Additionally, an interesting
direction to explore is using Web corpus in addi-
tion to a compiled corpus for correcting typos. Yet
another direction of research would be to consider
errors related to a missing or redundant character,
or collect data from user to update channel proba-
bilities dynamically.
In summary, we have introduced a novel
method for Chinese spell checking. In our ap-
proach, the channel model is trained based the
sound and shape similarity using Web corpus, and
the potential typos in a given sentence is cor-
rected using a noisy channel model. In the train-
ing phase, we limit the confusable characters, re-
trieve the ngrams from the Web corpus, and cor-
rect ngrams and estimate the channel probability.
At run-time, our system generate the correction
candidates and calculate their probabilities using
the language model and channel model from a
given sentence. The results prove that the chan-
nel probability we estimate for the noisy channel
model are useful in Chinese spell checking.
</bodyText>
<sectionHeader confidence="0.996432" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999702666666667">
[Chiu et al.2013] Hsun-wen Chiu, Jian-cheng Wu, and
Jason S. Chang. 2013. Chinese spelling checker
based on statistical machine translation. In Sixth In-
ternational Joint Conference on Natural Language
Processing, page 49.
[Liu et al.2011] C-L Liu, M-H Lai, K-W Tien, Y-H
Chuang, S-H Wu, and C-Y Lee. 2011. Visually
and phonologically similar characters in incorrect
chinese words: Analyses, identification, and appli-
cations. ACM Transactions on Asian Language In-
formation Processing (TALIP), 10(2):10.
[Stolcke et al.2011] Andreas Stolcke, Jing Zheng, Wen
Wang, and Victor Abrash. 2011. Srilm at sixteen:
Update and outlook. In Proceedings of IEEE Auto-
matic Speech Recognition and Understanding Work-
shop, page 5.
[Wu et al.2013] Shih-Hung Wu, Chao-Lin Wu, and
Lung-Hao Lee. 2013. Chinese spelling check evalu-
ation at sighan bake-off 2013. In Proceedings of the
7th SIGHAN Workshop on Chinese Language Pro-
cessing, pages 35–42.
</reference>
<page confidence="0.998957">
209
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.948517">
<title confidence="0.996439">Chinese Spell Checking Based on Noisy Channel Model</title>
<author confidence="0.999755">Hsun-wen Chiu Jian-cheng Wu Jason S Chang</author>
<affiliation confidence="0.9996195">Department of Institute of Information Systems and National Tsing Hua University</affiliation>
<email confidence="0.960943">chiuhsunwen@gmail.comwujc86@gmail.comjason.jschang@gmail.com</email>
<abstract confidence="0.999658730769231">Chinese spell checking is an important component of many NLP applications, including word processors, search engines, and automatic essay rating. Compared to English, Chinese has no word boundaries and there are various Chinese input methods that cause different kinds of typos, so it is more difficult to develop spell checkers for Chinese. In this paper, we introduce a novel method for correcting Chinese typographical errors based on sound or shape similarity. In our approach, similar characters are automatically generated using Web corpora, and potential typos in a given sentence are then corrected using a channel model and a characterbased language model in the noisy channel model. In the training phase, we estimate the channel probabilities for each character based on ngrams in Web corpus. At run-time, the system generates correction candidates for each character in the given sentence and selects the appropriate correction using the channel model and the language model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hsun-wen Chiu</author>
<author>Jian-cheng Wu</author>
<author>Jason S Chang</author>
</authors>
<title>Chinese spelling checker based on statistical machine translation.</title>
<date>2013</date>
<booktitle>In Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>49</pages>
<marker>[Chiu et al.2013]</marker>
<rawString>Hsun-wen Chiu, Jian-cheng Wu, and Jason S. Chang. 2013. Chinese spelling checker based on statistical machine translation. In Sixth International Joint Conference on Natural Language Processing, page 49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-L Liu</author>
<author>M-H Lai</author>
<author>K-W Tien</author>
<author>Y-H Chuang</author>
<author>S-H Wu</author>
<author>C-Y Lee</author>
</authors>
<title>Visually and phonologically similar characters in incorrect chinese words: Analyses, identification, and applications.</title>
<date>2011</date>
<journal>ACM Transactions on Asian Language Information Processing (TALIP),</journal>
<volume>10</volume>
<issue>2</issue>
<marker>[Liu et al.2011]</marker>
<rawString>C-L Liu, M-H Lai, K-W Tien, Y-H Chuang, S-H Wu, and C-Y Lee. 2011. Visually and phonologically similar characters in incorrect chinese words: Analyses, identification, and applications. ACM Transactions on Asian Language Information Processing (TALIP), 10(2):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Jing Zheng</author>
<author>Wen Wang</author>
<author>Victor Abrash</author>
</authors>
<title>Srilm at sixteen: Update and outlook.</title>
<date>2011</date>
<booktitle>In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop,</booktitle>
<pages>5</pages>
<marker>[Stolcke et al.2011]</marker>
<rawString>Andreas Stolcke, Jing Zheng, Wen Wang, and Victor Abrash. 2011. Srilm at sixteen: Update and outlook. In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop, page 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shih-Hung Wu</author>
<author>Chao-Lin Wu</author>
<author>Lung-Hao Lee</author>
</authors>
<title>Chinese spelling check evaluation at sighan bake-off</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>35--42</pages>
<marker>[Wu et al.2013]</marker>
<rawString>Shih-Hung Wu, Chao-Lin Wu, and Lung-Hao Lee. 2013. Chinese spelling check evaluation at sighan bake-off 2013. In Proceedings of the 7th SIGHAN Workshop on Chinese Language Processing, pages 35–42.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>