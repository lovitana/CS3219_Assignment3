<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001050">
<title confidence="0.9968175">
Facilitating Multi-Lingual Sense Annotation:
Human Mediated Lemmatizer
</title>
<author confidence="0.961704">
Pushpak Bhattacharyya Ankit Bahuguna Lavita Talukdar Bornali Phukan
</author>
<affiliation confidence="0.974015">
IIT Bombay IIT Bombay / TU Munich IIT Bombay IIT Bombay
</affiliation>
<email confidence="0.988867">
pushpakbh@gmail.com ankitbahuguna@outlook.com lavita.talukdar@gmail.com bornali31phukan@gmail.com
</email>
<sectionHeader confidence="0.99371" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999894358974359">
Sense marked corpora is essential for super-
vised word sense disambiguation (WSD). The
marked sense ids come from wordnets. How-
ever, words in corpora appear in morphed
forms, while wordnets store lemma. This sit-
uation calls for accurate lemmatizers. The
lemma is the gateway to the wordnet. How-
ever, the problem is that for many languages,
lemmatizers do not exist, and this problem is
not easy to solve, since rule based lemmatiz-
ers take time and require highly skilled lin-
guists.Satistical stemmers on the other hand do
not return legitimate lemma.
We present here a novel scheme for creating
accurate lemmatizers quickly. These lemma-
tizers are human mediated. The key idea is that
a trie is created out of the vocabulary of the
language. The lemmatizing process consists in
navigating the trie, trying to find a match be-
tween the input word and an entry in the trie.
At the point of first mismatch, the yield of the
subtree rooted at the partially matched node is
output as the list of possible lemma. If the cor-
rect lemma does not appear in the list- as noted
by a human lexicographer- backtracking is ini-
tiated. This can output more possibilities. A
ranking function filters and orders the output
list of lemma.
We have evaluated the performance of this
human mediated lemmatizer for eighteen In-
dian Languages and five European languages.
We have compared accuracy values against
well known lemmatizers/stemmers like Mor-
pha, Morfessor and Snowball stemmers, and
observed superior performance in all cases.
Our work shows a way of speedily creating
human assisted accurate lemmatizers, thereby
removing a difficult roadblock in many NLP
tasks, e.g., sense annotation.
</bodyText>
<sectionHeader confidence="0.999011" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997157">
Supervised WSD- the ruling paradigm for high
accuracy sense determination- requires sense
marked corpus in large quantity. Sense annota-
tion is a difficult job, requiring linguistic expertise,
knowledge of the topic and domain, and most im-
portantly a fine sense of word meanings.
Most often the sense annotation task is accom-
plished by using a Sense Marker Tool, like the one
described in Chatterjee et. al. (2010). This partic-
ular tool, equipped with an easy to use GUI facili-
tates the task of manually marking each word with
the correct sense of the word, as available in the
wordnet of the language. The tool has the word-
net sense repository resident in its memory. It dis-
plays the senses of word for the human annotator
to choose from. The mentioned tool is extensively
used by a number of language groups in India to
produce high quality sense marked corpus. Figure
1 shows the Sense Marker Tool, where a user is
marking the sense of the word “banks” in English.
</bodyText>
<figureCaption confidence="0.8117655">
Figure 1: Sense Marking Tool - manually marking
correct sense for English word “banks”
</figureCaption>
<bodyText confidence="0.985897779411765">
Now it is obvious that if the wordnet is to be ac-
cessed for the senses to be displayed, the lemma
of the words must be available. The lemma is the
gateway to the wordnet. Lemmatization is an im-
portant activity in many NLP applications. We
stress at this point that our focus of attention is
lemmatization and not stemming. As a process,
stemming aims to reduce a set of words into a can-
nonical form which may or may not be a dictio-
nary word of the language. Lemmatization, on the
other hand, always produces a legal root word of
the language. To give an example, a stemmer can
give rise to “ladi” from “ladies”. But a lemmatizer
will have to produce “lady”. And if the senses of
‘ladies’ has to be found, the lemma ‘lady’ is re-
quired.
There are three basic approaches to lemmatiza-
tion, viz., affix removal (rule based systems), sta-
tistical (supervised/unsupervised) and hybrid (rule
based + statistical). Developing a rule based
system is an uphill task, requiring a number of
language experts and enormous amount of time.
Purely statistical systems fail exploit linguistic
features, and produce non-dictionary lexemes. A
hybrid system utilizes both the above mentioned
approaches.
Figure 2: Sense Marking Tool - Input Language:
Hindi
In this paper, we discuss an alternative approach
to lemmatization which is quick, takes user help
and is exact. The key idea is that a trie is created
out of the vocabulary of the language. The lemma-
tizing process consists in navigating the trie, trying
to find a match between the input word and an en-
try in the trie. At the point offirst mismatch- i.e.,
maximum prefix matching, the yield of the subtree
rooted at the partially matched node is output as
the list of possible lemma. If the correct lemma
does not appear in the list- as noted by a human
lexicographer- a backtracking is initiated. This can
output more possibilities, since the yield of a node
at a higher level of the trie is output. A ranking
function filters and orders the output list of lemma.
Our ultimate goal is to integrate the human me-
diated lemmatizer with the Sense Marking Tool
(Figure 2).Currently, the tool supports the follow-
ing 9 languages: English, Hindi, Marathi, Tamil,
Telugu, Kannada, Malayalam, Bengali and Pun-
jabi.
We give an example to give a feel for how our
lemmatiser works. When a linguist tries to mark
the correct sense of the inflected Assamese word
as shown in Figure 3 (‘gharalai’ meaning ‘in the
house’), in the current scenario no output is dis-
played, but with our lemmatizer integrated, it will
show the possible lemma of that word.
Here, the correct lemma is shown at the top of
the list, and the lemma can pull out the senses from
the wordnet for the linguist to tag with.
The remainder of this paper is organized as fol-
lows. We describe related work and background
in section 2. Section 3 explains the core of our
human mediated lemmatiser. Implementation de-
tails are in Section 4. Experiments and results are
discussed in Section 5. Comparison with existing
stemmers/lemmatizers are in Section 6. Section
7 concludes the paper and points to future direc-
tions.
</bodyText>
<sectionHeader confidence="0.997974" genericHeader="related work">
2 Related Work and Background
</sectionHeader>
<bodyText confidence="0.960914571428572">
Lovins described the first stemmer (Lovins, 1968),
which was developed specifically for IR/NLP ap-
plications. His approach consisted of the use of
a manually developed list of 294 suffixes, each
linked to 29 conditions, plus 35 transformation
rules. For an input word, the suffix with an
appropriate condition is checked and removed.
Porter developed the Porter stemming algorithm
(Porter, 1980) which became the most widely
used stemming algorithm for English language.
Later, he developed stemmers that covered Ro-
mance (French, Italian, Portuguese and Spanish),
Germanic (Dutch and German) and Scandinavian
languages (Danish, Norwegian and Swedish), as
</bodyText>
<figureCaption confidence="0.991271">
Figure 3: Tool shows no output for inflected Assamese word “ghoroloi” (highlighted) meaning to home.
</figureCaption>
<bodyText confidence="0.99819905">
well as Finnish and Russian (Porter, 2006). These
stemmers were described in a very high level lan-
guage known as Snowball1.
A number of statistical approaches have been
developed for stemming. Notable works in-
clude: Goldsmith’s unsupervised algorithm for
learning morphology of a language based on the
Minimum Description Length (MDL) framework
(Goldsmith, 2001; 2006). Creutz uses prob-
abilistic maximum a posteriori (MAP) formu-
lation for unsupervised morpheme segmentation
(Creutz, 2005; 2007).
A few approaches are based on the application
of Hidden Markov models (Melucci et al., 2003).
In this technique, each word is considered to be
composed of two parts “prefix” and “suffix”. Here,
HMM states are divided into two disjoint sets:
Prefix state which generates the first part of the
word and Suffix state which generates the last part
of the word, if the word has a suffix. After a com-
plete and trained HMM is available for a language,
stemming can be performed directly.
Plisson proposed the most accepted rule based
approach for lemmatization (Plisson et al., 2008).
It is based on the word endings, where suffixes
are removed or added to get the normalized word
form. In another work, a method to automati-
cally develop lemmatization rules to generate the
lemma from the full form of a word was dis-
cussed (Jongejan et al., 2009). The lemmatizer
was trained on Danish, Dutch, English, German,
Greek, Icelandic, Norwegian, Polish, Slovene and
Swedish full form-lemma pairs respectively.
Kimmo (Karttunen et al., 1983) is a two level
morphological analyser containing a large set of
morphophonemic rules. The work started in 1980
and the first implementation n LIST was available
3 years later.
Tarek El-Shishtawy proposed the first non-
statistical Arabic lemmatizer algorithm (El-
</bodyText>
<footnote confidence="0.366121">
1Seehttp://snowball.tartarus.org/
</footnote>
<bodyText confidence="0.999670708333333">
Shishtawy et al., 2012). He makes use of different
Arabic language knowledge resources to generate
accurate lemma form and its relevant features that
support IR purposes and a maximum accuracy of
94.8% is reported.
OMA is a Turkish Morphological Analyzer
which gives all possible analyses for a given word
with the help of finite state technology. Two-level
morphology is used to build the lexicon for a lan-
guage (Ozturkmenoglu et al., 2012).
Grzegorz Chrupala (Chrupala et al., 2006) pre-
sented a simple data-driven context-sensitive ap-
proach to lemmatizating word forms. Shortest
Edit Script (SES) between reversed input and out-
put strings is computed to achieve this task. An
SES describes the transformations that have to be
applied to the input string (word form) in order to
convert it to the output string (lemma).
As for lemmatizers for Indian languages, the
earliest work by Ramanathan and Rao (2003) used
manually sorted suffix list and performed longest
match stripping for building a Hindi stemmer. Ma-
jumdar et. al (2007) developed YASS: Yet An-
other Suffix Stripper. Here conflation was viewed
as a clustering problem with a-priory unknown
number of clusters. They suggested several dis-
tance measures rewarding long matching prefixes
and penalizing early mismatches. In a recent work
related to Affix Stacking languages like Marathi,
(Dabre et al., 2012) Finite State Machine (FSM)
is used to develop a Marathi morphological Ana-
lyzer. In another approach, A Hindi Lemmatizer
is proposed, where suffixes are stripped according
to various rules and necessary addition of charac-
ter(s) is done to get a proper root form (Paul et
al., 2013). GRALE is a graph based lemmatizer
for Bengali comprising two steps (Loponen et al.,
2013). In the first, step it extracts the set of fre-
quent suffixes and in the second step, a human
manually identifies the case suffixes. Words are
often considered as node and edge from node u to
v exist if only v can be generated from u by addi-
tion of a suffix.
Unlike the above mentioned rule based and sta-
tistical approaches, our human mediated lemma-
tizer uses the properties of a “trie” data structure
which allows retrieving possible lemma of a given
inflected word, with human help at critical steps.
</bodyText>
<sectionHeader confidence="0.989169" genericHeader="method">
3 Our Approach to lemmatization
</sectionHeader>
<bodyText confidence="0.997879684210526">
The scope of our work is suffix based morphology.
We do not consider infix and prefix morphology.
We first setup the data structure ‘Trie’ (Cormen et
al., 2001) using the words in the wordnet of the
language. Next, we match, byte by byte, the input
word form and wordnet words. The output is all
wordnet words which have the maximum prefix
match with the input word. This is the “direct”
variant of our lemmatizer.
The second or “backtrack” variant prints the re-
sults ‘n’ levels previous to the maximum matched
prefix obtained in the ‘direct’ variant. The value
of ‘n’ is usr controlled. A ranking function then
decides the final output displayed to the user.
In Figure 5, a sample trie diagram is shown con-
sisting of Hindi words given at Figure 4. The
words are stored starting from a node subsequent
to the root node, in a character by character uni-
code byte order.
</bodyText>
<figureCaption confidence="0.991912">
Figure 4: List of sample words.
</figureCaption>
<bodyText confidence="0.99632225">
At each level, we insert the characters of the
word in an alphabetical order pertaining to uni-
code standard for different languages from left to
right.
We illustrate the search in the trie with the ex-
ample of the inflected word “lwEkyA ” (ladkiyan,
i.e., girls). Our lemmatizer gives the following
output:
</bodyText>
<figureCaption confidence="0.766656">
Figure 5: A simple trie storing Hindi words (ka-
marband, kamara, kamari, kamal, lad, ladakpan,
ladka, ladki and ladna)
</figureCaption>
<bodyText confidence="0.9962782">
From this result set, a trained lexicographer can
easily pick the root word as “lwkF” (ladki, i.e.,
girl). It is the user controlled backtracking which
is novel and very useful in our lemmatizer. We
elaborate on backtracking below.
</bodyText>
<subsectionHeader confidence="0.997971">
3.1 Backtracking
</subsectionHeader>
<bodyText confidence="0.9981535">
We explain backtracking using the sample words
in Figure 6 and the trie as shown in Figure 7.
</bodyText>
<figureCaption confidence="0.991983">
Figure 6: List of sample words : Backtracking.
</figureCaption>
<bodyText confidence="0.997112789473684">
We take the example of asl�l� (aslele) which
is an inflected form of the Marathi word asZ�
(asane). Here, when we call the first iterative
procedure without backtracking, the word aslF
(asali) is given as output. Although, being a valid
wordnet word, it is not the correct root form of
the word asl�l�. Hence, we perform a back-
track from asl (asal) to as (asa) thereby get-
ting asZ� (asane) as one of the outputs.
An example involving two levels of backtrack-
ing is that of a Marathi word kApsAlA (kApsAlA),
which is an inflected form of the root word kAp� s,
(kApusa) i.e., cotton). Here are the results from
our lemmatizer:
function then applies the ranking heuristic based
on length and then sorts them in their ascending
order. Thus, the final lemmatizer output is gener-
ated with the root word B�* (asane) in first posi-
tion.
</bodyText>
<figureCaption confidence="0.997085">
Figure 7: Search in Trie - Backtracking in case of
Marathi word “B�����” (aslele)
</figureCaption>
<bodyText confidence="0.9999095">
Thus, we can find the root word WFW at 10th
position in the result list of two level backtrack.
</bodyText>
<subsectionHeader confidence="0.999832">
3.2 Ranking Lemmatizer Results
</subsectionHeader>
<bodyText confidence="0.9762362">
Our lemmatizer by default prints out all the pos-
sible root forms given a queried word. We have
employed a heuristic to filter the results and hence
minimize the size of the result set:
1. Only those output matches are accepted
whose length is smaller than or equal to the
length of the queried word. This is based on
an assumption that the root word length shall
not be greater than the length of its equiva-
lent inflected word form (we agree that this is
not universally true; hence the word ’heuris-
tic’ for the pruning strategy).
2. The filtered results are sorted on the basis of
the length (in an ascending order) which in
most cases displays the root word earlier in a
given set of words.
For example, in case of the Marathi word
“B�����” (aslele) the ranking function receives a
number of words as input, after a first level back-
track is performed (as shown in Figure 8). The
</bodyText>
<figureCaption confidence="0.9240705">
Figure 8: Ranking of results - For Marathi word
“B�” (aslele)
</figureCaption>
<sectionHeader confidence="0.993446" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.999981807692308">
We have developed an on-line interface (Figure
9) and a downloadable Java based executable jar
which can be used to test our implementation.
The interface allows input from 18 different Indian
languages (Hindi, Assamese, Bengali, Bodo, Gu-
jarati, Kannada, Kashmiri, Konkani, Malayalam,
Manipuri, Marathi, Nepali, Sanskrit, Tamil, Tel-
ugu, Punjabi, Urdu and Odiya) and 5 European
languages (Italian, Danish, Hungarian, French and
English) and they are linked to their respective lex-
ical databases. For easy typing, a virtual keyboard
is also provided. The first iteration of stemming
is performed by clicking “Find” and backtracking
is performed by clicking “Backtrack”. The back-
track utility allows us to backtrack upto 8 levels
and the level of backtrack is displayed in a field.
This was implemented, since there are several in-
flected words in our test data which required a
backtrack of more than one level to get the root
word. The interface also has a facility to upload a
text document related to a specific language. We
can then download the results in an output file con-
taining possible stems of all the words present in
the input document. The human annotator can
thus choose the correct lemma from the list of pos-
sible stems associated with each word.
</bodyText>
<sectionHeader confidence="0.995518" genericHeader="method">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.996544">
We performed several experiments to evaluate the
performance of the lemmatizer. The basis of our
</bodyText>
<figureCaption confidence="0.9978385">
Figure 9: Online Interface - Language Indepen-
dent Human Mediated Lemmatizer
</figureCaption>
<bodyText confidence="0.996436285714286">
evaluation was that for every inflected input word,
a set of output root forms will be generated by
the lemmatizer. Even if one of the result in the
top 10 from this set matches the root in the
gold standard, then we consider our result to
be correct. Following this approach the accuracy
of inflected nouns undergoing stemming is very
high. Although, due to readjustment in verbs, for
the first iteration without backtracking, our lem-
matizer gives a fairly low accuracy. This can be
further improved through backtracking, when we
traversed the trie, one level up at a time. The first
iteration of stemming gives result among the best
five outputs and the backtracking approach gives
among the best ten outputs. Interestingly, for in-
flected words in Italian our lemmatizer performs
better when we include the results of one level
backtrack as compared to a non-backtrack vari-
ant. The results for various languages are shown in
Table 1 based on the lemmatizer’s default variant,
i.e., without using backtrack feature.
</bodyText>
<subsectionHeader confidence="0.999473">
5.1 Preparation of Gold Data
</subsectionHeader>
<bodyText confidence="0.9996445">
We prepared the gold data to perform evaluation
for Hindi and Marathi languages, by using the do-
main specific sense marked corpus2 which con-
tains inflected words along with their root word
forms. This corpus was created by trained lexicog-
raphers. Similarly, we had a sense marked corpus
for Bengali, Assamese, Punjabi and Konkani.
For Dravidian languages like Malayalam and
Kannada and for European languages like French
and Italian, we had to perfrom manual evaluation
as the sense marked data was unavailable. We did
this, with a list of inflected words provided by na-
tive speakers and found remarkable precision in
result.
</bodyText>
<footnote confidence="0.998466">
2See http://www.cfilt.iitb.ac.in/wsd/
</footnote>
<page confidence="0.387085">
annotated_corpus/
</page>
<table confidence="0.999959666666667">
Language Corpus Total Precision
Type Words Value
Hindi Health 8626 89.268
Hindi Tourism 16076 87.953
Bengali Health 11627 93.249
Bengali Tourism 11305 93.199
Assamese General 3740 96.791
Punjabi Tourism 6130 98.347
Marathi Health 11510 87.655
Marathi Tourism 13176 85.620
Konkani Tourism 12388 75.721
Malayalam* General 135 100.00
Kannada* General 39 84.615
Italian* General 42 88.095 #
French* General 50 94.00
</table>
<tableCaption confidence="0.9671915">
Table 1: Precision calculation for output produced
by our lemmatizer based on the first variant, i.e.,
without using backtrack feature. * denotes manual
evaluation and # denotes one level backtracking.
</tableCaption>
<subsectionHeader confidence="0.999232">
5.2 Analysis
</subsectionHeader>
<bodyText confidence="0.999116">
Errors are due to the following:
</bodyText>
<listItem confidence="0.986053">
1. Agglutination in Marathi and Dravidian lan-
guages.
</listItem>
<bodyText confidence="0.938499666666667">
Marathi and Dravidian languages like Kan-
nada and Malayalam show the process of ag-
glutination3. It is a process where a complex
word is formed by combining morphemes
each of which have a distinct grammatical or
semantic meaning. Such words do not pro-
duce correct results in the first go, and we
need to back track the trie upto a certain level
to get the correct root form.
</bodyText>
<listItem confidence="0.556416">
2. Suppletion.
</listItem>
<bodyText confidence="0.999894272727273">
The term suppletion4 implies that a gap in the
paradigm was filled by a form “supplied” by
a different paradigm. For example, the root
word “go”, has an irregular past tense form
“went”. For these irregular words the out-
put of the lemmatizer is incorrect, as the root
words are stored in their regular forms in the
trie.
We have reported the precision scores (Table 1)
for all the languages (except Italian) on the ”di-
rect” variant of our lemmatizer, i.e., without using
</bodyText>
<footnote confidence="0.908693">
3See http://en.wikipedia.org/wiki/
Agglutination
4See https://en.wikipedia.org/wiki/
Suppletion
</footnote>
<table confidence="0.989892">
Corpus Name Human Mediated Lemmatizer Morpha Snowball Morfessor
English General 89.20 90.17 53.125 79.16
Hindi General 90.83 NA NA 26.14
Marathi General 96.51 NA NA 37.26
</table>
<tableCaption confidence="0.9406905">
Table 2: Comparative Evaluation (precision values) of Human Mediated Lemmatizer [Without using
Backtracking] against other classic stemming systems like Morpha, Snowball and Morfessor
</tableCaption>
<bodyText confidence="0.947375">
backtrack feature. It is clear from our examples
in Marathi viz. “a�����” (aslele) and the scores
reported in Italian that precision improves when
backtracking is used.
</bodyText>
<sectionHeader confidence="0.6837235" genericHeader="method">
6 Comparative evaluation with existing
lemmatizers/stemmer
</sectionHeader>
<bodyText confidence="0.999884875">
We compared performance of our system
against three most commonly used lemmatiz-
ers/stemmers, viz. Morpha (Guido et al., 2001),
Snowball 5 and Morfessor (Creutz, 2005; 2007).
The results are shown in Table 2. Our lemmatizer
works better than Morfessor for Hindi (up by
64%) and Marathi (up by 59%). For English, our
lemmatizer outperforms Snowball by almost 36%
and Morfessor by almost 10%. Although, as an
exception, Morpha lemmatizer works better by
about 1% in this case.
Snowball and Morpha lemmatizers are not
available for Indian Languages and thus the re-
sults are marked with ‘NA’. Morfessor being sta-
tistical in nature does not capture all the linguistic
and morphological phenomenons associated with
Indian languages and Snowball and Morpha are
strictly rule based in nature and do not use any
linguistic resource to validate the output. We
have, of course, compared our lemmatizer with
in-house rule based Hindi and Marathi morph an-
alyzers. The Marathi Morphological Analyzer
(Dabre et al., 2012) has an accuracy of 72.18%,
with a usability of 94.33%, where as the in-house
Hindi Morphological Analyzer6 accuracy is close
to 100% with average usability around 96.5% (Ta-
ble 3). Here, usability is the percentage of total
number of words analyzed out of total words in
corpus.
However, these morph analysers have taken
years to build with many false starts and false hits
and misses. Compared to this, our human medi-
</bodyText>
<footnote confidence="0.9303095">
5See http://snowball.tartarus.org/
index.php
6See http://www.cfilt.iitb.ac.in/
˜ankitb/ma/
</footnote>
<table confidence="0.9990545">
Nouns Verbs
Total words in test Corpus 14475 13160
Correctly analyzed words 13453 13044
Unidentified words 1022 116
</table>
<tableCaption confidence="0.999825">
Table 3: Hindi Morphological Analyzer - Results
</tableCaption>
<bodyText confidence="0.999232833333333">
ated lemmatizer was constructed in a few weeks’
time. Once it was realized that we need lemma-
tizers for accessing senses of words, the system
was built in no time. It is the preparation of gold
data, generation of accuracy values and compari-
son with existing systems that took time.
</bodyText>
<sectionHeader confidence="0.955402" genericHeader="conclusions">
7 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999983047619048">
We gave an approach for developing light weight
and quick-to-create human mediated lemmatizer.
We applied the lemmatizer to 18 different Indian
languages and 5 European languages. Our ap-
proach uses the longest prefix match functionality
of a trie data structure. Without using any man-
ually created rule list or statistical measure, we
were able to find lemma of the input word within
a ranked list of 5-15 outputs. The human annota-
tor can thus choose from a small set of results and
proceed with sense marking, thereby greatly help-
ing the overall task of Machine Translation and
Word Sense Disambiguation. We also confirm the
fact that the combination of man and machine can
identify the root to near 100 percent accuracy.
In future, we want to further prune of output list,
making the ranking much more intelligent. Inte-
gration of the human mediated lemmatizer to all
languages’ sense marking task needs to be com-
pleted. Also we want to expand our work to in-
clude languages from different linguistic families.
</bodyText>
<sectionHeader confidence="0.998197" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998652504854369">
Arindam Chatterjee, Salil Rajeev Joshi, Mitesh M.
Khapra and Pushpak Bhattacharyya 2010. Intro-
duction to Tools for IndoWordnet and Word Sense
Disambiguation, The 3rd IndoWordnet Workshop,
Eighth International Conference on Natural Lan-
guage Processing (ICON 2010), IIT Kharagpur, In-
dia.
Grzegorz Chrupala 2006. Simple data-driven context-
sensitive lemmatization , Chrupaa, Grzegorz (2006)
Simple data-driven context-sensitive lemmatization.
In: SEPLN 2006, 13-15 September 2006, Zaragoza,
Spain.
Thomas H. Cormen, Clifford Stein, Ronald L. Rivest
and Charles E. Leiserson 2001. Introduction
to Algorithms, 2nd Edition, ISBN:0070131511,
McGraw-Hill Higher Education.
Mathis Creutz and Krista Lagus. 2005. Unsupervised
morpheme segmentation and morphology induction
from text corpora using Morfessor 1.0., Technical
Report A81, Publications in Computer and Informa-
tion Science, Helsinki University of Technology.
Mathis Creutz and Krista Lagus. 2007. Unsupervised
models for morpheme segmentation and morphol-
ogy learning, Association for Computing Machinery
Transactions on Speech and Language Processing,
4(1):1-34
Raj Dabre, Archana Amberkar and Pushpak Bhat-
tacharyya 2012. Morphology Analyser for Affix
Stacking Languages: a case study in Marathi, COL-
ING 2012, Mumbai, India, 10-14 Dec, 2012.
Tarek El-Shishtawy and Fatma El-Ghannam 2012. An
Accurate Arabic Root-Based Lemmatizer for Infor-
mation Retrieval Purposes, IJCSI International Jour-
nal of Computer Science Issues, Vol. 9, Issue 1, No
3, January 2012 ISSN (Online): 1694-0814.
John A. Goldsmith 2001. Unsupervised Learning of
the morphology of a Natural Language, Computa-
tional Linguistics, 27(2): 153-198
John A. Goldsmith 2006. An algorithm for the unsu-
pervised Learning of morphology, Natural Language
Engineering, 12(4): 353-371
Bart Jongejan and Hercules Dalianis 2009. Automatic
training of lemmatization rules that handle morpho-
logical changes in pre-, in- and suffixes alike, Pro-
ceedings of the 47th Annual Meeting of the ACL
and the 4th IJCNLP of the AFNLP, pages 145 - 153,
Suntec, Singapore, 2-7 August 2009
Lauri Karttunen 1983. KIMMO: A General Mor-
phological Processor, Texas Linguistic Forum, 22
(1983), 163-186.
Aki Loponen, Jiaul H. Paik and Kalervo Jarvelin 2013.
UTA Stemming and Lemmatization Experiments in
the FIRE Bengali Ad Hoc Task, Multilingual Infor-
mation Access in South Asian Languages Lecture
Notes in Computer Science Volume 7536, 2013, pp
258-268
J.B. Lovins 1968. Development of a stemming algo-
rithm, Mechanical Translations and Computational
Linguistics Vol.11 Nos 1 and 2, pp. 22-31.
Prasenjit Majumder, Mandar Mitra, Swapan K. Parui,
Gobinda Kole, Pabitra Mitra, and Kalyankumar
Datta. 2007. YASS: Yet another suffix stripper, As-
sociation for Computing Machinery Transactions on
Information Systems, 25(4):18-38.
Prasenjit Majumder, Mandar Mitra and Kalyankumar
Datta 2007. Statistical vs Rule-Based Stemming for
Monolingual French Retrieval, Evaluation of Multi-
lingual and Multi-modal Information Retrieval, Lec-
ture Notes in Computer Science vol. 4370, ISBN
978-3-540-74998-1, Springer, Berlin, Heidelberg.
James Mayfield and Paul McNamee 2003. Single N-
gram Stemming, SIGIR ‘03, Toronto, Canada.
Massimo Melucci and Nicola Orio 2003. A novel
method of Stemmer Generation Based on Hid-
den Markov Models, CIKM ‘03, New Orleans,
Louisiana, USA.
Guido Minnen,John Carroll and Darren Pearce. 2001.
Applied morphological processing of English, Natu-
ral Language Engineering, 7(3). 207-223.
Okan Ozturkmenoglu and Adil Alpkocak 2012. Com-
parison of different lemmatization approaches for
information retrieval on Turkish text collection , In-
novations in Intelligent Systems and Applications
(INISTA), 2012 International Symposium on.
Plisson Jo¨el, Lavrac Nada, Mladenic Dunja 2008. A
rule based approach to word lemmatization, Pro-
ceedings of 7th International Multi-conference In-
formation Society, IS 2004, Institute Jozef Stefen,
Ljubljana, pp.83-86, 2008
Snigdha Paul, Nisheeth Joshi and Iti Mathur 2013.
Development of a Hindi Lemmatizer, CoRR,
DBLP:journals/corr/abs/1305.6211 2013
M.F. Porter 1980. An algorithm for suffix stripping,
Program; 14, 130-137
M.F. Porter 2006. Stemming algorithms for var-
ious European languages, Available at [URL]
http://snowball.tartarus.org/
texts/stemmersoverview.html As
seen on May 16, 2013
Ananthakrishnan Ramanathan, and Durgesh D Rao
2003. A Lightweight Stemmer for Hindi. , Work-
shop on Computational Linguistics for South-Asian
Languages, EACL
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.869136">
<title confidence="0.9820075">Facilitating Multi-Lingual Sense Human Mediated Lemmatizer</title>
<author confidence="0.991369">Pushpak Bhattacharyya Ankit Bahuguna Lavita Talukdar Bornali Phukan</author>
<affiliation confidence="0.957707">IIT Bombay IIT Bombay / TU Munich IIT Bombay IIT Bombay</affiliation>
<email confidence="0.989417">pushpakbh@gmail.comankitbahuguna@outlook.comlavita.talukdar@gmail.combornali31phukan@gmail.com</email>
<abstract confidence="0.99886945">Sense marked corpora is essential for supervised word sense disambiguation (WSD). The marked sense ids come from wordnets. However, words in corpora appear in morphed forms, while wordnets store lemma. This sitcalls for accurate lemmatizers. is the gateway to the However, the problem is that for many languages, lemmatizers do not exist, and this problem is not easy to solve, since rule based lemmatizers take time and require highly skilled linguists.Satistical stemmers on the other hand do not return legitimate lemma. We present here a novel scheme for creating accurate lemmatizers quickly. These lemmaare The key idea is that a trie is created out of the vocabulary of the language. The lemmatizing process consists in navigating the trie, trying to find a match between the input word and an entry in the trie. At the point of first mismatch, the yield of the subtree rooted at the partially matched node is output as the list of possible lemma. If the correct lemma does not appear in the listas noted by a human lexicographerbacktracking is initiated. This can output more possibilities. A ranking function filters and orders the output list of lemma. We have evaluated the performance of this human mediated lemmatizer for eighteen Indian Languages and five European languages. We have compared accuracy values against well known lemmatizers/stemmers like Morpha, Morfessor and Snowball stemmers, and observed superior performance in all cases. Our work shows a way of speedily creating human assisted accurate lemmatizers, thereby removing a difficult roadblock in many NLP tasks, e.g., sense annotation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Arindam Chatterjee</author>
<author>Salil Rajeev Joshi</author>
<author>M Mitesh</author>
</authors>
<title>Khapra and Pushpak Bhattacharyya 2010. Introduction to Tools for IndoWordnet and Word Sense Disambiguation,</title>
<booktitle>The 3rd IndoWordnet Workshop, Eighth International Conference on Natural Language Processing (ICON 2010), IIT</booktitle>
<location>Kharagpur, India.</location>
<marker>Chatterjee, Joshi, Mitesh, </marker>
<rawString>Arindam Chatterjee, Salil Rajeev Joshi, Mitesh M. Khapra and Pushpak Bhattacharyya 2010. Introduction to Tools for IndoWordnet and Word Sense Disambiguation, The 3rd IndoWordnet Workshop, Eighth International Conference on Natural Language Processing (ICON 2010), IIT Kharagpur, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupala</author>
</authors>
<title>Simple data-driven contextsensitive lemmatization , Chrupaa, Grzegorz</title>
<date>2006</date>
<pages>13--15</pages>
<location>Zaragoza,</location>
<marker>Chrupala, 2006</marker>
<rawString>Grzegorz Chrupala 2006. Simple data-driven contextsensitive lemmatization , Chrupaa, Grzegorz (2006) Simple data-driven context-sensitive lemmatization. In: SEPLN 2006, 13-15 September 2006, Zaragoza, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Cormen</author>
<author>Clifford Stein</author>
<author>Ronald L Rivest</author>
<author>Charles E Leiserson</author>
</authors>
<date>2001</date>
<booktitle>Introduction to Algorithms, 2nd Edition, ISBN:0070131511, McGraw-Hill Higher Education.</booktitle>
<contexts>
<context position="11179" citStr="Cormen et al., 2001" startWordPosition="1832" endWordPosition="1835">cond step, a human manually identifies the case suffixes. Words are often considered as node and edge from node u to v exist if only v can be generated from u by addition of a suffix. Unlike the above mentioned rule based and statistical approaches, our human mediated lemmatizer uses the properties of a “trie” data structure which allows retrieving possible lemma of a given inflected word, with human help at critical steps. 3 Our Approach to lemmatization The scope of our work is suffix based morphology. We do not consider infix and prefix morphology. We first setup the data structure ‘Trie’ (Cormen et al., 2001) using the words in the wordnet of the language. Next, we match, byte by byte, the input word form and wordnet words. The output is all wordnet words which have the maximum prefix match with the input word. This is the “direct” variant of our lemmatizer. The second or “backtrack” variant prints the results ‘n’ levels previous to the maximum matched prefix obtained in the ‘direct’ variant. The value of ‘n’ is usr controlled. A ranking function then decides the final output displayed to the user. In Figure 5, a sample trie diagram is shown consisting of Hindi words given at Figure 4. The words a</context>
</contexts>
<marker>Cormen, Stein, Rivest, Leiserson, 2001</marker>
<rawString>Thomas H. Cormen, Clifford Stein, Ronald L. Rivest and Charles E. Leiserson 2001. Introduction to Algorithms, 2nd Edition, ISBN:0070131511, McGraw-Hill Higher Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathis Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0.,</title>
<date>2005</date>
<tech>Technical Report A81,</tech>
<institution>Publications in Computer and Information Science, Helsinki University of Technology.</institution>
<marker>Creutz, Lagus, 2005</marker>
<rawString>Mathis Creutz and Krista Lagus. 2005. Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0., Technical Report A81, Publications in Computer and Information Science, Helsinki University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathis Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised models for morpheme segmentation and morphology learning,</title>
<date>2007</date>
<journal>Association for Computing Machinery Transactions on Speech and Language Processing,</journal>
<pages>4--1</pages>
<marker>Creutz, Lagus, 2007</marker>
<rawString>Mathis Creutz and Krista Lagus. 2007. Unsupervised models for morpheme segmentation and morphology learning, Association for Computing Machinery Transactions on Speech and Language Processing, 4(1):1-34</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raj Dabre</author>
</authors>
<title>Archana Amberkar and Pushpak Bhattacharyya 2012. Morphology Analyser for Affix Stacking Languages: a case study</title>
<date>2012</date>
<booktitle>in Marathi, COLING 2012,</booktitle>
<pages>10--14</pages>
<location>Mumbai, India,</location>
<marker>Dabre, 2012</marker>
<rawString>Raj Dabre, Archana Amberkar and Pushpak Bhattacharyya 2012. Morphology Analyser for Affix Stacking Languages: a case study in Marathi, COLING 2012, Mumbai, India, 10-14 Dec, 2012.</rawString>
</citation>
<citation valid="true">
<title>Tarek El-Shishtawy and Fatma El-Ghannam 2012. An Accurate Arabic Root-Based Lemmatizer for Information Retrieval Purposes,</title>
<date>2012</date>
<journal>IJCSI International Journal of Computer Science Issues,</journal>
<volume>9</volume>
<pages>1694--0814</pages>
<publisher>ISSN (Online):</publisher>
<marker>2012</marker>
<rawString>Tarek El-Shishtawy and Fatma El-Ghannam 2012. An Accurate Arabic Root-Based Lemmatizer for Information Retrieval Purposes, IJCSI International Journal of Computer Science Issues, Vol. 9, Issue 1, No 3, January 2012 ISSN (Online): 1694-0814.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Goldsmith</author>
</authors>
<title>Unsupervised Learning of the morphology of a Natural Language,</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<pages>153--198</pages>
<contexts>
<context position="7291" citStr="Goldsmith, 2001" startWordPosition="1200" endWordPosition="1201">at covered Romance (French, Italian, Portuguese and Spanish), Germanic (Dutch and German) and Scandinavian languages (Danish, Norwegian and Swedish), as Figure 3: Tool shows no output for inflected Assamese word “ghoroloi” (highlighted) meaning to home. well as Finnish and Russian (Porter, 2006). These stemmers were described in a very high level language known as Snowball1. A number of statistical approaches have been developed for stemming. Notable works include: Goldsmith’s unsupervised algorithm for learning morphology of a language based on the Minimum Description Length (MDL) framework (Goldsmith, 2001; 2006). Creutz uses probabilistic maximum a posteriori (MAP) formulation for unsupervised morpheme segmentation (Creutz, 2005; 2007). A few approaches are based on the application of Hidden Markov models (Melucci et al., 2003). In this technique, each word is considered to be composed of two parts “prefix” and “suffix”. Here, HMM states are divided into two disjoint sets: Prefix state which generates the first part of the word and Suffix state which generates the last part of the word, if the word has a suffix. After a complete and trained HMM is available for a language, stemming can be perf</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>John A. Goldsmith 2001. Unsupervised Learning of the morphology of a Natural Language, Computational Linguistics, 27(2): 153-198</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Goldsmith</author>
</authors>
<title>An algorithm for the unsupervised Learning of morphology,</title>
<date>2006</date>
<journal>Natural Language Engineering,</journal>
<volume>12</volume>
<issue>4</issue>
<pages>353--371</pages>
<marker>Goldsmith, 2006</marker>
<rawString>John A. Goldsmith 2006. An algorithm for the unsupervised Learning of morphology, Natural Language Engineering, 12(4): 353-371</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bart Jongejan</author>
<author>Hercules Dalianis</author>
</authors>
<title>Automatic training of lemmatization rules that handle morphological changes in pre-, in- and suffixes alike,</title>
<date>2009</date>
<booktitle>Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP,</booktitle>
<pages>145--153</pages>
<location>Suntec,</location>
<marker>Jongejan, Dalianis, 2009</marker>
<rawString>Bart Jongejan and Hercules Dalianis 2009. Automatic training of lemmatization rules that handle morphological changes in pre-, in- and suffixes alike, Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 145 - 153, Suntec, Singapore, 2-7 August 2009</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>KIMMO: A General Morphological Processor, Texas Linguistic Forum,</title>
<date>1983</date>
<volume>22</volume>
<pages>163--186</pages>
<marker>Karttunen, 1983</marker>
<rawString>Lauri Karttunen 1983. KIMMO: A General Morphological Processor, Texas Linguistic Forum, 22 (1983), 163-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aki Loponen</author>
<author>Jiaul H Paik</author>
<author>Kalervo Jarvelin</author>
</authors>
<date>2013</date>
<booktitle>UTA Stemming and Lemmatization Experiments in the FIRE Bengali Ad Hoc Task, Multilingual Information Access in South Asian Languages Lecture Notes in Computer Science</booktitle>
<volume>7536</volume>
<pages>258--268</pages>
<contexts>
<context position="10484" citStr="Loponen et al., 2013" startWordPosition="1708" endWordPosition="1711">ring problem with a-priory unknown number of clusters. They suggested several distance measures rewarding long matching prefixes and penalizing early mismatches. In a recent work related to Affix Stacking languages like Marathi, (Dabre et al., 2012) Finite State Machine (FSM) is used to develop a Marathi morphological Analyzer. In another approach, A Hindi Lemmatizer is proposed, where suffixes are stripped according to various rules and necessary addition of character(s) is done to get a proper root form (Paul et al., 2013). GRALE is a graph based lemmatizer for Bengali comprising two steps (Loponen et al., 2013). In the first, step it extracts the set of frequent suffixes and in the second step, a human manually identifies the case suffixes. Words are often considered as node and edge from node u to v exist if only v can be generated from u by addition of a suffix. Unlike the above mentioned rule based and statistical approaches, our human mediated lemmatizer uses the properties of a “trie” data structure which allows retrieving possible lemma of a given inflected word, with human help at critical steps. 3 Our Approach to lemmatization The scope of our work is suffix based morphology. We do not consi</context>
</contexts>
<marker>Loponen, Paik, Jarvelin, 2013</marker>
<rawString>Aki Loponen, Jiaul H. Paik and Kalervo Jarvelin 2013. UTA Stemming and Lemmatization Experiments in the FIRE Bengali Ad Hoc Task, Multilingual Information Access in South Asian Languages Lecture Notes in Computer Science Volume 7536, 2013, pp 258-268</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Lovins</author>
</authors>
<title>Development of a stemming algorithm,</title>
<date>1968</date>
<booktitle>Mechanical Translations and Computational Linguistics Vol.11 Nos</booktitle>
<volume>1</volume>
<pages>22--31</pages>
<contexts>
<context position="6224" citStr="Lovins, 1968" startWordPosition="1042" endWordPosition="1043">d. Here, the correct lemma is shown at the top of the list, and the lemma can pull out the senses from the wordnet for the linguist to tag with. The remainder of this paper is organized as follows. We describe related work and background in section 2. Section 3 explains the core of our human mediated lemmatiser. Implementation details are in Section 4. Experiments and results are discussed in Section 5. Comparison with existing stemmers/lemmatizers are in Section 6. Section 7 concludes the paper and points to future directions. 2 Related Work and Background Lovins described the first stemmer (Lovins, 1968), which was developed specifically for IR/NLP applications. His approach consisted of the use of a manually developed list of 294 suffixes, each linked to 29 conditions, plus 35 transformation rules. For an input word, the suffix with an appropriate condition is checked and removed. Porter developed the Porter stemming algorithm (Porter, 1980) which became the most widely used stemming algorithm for English language. Later, he developed stemmers that covered Romance (French, Italian, Portuguese and Spanish), Germanic (Dutch and German) and Scandinavian languages (Danish, Norwegian and Swedish)</context>
</contexts>
<marker>Lovins, 1968</marker>
<rawString>J.B. Lovins 1968. Development of a stemming algorithm, Mechanical Translations and Computational Linguistics Vol.11 Nos 1 and 2, pp. 22-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prasenjit Majumder</author>
<author>Mandar Mitra</author>
<author>Swapan K Parui</author>
<author>Gobinda Kole</author>
<author>Pabitra Mitra</author>
<author>Kalyankumar Datta</author>
</authors>
<title>YASS: Yet another suffix stripper,</title>
<date>2007</date>
<journal>Association for Computing Machinery Transactions on Information Systems,</journal>
<pages>25--4</pages>
<marker>Majumder, Mitra, Parui, Kole, Mitra, Datta, 2007</marker>
<rawString>Prasenjit Majumder, Mandar Mitra, Swapan K. Parui, Gobinda Kole, Pabitra Mitra, and Kalyankumar Datta. 2007. YASS: Yet another suffix stripper, Association for Computing Machinery Transactions on Information Systems, 25(4):18-38.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Prasenjit Majumder</author>
</authors>
<title>Mandar Mitra and Kalyankumar Datta 2007. Statistical vs Rule-Based Stemming for Monolingual French Retrieval, Evaluation of Multilingual and Multi-modal Information Retrieval,</title>
<journal>Lecture Notes in Computer Science</journal>
<volume>4370</volume>
<pages>978--3</pages>
<publisher>Springer,</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Majumder, </marker>
<rawString>Prasenjit Majumder, Mandar Mitra and Kalyankumar Datta 2007. Statistical vs Rule-Based Stemming for Monolingual French Retrieval, Evaluation of Multilingual and Multi-modal Information Retrieval, Lecture Notes in Computer Science vol. 4370, ISBN 978-3-540-74998-1, Springer, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Mayfield</author>
<author>Paul McNamee</author>
</authors>
<date>2003</date>
<booktitle>Single Ngram Stemming, SIGIR ‘03,</booktitle>
<location>Toronto, Canada.</location>
<marker>Mayfield, McNamee, 2003</marker>
<rawString>James Mayfield and Paul McNamee 2003. Single Ngram Stemming, SIGIR ‘03, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Melucci</author>
<author>Nicola Orio</author>
</authors>
<title>A novel method of Stemmer Generation</title>
<date>2003</date>
<booktitle>Based on Hidden Markov Models, CIKM ‘03,</booktitle>
<location>New Orleans, Louisiana, USA.</location>
<marker>Melucci, Orio, 2003</marker>
<rawString>Massimo Melucci and Nicola Orio 2003. A novel method of Stemmer Generation Based on Hidden Markov Models, CIKM ‘03, New Orleans, Louisiana, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Applied morphological processing of English,</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>207--223</pages>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Guido Minnen,John Carroll and Darren Pearce. 2001. Applied morphological processing of English, Natural Language Engineering, 7(3). 207-223.</rawString>
</citation>
<citation valid="false">
<title>Okan Ozturkmenoglu and Adil Alpkocak 2012. Comparison of different lemmatization approaches for information retrieval on</title>
<booktitle>Turkish text collection , Innovations in Intelligent Systems and Applications (INISTA), 2012 International Symposium on.</booktitle>
<marker></marker>
<rawString>Okan Ozturkmenoglu and Adil Alpkocak 2012. Comparison of different lemmatization approaches for information retrieval on Turkish text collection , Innovations in Intelligent Systems and Applications (INISTA), 2012 International Symposium on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Plisson Jo¨el</author>
<author>Lavrac Nada</author>
</authors>
<title>Mladenic Dunja 2008. A rule based approach to word lemmatization,</title>
<date>2008</date>
<booktitle>Proceedings of 7th International Multi-conference Information Society, IS 2004, Institute Jozef Stefen,</booktitle>
<pages>83--86</pages>
<location>Ljubljana,</location>
<marker>Jo¨el, Nada, 2008</marker>
<rawString>Plisson Jo¨el, Lavrac Nada, Mladenic Dunja 2008. A rule based approach to word lemmatization, Proceedings of 7th International Multi-conference Information Society, IS 2004, Institute Jozef Stefen, Ljubljana, pp.83-86, 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>Snigdha Paul</author>
</authors>
<title>Nisheeth Joshi and Iti Mathur 2013. Development of a Hindi Lemmatizer, CoRR,</title>
<date>1305</date>
<marker>Paul, 1305</marker>
<rawString>Snigdha Paul, Nisheeth Joshi and Iti Mathur 2013. Development of a Hindi Lemmatizer, CoRR, DBLP:journals/corr/abs/1305.6211 2013</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping,</title>
<date>1980</date>
<journal>Program;</journal>
<volume>14</volume>
<pages>130--137</pages>
<contexts>
<context position="6569" citStr="Porter, 1980" startWordPosition="1095" endWordPosition="1096">ection 4. Experiments and results are discussed in Section 5. Comparison with existing stemmers/lemmatizers are in Section 6. Section 7 concludes the paper and points to future directions. 2 Related Work and Background Lovins described the first stemmer (Lovins, 1968), which was developed specifically for IR/NLP applications. His approach consisted of the use of a manually developed list of 294 suffixes, each linked to 29 conditions, plus 35 transformation rules. For an input word, the suffix with an appropriate condition is checked and removed. Porter developed the Porter stemming algorithm (Porter, 1980) which became the most widely used stemming algorithm for English language. Later, he developed stemmers that covered Romance (French, Italian, Portuguese and Spanish), Germanic (Dutch and German) and Scandinavian languages (Danish, Norwegian and Swedish), as Figure 3: Tool shows no output for inflected Assamese word “ghoroloi” (highlighted) meaning to home. well as Finnish and Russian (Porter, 2006). These stemmers were described in a very high level language known as Snowball1. A number of statistical approaches have been developed for stemming. Notable works include: Goldsmith’s unsupervise</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M.F. Porter 1980. An algorithm for suffix stripping, Program; 14, 130-137</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>Stemming algorithms for various European languages, Available at [URL] http://snowball.tartarus.org/</title>
<date>2006</date>
<contexts>
<context position="6972" citStr="Porter, 2006" startWordPosition="1153" endWordPosition="1154">xes, each linked to 29 conditions, plus 35 transformation rules. For an input word, the suffix with an appropriate condition is checked and removed. Porter developed the Porter stemming algorithm (Porter, 1980) which became the most widely used stemming algorithm for English language. Later, he developed stemmers that covered Romance (French, Italian, Portuguese and Spanish), Germanic (Dutch and German) and Scandinavian languages (Danish, Norwegian and Swedish), as Figure 3: Tool shows no output for inflected Assamese word “ghoroloi” (highlighted) meaning to home. well as Finnish and Russian (Porter, 2006). These stemmers were described in a very high level language known as Snowball1. A number of statistical approaches have been developed for stemming. Notable works include: Goldsmith’s unsupervised algorithm for learning morphology of a language based on the Minimum Description Length (MDL) framework (Goldsmith, 2001; 2006). Creutz uses probabilistic maximum a posteriori (MAP) formulation for unsupervised morpheme segmentation (Creutz, 2005; 2007). A few approaches are based on the application of Hidden Markov models (Melucci et al., 2003). In this technique, each word is considered to be com</context>
</contexts>
<marker>Porter, 2006</marker>
<rawString>M.F. Porter 2006. Stemming algorithms for various European languages, Available at [URL] http://snowball.tartarus.org/</rawString>
</citation>
<citation valid="true">
<title>texts/stemmersoverview.html As seen on</title>
<date>2013</date>
<marker>2013</marker>
<rawString>texts/stemmersoverview.html As seen on May 16, 2013</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ananthakrishnan Ramanathan</author>
<author>Durgesh D Rao</author>
</authors>
<title>A Lightweight Stemmer for Hindi.</title>
<date>2003</date>
<booktitle>Workshop on Computational Linguistics for South-Asian Languages, EACL</booktitle>
<contexts>
<context position="9655" citStr="Ramanathan and Rao (2003)" startWordPosition="1576" endWordPosition="1579">lyses for a given word with the help of finite state technology. Two-level morphology is used to build the lexicon for a language (Ozturkmenoglu et al., 2012). Grzegorz Chrupala (Chrupala et al., 2006) presented a simple data-driven context-sensitive approach to lemmatizating word forms. Shortest Edit Script (SES) between reversed input and output strings is computed to achieve this task. An SES describes the transformations that have to be applied to the input string (word form) in order to convert it to the output string (lemma). As for lemmatizers for Indian languages, the earliest work by Ramanathan and Rao (2003) used manually sorted suffix list and performed longest match stripping for building a Hindi stemmer. Majumdar et. al (2007) developed YASS: Yet Another Suffix Stripper. Here conflation was viewed as a clustering problem with a-priory unknown number of clusters. They suggested several distance measures rewarding long matching prefixes and penalizing early mismatches. In a recent work related to Affix Stacking languages like Marathi, (Dabre et al., 2012) Finite State Machine (FSM) is used to develop a Marathi morphological Analyzer. In another approach, A Hindi Lemmatizer is proposed, where suf</context>
</contexts>
<marker>Ramanathan, Rao, 2003</marker>
<rawString>Ananthakrishnan Ramanathan, and Durgesh D Rao 2003. A Lightweight Stemmer for Hindi. , Workshop on Computational Linguistics for South-Asian Languages, EACL</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>