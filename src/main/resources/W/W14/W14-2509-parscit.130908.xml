<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000912">
<title confidence="0.984673">
Finding Eyewitness Tweets During Crises
</title>
<author confidence="0.999251">
Fred Morstatter&apos;, Nichola Lubold&apos;, Heather Pon-Barry&apos;, J¨urgen Pfeffer2, and Huan Liu&apos;
</author>
<affiliation confidence="0.99379">
&apos;Arizona State University, Tempe, Arizona, USA
2Carnegie Mellon University, Pittsburgh, Pennsylvania, USA
</affiliation>
<email confidence="0.863859">
{fred.morstatter, nlubold, ponbarry, huan.liu}@asu.edu, jpfeffer@cs.cmu.edu
</email>
<sectionHeader confidence="0.993477" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998489">
Disaster response agencies incorporate so-
cial media as a source of fast-breaking in-
formation to understand the needs of peo-
ple affected by the many crises that oc-
cur around the world. These agencies look
for tweets from within the region affected
by the crisis to get the latest updates on
the status of the affected region. However
only 1% of all tweets are “geotagged” with
explicit location information. In this work
we seek to identify non-geotagged tweets
that originate from within the crisis region.
Towards this, we address three questions:
(1) is there a difference between the lan-
guage of tweets originating within a crisis
region, (2) what linguistic patterns differ-
entiate within-region and outside-region
tweets, and (3) can we automatically iden-
tify those originating within the crisis re-
gion in real-time?
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999748523809524">
Due to Twitter’s massive popularity, it has become
a tool used by first responders—those who provide
first-hand aid in times of crisis—to understand cri-
sis situations and identify the people in the most
dire need of assistance (United Nations, 2012). To
do this, first responders can survey “geotagged”
tweets: those where the user has supplied a ge-
ographic location. The advantage of geotagged
tweets is that first responders know whether a per-
son is tweeting from within the affected region or
is tweeting from afar. Tweets from within this
region are more likely to contain emerging top-
ics (Kumar et al., 2013) and tactical, actionable,
information that contribute to situational aware-
ness (Verma et al., 2011).
A major limitation of surveying geotagged
tweets is that only 1% of all tweets are geo-
tagged (Morstatter et al., 2013). This leaves the
first responders unable to tap into the vast major-
ity of the tweets they collect. This limitation leads
to the question driving this work: can we discover
whether a tweet originates from within a crisis re-
gion using only the language used of the tweet?
We focus on the language of a tweet as the
defining factor of location for three major reasons:
(1) the language of Twitter users is dependent on
their location (Cheng et al., 2010), (2) the text is
readily available in every tweet, and (3) the text al-
lows for real-time analysis. Due to the short time
window presented by most crises, first responders
need to be able to locate users quickly.
Towards this goal, we examine tweets from two
recent crises: the Boston Marathon bombing and
Hurricane Sandy. We show that linguistic differ-
ences exist between tweets authored inside and
outside the affected regions. By analyzing the text
of individual tweets we can predict whether the
tweet originates from within the crisis region, in
real-time. To better understand the characteristics
of crisis-time language on Twitter, we conclude
with a discussion of the linguistic features that our
models find most discriminative.
</bodyText>
<sectionHeader confidence="0.821696" genericHeader="method">
2 Language Differences in Crises
</sectionHeader>
<bodyText confidence="0.9999787">
In order for a language-based approach to be able
to distinguish tweets inside of the crisis region, the
language used by those in the region during cri-
sis has to be different from those outside. In this
section, we verify that there are both regional and
temporal differences in the language tweeted. To
start, we introduce the data sets we use throughout
the rest of this paper. We then measure the differ-
ence in language, finding that language changes
temporally and regionally at the time of the crisis.
</bodyText>
<subsectionHeader confidence="0.969343">
2.1 Twitter Crisis Datasets
</subsectionHeader>
<bodyText confidence="0.99423775">
The Twitter data used in our experiments comes
from two crises: the Boston Marathon bombing
and Hurricane Sandy. Both events provoked a sig-
nificant Twitter response from within and beyond
</bodyText>
<page confidence="0.984868">
23
</page>
<note confidence="0.481016">
Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 23–27,
Baltimore, Maryland, USA, June 26, 2014. c�2014 Association for Computational Linguistics
</note>
<tableCaption confidence="0.999068">
Table 1: Properties of the Twitter crisis datasets.
</tableCaption>
<subsectionHeader confidence="0.292571">
Property Boston Sandy
</subsectionHeader>
<bodyText confidence="0.246123333333333">
Crisis Start 15 Apr 14:48 29 Oct 20:00
Crisis End 16 Apr 00:00 30 Oct 01:00
Epicenter 42.35, −71.08 40.75, −73.99
</bodyText>
<equation confidence="0.650881">
Radius 19 km 20 km
|IR |11,601 5,017
|OR |541,581 195,957
|PC-IR |14,052 N/A
|PC-OR |228,766 N/A
</equation>
<bodyText confidence="0.9959366">
the affected regions.
The Boston Marathon Bombing occurred at
the finish line of the Boston Marathon on April
15th, 2013 at 14:48 Eastern. We collected geo-
tagged tweets from the continental United States
from 2013-04-09 00:00 to 2013-04-22 00:00 uti-
lizing Twitter’s Filter API.
Hurricane Sandy was a “superstorm” that
ravaged the Eastern United States in October,
2012. Utilizing Twitter’s Filter API, we collected
tweets based on several keywords pertaining to the
storm. Filtering by keywords, this dataset contains
both geotagged and non-geotagged data beginning
from the day the storm made landfall (2012-10-29)
to several days after (2012-11-02).
</bodyText>
<subsectionHeader confidence="0.998005">
2.2 Data Partitioning
</subsectionHeader>
<bodyText confidence="0.9999761875">
For the Boston Bombing and Hurricane Sandy
datasets, we partitioned the tweets published dur-
ing the crisis time into two distinct parts based on
location: (1) inside the crisis region (IR), and (2)
outside the crisis region (OR).
For the Boston Bombing dataset, we are able to
extract two additional groups: (1) pre-crisis tweets
(posted before the time of the crisis) from inside
the crisis region (PC-IR) and (2) pre-crisis tweets
from outside the crisis region (PC-OR). We take a
time-based sample from 10:00–14:48 Eastern on
April 15th, 2013 to obtain PC-IR and PC-OR.
Because the bombing was an abrupt event with
no warning, we choose a time period immediately
preceding its onset. The number of tweets in each
dataset partition is shown in Table 1.
</bodyText>
<subsectionHeader confidence="0.998666">
2.3 Pre-Crisis vs. During-Crisis Language
</subsectionHeader>
<bodyText confidence="0.999949">
For the Boston dataset, we compare the words
used hour by hour between 10:00–19:00 on April
15th. For each pair of hours, we compute the
Jensen-Shannon (J-S) divergence (Lin, 1991) of
the probability distributions of the words used
</bodyText>
<figure confidence="0.885482">
(a) Temporal lan- (b) Geographic lan- (c) Geographic lan-
</figure>
<figureCaption confidence="0.782135333333333">
guage differences. guage differences: guage differences:
tranquil time. crisis time.
Figure 1: Temporal and geographic differences of
</figureCaption>
<bodyText confidence="0.877164166666667">
language (calculated using Jensen-Shannon diver-
gence); darker shades represent greater difference.
To illustrate geographic differences, we compare
Boston with three other major U.S. cities.
within those hours. Figure 1(a) shows these J-S
divergence values. We see an abrupt change in
language in the hours before the bombing (10:00–
14:00) and those after the bombing (15:00–19:00).
We also note that the tranquil hours are relatively
stable. This suggests that language models trained
on tweets from tranquil time are less informative
for modeling crisis-time langauge.
</bodyText>
<subsectionHeader confidence="0.933069">
2.4 IR vs. OR Language
</subsectionHeader>
<bodyText confidence="0.999997583333333">
We verify that the tweets authored inside of the
crisis use different words from those outside the
region. We compare the difference in Boston (B)
to three other major U.S. cities: Chicago (C), Los
Angeles (L), and Miami (M). To obtain a base-
line, we compare the cities during tranquil times
using PC-IR and PC-OR datasets. The results are
shown in Figure 1. The tranquil time comparison,
shown in Figure 1(b), displays a low divergence
between all pairs of cities. In contrast, Figure 1(c)
shows a wider divergence between the same cities,
with Boston displaying the greatest divergence.
</bodyText>
<sectionHeader confidence="0.984829" genericHeader="method">
3 Linguistic Features
</sectionHeader>
<bodyText confidence="0.996250142857143">
As Twitter is a conversational, real-time, mi-
croblogging site, the structure of tweets offers
many opportunities for extracting different types
of features that represent the different linguistic
properties of informal text. Our approach is to
compare the utility, in classifying tweets as IR or
OR, of several linguistic features. We preprocess
the tweets by extracting tokens using the CMU
Twitter NLP tokenizer (Owoputi et al., 2013).
Unigrams and Bigrams We extract the raw fre-
quency counts of the word unigrams and bigrams.
POS Tags We extract part-of-speech tags for
each word in the tweet using the CMU Twitter
NLP POS tagger (Owoputi et al., 2013). We con-
</bodyText>
<page confidence="0.994059">
24
</page>
<bodyText confidence="0.998500647058823">
sider CMU ARK POS tags, developed specifically
for the dynamic and informal nature of tweets, as
well as Penn Treebank (PTB) style POS tags. The
ARK POS tags are coarser than the PTB tags and
can identify Twitter-specific entities in the data
like hashtags. By comparing both tag sets, we can
measure the effectiveness of both the fine-grained
versus coarse-grained tag sets.
Shallow Parsing In addition to the POS tags,
we extract shallow parsing tags along with the
headword associated with the tag using the tool
provided by Ritter et al. (2011). For example,
in the noun phrase “the movie” we would ex-
tract the headword “movie” and represent it as
[...movie...]NP. The underlying motivation is that
this class may give more insight into the syntactic
differences of IR tweets versus OR tweets.
</bodyText>
<listItem confidence="0.831654541666667">
Crisis-Sensitive (CS) Features We create a
mixed-class of “crisis sensitive” features com-
posed of word-based, part of speech, and syntac-
tic constituent attributes. These are based on our
analysis of the Boston Marathon data set. We later
apply these features to the Hurricane Sandy data
set to validate whether the features are generaliz-
able across crises and discuss this in the results.
• We extract “in” prepositional phrases of the
form [in ... /N]PP. For example, “in Boston.” The
motivation is this use of “in,” such as with a lo-
cation or a nonspecific time, may be indicative of
crisis language.
• We extract verbs in relationship to the exis-
tential there. As the existential there is usually
the grammatical subject and describes an abstrac-
tion, it may be indicative of situational awareness
messages within the disaster region.
• Part-of-Speech tag sequences that are fre-
quent in IR tweets (from our development set) are
given special consideration. We find sequences
which are used more widely during the time of this
disaster. Some of the ARK tag sequences include:
(N R), (L A), (N P), (P D N), (L A !), (A N P).
</listItem>
<sectionHeader confidence="0.998962" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.88253925">
Here, we assess the effectiveness of our linguistic
features at the task of identifying tweets originat-
ing from within the crisis region. To do this we
use a Naive Bayes classifier configured with an
individual set of feature classes. Each of our fea-
tures are represented as raw frequency counts of
the number of times they occur within the tweet.
The output is a prediction of whether the tweet
is inside region (IR) or outside region (OR). We
Table 2: Top Feature Combinations: Unigrams
(Uni), Bigrams (Bi) and Crisis-Sensitive (CS)
combinations have the best results.
</bodyText>
<table confidence="0.999588636363636">
Top Feature Combos Prec. Recall F1
Boston Bombing
Uni + Bi 0.853 0.805 0.828
Uni + Bi + Shallow Parse 0.892 0.771 0.828
Uni + Bi + CS 0.857 0.806 0.831
All Features 0.897 0.742 0.812
Hurricane Sandy
Uni + Bi 0.942 0.820 0.877
Uni + Bi + Shallow Parse + CS 0.956 0.803 0.873
Uni + Bi + CS 0.947 0.826 0.882
All Features 0.960 0.786 0.864
</table>
<bodyText confidence="0.92781">
identify the features that can differentiate the two
classes of users, and we show that this process can
indeed be automated.
</bodyText>
<subsectionHeader confidence="0.969458">
4.1 Experiment Procedure
</subsectionHeader>
<bodyText confidence="0.999991125">
We ensure a 50/50 split of IR and OR instances
by sampling the OR dataset. Using the classifier
described above, we perform 3 x 5-fold cross val-
idation on the data. Because of the 50/50 split,
a “select-all” baseline that labels all tweets as IR
will have an accuracy of 50%, a precision of 50%,
and a recall of 100%. All precision and recall val-
ues are from the perspective of the IR class.
</bodyText>
<subsectionHeader confidence="0.966312">
4.2 Feature Class Analysis
</subsectionHeader>
<bodyText confidence="0.9999948">
We compare all possible combinations of individ-
ual feature classes and we report precision, recall,
and F1-scores for the best combinations in Table 2.
In both crises all of the top performing fea-
ture combinations contain both bigram and uni-
gram feature classes. However, our top perform-
ing feature combinations demonstrate that bigrams
in combination with unigrams have added util-
ity. We also see that the crisis-sensitive features
are present in the top performing combinations for
both data sets. The CS feature class was derived
from Boston Bombing data, so its presence in the
top groups from Hurricane Sandy is an indication
that these features are general, and may be useful
for finding users in these and future crises.
</bodyText>
<subsectionHeader confidence="0.999549">
4.3 Most Informative Linguistic Features
</subsectionHeader>
<bodyText confidence="0.9999649">
To see which individual features within the classes
give the best information, we make a modification
to the experiment setup described in Section 4.1:
we replace the Naive Bayes classifier with a Logis-
tic Regression classifier to utilize the coefficients
it learns as a metric for feature importance. We re-
port the top three features of each class label from
each feature set in Table 3.
The individual unigram and bigram features
with the most weight have a clear semantic rela-
</bodyText>
<page confidence="0.999317">
25
</page>
<tableCaption confidence="0.999779">
Table 3: Top 3 features indicative of each class within each feature set for both crises.
</tableCaption>
<table confidence="0.999814941176471">
Feature Set (Class) Boston Marathon Bombing Hurricane Sandy
Unigram (IR) #prayforboston, boston, explosion @kiirkobangz, upset, staying
Unigram (OR) money, weather, gone #tomyfuturechildren, #tomyfutureson, bye
Bigram (IR) (in boston), (the marathon), (i’m safe) (railroad:), (evacuation zone), (storm warning)
Bigram (OR) (i’m at), (s/o to), (, fl) (you will), (: i’ve), (hurricane,)
ARK POS (IR) (P $ &amp;quot; ), (L !), (! R P) (P #), (— &amp;quot; A), (@ @ #)
ARK POS (OR) (O #), (! N O), (L P R) (P V $), (A &amp;quot; &amp;quot;), (N L A)
PTB POS (IR) (CD NN JJ), (CD VBD), (JJS NN TO) (USR DT JJS), (VB TO RB), (IN RB JJ)
PTB POS (OR) (NNP -RRB-), (. JJ JJ), (JJ NN CD) (NNS IN NNS), (PRP JJ PRP), (JJ NNP NNP)
Shallow Parse (IR) [...explosion...]NP, [...marathon...]NP, [...bomb...]NP, [...waz...]V P,
[...bombs...]NP [...evacuation...]NP
Shallow Parse (OR) [...school...]NP, [...song...]NP, [...school...]NP, [...head...]NP, [...wit...]PP
[...breakfast...]NP
CS (IR) [in boston/N]PP, [for boston/N]PP, (while/P a/D hurricane/N), (of/P my/D
(i’m/L safe/A) house/N), [in http://t.co/UxkKJLoX/N]PP
CS (OR) (to/P the/D beach/N), [at la/N]PP, [like water/N]PP, (shutdowns/N on/P),
[in love/N]PP (prayer/N for/P)
</table>
<bodyText confidence="0.999747916666667">
tionship to the crisis. Comparing the two crises,
the top features for Hurricane Sandy are more con-
cerned with user-user communication. For ex-
ample, the heavily-weighted ARK POS trigram
(@ @ #) is highly indicative of users spreading
information between each other. One explanation
is that the concern with communication could be
a result of the warning that came from the storm.
The bigram (hurricane ,) is the 3rd most in-
dicative of a tweet originating from outside the re-
gion. This is likely because the word occurs in the
general discussion outside of the crisis region.
</bodyText>
<sectionHeader confidence="0.999851" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99964956">
Geolocation: Eisenstein et al. (2010) first looked
at the problem of using latent variables to ex-
plain the distribution of text in tweets. This prob-
lem was revisited from the perspective of geodesic
grids in Wing and Baldridge (2011) and further
improved by flexible adaptive grids (Roller et al.,
2012). Cheng et al. (2010) employed an approach
that looks at a user’s tweets and estimates the
user’s location based on words with a local geo-
graphical scope. Han et al. (2013) combines tweet
text with metadata to predict a user’s location.
Mass Emergencies: De Longueville et al.
(2009) study Twitter’s use as a sensor for crisis
information by studying the geographical proper-
ties of users’ tweets. In Castillo et al. (2011),
the authors analyze the text and social network
of tweets to classify their newsworthiness. Kumar
et al. (2013) use geotagged tweets to find emerg-
ing topics in crisis data. Investigating linguistic
features, Verma et al. (2011) show the efficacy
of language features at finding crisis-time tweets
that contain tactical, actionable information, con-
tributing to situational awareness. Using a larger
dataset, we automatically discover linguistic fea-
tures that can help with situational awareness.
</bodyText>
<sectionHeader confidence="0.996167" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999612">
This paper addresses the challenge of finding
tweets that originate from a crisis region using
only the language of each tweet. We find that the
tweets authored from within the crisis region do
differ, from both tweets published during tranquil
time periods and from tweets published from other
geographic regions. We compare the utility of sev-
eral linguistic feature classes that may help to dis-
tinguish the two classes and build a classifier based
on these features to automate the process of iden-
tifying the IR tweets. We find that our classifier
performs well and that this approach is suitable for
attacking this problem.
Future work includes incorporating the wealth
of tweets preceding the disaster for better predic-
tions. Preliminary tests have shown positive re-
sults; for example we found early, non-geotagged
reports of flooding in the Hoboken train tunnels
during Hurricane Sandy1. Future work may also
consider additional features, such as sentiment.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999494">
This work is sponsored in part by the Office
of Naval Research, grants N000141010091 and
N000141110527, and the Ira A. Fulton Schools of
Engineering, through fellowships to F. Morstatter
and N. Lubold. We thank Alan Ritter and the ARK
research group at CMU for sharing their tools.
</bodyText>
<footnote confidence="0.9997135">
1An extended version of this paper is available at: http://
www.public.asu.edu/∼fmorstat/paperpdfs/lang loc.pdf.
</footnote>
<page confidence="0.996815">
26
</page>
<sectionHeader confidence="0.974821" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998069671232877">
Carlos Castillo, Marcelo Mendoza, and Barbara
Poblete. 2011. Information Credibility on Twitter.
In Proceedings of the 20th International Conference
on World Wide Web, pages 675–684. ACM.
Zhiyuan Cheng, James Caverlee, and Kyumin Lee.
2010. You Are Where You Tweet: A Content-Based
Approach to Geo-locating Twitter Users. In Pro-
ceedings of the 19th ACM International Conference
on Information and Knowledge Management, pages
759–768. ACM.
Bertrand De Longueville, Robin S Smith, and Gian-
luca Luraschi. 2009. “OMG, from here, I can
see the flames!”: a use case of mining Location
Based Social Networks to acquire spatio-temporal
data on forest fires. In Proceedings of the 2009 In-
ternational Workshop on Location Based Social Net-
works, pages 73–80. ACM.
Jacob Eisenstein, Brendan O’Connor, Noah A Smith,
and Eric P Xing. 2010. A Latent Variable Model
for Geographic Lexical Variation. In Proceedings of
the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1277–1287. Asso-
ciation for Computational Linguistics.
Bo Han, Paul Cook, and Timothy Baldwin. 2013. A
Stacking-based Approach to Twitter User Geoloca-
tion Prediction. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics (ACL 2013): System Demonstrations, pages
7–12.
Shamanth Kumar, Fred Morstatter, Reza Zafarani, and
Huan Liu. 2013. Whom Should I Follow?: Identi-
fying Relevant Users During Crises. In Proceedings
of the 24th ACM Conference on Hypertext and So-
cial Media, HT ’13, pages 139–147, New York, NY,
USA. ACM.
Jianhua Lin. 1991. Divergence measures based on the
shannon entropy. IEEE Transactions on Information
Theory, 37(1):145–151.
Fred Morstatter, J¨urgen Pfeffer, Huan Liu, and Kath-
leen M Carley. 2013. Is the Sample Good Enough?
Comparing Data from Twitter’s Streaming API with
Twitter’s Firehose. Proceedings of The Interna-
tional Conference on Weblogs and Social Media.
Olutobi Owoputi, Brendan O’Connor, Chris Dyer,
Kevin Gimpel, Nathan Schneider, and Noah A
Smith. 2013. Improved Part-of-Speech Tagging for
Online Conversational Text with Word Clusters. In
Proceedings of NAACL-HLT, pages 380–390.
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.
2011. Named entity recognition in tweets: An ex-
perimental study. In EMNLP.
Stephen Roller, Michael Speriosu, Sarat Rallapalli,
Benjamin Wing, and Jason Baldridge. 2012. Super-
vised Text-Based Geolocation using Language Mod-
els on an Adaptive Grid. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, pages 1500–1510. Association
for Computational Linguistics.
United Nations. 2012. Humanitarianism in the Net-
work Age. United Nations Office for the Coordina-
tion of Humanitarian Affairs.
Sudha Verma, Sarah Vieweg, William J Corvey, Leysia
Palen, James H Martin, Martha Palmer, Aaron
Schram, and Kenneth Mark Anderson. 2011. Natu-
ral Language Processing to the Rescue? Extracting
“Situational Awareness” Tweets During Mass Emer-
gency. In ICWSM.
Benjamin Wing and Jason Baldridge. 2011. Simple
Supervised Document Geolocation with Geodesic
Grids. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics (ACL
2011), pages 955–964.
</reference>
<page confidence="0.998809">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.716193">
<title confidence="0.999986">Finding Eyewitness Tweets During Crises</title>
<author confidence="0.994337">Nichola Heather J¨urgen</author>
<author confidence="0.994337">Huan</author>
<affiliation confidence="0.999701">State University, Tempe, Arizona,</affiliation>
<address confidence="0.970586">Mellon University, Pittsburgh, Pennsylvania, USA</address>
<email confidence="0.999479">nlubold,ponbarry,jpfeffer@cs.cmu.edu</email>
<abstract confidence="0.987627238095238">Disaster response agencies incorporate social media as a source of fast-breaking information to understand the needs of people affected by the many crises that occur around the world. These agencies look for tweets from within the region affected by the crisis to get the latest updates on the status of the affected region. However only 1% of all tweets are “geotagged” with explicit location information. In this work we seek to identify non-geotagged tweets that originate from within the crisis region. Towards this, we address three questions: (1) is there a difference between the language of tweets originating within a crisis region, (2) what linguistic patterns differentiate within-region and outside-region tweets, and (3) can we automatically identify those originating within the crisis region in real-time?</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Carlos Castillo</author>
<author>Marcelo Mendoza</author>
<author>Barbara Poblete</author>
</authors>
<title>Information Credibility on Twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th International Conference on World Wide Web,</booktitle>
<pages>675--684</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15438" citStr="Castillo et al. (2011)" startWordPosition="2512" endWordPosition="2515">the distribution of text in tweets. This problem was revisited from the perspective of geodesic grids in Wing and Baldridge (2011) and further improved by flexible adaptive grids (Roller et al., 2012). Cheng et al. (2010) employed an approach that looks at a user’s tweets and estimates the user’s location based on words with a local geographical scope. Han et al. (2013) combines tweet text with metadata to predict a user’s location. Mass Emergencies: De Longueville et al. (2009) study Twitter’s use as a sensor for crisis information by studying the geographical properties of users’ tweets. In Castillo et al. (2011), the authors analyze the text and social network of tweets to classify their newsworthiness. Kumar et al. (2013) use geotagged tweets to find emerging topics in crisis data. Investigating linguistic features, Verma et al. (2011) show the efficacy of language features at finding crisis-time tweets that contain tactical, actionable information, contributing to situational awareness. Using a larger dataset, we automatically discover linguistic features that can help with situational awareness. 6 Conclusion and Future Work This paper addresses the challenge of finding tweets that originate from a</context>
</contexts>
<marker>Castillo, Mendoza, Poblete, 2011</marker>
<rawString>Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information Credibility on Twitter. In Proceedings of the 20th International Conference on World Wide Web, pages 675–684. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Cheng</author>
<author>James Caverlee</author>
<author>Kyumin Lee</author>
</authors>
<title>You Are Where You Tweet: A Content-Based Approach to Geo-locating Twitter Users.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM International Conference on Information and Knowledge Management,</booktitle>
<pages>759--768</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2439" citStr="Cheng et al., 2010" startWordPosition="383" endWordPosition="386">e to situational awareness (Verma et al., 2011). A major limitation of surveying geotagged tweets is that only 1% of all tweets are geotagged (Morstatter et al., 2013). This leaves the first responders unable to tap into the vast majority of the tweets they collect. This limitation leads to the question driving this work: can we discover whether a tweet originates from within a crisis region using only the language used of the tweet? We focus on the language of a tweet as the defining factor of location for three major reasons: (1) the language of Twitter users is dependent on their location (Cheng et al., 2010), (2) the text is readily available in every tweet, and (3) the text allows for real-time analysis. Due to the short time window presented by most crises, first responders need to be able to locate users quickly. Towards this goal, we examine tweets from two recent crises: the Boston Marathon bombing and Hurricane Sandy. We show that linguistic differences exist between tweets authored inside and outside the affected regions. By analyzing the text of individual tweets we can predict whether the tweet originates from within the crisis region, in real-time. To better understand the characteristi</context>
<context position="15037" citStr="Cheng et al. (2010)" startWordPosition="2445" endWordPosition="2448">oncern with communication could be a result of the warning that came from the storm. The bigram (hurricane ,) is the 3rd most indicative of a tweet originating from outside the region. This is likely because the word occurs in the general discussion outside of the crisis region. 5 Related Work Geolocation: Eisenstein et al. (2010) first looked at the problem of using latent variables to explain the distribution of text in tweets. This problem was revisited from the perspective of geodesic grids in Wing and Baldridge (2011) and further improved by flexible adaptive grids (Roller et al., 2012). Cheng et al. (2010) employed an approach that looks at a user’s tweets and estimates the user’s location based on words with a local geographical scope. Han et al. (2013) combines tweet text with metadata to predict a user’s location. Mass Emergencies: De Longueville et al. (2009) study Twitter’s use as a sensor for crisis information by studying the geographical properties of users’ tweets. In Castillo et al. (2011), the authors analyze the text and social network of tweets to classify their newsworthiness. Kumar et al. (2013) use geotagged tweets to find emerging topics in crisis data. Investigating linguistic</context>
</contexts>
<marker>Cheng, Caverlee, Lee, 2010</marker>
<rawString>Zhiyuan Cheng, James Caverlee, and Kyumin Lee. 2010. You Are Where You Tweet: A Content-Based Approach to Geo-locating Twitter Users. In Proceedings of the 19th ACM International Conference on Information and Knowledge Management, pages 759–768. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bertrand De Longueville</author>
<author>Robin S Smith</author>
<author>Gianluca Luraschi</author>
</authors>
<title>OMG, from here, I can see the flames!”: a use case of mining Location Based Social Networks to acquire spatio-temporal data on forest fires.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 International Workshop on Location Based Social Networks,</booktitle>
<pages>73--80</pages>
<publisher>ACM.</publisher>
<marker>De Longueville, Smith, Luraschi, 2009</marker>
<rawString>Bertrand De Longueville, Robin S Smith, and Gianluca Luraschi. 2009. “OMG, from here, I can see the flames!”: a use case of mining Location Based Social Networks to acquire spatio-temporal data on forest fires. In Proceedings of the 2009 International Workshop on Location Based Social Networks, pages 73–80. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>A Latent Variable Model for Geographic Lexical Variation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1277--1287</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Jacob Eisenstein, Brendan O’Connor, Noah A Smith, and Eric P Xing. 2010. A Latent Variable Model for Geographic Lexical Variation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1277–1287. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>A Stacking-based Approach to Twitter User Geolocation Prediction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013): System Demonstrations,</booktitle>
<pages>7--12</pages>
<contexts>
<context position="15188" citStr="Han et al. (2013)" startWordPosition="2472" endWordPosition="2475">nating from outside the region. This is likely because the word occurs in the general discussion outside of the crisis region. 5 Related Work Geolocation: Eisenstein et al. (2010) first looked at the problem of using latent variables to explain the distribution of text in tweets. This problem was revisited from the perspective of geodesic grids in Wing and Baldridge (2011) and further improved by flexible adaptive grids (Roller et al., 2012). Cheng et al. (2010) employed an approach that looks at a user’s tweets and estimates the user’s location based on words with a local geographical scope. Han et al. (2013) combines tweet text with metadata to predict a user’s location. Mass Emergencies: De Longueville et al. (2009) study Twitter’s use as a sensor for crisis information by studying the geographical properties of users’ tweets. In Castillo et al. (2011), the authors analyze the text and social network of tweets to classify their newsworthiness. Kumar et al. (2013) use geotagged tweets to find emerging topics in crisis data. Investigating linguistic features, Verma et al. (2011) show the efficacy of language features at finding crisis-time tweets that contain tactical, actionable information, cont</context>
</contexts>
<marker>Han, Cook, Baldwin, 2013</marker>
<rawString>Bo Han, Paul Cook, and Timothy Baldwin. 2013. A Stacking-based Approach to Twitter User Geolocation Prediction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013): System Demonstrations, pages 7–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shamanth Kumar</author>
<author>Fred Morstatter</author>
<author>Reza Zafarani</author>
<author>Huan Liu</author>
</authors>
<title>Whom Should I Follow?: Identifying Relevant Users During Crises.</title>
<date>2013</date>
<booktitle>In Proceedings of the 24th ACM Conference on Hypertext and Social Media, HT ’13,</booktitle>
<pages>139--147</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1767" citStr="Kumar et al., 2013" startWordPosition="267" endWordPosition="270">ction Due to Twitter’s massive popularity, it has become a tool used by first responders—those who provide first-hand aid in times of crisis—to understand crisis situations and identify the people in the most dire need of assistance (United Nations, 2012). To do this, first responders can survey “geotagged” tweets: those where the user has supplied a geographic location. The advantage of geotagged tweets is that first responders know whether a person is tweeting from within the affected region or is tweeting from afar. Tweets from within this region are more likely to contain emerging topics (Kumar et al., 2013) and tactical, actionable, information that contribute to situational awareness (Verma et al., 2011). A major limitation of surveying geotagged tweets is that only 1% of all tweets are geotagged (Morstatter et al., 2013). This leaves the first responders unable to tap into the vast majority of the tweets they collect. This limitation leads to the question driving this work: can we discover whether a tweet originates from within a crisis region using only the language used of the tweet? We focus on the language of a tweet as the defining factor of location for three major reasons: (1) the langu</context>
<context position="15551" citStr="Kumar et al. (2013)" startWordPosition="2530" endWordPosition="2533">ldridge (2011) and further improved by flexible adaptive grids (Roller et al., 2012). Cheng et al. (2010) employed an approach that looks at a user’s tweets and estimates the user’s location based on words with a local geographical scope. Han et al. (2013) combines tweet text with metadata to predict a user’s location. Mass Emergencies: De Longueville et al. (2009) study Twitter’s use as a sensor for crisis information by studying the geographical properties of users’ tweets. In Castillo et al. (2011), the authors analyze the text and social network of tweets to classify their newsworthiness. Kumar et al. (2013) use geotagged tweets to find emerging topics in crisis data. Investigating linguistic features, Verma et al. (2011) show the efficacy of language features at finding crisis-time tweets that contain tactical, actionable information, contributing to situational awareness. Using a larger dataset, we automatically discover linguistic features that can help with situational awareness. 6 Conclusion and Future Work This paper addresses the challenge of finding tweets that originate from a crisis region using only the language of each tweet. We find that the tweets authored from within the crisis reg</context>
</contexts>
<marker>Kumar, Morstatter, Zafarani, Liu, 2013</marker>
<rawString>Shamanth Kumar, Fred Morstatter, Reza Zafarani, and Huan Liu. 2013. Whom Should I Follow?: Identifying Relevant Users During Crises. In Proceedings of the 24th ACM Conference on Hypertext and Social Media, HT ’13, pages 139–147, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianhua Lin</author>
</authors>
<title>Divergence measures based on the shannon entropy.</title>
<date>1991</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="6072" citStr="Lin, 1991" startWordPosition="967" endWordPosition="968">) from inside the crisis region (PC-IR) and (2) pre-crisis tweets from outside the crisis region (PC-OR). We take a time-based sample from 10:00–14:48 Eastern on April 15th, 2013 to obtain PC-IR and PC-OR. Because the bombing was an abrupt event with no warning, we choose a time period immediately preceding its onset. The number of tweets in each dataset partition is shown in Table 1. 2.3 Pre-Crisis vs. During-Crisis Language For the Boston dataset, we compare the words used hour by hour between 10:00–19:00 on April 15th. For each pair of hours, we compute the Jensen-Shannon (J-S) divergence (Lin, 1991) of the probability distributions of the words used (a) Temporal lan- (b) Geographic lan- (c) Geographic language differences. guage differences: guage differences: tranquil time. crisis time. Figure 1: Temporal and geographic differences of language (calculated using Jensen-Shannon divergence); darker shades represent greater difference. To illustrate geographic differences, we compare Boston with three other major U.S. cities. within those hours. Figure 1(a) shows these J-S divergence values. We see an abrupt change in language in the hours before the bombing (10:00– 14:00) and those after t</context>
</contexts>
<marker>Lin, 1991</marker>
<rawString>Jianhua Lin. 1991. Divergence measures based on the shannon entropy. IEEE Transactions on Information Theory, 37(1):145–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Morstatter</author>
<author>J¨urgen Pfeffer</author>
<author>Huan Liu</author>
<author>Kathleen M Carley</author>
</authors>
<title>Is the Sample Good Enough? Comparing Data from Twitter’s Streaming API with Twitter’s Firehose.</title>
<date>2013</date>
<booktitle>Proceedings of The International Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="1987" citStr="Morstatter et al., 2013" startWordPosition="302" endWordPosition="305">eed of assistance (United Nations, 2012). To do this, first responders can survey “geotagged” tweets: those where the user has supplied a geographic location. The advantage of geotagged tweets is that first responders know whether a person is tweeting from within the affected region or is tweeting from afar. Tweets from within this region are more likely to contain emerging topics (Kumar et al., 2013) and tactical, actionable, information that contribute to situational awareness (Verma et al., 2011). A major limitation of surveying geotagged tweets is that only 1% of all tweets are geotagged (Morstatter et al., 2013). This leaves the first responders unable to tap into the vast majority of the tweets they collect. This limitation leads to the question driving this work: can we discover whether a tweet originates from within a crisis region using only the language used of the tweet? We focus on the language of a tweet as the defining factor of location for three major reasons: (1) the language of Twitter users is dependent on their location (Cheng et al., 2010), (2) the text is readily available in every tweet, and (3) the text allows for real-time analysis. Due to the short time window presented by most c</context>
</contexts>
<marker>Morstatter, Pfeffer, Liu, Carley, 2013</marker>
<rawString>Fred Morstatter, J¨urgen Pfeffer, Huan Liu, and Kathleen M Carley. 2013. Is the Sample Good Enough? Comparing Data from Twitter’s Streaming API with Twitter’s Firehose. Proceedings of The International Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olutobi Owoputi</author>
<author>Brendan O’Connor</author>
<author>Chris Dyer</author>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Improved Part-of-Speech Tagging for Online Conversational Text with Word Clusters.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>380--390</pages>
<marker>Owoputi, O’Connor, Dyer, Gimpel, Schneider, Smith, 2013</marker>
<rawString>Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, Nathan Schneider, and Noah A Smith. 2013. Improved Part-of-Speech Tagging for Online Conversational Text with Word Clusters. In Proceedings of NAACL-HLT, pages 380–390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: An experimental study.</title>
<date>2011</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="8734" citStr="Ritter et al. (2011)" startWordPosition="1388" endWordPosition="1391">t using the CMU Twitter NLP POS tagger (Owoputi et al., 2013). We con24 sider CMU ARK POS tags, developed specifically for the dynamic and informal nature of tweets, as well as Penn Treebank (PTB) style POS tags. The ARK POS tags are coarser than the PTB tags and can identify Twitter-specific entities in the data like hashtags. By comparing both tag sets, we can measure the effectiveness of both the fine-grained versus coarse-grained tag sets. Shallow Parsing In addition to the POS tags, we extract shallow parsing tags along with the headword associated with the tag using the tool provided by Ritter et al. (2011). For example, in the noun phrase “the movie” we would extract the headword “movie” and represent it as [...movie...]NP. The underlying motivation is that this class may give more insight into the syntactic differences of IR tweets versus OR tweets. Crisis-Sensitive (CS) Features We create a mixed-class of “crisis sensitive” features composed of word-based, part of speech, and syntactic constituent attributes. These are based on our analysis of the Boston Marathon data set. We later apply these features to the Hurricane Sandy data set to validate whether the features are generalizable across c</context>
</contexts>
<marker>Ritter, Clark, Mausam, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named entity recognition in tweets: An experimental study. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Roller</author>
<author>Michael Speriosu</author>
<author>Sarat Rallapalli</author>
<author>Benjamin Wing</author>
<author>Jason Baldridge</author>
</authors>
<title>Supervised Text-Based Geolocation using Language Models on an Adaptive Grid.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1500--1510</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15016" citStr="Roller et al., 2012" startWordPosition="2441" endWordPosition="2444">lanation is that the concern with communication could be a result of the warning that came from the storm. The bigram (hurricane ,) is the 3rd most indicative of a tweet originating from outside the region. This is likely because the word occurs in the general discussion outside of the crisis region. 5 Related Work Geolocation: Eisenstein et al. (2010) first looked at the problem of using latent variables to explain the distribution of text in tweets. This problem was revisited from the perspective of geodesic grids in Wing and Baldridge (2011) and further improved by flexible adaptive grids (Roller et al., 2012). Cheng et al. (2010) employed an approach that looks at a user’s tweets and estimates the user’s location based on words with a local geographical scope. Han et al. (2013) combines tweet text with metadata to predict a user’s location. Mass Emergencies: De Longueville et al. (2009) study Twitter’s use as a sensor for crisis information by studying the geographical properties of users’ tweets. In Castillo et al. (2011), the authors analyze the text and social network of tweets to classify their newsworthiness. Kumar et al. (2013) use geotagged tweets to find emerging topics in crisis data. Inv</context>
</contexts>
<marker>Roller, Speriosu, Rallapalli, Wing, Baldridge, 2012</marker>
<rawString>Stephen Roller, Michael Speriosu, Sarat Rallapalli, Benjamin Wing, and Jason Baldridge. 2012. Supervised Text-Based Geolocation using Language Models on an Adaptive Grid. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1500–1510. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>United Nations</author>
</authors>
<title>Humanitarianism in the Network Age. United Nations Office for the Coordination of Humanitarian Affairs.</title>
<date>2012</date>
<contexts>
<context position="1403" citStr="Nations, 2012" startWordPosition="207" endWordPosition="208">nate from within the crisis region. Towards this, we address three questions: (1) is there a difference between the language of tweets originating within a crisis region, (2) what linguistic patterns differentiate within-region and outside-region tweets, and (3) can we automatically identify those originating within the crisis region in real-time? 1 Introduction Due to Twitter’s massive popularity, it has become a tool used by first responders—those who provide first-hand aid in times of crisis—to understand crisis situations and identify the people in the most dire need of assistance (United Nations, 2012). To do this, first responders can survey “geotagged” tweets: those where the user has supplied a geographic location. The advantage of geotagged tweets is that first responders know whether a person is tweeting from within the affected region or is tweeting from afar. Tweets from within this region are more likely to contain emerging topics (Kumar et al., 2013) and tactical, actionable, information that contribute to situational awareness (Verma et al., 2011). A major limitation of surveying geotagged tweets is that only 1% of all tweets are geotagged (Morstatter et al., 2013). This leaves th</context>
</contexts>
<marker>Nations, 2012</marker>
<rawString>United Nations. 2012. Humanitarianism in the Network Age. United Nations Office for the Coordination of Humanitarian Affairs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sudha Verma</author>
<author>Sarah Vieweg</author>
<author>William J Corvey</author>
<author>Leysia Palen</author>
<author>James H Martin</author>
<author>Martha Palmer</author>
<author>Aaron Schram</author>
<author>Kenneth Mark Anderson</author>
</authors>
<title>Natural Language Processing to the Rescue? Extracting “Situational Awareness” Tweets During Mass Emergency.</title>
<date>2011</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="1867" citStr="Verma et al., 2011" startWordPosition="281" endWordPosition="284">rovide first-hand aid in times of crisis—to understand crisis situations and identify the people in the most dire need of assistance (United Nations, 2012). To do this, first responders can survey “geotagged” tweets: those where the user has supplied a geographic location. The advantage of geotagged tweets is that first responders know whether a person is tweeting from within the affected region or is tweeting from afar. Tweets from within this region are more likely to contain emerging topics (Kumar et al., 2013) and tactical, actionable, information that contribute to situational awareness (Verma et al., 2011). A major limitation of surveying geotagged tweets is that only 1% of all tweets are geotagged (Morstatter et al., 2013). This leaves the first responders unable to tap into the vast majority of the tweets they collect. This limitation leads to the question driving this work: can we discover whether a tweet originates from within a crisis region using only the language used of the tweet? We focus on the language of a tweet as the defining factor of location for three major reasons: (1) the language of Twitter users is dependent on their location (Cheng et al., 2010), (2) the text is readily av</context>
<context position="15667" citStr="Verma et al. (2011)" startWordPosition="2548" endWordPosition="2551">n approach that looks at a user’s tweets and estimates the user’s location based on words with a local geographical scope. Han et al. (2013) combines tweet text with metadata to predict a user’s location. Mass Emergencies: De Longueville et al. (2009) study Twitter’s use as a sensor for crisis information by studying the geographical properties of users’ tweets. In Castillo et al. (2011), the authors analyze the text and social network of tweets to classify their newsworthiness. Kumar et al. (2013) use geotagged tweets to find emerging topics in crisis data. Investigating linguistic features, Verma et al. (2011) show the efficacy of language features at finding crisis-time tweets that contain tactical, actionable information, contributing to situational awareness. Using a larger dataset, we automatically discover linguistic features that can help with situational awareness. 6 Conclusion and Future Work This paper addresses the challenge of finding tweets that originate from a crisis region using only the language of each tweet. We find that the tweets authored from within the crisis region do differ, from both tweets published during tranquil time periods and from tweets published from other geograph</context>
</contexts>
<marker>Verma, Vieweg, Corvey, Palen, Martin, Palmer, Schram, Anderson, 2011</marker>
<rawString>Sudha Verma, Sarah Vieweg, William J Corvey, Leysia Palen, James H Martin, Martha Palmer, Aaron Schram, and Kenneth Mark Anderson. 2011. Natural Language Processing to the Rescue? Extracting “Situational Awareness” Tweets During Mass Emergency. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Wing</author>
<author>Jason Baldridge</author>
</authors>
<title>Simple Supervised Document Geolocation with Geodesic Grids.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>955--964</pages>
<contexts>
<context position="14946" citStr="Wing and Baldridge (2011)" startWordPosition="2430" endWordPosition="2433">ighly indicative of users spreading information between each other. One explanation is that the concern with communication could be a result of the warning that came from the storm. The bigram (hurricane ,) is the 3rd most indicative of a tweet originating from outside the region. This is likely because the word occurs in the general discussion outside of the crisis region. 5 Related Work Geolocation: Eisenstein et al. (2010) first looked at the problem of using latent variables to explain the distribution of text in tweets. This problem was revisited from the perspective of geodesic grids in Wing and Baldridge (2011) and further improved by flexible adaptive grids (Roller et al., 2012). Cheng et al. (2010) employed an approach that looks at a user’s tweets and estimates the user’s location based on words with a local geographical scope. Han et al. (2013) combines tweet text with metadata to predict a user’s location. Mass Emergencies: De Longueville et al. (2009) study Twitter’s use as a sensor for crisis information by studying the geographical properties of users’ tweets. In Castillo et al. (2011), the authors analyze the text and social network of tweets to classify their newsworthiness. Kumar et al. (</context>
</contexts>
<marker>Wing, Baldridge, 2011</marker>
<rawString>Benjamin Wing and Jason Baldridge. 2011. Simple Supervised Document Geolocation with Geodesic Grids. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011), pages 955–964.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>