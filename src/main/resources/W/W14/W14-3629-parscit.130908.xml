<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001104">
<title confidence="0.983553">
Arabizi Detection and Conversion to Arabic
</title>
<author confidence="0.997865">
Kareem Darwish
</author>
<affiliation confidence="0.9211155">
Qatar Computing Research Institute
Qatar Foundation, Doha, Qatar
</affiliation>
<email confidence="0.988445">
kdarwish@qf.org.qa
</email>
<sectionHeader confidence="0.99729" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995489375">
Arabizi is Arabic text that is written using Latin
characters. Arabizi is used to present both Mod-
ern Standard Arabic (MSA) or Arabic dialects. It
is commonly used in informal settings such as so-
cial networking sites and is often with mixed with
English. In this paper we address the problems of:
identifying Arabizi in text and converting it to Ara-
bic characters. We used word and sequence-level
features to identify Arabizi that is mixed with En-
glish. We achieved an identification accuracy of
98.5%. As for conversion, we used transliteration
mining with language modeling to generate equiva-
lent Arabic text. We achieved 88.7% conversion ac-
curacy, with roughly a third of errors being spelling
and morphological variants of the forms in ground
truth.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998358361702128">
Arabic is often written using Latin characters in
transliterated form, which is often referred to as Ara-
bizi, Arabish, Franco-Arab, and other names. Ara-
bizi uses numerals to represent Arabic letters for
which there is no phonetic equivalent in English or
to account for the fact that Arabic has more letters
than English. For example, “2” and “3” represent
�
the letters I (that sounds like “a” as in apple) and L
(that is a guttural “aa”) respectively. Arabizi is par-
ticularly popular in Arabic social media. Arabizi has
grown out of a need to write Arabic on systems that
do not support Arabic script natively. For example,
Internet Explorer 5.0, which was released in March
1999, was the first version of the browser to sup-
port Arabic display natively1. Windows Mobile and
Android did not support Arabic except through third
party support until versions 6.5x and 3.x respec-
tively. Despite the increasing support of Arabic in
many platforms, Arabizi continues to be popular due
to the familiarity of users with it and the higher profi-
ciency of users to use an English keyboard compared
to an Arabic keyboard. Arabizi is used to present
both MSA as well as different Arabic dialects, which
lack commonly used spelling conventions and differ
morphologically and phonetically from MSA. There
has been recent efforts to standardize the spelling
of some Arabic dialects (Habash et al., 2012), but
such standards are not widely adopted on social me-
dia. Additionally, due to the fact that many of the
Arabic speakers are bilingual (with their second lan-
guage being either English or French), another com-
monly observed phenomenon is the presence of En-
glish (or French) and Arabizi mixed together within
sentences, where users code switch between both
languages. In this paper we focus on performing two
tasks, namely: detecting Arabizi even when juxta-
posed with English; and converting Arabizi to Ara-
bic script regardless of it being MSA or dialectal.
Detecting and converting Arabizi to Arabic script
would help: ease the reading of the text, where
Arabizi is difficult to read; allow for the process-
ing of Arabizi (post conversion) using existing NLP
tools; and normalize Arabic and Arabizi into a uni-
fied form for text processing and search. Detecting
and converting Arabizi are complicated by the fol-
lowing challenges:
</bodyText>
<footnote confidence="0.9843215">
1http://en.wikipedia.org/wiki/Internet_
Explorer
</footnote>
<page confidence="0.896933">
217
</page>
<note confidence="0.8697655">
Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 217–224,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<listItem confidence="0.9714008">
1. Due to the lack of spelling conventions for Ara-
bizi and Arabic dialectal text, which Arabizi of-
ten encodes, building a comprehensive dictio-
nary of Arabizi words is prohibitive. Consider
the following examples:
(a) The MSA word (liberty) has the fol-
lowing popular Arabizi spellings: ta7rir,
t7rir, tahrir, ta7reer, tahreer, etc.
(b) The dialectal equivalents to the MSA
,.. V (he does not play) could be
</listItem>
<bodyText confidence="0.863593863636364">
���������L-, ��������L-, ��������-, ��������L-
�
etc. The resultant Arabizi could be:
mayel3absh, mabyelaabsh, mabyel3absh,
etc.
2. Some Arabizi and English words share a com-
mon spelling, making solely relying on an En-
glish dictionary insufficient to identify English
words. Consider the following examples (am-
biguous words are bolded):
(a) Ana 3awez aroo7 men America leh
Canada (I want to go from America to
Canada). The word “men” meaning
“from” is also an English word.
(b) I called Mohamed last night. “Mohamed”
in this context is an English word, though
it is a transliterated Arabic name.
3. Within social media, users often use creative
spellings of English words to shorten text, em-
phasize, or express emotion. This can compli-
cate the differentiation of English and Arabizi.
Consider the following examples:
</bodyText>
<listItem confidence="0.686185666666667">
(a) I want 2 go with u tmrw, cuz my car is
broken.
(b) Woooooow. Ur car is cooooooool.
</listItem>
<bodyText confidence="0.997972545454546">
Due to these factors, classifying a word as Ara-
bizi or English has to be done in-context. Thus, we
employed sequence labeling using Conditional Ran-
dom Fields (CRF) to detect Arabizi in context. The
CRF was trained using word-level and sequence-
level features. For converting Arabizi to Arabic
script, we used transliteration mining in combination
with a large Arabic language model that covers both
MSA and other Arabic dialects to properly choose
the best transliterations in context.
The contributions of this paper are:
</bodyText>
<listItem confidence="0.998098222222222">
• We employed sequence labeling that is trained
using word-level and sequence-level features
to identify in-sentence code-switching between
two languages that share a common alphabet.
• We used transliteration mining and language
modeling to convert form Arabizi to Arabic
script.
• We plan to publicly release all our training and
test data.
</listItem>
<bodyText confidence="0.932540142857143">
The remainder of the paper is organized as fol-
lows: Section 2 provides related work; Section 3
presents our Arabizi detection and reports on the
detection accuracy; Section 4 describes our Arabizi
to Arabic conversion approach and reports the ac-
curacy of conversion; and Section 5 concludes the
paper.
</bodyText>
<sectionHeader confidence="0.9999" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999987416666667">
There are two aspects to this work: the first is lan-
guage identification, and the second is translitera-
tion. There is much work on language identifica-
tion including open source utilities, such as the Lan-
guage Detection Library for Java2. Murthy and Ku-
mar (2006) surveyed many techniques for language
identification. Some of the more successful tech-
niques use character n-gram models (Beesley, 1988;
Dunning, 1994) in combination with a machine
learning technique such as hidden Markov mod-
els (HMM) or Bayesian classification (Xafopoulos
et al., 2004; Dunning, 1994). Murthy and Ku-
mar (2006) used logistic regression-like classifica-
tion that employed so-called “aksharas” which are
sub-word character sequences as features for identi-
fying different Indian languages. Ehara and Tanaka-
Ishii (2008) developed an online language detec-
tion system that detects code switching during typ-
ing, suggests the language to switch to the user,
and interactively invokes the appropriate text entry
method. They used HMM based language iden-
tification in conjunction with an n-gram character
language model. They reported up to 97% accu-
racy when detecting between two languages on a
</bodyText>
<footnote confidence="0.9462685">
2http://code.google.com/p/
language-detection/
</footnote>
<page confidence="0.995555">
218
</page>
<bodyText confidence="0.999973254545455">
synthetic test set. In our work, we performed of-
fline word-level language identification using CRF
sequence labeling, which conceptually combines
logistic regression-like discriminative classification
with an HMM-like generative model (Lafferty et al.,
2001). We opted to use a CRF sequence labeling be-
cause it allowed us to use both state and sequence
features, which in our case corresponded to word-
and sequence-level features respectively. One of the
downsides of using a CRF sequence labeler is that
most implementations, including CRF++ which was
used in this work, only use nominal features. This
required us to quantize all real-valued features.
Converting between from Arabizi to Arabic is
akin to transliteration or Transliteration Mining
(TM). In transliteration, a sequence in a source al-
phabet or writing system is used to generate a pho-
netically similar sequence in a target alphabet or
writing system. In TM, a sequence in a source al-
phabet or writing system is used to find the most
similar sequence in a lexicon that is written in the
target alphabet or writing system. Both problems
are fairly well studied with multiple evaluation cam-
paigns, particularly at the different editions of the
Named Entities Workshop (NEWS) (Zhang et al.,
2011; Zhang et al., 2012). In our work we relied
on TM from a large corpus of Arabic microblogs.
TM typically involves using transliteration pairs in
two different writing systems or alphabets to learn-
ing character (or character-sequence) level map-
pings between them. The learning can be done using
the EM algorithm (Kuo et al., 2006) or HMM align-
ment (Udupa et al., 2009). Once these mappings are
learned, a common approach involves using a gen-
erative model that attempts to generate all possible
transliterations of a source word, given the charac-
ter mappings between two languages, and restricting
the output to words in the target language (El-Kahki
et al., 2011; Noeman and Madkour, 2010). Other
approaches include the use of locality sensitive hash-
ing (Udupa and Kumar, 2010) and classification (Ji-
ampojamarn et al., 2010). Another dramatically dif-
ferent approaches involves the unsupervised learn-
ing of transliteration mappings from a large paral-
lel corpus instead of transliteration pairs (Sajjad et
al., 2012). In our work, we used the baseline sys-
tem of El-Kahky et al. (2011). There are three com-
mercial Input Method Editors (IMEs) that convert
from Arabizi to Arabic, namely: Yamli3, Microsoft
Maren4, and Google t3reeb5. Since they are IMEs,
they only work in an interactive mode and don’t al-
low for batch processing. Thus they are difficult
to compare against. Also, from interactively using
Arabic IMEs, it seems that they only use unigram
language modeling.
</bodyText>
<sectionHeader confidence="0.981213" genericHeader="method">
3 Identifying Arabizi
</sectionHeader>
<bodyText confidence="0.95776">
As mentioned earlier, classifying words as En-
glish or Arabizi requires the use of word-level and
sequence-level features. We opted to use CRF se-
quence labeling to identify Arabizi words. We used
the CRF++ implementation with default parame-
ters (Sha and Pereira, 2003). We constructed train-
ing and test sets for word-level language classifica-
tion from tweets that contain English, Arabizi, or a
mixture of English and Arabizi. We collected the
tweets in the following manner:
1. We issued commonly used Arabizi words as
queries against Twitter multiple times. These
words were “e7na” (we), “3shan” (because),
and “la2a” (no). We issued these queries ev-
ery 30 seconds for roughly 1 hour. We put large
time gaps between queries to ensure that the re-
sults were refreshed.
2. We extracted the user IDs of all the authors of
the tweets that we found, and used the IDs as
queries to Twitter to get the remaining tweets
that they have authored. Our intuition was that
tweeps who authored once in Arabizi would
likely have more Arabizi tweets. Doing so
helped us find Arabizi tweets that don’t neces-
sarily have the aforementioned common words
and helped us find significantly more Arabizi
text. In all we identified 265 tweeps who au-
thored 16,507 tweets in the last 7 days, contain-
ing 132,236 words. Of the words in the tweets,
some of them were English, but most of them
were Arabizi.
We filtered tweets where most of the words con-
tained Arabic letters. As in Table 1, all the tokens in
</bodyText>
<footnote confidence="0.999905666666667">
3http://www.yamli.com/editor/ar/
4http://www.getmaren.com
5http://www.google.com/ta3reeb
</footnote>
<page confidence="0.981932">
219
</page>
<table confidence="0.9642218">
Label Explanation
a Arabizi
e English
o Other including URL’s, user mentions, hashtags,
laughs (lol, , :P, xd), and none words
</table>
<tableCaption confidence="0.999913">
Table 1: Used labels for words
</tableCaption>
<bodyText confidence="0.99995334375">
the set were manually labeled as English (“e”), Ara-
bizi (“a”), or other (“o”). For training, we used 522
tweets, containing 5,207 tokens. The breakdown of
tokens is: 3,307 English tokens; 1,203 Arabizi to-
kens; and 697 other tokens. For testing, we used
101 tweets containing 3,491 tokens. The breakdown
of the tokens is: 797 English tokens; 1,926 Arabizi
tokens; and 768 other tokens. Though there is some
mismatch in the distribution of English and Arabizi
tokens between training and test sets, this mismatch
happened naturally and is unlikely to affect overall
accuracy numbers. For language models, we trained
two character level language models: the first us-
ing 9.4 million English words; and the second us-
ing 1,000 Arabizi words (excluding words in the test
set). We used the BerkeleyLM language modeling
toolkit.
We trained the CRF++ implementation of CRF
sequence labeler using the features in Table 2 along
with the previous word and next word. The Table
describes each feature and shows the features values
for the word “Yesss”.
Table 3 reports on the language identification re-
sults and breaks down the results per word type
and provides examples of mislabeling. Overall we
achieved a word-level language identification accu-
racy of 98.5%. As the examples in the table show,
the few mislabeling mistakes included: Arabized
English words, Arabizi words that happen to be En-
glish words, single Arabizi words surrounded by En-
glish words (or vice versa), and misspelled English
words.
</bodyText>
<sectionHeader confidence="0.98447" genericHeader="method">
4 Arabizi to Arabic
</sectionHeader>
<bodyText confidence="0.999154545454546">
As mentioned earlier, Arabizi is simply Arabic,
whether MSA or dialectal, that is written using Latin
characters. We were able to collect Arabizi text
by searching for common Arabizi words on Twit-
ter, identifying the authors of these tweets, and then
scraping their tweets to find more tweets written
in Arabizi. In all, we constructed a collection that
contained 3,452 training pairs that have both Ara-
bizi and Arabic equivalents. All Arabizi words were
manually transliterated into Arabic by a native Ara-
bic speaker. Some example pairs are:
</bodyText>
<listItem confidence="0.999687">
• 3endek → 1/4Y�J« (meaning “in your care”)
• bytl3 → ©Ê¢J�K. (meaning “he ascends”)
</listItem>
<bodyText confidence="0.99597125">
For testing, we constructed a set of 127 random
Arabizi tweets containing 1,385 word. Again, we
had a native Arabic speaker transliterate all tweets
into Arabic script. An example sentences is:
</bodyText>
<listItem confidence="0.98025825">
• sa7el eih ? howa ntii mesh hatigi bokra →
�èQºK. ú j J��Jë ~•Ó ú ~æ K@ ñë ? éK�@ ÉgAƒ
• meaning: what coast ? aren’t you coming to-
morrow
</listItem>
<bodyText confidence="0.8998855">
We applied the following preprocessing steps on
the training and test data:
</bodyText>
<listItem confidence="0.823614076923077">
• We performed the following Arabic letter nor-
malizations (Habash, 2010):
– ø (alef maqsoura) → ø� (ya)
� �
– @ (alef maad), @ (alef with hamza on top),
and �@ (alef with hamza on the bottom) → @
(alef)
– ð�(hamza on w), and Zø (hamza on ya)
→ Z (hamza)
�
– è (taa marbouta) → è (haa)
• Since people often repeat letters in tweets to
indicate stress or to express emotions, we re-
moved any repetition of a letter beyond 2 repe-
titions (Darwish et al., 2012). For example, we
transformed the word “salaaaam” to “salaam”.
• Many people tend to segment Arabic words in
Arabizi into separate constituent parts. For ex-
ample, you may find “w el kitab” (meaning
“and the book”) as 3 separate tokens, while
in Arabic they are concatenated into a single
token, namely “H. A:ºË@ð”. Thus, we concate-
nated short tokens that represent coordinating
conjunctions and prepositions to the tokens that
follow them. These tokens are: w, l, el, ll, la,
we, f, fel, fil, fl, lel, al, wel, and b.
</listItem>
<page confidence="0.987551">
220
</page>
<table confidence="0.998832217391305">
Feature Explanation Ex.
Word This would help label words that appear in the training examples. This feature is particularly useful for frequent yesss
words.
Short This would remove repeated characters in a word. Colloquial text such as tweets and Facebook statuses contain yes
word elongations.
IsLaugh This indicates if a word looks like a laugh or emoticon. For example lol, J, :D, :P, xD, (ha)+, etc. Smiles and laughs 0
should get an “o” label.
IsURL This indicates if a token resembles as URL of the form: http:/[a-zA-z0-9˙]+/. URLs should get an “o” label. 0
IsNo This indicates if a token is composed of numbers only. Numbers should get an “o” label 0
Is!Latin This indicates if a word is composed of non-Latin letters. If a word is composed on non-Latin characters, it is not 0
“e”.
WordLength This feature is simply the token length. Transliterated words are typically longer than native words 8
IsHashtag This indicates if it is a hashtag. Hashtags would get an “e” label. 0
IsNameMention This indicates if it is a name mention. Name mentions, which start with “@” sign, should get an “o” label. 0
IsEmail This indicates if it is an email. Emails, which match [\S\.\-_]+@[\S\.\-_]+ should get an “o” label. 0
wordEnUni Unigram probability in English word-level language model. The language model is built on English tweets. If a -4
word has a high probability of being English then it is likely English.
wordEnBi Bigram probability in English word-level language model of the word with the word that precedes it. If the proba- -4
bility is high then it is likely that it is an English word that follows another English word.
charEnNgram Trigram probability in English character-level language model of characters in a word. This checks if it is likely -2
sequence of characters in an English word.
charArNgram Trigram probability in Arabizi character-level language model of characters in a word. This checks if it is likely -13
sequence of characters in an Arabizi word.
</table>
<tableCaption confidence="0.985751">
Table 2: Used labels for words
</tableCaption>
<table confidence="0.929086176470588">
Actual Tag Predicted Tag Count Percent Example (Misclassified Token High- Analysis
lighted)
a a 1909 99.1%
a e 12 0.6% tfker b2y shy be relax, tab 3 3ashan el shy &amp; tab: words that exist in English but are
talta tabta actually Arabic in context
al weekend eljaay ya5i weekend: Arabized English words
wow be7keelk the cloud covered bt7keelk: sudden context switch before and af-
ter
a o 5 0.3% ya Yara ha call u @fjoooj eeeeeeeh ha &amp; eeeeeeh: mistaken for smiles or laughs
e e 773 97.0%
e a 21 2.6% el eye drope eh ya fara7 eye &amp; drop: sudden context switch
offtoschool offtoschool: misspelled English words
e o 3 0.4% 4 those going 2 tahrir 4 &amp; 2: numbers used instead of words
o o 758 98.7%
o e 3 0.4% URL’s and name mentions Could be fixed with either a simple rule or more
training data
o a 7 0.9%
</table>
<tableCaption confidence="0.999824">
Table 3: Used labels for words
</tableCaption>
<listItem confidence="0.544324">
• We directly transliterated the words “isA”
and “jAk” to “���l ��.: -�l�” (meaning “God
�
welling”) and to “l_���- 0l Al-_��” (meaning
“may God reward you”) respectively.
</listItem>
<bodyText confidence="0.999108909090909">
For training, we aligned the word-pairs at char-
acter level. The pairs were aligned using GIZA++
and the phrase extractor and scorer from the Moses
machine translation package (Koehn et al., 2007) .
To apply a machine translation analogy, we treated
words as sentences and the letters from which were
constructed as tokens. The alignment produced let-
ter sequence mappings. The alignment produced
mappings between Latin letters sequences and Ara-
bic letter sequences with associated mapping proba-
bilities. For example, here is a sample mapping:
</bodyText>
<listItem confidence="0.95979">
• 2r →_�&apos; (p = 0.459)
</listItem>
<bodyText confidence="0.994797">
To generate Arabic words from Arabizi words, we
made the fundamental simplifying assumption that
any generated Arabic word should exist in a large
word list. Though the assumption fundamentally
limits generation to previously seen words only, we
built the word list from a large set of tweets. Thus,
the probability that a correctly generated word did
not exist in the word list would be negligible. This
assumption allowed us to treat the problem as a min-
</bodyText>
<page confidence="0.995169">
221
</page>
<bodyText confidence="0.9998085">
ing problem instead of a generation problem where
our task was to find a correct transliteration in a list
of words instead of generating an arbitrary word. We
built the word list from a tweet set containing a lit-
tle over 112 million Arabic tweets that we scraped
from Twitter between November 20, 2011 and Jan-
uary 9, 2012. We collected the tweets by issuing
the query “lang:ar” against Twitter. We utilized the
tweet4j package for collection. The tweet set had
5.1 million unique words, and nearly half of them
appeared only once.
Our method involved doing two steps:
Producing candidate transliterations: We im-
plemented transliteration in a manner that is akin to
the baseline system in El-Kahki et al. (2011). Given
an Arabizi word waz, we produced all its possible
segmentations along with their associated mappings
into Arabic characters. Valid target sequences were
retained and sorted by the product of the constituent
mapping probabilities. The top n (we picked n = 10)
candidates, waT1..n with the highest probability were
generated. Using Bayes rule, we computed:
</bodyText>
<equation confidence="0.9602515">
argmax p(waTi|waz) = p(waz|waTi)p(waTi) (1)
wari∈1..n
</equation>
<bodyText confidence="0.999594428571429">
where p(waz|waTi) is the posterior probability of
mapping, which is computed as the product of the
mappings required to generate waz from waTi, and
p(waTi) is the prior probability of the word.
Picking the best candidate in context: We uti-
lized a large word language model to help pick the
best transliteration candidate in context. We built
a trigram language model using the IRSTLM lan-
guage modeling toolkit (Federico et al., 2008). The
advantage of this language model was that it con-
tained both MSA and dialectal text. Given the top
transliteration candidates and the language model
we trained, we wanted to find the transliteration that
would maximize the transliteration probability and
language model probability. Given a word wi with
candidates wi1−10, we wanted to find wi E wi1−10
that maximizes the product of the transliteration
probabilities (for all the candidates for all the words
in the path) and the path probability, where the prob-
ability of the path is estimated using the trigram lan-
guage model.
</bodyText>
<table confidence="0.999240307692308">
rank count precentage
1 1,068 77.1%
2 129 9.3%
3 49 3.5%
4 30 2.2%
5 19 1.4%
6 12 0.9%
7 5 0.04%
8 2 0.01%
9 1 0.01%
10 3 0.02%
Not found 68 4.9%
Total 1385
</table>
<tableCaption confidence="0.9983335">
Table 4: Results of converting from Arabizi to Arabic
with rank of correct candidates
</tableCaption>
<bodyText confidence="0.999917588235294">
For testing, we used the aforementioned set of
127 random Arabizi tweets containing 1,385 word.
We performed two evaluations as follows:
Out of context evaluation. In this evaluation we
wanted to evaluate the quality of the generated list
of candidates. Intuitively, a higher rank for the cor-
rect transliteration in the list of transliterations is
desirable. Thus, we used Mean Reciprocal Rank
(MRR) to evaluate the generated candidates. Recip-
rocal Rank (RR) is simply 1
Tank of the correct candi-
date. If the correct candidate is not in the generated
list, we assumed that the rank was very large and we
set RR = 0. MRR is the average across all test cases.
Notice that RR is 1 if the correct candidate is at po-
sition 1, 0.5 if correct is at position 2, etc. Thus the
penalty for not being at rank 1 is quite severe.
For out of context evaluation, we achieved an MRR
of 0.84. Table 4 shows the breakdown of the ranks
of the correct transliterations in the test set. As can
be seen, the correct candidate was at position one
77.1% of the time. No correct candidates were found
4.9% of the time. This meant that the best possible
accuracy that we could achieve for in context evalua-
tion was 95.1%. Further, we examined the 68 words
for which we did not generate a correct candidate.
Table 5 categorizes the 68 words (words are pre-
sented using Arabic script and Buckwalter encod-
ing). Though there has been recent efforts to codify
a standard spelling convention for some Arabic di-
alects (Habash et al., 2012), there is no commonly
adopted standard that is widely used on social me-
dia. Thus, some of the words that we generated had a
variant spelling from the ground truth. Also in other
</bodyText>
<page confidence="0.990202">
222
</page>
<bodyText confidence="0.9997675">
cases, the correct morphological form did not exist
in the word list or was infrequent. In some of these
cases, we generated morphologically related candi-
dates that have an affix added or removed. Some ex-
ample affixes including coordinating conjunctions,
prepositions, and feminine markers.
</bodyText>
<table confidence="0.99950575">
Type Count Examples
no correct candidate 23 wbenla2a7 “and we hint to”
- truth i�®Ê�JK.ð wbnqH
oleely “tell me”
- truth ú�ÎJ�Ëñ�¯ qwlyly
fsanya “in a second”
-truth iJ�7A~K ú
¯� fy vAnyp
spelling variant of word 17 online “online”
- truth uK
C;ð@ AwnlAyn
-guess �áK�C�K@AnlAyn
betshoot “you kick”
- truth ñ :..iK. bt$wT
-guess Dñ �‚��K.bt$wt
morphological variant 17 bt7bii “you (fm.) like”
- truth ú
æ.j~JK. btHby
-guess �á��J.j��K. btHbyn
tesharadeeni “you kick me out”
- truth ú
æK�XQå�„�� t$rdyny
-guess �áK�XQå�„�� t$rdyn
English word 4 cute; mention; nation; TV
no candidate generated 4 belnesbalko “for you”
- truth ÕºÊJ.‚J, AK. bAlnsblkm
filente5abat “in the election”
- truth uAJ.� BA ¯ fAlAntxbAt
mixed Arabic &amp; English 3 felguc “in the GUC”
- truth ÈA�¯GUC fAl-GUC
ellive “the live”
- truth È@live Al-live
</table>
<tableCaption confidence="0.9862815">
Table 5: Analysis of words for which we did not generate
candidates
</tableCaption>
<bodyText confidence="0.999924333333333">
In context evaluation. In this evaluation, we
computed accuracy of producing the correct translit-
erated equivalent in context. For in context evalua-
tion, if we used a baseline that used the top out-of-
context choice, we would achieve 77.1% accuracy.
Adding a trigram language model, we achieved an
accuracy of 88.7% (157 wrong out of 1,385). Of the
wrong guesses, 91 were completely unrelated words
and 46 were spelling or morphological variants.
</bodyText>
<sectionHeader confidence="0.999301" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999962">
In this paper, we presented methods of detecting
Arabizi that is mixed with English text and convert-
ing Arabizi to Arabic. For language detection we
used a sequence labeler that used word and character
level features. Language detection was trained and
tested on datasets that were constructed from tweets.
We achieved an overall accuracy of 98.5%. For con-
verting from Arabizi to Arabic, we trained a translit-
eration miner that attempted to find the most likely
Arabic word that could have generated an Arabizi
word. We used both character transliteration proba-
bilities as well as language modeling. We achieved
88.7% transliteration accuracy.
For future work, we would like to experiment
with additional training data and improved language
models that account for the morphological complex-
ities of Arabic. Also, the lack of commonly used
spelling conventions for Arabic dialects may war-
rant detecting variant spellings of individual dialec-
tal words and perhaps converting from dialectal text
to MSA.
</bodyText>
<sectionHeader confidence="0.999411" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99967078125">
B. Alex, A. Dubey, and F. Keller. 2007. Using foreign
inclusion detection to improve parsing performance. In
Proceedings of EMNLP-CoNLL
K. Beesley. 1988. Language Identifier: A computer pro-
gram for automatic natural-language identification of
on-line text. Proceedings of the 29th Annual Confer-
ence of the American Translators Association, 4754.
Kareem Darwish, Walid Magdy, and Ahmed Mourad.
2012. Language processing for arabic microblog re-
trieval. Proceedings of the 21st ACM international
conference on Information and knowledge manage-
ment. ACM, 2012.
T. Dunning. 1994. Statistical identification of language.
Technical Report, CRL MCCS-94-273, New Mexico
State University.
Y. Ehara, K. Tanaka-Ishii. 2008. Multilingual text entry
using automatic language detection. In Proceedings of
IJCNLP-2008.
Ali El-Kahky, Kareem Darwish, Ahmed Saad Aldein,
Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed
Ammar. 2001. Improved transliteration mining using
graph reinforcement. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, pp. 1384-1393. Association for Computational
Linguistics, 2011.
Marcello Federico, Nicola Bertoldi, and Mauro Cettolo.
2008. IRSTLM: an open source toolkit for handling
large scale language models. Proceedings of Inter-
speech. 2008.
Nizar Habash. 2010. Introduction to Arabic natural lan-
guage processing. Synthesis Lectures on Human Lan-
guage Technologies 3.1 (2010): 1-187.
</reference>
<page confidence="0.984751">
223
</page>
<reference confidence="0.999934290909091">
Nizar Habash, Mona T. Diab, Owen Rambow. 2012. Con-
ventional Orthography for Dialectal Arabic. LREC,
pp. 711-718. 2012.
Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma,
Aditya Bhargava, Qing Dou, Mi-Young Kim and
Grzegorz Kondrak. 2010. Transliteration Generation
and Mining with Limited Training Resources. ACL
NEWS workshop 2010.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, Evan Herbst, Moses: Open Source Toolkit
for Statistical Machine Translation, Annual Meeting of
the Association for Computational Linguistics (ACL),
demonstration session, Prague, Czech Republic, June
2007.
Jin-Shea Kuo, Haizhou Li, Ying-Kuei Yang. 2006. Learn-
ing Transliteration Lexicons from the Web. COLING-
ACL 2006, Sydney, Australia, 11291136.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data, In Proc. of ICML,
pp.282-289, 2001.
Kavi Narayana Murthy and G. Bharadwaja Kumar. 2006.
Language identification from small text samples. Jour-
nal of Quantitative Linguistics 13.01 (2006): 57-80.
Sara Noeman and Amgad Madkour. 2010. Language In-
dependent Transliteration Mining System Using Finite
State Automata Framework. ACL NEWS workshop
2010.
Hassan Sajjad, Alexander Fraser, Helmut Schmid. 2012.
A Statistical Model for Unsupervised and Semi-
supervised Transliteration Mining. ACL (1) 2012:
469-477
F. Sha and F. Pereira. 2003. Shallow parsing with condi-
tional random fields, In Proc. of HLT/NAACL 2003
Raghavendra Udupa, K. Saravanan, Anton Bakalov, Ab-
hijit Bhole. 2009. ”They Are Out There, If You Know
Where to Look”: Mining Transliterations of OOV
Query Terms for Cross-Language Information Re-
trieval. ECIR-2009, Toulouse, France, 2009.
Raghavendra Udupa, Shaishav Kumar. 2010. Hashing-
based Approaches to Spelling Correction of Personal
Names. EMNLP 2010.
A. Xafopoulos, C. Kotropoulos, G. Almpanidis, I. Pitas.
2004. Language identification in web documents using
discrete hidden Markov models. Pattern Recognition,
37 (3), 583594
Min Zhang, A Kumaran, Haizhou Li. 2011. Whitepaper
of NEWS 2012 Shared Task on Machine Translitera-
tion. IJCNLP-2011 NEWS workshop.
Min Zhang, Haizhou Li, Ming Liu, A Kumaran. 2012.
Whitepaper of NEWS 2012 Shared Task on Machine
Transliteration. ACL-2012 NEWS workshop.
</reference>
<page confidence="0.998711">
224
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.440483">
<title confidence="0.997844">Arabizi Detection and Conversion to Arabic</title>
<author confidence="0.982996">Kareem</author>
<affiliation confidence="0.996035">Qatar Computing Research</affiliation>
<address confidence="0.510199">Qatar Foundation, Doha,</address>
<email confidence="0.994749">kdarwish@qf.org.qa</email>
<abstract confidence="0.992949117647059">Arabizi is Arabic text that is written using Latin characters. Arabizi is used to present both Modern Standard Arabic (MSA) or Arabic dialects. It is commonly used in informal settings such as social networking sites and is often with mixed with English. In this paper we address the problems of: identifying Arabizi in text and converting it to Arabic characters. We used word and sequence-level features to identify Arabizi that is mixed with English. We achieved an identification accuracy of 98.5%. As for conversion, we used transliteration mining with language modeling to generate equivalent Arabic text. We achieved 88.7% conversion accuracy, with roughly a third of errors being spelling and morphological variants of the forms in ground truth.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Alex</author>
<author>A Dubey</author>
<author>F Keller</author>
</authors>
<title>Using foreign inclusion detection to improve parsing performance.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL</booktitle>
<marker>Alex, Dubey, Keller, 2007</marker>
<rawString>B. Alex, A. Dubey, and F. Keller. 2007. Using foreign inclusion detection to improve parsing performance. In Proceedings of EMNLP-CoNLL</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Beesley</author>
</authors>
<title>Language Identifier: A computer program for automatic natural-language identification of on-line text.</title>
<date>1988</date>
<booktitle>Proceedings of the 29th Annual Conference of the American Translators Association,</booktitle>
<pages>4754</pages>
<contexts>
<context position="6357" citStr="Beesley, 1988" startWordPosition="1019" endWordPosition="1020">ts our Arabizi detection and reports on the detection accuracy; Section 4 describes our Arabizi to Arabic conversion approach and reports the accuracy of conversion; and Section 5 concludes the paper. 2 Related Work There are two aspects to this work: the first is language identification, and the second is transliteration. There is much work on language identification including open source utilities, such as the Language Detection Library for Java2. Murthy and Kumar (2006) surveyed many techniques for language identification. Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al., 2004; Dunning, 1994). Murthy and Kumar (2006) used logistic regression-like classification that employed so-called “aksharas” which are sub-word character sequences as features for identifying different Indian languages. Ehara and TanakaIshii (2008) developed an online language detection system that detects code switching during typing, suggests the language to switch to the user, and interactively invokes the appropriate text entry method. They us</context>
</contexts>
<marker>Beesley, 1988</marker>
<rawString>K. Beesley. 1988. Language Identifier: A computer program for automatic natural-language identification of on-line text. Proceedings of the 29th Annual Conference of the American Translators Association, 4754.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
<author>Walid Magdy</author>
<author>Ahmed Mourad</author>
</authors>
<title>Language processing for arabic microblog retrieval.</title>
<date>2012</date>
<booktitle>Proceedings of the 21st ACM international conference on Information and knowledge management. ACM,</booktitle>
<contexts>
<context position="14657" citStr="Darwish et al., 2012" startWordPosition="2379" endWordPosition="2382">. ú j J��Jë ~•Ó ú ~æ K@ ñë ? éK�@ ÉgAƒ • meaning: what coast ? aren’t you coming tomorrow We applied the following preprocessing steps on the training and test data: • We performed the following Arabic letter normalizations (Habash, 2010): – ø (alef maqsoura) → ø� (ya) � � – @ (alef maad), @ (alef with hamza on top), and �@ (alef with hamza on the bottom) → @ (alef) – ð�(hamza on w), and Zø (hamza on ya) → Z (hamza) � – è (taa marbouta) → è (haa) • Since people often repeat letters in tweets to indicate stress or to express emotions, we removed any repetition of a letter beyond 2 repetitions (Darwish et al., 2012). For example, we transformed the word “salaaaam” to “salaam”. • Many people tend to segment Arabic words in Arabizi into separate constituent parts. For example, you may find “w el kitab” (meaning “and the book”) as 3 separate tokens, while in Arabic they are concatenated into a single token, namely “H. A:ºË@ð”. Thus, we concatenated short tokens that represent coordinating conjunctions and prepositions to the tokens that follow them. These tokens are: w, l, el, ll, la, we, f, fel, fil, fl, lel, al, wel, and b. 220 Feature Explanation Ex. Word This would help label words that appear in the tr</context>
</contexts>
<marker>Darwish, Magdy, Mourad, 2012</marker>
<rawString>Kareem Darwish, Walid Magdy, and Ahmed Mourad. 2012. Language processing for arabic microblog retrieval. Proceedings of the 21st ACM international conference on Information and knowledge management. ACM, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Statistical identification of language.</title>
<date>1994</date>
<tech>Technical Report, CRL MCCS-94-273,</tech>
<institution>New Mexico State University.</institution>
<contexts>
<context position="6373" citStr="Dunning, 1994" startWordPosition="1021" endWordPosition="1022">detection and reports on the detection accuracy; Section 4 describes our Arabizi to Arabic conversion approach and reports the accuracy of conversion; and Section 5 concludes the paper. 2 Related Work There are two aspects to this work: the first is language identification, and the second is transliteration. There is much work on language identification including open source utilities, such as the Language Detection Library for Java2. Murthy and Kumar (2006) surveyed many techniques for language identification. Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al., 2004; Dunning, 1994). Murthy and Kumar (2006) used logistic regression-like classification that employed so-called “aksharas” which are sub-word character sequences as features for identifying different Indian languages. Ehara and TanakaIshii (2008) developed an online language detection system that detects code switching during typing, suggests the language to switch to the user, and interactively invokes the appropriate text entry method. They used HMM based lan</context>
</contexts>
<marker>Dunning, 1994</marker>
<rawString>T. Dunning. 1994. Statistical identification of language. Technical Report, CRL MCCS-94-273, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ehara</author>
<author>K Tanaka-Ishii</author>
</authors>
<title>Multilingual text entry using automatic language detection.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCNLP-2008.</booktitle>
<marker>Ehara, Tanaka-Ishii, 2008</marker>
<rawString>Y. Ehara, K. Tanaka-Ishii. 2008. Multilingual text entry using automatic language detection. In Proceedings of IJCNLP-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali El-Kahky</author>
<author>Kareem Darwish</author>
</authors>
<title>Ahmed Saad Aldein, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1384--1393</pages>
<marker>El-Kahky, Darwish, 2001</marker>
<rawString>Ali El-Kahky, Kareem Darwish, Ahmed Saad Aldein, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar. 2001. Improved transliteration mining using graph reinforcement. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1384-1393. Association for Computational Linguistics, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
</authors>
<title>IRSTLM: an open source toolkit for handling large scale language models.</title>
<date>2008</date>
<booktitle>Proceedings of Interspeech.</booktitle>
<contexts>
<context position="20779" citStr="Federico et al., 2008" startWordPosition="3420" endWordPosition="3423">bilities. The top n (we picked n = 10) candidates, waT1..n with the highest probability were generated. Using Bayes rule, we computed: argmax p(waTi|waz) = p(waz|waTi)p(waTi) (1) wari∈1..n where p(waz|waTi) is the posterior probability of mapping, which is computed as the product of the mappings required to generate waz from waTi, and p(waTi) is the prior probability of the word. Picking the best candidate in context: We utilized a large word language model to help pick the best transliteration candidate in context. We built a trigram language model using the IRSTLM language modeling toolkit (Federico et al., 2008). The advantage of this language model was that it contained both MSA and dialectal text. Given the top transliteration candidates and the language model we trained, we wanted to find the transliteration that would maximize the transliteration probability and language model probability. Given a word wi with candidates wi1−10, we wanted to find wi E wi1−10 that maximizes the product of the transliteration probabilities (for all the candidates for all the words in the path) and the path probability, where the probability of the path is estimated using the trigram language model. rank count prece</context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. Proceedings of Interspeech. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic natural language processing.</title>
<date>2010</date>
<journal>Synthesis Lectures on Human Language Technologies</journal>
<volume>3</volume>
<pages>1--187</pages>
<contexts>
<context position="14274" citStr="Habash, 2010" startWordPosition="2300" endWordPosition="2301">native Arabic speaker. Some example pairs are: • 3endek → 1/4Y�J« (meaning “in your care”) • bytl3 → ©Ê¢J�K. (meaning “he ascends”) For testing, we constructed a set of 127 random Arabizi tweets containing 1,385 word. Again, we had a native Arabic speaker transliterate all tweets into Arabic script. An example sentences is: • sa7el eih ? howa ntii mesh hatigi bokra → �èQºK. ú j J��Jë ~•Ó ú ~æ K@ ñë ? éK�@ ÉgAƒ • meaning: what coast ? aren’t you coming tomorrow We applied the following preprocessing steps on the training and test data: • We performed the following Arabic letter normalizations (Habash, 2010): – ø (alef maqsoura) → ø� (ya) � � – @ (alef maad), @ (alef with hamza on top), and �@ (alef with hamza on the bottom) → @ (alef) – ð�(hamza on w), and Zø (hamza on ya) → Z (hamza) � – è (taa marbouta) → è (haa) • Since people often repeat letters in tweets to indicate stress or to express emotions, we removed any repetition of a letter beyond 2 repetitions (Darwish et al., 2012). For example, we transformed the word “salaaaam” to “salaam”. • Many people tend to segment Arabic words in Arabizi into separate constituent parts. For example, you may find “w el kitab” (meaning “and the book”) as </context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic natural language processing. Synthesis Lectures on Human Language Technologies 3.1 (2010): 1-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Mona T Diab</author>
<author>Owen Rambow</author>
</authors>
<date>2012</date>
<booktitle>Conventional Orthography for Dialectal Arabic. LREC,</booktitle>
<pages>711--718</pages>
<contexts>
<context position="2308" citStr="Habash et al., 2012" startWordPosition="372" endWordPosition="375">ile and Android did not support Arabic except through third party support until versions 6.5x and 3.x respectively. Despite the increasing support of Arabic in many platforms, Arabizi continues to be popular due to the familiarity of users with it and the higher proficiency of users to use an English keyboard compared to an Arabic keyboard. Arabizi is used to present both MSA as well as different Arabic dialects, which lack commonly used spelling conventions and differ morphologically and phonetically from MSA. There has been recent efforts to standardize the spelling of some Arabic dialects (Habash et al., 2012), but such standards are not widely adopted on social media. Additionally, due to the fact that many of the Arabic speakers are bilingual (with their second language being either English or French), another commonly observed phenomenon is the presence of English (or French) and Arabizi mixed together within sentences, where users code switch between both languages. In this paper we focus on performing two tasks, namely: detecting Arabizi even when juxtaposed with English; and converting Arabizi to Arabic script regardless of it being MSA or dialectal. Detecting and converting Arabizi to Arabic</context>
<context position="23111" citStr="Habash et al., 2012" startWordPosition="3837" endWordPosition="3840">hows the breakdown of the ranks of the correct transliterations in the test set. As can be seen, the correct candidate was at position one 77.1% of the time. No correct candidates were found 4.9% of the time. This meant that the best possible accuracy that we could achieve for in context evaluation was 95.1%. Further, we examined the 68 words for which we did not generate a correct candidate. Table 5 categorizes the 68 words (words are presented using Arabic script and Buckwalter encoding). Though there has been recent efforts to codify a standard spelling convention for some Arabic dialects (Habash et al., 2012), there is no commonly adopted standard that is widely used on social media. Thus, some of the words that we generated had a variant spelling from the ground truth. Also in other 222 cases, the correct morphological form did not exist in the word list or was infrequent. In some of these cases, we generated morphologically related candidates that have an affix added or removed. Some example affixes including coordinating conjunctions, prepositions, and feminine markers. Type Count Examples no correct candidate 23 wbenla2a7 “and we hint to” - truth i�®Ê�JK.ð wbnqH oleely “tell me” - truth ú�ÎJ�Ë</context>
</contexts>
<marker>Habash, Diab, Rambow, 2012</marker>
<rawString>Nizar Habash, Mona T. Diab, Owen Rambow. 2012. Conventional Orthography for Dialectal Arabic. LREC, pp. 711-718. 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Kenneth Dwyer</author>
<author>Shane Bergsma</author>
</authors>
<title>Aditya Bhargava, Qing Dou, Mi-Young Kim and Grzegorz Kondrak.</title>
<date>2010</date>
<booktitle>ACL NEWS workshop</booktitle>
<contexts>
<context position="9256" citStr="Jiampojamarn et al., 2010" startWordPosition="1469" endWordPosition="1473">ng character (or character-sequence) level mappings between them. The learning can be done using the EM algorithm (Kuo et al., 2006) or HMM alignment (Udupa et al., 2009). Once these mappings are learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Other approaches include the use of locality sensitive hashing (Udupa and Kumar, 2010) and classification (Jiampojamarn et al., 2010). Another dramatically different approaches involves the unsupervised learning of transliteration mappings from a large parallel corpus instead of transliteration pairs (Sajjad et al., 2012). In our work, we used the baseline system of El-Kahky et al. (2011). There are three commercial Input Method Editors (IMEs) that convert from Arabizi to Arabic, namely: Yamli3, Microsoft Maren4, and Google t3reeb5. Since they are IMEs, they only work in an interactive mode and don’t allow for batch processing. Thus they are difficult to compare against. Also, from interactively using Arabic IMEs, it seems </context>
</contexts>
<marker>Jiampojamarn, Dwyer, Bergsma, 2010</marker>
<rawString>Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma, Aditya Bhargava, Qing Dou, Mi-Young Kim and Grzegorz Kondrak. 2010. Transliteration Generation and Mining with Limited Training Resources. ACL NEWS workshop 2010.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<date>2007</date>
<booktitle>Open Source Toolkit for Statistical Machine Translation, Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst, Moses:</location>
<contexts>
<context position="18389" citStr="Koehn et al., 2007" startWordPosition="3030" endWordPosition="3033">: misspelled English words e o 3 0.4% 4 those going 2 tahrir 4 &amp; 2: numbers used instead of words o o 758 98.7% o e 3 0.4% URL’s and name mentions Could be fixed with either a simple rule or more training data o a 7 0.9% Table 3: Used labels for words • We directly transliterated the words “isA” and “jAk” to “���l ��.: -�l�” (meaning “God � welling”) and to “l_���- 0l Al-_��” (meaning “may God reward you”) respectively. For training, we aligned the word-pairs at character level. The pairs were aligned using GIZA++ and the phrase extractor and scorer from the Moses machine translation package (Koehn et al., 2007) . To apply a machine translation analogy, we treated words as sentences and the letters from which were constructed as tokens. The alignment produced letter sequence mappings. The alignment produced mappings between Latin letters sequences and Arabic letter sequences with associated mapping probabilities. For example, here is a sample mapping: • 2r →_�&apos; (p = 0.459) To generate Arabic words from Arabizi words, we made the fundamental simplifying assumption that any generated Arabic word should exist in a large word list. Though the assumption fundamentally limits generation to previously seen </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst, Moses: Open Source Toolkit for Statistical Machine Translation, Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Shea Kuo</author>
<author>Haizhou Li</author>
<author>Ying-Kuei Yang</author>
</authors>
<date>2006</date>
<booktitle>Learning Transliteration Lexicons from the Web. COLINGACL 2006,</booktitle>
<pages>11291136</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="8762" citStr="Kuo et al., 2006" startWordPosition="1390" endWordPosition="1393">tem is used to find the most similar sequence in a lexicon that is written in the target alphabet or writing system. Both problems are fairly well studied with multiple evaluation campaigns, particularly at the different editions of the Named Entities Workshop (NEWS) (Zhang et al., 2011; Zhang et al., 2012). In our work we relied on TM from a large corpus of Arabic microblogs. TM typically involves using transliteration pairs in two different writing systems or alphabets to learning character (or character-sequence) level mappings between them. The learning can be done using the EM algorithm (Kuo et al., 2006) or HMM alignment (Udupa et al., 2009). Once these mappings are learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Other approaches include the use of locality sensitive hashing (Udupa and Kumar, 2010) and classification (Jiampojamarn et al., 2010). Another dramatically different approaches involves the unsupervised learning of transliteration mappings</context>
</contexts>
<marker>Kuo, Li, Yang, 2006</marker>
<rawString>Jin-Shea Kuo, Haizhou Li, Ying-Kuei Yang. 2006. Learning Transliteration Lexicons from the Web. COLINGACL 2006, Sydney, Australia, 11291136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data,</title>
<date>2001</date>
<booktitle>In Proc. of ICML,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="7434" citStr="Lafferty et al., 2001" startWordPosition="1169" endWordPosition="1172">s code switching during typing, suggests the language to switch to the user, and interactively invokes the appropriate text entry method. They used HMM based language identification in conjunction with an n-gram character language model. They reported up to 97% accuracy when detecting between two languages on a 2http://code.google.com/p/ language-detection/ 218 synthetic test set. In our work, we performed offline word-level language identification using CRF sequence labeling, which conceptually combines logistic regression-like discriminative classification with an HMM-like generative model (Lafferty et al., 2001). We opted to use a CRF sequence labeling because it allowed us to use both state and sequence features, which in our case corresponded to wordand sequence-level features respectively. One of the downsides of using a CRF sequence labeler is that most implementations, including CRF++ which was used in this work, only use nominal features. This required us to quantize all real-valued features. Converting between from Arabizi to Arabic is akin to transliteration or Transliteration Mining (TM). In transliteration, a sequence in a source alphabet or writing system is used to generate a phonetically</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data, In Proc. of ICML, pp.282-289, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kavi Narayana Murthy</author>
<author>G Bharadwaja Kumar</author>
</authors>
<title>Language identification from small text samples.</title>
<date>2006</date>
<journal>Journal of Quantitative Linguistics</journal>
<volume>13</volume>
<pages>57--80</pages>
<contexts>
<context position="6221" citStr="Murthy and Kumar (2006)" startWordPosition="997" endWordPosition="1001">icly release all our training and test data. The remainder of the paper is organized as follows: Section 2 provides related work; Section 3 presents our Arabizi detection and reports on the detection accuracy; Section 4 describes our Arabizi to Arabic conversion approach and reports the accuracy of conversion; and Section 5 concludes the paper. 2 Related Work There are two aspects to this work: the first is language identification, and the second is transliteration. There is much work on language identification including open source utilities, such as the Language Detection Library for Java2. Murthy and Kumar (2006) surveyed many techniques for language identification. Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al., 2004; Dunning, 1994). Murthy and Kumar (2006) used logistic regression-like classification that employed so-called “aksharas” which are sub-word character sequences as features for identifying different Indian languages. Ehara and TanakaIshii (2008) developed an online language detection system that detects code sw</context>
</contexts>
<marker>Murthy, Kumar, 2006</marker>
<rawString>Kavi Narayana Murthy and G. Bharadwaja Kumar. 2006. Language identification from small text samples. Journal of Quantitative Linguistics 13.01 (2006): 57-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Noeman</author>
<author>Amgad Madkour</author>
</authors>
<title>Language Independent Transliteration Mining System Using Finite State Automata Framework.</title>
<date>2010</date>
<booktitle>ACL NEWS workshop</booktitle>
<contexts>
<context position="9121" citStr="Noeman and Madkour, 2010" startWordPosition="1449" endWordPosition="1452">corpus of Arabic microblogs. TM typically involves using transliteration pairs in two different writing systems or alphabets to learning character (or character-sequence) level mappings between them. The learning can be done using the EM algorithm (Kuo et al., 2006) or HMM alignment (Udupa et al., 2009). Once these mappings are learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Other approaches include the use of locality sensitive hashing (Udupa and Kumar, 2010) and classification (Jiampojamarn et al., 2010). Another dramatically different approaches involves the unsupervised learning of transliteration mappings from a large parallel corpus instead of transliteration pairs (Sajjad et al., 2012). In our work, we used the baseline system of El-Kahky et al. (2011). There are three commercial Input Method Editors (IMEs) that convert from Arabizi to Arabic, namely: Yamli3, Microsoft Maren4, and Google t3reeb5. Since they are IMEs, they only work in an interactive mode </context>
</contexts>
<marker>Noeman, Madkour, 2010</marker>
<rawString>Sara Noeman and Amgad Madkour. 2010. Language Independent Transliteration Mining System Using Finite State Automata Framework. ACL NEWS workshop 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sajjad</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
</authors>
<title>A Statistical Model for Unsupervised and Semisupervised Transliteration Mining.</title>
<date>2012</date>
<journal>ACL</journal>
<volume>1</volume>
<pages>469--477</pages>
<contexts>
<context position="9446" citStr="Sajjad et al., 2012" startWordPosition="1497" endWordPosition="1500">learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Other approaches include the use of locality sensitive hashing (Udupa and Kumar, 2010) and classification (Jiampojamarn et al., 2010). Another dramatically different approaches involves the unsupervised learning of transliteration mappings from a large parallel corpus instead of transliteration pairs (Sajjad et al., 2012). In our work, we used the baseline system of El-Kahky et al. (2011). There are three commercial Input Method Editors (IMEs) that convert from Arabizi to Arabic, namely: Yamli3, Microsoft Maren4, and Google t3reeb5. Since they are IMEs, they only work in an interactive mode and don’t allow for batch processing. Thus they are difficult to compare against. Also, from interactively using Arabic IMEs, it seems that they only use unigram language modeling. 3 Identifying Arabizi As mentioned earlier, classifying words as English or Arabizi requires the use of word-level and sequence-level features. </context>
</contexts>
<marker>Sajjad, Fraser, Schmid, 2012</marker>
<rawString>Hassan Sajjad, Alexander Fraser, Helmut Schmid. 2012. A Statistical Model for Unsupervised and Semisupervised Transliteration Mining. ACL (1) 2012: 469-477</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sha</author>
<author>F Pereira</author>
</authors>
<title>Shallow parsing with conditional random fields,</title>
<date>2003</date>
<booktitle>In Proc. of HLT/NAACL</booktitle>
<contexts>
<context position="10191" citStr="Sha and Pereira, 2003" startWordPosition="1619" endWordPosition="1622">) that convert from Arabizi to Arabic, namely: Yamli3, Microsoft Maren4, and Google t3reeb5. Since they are IMEs, they only work in an interactive mode and don’t allow for batch processing. Thus they are difficult to compare against. Also, from interactively using Arabic IMEs, it seems that they only use unigram language modeling. 3 Identifying Arabizi As mentioned earlier, classifying words as English or Arabizi requires the use of word-level and sequence-level features. We opted to use CRF sequence labeling to identify Arabizi words. We used the CRF++ implementation with default parameters (Sha and Pereira, 2003). We constructed training and test sets for word-level language classification from tweets that contain English, Arabizi, or a mixture of English and Arabizi. We collected the tweets in the following manner: 1. We issued commonly used Arabizi words as queries against Twitter multiple times. These words were “e7na” (we), “3shan” (because), and “la2a” (no). We issued these queries every 30 seconds for roughly 1 hour. We put large time gaps between queries to ensure that the results were refreshed. 2. We extracted the user IDs of all the authors of the tweets that we found, and used the IDs as qu</context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>F. Sha and F. Pereira. 2003. Shallow parsing with conditional random fields, In Proc. of HLT/NAACL 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghavendra Udupa</author>
<author>K Saravanan</author>
</authors>
<title>Anton Bakalov, Abhijit Bhole.</title>
<date>2009</date>
<booktitle>ECIR-2009,</booktitle>
<location>Toulouse, France,</location>
<marker>Udupa, Saravanan, 2009</marker>
<rawString>Raghavendra Udupa, K. Saravanan, Anton Bakalov, Abhijit Bhole. 2009. ”They Are Out There, If You Know Where to Look”: Mining Transliterations of OOV Query Terms for Cross-Language Information Retrieval. ECIR-2009, Toulouse, France, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghavendra Udupa</author>
<author>Shaishav Kumar</author>
</authors>
<title>Hashingbased Approaches to Spelling Correction of Personal Names.</title>
<date>2010</date>
<publisher>EMNLP</publisher>
<contexts>
<context position="9209" citStr="Udupa and Kumar, 2010" startWordPosition="1463" endWordPosition="1466">rent writing systems or alphabets to learning character (or character-sequence) level mappings between them. The learning can be done using the EM algorithm (Kuo et al., 2006) or HMM alignment (Udupa et al., 2009). Once these mappings are learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Other approaches include the use of locality sensitive hashing (Udupa and Kumar, 2010) and classification (Jiampojamarn et al., 2010). Another dramatically different approaches involves the unsupervised learning of transliteration mappings from a large parallel corpus instead of transliteration pairs (Sajjad et al., 2012). In our work, we used the baseline system of El-Kahky et al. (2011). There are three commercial Input Method Editors (IMEs) that convert from Arabizi to Arabic, namely: Yamli3, Microsoft Maren4, and Google t3reeb5. Since they are IMEs, they only work in an interactive mode and don’t allow for batch processing. Thus they are difficult to compare against. Also, </context>
</contexts>
<marker>Udupa, Kumar, 2010</marker>
<rawString>Raghavendra Udupa, Shaishav Kumar. 2010. Hashingbased Approaches to Spelling Correction of Personal Names. EMNLP 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Xafopoulos</author>
<author>C Kotropoulos</author>
<author>G Almpanidis</author>
<author>I Pitas</author>
</authors>
<title>Language identification in web documents using discrete hidden Markov models.</title>
<date>2004</date>
<journal>Pattern Recognition,</journal>
<volume>37</volume>
<issue>3</issue>
<pages>583594</pages>
<contexts>
<context position="6509" citStr="Xafopoulos et al., 2004" startWordPosition="1040" endWordPosition="1043">accuracy of conversion; and Section 5 concludes the paper. 2 Related Work There are two aspects to this work: the first is language identification, and the second is transliteration. There is much work on language identification including open source utilities, such as the Language Detection Library for Java2. Murthy and Kumar (2006) surveyed many techniques for language identification. Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al., 2004; Dunning, 1994). Murthy and Kumar (2006) used logistic regression-like classification that employed so-called “aksharas” which are sub-word character sequences as features for identifying different Indian languages. Ehara and TanakaIshii (2008) developed an online language detection system that detects code switching during typing, suggests the language to switch to the user, and interactively invokes the appropriate text entry method. They used HMM based language identification in conjunction with an n-gram character language model. They reported up to 97% accuracy when detecting between two</context>
</contexts>
<marker>Xafopoulos, Kotropoulos, Almpanidis, Pitas, 2004</marker>
<rawString>A. Xafopoulos, C. Kotropoulos, G. Almpanidis, I. Pitas. 2004. Language identification in web documents using discrete hidden Markov models. Pattern Recognition, 37 (3), 583594</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>A Kumaran</author>
<author>Haizhou Li</author>
</authors>
<date>2011</date>
<booktitle>Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. IJCNLP-2011 NEWS workshop.</booktitle>
<contexts>
<context position="8432" citStr="Zhang et al., 2011" startWordPosition="1335" endWordPosition="1338">lued features. Converting between from Arabizi to Arabic is akin to transliteration or Transliteration Mining (TM). In transliteration, a sequence in a source alphabet or writing system is used to generate a phonetically similar sequence in a target alphabet or writing system. In TM, a sequence in a source alphabet or writing system is used to find the most similar sequence in a lexicon that is written in the target alphabet or writing system. Both problems are fairly well studied with multiple evaluation campaigns, particularly at the different editions of the Named Entities Workshop (NEWS) (Zhang et al., 2011; Zhang et al., 2012). In our work we relied on TM from a large corpus of Arabic microblogs. TM typically involves using transliteration pairs in two different writing systems or alphabets to learning character (or character-sequence) level mappings between them. The learning can be done using the EM algorithm (Kuo et al., 2006) or HMM alignment (Udupa et al., 2009). Once these mappings are learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the</context>
</contexts>
<marker>Zhang, Kumaran, Li, 2011</marker>
<rawString>Min Zhang, A Kumaran, Haizhou Li. 2011. Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. IJCNLP-2011 NEWS workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Haizhou Li</author>
<author>Ming Liu</author>
<author>A Kumaran</author>
</authors>
<date>2012</date>
<booktitle>Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. ACL-2012 NEWS workshop.</booktitle>
<contexts>
<context position="8453" citStr="Zhang et al., 2012" startWordPosition="1339" endWordPosition="1342">rting between from Arabizi to Arabic is akin to transliteration or Transliteration Mining (TM). In transliteration, a sequence in a source alphabet or writing system is used to generate a phonetically similar sequence in a target alphabet or writing system. In TM, a sequence in a source alphabet or writing system is used to find the most similar sequence in a lexicon that is written in the target alphabet or writing system. Both problems are fairly well studied with multiple evaluation campaigns, particularly at the different editions of the Named Entities Workshop (NEWS) (Zhang et al., 2011; Zhang et al., 2012). In our work we relied on TM from a large corpus of Arabic microblogs. TM typically involves using transliteration pairs in two different writing systems or alphabets to learning character (or character-sequence) level mappings between them. The learning can be done using the EM algorithm (Kuo et al., 2006) or HMM alignment (Udupa et al., 2009). Once these mappings are learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the output to words in t</context>
</contexts>
<marker>Zhang, Li, Liu, Kumaran, 2012</marker>
<rawString>Min Zhang, Haizhou Li, Ming Liu, A Kumaran. 2012. Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. ACL-2012 NEWS workshop.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>