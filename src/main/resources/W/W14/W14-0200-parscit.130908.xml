<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000030">
<note confidence="0.535399">
EACL 2014
</note>
<title confidence="0.7965155">
14th Conference of the European Chapter of the
Association for Computational Linguistics
Proceedings of the Workshop on Dialogue in Motion (DM)
April 26, 2014
Gothenburg, Sweden
c�2014 The Association for Computational Linguistics
</title>
<page confidence="0.645502">
ii
</page>
<affiliation confidence="0.5411135">
Order copies of this and other ACL proceedings from:
Association for Computational Linguistics (ACL)
</affiliation>
<address confidence="0.7259672">
209 N. Eighth Street
Stroudsburg, PA 18360
USA
Tel: +1-570-476-8006
Fax: +1-570-476-0860
</address>
<email confidence="0.918349">
acl@aclweb.org
</email>
<sectionHeader confidence="0.676752" genericHeader="abstract">
ISBN 978-1-937284-81-7
</sectionHeader>
<page confidence="0.434491">
iii
</page>
<sectionHeader confidence="0.970166" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999972258064516">
Spoken dialogue systems used in call centers and car dashboards reflect years of technological
development. But the smart devices that now accompany people throughout their daily activities and
the extensive integration of sensors and actuators into people’s environments demand new concepts in
dialogue modeling and management in order to provide intuitive, proactive, personalized, context-aware,
multi-modal, multi-domain dialogue systems.
The past few years have seen the development of many intelligent speech-enabled virtual assistants for
mobile users, such as Siri, S Voice, Google Now, SpeakToIt, Vlingo and Iris. These applications use
GIS connectivity for navigation and to contextualize tasks such as search. Other multimodal applications
(e.g. Wikitude, WikiHood, FieldTrip) can pro-actively present encyclopedic information about the user’s
surroundings, such as landmarks and points of interest, as the user walks around. Augmented reality and
wearable technology such as Google Glass are presenting new opportunities for dialogue systems ‘on
the go’.
In this proliferation of location-aware systems in the industry, together with research efforts in spatial
and mobile contexts, we see a convergence of efforts (e.g. the Word2Actions workshop at NAACL 2012,
the Computational Models of Spatial Language Interpretation and Generation workshop series and the
Vision and Language workshop at NAACL 2013) towards what we call Dialogue In Motion: any form
of interaction between a computer/robot and a human in motion - for example a pedestrian or a driver, in
the real world or in a simulated environment. Natural language interactions are promoted as a more direct
interaction medium, but they raise additional challenges in the context of dynamic spatial environments.
This workshop focuses on these challenging issues in language processing for dialogues in motion.
We received 20 submissions; all papers received three reviews from our program committee. We accepted
seven papers for oral presentation and six for poster and/or demo presentation. Several of the papers are
on in-car dialogue systems, which have a long track record of non-trivial implementations combining
voice, GUI, haptic, and gestures with additional constraints on user’s cognitive load and environment
context. Others are on pedestrian navigation and virtual guides, human-robot interaction, and rapid
prototyping and statistical dialogue management for dialogue in motion.
We wish to thank all those who submitted papers. We also gratefully acknowledge the work of the
members of our program committee. Special thanks go to Tiphaine Dalmas (University of Edinburgh)
for acting as main contact for the workshop, and to Bonnie Webber (University of Edinburgh) for helpful
comments along the way.
We hope you enjoy the workshop!
</bodyText>
<page confidence="0.416546">
iv
</page>
<reference confidence="0.817872666666667">
Dialog in Motion Organising Committee
Tiphaine Dalmas, ILCC, University of Edinburgh (United Kingdom)
Jana Götze, KTH, Royal Institute of Technology (Sweden)
Joakim Gustafson, KTH, Royal Institute of Technology (Sweden)
Srinivasan Janarthanam, Heriot-Watt University (United Kingdom)
Jan Kleindienst, IBM Czech Republic, Prague (Czech Republic)
Christian Mueller, DFKI, Saarbruecken (Germany)
Amanda Stent, Yahoo! Labs, New York (USA)
Andreas Vlachos, University of Cambridge (United Kingdom)
</reference>
<author confidence="0.5663">
Dialog in Motion Program Committee
</author>
<affiliation confidence="0.74839475">
Yoav Artzi, University of Washington (USA)
Luciana Benotti, University of Cordoba (Spain)
Johan Boye, KTH Royal Institute of Technology (Sweden)
Stephen Clark, University of Cambridge (United Kingdom)
</affiliation>
<table confidence="0.965434772727273">
Jan Curin, IBM Czech Republic, Prague (Czech Republic)
Nina Dethlefs, Heriot-Watt University (United Kingdom)
Jens Edlund, KTH, Stockholm (Sweden)
Dan Goldwasser, University of Maryland (USA)
Joakim Gustafson, KTH, Stockholm (Sweden)
Peter Heeman, OGI, Oregon Health and Science University (USA)
Filip Jurcicek, Charles University, Prague (Czech Republic)
John Kelleher, Dublin Institute of Technology (Ireland)
Kazunori Komatani, Nagoya University (Japan)
Tom Kwiatkowski, University of Washington (USA)
Staffan Larsson, Gothenburg University (Sweden)
Oliver Lemon, Heriot-Watt University (United Kingdom)
Nils Lenke, Nuance Communications, Aachen (Germany)
Jan Macek, IBM Czech Republic, Prague (Czech Republic)
Tomas Macek, IBM Czech Republic, Prague (Czech Republic)
Ray Mooney, University of Texas, Austin (USA)
Deepak Ramachandran, Nuance Communications (USA)
Verena Rieser, Heriot-Watt University (United Kingdom)
Hui Shi, Singapore-MIT Alliance for Research and Technology (Singapore)
Thora Tenbrink, Bangor University (United Kingdom)
Jason Williams, Microsoft Research (USA)
v
</table>
<tableCaption confidence="0.979218">
Table of Contents
</tableCaption>
<figure confidence="0.955544895833333">
In-Car Multi-Domain Spoken Dialogs: A Wizard of Oz Study
Sven Reichel, Ute Ehrlich, André Berton and Michael Weber 1
IBM’s Belief Tracker: Results On Dialog State Tracking Challenge Datasets
Rudolf Kadlec, Jindrich Libovicky, Jan Macek and Jan Kleindienst 10
Click or Type: An Analysis of Wizard’s Interaction for Future Wizard Interface Design
Srinivasan Janarthanam, Robin Hill, Anna Dickinson and Morgan Fredriksson 19
Recipes for building voice search UIs for automotive
Martin Labsky, Ladislav Kunc, Tomas Macek, Jan Kleindienst and Jan Vystrcil 28
A Natural Language Instructor for pedestrian navigation based in generation by selection
Santiago Avalos and Luciana Benotti 33
Mining human interactions to construct a virtual guide for a virtual fair
Andrés Luna and Luciana Benotti 38
Collaborative Exploration in Human-Robot Teams: What’s in their Corpora of Dialog, Video, &amp; LIDAR
Messages?
Clare Voss, Taylor Cassidy and Douglas Summer-Stay 43
Multi-threaded Interaction Management for Dynamic Spatial Applications
Srinivasan Janarthanam and Oliver Lemon 48
Mostly Passive Information Delivery – a Prototype
Jan Vystrcil, Tomas Macek, David Luksch, Martin Labsky, Kunc Ladislav, Jan Kleindienst and
Tereza Kasparova 53
Navigation Dialog of Blind People: Recovery from Getting Lost
Jan Vystrcil, Ivo Maly, Jan Balata and Zdenek Mikovec 58
Conversational Strategies for Robustly Managing Dialog in Public Spaces
Aasish Pappu, Ming Sun, Seshadri Sridharan and Alexander Rudnicky 63
Situationally Aware In-Car Information Presentation Using Incremental Speech Generation: Safer, and
More Effective
Spyros Kousidis, Casey Kennington, Timo Baumann, Hendrik Buschmeier, Stefan Kopp and David
Schlangen 68
Human pause and resume behaviours for unobtrusive humanlike in-car spoken dialogue systems
Jens Edlund, Fredrik Edelstam and Joakim Gustafson 73
vii
Conference Program
(09:00-10:30) Session I
09:00-10:00 Invited speaker (TBA)
10:00–10:30 In-Car Multi-Domain Spoken Dialogs: A Wizard of Oz Study
Sven Reichel, Ute Ehrlich, André Berton and Michael Weber
(10:30-11:00) Coffee break
(11:00-12:00) Session II
11:00–11:30 IBM’s Belief Tracker: Results On Dialog State Tracking Challenge Datasets
Rudolf Kadlec, Jindrich Libovicky, Jan Macek and Jan Kleindienst
11:30–12:00 Click or Type: An Analysis of Wizard’s Interaction for Future Wizard Interface De-
sign
Srinivasan Janarthanam, Robin Hill, Anna Dickinson and Morgan Fredriksson
(13:30-14:30) Posters and demonstrations
Recipes for building voice search UIs for automotive
Martin Labsky, Ladislav Kunc, Tomas Macek, Jan Kleindienst and Jan Vystrcil
A Natural Language Instructor for pedestrian navigation based in generation by
selection
</figure>
<reference confidence="0.975909555555556">
Santiago Avalos and Luciana Benotti
Mining human interactions to construct a virtual guide for a virtual fair
Andrés Luna and Luciana Benotti
Collaborative Exploration in Human-Robot Teams: What’s in their Corpora of Di-
alog, Video, &amp; LIDAR Messages?
Clare Voss, Taylor Cassidy and Douglas Summer-Stay
Multi-threaded Interaction Management for Dynamic Spatial Applications
Srinivasan Janarthanam and Oliver Lemon
Mostly Passive Information Delivery – a Prototype
Jan Vystrcil, Tomas Macek, David Luksch, Martin Labsky, Kunc Ladislav, Jan
Kleindienst and Tereza Kasparova
ix
No Day Set (continued)
Session 14:30-15:30: Session III
14:30–15:00 Navigation Dialog of Blind People: Recovery from Getting Lost
Jan Vystrcil, Ivo Maly, Jan Balata and Zdenek Mikovec
15:00–15:30 Conversational Strategies for Robustly Managing Dialog in Public Spaces
Aasish Pappu, Ming Sun, Seshadri Sridharan and Alexander Rudnicky
(15:30-16:00) Coffee break
(16:00-17:00) Session IV
16:00–16:30 Situationally Aware In-Car Information Presentation Using Incremental Speech Genera-
tion: Safer, and More Effective
Spyros Kousidis, Casey Kennington, Timo Baumann, Hendrik Buschmeier, Stefan Kopp
and David Schlangen
16:30–17:00 Human pause and resume behaviours for unobtrusive humanlike in-car spoken dialogue
systems
Jens Edlund, Fredrik Edelstam and Joakim Gustafson
</reference>
<page confidence="0.815665">
x
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.020268">
<note confidence="0.98124925">EACL 2014 14th Conference of the European Chapter of Association for Computational Linguistics Proceedings of the Workshop on Dialogue in Motion (DM)</note>
<date confidence="0.820427">April 26, 2014</date>
<author confidence="0.325749">Sweden Gothenburg</author>
<affiliation confidence="0.422226">The Association for Computational Linguistics</affiliation>
<address confidence="0.228567">ii</address>
<author confidence="0.358439">Order copies of this</author>
<author confidence="0.358439">other ACL proceedings from</author>
<affiliation confidence="0.835458">Association for Computational Linguistics (ACL)</affiliation>
<address confidence="0.998979666666667">209 N. Eighth Street Stroudsburg, PA 18360 USA</address>
<phone confidence="0.9993625">Tel: +1-570-476-8006 Fax: +1-570-476-0860</phone>
<email confidence="0.946257">acl@aclweb.org</email>
<phone confidence="0.455842">ISBN 978-1-937284-81-7</phone>
<intro confidence="0.649066">iii</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Dialog in Motion Organising Committee Tiphaine Dalmas, ILCC,</title>
<institution>University of Edinburgh (United Kingdom) Jana Götze, KTH, Royal Institute of Technology (Sweden)</institution>
<marker></marker>
<rawString>Dialog in Motion Organising Committee Tiphaine Dalmas, ILCC, University of Edinburgh (United Kingdom) Jana Götze, KTH, Royal Institute of Technology (Sweden)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Gustafson</author>
<author>KTH</author>
</authors>
<date></date>
<institution>Royal Institute of Technology (Sweden) Srinivasan Janarthanam, Heriot-Watt University (United Kingdom) Jan Kleindienst, IBM Czech</institution>
<location>Republic, Prague (Czech Republic) Christian Mueller, DFKI, Saarbruecken</location>
<marker>Gustafson, KTH, </marker>
<rawString>Joakim Gustafson, KTH, Royal Institute of Technology (Sweden) Srinivasan Janarthanam, Heriot-Watt University (United Kingdom) Jan Kleindienst, IBM Czech Republic, Prague (Czech Republic) Christian Mueller, DFKI, Saarbruecken (Germany)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Amanda Stent</author>
<author>Yahoo Labs</author>
</authors>
<institution>Andreas Vlachos, University of Cambridge (United Kingdom)</institution>
<location>New York (USA)</location>
<marker>Stent, Labs, </marker>
<rawString>Amanda Stent, Yahoo! Labs, New York (USA) Andreas Vlachos, University of Cambridge (United Kingdom)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Santiago Avalos</author>
<author>Luciana Benotti</author>
</authors>
<title>Mining human interactions to construct a virtual guide for a virtual fair Andrés Luna and Luciana Benotti Collaborative Exploration in Human-Robot Teams: What’s in their Corpora of Dialog, Video,</title>
<journal>LIDAR Messages?</journal>
<marker>Avalos, Benotti, </marker>
<rawString>Santiago Avalos and Luciana Benotti Mining human interactions to construct a virtual guide for a virtual fair Andrés Luna and Luciana Benotti Collaborative Exploration in Human-Robot Teams: What’s in their Corpora of Dialog, Video, &amp; LIDAR Messages?</rawString>
</citation>
<citation valid="false">
<authors>
<author>Clare Voss</author>
</authors>
<title>Taylor Cassidy and Douglas Summer-Stay Multi-threaded Interaction Management for Dynamic Spatial Applications Srinivasan Janarthanam and Oliver Lemon Mostly Passive Information Delivery – a Prototype</title>
<marker>Voss, </marker>
<rawString>Clare Voss, Taylor Cassidy and Douglas Summer-Stay Multi-threaded Interaction Management for Dynamic Spatial Applications Srinivasan Janarthanam and Oliver Lemon Mostly Passive Information Delivery – a Prototype</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Vystrcil</author>
<author>Tomas Macek</author>
<author>David Luksch</author>
<author>Martin Labsky</author>
<author>Kunc Ladislav</author>
</authors>
<title>Kleindienst and Tereza Kasparova ix</title>
<date></date>
<marker>Vystrcil, Macek, Luksch, Labsky, Ladislav, </marker>
<rawString>Jan Vystrcil, Tomas Macek, David Luksch, Martin Labsky, Kunc Ladislav, Jan Kleindienst and Tereza Kasparova ix</rawString>
</citation>
<citation valid="false">
<authors>
<author>No Day</author>
</authors>
<title>Set (continued) Session 14:30-15:30: Session III 14:30–15:00 Navigation Dialog of Blind People: Recovery from Getting Lost Jan Vystrcil, Ivo Maly, Jan Balata and Zdenek Mikovec</title>
<marker>Day, </marker>
<rawString>No Day Set (continued) Session 14:30-15:30: Session III 14:30–15:00 Navigation Dialog of Blind People: Recovery from Getting Lost Jan Vystrcil, Ivo Maly, Jan Balata and Zdenek Mikovec</rawString>
</citation>
<citation valid="false">
<title>15:00–15:30 Conversational Strategies for Robustly Managing Dialog in Public Spaces Aasish Pappu, Ming Sun, Seshadri Sridharan and Alexander Rudnicky (15:30-16:00) Coffee break (16:00-17:00) Session IV</title>
<marker></marker>
<rawString>15:00–15:30 Conversational Strategies for Robustly Managing Dialog in Public Spaces Aasish Pappu, Ming Sun, Seshadri Sridharan and Alexander Rudnicky (15:30-16:00) Coffee break (16:00-17:00) Session IV</rawString>
</citation>
<citation valid="false">
<title>16:00–16:30 Situationally Aware In-Car Information Presentation Using Incremental Speech Generation: Safer, and More Effective Spyros Kousidis, Casey Kennington, Timo Baumann, Hendrik Buschmeier, Stefan Kopp and David</title>
<location>Schlangen</location>
<marker></marker>
<rawString>16:00–16:30 Situationally Aware In-Car Information Presentation Using Incremental Speech Generation: Safer, and More Effective Spyros Kousidis, Casey Kennington, Timo Baumann, Hendrik Buschmeier, Stefan Kopp and David Schlangen</rawString>
</citation>
<citation valid="false">
<title>16:30–17:00 Human pause and resume behaviours for unobtrusive humanlike in-car spoken dialogue systems</title>
<marker></marker>
<rawString>16:30–17:00 Human pause and resume behaviours for unobtrusive humanlike in-car spoken dialogue systems</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jens Edlund</author>
</authors>
<title>Fredrik Edelstam and Joakim Gustafson</title>
<marker>Edlund, </marker>
<rawString>Jens Edlund, Fredrik Edelstam and Joakim Gustafson</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>