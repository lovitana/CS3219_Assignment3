<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000138">
<title confidence="0.987716">
Automatic Transliteration of Romanized Dialectal Arabic
</title>
<author confidence="0.992755">
Mohamed Al-Badrashiny†, Ramy Eskander, Nizar Habash and Owen Rambow
</author>
<affiliation confidence="0.99865">
†Department of Computer Science, The George Washington University, Washington, DC
</affiliation>
<email confidence="0.967909">
†badrashiny@gwu.edu
</email>
<affiliation confidence="0.649022">
Center for Computational Learning Systems, Columbia University, NYC, NY
</affiliation>
<email confidence="0.996845">
{reskander,habash,rambow}@ccls.columbia.edu
</email>
<sectionHeader confidence="0.997361" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999739875">
In this paper, we address the problem
of converting Dialectal Arabic (DA) text
that is written in the Latin script (called
Arabizi) into Arabic script following the
CODA convention for DA orthography.
The presented system uses a finite state
transducer trained at the character level
to generate all possible transliterations for
the input Arabizi words. We then filter
the generated list using a DA morpholog-
ical analyzer. After that we pick the best
choice for each input word using a lan-
guage model. We achieve an accuracy of
69.4% on an unseen test set compared to
63.1% using a system which represents a
previously proposed approach.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998451736842105">
The Arabic language is a collection of varieties:
Modern Standard Arabic (MSA), which is used
in formal settings and has a standard orthogra-
phy, and different forms of Dialectal Arabic (DA),
which are commonly used informally and with in-
creasing presence on the web, but which do not
have standard orthographies. While both MSA
and DA are commonly written in the Arabic script,
DA (and less so MSA) is sometimes written in
the Latin script. This happens when using an Ara-
bic keyboard is dispreferred or impossible, for ex-
ample when communicating from a mobile phone
that has no Arabic script support. Arabic written
in the Latin script is often referred to as “Arabizi”.
Arabizi is not a letter-based transliteration from
the Arabic script as is, for example, the Buck-
walter transliteration (Buckwalter, 2004). Instead,
roughly speaking, writers use sound-to-letter rules
inspired by those of English1 as well as informally
</bodyText>
<footnote confidence="0.7962555">
1In different parts of the Arab World, the basis for the
Latin script rendering of DA may come from different lan-
</footnote>
<bodyText confidence="0.95165845">
established conventions to render the sounds of the
DA sentence. Because the sound-to-letter rules
of English are very different from those of Ara-
bic, we obtain complex mappings between the two
writing systems. This issue is compounded by the
underlying problem that DA itself does not have
any standard orthography in the Arabic script. Ta-
ble 1 shows different plausible ways of writing an
Egyptian Arabic (EGY) sentence in Arabizi and
in Arabic script.
Arabizi poses a problem for natural language
processing (NLP). While some tools have recently
become available for processing EGY input, e.g.,
(Habash et al., 2012b; Habash et al., 2013; Pasha
et al., 2014), they expect Arabic script input (or a
Buckwalter transliteration). They cannot process
Arabizi. We therefore need a tool that converts
from Arabizi to Arabic script. However, the lack
of standard orthography in EGY compounds the
problem: what should we convert Arabizi into?
Our answer to this question is to use CODA, a
conventional orthography created for the purpose
of supporting NLP tools (Habash et al., 2012a).
The goal of CODA is to reduce the data sparseness
that comes from the same word form appearing in
many spontaneous orthographies in data (be it an-
notated or unannotated). CODA has been defined
for EGY as well as Tunisian Arabic (Zribi et al.,
2014), and it has been used as part of different ap-
proaches for modeling DA morphology (Habash
et al., 2012b), tagging (Habash et al., 2013; Pasha
et al., 2014) and spelling correction (Eskander et
al., 2013; Farra et al., 2014).
This paper makes two main contributions. First,
we clearly define the computational problem of
transforming Arabizi to CODA. This improves
over previous work by unambiguously fixing the
guages that natively uses the Latin script, such as English
or French. In this paper, we concentrate on Egyptian Arabic,
which uses English as its main source of sound-to-letter rules.
</bodyText>
<page confidence="0.972805">
30
</page>
<note confidence="0.688524">
Proceedings of the Eighteenth Conference on Computational Language Learning, pages 30–38,
Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999976315789474">
target representation for the transformation. Sec-
ond, we perform experiments using different com-
ponents in a transformation pipeline, and show
that a combination of character-based transduc-
tion, filtering using a morphological analyzer, and
using a language model outperforms other archi-
tectures, including the state-of-the-art system de-
scribed in Darwish (2013). Darwish (2013) pre-
sented a conversion tool, but did not discuss con-
version into a conventionalized orthography, and
did not investigate different architectures. We
show in this paper that our proposed architecture,
which includes an EGY morphological analyzer,
improves over Darwish’s architecture.
This paper is structured as follows. We start out
by presenting relevant linguistic facts (Section 2)
and then we discuss related work. We present our
approach in Section 4 and our experiments and re-
sults in Section 5.
</bodyText>
<sectionHeader confidence="0.997996" genericHeader="method">
2 Linguistic Facts
</sectionHeader>
<subsectionHeader confidence="0.991266">
2.1 EGY Spontaneous Orthography
</subsectionHeader>
<bodyText confidence="0.99973225">
An orthography is a specification of how to use
a particular writing system (script) to write the
words of a particular language. In cases where
there is no standard orthography, people use a
spontaneous orthography that is based on dif-
ferent criteria. The main criterion is phonol-
ogy: how to render a word pronunciation in
the given writing system. This mainly de-
pends on language-specific assumptions about the
grapheme-to-phoneme mapping. Another crite-
rion is to use cognates in a related language (sim-
ilar language or a language variant), where two
words represent a cognate if they are related et-
ymologically and have the same meaning. Ad-
ditionally, a spontaneous orthography may be af-
fected by speech effects, which are the lengthen-
ing of specific syllables to show emphasis or other
effects (such asQ��J�J���-J»ktyyyyr 2 ‘veeeery’).
EGY has no standard orthography. Instead,
it has a spontaneous orthography that is related
to the standard orthography of Modern Standard
Arabic. Table 1 shows an example of writing a
sentence in EGY spontaneous orthography in dif-
ferent variants.
</bodyText>
<footnote confidence="0.810916">
2Arabic transliteration is presented in the Habash-Soudi-
Buckwalter scheme (Habash et al., 2007): (in alphabetical
order) AbtθjHxdðrzsSDT Dςγfqklmnhwy and the additional
symbols: ’ Z, Â�@, Aˇ@�, A¯�@, wˆ j , yˆZø , ¯h o, ý ø.
</footnote>
<subsectionHeader confidence="0.995716">
2.2 Arabizi
</subsectionHeader>
<bodyText confidence="0.97649004">
Arabizi is a spontaneous orthography used to write
DA using the Latin script, the so-called Arabic
numerals, and other symbols commonly found on
various input devices such as punctuation. Arabizi
is commonly used by Arabic speakers to write in
social media and SMS and chat applications.
The orthography decisions made for writing
in Arabizi mainly depend on a phoneme-to-
grapheme mapping between the Arabic pronunci-
ation and the Latin script. This is largely based
on the phoneme-to-grapheme mapping used in En-
glish. Crucially, Arabizi is not a simple transliter-
ation of Arabic, under which each Arabic letter in
some orthography is replaced by a Latin letter (as
is the case in the Buckwalter transliteration used
widely in natural language processing but nowhere
else). As a result, it is not straightforward to con-
vert Arabizi to Arabic. We discuss some specific
aspects of Arabizi.
Vowels While EGY orthography omits vocalic
diacritics representing short vowels, Arabizi uses
the Latin script symbols for vowels (a, e, i, o, u, y)
to represent EGY’s short and long vowels, making
them ambiguous. In some cases, Arabizi words
omit short vowels altogether as is done in Arabic
orthography.
Consonants Another source of ambiguity is the
use of a single Latin letter to refer to multiple Ara-
bic phonemes. For example, the Latin letter &amp;quot;d&amp;quot; is
used to represent the sounds of the Arabic letters
X d and • D. Additionally, some pairs of Arabizi
letters can ambiguously map to a single Arabic let-
ter or pairs of letters: &amp;quot;sh&amp;quot; can be use to represent
€: š or éƒ sh. Arabizi also uses digits to repre-
sent some Arabic letters. For example, the dig-
its 2, 3, 5, 6, 7 and 9 are used to represent the
Hamza (glottal stop), and the sounds of the letters
¨ ς, p x, T, hH and • S, respectively. How-
ever, when followed by &amp;quot;’&amp;quot;, the digits 3, 6, 7 and
9 change their interpretations to the dotted version
of the Arabic letter: ¨� γ, D, p x and • D, re-
spectively. Moreover, &amp;quot;’&amp;quot; (as well as &amp;quot;q&amp;quot;) may also
refer to the glottal stop.
Foreign Words Arabizi contains a large num-
ber of foreign words, that are either borrowings
such as mobile or instances of code switching such
as I love you.
Abbreviations Arabizi may also include some
abbreviations such as isa which means é&lt;Ë@ZAƒ��à@�
�An A’ Allh ‘God willing’.
</bodyText>
<page confidence="0.999672">
31
</page>
<table confidence="0.999271416666666">
Orthography Example
CODA hPAJ.Ó@ �áÓ ú�G.Am�• �•���® ƒ� AÓ
mA šftš SHAby mn AmbArH
Non-CODA hPAJ.Ó@ �áÓ úG.Agñ“ �•���¯ñ �ƒAÓ
Arabic Script mAšwftš SwHAbý mn AmbArH
hPAJ.�K@� &amp;Ó úG.Am�• �•���® �‚Ó
mšftš SHAbý mn ˇAnbArH
hPAJ.Ó@� �áÓ ú�G.Am�• �•���J�® ƒ� AÓ
mA šftyš SHAby mn ˇAmbArH
Arabizi mashoftesh sohaby men embare7
ma shftesh swhabi mn imbareh
mshwftish swhaby min ambare7
</table>
<tableCaption confidence="0.9664765">
Table 1: The different spelling variants in EGY and Arabizi for writing the sentence &amp;quot;I have not seen my
friends since yesterday&amp;quot; versus its corresponding CODA form.
</tableCaption>
<subsectionHeader confidence="0.991665">
2.3 CODA 3 Related Work
</subsectionHeader>
<bodyText confidence="0.99997320967742">
CODA is a conventionalized orthography for Di-
alectal Arabic (Habash et al., 2012a). In CODA,
every word has a single orthographic representa-
tion. CODA has five key properties (Eskander
et al., 2013). First, CODA is an internally con-
sistent and coherent convention for writing DA.
Second, CODA is primarily created for computa-
tional purposes, but is easy to learn and recognize
by educated Arabic speakers. Third, CODA uses
the Arabic script as used for MSA, with no ex-
tra symbols from, for example, Persian or Urdu.
Fourth, CODA is intended as a unified framework
for writing all dialects. CODA has been defined
for EGY (Habash et al., 2012a) as well as Tunisian
Arabic (Zribi et al., 2014). Finally, CODA aims
to maintain a level of dialectal uniqueness while
using conventions based on similarities between
MSA and the dialects. For a full presentation of
CODA and a justification and explanation of its
choices, see (Habash et al., 2012a).
CODA has been used as part of different ap-
proaches for modeling DA morphology (Habash
et al., 2012b), tagging (Habash et al., 2013; Pasha
et al., 2014) and spelling correction (Eskander et
al., 2013; Farra et al., 2014). Converting Dialec-
tal Arabic (written using a spontaneous Arabic or-
thography or Arabizi) to CODA is beneficial to
NLP applications that better perform on standard-
ized data with less sparsity (Eskander et al., 2013).
Table 1 shows the CODA form corresponding
to spontaneously written Arabic.
Our proposed work has some similarities to Dar-
wish (2013). His work is divided into two sec-
tions: language identification and transliteration.
He used word and sequence-level features to iden-
tify Arabizi that is mixed with English. For Arabic
words, he modeled transliteration from Arabizi to
Arabic script, and then applied language model-
ing on the transliterated text. This is similar to our
proposed work in terms of transliteration and lan-
guage modeling. However, Darwish (2013) does
not target a conventionalized orthography, while
our system targets CODA. Additionally, Darwish
(2013) transliterates Arabic words only after filter-
ing out non-Arabic words, while we transliterate
the whole input Arabizi. Finally, he does not use
any morphological information, while we intro-
duce the use of a morphological analyzer to sup-
port the transliteration pipeline.
Chalabi and Gerges (2012) presented a hybrid
approach for Arabizi transliteration. Their work
relies on the use of character transformation rules
that are either handcrafted by a linguist or au-
tomatically generated from training data. They
also employ word-based and character-based lan-
guage models for the final transliteration choice.
Like Darwish (2013), the work done by Chalabi
and Gerges (2012) is similar to ours except that
it does not target a conventionalized orthography,
and does not use deep morphological information,
while our system does.
There are three commercial products that con-
</bodyText>
<page confidence="0.996051">
32
</page>
<bodyText confidence="0.9999793125">
vert Arabizi to Arabic, namely: Microsoft Maren,3
Google Ta3reeb4 and Yamli.5 However, since
these products are for commercial purposes, there
is not enough information about their approaches.
But given their output, it is clear that they do
not follow a well-defined standardized orthogra-
phy like we do. Furthermore, these tools are pri-
marily intended as input method support, not full
text transliteration. As a result, their users’ goal
is to produce Arabic script text not Arabizi text.
We expect, for instance, that users of these input
method support systems will use less or no code
switching to English, and they may employ char-
acter sequences that help them arrive at the target
Arabic script form, which otherwise they would
not write if they are targeting Arabizi.
Eskander et al. (2013) introduced a system
to convert spontaneous EGY to CODA, called
CODAFY. The difference between CODAFY and
our proposed system is that CODAFY works on
spontaneous text written in Arabic script, while
our system works on Arabizi, which involves a
higher degree of ambiguity. However, we use
CODAFY as a black-box module in our prepro-
cessing.
Additionally, there is some work on convert-
ing from dialectal Arabic to MSA, which is sim-
ilar to our work in terms of processing a dialec-
tal input. However, our final output is in EGY
and not MSA. Shaalan et al. (2007) introduced a
rule-based approach to convert EGY to MSA. Al-
Gaphari and Al-Yadoumi (2010) also used a rule-
based method to transform from Sanaani dialect to
MSA. Sawaf (2010), Salloum and Habash (2011)
and Salloum and Habash (2013) used morpholog-
ical analysis and morphosyntactic transformation
rules for processing EGY and Levantine Arabic.
There has been some work on machine translit-
eration by Knight and Graehl (1997). Al-Onaizan
and Knight (2002) introduced an approach for ma-
chine transliteration of Arabic names. Freeman
et al. (2006) also introduced a system for name
matching between English and Arabic, which
Habash (2008) employed as part of generating
English transliterations from Arabic words in the
context of machine translation. This work is sim-
ilar to ours in terms of text transliteration. How-
ever, our work is not restricted to names.
</bodyText>
<footnote confidence="0.999913">
3http://www.getmaren.com
4http://www.google.com/ta3reeb
5http://www.yamli.com/
</footnote>
<sectionHeader confidence="0.996766" genericHeader="method">
4 Approach
</sectionHeader>
<subsectionHeader confidence="0.999063">
4.1 Defining the Task
</subsectionHeader>
<bodyText confidence="0.9998964375">
Our task is as follows: for each Arabizi word in
the input, we choose the Arabic script word which
is the correct CODA spelling of the input word
and which carries the intended meaning (as deter-
mined in the context of the entire available text).
We do not merge two or more input words into
a single Arabic script word. If CODA requires
two consecutive input Arabizi words to be merged,
we indicate this by attaching a plus to the end of
the first word. On the other hand, if CODA re-
quires an input Arabizi word to be broken into two
or more Arabic script words, we indicate this by
inserting a dash between the words. We do this
to maintain the bijection between input and out-
put words, i.e., to allow easy tracing of the Arabic
script back to the Arabizi input.
</bodyText>
<subsectionHeader confidence="0.977798">
4.2 Transliteration Pipeline
</subsectionHeader>
<bodyText confidence="0.999626344827586">
The proposed system in this paper is called 3AR-
RIB.6 Using the context of an input Arabizi word,
3ARRIB produces the word’s best Arabic script
CODA transliteration. Figure 1 illustrates the dif-
ferent components of 3ARRIB in both the train-
ing and processing phases. We summarize the full
transliteration process as follows. Each Arabizi
sentence input to 3ARRIB goes through a pre-
processing step of lowercasing (de-capitalization),
speech effects handling, and punctuation split-
ting. 3ARRIB then generates a list of all possi-
ble transliterations for each word in the input sen-
tence using a finite-state transducer that is trained
on character-level alignment from Arabizi to Ara-
bic script. We then experiment with different com-
binations of the following two components:
Morphological Analyzer We use CALIMA
(Habash et al., 2012b), a morphological analyzer
for EGY. For each input word, CALIMA provides
all possible morphological analyses, including the
CODA spelling for each analysis. All generated
candidates are passed through CALIMA. If CAL-
IMA has no analysis for a candidate, then that
candidate gets filtered out; otherwise, the CODA
spellings of the analyses from CALIMA become
the new candidates in the rest of the transliteration
pipeline. For some words, CALIMA may sug-
gest multiple CODA spellings that reflect different
analyses of the word.
</bodyText>
<footnote confidence="0.785248">
63ARRIB (pronounced /ar-rib/) means “Arabize!”.
</footnote>
<page confidence="0.98862">
33
</page>
<figure confidence="0.99980012">
Input Arabizi
Script
Preprocessing
FSM
Arabizi – Arabic
Parallel Data
FSM
Candidates
FST model
Giza++
FST
CALIMA
(+tokenization)
Training phase
Egyptian Corpus
MADAMIRA
CALIMA
Output
SRILM
LM
A* Search
Output Arabic
Script
Best
Selections
</figure>
<figureCaption confidence="0.912410333333333">
Figure 1: An illustration of the different components of the 3ARRIB system in both the training and
processing phases. FST: finite-state Transducer; LM: Language Model; CALIMA: Morphological Ana-
lyzer for Dialectal Arabic; MADAMIRA: Morphological Tagger for Arabic.
</figureCaption>
<bodyText confidence="0.98684525">
Language Model We disambiguate among the
possibilities for all input words (which consti-
tute a “sausage” lattice) using an n-gram language
model.
</bodyText>
<subsectionHeader confidence="0.998837">
4.3 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999091">
We apply the following preprocessing steps to the
input Arabizi text:
</bodyText>
<listItem confidence="0.833278133333333">
• We separate all attached emoticons such as
(:D, :p, etc.) and punctuation from the words.
We only keep the apostrophe because it is
used in Arabizi to distinguish between dif-
ferent sounds. 3ARRIB keeps track of any
word offset change, so that it can reconstruct
the same number of tokens at the end of the
pipeline.
• We tag emoticons and punctuation to protect
them from any change through the pipeline.
• We lowercase all letters.
• We handle speech effects by replacing any
sequence of the same letter whose length is
greater than two by a sequence of exactly
length two; for example, iiiii becomes ii.
</listItem>
<subsectionHeader confidence="0.981955">
4.4 Character-Based Transduction
</subsectionHeader>
<bodyText confidence="0.99998528125">
We use a parallel corpus of Arabizi-Arabic words
to learn a character-based transduction model.
The parallel data consists of two sources. First,
we use 2,200 Arabizi-to-Arabic script pairs from
the training data used by (Darwish, 2013). We
manually revised the Arabic side to be CODA-
compliant. Second, we use about 6,300 pairs
of proper names in Arabic and English from
the Buckwalter Arabic Morphological Analyzer
(Buckwalter, 2004). Since proper names are typ-
ically transliterated, we expect them to be a rich
source for learning transliteration mappings.
The words in the parallel data are turned into
space-separated character tokens, which we align
using Giza++ (Och and Ney, 2003). We then use
the phrase extraction utility in the Moses statistical
machine translation system (Koehn et al., 2007) to
extract a phrase table which operates over char-
acters. The phrase table is then used to build a
finite-state transducer (FST) that maps sequences
of Arabizi characters into sequences of Arabic
script characters. We use the negative logarithmic
conditional probabilities of the Arabizi-to-Arabic
pairs in the phrase tables as costs inside the FST.
We use the FST to transduce an input Arabizi word
to one or more words in Arabic script, where ev-
ery resulting word in Arabic script is given a prob-
abilistic score.
As part of the preprocessing of the parallel data,
we associate all Arabizi letters with their word
location information (beginning, middle and end-
ing letters). This is necessary since some Arabizi
</bodyText>
<page confidence="0.997929">
34
</page>
<bodyText confidence="0.991351">
mapping phenomena happen only at specific loca-
tions. For example, the Arabizi letter &amp;quot;o&amp;quot; is likely
�
to be transliterated into I Â in Arabic if it appears
at the beginning of the word, but almost never so
if it appears in the middle of the word.
For some special Arabizi cases, we directly
transliterate input words to their correct Arabic
form using a table, without going through the FST.
For example, isa is mapped to 4��I �� �� ��I� �An A’
�
Allh ‘God willing’. There are currently 32 entries
in this table.
</bodyText>
<subsectionHeader confidence="0.997877">
4.5 Morphological Analyzer
</subsectionHeader>
<bodyText confidence="0.999585777777778">
For every word in the Arabizi input, all the candi-
dates generated by the character-based transduc-
tion are passed through the CALIMA morpholog-
ical analyzer. For every candidate, CALIMA pro-
duces a list of all the possible morphological anal-
yses. The CODA for these analyses need not be
the same. For example, if the output from the char-
acter based transducer is Aly, then CALIMA pro-
duces the following CODA-compliant spellings:
</bodyText>
<equation confidence="0.817249">
�
LjI� Alý ‘to’, LjI� Alý ‘to me’ and LjI Aly ‘automatic’
� �
</equation>
<bodyText confidence="0.999430142857143">
or ‘my family’. All of these CODA spellings are
the output of CALIMA for that particular input
word. The output from CALIMA then becomes
the set of final candidates of the input Arabizi in
the rest of the transliteration pipeline. If a word
is not recognized by CALIMA, it gets filtered out
from the transliteration pipeline. However, if all
the candidates of some word are not recognized
by CALIMA, then we retain them all since there
should be an output for every input word.
We additionally run a tokenization step that
makes use of the generated CALIMA morphologi-
cal analysis. The tokenization scheme we target is
D3, which separates all clitics associated with the
word (Habash, 2010). For every word, we keep
a list of the possible tokenized and untokenized
CODA-compliant pairs. We use the tokenized or
untokenized forms as inputs to either a tokenized
or untokenized language model, respectively, as
described in the next subsection. The untokenized
form is necessary to retain the surface form at the
end of the transliteration process.
Standalone clitics are sometimes found in Ara-
bizi such as lel ragel (which corresponds to
J° I� +jll+ rAjl ‘for the man’). Since CALIMA
does not handle most standalone clitics, we keep
a lookup table that associates them with their tok-
enization information.
</bodyText>
<subsectionHeader confidence="0.919847">
4.6 Language Model
</subsectionHeader>
<bodyText confidence="0.999789971428571">
We then use an EGY language model that is
trained on CODA-compliant text. We investi-
gate two options: a language model that has stan-
dard CODA white-space word tokenization con-
ventions (“untokenized”), and a language model
that has a D3 tokenized form of CODA in which
all clitics are separated (“tokenized”). The output
of the morphological analyzer (which is the input
to the LM component) is processed to match the
tokenization used in the LM.
The language models are built from a large
corpus of 392M EGY words.7 The corpus is
first processed using CODAFY (Eskander et al.,
2013), a system for spontaneous text convention-
alization into CODA. This is necessary so that
our system remains CODA-compliant across the
whole transliteration pipeline. Eskander et al.
(2013) states that the best conventionalization re-
sults are obtained by running the MLE component
of CODAFY followed by an EGY morphological
tagger, MADA-ARZ (Habash et al., 2013). In the
work reported here, we use the newer version of
MADA-ARZ, named MADAMIRA (Pasha et al.,
2014). For the tokenized language model, we run
a D3 tokenization step on top of the processed text
by MADAMIRA. The processed data is used to
build a language model with Kneser-Ney smooth-
ing using the SRILM toolkit (Stolcke, 2002).
We use A* search to pick the best transliteration
for each word given its context. The probability of
any path in the A* search space combines the FST
probability of the words with the probability from
the language model. Thus, for any certain path of
selected Arabic possibilities A0,i = {a0, a1, ...ai}
given the corresponding input Arabizi sequence
</bodyText>
<equation confidence="0.85059425">
W0,i = {w0, w1, ...wi}, the transliteration prob-
ability can be defined by equation (1).
i
P(A0,i|W0,i) = ri0 (P(aj |wj) ~ P(aj|aj−N+1,j−1)) (1)
</equation>
<bodyText confidence="0.8834715">
Where, N is the maximum affordable n-
gram length in the LM, P(aj|wj) is the
FST probability of transliterating the Ara-
bizi word wj into the Arabic word aj, and
P(aj|aj−N+1,j−1) is the LM probability of the se-
quence {aj−N+1, aj−N+2, ...aj}.
</bodyText>
<footnote confidence="0.99624">
7All of the resources we use are available from the Lin-
guistic Data Consortium: www.ldc.upenn.edu.
</footnote>
<page confidence="0.999111">
35
</page>
<sectionHeader confidence="0.99302" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.990024">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.9998926">
We use two in-house data sets for development
(Dev; 502 words) and blind testing (Test; 1004
words). The data contains EGY Arabizi SMS
conversations that are mapped to Arabic script in
CODA by a CODA-trained EGY native speaker.
</bodyText>
<subsectionHeader confidence="0.995388">
5.2 Experiments
</subsectionHeader>
<bodyText confidence="0.992171833333333">
We conducted a suite of experiments to evaluate
the performance of our approach and identify op-
timal settings on the Dev set. The optimal result
and the baseline are then applied to the blind Test
set. During development, the following settings
were explored:
</bodyText>
<listItem confidence="0.979838076923077">
• INV-Selection: The training data of the finite
state transducer is used to generate the list of
possibilities for each input Arabizi word. If
the input word cannot be found in the FST
training data, the word is kept in Arabizi.
• FST-ONLY: Pick the top choice from the list
generated by the finite state transducer.
• FST-CALIMA: Pick the top choice from the
list after the CALIMA filtering.
• FST-CALIMA-Tokenized-LM-5: Run the
full pipeline of 3ARRIB with a 5-gram to-
kenized LM.8
• FST-CALIMA-Tokenized-LM-5-MLE:
</listItem>
<bodyText confidence="0.9516324">
The same as FST-CALIMA-Tokenized-
LM-5, but for an Arabizi word that appears
in training, force its most frequently seen
mapping directly instead of running the
transliteration pipeline for that word.
</bodyText>
<listItem confidence="0.9460728">
• FST-CALIMA-Untokenized-LM-5: Run
the full pipeline of 3ARRIB with a 5-gram
untokenized LM.
• FST-Untokenized-LM-5: Run the full
pipeline of 3ARRIB minus the CALIMA fil-
</listItem>
<bodyText confidence="0.9004866">
tering with a 5-gram untokenized LM. This
setup is analogous to the transliteration ap-
proach proposed by (Darwish, 2013). Thus
we use it as our baseline.
Each of the above experiments is evaluated
with exact match, and with Alif/Ya normalization
(El Kholy and Habash, 2010; Habash, 2010).
83, 5, and 7-gram LMs have been tested. The 3 and 5-
gram LMs give the same performance while the 7-gram LM
is the worst.
</bodyText>
<subsectionHeader confidence="0.933446">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.99997025">
Table 2 summarizes the results on the Dev set.
Our best performing setup is FST-CALIMA-
Tokenized-LM-5 which has 77.5% accuracy and
79.1% accuracy with normalization. The baseline
system, FST-Untokenized-LM-5, gives 74.1% ac-
curacy and 74.9 % accuracy with normalization.
This highlights the value of morphological filter-
ing as well as sparsity-reducing tokenization.
Table 3 shows how we do (best system and best
baseline) on a blind Test set. Although the accu-
racy drops overall, the gap between the best sys-
tem and the baseline increases.
</bodyText>
<subsectionHeader confidence="0.962315">
5.4 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999941527777778">
We conducted two error analyses for the best per-
forming transliteration setting on the Dev set. We
first analyze in which component the Dev set er-
rors occur. About 29% of the errors are cases
where the FST does not generate the correct an-
swer. An additional 15% of the errors happen be-
cause the correct answer is not covered by CAL-
IMA. The language model does not include the
correct answer in an additional 8% of the errors.
The rest of the errors (48%) are cases where the
correct answer is available in all components but
does not get selected.
Motivated by the value of Arabizi transliteration
for machine translation into English, we distin-
guish between two types of words: words that re-
main the same when translated into English, such
as English words, proper nouns, laughs, emoti-
cons, punctuations and digits (EN-SET) versus
EGY-only words (EGY-SET). Examples of words
in EN-SET are: love you very much (code switch-
ing), Peter (proper noun), haha (laugh), :D (emoti-
con), ! (punctuation) and 123 (digits).
While the overall performance of our best set-
tings is 77.5%, the accuracy of the EGY-SET by
itself is 84.6% as opposed to 46.2% for EN-SET.
This large difference reflects the fact that we do
not target English word transliteration into Arabic
script explicitly.
We now perform a second error analysis only on
the errors in the EGY-SET, in which we categorize
the errors by their linguistic type. About 25% of
the errors are non-CODA-compliant system out-
put, where the answer is a plausible non-CODA
form, i.e., a form that may be written or read eas-
ily by a native speaker who is not aware of CODA.
For example, the system generates the non-CODA
</bodyText>
<page confidence="0.995929">
36
</page>
<table confidence="0.9991175">
System Exact-Matching A/Y-normalization
INV-Selection 37.1 40.6
FST-ONLY (pick top choice) 63.1 65.1
FST-CALIMA (pick top choice) 66.1 68.9
FST-CALIMA-Tokenized-LM-5 77.5 79.1
FST-CALIMA-Tokenized-LM-5-MLE 68.7 73.5
FST-CALIMA-Untokenized-LM-5 77.3 78.9
FST-Untokenized-LM-5 74.1 74.9
</table>
<tableCaption confidence="0.994481">
Table 2: Results on the Dev set in terms of accuracy (%).
</tableCaption>
<table confidence="0.998700666666667">
System Exact-Matching A/Y-normalization
FST-CALIMA-Tokenized-LM-5 69.4 73.9
FST-Untokenized-LM-5 63.1 65.4
</table>
<tableCaption confidence="0.999946">
Table 3: Results on the blind Test set in terms of accuracy (%).
</tableCaption>
<bodyText confidence="0.996026451612903">
form�•ª�®�JJ
Ó mynfsš instead of the correct CODA
form Lªa�JK� AÓ mA ynfsš ‘it doesn’t work’. Ignor-
ing the CODA-related errors increases the overall
accuracy by about 3.0% to become 80.5%. The ac-
curacy of the EGY-SET rises to 88.3% as opposed
to 84.6% when considering CODA compliance.
Ambiguous Arabizi input contributes to an ad-
ditional 27% of the errors, where the system as-
signs a plausible answer that is incorrect in con-
text. For example, the word matar in the input
Arabizi fel matar ‘at the airport’ has two plausi-
ble out-of-context solutions: PA¢Ó mTAr ‘airport’
(contextually correct) and Q¢Ó mTr ‘rain’ (contex-
tually incorrect).
In about 2% of the errors, the Arabizi input con-
tains a typo making it impossible to produce the
gold reference. For example, the input Arabizi
ba7bet contains a typo where the final t should turn
into k, so that it means 1/2J.kAK. bAHbk ‘I love you
[2fs]’.
In the rest of the errors (about 46%), the sys-
tem fails to come up with the correct answer. In-
stead, it assigns a completely different word or
even an impossible word. For example, the cor-
rect answer for the input Arabizi sora ‘picture’ is
oPñ“ Swr¯h, while the system produces the word
Pñƒ swr ‘wall’. Another example is the input Ara-
bizi talabt ‘I asked for’, where the output from the
system is ZJ.ËA£ TAlb¯h ‘student’, while the correct
answer is :,.Ê£ tlbt ‘I asked for, ordered’ instead.
</bodyText>
<sectionHeader confidence="0.998761" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999899642857143">
We presented a method for converting dialectal
Arabic (specifically, EGY) written in Arabizi to
Arabic script following the CODA convention for
DA orthography. We achieve a 17% error reduc-
tion over our implementation of a previously pub-
lished work (Darwish, 2013) on a blind test set.
In the future, we plan to improve several aspects
of our models, particularly FST character map-
ping, the morphological analyzer coverage, and
language models. We also plan to work on the
problem of automatic identification of non-Arabic
words. We will extend the system to work on other
Arabic dialects. We also plan to make the 3AR-
RIB system publicly available.
</bodyText>
<sectionHeader confidence="0.970251" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999540285714286">
This paper is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-12-C-
0014. Any opinions, findings and conclusions or
recommendations expressed in this paper are those
of the authors and do not necessarily reflect the
views of DARPA.
</bodyText>
<sectionHeader confidence="0.998179" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9216665">
G. Al-Gaphari and M. Al-Yadoumi. 2010. A method
to convert Sana’ani accent to Modern Standard Ara-
bic. International Journal of Information Science
and Management, pages 39–49.
Yaser Al-Onaizan and Kevin Knight. 2002. Machine
transliteration of names in arabic text. In Proceed-
ings of the ACL-02 Workshop on Computational Ap-
proaches to Semitic Languages.
</reference>
<page confidence="0.996671">
37
</page>
<reference confidence="0.998836560344828">
Tim Buckwalter. 2004. Buckwalter Arabic Morpho-
logical Analyzer Version 2.0. LDC catalog number
LDC2004L02, ISBN 1-58563-324-0.
Achraf Chalabi and Hany Gerges. 2012. Romanized
Arabic Transliteration. In Proceedings of the Sec-
ond Workshop on Advances in Text Input Methods
(WTIM 2012).
Kareem Darwish. 2013. Arabizi Detection and Con-
version to Arabic. CoRR.
Ahmed El Kholy and Nizar Habash. 2010. Techniques
for Arabic Morphological Detokenization and Or-
thographic Denormalization. In Proceedings of the
seventh International Conference on Language Re-
sources and Evaluation (LREC), Valletta, Malta.
Ramy Eskander, Nizar Habash, Owen Rambow, and
Nadi Tomeh. 2013. Processing Spontaneous Or-
thography. In Proceedings of the 2013 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies (NAACL-HLT), Atlanta, GA.
Noura Farra, Nadi Tomeh, Alla Rozovskaya, and
Nizar Habash. 2014. Generalized Character-Level
Spelling Error Correction. In Proceedings of the
Conference of the Association for Computational
Linguistics (ACL), Baltimore, Maryland, USA.
Andrew Freeman, Sherri Condon, and Christopher
Ackerman. 2006. Cross linguistic name matching
in English and Arabic. In Proceedings of the Human
Language Technology Conference of the NAACL,
Main Conference, pages 471–478, New York City,
USA.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den
Bosch and A. Soudi, editors, Arabic Computa-
tional Morphology: Knowledge-based and Empiri-
cal Methods. Springer.
Nizar Habash, Mona Diab, and Owen Rabmow. 2012a.
Conventional Orthography for Dialectal Arabic. In
Proceedings of the Language Resources and Evalu-
ation Conference (LREC), Istanbul.
Nizar Habash, Ramy Eskander, and Abdelati Hawwari.
2012b. A Morphological Analyzer for Egyptian
Arabic. In Proceedings of the Twelfth Meeting of the
Special Interest Group on Computational Morphol-
ogy and Phonology, pages 1–9, Montréal, Canada.
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-
kander, and Nadi Tomeh. 2013. Morphological
Analysis and Disambiguation for Dialectal Arabic.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL-HLT), Atlanta, GA.
Nizar Habash. 2008. Four Techniques for Online
Handling of Out-of-Vocabulary Words in Arabic-
English Statistical Machine Translation. In Pro-
ceedings of ACL-08: HLT, Short Papers, pages 57–
60, Columbus, Ohio.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Kevin Knight and Jonathan Graehl. 1997. Machine
transliteration. In Proceedings of the European
chapter of the Association for Computational Lin-
guistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the Association for Computational
Linguistics, Prague, Czech Republic.
Franz Joseph Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,
Ahmed El Kholy, Ramy Eskander, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan M. Roth.
2014. MADAMIRA: A Fast, Comprehensive Tool
for Morphological Analysis and Disambiguation of
Arabic. In Proceedings of the Language Resources
and Evaluation Conference (LREC), Reykjavik, Ice-
land.
Wael Salloum and Nizar Habash. 2011. Dialectal to
Standard Arabic Paraphrasing to Improve Arabic-
English Statistical Machine Translation. In Pro-
ceedings of the First Workshop on Algorithms and
Resources for Modelling of Dialects and Language
Varieties, pages 10–21, Edinburgh, Scotland.
Wael Salloum and Nizar Habash. 2013. Dialectal
Arabic to English Machine Translation: Pivoting
through Modern Standard Arabic. In Proceedings of
the 2013 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies (NAACL-HLT), At-
lanta, GA.
Hassan Sawaf. 2010. Arabic dialect handling in hybrid
machine translation. In Proceedings of the Confer-
ence of the Association for Machine Translation in
the Americas (AMTA), Denver, Colorado.
Khaled Shaalan, Hitham Abo Bakr, and Ibrahim
Ziedan. 2007. Transferring Egyptian Colloquial
into Modern Standard Arabic. In International Con-
ference on Recent Advances in Natural Language
Processing (RANLP), Borovets, Bulgaria.
Andreas Stolcke. 2002. SRILM - an Extensible Lan-
guage Modeling Toolkit. In Proceedings of the In-
ternational Conference on Spoken Language Pro-
cessing (ICSLP), volume 2, pages 901–904, Denver,
CO.
Ines Zribi, Rahma Boujelbane, Abir Masmoudi,
Mariem Ellouze, Lamia Belguith, and Nizar Habash.
2014. A Conventional Orthography for Tunisian
Arabic. In Proceedings of the Language Resources
and Evaluation Conference (LREC), Reykjavik, Ice-
land.
</reference>
<page confidence="0.999348">
38
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.983320">
<title confidence="0.999195">Automatic Transliteration of Romanized Dialectal Arabic</title>
<author confidence="0.997882">Ramy Eskander</author>
<author confidence="0.997882">Nizar Habash</author>
<author confidence="0.997882">Owen</author>
<affiliation confidence="0.9987005">of Computer Science, The George Washington University, Washington, Center for Computational Learning Systems, Columbia University, NYC,</affiliation>
<email confidence="0.999462">reskander@ccls.columbia.edu</email>
<email confidence="0.999462">habash@ccls.columbia.edu</email>
<email confidence="0.999462">rambow@ccls.columbia.edu</email>
<abstract confidence="0.999291411764706">In this paper, we address the problem of converting Dialectal Arabic (DA) text that is written in the Latin script (called Arabizi) into Arabic script following the CODA convention for DA orthography. The presented system uses a finite state transducer trained at the character level to generate all possible transliterations for the input Arabizi words. We then filter the generated list using a DA morphological analyzer. After that we pick the best choice for each input word using a language model. We achieve an accuracy of 69.4% on an unseen test set compared to 63.1% using a system which represents a previously proposed approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Al-Gaphari</author>
<author>M Al-Yadoumi</author>
</authors>
<title>A method to convert Sana’ani accent to Modern Standard Arabic.</title>
<date>2010</date>
<journal>International Journal of Information Science and Management,</journal>
<pages>39--49</pages>
<marker>Al-Gaphari, Al-Yadoumi, 2010</marker>
<rawString>G. Al-Gaphari and M. Al-Yadoumi. 2010. A method to convert Sana’ani accent to Modern Standard Arabic. International Journal of Information Science and Management, pages 39–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Machine transliteration of names in arabic text.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="13996" citStr="Al-Onaizan and Knight (2002)" startWordPosition="2253" endWordPosition="2256">verting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is not restricted to names. 3http://www.getmaren.com 4http://www.google.com/ta3reeb 5http://www.yamli.com/ 4 Approach 4.1 Defining the Task Our task is as follows: for each Arabizi word in the input, we choose the Arabic scr</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002. Machine transliteration of names in arabic text. In Proceedings of the ACL-02 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<date>2004</date>
<booktitle>Buckwalter Arabic Morphological Analyzer Version 2.0. LDC catalog number LDC2004L02, ISBN</booktitle>
<pages>1--58563</pages>
<contexts>
<context position="1814" citStr="Buckwalter, 2004" startWordPosition="277" endWordPosition="278">hich are commonly used informally and with increasing presence on the web, but which do not have standard orthographies. While both MSA and DA are commonly written in the Arabic script, DA (and less so MSA) is sometimes written in the Latin script. This happens when using an Arabic keyboard is dispreferred or impossible, for example when communicating from a mobile phone that has no Arabic script support. Arabic written in the Latin script is often referred to as “Arabizi”. Arabizi is not a letter-based transliteration from the Arabic script as is, for example, the Buckwalter transliteration (Buckwalter, 2004). Instead, roughly speaking, writers use sound-to-letter rules inspired by those of English1 as well as informally 1In different parts of the Arab World, the basis for the Latin script rendering of DA may come from different lanestablished conventions to render the sounds of the DA sentence. Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems. This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script. Table 1 shows different plausible </context>
<context position="18521" citStr="Buckwalter, 2004" startWordPosition="2976" endWordPosition="2977">cts by replacing any sequence of the same letter whose length is greater than two by a sequence of exactly length two; for example, iiiii becomes ii. 4.4 Character-Based Transduction We use a parallel corpus of Arabizi-Arabic words to learn a character-based transduction model. The parallel data consists of two sources. First, we use 2,200 Arabizi-to-Arabic script pairs from the training data used by (Darwish, 2013). We manually revised the Arabic side to be CODAcompliant. Second, we use about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). Since proper names are typically transliterated, we expect them to be a rich source for learning transliteration mappings. The words in the parallel data are turned into space-separated character tokens, which we align using Giza++ (Och and Ney, 2003). We then use the phrase extraction utility in the Moses statistical machine translation system (Koehn et al., 2007) to extract a phrase table which operates over characters. The phrase table is then used to build a finite-state transducer (FST) that maps sequences of Arabizi characters into sequences of Arabic script characters. We use the nega</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Tim Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer Version 2.0. LDC catalog number LDC2004L02, ISBN 1-58563-324-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Achraf Chalabi</author>
<author>Hany Gerges</author>
</authors>
<title>Romanized Arabic Transliteration.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second Workshop on Advances in Text Input Methods (WTIM</booktitle>
<contexts>
<context position="11614" citStr="Chalabi and Gerges (2012)" startWordPosition="1868" endWordPosition="1871">ransliteration from Arabizi to Arabic script, and then applied language modeling on the transliterated text. This is similar to our proposed work in terms of transliteration and language modeling. However, Darwish (2013) does not target a conventionalized orthography, while our system targets CODA. Additionally, Darwish (2013) transliterates Arabic words only after filtering out non-Arabic words, while we transliterate the whole input Arabizi. Finally, he does not use any morphological information, while we introduce the use of a morphological analyzer to support the transliteration pipeline. Chalabi and Gerges (2012) presented a hybrid approach for Arabizi transliteration. Their work relies on the use of character transformation rules that are either handcrafted by a linguist or automatically generated from training data. They also employ word-based and character-based language models for the final transliteration choice. Like Darwish (2013), the work done by Chalabi and Gerges (2012) is similar to ours except that it does not target a conventionalized orthography, and does not use deep morphological information, while our system does. There are three commercial products that con32 vert Arabizi to Arabic,</context>
</contexts>
<marker>Chalabi, Gerges, 2012</marker>
<rawString>Achraf Chalabi and Hany Gerges. 2012. Romanized Arabic Transliteration. In Proceedings of the Second Workshop on Advances in Text Input Methods (WTIM 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
</authors>
<title>Arabizi Detection and Conversion to Arabic.</title>
<date>2013</date>
<publisher>CoRR.</publisher>
<contexts>
<context position="4513" citStr="Darwish (2013)" startWordPosition="701" endWordPosition="702">ic, which uses English as its main source of sound-to-letter rules. 30 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 30–38, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics target representation for the transformation. Second, we perform experiments using different components in a transformation pipeline, and show that a combination of character-based transduction, filtering using a morphological analyzer, and using a language model outperforms other architectures, including the state-of-the-art system described in Darwish (2013). Darwish (2013) presented a conversion tool, but did not discuss conversion into a conventionalized orthography, and did not investigate different architectures. We show in this paper that our proposed architecture, which includes an EGY morphological analyzer, improves over Darwish’s architecture. This paper is structured as follows. We start out by presenting relevant linguistic facts (Section 2) and then we discuss related work. We present our approach in Section 4 and our experiments and results in Section 5. 2 Linguistic Facts 2.1 EGY Spontaneous Orthography An orthography is a specifica</context>
<context position="10784" citStr="Darwish (2013)" startWordPosition="1744" endWordPosition="1746">n of its choices, see (Habash et al., 2012a). CODA has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). Converting Dialectal Arabic (written using a spontaneous Arabic orthography or Arabizi) to CODA is beneficial to NLP applications that better perform on standardized data with less sparsity (Eskander et al., 2013). Table 1 shows the CODA form corresponding to spontaneously written Arabic. Our proposed work has some similarities to Darwish (2013). His work is divided into two sections: language identification and transliteration. He used word and sequence-level features to identify Arabizi that is mixed with English. For Arabic words, he modeled transliteration from Arabizi to Arabic script, and then applied language modeling on the transliterated text. This is similar to our proposed work in terms of transliteration and language modeling. However, Darwish (2013) does not target a conventionalized orthography, while our system targets CODA. Additionally, Darwish (2013) transliterates Arabic words only after filtering out non-Arabic wo</context>
<context position="18323" citStr="Darwish, 2013" startWordPosition="2945" endWordPosition="2946"> the same number of tokens at the end of the pipeline. • We tag emoticons and punctuation to protect them from any change through the pipeline. • We lowercase all letters. • We handle speech effects by replacing any sequence of the same letter whose length is greater than two by a sequence of exactly length two; for example, iiiii becomes ii. 4.4 Character-Based Transduction We use a parallel corpus of Arabizi-Arabic words to learn a character-based transduction model. The parallel data consists of two sources. First, we use 2,200 Arabizi-to-Arabic script pairs from the training data used by (Darwish, 2013). We manually revised the Arabic side to be CODAcompliant. Second, we use about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). Since proper names are typically transliterated, we expect them to be a rich source for learning transliteration mappings. The words in the parallel data are turned into space-separated character tokens, which we align using Giza++ (Och and Ney, 2003). We then use the phrase extraction utility in the Moses statistical machine translation system (Koehn et al., 2007) to extract a phrase table which </context>
<context position="25612" citStr="Darwish, 2013" startWordPosition="4152" endWordPosition="4153">g. • FST-CALIMA-Tokenized-LM-5: Run the full pipeline of 3ARRIB with a 5-gram tokenized LM.8 • FST-CALIMA-Tokenized-LM-5-MLE: The same as FST-CALIMA-TokenizedLM-5, but for an Arabizi word that appears in training, force its most frequently seen mapping directly instead of running the transliteration pipeline for that word. • FST-CALIMA-Untokenized-LM-5: Run the full pipeline of 3ARRIB with a 5-gram untokenized LM. • FST-Untokenized-LM-5: Run the full pipeline of 3ARRIB minus the CALIMA filtering with a 5-gram untokenized LM. This setup is analogous to the transliteration approach proposed by (Darwish, 2013). Thus we use it as our baseline. Each of the above experiments is evaluated with exact match, and with Alif/Ya normalization (El Kholy and Habash, 2010; Habash, 2010). 83, 5, and 7-gram LMs have been tested. The 3 and 5- gram LMs give the same performance while the 7-gram LM is the worst. 5.3 Results Table 2 summarizes the results on the Dev set. Our best performing setup is FST-CALIMATokenized-LM-5 which has 77.5% accuracy and 79.1% accuracy with normalization. The baseline system, FST-Untokenized-LM-5, gives 74.1% accuracy and 74.9 % accuracy with normalization. This highlights the value of</context>
<context position="30333" citStr="Darwish, 2013" startWordPosition="4937" endWordPosition="4938">example, the correct answer for the input Arabizi sora ‘picture’ is oPñ“ Swr¯h, while the system produces the word Pñƒ swr ‘wall’. Another example is the input Arabizi talabt ‘I asked for’, where the output from the system is ZJ.ËA£ TAlb¯h ‘student’, while the correct answer is :,.Ê£ tlbt ‘I asked for, ordered’ instead. 6 Conclusion and Future Work We presented a method for converting dialectal Arabic (specifically, EGY) written in Arabizi to Arabic script following the CODA convention for DA orthography. We achieve a 17% error reduction over our implementation of a previously published work (Darwish, 2013) on a blind test set. In the future, we plan to improve several aspects of our models, particularly FST character mapping, the morphological analyzer coverage, and language models. We also plan to work on the problem of automatic identification of non-Arabic words. We will extend the system to work on other Arabic dialects. We also plan to make the 3ARRIB system publicly available. Acknowledgement This paper is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-12-C0014. Any opinions, findings and conclusions or recommendations expresse</context>
</contexts>
<marker>Darwish, 2013</marker>
<rawString>Kareem Darwish. 2013. Arabizi Detection and Conversion to Arabic. CoRR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed El Kholy</author>
<author>Nizar Habash</author>
</authors>
<title>Techniques for Arabic Morphological Detokenization and Orthographic Denormalization.</title>
<date>2010</date>
<booktitle>In Proceedings of the seventh International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Valletta,</location>
<marker>El Kholy, Habash, 2010</marker>
<rawString>Ahmed El Kholy and Nizar Habash. 2010. Techniques for Arabic Morphological Detokenization and Orthographic Denormalization. In Proceedings of the seventh International Conference on Language Resources and Evaluation (LREC), Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Nadi Tomeh</author>
</authors>
<title>Processing Spontaneous Orthography.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="3573" citStr="Eskander et al., 2013" startWordPosition="565" endWordPosition="568">ld we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or unannotated). CODA has been defined for EGY as well as Tunisian Arabic (Zribi et al., 2014), and it has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). This paper makes two main contributions. First, we clearly define the computational problem of transforming Arabizi to CODA. This improves over previous work by unambiguously fixing the guages that natively uses the Latin script, such as English or French. In this paper, we concentrate on Egyptian Arabic, which uses English as its main source of sound-to-letter rules. 30 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 30–38, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics target representation </context>
<context position="9471" citStr="Eskander et al., 2013" startWordPosition="1525" endWordPosition="1528">tš SwHAbý mn AmbArH hPAJ.�K@� &amp;Ó úG.Am�• �•���® �‚Ó mšftš SHAbý mn ˇAnbArH hPAJ.Ó@� �áÓ ú�G.Am�• �•���J�® ƒ� AÓ mA šftyš SHAby mn ˇAmbArH Arabizi mashoftesh sohaby men embare7 ma shftesh swhabi mn imbareh mshwftish swhaby min ambare7 Table 1: The different spelling variants in EGY and Arabizi for writing the sentence &amp;quot;I have not seen my friends since yesterday&amp;quot; versus its corresponding CODA form. 2.3 CODA 3 Related Work CODA is a conventionalized orthography for Dialectal Arabic (Habash et al., 2012a). In CODA, every word has a single orthographic representation. CODA has five key properties (Eskander et al., 2013). First, CODA is an internally consistent and coherent convention for writing DA. Second, CODA is primarily created for computational purposes, but is easy to learn and recognize by educated Arabic speakers. Third, CODA uses the Arabic script as used for MSA, with no extra symbols from, for example, Persian or Urdu. Fourth, CODA is intended as a unified framework for writing all dialects. CODA has been defined for EGY (Habash et al., 2012a) as well as Tunisian Arabic (Zribi et al., 2014). Finally, CODA aims to maintain a level of dialectal uniqueness while using conventions based on similariti</context>
<context position="12989" citStr="Eskander et al. (2013)" startWordPosition="2086" endWordPosition="2089">heir approaches. But given their output, it is clear that they do not follow a well-defined standardized orthography like we do. Furthermore, these tools are primarily intended as input method support, not full text transliteration. As a result, their users’ goal is to produce Arabic script text not Arabizi text. We expect, for instance, that users of these input method support systems will use less or no code switching to English, and they may employ character sequences that help them arrive at the target Arabic script form, which otherwise they would not write if they are targeting Arabizi. Eskander et al. (2013) introduced a system to convert spontaneous EGY to CODA, called CODAFY. The difference between CODAFY and our proposed system is that CODAFY works on spontaneous text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to conve</context>
<context position="22540" citStr="Eskander et al., 2013" startWordPosition="3650" endWordPosition="3653">ization information. 4.6 Language Model We then use an EGY language model that is trained on CODA-compliant text. We investigate two options: a language model that has standard CODA white-space word tokenization conventions (“untokenized”), and a language model that has a D3 tokenized form of CODA in which all clitics are separated (“tokenized”). The output of the morphological analyzer (which is the input to the LM component) is processed to match the tokenization used in the LM. The language models are built from a large corpus of 392M EGY words.7 The corpus is first processed using CODAFY (Eskander et al., 2013), a system for spontaneous text conventionalization into CODA. This is necessary so that our system remains CODA-compliant across the whole transliteration pipeline. Eskander et al. (2013) states that the best conventionalization results are obtained by running the MLE component of CODAFY followed by an EGY morphological tagger, MADA-ARZ (Habash et al., 2013). In the work reported here, we use the newer version of MADA-ARZ, named MADAMIRA (Pasha et al., 2014). For the tokenized language model, we run a D3 tokenization step on top of the processed text by MADAMIRA. The processed data is used to</context>
</contexts>
<marker>Eskander, Habash, Rambow, Tomeh, 2013</marker>
<rawString>Ramy Eskander, Nizar Habash, Owen Rambow, and Nadi Tomeh. 2013. Processing Spontaneous Orthography. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noura Farra</author>
<author>Nadi Tomeh</author>
<author>Alla Rozovskaya</author>
<author>Nizar Habash</author>
</authors>
<title>Generalized Character-Level Spelling Error Correction.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL),</booktitle>
<location>Baltimore, Maryland, USA.</location>
<contexts>
<context position="3594" citStr="Farra et al., 2014" startWordPosition="569" endWordPosition="572">nto? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or unannotated). CODA has been defined for EGY as well as Tunisian Arabic (Zribi et al., 2014), and it has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). This paper makes two main contributions. First, we clearly define the computational problem of transforming Arabizi to CODA. This improves over previous work by unambiguously fixing the guages that natively uses the Latin script, such as English or French. In this paper, we concentrate on Egyptian Arabic, which uses English as its main source of sound-to-letter rules. 30 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 30–38, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics target representation for the transformatio</context>
<context position="10435" citStr="Farra et al., 2014" startWordPosition="1688" endWordPosition="1691"> a unified framework for writing all dialects. CODA has been defined for EGY (Habash et al., 2012a) as well as Tunisian Arabic (Zribi et al., 2014). Finally, CODA aims to maintain a level of dialectal uniqueness while using conventions based on similarities between MSA and the dialects. For a full presentation of CODA and a justification and explanation of its choices, see (Habash et al., 2012a). CODA has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). Converting Dialectal Arabic (written using a spontaneous Arabic orthography or Arabizi) to CODA is beneficial to NLP applications that better perform on standardized data with less sparsity (Eskander et al., 2013). Table 1 shows the CODA form corresponding to spontaneously written Arabic. Our proposed work has some similarities to Darwish (2013). His work is divided into two sections: language identification and transliteration. He used word and sequence-level features to identify Arabizi that is mixed with English. For Arabic words, he modeled transliteration from Arabizi to Arabic script, </context>
</contexts>
<marker>Farra, Tomeh, Rozovskaya, Habash, 2014</marker>
<rawString>Noura Farra, Nadi Tomeh, Alla Rozovskaya, and Nizar Habash. 2014. Generalized Character-Level Spelling Error Correction. In Proceedings of the Conference of the Association for Computational Linguistics (ACL), Baltimore, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Freeman</author>
<author>Sherri Condon</author>
<author>Christopher Ackerman</author>
</authors>
<title>Cross linguistic name matching in English and Arabic.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>471--478</pages>
<location>New York City, USA.</location>
<contexts>
<context position="14086" citStr="Freeman et al. (2006)" startWordPosition="2267" endWordPosition="2270">ctal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is not restricted to names. 3http://www.getmaren.com 4http://www.google.com/ta3reeb 5http://www.yamli.com/ 4 Approach 4.1 Defining the Task Our task is as follows: for each Arabizi word in the input, we choose the Arabic script word which is the correct CODA spelling of the input word and which carries the intend</context>
</contexts>
<marker>Freeman, Condon, Ackerman, 2006</marker>
<rawString>Andrew Freeman, Sherri Condon, and Christopher Ackerman. 2006. Cross linguistic name matching in English and Arabic. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 471–478, New York City, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="6266" citStr="Habash et al., 2007" startWordPosition="973" endWordPosition="976">resent a cognate if they are related etymologically and have the same meaning. Additionally, a spontaneous orthography may be affected by speech effects, which are the lengthening of specific syllables to show emphasis or other effects (such asQ��J�J���-J»ktyyyyr 2 ‘veeeery’). EGY has no standard orthography. Instead, it has a spontaneous orthography that is related to the standard orthography of Modern Standard Arabic. Table 1 shows an example of writing a sentence in EGY spontaneous orthography in different variants. 2Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical order) AbtθjHxdðrzsSDT Dςγfqklmnhwy and the additional symbols: ’ Z, Â�@, Aˇ@�, A¯�@, wˆ j , yˆZø , ¯h o, ý ø. 2.2 Arabizi Arabizi is a spontaneous orthography used to write DA using the Latin script, the so-called Arabic numerals, and other symbols commonly found on various input devices such as punctuation. Arabizi is commonly used by Arabic speakers to write in social media and SMS and chat applications. The orthography decisions made for writing in Arabizi mainly depend on a phoneme-tographeme mapping between the Arabic pronunciation and the Latin script. This is largel</context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Owen Rabmow</author>
</authors>
<title>Conventional Orthography for Dialectal Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC),</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="2660" citStr="Habash et al., 2012" startWordPosition="411" endWordPosition="414">nestablished conventions to render the sounds of the DA sentence. Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems. This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script. Table 1 shows different plausible ways of writing an Egyptian Arabic (EGY) sentence in Arabizi and in Arabic script. Arabizi poses a problem for natural language processing (NLP). While some tools have recently become available for processing EGY input, e.g., (Habash et al., 2012b; Habash et al., 2013; Pasha et al., 2014), they expect Arabic script input (or a Buckwalter transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data </context>
<context position="9353" citStr="Habash et al., 2012" startWordPosition="1506" endWordPosition="1509">.Ó@ �áÓ ú�G.Am�• �•���® ƒ� AÓ mA šftš SHAby mn AmbArH Non-CODA hPAJ.Ó@ �áÓ úG.Agñ“ �•���¯ñ �ƒAÓ Arabic Script mAšwftš SwHAbý mn AmbArH hPAJ.�K@� &amp;Ó úG.Am�• �•���® �‚Ó mšftš SHAbý mn ˇAnbArH hPAJ.Ó@� �áÓ ú�G.Am�• �•���J�® ƒ� AÓ mA šftyš SHAby mn ˇAmbArH Arabizi mashoftesh sohaby men embare7 ma shftesh swhabi mn imbareh mshwftish swhaby min ambare7 Table 1: The different spelling variants in EGY and Arabizi for writing the sentence &amp;quot;I have not seen my friends since yesterday&amp;quot; versus its corresponding CODA form. 2.3 CODA 3 Related Work CODA is a conventionalized orthography for Dialectal Arabic (Habash et al., 2012a). In CODA, every word has a single orthographic representation. CODA has five key properties (Eskander et al., 2013). First, CODA is an internally consistent and coherent convention for writing DA. Second, CODA is primarily created for computational purposes, but is easy to learn and recognize by educated Arabic speakers. Third, CODA uses the Arabic script as used for MSA, with no extra symbols from, for example, Persian or Urdu. Fourth, CODA is intended as a unified framework for writing all dialects. CODA has been defined for EGY (Habash et al., 2012a) as well as Tunisian Arabic (Zribi et </context>
<context position="16131" citStr="Habash et al., 2012" startWordPosition="2603" endWordPosition="2606">nts of 3ARRIB in both the training and processing phases. We summarize the full transliteration process as follows. Each Arabizi sentence input to 3ARRIB goes through a preprocessing step of lowercasing (de-capitalization), speech effects handling, and punctuation splitting. 3ARRIB then generates a list of all possible transliterations for each word in the input sentence using a finite-state transducer that is trained on character-level alignment from Arabizi to Arabic script. We then experiment with different combinations of the following two components: Morphological Analyzer We use CALIMA (Habash et al., 2012b), a morphological analyzer for EGY. For each input word, CALIMA provides all possible morphological analyses, including the CODA spelling for each analysis. All generated candidates are passed through CALIMA. If CALIMA has no analysis for a candidate, then that candidate gets filtered out; otherwise, the CODA spellings of the analyses from CALIMA become the new candidates in the rest of the transliteration pipeline. For some words, CALIMA may suggest multiple CODA spellings that reflect different analyses of the word. 63ARRIB (pronounced /ar-rib/) means “Arabize!”. 33 Input Arabizi Script Pr</context>
</contexts>
<marker>Habash, Diab, Rabmow, 2012</marker>
<rawString>Nizar Habash, Mona Diab, and Owen Rabmow. 2012a. Conventional Orthography for Dialectal Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ramy Eskander</author>
<author>Abdelati Hawwari</author>
</authors>
<title>A Morphological Analyzer for Egyptian Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology,</booktitle>
<pages>1--9</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="2660" citStr="Habash et al., 2012" startWordPosition="411" endWordPosition="414">nestablished conventions to render the sounds of the DA sentence. Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems. This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script. Table 1 shows different plausible ways of writing an Egyptian Arabic (EGY) sentence in Arabizi and in Arabic script. Arabizi poses a problem for natural language processing (NLP). While some tools have recently become available for processing EGY input, e.g., (Habash et al., 2012b; Habash et al., 2013; Pasha et al., 2014), they expect Arabic script input (or a Buckwalter transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data </context>
<context position="9353" citStr="Habash et al., 2012" startWordPosition="1506" endWordPosition="1509">.Ó@ �áÓ ú�G.Am�• �•���® ƒ� AÓ mA šftš SHAby mn AmbArH Non-CODA hPAJ.Ó@ �áÓ úG.Agñ“ �•���¯ñ �ƒAÓ Arabic Script mAšwftš SwHAbý mn AmbArH hPAJ.�K@� &amp;Ó úG.Am�• �•���® �‚Ó mšftš SHAbý mn ˇAnbArH hPAJ.Ó@� �áÓ ú�G.Am�• �•���J�® ƒ� AÓ mA šftyš SHAby mn ˇAmbArH Arabizi mashoftesh sohaby men embare7 ma shftesh swhabi mn imbareh mshwftish swhaby min ambare7 Table 1: The different spelling variants in EGY and Arabizi for writing the sentence &amp;quot;I have not seen my friends since yesterday&amp;quot; versus its corresponding CODA form. 2.3 CODA 3 Related Work CODA is a conventionalized orthography for Dialectal Arabic (Habash et al., 2012a). In CODA, every word has a single orthographic representation. CODA has five key properties (Eskander et al., 2013). First, CODA is an internally consistent and coherent convention for writing DA. Second, CODA is primarily created for computational purposes, but is easy to learn and recognize by educated Arabic speakers. Third, CODA uses the Arabic script as used for MSA, with no extra symbols from, for example, Persian or Urdu. Fourth, CODA is intended as a unified framework for writing all dialects. CODA has been defined for EGY (Habash et al., 2012a) as well as Tunisian Arabic (Zribi et </context>
<context position="16131" citStr="Habash et al., 2012" startWordPosition="2603" endWordPosition="2606">nts of 3ARRIB in both the training and processing phases. We summarize the full transliteration process as follows. Each Arabizi sentence input to 3ARRIB goes through a preprocessing step of lowercasing (de-capitalization), speech effects handling, and punctuation splitting. 3ARRIB then generates a list of all possible transliterations for each word in the input sentence using a finite-state transducer that is trained on character-level alignment from Arabizi to Arabic script. We then experiment with different combinations of the following two components: Morphological Analyzer We use CALIMA (Habash et al., 2012b), a morphological analyzer for EGY. For each input word, CALIMA provides all possible morphological analyses, including the CODA spelling for each analysis. All generated candidates are passed through CALIMA. If CALIMA has no analysis for a candidate, then that candidate gets filtered out; otherwise, the CODA spellings of the analyses from CALIMA become the new candidates in the rest of the transliteration pipeline. For some words, CALIMA may suggest multiple CODA spellings that reflect different analyses of the word. 63ARRIB (pronounced /ar-rib/) means “Arabize!”. 33 Input Arabizi Script Pr</context>
</contexts>
<marker>Habash, Eskander, Hawwari, 2012</marker>
<rawString>Nizar Habash, Ramy Eskander, and Abdelati Hawwari. 2012b. A Morphological Analyzer for Egyptian Arabic. In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology, pages 1–9, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Ramy Eskander</author>
<author>Nadi Tomeh</author>
</authors>
<title>Morphological Analysis and Disambiguation for Dialectal Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="2682" citStr="Habash et al., 2013" startWordPosition="415" endWordPosition="418">ns to render the sounds of the DA sentence. Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems. This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script. Table 1 shows different plausible ways of writing an Egyptian Arabic (EGY) sentence in Arabizi and in Arabic script. Arabizi poses a problem for natural language processing (NLP). While some tools have recently become available for processing EGY input, e.g., (Habash et al., 2012b; Habash et al., 2013; Pasha et al., 2014), they expect Arabic script input (or a Buckwalter transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or un</context>
<context position="10346" citStr="Habash et al., 2013" startWordPosition="1673" endWordPosition="1676">SA, with no extra symbols from, for example, Persian or Urdu. Fourth, CODA is intended as a unified framework for writing all dialects. CODA has been defined for EGY (Habash et al., 2012a) as well as Tunisian Arabic (Zribi et al., 2014). Finally, CODA aims to maintain a level of dialectal uniqueness while using conventions based on similarities between MSA and the dialects. For a full presentation of CODA and a justification and explanation of its choices, see (Habash et al., 2012a). CODA has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). Converting Dialectal Arabic (written using a spontaneous Arabic orthography or Arabizi) to CODA is beneficial to NLP applications that better perform on standardized data with less sparsity (Eskander et al., 2013). Table 1 shows the CODA form corresponding to spontaneously written Arabic. Our proposed work has some similarities to Darwish (2013). His work is divided into two sections: language identification and transliteration. He used word and sequence-level features to identify Arabizi that is mixed w</context>
<context position="22901" citStr="Habash et al., 2013" startWordPosition="3704" endWordPosition="3707">the morphological analyzer (which is the input to the LM component) is processed to match the tokenization used in the LM. The language models are built from a large corpus of 392M EGY words.7 The corpus is first processed using CODAFY (Eskander et al., 2013), a system for spontaneous text conventionalization into CODA. This is necessary so that our system remains CODA-compliant across the whole transliteration pipeline. Eskander et al. (2013) states that the best conventionalization results are obtained by running the MLE component of CODAFY followed by an EGY morphological tagger, MADA-ARZ (Habash et al., 2013). In the work reported here, we use the newer version of MADA-ARZ, named MADAMIRA (Pasha et al., 2014). For the tokenized language model, we run a D3 tokenization step on top of the processed text by MADAMIRA. The processed data is used to build a language model with Kneser-Ney smoothing using the SRILM toolkit (Stolcke, 2002). We use A* search to pick the best transliteration for each word given its context. The probability of any path in the A* search space combines the FST probability of the words with the probability from the language model. Thus, for any certain path of selected Arabic po</context>
</contexts>
<marker>Habash, Roth, Rambow, Eskander, Tomeh, 2013</marker>
<rawString>Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Four Techniques for Online Handling of Out-of-Vocabulary Words in ArabicEnglish Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<pages>57--60</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="14177" citStr="Habash (2008)" startWordPosition="2283" endWordPosition="2284">e-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is not restricted to names. 3http://www.getmaren.com 4http://www.google.com/ta3reeb 5http://www.yamli.com/ 4 Approach 4.1 Defining the Task Our task is as follows: for each Arabizi word in the input, we choose the Arabic script word which is the correct CODA spelling of the input word and which carries the intended meaning (as determined in the context of the entire available text). We do not merge two</context>
</contexts>
<marker>Habash, 2008</marker>
<rawString>Nizar Habash. 2008. Four Techniques for Online Handling of Out-of-Vocabulary Words in ArabicEnglish Statistical Machine Translation. In Proceedings of ACL-08: HLT, Short Papers, pages 57– 60, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="21324" citStr="Habash, 2010" startWordPosition="3451" endWordPosition="3452">t particular input word. The output from CALIMA then becomes the set of final candidates of the input Arabizi in the rest of the transliteration pipeline. If a word is not recognized by CALIMA, it gets filtered out from the transliteration pipeline. However, if all the candidates of some word are not recognized by CALIMA, then we retain them all since there should be an output for every input word. We additionally run a tokenization step that makes use of the generated CALIMA morphological analysis. The tokenization scheme we target is D3, which separates all clitics associated with the word (Habash, 2010). For every word, we keep a list of the possible tokenized and untokenized CODA-compliant pairs. We use the tokenized or untokenized forms as inputs to either a tokenized or untokenized language model, respectively, as described in the next subsection. The untokenized form is necessary to retain the surface form at the end of the transliteration process. Standalone clitics are sometimes found in Arabizi such as lel ragel (which corresponds to J° I� +jll+ rAjl ‘for the man’). Since CALIMA does not handle most standalone clitics, we keep a lookup table that associates them with their tokenizatio</context>
<context position="25764" citStr="Habash, 2010" startWordPosition="4178" endWordPosition="4179">izedLM-5, but for an Arabizi word that appears in training, force its most frequently seen mapping directly instead of running the transliteration pipeline for that word. • FST-CALIMA-Untokenized-LM-5: Run the full pipeline of 3ARRIB with a 5-gram untokenized LM. • FST-Untokenized-LM-5: Run the full pipeline of 3ARRIB minus the CALIMA filtering with a 5-gram untokenized LM. This setup is analogous to the transliteration approach proposed by (Darwish, 2013). Thus we use it as our baseline. Each of the above experiments is evaluated with exact match, and with Alif/Ya normalization (El Kholy and Habash, 2010; Habash, 2010). 83, 5, and 7-gram LMs have been tested. The 3 and 5- gram LMs give the same performance while the 7-gram LM is the worst. 5.3 Results Table 2 summarizes the results on the Dev set. Our best performing setup is FST-CALIMATokenized-LM-5 which has 77.5% accuracy and 79.1% accuracy with normalization. The baseline system, FST-Untokenized-LM-5, gives 74.1% accuracy and 74.9 % accuracy with normalization. This highlights the value of morphological filtering as well as sparsity-reducing tokenization. Table 3 shows how we do (best system and best baseline) on a blind Test set. Althoug</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>Machine transliteration.</title>
<date>1997</date>
<booktitle>In Proceedings of the European chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="13966" citStr="Knight and Graehl (1997)" startWordPosition="2249" endWordPosition="2252"> there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is not restricted to names. 3http://www.getmaren.com 4http://www.google.com/ta3reeb 5http://www.yamli.com/ 4 Approach 4.1 Defining the Task Our task is as follows: for each Arabizi word in the i</context>
</contexts>
<marker>Knight, Graehl, 1997</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1997. Machine transliteration. In Proceedings of the European chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="18890" citStr="Koehn et al., 2007" startWordPosition="3032" endWordPosition="3035">pairs from the training data used by (Darwish, 2013). We manually revised the Arabic side to be CODAcompliant. Second, we use about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). Since proper names are typically transliterated, we expect them to be a rich source for learning transliteration mappings. The words in the parallel data are turned into space-separated character tokens, which we align using Giza++ (Och and Ney, 2003). We then use the phrase extraction utility in the Moses statistical machine translation system (Koehn et al., 2007) to extract a phrase table which operates over characters. The phrase table is then used to build a finite-state transducer (FST) that maps sequences of Arabizi characters into sequences of Arabic script characters. We use the negative logarithmic conditional probabilities of the Arabizi-to-Arabic pairs in the phrase tables as costs inside the FST. We use the FST to transduce an input Arabizi word to one or more words in Arabic script, where every resulting word in Arabic script is given a probabilistic score. As part of the preprocessing of the parallel data, we associate all Arabizi letters </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the Association for Computational Linguistics, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Joseph Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="18774" citStr="Och and Ney, 2003" startWordPosition="3014" endWordPosition="3017">-based transduction model. The parallel data consists of two sources. First, we use 2,200 Arabizi-to-Arabic script pairs from the training data used by (Darwish, 2013). We manually revised the Arabic side to be CODAcompliant. Second, we use about 6,300 pairs of proper names in Arabic and English from the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004). Since proper names are typically transliterated, we expect them to be a rich source for learning transliteration mappings. The words in the parallel data are turned into space-separated character tokens, which we align using Giza++ (Och and Ney, 2003). We then use the phrase extraction utility in the Moses statistical machine translation system (Koehn et al., 2007) to extract a phrase table which operates over characters. The phrase table is then used to build a finite-state transducer (FST) that maps sequences of Arabizi characters into sequences of Arabic script characters. We use the negative logarithmic conditional probabilities of the Arabizi-to-Arabic pairs in the phrase tables as costs inside the FST. We use the FST to transduce an input Arabizi word to one or more words in Arabic script, where every resulting word in Arabic script </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Joseph Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arfath Pasha</author>
<author>Mohamed Al-Badrashiny</author>
<author>Mona Diab</author>
<author>Ahmed El Kholy</author>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Manoj Pooleery</author>
<author>Owen Rambow</author>
<author>Ryan M Roth</author>
</authors>
<title>MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik,</booktitle>
<marker>Pasha, Al-Badrashiny, Diab, El Kholy, Eskander, Habash, Pooleery, Rambow, Roth, 2014</marker>
<rawString>Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab, Ahmed El Kholy, Ramy Eskander, Nizar Habash, Manoj Pooleery, Owen Rambow, and Ryan M. Roth. 2014. MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,</booktitle>
<pages>10--21</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="13746" citStr="Salloum and Habash (2011)" startWordPosition="2216" endWordPosition="2219">t CODAFY works on spontaneous text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text translite</context>
</contexts>
<marker>Salloum, Habash, 2011</marker>
<rawString>Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10–21, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal Arabic to English Machine Translation: Pivoting through Modern Standard Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="13776" citStr="Salloum and Habash (2013)" startWordPosition="2221" endWordPosition="2224">text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours in terms of text transliteration. However, our work is n</context>
</contexts>
<marker>Salloum, Habash, 2013</marker>
<rawString>Wael Salloum and Nizar Habash. 2013. Dialectal Arabic to English Machine Translation: Pivoting through Modern Standard Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sawaf</author>
</authors>
<title>Arabic dialect handling in hybrid machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="13719" citStr="Sawaf (2010)" startWordPosition="2214" endWordPosition="2215"> system is that CODAFY works on spontaneous text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English and Arabic, which Habash (2008) employed as part of generating English transliterations from Arabic words in the context of machine translation. This work is similar to ours</context>
</contexts>
<marker>Sawaf, 2010</marker>
<rawString>Hassan Sawaf. 2010. Arabic dialect handling in hybrid machine translation. In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA), Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khaled Shaalan</author>
<author>Hitham Abo Bakr</author>
<author>Ibrahim Ziedan</author>
</authors>
<title>Transferring Egyptian Colloquial into Modern Standard Arabic.</title>
<date>2007</date>
<booktitle>In International Conference on Recent Advances in Natural Language Processing (RANLP), Borovets,</booktitle>
<contexts>
<context position="13547" citStr="Shaalan et al. (2007)" startWordPosition="2183" endWordPosition="2186">not write if they are targeting Arabizi. Eskander et al. (2013) introduced a system to convert spontaneous EGY to CODA, called CODAFY. The difference between CODAFY and our proposed system is that CODAFY works on spontaneous text written in Arabic script, while our system works on Arabizi, which involves a higher degree of ambiguity. However, we use CODAFY as a black-box module in our preprocessing. Additionally, there is some work on converting from dialectal Arabic to MSA, which is similar to our work in terms of processing a dialectal input. However, our final output is in EGY and not MSA. Shaalan et al. (2007) introduced a rule-based approach to convert EGY to MSA. AlGaphari and Al-Yadoumi (2010) also used a rulebased method to transform from Sanaani dialect to MSA. Sawaf (2010), Salloum and Habash (2011) and Salloum and Habash (2013) used morphological analysis and morphosyntactic transformation rules for processing EGY and Levantine Arabic. There has been some work on machine transliteration by Knight and Graehl (1997). Al-Onaizan and Knight (2002) introduced an approach for machine transliteration of Arabic names. Freeman et al. (2006) also introduced a system for name matching between English a</context>
</contexts>
<marker>Shaalan, Bakr, Ziedan, 2007</marker>
<rawString>Khaled Shaalan, Hitham Abo Bakr, and Ibrahim Ziedan. 2007. Transferring Egyptian Colloquial into Modern Standard Arabic. In International Conference on Recent Advances in Natural Language Processing (RANLP), Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP),</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="23229" citStr="Stolcke, 2002" startWordPosition="3763" endWordPosition="3764">ssary so that our system remains CODA-compliant across the whole transliteration pipeline. Eskander et al. (2013) states that the best conventionalization results are obtained by running the MLE component of CODAFY followed by an EGY morphological tagger, MADA-ARZ (Habash et al., 2013). In the work reported here, we use the newer version of MADA-ARZ, named MADAMIRA (Pasha et al., 2014). For the tokenized language model, we run a D3 tokenization step on top of the processed text by MADAMIRA. The processed data is used to build a language model with Kneser-Ney smoothing using the SRILM toolkit (Stolcke, 2002). We use A* search to pick the best transliteration for each word given its context. The probability of any path in the A* search space combines the FST probability of the words with the probability from the language model. Thus, for any certain path of selected Arabic possibilities A0,i = {a0, a1, ...ai} given the corresponding input Arabizi sequence W0,i = {w0, w1, ...wi}, the transliteration probability can be defined by equation (1). i P(A0,i|W0,i) = ri0 (P(aj |wj) ~ P(aj|aj−N+1,j−1)) (1) Where, N is the maximum affordable ngram length in the LM, P(aj|wj) is the FST probability of translit</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing (ICSLP), volume 2, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Zribi</author>
<author>Rahma Boujelbane</author>
<author>Abir Masmoudi</author>
<author>Mariem Ellouze</author>
<author>Lamia Belguith</author>
<author>Nizar Habash</author>
</authors>
<title>A Conventional Orthography for Tunisian Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik,</booktitle>
<contexts>
<context position="3371" citStr="Zribi et al., 2014" startWordPosition="530" endWordPosition="533">r transliteration). They cannot process Arabizi. We therefore need a tool that converts from Arabizi to Arabic script. However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into? Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools (Habash et al., 2012a). The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or unannotated). CODA has been defined for EGY as well as Tunisian Arabic (Zribi et al., 2014), and it has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). This paper makes two main contributions. First, we clearly define the computational problem of transforming Arabizi to CODA. This improves over previous work by unambiguously fixing the guages that natively uses the Latin script, such as English or French. In this paper, we concentrate on Egyptian Arabic, which uses English as its main source of sound-to-letter rules. 30 P</context>
<context position="9963" citStr="Zribi et al., 2014" startWordPosition="1610" endWordPosition="1613">al., 2012a). In CODA, every word has a single orthographic representation. CODA has five key properties (Eskander et al., 2013). First, CODA is an internally consistent and coherent convention for writing DA. Second, CODA is primarily created for computational purposes, but is easy to learn and recognize by educated Arabic speakers. Third, CODA uses the Arabic script as used for MSA, with no extra symbols from, for example, Persian or Urdu. Fourth, CODA is intended as a unified framework for writing all dialects. CODA has been defined for EGY (Habash et al., 2012a) as well as Tunisian Arabic (Zribi et al., 2014). Finally, CODA aims to maintain a level of dialectal uniqueness while using conventions based on similarities between MSA and the dialects. For a full presentation of CODA and a justification and explanation of its choices, see (Habash et al., 2012a). CODA has been used as part of different approaches for modeling DA morphology (Habash et al., 2012b), tagging (Habash et al., 2013; Pasha et al., 2014) and spelling correction (Eskander et al., 2013; Farra et al., 2014). Converting Dialectal Arabic (written using a spontaneous Arabic orthography or Arabizi) to CODA is beneficial to NLP applicati</context>
</contexts>
<marker>Zribi, Boujelbane, Masmoudi, Ellouze, Belguith, Habash, 2014</marker>
<rawString>Ines Zribi, Rahma Boujelbane, Abir Masmoudi, Mariem Ellouze, Lamia Belguith, and Nizar Habash. 2014. A Conventional Orthography for Tunisian Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Reykjavik, Iceland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>