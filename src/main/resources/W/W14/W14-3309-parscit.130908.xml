<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.990159">
Edinburgh’s Phrase-based Machine Translation Systems for WMT-14
</title>
<author confidence="0.998465">
Nadir Durrani Barry Haddow Philipp Koehn
</author>
<affiliation confidence="0.9984825">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.994333">
{dnadir,bhaddow,pkoehn}@inf.ed.ac.uk
</email>
<author confidence="0.995299">
Kenneth Heafield
</author>
<affiliation confidence="0.9923235">
Computer Science Department
Stanford University
</affiliation>
<email confidence="0.996396">
heafield@cs.stanford.edu
</email>
<sectionHeader confidence="0.997368" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999992875">
This paper describes the University of Ed-
inburgh’s (UEDIN) phrase-based submis-
sions to the translation and medical trans-
lation shared tasks of the 2014 Work-
shop on Statistical Machine Translation
(WMT). We participated in all language
pairs. We have improved upon our 2013
system by i) using generalized represen-
tations, specifically automatic word clus-
ters for translations out of English, ii) us-
ing unsupervised character-based models
to translate unknown words in Russian-
English and Hindi-English pairs, iii) syn-
thesizing Hindi data from closely-related
Urdu data, and iv) building huge language
on the common crawl corpus.
</bodyText>
<sectionHeader confidence="0.982064" genericHeader="categories and subject descriptors">
1 Translation Task
</sectionHeader>
<bodyText confidence="0.999889">
Our baseline systems are based on the setup de-
scribed in (Durrani et al., 2013b) that we used
for the Eighth Workshop on Statistical Machine
Translation (Bojar et al., 2013). The notable fea-
tures of these systems are described in the follow-
ing section. The experiments that we carried out
for this year’s translation task are described in the
following sections.
</bodyText>
<subsectionHeader confidence="0.936311">
1.1 Baseline
</subsectionHeader>
<bodyText confidence="0.99995925">
We trained our systems with the following set-
tings: a maximum sentence length of 80, grow-
diag-final-and symmetrization of GIZA++ align-
ments, an interpolated Kneser-Ney smoothed 5-
gram language model with KenLM (Heafield,
2011) used at runtime, hierarchical lexicalized re-
ordering (Galley and Manning, 2008), a lexically-
driven 5-gram operation sequence model (OSM)
(Durrani et al., 2013a) with 4 count-based sup-
portive features, sparse domain indicator, phrase
length, and count bin features (Blunsom and Os-
borne, 2008; Chiang et al., 2009), a distortion limit
of 6, maximum phrase-length of 5, 100-best trans-
lation options, Minimum Bayes Risk decoding
(Kumar and Byrne, 2004), Cube Pruning (Huang
and Chiang, 2007), with a stack-size of 1000
during tuning and 5000 during test and the no-
reordering-over-punctuation heuristic (Koehn and
Haddow, 2009). We used POS and morphologi-
cal tags as additional factors in phrase translation
models (Koehn and Hoang, 2007) for German-
English language pairs. We also trained target se-
quence models on the in-domain subset of the par-
allel corpus using Kneser-Ney smoothed 7-gram
models. We used syntactic-preordering (Collins
et al., 2005) and compound splitting (Koehn and
Knight, 2003) for German-to-English systems.
We used trivia tokenizer for tokenizing Hindi.
The systems were tuned on a very large tun-
ing set consisting of the test sets from 2008-2012,
with a total of 13,071 sentences. We used news-
test 2013 for the dev experiments. For Russian-
English pairs news-test 2012 was used for tuning
and for Hindi-English pairs, we divided the news-
dev 2014 into two halves, used the first half for
tuning and second for dev experiments.
</bodyText>
<subsectionHeader confidence="0.996231">
1.2 Using Generalized Word Representations
</subsectionHeader>
<bodyText confidence="0.999976125">
We explored the use of automatic word clusters
in phrase-based models (Durrani et al., 2014a).
We computed the clusters with GIZA++’s mkcls
(Och, 1999) on the source and target side of the
parallel training corpus. Clusters are word classes
that are optimized to reduce n-gram perplexity.
By generating a cluster identifier for each out-
put word, we are able to add an n-gram model
</bodyText>
<page confidence="0.995931">
97
</page>
<note confidence="0.7140395">
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97–104,
Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.99959235">
over these identifiers as an additional scoring func-
tion. The inclusion of such an additional factor
is trivial given the factored model implementation
(Koehn and Hoang, 2007) of Moses (Koehn et al.,
2007). The n-gram model is trained in the similar
way as the regular language model. We trained
domain-specific language models separately and
then linearly interpolated them using SRILM with
weights optimized on the tuning set (Schwenk and
Koehn, 2008).
We also trained OSM models over cluster-ids
(?). The lexically driven OSM model falls back to
very small context sizes of two to three operations
due to data sparsity. Learning operation sequences
over cluster-ids enables us to learn richer trans-
lation and reordering patterns that can generalize
better in sparse data conditions. Table 1 shows
gains from adding target LM and OSM models
over cluster-ids. Using word clusters was found
more useful translating from English-to-*.
</bodyText>
<table confidence="0.902121571428571">
from English into English
Lang B0 +Cid 0 B0 +Cid 0
20.60 20.85 +0.25 27.44 27.34 -0.10
18.84 19.39 +0.55 26.42 26.42 ±0.00
30.73 30.82 +0.09 31.64 31.76 +0.12
18.78 19.67 +0.89 24.45 24.63 +0.18
10.39 10.52 +0.13 15.48 15.26 -0.22
</table>
<tableCaption confidence="0.999462">
Table 1: Using Word Clusters in Phrase-based and
</tableCaption>
<bodyText confidence="0.904420333333333">
OSM models – B0 = System without Clusters,
+Cid = with Cluster
We also trained OSM models over POS and
morph tags. For the English-to-German sys-
tem we added an OSM model over [pos, morph]
(source:pos, target:morph) and for the German-
to-English system we added an OSM model over
[morph,pos] (source:morph, target:pos), a config-
uration that was found to work best in our previous
experiments (Birch et al., 2013). Table 2 shows
gains from additionally using OSM models over
POS/morph tags.
</bodyText>
<tableCaption confidence="0.94515">
Table 2: Using POS and Morph Tags in
OSM models – B0 = Baseline, +OSMp,m =
POS/Morph-based OSM
</tableCaption>
<subsectionHeader confidence="0.970308">
1.3 Unsupervised Transliteration Model
</subsectionHeader>
<bodyText confidence="0.998200428571428">
Last year, our Russian-English systems performed
badly on the human evaluation. In comparison
other participants that used transliteration did well.
We could not train a transliteration system due
to unavailability of a transliteration training data.
This year we used an EM-based method to in-
duce unsupervised transliteration models (Durrani
et al., 2014b). We extracted transliteration pairs
automatically from the word-aligned parallel data
and used it to learn a transliteration system. We
then built transliteration phrase-tables for trans-
lating OOV words and used the post-decoding
method (Method 2 as described in the paper) to
translate these.
</bodyText>
<equation confidence="0.4898206">
Pair Training OOV B0 +TT 0
Table 3: Using Unsupervised Transliteration
Model – Training = Extracted Transliteration Cor-
pus (types), OOV = Out-of-vocabulary words (to-
kens) B0 = System without Transliteration, +Tr
</equation>
<bodyText confidence="0.943887166666667">
= Transliterating OOVs
Table 3 shows the number (types) of translit-
eration pairs extracted using unsupervised min-
ing, number of OOV words (tokens) in each pair
and the gains achieved by transliterating unknown
words.
</bodyText>
<subsectionHeader confidence="0.999614">
1.4 Synthesizing Hindi Data from Urdu
</subsectionHeader>
<bodyText confidence="0.999311928571429">
Hindi and Urdu are closely related language pairs
that share grammatical structure and have a large
overlap in vocabulary. This provides a strong
motivation to transform any Urdu-English paral-
lel data into Hindi-English by translating the Urdu
part into Hindi. We made use of the Urdu-English
segment of the Indic multi-parallel corpus (Post
et al., 2012) which contains roughly 87K sentence
pairs. The Hindi-English segment of this corpus
is a subset of parallel data made available for the
translation task but is completely disjoint from the
Urdu-English segment.
We initially trained a Urdu-to-Hindi SMT sys-
tem using a very tiny EMILLE1 corpus (Baker
</bodyText>
<footnote confidence="0.9589475">
1EMILLE corpus contains roughly 12000 sentences of
Hindi and Urdu comparable data. From these we were able
to sentence align 7000 sentences to build an Urdu-to-Hindi
system.
</footnote>
<figure confidence="0.9641313125">
en-de 20.44 20.60 +0.16
de-en 27.24 27.44 +0.20
Lang B0 +OSMp,M 0
232K 1356 24.63 25.06 +0.41
232K 681 19.67 19.91 +0.24
38K 503 14.67 15.48 +0.81
38K 394 11.76 12.83 +1.07
ru-en
en-ru
hi-en
en-hi
de
cs
fr
ru
hi
</figure>
<page confidence="0.999331">
98
</page>
<bodyText confidence="0.999542733333333">
et al., 2002). But we found this system to be use-
less for translating the Urdu part of Indic data due
to domain mismatch and huge number of OOV
words (approximately 310K tokens). To reduce
sparsity we synthesized additional phrase-tables
using interpolation and transliteration.
Interpolation: We trained two phrase transla-
tion tables p( ¯ui|¯ei) and p(¯ei|¯hi), from Urdu-
English (Indic corpus) and Hindi-English (Hin-
dEnCorp (Bojar et al., 2014)) bilingual cor-
pora. Given the phrase-table for Urdu-English
p( ¯ui |¯ei) and the phrase-table for English-Hindi
p(¯ei |¯hi), we estimated a Urdu-Hindi phrase-table
p( ¯ui |¯hi) using the well-known convolution model
(Utiyama and Isahara, 2007; Wu and Wang, 2007):
</bodyText>
<equation confidence="0.949154">
p( ¯ui |�¯hi) = p( ¯ui|¯ei)p(¯ei |hi)
¯ei
</equation>
<bodyText confidence="0.999832">
The number of entries in the baseline Urdu-to-
Hindi phrase-table were approximately 254K. Us-
ing interpolation we were able to build a phrase-
table containing roughly 10M phrases. This re-
duced the number of OOV tokens from 310K to
approximately 50K.
Transliteration: Urdu and Hindi are written in
different scripts (Arabic and Devanagri respec-
tively). We added a transliteration component
to our Urdu-to-Hindi system. An unsupervised
transliteration model is learned from the word-
alignments of Urdu-Hindi parallel data. We were
able to extract around 2800 transliteration pairs.
To learn a richer transliteration model, we addi-
tionally fed the interpolated phrase-table, as de-
scribed above, to the transliteration miner. We
were able to mine additional 21000 translitera-
tion pairs and built a Urdu-Hindi character-based
model from it. The transliteration module can
be used to translate the 50K OOV words but
previous research (Durrani et al., 2010; Nakov
and Tiedemann, 2012) has shown that translit-
eration is useful for more than just translating
OOV words when translating closely related lan-
guage pairs. To fully capitalize on the large over-
lap in Hindi–Urdu vocabulary, we transliterated
each word in the Urdu test-data into Hindi and
produced a phrase-table with 100-best transliter-
ations. The two synthesized (triangulated and
transliterated) phrase-tables are then used along
with the baseline Urdu-to-Hindi phrase-table in
a log-linear model. Detailed results on Urdu-to-
Hindi baseline and improvements obtained from
using transliteration and triangulated phrase-tables
are presented in Durrani and Koehn (2014). Using
our best Urdu-to-Hindi system, we translated the
Urdu part of the multi-indic corpus to form Hindi-
English parallel data. Table 4 shows results from
using the synthesized Hindi-English corpus in iso-
lation (Syn) and on top of the baseline system
</bodyText>
<table confidence="0.7475515">
(Bo + Syn).
Pair Bo Syn Δ Bo + Syn Δ
14.28 10.49 -3.79 14.72 +0.44
10.59 9.01 -1.58 11.76 +1.17
</table>
<tableCaption confidence="0.933836333333333">
Table 4: Evaluating Synthesized (Syn) Hindi-
English Parallel Data, Bo = System without Syn-
thesized Data
</tableCaption>
<subsectionHeader confidence="0.992686">
1.5 Huge Language Models
</subsectionHeader>
<bodyText confidence="0.999970105263158">
Our unconstrained submissions use an additional
language model trained on web pages from the
2012, 2013, and winter 2013 CommonCrawl.2
The additional language model is the only differ-
ence between the constrained and unconstrained
submissions; we did not use additional parallel
data. These language models were trained on text
provided by the CommonCrawl foundation, which
they converted to UTF-8 after stripping HTML.
Languages were detected using the Compact Lan-
guage Detection 23 and, except for Hindi where
we lack tools, sentences were split with the Eu-
roparl sentence splitter (Koehn, 2005). All text
was then deduplicated, minimizing the impact of
boilerplate, such as social media sharing buttons.
We then tokenized and truecased the text as usual.
Statistics are shown in Table 5. A full description
of the pipeline, including a public data release, ap-
pears in Buck et al. (2014).
</bodyText>
<table confidence="0.962405">
Lang Lines (B) Tokens (B) Bytes
en 59.13 975.63 5.14 TiB
de 3.87 51.93 317.46 GiB
fr 3.04 49.31 273.96 GiB
ru 1.79 21.41 220.62 GiB
cs 0.47 5.79 34.67 GiB
hi 0.01 0.28 3.39 GiB
</table>
<tableCaption confidence="0.996753">
Table 5: Size of huge language model training data
</tableCaption>
<bodyText confidence="0.908696">
We built unpruned modified Kneser-Ney lan-
guage models using lmplz (Heafield et al., 2013).
</bodyText>
<footnote confidence="0.9937135">
2http://commoncrawl.org
3https://code.google.com/p/cld2/
</footnote>
<bodyText confidence="0.5594995">
hi-en
en-hi
</bodyText>
<page confidence="0.967937">
99
</page>
<table confidence="0.993334076923077">
Pair Bo +L
newstest 2013 2014
2013 2014
– 20.61 +0.51
20.03 +0.64 21.60 +0.60
20.80 +0.90 29.90 +1.20
12.83 +1.40 12.50 +1.40
– 14.80 +0.90
en-de 20.85 20.10
en-cs 19.39 21.00
en-ru 19.90 28.70
en-hi 11.43 11.10
hi-en 15.48 13.90
</table>
<tableCaption confidence="0.8165335">
Table 6: Gains obtained by using huge language
models – Bo = Baseline, +L = Adding Huge LM
</tableCaption>
<bodyText confidence="0.999693266666666">
While the Hindi and Czech models are small
enough to run directly, models for other languages
are quite large.We therefore created a filter that op-
erates directly on files in KenLM trie binary for-
mat, preserving only n-grams whose words all ap-
pear in the target side vocabulary of at least one
source sentence. For example, an English lan-
guage model trained on just the 2012 and 2013
crawls takes 3.5 TB without any quantization. Af-
ter filtering to the Hindi-English tuning set, the
model fit in 908 GB, again without quantization.
We were then able to tune the system on a machine
with 1 TB RAM. Results are shown in Table 6; we
did not submit to English-French because the sys-
tem takes too long to tune.
</bodyText>
<subsectionHeader confidence="0.94497">
1.6 Miscellaneous
</subsectionHeader>
<bodyText confidence="0.9996125">
Hindi-English: 1) A large number of Hindi sen-
tences in the Hindi-English parallel corpus were
ending with a full-stop “.”, although the end-of-
the-sentence marker in Hindi is “Danda” (1). Re-
placing full-stops with Danda gave improvement
of +0.20 for hi-en and +0.40 in en-hi. 2) Using
Wiki subtitles did not give any improvement in
BLEU and were in fact harmful for the en-hi di-
rection.
Russian-English: We tried to improve word-
alignments by integrating a transliteration sub-
model into GIZA++ word aligner. The probabil-
ity of a word pair is calculated as an interpola-
tion of the transliteration probability and transla-
tion probability stored in the t-table of the differ-
ent alignment models used by the GIZA++ aligner.
This interpolation is done for all iterations of all
alignment models (See Sajjad et al. (2013) for de-
tails). Due to shortage of time we could only run it
for Russian-to-English. The improved alignments
gave a gain of +0.21 on news-test 2013 and +0.40
on news-test 2014.
</bodyText>
<tableCaption confidence="0.853411166666667">
avg +.03
Table 7: Comparison of fast word alignment
method (Dyer et al., 2013) against GIZA++
(WMT 2013 data condition, test on new-
stest2012). The method was not used in the official
submission.
</tableCaption>
<table confidence="0.998568083333334">
Baseline MSD Hier. MSD Hier. MSLR
27.04 27.10 +.06 27.17 +.13
31.63 - 31.65 +.02
31.20 31.14 –.06 31.25 +.05
26.11 26.32 +.21 26.26 +.15
24.09 24.01 –.08 24.19 +.11
20.43 20.34 –.09 20.32 -.11
30.54 - 30.52 –.02
30.36 30.44 +.08 30.51 +.15
18.53 18.59 +.06 18.66 +.13
18.37 18.47 +.10 18.19 –.18
avg + .035 +.045
</table>
<tableCaption confidence="0.932822">
Table 8: Hierarchical lexicalized reordering model
(Galley and Manning, 2008).
</tableCaption>
<bodyText confidence="0.9972644">
Fast align: In preliminary experiments, we
compared the fast word alignment method by
Dyer et al. (2013) against our traditional use of
GIZA++. Results are quite mixed (Table 7), rang-
ing from a gain of +.35 for Russian-English to a
loss of –.19 for Czech-English. We stayed with
GIZA++ for all of our other experiments.
Hierarchical lexicalized reordering model:
We explored the use of the hierarchical lexicalized
reordering model (Galley and Manning, 2008)
in two variants: using the same orientations as
our traditional model (monotone, discontinuous,
swap), and one that distinguishes the discontin-
uous orientations to the left and right. Table 8
shows slight improvements with these models, so
we used them in our baseline.
Threshold filtering of phrase table: We exper-
imented with discarding some phrase table entry
due to their low probability. We found that phrase
translations with the phrase translation probability
</bodyText>
<table confidence="0.684319095238095">
Pair
de-en
fr-en
es-en
cs-en
ru-en
en-de
en-fr
en-es
en-cs
en-ru
Pair GIZA++ Fast Align Δ
de-en 24.02 23.89 –.13
fr-en 30.78 30.66 –.12
es-en 34.07 34.24 +.17
cs-en 22.63 22.44 –.19
ru-en 31.68 32.03 +.35
en-de 18.04 17.88 –.16
en-fr 28.96 28.83 –.13
en-es 34.15 34.32 +.17
en-cs 15.70 16.02 +.32
</table>
<page confidence="0.389935">
100
</page>
<note confidence="0.607201">
O(f|e)&lt;10−4 can be safely discarded with almost
</note>
<bodyText confidence="0.9975836">
no change in translations. However, discarding
phrase translations with the inverse phrase transla-
tion probability O(e|f)&lt;10−4 is more risky, espe-
cially with morphologically rich target languages,
so we kept those.
</bodyText>
<subsectionHeader confidence="0.981425">
1.7 Summary
</subsectionHeader>
<bodyText confidence="0.999481857142857">
Table 9 shows cumulative gains obtained from us-
ing word classes, transliteration and big language
models4 over the baseline system. Our German-
English constrained systems were used for EU-
Bridge system combination, a collaborative effort
to improve the state-of-the-art in machine transla-
tion (See Freitag et al. (2014) for details).
</bodyText>
<figure confidence="0.973912368421053">
from English into English
Lang B0 B1 Δ B0 B1 Δ
Data Set
coppa-in
PatTR-in-claims
PatTR-in-abstract
PatTR-in-titles
UMLS
MuchMore
EMEA
WikiTitles
PatTR-out
coppa-out
MultiUN
czeng
europarl
news-comm
commoncrawl
FrEnGiga
</figure>
<bodyText confidence="0.659169">
Table 10: Parallel data sets used in the medical
translation task. The sets above the line were clas-
sified as “in-domain” and those below as “out-of-
domain”.
</bodyText>
<figure confidence="0.932612631578947">
cs-en de-en fr-en
n n y
n y y
n y y
n y y
y y y
n y n
y y y
y y y
n y y
n n y
n n y
y n n
y y y
y y y
y y y
n n y
20.44 20.85 +0.41 27.24 27.44 +0.20
18.84 20.03 +1.19 26.42 26.42 ±0.00
30.73 30.82 +0.09 31.64 31.76 +0.12
18.78 20.81 +2.03 24.45 25.21 +0.76
9.27 12.83 +3.56 14.08 15.48 +1.40
Table 9: Cumulative gains obtained for each lan-
guage – B0 = Baseline, B1 = Best System
de
cs
fr
ru
hi
Data Set cs de en fr
PIL n n y n
DrugBank n n y n
WikiArticles y y y y
PatTR-in-description n y y y
GENIA n n y n
FMA n n y n
AACT n n y n
PatTR-out-description n y y y
</figure>
<sectionHeader confidence="0.976495" genericHeader="general terms">
2 Medical Translation Task
</sectionHeader>
<bodyText confidence="0.999813714285714">
For the medical translation task, the organisers
supplied several medical domain corpora (detailed
on the task website), as well some out-of-domain
patent data, and also all the data available for the
constrained track of the news translation task was
permitted. In general, we attempted to use all of
this data, except for the LDC Gigaword language
model data (for reasons of time) and we divided
the data into “in-domain” and “out-of-domain”
corpora. The data sets are summarised in Tables
10 and 11.
In order to create systems for the medical trans-
lation tasks, we used phrase-based Moses with ex-
actly the same settings as for the news translation
task, including the OSM (Durrani et al., 2011),
and compound splitting Koehn and Knight (2003)
for German source. We did not use word clusters
(Section 1.2), as they did not give good results on
this task, but we have yet to find a reason for this.
For language model training, we decided not to
build separate models on each corpus as there was
</bodyText>
<footnote confidence="0.9693705">
4Cumulative gains do not include gains obtain from big
language models for hi-en and en-de.
</footnote>
<bodyText confidence="0.987923391304348">
Table 11: Additional monolingual data used in
the medical translation task. Those above the line
were classified as “in-domain” and the one below
as “out-of-domain”. We also used the target sides
of all the parallel corpora for language modelling.
a large variation in corpus sizes. Instead we con-
catenated the in-domain target sides with the in-
domain extra monolingual data to create training
data for an in-domain language model, and simi-
larly for the out-of-domain data. The two language
models were interpolated using SRILM, minimis-
ing perplexity on the Khresmoi summary develop-
ment data.
During system development, we only had 500
sentences of development data (SUMMARY-DEV)
from the Khresmoi project, so we decided to se-
lect further development and devtest data from the
EMEA corpus, reasoning that it was fairly close
in domain to SUMMARY-DEV. We selected a tun-
ing set (5000 sentence pairs, which were added to
SUMMARY-DEV) and a devtest set (3000 sentence
pairs) from EMEA after first de-duplicating it, and
ignoring sentence pairs which were too short, or
</bodyText>
<page confidence="0.997668">
101
</page>
<bodyText confidence="0.999903740740741">
contained too many capital letters or numbers. The
EMEA contains many duplicated sentences, and
we removed all sentence pairs where either side
was a duplicate, reducing the size of the corpus
to about 25% of the original. We also removed
EMEA from Czeng, since otherwise it would over-
lap with our selected development sets.
We also experimented with modified Moore-
Lewis (Moore and Lewis, 2010; Axelrod et al.,
2011) data selection, using the EMEA corpus as
the in-domain corpus (for the language model re-
quired in MML) and selecting from all the out-of-
domain data.
When running on the final test set (SUMMARY-
TEST) we found that it was better to tune just on
SUMMARY-DEV, even though it was much smaller
than the EMEA dev set we had selected. All but
two (cs-en, de-en) of our submitted systems used
the MML selection, because it worked better on
our EMEA devtest set. However, as can be seen
from Table 12, systems built with all the data gen-
erally perform better. We concluded that EMEA
was not a good representative of the Khresmoi
data, perhaps because of domain differences, or
perhaps just because of the alignment noise that
appears (from informal inspection) to be present
in EMEA.
</bodyText>
<table confidence="0.499095">
de 18.59 20.88 – 36.17 – 38.57
cs 18.78 23.45 23.77 30.12 – 36.32
fr 35.24 40.74 41.04 45.15 46.44 46.58
</table>
<tableCaption confidence="0.575783">
Table 12: Results (cased BLEU) on the khresmoi
</tableCaption>
<bodyText confidence="0.9988941875">
summary test set. The “in” systems include all
in-domain data, the “in+20” systems also include
20% of the out-of-domain data and the “out” sys-
tems include all data. The submitted systems are
shown in italics, except for de-en and cs-en where
we submitted a “in+out” systems. For de-en, this
was tuned on SUMMARY-DEV plus the EMEA dev
set and scored 37.31, whilst for cs-en we included
LDC Giga in the LM, and scored 36.65.
For translating the Khresmoi queries, we used
the same systems as for the summaries, except that
generally we did not retune on the SUMMARY-DEV
data. We added a post-processing script to strip
out extraneous stop words, which improved BLEU,
but we would not expect it to matter in a real CLIR
system as it would do its own stop-word removal.
</bodyText>
<sectionHeader confidence="0.985217" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997403133333333">
The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreements n◦ 287658 (EU-BRIDGE),
n◦ 287688 (MateCat) and n◦ 288769 (ACCEPT).
Huge language model experiments made use of
the Stampede supercomputer provided by the
Texas Advanced Computing Center (TACC) at
The University of Texas at Austin under NSF
XSEDE allocation TG-CCR140009. We also ac-
knowledge the support of the Defense Advanced
Research Projects Agency (DARPA) Broad Op-
erational Language Translation (BOLT) program
through IBM. This publication only reflects the
authors’ views.
</bodyText>
<sectionHeader confidence="0.931142" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.93848695">
Axelrod, A., He, X., and Gao, J. (2011). Domain
adaptation via pseudo in-domain data selection.
In Proceedings of the 2011 Conference on Em-
pirical Methods in Natural Language Process-
ing, pages 355–362, Edinburgh, Scotland, UK.
Association for Computational Linguistics.
Baker, P., Hardie, A., McEnery, T., Cunningham,
H., and Gaizauskas, R. J. (2002). EMILLE,
a 67-million word corpus of indic languages:
Data collection, mark-up and harmonisation. In
LREC.
Birch, A., Durrani, N., and Koehn, P. (2013). Ed-
inburgh SLT and MT system description for the
IWSLT 2013 evaluation. In Proceedings of the
10th International Workshop on Spoken Lan-
guage Translation, pages 40–48, Heidelberg,
Germany.
Blunsom, P. and Osborne, M. (2008). Probabilis-
tic inference for machine translation. In Pro-
ceedings of the 2008 Conference on Empiri-
</bodyText>
<reference confidence="0.9737955">
cal Methods in Natural Language Processing,
pages 215–223, Honolulu, Hawaii. Association
for Computational Linguistics.
Bojar, O., Buck, C., Callison-Burch, C., Feder-
mann, C., Haddow, B., Koehn, P., Monz, C.,
Post, M., Soricut, R., and Specia, L. (2013).
Findings of the 2013 workshop on statistical
machine translation. In Eighth Workshop on
Statistical Machine Translation, WMT-2013,
pages 1–44, Sofia, Bulgaria.
Bojar, O., Diatka, V., Rychl´y, P., Straˇn´ak, P.,
Tamchyna, A., and Zeman, D. (2014). Hindi-
</reference>
<bodyText confidence="0.407259">
from English into English
in in+20 in+out in in+20 in+out
</bodyText>
<page confidence="0.982989">
102
</page>
<reference confidence="0.94643722">
English and Hindi-only Corpus for Machine
Translation. In Proceedings of the Ninth In-
ternational Language Resources and Evalua-
tion Conference (LREC’14), Reykjavik, Ice-
land. ELRA, European Language Resources
Association. in prep.
Buck, C., Heafield, K., and van Ooyen, B. (2014).
N-gram counts and language models from the
common crawl. In Proceedings of the Language
Resources and Evaluation Conference, Reyk-
javik, Iceland.
Chiang, D., Knight, K., and Wang, W. (2009).
11,001 New Features for Statistical Machine
Translation. In Proceedings of Human Lan-
guage Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the As-
sociation for Computational Linguistics, pages
218–226, Boulder, Colorado. Association for
Computational Linguistics.
Collins, M., Koehn, P., and Kucerova, I. (2005).
Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual
Meeting of the Association for Computational
Linguistics (ACL’05), pages 531–540, Ann Ar-
bor, Michigan. Association for Computational
Linguistics.
Durrani, N., Fraser, A., Schmid, H., Hoang, H.,
and Koehn, P. (2013a). Can markov mod-
els over minimal translation units help phrase-
based SMT? In Proceedings of the 51st An-
nual Meeting of the Association for Computa-
tional Linguistics, Sofia, Bulgaria. Association
for Computational Linguistics.
Durrani, N., Haddow, B., Heafield, K., and Koehn,
P. (2013b). Edinburgh’s machine translation
systems for european language pairs. In Pro-
ceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria. Associa-
tion for Computational Linguistics.
Durrani, N. and Koehn, P. (2014). Improving ma-
chine translation via triangulation and transliter-
ation. In Proceedings of the 17th Annual Con-
ference of the European Association for Ma-
chine Translation (EAMT), Dubrovnik, Croatia.
Durrani, N., Koehn, P., Schmid, H., and Fraser,
A. (2014a). Investigating the usefulness of
generalized word representations in SMT. In
Proceedings of the 25th Annual Conference on
Computational Linguistics (COLING), Dublin,
Ireland. To Appear.
Durrani, N., Sajjad, H., Fraser, A., and Schmid,
H. (2010). Hindi-to-urdu machine translation
through transliteration. In Proceedings of the
48th Annual Meeting of the Association for
Computational Linguistics, pages 465–474, Up-
psala, Sweden. Association for Computational
Linguistics.
Durrani, N., Sajjad, H., Hoang, H., and Koehn, P.
(2014b). Integrating an unsupervised translit-
eration model into statistical machine transla-
tion. In Proceedings of the 15th Conference of
the European Chapter of the ACL (EACL 2014),
Gothenburg, Sweden. Association for Compu-
tational Linguistics.
Durrani, N., Schmid, H., and Fraser, A. (2011).
A joint sequence translation model with inte-
grated reordering. In Proceedings of the 49th
Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Tech-
nologies, pages 1045–1054, Portland, Oregon,
USA.
Dyer, C., Chahuneau, V., and Smith, N. A. (2013).
A simple, fast, and effective reparameterization
of ibm model 2. In Proceedings of the 2013
Conference of the North American Chapter of
the Association for Computational Linguistics:
Human Language Technologies, pages 644–
648, Atlanta, Georgia. Association for Compu-
tational Linguistics.
Freitag, M., Peitz, S., Wuebker, J., Ney, H., Huck,
M., Sennrich, R., Durrani, N., Nadejde, M.,
Williams, P., Koehn, P., Herrmann, T., Cho,
E., and Waibel, A. (2014). EU-BRIDGE MT:
combined machine translation. In Proceedings
of the ACL 2014 Ninth Workshop on Statistical
Machine Translation, Baltimore, MD, USA.
Galley, M. and Manning, C. D. (2008). A sim-
ple and effective hierarchical phrase reorder-
ing model. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 848–856, Honolulu,
Hawaii.
Heafield, K. (2011). Kenlm: Faster and smaller
language model queries. In Proceedings of the
Sixth Workshop on Statistical Machine Trans-
lation, pages 187–197, Edinburgh, Scotland,
United Kingdom.
Heafield, K., Pouzyrevsky, I., Clark, J. H., and
Koehn, P. (2013). Scalable modified Kneser-
Ney language model estimation. In Proceedings
</reference>
<page confidence="0.988426">
103
</page>
<reference confidence="0.995791736263736">
of the 51st Annual Meeting of the Association
for Computational Linguistics, Sofia, Bulgaria.
Huang, L. and Chiang, D. (2007). Forest rescor-
ing: Faster decoding with integrated language
models. In Proceedings of the 45th Annual
Meeting of the Association of Computational
Linguistics, pages 144–151, Prague, Czech Re-
public. Association for Computational Linguis-
tics.
Koehn, P. (2005). Europarl: A parallel corpus for
statistical machine translation. In Proceedings
of MT Summit.
Koehn, P. and Haddow, B. (2009). Edinburgh’s
Submission to all Tracks of the WMT 2009
Shared Task with Reordering and Speed Im-
provements to Moses. In Proceedings of the
Fourth Workshop on Statistical Machine Trans-
lation, pages 160–164, Athens, Greece. Associ-
ation for Computational Linguistics.
Koehn, P. and Hoang, H. (2007). Factored trans-
lation models. In Proceedings of the 2007
Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL),
pages 868–876, Prague, Czech Republic. Asso-
ciation for Computational Linguistics.
Koehn, P., Hoang, H., Birch, A., Callison-Burch,
C., Federico, M., Bertoldi, N., Cowan, B.,
Shen, W., Moran, C., Zens, R., Dyer, C., Bo-
jar, O., Constantin, A., and Herbst, E. (2007).
Moses: Open source toolkit for statistical ma-
chine translation. In ACL 2007 Demonstrations,
Prague, Czech Republic.
Koehn, P. and Knight, K. (2003). Empirical meth-
ods for compound splitting. In Proceedings of
Meeting of the European Chapter of the Associ-
ation of Computational Linguistics (EACL).
Kumar, S. and Byrne, W. J. (2004). Mini-
mum bayes-risk decoding for statistical ma-
chine translation. In HLT-NAACL, pages 169–
176.
Moore, R. C. and Lewis, W. (2010). Intelligent
selection of language model training data. In
Proceedings of the ACL 2010 Conference Short
Papers, pages 220–224, Uppsala, Sweden. As-
sociation for Computational Linguistics.
Nakov, P. and Tiedemann, J. (2012). Combining
word-level and character-level models for ma-
chine translation between closely-related lan-
guages. In Proceedings of the 50th Annual
Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers), pages
301–305, Jeju Island, Korea. Association for
Computational Linguistics.
Och, F. J. (1999). An efficient method for deter-
mining bilingual word classes. In Ninth Confer-
ence the European Chapter of the Association
for Computational Linguistics (EACL), pages
71–76.
Post, M., Callison-Burch, C., and Osborne, M.
(2012). Constructing parallel corpora for six in-
dian languages via crowdsourcing. In Proceed-
ings of the Seventh Workshop on Statistical Ma-
chine Translation, pages 401–409, Montr´eal,
Canada. Association for Computational Lin-
guistics.
Sajjad, H., Smekalova, S., Durrani, N., Fraser, A.,
and Schmid, H. (2013). QCRI-MES submis-
sion at wmt13: Using transliteration mining to
improve statistical machine translation. In Pro-
ceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria. Associa-
tion for Computational Linguistics.
Schwenk, H. and Koehn, P. (2008). Large and di-
verse language models for statistical machine
translation. In International Joint Conference
on Natural Language Processing, pages 661–
666.
Utiyama, M. and Isahara, H. (2007). A compar-
ison of pivot methods for phrase-based statis-
tical machine translation. In 2007 Meeting of
the North American Chapter of the Association
for Computational Linguistics (NAACL), pages
484–491.
Wu, H. and Wang, H. (2007). Pivot language
approach for phrase-based statistical machine
translation. In Proceedings of the 45th Annual
Meeting of the Association of Computational
Linguistics, pages 856–863, Prague, Czech Re-
public. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.99878">
104
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.904057">Edinburgh’s Phrase-based Machine Translation Systems for WMT-14</title>
<author confidence="0.991744">Nadir Durrani Barry Haddow Philipp</author>
<affiliation confidence="0.8633136">School of University of Kenneth Computer Science Stanford</affiliation>
<email confidence="0.999706">heafield@cs.stanford.edu</email>
<abstract confidence="0.961857021212121">This paper describes the University of Edinburgh’s (UEDIN) phrase-based submissions to the translation and medical translation shared tasks of the 2014 Workshop on Statistical Machine Translation (WMT). We participated in all language pairs. We have improved upon our 2013 system by i) using generalized representations, specifically automatic word clusters for translations out of English, ii) using unsupervised character-based models to translate unknown words in Russian- English and Hindi-English pairs, iii) synthesizing Hindi data from closely-related Urdu data, and iv) building huge language on the common crawl corpus. 1 Translation Task Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013). The notable features of these systems are described in the following section. The experiments that we carried out for this year’s translation task are described in the following sections. 1.1 Baseline We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for German- English language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 2013 for the dev experiments. For Russian- English pairs news-test 2012 was used for tuning and for Hindi-English pairs, we divided the newsdev 2014 into two halves, used the first half for tuning and second for dev experiments. 1.2 Using Generalized Word Representations We explored the use of automatic word clusters in phrase-based models (Durrani et al., 2014a). computed the clusters with GIZA++’s (Och, 1999) on the source and target side of the parallel training corpus. Clusters are word classes that are optimized to reduce n-gram perplexity. By generating a cluster identifier for each output word, we are able to add an n-gram model 97 of the Ninth Workshop on Statistical Machine pages Maryland USA, June 26–27, 2014. Association for Computational Linguistics over these identifiers as an additional scoring function. The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn et al., 2007). The n-gram model is trained in the similar way as the regular language model. We trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the tuning set (Schwenk and Koehn, 2008). We also trained OSM models over cluster-ids The lexically driven OSM model falls back to very small context sizes of two to three operations due to data sparsity. Learning operation sequences over cluster-ids enables us to learn richer translation and reordering patterns that can generalize better in sparse data conditions. Table 1 shows gains from adding target LM and OSM models over cluster-ids. Using word clusters was found more useful translating from English-to-*. from English into English 20.60 20.85 +0.25 27.44 27.34 -0.10 18.84 19.39 +0.55 26.42 26.42 30.73 30.82 +0.09 31.64 31.76 +0.12 18.78 19.67 +0.89 24.45 24.63 +0.18 10.39 10.52 +0.13 15.48 15.26 -0.22 Table 1: Using Word Clusters in Phrase-based and models – System without Clusters, with Cluster We also trained OSM models over POS and morph tags. For the English-to-German system we added an OSM model over [pos, morph] (source:pos, target:morph) and for the Germanto-English system we added an OSM model over [morph,pos] (source:morph, target:pos), a configuration that was found to work best in our previous experiments (Birch et al., 2013). Table 2 shows gains from additionally using OSM models over POS/morph tags. Table 2: Using POS and Morph Tags in models – Baseline, POS/Morph-based OSM 1.3 Unsupervised Transliteration Model Last year, our Russian-English systems performed badly on the human evaluation. In comparison other participants that used transliteration did well. We could not train a transliteration system due to unavailability of a transliteration training data. This year we used an EM-based method to induce unsupervised transliteration models (Durrani et al., 2014b). We extracted transliteration pairs automatically from the word-aligned parallel data and used it to learn a transliteration system. We then built transliteration phrase-tables for translating OOV words and used the post-decoding method (Method 2 as described in the paper) to translate these. Training OOV 0 Table 3: Using Unsupervised Transliteration Model – Training = Extracted Transliteration Corpus (types), OOV = Out-of-vocabulary words (to- System without Transliteration, = Transliterating OOVs Table 3 shows the number (types) of transliteration pairs extracted using unsupervised mining, number of OOV words (tokens) in each pair and the gains achieved by transliterating unknown words. 1.4 Synthesizing Hindi Data from Urdu Hindi and Urdu are closely related language pairs that share grammatical structure and have a large overlap in vocabulary. This provides a strong motivation to transform any Urdu-English parallel data into Hindi-English by translating the Urdu part into Hindi. We made use of the Urdu-English segment of the Indic multi-parallel corpus (Post et al., 2012) which contains roughly 87K sentence pairs. The Hindi-English segment of this corpus is a subset of parallel data made available for the translation task but is completely disjoint from the Urdu-English segment. We initially trained a Urdu-to-Hindi SMT sysusing a very tiny corpus (Baker corpus contains roughly 12000 sentences of Hindi and Urdu comparable data. From these we were able to sentence align 7000 sentences to build an Urdu-to-Hindi system. en-de 20.44 20.60 +0.16 de-en 27.24 27.44 +0.20 232K 1356 24.63 25.06 +0.41 232K 681 19.67 19.91 +0.24 38K 503 14.67 15.48 +0.81 38K 394 11.76 12.83 +1.07 ru-en en-ru hi-en en-hi de cs fr ru hi 98 et al., 2002). But we found this system to be useless for translating the Urdu part of Indic data due to domain mismatch and huge number of OOV words (approximately 310K tokens). To reduce sparsity we synthesized additional phrase-tables using interpolation and transliteration. trained two phrase translatables from Urdu- English (Indic corpus) and Hindi-English (HindEnCorp (Bojar et al., 2014)) bilingual corpora. Given the phrase-table for Urdu-English the phrase-table for English-Hindi we estimated a Urdu-Hindi phrase-table the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007): = The number of entries in the baseline Urdu-to- Hindi phrase-table were approximately 254K. Using interpolation we were able to build a phrasetable containing roughly 10M phrases. This reduced the number of OOV tokens from 310K to approximately 50K. and Hindi are written in different scripts (Arabic and Devanagri respectively). We added a transliteration component to our Urdu-to-Hindi system. An unsupervised transliteration model is learned from the wordalignments of Urdu-Hindi parallel data. We were able to extract around 2800 transliteration pairs. To learn a richer transliteration model, we additionally fed the interpolated phrase-table, as described above, to the transliteration miner. We were able to mine additional 21000 transliteration pairs and built a Urdu-Hindi character-based model from it. The transliteration module can be used to translate the 50K OOV words but previous research (Durrani et al., 2010; Nakov and Tiedemann, 2012) has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs. To fully capitalize on the large overlap in Hindi–Urdu vocabulary, we transliterated each word in the Urdu test-data into Hindi and produced a phrase-table with 100-best transliterations. The two synthesized (triangulated and transliterated) phrase-tables are then used along with the baseline Urdu-to-Hindi phrase-table in a log-linear model. Detailed results on Urdu-to- Hindi baseline and improvements obtained from using transliteration and triangulated phrase-tables are presented in Durrani and Koehn (2014). Using our best Urdu-to-Hindi system, we translated the Urdu part of the multi-indic corpus to form Hindi- English parallel data. Table 4 shows results from using the synthesized Hindi-English corpus in isoand on top of the baseline system 14.28 10.49 -3.79 14.72 +0.44 10.59 9.01 -1.58 11.76 +1.17 Table 4: Evaluating Synthesized (Syn) Hindi- Parallel Data, System without Synthesized Data 1.5 Huge Language Models Our unconstrained submissions use an additional language model trained on web pages from the 2013, and winter 2013 The additional language model is the only difference between the constrained and unconstrained submissions; we did not use additional parallel data. These language models were trained on text provided by the CommonCrawl foundation, which they converted to UTF-8 after stripping HTML. Languages were detected using the Compact Lan- Detection except for Hindi where we lack tools, sentences were split with the Europarl sentence splitter (Koehn, 2005). All text was then deduplicated, minimizing the impact of boilerplate, such as social media sharing buttons. We then tokenized and truecased the text as usual. Statistics are shown in Table 5. A full description of the pipeline, including a public data release, appears in Buck et al. (2014). Lang Lines (B) Tokens (B) Bytes en 59.13 975.63 de 3.87 51.93 fr 3.04 49.31 ru 1.79 21.41 cs 0.47 5.79 hi 0.01 0.28 Table 5: Size of huge language model training data We built unpruned modified Kneser-Ney language models using lmplz (Heafield et al., 2013). hi-en en-hi 99 newstest 2013 2014 2013 2014 – 20.61 +0.51 20.03 +0.64 21.60 +0.60 20.80 +0.90 29.90 +1.20 12.83 +1.40 12.50 +1.40 – 14.80 +0.90 en-de 20.85 20.10 en-cs 19.39 21.00 en-ru 19.90 28.70 en-hi 11.43 11.10 hi-en 15.48 13.90 Table 6: Gains obtained by using huge language – Baseline, Adding Huge LM While the Hindi and Czech models are small enough to run directly, models for other languages are quite large.We therefore created a filter that operates directly on files in KenLM trie binary forpreserving only whose words all appear in the target side vocabulary of at least one source sentence. For example, an English language model trained on just the 2012 and 2013 crawls takes 3.5 TB without any quantization. After filtering to the Hindi-English tuning set, the model fit in 908 GB, again without quantization. We were then able to tune the system on a machine with 1 TB RAM. Results are shown in Table 6; we did not submit to English-French because the system takes too long to tune. 1.6 Miscellaneous A large number of Hindi sentences in the Hindi-English parallel corpus were ending with a full-stop “.”, although the end-ofmarker in Hindi is “Danda” Replacing full-stops with Danda gave improvement of +0.20 for hi-en and +0.40 in en-hi. 2) Using Wiki subtitles did not give any improvement in BLEU and were in fact harmful for the en-hi direction. tried to improve wordalignments by integrating a transliteration submodel into GIZA++ word aligner. The probability of a word pair is calculated as an interpolation of the transliteration probability and translation probability stored in the t-table of the different alignment models used by the GIZA++ aligner. This interpolation is done for all iterations of all alignment models (See Sajjad et al. (2013) for details). Due to shortage of time we could only run it for Russian-to-English. The improved alignments gave a gain of +0.21 on news-test 2013 and +0.40 on news-test 2014. avg +.03 Table 7: Comparison of fast word alignment method (Dyer et al., 2013) against GIZA++ (WMT 2013 data condition, test on newstest2012). The method was not used in the official submission.</abstract>
<address confidence="0.495106666666667">Baseline MSD Hier. MSD Hier. MSLR 27.04 27.10 +.06 27.17 +.13 31.63 - 31.65 +.02</address>
<phone confidence="0.515405142857143">31.20 31.14 –.06 31.25 +.05 26.11 26.32 +.21 26.26 +.15 24.09 24.01 –.08 24.19 +.11 20.43 20.34 –.09 20.32 -.11 30.54 - 30.52 –.02 30.36 30.44 +.08 30.51 +.15 18.53 18.59 +.06 18.66 +.13</phone>
<abstract confidence="0.986644833333334">18.37 18.47 +.10 18.19 –.18 avg + .035 +.045 Table 8: Hierarchical lexicalized reordering model (Galley and Manning, 2008). align: preliminary experiments, we compared the fast word alignment method by Dyer et al. (2013) against our traditional use of GIZA++. Results are quite mixed (Table 7), ranging from a gain of +.35 for Russian-English to a loss of –.19 for Czech-English. We stayed with GIZA++ for all of our other experiments. Hierarchical lexicalized reordering model: We explored the use of the hierarchical lexicalized reordering model (Galley and Manning, 2008) in two variants: using the same orientations as traditional model discontinuous, and one that distinguishes the discontinto the Table 8 shows slight improvements with these models, so we used them in our baseline. filtering of phrase table: experimented with discarding some phrase table entry due to their low probability. We found that phrase translations with the phrase translation probability Pair de-en fr-en es-en cs-en ru-en en-de en-fr en-es en-cs en-ru GIZA++ Fast Align de-en 24.02 23.89 –.13 fr-en 30.78 30.66 –.12 es-en 34.07 34.24 +.17 cs-en 22.63 22.44 –.19 ru-en 31.68 32.03 +.35 en-de 18.04 17.88 –.16 en-fr 28.96 28.83 –.13 en-es 34.15 34.32 +.17 en-cs 15.70 16.02 +.32 100 can be safely discarded with almost no change in translations. However, discarding phrase translations with the inverse phrase translaprobability is more risky, especially with morphologically rich target languages, so we kept those. 1.7 Summary Table 9 shows cumulative gains obtained from using word classes, transliteration and big language over the baseline system. Our German- English constrained systems were used for EU- Bridge system combination, a collaborative effort to improve the state-of-the-art in machine translation (See Freitag et al. (2014) for details).</abstract>
<title confidence="0.6893669">from English into English Data Set coppa-in PatTR-in-claims PatTR-in-abstract PatTR-in-titles UMLS MuchMore EMEA WikiTitles</title>
<abstract confidence="0.945342038961039">PatTR-out coppa-out MultiUN czeng europarl news-comm commoncrawl FrEnGiga Table 10: Parallel data sets used in the medical translation task. The sets above the line were classified as “in-domain” and those below as “out-ofdomain”. cs-en n n n n y n y y de-en n y y y y y y y fr-en y y y y y n y y n y y n n y n n y y n n y y y y y y y y y n n y 20.44 20.85 +0.41 27.24 27.44 +0.20 18.84 20.03 +1.19 26.42 26.42 30.73 30.82 +0.09 31.64 31.76 +0.12 18.78 20.81 +2.03 24.45 25.21 +0.76 9.27 12.83 +3.56 14.08 15.48 +1.40 Table 9: Cumulative gains obtained for each lan- – Baseline, Best System de cs fr ru hi Data Set cs de en fr PIL n n y n n n n n n y y n n n y y y y y y y n n y y n n n DrugBank WikiArticles PatTR-in-description GENIA FMA AACT PatTR-out-description n y y y 2 Medical Translation Task For the medical translation task, the organisers supplied several medical domain corpora (detailed on the task website), as well some out-of-domain patent data, and also all the data available for the constrained track of the news translation task was permitted. In general, we attempted to use all of this data, except for the LDC Gigaword language model data (for reasons of time) and we divided the data into “in-domain” and “out-of-domain” corpora. The data sets are summarised in Tables 10 and 11. In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source. We did not use word clusters (Section 1.2), as they did not give good results on this task, but we have yet to find a reason for this. For language model training, we decided not to build separate models on each corpus as there was gains do not include gains obtain from big language models for hi-en and en-de. Table 11: Additional monolingual data used in the medical translation task. Those above the line were classified as “in-domain” and the one below as “out-of-domain”. We also used the target sides of all the parallel corpora for language modelling. a large variation in corpus sizes. Instead we concatenated the in-domain target sides with the indomain extra monolingual data to create training data for an in-domain language model, and similarly for the out-of-domain data. The two language models were interpolated using SRILM, minimising perplexity on the Khresmoi summary development data. During system development, we only had 500 of development data from the Khresmoi project, so we decided to select further development and devtest data from the EMEA corpus, reasoning that it was fairly close domain to We selected a tuning set (5000 sentence pairs, which were added to and a devtest set (3000 sentence pairs) from EMEA after first de-duplicating it, and ignoring sentence pairs which were too short, or 101 contained too many capital letters or numbers. The EMEA contains many duplicated sentences, and we removed all sentence pairs where either side was a duplicate, reducing the size of the corpus to about 25% of the original. We also removed EMEA from Czeng, since otherwise it would overlap with our selected development sets. We also experimented with modified Moore- Lewis (Moore and Lewis, 2010; Axelrod et al., 2011) data selection, using the EMEA corpus as the in-domain corpus (for the language model required in MML) and selecting from all the out-ofdomain data. running on the final test set we found that it was better to tune just on even though it was much smaller than the EMEA dev set we had selected. All but two (cs-en, de-en) of our submitted systems used the MML selection, because it worked better on our EMEA devtest set. However, as can be seen from Table 12, systems built with all the data generally perform better. We concluded that EMEA was not a good representative of the Khresmoi data, perhaps because of domain differences, or perhaps just because of the alignment noise that appears (from informal inspection) to be present in EMEA. de 18.59 20.88 – 36.17 – 38.57 cs 18.78 23.45 23.77 30.12 – 36.32 fr 35.24 40.74 41.04 45.15 46.44 46.58 12: Results (cased on the khresmoi summary test set. The “in” systems include all in-domain data, the “in+20” systems also include 20% of the out-of-domain data and the “out” systems include all data. The submitted systems are shown in italics, except for de-en and cs-en where we submitted a “in+out” systems. For de-en, this tuned on the EMEA dev set and scored 37.31, whilst for cs-en we included LDC Giga in the LM, and scored 36.65. For translating the Khresmoi queries, we used the same systems as for the summaries, except that we did not retune on the data. We added a post-processing script to strip extraneous stop words, which improved but we would not expect it to matter in a real CLIR system as it would do its own stop-word removal. Acknowledgments The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) ungrant agreements 287658 (EU-BRIDGE), (MateCat) and 288769 (ACCEPT). Huge language model experiments made use of the Stampede supercomputer provided by the Texas Advanced Computing Center (TACC) at The University of Texas at Austin under NSF XSEDE allocation TG-CCR140009. We also acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Broad Operational Language Translation (BOLT) program through IBM. This publication only reflects the authors’ views. References Axelrod, A., He, X., and Gao, J. (2011). Domain adaptation via pseudo in-domain data selection. of the 2011 Conference on Empirical Methods in Natural Language Process-</abstract>
<note confidence="0.964762566666667">pages 355–362, Edinburgh, Scotland, UK. Association for Computational Linguistics. Baker, P., Hardie, A., McEnery, T., Cunningham, H., and Gaizauskas, R. J. (2002). EMILLE, a 67-million word corpus of indic languages: Data collection, mark-up and harmonisation. In Birch, A., Durrani, N., and Koehn, P. (2013). Edinburgh SLT and MT system description for the 2013 evaluation. In of the 10th International Workshop on Spoken Lanpages 40–48, Heidelberg, Germany. Blunsom, P. and Osborne, M. (2008). Probabilisinference for machine translation. In Proceedings of the 2008 Conference on Empiri- Methods in Natural Language pages 215–223, Honolulu, Hawaii. Association for Computational Linguistics. Bojar, O., Buck, C., Callison-Burch, C., Federmann, C., Haddow, B., Koehn, P., Monz, C., Post, M., Soricut, R., and Specia, L. (2013). Findings of the 2013 workshop on statistical translation. In Workshop on Machine WMT-2013, pages 1–44, Sofia, Bulgaria. Bojar, O., Diatka, V., Rychl´y, P., Straˇn´ak, P., A., and Zeman, D. (2014). Hindifrom English into English in in+20 in+out in in+20 in+out 102</note>
<title confidence="0.6248126">English and Hindi-only Corpus for Machine In of the Ninth International Language Resources and Evalua- Conference Reykjavik, Iceland. ELRA, European Language Resources</title>
<note confidence="0.775963775">Association. in prep. Buck, C., Heafield, K., and van Ooyen, B. (2014). N-gram counts and language models from the crawl. In of the Language and Evaluation Reykjavik, Iceland. Chiang, D., Knight, K., and Wang, W. (2009). 11,001 New Features for Statistical Machine In of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Asfor Computational pages 218–226, Boulder, Colorado. Association for Computational Linguistics. Collins, M., Koehn, P., and Kucerova, I. (2005). Clause restructuring for statistical machine In of the 43rd Annual Meeting of the Association for Computational pages 531–540, Ann Arbor, Michigan. Association for Computational Linguistics. Durrani, N., Fraser, A., Schmid, H., Hoang, H., and Koehn, P. (2013a). Can markov models over minimal translation units help phrase- SMT? In of the 51st Annual Meeting of the Association for Computa- Sofia, Bulgaria. Association for Computational Linguistics. Durrani, N., Haddow, B., Heafield, K., and Koehn, P. (2013b). Edinburgh’s machine translation for european language pairs. In Proceedings of the Eighth Workshop on Statistical Sofia, Bulgaria. Association for Computational Linguistics. Durrani, N. and Koehn, P. (2014). Improving machine translation via triangulation and transliter- In of the 17th Annual Conference of the European Association for Ma- Translation Dubrovnik, Croatia. Durrani, N., Koehn, P., Schmid, H., and Fraser, A. (2014a). Investigating the usefulness of generalized word representations in SMT. In Proceedings of the 25th Annual Conference on Linguistics Dublin, Ireland. To Appear. Durrani, N., Sajjad, H., Fraser, A., and Schmid, H. (2010). Hindi-to-urdu machine translation transliteration. In of the 48th Annual Meeting of the Association for pages 465–474, Uppsala, Sweden. Association for Computational Linguistics. Durrani, N., Sajjad, H., Hoang, H., and Koehn, P. (2014b). Integrating an unsupervised transliteration model into statistical machine transla- In of the 15th Conference of European Chapter of the ACL (EACL Gothenburg, Sweden. Association for Computational Linguistics. Durrani, N., Schmid, H., and Fraser, A. (2011). A joint sequence translation model with intereordering. In of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Techpages 1045–1054, Portland, Oregon, USA. Dyer, C., Chahuneau, V., and Smith, N. A. (2013). A simple, fast, and effective reparameterization ibm model 2. In of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Language pages 644– 648, Atlanta, Georgia. Association for Computational Linguistics. Freitag, M., Peitz, S., Wuebker, J., Ney, H., Huck, M., Sennrich, R., Durrani, N., Nadejde, M., Williams, P., Koehn, P., Herrmann, T., Cho, E., and Waibel, A. (2014). EU-BRIDGE MT: machine translation. In of the ACL 2014 Ninth Workshop on Statistical</note>
<address confidence="0.7897655">Baltimore, MD, USA. Galley, M. and Manning, C. D. (2008). A sim-</address>
<email confidence="0.248378">pleandeffectivehierarchicalphrasereorder-</email>
<note confidence="0.791527235294118">model. In of the 2008 Conference on Empirical Methods in Natural Lanpages 848–856, Honolulu, Hawaii. Heafield, K. (2011). Kenlm: Faster and smaller model queries. In of the Sixth Workshop on Statistical Machine Transpages 187–197, Edinburgh, Scotland, United Kingdom. Heafield, K., Pouzyrevsky, I., Clark, J. H., and Koehn, P. (2013). Scalable modified Kneserlanguage model estimation. In 103 of the 51st Annual Meeting of the Association Computational Sofia, Bulgaria. Huang, L. and Chiang, D. (2007). Forest rescoring: Faster decoding with integrated language In of the 45th Annual Meeting of the Association of Computational pages 144–151, Prague, Czech Republic. Association for Computational Linguistics. Koehn, P. (2005). Europarl: A parallel corpus for machine translation. In MT Koehn, P. and Haddow, B. (2009). Edinburgh’s Submission to all Tracks of the WMT 2009 Shared Task with Reordering and Speed Imto Moses. In of the Fourth Workshop on Statistical Machine Transpages 160–164, Athens, Greece. Association for Computational Linguistics. Koehn, P. and Hoang, H. (2007). Factored transmodels. In of the 2007</note>
<title confidence="0.667568666666667">Joint Conference on Empirical Methods in Natural Language Processing and Computational Language Learning</title>
<note confidence="0.722403181818182">pages 868–876, Prague, Czech Republic. Association for Computational Linguistics. Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007). Moses: Open source toolkit for statistical matranslation. In 2007 Prague, Czech Republic. Koehn, P. and Knight, K. (2003). Empirical methfor compound splitting. In of Meeting of the European Chapter of the Associof Computational Linguistics Kumar, S. and Byrne, W. J. (2004). Minimum bayes-risk decoding for statistical matranslation. In pages 169– 176. Moore, R. C. and Lewis, W. (2010). Intelligent selection of language model training data. In Proceedings of the ACL 2010 Conference Short pages 220–224, Uppsala, Sweden. Association for Computational Linguistics. Nakov, P. and Tiedemann, J. (2012). Combining word-level and character-level models for matranslation between closely-related lan- In of the 50th Annual Meeting of the Association for Computational (Volume 2: Short pages 301–305, Jeju Island, Korea. Association for Computational Linguistics. Och, F. J. (1999). An efficient method for deterbilingual word classes. In Conference the European Chapter of the Association Computational Linguistics pages 71–76. Post, M., Callison-Burch, C., and Osborne, M. (2012). Constructing parallel corpora for six inlanguages via crowdsourcing. In Proceedings of the Seventh Workshop on Statistical Mapages 401–409, Montr´eal, Canada. Association for Computational Linguistics. Sajjad, H., Smekalova, S., Durrani, N., Fraser, A., and Schmid, H. (2013). QCRI-MES submission at wmt13: Using transliteration mining to statistical machine translation. In Proceedings of the Eighth Workshop on Statistical Sofia, Bulgaria. Association for Computational Linguistics. Schwenk, H. and Koehn, P. (2008). Large and diverse language models for statistical machine In Joint Conference Natural Language pages 661– 666. Utiyama, M. and Isahara, H. (2007). A compar-</note>
<abstract confidence="0.790061583333333">ison of pivot methods for phrase-based statismachine translation. In Meeting of the North American Chapter of the Association Computational Linguistics pages 484–491. Wu, H. and Wang, H. (2007). Pivot language approach for phrase-based statistical machine In of the 45th Annual Meeting of the Association of Computational pages 856–863, Prague, Czech Republic. Association for Computational Linguistics.</abstract>
<intro confidence="0.601644">104</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>cal Methods in Natural Language Processing,</booktitle>
<pages>215--223</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii.</location>
<marker></marker>
<rawString>cal Methods in Natural Language Processing, pages 215–223, Honolulu, Hawaii. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bojar</author>
<author>C Buck</author>
<author>C Callison-Burch</author>
<author>C Federmann</author>
<author>B Haddow</author>
<author>P Koehn</author>
<author>C Monz</author>
<author>M Post</author>
<author>R Soricut</author>
<author>L Specia</author>
</authors>
<date>2013</date>
<booktitle>Findings of the 2013 workshop on statistical machine translation. In Eighth Workshop on Statistical Machine Translation, WMT-2013,</booktitle>
<pages>1--44</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="1106" citStr="Bojar et al., 2013" startWordPosition="153" endWordPosition="156">). We participated in all language pairs. We have improved upon our 2013 system by i) using generalized representations, specifically automatic word clusters for translations out of English, ii) using unsupervised character-based models to translate unknown words in RussianEnglish and Hindi-English pairs, iii) synthesizing Hindi data from closely-related Urdu data, and iv) building huge language on the common crawl corpus. 1 Translation Task Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013). The notable features of these systems are described in the following section. The experiments that we carried out for this year’s translation task are described in the following sections. 1.1 Baseline We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 c</context>
</contexts>
<marker>Bojar, Buck, Callison-Burch, Federmann, Haddow, Koehn, Monz, Post, Soricut, Specia, 2013</marker>
<rawString>Bojar, O., Buck, C., Callison-Burch, C., Federmann, C., Haddow, B., Koehn, P., Monz, C., Post, M., Soricut, R., and Specia, L. (2013). Findings of the 2013 workshop on statistical machine translation. In Eighth Workshop on Statistical Machine Translation, WMT-2013, pages 1–44, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bojar</author>
<author>V Diatka</author>
<author>P Rychl´y</author>
<author>P Straˇn´ak</author>
<author>A Tamchyna</author>
<author>D Zeman</author>
</authors>
<title>HindiEnglish and Hindi-only Corpus for Machine Translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Language Resources and Evaluation Conference (LREC’14), Reykjavik, Iceland. ELRA, European</booktitle>
<note>in prep.</note>
<marker>Bojar, Diatka, Rychl´y, Straˇn´ak, Tamchyna, Zeman, 2014</marker>
<rawString>Bojar, O., Diatka, V., Rychl´y, P., Straˇn´ak, P., Tamchyna, A., and Zeman, D. (2014). HindiEnglish and Hindi-only Corpus for Machine Translation. In Proceedings of the Ninth International Language Resources and Evaluation Conference (LREC’14), Reykjavik, Iceland. ELRA, European Language Resources Association. in prep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Buck</author>
<author>K Heafield</author>
<author>B van Ooyen</author>
</authors>
<title>N-gram counts and language models from the common crawl.</title>
<date>2014</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference,</booktitle>
<location>Reykjavik, Iceland.</location>
<marker>Buck, Heafield, van Ooyen, 2014</marker>
<rawString>Buck, C., Heafield, K., and van Ooyen, B. (2014). N-gram counts and language models from the common crawl. In Proceedings of the Language Resources and Evaluation Conference, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
<author>K Knight</author>
<author>W Wang</author>
</authors>
<title>11,001 New Features for Statistical Machine Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>218--226</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1849" citStr="Chiang et al., 2009" startWordPosition="267" endWordPosition="270">s year’s translation task are described in the following sections. 1.1 Baseline We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic</context>
</contexts>
<marker>Chiang, Knight, Wang, 2009</marker>
<rawString>Chiang, D., Knight, K., and Wang, W. (2009). 11,001 New Features for Statistical Machine Translation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 218–226, Boulder, Colorado. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kucerova</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>531--540</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="2484" citStr="Collins et al., 2005" startWordPosition="365" endWordPosition="368"> limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 2013 for the dev experiments. For RussianEnglish pairs news-test 2012 was used for tuning and for Hindi-English pairs, we divided the newsdev 2014 into two halves, used the first half for tuning and second for dev experiments. 1.2 Using Generalized Word Representations We explored the use of automatic word clusters in phrase-b</context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Collins, M., Koehn, P., and Kucerova, I. (2005). Clause restructuring for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 531–540, Ann Arbor, Michigan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>A Fraser</author>
<author>H Schmid</author>
<author>H Hoang</author>
<author>P Koehn</author>
</authors>
<title>Can markov models over minimal translation units help phrasebased SMT?</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics, Sofia, Bulgaria. Association for Computational Linguistics.</institution>
<contexts>
<context position="1011" citStr="Durrani et al., 2013" startWordPosition="138" endWordPosition="141">nd medical translation shared tasks of the 2014 Workshop on Statistical Machine Translation (WMT). We participated in all language pairs. We have improved upon our 2013 system by i) using generalized representations, specifically automatic word clusters for translations out of English, ii) using unsupervised character-based models to translate unknown words in RussianEnglish and Hindi-English pairs, iii) synthesizing Hindi data from closely-related Urdu data, and iv) building huge language on the common crawl corpus. 1 Translation Task Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013). The notable features of these systems are described in the following section. The experiments that we carried out for this year’s translation task are described in the following sections. 1.1 Baseline We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, </context>
</contexts>
<marker>Durrani, Fraser, Schmid, Hoang, Koehn, 2013</marker>
<rawString>Durrani, N., Fraser, A., Schmid, H., Hoang, H., and Koehn, P. (2013a). Can markov models over minimal translation units help phrasebased SMT? In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>B Haddow</author>
<author>K Heafield</author>
<author>P Koehn</author>
</authors>
<title>Edinburgh’s machine translation systems for european language pairs.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="1011" citStr="Durrani et al., 2013" startWordPosition="138" endWordPosition="141">nd medical translation shared tasks of the 2014 Workshop on Statistical Machine Translation (WMT). We participated in all language pairs. We have improved upon our 2013 system by i) using generalized representations, specifically automatic word clusters for translations out of English, ii) using unsupervised character-based models to translate unknown words in RussianEnglish and Hindi-English pairs, iii) synthesizing Hindi data from closely-related Urdu data, and iv) building huge language on the common crawl corpus. 1 Translation Task Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013). The notable features of these systems are described in the following section. The experiments that we carried out for this year’s translation task are described in the following sections. 1.1 Baseline We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, </context>
</contexts>
<marker>Durrani, Haddow, Heafield, Koehn, 2013</marker>
<rawString>Durrani, N., Haddow, B., Heafield, K., and Koehn, P. (2013b). Edinburgh’s machine translation systems for european language pairs. In Proceedings of the Eighth Workshop on Statistical Machine Translation, Sofia, Bulgaria. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>P Koehn</author>
</authors>
<title>Improving machine translation via triangulation and transliteration.</title>
<date>2014</date>
<booktitle>In Proceedings of the 17th Annual Conference of the European Association for Machine Translation (EAMT),</booktitle>
<location>Dubrovnik, Croatia.</location>
<contexts>
<context position="9953" citStr="Durrani and Koehn (2014)" startWordPosition="1535" endWordPosition="1538">nsliteration is useful for more than just translating OOV words when translating closely related language pairs. To fully capitalize on the large overlap in Hindi–Urdu vocabulary, we transliterated each word in the Urdu test-data into Hindi and produced a phrase-table with 100-best transliterations. The two synthesized (triangulated and transliterated) phrase-tables are then used along with the baseline Urdu-to-Hindi phrase-table in a log-linear model. Detailed results on Urdu-toHindi baseline and improvements obtained from using transliteration and triangulated phrase-tables are presented in Durrani and Koehn (2014). Using our best Urdu-to-Hindi system, we translated the Urdu part of the multi-indic corpus to form HindiEnglish parallel data. Table 4 shows results from using the synthesized Hindi-English corpus in isolation (Syn) and on top of the baseline system (Bo + Syn). Pair Bo Syn Δ Bo + Syn Δ 14.28 10.49 -3.79 14.72 +0.44 10.59 9.01 -1.58 11.76 +1.17 Table 4: Evaluating Synthesized (Syn) HindiEnglish Parallel Data, Bo = System without Synthesized Data 1.5 Huge Language Models Our unconstrained submissions use an additional language model trained on web pages from the 2012, 2013, and winter 2013 Com</context>
</contexts>
<marker>Durrani, Koehn, 2014</marker>
<rawString>Durrani, N. and Koehn, P. (2014). Improving machine translation via triangulation and transliteration. In Proceedings of the 17th Annual Conference of the European Association for Machine Translation (EAMT), Dubrovnik, Croatia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>P Koehn</author>
<author>H Schmid</author>
<author>A Fraser</author>
</authors>
<title>Investigating the usefulness of generalized word representations in SMT.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th Annual Conference on Computational Linguistics (COLING),</booktitle>
<location>Dublin, Ireland.</location>
<note>To Appear.</note>
<contexts>
<context position="3117" citStr="Durrani et al., 2014" startWordPosition="469" endWordPosition="472"> splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 2013 for the dev experiments. For RussianEnglish pairs news-test 2012 was used for tuning and for Hindi-English pairs, we divided the newsdev 2014 into two halves, used the first half for tuning and second for dev experiments. 1.2 Using Generalized Word Representations We explored the use of automatic word clusters in phrase-based models (Durrani et al., 2014a). We computed the clusters with GIZA++’s mkcls (Och, 1999) on the source and target side of the parallel training corpus. Clusters are word classes that are optimized to reduce n-gram perplexity. By generating a cluster identifier for each output word, we are able to add an n-gram model 97 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97–104, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics over these identifiers as an additional scoring function. The inclusion of such an additional factor is trivial given the factored </context>
<context position="5777" citStr="Durrani et al., 2014" startWordPosition="891" endWordPosition="894">best in our previous experiments (Birch et al., 2013). Table 2 shows gains from additionally using OSM models over POS/morph tags. Table 2: Using POS and Morph Tags in OSM models – B0 = Baseline, +OSMp,m = POS/Morph-based OSM 1.3 Unsupervised Transliteration Model Last year, our Russian-English systems performed badly on the human evaluation. In comparison other participants that used transliteration did well. We could not train a transliteration system due to unavailability of a transliteration training data. This year we used an EM-based method to induce unsupervised transliteration models (Durrani et al., 2014b). We extracted transliteration pairs automatically from the word-aligned parallel data and used it to learn a transliteration system. We then built transliteration phrase-tables for translating OOV words and used the post-decoding method (Method 2 as described in the paper) to translate these. Pair Training OOV B0 +TT 0 Table 3: Using Unsupervised Transliteration Model – Training = Extracted Transliteration Corpus (types), OOV = Out-of-vocabulary words (tokens) B0 = System without Transliteration, +Tr = Transliterating OOVs Table 3 shows the number (types) of transliteration pairs extracted </context>
</contexts>
<marker>Durrani, Koehn, Schmid, Fraser, 2014</marker>
<rawString>Durrani, N., Koehn, P., Schmid, H., and Fraser, A. (2014a). Investigating the usefulness of generalized word representations in SMT. In Proceedings of the 25th Annual Conference on Computational Linguistics (COLING), Dublin, Ireland. To Appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>H Sajjad</author>
<author>A Fraser</author>
<author>H Schmid</author>
</authors>
<title>Hindi-to-urdu machine translation through transliteration.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>465--474</pages>
<institution>Uppsala, Sweden. Association for Computational Linguistics.</institution>
<contexts>
<context position="9282" citStr="Durrani et al., 2010" startWordPosition="1439" endWordPosition="1442">evanagri respectively). We added a transliteration component to our Urdu-to-Hindi system. An unsupervised transliteration model is learned from the wordalignments of Urdu-Hindi parallel data. We were able to extract around 2800 transliteration pairs. To learn a richer transliteration model, we additionally fed the interpolated phrase-table, as described above, to the transliteration miner. We were able to mine additional 21000 transliteration pairs and built a Urdu-Hindi character-based model from it. The transliteration module can be used to translate the 50K OOV words but previous research (Durrani et al., 2010; Nakov and Tiedemann, 2012) has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs. To fully capitalize on the large overlap in Hindi–Urdu vocabulary, we transliterated each word in the Urdu test-data into Hindi and produced a phrase-table with 100-best transliterations. The two synthesized (triangulated and transliterated) phrase-tables are then used along with the baseline Urdu-to-Hindi phrase-table in a log-linear model. Detailed results on Urdu-toHindi baseline and improvements obtained from using transliteration a</context>
</contexts>
<marker>Durrani, Sajjad, Fraser, Schmid, 2010</marker>
<rawString>Durrani, N., Sajjad, H., Fraser, A., and Schmid, H. (2010). Hindi-to-urdu machine translation through transliteration. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 465–474, Uppsala, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>H Sajjad</author>
<author>H Hoang</author>
<author>P Koehn</author>
</authors>
<title>Integrating an unsupervised transliteration model into statistical machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 15th Conference of the European Chapter of the ACL (EACL 2014), Gothenburg, Sweden. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3117" citStr="Durrani et al., 2014" startWordPosition="469" endWordPosition="472"> splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 2013 for the dev experiments. For RussianEnglish pairs news-test 2012 was used for tuning and for Hindi-English pairs, we divided the newsdev 2014 into two halves, used the first half for tuning and second for dev experiments. 1.2 Using Generalized Word Representations We explored the use of automatic word clusters in phrase-based models (Durrani et al., 2014a). We computed the clusters with GIZA++’s mkcls (Och, 1999) on the source and target side of the parallel training corpus. Clusters are word classes that are optimized to reduce n-gram perplexity. By generating a cluster identifier for each output word, we are able to add an n-gram model 97 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97–104, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics over these identifiers as an additional scoring function. The inclusion of such an additional factor is trivial given the factored </context>
<context position="5777" citStr="Durrani et al., 2014" startWordPosition="891" endWordPosition="894">best in our previous experiments (Birch et al., 2013). Table 2 shows gains from additionally using OSM models over POS/morph tags. Table 2: Using POS and Morph Tags in OSM models – B0 = Baseline, +OSMp,m = POS/Morph-based OSM 1.3 Unsupervised Transliteration Model Last year, our Russian-English systems performed badly on the human evaluation. In comparison other participants that used transliteration did well. We could not train a transliteration system due to unavailability of a transliteration training data. This year we used an EM-based method to induce unsupervised transliteration models (Durrani et al., 2014b). We extracted transliteration pairs automatically from the word-aligned parallel data and used it to learn a transliteration system. We then built transliteration phrase-tables for translating OOV words and used the post-decoding method (Method 2 as described in the paper) to translate these. Pair Training OOV B0 +TT 0 Table 3: Using Unsupervised Transliteration Model – Training = Extracted Transliteration Corpus (types), OOV = Out-of-vocabulary words (tokens) B0 = System without Transliteration, +Tr = Transliterating OOVs Table 3 shows the number (types) of transliteration pairs extracted </context>
</contexts>
<marker>Durrani, Sajjad, Hoang, Koehn, 2014</marker>
<rawString>Durrani, N., Sajjad, H., Hoang, H., and Koehn, P. (2014b). Integrating an unsupervised transliteration model into statistical machine translation. In Proceedings of the 15th Conference of the European Chapter of the ACL (EACL 2014), Gothenburg, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>H Schmid</author>
<author>A Fraser</author>
</authors>
<title>A joint sequence translation model with integrated reordering.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1045--1054</pages>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="17829" citStr="Durrani et al., 2011" startWordPosition="2888" endWordPosition="2891">main corpora (detailed on the task website), as well some out-of-domain patent data, and also all the data available for the constrained track of the news translation task was permitted. In general, we attempted to use all of this data, except for the LDC Gigaword language model data (for reasons of time) and we divided the data into “in-domain” and “out-of-domain” corpora. The data sets are summarised in Tables 10 and 11. In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source. We did not use word clusters (Section 1.2), as they did not give good results on this task, but we have yet to find a reason for this. For language model training, we decided not to build separate models on each corpus as there was 4Cumulative gains do not include gains obtain from big language models for hi-en and en-de. Table 11: Additional monolingual data used in the medical translation task. Those above the line were classified as “in-domain” and the one below as “out-of-domain”. We also used the target sides of all the p</context>
</contexts>
<marker>Durrani, Schmid, Fraser, 2011</marker>
<rawString>Durrani, N., Schmid, H., and Fraser, A. (2011). A joint sequence translation model with integrated reordering. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1045–1054, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
<author>V Chahuneau</author>
<author>N A Smith</author>
</authors>
<title>A simple, fast, and effective reparameterization of ibm model 2.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>644--648</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta,</location>
<contexts>
<context position="13822" citStr="Dyer et al., 2013" startWordPosition="2190" endWordPosition="2193">ing a transliteration submodel into GIZA++ word aligner. The probability of a word pair is calculated as an interpolation of the transliteration probability and translation probability stored in the t-table of the different alignment models used by the GIZA++ aligner. This interpolation is done for all iterations of all alignment models (See Sajjad et al. (2013) for details). Due to shortage of time we could only run it for Russian-to-English. The improved alignments gave a gain of +0.21 on news-test 2013 and +0.40 on news-test 2014. avg +.03 Table 7: Comparison of fast word alignment method (Dyer et al., 2013) against GIZA++ (WMT 2013 data condition, test on newstest2012). The method was not used in the official submission. Baseline MSD Hier. MSD Hier. MSLR 27.04 27.10 +.06 27.17 +.13 31.63 - 31.65 +.02 31.20 31.14 –.06 31.25 +.05 26.11 26.32 +.21 26.26 +.15 24.09 24.01 –.08 24.19 +.11 20.43 20.34 –.09 20.32 -.11 30.54 - 30.52 –.02 30.36 30.44 +.08 30.51 +.15 18.53 18.59 +.06 18.66 +.13 18.37 18.47 +.10 18.19 –.18 avg + .035 +.045 Table 8: Hierarchical lexicalized reordering model (Galley and Manning, 2008). Fast align: In preliminary experiments, we compared the fast word alignment method by Dyer </context>
</contexts>
<marker>Dyer, Chahuneau, Smith, 2013</marker>
<rawString>Dyer, C., Chahuneau, V., and Smith, N. A. (2013). A simple, fast, and effective reparameterization of ibm model 2. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 644– 648, Atlanta, Georgia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Freitag</author>
<author>S Peitz</author>
<author>J Wuebker</author>
<author>H Ney</author>
<author>M Huck</author>
<author>R Sennrich</author>
<author>N Durrani</author>
<author>M Nadejde</author>
<author>P Williams</author>
<author>P Koehn</author>
<author>T Herrmann</author>
<author>E Cho</author>
<author>A Waibel</author>
</authors>
<title>EU-BRIDGE MT: combined machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the ACL 2014 Ninth Workshop on Statistical Machine Translation,</booktitle>
<location>Baltimore, MD, USA.</location>
<contexts>
<context position="16150" citStr="Freitag et al. (2014)" startWordPosition="2561" endWordPosition="2564">7 en-cs 15.70 16.02 +.32 100 O(f|e)&lt;10−4 can be safely discarded with almost no change in translations. However, discarding phrase translations with the inverse phrase translation probability O(e|f)&lt;10−4 is more risky, especially with morphologically rich target languages, so we kept those. 1.7 Summary Table 9 shows cumulative gains obtained from using word classes, transliteration and big language models4 over the baseline system. Our GermanEnglish constrained systems were used for EUBridge system combination, a collaborative effort to improve the state-of-the-art in machine translation (See Freitag et al. (2014) for details). from English into English Lang B0 B1 Δ B0 B1 Δ Data Set coppa-in PatTR-in-claims PatTR-in-abstract PatTR-in-titles UMLS MuchMore EMEA WikiTitles PatTR-out coppa-out MultiUN czeng europarl news-comm commoncrawl FrEnGiga Table 10: Parallel data sets used in the medical translation task. The sets above the line were classified as “in-domain” and those below as “out-ofdomain”. cs-en de-en fr-en n n y n y y n y y n y y y y y n y n y y y y y y n y y n n y n n y y n n y y y y y y y y y n n y 20.44 20.85 +0.41 27.24 27.44 +0.20 18.84 20.03 +1.19 26.42 26.42 ±0.00 30.73 30.82 +0.09 31.64</context>
</contexts>
<marker>Freitag, Peitz, Wuebker, Ney, Huck, Sennrich, Durrani, Nadejde, Williams, Koehn, Herrmann, Cho, Waibel, 2014</marker>
<rawString>Freitag, M., Peitz, S., Wuebker, J., Ney, H., Huck, M., Sennrich, R., Durrani, N., Nadejde, M., Williams, P., Koehn, P., Herrmann, T., Cho, E., and Waibel, A. (2014). EU-BRIDGE MT: combined machine translation. In Proceedings of the ACL 2014 Ninth Workshop on Statistical Machine Translation, Baltimore, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>C D Manning</author>
</authors>
<title>A simple and effective hierarchical phrase reordering model.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>848--856</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="1616" citStr="Galley and Manning, 2008" startWordPosition="231" endWordPosition="234">Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013). The notable features of these systems are described in the following section. The experiments that we carried out for this year’s translation task are described in the following sections. 1.1 Baseline We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factor</context>
<context position="14329" citStr="Galley and Manning, 2008" startWordPosition="2277" endWordPosition="2280">-test 2013 and +0.40 on news-test 2014. avg +.03 Table 7: Comparison of fast word alignment method (Dyer et al., 2013) against GIZA++ (WMT 2013 data condition, test on newstest2012). The method was not used in the official submission. Baseline MSD Hier. MSD Hier. MSLR 27.04 27.10 +.06 27.17 +.13 31.63 - 31.65 +.02 31.20 31.14 –.06 31.25 +.05 26.11 26.32 +.21 26.26 +.15 24.09 24.01 –.08 24.19 +.11 20.43 20.34 –.09 20.32 -.11 30.54 - 30.52 –.02 30.36 30.44 +.08 30.51 +.15 18.53 18.59 +.06 18.66 +.13 18.37 18.47 +.10 18.19 –.18 avg + .035 +.045 Table 8: Hierarchical lexicalized reordering model (Galley and Manning, 2008). Fast align: In preliminary experiments, we compared the fast word alignment method by Dyer et al. (2013) against our traditional use of GIZA++. Results are quite mixed (Table 7), ranging from a gain of +.35 for Russian-English to a loss of –.19 for Czech-English. We stayed with GIZA++ for all of our other experiments. Hierarchical lexicalized reordering model: We explored the use of the hierarchical lexicalized reordering model (Galley and Manning, 2008) in two variants: using the same orientations as our traditional model (monotone, discontinuous, swap), and one that distinguishes the disco</context>
</contexts>
<marker>Galley, Manning, 2008</marker>
<rawString>Galley, M. and Manning, C. D. (2008). A simple and effective hierarchical phrase reordering model. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 848–856, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Heafield</author>
</authors>
<title>Kenlm: Faster and smaller language model queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>187--197</pages>
<location>Edinburgh, Scotland, United Kingdom.</location>
<contexts>
<context position="1536" citStr="Heafield, 2011" startWordPosition="222" endWordPosition="223">lation Task Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013). The notable features of these systems are described in the following section. The experiments that we carried out for this year’s translation task are described in the following sections. 1.1 Baseline We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Heafield, K. (2011). Kenlm: Faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Heafield</author>
<author>I Pouzyrevsky</author>
<author>J H Clark</author>
<author>P Koehn</author>
</authors>
<title>Scalable modified KneserNey language model estimation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="11636" citStr="Heafield et al., 2013" startWordPosition="1816" endWordPosition="1819">oehn, 2005). All text was then deduplicated, minimizing the impact of boilerplate, such as social media sharing buttons. We then tokenized and truecased the text as usual. Statistics are shown in Table 5. A full description of the pipeline, including a public data release, appears in Buck et al. (2014). Lang Lines (B) Tokens (B) Bytes en 59.13 975.63 5.14 TiB de 3.87 51.93 317.46 GiB fr 3.04 49.31 273.96 GiB ru 1.79 21.41 220.62 GiB cs 0.47 5.79 34.67 GiB hi 0.01 0.28 3.39 GiB Table 5: Size of huge language model training data We built unpruned modified Kneser-Ney language models using lmplz (Heafield et al., 2013). 2http://commoncrawl.org 3https://code.google.com/p/cld2/ hi-en en-hi 99 Pair Bo +L newstest 2013 2014 2013 2014 – 20.61 +0.51 20.03 +0.64 21.60 +0.60 20.80 +0.90 29.90 +1.20 12.83 +1.40 12.50 +1.40 – 14.80 +0.90 en-de 20.85 20.10 en-cs 19.39 21.00 en-ru 19.90 28.70 en-hi 11.43 11.10 hi-en 15.48 13.90 Table 6: Gains obtained by using huge language models – Bo = Baseline, +L = Adding Huge LM While the Hindi and Czech models are small enough to run directly, models for other languages are quite large.We therefore created a filter that operates directly on files in KenLM trie binary format, pres</context>
</contexts>
<marker>Heafield, Pouzyrevsky, Clark, Koehn, 2013</marker>
<rawString>Heafield, K., Pouzyrevsky, I., Clark, J. H., and Koehn, P. (2013). Scalable modified KneserNey language model estimation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
<author>D Chiang</author>
</authors>
<title>Forest rescoring: Faster decoding with integrated language models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>144--151</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2024" citStr="Huang and Chiang, 2007" startWordPosition="294" endWordPosition="297">g-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems w</context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Huang, L. and Chiang, D. (2007). Forest rescoring: Faster decoding with integrated language models. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 144–151, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of MT Summit.</booktitle>
<contexts>
<context position="11025" citStr="Koehn, 2005" startWordPosition="1710" endWordPosition="1711">Language Models Our unconstrained submissions use an additional language model trained on web pages from the 2012, 2013, and winter 2013 CommonCrawl.2 The additional language model is the only difference between the constrained and unconstrained submissions; we did not use additional parallel data. These language models were trained on text provided by the CommonCrawl foundation, which they converted to UTF-8 after stripping HTML. Languages were detected using the Compact Language Detection 23 and, except for Hindi where we lack tools, sentences were split with the Europarl sentence splitter (Koehn, 2005). All text was then deduplicated, minimizing the impact of boilerplate, such as social media sharing buttons. We then tokenized and truecased the text as usual. Statistics are shown in Table 5. A full description of the pipeline, including a public data release, appears in Buck et al. (2014). Lang Lines (B) Tokens (B) Bytes en 59.13 975.63 5.14 TiB de 3.87 51.93 317.46 GiB fr 3.04 49.31 273.96 GiB ru 1.79 21.41 220.62 GiB cs 0.47 5.79 34.67 GiB hi 0.01 0.28 3.39 GiB Table 5: Size of huge language model training data We built unpruned modified Kneser-Ney language models using lmplz (Heafield et</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Koehn, P. (2005). Europarl: A parallel corpus for statistical machine translation. In Proceedings of MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>B Haddow</author>
</authors>
<title>Edinburgh’s Submission to all Tracks of the WMT</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>160--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece.</location>
<contexts>
<context position="2159" citStr="Koehn and Haddow, 2009" startWordPosition="314" endWordPosition="317"> used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 201</context>
</contexts>
<marker>Koehn, Haddow, 2009</marker>
<rawString>Koehn, P. and Haddow, B. (2009). Edinburgh’s Submission to all Tracks of the WMT 2009 Shared Task with Reordering and Speed Improvements to Moses. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 160–164, Athens, Greece. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868--876</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2270" citStr="Koehn and Hoang, 2007" startWordPosition="332" endWordPosition="335">tion sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 2013 for the dev experiments. For RussianEnglish pairs news-test 2012 was used for tuning and for Hindi-English pa</context>
<context position="3761" citStr="Koehn and Hoang, 2007" startWordPosition="568" endWordPosition="571">usters with GIZA++’s mkcls (Och, 1999) on the source and target side of the parallel training corpus. Clusters are word classes that are optimized to reduce n-gram perplexity. By generating a cluster identifier for each output word, we are able to add an n-gram model 97 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97–104, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics over these identifiers as an additional scoring function. The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn et al., 2007). The n-gram model is trained in the similar way as the regular language model. We trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the tuning set (Schwenk and Koehn, 2008). We also trained OSM models over cluster-ids (?). The lexically driven OSM model falls back to very small context sizes of two to three operations due to data sparsity. Learning operation sequences over cluster-ids enables us to learn richer translation and reordering patterns that can generalize better in sparse data c</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Koehn, P. and Hoang, H. (2007). Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868–876, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL 2007 Demonstrations,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3791" citStr="Koehn et al., 2007" startWordPosition="574" endWordPosition="577">1999) on the source and target side of the parallel training corpus. Clusters are word classes that are optimized to reduce n-gram perplexity. By generating a cluster identifier for each output word, we are able to add an n-gram model 97 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97–104, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics over these identifiers as an additional scoring function. The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn et al., 2007). The n-gram model is trained in the similar way as the regular language model. We trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the tuning set (Schwenk and Koehn, 2008). We also trained OSM models over cluster-ids (?). The lexically driven OSM model falls back to very small context sizes of two to three operations due to data sparsity. Learning operation sequences over cluster-ids enables us to learn richer translation and reordering patterns that can generalize better in sparse data conditions. Table 1 shows gains</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007). Moses: Open source toolkit for statistical machine translation. In ACL 2007 Demonstrations, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In Proceedings of Meeting of the European Chapter of the Association of Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="2532" citStr="Koehn and Knight, 2003" startWordPosition="372" endWordPosition="375">est translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 2013 for the dev experiments. For RussianEnglish pairs news-test 2012 was used for tuning and for Hindi-English pairs, we divided the newsdev 2014 into two halves, used the first half for tuning and second for dev experiments. 1.2 Using Generalized Word Representations We explored the use of automatic word clusters in phrase-based models (Durrani et al., 2014a). We computed</context>
<context position="17877" citStr="Koehn and Knight (2003)" startWordPosition="2895" endWordPosition="2898">s well some out-of-domain patent data, and also all the data available for the constrained track of the news translation task was permitted. In general, we attempted to use all of this data, except for the LDC Gigaword language model data (for reasons of time) and we divided the data into “in-domain” and “out-of-domain” corpora. The data sets are summarised in Tables 10 and 11. In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source. We did not use word clusters (Section 1.2), as they did not give good results on this task, but we have yet to find a reason for this. For language model training, we decided not to build separate models on each corpus as there was 4Cumulative gains do not include gains obtain from big language models for hi-en and en-de. Table 11: Additional monolingual data used in the medical translation task. Those above the line were classified as “in-domain” and the one below as “out-of-domain”. We also used the target sides of all the parallel corpora for language modelling. a large </context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Koehn, P. and Knight, K. (2003). Empirical methods for compound splitting. In Proceedings of Meeting of the European Chapter of the Association of Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W J Byrne</author>
</authors>
<title>Minimum bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>169--176</pages>
<contexts>
<context position="1985" citStr="Kumar and Byrne, 2004" startWordPosition="288" endWordPosition="291">maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009). We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs. We also trained target sequence models on the in-domain subset of the parallel corpus using Kneser-Ney smoothed 7-gram models. We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems. We used trivia tokeni</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Kumar, S. and Byrne, W. J. (2004). Minimum bayes-risk decoding for statistical machine translation. In HLT-NAACL, pages 169– 176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
<author>W Lewis</author>
</authors>
<title>Intelligent selection of language model training data.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>220--224</pages>
<institution>Uppsala, Sweden. Association for Computational Linguistics.</institution>
<contexts>
<context position="19683" citStr="Moore and Lewis, 2010" startWordPosition="3195" endWordPosition="3198">MARY-DEV. We selected a tuning set (5000 sentence pairs, which were added to SUMMARY-DEV) and a devtest set (3000 sentence pairs) from EMEA after first de-duplicating it, and ignoring sentence pairs which were too short, or 101 contained too many capital letters or numbers. The EMEA contains many duplicated sentences, and we removed all sentence pairs where either side was a duplicate, reducing the size of the corpus to about 25% of the original. We also removed EMEA from Czeng, since otherwise it would overlap with our selected development sets. We also experimented with modified MooreLewis (Moore and Lewis, 2010; Axelrod et al., 2011) data selection, using the EMEA corpus as the in-domain corpus (for the language model required in MML) and selecting from all the out-ofdomain data. When running on the final test set (SUMMARYTEST) we found that it was better to tune just on SUMMARY-DEV, even though it was much smaller than the EMEA dev set we had selected. All but two (cs-en, de-en) of our submitted systems used the MML selection, because it worked better on our EMEA devtest set. However, as can be seen from Table 12, systems built with all the data generally perform better. We concluded that EMEA was </context>
</contexts>
<marker>Moore, Lewis, 2010</marker>
<rawString>Moore, R. C. and Lewis, W. (2010). Intelligent selection of language model training data. In Proceedings of the ACL 2010 Conference Short Papers, pages 220–224, Uppsala, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Nakov</author>
<author>J Tiedemann</author>
</authors>
<title>Combining word-level and character-level models for machine translation between closely-related languages.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>301--305</pages>
<institution>Jeju Island, Korea. Association for Computational Linguistics.</institution>
<contexts>
<context position="9310" citStr="Nakov and Tiedemann, 2012" startWordPosition="1443" endWordPosition="1446">. We added a transliteration component to our Urdu-to-Hindi system. An unsupervised transliteration model is learned from the wordalignments of Urdu-Hindi parallel data. We were able to extract around 2800 transliteration pairs. To learn a richer transliteration model, we additionally fed the interpolated phrase-table, as described above, to the transliteration miner. We were able to mine additional 21000 transliteration pairs and built a Urdu-Hindi character-based model from it. The transliteration module can be used to translate the 50K OOV words but previous research (Durrani et al., 2010; Nakov and Tiedemann, 2012) has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs. To fully capitalize on the large overlap in Hindi–Urdu vocabulary, we transliterated each word in the Urdu test-data into Hindi and produced a phrase-table with 100-best transliterations. The two synthesized (triangulated and transliterated) phrase-tables are then used along with the baseline Urdu-to-Hindi phrase-table in a log-linear model. Detailed results on Urdu-toHindi baseline and improvements obtained from using transliteration and triangulated phrase-table</context>
</contexts>
<marker>Nakov, Tiedemann, 2012</marker>
<rawString>Nakov, P. and Tiedemann, J. (2012). Combining word-level and character-level models for machine translation between closely-related languages. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 301–305, Jeju Island, Korea. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>An efficient method for determining bilingual word classes.</title>
<date>1999</date>
<booktitle>In Ninth Conference the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>71--76</pages>
<contexts>
<context position="3177" citStr="Och, 1999" startWordPosition="480" endWordPosition="481">used trivia tokenizer for tokenizing Hindi. The systems were tuned on a very large tuning set consisting of the test sets from 2008-2012, with a total of 13,071 sentences. We used newstest 2013 for the dev experiments. For RussianEnglish pairs news-test 2012 was used for tuning and for Hindi-English pairs, we divided the newsdev 2014 into two halves, used the first half for tuning and second for dev experiments. 1.2 Using Generalized Word Representations We explored the use of automatic word clusters in phrase-based models (Durrani et al., 2014a). We computed the clusters with GIZA++’s mkcls (Och, 1999) on the source and target side of the parallel training corpus. Clusters are word classes that are optimized to reduce n-gram perplexity. By generating a cluster identifier for each output word, we are able to add an n-gram model 97 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97–104, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics over these identifiers as an additional scoring function. The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn</context>
</contexts>
<marker>Och, 1999</marker>
<rawString>Och, F. J. (1999). An efficient method for determining bilingual word classes. In Ninth Conference the European Chapter of the Association for Computational Linguistics (EACL), pages 71–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Post</author>
<author>C Callison-Burch</author>
<author>M Osborne</author>
</authors>
<title>Constructing parallel corpora for six indian languages via crowdsourcing.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>401--409</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="6896" citStr="Post et al., 2012" startWordPosition="1062" endWordPosition="1065">on, +Tr = Transliterating OOVs Table 3 shows the number (types) of transliteration pairs extracted using unsupervised mining, number of OOV words (tokens) in each pair and the gains achieved by transliterating unknown words. 1.4 Synthesizing Hindi Data from Urdu Hindi and Urdu are closely related language pairs that share grammatical structure and have a large overlap in vocabulary. This provides a strong motivation to transform any Urdu-English parallel data into Hindi-English by translating the Urdu part into Hindi. We made use of the Urdu-English segment of the Indic multi-parallel corpus (Post et al., 2012) which contains roughly 87K sentence pairs. The Hindi-English segment of this corpus is a subset of parallel data made available for the translation task but is completely disjoint from the Urdu-English segment. We initially trained a Urdu-to-Hindi SMT system using a very tiny EMILLE1 corpus (Baker 1EMILLE corpus contains roughly 12000 sentences of Hindi and Urdu comparable data. From these we were able to sentence align 7000 sentences to build an Urdu-to-Hindi system. en-de 20.44 20.60 +0.16 de-en 27.24 27.44 +0.20 Lang B0 +OSMp,M 0 232K 1356 24.63 25.06 +0.41 232K 681 19.67 19.91 +0.24 38K 5</context>
</contexts>
<marker>Post, Callison-Burch, Osborne, 2012</marker>
<rawString>Post, M., Callison-Burch, C., and Osborne, M. (2012). Constructing parallel corpora for six indian languages via crowdsourcing. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 401–409, Montr´eal, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sajjad</author>
<author>S Smekalova</author>
<author>N Durrani</author>
<author>A Fraser</author>
<author>H Schmid</author>
</authors>
<title>QCRI-MES submission at wmt13: Using transliteration mining to improve statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="13568" citStr="Sajjad et al. (2013)" startWordPosition="2145" endWordPosition="2148">ing full-stops with Danda gave improvement of +0.20 for hi-en and +0.40 in en-hi. 2) Using Wiki subtitles did not give any improvement in BLEU and were in fact harmful for the en-hi direction. Russian-English: We tried to improve wordalignments by integrating a transliteration submodel into GIZA++ word aligner. The probability of a word pair is calculated as an interpolation of the transliteration probability and translation probability stored in the t-table of the different alignment models used by the GIZA++ aligner. This interpolation is done for all iterations of all alignment models (See Sajjad et al. (2013) for details). Due to shortage of time we could only run it for Russian-to-English. The improved alignments gave a gain of +0.21 on news-test 2013 and +0.40 on news-test 2014. avg +.03 Table 7: Comparison of fast word alignment method (Dyer et al., 2013) against GIZA++ (WMT 2013 data condition, test on newstest2012). The method was not used in the official submission. Baseline MSD Hier. MSD Hier. MSLR 27.04 27.10 +.06 27.17 +.13 31.63 - 31.65 +.02 31.20 31.14 –.06 31.25 +.05 26.11 26.32 +.21 26.26 +.15 24.09 24.01 –.08 24.19 +.11 20.43 20.34 –.09 20.32 -.11 30.54 - 30.52 –.02 30.36 30.44 +.08 </context>
</contexts>
<marker>Sajjad, Smekalova, Durrani, Fraser, Schmid, 2013</marker>
<rawString>Sajjad, H., Smekalova, S., Durrani, N., Fraser, A., and Schmid, H. (2013). QCRI-MES submission at wmt13: Using transliteration mining to improve statistical machine translation. In Proceedings of the Eighth Workshop on Statistical Machine Translation, Sofia, Bulgaria. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schwenk</author>
<author>P Koehn</author>
</authors>
<title>Large and diverse language models for statistical machine translation.</title>
<date>2008</date>
<booktitle>In International Joint Conference on Natural Language Processing,</booktitle>
<pages>661--666</pages>
<contexts>
<context position="4039" citStr="Schwenk and Koehn, 2008" startWordPosition="612" endWordPosition="615">edings of the Ninth Workshop on Statistical Machine Translation, pages 97–104, Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics over these identifiers as an additional scoring function. The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn et al., 2007). The n-gram model is trained in the similar way as the regular language model. We trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the tuning set (Schwenk and Koehn, 2008). We also trained OSM models over cluster-ids (?). The lexically driven OSM model falls back to very small context sizes of two to three operations due to data sparsity. Learning operation sequences over cluster-ids enables us to learn richer translation and reordering patterns that can generalize better in sparse data conditions. Table 1 shows gains from adding target LM and OSM models over cluster-ids. Using word clusters was found more useful translating from English-to-*. from English into English Lang B0 +Cid 0 B0 +Cid 0 20.60 20.85 +0.25 27.44 27.34 -0.10 18.84 19.39 +0.55 26.42 26.42 ±0</context>
</contexts>
<marker>Schwenk, Koehn, 2008</marker>
<rawString>Schwenk, H. and Koehn, P. (2008). Large and diverse language models for statistical machine translation. In International Joint Conference on Natural Language Processing, pages 661– 666.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Utiyama</author>
<author>H Isahara</author>
</authors>
<title>A comparison of pivot methods for phrase-based statistical machine translation. In</title>
<date>2007</date>
<booktitle>Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>484--491</pages>
<contexts>
<context position="8273" citStr="Utiyama and Isahara, 2007" startWordPosition="1282" endWordPosition="1285">lating the Urdu part of Indic data due to domain mismatch and huge number of OOV words (approximately 310K tokens). To reduce sparsity we synthesized additional phrase-tables using interpolation and transliteration. Interpolation: We trained two phrase translation tables p( ¯ui|¯ei) and p(¯ei|¯hi), from UrduEnglish (Indic corpus) and Hindi-English (HindEnCorp (Bojar et al., 2014)) bilingual corpora. Given the phrase-table for Urdu-English p( ¯ui |¯ei) and the phrase-table for English-Hindi p(¯ei |¯hi), we estimated a Urdu-Hindi phrase-table p( ¯ui |¯hi) using the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007): p( ¯ui |�¯hi) = p( ¯ui|¯ei)p(¯ei |hi) ¯ei The number of entries in the baseline Urdu-toHindi phrase-table were approximately 254K. Using interpolation we were able to build a phrasetable containing roughly 10M phrases. This reduced the number of OOV tokens from 310K to approximately 50K. Transliteration: Urdu and Hindi are written in different scripts (Arabic and Devanagri respectively). We added a transliteration component to our Urdu-to-Hindi system. An unsupervised transliteration model is learned from the wordalignments of Urdu-Hindi parallel data. We were able to ext</context>
</contexts>
<marker>Utiyama, Isahara, 2007</marker>
<rawString>Utiyama, M. and Isahara, H. (2007). A comparison of pivot methods for phrase-based statistical machine translation. In 2007 Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 484–491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wu</author>
<author>H Wang</author>
</authors>
<title>Pivot language approach for phrase-based statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>856--863</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="8293" citStr="Wu and Wang, 2007" startWordPosition="1286" endWordPosition="1289">ic data due to domain mismatch and huge number of OOV words (approximately 310K tokens). To reduce sparsity we synthesized additional phrase-tables using interpolation and transliteration. Interpolation: We trained two phrase translation tables p( ¯ui|¯ei) and p(¯ei|¯hi), from UrduEnglish (Indic corpus) and Hindi-English (HindEnCorp (Bojar et al., 2014)) bilingual corpora. Given the phrase-table for Urdu-English p( ¯ui |¯ei) and the phrase-table for English-Hindi p(¯ei |¯hi), we estimated a Urdu-Hindi phrase-table p( ¯ui |¯hi) using the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007): p( ¯ui |�¯hi) = p( ¯ui|¯ei)p(¯ei |hi) ¯ei The number of entries in the baseline Urdu-toHindi phrase-table were approximately 254K. Using interpolation we were able to build a phrasetable containing roughly 10M phrases. This reduced the number of OOV tokens from 310K to approximately 50K. Transliteration: Urdu and Hindi are written in different scripts (Arabic and Devanagri respectively). We added a transliteration component to our Urdu-to-Hindi system. An unsupervised transliteration model is learned from the wordalignments of Urdu-Hindi parallel data. We were able to extract around 2800 tra</context>
</contexts>
<marker>Wu, Wang, 2007</marker>
<rawString>Wu, H. and Wang, H. (2007). Pivot language approach for phrase-based statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 856–863, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>