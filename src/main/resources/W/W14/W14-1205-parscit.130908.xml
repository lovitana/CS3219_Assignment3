<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000418">
<title confidence="0.994681">
An eye-tracking evaluation of some parser complexity metrics
</title>
<author confidence="0.97927">
Matthew J. Green
</author>
<affiliation confidence="0.985022">
University of Aberdeen, UK
</affiliation>
<email confidence="0.991987">
mjgreen@abdn.ac.uk
</email>
<sectionHeader confidence="0.993744" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999627066666667">
Information theoretic measures of incre-
mental parser load were generated from a
phrase structure parser and a dependency
parser and then compared with incremen-
tal eye movement metrics collected for the
same temporarily syntactically ambiguous
sentences, focussing on the disambiguat-
ing word. The findings show that the
surprisal and entropy reduction metrics
computed over a phrase structure gram-
mar make good candidates for predictors
of text readability for human comprehen-
ders. This leads to a suggestion for the use
of such metrics in Natural Language Gen-
eration (NLG).
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999522956521739">
This work aims to predict automatically how dif-
ficult a generated sentence will be for a per-
son to read. Temporarily syntactically ambigu-
ous sentences were presented along with pre-
disambiguated controls to people to read while
their eye movements were recorded. The same
materials were given as input to two NLP parsers,
trained on portions of the Wall Street Journal part
of the Penn Treebank, that generate incremental
word by word metrics of parser load. The met-
rics of parser load were compared against a stan-
dard measure of human sentence processing load
regression path duration.
The purpose of the present article is to demon-
strate that the parser metrics can predict human
difficulty for a certain syntactically-ambiguous
sentence type (described in the next section). The
article also proposes that, if future work shows that
the parser metrics here also predict sentence pro-
cessing difficulty more broadly, then this method
would be a useful way for NLG systems to decide
on a particular output from among several possible
outputs that express the same information.
</bodyText>
<sectionHeader confidence="0.945747" genericHeader="method">
2 Complement ambiguity
</sectionHeader>
<bodyText confidence="0.999765571428571">
The sentences used in this article were represen-
tative of complement ambiguity. Sentences like
these are syntactically ambiguous until a disam-
biguating word, which resolves the ambiguity ei-
ther to no complement, direct object complement,
or sentential complement. This section gives the
linguistic aspects of this ambiguity type with ex-
amples. Material in parentheses indicates how
the unambiguous controls were constructed: by
means of punctuation indicating the clause bound-
ary in (1); and by means of an overt complemen-
tiser establishing the sentential complement in (2).
Phrase marker diagrams are given for the exam-
ples in Figures (1) and (2).
</bodyText>
<listItem confidence="0.770236">
(1) After the cadet saluted(,) the captain walked
to the gates of the enclosure. SENTENCE
TYPE 1
</listItem>
<bodyText confidence="0.9613987">
(2) The cadet noticed (that) the captain walked
to the gates of the enclosure. SENTENCE
TYPE 2
Sentential complement ambiguities exploit the
properties of ‘complement’ verbs like noticed that
can be followed either by a complement clause or
by a direct object, or by no complement. When
such verbs are followed by complements and an
overt complementiser like that is used, no tem-
porary syntactic ambiguity is present: however,
when the complementiser is omitted, which may
be done without violating the grammar, temporary
syntactic ambiguity arises with respect to the first
few words of the complement. These words may
be taken as a direct object instead, and then when
the complement verb appears, disambiguation en-
sues as the words that were taken to be part of a
direct object of the verb are revealed necessarily
to be part of a complement. Another possibility
afforded by the multiple subcategorisation frame
</bodyText>
<page confidence="0.988435">
38
</page>
<note confidence="0.9940925">
Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 38–46,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999804111111111">
of words like noticed is that the words immedi-
ately following could properly be the start of a
main clause where the clause containing noticed
is properly a subordinate clause. Such cases are
sometimes referred to as reduced complements.
In these cases only the presence of a main verb
resolves the temporary syntactic ambiguity, and
when it appears, some major restructuring is in-
volved. Complement ambiguities of both kinds
have been used to investigate the parsing of am-
biguous clauses (Holmes et al., 1987; Rayner and
Frazier, 1987; Sturt et al., 1999; Ferreira and
Henderson, 1991; Clifton Jr, 1993; Pickering and
Traxler, 1998; Trueswell et al., 1993).
Evidence from studies with human readers sup-
port the notion that there is a processing difficulty
differential across the two forms such that dis-
ambiguation in sentence type (1) is harder than
in sentence type (2). This has been shown using
grammaticality judgements (Ferreira and Hender-
son, 1991), self-paced reading times (Sturt et al.,
1999), and eye-tracking (Green, 2014).
The current article presents an eye-tracking
evaluation of the parser predictions for comple-
ment ambiguity, and discusses applications of syn-
tactic complexity metrics for evaluating test read-
ability.
</bodyText>
<sectionHeader confidence="0.9967" genericHeader="method">
3 Parser metrics
</sectionHeader>
<bodyText confidence="0.999729">
This section gives details of the surprisal, entropy
reduction, and retrieval time metrics, and how they
are computed.
</bodyText>
<subsectionHeader confidence="0.996931">
3.1 Surprisal
</subsectionHeader>
<bodyText confidence="0.999358782608696">
Surprisal was computed over a phase structure
parser, and over a dependency parser.
Surprisal is computed using two other quanti-
ties. These quantities are: (1) the probability of a
derivation: a derivation is a set of weighted rule
productions that result in the current partial string
of input words, such that a sentence fragment with
two alternative parses is represented as two deriva-
tions; (2) prefix probability: this is the probability
of the parse of the fragment seen so far, which is
composed of the sum of the probabilities of the
two derivations if the fragment is syntactically am-
biguous with two alternatives.
Let G be a probabilistic context free grammar
(PCFG). Let d be a derivation composed of a se-
quence of applications of grammar rules. Let i in-
dex these applications so that di is the ith applica-
tion in d, and let j be the total number of applica-
tions in the derivation. Then the probability p of
a derivation d given a grammar G and the current
sentence fragment w1...k is given by the product of
the probability of each rule applied in the deriva-
tion, thus:
</bodyText>
<equation confidence="0.9962485">
p(d, G, w1...k) = � j p(di, G, w1...k)
i=1
</equation>
<bodyText confidence="0.999583705882353">
Let D represent the set of all derivations d that
are present for the current sentence fragment –
when there are two alternative parses available for
the sentence fragment seen so far, D has two ele-
ments. Let w be the set of words in the sentence
fragment seen so far. Let wk be the word that
the parser encountered most recently at the current
state. Let wk+1 be the first word of the rest of the
sentence. As the parser transitions from its state at
wk to its state at wk+1 we can derive a prefix prob-
ability pp at wk+1 that represents the sum proba-
bility of the derivations of the string w1...k+1. So
the prefix probability of word wk+1 with respect
to a probabilistic context free grammar (PCFG) de-
noted G is given by the sum of the probability of
all derivations of the string w1...k+1 that the gram-
mar generates.
</bodyText>
<equation confidence="0.991056">
�pp(wk+1, G, w1...k) = p(d, G, w1...k)
d∈D
</equation>
<bodyText confidence="0.9998655">
The conditional probability cp of the next word
wk+1 is the ratio of the prefix probability of the
next word wk+1 to the prefix probability of the
current word wk.
</bodyText>
<equation confidence="0.998012">
cp(wk+1, G, w1...k) =
pp(wk, G, w1...k−1)
</equation>
<bodyText confidence="0.99969725">
The surprisal sp, measured in bits of informa-
tion, associated with the next word wk+1 is the
negative log of the conditional probability of the
next word wk+1
</bodyText>
<equation confidence="0.716686">
sp(wk+1, G, w1...k) = −log(cp(wk+1, G, w1...k))
</equation>
<bodyText confidence="0.99977975">
The TDPARSE top-down incremental parser pro-
vided by Roark (2013) and described in Roark
(2001) and Roark (2004) computes surprisal over
a phrase structural grammar, incrementally for
each word in a sentence. It is a parallel parser that
maintains potentially very many parses at each
state. For details of how the beam width varies
across a sentence, see Roark (2001).
</bodyText>
<equation confidence="0.843922">
pp(wk+1, G, w1...k)
</equation>
<page confidence="0.997418">
39
</page>
<figureCaption confidence="0.9977155">
Figure 1: Phrase markers showing disambiguation in sentence type 1. The left phrasemarker shows the
initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached
in the ultimately correct analysis.
Figure 2: Phrase markers showing disambiguation in sentence type 2. The left phrasemarker shows the
initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached
in the ultimately correct analysis.
</figureCaption>
<figure confidence="0.9985346">
S
ADVP S&apos;
IN S&apos; NP VP
After NP VP the captain walked ...
NP
the captain
the cadet V
saluted
the cadet V
saluted
S
ADVP S&apos;
IN S&apos;
After NP VP
S
S
NP VP
The cadet V
NP VP
noticed
the cadet V S&apos;
noticed NP VP
the captain walked ...
NP
the captain
</figure>
<bodyText confidence="0.999932705882353">
The HUMDEP parser provided by Boston
(2013) and described in Boston and Hale (2007)
and Boston (2012) computes surprisal over a de-
pendency grammar transition system, incremen-
tally for each word in a sentence. It is a k-best
parser. Here the value of k was set to 3, in line
with previous use of the parser to model human
disambiguation performance for garden-path sen-
tences in Boston and Hale (2007).
Hypothesis 1 Hale (2001), and also Levy
(2008), gave the hypothesis that surprisal is lin-
early related to the human effort of processing a
particular word in a sentence fragment. This hy-
pothesis casts disambiguation as the work incurred
by disconfirming all parses of the fragment that are
inconsistent with the fragment including the dis-
ambiguating word.
</bodyText>
<subsectionHeader confidence="0.998368">
3.2 Entropy reduction
</subsectionHeader>
<bodyText confidence="0.922583142857143">
Entropy reduction was computed over the output
of the phrase structure parser TDPARSE. In gen-
eral, the entropy (Shannon, 1948), denoted H, of a
random variable is the uncertainty associated with
that variable. Specifically, for a discrete random
variable X with outcomes x1, x2,... with proba-
bilities p1, p2, .. .
</bodyText>
<equation confidence="0.987753">
H(X) = − 1: px log2 px
x∈X
</equation>
<bodyText confidence="0.8992515">
Putting this in sentence processing terms, let D
be a set of derivations for a sentence fragment W
and let X be the extended sentence fragment that
results from adding a new word to the fragment.
1:
H(G, D, W) = − prp(G, X)log(prp(G, X))
The quantity entropy reduction is defined with a
lower bound of zero so that this quantity is never
</bodyText>
<page confidence="0.855475">
40
</page>
<equation confidence="0.704011">
negative:
ER = max(0, H(D|w1...k) − H(D|w1...k+1))
</equation>
<bodyText confidence="0.998657833333333">
Hypothesis 2 Hale (2004) and Hale (2006) gave
the entropy reduction hypothesis that the human
effort of processing a particular word in a sentence
fragment is the reduction in entropy from its value
given the fragment to its value given the fragment
including the disambiguating word.
</bodyText>
<subsectionHeader confidence="0.99964">
3.3 Retrieval time
</subsectionHeader>
<bodyText confidence="0.999880090909091">
Parsing in retrieval theory (Lewis and Vasishth,
2005) is accomplished by condition-action pairs
generated with reference to a phrase structure
grammar. A series of memory buffers stores el-
ements in short-term and long-term buffers. Par-
allel associative retrieval (McElree et al., 2003),
fluctuation of activation of elements already in
a memory buffer, and retrieval interference as a
function of similarity are combined to predict the
amount of time that it takes to read a word (Va-
sishth et al., 2008).
A word’s activation is based on two quantities:
the baseline activation of the word, which is taken
to decay given the passage of time; and the amount
of similarity based interference with other words
that have been parsed. The baseline activation B
for a word i is given here, taken from Lewis and
Vasishth (2005), and Patil et al. (2009), where tr
is the time since the rth retrieval of the word, the
summation is over all n retrievals, and d is a decay
factor set to 0.5 as in other ACT-R models (Ander-
son, 2005).
</bodyText>
<equation confidence="0.654951">
Bi = ln
</equation>
<bodyText confidence="0.997722">
The equation tracks the log odds that a word will
need to be retrieved, given its past usage history.
It yields not a smoothly decaying activation from
initial encoding to the current time, but a ”series
of spikes corresponding to the retrieval events”
(Lewis and Vasishth, 2005).
The overall activation A for word i is given here
</bodyText>
<equation confidence="0.9375625">
�Ai = Bi + WjSji
j
</equation>
<bodyText confidence="0.983235796296296">
from Lewis and Vasishth (2005). In this equation,
Bi is the fluctuating baseline level of activation for
word i which is subject to time-based decay. In the
model, a goal buffer contains retrieval cues for in-
tegrating the current word. Overall activation A
for word i is found by adding to the baseline ac-
tivation for word i an associative activation boost
received from retrieval cues in the goal buffer that
are associated with i. The variable j indexes those
retrieval cues in the goal buffer. Wjs are weights
on the retrieval cues in the goal buffer. The weight
on a retrieval cue represents the proportion of the
total activation available for the whole goal buffer
that is assigned to the particular retrieval cue j in
the goal buffer. Sjis are the strengths of associ-
ation from each retrieval cue j of the goal buffer
to word i. This equation is effectively adding to
the baseline activation an activation boost received
from retrieval cues in the goal buffer.
The amount of similarity based interference is
estimated by the weighted strengths of association
between the word to be retrieved and retrieval cues
from other words already parsed and with a trace
in memory. In the following equation, word i is
the current word, and retrieval cue j is from a
word that is similar to word i, with reference to
its part of speech tag, so that nouns interfere with
other nouns but not with verbs. If retrieval cue j
is similar to word i then the amount by which re-
trieval cue j interferes with word i varies accord-
ing to how many words have already been associ-
ated with retrieval cue j. The array of words that
is associated with retrieval cue j is considered to
form a fan so that fanj gives the number of words
in the fan for cue j. The constant S refers to the
maximum associative strength of 1.5 (Lewis and
Vasishth, 2005).
Sji = S − ln(fanj)
This equation is effectively reducing the maxi-
mum associative strength S by the log of the ”fan”
of cue j, that is, the number of items associated
with j.
The mapping from activation level to retrieval
time is given next. F is a scaling constant set
to 0.14 in Lewis and Vasishth (2005). Ai is the
word’s activation and e is Euler’s constant. Ti is
retrieval time for word i:
Ti = FeAi
The retrieval time measure comes from Lewis
and Vasishth (2005) where a theory of sentence
processing is expressed as set of processes cor-
responding with skilled retrievals of linguistic
components from memory. However in that pa-
per it is computed over a phrase structure gram-
</bodyText>
<equation confidence="0.861690666666667">
�tr − d
n
r=1
</equation>
<page confidence="0.987968">
41
</page>
<bodyText confidence="0.999229">
mar. Boston provides a method to compute re-
trieval time over a dependency grammar in the
HUMDEP3.0 parser and Boston’s method (Boston,
2013) is used here.
Hypothesis 3 Retrieval time is related to human
sentence processing difficulty.
</bodyText>
<sectionHeader confidence="0.983267" genericHeader="method">
4 Eye movement metrics
</sectionHeader>
<bodyText confidence="0.999960972972973">
This section gives the metrics used to index hu-
man sentence processing load at disambiguation.
Rayner et al. (2012, p. 93) set out the most com-
mon eye tracking measures. These include the fol-
lowing measures: First Fixation Duration (FFD);
First Pass Reading Time (FPRT); Regression Path
Duration (RPD). These are defined next. First fixa-
tion duration (FFD) is the mean duration of the first
fixation on a word regardless of other possible fix-
ations on the word. It has traditionally been treated
as a measure of early processing. First fixation du-
ration is interpreted to index lexical access. First
pass reading time (FPRT): also known as gaze du-
ration, is the sum of the durations of all fixations
on the word that occur before leaving the word in
any direction. This still captures the early pro-
cessing (FFD is a subset of FPRT) but FPRT also
includes any refixations that there might be on the
word before a regression is launched from it. First
pass reading time is often interpreted to index lex-
ical integration into the phrase marker. Regression
path duration (RPD) includes FPRT but adds to it
the durations of fixations on preceding words that
the eyes regress to before leaving the word to the
right to take in new material, as well as any refix-
ations on the launch word that occur before new
material is taken in. In this way RPD is sensitive
to integration difficulties that yield regressive eye
movements but it also includes early processing.
Regression path duration is often interpreted to in-
dex incremental syntactic integration of the new
word into the sentence’s representation including
any semantic problems that arise from this.
Since RPD is the measure most sensitive to syn-
tactic disambiguation, it is used in this article as
a measure that is representative of human parsing
load at disambiguation.
</bodyText>
<sectionHeader confidence="0.994315" genericHeader="method">
5 Method
</sectionHeader>
<bodyText confidence="0.999954181818182">
This section tells how the eye tracking experiment
was carried out.
Participants were forty native speakers of
British English who were students of Psychology
at the University of Exeter and who participated
for course credit. All had normal or corrected-
t-normal vision, were naive as to the purpose of
the experiment, aged between eighteen and thirty-
four.
Apparatus used was an SR Research EyeLink II
head-mounted eyetracker. This recorded partici-
pants’ eye movements with a sampling rate of 500
Hz while they read sentences displayed on a 19
inch Iiyama Vision Master Pro monitor at 1024 x
768 resolution at a refresh rate of 60 Hz. Viewing
was binocular but only the right eye was recorded.
Participants sat in a dimly lit room in front of the
computer at a viewing distance of approximately
75 cm the average viewing distance was approx-
imately 75 cm. At this viewing distance, and as-
suming that 1 character had 2 mm width on screen,
a single character subtended 0.153 degrees of vi-
sual angle, and approximately 6.5 characters sub-
tended 1 degree of visual angle. The font used
was Courier New 12 point. All sentences in this
experiment were displayed on a single line with a
maximum length of 100 characters. A 9 point cali-
bration procedure was used, on which participants
were required to achieve a score of ‘good’. Each
trial started with a drift correction routine where
the participant was required to fixate a target that
appeared in the same location as the first character
of the sentence would subsequently occupy, and
then required to press a button on the gamepad
while fixating this point to start the trial.
Participants were instructed to read silently for
comprehension at a comfortable speed. The prac-
tice trials and experimental trials were imple-
mented as separate consecutive blocks. The ex-
perimental trials were randomised by Experiment
Builder each time the experiment was run, i.e.,
in a different order for each participant, with
the constraint that a maximum of two trials of a
given type could appear in a continuous sequence.
There were four practice sentences, followed by a
drift correction routine preceding the experimen-
tal block containing 96 sentences, comprising 24
in experimental conditions (6 in each of 4 con-
ditions); 24 foils (sentences that contained com-
plement ambiguities that resolved to NP) and 48
fillers (sentences that did not contain complement
ambiguity). Participants were rotated over one
of four lists, implementing a Latin square design.
32 of the trials (including 8 of the experimental
conditions) were followed immediately by a com-
</bodyText>
<page confidence="0.998015">
42
</page>
<bodyText confidence="0.999855833333333">
prehension question. This was a simple question
about the sentence immediately preceding that re-
quired the participant to make a yes or no re-
sponse using the appropriate trigger button on the
gamepad. The whole procedure took about 20 to
40 minutes, depending on the participant.
</bodyText>
<sectionHeader confidence="0.997698" genericHeader="evaluation">
6 Results
</sectionHeader>
<figureCaption confidence="0.941228666666667">
This section shows how the comparisons were
made between patterns of differential processing
load at disambiguation in the parser metrics and
the human metrics. Per-condition means of all
metrics at the disambiguating word are given in
Figure 3.
</figureCaption>
<subsectionHeader confidence="0.996354">
6.1 Regression path duration (RPD)
</subsectionHeader>
<bodyText confidence="0.999161636363637">
A linear mixed effects model (Bates et al., 2013)
was constructed for regression path duration at the
disambiguating word i.e., walked in the example
sentences. RPD was modeled as a function of
word length, word (unigram) frequency (Brants
and Franz, 2006), ambiguity, and sentence type
(type 1 is exemplified in sentence 1 and type 2
is exemplified in sentence 2), and the ambiguity
x sentence type interaction; with random slopes
for the ambiguity x sentence type interaction over
both participant ID and over item ID. Word length
and word frequency both exerted non-significant
influences. There was a significant effect of am-
biguity with the ambiguous conditions leading to
146 ms more RPD than the disambiguated condi-
tions (0 = 135.15, 5E = 37.60, t = 3.56).
There was a significant disadvantage for type 1
sentences of 79 ms as a main effect (0 = −68.59,
5E = 30.66, t = −2.27). There was significant
interaction effect such that the effect of ambigu-
ity in type 1 sentences was greater than the effect
of ambiguity for type 2 sentences (0 = −64.28,
</bodyText>
<equation confidence="0.571916">
5E = 31.33, t = −2.05).
</equation>
<subsectionHeader confidence="0.999719">
6.2 Phrase structure surprisal
</subsectionHeader>
<bodyText confidence="0.997897545454545">
Phrase structure surprisal predicted that the am-
biguous cases would be harder then the unambigu-
ous cases; and that the disadvantage of sentence
type 1 in the ambiguous cases would turn around
into a disadvantage of sentence type 2 in the unam-
biguous conditions. Individual terms for ambigu-
ity and sentence type were included at each level
of item. Effects of ambiguity, sentence type and
the ambiguity x sentence type interaction were all
significant in the model, and the shapes of these
effects were broadly in line with the human data
</bodyText>
<equation confidence="0.626869666666667">
(0 = 0.65, 5E = 0.05, t = 12.32, 0 = −0.11,
5E = 0.03, t = −3.25, and 0 = −0.35, 5E =
0.01, t = −62.35 respectively).
</equation>
<subsectionHeader confidence="0.997613">
6.3 Phrase structure entropy reduction
</subsectionHeader>
<bodyText confidence="0.999360363636364">
The directions of the entropy reduction hypothesis
predictions were the same as for phrase structure
surprisal, although there was a relatively greater
difficulty with the type 2 cases versus surprisal.
Effects of ambiguity, sentence type and the am-
biguity x sentence type interaction were all sig-
nificant in the model (0 = 0.32, 5E = 0.02,
t = 14.04, 0 = −0.03, 5E = 0.02, t = −2.05,
and 0 = −0.17, 5E = 0.002, t = −55.79 respec-
tively). The shapes of these effects were broadly
in line with the human data.
</bodyText>
<subsectionHeader confidence="0.989079">
6.4 Dependency surprisal
</subsectionHeader>
<bodyText confidence="0.999838470588235">
The mean values of dependency surprisal at the
disambiguating word show that ambiguous sen-
tence types 1 and 2 are predicted to be equal. For
the unambiguous cases, type 1 is predicted to be
more difficult than type 2. Ambiguity did not
exert a significant effect on dependency surprisal
(0 = 0.0002, 5E = 0.01, t = 0.01). The ef-
fect of sentence type was significant, with type
1 causing more dependency surprisal than type 2
(0 = −0.09, 5E = 0.01, t = −6.26). The am-
biguity x sentence type interaction was significant
in the model (0 = 0.09, 5E = 0.002, t = 39.67)
but the shape of the interaction did not match the
shape of the human data: instead the model pre-
dicted a large effect of sentence type in the unam-
biguous conditions and a small effect of sentence
type in the unambiguous control sentences.
</bodyText>
<subsectionHeader confidence="0.996257">
6.5 Dependency retrieval time
</subsectionHeader>
<bodyText confidence="0.910398153846154">
The mean values for retrieval predicted that both
of the ambiguous sentence types and unambigu-
ous type 1 sentences should be equally difficult,
with unambiguous type 1 predicted to cause the
most difficulty. Main effects of ambiguity and
sentence type were significant in the model (0 =
−17.7, 5E = 0.60, t = −29.72 and 0 = 17.7,
5E = 0.6, t = 29.72 respectively). There was
a significant ambiguity x sentence type interaction
(0 = −17.7, 5E = 0.09, t = −191.25). Compar-
ing these prediction with the human data, the pre-
dictions are not in line with human performance at
all.
</bodyText>
<page confidence="0.999727">
43
</page>
<figure confidence="0.997155510204082">
RPD
●
10.0
9.5
9.0
8.5
TDP Surprisal
●
2.4
2.2
2.0
●
1.8
●
TDP E.R.
●
●
1.3
●
1.1
DEP Surprisal
●
260
●
220
●
DEP ACTR
●
●
500
450
400
350
300
●
●
2.6
●
1.4
1.2
●
280
240
●
●
●
sentence type 1
sentence type 2
ambig control ambig control ambig control ambig control ambig control
</figure>
<figureCaption confidence="0.9761792">
Figure 3: Per-condition means for each metric for the disambiguating word. RPD is the human eye
movement measure regression path duration, see section 6.1. TDP Surprisal is surprisal computed over
a phrase structure grammar, see section 6.2. TDP E.R. is entropy reduction computed over a phrase
structure grammar, see section 6.3. DEP Surprisal is surprisal computed over a dependency grammar,
section 6.4; DEP ATCR is retrieval time computed over a dependency grammar, section 6.5.
</figureCaption>
<sectionHeader confidence="0.995589" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999974791666668">
This section lays out the the conclusions that can
be drawn from this work, paying attention to the
question whether an information theoretic mea-
sure can be used in the NLG process as a proxy
for human reading difficulty, as part of an effort to
generate more readable texts.
For the metrics computed over a phrase struc-
ture grammar (phrase structure surprisal and phase
structure entropy reduction), the comparison with
human eye tracking metrics is relatively close.
This suggests that phrase structure surprisal and
phase structure entropy reduction are tracking hu-
man reading difficulty at disambiguation well.
Phrase structure surprisal and phase structure en-
tropy reduction are good predictors of the sort of
human parsing difficulty that is measured by re-
gression path duration, for these sentence types.
Dependency surprisal computed over a depen-
dency grammar using a k-best parser with k=3
produces the wrong predictions for the comple-
ment ambiguity sentence types in this article.
There is some scope for improving the predic-
tions of this parser, as follows. Firstly setting
k=3 may be restricting the beam width too much
such that the ultimately-correct analysis is pruned
too early. If so, simulations with increased val-
ues of k might be worth exploring. Secondly, one
of the sentence types in this article relies on dis-
ambiguation by punctuation. Punctuation is well-
handled in phrase structural grammars because it
serves as a clause boundary marker, and phrase
structure grammars natively express sentences as
phrase combinations, whereas dependency gram-
mars can only treat punctuation as a terminal in its
own right. This might turn out to lead to an un-
fair comparison between dependency parser per-
formance and phrase structure performance for the
sentence types examined here. There is a clear
case for examining dependency parsing for disam-
biguation types that use the sequence of words to
effect disambiguation. Future work in this direc-
tion could take advantage of previous work with
different ambiguities covered in e.g., Boston and
Hale (2007) and Boston (2012), and extending
it from using self-paced reading times to include
eye-tracking metrics.
Dependency retrieval time did not show the in-
teraction evident in the eye movement and phase
grammar parser data. This suggests either that the
Lewis and Vasishth (2005) model does not cover
very well the sentence types used in this experi-
ment, or that whatever coverage the Lewis and Va-
sishth (2005) model does have of the human data is
obscured in the transformation from phrase struc-
ture grammar to dependency grammar versions of
retrieval.
Previous work aimed at broad-coverage parsing
evaluated against human eye movement corpora
(Demberg and Keller, 2008; Boston et al., 2011)
indicates that, in those corpus-derived linguistic
environments, phrase structure surprisal and phase
structure entropy reduction account for different
components of variance in eye movement patterns.
If future work continues to find that surprisal and
entropy reduction predict human difficulty in psy-
cholinguistic eye movement lab-based investiga-
tions (and the present paper shows how that can
be done for one ambiguity type), then it will be
reasonable to propose that a good model of sen-
tence processing should use both surprisal and en-
tropy reduction to predict (human) reading diffi-
culty. Such a model would need to consider care-
</bodyText>
<page confidence="0.997114">
44
</page>
<bodyText confidence="0.999991105263158">
fully the nature of the relationship between these
different types of parser complexity. A starting
point could be the observation that surprisal is es-
sentially backwards-looking (seeks to disconfirm
past analyses) whereas entropy reduction is essen-
tially forward-looking (seeks to establish the un-
certainty that remains at the current word with re-
spect to how the rest of the sentence might pan
out).
For NLG, the importance of this proposal is that
such a model could be used to answer, algorith-
mically, questions that have previously only been
satisfactorily answered in the laboratory. For ex-
ample, in NLG the question often arises “For this
proposition P, which we want the generator to put
in a surface form SF for some given natural lan-
guage L, which of the many possible SFs that ex-
press P in L should we produce?”. So far this
question has only been satisfactorily addressed by
laboratory studies, which are few in number, ex-
pensive to run, and hard to generalise from.
When such generators are faced with this ques-
tion, a better way forward would be to generate
(some finite subset of) all possible SFs that ex-
press P in L, and then use surprisal and entropy
reduction metrics as thresholds for pruning and
ranking the SFs. This would lead the generator to
produce only SFs that avoid syntactic complexity
for the benefit of human readers. Different thresh-
olds could produce texts tailor-made for groups
with different reading abilities, or texts aimed to
meet other constraints on acceptable human dif-
ficulty, e.g., texts for beginners learning a given
natural language for the first time, or texts with
different forms aimed at novices and experts.
Reiter and Belz (2009) discuss and evaluate
some metrics for automatic evaluation of NLG in
the context of generating weather forecasts. How-
ever these are designed to fit human measures at
the whole-document level of NLG, different from
the sentence-level incremental predictions gener-
ated and evaluated here. Also the evaluations dis-
cussed by those authors are done by fitting mea-
sures from offline human ratings of text readabil-
ity, again different from the fine-grained detail
of online human processing provided by the eye-
tracking experiment here.
It seems clear that a combination of document-
level and sentence-level predictors of human diffi-
culty with generated text would be better than ei-
ther alone for guiding NLG systems. It is conceiv-
able that surprisal and entropy reduction might be-
come useful automatic metrics for sentence-level
evaluation of NLG texts, in the same way that
BLEU (Papineni et al., 2002) and similar metrics
serve in Machine Translation, but incrementally,
and at a finer-grained and level.
</bodyText>
<sectionHeader confidence="0.99854" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999808">
J.R. Anderson. 2005. Human symbol manipulation
within an integrated cognitive architecture. Cogni-
tive science, 29(3):313–341.
Douglas Bates, Martin Maechler, Ben Bolker, and
Steven Walker. 2013. lme4: Linear mixed-effects
models using Eigen and S4. R package version 1.0-
5.
M.F. Boston and J. Hale. 2007. Garden-pathing in a
statistical dependency parser. In Proceedings of the
Midwest Computational Linguistics Colloquium.
M.F. Boston, John T. Hale, Shravan Vasishth, and Rein-
hold Kliegl. 2011. Parallel processing and sentence
comprehension difficulty. Language and Cognitive
Processes, 26(3):301–349.
M.F. Boston. 2012. A Computational Model of Cogni-
tive Constraints in Syntactic Locality. Ph.D. thesis,
Cornell University, January.
M.F. Boston. 2013. Humdep3.0. An incremental
dependency parser developed for human sentence
processing modeling. http://conf.ling.
cornell.edu/Marisa.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-
gram Version. computed from Google, published by
Linguistic Data Consortium.
C. Clifton Jr. 1993. Thematic roles in sentence pars-
ing. Canadian Journal of Experimental Psychology,
47(2):222–46.
V. Demberg and F. Keller. 2008. Data from eye-
tracking corpora as evidence for theories of syntactic
processing complexity. Cognition, 109(2):193–210.
F. Ferreira and J.M. Henderson. 1991. Recovery from
misanalyses of garden-path sentences. Journal of
Memory and Language, 30(6):725–745.
M.J. Green. 2014. On Repairing Sentences: An Ex-
perimental and Computational Analysis of Recovery
from Unexpected Syntactic Disambiguation in Sen-
tence Parsing. Ph.D. thesis, Psychology, Exeter.
J. Hale. 2001. A Probabilistic Earley Parser as a Psy-
cholinguistic Model. In Proceedings Of The Second
Meeting Of The North American Chapter Of The As-
sociation For Computational Linguistics, pages 1–
8, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.983948">
45
</page>
<reference confidence="0.999931194444444">
J. Hale. 2004. The information-processing diffi-
culty of incremental parsing. In F. Keller, S. Clark,
M Crocker, and M. Steedman, editors, ACL Work-
shop Incremental Parsing: Bringing Engineering
and Cognition Together, pages 58–65. Association
for Computational Linguistics.
J. Hale. 2006. Uncertainty about the rest of the sen-
tence. Cognitive Science, 30(4):643–672.
V.M. Holmes, A. Kennedy, and W.S. Murray. 1987.
Syntactic structure and the garden path. The Quar-
terly Journal of Experimental Psychology Section A:
Human Experimental Psychology, 39(2):2 – 277.
R. Levy. 2008. Expectation-Based Syntactic Compre-
hension. Cognition, 106(3):1126–1177.
R.L. Lewis and S. Vasishth. 2005. An activation-based
model of sentence processing as skilled memory re-
trieval. Cognitive Science, 29:1–45.
B. McElree, S. Foraker, and L. Dyer. 2003. Mem-
ory structures that subserve sentence comprehen-
sion. Journal of Memory and Language, 48(1):67–
91.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th annual meeting on association for compu-
tational linguistics, pages 311–318. Association for
Computational Linguistics.
Umesh Patil, Shravan Vasishth, and Reinhold Kliegl.
2009. Compound effect of probabilistic disam-
biguation and memory retrievals on sentence pro-
cessing: Evidence from an eyetracking corpus. In
Proceedings of 9th International Conference on
Cognitive Modeling, Manchester.
M.J. Pickering and M.J. Traxler. 1998. Plausibility
and recovery from garden paths: An eye-tracking
study. Journal of Experimental Psychology: Learn-
ing, Memory, and Cognition, 24(4):940–961.
K. Rayner and L. Frazier. 1987. Parsing temporarily
ambiguous complements. The Quarterly Journal of
Experimental Psychology Section A: Human Exper-
imental Psychology, 39(4):657 – 673.
K. Rayner, A. Pollatsek, J. Ashby, and C. Clifton Jr.
2012. Psychology of Reading. Psychology Press,
2nd edition.
Ehud Reiter and Anja Belz. 2009. An investiga-
tion into the validity of some metrics for automat-
ically evaluating natural language generation sys-
tems. Computational Linguistics, 35(4):529–558.
Brian Roark. 2001. Probabilistic top-down parsing
and language modeling. Computational linguistics,
27(2):249–276.
Brian Roark. 2004. Robust garden path parsing. Nat-
ural language engineering, 10(1):1–24.
B. Roark. 2013. tdparse. An incremental top
downparser. http://code.google.com/p/
incremental-top-down-parser/.
Claude Shannon. 1948. A mathematical theory of
communication. Bell Systems Technical Journal,
27:379—423.
P. Sturt, M.J. Pickering, and M.W. Crocker. 1999.
Structural Change and Reanalysis Difficulty in Lan-
guage Comprehension. Journal of Memory and
Language, 40:136–150.
J C Trueswell, M K Tanenhaus, and C Kello. 1993.
Verb-specific constraints in sentence processing:
separating effects of lexical preference from garden-
paths. J Exp Psychol Learn Mem Cogn, 19(3):528–
53.
S. Vasishth, S. Br¨ussow, R.L. Lewis, and H. Drenhaus.
2008. Processing polarity: How the ungrammati-
cal intrudes on the grammatical. Cognitive Science,
32(4):685–712.
</reference>
<page confidence="0.999612">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.499565">
<title confidence="0.995331">An eye-tracking evaluation of some parser complexity metrics</title>
<author confidence="0.999999">Matthew J Green</author>
<affiliation confidence="0.999976">University of Aberdeen,</affiliation>
<email confidence="0.999126">mjgreen@abdn.ac.uk</email>
<abstract confidence="0.9685368125">Information theoretic measures of incremental parser load were generated from a phrase structure parser and a dependency parser and then compared with incremental eye movement metrics collected for the same temporarily syntactically ambiguous sentences, focussing on the disambiguating word. The findings show that the reduction computed over a phrase structure grammar make good candidates for predictors of text readability for human comprehenders. This leads to a suggestion for the use of such metrics in Natural Language Generation (NLG).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J R Anderson</author>
</authors>
<title>Human symbol manipulation within an integrated cognitive architecture. Cognitive science,</title>
<date>2005</date>
<pages>29--3</pages>
<contexts>
<context position="11447" citStr="Anderson, 2005" startWordPosition="1906" endWordPosition="1908">ty are combined to predict the amount of time that it takes to read a word (Vasishth et al., 2008). A word’s activation is based on two quantities: the baseline activation of the word, which is taken to decay given the passage of time; and the amount of similarity based interference with other words that have been parsed. The baseline activation B for a word i is given here, taken from Lewis and Vasishth (2005), and Patil et al. (2009), where tr is the time since the rth retrieval of the word, the summation is over all n retrievals, and d is a decay factor set to 0.5 as in other ACT-R models (Anderson, 2005). Bi = ln The equation tracks the log odds that a word will need to be retrieved, given its past usage history. It yields not a smoothly decaying activation from initial encoding to the current time, but a ”series of spikes corresponding to the retrieval events” (Lewis and Vasishth, 2005). The overall activation A for word i is given here �Ai = Bi + WjSji j from Lewis and Vasishth (2005). In this equation, Bi is the fluctuating baseline level of activation for word i which is subject to time-based decay. In the model, a goal buffer contains retrieval cues for integrating the current word. Over</context>
</contexts>
<marker>Anderson, 2005</marker>
<rawString>J.R. Anderson. 2005. Human symbol manipulation within an integrated cognitive architecture. Cognitive science, 29(3):313–341.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Bates</author>
<author>Martin Maechler</author>
<author>Ben Bolker</author>
<author>Steven Walker</author>
</authors>
<title>lme4: Linear mixed-effects models using Eigen and S4. R package version 1.0-5.</title>
<date>2013</date>
<contexts>
<context position="19635" citStr="Bates et al., 2013" startWordPosition="3310" endWordPosition="3313">rehension question. This was a simple question about the sentence immediately preceding that required the participant to make a yes or no response using the appropriate trigger button on the gamepad. The whole procedure took about 20 to 40 minutes, depending on the participant. 6 Results This section shows how the comparisons were made between patterns of differential processing load at disambiguation in the parser metrics and the human metrics. Per-condition means of all metrics at the disambiguating word are given in Figure 3. 6.1 Regression path duration (RPD) A linear mixed effects model (Bates et al., 2013) was constructed for regression path duration at the disambiguating word i.e., walked in the example sentences. RPD was modeled as a function of word length, word (unigram) frequency (Brants and Franz, 2006), ambiguity, and sentence type (type 1 is exemplified in sentence 1 and type 2 is exemplified in sentence 2), and the ambiguity x sentence type interaction; with random slopes for the ambiguity x sentence type interaction over both participant ID and over item ID. Word length and word frequency both exerted non-significant influences. There was a significant effect of ambiguity with the amb</context>
</contexts>
<marker>Bates, Maechler, Bolker, Walker, 2013</marker>
<rawString>Douglas Bates, Martin Maechler, Ben Bolker, and Steven Walker. 2013. lme4: Linear mixed-effects models using Eigen and S4. R package version 1.0-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Boston</author>
<author>J Hale</author>
</authors>
<title>Garden-pathing in a statistical dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the Midwest Computational Linguistics Colloquium.</booktitle>
<contexts>
<context position="8693" citStr="Boston and Hale (2007)" startWordPosition="1434" endWordPosition="1437">tached NP is attached in the ultimately correct analysis. Figure 2: Phrase markers showing disambiguation in sentence type 2. The left phrasemarker shows the initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached in the ultimately correct analysis. S ADVP S&apos; IN S&apos; NP VP After NP VP the captain walked ... NP the captain the cadet V saluted the cadet V saluted S ADVP S&apos; IN S&apos; After NP VP S S NP VP The cadet V NP VP noticed the cadet V S&apos; noticed NP VP the captain walked ... NP the captain The HUMDEP parser provided by Boston (2013) and described in Boston and Hale (2007) and Boston (2012) computes surprisal over a dependency grammar transition system, incrementally for each word in a sentence. It is a k-best parser. Here the value of k was set to 3, in line with previous use of the parser to model human disambiguation performance for garden-path sentences in Boston and Hale (2007). Hypothesis 1 Hale (2001), and also Levy (2008), gave the hypothesis that surprisal is linearly related to the human effort of processing a particular word in a sentence fragment. This hypothesis casts disambiguation as the work incurred by disconfirming all parses of the fragment t</context>
<context position="26177" citStr="Boston and Hale (2007)" startWordPosition="4441" endWordPosition="4444">ause boundary marker, and phrase structure grammars natively express sentences as phrase combinations, whereas dependency grammars can only treat punctuation as a terminal in its own right. This might turn out to lead to an unfair comparison between dependency parser performance and phrase structure performance for the sentence types examined here. There is a clear case for examining dependency parsing for disambiguation types that use the sequence of words to effect disambiguation. Future work in this direction could take advantage of previous work with different ambiguities covered in e.g., Boston and Hale (2007) and Boston (2012), and extending it from using self-paced reading times to include eye-tracking metrics. Dependency retrieval time did not show the interaction evident in the eye movement and phase grammar parser data. This suggests either that the Lewis and Vasishth (2005) model does not cover very well the sentence types used in this experiment, or that whatever coverage the Lewis and Vasishth (2005) model does have of the human data is obscured in the transformation from phrase structure grammar to dependency grammar versions of retrieval. Previous work aimed at broad-coverage parsing eval</context>
</contexts>
<marker>Boston, Hale, 2007</marker>
<rawString>M.F. Boston and J. Hale. 2007. Garden-pathing in a statistical dependency parser. In Proceedings of the Midwest Computational Linguistics Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Boston</author>
<author>John T Hale</author>
<author>Shravan Vasishth</author>
<author>Reinhold Kliegl</author>
</authors>
<title>Parallel processing and sentence comprehension difficulty. Language and Cognitive Processes,</title>
<date>2011</date>
<contexts>
<context position="26865" citStr="Boston et al., 2011" startWordPosition="4551" endWordPosition="4554">imes to include eye-tracking metrics. Dependency retrieval time did not show the interaction evident in the eye movement and phase grammar parser data. This suggests either that the Lewis and Vasishth (2005) model does not cover very well the sentence types used in this experiment, or that whatever coverage the Lewis and Vasishth (2005) model does have of the human data is obscured in the transformation from phrase structure grammar to dependency grammar versions of retrieval. Previous work aimed at broad-coverage parsing evaluated against human eye movement corpora (Demberg and Keller, 2008; Boston et al., 2011) indicates that, in those corpus-derived linguistic environments, phrase structure surprisal and phase structure entropy reduction account for different components of variance in eye movement patterns. If future work continues to find that surprisal and entropy reduction predict human difficulty in psycholinguistic eye movement lab-based investigations (and the present paper shows how that can be done for one ambiguity type), then it will be reasonable to propose that a good model of sentence processing should use both surprisal and entropy reduction to predict (human) reading difficulty. Such</context>
</contexts>
<marker>Boston, Hale, Vasishth, Kliegl, 2011</marker>
<rawString>M.F. Boston, John T. Hale, Shravan Vasishth, and Reinhold Kliegl. 2011. Parallel processing and sentence comprehension difficulty. Language and Cognitive Processes, 26(3):301–349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Boston</author>
</authors>
<title>A Computational Model of Cognitive Constraints</title>
<date>2012</date>
<booktitle>in Syntactic Locality. Ph.D. thesis,</booktitle>
<institution>Cornell University,</institution>
<contexts>
<context position="8711" citStr="Boston (2012)" startWordPosition="1439" endWordPosition="1440">e ultimately correct analysis. Figure 2: Phrase markers showing disambiguation in sentence type 2. The left phrasemarker shows the initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached in the ultimately correct analysis. S ADVP S&apos; IN S&apos; NP VP After NP VP the captain walked ... NP the captain the cadet V saluted the cadet V saluted S ADVP S&apos; IN S&apos; After NP VP S S NP VP The cadet V NP VP noticed the cadet V S&apos; noticed NP VP the captain walked ... NP the captain The HUMDEP parser provided by Boston (2013) and described in Boston and Hale (2007) and Boston (2012) computes surprisal over a dependency grammar transition system, incrementally for each word in a sentence. It is a k-best parser. Here the value of k was set to 3, in line with previous use of the parser to model human disambiguation performance for garden-path sentences in Boston and Hale (2007). Hypothesis 1 Hale (2001), and also Levy (2008), gave the hypothesis that surprisal is linearly related to the human effort of processing a particular word in a sentence fragment. This hypothesis casts disambiguation as the work incurred by disconfirming all parses of the fragment that are inconsiste</context>
<context position="26195" citStr="Boston (2012)" startWordPosition="4446" endWordPosition="4447">hrase structure grammars natively express sentences as phrase combinations, whereas dependency grammars can only treat punctuation as a terminal in its own right. This might turn out to lead to an unfair comparison between dependency parser performance and phrase structure performance for the sentence types examined here. There is a clear case for examining dependency parsing for disambiguation types that use the sequence of words to effect disambiguation. Future work in this direction could take advantage of previous work with different ambiguities covered in e.g., Boston and Hale (2007) and Boston (2012), and extending it from using self-paced reading times to include eye-tracking metrics. Dependency retrieval time did not show the interaction evident in the eye movement and phase grammar parser data. This suggests either that the Lewis and Vasishth (2005) model does not cover very well the sentence types used in this experiment, or that whatever coverage the Lewis and Vasishth (2005) model does have of the human data is obscured in the transformation from phrase structure grammar to dependency grammar versions of retrieval. Previous work aimed at broad-coverage parsing evaluated against huma</context>
</contexts>
<marker>Boston, 2012</marker>
<rawString>M.F. Boston. 2012. A Computational Model of Cognitive Constraints in Syntactic Locality. Ph.D. thesis, Cornell University, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Boston</author>
</authors>
<title>Humdep3.0. An incremental dependency parser developed for human sentence processing modeling.</title>
<date>2013</date>
<note>http://conf.ling. cornell.edu/Marisa.</note>
<contexts>
<context position="8653" citStr="Boston (2013)" startWordPosition="1429" endWordPosition="1430">ws how the same initially misattached NP is attached in the ultimately correct analysis. Figure 2: Phrase markers showing disambiguation in sentence type 2. The left phrasemarker shows the initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached in the ultimately correct analysis. S ADVP S&apos; IN S&apos; NP VP After NP VP the captain walked ... NP the captain the cadet V saluted the cadet V saluted S ADVP S&apos; IN S&apos; After NP VP S S NP VP The cadet V NP VP noticed the cadet V S&apos; noticed NP VP the captain walked ... NP the captain The HUMDEP parser provided by Boston (2013) and described in Boston and Hale (2007) and Boston (2012) computes surprisal over a dependency grammar transition system, incrementally for each word in a sentence. It is a k-best parser. Here the value of k was set to 3, in line with previous use of the parser to model human disambiguation performance for garden-path sentences in Boston and Hale (2007). Hypothesis 1 Hale (2001), and also Levy (2008), gave the hypothesis that surprisal is linearly related to the human effort of processing a particular word in a sentence fragment. This hypothesis casts disambiguation as the work incurred by di</context>
<context position="14474" citStr="Boston, 2013" startWordPosition="2454" endWordPosition="2455"> is given next. F is a scaling constant set to 0.14 in Lewis and Vasishth (2005). Ai is the word’s activation and e is Euler’s constant. Ti is retrieval time for word i: Ti = FeAi The retrieval time measure comes from Lewis and Vasishth (2005) where a theory of sentence processing is expressed as set of processes corresponding with skilled retrievals of linguistic components from memory. However in that paper it is computed over a phrase structure gram�tr − d n r=1 41 mar. Boston provides a method to compute retrieval time over a dependency grammar in the HUMDEP3.0 parser and Boston’s method (Boston, 2013) is used here. Hypothesis 3 Retrieval time is related to human sentence processing difficulty. 4 Eye movement metrics This section gives the metrics used to index human sentence processing load at disambiguation. Rayner et al. (2012, p. 93) set out the most common eye tracking measures. These include the following measures: First Fixation Duration (FFD); First Pass Reading Time (FPRT); Regression Path Duration (RPD). These are defined next. First fixation duration (FFD) is the mean duration of the first fixation on a word regardless of other possible fixations on the word. It has traditionally</context>
</contexts>
<marker>Boston, 2013</marker>
<rawString>M.F. Boston. 2013. Humdep3.0. An incremental dependency parser developed for human sentence processing modeling. http://conf.ling. cornell.edu/Marisa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram Version. computed from Google, published by Linguistic Data Consortium.</title>
<date>2006</date>
<contexts>
<context position="19842" citStr="Brants and Franz, 2006" startWordPosition="3342" endWordPosition="3345"> whole procedure took about 20 to 40 minutes, depending on the participant. 6 Results This section shows how the comparisons were made between patterns of differential processing load at disambiguation in the parser metrics and the human metrics. Per-condition means of all metrics at the disambiguating word are given in Figure 3. 6.1 Regression path duration (RPD) A linear mixed effects model (Bates et al., 2013) was constructed for regression path duration at the disambiguating word i.e., walked in the example sentences. RPD was modeled as a function of word length, word (unigram) frequency (Brants and Franz, 2006), ambiguity, and sentence type (type 1 is exemplified in sentence 1 and type 2 is exemplified in sentence 2), and the ambiguity x sentence type interaction; with random slopes for the ambiguity x sentence type interaction over both participant ID and over item ID. Word length and word frequency both exerted non-significant influences. There was a significant effect of ambiguity with the ambiguous conditions leading to 146 ms more RPD than the disambiguated conditions (0 = 135.15, 5E = 37.60, t = 3.56). There was a significant disadvantage for type 1 sentences of 79 ms as a main effect (0 = −68</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram Version. computed from Google, published by Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Clifton Jr</author>
</authors>
<title>Thematic roles in sentence parsing.</title>
<date>1993</date>
<journal>Canadian Journal of Experimental Psychology,</journal>
<volume>47</volume>
<issue>2</issue>
<contexts>
<context position="4315" citStr="Jr, 1993" startWordPosition="680" endWordPosition="681">tics of words like noticed is that the words immediately following could properly be the start of a main clause where the clause containing noticed is properly a subordinate clause. Such cases are sometimes referred to as reduced complements. In these cases only the presence of a main verb resolves the temporary syntactic ambiguity, and when it appears, some major restructuring is involved. Complement ambiguities of both kinds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser predictions for complement ambiguity, and discusses applications of syntactic complexity metrics</context>
</contexts>
<marker>Jr, 1993</marker>
<rawString>C. Clifton Jr. 1993. Thematic roles in sentence parsing. Canadian Journal of Experimental Psychology, 47(2):222–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Demberg</author>
<author>F Keller</author>
</authors>
<title>Data from eyetracking corpora as evidence for theories of syntactic processing complexity.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>109</volume>
<issue>2</issue>
<contexts>
<context position="26843" citStr="Demberg and Keller, 2008" startWordPosition="4547" endWordPosition="4550">using self-paced reading times to include eye-tracking metrics. Dependency retrieval time did not show the interaction evident in the eye movement and phase grammar parser data. This suggests either that the Lewis and Vasishth (2005) model does not cover very well the sentence types used in this experiment, or that whatever coverage the Lewis and Vasishth (2005) model does have of the human data is obscured in the transformation from phrase structure grammar to dependency grammar versions of retrieval. Previous work aimed at broad-coverage parsing evaluated against human eye movement corpora (Demberg and Keller, 2008; Boston et al., 2011) indicates that, in those corpus-derived linguistic environments, phrase structure surprisal and phase structure entropy reduction account for different components of variance in eye movement patterns. If future work continues to find that surprisal and entropy reduction predict human difficulty in psycholinguistic eye movement lab-based investigations (and the present paper shows how that can be done for one ambiguity type), then it will be reasonable to propose that a good model of sentence processing should use both surprisal and entropy reduction to predict (human) re</context>
</contexts>
<marker>Demberg, Keller, 2008</marker>
<rawString>V. Demberg and F. Keller. 2008. Data from eyetracking corpora as evidence for theories of syntactic processing complexity. Cognition, 109(2):193–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ferreira</author>
<author>J M Henderson</author>
</authors>
<title>Recovery from misanalyses of garden-path sentences.</title>
<date>1991</date>
<journal>Journal of Memory and Language,</journal>
<volume>30</volume>
<issue>6</issue>
<contexts>
<context position="4297" citStr="Ferreira and Henderson, 1991" startWordPosition="675" endWordPosition="678"> Association for Computational Linguistics of words like noticed is that the words immediately following could properly be the start of a main clause where the clause containing noticed is properly a subordinate clause. Such cases are sometimes referred to as reduced complements. In these cases only the presence of a main verb resolves the temporary syntactic ambiguity, and when it appears, some major restructuring is involved. Complement ambiguities of both kinds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser predictions for complement ambiguity, and discusses applications of syntactic </context>
</contexts>
<marker>Ferreira, Henderson, 1991</marker>
<rawString>F. Ferreira and J.M. Henderson. 1991. Recovery from misanalyses of garden-path sentences. Journal of Memory and Language, 30(6):725–745.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Green</author>
</authors>
<title>On Repairing Sentences: An Experimental and Computational Analysis of Recovery from Unexpected Syntactic Disambiguation in Sentence Parsing.</title>
<date>2014</date>
<tech>Ph.D. thesis,</tech>
<institution>Psychology, Exeter.</institution>
<contexts>
<context position="4747" citStr="Green, 2014" startWordPosition="747" endWordPosition="748">ds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser predictions for complement ambiguity, and discusses applications of syntactic complexity metrics for evaluating test readability. 3 Parser metrics This section gives details of the surprisal, entropy reduction, and retrieval time metrics, and how they are computed. 3.1 Surprisal Surprisal was computed over a phase structure parser, and over a dependency parser. Surprisal is computed using two other quantities. These quantities are: (1) the probability of a derivation: a derivation is a set of weighted rule productions that</context>
</contexts>
<marker>Green, 2014</marker>
<rawString>M.J. Green. 2014. On Repairing Sentences: An Experimental and Computational Analysis of Recovery from Unexpected Syntactic Disambiguation in Sentence Parsing. Ph.D. thesis, Psychology, Exeter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hale</author>
</authors>
<title>A Probabilistic Earley Parser as a Psycholinguistic Model.</title>
<date>2001</date>
<booktitle>In Proceedings Of The Second Meeting Of The North American Chapter Of The Association For Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9035" citStr="Hale (2001)" startWordPosition="1496" endWordPosition="1497">NP the captain the cadet V saluted the cadet V saluted S ADVP S&apos; IN S&apos; After NP VP S S NP VP The cadet V NP VP noticed the cadet V S&apos; noticed NP VP the captain walked ... NP the captain The HUMDEP parser provided by Boston (2013) and described in Boston and Hale (2007) and Boston (2012) computes surprisal over a dependency grammar transition system, incrementally for each word in a sentence. It is a k-best parser. Here the value of k was set to 3, in line with previous use of the parser to model human disambiguation performance for garden-path sentences in Boston and Hale (2007). Hypothesis 1 Hale (2001), and also Levy (2008), gave the hypothesis that surprisal is linearly related to the human effort of processing a particular word in a sentence fragment. This hypothesis casts disambiguation as the work incurred by disconfirming all parses of the fragment that are inconsistent with the fragment including the disambiguating word. 3.2 Entropy reduction Entropy reduction was computed over the output of the phrase structure parser TDPARSE. In general, the entropy (Shannon, 1948), denoted H, of a random variable is the uncertainty associated with that variable. Specifically, for a discrete random </context>
</contexts>
<marker>Hale, 2001</marker>
<rawString>J. Hale. 2001. A Probabilistic Earley Parser as a Psycholinguistic Model. In Proceedings Of The Second Meeting Of The North American Chapter Of The Association For Computational Linguistics, pages 1– 8, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hale</author>
</authors>
<title>The information-processing difficulty of incremental parsing.</title>
<date>2004</date>
<booktitle>ACL Workshop Incremental Parsing: Bringing Engineering and Cognition Together,</booktitle>
<pages>58--65</pages>
<editor>In F. Keller, S. Clark, M Crocker, and M. Steedman, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<contexts>
<context position="10146" citStr="Hale (2004)" startWordPosition="1686" endWordPosition="1687">ndom variable is the uncertainty associated with that variable. Specifically, for a discrete random variable X with outcomes x1, x2,... with probabilities p1, p2, .. . H(X) = − 1: px log2 px x∈X Putting this in sentence processing terms, let D be a set of derivations for a sentence fragment W and let X be the extended sentence fragment that results from adding a new word to the fragment. 1: H(G, D, W) = − prp(G, X)log(prp(G, X)) The quantity entropy reduction is defined with a lower bound of zero so that this quantity is never 40 negative: ER = max(0, H(D|w1...k) − H(D|w1...k+1)) Hypothesis 2 Hale (2004) and Hale (2006) gave the entropy reduction hypothesis that the human effort of processing a particular word in a sentence fragment is the reduction in entropy from its value given the fragment to its value given the fragment including the disambiguating word. 3.3 Retrieval time Parsing in retrieval theory (Lewis and Vasishth, 2005) is accomplished by condition-action pairs generated with reference to a phrase structure grammar. A series of memory buffers stores elements in short-term and long-term buffers. Parallel associative retrieval (McElree et al., 2003), fluctuation of activation of ele</context>
</contexts>
<marker>Hale, 2004</marker>
<rawString>J. Hale. 2004. The information-processing difficulty of incremental parsing. In F. Keller, S. Clark, M Crocker, and M. Steedman, editors, ACL Workshop Incremental Parsing: Bringing Engineering and Cognition Together, pages 58–65. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hale</author>
</authors>
<title>Uncertainty about the rest of the sentence.</title>
<date>2006</date>
<journal>Cognitive Science,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="10162" citStr="Hale (2006)" startWordPosition="1689" endWordPosition="1690"> the uncertainty associated with that variable. Specifically, for a discrete random variable X with outcomes x1, x2,... with probabilities p1, p2, .. . H(X) = − 1: px log2 px x∈X Putting this in sentence processing terms, let D be a set of derivations for a sentence fragment W and let X be the extended sentence fragment that results from adding a new word to the fragment. 1: H(G, D, W) = − prp(G, X)log(prp(G, X)) The quantity entropy reduction is defined with a lower bound of zero so that this quantity is never 40 negative: ER = max(0, H(D|w1...k) − H(D|w1...k+1)) Hypothesis 2 Hale (2004) and Hale (2006) gave the entropy reduction hypothesis that the human effort of processing a particular word in a sentence fragment is the reduction in entropy from its value given the fragment to its value given the fragment including the disambiguating word. 3.3 Retrieval time Parsing in retrieval theory (Lewis and Vasishth, 2005) is accomplished by condition-action pairs generated with reference to a phrase structure grammar. A series of memory buffers stores elements in short-term and long-term buffers. Parallel associative retrieval (McElree et al., 2003), fluctuation of activation of elements already in</context>
</contexts>
<marker>Hale, 2006</marker>
<rawString>J. Hale. 2006. Uncertainty about the rest of the sentence. Cognitive Science, 30(4):643–672.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V M Holmes</author>
<author>A Kennedy</author>
<author>W S Murray</author>
</authors>
<title>Syntactic structure and the garden path.</title>
<date>1987</date>
<journal>The Quarterly Journal of Experimental Psychology Section A: Human Experimental Psychology,</journal>
<volume>39</volume>
<issue>2</issue>
<pages>277</pages>
<contexts>
<context position="4221" citStr="Holmes et al., 1987" startWordPosition="663" endWordPosition="666">ACL 2014, pages 38–46, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics of words like noticed is that the words immediately following could properly be the start of a main clause where the clause containing noticed is properly a subordinate clause. Such cases are sometimes referred to as reduced complements. In these cases only the presence of a main verb resolves the temporary syntactic ambiguity, and when it appears, some major restructuring is involved. Complement ambiguities of both kinds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser pr</context>
</contexts>
<marker>Holmes, Kennedy, Murray, 1987</marker>
<rawString>V.M. Holmes, A. Kennedy, and W.S. Murray. 1987. Syntactic structure and the garden path. The Quarterly Journal of Experimental Psychology Section A: Human Experimental Psychology, 39(2):2 – 277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Levy</author>
</authors>
<title>Expectation-Based Syntactic Comprehension.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>106</volume>
<issue>3</issue>
<contexts>
<context position="9057" citStr="Levy (2008)" startWordPosition="1500" endWordPosition="1501">et V saluted the cadet V saluted S ADVP S&apos; IN S&apos; After NP VP S S NP VP The cadet V NP VP noticed the cadet V S&apos; noticed NP VP the captain walked ... NP the captain The HUMDEP parser provided by Boston (2013) and described in Boston and Hale (2007) and Boston (2012) computes surprisal over a dependency grammar transition system, incrementally for each word in a sentence. It is a k-best parser. Here the value of k was set to 3, in line with previous use of the parser to model human disambiguation performance for garden-path sentences in Boston and Hale (2007). Hypothesis 1 Hale (2001), and also Levy (2008), gave the hypothesis that surprisal is linearly related to the human effort of processing a particular word in a sentence fragment. This hypothesis casts disambiguation as the work incurred by disconfirming all parses of the fragment that are inconsistent with the fragment including the disambiguating word. 3.2 Entropy reduction Entropy reduction was computed over the output of the phrase structure parser TDPARSE. In general, the entropy (Shannon, 1948), denoted H, of a random variable is the uncertainty associated with that variable. Specifically, for a discrete random variable X with outcom</context>
</contexts>
<marker>Levy, 2008</marker>
<rawString>R. Levy. 2008. Expectation-Based Syntactic Comprehension. Cognition, 106(3):1126–1177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Lewis</author>
<author>S Vasishth</author>
</authors>
<title>An activation-based model of sentence processing as skilled memory retrieval.</title>
<date>2005</date>
<journal>Cognitive Science,</journal>
<pages>29--1</pages>
<contexts>
<context position="10480" citStr="Lewis and Vasishth, 2005" startWordPosition="1737" endWordPosition="1740">sentence fragment that results from adding a new word to the fragment. 1: H(G, D, W) = − prp(G, X)log(prp(G, X)) The quantity entropy reduction is defined with a lower bound of zero so that this quantity is never 40 negative: ER = max(0, H(D|w1...k) − H(D|w1...k+1)) Hypothesis 2 Hale (2004) and Hale (2006) gave the entropy reduction hypothesis that the human effort of processing a particular word in a sentence fragment is the reduction in entropy from its value given the fragment to its value given the fragment including the disambiguating word. 3.3 Retrieval time Parsing in retrieval theory (Lewis and Vasishth, 2005) is accomplished by condition-action pairs generated with reference to a phrase structure grammar. A series of memory buffers stores elements in short-term and long-term buffers. Parallel associative retrieval (McElree et al., 2003), fluctuation of activation of elements already in a memory buffer, and retrieval interference as a function of similarity are combined to predict the amount of time that it takes to read a word (Vasishth et al., 2008). A word’s activation is based on two quantities: the baseline activation of the word, which is taken to decay given the passage of time; and the amou</context>
<context position="11736" citStr="Lewis and Vasishth, 2005" startWordPosition="1955" endWordPosition="1958">ence with other words that have been parsed. The baseline activation B for a word i is given here, taken from Lewis and Vasishth (2005), and Patil et al. (2009), where tr is the time since the rth retrieval of the word, the summation is over all n retrievals, and d is a decay factor set to 0.5 as in other ACT-R models (Anderson, 2005). Bi = ln The equation tracks the log odds that a word will need to be retrieved, given its past usage history. It yields not a smoothly decaying activation from initial encoding to the current time, but a ”series of spikes corresponding to the retrieval events” (Lewis and Vasishth, 2005). The overall activation A for word i is given here �Ai = Bi + WjSji j from Lewis and Vasishth (2005). In this equation, Bi is the fluctuating baseline level of activation for word i which is subject to time-based decay. In the model, a goal buffer contains retrieval cues for integrating the current word. Overall activation A for word i is found by adding to the baseline activation for word i an associative activation boost received from retrieval cues in the goal buffer that are associated with i. The variable j indexes those retrieval cues in the goal buffer. Wjs are weights on the retrieval</context>
<context position="13634" citStr="Lewis and Vasishth, 2005" startWordPosition="2300" endWordPosition="2303">n, word i is the current word, and retrieval cue j is from a word that is similar to word i, with reference to its part of speech tag, so that nouns interfere with other nouns but not with verbs. If retrieval cue j is similar to word i then the amount by which retrieval cue j interferes with word i varies according to how many words have already been associated with retrieval cue j. The array of words that is associated with retrieval cue j is considered to form a fan so that fanj gives the number of words in the fan for cue j. The constant S refers to the maximum associative strength of 1.5 (Lewis and Vasishth, 2005). Sji = S − ln(fanj) This equation is effectively reducing the maximum associative strength S by the log of the ”fan” of cue j, that is, the number of items associated with j. The mapping from activation level to retrieval time is given next. F is a scaling constant set to 0.14 in Lewis and Vasishth (2005). Ai is the word’s activation and e is Euler’s constant. Ti is retrieval time for word i: Ti = FeAi The retrieval time measure comes from Lewis and Vasishth (2005) where a theory of sentence processing is expressed as set of processes corresponding with skilled retrievals of linguistic compon</context>
<context position="26452" citStr="Lewis and Vasishth (2005)" startWordPosition="4484" endWordPosition="4487">ormance and phrase structure performance for the sentence types examined here. There is a clear case for examining dependency parsing for disambiguation types that use the sequence of words to effect disambiguation. Future work in this direction could take advantage of previous work with different ambiguities covered in e.g., Boston and Hale (2007) and Boston (2012), and extending it from using self-paced reading times to include eye-tracking metrics. Dependency retrieval time did not show the interaction evident in the eye movement and phase grammar parser data. This suggests either that the Lewis and Vasishth (2005) model does not cover very well the sentence types used in this experiment, or that whatever coverage the Lewis and Vasishth (2005) model does have of the human data is obscured in the transformation from phrase structure grammar to dependency grammar versions of retrieval. Previous work aimed at broad-coverage parsing evaluated against human eye movement corpora (Demberg and Keller, 2008; Boston et al., 2011) indicates that, in those corpus-derived linguistic environments, phrase structure surprisal and phase structure entropy reduction account for different components of variance in eye move</context>
</contexts>
<marker>Lewis, Vasishth, 2005</marker>
<rawString>R.L. Lewis and S. Vasishth. 2005. An activation-based model of sentence processing as skilled memory retrieval. Cognitive Science, 29:1–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B McElree</author>
<author>S Foraker</author>
<author>L Dyer</author>
</authors>
<title>Memory structures that subserve sentence comprehension.</title>
<date>2003</date>
<journal>Journal of Memory and Language,</journal>
<volume>48</volume>
<issue>1</issue>
<pages>91</pages>
<contexts>
<context position="10712" citStr="McElree et al., 2003" startWordPosition="1771" endWordPosition="1774">, H(D|w1...k) − H(D|w1...k+1)) Hypothesis 2 Hale (2004) and Hale (2006) gave the entropy reduction hypothesis that the human effort of processing a particular word in a sentence fragment is the reduction in entropy from its value given the fragment to its value given the fragment including the disambiguating word. 3.3 Retrieval time Parsing in retrieval theory (Lewis and Vasishth, 2005) is accomplished by condition-action pairs generated with reference to a phrase structure grammar. A series of memory buffers stores elements in short-term and long-term buffers. Parallel associative retrieval (McElree et al., 2003), fluctuation of activation of elements already in a memory buffer, and retrieval interference as a function of similarity are combined to predict the amount of time that it takes to read a word (Vasishth et al., 2008). A word’s activation is based on two quantities: the baseline activation of the word, which is taken to decay given the passage of time; and the amount of similarity based interference with other words that have been parsed. The baseline activation B for a word i is given here, taken from Lewis and Vasishth (2005), and Patil et al. (2009), where tr is the time since the rth retr</context>
</contexts>
<marker>McElree, Foraker, Dyer, 2003</marker>
<rawString>B. McElree, S. Foraker, and L. Dyer. 2003. Memory structures that subserve sentence comprehension. Journal of Memory and Language, 48(1):67– 91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th annual meeting on association for computational linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Umesh Patil</author>
<author>Shravan Vasishth</author>
<author>Reinhold Kliegl</author>
</authors>
<title>Compound effect of probabilistic disambiguation and memory retrievals on sentence processing: Evidence from an eyetracking corpus.</title>
<date>2009</date>
<booktitle>In Proceedings of 9th International Conference on Cognitive Modeling,</booktitle>
<location>Manchester.</location>
<contexts>
<context position="11271" citStr="Patil et al. (2009)" startWordPosition="1869" endWordPosition="1872">ffers. Parallel associative retrieval (McElree et al., 2003), fluctuation of activation of elements already in a memory buffer, and retrieval interference as a function of similarity are combined to predict the amount of time that it takes to read a word (Vasishth et al., 2008). A word’s activation is based on two quantities: the baseline activation of the word, which is taken to decay given the passage of time; and the amount of similarity based interference with other words that have been parsed. The baseline activation B for a word i is given here, taken from Lewis and Vasishth (2005), and Patil et al. (2009), where tr is the time since the rth retrieval of the word, the summation is over all n retrievals, and d is a decay factor set to 0.5 as in other ACT-R models (Anderson, 2005). Bi = ln The equation tracks the log odds that a word will need to be retrieved, given its past usage history. It yields not a smoothly decaying activation from initial encoding to the current time, but a ”series of spikes corresponding to the retrieval events” (Lewis and Vasishth, 2005). The overall activation A for word i is given here �Ai = Bi + WjSji j from Lewis and Vasishth (2005). In this equation, Bi is the fluc</context>
</contexts>
<marker>Patil, Vasishth, Kliegl, 2009</marker>
<rawString>Umesh Patil, Shravan Vasishth, and Reinhold Kliegl. 2009. Compound effect of probabilistic disambiguation and memory retrievals on sentence processing: Evidence from an eyetracking corpus. In Proceedings of 9th International Conference on Cognitive Modeling, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Pickering</author>
<author>M J Traxler</author>
</authors>
<title>Plausibility and recovery from garden paths: An eye-tracking study.</title>
<date>1998</date>
<journal>Journal of Experimental Psychology: Learning, Memory, and Cognition,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="4344" citStr="Pickering and Traxler, 1998" startWordPosition="682" endWordPosition="685">rds like noticed is that the words immediately following could properly be the start of a main clause where the clause containing noticed is properly a subordinate clause. Such cases are sometimes referred to as reduced complements. In these cases only the presence of a main verb resolves the temporary syntactic ambiguity, and when it appears, some major restructuring is involved. Complement ambiguities of both kinds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser predictions for complement ambiguity, and discusses applications of syntactic complexity metrics for evaluating test readabil</context>
</contexts>
<marker>Pickering, Traxler, 1998</marker>
<rawString>M.J. Pickering and M.J. Traxler. 1998. Plausibility and recovery from garden paths: An eye-tracking study. Journal of Experimental Psychology: Learning, Memory, and Cognition, 24(4):940–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Rayner</author>
<author>L Frazier</author>
</authors>
<title>Parsing temporarily ambiguous complements.</title>
<date>1987</date>
<journal>The Quarterly Journal of Experimental Psychology Section A: Human Experimental Psychology,</journal>
<volume>39</volume>
<issue>4</issue>
<pages>673</pages>
<contexts>
<context position="4247" citStr="Rayner and Frazier, 1987" startWordPosition="667" endWordPosition="670">, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics of words like noticed is that the words immediately following could properly be the start of a main clause where the clause containing noticed is properly a subordinate clause. Such cases are sometimes referred to as reduced complements. In these cases only the presence of a main verb resolves the temporary syntactic ambiguity, and when it appears, some major restructuring is involved. Complement ambiguities of both kinds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser predictions for complement a</context>
</contexts>
<marker>Rayner, Frazier, 1987</marker>
<rawString>K. Rayner and L. Frazier. 1987. Parsing temporarily ambiguous complements. The Quarterly Journal of Experimental Psychology Section A: Human Experimental Psychology, 39(4):657 – 673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Rayner</author>
<author>A Pollatsek</author>
<author>J Ashby</author>
<author>C Clifton Jr</author>
</authors>
<title>Psychology of Reading.</title>
<date>2012</date>
<publisher>Psychology Press,</publisher>
<note>2nd edition.</note>
<contexts>
<context position="14706" citStr="Rayner et al. (2012" startWordPosition="2489" endWordPosition="2492">d Vasishth (2005) where a theory of sentence processing is expressed as set of processes corresponding with skilled retrievals of linguistic components from memory. However in that paper it is computed over a phrase structure gram�tr − d n r=1 41 mar. Boston provides a method to compute retrieval time over a dependency grammar in the HUMDEP3.0 parser and Boston’s method (Boston, 2013) is used here. Hypothesis 3 Retrieval time is related to human sentence processing difficulty. 4 Eye movement metrics This section gives the metrics used to index human sentence processing load at disambiguation. Rayner et al. (2012, p. 93) set out the most common eye tracking measures. These include the following measures: First Fixation Duration (FFD); First Pass Reading Time (FPRT); Regression Path Duration (RPD). These are defined next. First fixation duration (FFD) is the mean duration of the first fixation on a word regardless of other possible fixations on the word. It has traditionally been treated as a measure of early processing. First fixation duration is interpreted to index lexical access. First pass reading time (FPRT): also known as gaze duration, is the sum of the durations of all fixations on the word th</context>
</contexts>
<marker>Rayner, Pollatsek, Ashby, Jr, 2012</marker>
<rawString>K. Rayner, A. Pollatsek, J. Ashby, and C. Clifton Jr. 2012. Psychology of Reading. Psychology Press, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Anja Belz</author>
</authors>
<title>An investigation into the validity of some metrics for automatically evaluating natural language generation systems.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="29187" citStr="Reiter and Belz (2009)" startWordPosition="4933" endWordPosition="4936">o generate (some finite subset of) all possible SFs that express P in L, and then use surprisal and entropy reduction metrics as thresholds for pruning and ranking the SFs. This would lead the generator to produce only SFs that avoid syntactic complexity for the benefit of human readers. Different thresholds could produce texts tailor-made for groups with different reading abilities, or texts aimed to meet other constraints on acceptable human difficulty, e.g., texts for beginners learning a given natural language for the first time, or texts with different forms aimed at novices and experts. Reiter and Belz (2009) discuss and evaluate some metrics for automatic evaluation of NLG in the context of generating weather forecasts. However these are designed to fit human measures at the whole-document level of NLG, different from the sentence-level incremental predictions generated and evaluated here. Also the evaluations discussed by those authors are done by fitting measures from offline human ratings of text readability, again different from the fine-grained detail of online human processing provided by the eyetracking experiment here. It seems clear that a combination of documentlevel and sentence-level </context>
</contexts>
<marker>Reiter, Belz, 2009</marker>
<rawString>Ehud Reiter and Anja Belz. 2009. An investigation into the validity of some metrics for automatically evaluating natural language generation systems. Computational Linguistics, 35(4):529–558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
</authors>
<title>Probabilistic top-down parsing and language modeling.</title>
<date>2001</date>
<booktitle>Computational linguistics,</booktitle>
<pages>27--2</pages>
<contexts>
<context position="7593" citStr="Roark (2001)" startWordPosition="1248" endWordPosition="1249">erivations of the string w1...k+1 that the grammar generates. �pp(wk+1, G, w1...k) = p(d, G, w1...k) d∈D The conditional probability cp of the next word wk+1 is the ratio of the prefix probability of the next word wk+1 to the prefix probability of the current word wk. cp(wk+1, G, w1...k) = pp(wk, G, w1...k−1) The surprisal sp, measured in bits of information, associated with the next word wk+1 is the negative log of the conditional probability of the next word wk+1 sp(wk+1, G, w1...k) = −log(cp(wk+1, G, w1...k)) The TDPARSE top-down incremental parser provided by Roark (2013) and described in Roark (2001) and Roark (2004) computes surprisal over a phrase structural grammar, incrementally for each word in a sentence. It is a parallel parser that maintains potentially very many parses at each state. For details of how the beam width varies across a sentence, see Roark (2001). pp(wk+1, G, w1...k) 39 Figure 1: Phrase markers showing disambiguation in sentence type 1. The left phrasemarker shows the initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached in the ultimately correct analysis. Figure 2: Phrase markers showing disambiguation in sentence type</context>
</contexts>
<marker>Roark, 2001</marker>
<rawString>Brian Roark. 2001. Probabilistic top-down parsing and language modeling. Computational linguistics, 27(2):249–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
</authors>
<title>Robust garden path parsing. Natural language engineering,</title>
<date>2004</date>
<pages>10--1</pages>
<contexts>
<context position="7610" citStr="Roark (2004)" startWordPosition="1251" endWordPosition="1252"> string w1...k+1 that the grammar generates. �pp(wk+1, G, w1...k) = p(d, G, w1...k) d∈D The conditional probability cp of the next word wk+1 is the ratio of the prefix probability of the next word wk+1 to the prefix probability of the current word wk. cp(wk+1, G, w1...k) = pp(wk, G, w1...k−1) The surprisal sp, measured in bits of information, associated with the next word wk+1 is the negative log of the conditional probability of the next word wk+1 sp(wk+1, G, w1...k) = −log(cp(wk+1, G, w1...k)) The TDPARSE top-down incremental parser provided by Roark (2013) and described in Roark (2001) and Roark (2004) computes surprisal over a phrase structural grammar, incrementally for each word in a sentence. It is a parallel parser that maintains potentially very many parses at each state. For details of how the beam width varies across a sentence, see Roark (2001). pp(wk+1, G, w1...k) 39 Figure 1: Phrase markers showing disambiguation in sentence type 1. The left phrasemarker shows the initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached in the ultimately correct analysis. Figure 2: Phrase markers showing disambiguation in sentence type 2. The left phra</context>
</contexts>
<marker>Roark, 2004</marker>
<rawString>Brian Roark. 2004. Robust garden path parsing. Natural language engineering, 10(1):1–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
</authors>
<title>tdparse. An incremental top downparser.</title>
<date>2013</date>
<note>http://code.google.com/p/ incremental-top-down-parser/.</note>
<contexts>
<context position="7563" citStr="Roark (2013)" startWordPosition="1243" endWordPosition="1244">um of the probability of all derivations of the string w1...k+1 that the grammar generates. �pp(wk+1, G, w1...k) = p(d, G, w1...k) d∈D The conditional probability cp of the next word wk+1 is the ratio of the prefix probability of the next word wk+1 to the prefix probability of the current word wk. cp(wk+1, G, w1...k) = pp(wk, G, w1...k−1) The surprisal sp, measured in bits of information, associated with the next word wk+1 is the negative log of the conditional probability of the next word wk+1 sp(wk+1, G, w1...k) = −log(cp(wk+1, G, w1...k)) The TDPARSE top-down incremental parser provided by Roark (2013) and described in Roark (2001) and Roark (2004) computes surprisal over a phrase structural grammar, incrementally for each word in a sentence. It is a parallel parser that maintains potentially very many parses at each state. For details of how the beam width varies across a sentence, see Roark (2001). pp(wk+1, G, w1...k) 39 Figure 1: Phrase markers showing disambiguation in sentence type 1. The left phrasemarker shows the initial misattachment. The right phrasemarker shows how the same initially misattached NP is attached in the ultimately correct analysis. Figure 2: Phrase markers showing d</context>
</contexts>
<marker>Roark, 2013</marker>
<rawString>B. Roark. 2013. tdparse. An incremental top downparser. http://code.google.com/p/ incremental-top-down-parser/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claude Shannon</author>
</authors>
<title>A mathematical theory of communication.</title>
<date>1948</date>
<journal>Bell Systems Technical Journal,</journal>
<pages>27--379</pages>
<contexts>
<context position="9515" citStr="Shannon, 1948" startWordPosition="1572" endWordPosition="1573"> of the parser to model human disambiguation performance for garden-path sentences in Boston and Hale (2007). Hypothesis 1 Hale (2001), and also Levy (2008), gave the hypothesis that surprisal is linearly related to the human effort of processing a particular word in a sentence fragment. This hypothesis casts disambiguation as the work incurred by disconfirming all parses of the fragment that are inconsistent with the fragment including the disambiguating word. 3.2 Entropy reduction Entropy reduction was computed over the output of the phrase structure parser TDPARSE. In general, the entropy (Shannon, 1948), denoted H, of a random variable is the uncertainty associated with that variable. Specifically, for a discrete random variable X with outcomes x1, x2,... with probabilities p1, p2, .. . H(X) = − 1: px log2 px x∈X Putting this in sentence processing terms, let D be a set of derivations for a sentence fragment W and let X be the extended sentence fragment that results from adding a new word to the fragment. 1: H(G, D, W) = − prp(G, X)log(prp(G, X)) The quantity entropy reduction is defined with a lower bound of zero so that this quantity is never 40 negative: ER = max(0, H(D|w1...k) − H(D|w1..</context>
</contexts>
<marker>Shannon, 1948</marker>
<rawString>Claude Shannon. 1948. A mathematical theory of communication. Bell Systems Technical Journal, 27:379—423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sturt</author>
<author>M J Pickering</author>
<author>M W Crocker</author>
</authors>
<title>Structural Change and Reanalysis Difficulty in Language Comprehension.</title>
<date>1999</date>
<journal>Journal of Memory and Language,</journal>
<pages>40--136</pages>
<contexts>
<context position="4267" citStr="Sturt et al., 1999" startWordPosition="671" endWordPosition="674">l 26-30 2014. c�2014 Association for Computational Linguistics of words like noticed is that the words immediately following could properly be the start of a main clause where the clause containing noticed is properly a subordinate clause. Such cases are sometimes referred to as reduced complements. In these cases only the presence of a main verb resolves the temporary syntactic ambiguity, and when it appears, some major restructuring is involved. Complement ambiguities of both kinds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser predictions for complement ambiguity, and discus</context>
</contexts>
<marker>Sturt, Pickering, Crocker, 1999</marker>
<rawString>P. Sturt, M.J. Pickering, and M.W. Crocker. 1999. Structural Change and Reanalysis Difficulty in Language Comprehension. Journal of Memory and Language, 40:136–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Trueswell</author>
<author>M K Tanenhaus</author>
<author>C Kello</author>
</authors>
<title>Verb-specific constraints in sentence processing: separating effects of lexical preference from gardenpaths.</title>
<date>1993</date>
<journal>J Exp Psychol Learn Mem Cogn,</journal>
<volume>19</volume>
<issue>3</issue>
<pages>53</pages>
<contexts>
<context position="4369" citStr="Trueswell et al., 1993" startWordPosition="686" endWordPosition="689">words immediately following could properly be the start of a main clause where the clause containing noticed is properly a subordinate clause. Such cases are sometimes referred to as reduced complements. In these cases only the presence of a main verb resolves the temporary syntactic ambiguity, and when it appears, some major restructuring is involved. Complement ambiguities of both kinds have been used to investigate the parsing of ambiguous clauses (Holmes et al., 1987; Rayner and Frazier, 1987; Sturt et al., 1999; Ferreira and Henderson, 1991; Clifton Jr, 1993; Pickering and Traxler, 1998; Trueswell et al., 1993). Evidence from studies with human readers support the notion that there is a processing difficulty differential across the two forms such that disambiguation in sentence type (1) is harder than in sentence type (2). This has been shown using grammaticality judgements (Ferreira and Henderson, 1991), self-paced reading times (Sturt et al., 1999), and eye-tracking (Green, 2014). The current article presents an eye-tracking evaluation of the parser predictions for complement ambiguity, and discusses applications of syntactic complexity metrics for evaluating test readability. 3 Parser metrics Thi</context>
</contexts>
<marker>Trueswell, Tanenhaus, Kello, 1993</marker>
<rawString>J C Trueswell, M K Tanenhaus, and C Kello. 1993. Verb-specific constraints in sentence processing: separating effects of lexical preference from gardenpaths. J Exp Psychol Learn Mem Cogn, 19(3):528– 53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vasishth</author>
<author>S Br¨ussow</author>
<author>R L Lewis</author>
<author>H Drenhaus</author>
</authors>
<title>Processing polarity: How the ungrammatical intrudes on the grammatical.</title>
<date>2008</date>
<journal>Cognitive Science,</journal>
<volume>32</volume>
<issue>4</issue>
<marker>Vasishth, Br¨ussow, Lewis, Drenhaus, 2008</marker>
<rawString>S. Vasishth, S. Br¨ussow, R.L. Lewis, and H. Drenhaus. 2008. Processing polarity: How the ungrammatical intrudes on the grammatical. Cognitive Science, 32(4):685–712.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>