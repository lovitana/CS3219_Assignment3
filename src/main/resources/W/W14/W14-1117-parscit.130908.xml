<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.065284">
<title confidence="0.9781155">
Detecting drugs and adverse events from Spanish health social media
streams
</title>
<author confidence="0.999702">
Isabel Segura-Bedmar, Ricardo Revert, Paloma Mart’nez
</author>
<affiliation confidence="0.9819515">
Computer Science Department,
Carlos III University of Madrid, Spain
</affiliation>
<email confidence="0.995668">
{isegura,rrevert,pmf}@inf.uc3m.es
</email>
<sectionHeader confidence="0.995601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999567454545455">
To the best of our knowledge, this is the first
work that does drug and adverse event
detection from Spanish posts collected from a
health social media. First, we created a gold-
standard corpus annotated with drugs and
adverse events from social media. Then,
Textalytics, a multilingual text analysis
engine, was applied to identify drugs and
possible adverse events. Overall recall and
precision were 0.80 and 0.87 for drugs, and
0.56 and 0.85 for adverse events.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999952222222223">
It is well-known that adverse drug reactions
(ADRs) are an important health problem. Indeed,
ADRs are the 4th cause of death in hospitalized
patients (Wester et al., 2008). Thus, the field of
pharmacovigilance has received a great deal of
attention due to the high and growing incidence
of drug safety incidents (Bond and Raehl, 2006)
as well as to their high associated costs (van Der
Hooft et al., 2006).
Since many ADRs are not captured during
clinical trials, the major medicine regulatory
agencies such as the US Food and Drug
Administration (FDA) or the European
Medicines Agency (EMA) require healthcare
professionals to report all suspected adverse drug
reactions. However, some studies have shown
that ADRs are under-estimated due to the fact
that they are reported by voluntary reporting
systems (Bates et al., 2003; van Der Hooft et al.,
2006; McClellan, 2007). In fact, it is estimated
that only between 2 and 10 per cent of ADRs are
reported (Rawlins, 1995). Healthcare
professionals must perform many tasks during
their workdays and thus finding the time to use
these surveillance reporting systems is very
difficult. Also, healthcare professionals tend to
report only those ADRs on which they have
absolute certainty of their existence. Several
medicines agencies have implemented
spontaneous patient reporting systems in order
for patients to report ADRs themselves. Some of
these systems are the MedWatch from the FDA,
the Yellow Cards from the UK Medicines
agency (MHRA) or the website1 developed by
the Spanish Agency of Medicines and Medical
devices (AEMPS). Unlike reports from
healthcare professionals, patient reports often
provide more detailed and explicit information
about ADRs (Herxheimer et al., 2010). Another
important contribution of spontaneous patient
reporting systems is to achieve patients having a
more central role in their treatments. However,
despite the fact that these systems are well-
established, the rate of spontaneous patient
reporting is very low probably because many
</bodyText>
<footnote confidence="0.96214">
1 https://www.notificaram.es/
</footnote>
<page confidence="0.914928">
106
</page>
<note confidence="0.993372">
Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 106–115,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.995320340909091">
patients are still unaware of their existence and
even may feel embarrassed when describing their
symptoms.
In this study, our hypothesis is that health-
related social media can be used as a
complementary data source to spontaneous
reporting systems in order to detect unknown
ADRs and thereby to increase drug safety. In
recent days, social media on health information,
just like has happened in other areas, have seen a
tremendous growth (Hill et al., 2013). Examples
of social media sites include blogs, online forums,
social networking, and wikis, among many
others. In this work, we focus on health forums
where patients often exchange information about
their personal medical experiences with other
patients who suffer the same illness or receive
similar treatment. Some patients may feel more
comfortable sharing their medical experiences
with each other rather than with their healthcare
professionals. These forums contain a large
number of comments describing patient
experiences that would be a fertile source of data
to detect unknown ADRs.
Although there have been several
research efforts devoted to developing systems
for extracting ADRs from social media, all
studies have focused on social media in English,
and none of them have addressed the extraction
from Spanish social media. Moreover, the
problem is that these studies have not been
compared with each other, and hence it is very
difficult to determine the current “state-of-art” of
the techniques for ADRs extraction from social
media. This comparison has not been performed
due to the lack of a gold-standard corpus for
ADRs. Thus, the goal of our work is twofold: i)
to create a gold-standard corpus annotated with
drugs and adverse events and ii) to develop a
system to automatically extract mentions of
drugs and adverse events from Spanish health-
related social media sites. The corpus is
composed by patients’ comments from
Forumclinic2, a health online networking website
</bodyText>
<footnote confidence="0.839789">
2 http://www.forumclinic.org
</footnote>
<bodyText confidence="0.999559769230769">
in Spanish. This is the first corpus of patient
comments annotated with drugs and adverse
events in Spanish. Also, we believe that this
corpus will facilitate comparison for future
ADRs detection from Spanish social media.
This is a preliminary work, in which we have
only focused on the automatic detection of
mentions of drugs and adverse events. Our final
goal will be to develop a system to automatically
extract drugs and their side effects. We hope our
system will be beneficial to AEMPS as well as to
the pharmaceutical industry in the improvement
of their pharmacovigilance systems.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999815193548387">
In recent years, the application of Natural
Language Processing (NLP) techniques to mine
adverse reactions from texts has been explored
with promising results, mainly in the context of
drug labels (Gurulingappa et al., 2013; Li et al.,
2013; Kuhn et al., 2010), biomedical literature
(Xu and Wang, 2013), medical case reports
(Gurulingappa et al., 2012) and health records
(Friedman, 2009; Sohn et al., 2011). However, as
it will be described below, the extraction of
adverse reactions from social media has received
much less attention.
In general, medical literature, such as
scientific publications and drug labels, contains
few grammatical and spelling mistakes. Another
important advantage is that this type of texts can
be easily linked to biomedical ontologies.
Similarly, clinical records present specific
medical terminology and can also be mapped to
biomedical ontologies and resources. Meanwhile
social media texts are markedly different from
clinical records and scientific articles, and
thereby the processing of social media texts
poses additional challenges such as the
management of meta-information included in the
text (for example as tags in tweets) (Bouillot et
al., 2013), the detection of typos and
unconventional spelling, word shortenings
(Neunedert et al, 2013; Moreira et al., 2013) and
slang and emoticons (Balahur, 2013), among
others. Moreover, these texts are often very short
</bodyText>
<page confidence="0.998167">
107
</page>
<bodyText confidence="0.998916021739131">
and with an informal nature, making the
processing task extremely challenging.
trazodone and ziprasidone. The system achieved
a good performance, with a precision of 78.3%
and a recall of 69.9%.
Regarding the identification of drug names in
text, during the last four years there has been
significant research efforts directed to encourage
the development of systems for detecting these
entities. Concretely, shared tasks such as
DDIExtraction 2013 (Segura-Bedmar et al.,
2013), CHEMDNER 2013 (Krallinger et al.,
2013) or the i2b2 Medication Extraction
challenge (Uzuner et al., 2010) have been held
for the advancement of the state of the art in this
problem. However, most of the work on
recognizing drugs concerns either biomedical
literature (for example, MedLine articles) or
clinical records, thus leaving unexplored this task
in social media streams.
Leaman et al., (2010) developed a system to
automatically recognize adverse effects in user
comments. A corpus of 3,600 comments from
the DailyStrength health-related social network
was collected and manually annotated with a
total of 1,866 drug conditions, including
beneficial effects, adverse effects, indications
and others. To identify the adverse effects in the
user comments, a lexicon was compiled from the
following resources: (1) the COSTART
vocabulary (National Library of Medicine, 2008),
(2) the SIDER database (Kuhn et al., 2010), (3)
MedEffect3 and (4) a list of colloquial phrases
which were manually collected from the
DailyStrength comments. The final lexicon
consisted of 4,201 concepts (terms with the same
CUI were grouped in the same concept). Finally,
the terms in the lexicon were mapped against
user comments to identify the adverse effects. In
order to distinguish adverse effects from the
other drug conditions (beneficial effects,
indications and others), the systems used a list of
verbs denoting indications (for example, help,
work, prescribe). Drug name recognition was not
necessary because the evaluation focused only on
a set of four drugs: carbamazepine, olanzapine,
</bodyText>
<footnote confidence="0.703198">
3 http://www.hc-sc.gc.ca/dhp-mps/medeff/index-
eng.php
</footnote>
<bodyText confidence="0.999981175">
An extension of this system was accomplished
by Nikfarjam and Gonzalez (2011). The authors
applied association rule mining to extract
frequent patterns describing opinions about drugs.
The rules were generated using the Apriori tool4,
an implementation of the Apriori algorithm
(Agrawal and Srikant, 1994) for association rule
mining. The system was evaluated using the
same corpus created for their previous work
(Leaman et al., 2010), and which has been
described above. The system achieved a
precision of 70.01% and a recall of 66.32%. The
main advantage of this system is that it can be
easily adapted for other domains and languages.
Another important advantage of this approach
over a dictionary based approach is that the
system is able to detect terms not included in the
dictionary.
Benton et al., (2011) created a corpus of posts
from several online forums about breast cancer,
which later was used to extract potential adverse
reactions from the most commonly used drugs to
treat this disease: tamoxifen, anastrozole,
letrozole and axemestane. The authors collected
a lexicon of lay medical terms from websites and
databases about drugs and adverse events. The
lexicon was extended with the Consumer Health
Vocabulary (CHV)5, a vocabulary closer to the
lay terms, which patients usually use to describe
their medical experiences. Then, pairs of terms
co-occurring within a window of 20 tokens were
considered. The Fisher’s exact test (Fisher, 1922)
was used to calculate the probability that the two
terms co-occurred independently by chance. To
evaluate the system, the authors focused on the
four drugs mentioned above, and then collected
their adverse effects from their drug labels. Then,
precision and recall were calculated by
comparing the adverse effects from drug labels
and the adverse effects obtained by the system.
</bodyText>
<footnote confidence="0.998732">
4 http://www.borgelt.net/apriori.html
5 http://consumerhealthvocab.org
</footnote>
<page confidence="0.997294">
108
</page>
<bodyText confidence="0.999963046511628">
The system obtained an average precision of 77%
and an average recall of 35.1% for all four drugs.
UDWarning (Wu et al., 2012) is an ongoing
prototype whose main goal is to extract adverse
drug reactions from Google discussions. A
knowledge base of drugs and their adverse
effects was created by integrating information
from different resources such as SIDER,
DailyMed6, Drugs.com7 and MedLinePlus. The
authors hypothesized that unknown adverse drug
effects would have a high volume of discussions
over the time. Thus, the systems should monitor
the number of relevant discussions for each
adverse drug effect. However, to the best of our
knowledge, the UDWarning’s component
devoted to the detection of unrecognized adverse
drug effects has not been developed yet.
Bian et al., (2012) developed a system to
detect tweets describing adverse drug reactions.
The systems used a SVM classifier trained on a
corpus of tweets, which were manually labeled
by two experts. MetaMap (Aronson and Lang,
2010) was used to analyze the tweets and to find
the UMLS concepts present in the tweets. The
system produced poor results, mainly because
tweets are riddled with spelling and grammar
mistakes. Moreover, MetaMap is not a suitable
tool to analyze this type of texts since patients do
not usually use medical terminology to describe
their medical experiences.
As it was already mentioned, the recognition
of drugs in social media texts has hardly been
tackled and little research has been conducted to
extract relationships between drugs and their side
effects, since most systems were focused on a
given and fixed set of drugs. Most systems for
extracting ADRs follow a dictionary-based
approach. The main drawback of these systems is
that they fail to recognize terms which are not
included in the dictionary. In addition, the
dictionary-based approach is not able to handle
the large number of spelling and grammar errors
in social media texts. Moreover, the detection of
</bodyText>
<footnote confidence="0.9834635">
6 http://dailymed.nlm.nih.gov/dailymed/
7 http://www.drugs.com/
</footnote>
<bodyText confidence="0.999829142857143">
ADRs has not been attempted for languages
other than English. Indeed, automatic
information extraction from Spanish-language
social media in the field of health remains largely
unexplored. Additionally, to the best of our
knowledge, there is no corpus annotated with
ADRs in social media texts available today.
</bodyText>
<sectionHeader confidence="0.996891" genericHeader="method">
3 Method
</sectionHeader>
<subsectionHeader confidence="0.999923">
3.1 Corpus creation
</subsectionHeader>
<bodyText confidence="0.999970885714286">
In order to create the first corpus in Spanish
annotated with drugs and adverse events, we
reviewed the main health-related social networks
in Spanish language to select the most
appropriate source of user comments. This
corpus will be used to evaluate our system.
Twitter was initially our preferred option due
to the tremendous amount of tweets published
each day (nearly 400 millions). However, we
decided to discard it because Twitter does not
seem to be the preferred source for users to
describe their ADRs. Gonzalez et al. (2013)
gathered a total of 42,327 in a one-month period,
from which only 216 described ADRs. Although
Facebook is the most popular social media and
many Facebook groups dedicated to specific
diseases have emerged in the last years, we
discarded it because most of these groups usually
have restricted access to their members. Online
health-related forums are an attractive source of
data for our corpus due to their high dynamism,
their great number of users as well as their easy
access. After reviewing the main health forums
in Spanish, we chose ForumClinic, an interactive
program for patients, whose main goal is to
provide rigorous information about specific
diseases (such as breast cancer, HIV, bipolar
disorder, depression, schizophrenia, ischemic
heart disease, among others) and their treatments.
Also, this platform aims to increase the
participation of patients maintaining a discussion
forum where patients can exchange information
about their experiences. Figure 1 shows the
distribution of user comments across the main
twelve categories defined in the forum. We
</bodyText>
<page confidence="0.996449">
109
</page>
<bodyText confidence="0.984483">
implemented a web crawler to gather all user
comments published in ForumClinic to date.
</bodyText>
<figureCaption confidence="0.996581">
Figure 1 Distribution of user comments.
</figureCaption>
<bodyText confidence="0.9999624">
Then, we randomly selected a sample of 400
comments that were manually labeled with drugs
and adverse events by two annotators with
expertise in Pharmacovigilance. It should be
noted that adverse events and ADRs do not refer
to the same: while an adverse event may or may
not be caused by a drug, an ADR is an adverse
event that is suspected to be caused by a drug. A
drug is a substance used in the treatment, cure,
prevention or diagnosis of diseases. The corpus
includes generic and brand drugs as well as drug
families. Disagreements between the annotators
were discussed and reconciled during the
harmonization process, where a third annotator
helped to make the final decision (some
examples are shown in Table 1). All the
mentions of drugs and adverse events were
annotated, even those containing spelling or
grammatical errors (for example, hemorrajia).
Nominal anaphoric expressions, which refer to
previous adverse events or drugs in the comment,
were also included in the annotation. The
annotators found 187 drugs (from which 40 were
nominal anaphors and 14 spelling errors) and
636 adverse events (from which 48 were nominal
anaphors and 17 spelling errors). The corpus is
available for academic purposes8.
To measure the inter-annotator agreement we
used the F-measure metric. This metric
approximates the kappa coefficient (Cohen, 1960)
</bodyText>
<footnote confidence="0.622214">
8 http://labda.inf.uc3m.es/SpanishADRCorpus
</footnote>
<bodyText confidence="0.999778611111111">
when the number of true negatives (TN) is very
large (Hripcsak and Rothschild, 2005). In our
case, we can state that the number of TN is very
high since TN are all the terms that are not true
positives, false positives nor false negatives. The
F-measure was calculated by comparing the two
corpora created by the two first annotators. The
corpus labelled by the first annotator was
considered the gold-standard. As it was expected,
drugs exhibit a high IAA (0.89), while adverse
events point to moderate agreement (0.59). As
drugs have specific names and there are a limited
number of them, it is possible to create a limited
and controlled vocabulary to gather many of the
existing drugs. On the other hand, patients can
express their adverse events in many different
ways due to the variability and richness of
natural language.
</bodyText>
<table confidence="0.998449">
Sentence Final Decision
De entre los distintos Names in bold type refer
antiretrovirales, transcriptasa to four families of
inversa, proteasa, integrasa y inhibitors (that is, drug
fusi—n, que grupo ser’a el families), and thereby,
más potente y cual el menos. they should be annotated.
Como complemento proteico The mention
recomendamos el de los “complementos del
laboratorio Vegenat. Si Decathlon” should not be
compras los complementos annotated as a drug since
del Decathlon, asegiurate que it is not a brand-marked
contenga prote’nas. drug.
</table>
<tableCaption confidence="0.989198">
Table 1: Some examples of disagreements between
annotators
</tableCaption>
<subsectionHeader confidence="0.976862">
3.2 Constructing a dictionary for drugs and
adverse events
</subsectionHeader>
<bodyText confidence="0.998834714285714">
Since our goal is to identify drugs and adverse
events from user comments, the first challenge is
to create a dictionary that contains all of the
drugs and known adverse events.
CIMA9 is an online information center about
medicines that provides all the daily updated
official information about drugs. CIMA is
</bodyText>
<footnote confidence="0.911181">
9 http://www.aemps.gob.es/cima/
</footnote>
<page confidence="0.997817">
110
</page>
<bodyText confidence="0.999510181818182">
maintained by the Spanish Agency for Medicines
and Health Products (AEMPS). It includes
information on all drugs authorized in Spain and
their current authorization status. CIMA contains
a total of 16,418 brand drugs and 2,228 generic
drugs. Many brand drug names include
additional information such as dosages, mode
and route of administration, laboratory, among
others (for example, ` ESPIDIFEN 400 mg
GRANULADO PARA SOLUCION ORAL
SABOR ALBARICOQUE” or ` ESPIDIFEN 600
mg GRANULADO PARA SOLUCION ORAL
SABOR LIMON EFG, 20 sobres”). Since it is
unlikely that these long names are used by
patients, we implemented a method to shorten
them by removing their additional information
(for example, ` ESPIDIFEN”). After applying
this method, the resulting list of brand drug
names consisted of 3,662 terms. The main
limitation of CIMA is that it only provides
information about drugs authorized in Spain.
That is, CIMA does not contain information
about drugs approved only in Latin America.
CIMA is free and offers a downloadable version
in XML format. Thus, it provides the
information in a well-structured format that
makes it possible to directly extract generic and
brand drug names as well as other related
information such as their ATC codes, their
pharmaceutical company, among others.
Unfortunately, CIMA does not provide
information about drug groups. For this reason,
we decided to consider the WHO ATC system10,
a classification system of drugs, as an additional
resource to obtain a list of drug groups.
MedDRA 11 is a medical terminology
dictionary about events associated with drugs. It
is a multilingual terminology, which includes the
following languages: Chinese, Czech, Dutch,
French, German, Hungarian, Italian, Japanese,
Portuguese and Spanish. Its main goal is to
provide a classification system for efficient
communication of ADRs data between countries.
The main advantage of MedDRA is that its
</bodyText>
<footnote confidence="0.944455">
10 http://www.whocc.no/atc_ddd_index/
11 http://www.meddra.org/
</footnote>
<bodyText confidence="0.999950146341463">
structured format allows easily obtaining a list of
possible adverse events. MedDRA is composed
of a five levels hierarchy. We collected the terms
from the most specific level, &amp;quot;Lowest Level
Terms&amp;quot; (LLTs)”. This level contains a total of
72,072 terms, which express how information is
communicated in practice.
By analyzing the information from these
resources, we found that none of them contained
all of the drugs and adverse events. Patients
usually use lay terms to describe their symptoms
and their treatments. Unfortunately, many of
these lay terms are not included in the above
mentioned resources. Therefore, we decided to
integrate additional information from other
resources devoted to patients to build a more
complete and comprehensive dictionary. There
are several online websites that provide
information to patients on drugs and their side
effects in Spanish language. For example,
MedLinePlus and Vademecum contain
information about drugs and their side effects.
These websites allow users to browse by generic
or drug name, providing an information leaflet
for each drug in a HTML page. Since these
leaflets are unstructured, the extraction of drugs
and their adverse effects is a challenging task.
While drug names are often located in specific
fields (such as title), their adverse events are
usually descriptions of harmful reactions in
natural language. We only developed a web
crawler to browse and download pages related to
drugs from Vademecum since this website
provided an easier access to its drug pages than
MedLinePlus. We plan to augment the list of
drugs and adverse events by crawling
MedLinePlus in future work.
After extracting drugs and adverse events
from these different resources, we created a
dictionary of drugs and adverse events. Table 2
shows the statistics of our final dictionary.
</bodyText>
<table confidence="0.997937142857143">
Resource Total
Generic drugs from CIMA 2,228
Brand drugs from CIMA 3,662
Drug group names from the ATC system 466
Drug names (which are not in CIMA) from 1,237
Vademecum
Total Drugs: 7,593
</table>
<tableCaption confidence="0.94308">
Table 2: Number of drugs in the dictionary.
</tableCaption>
<table confidence="0.9998574">
Resource Total
Adverse events from MedDRA 72,072
Adverse events from Vademecum 2,793
(which are not in MedDRA)
Total adverse events: 74,865
</table>
<tableCaption confidence="0.999757">
Table 3: Number of adverse events in the dictionary.
</tableCaption>
<subsectionHeader confidence="0.996052">
3.3 Using Textalytics and gazetteers to
</subsectionHeader>
<bodyText confidence="0.98042752631579">
identify drugs and adverse events
Textalytics 12 is a multilingual text analysis
engine to extract information from any type of
texts such as tweets, posts, comments, news,
contracts, etc. This tool offers a wide variety of
functionalities such as text classification, entity
recognition, concept extraction, relation
extraction and sentiment analysis, among others.
We used a plugin that integrates Textalytics with
GATE. In this paper, we applied entity
recognition provided by Textalytics, which
follows a dictionary-based approach to identify
entities in texts. We created a dictionary for
drugs and adverse events from CIMA and
MedDRA. This dictionary was integrated into
Textalytics. Additionally, the lists of drugs and
adverse events collected from the others
resources (ATC system and Vademecum) were
used to create GATE gazetteers.
</bodyText>
<sectionHeader confidence="0.998531" genericHeader="evaluation">
4 Results and error analysis
</sectionHeader>
<bodyText confidence="0.99993188">
We evaluated the system on the corpus annotated
with drugs and adverse events. The results of
this study show a precision of 87% for drugs and
85% for adverse events, and a recall of 80% for
drugs and 56% for adverse events.
We performed an analysis to determine the
main sources of error in the system. A sample of
50 user comments were randomly selected and
analyzed. Regarding the detection of adverse
events, the major cause of false negatives was
the use of colloquial expressions to describe an
adverse event. Phrases like “me deja ko (it makes
me KO)” or “me cuesta más levantarme (it’s
harder for me to wake up)” were used by patients
for expressing their adverse events. These
phrases are not included in our dictionary. A
possible solution may be to create a lexicon
containing this kind of idiomatic expressions.
The second highest cause of false negatives for
adverse events was due to the different lexical
variations of the same adverse event. For
example, ‘depresi—n (depression)’ is included in
our dictionary, but their lexical variations such as
“depremido (depress)”, “me deprimo (I get
depressed)”, “depresivo (depressive)” or
“deprimente (depressing)” were not detected by
our system since they are not in our dictionary.
Nominalization may be used to identify all the
possible lexical variations of a same adverse
event. Another important error source of false
negatives was spelling mistakes (eg. hemorrajia
instead of hemorragia). Many users have great
difficulty in spelling unusual and complex
technical terms. This error source may be
handled by a more advanced matching method
capable of dealing with the spelling error
problem. The use of abbreviations (“depre” is an
abbreviation for “depression”) also produces
false negatives. Techniques such as
lemmatization and stemming may help to resolve
this kind of abbreviations.
False positives for adverse events were mainly
due to the inclusion of MedDRA terms referring
to procedures (such as therapeutic, preventive or
laboratory procedures) and tests in our dictionary.
MedDRA includes terms for diseases, signs,
abnormalities, procedures and tests. We should
have not included those terms referring to
procedures and tests since they do not represent
adverse events.
</bodyText>
<footnote confidence="0.909822">
12 https://textalytics.com/
</footnote>
<page confidence="0.996618">
112
</page>
<bodyText confidence="0.999955047619048">
The main source of false negatives for drugs
seems to be that users often misspelled drug
names. Some generic and brand drugs have
complex names for patients. Some examples of
misspelled drugs are avilify (Abilify) or rivotril
(ribotril). Another important cause of false
negatives was due to the fact that our dictionary
does not include drugs approved in other
countries than Spain (for example,
Clorimipramina, Ureadin or Paxil). However,
ForumClinic has a large number of users in Latin
America. It is possible that these users have
posted comments about some drugs that have
only been approved in their countries. The third
largest source of errors was the abbreviations for
drug families. For instance, benzodiacepinas
(benzodiazepine) is commonly used as benzos,
which is not included in our dictionary. An
interesting source of errors to point out is the use
of acronyms referring to a combination of two or
more drugs. For instance, FEC is a combination
of Fluorouracil, Epirubicin and
Cyclophosphamide, three chemotherapy drugs
used to treat breast cancer. This combination of
drugs is not registered in the resources (CIMA
and Vademecum) used to create our dictionary.
Most false positives for drugs were due to a
lack of ambiguity resolution. Some drug names
are common Spanish words such as “All’” (a
slimming drug) or “Puntual” (a laxative). These
terms are ambiguous and resolve to multiple
senses, depending on the context in which they
are used. Similarly, some drug names such as
“alcohol” or “oxygen” can take a meaning
different than the one of pharmaceutical
substance. Another important cause of false
positives is due to the use of drug family names
as adjectives that specify an effect. This is the
case of sedante (sedative) or antidepresivo
(antidepressant), which can refer to a family of
drugs, but also to the definition of an effect or
disorder caused by a drug (sedative effects).
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999557">
In this research, we created the first Spanish
corpus of health user comments annotated with
drugs and adverse events. The corpus is available
for research. In this work, we only focused on
the detection of the mentions of drugs and
adverse events, but not the relationships among
them. In future work, we plan to extend the
system to detect the relationships between drugs
and their side effects. Also, we would like to
identify their indications and beneficial effects.
</bodyText>
<sectionHeader confidence="0.997544" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999719">
This work was supported by the EU project
TrendMiner [FP7-ICT287863], by the project
MULTIMEDICA [TIN2010-20644-C03-01], and
by the Research Network MA2VICMR
[S2009/TIC-1542].
</bodyText>
<sectionHeader confidence="0.998898" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987045966666667">
Rakesh Agrawal and Ramakrishnan Srikant. 1994.
Fast algorithms for mining association rules. In
Proc. 20th Int. Conf. Very Large Data Bases,
1215:487-499.
Alan R Aronson and Francois-Michel Lang. 2010. An
overview of MetaMap: historical perspective and
recent advances. Journal of the American Medical
Informatics Association, 17(3):229-236.
Alexandra Balahur. 2013. Sentiment Analysis in
Social Media Texts. WASSA 2013, 120.
David W. Bates, R Scott Evans, Harvey Murff, Peter
D. Stetson, Lisa Pizziferri and George Hripcsak.
2003. Detecting adverse events using information
technology. Journal of the American Medical
Informatics Association, 10(2):115-128.
Adrian Benton, Lye Ungar, Shawndra Hill, Sean
Hennessy, Jun Mao, Annie Chung, Charles E.
Leonarda and John H. Holmes. 2011. Identifying
potential adverse effects using the web: A new
approach to medical hypothesis generation.
Journal of biomedical informatics, 44(6): 989-996.
Jiang Bian, Umit Topaloglu and Fan Yu. 2012.
Towards large-scale twitter mining for drug-related
adverse events. In Proceedings of the 2012
international workshop on Smart health and
wellbeing, 25-32.
CA. Bond and Cynthia L. Raehl. 2006. Adverse drug
reactions in United States hospitals.
Pharmacotherapy: The Journal of Human
Pharmacology and Drug Therapy, 26(5):601-608.
</reference>
<page confidence="0.997066">
113
</page>
<reference confidence="0.996586231578947">
Jacob Cohen. 1960. A coefficient of agreement for
nominal scales. Educational and Psychol
Meas ;20:37e46.
Ronald A. Fisher. 1922. On the interpretation of χ 2
from contingency tables, and the calculation of P.
Journal of the Royal Statistical Society, 85(1):87-
94.
Flavien Bouillot, Phan N. Hai, Nicolas Bechet, Sandra
Bringay, Dino Ienco, Stan Matwin, Pascal
Poncelet, Mathiue Roche and Maguelonne
Teisseire. 2013. How to Extract Relevant
Knowledge from Tweets?. Communications in
Computer and Information Science.
Carol Friedman. 2009. Discovering novel adverse
drug events using natural language processing and
mining of the electronic health record. In Artificial
Intelligence in Medicine. LNAI 5651:1 -5.
Graciela H. Gonzalez, Matthew L Scotch and Garrick
L Wallstrom. Mining Social Network Postings for
Mentions of Potential Adverse Drug Reactions.
HHS-NIH-NLM (9/10/2012 - 8/31/2016).
Harsha Gurulingappa, Abdul Mateen-Rajput and Luca
Toldo. 2012. Extraction of potential adverse drug
events from medical case reports. Journal of
biomedical semantics. 3(1):15.
Harsha Gurulingappa, Luca Toldo, Abdul Mateen-
Rajput, Jan A. Kors, Adel Taweel and Yorki
Tayrouz. 2013. Automatic detection of adverse
events to predict drug label changes using text and
data mining techniques. Pharmacoepidemiology
and drug safety, 22(11):1189-1194.
A Herxheimer, MR Crombag and TL Alves. 2010.
Direct patient reporting of adverse drug reactions.
A twelve-country survey &amp; literature
review. Health Action International (HAI). Europe.
Paper Series Reference 01-2010/01.
Shawndra Hill, Raina Merchant and Lile Ungar.
(2013). Lessons Learned About Public Health from
Online Crowd Surveillance. Big Data, 1(3):160-
167.
George Hripcsak and Adam S. Rothschild. 2005.
Agreement, the F-measure, and reliability in
information retrieval. J Am Med Inform
Assoc.12:296e8.
Martin Krallinger, Florian Leitner, Obdulia Rabal,
Miguel Vazquez, Julen Oyarzabal and Alfonso
Valencia. 2013. Overview of the chemical
compound and drug name recognition
(CHEMDNER) task. In BioCreative Challenge
Evaluation Worksho. 2:2-33.
Michael Kuhn, Monica Campillos, Ivica Letunic, Lars
J. Jensen and Peer Bork. 2010. A side effect
resource to capture phenotypic effects of drugs.
Molecular systems biology, 6(343):1-6.
Robert Leaman, Laura Wojtulewicz, Ryan Sullivan,
Annie Skariah, Jian Yang and Graciela Gonzalez.
2010. Towards internet-age pharmacovigilance:
extracting adverse drug reactions from user posts to
health-related social networks. In Proceedings of
the 2010 workshop on biomedical natural
language processing. 117-125. Association for
Computational Linguistics.
Anne J. Leendertse, Antoine C. Egberts, Lennar J.
Stoker, &amp; Patricia M.L.A. van den Bemt. 2008.
Frequency of and risk factors for preventable
medication-related hospital admissions in the
Netherlands. Archives of internal medicine,
168(17), 1890.
Qi Li, Louise Deleger, Todd Lingren, Haijun Zhai,
Megan Kaiser, Laura Stoutenborough Anil G Jegga,
Kevin B Cohen and Imre Solti. 2013. Mining FDA
drug labels for medical conditions. BMC medical
informatics and decision making, 13(1):53.
Mark McClellan. 2007. Drug Safety Reform at the
FDA-Pendulum Swing or Systematic
Improvement?. New England Journal of Medicine,
356(17):1700-1702.
Silvio Moreira, Joao Filgueiras, Bruno Martins,
Francisco Couto and Mario J. Silva. 2013.
REACTION: A naive machine learning approach
for sentiment classification. In 2nd Joint
Conference on. Lexical and Computational
Semantics. 2:490-494.
Melanie Neunerdt, Michael Reyer and Rudolf Mathar.
2013. A POS Tagger for Social Media Texts
trained on Web Comments. Polibits, 48:59-66.
Azadeh Nikfarjam and Graciela H. Gonzalez. 2011.
Pattern mining for extraction of mentions of
adverse drug reactions from user comments.
In AMIA Annual Symposium Proceedings,
2011:1019-1026. American Medical Informatics
Association.
Isabel Segura-Bedmar, Paloma Martõnez and Mar’a
Herrero-Zazo. 2013. SemEval-2013 Task 9:
Extraction of Drug-Drug Interactions from
</reference>
<page confidence="0.988271">
114
</page>
<reference confidence="0.99970409375">
Biomedical Texts (DDIExtraction 2013). 3206(65):
341-351.
Cornelis S. van Der Hooft, Miriam CJM Sturkenboom,
Kees van Grootheest, Herre J. Kingma and Bruno
HCh Stricker. 2006. Adverse drug reaction-related
hospitalisations. Drug Safety, 29(2):161-168.
Hamish Cunningham. 2002. GATE, a general
architecture for text engineering. Computers and
the Humanities, 36(2):223-254.
M Rawlins. 1995. Pharmacovigilance: paradise lost,
regained or postponed? The William Withering
Lecture 1994. Journal of the Royal College of
Physicians of London, 29(1): 41-49.
Sunghwan Sohn, Jean-Pierre A. Kocher, Christopher
G. Chute and Guergana K. Savova. 2011. Drug
side effect extraction from clinical narratives of
psychiatry and psychology patients. Journal of the
American Medical Informatics Association,
18(Suppl 1):i144-i149.
...zlem Uzuner, Imre Solti and Eithon Cadag. 2010.
Extracting medication information from clinical
text. Journal of the American Medical Informatics
Association. 17(5):514-518.
Rong Xu and QuanQiu Wang. 2013. Large-scale
extraction of accurate drug-disease treatment pairs
from biomedical literature for drug repurposing.
BMC Bioinformatics, 14(1):181.
Karin Wester, Anna K. Jšnsson, Olav Spigset, Henrik
Druid and Staffan HŠgg. 2008. Incidence of fatal
adverse drug reactions: a population based study.
British journal of clinical pharmacology,
65(4):573-579.
</reference>
<page confidence="0.999006">
115
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.823335">
<title confidence="0.9780315">Detecting drugs and adverse events from Spanish health social media streams</title>
<author confidence="0.994565">Isabel Segura-Bedmar</author>
<author confidence="0.994565">Ricardo Revert</author>
<author confidence="0.994565">Paloma</author>
<affiliation confidence="0.987922">Computer Science Carlos III University of Madrid,</affiliation>
<email confidence="0.944422">isegura@inf.uc3m.es</email>
<email confidence="0.944422">rrevert@inf.uc3m.es</email>
<email confidence="0.944422">pmf@inf.uc3m.es</email>
<abstract confidence="0.992231583333333">To the best of our knowledge, this is the first work that does drug and adverse event detection from Spanish posts collected from a health social media. First, we created a goldstandard corpus annotated with drugs and adverse events from social media. Then, Textalytics, a multilingual text analysis engine, was applied to identify drugs and possible adverse events. Overall recall and precision were 0.80 and 0.87 for drugs, and 0.56 and 0.85 for adverse events.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rakesh Agrawal</author>
<author>Ramakrishnan Srikant</author>
</authors>
<title>Fast algorithms for mining association rules.</title>
<date>1994</date>
<booktitle>In Proc. 20th Int. Conf. Very Large Data Bases,</booktitle>
<pages>1215--487</pages>
<contexts>
<context position="9404" citStr="Agrawal and Srikant, 1994" startWordPosition="1424" endWordPosition="1427">ns (beneficial effects, indications and others), the systems used a list of verbs denoting indications (for example, help, work, prescribe). Drug name recognition was not necessary because the evaluation focused only on a set of four drugs: carbamazepine, olanzapine, 3 http://www.hc-sc.gc.ca/dhp-mps/medeff/indexeng.php An extension of this system was accomplished by Nikfarjam and Gonzalez (2011). The authors applied association rule mining to extract frequent patterns describing opinions about drugs. The rules were generated using the Apriori tool4, an implementation of the Apriori algorithm (Agrawal and Srikant, 1994) for association rule mining. The system was evaluated using the same corpus created for their previous work (Leaman et al., 2010), and which has been described above. The system achieved a precision of 70.01% and a recall of 66.32%. The main advantage of this system is that it can be easily adapted for other domains and languages. Another important advantage of this approach over a dictionary based approach is that the system is able to detect terms not included in the dictionary. Benton et al., (2011) created a corpus of posts from several online forums about breast cancer, which later was u</context>
</contexts>
<marker>Agrawal, Srikant, 1994</marker>
<rawString>Rakesh Agrawal and Ramakrishnan Srikant. 1994. Fast algorithms for mining association rules. In Proc. 20th Int. Conf. Very Large Data Bases, 1215:487-499.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan R Aronson</author>
<author>Francois-Michel Lang</author>
</authors>
<title>An overview of MetaMap: historical perspective and recent advances.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<pages>17--3</pages>
<contexts>
<context position="12011" citStr="Aronson and Lang, 2010" startWordPosition="1831" endWordPosition="1834">s.com7 and MedLinePlus. The authors hypothesized that unknown adverse drug effects would have a high volume of discussions over the time. Thus, the systems should monitor the number of relevant discussions for each adverse drug effect. However, to the best of our knowledge, the UDWarning’s component devoted to the detection of unrecognized adverse drug effects has not been developed yet. Bian et al., (2012) developed a system to detect tweets describing adverse drug reactions. The systems used a SVM classifier trained on a corpus of tweets, which were manually labeled by two experts. MetaMap (Aronson and Lang, 2010) was used to analyze the tweets and to find the UMLS concepts present in the tweets. The system produced poor results, mainly because tweets are riddled with spelling and grammar mistakes. Moreover, MetaMap is not a suitable tool to analyze this type of texts since patients do not usually use medical terminology to describe their medical experiences. As it was already mentioned, the recognition of drugs in social media texts has hardly been tackled and little research has been conducted to extract relationships between drugs and their side effects, since most systems were focused on a given an</context>
</contexts>
<marker>Aronson, Lang, 2010</marker>
<rawString>Alan R Aronson and Francois-Michel Lang. 2010. An overview of MetaMap: historical perspective and recent advances. Journal of the American Medical Informatics Association, 17(3):229-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Balahur</author>
</authors>
<title>Sentiment Analysis in Social Media Texts. WASSA</title>
<date>2013</date>
<pages>120</pages>
<contexts>
<context position="6922" citStr="Balahur, 2013" startWordPosition="1059" endWordPosition="1060">y linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwhile social media texts are markedly different from clinical records and scientific articles, and thereby the processing of social media texts poses additional challenges such as the management of meta-information included in the text (for example as tags in tweets) (Bouillot et al., 2013), the detection of typos and unconventional spelling, word shortenings (Neunedert et al, 2013; Moreira et al., 2013) and slang and emoticons (Balahur, 2013), among others. Moreover, these texts are often very short 107 and with an informal nature, making the processing task extremely challenging. trazodone and ziprasidone. The system achieved a good performance, with a precision of 78.3% and a recall of 69.9%. Regarding the identification of drug names in text, during the last four years there has been significant research efforts directed to encourage the development of systems for detecting these entities. Concretely, shared tasks such as DDIExtraction 2013 (Segura-Bedmar et al., 2013), CHEMDNER 2013 (Krallinger et al., 2013) or the i2b2 Medica</context>
</contexts>
<marker>Balahur, 2013</marker>
<rawString>Alexandra Balahur. 2013. Sentiment Analysis in Social Media Texts. WASSA 2013, 120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David W Bates</author>
<author>R Scott Evans</author>
<author>Harvey Murff</author>
<author>Peter D Stetson</author>
<author>Lisa Pizziferri</author>
<author>George Hripcsak</author>
</authors>
<title>Detecting adverse events using information technology.</title>
<date>2003</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<pages>10--2</pages>
<contexts>
<context position="1545" citStr="Bates et al., 2003" startWordPosition="235" endWordPosition="238">ce has received a great deal of attention due to the high and growing incidence of drug safety incidents (Bond and Raehl, 2006) as well as to their high associated costs (van Der Hooft et al., 2006). Since many ADRs are not captured during clinical trials, the major medicine regulatory agencies such as the US Food and Drug Administration (FDA) or the European Medicines Agency (EMA) require healthcare professionals to report all suspected adverse drug reactions. However, some studies have shown that ADRs are under-estimated due to the fact that they are reported by voluntary reporting systems (Bates et al., 2003; van Der Hooft et al., 2006; McClellan, 2007). In fact, it is estimated that only between 2 and 10 per cent of ADRs are reported (Rawlins, 1995). Healthcare professionals must perform many tasks during their workdays and thus finding the time to use these surveillance reporting systems is very difficult. Also, healthcare professionals tend to report only those ADRs on which they have absolute certainty of their existence. Several medicines agencies have implemented spontaneous patient reporting systems in order for patients to report ADRs themselves. Some of these systems are the MedWatch fro</context>
</contexts>
<marker>Bates, Evans, Murff, Stetson, Pizziferri, Hripcsak, 2003</marker>
<rawString>David W. Bates, R Scott Evans, Harvey Murff, Peter D. Stetson, Lisa Pizziferri and George Hripcsak. 2003. Detecting adverse events using information technology. Journal of the American Medical Informatics Association, 10(2):115-128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Benton</author>
<author>Lye Ungar</author>
<author>Shawndra Hill</author>
<author>Sean Hennessy</author>
<author>Jun Mao</author>
<author>Annie Chung</author>
<author>Charles E Leonarda</author>
<author>John H Holmes</author>
</authors>
<title>Identifying potential adverse effects using the web: A new approach to medical hypothesis generation.</title>
<date>2011</date>
<journal>Journal of biomedical informatics,</journal>
<volume>44</volume>
<issue>6</issue>
<pages>989--996</pages>
<contexts>
<context position="9912" citStr="Benton et al., (2011)" startWordPosition="1510" endWordPosition="1513">es were generated using the Apriori tool4, an implementation of the Apriori algorithm (Agrawal and Srikant, 1994) for association rule mining. The system was evaluated using the same corpus created for their previous work (Leaman et al., 2010), and which has been described above. The system achieved a precision of 70.01% and a recall of 66.32%. The main advantage of this system is that it can be easily adapted for other domains and languages. Another important advantage of this approach over a dictionary based approach is that the system is able to detect terms not included in the dictionary. Benton et al., (2011) created a corpus of posts from several online forums about breast cancer, which later was used to extract potential adverse reactions from the most commonly used drugs to treat this disease: tamoxifen, anastrozole, letrozole and axemestane. The authors collected a lexicon of lay medical terms from websites and databases about drugs and adverse events. The lexicon was extended with the Consumer Health Vocabulary (CHV)5, a vocabulary closer to the lay terms, which patients usually use to describe their medical experiences. Then, pairs of terms co-occurring within a window of 20 tokens were cons</context>
</contexts>
<marker>Benton, Ungar, Hill, Hennessy, Mao, Chung, Leonarda, Holmes, 2011</marker>
<rawString>Adrian Benton, Lye Ungar, Shawndra Hill, Sean Hennessy, Jun Mao, Annie Chung, Charles E. Leonarda and John H. Holmes. 2011. Identifying potential adverse effects using the web: A new approach to medical hypothesis generation. Journal of biomedical informatics, 44(6): 989-996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Bian</author>
<author>Umit Topaloglu</author>
<author>Fan Yu</author>
</authors>
<title>Towards large-scale twitter mining for drug-related adverse events.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 international workshop on Smart health and wellbeing,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="11798" citStr="Bian et al., (2012)" startWordPosition="1797" endWordPosition="1800"> is to extract adverse drug reactions from Google discussions. A knowledge base of drugs and their adverse effects was created by integrating information from different resources such as SIDER, DailyMed6, Drugs.com7 and MedLinePlus. The authors hypothesized that unknown adverse drug effects would have a high volume of discussions over the time. Thus, the systems should monitor the number of relevant discussions for each adverse drug effect. However, to the best of our knowledge, the UDWarning’s component devoted to the detection of unrecognized adverse drug effects has not been developed yet. Bian et al., (2012) developed a system to detect tweets describing adverse drug reactions. The systems used a SVM classifier trained on a corpus of tweets, which were manually labeled by two experts. MetaMap (Aronson and Lang, 2010) was used to analyze the tweets and to find the UMLS concepts present in the tweets. The system produced poor results, mainly because tweets are riddled with spelling and grammar mistakes. Moreover, MetaMap is not a suitable tool to analyze this type of texts since patients do not usually use medical terminology to describe their medical experiences. As it was already mentioned, the r</context>
</contexts>
<marker>Bian, Topaloglu, Yu, 2012</marker>
<rawString>Jiang Bian, Umit Topaloglu and Fan Yu. 2012. Towards large-scale twitter mining for drug-related adverse events. In Proceedings of the 2012 international workshop on Smart health and wellbeing, 25-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bond</author>
<author>Cynthia L Raehl</author>
</authors>
<title>Adverse drug reactions in United States hospitals.</title>
<date>2006</date>
<journal>Pharmacotherapy: The Journal of Human Pharmacology and Drug Therapy,</journal>
<pages>26--5</pages>
<contexts>
<context position="1054" citStr="Bond and Raehl, 2006" startWordPosition="157" endWordPosition="160"> annotated with drugs and adverse events from social media. Then, Textalytics, a multilingual text analysis engine, was applied to identify drugs and possible adverse events. Overall recall and precision were 0.80 and 0.87 for drugs, and 0.56 and 0.85 for adverse events. 1 Introduction It is well-known that adverse drug reactions (ADRs) are an important health problem. Indeed, ADRs are the 4th cause of death in hospitalized patients (Wester et al., 2008). Thus, the field of pharmacovigilance has received a great deal of attention due to the high and growing incidence of drug safety incidents (Bond and Raehl, 2006) as well as to their high associated costs (van Der Hooft et al., 2006). Since many ADRs are not captured during clinical trials, the major medicine regulatory agencies such as the US Food and Drug Administration (FDA) or the European Medicines Agency (EMA) require healthcare professionals to report all suspected adverse drug reactions. However, some studies have shown that ADRs are under-estimated due to the fact that they are reported by voluntary reporting systems (Bates et al., 2003; van Der Hooft et al., 2006; McClellan, 2007). In fact, it is estimated that only between 2 and 10 per cent </context>
</contexts>
<marker>Bond, Raehl, 2006</marker>
<rawString>CA. Bond and Cynthia L. Raehl. 2006. Adverse drug reactions in United States hospitals. Pharmacotherapy: The Journal of Human Pharmacology and Drug Therapy, 26(5):601-608.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychol Meas ;20:37e46.</booktitle>
<contexts>
<context position="16475" citStr="Cohen, 1960" startWordPosition="2536" endWordPosition="2537">f drugs and adverse events were annotated, even those containing spelling or grammatical errors (for example, hemorrajia). Nominal anaphoric expressions, which refer to previous adverse events or drugs in the comment, were also included in the annotation. The annotators found 187 drugs (from which 40 were nominal anaphors and 14 spelling errors) and 636 adverse events (from which 48 were nominal anaphors and 17 spelling errors). The corpus is available for academic purposes8. To measure the inter-annotator agreement we used the F-measure metric. This metric approximates the kappa coefficient (Cohen, 1960) 8 http://labda.inf.uc3m.es/SpanishADRCorpus when the number of true negatives (TN) is very large (Hripcsak and Rothschild, 2005). In our case, we can state that the number of TN is very high since TN are all the terms that are not true positives, false positives nor false negatives. The F-measure was calculated by comparing the two corpora created by the two first annotators. The corpus labelled by the first annotator was considered the gold-standard. As it was expected, drugs exhibit a high IAA (0.89), while adverse events point to moderate agreement (0.59). As drugs have specific names and </context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychol Meas ;20:37e46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald A Fisher</author>
</authors>
<title>On the interpretation of χ 2 from contingency tables, and the calculation of P.</title>
<date>1922</date>
<journal>Journal of the Royal Statistical Society,</journal>
<pages>85--1</pages>
<contexts>
<context position="10558" citStr="Fisher, 1922" startWordPosition="1611" endWordPosition="1612">everal online forums about breast cancer, which later was used to extract potential adverse reactions from the most commonly used drugs to treat this disease: tamoxifen, anastrozole, letrozole and axemestane. The authors collected a lexicon of lay medical terms from websites and databases about drugs and adverse events. The lexicon was extended with the Consumer Health Vocabulary (CHV)5, a vocabulary closer to the lay terms, which patients usually use to describe their medical experiences. Then, pairs of terms co-occurring within a window of 20 tokens were considered. The Fisher’s exact test (Fisher, 1922) was used to calculate the probability that the two terms co-occurred independently by chance. To evaluate the system, the authors focused on the four drugs mentioned above, and then collected their adverse effects from their drug labels. Then, precision and recall were calculated by comparing the adverse effects from drug labels and the adverse effects obtained by the system. 4 http://www.borgelt.net/apriori.html 5 http://consumerhealthvocab.org 108 The system obtained an average precision of 77% and an average recall of 35.1% for all four drugs. UDWarning (Wu et al., 2012) is an ongoing prot</context>
</contexts>
<marker>Fisher, 1922</marker>
<rawString>Ronald A. Fisher. 1922. On the interpretation of χ 2 from contingency tables, and the calculation of P. Journal of the Royal Statistical Society, 85(1):87-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Flavien Bouillot</author>
<author>Phan N Hai</author>
<author>Nicolas Bechet</author>
<author>Sandra Bringay</author>
<author>Dino Ienco</author>
<author>Stan Matwin</author>
<author>Pascal Poncelet</author>
</authors>
<title>Mathiue Roche and Maguelonne Teisseire.</title>
<date>2013</date>
<journal>Communications in Computer and Information Science.</journal>
<contexts>
<context position="6766" citStr="Bouillot et al., 2013" startWordPosition="1034" endWordPosition="1037">such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwhile social media texts are markedly different from clinical records and scientific articles, and thereby the processing of social media texts poses additional challenges such as the management of meta-information included in the text (for example as tags in tweets) (Bouillot et al., 2013), the detection of typos and unconventional spelling, word shortenings (Neunedert et al, 2013; Moreira et al., 2013) and slang and emoticons (Balahur, 2013), among others. Moreover, these texts are often very short 107 and with an informal nature, making the processing task extremely challenging. trazodone and ziprasidone. The system achieved a good performance, with a precision of 78.3% and a recall of 69.9%. Regarding the identification of drug names in text, during the last four years there has been significant research efforts directed to encourage the development of systems for detecting </context>
</contexts>
<marker>Bouillot, Hai, Bechet, Bringay, Ienco, Matwin, Poncelet, 2013</marker>
<rawString>Flavien Bouillot, Phan N. Hai, Nicolas Bechet, Sandra Bringay, Dino Ienco, Stan Matwin, Pascal Poncelet, Mathiue Roche and Maguelonne Teisseire. 2013. How to Extract Relevant Knowledge from Tweets?. Communications in Computer and Information Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Friedman</author>
</authors>
<title>Discovering novel adverse drug events using natural language processing and mining of the electronic health record.</title>
<date>2009</date>
<booktitle>In Artificial Intelligence in Medicine. LNAI</booktitle>
<volume>5651</volume>
<pages>5</pages>
<contexts>
<context position="5962" citStr="Friedman, 2009" startWordPosition="918" endWordPosition="919">op a system to automatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwhile social media texts are markedly different from clinical records and scientific ar</context>
</contexts>
<marker>Friedman, 2009</marker>
<rawString>Carol Friedman. 2009. Discovering novel adverse drug events using natural language processing and mining of the electronic health record. In Artificial Intelligence in Medicine. LNAI 5651:1 -5.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Graciela H Gonzalez</author>
<author>Matthew L Scotch</author>
<author>Garrick L Wallstrom</author>
</authors>
<title>Mining Social Network Postings for Mentions of Potential Adverse Drug Reactions.</title>
<journal>HHS-NIH-NLM</journal>
<pages>9--10</pages>
<marker>Gonzalez, Scotch, Wallstrom, </marker>
<rawString>Graciela H. Gonzalez, Matthew L Scotch and Garrick L Wallstrom. Mining Social Network Postings for Mentions of Potential Adverse Drug Reactions. HHS-NIH-NLM (9/10/2012 - 8/31/2016).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harsha Gurulingappa</author>
<author>Abdul Mateen-Rajput</author>
<author>Luca Toldo</author>
</authors>
<title>Extraction of potential adverse drug events from medical case reports.</title>
<date>2012</date>
<journal>Journal of biomedical semantics.</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="5927" citStr="Gurulingappa et al., 2012" startWordPosition="911" endWordPosition="914">adverse events. Our final goal will be to develop a system to automatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwhile social media texts are markedly different from</context>
</contexts>
<marker>Gurulingappa, Mateen-Rajput, Toldo, 2012</marker>
<rawString>Harsha Gurulingappa, Abdul Mateen-Rajput and Luca Toldo. 2012. Extraction of potential adverse drug events from medical case reports. Journal of biomedical semantics. 3(1):15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harsha Gurulingappa</author>
<author>Luca Toldo</author>
<author>Abdul MateenRajput</author>
<author>Jan A Kors</author>
</authors>
<title>Adel Taweel and Yorki Tayrouz.</title>
<date>2013</date>
<pages>22--11</pages>
<contexts>
<context position="5797" citStr="Gurulingappa et al., 2013" startWordPosition="890" endWordPosition="893">nish social media. This is a preliminary work, in which we have only focused on the automatic detection of mentions of drugs and adverse events. Our final goal will be to develop a system to automatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical t</context>
</contexts>
<marker>Gurulingappa, Toldo, MateenRajput, Kors, 2013</marker>
<rawString>Harsha Gurulingappa, Luca Toldo, Abdul MateenRajput, Jan A. Kors, Adel Taweel and Yorki Tayrouz. 2013. Automatic detection of adverse events to predict drug label changes using text and data mining techniques. Pharmacoepidemiology and drug safety, 22(11):1189-1194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Herxheimer</author>
<author>MR Crombag</author>
<author>TL Alves</author>
</authors>
<title>Direct patient reporting of adverse drug reactions. A twelve-country survey &amp; literature review.</title>
<date>2010</date>
<booktitle>Health Action International (HAI). Europe. Paper Series Reference</booktitle>
<pages>01--2010</pages>
<contexts>
<context position="2450" citStr="Herxheimer et al., 2010" startWordPosition="373" endWordPosition="376">ystems is very difficult. Also, healthcare professionals tend to report only those ADRs on which they have absolute certainty of their existence. Several medicines agencies have implemented spontaneous patient reporting systems in order for patients to report ADRs themselves. Some of these systems are the MedWatch from the FDA, the Yellow Cards from the UK Medicines agency (MHRA) or the website1 developed by the Spanish Agency of Medicines and Medical devices (AEMPS). Unlike reports from healthcare professionals, patient reports often provide more detailed and explicit information about ADRs (Herxheimer et al., 2010). Another important contribution of spontaneous patient reporting systems is to achieve patients having a more central role in their treatments. However, despite the fact that these systems are wellestablished, the rate of spontaneous patient reporting is very low probably because many 1 https://www.notificaram.es/ 106 Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 106–115, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics patients are still unaware of their existence and even may feel</context>
</contexts>
<marker>Herxheimer, Crombag, Alves, 2010</marker>
<rawString>A Herxheimer, MR Crombag and TL Alves. 2010. Direct patient reporting of adverse drug reactions. A twelve-country survey &amp; literature review. Health Action International (HAI). Europe. Paper Series Reference 01-2010/01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shawndra Hill</author>
<author>Raina Merchant</author>
<author>Lile Ungar</author>
</authors>
<date>2013</date>
<booktitle>Lessons Learned About Public Health from Online Crowd Surveillance. Big Data,</booktitle>
<pages>1--3</pages>
<contexts>
<context position="3445" citStr="Hill et al., 2013" startWordPosition="522" endWordPosition="525">Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 106–115, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics patients are still unaware of their existence and even may feel embarrassed when describing their symptoms. In this study, our hypothesis is that healthrelated social media can be used as a complementary data source to spontaneous reporting systems in order to detect unknown ADRs and thereby to increase drug safety. In recent days, social media on health information, just like has happened in other areas, have seen a tremendous growth (Hill et al., 2013). Examples of social media sites include blogs, online forums, social networking, and wikis, among many others. In this work, we focus on health forums where patients often exchange information about their personal medical experiences with other patients who suffer the same illness or receive similar treatment. Some patients may feel more comfortable sharing their medical experiences with each other rather than with their healthcare professionals. These forums contain a large number of comments describing patient experiences that would be a fertile source of data to detect unknown ADRs. Althou</context>
</contexts>
<marker>Hill, Merchant, Ungar, 2013</marker>
<rawString>Shawndra Hill, Raina Merchant and Lile Ungar. (2013). Lessons Learned About Public Health from Online Crowd Surveillance. Big Data, 1(3):160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Hripcsak</author>
<author>Adam S Rothschild</author>
</authors>
<title>Agreement, the F-measure, and reliability in information retrieval.</title>
<date>2005</date>
<journal>J Am Med Inform Assoc.12:296e8.</journal>
<contexts>
<context position="16604" citStr="Hripcsak and Rothschild, 2005" startWordPosition="2550" endWordPosition="2553">emorrajia). Nominal anaphoric expressions, which refer to previous adverse events or drugs in the comment, were also included in the annotation. The annotators found 187 drugs (from which 40 were nominal anaphors and 14 spelling errors) and 636 adverse events (from which 48 were nominal anaphors and 17 spelling errors). The corpus is available for academic purposes8. To measure the inter-annotator agreement we used the F-measure metric. This metric approximates the kappa coefficient (Cohen, 1960) 8 http://labda.inf.uc3m.es/SpanishADRCorpus when the number of true negatives (TN) is very large (Hripcsak and Rothschild, 2005). In our case, we can state that the number of TN is very high since TN are all the terms that are not true positives, false positives nor false negatives. The F-measure was calculated by comparing the two corpora created by the two first annotators. The corpus labelled by the first annotator was considered the gold-standard. As it was expected, drugs exhibit a high IAA (0.89), while adverse events point to moderate agreement (0.59). As drugs have specific names and there are a limited number of them, it is possible to create a limited and controlled vocabulary to gather many of the existing d</context>
</contexts>
<marker>Hripcsak, Rothschild, 2005</marker>
<rawString>George Hripcsak and Adam S. Rothschild. 2005. Agreement, the F-measure, and reliability in information retrieval. J Am Med Inform Assoc.12:296e8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Krallinger</author>
<author>Florian Leitner</author>
<author>Obdulia Rabal</author>
<author>Miguel Vazquez</author>
<author>Julen Oyarzabal</author>
<author>Alfonso Valencia</author>
</authors>
<title>Overview of the chemical compound and drug name recognition (CHEMDNER) task.</title>
<date>2013</date>
<booktitle>In BioCreative Challenge Evaluation Worksho.</booktitle>
<pages>2--2</pages>
<contexts>
<context position="7503" citStr="Krallinger et al., 2013" startWordPosition="1144" endWordPosition="1147">13) and slang and emoticons (Balahur, 2013), among others. Moreover, these texts are often very short 107 and with an informal nature, making the processing task extremely challenging. trazodone and ziprasidone. The system achieved a good performance, with a precision of 78.3% and a recall of 69.9%. Regarding the identification of drug names in text, during the last four years there has been significant research efforts directed to encourage the development of systems for detecting these entities. Concretely, shared tasks such as DDIExtraction 2013 (Segura-Bedmar et al., 2013), CHEMDNER 2013 (Krallinger et al., 2013) or the i2b2 Medication Extraction challenge (Uzuner et al., 2010) have been held for the advancement of the state of the art in this problem. However, most of the work on recognizing drugs concerns either biomedical literature (for example, MedLine articles) or clinical records, thus leaving unexplored this task in social media streams. Leaman et al., (2010) developed a system to automatically recognize adverse effects in user comments. A corpus of 3,600 comments from the DailyStrength health-related social network was collected and manually annotated with a total of 1,866 drug conditions, in</context>
</contexts>
<marker>Krallinger, Leitner, Rabal, Vazquez, Oyarzabal, Valencia, 2013</marker>
<rawString>Martin Krallinger, Florian Leitner, Obdulia Rabal, Miguel Vazquez, Julen Oyarzabal and Alfonso Valencia. 2013. Overview of the chemical compound and drug name recognition (CHEMDNER) task. In BioCreative Challenge Evaluation Worksho. 2:2-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kuhn</author>
<author>Monica Campillos</author>
<author>Ivica Letunic</author>
<author>Lars J Jensen</author>
<author>Peer Bork</author>
</authors>
<title>A side effect resource to capture phenotypic effects of drugs. Molecular systems biology,</title>
<date>2010</date>
<pages>6--343</pages>
<contexts>
<context position="5834" citStr="Kuhn et al., 2010" startWordPosition="898" endWordPosition="901">k, in which we have only focused on the automatic detection of mentions of drugs and adverse events. Our final goal will be to develop a system to automatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to </context>
<context position="8386" citStr="Kuhn et al., 2010" startWordPosition="1277" endWordPosition="1280">inical records, thus leaving unexplored this task in social media streams. Leaman et al., (2010) developed a system to automatically recognize adverse effects in user comments. A corpus of 3,600 comments from the DailyStrength health-related social network was collected and manually annotated with a total of 1,866 drug conditions, including beneficial effects, adverse effects, indications and others. To identify the adverse effects in the user comments, a lexicon was compiled from the following resources: (1) the COSTART vocabulary (National Library of Medicine, 2008), (2) the SIDER database (Kuhn et al., 2010), (3) MedEffect3 and (4) a list of colloquial phrases which were manually collected from the DailyStrength comments. The final lexicon consisted of 4,201 concepts (terms with the same CUI were grouped in the same concept). Finally, the terms in the lexicon were mapped against user comments to identify the adverse effects. In order to distinguish adverse effects from the other drug conditions (beneficial effects, indications and others), the systems used a list of verbs denoting indications (for example, help, work, prescribe). Drug name recognition was not necessary because the evaluation focu</context>
</contexts>
<marker>Kuhn, Campillos, Letunic, Jensen, Bork, 2010</marker>
<rawString>Michael Kuhn, Monica Campillos, Ivica Letunic, Lars J. Jensen and Peer Bork. 2010. A side effect resource to capture phenotypic effects of drugs. Molecular systems biology, 6(343):1-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Laura Wojtulewicz</author>
<author>Ryan Sullivan</author>
<author>Annie Skariah</author>
<author>Jian Yang</author>
<author>Graciela Gonzalez</author>
</authors>
<title>Towards internet-age pharmacovigilance: extracting adverse drug reactions from user posts to health-related social networks.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 workshop on biomedical natural language processing.</booktitle>
<pages>117--125</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="7864" citStr="Leaman et al., (2010)" startWordPosition="1201" endWordPosition="1204">last four years there has been significant research efforts directed to encourage the development of systems for detecting these entities. Concretely, shared tasks such as DDIExtraction 2013 (Segura-Bedmar et al., 2013), CHEMDNER 2013 (Krallinger et al., 2013) or the i2b2 Medication Extraction challenge (Uzuner et al., 2010) have been held for the advancement of the state of the art in this problem. However, most of the work on recognizing drugs concerns either biomedical literature (for example, MedLine articles) or clinical records, thus leaving unexplored this task in social media streams. Leaman et al., (2010) developed a system to automatically recognize adverse effects in user comments. A corpus of 3,600 comments from the DailyStrength health-related social network was collected and manually annotated with a total of 1,866 drug conditions, including beneficial effects, adverse effects, indications and others. To identify the adverse effects in the user comments, a lexicon was compiled from the following resources: (1) the COSTART vocabulary (National Library of Medicine, 2008), (2) the SIDER database (Kuhn et al., 2010), (3) MedEffect3 and (4) a list of colloquial phrases which were manually coll</context>
<context position="9534" citStr="Leaman et al., 2010" startWordPosition="1445" endWordPosition="1448">be). Drug name recognition was not necessary because the evaluation focused only on a set of four drugs: carbamazepine, olanzapine, 3 http://www.hc-sc.gc.ca/dhp-mps/medeff/indexeng.php An extension of this system was accomplished by Nikfarjam and Gonzalez (2011). The authors applied association rule mining to extract frequent patterns describing opinions about drugs. The rules were generated using the Apriori tool4, an implementation of the Apriori algorithm (Agrawal and Srikant, 1994) for association rule mining. The system was evaluated using the same corpus created for their previous work (Leaman et al., 2010), and which has been described above. The system achieved a precision of 70.01% and a recall of 66.32%. The main advantage of this system is that it can be easily adapted for other domains and languages. Another important advantage of this approach over a dictionary based approach is that the system is able to detect terms not included in the dictionary. Benton et al., (2011) created a corpus of posts from several online forums about breast cancer, which later was used to extract potential adverse reactions from the most commonly used drugs to treat this disease: tamoxifen, anastrozole, letroz</context>
</contexts>
<marker>Leaman, Wojtulewicz, Sullivan, Skariah, Yang, Gonzalez, 2010</marker>
<rawString>Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, Annie Skariah, Jian Yang and Graciela Gonzalez. 2010. Towards internet-age pharmacovigilance: extracting adverse drug reactions from user posts to health-related social networks. In Proceedings of the 2010 workshop on biomedical natural language processing. 117-125. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne J Leendertse</author>
<author>Antoine C Egberts</author>
<author>Lennar J Stoker</author>
<author>Patricia M L A van den Bemt</author>
</authors>
<title>Frequency of and risk factors for preventable medication-related hospital admissions in the Netherlands. Archives of internal medicine,</title>
<date>2008</date>
<volume>168</volume>
<issue>17</issue>
<pages>1890</pages>
<marker>Leendertse, Egberts, Stoker, van den Bemt, 2008</marker>
<rawString>Anne J. Leendertse, Antoine C. Egberts, Lennar J. Stoker, &amp; Patricia M.L.A. van den Bemt. 2008. Frequency of and risk factors for preventable medication-related hospital admissions in the Netherlands. Archives of internal medicine, 168(17), 1890.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Louise Deleger</author>
<author>Todd Lingren</author>
<author>Haijun Zhai</author>
<author>Megan Kaiser</author>
</authors>
<title>Mining FDA drug labels for medical conditions. BMC medical informatics and decision making,</title>
<date>2013</date>
<journal>Laura Stoutenborough Anil G Jegga, Kevin B Cohen and Imre</journal>
<pages>13--1</pages>
<contexts>
<context position="5814" citStr="Li et al., 2013" startWordPosition="894" endWordPosition="897">a preliminary work, in which we have only focused on the automatic detection of mentions of drugs and adverse events. Our final goal will be to develop a system to automatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and ca</context>
</contexts>
<marker>Li, Deleger, Lingren, Zhai, Kaiser, 2013</marker>
<rawString>Qi Li, Louise Deleger, Todd Lingren, Haijun Zhai, Megan Kaiser, Laura Stoutenborough Anil G Jegga, Kevin B Cohen and Imre Solti. 2013. Mining FDA drug labels for medical conditions. BMC medical informatics and decision making, 13(1):53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark McClellan</author>
</authors>
<title>Drug Safety Reform at the FDA-Pendulum Swing or Systematic Improvement?. New England</title>
<date>2007</date>
<journal>Journal of Medicine,</journal>
<pages>356--17</pages>
<contexts>
<context position="1591" citStr="McClellan, 2007" startWordPosition="245" endWordPosition="246"> the high and growing incidence of drug safety incidents (Bond and Raehl, 2006) as well as to their high associated costs (van Der Hooft et al., 2006). Since many ADRs are not captured during clinical trials, the major medicine regulatory agencies such as the US Food and Drug Administration (FDA) or the European Medicines Agency (EMA) require healthcare professionals to report all suspected adverse drug reactions. However, some studies have shown that ADRs are under-estimated due to the fact that they are reported by voluntary reporting systems (Bates et al., 2003; van Der Hooft et al., 2006; McClellan, 2007). In fact, it is estimated that only between 2 and 10 per cent of ADRs are reported (Rawlins, 1995). Healthcare professionals must perform many tasks during their workdays and thus finding the time to use these surveillance reporting systems is very difficult. Also, healthcare professionals tend to report only those ADRs on which they have absolute certainty of their existence. Several medicines agencies have implemented spontaneous patient reporting systems in order for patients to report ADRs themselves. Some of these systems are the MedWatch from the FDA, the Yellow Cards from the UK Medici</context>
</contexts>
<marker>McClellan, 2007</marker>
<rawString>Mark McClellan. 2007. Drug Safety Reform at the FDA-Pendulum Swing or Systematic Improvement?. New England Journal of Medicine, 356(17):1700-1702.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silvio Moreira</author>
<author>Joao Filgueiras</author>
<author>Bruno Martins</author>
<author>Francisco Couto</author>
<author>Mario J Silva</author>
</authors>
<title>REACTION: A naive machine learning approach for sentiment classification.</title>
<date>2013</date>
<booktitle>In 2nd Joint Conference on. Lexical and Computational Semantics.</booktitle>
<pages>2--490</pages>
<contexts>
<context position="6882" citStr="Moreira et al., 2013" startWordPosition="1051" endWordPosition="1054">vantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwhile social media texts are markedly different from clinical records and scientific articles, and thereby the processing of social media texts poses additional challenges such as the management of meta-information included in the text (for example as tags in tweets) (Bouillot et al., 2013), the detection of typos and unconventional spelling, word shortenings (Neunedert et al, 2013; Moreira et al., 2013) and slang and emoticons (Balahur, 2013), among others. Moreover, these texts are often very short 107 and with an informal nature, making the processing task extremely challenging. trazodone and ziprasidone. The system achieved a good performance, with a precision of 78.3% and a recall of 69.9%. Regarding the identification of drug names in text, during the last four years there has been significant research efforts directed to encourage the development of systems for detecting these entities. Concretely, shared tasks such as DDIExtraction 2013 (Segura-Bedmar et al., 2013), CHEMDNER 2013 (Kra</context>
</contexts>
<marker>Moreira, Filgueiras, Martins, Couto, Silva, 2013</marker>
<rawString>Silvio Moreira, Joao Filgueiras, Bruno Martins, Francisco Couto and Mario J. Silva. 2013. REACTION: A naive machine learning approach for sentiment classification. In 2nd Joint Conference on. Lexical and Computational Semantics. 2:490-494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melanie Neunerdt</author>
<author>Michael Reyer</author>
<author>Rudolf Mathar</author>
</authors>
<title>A POS Tagger for Social Media Texts trained on Web Comments.</title>
<date>2013</date>
<pages>48--59</pages>
<publisher>Polibits,</publisher>
<marker>Neunerdt, Reyer, Mathar, 2013</marker>
<rawString>Melanie Neunerdt, Michael Reyer and Rudolf Mathar. 2013. A POS Tagger for Social Media Texts trained on Web Comments. Polibits, 48:59-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Azadeh Nikfarjam</author>
<author>Graciela H Gonzalez</author>
</authors>
<title>Pattern mining for extraction of mentions of adverse drug reactions from user comments.</title>
<date>2011</date>
<booktitle>In AMIA Annual Symposium Proceedings,</booktitle>
<pages>2011--1019</pages>
<publisher>American Medical Informatics Association.</publisher>
<contexts>
<context position="9176" citStr="Nikfarjam and Gonzalez (2011)" startWordPosition="1392" endWordPosition="1395">s (terms with the same CUI were grouped in the same concept). Finally, the terms in the lexicon were mapped against user comments to identify the adverse effects. In order to distinguish adverse effects from the other drug conditions (beneficial effects, indications and others), the systems used a list of verbs denoting indications (for example, help, work, prescribe). Drug name recognition was not necessary because the evaluation focused only on a set of four drugs: carbamazepine, olanzapine, 3 http://www.hc-sc.gc.ca/dhp-mps/medeff/indexeng.php An extension of this system was accomplished by Nikfarjam and Gonzalez (2011). The authors applied association rule mining to extract frequent patterns describing opinions about drugs. The rules were generated using the Apriori tool4, an implementation of the Apriori algorithm (Agrawal and Srikant, 1994) for association rule mining. The system was evaluated using the same corpus created for their previous work (Leaman et al., 2010), and which has been described above. The system achieved a precision of 70.01% and a recall of 66.32%. The main advantage of this system is that it can be easily adapted for other domains and languages. Another important advantage of this ap</context>
</contexts>
<marker>Nikfarjam, Gonzalez, 2011</marker>
<rawString>Azadeh Nikfarjam and Graciela H. Gonzalez. 2011. Pattern mining for extraction of mentions of adverse drug reactions from user comments. In AMIA Annual Symposium Proceedings, 2011:1019-1026. American Medical Informatics Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabel Segura-Bedmar</author>
<author>Paloma Martõnez</author>
<author>Mar’a Herrero-Zazo</author>
</authors>
<date>2013</date>
<booktitle>SemEval-2013 Task 9: Extraction of Drug-Drug Interactions from Biomedical Texts (DDIExtraction</booktitle>
<volume>3206</volume>
<issue>65</issue>
<pages>341--351</pages>
<contexts>
<context position="7462" citStr="Segura-Bedmar et al., 2013" startWordPosition="1138" endWordPosition="1141">s (Neunedert et al, 2013; Moreira et al., 2013) and slang and emoticons (Balahur, 2013), among others. Moreover, these texts are often very short 107 and with an informal nature, making the processing task extremely challenging. trazodone and ziprasidone. The system achieved a good performance, with a precision of 78.3% and a recall of 69.9%. Regarding the identification of drug names in text, during the last four years there has been significant research efforts directed to encourage the development of systems for detecting these entities. Concretely, shared tasks such as DDIExtraction 2013 (Segura-Bedmar et al., 2013), CHEMDNER 2013 (Krallinger et al., 2013) or the i2b2 Medication Extraction challenge (Uzuner et al., 2010) have been held for the advancement of the state of the art in this problem. However, most of the work on recognizing drugs concerns either biomedical literature (for example, MedLine articles) or clinical records, thus leaving unexplored this task in social media streams. Leaman et al., (2010) developed a system to automatically recognize adverse effects in user comments. A corpus of 3,600 comments from the DailyStrength health-related social network was collected and manually annotated </context>
</contexts>
<marker>Segura-Bedmar, Martõnez, Herrero-Zazo, 2013</marker>
<rawString>Isabel Segura-Bedmar, Paloma Martõnez and Mar’a Herrero-Zazo. 2013. SemEval-2013 Task 9: Extraction of Drug-Drug Interactions from Biomedical Texts (DDIExtraction 2013). 3206(65): 341-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cornelis S van Der Hooft</author>
<author>Miriam CJM Sturkenboom</author>
<author>Kees van Grootheest</author>
<author>Herre J Kingma</author>
<author>Bruno HCh Stricker</author>
</authors>
<title>Adverse drug reaction-related hospitalisations. Drug Safety,</title>
<date>2006</date>
<pages>29--2</pages>
<marker>van Der Hooft, Sturkenboom, van Grootheest, Kingma, Stricker, 2006</marker>
<rawString>Cornelis S. van Der Hooft, Miriam CJM Sturkenboom, Kees van Grootheest, Herre J. Kingma and Bruno HCh Stricker. 2006. Adverse drug reaction-related hospitalisations. Drug Safety, 29(2):161-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
</authors>
<title>GATE, a general architecture for text engineering. Computers and the Humanities,</title>
<date>2002</date>
<pages>36--2</pages>
<marker>Cunningham, 2002</marker>
<rawString>Hamish Cunningham. 2002. GATE, a general architecture for text engineering. Computers and the Humanities, 36(2):223-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rawlins</author>
</authors>
<title>Pharmacovigilance: paradise lost, regained or postponed? The William Withering Lecture</title>
<date>1995</date>
<journal>Journal of the Royal College of Physicians of London,</journal>
<volume>29</volume>
<issue>1</issue>
<pages>41--49</pages>
<contexts>
<context position="1690" citStr="Rawlins, 1995" startWordPosition="264" endWordPosition="265">igh associated costs (van Der Hooft et al., 2006). Since many ADRs are not captured during clinical trials, the major medicine regulatory agencies such as the US Food and Drug Administration (FDA) or the European Medicines Agency (EMA) require healthcare professionals to report all suspected adverse drug reactions. However, some studies have shown that ADRs are under-estimated due to the fact that they are reported by voluntary reporting systems (Bates et al., 2003; van Der Hooft et al., 2006; McClellan, 2007). In fact, it is estimated that only between 2 and 10 per cent of ADRs are reported (Rawlins, 1995). Healthcare professionals must perform many tasks during their workdays and thus finding the time to use these surveillance reporting systems is very difficult. Also, healthcare professionals tend to report only those ADRs on which they have absolute certainty of their existence. Several medicines agencies have implemented spontaneous patient reporting systems in order for patients to report ADRs themselves. Some of these systems are the MedWatch from the FDA, the Yellow Cards from the UK Medicines agency (MHRA) or the website1 developed by the Spanish Agency of Medicines and Medical devices </context>
</contexts>
<marker>Rawlins, 1995</marker>
<rawString>M Rawlins. 1995. Pharmacovigilance: paradise lost, regained or postponed? The William Withering Lecture 1994. Journal of the Royal College of Physicians of London, 29(1): 41-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunghwan Sohn</author>
<author>Jean-Pierre A Kocher</author>
<author>Christopher G Chute</author>
<author>Guergana K Savova</author>
</authors>
<title>Drug side effect extraction from clinical narratives of psychiatry and psychology patients.</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>18</volume>
<pages>1--144</pages>
<contexts>
<context position="5982" citStr="Sohn et al., 2011" startWordPosition="920" endWordPosition="923">utomatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwhile social media texts are markedly different from clinical records and scientific articles, and thereby </context>
</contexts>
<marker>Sohn, Kocher, Chute, Savova, 2011</marker>
<rawString>Sunghwan Sohn, Jean-Pierre A. Kocher, Christopher G. Chute and Guergana K. Savova. 2011. Drug side effect extraction from clinical narratives of psychiatry and psychology patients. Journal of the American Medical Informatics Association, 18(Suppl 1):i144-i149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>zlem Uzuner</author>
</authors>
<title>Imre Solti and Eithon Cadag.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association.</journal>
<pages>17--5</pages>
<marker>Uzuner, 2010</marker>
<rawString>...zlem Uzuner, Imre Solti and Eithon Cadag. 2010. Extracting medication information from clinical text. Journal of the American Medical Informatics Association. 17(5):514-518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong Xu</author>
<author>QuanQiu Wang</author>
</authors>
<title>Large-scale extraction of accurate drug-disease treatment pairs from biomedical literature for drug repurposing.</title>
<date>2013</date>
<journal>BMC Bioinformatics,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="5877" citStr="Xu and Wang, 2013" startWordPosition="904" endWordPosition="907">omatic detection of mentions of drugs and adverse events. Our final goal will be to develop a system to automatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwh</context>
</contexts>
<marker>Xu, Wang, 2013</marker>
<rawString>Rong Xu and QuanQiu Wang. 2013. Large-scale extraction of accurate drug-disease treatment pairs from biomedical literature for drug repurposing. BMC Bioinformatics, 14(1):181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Wester</author>
<author>Anna K Jšnsson</author>
<author>Olav Spigset</author>
</authors>
<title>Henrik Druid and Staffan HŠgg.</title>
<date>2008</date>
<pages>65--4</pages>
<contexts>
<context position="891" citStr="Wester et al., 2008" startWordPosition="130" endWordPosition="133">this is the first work that does drug and adverse event detection from Spanish posts collected from a health social media. First, we created a goldstandard corpus annotated with drugs and adverse events from social media. Then, Textalytics, a multilingual text analysis engine, was applied to identify drugs and possible adverse events. Overall recall and precision were 0.80 and 0.87 for drugs, and 0.56 and 0.85 for adverse events. 1 Introduction It is well-known that adverse drug reactions (ADRs) are an important health problem. Indeed, ADRs are the 4th cause of death in hospitalized patients (Wester et al., 2008). Thus, the field of pharmacovigilance has received a great deal of attention due to the high and growing incidence of drug safety incidents (Bond and Raehl, 2006) as well as to their high associated costs (van Der Hooft et al., 2006). Since many ADRs are not captured during clinical trials, the major medicine regulatory agencies such as the US Food and Drug Administration (FDA) or the European Medicines Agency (EMA) require healthcare professionals to report all suspected adverse drug reactions. However, some studies have shown that ADRs are under-estimated due to the fact that they are repor</context>
</contexts>
<marker>Wester, Jšnsson, Spigset, 2008</marker>
<rawString>Karin Wester, Anna K. Jšnsson, Olav Spigset, Henrik Druid and Staffan HŠgg. 2008. Incidence of fatal adverse drug reactions: a population based study. British journal of clinical pharmacology, 65(4):573-579.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>