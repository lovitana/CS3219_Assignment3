<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000399">
<title confidence="0.9973195">
Automatic Annotation of Parameters from Nanodevice Development
Research Papers
</title>
<author confidence="0.979156">
Thaer M. Dieb Masaharu Yoshioka Shinjiro Hara Marcus C. Newton
</author>
<affiliation confidence="0.9502985">
Graduate school of Graduate school of RCIQE, Hokkaido Physics &amp; Astron-
IST, Hokkaido Uni- IST, Hokkaido Uni- University, Sapporo, omy, University of
versity, Sapporo, versity, Sapporo, Japan Southampton,
Japan Japan hara@rciqe.hoku Southampton, UK
</affiliation>
<email confidence="0.671068333333333">
diebt@kb.ist.h yoshi- dai.ac.jp M.C.Newton@sot
okudai.ac.jp oka@ist.hokuda on.ac.uk
i.ac.jp
</email>
<sectionHeader confidence="0.995223" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997333">
In utilizing nanodevice development research papers to assist in experimental planning and de-
sign, it is useful to identify and annotate characteristic categories of information contained in
those papers such as source material, evaluation parameter, etc. In order to support this annota-
tion process, we have been working to construct a nanodevice development corpus and a com-
plementary automatic annotation scheme. Due to the variations of terms, however, recall of the
automatic annotation in some information categories was not adequate.
In this paper, we propose to use a basic physical quantities list to extract parameter informa-
tion. We confirmed the efficiency of this method to improve the annotation of parameters.
Recall for parameters increases between 4% and 7% depending on the type of parameter and
analysis metric.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941555555556">
“Nanoinformatics” is an emerging interdisciplinary research field in developing a computational
framework to support nanoscale research (Karl et al. 2004). Nanoinformatics is the science and prac-
tice of determining which information is relevant to the nanoscale science and engineering commu-
nity, and then developing and implementing effective mechanisms for collecting, validating, storing,
sharing, analyzing, modeling, and applying this information (De la Iglesia et al. 2011). In order to
support nanodevice development process, we have been working on a project that aims at analyzing
the experiment results related to nanodevice development to provide insights for nanodevice novice
researchers to help them planning their experiments more effectively (Yoshioka et al. 2010). In this
project, we have proposed a framework to annotate useful information from research papers related to
nanodevice development (e.g., source material, evaluation parameter, and so on), and use them for
analyzing experiment results (Dieb et al. 2011). In order to speed up the annotation process, we have
built an automatic annotation framework using machine-learning techniques to annotate research pa-
pers (Dieb et al. 2012).
However, due to the variations of terms, this framework may miss to annotate terms that are not in
the training data set. Therefore, we have used chemical named entity recognition system to add gener-
alized feature to extract “source material” terms. This generalized information is useful to extract
“source material” terms and recall of this category increased. However, there are several other catego-
ries whose recall is inadequate.
</bodyText>
<footnote confidence="0.577528333333333">
This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://
creativecommons.org/licenses/by/4.0/
</footnote>
<page confidence="0.966618">
77
</page>
<note confidence="0.984741">
Proceedings of the 4th International Workshop on Computational Terminology, pages 77–85,
Dublin, Ireland, August 23 2014.
</note>
<bodyText confidence="0.999876055555556">
In this paper, we propose to use a physical quantities list for adding generalized feature for extract-
ing parameter terms in two categories (“evaluation parameter” and “experiment parameter”). In those
two categories, since “experiment parameter” represents a control parameter for the experimental
equipment and “evaluation parameter” represents ones measured by measuring devices, most of the
terms are associated with physical quantities and they contains (a) term(s) that represent(s) its charac-
teristics. We use 2 methods for the identification: first one we try to identify parameters (experiment
and evaluation) using the new automatic annotated framework. The other one, we identify the parame-
ters (in general) using the automatic annotation framework, and then classify the parameters into ex-
periment and evaluation using SVM (Support Vector Machine) (Li 2005).
Several attempts have been made to use dictionary to enhance machine-learning performance. For
example, Usié et al. (2013) is using a dictionary to assist in identifying certain categories of chemical
entities in biomedical text. Our method is using the physical quantities list to enhance the identifica-
tion of parameter information.
This paper has five sections. The first one is introduction. Second one introduces the nanodevice
development papers corpus we have developed (Dieb et al, 2011) and the automatic annotation
framework we have built (Dieb et al., 2012) in brief. Section 3 discusses parameter identification
methods. In section 4, we demonstrate the experiment and discuss the results, and section 5 is a con-
clusion.
</bodyText>
<sectionHeader confidence="0.972091" genericHeader="method">
2 Automatic Annotation Framework for Ianodevice Development Papers
</sectionHeader>
<subsectionHeader confidence="0.93272">
2.1 Ianodevice Development Papers Corpus
</subsectionHeader>
<bodyText confidence="0.9973175">
In order to analyze experiment results related to nanodevice development, we constructed nanodevice
development papers corpus that annotates characteristic information from research papers Dieb et al.
(2011). It was very critical to decide on what categories of information are necessary and adequate for
the analysis of experiment results. Based on discussion with nanodevice development researchers, we
were able to build an abstract for a development experiment in order to define the necessary terms for
the analysis. We have defined eight categories of information for annotation as below:
</bodyText>
<listItem confidence="0.999971375">
• Source Material (SMaterial) e.g., As, InGaAs
• Source Material Characteristic (SMChar) e.g.,(111)B
• Experiment Parameter (ExP) e.g., total pressure
• Value of the Experiment parameter (ExPVal) e.g., 50 nm
• Evaluation Parameter (EvP) e.g., peak energy, FWHMs
• Value of the Evaluation Parameter (EvPVal) e.g., 1.22eV
• Manufacturing Method (MMethod) e.g., SA-MOVPE
• Final Product (TArtifact) e.g., semiconductor
</listItem>
<bodyText confidence="0.940896642857143">
The information in the papers is annotated using XML format. Figure 1 shows an example of an an-
notated paper.
We demonstrate the successful formation of &lt;TArtifact&gt;
&lt;SMChar&gt;ferromagnetic&lt;/SMChar&gt; &lt;SMaterial&gt;MnAs&lt;/SMaterial&gt; nano-
clusters &lt;/TArtifact&gt; self-assembled on &lt;SMaterial&gt;
GaInAs&lt;/SMaterial&gt;&lt;SMChar&gt; (1 1 1) B &lt;/SMChar&gt; surfaces by &lt;MMe-
thod&gt;metalorganic vapor phase epitaxy
&lt;/MMethod&gt;&lt;MMethod&gt;MOVPE&lt;/MMethod&gt;).
The &lt;TArtifact&gt;&lt;SMChar&gt;hexagonal&lt;/SMChar&gt; &lt;SMate-
rial&gt;MnAs&lt;/SMaterial&gt;nanoclusters&lt;/TArtifact&gt; show &lt;EvP-
Val&gt;strong&lt;/EvPVal&gt; &lt;EvP&gt;ferromagnetic coupling&lt;/EvP&gt;&lt;ExPVal&gt;at room
temperature &lt;/ExPVal&gt; when the &lt;ExP&gt;external magnetic fields &lt;/ExP&gt; are ap-
plied &lt;ExPVal&gt;in a direction parallel to the &lt;SMate-
rial&gt;InP&lt;/SMaterial&gt;&lt;SMChar&gt;(1 1 1) B&lt;/SMChar&gt; wafer planes&lt;/ExPVal&gt;.
</bodyText>
<figureCaption confidence="0.986584">
Fig. 1: Example of annotated paper
</figureCaption>
<page confidence="0.995926">
78
</page>
<bodyText confidence="0.9998687">
Manual annotation of research papers is a time consuming process. Papers were first annotated by
graduate students in nanodevice development domain. Several experiments and discussions have been
held to improve the reliability of the corpus by resolving mismatches between different annotators.
Papers then were corrected manually based on discussion with annotators. So far, we were able to
complete five fully annotated papers, which can allow us to start our preliminary experiments concern-
ing extracting and utilizing characteristic information in supporting nanodevice development. These
papers are currently from the same research group (e.g., (Hara et al. 2006)). We also started to collabo-
rate with other research groups to enlarge and include different research topics related to nanodevice
development. Other information categories can be added to our model as needed along the way of the
corpus development. Currently this corpus is still under construction, and not yet available.
</bodyText>
<subsectionHeader confidence="0.998669">
2.2 Automatic Annotation Framework
</subsectionHeader>
<bodyText confidence="0.999586">
In order to speed up the annotation process that also require domain expert, we have built an automatic
annotation framework using the machine learning techniques to annotate the desired categories of in-
formation Dieb et al. (2012).
There are two main issues to be discussed in this automatic annotation framework:
</bodyText>
<listItem confidence="0.90661">
(1) Chemical entity recognition:
</listItem>
<bodyText confidence="0.9928644">
In literature related to nanodevice development, most of the source material items are chemical
compounds. If large training data set is available, the machine might be able to identify source mate-
rial based on the training data only with no need to additional clue. However, since training data size is
still very small, more clues are needed to identify Source Material. Identifying chemical entities can
add more clues and will help the machine to recognize Source Material terms.
A new chemical entity recognizer called SERB-CNER (Syntactically Enhanced Rule-Based CNER)
is used to enhance the identification of Source Material terms. SERB-CNER is a rule-based chemical
entity recognizer that uses regular expressions to identify chemical compounds. In addition to that,
SERB-CNER uses syntactic rules to eliminate some mismatches that might occur between chemical
entities and general text.
</bodyText>
<listItem confidence="0.62092">
(2) Overlapped term structure:
</listItem>
<bodyText confidence="0.999091333333333">
In nanodevice development domain, terms sometimes can overlap within each other, and not always
simple. This might be a common issue in several other domains. Figure 2 shows an example of term
overlapping.
</bodyText>
<figureCaption confidence="0.764947">
Fig. 2 Example of overlapped term structure
</figureCaption>
<bodyText confidence="0.9999770625">
Because of this overlapping between different terms, same chunk of text might have information re-
lated to more than one term at the same time. That makes it difficult for the machine to learn to set the
correct term information all at once. To tackle this issue, we have separated overlapped term catego-
ries into four groups where terms do not overlap within other terms from the same group. Based on
these 4 groups, the machine learning process also divided into 4 cascading levels i.e. cascading named
entity recognition (Kano et al. 2011).
For the automatic annotation framework, YamCha 0.33 (YamCha) was used, as a machine learning
based sequence labelling tools. For the features, we use linguistic features like POS tag and orthogonal
feature. POS tag was generated using rb tagger (rb tagger), which is A Simple Ruby Rule-Based Part
of Speech Tagger based on the work of Eric Brill. Orthogonal feature was calculated using regular
expressions. Chemical entity feature (CM) was calculated using SERB-CNER that identifies chemical
entities as we discussed before. Term group&apos;s features were estimated in cascading style. In each level
of this cascading style, we apply machine-learning technique to estimate the target feature for this
level using information estimated from previous levels. For example, in cascading level 1, the machine
will try to estimate term group 1 (TG1) using information of {Word, POS, Orth, CM}. In cascading
level two, the machine will try to estimate term group 2 (TG2) using information of {Word, POS,
</bodyText>
<figure confidence="0.754113">
SMChar SMaterial TArtifact
ferromagnetic
MnAs
nanocluster
</figure>
<page confidence="0.977083">
79
</page>
<bodyText confidence="0.986376">
Orth, CM}, and TG1 that the machine estimated in cascading level 1. Figure 3 illustrates the cascading
style annotation on an example of input data in IOB format.
</bodyText>
<table confidence="0.9063895">
Word POS Orth CM TG1 TG2 TG3 TG4
hexagonal JJ Lowercase O B-SMChar B-TArtifact O O
MnAs NNP TwoCaps B-CM B-SMaterial I-TArtifact O O
nanoclusters NNS Lowercase O O I-TArtifact O O
show VBP Lowercase O O O O O
strong JJ Lowercase O O O O B-EvPVal
ferromagnetic JJ Lowercase O O O B-EvP O
Note: POS=POS tag, Orth=orthogonal feature, CM=chemical compound, TG1, ... TG4=term group.
</table>
<figureCaption confidence="0.704503">
Fig. 3 Cascading style annotation on input data for the automatic annotation framework
</figureCaption>
<bodyText confidence="0.999948">
We have tested this system using only two fully annotated papers with 10 fold cross validation. We
use two metrics for analysis. One is tight agreement, which takes term category and term boundary
into consideration and the other one is loose agreement, which checks term categories only. Table 1
shows the result of the automatic annotation framework. As we can see from the table, some catego-
ries have low recall, for example, EvP and EvPVal that depends on EvP for assessment.
</bodyText>
<sectionHeader confidence="0.739413" genericHeader="method">
3 Usage of Physical Quantities for Parameter Identification
</sectionHeader>
<subsectionHeader confidence="0.995965">
3.1 Basic Idea
</subsectionHeader>
<bodyText confidence="0.962667833333334">
In the framework we proposed (Dieb et. al, 2012), recall and precision of each categories are evalu-
ated, and recall and precision of “evaluation parameter” (EvP) is lower than average. One of the rea-
sons about this problem is a variety of parameter terms used in the paper. Machine learning based se-
quence labelling tools is good at extracting terms that are also exists in the training data set, but it is
necessary to extract more generalized clue to identify terms that do not appear in the training data set.
level 1
level 2
level 3
level 4
Input features
Target
feature
</bodyText>
<tableCaption confidence="0.993696">
Table 1: Automatic annotation framework performance
</tableCaption>
<table confidence="0.999951363636364">
Tight Tight Loose Loose
/precision /recall /precision /recall
SMaterial 0.99 0.96 0.99 0.96
SMChar 0.89 0.69 0.89 0.69
MMethod 0.93 0.86 0.95 0.88
TArtifact 0.86 0.73 0.93 0.79
ExP 0.91 0.81 0.97 0.86
EvP 0.76 0.60 0.87 0.69
ExPVal 0.72 0.57 0.85 0.67
EvPVal 0.86 0.60 0.97 0.67
Overall 0.89 0.76 0.94 0.80
</table>
<page confidence="0.985539">
80
</page>
<bodyText confidence="0.999827125">
Identification of chemical named entity is helpful to extract such clue from the corpus, but it is not
sufficient.
As Nakagawa and Mori (2003) discussed, most of the compound nouns are constructed from basic
noun and identification of terms that contribute to make up compound noun is useful to extract terms.
Since “experiment parameter” (ExP) represents a control parameter for the experimental equipment
and “evaluation parameter” (EvP) represents ones measured by measuring devices, most of the terms
are associated with physical quantities and they contains (a) term(s) that represent(s) its characteristics.
For example, “density of the nanoclusters” and “height of the nanoclusters” contains physical quantity
term “density” and “height” respectively. Identification of physical quantities of test data may support
to extract new terms. For example, identification of &amp;quot;size&amp;quot; as a physical quantity might support identi-
fication of “size of nanoclusters” as a parameter.
There are two types of parameters exist in this nanodevice development papers corpus; Experiment
parameter that is used to control the conditions of the experiment like temperature, pressure, gas flow
rate, and so on; The other type is evaluation parameter that is used to evaluate the quality of the ex-
periment output like smoothness of the surface, conductivity, and so on. In this paper, a list of physical
quantities is used to support extracting terms of those two types of parameters.
</bodyText>
<subsectionHeader confidence="0.998581">
3.2 Physical Quantities List
</subsectionHeader>
<bodyText confidence="0.999941375">
In order to construct a list of physical quantities, we started with a basic list of physical properties of
matter, collected by Dr. Anne Marie Helmenstine, Ph.D. in biomedical science. 1 This list includes but
not limited to the physical properties of an object. For example, concentration, density, and so on. In
addition to this list, we have added several other common parameters that commonly found in nanode-
vice development research papers. For example, height, conductivity, and so on. Additionally, we
have added several keywords that usually in close relation with parameters like ratio, rate, percentage,
and so on. We collected these keywords from research papers related to nanodevice development. The
compiled list then checked by nanodevice researchers as a basic list for physical quantities.
</bodyText>
<subsectionHeader confidence="0.994403">
3.3 Parameter Classification
</subsectionHeader>
<bodyText confidence="0.999947545454545">
In the automatic annotation framework, we proposed (Dieb et al, 2012), experiment and evaluation
parameters (ExP and EvP) are exclusive categories and identified at the same time. However, in this
approach, recall and word boundary identification rate of terms is lower than SMaterial and MMethod.
In order to identify good term boundaries to identify parameter terms, it is better to have large varia-
tion of compound terms for representing parameter. However, since our corpus size is limited, it is
better to merge two parameter categories into one &amp;quot;Parameter&amp;quot; category to enlarge training example
for making compound parameter terms. After extracting parameter terms, another machine learning
classifier is used for categorize each extracted parameter.
Since two parameter categories (ExP and EvP) represent role of parameter in the paper, it is better
to include results of dependency analysis and verbs related to the terms. Therefore, in this paper, we
use SVM with following features to identify its category.
</bodyText>
<listItem confidence="0.988843875">
1. Information about term
A) Surface description of the term
B) lemmatized element(s) of the term
C) (a) term(s) that is (are) identified as physical quantity by a physical quantities list
2. Dependency structure results
A) First verb that given parameter terms directly depends
B) First preposition that given parameter terms directly depends
C) Lemmas that parameter terms depends.
</listItem>
<bodyText confidence="0.9471814">
Following is example of extracted features for a sentence that contains parameter term “tempera-
ture”
Figure 4 represents an example of feature extraction. Stanford Core NLP tools are used for generat-
ing dependency analysis results. Features that start with “1stVB++”, “1stIN++”, “plemma++”, and
“PAR++” represents 2-A,B,C and 1-C respectively. Other elements correspond to 1-A and 1-B.
</bodyText>
<footnote confidence="0.98126">
1 This list of physical properties of matter is available online at: http://chemistry.about.com/od/matter/a/Physical-Properties-
List.htm
</footnote>
<page confidence="0.997224">
81
</page>
<figure confidence="0.668795038461538">
Input: The size of the MnAs nanoclusters are controllable
by optimizing MOVPE growth conditions.
Experiment parameter (ExP): MOVPE growth conditions
y
MOVPE__growth__conditions MOVPE growth condition
plemma++condition plemma++optimize 1stVB++optimize
plemma++by 1stIN++by plemma++controllable
PAR++size
Evaluation parameter (EvP): size of the MnAs nanoclusters
y
The__size__of__the__MnAs the size of the mna
plemma++size plemma++controllable
-&gt; controllable-JJ (root)
-&gt; size-NN (nsubj)
-&gt; The-DT (det)
-&gt; of-IN (prep)
-&gt; nanoclusters-NNS (pobj)
-&gt; the-DT (det)
-&gt; MnAs-NNS (nn)
-&gt; are-VBP (cop)
-&gt; by-IN (prep)
-&gt; optimizing-VBG (pcomp)
-&gt; conditions-NNS (dobj)
-&gt; MOVPE-NNP (nn)
-&gt; growth-NN (nn)
Dependency analysis results
</figure>
<figureCaption confidence="0.936623">
Fig. 4 Example of feature extraction for two parameters from a text
</figureCaption>
<sectionHeader confidence="0.997854" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.974516">
4.1 Setup
</subsectionHeader>
<bodyText confidence="0.999636">
In order to confirm the effectiveness of our proposed framework, we conduct automatic annotation
experiments by using nanodevice development papers corpus with following three systems.
</bodyText>
<listItem confidence="0.994304">
• Base line system: we use the automatic annotation framework we previously proposed (Dieb et al.
2012) without physical quantities list for parameter identification.
• Suggested system without parameter classification: we integrated the physical quantities list for
parameter identification component in the automatic annotation framework. This component can-
not separate experiment (ExP) from evaluation parameter (EvP) because that depends on the con-
text, so the CRF will handle this separation based on training data.
• Suggested system with parameter classification using SVM: after annotating parameters using
automatic annotation framework with physical quantities for parameter identification component
integrated, SVM will handle the classification of parameters using statistical data into experiment
(ExP) and evaluation parameter (EvP).
</listItem>
<bodyText confidence="0.9997582">
All systems use CRF++ (CRFpp) implementation of Conditional Random field (CRF) (John et al.
2001) as the machine learning system. Additionally, we have added one more level for the cascading
for the SMChar term category, since we found some cases that caused overlap between SMChar and
SMaterial that used to be in the same term group. Figure 5 shows an example of the input data in IOB
format. Since chemical compound and parameters do not overlap between each other, we use the same
feature column for both (CM is chemical entity feature, and PAR is parameter feature based on the
physical quantity list).
For experiment 1: the feature CM/PAR has only CM type of values.
For experiment 3: the feature TG4 has Param type of values (general parameter replaces ExP, and
EvP without separation. Classification is done independently with SVM)
</bodyText>
<subsectionHeader confidence="0.906076">
4.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999988714285714">
We have five fully annotated papers. In order to check the performance of these three systems, we use
five cross fold validation (training on four papers, and testing on the 5th) for each system. We use tight
and loose agreement metrics for analysis (same as explained in section 2.2). Table 2 shows compara-
tive average results for the three experiments. In this experiment, since it is necessary to identify new
terms that are only exists in one paper; recall of baseline system is lower than the value in Table 1.
Statistical significance test is conducted for the difference between value of baseline system and value
of proposed system. “*” represents difference is statistically significant (P&lt;0.05) in both side test.
</bodyText>
<page confidence="0.995479">
82
</page>
<table confidence="0.941552">
Word POS Orth CM/PAR TG1 TG2 TG3 TG4 TG5
V/ NP Other O O O O B-ExP O
Mn NP InitCap B-CM B-SMaterial O O I-ExP O
ratio NN Lowercase B-PAR O O O I-ExP O
were VBD Lowercase O O O O O O
850 CD DigitNumber O O O O O B-ExPVal
°C NN Other O O O O O I-ExPVal
Note: POS=POS tag, Orth=orthogonal feature, CM/PAR=chemical compound/parameter list, TG1, ... TG5=term group.
</table>
<tableCaption confidence="0.923325">
Fig. 5 Example of input data for our suggested system
Table 2: Performance comparison between base line system and suggested one
</tableCaption>
<table confidence="0.971397857142857">
Base line system Our system without pa- Our system with parameter
rameter classification classification using SVM
T pre T rec L pre L rec T pre T rec L pre L rec T pre T rec L pre L rec
SMaterial 0.94 0.92 0.97 0.95 0.94 0.92 0.97 0.95 0.94 0.92 0.97 0.95
MMethod 0.97 0.70 0.98 0.70 0.98 0.72 0.98 0.72 0.98 0.72 0.98 0.72
SMChar 0.87 0.68 0.90 0.70 0.87 0.69 0.90 0.71 0.87 0.69 0.90 0.71
TArtifact 0.88 0.72 0.93 0.76 0.89 0.72 0.93 0.75 0.89 0.72 0.93 0.75
Param 0.67 0.45 0.86 0.58 0.67 0.49 0.87 0.64 0.66 0.52 0.85 0.67
ExP 0.85 0.59 0.91 0.63 0.84 0.62 0.91 0.67 0.80 0.63 0.88 0.70
EvP 0.50 0.32 0.78 0.51 0.50 0.35 0.78 0.55* 0.50 0.38* 0.76 0.57*
ExPVal 0.67 0.42 0.81 0.53 0.67 0.42 0.80 0.52 0.70 0.43 0.82 0.52
EvPVal 0.62 0.34 0.79 0.43 0.63 0.37 0.78 0.46 0.62 0.37 0.78 0.46
overall 0.82 0.63 0.90 0.69 0.82 0.64 0.90 0.71 0.81 0.64 0.89 0.71
Note: T_pre=Tight precision T_rec=Tight recall, L_pre=Loose, L_rec= Loose recall, param= general parameter resulted from merging
</table>
<sectionHeader confidence="0.376872" genericHeader="evaluation">
ExP and EvP
</sectionHeader>
<bodyText confidence="0.999948869565217">
From this result, identification of physical quantities may not affect earlier stage of cascading term
extraction (SMaterial, MMethod, SMChar, and TArtifact). For both ExP and EvP, recall is increased
when we use physical quantities list, and increase even more when we use SVM classification. Espe-
cially for EvP, improvement of recall for loose agreement of both suggested systems are statistically
significant at the 5% level. In addition, improvement of recall for tight agreement of using SVM for
parameter classification is also statistically significant. These improvements justify usage of physical
quantities list is good for improving recall of ExP and EvP. In addition, using both examples of ExP
and EvP for identification of compound word boundary is also helpful. Even though precision of ExP
and EvP are decreased from baseline system, precision of parameter term (terms that belongs to ExP
or EvP) identification is almost same as baseline system.
In order to evaluate detailed behaviour of our proposed system, we check the data whose annotation
results are different from baseline system and proposed system. We confirm there are some cases in
which new parameters terms that did not exist in training data are extracted. For example, &amp;quot;tempera-
ture of (MeCp)2Mn&amp;quot; did not exist at all in the training data, and was not able to be annotated by CRF
in test data before adding physical quantities list. After marking &amp;quot;temperature&amp;quot; as parameter, CRF was
able to find &amp;quot;temperature of (MeCp)2Mn&amp;quot; by learning compound term construction rule (i.e., PAR of
CM may be a parameter term). On the other hand, merging parameters into one category then classify-
ing them seems to be effective, because we can get use of a larger training data. For example, &amp;quot;partial
pressure&amp;quot; (where &amp;quot;pressure&amp;quot; is in the physical quantities list) did not exist in the training data. It was
not recognized neither by the baseline system nor by the suggested system without parameter classifi-
cation; However, when we merge the parameters into one category (allowing for larger training data
for the identification of parameter), the suggested system with parameter classification was able to
identify such entity. Another example, &amp;quot;period of the mask openings&amp;quot; where &amp;quot;period&amp;quot; is in the physical
</bodyText>
<page confidence="0.996048">
83
</page>
<bodyText confidence="0.9993797">
quantities list. In this example also, only the suggested system with parameter classification were able
to identify such entity using physical quantities list.
Regarding the precision, there are several cases whose parameter types are difficult to identify by
using sentence information only. For example, &amp;quot;diameter&amp;quot; can be some cases as experiment parameter,
and can be evaluation parameter in other cases depending on the context. In &amp;quot;the typical diameter of
the initial circular opening&amp;quot; it is ExP, however, in “diameter of the NCs&amp;quot;, it is EvP. Even though both
texts have similar style, &amp;quot;diameter&amp;quot; can be of different types. In order to improve the quality of pa-
rameter type classification, it is better to use other information that cannot be extracted from one sen-
tence (e.g., description of same parameter in other sentences of the same paper, position of first pa-
rameter term appearance).
</bodyText>
<sectionHeader confidence="0.997505" genericHeader="conclusions">
5 Conclusion and Future Development
</sectionHeader>
<bodyText confidence="0.999869166666667">
In this paper, we proposed to use a basic physical quantities list in combination with machine learning
technique to improve the extraction of parameter information from research papers related to nanode-
vice development. We confirmed our proposed system improve recall of parameters between 4% and
7% depending on the type of parameter and analysis metric, and using both example of Experiment
parameter and Evaluation parameter for term boundary identification is helpful.
In future studies, and as further manuscripts are annotated, we plan to make use of a larger corpus
thus allowing us to evaluate our system on a larger text collection. Additionally, we are planning to
develop a new POS tagger for the nanodevice development domain. Brill tagger is developed for gen-
eral language POS tagging purposes, and changing it with specialized POS tagger might improve the
results. It is beneficial to study the impact of each component of the system (POS tagger, the chemical
named entity recognizer, or the machine learning system) on the overall performance (Kolluru et al,
2011)
</bodyText>
<sectionHeader confidence="0.998199" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9976205">
This work was partially supported by MEXT/JSPS KAKENHI Grant Number 24240021 and
26540165.
</bodyText>
<sectionHeader confidence="0.991888" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.98651435">
CRFpp: available online at http://crfpp.googlecode.com/svn/trunk/doc/index.html
GPoSTTL: available online at http://gposttl.sourceforge.net.
Thaer M. Dieb, Masaharu Yoshioka, and Shinjiroh Hara. Automatic Information Extraction of Experiments from
Nanodevices Development Papers, IIAIAAI 2012 Proceedings of 2012 IIAI International Conference on Ad-
vanced Applied Informatics,pp.42-47,2012
Thaer M. Dieb, Masaharu Yoshioka, and Shinjiroh Hara. Construction of Tagged Corpus for Nanodevices De-
velopment Papers, GrC, 2011 Proceedings of the 2011 IEEE International Conference on Granular Comput-
ing, pp. 167–170, 2011.
Shinjiroh Hara, and Takahashi Fukui. Hexagonal ferromagnetic MnAs nanocluster formation on GaInAs/InP
(111) B layers by metal–organic vapor phase epitaxy. Applied Physics Letters, Vol. 89, 113111, 2006.
Diana de la Iglesia, Stacey Harper, Mark D. Hoover, Fred Klaessig, Phil Lippel, Bettye Maddux, Jeff Morse,
André Nel, Krishna Rajan, Rebecca Reznik-Zellen, and Mark Tuominen, (2011, Apr.). Nanoinformatics 2020
Roadmap, National Nanomanufacturing Network. Amherst, MA 01003. [Online]. Available:
http://eprints.internano.org/607/1/Roadmap_FINAL041311.pdf, 2011.
Yoshinobu Kano, Makoto Miwa, K Bretonnel Cohen, Lawrence E Hunter, Sophia Ananiadou, and Jun&apos;ichi
Tsujii. U-Compare: a modular NLP workflow construction and evaluation system. In IBM Journal of Re-
search and Development, vol. 55, no. 3, pp. 11:1-11:10, 2011.
BalaKrishna Kolluru, Lezan Hawizy, Peter Murray-Rust, Junichi Tsujii, Sophia Ananiadou. Using Workflows to
Explore and Optimise Named Entity Recognition for Chemistry. PLoS ONE, 6(5), 2011. DOI:
10.1371/journal.pone.0020181
</reference>
<page confidence="0.983679">
84
</page>
<reference confidence="0.994346947368421">
John D Lafferty, Andrew McCallum, Fernando Pereira. Conditional random fields: Probabilistic models for
segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Ma-
chine Learning. ICML ’01, San Francisco, CA, USA, Morgan Kaufmann Publishers Inc. (2001) 282–289
Yaoyong Li, Kalina Bontcheva, Hamish Cunningham SVM-based learning system for information extraction. In
Proceedings of the First international conference on Deterministic and Statistical Methods in Machine Learn-
ing, pp. 319–339, 2005.
Hiroshi Nakagawa and Tatsunori Mori: Automatic term recognition based on statistics of compound nouns and
their components, In Terminology, Vol. 9, No. 2, pp. 201-219, 2003
rb tagger: available online at http://rbtagger.rubyforge.org/
Karl Ruping and Woody Sherman. Nanoinformatics: Emerging computational tools in nanoscale research. In
Technical Proceedings of the 2004 NSTI Nanotechnology Conference and Trade Show, Volume 3, pp. 525–
528, 2004
Anabel Usié, Joaquim Cruz, Jorge Comas, Francesc Solsona, Rui Alves. A tool for the identification of chemical
entities (CheNER-BioC). Proceedings of the Fourth BioCreative Challenge Evaluation Workshop vol. 2 ,66-
69 (2013)
YamCha : available on line at http://chasen.org/ taku/software/yamcha/.
Masaharu Yoshioka, Katsuhiro Tomioka, Shinjiroh Hara, and Takahashi Fukui. Knowledge exploratory project
for nanodevice design and manuacturing. In iiWAS ’10 Proceedings of the 12th International Conference on
Information Integration and Web-based Application &amp; Services, pp. 869-872, 2010.
</reference>
<page confidence="0.999695">
85
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.473701">
<title confidence="0.9984365">Automatic Annotation of Parameters from Nanodevice Research Papers</title>
<author confidence="0.999217">Thaer M Dieb Masaharu Yoshioka Shinjiro Hara Marcus C Newton</author>
<affiliation confidence="0.962996">Graduate school of Graduate school of RCIQE, Hokkaido &amp; Astron- IST, Hokkaido Uni-versity, Sapporo, Hokkaido University, omy, University</affiliation>
<address confidence="0.796163">versity, Sapporo, Japan Southampton, Japan Japan hara@rciqe.hoku Southampton, UK</address>
<abstract confidence="0.966066230769231">diebt@kb.ist.h yoshidai.ac.jp M.C.Newton@sot okudai.ac.jp i.ac.jp on.ac.uk Abstract In utilizing nanodevice development research papers to assist in experimental planning and design, it is useful to identify and annotate characteristic categories of information contained in those papers such as source material, evaluation parameter, etc. In order to support this annotation process, we have been working to construct a nanodevice development corpus and a complementary automatic annotation scheme. Due to the variations of terms, however, recall of the automatic annotation in some information categories was not adequate. In this paper, we propose to use a basic physical quantities list to extract parameter information. We confirmed the efficiency of this method to improve the annotation of parameters. Recall for parameters increases between 4% and 7% depending on the type of parameter and analysis metric.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>CRFpp: available online at http://crfpp.googlecode.com/svn/trunk/doc/index.html GPoSTTL: available online at http://gposttl.sourceforge.net.</title>
<marker></marker>
<rawString>CRFpp: available online at http://crfpp.googlecode.com/svn/trunk/doc/index.html GPoSTTL: available online at http://gposttl.sourceforge.net.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Thaer M Dieb</author>
<author>Masaharu Yoshioka</author>
<author>Shinjiroh Hara</author>
</authors>
<title>Automatic Information Extraction of Experiments from Nanodevices Development Papers,</title>
<booktitle>IIAIAAI 2012 Proceedings of 2012 IIAI International Conference on Advanced Applied Informatics,pp.42-47,2012</booktitle>
<marker>Dieb, Yoshioka, Hara, </marker>
<rawString>Thaer M. Dieb, Masaharu Yoshioka, and Shinjiroh Hara. Automatic Information Extraction of Experiments from Nanodevices Development Papers, IIAIAAI 2012 Proceedings of 2012 IIAI International Conference on Advanced Applied Informatics,pp.42-47,2012</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thaer M Dieb</author>
<author>Masaharu Yoshioka</author>
<author>Shinjiroh Hara</author>
</authors>
<title>Construction of Tagged Corpus for Nanodevices Development Papers, GrC,</title>
<date>2011</date>
<booktitle>Proceedings of the 2011 IEEE International Conference on Granular Computing,</booktitle>
<pages>167--170</pages>
<contexts>
<context position="2372" citStr="Dieb et al. 2011" startWordPosition="333" endWordPosition="336">g, and applying this information (De la Iglesia et al. 2011). In order to support nanodevice development process, we have been working on a project that aims at analyzing the experiment results related to nanodevice development to provide insights for nanodevice novice researchers to help them planning their experiments more effectively (Yoshioka et al. 2010). In this project, we have proposed a framework to annotate useful information from research papers related to nanodevice development (e.g., source material, evaluation parameter, and so on), and use them for analyzing experiment results (Dieb et al. 2011). In order to speed up the annotation process, we have built an automatic annotation framework using machine-learning techniques to annotate research papers (Dieb et al. 2012). However, due to the variations of terms, this framework may miss to annotate terms that are not in the training data set. Therefore, we have used chemical named entity recognition system to add generalized feature to extract “source material” terms. This generalized information is useful to extract “source material” terms and recall of this category increased. However, there are several other categories whose recall is </context>
<context position="4688" citStr="Dieb et al, 2011" startWordPosition="672" endWordPosition="675"> framework, and then classify the parameters into experiment and evaluation using SVM (Support Vector Machine) (Li 2005). Several attempts have been made to use dictionary to enhance machine-learning performance. For example, Usié et al. (2013) is using a dictionary to assist in identifying certain categories of chemical entities in biomedical text. Our method is using the physical quantities list to enhance the identification of parameter information. This paper has five sections. The first one is introduction. Second one introduces the nanodevice development papers corpus we have developed (Dieb et al, 2011) and the automatic annotation framework we have built (Dieb et al., 2012) in brief. Section 3 discusses parameter identification methods. In section 4, we demonstrate the experiment and discuss the results, and section 5 is a conclusion. 2 Automatic Annotation Framework for Ianodevice Development Papers 2.1 Ianodevice Development Papers Corpus In order to analyze experiment results related to nanodevice development, we constructed nanodevice development papers corpus that annotates characteristic information from research papers Dieb et al. (2011). It was very critical to decide on what catego</context>
</contexts>
<marker>Dieb, Yoshioka, Hara, 2011</marker>
<rawString>Thaer M. Dieb, Masaharu Yoshioka, and Shinjiroh Hara. Construction of Tagged Corpus for Nanodevices Development Papers, GrC, 2011 Proceedings of the 2011 IEEE International Conference on Granular Computing, pp. 167–170, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shinjiroh Hara</author>
<author>Takahashi Fukui</author>
</authors>
<title>Hexagonal ferromagnetic MnAs nanocluster formation on GaInAs/InP (111) B layers by metal–organic vapor phase epitaxy.</title>
<date>2006</date>
<journal>Applied Physics Letters,</journal>
<volume>89</volume>
<pages>113111</pages>
<marker>Hara, Fukui, 2006</marker>
<rawString>Shinjiroh Hara, and Takahashi Fukui. Hexagonal ferromagnetic MnAs nanocluster formation on GaInAs/InP (111) B layers by metal–organic vapor phase epitaxy. Applied Physics Letters, Vol. 89, 113111, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana de la Iglesia</author>
<author>Stacey Harper</author>
<author>Mark D Hoover</author>
<author>Fred Klaessig</author>
<author>Phil Lippel</author>
<author>Bettye Maddux</author>
<author>Jeff Morse</author>
<author>André Nel</author>
<author>Krishna Rajan</author>
<author>Rebecca Reznik-Zellen</author>
<author>Mark Tuominen</author>
</authors>
<date>2011</date>
<booktitle>Nanoinformatics 2020 Roadmap, National Nanomanufacturing Network. Amherst, MA 01003. [Online]. Available: http://eprints.internano.org/607/1/Roadmap_FINAL041311.pdf,</booktitle>
<contexts>
<context position="1815" citStr="Iglesia et al. 2011" startWordPosition="251" endWordPosition="254">tion of parameters. Recall for parameters increases between 4% and 7% depending on the type of parameter and analysis metric. 1 Introduction “Nanoinformatics” is an emerging interdisciplinary research field in developing a computational framework to support nanoscale research (Karl et al. 2004). Nanoinformatics is the science and practice of determining which information is relevant to the nanoscale science and engineering community, and then developing and implementing effective mechanisms for collecting, validating, storing, sharing, analyzing, modeling, and applying this information (De la Iglesia et al. 2011). In order to support nanodevice development process, we have been working on a project that aims at analyzing the experiment results related to nanodevice development to provide insights for nanodevice novice researchers to help them planning their experiments more effectively (Yoshioka et al. 2010). In this project, we have proposed a framework to annotate useful information from research papers related to nanodevice development (e.g., source material, evaluation parameter, and so on), and use them for analyzing experiment results (Dieb et al. 2011). In order to speed up the annotation proce</context>
</contexts>
<marker>Iglesia, Harper, Hoover, Klaessig, Lippel, Maddux, Morse, Nel, Rajan, Reznik-Zellen, Tuominen, 2011</marker>
<rawString>Diana de la Iglesia, Stacey Harper, Mark D. Hoover, Fred Klaessig, Phil Lippel, Bettye Maddux, Jeff Morse, André Nel, Krishna Rajan, Rebecca Reznik-Zellen, and Mark Tuominen, (2011, Apr.). Nanoinformatics 2020 Roadmap, National Nanomanufacturing Network. Amherst, MA 01003. [Online]. Available: http://eprints.internano.org/607/1/Roadmap_FINAL041311.pdf, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshinobu Kano</author>
<author>Makoto Miwa</author>
<author>K Bretonnel Cohen</author>
<author>Lawrence E Hunter</author>
</authors>
<title>Sophia Ananiadou, and Jun&apos;ichi Tsujii. U-Compare: a modular NLP workflow construction and evaluation system.</title>
<date>2011</date>
<booktitle>In IBM Journal of Research and Development,</booktitle>
<volume>55</volume>
<pages>11--1</pages>
<contexts>
<context position="9962" citStr="Kano et al. 2011" startWordPosition="1435" endWordPosition="1438">an example of term overlapping. Fig. 2 Example of overlapped term structure Because of this overlapping between different terms, same chunk of text might have information related to more than one term at the same time. That makes it difficult for the machine to learn to set the correct term information all at once. To tackle this issue, we have separated overlapped term categories into four groups where terms do not overlap within other terms from the same group. Based on these 4 groups, the machine learning process also divided into 4 cascading levels i.e. cascading named entity recognition (Kano et al. 2011). For the automatic annotation framework, YamCha 0.33 (YamCha) was used, as a machine learning based sequence labelling tools. For the features, we use linguistic features like POS tag and orthogonal feature. POS tag was generated using rb tagger (rb tagger), which is A Simple Ruby Rule-Based Part of Speech Tagger based on the work of Eric Brill. Orthogonal feature was calculated using regular expressions. Chemical entity feature (CM) was calculated using SERB-CNER that identifies chemical entities as we discussed before. Term group&apos;s features were estimated in cascading style. In each level o</context>
</contexts>
<marker>Kano, Miwa, Cohen, Hunter, 2011</marker>
<rawString>Yoshinobu Kano, Makoto Miwa, K Bretonnel Cohen, Lawrence E Hunter, Sophia Ananiadou, and Jun&apos;ichi Tsujii. U-Compare: a modular NLP workflow construction and evaluation system. In IBM Journal of Research and Development, vol. 55, no. 3, pp. 11:1-11:10, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>BalaKrishna Kolluru</author>
</authors>
<title>Lezan Hawizy, Peter Murray-Rust, Junichi Tsujii, Sophia Ananiadou. Using Workflows to Explore and Optimise Named Entity Recognition for Chemistry.</title>
<date>2011</date>
<journal>PLoS ONE,</journal>
<volume>6</volume>
<issue>5</issue>
<pages>10--1371</pages>
<marker>Kolluru, 2011</marker>
<rawString>BalaKrishna Kolluru, Lezan Hawizy, Peter Murray-Rust, Junichi Tsujii, Sophia Ananiadou. Using Workflows to Explore and Optimise Named Entity Recognition for Chemistry. PLoS ONE, 6(5), 2011. DOI: 10.1371/journal.pone.0020181</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning. ICML ’01,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA,</location>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D Lafferty, Andrew McCallum, Fernando Pereira. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning. ICML ’01, San Francisco, CA, USA, Morgan Kaufmann Publishers Inc. (2001) 282–289</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaoyong Li</author>
<author>Kalina Bontcheva</author>
</authors>
<title>Hamish Cunningham SVM-based learning system for information extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the First international conference on Deterministic and Statistical Methods in Machine Learning,</booktitle>
<pages>319--339</pages>
<marker>Li, Bontcheva, 2005</marker>
<rawString>Yaoyong Li, Kalina Bontcheva, Hamish Cunningham SVM-based learning system for information extraction. In Proceedings of the First international conference on Deterministic and Statistical Methods in Machine Learning, pp. 319–339, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Nakagawa</author>
<author>Tatsunori Mori</author>
</authors>
<title>Automatic term recognition based on statistics of compound nouns and their components,</title>
<date>2003</date>
<journal>In Terminology,</journal>
<volume>9</volume>
<pages>201--219</pages>
<contexts>
<context position="13281" citStr="Nakagawa and Mori (2003)" startWordPosition="1983" endWordPosition="1986">entify terms that do not appear in the training data set. level 1 level 2 level 3 level 4 Input features Target feature Table 1: Automatic annotation framework performance Tight Tight Loose Loose /precision /recall /precision /recall SMaterial 0.99 0.96 0.99 0.96 SMChar 0.89 0.69 0.89 0.69 MMethod 0.93 0.86 0.95 0.88 TArtifact 0.86 0.73 0.93 0.79 ExP 0.91 0.81 0.97 0.86 EvP 0.76 0.60 0.87 0.69 ExPVal 0.72 0.57 0.85 0.67 EvPVal 0.86 0.60 0.97 0.67 Overall 0.89 0.76 0.94 0.80 80 Identification of chemical named entity is helpful to extract such clue from the corpus, but it is not sufficient. As Nakagawa and Mori (2003) discussed, most of the compound nouns are constructed from basic noun and identification of terms that contribute to make up compound noun is useful to extract terms. Since “experiment parameter” (ExP) represents a control parameter for the experimental equipment and “evaluation parameter” (EvP) represents ones measured by measuring devices, most of the terms are associated with physical quantities and they contains (a) term(s) that represent(s) its characteristics. For example, “density of the nanoclusters” and “height of the nanoclusters” contains physical quantity term “density” and “heigh</context>
</contexts>
<marker>Nakagawa, Mori, 2003</marker>
<rawString>Hiroshi Nakagawa and Tatsunori Mori: Automatic term recognition based on statistics of compound nouns and their components, In Terminology, Vol. 9, No. 2, pp. 201-219, 2003 rb tagger: available online at http://rbtagger.rubyforge.org/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Ruping</author>
<author>Woody Sherman</author>
</authors>
<title>Nanoinformatics: Emerging computational tools in nanoscale research.</title>
<date>2004</date>
<booktitle>In Technical Proceedings of the 2004 NSTI Nanotechnology Conference and Trade Show,</booktitle>
<volume>3</volume>
<pages>525--528</pages>
<marker>Ruping, Sherman, 2004</marker>
<rawString>Karl Ruping and Woody Sherman. Nanoinformatics: Emerging computational tools in nanoscale research. In Technical Proceedings of the 2004 NSTI Nanotechnology Conference and Trade Show, Volume 3, pp. 525– 528, 2004</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anabel Usié</author>
<author>Joaquim Cruz</author>
<author>Jorge Comas</author>
</authors>
<title>Francesc Solsona, Rui Alves. A tool for the identification of chemical entities (CheNER-BioC).</title>
<date>2013</date>
<booktitle>Proceedings of the Fourth BioCreative Challenge Evaluation Workshop</booktitle>
<volume>2</volume>
<pages>66--69</pages>
<contexts>
<context position="4315" citStr="Usié et al. (2013)" startWordPosition="615" endWordPosition="618">evices, most of the terms are associated with physical quantities and they contains (a) term(s) that represent(s) its characteristics. We use 2 methods for the identification: first one we try to identify parameters (experiment and evaluation) using the new automatic annotated framework. The other one, we identify the parameters (in general) using the automatic annotation framework, and then classify the parameters into experiment and evaluation using SVM (Support Vector Machine) (Li 2005). Several attempts have been made to use dictionary to enhance machine-learning performance. For example, Usié et al. (2013) is using a dictionary to assist in identifying certain categories of chemical entities in biomedical text. Our method is using the physical quantities list to enhance the identification of parameter information. This paper has five sections. The first one is introduction. Second one introduces the nanodevice development papers corpus we have developed (Dieb et al, 2011) and the automatic annotation framework we have built (Dieb et al., 2012) in brief. Section 3 discusses parameter identification methods. In section 4, we demonstrate the experiment and discuss the results, and section 5 is a c</context>
</contexts>
<marker>Usié, Cruz, Comas, 2013</marker>
<rawString>Anabel Usié, Joaquim Cruz, Jorge Comas, Francesc Solsona, Rui Alves. A tool for the identification of chemical entities (CheNER-BioC). Proceedings of the Fourth BioCreative Challenge Evaluation Workshop vol. 2 ,66-69 (2013) YamCha : available on line at http://chasen.org/ taku/software/yamcha/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaharu Yoshioka</author>
<author>Katsuhiro Tomioka</author>
<author>Shinjiroh Hara</author>
<author>Takahashi Fukui</author>
</authors>
<title>Knowledge exploratory project for nanodevice design and manuacturing.</title>
<date>2010</date>
<booktitle>In iiWAS ’10 Proceedings of the 12th International Conference on Information Integration and Web-based Application &amp; Services,</booktitle>
<pages>869--872</pages>
<contexts>
<context position="2116" citStr="Yoshioka et al. 2010" startWordPosition="295" endWordPosition="298">oinformatics is the science and practice of determining which information is relevant to the nanoscale science and engineering community, and then developing and implementing effective mechanisms for collecting, validating, storing, sharing, analyzing, modeling, and applying this information (De la Iglesia et al. 2011). In order to support nanodevice development process, we have been working on a project that aims at analyzing the experiment results related to nanodevice development to provide insights for nanodevice novice researchers to help them planning their experiments more effectively (Yoshioka et al. 2010). In this project, we have proposed a framework to annotate useful information from research papers related to nanodevice development (e.g., source material, evaluation parameter, and so on), and use them for analyzing experiment results (Dieb et al. 2011). In order to speed up the annotation process, we have built an automatic annotation framework using machine-learning techniques to annotate research papers (Dieb et al. 2012). However, due to the variations of terms, this framework may miss to annotate terms that are not in the training data set. Therefore, we have used chemical named entity</context>
</contexts>
<marker>Yoshioka, Tomioka, Hara, Fukui, 2010</marker>
<rawString>Masaharu Yoshioka, Katsuhiro Tomioka, Shinjiroh Hara, and Takahashi Fukui. Knowledge exploratory project for nanodevice design and manuacturing. In iiWAS ’10 Proceedings of the 12th International Conference on Information Integration and Web-based Application &amp; Services, pp. 869-872, 2010.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>