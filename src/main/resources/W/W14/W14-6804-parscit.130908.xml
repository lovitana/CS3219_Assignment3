<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002522">
<title confidence="0.997315">
Maximum Entropy for Chinese Comma Classification with Rich Lin-
guistic Features
</title>
<author confidence="0.99858">
Xiaojuan Li
</author>
<affiliation confidence="0.998197666666667">
School of Mathematics and
Computer Science, Guizhou
Normal University
</affiliation>
<email confidence="0.987716">
596025763@qq.com
</email>
<author confidence="0.98714">
Hua Yang*
</author>
<affiliation confidence="0.895454833333333">
School of Mathematics and
Computer Science, Guizhou
Normal University
College of Chinese Language
and Literature, Wuhan Univer-
sity
</affiliation>
<email confidence="0.99725">
yanghuastory@foxmail.com
</email>
<author confidence="0.997694">
JiangPing Huang
</author>
<affiliation confidence="0.9558635">
School of Computer, Wuhan
University
</affiliation>
<email confidence="0.995109">
hjp@whu.edu.cn
</email>
<sectionHeader confidence="0.995595" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999677461538462">
Discourse relation is an important content
of discourse semantic analysis, and the
study of punctuation is of importance for
discourse relation. In this paper, we pro-
pose a method of Chinese comma classi-
fication based on maximum entropy
(ME). This method classifies the sen-
tence relation based on comma with ME
by extracting rich linguistic features be-
fore and after the commas in sentences.
Experimental results show that this me-
thod of sentence relation based on com-
ma is feasible.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986115102941176">
Discourse consists of word, phrase, sentence and
sentence group, also known as text or utterance. Dis-
course relation studies the intrinsic structure of natural
language text and understands the semantic relation
between the text units, which plays a vital role in lan-
guage understanding and natural language generation,
is a challenge and difficult research hotspot in recent
years((Li Yan-cui et al.,2013). Discourse relation is a
fundamental work in the research of discourse analy-
sis. Discourse relation means the logical semantic
relation, between two text unit (section, clause, sen-
tence, sentence group, paragraphs, etc.) in one dis-
course, such as coordinative relation, progressive rela-
tion, adversative relation (Sun Jing et al., 2014), etc.
Defining a hierarchical semantic relationship type
system to extend sentence semantic analysis results in
that discourse level of semantic information become
one of the important ways to solve the discourse se-
mantic analysis, which is benefit to many NLP tasks
such as automatic summarization, automatic question
answering and machine translation (Zhang Mu-yu et
al., 2013).
The commas separates a sentence into two parts,
each part is called an argument of the sentence. Dis-
course relation can be generally classified into explicit
relation and implicit relation. Explicit relation recog-
nition is to identify the logical relationship between
two arguments in the presence of conjunctions (Sun
Jing et al., 2014) while implicit relation recognition is
to identify the logical relationship without the pres-
ence of conjunctions. Example 1 exemplifies the ex-
plicit relation of coordination with the conjunction
word “并(and)”, and example 2 exemplifies the im-
plicit relation of coordination in the absence of “并
(and)”, in which conjunction does not appear. For the
implicit relation recognition, the absence of conjunc-
tion entails methods that can deduce the semantic type
from other features in the context before and/or after
commas. In previous researches, explicit relation rec-
ognition often has a higher precision only based on
conjunction, while implicit relation recognition is
much more difficult than explicit relation recognition.
Some additional information is gradually introduced
in addition to lexical features (Zhang Mu-yu et al.,
2013).
eg. 1:跳水选手已全部抵达罗马,并开始赛前训
练。
&amp;quot;All divers have arrived in Rome, and start training
before the game.&amp;quot;
eg. 2:中国的稳定和发展有利于世界的和平与发
展,中国的繁荣与稳定是澳门繁荣与稳定的根本
保证。
&amp;quot;China&apos;s stability and development are conducive to
world&apos;s peace and development, China&apos;s prosperity
and stability are the fundamental guarantee of Macro&apos;s
prosperity and stability.&amp;quot;
Most researches about discourse relation recog-
nition are mainly for English. Although there are
some Chinese-oriented research (Jin Mei-xun et al.,
2004; Xu Sheng-qin and Li Pei-feng, 2013; Yang ya-
qin and Xue Nianwen, 2012), they are mainly concen-
trated on the analysis and corpus annotation, rarely
involving discourse relation recognition; and existing
research mostly directly used the English discourse
relation system, ignoring the linguistic characteristics
of Chinese language itself.
According to the classification of compound sen-
tence theories (Xing Fu-yi, 2001; Lv Shuxiang and
</bodyText>
<page confidence="0.997341">
11
</page>
<note confidence="0.6543285">
Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 11–17,
Wuhan, China, 20-21 October 2014
</note>
<bodyText confidence="0.999749222222222">
Zhu De-xi, 1952; Shao Jing-min, 2007), in this paper,
we propose 9 categories of Chinese comma classifica-
tion for sentence relation, including Coordination(A
�iq), Interpretation(ffi ), Location(AA), Progres-
siveness(AA), Reliance(nfF&amp;quot;1&apos;), Subsequence( diff ),
Time(K&apos;17), Purpose(Hn), Cause and Effect(QA),
and classify Chinese comma into these 9 classes with
maximum entropy method (ME), the corpus we used
is annotated with a well-established representation
scheme for Chinese comma, and the features we used
are extracted from the corpus that is based on the sen-
tences’ words information on both sides of the comma.
We carried out the classification experiment on both
the explicit relation recognition and the implicit rela-
tion recognition respectively consisted of the 9 cate-
gories mentioned above.
The rest of the paper is organized as follows. In
section 2, we describe the related work about comma
classification research. Section 3 introduces the fea-
tures we used and other features selecting method
used in related work. Section 4 reviews ME method
and describe the comma classification method based
on ME model. In section 5, we present the process of
our experiment and evaluate the experimental result.
In section 6, we analyze the causes that lead to the
main classification error in different aspects. Finally,
a conclusion and future work are put forward.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999968561403509">
As elemental segmentation units of discourse,
punctuations provide a new clue for discourse
analysis. Many researches about punctuation are
closely related with many natural language processing
tasks, such as long sentences segmentation,
elementary discourse unit recognition, the
classification of the relationship between sentences,
semantic disambiguation, etc. 16 kinds of
punctuations are widely used in Chinese, such as
comma, period, question mark, etc. With more than
20 different usages, comma is one of the most
common punctuations. Chinese comma can be used to
separate coordinate composition or coordinate clause
of the sentence, or to separate the words, phrases,
clauses which indicate time, place, purpose, condition,
or to express a pause between the clauses separated by
conjunction (Gu Jing-jing and Zhou Guo-dong, 2014),
etc. In recent years, with the progress of the research
about punctuation, the study of comma classification
gradually caught attention.
Jin and Li (Jin Mei-xun et al., 2004) viewed
comma as an important role in long Chinese sentence
segmentation, they proposed a method for classifying
commas in Chinese sentences by their context, then
segmented a long sentence according to the
classification results. Element discourse unit (EDU)
recognition is a fundamental task of discourse
analysis and Chinese punctuation is viewed as a
elementary delimiter. Xu Sheng-qin and Li Pei-feng
(Xu Sheng-qin and Li Pei-feng, 2013) considered
Chinese comma to be the boundary of the discourse
units and anchor discourse relations between units
separated by comma. They classified comma’s role
into seven major types and implemented automatic
disambiguation of the Chinese comma type. Xue and
Yang (Xue Nian-wen and Yang Ya-qin, 2011) held
that the central problem of Chinese sentence segmen-
tation was comma disambiguation, and in some
context it identifies the boundary of a sentence just as
a period, a question mark, or an exclamation mark
does. Yang and Xue (Yang ya-qin and Xue Nian-wen,
2012) further pointed out that the Chinese comma
signifies the boundary of discourse units and also
anchors discourse relations between adjacent text
spans, and they proposed a discourse structure-
oriented classification of the comma that can be
automatically extracted from the Chinese Treebank
based on syntactic patterns, and use this method to
disambiguate the Chinese comma.
In this paper, we propose a method of sentence
relation classification based on rich linguistic features
around Chinese comma in sentences. We try to find
out the difference among sentence relation types by
rich linguistic features, which is found by potential
semantic rules derived by statistical method, which is
of significance especially for the implicit relation
recognition.
</bodyText>
<sectionHeader confidence="0.996603" genericHeader="method">
3 Features Selection
</sectionHeader>
<bodyText confidence="0.999989366666667">
Currently, few research about sentence relation
is based on comma. Sun jing (Sun Jing et al., 2014)
classified the discourse relation into four categories:
cause and effect( Q A ), coordination( A �iq ),
transition(**), explanation(*i;�) with maximum
entropy, on the basis of utilizing a set of context
features, lexical features and dependency tree features
extracted from the corpus of Chinese discourse built
by themselves. Lin (Lin Zi-heng et al., 2009) imple-
mented an implicit discourse relation classifier and
showed initial results based on the recently released
Penn Discourse Treebank. The features they used
include the modeling of the context of relations,
features extracted from constituent parse trees and
dependency parse trees, and word pair features. Zheng
(Zheng Lue-xing et al., 2013) presented an approach
of Chinese coordination relations recognition based
on CRFs. They extracted role information according
to their functions in the generation of Chinese
coordination relations.
We analyze the feature of different types of
sentences, refer to the features proposed in the paper
of Li Yancui (Li Yan-cui et al., 2013) and Xue (Xue
Nian-wen and Yang Ya-qin, 2011), and propose to
learn discourse relation rules through linguistic
features of the sentences. This method extract
linguistic features from both sides of comma in the
sentence. Before extracting the features, the following
pre-processing is adopted: 1) segment the sentences
into words by using the Chinese lexical analysis
</bodyText>
<page confidence="0.994">
12
</page>
<bodyText confidence="0.999907166666667">
system (ICTCLAS) designed by institute of
computing technology, Chinese academy of sciences;
2) eliminate the extremely precise POS type for the
words, which belongs to the same POS on more
general level. For example, &amp;quot;nr&amp;quot; expresses name, &amp;quot;ns&amp;quot;
expresses place name), and we use &amp;quot;n&amp;quot; to express the
noun, &amp;quot;v&amp;quot; to express verb uniformly, etc.
We call the sentence on the left of the comma as
argument 1, denoted as &amp;quot;l&amp;quot;, and call the sentence after
the comma as argument 2 and express it with &amp;quot;r&amp;quot;.
Features we selected and their descriptions are shown
in table 1.
</bodyText>
<tableCaption confidence="0.990586">
Table 1 the selected features and their description
</tableCaption>
<table confidence="0.984808318181818">
feature description
1 f1,f1_p The first word of argument 1 and its part of speech(POS)
2 f2 Conjunction that connects the clauses on both sides of the comma, if no con-
3 f3 junction appear, f2 =null
4 f4,f4_p Difference of clause lengths between argument 1 and argument 2, if the length
5 f5_l,f5_r of argument 1 is greater than the argument 2, f3=1, otherwise f3=0
6 f6,f6_p The first word of argument 2 and its POS
7 f7 Whether the l and r contain a conjunction
8 f8 The last word of argument 1 and its POS
9 f9 The POS of the first word combination of argument 1 and argument
10 f10 2(f1_p+f4_p)
11 f11 Combination of the POS of the first word and last word in argument
12 f12 1(f1_p+f6_p)
Let x denote whether the first word of l is a conjunction, x=1 if the first word
of l is a conjunction, else x =0. f9 is the combination of x and POS of the first
word of l
Feature 10 is analogous to f9, while x denotes whether the last word of l is a
conjunction.
Feature 11 is analogous to f9, while x denotes whether the first word of r is a
conjunction.
f12=1 if the first word and the last word of argument 1 constitute a conjunc-
tion, else f12=0
</table>
<bodyText confidence="0.990595625">
Features of case 1 and case 2 mentioned above
are as follows.
1:f1=Oh7KA_T-, f1p=n, f2=A, f3=1, f4=A,
f4p=c, f5l=0, f5r=1, f6=_W j, f6p=n, f7=n+c, f8=n+n,
f9=0+n, f10=0+n, f11=1+c, f12=0
2:f1=Oh7KA_T-, f1p=n, f2=null, f3=1, f4=}f44n,
f4p=ad, f5l=0, f5r=0, f6= _W j , f6p=n, f7=n+v,
f8=n+n, f9=0+n, f10=0+n, f11=1+v, f12=0
</bodyText>
<sectionHeader confidence="0.9731905" genericHeader="method">
4 Maximum Entropy for Comma Clas-
sification
</sectionHeader>
<bodyText confidence="0.9996712">
Maximum entropy model (ME) method is to
select the model with the maximum entropy that
meets some constraint conditions. Maximum entropy
model can be applied to classification(Li Hang, 2012,
Sang Haiyan et al., 2013).
In our implementation, ME model uses the
features listed in table1.
Let C be the set of types of the 9 sentence rela-
tion classes we have defined, and S be the sentence set,
we can calculate p(cj  |si) through maximum en-
tropy model, which means the probability si belongs
to cj , where si ∈S and cj ∈C. For comma classifi-
cation problem, cj with arg max p(cj  |si) will be
the class that the sentence si belongs to.
The comma classification method is similar to
text classification method, their basic idea is to use
learning set composed of training samples to train a
classifier, to test the performance of the classifier with
testing samples in testing set, and use the trained
classifier to classify new sentences.
</bodyText>
<sectionHeader confidence="0.994748" genericHeader="method">
5 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.999909941176471">
Corpus used in our experiment is rebuilt from
part of CTB 5.0. We annotated it with the information
of class. The corpus is divided into explicit relation
and implicit relation according to whether the
sentences contain conjunction. The distribution of the
sample set for each class is shown in table 2 .
The eigenvector expressed with features in Table
1 for each sentence in Table 2 is obtained. All the
eigenvectors obtained constitute our data set. The data
set is divided into training data set and testing data set
with the proportion of 80% : 20%, 10-times 10-fold
cross-validation policy is employed. All of above
prepared, one of the mallet toolkit classifier--
maximum entropy (MaxEnt) classifier is adopted to
train and test the final model. The experimental
results, i.e., classification precisions for all sentence
relation class, are shown in table 3.
</bodyText>
<page confidence="0.999753">
13
</page>
<tableCaption confidence="0.998545">
Table 2 distribution of sentence relationship
</tableCaption>
<table confidence="0.966898909090909">
number data
categories explicit implicit
1 Coordination(BL) 25 24
2 Interpretation(CS) 25 25
3 Location(DD) 25 6
4 Progressiveness(DJ) 25 11
5 Reliance(PJ) 25 10
6 Subsequence(SC) 12 25
7 Time(SJ) 25 24
8 Purpose(MD) 25 6
9 Cause and Effect(YG) 25 25
</table>
<bodyText confidence="0.991902153846154">
We conducted several experiments on different
training set size and testing set size. Results show that
the unbalance of training set size has a significant
effect on the experimental results. So we use the same
training set size avoid this instability. As can be seen
in table 3, results for four relations (Location, Pro-
gressiveness, Reliance and Purpose) are absent. The
reason for the absence is that the corresponding preci-
sion is unreliable due to the sparseness of related
samples in training data showed in Table 2. In addi-
tion, the precision for implicit relations is signifi-
cantly lower than that for the explicit relations.
Table 3 experimental results
</bodyText>
<equation confidence="0.953642444444445">
category of relationship explicit precision implicit precision
Coordination(BL) 56.5% 49.7%
Interpretation(CS) 62.4% 47.3%
Location(DD) 84.9% --
Progressiveness(DJ) 63.2% --
Reliance(PJ) 71.2% --
Subsequence(SC) -- 38.9%
Time(SJ) 43.1% 54.2%
Purpose(MD) 55.5% --
</equation>
<bodyText confidence="0.574351">
Cause and Effect(YG) 72% 74.1%
ALL 65.2% 50.6%
</bodyText>
<sectionHeader confidence="0.990138" genericHeader="method">
6 Analysis
</sectionHeader>
<bodyText confidence="0.997137615384616">
Table 4 shows the details of explicit relation
classification, which includes the percentage of the
samples that are correctly classified and falsely
classified into other classes. Each item in Table 4 is
the average calculated from 10 times repeated ex-
periment. Table 5 is corresponding result for implicit
relation classification.
As can be seen in Table 4 and Table 5, main er-
rors mainly occur as follows:
(1)For explicit relation, Many Location rela-
tion and Time relation are falsely classified into each
other; Time relation is cline to be classified into Reli-
ance; Purpose relation is classified into Reliance. The
reasons for falsely classification for Location and
Time is: the first word in argument 1 is preposition in
most cases, and the last word in argument 1 means a
location expressed as “f” in some cases, as shown in
example 3 and example 4; for the relation of Purpose
and Reliance, the reason for falsely classification is
that the first word in argument 1 is preposition in
most cases, as shown in example 5 and example 6 ;
for the relation of Time and Reliance, the reason for
falsely classification is that the first word in argument
1 is preposition in most cases and their conjunction is
composed of the first word and the last word of argu-
ment 1, as shown in example 4 and example 6.
</bodyText>
<page confidence="0.999502">
14
</page>
<tableCaption confidence="0.970403">
Table 4 details for explicit relation classification
</tableCaption>
<table confidence="0.999606">
Interpre- Location Progres- Reli- Time Coordina- Purpos Cause
tation siveness ance tion e and
Effect
Interpre- 64% 4% 11% 0 0 14% 4% 4%
tation
Location 0 73% 5% 0 14% 0 5% 5%
Progres- 15% 7% 56% 0 0 22% 0 0
siveness
Reliance 4% 0 0 83% 4% 0 8% 0
Time 0 28% 8% 12% 44% 4% 4% 0
Coordi- 12% 0 16% 0 0 64% 8% 0
nation
Purpose 5% 0 0 20% 5% 5% 65% 0
Cause 0 0 7% 0 0 0 0 93%
and Ef-
fect
</table>
<tableCaption confidence="0.834026">
Table5 details for implicit relation classification
</tableCaption>
<table confidence="0.992929">
Coordination Interpretation Subsequence Time Cause and
Effect
Coordination 12% 23% 35% 31% 0
Interpretation 37% 56% 7% 0 0
Subsequence 0 6% 71% 24% 0
Time 21% 8% 33% 33% 4%
Cause and 0 4% 0 0 96%
Effect
</table>
<bodyText confidence="0.971506910714286">
eg. 3:在今天的比赛中,中国国际大师徐俊
迎战队友、国际特级大师叶荣光。(地点)
&amp;quot;In today&apos;s competition, the Chinese international
master Jun xu will meet his teammate who is an
international grandmaster Rongguang Ye.&amp;quot;
eg. 4:在这一巨大的变革中,德国成为最大
的得益者。(时间)
&amp;quot;In this huge change, Germany is the biggest
beneficiary.&amp;quot;
eg. 5:为解决庞大资金需求,公司正争取发
行股票和尝试更多的融资渠道。(目的)
&amp;quot;To solve the large capital demand, the company
is seeking to issue shares and try more financing
channels.&amp;quot;
eg. 6:据预测,今年全球经济增长幅度可达
到百分之四点一。(凭借)
&amp;quot;It is predicted that the global economic growth
can reach 4.1% this year.&amp;quot;
Example 3, 4, 5, 6 represents the Location, Time,
Purpose and Reliance respectively. In example 3, the
conjunction is the combination of “在” and “中”,
and the pos-of-part of “在” is preposition, the “中”
means location. In example 4 sentence, the conjunc-
tion is the combination of “在” and “中”, the pos-
of-part of this conjunction is same as example 3. In
example 5 sentence, the conjunction is “为”, and its
pos-of-part is preposition. In example 6 sentence, the
conjunction is the combination of “据” and “预测”,
the pos-of-part of “据” is preposition.
(2)Subsequence and other relations class in
implicit relations
Implicit relation has no obvious semantic type
sign (conjunction) so that it is difficult to determine
the existence of relation and the relation type without
human&apos;s judgment. Subsequence relation is very spe-
cial that can not be easily differentiated from other
relation types even by human, which often result in
controversy among annotator, and reduce precision of
the implicit relation recognition. For example, the
subsequence relation expresses the sentence relation
of time, space or logical sequence, etc. However,
most other relations involve certain subsequence rela-
tion to some degree, resulting in that other relation is
easily classified as subsequence in the implicit rela-
tion recognition. Example 7 represents the coordina-
tion, and example 8 represents the subsequence as
shown below.
eg. 7:拉美是一个充满希望的大陆,具有巨
大的发展潜力。(并列)
&amp;quot;Latin America is a continent of hope, possess-
ing huge development potential.&amp;quot;
eg. 8:《新中东》一书原为英文版,去年秋
冬之交出版。(顺承)
&amp;quot;“The new Middle East” was English version,
and published since the turn of the last autumn and
winter.&amp;quot;
</bodyText>
<page confidence="0.992971">
15
</page>
<bodyText confidence="0.945221935483871">
(3)Coordination, Progressiveness and Inter-
pretation, Coordination and Time
In Chinese, Coordination relation describes the
parallelism between clauses or words, which can be
split into two independent arguments by the comma.
Progressiveness relation always implies that the sec-
ond argument contains more information. However,
in many cases, the conjunction “并” (expressing par-
allelism in most cases) can also express progressive
relationship. No matter in the explicit or implicit rela-
tionship recognition, Progressive and Coordinate are
easy to be confused with each other because they have
similar structure and POS information.
The examples below are two sentences extracted
from the corpus, example 9 represents the coordina-
tion, and example 10 represents the progressiveness.
eg. 9:两年多来两国经贸合作已顺利起步,
并取得可观的进展。(并列)
&amp;quot;For more than two years the bilateral economic
and trade cooperation has started smoothly, and
achieved considerable progress. &amp;quot;
eg. 10:中国已确定了未来五年高技术研究重
点,并着手制订下世纪的高科技研究计划。(递
进)
&amp;quot;China has determined the high-tech research
focal point of the next five years, and has began to
make plan of high-tech research for next century.&amp;quot;
It is difficult to analyze the difference between
coordination and progressiveness from above
examples, which is one of the causes in classification
errors.
</bodyText>
<sectionHeader confidence="0.991646" genericHeader="conclusions">
7 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999990388888889">
We proposed the Chinese comma classification
based on Chinese discourse relationship corpus. Rich
linguistic features have been selected in the classifica-
tion and sentence relations are classified into 9 cate-
gories with maximum entropy method. The experi-
mental results show that the method based on linguis-
tic features for classification of comma is feasible.
However, from the result we can see that the overall
classification precision still needs to be improved,
especially for the implicit relation. In future work, we
will further study how to extract more effective fea-
tures, try to attach great importance to the role of con-
junctions, which is vital to distinguish the explicit
relation between sentences, and combine these fea-
tures with the structure of the sentences to improve
classification accuracy. In addition, we also need to
solve the problem of the small scale of sample set and
data sparsity.
</bodyText>
<sectionHeader confidence="0.987043" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.690879818181818">
This paper is supported by Natural Science Founda-
tion Project (61070243, 6133012), Major Project of
Invitation for Bid of National Social Science Founda-
tion (11&amp;ZD189), Guizhou High-level Talent Re-
search Project (TZJF-2010-048), Guizhou Normal
University PhD Start-up Research Project (11904-
05032110011), and Governor Special Fund Grant of
Guizhou Province for Prominent Science and Tech-
nology Talents (identification serial number &amp;quot;,,n*�
a -- (2012)155 4� &amp;quot;), China Postdoctoral Science
Foundation(2013M531730).
</bodyText>
<sectionHeader confidence="0.666348" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999183911111111">
Li Yan-cui, Feng Wen-he, Zhou Guo-dong. 2013.
Research of Chinese clause identificiton based on
comma. Journal of Beijing University (Natural Sci-
ence Edition), 2013(01): 7-14.
Sun Jing, Li Yan-cui, Zhou Guo-dong. 2014. Re-
search of Chinese implicit discourse relation rec-
ognition. Journal of Beijing University (Natural
Science Edition), 2014(01): 111-117.
Gu Jing-jing, Zhou Guo-dong. Chinese comma classi-
fication based on segmentation and part of speech-
tagging. 2014. Computer Engineering and Applica-
tions.
Jin Mei-xun, Mi-Young Kim, Donggil Kim, Jong-
Hyeok Lee. 2004. Segmentation of Chinese long-
sentences using commas. SIGHAN2004
Xu Sheng-qin, Li Pei-feng. 2013. Recognizing Chi-
nese elementary discourse unit on comma. Asian
Language Processing (IALP),2013 Internationa.
IEEE, 2013: 3-6.
Yang Ya-qin , Xue Nian-wen . 2012. Chinese comma
disambiguation for discourse analysis. Proceedings
of the 50th Annual Meeting of the Asso. Associa-
tion for Computational Li, 2012: 786-794.
Xing Fu-yi. 2001. The study of Chinese complex sen-
tence. Beijing:Commercial Press,2001
Lv Shu-xiang, Dexi Zhu. 1952. Grammatical rhetoric
speech. Liaoning:Liaoning Education Press,1952
Shao Jing-min. 2007. The general theory of modern
Chinese. Liaoning:Shanghai Education Press,2007
Lin Zi-heng, Kan Min-yen, Hwee Tou Ng . 2009.
Recognizing implicit discourse relations in the
Penn Discourse Treebank. Proceedings of the 2009
Conference on Empirical Me Association for
Computational Li, 2009: 343-351.
Li Hang. 2012. Statistical learning method. Beijing:
Tsinghua University Press, 2012: 80-87
Sang Hai-yan, Gu Lia-Altenbek, Niu Ning-ning. 2013.
Kazakh part-of-speech tagging method based on
maximum entropy. Computer Engineering and Ap-
plications, 2013, 49(11): 126-129,16.
Zhang Mu-yu,Song Yuan,Qin Bing,Liu Ting 2013.
Chinese Discourse Relation Recognition. Journal
of Chinese information, 2013,27(6): 51-57.
Xue Nian-wen, Yang Ya-qin . 2011. Chinese sentence
segmentation as comma classification. Proceedings
</reference>
<page confidence="0.971595">
16
</page>
<reference confidence="0.992792333333333">
of the 49th Annual Meeting of the Asso. Associa-
tion for Computational Li, 2011: 631-635.
Zheng Lue-xing, Lv Xue-qiang, Liu Kun, Lin Jin.
2013. Automatic Identification of Chinese Coordi-
nation Relations. Journal of Beijing University
(Natural Science Edition),2013,49(1):20-24.
</reference>
<page confidence="0.999409">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.361463">
<title confidence="0.9931215">Entropy for Chinese Comma Classification with Rich guistic Features</title>
<author confidence="0.970007">Xiaojuan</author>
<affiliation confidence="0.999703333333333">School of Mathematics Computer Science, Normal University</affiliation>
<email confidence="0.947776">596025763@qq.com</email>
<affiliation confidence="0.97634925">School of Mathematics Computer Science, Normal College of Chinese</affiliation>
<address confidence="0.984708">Literature, Wuhan</address>
<email confidence="0.9842175">sityyanghuastory@foxmail.com</email>
<author confidence="0.616301">JiangPing</author>
<affiliation confidence="0.9768505">School of Computer, University</affiliation>
<email confidence="0.823944">hjp@whu.edu.cn</email>
<abstract confidence="0.996386428571429">Discourse relation is an important content of discourse semantic analysis, and the study of punctuation is of importance for discourse relation. In this paper, we propose a method of Chinese comma classification based on maximum entropy (ME). This method classifies the sentence relation based on comma with ME by extracting rich linguistic features before and after the commas in sentences. Experimental results show that this method of sentence relation based on comma is feasible.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Li Yan-cui</author>
<author>Feng Wen-he</author>
<author>Zhou Guo-dong</author>
</authors>
<title>Research of Chinese clause identificiton based on comma.</title>
<date>2013</date>
<journal>Journal of Beijing University (Natural Science Edition),</journal>
<volume>2013</volume>
<issue>01</issue>
<pages>7--14</pages>
<contexts>
<context position="9603" citStr="Yan-cui et al., 2013" startWordPosition="1430" endWordPosition="1433">owed initial results based on the recently released Penn Discourse Treebank. The features they used include the modeling of the context of relations, features extracted from constituent parse trees and dependency parse trees, and word pair features. Zheng (Zheng Lue-xing et al., 2013) presented an approach of Chinese coordination relations recognition based on CRFs. They extracted role information according to their functions in the generation of Chinese coordination relations. We analyze the feature of different types of sentences, refer to the features proposed in the paper of Li Yancui (Li Yan-cui et al., 2013) and Xue (Xue Nian-wen and Yang Ya-qin, 2011), and propose to learn discourse relation rules through linguistic features of the sentences. This method extract linguistic features from both sides of comma in the sentence. Before extracting the features, the following pre-processing is adopted: 1) segment the sentences into words by using the Chinese lexical analysis 12 system (ICTCLAS) designed by institute of computing technology, Chinese academy of sciences; 2) eliminate the extremely precise POS type for the words, which belongs to the same POS on more general level. For example, &amp;quot;nr&amp;quot; expres</context>
</contexts>
<marker>Yan-cui, Wen-he, Guo-dong, 2013</marker>
<rawString>Li Yan-cui, Feng Wen-he, Zhou Guo-dong. 2013. Research of Chinese clause identificiton based on comma. Journal of Beijing University (Natural Science Edition), 2013(01): 7-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sun Jing</author>
<author>Li Yan-cui</author>
<author>Zhou Guo-dong</author>
</authors>
<title>Research of Chinese implicit discourse relation recognition.</title>
<date>2014</date>
<journal>Journal of Beijing University (Natural Science Edition),</journal>
<volume>2014</volume>
<issue>01</issue>
<pages>111--117</pages>
<contexts>
<context position="1663" citStr="Jing et al., 2014" startWordPosition="242" endWordPosition="245">the intrinsic structure of natural language text and understands the semantic relation between the text units, which plays a vital role in language understanding and natural language generation, is a challenge and difficult research hotspot in recent years((Li Yan-cui et al.,2013). Discourse relation is a fundamental work in the research of discourse analysis. Discourse relation means the logical semantic relation, between two text unit (section, clause, sentence, sentence group, paragraphs, etc.) in one discourse, such as coordinative relation, progressive relation, adversative relation (Sun Jing et al., 2014), etc. Defining a hierarchical semantic relationship type system to extend sentence semantic analysis results in that discourse level of semantic information become one of the important ways to solve the discourse semantic analysis, which is benefit to many NLP tasks such as automatic summarization, automatic question answering and machine translation (Zhang Mu-yu et al., 2013). The commas separates a sentence into two parts, each part is called an argument of the sentence. Discourse relation can be generally classified into explicit relation and implicit relation. Explicit relation recognitio</context>
<context position="8563" citStr="Jing et al., 2014" startWordPosition="1274" endWordPosition="1277">acted from the Chinese Treebank based on syntactic patterns, and use this method to disambiguate the Chinese comma. In this paper, we propose a method of sentence relation classification based on rich linguistic features around Chinese comma in sentences. We try to find out the difference among sentence relation types by rich linguistic features, which is found by potential semantic rules derived by statistical method, which is of significance especially for the implicit relation recognition. 3 Features Selection Currently, few research about sentence relation is based on comma. Sun jing (Sun Jing et al., 2014) classified the discourse relation into four categories: cause and effect( Q A ), coordination( A �iq ), transition(**), explanation(*i;�) with maximum entropy, on the basis of utilizing a set of context features, lexical features and dependency tree features extracted from the corpus of Chinese discourse built by themselves. Lin (Lin Zi-heng et al., 2009) implemented an implicit discourse relation classifier and showed initial results based on the recently released Penn Discourse Treebank. The features they used include the modeling of the context of relations, features extracted from constit</context>
</contexts>
<marker>Jing, Yan-cui, Guo-dong, 2014</marker>
<rawString>Sun Jing, Li Yan-cui, Zhou Guo-dong. 2014. Research of Chinese implicit discourse relation recognition. Journal of Beijing University (Natural Science Edition), 2014(01): 111-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gu Jing-jing</author>
</authors>
<title>Zhou Guo-dong. Chinese comma classification based on segmentation and part of speechtagging.</title>
<date>2014</date>
<journal>Computer Engineering and Applications.</journal>
<marker>Jing-jing, 2014</marker>
<rawString>Gu Jing-jing, Zhou Guo-dong. Chinese comma classification based on segmentation and part of speechtagging. 2014. Computer Engineering and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin Mei-xun</author>
<author>Mi-Young Kim</author>
<author>Donggil Kim</author>
<author>JongHyeok Lee</author>
</authors>
<title>Segmentation of Chinese longsentences using commas.</title>
<date>2004</date>
<pages>2004</pages>
<contexts>
<context position="3706" citStr="Mei-xun et al., 2004" startWordPosition="540" endWordPosition="543">relation recognition. Some additional information is gradually introduced in addition to lexical features (Zhang Mu-yu et al., 2013). eg. 1:跳水选手已全部抵达罗马,并开始赛前训 练。 &amp;quot;All divers have arrived in Rome, and start training before the game.&amp;quot; eg. 2:中国的稳定和发展有利于世界的和平与发 展,中国的繁荣与稳定是澳门繁荣与稳定的根本 保证。 &amp;quot;China&apos;s stability and development are conducive to world&apos;s peace and development, China&apos;s prosperity and stability are the fundamental guarantee of Macro&apos;s prosperity and stability.&amp;quot; Most researches about discourse relation recognition are mainly for English. Although there are some Chinese-oriented research (Jin Mei-xun et al., 2004; Xu Sheng-qin and Li Pei-feng, 2013; Yang yaqin and Xue Nianwen, 2012), they are mainly concentrated on the analysis and corpus annotation, rarely involving discourse relation recognition; and existing research mostly directly used the English discourse relation system, ignoring the linguistic characteristics of Chinese language itself. According to the classification of compound sentence theories (Xing Fu-yi, 2001; Lv Shuxiang and 11 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 11–17, Wuhan, China, 20-21 October 2014 Zhu De-xi, 1952; Shao Jing-m</context>
<context position="6679" citStr="Mei-xun et al., 2004" startWordPosition="985" endWordPosition="988"> widely used in Chinese, such as comma, period, question mark, etc. With more than 20 different usages, comma is one of the most common punctuations. Chinese comma can be used to separate coordinate composition or coordinate clause of the sentence, or to separate the words, phrases, clauses which indicate time, place, purpose, condition, or to express a pause between the clauses separated by conjunction (Gu Jing-jing and Zhou Guo-dong, 2014), etc. In recent years, with the progress of the research about punctuation, the study of comma classification gradually caught attention. Jin and Li (Jin Mei-xun et al., 2004) viewed comma as an important role in long Chinese sentence segmentation, they proposed a method for classifying commas in Chinese sentences by their context, then segmented a long sentence according to the classification results. Element discourse unit (EDU) recognition is a fundamental task of discourse analysis and Chinese punctuation is viewed as a elementary delimiter. Xu Sheng-qin and Li Pei-feng (Xu Sheng-qin and Li Pei-feng, 2013) considered Chinese comma to be the boundary of the discourse units and anchor discourse relations between units separated by comma. They classified comma’s r</context>
</contexts>
<marker>Mei-xun, Kim, Kim, Lee, 2004</marker>
<rawString>Jin Mei-xun, Mi-Young Kim, Donggil Kim, JongHyeok Lee. 2004. Segmentation of Chinese longsentences using commas. SIGHAN2004</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xu Sheng-qin</author>
<author>Li Pei-feng</author>
</authors>
<title>Recognizing Chinese elementary discourse unit on comma.</title>
<date>2013</date>
<booktitle>Asian Language Processing (IALP),2013 Internationa. IEEE,</booktitle>
<pages>3--6</pages>
<marker>Sheng-qin, Pei-feng, 2013</marker>
<rawString>Xu Sheng-qin, Li Pei-feng. 2013. Recognizing Chinese elementary discourse unit on comma. Asian Language Processing (IALP),2013 Internationa. IEEE, 2013: 3-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xue Nian-wen</author>
</authors>
<title>Chinese comma disambiguation for discourse analysis.</title>
<date>2012</date>
<booktitle>Proceedings of the 50th Annual Meeting of the Asso. Association for Computational Li,</booktitle>
<pages>786--794</pages>
<contexts>
<context position="7687" citStr="Nian-wen, 2012" startWordPosition="1144" endWordPosition="1145"> Li Pei-feng (Xu Sheng-qin and Li Pei-feng, 2013) considered Chinese comma to be the boundary of the discourse units and anchor discourse relations between units separated by comma. They classified comma’s role into seven major types and implemented automatic disambiguation of the Chinese comma type. Xue and Yang (Xue Nian-wen and Yang Ya-qin, 2011) held that the central problem of Chinese sentence segmentation was comma disambiguation, and in some context it identifies the boundary of a sentence just as a period, a question mark, or an exclamation mark does. Yang and Xue (Yang ya-qin and Xue Nian-wen, 2012) further pointed out that the Chinese comma signifies the boundary of discourse units and also anchors discourse relations between adjacent text spans, and they proposed a discourse structureoriented classification of the comma that can be automatically extracted from the Chinese Treebank based on syntactic patterns, and use this method to disambiguate the Chinese comma. In this paper, we propose a method of sentence relation classification based on rich linguistic features around Chinese comma in sentences. We try to find out the difference among sentence relation types by rich linguistic fea</context>
</contexts>
<marker>Nian-wen, 2012</marker>
<rawString>Yang Ya-qin , Xue Nian-wen . 2012. Chinese comma disambiguation for discourse analysis. Proceedings of the 50th Annual Meeting of the Asso. Association for Computational Li, 2012: 786-794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xing Fu-yi</author>
</authors>
<title>The study of Chinese complex sentence.</title>
<date>2001</date>
<tech>Beijing:Commercial Press,2001</tech>
<contexts>
<context position="4125" citStr="Fu-yi, 2001" startWordPosition="602" endWordPosition="603">e of Macro&apos;s prosperity and stability.&amp;quot; Most researches about discourse relation recognition are mainly for English. Although there are some Chinese-oriented research (Jin Mei-xun et al., 2004; Xu Sheng-qin and Li Pei-feng, 2013; Yang yaqin and Xue Nianwen, 2012), they are mainly concentrated on the analysis and corpus annotation, rarely involving discourse relation recognition; and existing research mostly directly used the English discourse relation system, ignoring the linguistic characteristics of Chinese language itself. According to the classification of compound sentence theories (Xing Fu-yi, 2001; Lv Shuxiang and 11 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 11–17, Wuhan, China, 20-21 October 2014 Zhu De-xi, 1952; Shao Jing-min, 2007), in this paper, we propose 9 categories of Chinese comma classification for sentence relation, including Coordination(A �iq), Interpretation(ffi ), Location(AA), Progressiveness(AA), Reliance(nfF&amp;quot;1&apos;), Subsequence( diff ), Time(K&apos;17), Purpose(Hn), Cause and Effect(QA), and classify Chinese comma into these 9 classes with maximum entropy method (ME), the corpus we used is annotated with a well-established re</context>
</contexts>
<marker>Fu-yi, 2001</marker>
<rawString>Xing Fu-yi. 2001. The study of Chinese complex sentence. Beijing:Commercial Press,2001</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lv Shu-xiang</author>
<author>Dexi Zhu</author>
</authors>
<title>Grammatical rhetoric speech. Liaoning:Liaoning Education Press,1952</title>
<date>1952</date>
<marker>Shu-xiang, Zhu, 1952</marker>
<rawString>Lv Shu-xiang, Dexi Zhu. 1952. Grammatical rhetoric speech. Liaoning:Liaoning Education Press,1952</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shao Jing-min</author>
</authors>
<title>The general theory of modern Chinese. Liaoning:Shanghai Education Press,2007</title>
<date>2007</date>
<contexts>
<context position="4315" citStr="Jing-min, 2007" startWordPosition="630" endWordPosition="631">, 2004; Xu Sheng-qin and Li Pei-feng, 2013; Yang yaqin and Xue Nianwen, 2012), they are mainly concentrated on the analysis and corpus annotation, rarely involving discourse relation recognition; and existing research mostly directly used the English discourse relation system, ignoring the linguistic characteristics of Chinese language itself. According to the classification of compound sentence theories (Xing Fu-yi, 2001; Lv Shuxiang and 11 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 11–17, Wuhan, China, 20-21 October 2014 Zhu De-xi, 1952; Shao Jing-min, 2007), in this paper, we propose 9 categories of Chinese comma classification for sentence relation, including Coordination(A �iq), Interpretation(ffi ), Location(AA), Progressiveness(AA), Reliance(nfF&amp;quot;1&apos;), Subsequence( diff ), Time(K&apos;17), Purpose(Hn), Cause and Effect(QA), and classify Chinese comma into these 9 classes with maximum entropy method (ME), the corpus we used is annotated with a well-established representation scheme for Chinese comma, and the features we used are extracted from the corpus that is based on the sentences’ words information on both sides of the comma. We carried out the</context>
</contexts>
<marker>Jing-min, 2007</marker>
<rawString>Shao Jing-min. 2007. The general theory of modern Chinese. Liaoning:Shanghai Education Press,2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Zi-heng</author>
<author>Kan Min-yen</author>
</authors>
<title>Hwee Tou Ng .</title>
<date>2009</date>
<booktitle>Proceedings of the 2009 Conference on Empirical Me Association for Computational Li,</booktitle>
<pages>343--351</pages>
<marker>Zi-heng, Min-yen, 2009</marker>
<rawString>Lin Zi-heng, Kan Min-yen, Hwee Tou Ng . 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. Proceedings of the 2009 Conference on Empirical Me Association for Computational Li, 2009: 343-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Hang</author>
</authors>
<title>Statistical learning method.</title>
<date>2012</date>
<pages>80--87</pages>
<publisher>Tsinghua University Press,</publisher>
<location>Beijing:</location>
<contexts>
<context position="12282" citStr="Hang, 2012" startWordPosition="1903" endWordPosition="1904">word of argument 1 constitute a conjunction, else f12=0 Features of case 1 and case 2 mentioned above are as follows. 1:f1=Oh7KA_T-, f1p=n, f2=A, f3=1, f4=A, f4p=c, f5l=0, f5r=1, f6=_W j, f6p=n, f7=n+c, f8=n+n, f9=0+n, f10=0+n, f11=1+c, f12=0 2:f1=Oh7KA_T-, f1p=n, f2=null, f3=1, f4=}f44n, f4p=ad, f5l=0, f5r=0, f6= _W j , f6p=n, f7=n+v, f8=n+n, f9=0+n, f10=0+n, f11=1+v, f12=0 4 Maximum Entropy for Comma Classification Maximum entropy model (ME) method is to select the model with the maximum entropy that meets some constraint conditions. Maximum entropy model can be applied to classification(Li Hang, 2012, Sang Haiyan et al., 2013). In our implementation, ME model uses the features listed in table1. Let C be the set of types of the 9 sentence relation classes we have defined, and S be the sentence set, we can calculate p(cj |si) through maximum entropy model, which means the probability si belongs to cj , where si ∈S and cj ∈C. For comma classification problem, cj with arg max p(cj |si) will be the class that the sentence si belongs to. The comma classification method is similar to text classification method, their basic idea is to use learning set composed of training samples to train a class</context>
</contexts>
<marker>Hang, 2012</marker>
<rawString>Li Hang. 2012. Statistical learning method. Beijing: Tsinghua University Press, 2012: 80-87</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sang Hai-yan</author>
<author>Gu Lia-Altenbek</author>
<author>Niu Ning-ning</author>
</authors>
<title>Kazakh part-of-speech tagging method based on maximum entropy. Computer Engineering and Applications,</title>
<date>2013</date>
<volume>49</volume>
<issue>11</issue>
<pages>126--129</pages>
<marker>Hai-yan, Lia-Altenbek, Ning-ning, 2013</marker>
<rawString>Sang Hai-yan, Gu Lia-Altenbek, Niu Ning-ning. 2013. Kazakh part-of-speech tagging method based on maximum entropy. Computer Engineering and Applications, 2013, 49(11): 126-129,16.</rawString>
</citation>
<citation valid="false">
<title>Zhang Mu-yu,Song Yuan,Qin Bing,Liu Ting 2013. Chinese Discourse Relation Recognition.</title>
<journal>Journal of Chinese information,</journal>
<volume>27</volume>
<issue>6</issue>
<pages>51--57</pages>
<marker></marker>
<rawString>Zhang Mu-yu,Song Yuan,Qin Bing,Liu Ting 2013. Chinese Discourse Relation Recognition. Journal of Chinese information, 2013,27(6): 51-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xue Nian-wen</author>
<author>Yang Ya-qin</author>
</authors>
<title>Chinese sentence segmentation as comma classification.</title>
<date>2011</date>
<booktitle>Proceedings of the 49th Annual Meeting of the Asso. Association for Computational Li,</booktitle>
<pages>631--635</pages>
<marker>Nian-wen, Ya-qin, 2011</marker>
<rawString>Xue Nian-wen, Yang Ya-qin . 2011. Chinese sentence segmentation as comma classification. Proceedings of the 49th Annual Meeting of the Asso. Association for Computational Li, 2011: 631-635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Lue-xing</author>
<author>Lv Xue-qiang</author>
<author>Liu Kun</author>
<author>Lin Jin</author>
</authors>
<title>Automatic Identification of Chinese Coordination Relations.</title>
<date>2013</date>
<journal>Journal</journal>
<institution>of Beijing University (Natural Science Edition),2013,49(1):20-24.</institution>
<contexts>
<context position="9267" citStr="Lue-xing et al., 2013" startWordPosition="1379" endWordPosition="1382">coordination( A �iq ), transition(**), explanation(*i;�) with maximum entropy, on the basis of utilizing a set of context features, lexical features and dependency tree features extracted from the corpus of Chinese discourse built by themselves. Lin (Lin Zi-heng et al., 2009) implemented an implicit discourse relation classifier and showed initial results based on the recently released Penn Discourse Treebank. The features they used include the modeling of the context of relations, features extracted from constituent parse trees and dependency parse trees, and word pair features. Zheng (Zheng Lue-xing et al., 2013) presented an approach of Chinese coordination relations recognition based on CRFs. They extracted role information according to their functions in the generation of Chinese coordination relations. We analyze the feature of different types of sentences, refer to the features proposed in the paper of Li Yancui (Li Yan-cui et al., 2013) and Xue (Xue Nian-wen and Yang Ya-qin, 2011), and propose to learn discourse relation rules through linguistic features of the sentences. This method extract linguistic features from both sides of comma in the sentence. Before extracting the features, the followi</context>
</contexts>
<marker>Lue-xing, Xue-qiang, Kun, Jin, 2013</marker>
<rawString>Zheng Lue-xing, Lv Xue-qiang, Liu Kun, Lin Jin. 2013. Automatic Identification of Chinese Coordination Relations. Journal of Beijing University (Natural Science Edition),2013,49(1):20-24.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>