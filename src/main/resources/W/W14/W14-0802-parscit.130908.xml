<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000208">
<title confidence="0.999584">
A Supervised Model for Extraction of Multiword Expressions Based on
Statistical Context Features
</title>
<author confidence="0.980852">
Meghdad Farahmand
</author>
<affiliation confidence="0.992608">
The Computer Science Center
University of Geneva
</affiliation>
<address confidence="0.630016">
Switzerland
</address>
<email confidence="0.995312">
meghdad.farahmand@unige.ch
</email>
<sectionHeader confidence="0.993818" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999972545454546">
We present a method for extracting Multi-
word Expressions (MWEs) based on the
immediate context they occur in, using a
supervised model. We show some of these
contextual features can be very discrim-
inant and combining them with MWE-
specific features results in a relatively ac-
curate extraction. We define context as
a sequential structure and not a bag of
words, consequently, it becomes much
more informative about MWEs.
</bodyText>
<sectionHeader confidence="0.998761" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999435481481482">
Multiword Expressions (MWEs) are an important
research topic in the area of Natural Language
Processing (NLP). Efficient and effective extrac-
tion and interpretation of MWEs is crucial in most
NLP tasks. They exist in many types of text and
cause major problems in all kinds of natural lan-
guage processing applications (Sag et al., 2002).
However, identifying and lexicalizing these im-
portant but hard to identify structures need to be
improved in most major computational lexicons
(Calzolari et al., 2002). Jackendoff (1997) esti-
mates that the number of MWEs is equal to the
number of single words in a speaker’s lexicon,
while Sag et al. (2002) believe that the number
is even greater than this. Moreover, as a lan-
guage evolves, the number of MWEs consistently
increases. MWEs are a powerful way of extending
languages’ lexicons. Their role in language evolu-
tion is so important that according to Baldwin and
Kim (2010), “It is highly doubtful that any lan-
guage would evolve without MWEs of some de-
scription”.
The efficient identification and extraction of
MWEs can positively influence many other NLP
tasks, e.g., part of speech tagging, parsing,
syntactic disambiguation, semantic tagging, ma-
chine translation, and natural language generation.
</bodyText>
<page confidence="0.991515">
10
</page>
<note confidence="0.800894333333333">
Ronaldo Martins
UNDL Foundation
Geneva - Switzerland
</note>
<email confidence="0.937086">
r.martins@undl.ch
</email>
<bodyText confidence="0.999805954545455">
MWEs also have important applications outside
NLP. For instance in document indexing, informa-
tion retrieval (Acosta et al., 2011), and cross lin-
gual information retrieval (Hull and Grefenstette,
1996).
In this paper we present a method of extracting
MWEs which is relatively different from most of
the state of the art approaches. We characterize
MWEs based on the statistical properties of the
immediate context they occur in. For each pos-
sible MWE candidate we define a set of contex-
tual features (e.g., prefixes, suffixes, etc.). The
contextual feature vector is then enriched with a
few MWE-specific features such as the frequency
of its components, type frequency of the candi-
date MWE, and the association between these two
(which is learned by a supervised model). Subse-
quently the MWEhood of the extracted candidates
is predicted based on this feature representation,
using a Support Vector Machine (SVM). The sys-
tem reaches a relatively high accuracy of predict-
ing MWEs on unseen data.
</bodyText>
<subsectionHeader confidence="0.971701">
1.1 Previous Work
</subsectionHeader>
<bodyText confidence="0.981886096153846">
Attempts to extract MWEs are of different types.
The most common techniques are primarily fo-
cused on collocations. Some of these techniques
are rule-based and symbolic e.g., (Seretan, 2011;
Goldman et al., 2001; Nerima et al., 2003; Bald-
win, 2005; Piao et al., 2003; McCarthy et al.,
2003; Jacquemin et al., 1997). Some rely on lexi-
cons (Michiels and Dufour, 1998; Li et al., 2003)
and (Pearce, 2001) that uses WordNet to evalu-
ate the candidate MWE based on anti-collocations.
Other approaches are hybrid in the sense that
they benefit from both statistical and linguistic
information. For instance (Seretan and Wehrli,
2006; Baldwin and Villavicencio, 2002; Piao and
McEnery, 2001; Dias, 2003).
There are also fully statistical approaches. For
instance (Pecina, 2010; Evert, 2005; Lapata and
Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16,
Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics
Lascarides, 2003; Smadja et al., 1996), or the early
work Xtract (Smadja, 1993).
Other approaches consider all types of MWEs
(Zhang et al., 2006). Some of these approaches
build upon generic properties of MWEs, for in-
stance semantic non-compositionality (Van de
Cruys and Moir´on, 2007).
A different approach is presented in (Widdows
and Dorow, 2005). The authors present a graph-
based model to capture and assess fixed expres-
sions in form of Noun and/or Noun.
There are also bilingual models which are
mostly based on the assumption that a translation
of the MWE in a source language exists in a tar-
get language. For instance (de Medeiros Caseli
et al., 2010; Ren et al., 2009), and (Moir´on and
Tiedemann, 2006) which measures MWEs candi-
dates’ idiomaticity based on translational entropy.
Another example is (Duan et al., 2009) which is
a hybrid model that aims at extracting bilingual
(English-Chinese) MWEs . It combines Multi-
ple Sequence Alignment Model with some filter-
ing based on hard rules to obtain an improved ex-
traction.
A more generic model is presented in (Ramisch,
2012) where the author develops a flexible plat-
form that can accept different types of criteria
(from statistical to deep linguistic) in order to ex-
tract and filter MWEs. However, in this work,
as the author claims, the quality of the extracted
MWEs is highly dependent on the level of deep
linguistic analysis, and thereby, the role of statisti-
cal criterion is less significant.
</bodyText>
<subsectionHeader confidence="0.991843">
1.2 Motivation
</subsectionHeader>
<bodyText confidence="0.990241566666667">
We propose an original method to extract multi-
word expressions based on statistical contextual
features, e.g., a set of immediate prefixes, suffixes,
circumfixes, infixes to circumfixes, etc., (see Sec.
2). These features are used to form a feature repre-
sentation, which together with a set of annotations
train a supervised model in order to predict and
extract MWEs from a large corpus.
We observed some discriminant behavior in
contextual features (such as prefixes, suffixes, cir-
cumfixes, etc.) of a set of manually selected
MWEs. A supervised model is then applied to
learn MWEhood based on these features.
In general, modeling lexical and syntactic (and
not semantic) characteristics of continuous MWEs
is the focus of this paper. In order for the MWE de-
composability condition to hold, we consider bi-
grams and above (up to size 4). Idiomaticity at
some level is a necessary prerequisite of MWEs.
Hereby, we consider idiomaticity at lexical, syn-
tactic and statistical levels, and leave the semantic
idiomaticity to the future work.
Relatively similar models have been previously
applied to problems similar to MWEs, for instance
named entity recognition (Nadeau and Sekine,
2007; Ratinov and Roth, 2009).
The focus on contextual features allows some
degree of generalization, i.e., we can apply this
model to a family of languages.1 However, this
work focuses only on English MWEs.
</bodyText>
<sectionHeader confidence="0.955679" genericHeader="method">
2 Proposed System
</sectionHeader>
<bodyText confidence="0.975089975609756">
We prepared a corpus that comprises 100K
Wikipedia documents for each of the mentioned
languages.1 After cleaning and segmenting the
corpus, we extracted all possible n-grams (up to
size 7) and their token and type frequencies. Then
two basic statistical filters were applied in order to
systematically decrease the size of our immense
n-gram set: (i) Frequency filter, where we filter
an n-gram if its frequency is less than the ratio
between tokens and types, where for a given size
of n-grams, the total number of n-grams and the
number of distinct n-grams of that size, are con-
sidered tokens and types, respectively. (ii) Redun-
dancy filter where we consider an n-gram to be
redundant if it is subsumed by any other n&apos;-gram,
where n&apos; &gt; n. This gives us a pruned set of n-
grams which we refer to as the statistically signifi-
cant set. Table 1 presents a count-wise description
of the filtering results on the English corpus.
raw frq flt rdund flt
1-grams 1782993 64204 64204
2-grams 14573453 1117784 1085787
3-grams 38749315 3797456 3394414
4-grams 53023415 5409794 3850944
5-grams 53191941 2812650 2324912
6-grams 47249534 1384821 568645
7-grams 39991254 757606 757606
1We are adapting our model so that it can handle clusters
of similar languages. So far we have processed the following
9 widely-spoken languages: English, German, Dutch, Span-
ish, French, Italian, Portuguese, Polish, and Russian. How-
ever, to study the efficiency of the presented model applied to
languages other than English, remains a future work.
Table 1: Number of extracted n-grams for EN.
First column indicates raw data, second and third
columns indicate the number of n-grams after fre-
quency and redundancy filters respectively.
For the set of significant n-grams a set of statis-
tical features are extracted which will be described
shortly. Fig. 1 illustrates the workflow of the sys-
tem.
</bodyText>
<figureCaption confidence="0.687341">
Figure 1: Schematic of pre-processing, n-gram ex-
traction and filtering. Blended and plain nodes
represent resources, and operations respectively.
</figureCaption>
<bodyText confidence="0.794200888888889">
While studying the English corpus and different
MWEs therein, it was observed that often, MWEs
(as well as some other types of syntactic units)
are followed, preceded or surrounded by a lim-
ited number of high frequency significant n-gram
types. Moreover, our manual evaluation and con-
stituency tests reveal that generally when a fre-
quent significant prefix co-occurs with a frequent
significant suffix, they form a circumfix whose sig-
nificant infixes are (i) many, (ii) can mostly be con-
sidered syntactic unit, specifically when it comes
to bi/trigrams. Table 2 illustrates a randomly se-
lected sample of infixes of such circumfix (the..of).
Remarkably, the majority of them are idiomatic at
least at one level.
franz liszt academy official list
most important albums closest relatives
ministry of commerce protestant church
executive vice president peak period
famous italian architect manhattan school
blessed virgin mary rise and fall
world cup winner former head
Table 2: Examples of bi/trigrams surrounded by
the circumfix the..of
The immediate proximity of these particular con-
text features to MWEs keeps emerging while eval-
uating similar circumfixes. We believe it sug-
gests the presence of a discriminant attribute that
we model with features 5-8 (see Table 3) and
learn using a supervised model. Nevertheless,
the fact that MWEs share these features with
other types of syntactic units encourages introduc-
ing more MWE-specific features (namely, MWE’s
frequency, the frequency of its components, and
their associations), then enforcing the learning
model to recognize a MWE based on the combi-
nation of these two types of features. Note that
the association between the type frequency of a
MWE, and the frequency of its components is im-
plicitly learned by the supervised model through-
out the learning phase. A candidate MWE can be
represented as:
y = (x1, ..., xm, xm+1, ..., xn) ∈ N0 (1)
Where x1, ..., xm are contextual, and
xm+1, ..., xn are specific features (m = 8,
and n = 11). These features are described in
Table 3.
contextual features
x1 # set of all possible prefixes of y
x2 # set of distinct prefixes of y
x3 # set of all possible suffixes of y
x4 # set of distinct suffixes of y
x5 # set of all possible circumfixes of y
x6 # set of distinct circumfixes of y (C)
x7 # set of all possible infixes to members of C
x8 # set of distinct infixes to members of C
specific features
xg the size of y
x10 number of occurrences of y in the corpus
x11 list of frequencies of the components of y
This set is used in
annotation and generation
of test/training data
</bodyText>
<figure confidence="0.847285875">
(MWE candidate
, {|f1|,|f2|,...)
Language
Model
Corpus
cleaning;
extraction
feature
extraction
removing tags,
cleaning,
segmentation
n-grams
indexing
Index
freq &amp;
redundancy
Filters
statistically
significant
n-grams
100K
Wikipedia
docs
</figure>
<tableCaption confidence="0.993934">
Table 3: Description of the extracted features
</tableCaption>
<page confidence="0.996885">
12
</page>
<bodyText confidence="0.999571615384615">
A prefix of y is the longest n-gram immediately
before y, if any or the boundary marker #, other-
wise. A suffix of y is the longest n-gram imme-
diately after y, if any or the boundary marker #,
otherwise. A circumfix (ci E C) of y is the pair
(p, s) where p and s are respectively the prefix and
the suffix of a given occurrence of y. An Infix of
ci is an n-gram that occurs between p and s.
Components to generate candidate MWEs, fil-
ter them and extract their relevant features were
very memory and CPU intensive. To address the
performance issues we implemented parallel pro-
grams and ran them on a high performance cluster.
</bodyText>
<sectionHeader confidence="0.999141" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.999588714285714">
A set of ≈ 10K negative and positive English
MWE examples were annotated. This set does
not particularly belong in any specific genre, as
the examples were chosen randomly from across
a general-purpose corpus. This set comprises an
equal number of positive and negative annotations.
Part of it was annotated manually at UNDL foun-
dation,2 and part of it was acquired from the man-
ually examined MWE lexicon presented in (Ner-
ima et al., 2003). The set of positive and negative
annotated n-grams is detailed in Table 4. The bias
toward bigrams is due to the fact that the majority
of manually verified MWEs that could be obtained
are bigrams.
</bodyText>
<table confidence="0.99751475">
size + examples − examples
2-grams 4,632 5,173
3-grams 500 22
4-grams 68 15
</table>
<tableCaption confidence="0.999605">
Table 4: Annotations’ statistics
</tableCaption>
<bodyText confidence="0.999754333333333">
This set was divided into 1/3 test and 2/3 train-
ing data, which were selected randomly but were
evenly distributed with respect to positive and neg-
ative examples. The test set remains completely
unseen to the model during the learning phase. We
then train a linear SVM:
</bodyText>
<equation confidence="0.997953">
h(y) = wT y + b (2)
</equation>
<bodyText confidence="0.998465333333333">
Where h(y) is a discriminant hyperplane, w is
the weight vector, and y is a set of MWE exam-
ples, where each example is defined as: yj =
x1, ..., x11. Table 5 shows the results of the
model’s multiple runs on five different pairs of
training and test sets.
</bodyText>
<footnote confidence="0.9994865">
2The Universal Networking Digital Language Founda-
tion: http://www.undlfoundation.org/
</footnote>
<table confidence="0.999825666666667">
precision (%) recall (%) accuracy(%)
run 1 84.8 96.8 89.7
run 2 82.5 97.4 88.4
run 3 83.6 97.8 89.3
run 4 84.1 97.5 89.5
run 5 83.4 97.1 88.9
</table>
<tableCaption confidence="0.730835428571429">
Table 5: Performance of the SVM which learns the
MWEhood based on contextual and specific fea-
tures (x1 − x11)
Table 6 illustrates the trained model’s predic-
tions on a set of randomly selected test examples.
The overall performance of the model is shown in
the form of a precision-recall curve in Fig. 2.
</tableCaption>
<figureCaption confidence="0.9888896">
n-grams classified as MWE
spend time genetically modified
hijack a plane fish tank
top dog toy car
factory outlet motorcycle racing
season nine vintage car
video conference chestnut tree
kill your entry fee
safety precaution quantum leap
version shown make an appeal
flood damage drug dealer
bargaining chip lung transplant
grant her tone like
postgraduate student make a phone call
raise the price ozone layer
n-grams classified as non-MWE
score is and dartmouth
the tabular capped a
on sale clarified his
liver was the cancan
the regulating an ending
the rabi warns the
this manuscript a few
an exponential an institution
the petal blades are
or ended difficulties he
and workmen the guidance
the eyelids the examined
the vices the episodes
they work monument is
</figureCaption>
<tableCaption confidence="0.902625">
Table 6: Sample SVM’s output on unseen data.
</tableCaption>
<bodyText confidence="0.939155333333333">
A t-test ranks the significance of the defined fea-
tures in classifying n-grams into MWE, and non-
MWE classes, as illustrated in Fig. 3. The most
</bodyText>
<page confidence="0.995537">
13
</page>
<figure confidence="0.998870777777778">
Precision−recall curve
Precision 1
0.9
0.8
0.7
0.6
0.50
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
</figure>
<figureCaption confidence="0.996096">
Figure 2: Precision-recall curve
</figureCaption>
<bodyText confidence="0.974326941176471">
f(t)
important features are the size of examples (x9),
and the frequencies of their components (x11).
The significance of x9 is due to the fact that in
the training set majority of MWEs are bigrams.
Therefore, by the SVM, being a bigram is consid-
ered as a substantial feature of MWEs. Neverthe-
less since the number of negative and positive ex-
amples which are bigrams are approximately the
same, the bias toward x9 in discriminating MWEs
from non-MWE balances out. However its as-
sociation with other features which is implicitly
learned still has an impact on discriminating these
two classes. x7 and x8 are the next two important
features, as we expected. These two are the fea-
tures whose magnitude suggests the presence or
lack of contexts such as (the..of).
</bodyText>
<figure confidence="0.9803991">
3 x 106
−1
1
2
1
0
−1
−2
−3
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
</figure>
<figureCaption confidence="0.997627">
Figure 4: Andrews curve for the training exam-
ples. Bold line in the middle, and bold dotted
line represent the median of MWE and non-MWE
classes respectively.
</figureCaption>
<figure confidence="0.979380444444444">
4 Conclusions and Future Work
Ranks
0
20
15
10
5
x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11(avg rnk)
Features
</figure>
<figureCaption confidence="0.9930705">
Figure 3: Ranks of the features that represent their
discriminant impact.
</figureCaption>
<bodyText confidence="0.96943975">
The class separability of MWE (1), and non-
MWE (−1) examples can be seen in Fig. 4, where
the bidimentional projection of the examples of
two classes is visualized. A star plot of a sample
of 50 manually annotated examples is shown in
Fig. 5. In many cases, but not always, non-MWEs
can be discriminated from MWEs, in this eleven
dimensional visualization. Same pattern was ob-
served in the visualization of 500 examples (which
would be hard to demonstrate in the present pa-
per’s scale).
We presented a method to extract MWEs based
on the immediate context they occur in, using
a supervised model. Several contextual features
were extracted from a large corpus. The size of
the corpus had a profound effect on the effective-
ness of these features. The presented MWE ex-
traction model reaches a relatively high accuracy
on an unseen test set. In future work, the effi-
ciency of this approach on languages other than
English will be studied. Furthermore, other fea-
tures - specifically deep linguistic ones e.g., de-
gree of constituency as described in (Ponvert et
al., 2011) or POS tags, will be added to the fea-
ture representation of MWE candidates. Finally
context-based probabilistic scores which are lin-
guistically motivated can be investigated and com-
pared with the supervised model. Another inter-
esting work would be to introduce kernels so that
we can go from statistics of contextual features to
training the supervised model directly on the tex-
tual context.
</bodyText>
<page confidence="0.968324">
14
</page>
<equation confidence="0.984803857142857">
−1 1 −1 1 1 −1 −1 1
1 −1 1 −1 −1 −1 1 1
1 1 −1 −1 1 −1 1 −1
−1 −1 1 −1 −1 −1 −1 −1
−1 1 1 −1 1 1 1 1
−1 −1 −1 −1 −1 1 −1 −1
−1 1
</equation>
<figureCaption confidence="0.856923">
Figure 5: Star plot of 50 MWE (1), and non-MWE
(−1) examples
</figureCaption>
<sectionHeader confidence="0.820103" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.965917024390244">
Otavio Acosta, Aline Villavicencio, and Viviane Mor-
eira. 2011. Identification and treatment of multi-
word expressions applied to information retrieval.
Kordoni et al, pages 101–109.
Timothy Baldwin and Su Nam Kim. 2010. Multiword
expressions. Handbook of Natural Language Pro-
cessing, second edition. Morgan and Claypool.
Timothy Baldwin and Aline Villavicencio. 2002. Ex-
tracting the unextractable: A case study on verb-
particles. In proceedings of the 6th conference on
Natural language learning-Volume 20, pages 1–7.
Association for Computational Linguistics.
Timothy Baldwin. 2005. Deep lexical acquisition of
verb–particle constructions. Computer Speech &amp;
Language, 19(4):398–414.
Nicoletta Calzolari, Charles J Fillmore, Ralph Gr-
ishman, Nancy Ide, Alessandro Lenci, Catherine
MacLeod, and Antonio Zampolli. 2002. Towards
best practice for multiword expressions in computa-
tional lexicons. In LREC.
Helena de Medeiros Caseli, Carlos Ramisch, Maria das
Grac¸as Volpe Nunes, and Aline Villavicencio. 2010.
Alignment-based extraction of multiword expres-
sions. Language resources and evaluation, 44(1-
2):59–77.
Ga¨el Dias. 2003. Multiword unit hybrid extrac-
tion. In Proceedings of the ACL 2003 workshop
on Multiword expressions: analysis, acquisition and
treatment-Volume 18, pages 41–48. Association for
Computational Linguistics.
Jianyong Duan, Mei Zhang, Lijing Tong, and Feng
Guo. 2009. A hybrid approach to improve bilin-
gual multiword expression extraction. In Advances
in Knowledge Discovery and Data Mining, pages
541–547. Springer.
David A Hull and Gregory Grefenstette. 1996. Query-
ing across languages: a dictionary-based approach
to multilingual information retrieval. In Proceed-
ings of the 19th annual international ACM SIGIR
conference on Research and development in infor-
mation retrieval, pages 49–57. ACM.
Ray Jackendoff. 1997. The architecture of the lan-
guage faculty. Number 28. MIT Press.
Christian Jacquemin, Judith L Klavans, and Evelyne
Tzoukermann. 1997. Expansion of multi-word
terms for indexing and retrieval using morphology
and syntax. In Proceedings of the eighth conference
on European chapter of the Association for Com-
putational Linguistics, pages 24–31. Association for
Computational Linguistics.
Mirella Lapata and Alex Lascarides. 2003. Detect-
ing novel compounds: The role of distributional ev-
idence. In Proceedings of the tenth conference on
European chapter of the Association for Computa-
tional Linguistics-Volume 1, pages 235–242. Asso-
ciation for Computational Linguistics.
Wei Li, Xiuhong Zhang, Cheng Niu, Yuankai Jiang,
and Rohini Srihari. 2003. An expert lexicon ap-
proach to identifying english phrasal verbs. In Pro-
ceedings of the 41st Annual Meeting on Associa-
tion for Computational Linguistics-Volume 1, pages
513–520. Association for Computational Linguis-
tics.
Diana McCarthy, Bill Keller, and John Carroll.
2003. Detecting a continuum of compositionality
in phrasal verbs. In Proceedings of the ACL 2003
workshop on Multiword expressions: analysis, ac-
quisition and treatment-Volume 18, pages 73–80.
Association for Computational Linguistics.
Archibald Michiels and Nicolas Dufour. 1998. Defi,
a tool for automatic multi-word unit recognition,
meaning assignment and translation selection. In
Proceedings of the first international conference on
language resources &amp; evaluation, pages 1179–1186.
Begona Villada Moir´on and J¨org Tiedemann. 2006.
Identifying idiomatic expressions using automatic
word-alignment. In Proceedings of the EACL 2006
Workshop on Multi-wordexpressions in a multilin-
gual context, pages 33–40.
David Nadeau and Satoshi Sekine. 2007. A sur-
vey of named entity recognition and classification.
Lingvisticae Investigationes, 30(1):3–26.
</reference>
<bodyText confidence="0.975522428571429">
Stefan Evert. 2005. The statistics of word cooccur-
rences. Ph.D. thesis, Dissertation, Stuttgart Univer-
sity.
Jean-Philippe Goldman, Luka Nerima, and Eric
Wehrli. 2001. Collocation extraction using a syn-
tactic parser. In Proceedings of the ACL Workshop
on Collocations, pages 61–66.
</bodyText>
<page confidence="0.996542">
15
</page>
<reference confidence="0.998875894117647">
Luka Nerima, Violeta Seretan, and Eric Wehrli. 2003.
Creating a multilingual collocation dictionary from
large text corpora. In Proceedings of the tenth con-
ference on European chapter of the Association for
Computational Linguistics-Volume 2, pages 131–
134. Association for Computational Linguistics.
Darren Pearce. 2001. Synonymy in collocation ex-
traction. In Proceedings of the Workshop on Word-
Net and Other Lexical Resources, Second meeting of
the North American Chapter of the Association for
Computational Linguistics, pages 41–46. Citeseer.
Pavel Pecina. 2010. Lexical association measures
and collocation extraction. Language resources and
evaluation, 44(1-2):137–158.
Scott Songlin Piao and Tony McEnery. 2001. Multi-
word unit alignment in english-chinese parallel cor-
pora. In the Proceedings of the Corpus Linguistics
2001, pages 466–475.
Scott SL Piao, Paul Rayson, Dawn Archer, Andrew
Wilson, and Tony McEnery. 2003. Extracting mul-
tiword expressions with a semantic tagger. In Pro-
ceedings of the ACL 2003 workshop on Multiword
expressions: analysis, acquisition and treatment-
Volume 18, pages 49–56. Association for Computa-
tional Linguistics.
Elias Ponvert, Jason Baldridge, and Katrin Erk. 2011.
Simple unsupervised grammar induction from raw
text with cascaded finite state models. In ACL, pages
1077–1086.
Carlos Ramisch. 2012. A generic framework for mul-
tiword expressions treatment: from acquisition to
applications. In Proceedings of ACL 2012 Student
Research Workshop, pages 61–66. Association for
Computational Linguistics.
Lev Ratinov and Dan Roth. 2009. Design challenges
and misconceptions in named entity recognition. In
Proceedings of the Thirteenth Conference on Com-
putational Natural Language Learning, pages 147–
155. Association for Computational Linguistics.
Zhixiang Ren, Yajuan L¨u, Jie Cao, Qun Liu, and Yun
Huang. 2009. Improving statistical machine trans-
lation using domain bilingual multiword expres-
sions. In Proceedings of the Workshop on Multiword
Expressions: Identification, Interpretation, Disam-
biguation and Applications, pages 47–54. Associa-
tion for Computational Linguistics.
Ivan A Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Compu-
tational Linguistics and Intelligent Text Processing,
pages 1–15. Springer.
Violeta Seretan and Eric Wehrli. 2006. Accurate col-
location extraction using a multilingual parser. In
Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 953–960. Association for Computa-
tional Linguistics.
Violeta Seretan. 2011. Syntax-based collocation ex-
traction, volume 44. Springer.
Frank Smadja, Kathleen R McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: A statistical approach. Compu-
tational linguistics, 22(1):1–38.
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Computational linguistics, 19(1):143–
177.
Tim Van de Cruys and Begona Villada Moir´on. 2007.
Semantics-based multiword expression extraction.
In Proceedings of the Workshop on a Broader Per-
spective on Multiword Expressions, pages 25–32.
Association for Computational Linguistics.
Dominic Widdows and Beate Dorow. 2005. Automatic
extraction of idioms using graph analysis and asym-
metric lexicosyntactic patterns. In Proceedings of
the ACL-SIGLEX Workshop on Deep Lexical Acqui-
sition, pages 48–56. Association for Computational
Linguistics.
Yi Zhang, Valia Kordoni, Aline Villavicencio, and
Marco Idiart. 2006. Automated multiword ex-
pression prediction for grammar engineering. In
Proceedings of the Workshop on Multiword Expres-
sions: Identifying and Exploiting Underlying Prop-
erties, pages 36–44. Association for Computational
Linguistics.
</reference>
<page confidence="0.998649">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.679998">
<title confidence="0.999308">A Supervised Model for Extraction of Multiword Expressions Based Statistical Context Features</title>
<author confidence="0.89484">Meghdad</author>
<affiliation confidence="0.9978085">The Computer Science University of</affiliation>
<email confidence="0.768971">meghdad.farahmand@unige.ch</email>
<abstract confidence="0.999165583333333">We present a method for extracting Multiword Expressions (MWEs) based on the immediate context they occur in, using a supervised model. We show some of these contextual features can be very discriminant and combining them with MWEspecific features results in a relatively accurate extraction. We define context as a sequential structure and not a bag of words, consequently, it becomes much more informative about MWEs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Otavio Acosta</author>
<author>Aline Villavicencio</author>
<author>Viviane Moreira</author>
</authors>
<title>Identification and treatment of multiword expressions applied to information retrieval. Kordoni et al,</title>
<date>2011</date>
<pages>101--109</pages>
<contexts>
<context position="2097" citStr="Acosta et al., 2011" startWordPosition="319" endWordPosition="322"> Their role in language evolution is so important that according to Baldwin and Kim (2010), “It is highly doubtful that any language would evolve without MWEs of some description”. The efficient identification and extraction of MWEs can positively influence many other NLP tasks, e.g., part of speech tagging, parsing, syntactic disambiguation, semantic tagging, machine translation, and natural language generation. 10 Ronaldo Martins UNDL Foundation Geneva - Switzerland r.martins@undl.ch MWEs also have important applications outside NLP. For instance in document indexing, information retrieval (Acosta et al., 2011), and cross lingual information retrieval (Hull and Grefenstette, 1996). In this paper we present a method of extracting MWEs which is relatively different from most of the state of the art approaches. We characterize MWEs based on the statistical properties of the immediate context they occur in. For each possible MWE candidate we define a set of contextual features (e.g., prefixes, suffixes, etc.). The contextual feature vector is then enriched with a few MWE-specific features such as the frequency of its components, type frequency of the candidate MWE, and the association between these two </context>
</contexts>
<marker>Acosta, Villavicencio, Moreira, 2011</marker>
<rawString>Otavio Acosta, Aline Villavicencio, and Viviane Moreira. 2011. Identification and treatment of multiword expressions applied to information retrieval. Kordoni et al, pages 101–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Su Nam Kim</author>
</authors>
<title>Multiword expressions. Handbook of Natural Language Processing, second edition.</title>
<date>2010</date>
<publisher>Morgan</publisher>
<contexts>
<context position="1567" citStr="Baldwin and Kim (2010)" startWordPosition="244" endWordPosition="247">essing applications (Sag et al., 2002). However, identifying and lexicalizing these important but hard to identify structures need to be improved in most major computational lexicons (Calzolari et al., 2002). Jackendoff (1997) estimates that the number of MWEs is equal to the number of single words in a speaker’s lexicon, while Sag et al. (2002) believe that the number is even greater than this. Moreover, as a language evolves, the number of MWEs consistently increases. MWEs are a powerful way of extending languages’ lexicons. Their role in language evolution is so important that according to Baldwin and Kim (2010), “It is highly doubtful that any language would evolve without MWEs of some description”. The efficient identification and extraction of MWEs can positively influence many other NLP tasks, e.g., part of speech tagging, parsing, syntactic disambiguation, semantic tagging, machine translation, and natural language generation. 10 Ronaldo Martins UNDL Foundation Geneva - Switzerland r.martins@undl.ch MWEs also have important applications outside NLP. For instance in document indexing, information retrieval (Acosta et al., 2011), and cross lingual information retrieval (Hull and Grefenstette, 1996</context>
</contexts>
<marker>Baldwin, Kim, 2010</marker>
<rawString>Timothy Baldwin and Su Nam Kim. 2010. Multiword expressions. Handbook of Natural Language Processing, second edition. Morgan and Claypool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Aline Villavicencio</author>
</authors>
<title>Extracting the unextractable: A case study on verbparticles.</title>
<date>2002</date>
<booktitle>In proceedings of the 6th conference on Natural language learning-Volume 20,</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3637" citStr="Baldwin and Villavicencio, 2002" startWordPosition="569" endWordPosition="572">re of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A diff</context>
</contexts>
<marker>Baldwin, Villavicencio, 2002</marker>
<rawString>Timothy Baldwin and Aline Villavicencio. 2002. Extracting the unextractable: A case study on verbparticles. In proceedings of the 6th conference on Natural language learning-Volume 20, pages 1–7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>Deep lexical acquisition of verb–particle constructions.</title>
<date>2005</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="3226" citStr="Baldwin, 2005" startWordPosition="504" endWordPosition="506">ponents, type frequency of the candidate MWE, and the association between these two (which is learned by a supervised model). Subsequently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Express</context>
</contexts>
<marker>Baldwin, 2005</marker>
<rawString>Timothy Baldwin. 2005. Deep lexical acquisition of verb–particle constructions. Computer Speech &amp; Language, 19(4):398–414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicoletta Calzolari</author>
<author>Charles J Fillmore</author>
<author>Ralph Grishman</author>
<author>Nancy Ide</author>
<author>Alessandro Lenci</author>
<author>Catherine MacLeod</author>
<author>Antonio Zampolli</author>
</authors>
<title>Towards best practice for multiword expressions in computational lexicons.</title>
<date>2002</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="1152" citStr="Calzolari et al., 2002" startWordPosition="172" endWordPosition="175">equential structure and not a bag of words, consequently, it becomes much more informative about MWEs. 1 Introduction Multiword Expressions (MWEs) are an important research topic in the area of Natural Language Processing (NLP). Efficient and effective extraction and interpretation of MWEs is crucial in most NLP tasks. They exist in many types of text and cause major problems in all kinds of natural language processing applications (Sag et al., 2002). However, identifying and lexicalizing these important but hard to identify structures need to be improved in most major computational lexicons (Calzolari et al., 2002). Jackendoff (1997) estimates that the number of MWEs is equal to the number of single words in a speaker’s lexicon, while Sag et al. (2002) believe that the number is even greater than this. Moreover, as a language evolves, the number of MWEs consistently increases. MWEs are a powerful way of extending languages’ lexicons. Their role in language evolution is so important that according to Baldwin and Kim (2010), “It is highly doubtful that any language would evolve without MWEs of some description”. The efficient identification and extraction of MWEs can positively influence many other NLP ta</context>
</contexts>
<marker>Calzolari, Fillmore, Grishman, Ide, Lenci, MacLeod, Zampolli, 2002</marker>
<rawString>Nicoletta Calzolari, Charles J Fillmore, Ralph Grishman, Nancy Ide, Alessandro Lenci, Catherine MacLeod, and Antonio Zampolli. 2002. Towards best practice for multiword expressions in computational lexicons. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helena de Medeiros Caseli</author>
</authors>
<title>Carlos Ramisch, Maria das Grac¸as Volpe Nunes, and Aline Villavicencio.</title>
<date>2010</date>
<pages>44--1</pages>
<marker>Caseli, 2010</marker>
<rawString>Helena de Medeiros Caseli, Carlos Ramisch, Maria das Grac¸as Volpe Nunes, and Aline Villavicencio. 2010. Alignment-based extraction of multiword expressions. Language resources and evaluation, 44(1-2):59–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ga¨el Dias</author>
</authors>
<title>Multiword unit hybrid extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment-Volume 18,</booktitle>
<pages>41--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Ga¨el Dias, 2003</marker>
<rawString>Ga¨el Dias. 2003. Multiword unit hybrid extraction. In Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment-Volume 18, pages 41–48. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianyong Duan</author>
<author>Mei Zhang</author>
<author>Lijing Tong</author>
<author>Feng Guo</author>
</authors>
<title>A hybrid approach to improve bilingual multiword expression extraction.</title>
<date>2009</date>
<booktitle>In Advances in Knowledge Discovery and Data Mining,</booktitle>
<pages>541--547</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="4771" citStr="Duan et al., 2009" startWordPosition="748" endWordPosition="751"> for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A different approach is presented in (Widdows and Dorow, 2005). The authors present a graphbased model to capture and assess fixed expressions in form of Noun and/or Noun. There are also bilingual models which are mostly based on the assumption that a translation of the MWE in a source language exists in a target language. For instance (de Medeiros Caseli et al., 2010; Ren et al., 2009), and (Moir´on and Tiedemann, 2006) which measures MWEs candidates’ idiomaticity based on translational entropy. Another example is (Duan et al., 2009) which is a hybrid model that aims at extracting bilingual (English-Chinese) MWEs . It combines Multiple Sequence Alignment Model with some filtering based on hard rules to obtain an improved extraction. A more generic model is presented in (Ramisch, 2012) where the author develops a flexible platform that can accept different types of criteria (from statistical to deep linguistic) in order to extract and filter MWEs. However, in this work, as the author claims, the quality of the extracted MWEs is highly dependent on the level of deep linguistic analysis, and thereby, the role of statistical </context>
</contexts>
<marker>Duan, Zhang, Tong, Guo, 2009</marker>
<rawString>Jianyong Duan, Mei Zhang, Lijing Tong, and Feng Guo. 2009. A hybrid approach to improve bilingual multiword expression extraction. In Advances in Knowledge Discovery and Data Mining, pages 541–547. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Hull</author>
<author>Gregory Grefenstette</author>
</authors>
<title>Querying across languages: a dictionary-based approach to multilingual information retrieval.</title>
<date>1996</date>
<booktitle>In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>49--57</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2168" citStr="Hull and Grefenstette, 1996" startWordPosition="329" endWordPosition="332">g to Baldwin and Kim (2010), “It is highly doubtful that any language would evolve without MWEs of some description”. The efficient identification and extraction of MWEs can positively influence many other NLP tasks, e.g., part of speech tagging, parsing, syntactic disambiguation, semantic tagging, machine translation, and natural language generation. 10 Ronaldo Martins UNDL Foundation Geneva - Switzerland r.martins@undl.ch MWEs also have important applications outside NLP. For instance in document indexing, information retrieval (Acosta et al., 2011), and cross lingual information retrieval (Hull and Grefenstette, 1996). In this paper we present a method of extracting MWEs which is relatively different from most of the state of the art approaches. We characterize MWEs based on the statistical properties of the immediate context they occur in. For each possible MWE candidate we define a set of contextual features (e.g., prefixes, suffixes, etc.). The contextual feature vector is then enriched with a few MWE-specific features such as the frequency of its components, type frequency of the candidate MWE, and the association between these two (which is learned by a supervised model). Subsequently the MWEhood of t</context>
</contexts>
<marker>Hull, Grefenstette, 1996</marker>
<rawString>David A Hull and Gregory Grefenstette. 1996. Querying across languages: a dictionary-based approach to multilingual information retrieval. In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval, pages 49–57. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>The architecture of the language faculty.</title>
<date>1997</date>
<journal>Number</journal>
<volume>28</volume>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1171" citStr="Jackendoff (1997)" startWordPosition="176" endWordPosition="177">ot a bag of words, consequently, it becomes much more informative about MWEs. 1 Introduction Multiword Expressions (MWEs) are an important research topic in the area of Natural Language Processing (NLP). Efficient and effective extraction and interpretation of MWEs is crucial in most NLP tasks. They exist in many types of text and cause major problems in all kinds of natural language processing applications (Sag et al., 2002). However, identifying and lexicalizing these important but hard to identify structures need to be improved in most major computational lexicons (Calzolari et al., 2002). Jackendoff (1997) estimates that the number of MWEs is equal to the number of single words in a speaker’s lexicon, while Sag et al. (2002) believe that the number is even greater than this. Moreover, as a language evolves, the number of MWEs consistently increases. MWEs are a powerful way of extending languages’ lexicons. Their role in language evolution is so important that according to Baldwin and Kim (2010), “It is highly doubtful that any language would evolve without MWEs of some description”. The efficient identification and extraction of MWEs can positively influence many other NLP tasks, e.g., part of </context>
</contexts>
<marker>Jackendoff, 1997</marker>
<rawString>Ray Jackendoff. 1997. The architecture of the language faculty. Number 28. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
<author>Judith L Klavans</author>
<author>Evelyne Tzoukermann</author>
</authors>
<title>Expansion of multi-word terms for indexing and retrieval using morphology and syntax.</title>
<date>1997</date>
<booktitle>In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>24--31</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3293" citStr="Jacquemin et al., 1997" startWordPosition="515" endWordPosition="518">ociation between these two (which is learned by a supervised model). Subsequently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014.</context>
</contexts>
<marker>Jacquemin, Klavans, Tzoukermann, 1997</marker>
<rawString>Christian Jacquemin, Judith L Klavans, and Evelyne Tzoukermann. 1997. Expansion of multi-word terms for indexing and retrieval using morphology and syntax. In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics, pages 24–31. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Detecting novel compounds: The role of distributional evidence.</title>
<date>2003</date>
<booktitle>In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume 1,</booktitle>
<pages>235--242</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Lapata, Lascarides, 2003</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2003. Detecting novel compounds: The role of distributional evidence. In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume 1, pages 235–242. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Li</author>
<author>Xiuhong Zhang</author>
<author>Cheng Niu</author>
<author>Yuankai Jiang</author>
<author>Rohini Srihari</author>
</authors>
<title>An expert lexicon approach to identifying english phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1,</booktitle>
<pages>513--520</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3361" citStr="Li et al., 2003" startWordPosition="528" endWordPosition="531">uently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; </context>
</contexts>
<marker>Li, Zhang, Niu, Jiang, Srihari, 2003</marker>
<rawString>Wei Li, Xiuhong Zhang, Cheng Niu, Yuankai Jiang, and Rohini Srihari. 2003. An expert lexicon approach to identifying english phrasal verbs. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 513–520. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>John Carroll</author>
</authors>
<title>Detecting a continuum of compositionality in phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment-Volume 18,</booktitle>
<pages>73--80</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3268" citStr="McCarthy et al., 2003" startWordPosition="511" endWordPosition="514">didate MWE, and the association between these two (which is learned by a supervised model). Subsequently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, </context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality in phrasal verbs. In Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment-Volume 18, pages 73–80. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Archibald Michiels</author>
<author>Nicolas Dufour</author>
</authors>
<title>Defi, a tool for automatic multi-word unit recognition, meaning assignment and translation selection.</title>
<date>1998</date>
<booktitle>In Proceedings of the first international conference on language resources &amp; evaluation,</booktitle>
<pages>1179--1186</pages>
<contexts>
<context position="3343" citStr="Michiels and Dufour, 1998" startWordPosition="524" endWordPosition="527">a supervised model). Subsequently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics </context>
</contexts>
<marker>Michiels, Dufour, 1998</marker>
<rawString>Archibald Michiels and Nicolas Dufour. 1998. Defi, a tool for automatic multi-word unit recognition, meaning assignment and translation selection. In Proceedings of the first international conference on language resources &amp; evaluation, pages 1179–1186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Begona Villada Moir´on</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Identifying idiomatic expressions using automatic word-alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 Workshop on Multi-wordexpressions in a multilingual context,</booktitle>
<pages>33--40</pages>
<marker>Moir´on, Tiedemann, 2006</marker>
<rawString>Begona Villada Moir´on and J¨org Tiedemann. 2006. Identifying idiomatic expressions using automatic word-alignment. In Proceedings of the EACL 2006 Workshop on Multi-wordexpressions in a multilingual context, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Satoshi Sekine</author>
</authors>
<title>A survey of named entity recognition and classification.</title>
<date>2007</date>
<journal>Lingvisticae Investigationes,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="6601" citStr="Nadeau and Sekine, 2007" startWordPosition="1043" endWordPosition="1046"> applied to learn MWEhood based on these features. In general, modeling lexical and syntactic (and not semantic) characteristics of continuous MWEs is the focus of this paper. In order for the MWE decomposability condition to hold, we consider bigrams and above (up to size 4). Idiomaticity at some level is a necessary prerequisite of MWEs. Hereby, we consider idiomaticity at lexical, syntactic and statistical levels, and leave the semantic idiomaticity to the future work. Relatively similar models have been previously applied to problems similar to MWEs, for instance named entity recognition (Nadeau and Sekine, 2007; Ratinov and Roth, 2009). The focus on contextual features allows some degree of generalization, i.e., we can apply this model to a family of languages.1 However, this work focuses only on English MWEs. 2 Proposed System We prepared a corpus that comprises 100K Wikipedia documents for each of the mentioned languages.1 After cleaning and segmenting the corpus, we extracted all possible n-grams (up to size 7) and their token and type frequencies. Then two basic statistical filters were applied in order to systematically decrease the size of our immense n-gram set: (i) Frequency filter, where we</context>
</contexts>
<marker>Nadeau, Sekine, 2007</marker>
<rawString>David Nadeau and Satoshi Sekine. 2007. A survey of named entity recognition and classification. Lingvisticae Investigationes, 30(1):3–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luka Nerima</author>
<author>Violeta Seretan</author>
<author>Eric Wehrli</author>
</authors>
<title>Creating a multilingual collocation dictionary from large text corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume 2,</booktitle>
<pages>131--134</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3211" citStr="Nerima et al., 2003" startWordPosition="500" endWordPosition="503"> frequency of its components, type frequency of the candidate MWE, and the association between these two (which is learned by a supervised model). Subsequently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Mu</context>
<context position="12777" citStr="Nerima et al., 2003" startWordPosition="2076" endWordPosition="2080">t features were very memory and CPU intensive. To address the performance issues we implemented parallel programs and ran them on a high performance cluster. 3 Experimental Results A set of ≈ 10K negative and positive English MWE examples were annotated. This set does not particularly belong in any specific genre, as the examples were chosen randomly from across a general-purpose corpus. This set comprises an equal number of positive and negative annotations. Part of it was annotated manually at UNDL foundation,2 and part of it was acquired from the manually examined MWE lexicon presented in (Nerima et al., 2003). The set of positive and negative annotated n-grams is detailed in Table 4. The bias toward bigrams is due to the fact that the majority of manually verified MWEs that could be obtained are bigrams. size + examples − examples 2-grams 4,632 5,173 3-grams 500 22 4-grams 68 15 Table 4: Annotations’ statistics This set was divided into 1/3 test and 2/3 training data, which were selected randomly but were evenly distributed with respect to positive and negative examples. The test set remains completely unseen to the model during the learning phase. We then train a linear SVM: h(y) = wT y + b (2) W</context>
</contexts>
<marker>Nerima, Seretan, Wehrli, 2003</marker>
<rawString>Luka Nerima, Violeta Seretan, and Eric Wehrli. 2003. Creating a multilingual collocation dictionary from large text corpora. In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics-Volume 2, pages 131– 134. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darren Pearce</author>
</authors>
<title>Synonymy in collocation extraction.</title>
<date>2001</date>
<booktitle>In Proceedings of the Workshop on WordNet and Other Lexical Resources, Second meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>41--46</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="3380" citStr="Pearce, 2001" startWordPosition="533" endWordPosition="534">the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>Darren Pearce. 2001. Synonymy in collocation extraction. In Proceedings of the Workshop on WordNet and Other Lexical Resources, Second meeting of the North American Chapter of the Association for Computational Linguistics, pages 41–46. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
</authors>
<title>Lexical association measures and collocation extraction. Language resources and evaluation,</title>
<date>2010</date>
<pages>44--1</pages>
<contexts>
<context position="3747" citStr="Pecina, 2010" startWordPosition="587" endWordPosition="588">and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A different approach is presented in (Widdows and Dorow, 2005). The authors present a graphbased model to capture an</context>
</contexts>
<marker>Pecina, 2010</marker>
<rawString>Pavel Pecina. 2010. Lexical association measures and collocation extraction. Language resources and evaluation, 44(1-2):137–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Songlin Piao</author>
<author>Tony McEnery</author>
</authors>
<title>Multiword unit alignment in english-chinese parallel corpora.</title>
<date>2001</date>
<booktitle>In the Proceedings of the Corpus Linguistics</booktitle>
<pages>466--475</pages>
<contexts>
<context position="3661" citStr="Piao and McEnery, 2001" startWordPosition="573" endWordPosition="576">ommon techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A different approach is presen</context>
</contexts>
<marker>Piao, McEnery, 2001</marker>
<rawString>Scott Songlin Piao and Tony McEnery. 2001. Multiword unit alignment in english-chinese parallel corpora. In the Proceedings of the Corpus Linguistics 2001, pages 466–475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott SL Piao</author>
<author>Paul Rayson</author>
<author>Dawn Archer</author>
<author>Andrew Wilson</author>
<author>Tony McEnery</author>
</authors>
<title>Extracting multiword expressions with a semantic tagger.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>49--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3245" citStr="Piao et al., 2003" startWordPosition="507" endWordPosition="510">requency of the candidate MWE, and the association between these two (which is learned by a supervised model). Subsequently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pa</context>
</contexts>
<marker>Piao, Rayson, Archer, Wilson, McEnery, 2003</marker>
<rawString>Scott SL Piao, Paul Rayson, Dawn Archer, Andrew Wilson, and Tony McEnery. 2003. Extracting multiword expressions with a semantic tagger. In Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatmentVolume 18, pages 49–56. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elias Ponvert</author>
<author>Jason Baldridge</author>
<author>Katrin Erk</author>
</authors>
<title>Simple unsupervised grammar induction from raw text with cascaded finite state models.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>1077--1086</pages>
<marker>Ponvert, Baldridge, Erk, 2011</marker>
<rawString>Elias Ponvert, Jason Baldridge, and Katrin Erk. 2011. Simple unsupervised grammar induction from raw text with cascaded finite state models. In ACL, pages 1077–1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
</authors>
<title>A generic framework for multiword expressions treatment: from acquisition to applications.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL 2012 Student Research Workshop,</booktitle>
<pages>61--66</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5027" citStr="Ramisch, 2012" startWordPosition="793" endWordPosition="794">also bilingual models which are mostly based on the assumption that a translation of the MWE in a source language exists in a target language. For instance (de Medeiros Caseli et al., 2010; Ren et al., 2009), and (Moir´on and Tiedemann, 2006) which measures MWEs candidates’ idiomaticity based on translational entropy. Another example is (Duan et al., 2009) which is a hybrid model that aims at extracting bilingual (English-Chinese) MWEs . It combines Multiple Sequence Alignment Model with some filtering based on hard rules to obtain an improved extraction. A more generic model is presented in (Ramisch, 2012) where the author develops a flexible platform that can accept different types of criteria (from statistical to deep linguistic) in order to extract and filter MWEs. However, in this work, as the author claims, the quality of the extracted MWEs is highly dependent on the level of deep linguistic analysis, and thereby, the role of statistical criterion is less significant. 1.2 Motivation We propose an original method to extract multiword expressions based on statistical contextual features, e.g., a set of immediate prefixes, suffixes, circumfixes, infixes to circumfixes, etc., (see Sec. 2). The</context>
</contexts>
<marker>Ramisch, 2012</marker>
<rawString>Carlos Ramisch. 2012. A generic framework for multiword expressions treatment: from acquisition to applications. In Proceedings of ACL 2012 Student Research Workshop, pages 61–66. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Design challenges and misconceptions in named entity recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>147--155</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6626" citStr="Ratinov and Roth, 2009" startWordPosition="1047" endWordPosition="1050"> based on these features. In general, modeling lexical and syntactic (and not semantic) characteristics of continuous MWEs is the focus of this paper. In order for the MWE decomposability condition to hold, we consider bigrams and above (up to size 4). Idiomaticity at some level is a necessary prerequisite of MWEs. Hereby, we consider idiomaticity at lexical, syntactic and statistical levels, and leave the semantic idiomaticity to the future work. Relatively similar models have been previously applied to problems similar to MWEs, for instance named entity recognition (Nadeau and Sekine, 2007; Ratinov and Roth, 2009). The focus on contextual features allows some degree of generalization, i.e., we can apply this model to a family of languages.1 However, this work focuses only on English MWEs. 2 Proposed System We prepared a corpus that comprises 100K Wikipedia documents for each of the mentioned languages.1 After cleaning and segmenting the corpus, we extracted all possible n-grams (up to size 7) and their token and type frequencies. Then two basic statistical filters were applied in order to systematically decrease the size of our immense n-gram set: (i) Frequency filter, where we filter an n-gram if its </context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>Lev Ratinov and Dan Roth. 2009. Design challenges and misconceptions in named entity recognition. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, pages 147– 155. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhixiang Ren</author>
<author>Yajuan L¨u</author>
<author>Jie Cao</author>
<author>Qun Liu</author>
<author>Yun Huang</author>
</authors>
<title>Improving statistical machine translation using domain bilingual multiword expressions.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications,</booktitle>
<pages>47--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Ren, L¨u, Cao, Liu, Huang, 2009</marker>
<rawString>Zhixiang Ren, Yajuan L¨u, Jie Cao, Qun Liu, and Yun Huang. 2009. Improving statistical machine translation using domain bilingual multiword expressions. In Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications, pages 47–54. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>1--15</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="983" citStr="Sag et al., 2002" startWordPosition="147" endWordPosition="150">ese contextual features can be very discriminant and combining them with MWEspecific features results in a relatively accurate extraction. We define context as a sequential structure and not a bag of words, consequently, it becomes much more informative about MWEs. 1 Introduction Multiword Expressions (MWEs) are an important research topic in the area of Natural Language Processing (NLP). Efficient and effective extraction and interpretation of MWEs is crucial in most NLP tasks. They exist in many types of text and cause major problems in all kinds of natural language processing applications (Sag et al., 2002). However, identifying and lexicalizing these important but hard to identify structures need to be improved in most major computational lexicons (Calzolari et al., 2002). Jackendoff (1997) estimates that the number of MWEs is equal to the number of single words in a speaker’s lexicon, while Sag et al. (2002) believe that the number is even greater than this. Moreover, as a language evolves, the number of MWEs consistently increases. MWEs are a powerful way of extending languages’ lexicons. Their role in language evolution is so important that according to Baldwin and Kim (2010), “It is highly </context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Computational Linguistics and Intelligent Text Processing, pages 1–15. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
<author>Eric Wehrli</author>
</authors>
<title>Accurate collocation extraction using a multilingual parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>953--960</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3604" citStr="Seretan and Wehrli, 2006" startWordPosition="565" endWordPosition="568">Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de</context>
</contexts>
<marker>Seretan, Wehrli, 2006</marker>
<rawString>Violeta Seretan and Eric Wehrli. 2006. Accurate collocation extraction using a multilingual parser. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 953–960. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
</authors>
<title>Syntax-based collocation extraction,</title>
<date>2011</date>
<volume>44</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="3168" citStr="Seretan, 2011" startWordPosition="494" endWordPosition="495">few MWE-specific features such as the frequency of its components, type frequency of the candidate MWE, and the association between these two (which is learned by a supervised model). Subsequently the MWEhood of the extracted candidates is predicted based on this feature representation, using a Support Vector Machine (SVM). The system reaches a relatively high accuracy of predicting MWEs on unseen data. 1.1 Previous Work Attempts to extract MWEs are of different types. The most common techniques are primarily focused on collocations. Some of these techniques are rule-based and symbolic e.g., (Seretan, 2011; Goldman et al., 2001; Nerima et al., 2003; Baldwin, 2005; Piao et al., 2003; McCarthy et al., 2003; Jacquemin et al., 1997). Some rely on lexicons (Michiels and Dufour, 1998; Li et al., 2003) and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata</context>
</contexts>
<marker>Seretan, 2011</marker>
<rawString>Violeta Seretan. 2011. Syntax-based collocation extraction, volume 44. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
<author>Kathleen R McKeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach.</title>
<date>1996</date>
<journal>Computational linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="3981" citStr="Smadja et al., 1996" startWordPosition="617" endWordPosition="620"> and (Pearce, 2001) that uses WordNet to evaluate the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A different approach is presented in (Widdows and Dorow, 2005). The authors present a graphbased model to capture and assess fixed expressions in form of Noun and/or Noun. There are also bilingual models which are mostly based on the assumption that a translation of the MWE in a source language exists in a target language. For instance (de Medeiros</context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Frank Smadja, Kathleen R McKeown, and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: A statistical approach. Computational linguistics, 22(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<journal>Xtract. Computational linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>177</pages>
<contexts>
<context position="4022" citStr="Smadja, 1993" startWordPosition="626" endWordPosition="627">e the candidate MWE based on anti-collocations. Other approaches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A different approach is presented in (Widdows and Dorow, 2005). The authors present a graphbased model to capture and assess fixed expressions in form of Noun and/or Noun. There are also bilingual models which are mostly based on the assumption that a translation of the MWE in a source language exists in a target language. For instance (de Medeiros Caseli et al., 2010; Ren et al., 2009), </context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving collocations from text: Xtract. Computational linguistics, 19(1):143– 177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Van de Cruys</author>
<author>Begona Villada Moir´on</author>
</authors>
<title>Semantics-based multiword expression extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on a Broader Perspective on Multiword Expressions,</booktitle>
<pages>25--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Van de Cruys, Moir´on, 2007</marker>
<rawString>Tim Van de Cruys and Begona Villada Moir´on. 2007. Semantics-based multiword expression extraction. In Proceedings of the Workshop on a Broader Perspective on Multiword Expressions, pages 25–32. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
</authors>
<title>Automatic extraction of idioms using graph analysis and asymmetric lexicosyntactic patterns.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition,</booktitle>
<pages>48--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4293" citStr="Widdows and Dorow, 2005" startWordPosition="666" endWordPosition="669">2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A different approach is presented in (Widdows and Dorow, 2005). The authors present a graphbased model to capture and assess fixed expressions in form of Noun and/or Noun. There are also bilingual models which are mostly based on the assumption that a translation of the MWE in a source language exists in a target language. For instance (de Medeiros Caseli et al., 2010; Ren et al., 2009), and (Moir´on and Tiedemann, 2006) which measures MWEs candidates’ idiomaticity based on translational entropy. Another example is (Duan et al., 2009) which is a hybrid model that aims at extracting bilingual (English-Chinese) MWEs . It combines Multiple Sequence Alignmen</context>
</contexts>
<marker>Widdows, Dorow, 2005</marker>
<rawString>Dominic Widdows and Beate Dorow. 2005. Automatic extraction of idioms using graph analysis and asymmetric lexicosyntactic patterns. In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 48–56. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Valia Kordoni</author>
<author>Aline Villavicencio</author>
<author>Marco Idiart</author>
</authors>
<title>Automated multiword expression prediction for grammar engineering.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>36--44</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4088" citStr="Zhang et al., 2006" startWordPosition="635" endWordPosition="638">ches are hybrid in the sense that they benefit from both statistical and linguistic information. For instance (Seretan and Wehrli, 2006; Baldwin and Villavicencio, 2002; Piao and McEnery, 2001; Dias, 2003). There are also fully statistical approaches. For instance (Pecina, 2010; Evert, 2005; Lapata and Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10–16, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics Lascarides, 2003; Smadja et al., 1996), or the early work Xtract (Smadja, 1993). Other approaches consider all types of MWEs (Zhang et al., 2006). Some of these approaches build upon generic properties of MWEs, for instance semantic non-compositionality (Van de Cruys and Moir´on, 2007). A different approach is presented in (Widdows and Dorow, 2005). The authors present a graphbased model to capture and assess fixed expressions in form of Noun and/or Noun. There are also bilingual models which are mostly based on the assumption that a translation of the MWE in a source language exists in a target language. For instance (de Medeiros Caseli et al., 2010; Ren et al., 2009), and (Moir´on and Tiedemann, 2006) which measures MWEs candidates’ </context>
</contexts>
<marker>Zhang, Kordoni, Villavicencio, Idiart, 2006</marker>
<rawString>Yi Zhang, Valia Kordoni, Aline Villavicencio, and Marco Idiart. 2006. Automated multiword expression prediction for grammar engineering. In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 36–44. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>