<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016676">
<title confidence="0.992012">
Two-Step Model for Sentiment Lexicon Extraction from Twitter Streams
</title>
<author confidence="0.989337">
Ilia Chetviorkin
</author>
<affiliation confidence="0.84482">
Lomonosov Moscow State University
Moscow, Leninskiye Gory 1
</affiliation>
<email confidence="0.978441">
ilia.chetviorkin@gmail.com
</email>
<author confidence="0.990463">
Natalia Loukachevitch
</author>
<affiliation confidence="0.8429525">
Lomonosov Moscow State University
Moscow, Leninskiye Gory 1
</affiliation>
<email confidence="0.982555">
louk nat@mail.ru
</email>
<sectionHeader confidence="0.993321" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999861588235294">
In this study we explore a novel technique
for creation of polarity lexicons from the
Twitter streams in Russian and English.
With this aim we make preliminary fil-
tering of subjective tweets using general
domain-independent lexicons in each lan-
guage. Then the subjective tweets are
used for extraction of domain-specific sen-
timent words. Relying on co-occurrence
statistics of extracted words in a large un-
labeled Twitter collections we utilize the
Markov random field framework for the
word polarity classification. To evaluate
the quality of the obtained sentiment lex-
icons they are used for tweet sentiment
classification and outperformed previous
results.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981839285715">
With growing popularity of microblogging ser-
vices such as Twitter, the amount of subjective in-
formation containing user opinions and sentiments
is increasing dramatically. People tend to express
their opinions about events in the real life and such
opinions contain valuable information for market
research, brand monitoring and political polls.
The task of automatic processing of such in-
formal resources is challenging because people
use a lot of slang, vulgarity and out-of-vocabulary
words to state their opinions about various ob-
jects and situations. In particular, it is difficult
to achieve the high quality of sentiment analy-
sis on such type of short informal texts as tweets
are. Standard domain-independent lexicon-based
methods suffer from low coverage, and for ma-
chine learning methods it is difficult to prepare a
representative collection of labeled data because
topics of discussion are changing rapidly.
Thus, special methods for processing social me-
dia data streams should be developed. We pro-
posed and evaluated our approach for Russian lan-
guage, where only a limited number of natural
language processing tools and resources are avail-
able. Then to demonstrate the robustness of the
method and to compare the results with the other
approaches we used it for English.
The current research can be separated into two
steps. We start with a special supervised model
based on statistical and linguistic features of sen-
timent words, which is trained and evaluated in
the movie domain. Then this model is utilized
for extraction of sentiment words from unlabeled
Twitter datasets, which are preliminary filtered us-
ing the domain-independent lexicons: Product-
SentiRus (Chetviorkin and Loukachevitch, 2012)
for Russian and MPQA (Wilson et al., 2005) for
English.
In the second step an algorithm for polarity clas-
sification of extracted sentiment words is intro-
duced. It is built using the Markov random field
framework and uses only information contained in
text collections.
To evaluate the quality of the created lexicons
extrinsically, we conduct the experiments on the
tweet subjectivity and polarity classification tasks
using various lexicons.
The key advantage of the proposed two-step al-
gorithm is that once trained it can be utilized to
different domains and languages with minor mod-
ifications. To demonstrate the ability of the pro-
posed algorithm to extract sentiment words in var-
ious domains we took significantly different col-
lections for training and testing: movie review col-
lection for training and large collections of tweets
for testing.
</bodyText>
<sectionHeader confidence="0.999646" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99921725">
There are two major approaches for creation
of a sentiment lexicon in a specific language:
dictionary-based methods and corpus-based meth-
ods.
</bodyText>
<page confidence="0.991353">
67
</page>
<bodyText confidence="0.995856946428572">
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 67–72,
Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics
Dictionary-based methods for various lan-
guages have received a lot of attention in the lit-
erature (P´erez-Rosas et al., 2012; Mohammad et
al., 2009; Clematide and Klenner, 2010), but the
main problem of such approaches is that it is diffi-
cult to apply them to processing social media. The
reason is that short informal texts contain a lot of
misspellings and out-of-vocabulary words.
Corpus-based methods are more suitable for
processing social media data. In such approaches
various statistical and linguistic features are used
to discriminate opinion words from all other
words (He et al., 2008; Jijkoun et al., 2010).
Another important group of approaches, which
can be both dictionary-based and corpus-based are
graph-based methods. In (Velikovich et al., 2010)
a new method for constructing a lexical network
was proposed, which aggregates the huge amount
of unlabeled data. Then the graph propagation al-
gorithm was used. Several other researchers uti-
lized the graph or label propagation techniques
for solving the problem of opinion word extrac-
tion (Rao and Ravichandran, 2009; Speriosu et al.,
2011).
In (Takamura et al., 2005) authors describe a
probabilistic model for assigning polarity to each
word in a collection. This model is based on
the Ising spin model of magnetism and is built
upon Markov random field framework, using var-
ious dictionary-based and linguistic features. In
our research, unlike (Takamura et al., 2005) we
use only information contained in a text collection
without any external dictionary resources (due to
the lack of necessary resources for Russian). Our
advantage is that we use only potential domain-
specific sentiment words during the construction
of the network.
A large body of research has been focused on
Twitter sentiment analysis during the previous sev-
eral years (Barbosa and Feng, 2010; Bermingham
and Smeaton, 2010; Bifet and Frank, 2010; Davi-
dov et al., 2010; Kouloumpis et al., 2011; Jiang
et al., 2011; Agarwal et al., 2011; Wang et al.,
2011). In (Chen et al., 2012) authors propose an
optimization framework for extraction of opinion
expressions from tweets. Using extracted lexicons
authors were able to improve the tweet sentiment
classification quality. Our approach is based on
similar assumptions (like consistency relations),
but we do not use any syntactic parsers and dic-
tionary resources. In (Volkova et al., 2013) a new
multilingual bootstrapping technique for building
tweet sentiment lexicons was introduced. This
method is used as a baseline in our work.
</bodyText>
<sectionHeader confidence="0.995248" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999964421052632">
For the experiments in this paper we use several
collections in two domains: movie review col-
lection in Russian for training and fine-tuning of
the proposed algorithms and Twitter collections
for evaluation and demonstration of robustness in
Russian and English languages.
Movie domain. The movie review dataset col-
lected from the online service imhonet.ru. There
are 28,773 movie reviews of various genres with
numeric scores specified by their authors (DOM).
Additionally, special collections with low con-
centration of sentiment words are utilized: the
contrast collection consists of 17, 980 movie plots
(DESC) and a collection of two million news doc-
uments (NEWS). Such collections are useful for
filtering out of domain-specific and general neu-
tral words, which are very frequent in news and
object descriptions.
Twitter collections. We use three datasets for
each language: 1M+ of unlabeled tweets (UNL)
for extraction of sentiment lexicons, 2K labeled
tweets for development data (DEV), and 2K la-
beled tweets for evaluation (TEST). DEV dataset
is used to find the best combination of various lex-
icons for processing Twitter data and TEST for
evaluating the quality of constructed lexicons.
The UNL dataset in Russian was collected dur-
ing one day using Twitter API. These tweets con-
tain various topics without any filtering. Only
strict duplicates and retweets were removed from
the dataset. The similar collection for English was
downloaded using the links from (Volkova et al.,
2013).
All tweets in DEV and TEST collections are
manually labeled by subjectivity and polarity us-
ing the Mechanical Turk with five workers (ma-
jority voting). This data was used for development
and evaluation in (Volkova et al., 2013).
</bodyText>
<sectionHeader confidence="0.997862" genericHeader="method">
4 Method for sentiment word extraction
</sectionHeader>
<bodyText confidence="0.999961333333333">
In this section we introduce an algorithm for
sentiment lexicon extraction, which is inspired
by the method described in (Chetviorkin and
Loukachevitch, 2012), but have more robust fea-
tures, which allow us to apply it to any unlabeled
text collection (e.g. tweets collection). The pro-
</bodyText>
<page confidence="0.996699">
68
</page>
<bodyText confidence="0.99979675">
posed algorithm is applied to text collections in
Russian and English and obtained results are eval-
uated intrinsically for Russian and extrinsically for
both languages.
</bodyText>
<subsectionHeader confidence="0.995445">
4.1 An extraction model
</subsectionHeader>
<bodyText confidence="0.99980456097561">
Our algorithm is based on several text collec-
tions: collection with the high concentration of
sentiment words (e.g. DOM collection), con-
trast domain-specific collection (e.g. DESC col-
lection), contrast domain-independent collection
(e.g. NEWS collection). Thus, taking into ac-
count statistical distributions of words in such col-
lections we are able to distinguish domain-specific
sentiment words.
We experimented with various features to create
the robust cross-domain feature representation of
sentiment words. As a result the eight most valu-
able features were used in further experiments:
Linguistic features. Adjective binary indica-
tor, noun binary indicator, feature reflecting part-
of-speech ambiguity (for lemma), binary feature
of predefined list of prefixes (e.g. un, im);
Statistical features. Frequency of capitalized
words, frequency of co-occurrence with polarity
shifters (e.g. no, very), TFIDF feature calculated
on the basis of various collection pairs, weirdness
feature (the ratio of relative frequencies of certain
lexical items in special and general collections)
calculated using several pairs of collections.
To train supervised machine learning algo-
rithms all words with frequency greater than three
in the Russian movie review collection (DOM)
were labeled manually by two assessors. If there
was a disagreement about the sentiment of a spe-
cific word, the collective judgment after the dis-
cussion was used as a final ground truth. As a re-
sult of the assessment procedure the list of 4079
sentiment words was obtained.
The best quality of classification using labeled
data was shown by the ensemble of three classi-
fiers: Logistic Regression, LogitBoost and Ran-
dom Forest. The quality according to Precision@n
measure can be found in Table 1. This trained
model was used in further experiments for extrac-
tion of sentiment words both in English and in
Russian.
</bodyText>
<subsectionHeader confidence="0.993847">
4.2 Extraction of subjective words from
Twitter data
</subsectionHeader>
<bodyText confidence="0.963994">
To verify the robustness of the model on new un-
labeled data it was utilized for sentiment word ex-
</bodyText>
<table confidence="0.999392333333333">
Lexicon P@100 P@1000
MovieLex 95.0% 78.3%
TwitterLex 95.0% 79.9%
</table>
<tableCaption confidence="0.925815">
Table 1: Quality of subjective word extraction in
Russian
</tableCaption>
<bodyText confidence="0.998742903225806">
traction from multi-topic tweet collection UNL in
each language. To apply this model we prepared
three collections: domain-specific with high con-
centration of sentiment words, domain-specific
with low concentration of sentiment words and
one general collection with low concentration of
sentiment words. As the general collection we
could take the same NEWS collection (see Sec-
tion 3) for Russian and British National Corpus1
for English.
To prepare domain-specific collections we clas-
sified the UNL collections by subjectivity using
general purpose sentiment lexicons ProductSen-
tiRus and MPQA in accordance with the language.
The subjectivity classifier predicted that a tweet
was subjective if it contained at least one subjec-
tive term from this lexicon. All subjective tweets
constituted a collection with the high concentra-
tion of sentiment words and all the other tweets
constituted the contrast collection.
Finally, using all specially prepared collections
and the trained model (in the movie domain), new
lexicons of twitter-specific sentiment words were
extracted. The quality of extraction in Russian ac-
cording to manual labeling of two assessors can be
found in Table 1. The resulting quality of extracted
Russian lexicon is on the same level as in the ini-
tial movie domain, what confirms the robustness
of the proposed model.
We took 5000 of the most probable sentiment
words from each lexicon for further work.
</bodyText>
<sectionHeader confidence="0.977389" genericHeader="method">
5 Polarity classification using MRF
</sectionHeader>
<bodyText confidence="0.99398">
In the second part of current research we describe
an algorithm for polarity classification of extracted
sentiment words. The proposed method relies on
several assumptions:
</bodyText>
<listItem confidence="0.988206">
• Each word has the prior sentiment score cal-
culated using the review scores where it ap-
pears (simple averaging);
• Words with similar polarity tend to co-occur
closely to each other;
</listItem>
<footnote confidence="0.989511">
1http://www.natcorp.ox.ac.uk/
</footnote>
<page confidence="0.996286">
69
</page>
<listItem confidence="0.967583">
• Negation between sentiment words leads to
the opposite polarity labels.
</listItem>
<subsectionHeader confidence="0.974094">
5.1 Algorithm description
</subsectionHeader>
<bodyText confidence="0.943751625">
To formalize all these assumptions we construct an
undirected graphical model using extracted sen-
timent word co-occurrence statistics. Each ex-
tracted word is represented by a vertex in a graph
and an edge between two vertexes is established in
case if they co-occur together more than once in
the collection. We drop all the edges where aver-
age distance between words is more than 8 words.
Our model by construction is similar to ap-
proach based on the Ising spin model described
in (Takamura et al., 2005). Ising model is used
to describe ferromagnetism in statistical mechan-
ics. In general, the system is composed of N bi-
nary variables (spins), where each variable xi E
{−1, +1}, i = 1, 2, ..., N. The energy function of
the system is the following:
</bodyText>
<equation confidence="0.9967815">
E(x) = − E Esijxixj − hixi (1)
ij i
</equation>
<bodyText confidence="0.9996895">
where sij represents the efficacy of interaction be-
tween two spins and hi stands for external field
added to xi. The probability of each system con-
figuration is provided by Boltzmann distribution:
</bodyText>
<equation confidence="0.999703">
P(X) =
exp −βE(X)
Z (2)
</equation>
<bodyText confidence="0.999794692307692">
where Z is a normalizing factor and Q = (T−1 &gt;
0) is inverse temperature, which is parameter of
the model. We calculate values of P(X) with sev-
eral different values of Q and try to find the locally
polarized state of the network.
To specify the initial polarity of each word, we
assume that each text from the collection has its
sentiment score. This condition is not very strict,
because there are a lot of internet review services
where people assign numerical scores to their re-
views. Using such scores we can calculate the de-
viation from the average score for each word in the
collection:
</bodyText>
<equation confidence="0.993605">
h(i) = E(c|wi) − E(c)
</equation>
<bodyText confidence="0.999694615384615">
where c is the review score random variable, E(c)
is the expectation of the score in the collection and
E(c|wi) is the expectation of the score for reviews
containing word wi. Thus we assign the initial
weight of each vertex i in the MRF to be equal
to h(i).
To specify the weight of each edge in the net-
work we made preliminary experiments to detect
the dependency between the probability of the
word pair to have similar polarity and average dis-
tance between them. The result of such experi-
ment for movie reviews can be found on Figure 1.
One can see that if the distance between the words
</bodyText>
<figureCaption confidence="0.9822495">
Figure 1: The dependency between the probability
to have similar polarity and average distance
</figureCaption>
<bodyText confidence="0.9996364">
is above four, then the probability is remain on the
same level which is slightly biased to similar po-
larity. Relying on this insight and taking into ac-
count the frequency of co-occurrence of the words
we used the following edge weights:
</bodyText>
<equation confidence="0.999768666666667">
s(i,j) = f(wi, wj) max 0.5
( d(wi, wj)
d(wi, wj) + 4,
</equation>
<bodyText confidence="0.999885217391304">
where f(wi, wj) is the co-occurrence frequency
in the collection and d(wi, wj) is the average dis-
tance between words wi and wj.
Finally, we revert the sign of this equation in
case of more than half of co-occurrences contains
negation (no, not, but) between opinion words.
In practice we can find approximate solution us-
ing such algorithms as: Loopy Belief Propagation
(BP), Mean Field (MF), Gibbs Sampling (Gibbs).
The performance of the methods was evalu-
ated for a lexical network constructed from the
first 3000 of the most probable extracted sentiment
words in the movie review collection (DOM). We
took from them 822 interconnected words with
strict polarity labeled by two assessors as a gold
standard. Testing was performed by varying Q
from 0.1 to 1.0. The primary measure in this ex-
periment was accuracy. The best results can be
found in Table 2.
The best performance was demonstrated by MF
algorithm and Q = 0.4. This algorithm and pa-
rameter value were used in further experiments on
unlabeled tweet collections.
</bodyText>
<equation confidence="0.355462">
0)
</equation>
<page confidence="0.985892">
70
</page>
<table confidence="0.999754454545455">
Lexicon P R Fsubj
Russian
Volkova, 2013 - - 61.0
TwitterLex 60.2 79.3 68.5
English
Volkova, 2013 - - 75.0
TwitterLex 58.8 95.5 73.0
Q BP MF Gibbs
0.4 83.8 85.2 83.7
0.5 83.6 84.5 82.0
0.6 85.0 83.1 79.4
</table>
<tableCaption confidence="0.7710225">
Table 2: Dependence between the accuracy of
classification and Q
</tableCaption>
<subsectionHeader confidence="0.94336">
5.2 Polarity classification of subjective words
from Twitter data
</subsectionHeader>
<bodyText confidence="0.999951178571428">
Using the general polarity lexicons we classify all
subjective tweets in large UNL collections into
positive and negative categories. For the polarity
classifier, we predict a tweet to be positive (nega-
tive) if it contains at least one positive (negative)
term from the lexicon taking into account nega-
tion. If a tweet contains both positive and nega-
tive terms, we take the majority label. In case if a
tweet does not contain any word from the lexicon
we predict it to be positive.
These labels (+1 for positive and −1 for nega-
tive) can be used to compute initial polarity h(i)
for all extracted sentiment words from the UNL
collections. The weights of the links between
words s(i, j) can be also computed using full un-
labeled collections.
Thus, we can utilize the algorithm for polarity
classification of sentiment words extracted from
Twitter. The resulting lexicon for Russian contains
2772 words and 2786 words for English (we take
only words that are connected in the network). To
evaluate the quality of the obtained lexicons the
Russian one was labeled by two assessors. In re-
sult of such markup 1734 words with strict posi-
tive or negative polarity were taken. The accuracy
of the lexicon on the basis of the markup was equal
to 72%, which is 1.5 % better than the simple av-
erage score baseline.
</bodyText>
<sectionHeader confidence="0.965314" genericHeader="method">
6 Lexicon Evaluations
</sectionHeader>
<bodyText confidence="0.995869090909091">
To evaluate all newly created lexicons they were
utilized in tweet polarity and subjectivity classifi-
cation tasks using the TEST collections. The re-
sults of the classification for both languages can
be found in Table 3 and Table 4.
As one can see, the newly created Twitter-
specific sentiment lexicon results outperform the
result of (Volkova et al., 2013) in subjectivity clas-
sification for Russian but slightly worse than the
result for English. On the other hand the re-
sults of polarity classification are on par or better
</bodyText>
<tableCaption confidence="0.882913">
Table 3: Quality of tweet subjectivity classifica-
tion
</tableCaption>
<table confidence="0.999979777777778">
Lexicon P R Fpol
Russian
Volkova, 2013 - - 73.0
TwitterLex 65.5 82.0 72.8
Combined 65.8 85.5 74.3
English
Volkova, 2013 - - 78.0
TwitterLex 72.1 88.1 79.3
Combined 73.2 89.3 80.4
</table>
<tableCaption confidence="0.999726">
Table 4: Quality of tweet polarity classification
</tableCaption>
<bodyText confidence="0.999893333333333">
than the results of (Volkova et al., 2013) lexicons
bootstrapped from domain-independent sentiment
lexicons. Thus, to push the quality of polarity
classification forward we combined the domain-
independent lexicons and our Twitter-specific lex-
icons. We experimented with various word counts
from general lexicons and found the optimal com-
bination on the DEV collection: all words from
TwitterLex and 2000 the most strong sentiment
words from ProductSentiRus in Russian and all
strong sentiment words from MPQA in English.
The lexicon combination outperforms all previous
results by F-measure leading to the conclusion that
proposed method can capture valuable domain-
specific sentiment words.
</bodyText>
<sectionHeader confidence="0.998501" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.998704909090909">
In this paper we proposed a new method for ex-
traction of domain-specific sentiment lexicons and
adopted the Ising model for polarity classifica-
tion of extracted words. This two-stage method
was applied to a large unlabeled Twitter dataset
and the extracted sentiment lexicons performed on
the high level in the tweet sentiment classification
task. Our method can be used in a streaming mode
for augmentation of sentiment lexicons and sup-
porting the high quality of multilingual sentiment
classification.
</bodyText>
<page confidence="0.99597">
71
</page>
<copyright confidence="0.789941">
Acknowledgements This work is partially sup-
ported by RFBR grant 14-07-00682.
</copyright>
<sectionHeader confidence="0.980489" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999882037037037">
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram-
bow, and Rebecca Passonneau. 2011. Sentiment
analysis of twitter data. In Proceedings of the Work-
shop on Languages in Social Media, pages 30–38.
Association for Computational Linguistics.
Luciano Barbosa and Junlan Feng. 2010. Robust sen-
timent detection on twitter from biased and noisy
data. In Proceedings of the 23rd International
Conference on Computational Linguistics: Posters,
pages 36–44. Association for Computational Lin-
guistics.
Adam Bermingham and Alan F Smeaton. 2010. Clas-
sifying sentiment in microblogs: is brevity an advan-
tage? In Proceedings of the 19th ACM international
conference on Information and knowledge manage-
ment, pages 1833–1836. ACM.
Albert Bifet and Eibe Frank. 2010. Sentiment knowl-
edge discovery in twitter streaming data. In Discov-
ery Science, pages 1–15. Springer.
Lu Chen, Wenbo Wang, Meenakshi Nagarajan, Shao-
jun Wang, and Amit P Sheth. 2012. Extracting
diverse sentiment expressions with target-dependent
polarity from twitter. In ICWSM.
Ilia Chetviorkin and Natalia V Loukachevitch. 2012.
Extraction of russian sentiment lexicon for product
meta-domain. In COLING, pages 593–610.
Simon Clematide and Manfred Klenner. 2010. Eval-
uation and extension of a polarity lexicon for ger-
man. In Proceedings of the First Workshop on Com-
putational Approaches to Subjectivity and Sentiment
Analysis, pages 7–13.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Enhanced sentiment learning using twitter hashtags
and smileys. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics:
Posters, pages 241–249. Association for Computa-
tional Linguistics.
Ben He, Craig Macdonald, Jiyin He, and Iadh Ounis.
2008. An effective statistical approach to blog post
opinion retrieval. In Proceedings of the 17th ACM
conference on Information and knowledge manage-
ment, pages 1063–1072. ACM.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
timent classification. In ACL, pages 151–160.
Valentin Jijkoun, Maarten de Rijke, and Wouter
Weerkamp. 2010. Generating focused topic-
specific sentiment lexicons. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 585–594. Association for
Computational Linguistics.
Efthymios Kouloumpis, Theresa Wilson, and Johanna
Moore. 2011. Twitter sentiment analysis: The good
the bad and the omg! In ICWSM.
Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009. Generating high-coverage semantic orien-
tation lexicons from overtly marked words and a
thesaurus. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Pro-
cessing: Volume 2, pages 599–608. Association for
Computational Linguistics.
Ver´onica P´erez-Rosas, Carmen Banea, and Rada Mi-
halcea. 2012. Learning sentiment lexicons in span-
ish. In LREC, pages 3077–3081.
Delip Rao and Deepak Ravichandran. 2009. Semi-
supervised polarity lexicon induction. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 675–682. Association for Computational Lin-
guistics.
Michael Speriosu, Nikita Sudan, Sid Upadhyay, and
Jason Baldridge. 2011. Twitter polarity classifica-
tion with label propagation over lexical links and the
follower graph. In Proceedings of the First work-
shop on Unsupervised Learning in NLP, pages 53–
63. Association for Computational Linguistics.
H. Takamura, T. Inui, and M. Okumura. 2005. Ex-
tracting semantic orientations of words using spin
model. In Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics, pages
133–140.
Leonid Velikovich, Sasha Blair-Goldensohn, Kerry
Hannan, and Ryan McDonald. 2010. The viability
of web-derived polarity lexicons. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 777–785. As-
sociation for Computational Linguistics.
Svitlana Volkova, Theresa Wilson, and David
Yarowsky. 2013. Exploring sentiment in social
media: Bootstrapping subjectivity clues from
multilingual twitter streams. In Proceedings
of the 51st Annual Meeting of the Association
for Computational Linguistics (ACL13), pages
505–510.
Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou,
and Ming Zhang. 2011. Topic sentiment analysis
in twitter: a graph-based hashtag sentiment classifi-
cation approach. In Proceedings of the 20th ACM
international conference on Information and knowl-
edge management, pages 1031–1040. ACM.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the con-
ference on human language technology and empiri-
cal methods in natural language processing, pages
347–354. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.998721">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.095051">
<title confidence="0.968912">Two-Step Model for Sentiment Lexicon Extraction from Twitter Streams</title>
<affiliation confidence="0.621892666666667">Ilia Lomonosov Moscow State Moscow, Leninskiye Gory</affiliation>
<email confidence="0.993842">ilia.chetviorkin@gmail.com</email>
<author confidence="0.758961">Natalia</author>
<affiliation confidence="0.746793">Lomonosov Moscow State Moscow, Leninskiye Gory</affiliation>
<email confidence="0.806213">louknat@mail.ru</email>
<abstract confidence="0.998268388888889">In this study we explore a novel technique for creation of polarity lexicons from the Twitter streams in Russian and English. With this aim we make preliminary filtering of subjective tweets using general domain-independent lexicons in each language. Then the subjective tweets are used for extraction of domain-specific sentiment words. Relying on co-occurrence statistics of extracted words in a large unlabeled Twitter collections we utilize the Markov random field framework for the word polarity classification. To evaluate the quality of the obtained sentiment lexicons they are used for tweet sentiment classification and outperformed previous results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Boyi Xie</author>
<author>Ilia Vovsha</author>
<author>Owen Rambow</author>
<author>Rebecca Passonneau</author>
</authors>
<title>Sentiment analysis of twitter data.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Languages in Social Media,</booktitle>
<pages>30--38</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5871" citStr="Agarwal et al., 2011" startWordPosition="896" endWordPosition="899">ary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method is used as a baseline in our work. 3 Data For the experiments in this paper we use sever</context>
</contexts>
<marker>Agarwal, Xie, Vovsha, Rambow, Passonneau, 2011</marker>
<rawString>Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data. In Proceedings of the Workshop on Languages in Social Media, pages 30–38. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<title>Robust sentiment detection on twitter from biased and noisy data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</booktitle>
<pages>36--44</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5729" citStr="Barbosa and Feng, 2010" startWordPosition="871" endWordPosition="874">in a collection. This model is based on the Ising spin model of magnetism and is built upon Markov random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building</context>
</contexts>
<marker>Barbosa, Feng, 2010</marker>
<rawString>Luciano Barbosa and Junlan Feng. 2010. Robust sentiment detection on twitter from biased and noisy data. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 36–44. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Bermingham</author>
<author>Alan F Smeaton</author>
</authors>
<title>Classifying sentiment in microblogs: is brevity an advantage?</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management,</booktitle>
<pages>1833--1836</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5759" citStr="Bermingham and Smeaton, 2010" startWordPosition="875" endWordPosition="878">del is based on the Ising spin model of magnetism and is built upon Markov random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was </context>
</contexts>
<marker>Bermingham, Smeaton, 2010</marker>
<rawString>Adam Bermingham and Alan F Smeaton. 2010. Classifying sentiment in microblogs: is brevity an advantage? In Proceedings of the 19th ACM international conference on Information and knowledge management, pages 1833–1836. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert Bifet</author>
<author>Eibe Frank</author>
</authors>
<title>Sentiment knowledge discovery in twitter streaming data.</title>
<date>2010</date>
<booktitle>In Discovery Science,</booktitle>
<pages>1--15</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5782" citStr="Bifet and Frank, 2010" startWordPosition="879" endWordPosition="882"> model of magnetism and is built upon Markov random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method</context>
</contexts>
<marker>Bifet, Frank, 2010</marker>
<rawString>Albert Bifet and Eibe Frank. 2010. Sentiment knowledge discovery in twitter streaming data. In Discovery Science, pages 1–15. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Chen</author>
<author>Wenbo Wang</author>
<author>Meenakshi Nagarajan</author>
<author>Shaojun Wang</author>
<author>Amit P Sheth</author>
</authors>
<title>Extracting diverse sentiment expressions with target-dependent polarity from twitter.</title>
<date>2012</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="5915" citStr="Chen et al., 2012" startWordPosition="905" endWordPosition="908">arch, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method is used as a baseline in our work. 3 Data For the experiments in this paper we use several collections in two domains: movie review </context>
</contexts>
<marker>Chen, Wang, Nagarajan, Wang, Sheth, 2012</marker>
<rawString>Lu Chen, Wenbo Wang, Meenakshi Nagarajan, Shaojun Wang, and Amit P Sheth. 2012. Extracting diverse sentiment expressions with target-dependent polarity from twitter. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilia Chetviorkin</author>
<author>Natalia V Loukachevitch</author>
</authors>
<title>Extraction of russian sentiment lexicon for product meta-domain. In</title>
<date>2012</date>
<booktitle>COLING,</booktitle>
<pages>593--610</pages>
<contexts>
<context position="2671" citStr="Chetviorkin and Loukachevitch, 2012" startWordPosition="395" endWordPosition="398">imited number of natural language processing tools and resources are available. Then to demonstrate the robustness of the method and to compare the results with the other approaches we used it for English. The current research can be separated into two steps. We start with a special supervised model based on statistical and linguistic features of sentiment words, which is trained and evaluated in the movie domain. Then this model is utilized for extraction of sentiment words from unlabeled Twitter datasets, which are preliminary filtered using the domain-independent lexicons: ProductSentiRus (Chetviorkin and Loukachevitch, 2012) for Russian and MPQA (Wilson et al., 2005) for English. In the second step an algorithm for polarity classification of extracted sentiment words is introduced. It is built using the Markov random field framework and uses only information contained in text collections. To evaluate the quality of the created lexicons extrinsically, we conduct the experiments on the tweet subjectivity and polarity classification tasks using various lexicons. The key advantage of the proposed two-step algorithm is that once trained it can be utilized to different domains and languages with minor modifications. To</context>
<context position="8344" citStr="Chetviorkin and Loukachevitch, 2012" startWordPosition="1281" endWordPosition="1284">s contain various topics without any filtering. Only strict duplicates and retweets were removed from the dataset. The similar collection for English was downloaded using the links from (Volkova et al., 2013). All tweets in DEV and TEST collections are manually labeled by subjectivity and polarity using the Mechanical Turk with five workers (majority voting). This data was used for development and evaluation in (Volkova et al., 2013). 4 Method for sentiment word extraction In this section we introduce an algorithm for sentiment lexicon extraction, which is inspired by the method described in (Chetviorkin and Loukachevitch, 2012), but have more robust features, which allow us to apply it to any unlabeled text collection (e.g. tweets collection). The pro68 posed algorithm is applied to text collections in Russian and English and obtained results are evaluated intrinsically for Russian and extrinsically for both languages. 4.1 An extraction model Our algorithm is based on several text collections: collection with the high concentration of sentiment words (e.g. DOM collection), contrast domain-specific collection (e.g. DESC collection), contrast domain-independent collection (e.g. NEWS collection). Thus, taking into acco</context>
</contexts>
<marker>Chetviorkin, Loukachevitch, 2012</marker>
<rawString>Ilia Chetviorkin and Natalia V Loukachevitch. 2012. Extraction of russian sentiment lexicon for product meta-domain. In COLING, pages 593–610.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Clematide</author>
<author>Manfred Klenner</author>
</authors>
<title>Evaluation and extension of a polarity lexicon for german.</title>
<date>2010</date>
<booktitle>In Proceedings of the First Workshop on Computational Approaches to Subjectivity and Sentiment Analysis,</booktitle>
<pages>7--13</pages>
<contexts>
<context position="4074" citStr="Clematide and Klenner, 2010" startWordPosition="610" endWordPosition="613">view collection for training and large collections of tweets for testing. 2 Related work There are two major approaches for creation of a sentiment lexicon in a specific language: dictionary-based methods and corpus-based methods. 67 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 67–72, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics Dictionary-based methods for various languages have received a lot of attention in the literature (P´erez-Rosas et al., 2012; Mohammad et al., 2009; Clematide and Klenner, 2010), but the main problem of such approaches is that it is difficult to apply them to processing social media. The reason is that short informal texts contain a lot of misspellings and out-of-vocabulary words. Corpus-based methods are more suitable for processing social media data. In such approaches various statistical and linguistic features are used to discriminate opinion words from all other words (He et al., 2008; Jijkoun et al., 2010). Another important group of approaches, which can be both dictionary-based and corpus-based are graph-based methods. In (Velikovich et al., 2010) a new metho</context>
</contexts>
<marker>Clematide, Klenner, 2010</marker>
<rawString>Simon Clematide and Manfred Klenner. 2010. Evaluation and extension of a polarity lexicon for german. In Proceedings of the First Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 7–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>Enhanced sentiment learning using twitter hashtags and smileys.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</booktitle>
<pages>241--249</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5804" citStr="Davidov et al., 2010" startWordPosition="883" endWordPosition="887"> is built upon Markov random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method is used as a baseline</context>
</contexts>
<marker>Davidov, Tsur, Rappoport, 2010</marker>
<rawString>Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010. Enhanced sentiment learning using twitter hashtags and smileys. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 241–249. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben He</author>
<author>Craig Macdonald</author>
<author>Jiyin He</author>
<author>Iadh Ounis</author>
</authors>
<title>An effective statistical approach to blog post opinion retrieval.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>1063--1072</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4493" citStr="He et al., 2008" startWordPosition="677" endWordPosition="680">tional Linguistics Dictionary-based methods for various languages have received a lot of attention in the literature (P´erez-Rosas et al., 2012; Mohammad et al., 2009; Clematide and Klenner, 2010), but the main problem of such approaches is that it is difficult to apply them to processing social media. The reason is that short informal texts contain a lot of misspellings and out-of-vocabulary words. Corpus-based methods are more suitable for processing social media data. In such approaches various statistical and linguistic features are used to discriminate opinion words from all other words (He et al., 2008; Jijkoun et al., 2010). Another important group of approaches, which can be both dictionary-based and corpus-based are graph-based methods. In (Velikovich et al., 2010) a new method for constructing a lexical network was proposed, which aggregates the huge amount of unlabeled data. Then the graph propagation algorithm was used. Several other researchers utilized the graph or label propagation techniques for solving the problem of opinion word extraction (Rao and Ravichandran, 2009; Speriosu et al., 2011). In (Takamura et al., 2005) authors describe a probabilistic model for assigning polarity</context>
</contexts>
<marker>He, Macdonald, He, Ounis, 2008</marker>
<rawString>Ben He, Craig Macdonald, Jiyin He, and Iadh Ounis. 2008. An effective statistical approach to blog post opinion retrieval. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 1063–1072. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>151--160</pages>
<contexts>
<context position="5849" citStr="Jiang et al., 2011" startWordPosition="892" endWordPosition="895">sing various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method is used as a baseline in our work. 3 Data For the experiments in t</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment classification. In ACL, pages 151–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Maarten de Rijke</author>
<author>Wouter Weerkamp</author>
</authors>
<title>Generating focused topicspecific sentiment lexicons.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>585--594</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Jijkoun, de Rijke, Weerkamp, 2010</marker>
<rawString>Valentin Jijkoun, Maarten de Rijke, and Wouter Weerkamp. 2010. Generating focused topicspecific sentiment lexicons. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 585–594. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efthymios Kouloumpis</author>
<author>Theresa Wilson</author>
<author>Johanna Moore</author>
</authors>
<title>Twitter sentiment analysis: The good the bad and the omg!</title>
<date>2011</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="5829" citStr="Kouloumpis et al., 2011" startWordPosition="888" endWordPosition="891">random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method is used as a baseline in our work. 3 Data For </context>
</contexts>
<marker>Kouloumpis, Wilson, Moore, 2011</marker>
<rawString>Efthymios Kouloumpis, Theresa Wilson, and Johanna Moore. 2011. Twitter sentiment analysis: The good the bad and the omg! In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Cody Dunne</author>
<author>Bonnie Dorr</author>
</authors>
<title>Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing:</booktitle>
<volume>2</volume>
<pages>599--608</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4044" citStr="Mohammad et al., 2009" startWordPosition="606" endWordPosition="609">g and testing: movie review collection for training and large collections of tweets for testing. 2 Related work There are two major approaches for creation of a sentiment lexicon in a specific language: dictionary-based methods and corpus-based methods. 67 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 67–72, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics Dictionary-based methods for various languages have received a lot of attention in the literature (P´erez-Rosas et al., 2012; Mohammad et al., 2009; Clematide and Klenner, 2010), but the main problem of such approaches is that it is difficult to apply them to processing social media. The reason is that short informal texts contain a lot of misspellings and out-of-vocabulary words. Corpus-based methods are more suitable for processing social media data. In such approaches various statistical and linguistic features are used to discriminate opinion words from all other words (He et al., 2008; Jijkoun et al., 2010). Another important group of approaches, which can be both dictionary-based and corpus-based are graph-based methods. In (Veliko</context>
</contexts>
<marker>Mohammad, Dunne, Dorr, 2009</marker>
<rawString>Saif Mohammad, Cody Dunne, and Bonnie Dorr. 2009. Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2, pages 599–608. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ver´onica P´erez-Rosas</author>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
</authors>
<title>Learning sentiment lexicons in spanish.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<pages>3077--3081</pages>
<marker>P´erez-Rosas, Banea, Mihalcea, 2012</marker>
<rawString>Ver´onica P´erez-Rosas, Carmen Banea, and Rada Mihalcea. 2012. Learning sentiment lexicons in spanish. In LREC, pages 3077–3081.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Semisupervised polarity lexicon induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>675--682</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4979" citStr="Rao and Ravichandran, 2009" startWordPosition="751" endWordPosition="754"> In such approaches various statistical and linguistic features are used to discriminate opinion words from all other words (He et al., 2008; Jijkoun et al., 2010). Another important group of approaches, which can be both dictionary-based and corpus-based are graph-based methods. In (Velikovich et al., 2010) a new method for constructing a lexical network was proposed, which aggregates the huge amount of unlabeled data. Then the graph propagation algorithm was used. Several other researchers utilized the graph or label propagation techniques for solving the problem of opinion word extraction (Rao and Ravichandran, 2009; Speriosu et al., 2011). In (Takamura et al., 2005) authors describe a probabilistic model for assigning polarity to each word in a collection. This model is based on the Ising spin model of magnetism and is built upon Markov random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construc</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>Delip Rao and Deepak Ravichandran. 2009. Semisupervised polarity lexicon induction. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 675–682. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Speriosu</author>
<author>Nikita Sudan</author>
<author>Sid Upadhyay</author>
<author>Jason Baldridge</author>
</authors>
<title>Twitter polarity classification with label propagation over lexical links and the follower graph.</title>
<date>2011</date>
<booktitle>In Proceedings of the First workshop on Unsupervised Learning in NLP,</booktitle>
<pages>53--63</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5003" citStr="Speriosu et al., 2011" startWordPosition="755" endWordPosition="758">statistical and linguistic features are used to discriminate opinion words from all other words (He et al., 2008; Jijkoun et al., 2010). Another important group of approaches, which can be both dictionary-based and corpus-based are graph-based methods. In (Velikovich et al., 2010) a new method for constructing a lexical network was proposed, which aggregates the huge amount of unlabeled data. Then the graph propagation algorithm was used. Several other researchers utilized the graph or label propagation techniques for solving the problem of opinion word extraction (Rao and Ravichandran, 2009; Speriosu et al., 2011). In (Takamura et al., 2005) authors describe a probabilistic model for assigning polarity to each word in a collection. This model is based on the Ising spin model of magnetism and is built upon Markov random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A l</context>
</contexts>
<marker>Speriosu, Sudan, Upadhyay, Baldridge, 2011</marker>
<rawString>Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Jason Baldridge. 2011. Twitter polarity classification with label propagation over lexical links and the follower graph. In Proceedings of the First workshop on Unsupervised Learning in NLP, pages 53– 63. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Takamura</author>
<author>T Inui</author>
<author>M Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>133--140</pages>
<contexts>
<context position="5031" citStr="Takamura et al., 2005" startWordPosition="760" endWordPosition="763">eatures are used to discriminate opinion words from all other words (He et al., 2008; Jijkoun et al., 2010). Another important group of approaches, which can be both dictionary-based and corpus-based are graph-based methods. In (Velikovich et al., 2010) a new method for constructing a lexical network was proposed, which aggregates the huge amount of unlabeled data. Then the graph propagation algorithm was used. Several other researchers utilized the graph or label propagation techniques for solving the problem of opinion word extraction (Rao and Ravichandran, 2009; Speriosu et al., 2011). In (Takamura et al., 2005) authors describe a probabilistic model for assigning polarity to each word in a collection. This model is based on the Ising spin model of magnetism and is built upon Markov random field framework, using various dictionary-based and linguistic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has be</context>
<context position="13273" citStr="Takamura et al., 2005" startWordPosition="2045" endWordPosition="2048">orp.ox.ac.uk/ 69 • Negation between sentiment words leads to the opposite polarity labels. 5.1 Algorithm description To formalize all these assumptions we construct an undirected graphical model using extracted sentiment word co-occurrence statistics. Each extracted word is represented by a vertex in a graph and an edge between two vertexes is established in case if they co-occur together more than once in the collection. We drop all the edges where average distance between words is more than 8 words. Our model by construction is similar to approach based on the Ising spin model described in (Takamura et al., 2005). Ising model is used to describe ferromagnetism in statistical mechanics. In general, the system is composed of N binary variables (spins), where each variable xi E {−1, +1}, i = 1, 2, ..., N. The energy function of the system is the following: E(x) = − E Esijxixj − hixi (1) ij i where sij represents the efficacy of interaction between two spins and hi stands for external field added to xi. The probability of each system configuration is provided by Boltzmann distribution: P(X) = exp −βE(X) Z (2) where Z is a normalizing factor and Q = (T−1 &gt; 0) is inverse temperature, which is parameter of t</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>H. Takamura, T. Inui, and M. Okumura. 2005. Extracting semantic orientations of words using spin model. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 133–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Velikovich</author>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
</authors>
<title>The viability of web-derived polarity lexicons.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>777--785</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4662" citStr="Velikovich et al., 2010" startWordPosition="701" endWordPosition="704">, 2009; Clematide and Klenner, 2010), but the main problem of such approaches is that it is difficult to apply them to processing social media. The reason is that short informal texts contain a lot of misspellings and out-of-vocabulary words. Corpus-based methods are more suitable for processing social media data. In such approaches various statistical and linguistic features are used to discriminate opinion words from all other words (He et al., 2008; Jijkoun et al., 2010). Another important group of approaches, which can be both dictionary-based and corpus-based are graph-based methods. In (Velikovich et al., 2010) a new method for constructing a lexical network was proposed, which aggregates the huge amount of unlabeled data. Then the graph propagation algorithm was used. Several other researchers utilized the graph or label propagation techniques for solving the problem of opinion word extraction (Rao and Ravichandran, 2009; Speriosu et al., 2011). In (Takamura et al., 2005) authors describe a probabilistic model for assigning polarity to each word in a collection. This model is based on the Ising spin model of magnetism and is built upon Markov random field framework, using various dictionary-based a</context>
</contexts>
<marker>Velikovich, Blair-Goldensohn, Hannan, McDonald, 2010</marker>
<rawString>Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Hannan, and Ryan McDonald. 2010. The viability of web-derived polarity lexicons. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 777–785. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svitlana Volkova</author>
<author>Theresa Wilson</author>
<author>David Yarowsky</author>
</authors>
<title>Exploring sentiment in social media: Bootstrapping subjectivity clues from multilingual twitter streams.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL13),</booktitle>
<pages>505--510</pages>
<contexts>
<context position="6273" citStr="Volkova et al., 2013" startWordPosition="957" endWordPosition="960"> sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method is used as a baseline in our work. 3 Data For the experiments in this paper we use several collections in two domains: movie review collection in Russian for training and fine-tuning of the proposed algorithms and Twitter collections for evaluation and demonstration of robustness in Russian and English languages. Movie domain. The movie review dataset collected from the online service imhonet.ru. There are 28,773 movie reviews of various genres with numeric scores specified by their au</context>
<context position="7916" citStr="Volkova et al., 2013" startWordPosition="1214" endWordPosition="1217">language: 1M+ of unlabeled tweets (UNL) for extraction of sentiment lexicons, 2K labeled tweets for development data (DEV), and 2K labeled tweets for evaluation (TEST). DEV dataset is used to find the best combination of various lexicons for processing Twitter data and TEST for evaluating the quality of constructed lexicons. The UNL dataset in Russian was collected during one day using Twitter API. These tweets contain various topics without any filtering. Only strict duplicates and retweets were removed from the dataset. The similar collection for English was downloaded using the links from (Volkova et al., 2013). All tweets in DEV and TEST collections are manually labeled by subjectivity and polarity using the Mechanical Turk with five workers (majority voting). This data was used for development and evaluation in (Volkova et al., 2013). 4 Method for sentiment word extraction In this section we introduce an algorithm for sentiment lexicon extraction, which is inspired by the method described in (Chetviorkin and Loukachevitch, 2012), but have more robust features, which allow us to apply it to any unlabeled text collection (e.g. tweets collection). The pro68 posed algorithm is applied to text collecti</context>
<context position="18413" citStr="Volkova et al., 2013" startWordPosition="2950" endWordPosition="2953"> by two assessors. In result of such markup 1734 words with strict positive or negative polarity were taken. The accuracy of the lexicon on the basis of the markup was equal to 72%, which is 1.5 % better than the simple average score baseline. 6 Lexicon Evaluations To evaluate all newly created lexicons they were utilized in tweet polarity and subjectivity classification tasks using the TEST collections. The results of the classification for both languages can be found in Table 3 and Table 4. As one can see, the newly created Twitterspecific sentiment lexicon results outperform the result of (Volkova et al., 2013) in subjectivity classification for Russian but slightly worse than the result for English. On the other hand the results of polarity classification are on par or better Table 3: Quality of tweet subjectivity classification Lexicon P R Fpol Russian Volkova, 2013 - - 73.0 TwitterLex 65.5 82.0 72.8 Combined 65.8 85.5 74.3 English Volkova, 2013 - - 78.0 TwitterLex 72.1 88.1 79.3 Combined 73.2 89.3 80.4 Table 4: Quality of tweet polarity classification than the results of (Volkova et al., 2013) lexicons bootstrapped from domain-independent sentiment lexicons. Thus, to push the quality of polarity </context>
</contexts>
<marker>Volkova, Wilson, Yarowsky, 2013</marker>
<rawString>Svitlana Volkova, Theresa Wilson, and David Yarowsky. 2013. Exploring sentiment in social media: Bootstrapping subjectivity clues from multilingual twitter streams. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL13), pages 505–510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaolong Wang</author>
<author>Furu Wei</author>
<author>Xiaohua Liu</author>
<author>Ming Zhou</author>
<author>Ming Zhang</author>
</authors>
<title>Topic sentiment analysis in twitter: a graph-based hashtag sentiment classification approach.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<pages>1031--1040</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5891" citStr="Wang et al., 2011" startWordPosition="900" endWordPosition="903">ic features. In our research, unlike (Takamura et al., 2005) we use only information contained in a text collection without any external dictionary resources (due to the lack of necessary resources for Russian). Our advantage is that we use only potential domainspecific sentiment words during the construction of the network. A large body of research has been focused on Twitter sentiment analysis during the previous several years (Barbosa and Feng, 2010; Bermingham and Smeaton, 2010; Bifet and Frank, 2010; Davidov et al., 2010; Kouloumpis et al., 2011; Jiang et al., 2011; Agarwal et al., 2011; Wang et al., 2011). In (Chen et al., 2012) authors propose an optimization framework for extraction of opinion expressions from tweets. Using extracted lexicons authors were able to improve the tweet sentiment classification quality. Our approach is based on similar assumptions (like consistency relations), but we do not use any syntactic parsers and dictionary resources. In (Volkova et al., 2013) a new multilingual bootstrapping technique for building tweet sentiment lexicons was introduced. This method is used as a baseline in our work. 3 Data For the experiments in this paper we use several collections in tw</context>
</contexts>
<marker>Wang, Wei, Liu, Zhou, Zhang, 2011</marker>
<rawString>Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou, and Ming Zhang. 2011. Topic sentiment analysis in twitter: a graph-based hashtag sentiment classification approach. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 1031–1040. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on human language technology and empirical methods in natural language processing,</booktitle>
<pages>347--354</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2714" citStr="Wilson et al., 2005" startWordPosition="403" endWordPosition="406">urces are available. Then to demonstrate the robustness of the method and to compare the results with the other approaches we used it for English. The current research can be separated into two steps. We start with a special supervised model based on statistical and linguistic features of sentiment words, which is trained and evaluated in the movie domain. Then this model is utilized for extraction of sentiment words from unlabeled Twitter datasets, which are preliminary filtered using the domain-independent lexicons: ProductSentiRus (Chetviorkin and Loukachevitch, 2012) for Russian and MPQA (Wilson et al., 2005) for English. In the second step an algorithm for polarity classification of extracted sentiment words is introduced. It is built using the Markov random field framework and uses only information contained in text collections. To evaluate the quality of the created lexicons extrinsically, we conduct the experiments on the tweet subjectivity and polarity classification tasks using various lexicons. The key advantage of the proposed two-step algorithm is that once trained it can be utilized to different domains and languages with minor modifications. To demonstrate the ability of the proposed al</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the conference on human language technology and empirical methods in natural language processing, pages 347–354. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>