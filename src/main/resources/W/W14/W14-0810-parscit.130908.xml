<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019421">
<title confidence="0.996667">
Mickey Mouse is not a Phrase: Improving Relevance in E-Commerce with
Multiword Expressions
</title>
<author confidence="0.949838">
Prathyusha Senthil Kumar, Vamsi Salaka, Tracy Holloway King, and Brian Johnson
</author>
<affiliation confidence="0.8634235">
Search Science
eBay, Inc.
</affiliation>
<address confidence="0.690379">
San Jose, CA, USA
</address>
<email confidence="0.960956">
{ prathykumar, vsalaka, tracyking, bjohnson } @ebay.com
</email>
<sectionHeader confidence="0.992101" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999967363636364">
We describe a method for detecting
phrases in e-commerce queries. The key
insight is that previous buyer purchasing
behavior as well as the general distribu-
tion of phrases in item titles must be used
to select phrases. Many multiword ex-
pression (mwe) phrases which might be
useful in other situations are not suitable
for buyer query phrases because relevant
items, as measured by purchases, do not
contain these terms as phrases.
</bodyText>
<sectionHeader confidence="0.952504" genericHeader="method">
1 Phrase MWE in e-Commerce Search
</sectionHeader>
<bodyText confidence="0.999967153846154">
Processing buyers’ queries is key for successful
e-commerce. As with web search queries, e-
commerce queries are shorter and have different
syntactic patterns than standard written language.
For a given query, the system must provide suffi-
cient recall (i.e. return all items relevant to the buy-
ers’ query, regardless of the tokens used) and suffi-
cient precision (i.e. exclude items which are token
matches but not relevant for the query). This paper
looks at how identifying phrases in buyer queries
can help with recall and precision in e-commerce
at eBay. We focus primarily on precision, which
is the harder problem to solve.
Phrases are a sub-type of mwe: one where
the tokens of the mwe appear strictly adjacent to
one another and in a specified order ((Sag et al.,
2002)’s words with spaces).
The eBay product search engine takes buyer
queries and retrieves items relevant to the buyer’s
purchasing intent. The items are listed in cate-
gories (e.g. women’s dresses) and each item has a
title provided by the seller. The buyer can choose
to sort the items by most relevant (e.g. similar
to web search ranking) or deterministically (e.g.
price low to high). There are versions of the e-
commerce site for different countries such as US,
</bodyText>
<page confidence="0.995221">
62
</page>
<bodyText confidence="0.997902">
UK, Germany, France, Poland, etc. and so the
query processing is language-specific according to
site. Here we report on incorporating phrases into
English for the US and German for Germany.
</bodyText>
<sectionHeader confidence="0.798381" genericHeader="method">
2 Controlling Retrieval via Query
Phrases
</sectionHeader>
<bodyText confidence="0.999930142857143">
The query processing system has three core capa-
bilities1 which expand tokens in the buyer’s query
into other forms. Both single and multiple to-
kens can be expanded. Token-to-token expan-
sions (Jammalamadaka and Salaka, 2012) include
acronyms, abbreviations, inflectional variants (e.g.
hats to hat), and space synonyms (e.g. ray ban to
rayban). Category expansions expand tokens to
all items in a given category (e.g. womens shoes
retrieves all items in the Womens’ Shoes cate-
gory). Finally, attribute expansions map tokens
to structured data (e.g. red retrieves any item with
Color=Reds in its structured data). These expan-
sions are used to increase the number of relevant
items brought back for a specific buyer query.
Precision issues occur when a buyer’s query re-
turns an item that is a spurious match. For exam-
ple, the query diamond ring size 10 matches all
the tokens in the title “10 kt gold, size 7 diamond
ring” even though it is not a size 10 ring.
Recall issues occur when relevant items are not
returned for a buyer’s query. The core capabilities
of token-to-token mappings, category mappings,
and attribute mapping largely address this. How-
ever, some query tokens are not covered by these
capabilities. For example, the query used cars for
sale contains the tokens for sale which rarely oc-
cur in e-commerce item titles.
</bodyText>
<footnote confidence="0.998443666666667">
1Here we ignore tokenization, although the quality of the
tokenizer affects the quality of all remaining components
(Manning et al., 2008).
</footnote>
<note confidence="0.791266">
Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 62–66,
Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.984897">
2.1 Hypothesis: Phrasing within Queries
</subsectionHeader>
<bodyText confidence="0.999382214285714">
To address these precision and recall issues, we
provide special treatment for phrases in queries.
To address the precision issue where spurious
items are returned, we require certain token se-
quences to be treated as phrases. For example, size
10 will be phrased and hence only match items
whose titles have those tokens in that order. To
address the recall issue, we identify queries which
contain phrases that can be dropped. For exam-
ple, in the query used cars for sale the tokens for
sale can be dropped; similarly for German kaufen
(buy) in the query waschtrockner kaufen (washer-
dryer buy). For the remainder of the paper we will
use the terminology:
</bodyText>
<listItem confidence="0.9726514">
• REQUIRED PHRASES: Token sequences re-
quired to be phrases when used in queries
(e.g. apple tv)
• DROPPED PHRASES: Phrases which allow
sub-phrase deletion (e.g. used cars for sale)
</listItem>
<bodyText confidence="0.999916909090909">
The required-phrases approach must be high
confidence since it will block items from being re-
turned for the buyer’s query.
We first mined candidate phrases for required
phrases and for dropped phrases in queries. From
this large set of candidates, we then used past
buyer behavior to determine whether the candi-
date was viable for application to queries (see
(Ramisch et al., 2008) on mwe candidate evalu-
ation in general). As we will see, many phrases
which seem to be intuitively well-formed mwe
cannot be used as e-commerce query phrases be-
cause they would block relevant inventory from
being returned (see (Diab et al., 2010) on mwe in
NLP applications).
The phrases which pass candidate selection
are then incorporated into the existing query ex-
pansions (i.e. token-to-token mappings, category
mappings, attribute mappings). The phrases are a
new type of token-to-token mapping which require
the query tokens to appear in order and adjacent,
i.e. as a mwe phrase, or to be dropped.
</bodyText>
<subsectionHeader confidence="0.999679">
2.2 Phrase Candidate Selection
</subsectionHeader>
<bodyText confidence="0.999992078947368">
The first stage of the algorithm is candidate selec-
tion: from all the possible buyer query n-grams we
determine which are potential mwe phrase candi-
dates. We use a straight-forward selection tech-
nique in order to gather a large candidate set; at
this stage we are concerned with recall, not preci-
sion, of the phrases.
First consider required phrases. For a given
site (US and Germany here), we consider all the
bi- and tri-grams seen in buyer queries. Since
e-commerce queries are relatively short, even
shorter than web queries, we do not consider
longer n-grams. The most frequent of these are
then considered candidates. Manual inspection
of the candidate set shows a variety of mwe se-
mantic types. As expected in the e-commerce do-
main, these contain primarily nominal mwe: brand
names, product types, and measure phrases (see
( O´ S´eaghdha and Copestake, 2007) on identifying
nominal mwe). Multiword verbs are non-existent
in buyer queries and relatively few adjectives are
candidates (e.g. navy blue, brand new).
Next consider dropped phrases. These are
stop words specialized to the e-commerce domain.
They are mined from behavioral logs by looking
at query-to-query transitions. We consider query
transitions where buyers drop a word or phrase in
the transition and show increased engagement af-
ter the transition. For example, buyers issue the
query used cars for sale followed by the query
used cars and subsequently engage with the search
results (e.g. view or purchase items). The most fre-
quent n-grams identified by this approach are can-
didates for dropped phrases and are contextually
dropped, i.e. they are dropped when they are parts
of specific larger phrases. Query context is impor-
tant because for sale should not be dropped when
part of the larger phrase plastic for sale signs.
</bodyText>
<subsectionHeader confidence="0.998026">
2.3 Phrase Selection: Sorry Mickey
</subsectionHeader>
<bodyText confidence="0.9999138125">
Once we have candidate phrases, we use buyer
behavioral data (Carterette et al., 2012) to deter-
mine which phrases to require in buyer queries.
For each query which contains a given phrase (e.g.
for the candidate phrase apple tv consider queries
such as apple tv, new apple tv, apple tv remote)
we see which items were purchased. Item titles
from purchased items which contain the phrase
are referred to as “phrase bought” while item ti-
tles shown in searches are “phrase impressed”. We
are interested only in high confidence phrases and
so focus on purchase behavior: this signal is rela-
tively sparse but is the strongest indicator of buyer
interest. To determine the candidates, we want to
compute the conditional probability of an item be-
ing bought (B(ought)) given a phrase (Ph(rase)).
</bodyText>
<equation confidence="0.999061">
P(B|Ph) = P(P |PB)P∗)(B) (1)
</equation>
<page confidence="0.981048">
63
</page>
<bodyText confidence="0.99993375">
However, this is computationally intensive in that
all items retrieved for a query must be considered.
In equation 1, P(Ph|B) is easy to compute since
only bought items are considered; P(Ph) can be ap-
proximated by the ratio of phrases to non-phrases
for bought items; P(B) is a constant and hence can
be ignored. So, we use the following two metrics
based on these probabilities:
</bodyText>
<listItem confidence="0.985604428571429">
• SALE EFFICIENCY: Probability of phrases in
bought items, P(Ph|B) &gt; 95%. Ensures qual-
ity and acts as an upper bound for the ex-
pected loss (equation 2).
• LIFT: Ensures phrasing has a positive rev-
enue impact and handles presentation bias
(equation 3).
</listItem>
<bodyText confidence="0.407491">
First consider sale efficiency:
</bodyText>
<equation confidence="0.999287">
P(P h�B) n(ph bought)
P(Ph|B) = P (B) = n(bought) (2)
</equation>
<bodyText confidence="0.999988535714286">
One drawback of sale efficiency P(Ph|B) is data
sparsity. There is a high false positive rate in
identifying phrases when the frequency of bought
items is low since it is hard to distinguish sig-
nal from noise with a strict threshold. We used
Beta-Binomial smoothing to avoid this (Schuck-
ers, 2003; Agarwal et al., 2009). Conceptually,
by incorporating Beta-Binomial smoothing, we
model the number of phrases bought as a binomial
process and use the Beta distribution, which is its
conjugate prior, for smoothing the sale efficiency.
However the sale efficiency as captured by the
conditional probability of being bought as a phrase
(equation 2) does not take into account the dis-
tribution of the phrases in the retrieved set. For
example for the phrase apple tv, 80% of the im-
pressed items contained the phrase while 99%
of the bought items contained the phrase, which
makes it an excellent phrase. However, for mount
rushmore 99% of the impressed items contained
the phrase while only 97% of the bought items
contained the phrase. This implies that the proba-
bility of being bought as a phrase for mount rush-
more is high because of presentation bias (i.e. the
vast majority of token matches contain phrases)
and not because the phrase itself is an indicator
of relevance. To address the issue of presentation
bias in P(Ph|B), we use the following lift metric:
</bodyText>
<equation confidence="0.9992175">
P(Ph|B) − P(Ph) &gt; 0 (3)
P(Ph)
</equation>
<bodyText confidence="0.999835333333333">
Lift (equation 3) measures the buyers’ tendency
to purchase phrase items. For a good phrase this
value should be high. For example, for apple tv
this value is +23.13% while for mount rushmore it
is −1.8%. We only consider phrases that have a
positive lift.
Examples of English phrases for buyer queries
include apple tv, bubble wrap, playstation 3, 4 x
4, tank top, nexus 4, rose gold, 1 gb, hot pack, 20
v, kindle fire, hard rock and new balance and Ger-
man phrases include geflochtene schnur (braided
line) and energiespar regler (energy-saving con-
troller). These form a disparate semantic set in-
cluding brand names (new balance), product types
(bubble wrap), and units of measure (1 gb).
Consider the phrases which were not selected
because a significant percentage of the buyer de-
mand was for items where the tokens appeared
either in a different order or not adjacent. These
include golf balls, hard drive and mickey mouse.
You might ask, what could possibly be a stronger
phrase in American English than mickey mouse?
Closer examination of the buyer behavioral data
shows that many buyers are using queries with the
tokens mickey mouse to find and purchase mickey
and minnie mouse items. The introduction of and
minnie in the item titles breaks the query phrase.
</bodyText>
<sectionHeader confidence="0.977354" genericHeader="evaluation">
3 Experiment Results
</sectionHeader>
<bodyText confidence="0.998590833333333">
We selected phrase candidates for two sites: The
US and Germany. These sites were selected be-
cause there was significant query and purchasing
data which alleviates data sparsity issues and be-
cause the language differences allowed us to test
the general applicability of the approach.2
We created query assets which contained the
existing production assets and modified them to
include the required phrases and the dropped
phrases. The relative query frequency of required
phrases (blue) vs. dropped phrases (red) in each
experiment is shown in Figure 2.
</bodyText>
<figureCaption confidence="0.975238">
Figure 2: Impacted Query Frequency: red=drop-
ped; blue=required
</figureCaption>
<bodyText confidence="0.730397">
For US and Germany, 10% of users were ex-
</bodyText>
<footnote confidence="0.816955">
2English and German are closely related languages. We
plan to apply mwe phrases to Russian and French.
US Germany
</footnote>
<page confidence="0.989653">
64
</page>
<figureCaption confidence="0.999806">
Figure 1: US Phrase Query Impressions: Head-vs.-tail queries
</figureCaption>
<bodyText confidence="0.99994456">
posed to the new phrase assets, while a 10% con-
trol3 were exposed to the existing production as-
sets. The test was run for two weeks. We mea-
sured the number of items bought in test vs. con-
trol, the revenue, and the behavior of new users.
Bought items and revenue are both measured to
determine whether changes in purchases are com-
ing from better deals (e.g. bought items might in-
crease while revenue is constant) or improved dis-
covery (e.g. more items are bought at the same
price). New user success is measured because new
users are generally sensitive to irrelevant items be-
ing returned for their queries; the required phrase
mwe in this experiment target this use case.
As a result of the phrase experiment, in the
US, revenue, bought items, and new user engage-
ment increased statistically significantly (p&lt;0.1).
The German test showed directionally similar re-
sults but was only statistically significant for new
buyers. We cannot show proprietary business re-
sults, but both experiences are now in production
in place of the previous query processing. The
graph in Figure 1 shows the distribution of head-
vs.-tail queries for the US with some sample af-
fected head queries.
</bodyText>
<sectionHeader confidence="0.998936" genericHeader="conclusions">
4 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.982080951219512">
We described a relatively straight-forward method
for detecting phrases in buyer queries. The key
insight is that previous buyer purchasing behavior
as well as the distribution of phrases in item titles
must be used to select which candidate phrases
to keep in the final analysis. Many mwe phrases
which might be useful in other situations (e.g.
3Technically there were two 5% controls which were
compared to determine variability within the control group.
our friend mickey mouse (§2.3)) are not suitable
for buyer queries because many relevant items, as
measured by purchases, do not contain these to-
kens phrases (e.g. mickey and minnie mouse).
Among the rejected candidate phrases, the
higher confidence ones are likely to be suitable for
ranking of the results even though they could not
be used to filter out results. This is an area of ac-
tive research: what mwe phrases can improve the
ranking of e-commerce results, especially given
the presence of the phrase in the buyer query?
Another method to increase phrase coverage is to
consider contextualized phrases, whereby token
sequences may be a phrase in one query but not
in another.
The experiments here were conducted on two
of our largest sites, thereby avoiding data spar-
sity issues. We have used the same algorithm
on smaller sites such as Australia: the resulting
required phrases and dropped phrases look rea-
sonable but have not been tested experimentally.
An interesting question is whether phrases from
same-language sites (e.g. UK, Australia, Canada,
US) can be combined or whether a site with more
behavioral data can be used to learn phrases for
smaller sites. The later has been done for Canada
using US data.
In sum, mwe phrases improved eBay e-
commerce, but it was important to use domain-
specific data in choosing the relevant phrases. This
suggests that the utility of universal vs. domain
specific mwe is an area requiring investigation.
</bodyText>
<page confidence="0.999497">
65
</page>
<sectionHeader confidence="0.998342" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997362710526316">
Deepak Agarwal, Bee-Chung Chen, and Pradheep
Elango. 2009. Spatio-temporal models for esti-
mating click-through rate. In Proceedings of the
18th International Conference on World Wide Web.
ACM.
Ben Carterette, Evangelos Kanoulas, Paul Clough, and
Mark Sanderson, editors. 2012. Information Re-
trieval Over Query Sessions. Springer Lecture
Notes in Computer Science.
Mona Diab, Valia Kordoni, and Hans Uszkoreit. 2010.
Multiword expressions: From theory to applica-
tions. Panel at MWE2010.
Ravi Chandra Jammalamadaka and Vamsi Salaka.
2012. Synonym mining and usage in e-commerce.
Presented at ECIR.
Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Sch¨utze. 2008. Introduction to Information
Retrieval. Cambridge University Press.
Diarmuid O´ S´eaghdha and Ann Copestake. 2007. Co-
occurrence contexts for noun compound interpreta-
tion. In Proceedings of the Workshop on A Broader
Perspective on Multiword Expressions, pages 57–64.
Association for Computational Linguistics.
Carlos Ramisch, Paulo Schreiner, Marco Idiart, and
Aline Villavicencio. 2008. An evaluation of meth-
ods for the extraction of multiword expressions. In
Towards a Shared Task for Multiword Expressions,
pages 50–53.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann A.
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the Third International Conference on
Computational Linguistics and Intelligent Text Pro-
cessing, CICLing ’02, pages 1–15. Springer-Verlag.
Michael E. Schuckers. 2003. Using the beta-binomial
distribution to assess performance of a biometric
identification device. International Journal of Im-
age and Graphics, pages 523–529.
</reference>
<page confidence="0.988349">
66
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.094473">
<title confidence="0.9975445">Mickey Mouse is not a Phrase: Improving Relevance in E-Commerce with Multiword Expressions</title>
<author confidence="0.997432">Senthil Kumar</author>
<author confidence="0.997432">Vamsi Salaka</author>
<author confidence="0.997432">Tracy Holloway King</author>
<affiliation confidence="0.493733">Search eBay,</affiliation>
<address confidence="0.576354">San Jose, CA,</address>
<email confidence="0.837969">vsalaka,tracyking,bjohnson</email>
<abstract confidence="0.998324355263158">We describe a method for detecting phrases in e-commerce queries. The key insight is that previous buyer purchasing behavior as well as the general distribution of phrases in item titles must be used to select phrases. Many multiword expression (mwe) phrases which might be useful in other situations are not suitable for buyer query phrases because relevant items, as measured by purchases, do not contain these terms as phrases. 1 Phrase MWE in e-Commerce Search Processing buyers’ queries is key for successful e-commerce. As with web search queries, ecommerce queries are shorter and have different syntactic patterns than standard written language. For a given query, the system must provide sufficient recall (i.e. return all items relevant to the buyers’ query, regardless of the tokens used) and sufficient precision (i.e. exclude items which are token matches but not relevant for the query). This paper looks at how identifying phrases in buyer queries can help with recall and precision in e-commerce at eBay. We focus primarily on precision, which is the harder problem to solve. Phrases are a sub-type of mwe: one where the tokens of the mwe appear strictly adjacent to one another and in a specified order ((Sag et al., 2002)’s words with spaces). The eBay product search engine takes buyer queries and retrieves items relevant to the buyer’s purchasing intent. The items are listed in categories (e.g. women’s dresses) and each item has a title provided by the seller. The buyer can choose to sort the items by most relevant (e.g. similar to web search ranking) or deterministically (e.g. price low to high). There are versions of the ecommerce site for different countries such as US, 62 UK, Germany, France, Poland, etc. and so the query processing is language-specific according to site. Here we report on incorporating phrases into English for the US and German for Germany. 2 Controlling Retrieval via Query Phrases The query processing system has three core capawhich expand tokens in the buyer’s query into other forms. Both single and multiple tokens can be expanded. Token-to-token expansions (Jammalamadaka and Salaka, 2012) include acronyms, abbreviations, inflectional variants (e.g. and space synonyms (e.g. ban Category expansions expand tokens to items in a given category (e.g. shoes retrieves all items in the Womens’ Shoes category). Finally, attribute expansions map tokens structured data (e.g. any item with Color=Reds in its structured data). These expansions are used to increase the number of relevant items brought back for a specific buyer query. Precision issues occur when a buyer’s query returns an item that is a spurious match. For examthe query ring size 10 all the tokens in the title “10 kt gold, size 7 diamond ring” even though it is not a size 10 ring. Recall issues occur when relevant items are not returned for a buyer’s query. The core capabilities of token-to-token mappings, category mappings, and attribute mapping largely address this. However, some query tokens are not covered by these For example, the query cars for the tokens sale rarely occur in e-commerce item titles. we ignore tokenization, although the quality of the tokenizer affects the quality of all remaining components</abstract>
<note confidence="0.8529928">(Manning et al., 2008). of the 10th Workshop on Multiword Expressions (MWE pages 62–66, Sweden, 26-27 April 2014. Association for Computational Linguistics 2.1 Hypothesis: Phrasing within Queries To address these precision and recall issues, we</note>
<abstract confidence="0.997338011904762">provide special treatment for phrases in queries. To address the precision issue where spurious items are returned, we require certain token seto be treated as phrases. For example, be phrased and hence only match items whose titles have those tokens in that order. To address the recall issue, we identify queries which contain phrases that can be dropped. For examin the query cars for sale tokens be dropped; similarly for German in the query kaufen (washerdryer buy). For the remainder of the paper we will use the terminology: • Token sequences required to be phrases when used in queries • Phrases which allow deletion (e.g. cars for The required-phrases approach must be high confidence since it will block items from being returned for the buyer’s query. We first mined candidate phrases for required phrases and for dropped phrases in queries. From this large set of candidates, we then used past buyer behavior to determine whether the candidate was viable for application to queries (see (Ramisch et al., 2008) on mwe candidate evaluation in general). As we will see, many phrases which seem to be intuitively well-formed mwe cannot be used as e-commerce query phrases because they would block relevant inventory from being returned (see (Diab et al., 2010) on mwe in NLP applications). The phrases which pass candidate selection are then incorporated into the existing query expansions (i.e. token-to-token mappings, category mappings, attribute mappings). The phrases are a new type of token-to-token mapping which require the query tokens to appear in order and adjacent, i.e. as a mwe phrase, or to be dropped. 2.2 Phrase Candidate Selection The first stage of the algorithm is candidate selection: from all the possible buyer query n-grams we determine which are potential mwe phrase candidates. We use a straight-forward selection technique in order to gather a large candidate set; at this stage we are concerned with recall, not precision, of the phrases. First consider required phrases. For a given site (US and Germany here), we consider all the biand tri-grams seen in buyer queries. Since e-commerce queries are relatively short, even shorter than web queries, we do not consider longer n-grams. The most frequent of these are then considered candidates. Manual inspection of the candidate set shows a variety of mwe semantic types. As expected in the e-commerce domain, these contain primarily nominal mwe: brand names, product types, and measure phrases (see ( O´ S´eaghdha and Copestake, 2007) on identifying nominal mwe). Multiword verbs are non-existent in buyer queries and relatively few adjectives are (e.g. blue, brand Next consider dropped phrases. These are stop words specialized to the e-commerce domain. They are mined from behavioral logs by looking at query-to-query transitions. We consider query transitions where buyers drop a word or phrase in the transition and show increased engagement after the transition. For example, buyers issue the cars for sale by the query cars subsequently engage with the search results (e.g. view or purchase items). The most frequent n-grams identified by this approach are candidates for dropped phrases and are contextually dropped, i.e. they are dropped when they are parts of specific larger phrases. Query context is imporbecause sale not be dropped when of the larger phrase for sale 2.3 Phrase Selection: Sorry Mickey Once we have candidate phrases, we use buyer behavioral data (Carterette et al., 2012) to determine which phrases to require in buyer queries. For each query which contains a given phrase (e.g. the candidate phrase tv queries as apple tv we see which items were purchased. Item titles from purchased items which contain the phrase are referred to as “phrase bought” while item titles shown in searches are “phrase impressed”. We are interested only in high confidence phrases and so focus on purchase behavior: this signal is relatively sparse but is the strongest indicator of buyer interest. To determine the candidates, we want to compute the conditional probability of an item being bought (B(ought)) given a phrase (Ph(rase)). = (1) 63 However, this is computationally intensive in that all items retrieved for a query must be considered. equation 1, is easy to compute since only bought items are considered; P(Ph) can be approximated by the ratio of phrases to non-phrases for bought items; P(B) is a constant and hence can be ignored. So, we use the following two metrics based on these probabilities: • Probability of phrases in items, Ensures quality and acts as an upper bound for the expected loss (equation 2). • Ensures phrasing has a positive revenue impact and handles presentation bias (equation 3). First consider sale efficiency: = P = drawback of sale efficiency is data sparsity. There is a high false positive rate in identifying phrases when the frequency of bought items is low since it is hard to distinguish signal from noise with a strict threshold. We used Beta-Binomial smoothing to avoid this (Schuckers, 2003; Agarwal et al., 2009). Conceptually, by incorporating Beta-Binomial smoothing, we model the number of phrases bought as a binomial process and use the Beta distribution, which is its conjugate prior, for smoothing the sale efficiency. However the sale efficiency as captured by the conditional probability of being bought as a phrase (equation 2) does not take into account the distribution of the phrases in the retrieved set. For for the phrase 80% of the impressed items contained the phrase while 99% of the bought items contained the phrase, which it an excellent phrase. However, for of the impressed items contained the phrase while only 97% of the bought items contained the phrase. This implies that the probaof being bought as a phrase for rushhigh because of presentation bias (i.e. the vast majority of token matches contain phrases) and not because the phrase itself is an indicator of relevance. To address the issue of presentation in we use the following lift metric: − &gt; Lift (equation 3) measures the buyers’ tendency to purchase phrase items. For a good phrase this should be high. For example, for tv value is +23.13% while for rushmore We only consider phrases that have a positive lift. Examples of English phrases for buyer queries tv, bubble wrap, playstation 3, 4 x 4, tank top, nexus 4, rose gold, 1 gb, hot pack, 20 kindle fire, hard rock balance Gerphrases include schnur and regler controller). These form a disparate semantic set inbrand names product types and units of measure Consider the phrases which were not selected because a significant percentage of the buyer demand was for items where the tokens appeared either in a different order or not adjacent. These balls, hard drive You might ask, what could possibly be a stronger in American English than Closer examination of the buyer behavioral data shows that many buyers are using queries with the mouse find and purchase</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Deepak Agarwal</author>
<author>Bee-Chung Chen</author>
<author>Pradheep Elango</author>
</authors>
<title>Spatio-temporal models for estimating click-through rate.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th International Conference on World Wide Web.</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="9441" citStr="Agarwal et al., 2009" startWordPosition="1548" endWordPosition="1551">rases in bought items, P(Ph|B) &gt; 95%. Ensures quality and acts as an upper bound for the expected loss (equation 2). • LIFT: Ensures phrasing has a positive revenue impact and handles presentation bias (equation 3). First consider sale efficiency: P(P h�B) n(ph bought) P(Ph|B) = P (B) = n(bought) (2) One drawback of sale efficiency P(Ph|B) is data sparsity. There is a high false positive rate in identifying phrases when the frequency of bought items is low since it is hard to distinguish signal from noise with a strict threshold. We used Beta-Binomial smoothing to avoid this (Schuckers, 2003; Agarwal et al., 2009). Conceptually, by incorporating Beta-Binomial smoothing, we model the number of phrases bought as a binomial process and use the Beta distribution, which is its conjugate prior, for smoothing the sale efficiency. However the sale efficiency as captured by the conditional probability of being bought as a phrase (equation 2) does not take into account the distribution of the phrases in the retrieved set. For example for the phrase apple tv, 80% of the impressed items contained the phrase while 99% of the bought items contained the phrase, which makes it an excellent phrase. However, for mount r</context>
</contexts>
<marker>Agarwal, Chen, Elango, 2009</marker>
<rawString>Deepak Agarwal, Bee-Chung Chen, and Pradheep Elango. 2009. Spatio-temporal models for estimating click-through rate. In Proceedings of the 18th International Conference on World Wide Web. ACM.</rawString>
</citation>
<citation valid="true">
<date>2012</date>
<booktitle>Information Retrieval Over Query Sessions. Springer Lecture Notes in Computer Science.</booktitle>
<editor>Ben Carterette, Evangelos Kanoulas, Paul Clough, and Mark Sanderson, editors.</editor>
<marker>2012</marker>
<rawString>Ben Carterette, Evangelos Kanoulas, Paul Clough, and Mark Sanderson, editors. 2012. Information Retrieval Over Query Sessions. Springer Lecture Notes in Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Valia Kordoni</author>
<author>Hans Uszkoreit</author>
</authors>
<title>Multiword expressions: From theory to applications. Panel at MWE2010.</title>
<date>2010</date>
<contexts>
<context position="5362" citStr="Diab et al., 2010" startWordPosition="873" endWordPosition="876">ed-phrases approach must be high confidence since it will block items from being returned for the buyer’s query. We first mined candidate phrases for required phrases and for dropped phrases in queries. From this large set of candidates, we then used past buyer behavior to determine whether the candidate was viable for application to queries (see (Ramisch et al., 2008) on mwe candidate evaluation in general). As we will see, many phrases which seem to be intuitively well-formed mwe cannot be used as e-commerce query phrases because they would block relevant inventory from being returned (see (Diab et al., 2010) on mwe in NLP applications). The phrases which pass candidate selection are then incorporated into the existing query expansions (i.e. token-to-token mappings, category mappings, attribute mappings). The phrases are a new type of token-to-token mapping which require the query tokens to appear in order and adjacent, i.e. as a mwe phrase, or to be dropped. 2.2 Phrase Candidate Selection The first stage of the algorithm is candidate selection: from all the possible buyer query n-grams we determine which are potential mwe phrase candidates. We use a straight-forward selection technique in order t</context>
</contexts>
<marker>Diab, Kordoni, Uszkoreit, 2010</marker>
<rawString>Mona Diab, Valia Kordoni, and Hans Uszkoreit. 2010. Multiword expressions: From theory to applications. Panel at MWE2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Chandra Jammalamadaka</author>
<author>Vamsi Salaka</author>
</authors>
<title>Synonym mining and usage in e-commerce. Presented at ECIR.</title>
<date>2012</date>
<contexts>
<context position="2438" citStr="Jammalamadaka and Salaka, 2012" startWordPosition="393" endWordPosition="396">st relevant (e.g. similar to web search ranking) or deterministically (e.g. price low to high). There are versions of the ecommerce site for different countries such as US, 62 UK, Germany, France, Poland, etc. and so the query processing is language-specific according to site. Here we report on incorporating phrases into English for the US and German for Germany. 2 Controlling Retrieval via Query Phrases The query processing system has three core capabilities1 which expand tokens in the buyer’s query into other forms. Both single and multiple tokens can be expanded. Token-to-token expansions (Jammalamadaka and Salaka, 2012) include acronyms, abbreviations, inflectional variants (e.g. hats to hat), and space synonyms (e.g. ray ban to rayban). Category expansions expand tokens to all items in a given category (e.g. womens shoes retrieves all items in the Womens’ Shoes category). Finally, attribute expansions map tokens to structured data (e.g. red retrieves any item with Color=Reds in its structured data). These expansions are used to increase the number of relevant items brought back for a specific buyer query. Precision issues occur when a buyer’s query returns an item that is a spurious match. For example, the </context>
</contexts>
<marker>Jammalamadaka, Salaka, 2012</marker>
<rawString>Ravi Chandra Jammalamadaka and Vamsi Salaka. 2012. Synonym mining and usage in e-commerce. Presented at ECIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Ann Copestake</author>
</authors>
<title>Cooccurrence contexts for noun compound interpretation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions,</booktitle>
<pages>57--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>S´eaghdha, Copestake, 2007</marker>
<rawString>Diarmuid O´ S´eaghdha and Ann Copestake. 2007. Cooccurrence contexts for noun compound interpretation. In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 57–64. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
<author>Paulo Schreiner</author>
<author>Marco Idiart</author>
<author>Aline Villavicencio</author>
</authors>
<title>An evaluation of methods for the extraction of multiword expressions. In Towards a Shared Task for Multiword Expressions,</title>
<date>2008</date>
<pages>50--53</pages>
<contexts>
<context position="5115" citStr="Ramisch et al., 2008" startWordPosition="831" endWordPosition="834">or the remainder of the paper we will use the terminology: • REQUIRED PHRASES: Token sequences required to be phrases when used in queries (e.g. apple tv) • DROPPED PHRASES: Phrases which allow sub-phrase deletion (e.g. used cars for sale) The required-phrases approach must be high confidence since it will block items from being returned for the buyer’s query. We first mined candidate phrases for required phrases and for dropped phrases in queries. From this large set of candidates, we then used past buyer behavior to determine whether the candidate was viable for application to queries (see (Ramisch et al., 2008) on mwe candidate evaluation in general). As we will see, many phrases which seem to be intuitively well-formed mwe cannot be used as e-commerce query phrases because they would block relevant inventory from being returned (see (Diab et al., 2010) on mwe in NLP applications). The phrases which pass candidate selection are then incorporated into the existing query expansions (i.e. token-to-token mappings, category mappings, attribute mappings). The phrases are a new type of token-to-token mapping which require the query tokens to appear in order and adjacent, i.e. as a mwe phrase, or to be drop</context>
</contexts>
<marker>Ramisch, Schreiner, Idiart, Villavicencio, 2008</marker>
<rawString>Carlos Ramisch, Paulo Schreiner, Marco Idiart, and Aline Villavicencio. 2008. An evaluation of methods for the extraction of multiword expressions. In Towards a Shared Task for Multiword Expressions, pages 50–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann A Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Computational Linguistics and Intelligent Text Processing, CICLing ’02,</booktitle>
<pages>1--15</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="1518" citStr="Sag et al., 2002" startWordPosition="243" endWordPosition="246">than standard written language. For a given query, the system must provide sufficient recall (i.e. return all items relevant to the buyers’ query, regardless of the tokens used) and sufficient precision (i.e. exclude items which are token matches but not relevant for the query). This paper looks at how identifying phrases in buyer queries can help with recall and precision in e-commerce at eBay. We focus primarily on precision, which is the harder problem to solve. Phrases are a sub-type of mwe: one where the tokens of the mwe appear strictly adjacent to one another and in a specified order ((Sag et al., 2002)’s words with spaces). The eBay product search engine takes buyer queries and retrieves items relevant to the buyer’s purchasing intent. The items are listed in categories (e.g. women’s dresses) and each item has a title provided by the seller. The buyer can choose to sort the items by most relevant (e.g. similar to web search ranking) or deterministically (e.g. price low to high). There are versions of the ecommerce site for different countries such as US, 62 UK, Germany, France, Poland, etc. and so the query processing is language-specific according to site. Here we report on incorporating p</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann A. Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the Third International Conference on Computational Linguistics and Intelligent Text Processing, CICLing ’02, pages 1–15. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael E Schuckers</author>
</authors>
<title>Using the beta-binomial distribution to assess performance of a biometric identification device.</title>
<date>2003</date>
<journal>International Journal of Image and Graphics,</journal>
<pages>523--529</pages>
<contexts>
<context position="9418" citStr="Schuckers, 2003" startWordPosition="1545" endWordPosition="1547">Probability of phrases in bought items, P(Ph|B) &gt; 95%. Ensures quality and acts as an upper bound for the expected loss (equation 2). • LIFT: Ensures phrasing has a positive revenue impact and handles presentation bias (equation 3). First consider sale efficiency: P(P h�B) n(ph bought) P(Ph|B) = P (B) = n(bought) (2) One drawback of sale efficiency P(Ph|B) is data sparsity. There is a high false positive rate in identifying phrases when the frequency of bought items is low since it is hard to distinguish signal from noise with a strict threshold. We used Beta-Binomial smoothing to avoid this (Schuckers, 2003; Agarwal et al., 2009). Conceptually, by incorporating Beta-Binomial smoothing, we model the number of phrases bought as a binomial process and use the Beta distribution, which is its conjugate prior, for smoothing the sale efficiency. However the sale efficiency as captured by the conditional probability of being bought as a phrase (equation 2) does not take into account the distribution of the phrases in the retrieved set. For example for the phrase apple tv, 80% of the impressed items contained the phrase while 99% of the bought items contained the phrase, which makes it an excellent phras</context>
</contexts>
<marker>Schuckers, 2003</marker>
<rawString>Michael E. Schuckers. 2003. Using the beta-binomial distribution to assess performance of a biometric identification device. International Journal of Image and Graphics, pages 523–529.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>