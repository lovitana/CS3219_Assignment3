<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000122">
<title confidence="0.9959415">
The DCU-ICTCAS MT system at WMT 2014 on German-English
Translation Task
</title>
<author confidence="0.914459">
Liangyou Li∗, Xiaofeng Wu∗, Santiago Cort´es Va´ıllo∗
Jun Xie†, Andy Way∗, Qun Liu∗†
</author>
<affiliation confidence="0.9633">
∗ CNGL Centre for Global Intelligent Content, School of Computing
Dublin City University, Dublin 9, Ireland
† Key Laboratory of Intelligent Information Processing, Institute of Computing Technology
Chinese Academy of Sciences, Beijing, China
</affiliation>
<email confidence="0.9864065">
{liangyouli,xiaofengwu,scortes,away,qliu}@computing.dcu.ie
xiejun@ict.ac.cn
</email>
<sectionHeader confidence="0.995503" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999726272727273">
This paper describes the DCU submis-
sion to WMT 2014 on German-English
translation task. Our system uses phrase-
based translation model with several pop-
ular techniques, including Lexicalized
Reordering Model, Operation Sequence
Model and Language Model interpolation.
Our final submission is the result of sys-
tem combination on several systems which
have different pre-processing and align-
ments.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9968318">
On the German-English translation task of WMT
2014, we submitted a system which is built with
Moses phrase-based model (Koehn et al., 2007).
For system training, we use all provided
German-English parallel data, and conducted sev-
eral pre-processing steps to clean the data. In ad-
dition, in order to improve the translation quali-
ty, we adopted some popular techniques, includ-
ing three Lexicalized Reordering Models (Axel-
rod et al., 2005; Galley and Manning, 2008), a 9-
gram Operation Sequence Model (Durrani et al.,
2011) and Language Model interpolation on sev-
eral datasets. And then we use system combina-
tion on several systems with different settings to
produce the final outputs.
Our phrase-based systems are tuned with k-best
MIRA (Cherry and Foster, 2012) on development
set. We set the maximum iteration to be 25.
The Language Models in our systems are
trained with SRILM (Stolcke, 2002). We trained
</bodyText>
<table confidence="0.979792">
Corpus Filtered Out (%)
Bilingual 7.17
Monolingual (English) 1.05
</table>
<tableCaption confidence="0.8491725">
Table 1: Results of language detection: percentage
of filtered out sentences
</tableCaption>
<bodyText confidence="0.986147555555556">
a 5-gram model with Kneser-Ney discounting
(Chen and Goodman, 1996).
In the next sections, we will describe our system
in detail. In section 2, we will explain our pre-
processing steps on corpus. Then in section 3, we
will describe some techniques we have tried for
this task and the experiment results. In section 4,
our final configuration for submitted system will
be presented. And we conclude in the last section.
</bodyText>
<sectionHeader confidence="0.824186" genericHeader="introduction">
2 Pre-processing
</sectionHeader>
<bodyText confidence="0.992389176470588">
We use all the training data for German-English
translation, including Europarl, News Commen-
tary and Common Crawl. The first thing we no-
ticed is that some Non-German and Non-English
sentences are included in our training data. So we
apply Language Detection (Shuyo, 2010) for both
monolingual and bilingual corpora. For mono-
lingual data (only including English sentences in
our task), we filter out sentences which are detect-
ed as other language with probability more than
0.999995. And for bilingual data, A sentence
pair is filtered out if the language detector detect-
s a different language with probability more than
0.999995 on either the source or the target. The
filtering results are given in Table 1.
In our experiment, German compound word-
s are splitted based on frequency (Koehn and
</bodyText>
<page confidence="0.983092">
136
</page>
<bodyText confidence="0.751787222222222">
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 136–141,
Baltimore, Maryland USA, June 26–27, 2014. c�2014 Association for Computational Linguistics
Knight, 2003). In addition, for both monolingual
and bilingual data, we apply tokenization, nor-
malizing punctuation and truecasing using Moses
scripts. For parallel training data, we also filter out
sentence pairs containing more than 80 tokens on
either side and sentence pairs whose length ratio
between source and target side is larger than 3.
</bodyText>
<sectionHeader confidence="0.99685" genericHeader="method">
3 Techniques
</sectionHeader>
<bodyText confidence="0.999755882352941">
In our preliminary experiments, we take newstest
2013 as our test data and newstest 2008-2012 as
our development data. In total, we have more
than 10,000 sentences for tuning. The tuning step
would be very time-consuming if we use them al-
l. So in this section, we use Feature Decay Al-
gorithm (FDA) (Bic¸ici and Yuret, 2014) to select
2000 sentences as our development set. Table 2
shows that system performance does not increase
with larger tuning set and the system using only
2K sentences selected by FDA is better than the
baseline tuned with all the development data.
In this section, alignment model is trained
by MGIZA++ (Gao and Vogel, 2008) with
grow-diag-final-and heuristic function.
And other settings are mostly default values in
Moses.
</bodyText>
<subsectionHeader confidence="0.997472">
3.1 Lexicalized Reordering Model
</subsectionHeader>
<bodyText confidence="0.968033823529412">
German and English have different word order
which brings a challenge in German-English ma-
chine translation. In our system, we adopt three
Lexicalized Reordering Models (LRMs) for ad-
dressing this problem. They are word-based LRM
(wLRM), phrase-based LRM (pLRM) and hierar-
chal LRM (hLRM).
These three models have different effect on the
translation. Word-based and phrase-based LRMs
are focus on local reordering phenomenon, while
hierarchical LRM could be applied into longer re-
ordering problem. Figure 1 shows the differences
(Galley and Manning, 2008). And Table 3 shows
effectiveness of different LRMs.
In our system based on Moses, we
use wbe-msd-bidirectional-fe,
phrase-msd-bidirectional-fe and
</bodyText>
<listItem confidence="0.852339307692308">
hier-mslr-bidirectional-fe to specify
these three LRMs. From Table 2, we could see
that LRMs significantly improves the translation.
Figure 1: Occurrence of a swap according to
the three orientation models: word-based, phrase-
based, and hierarchical. Black squares represen-
t word alignments, and gray squares represen-
t blocks identified by phrase-extract. In (a), block
bz = (ez, fa,z) is recognized as a swap according to
all three models. In (b), bz is not recognized as a
swap by the word-based model. In (c), bz is rec-
ognized as a swap only by the hierarchical model.
(Galley and Manning, 2008)
</listItem>
<subsectionHeader confidence="0.998002">
3.2 Operation Sequence Model
</subsectionHeader>
<bodyText confidence="0.9996202">
The Operation Sequence Model (OSM) (Durrani
et al., 2011) explains the translation procedure as
a linear sequence of operations which generates
source and target sentences in parallel. Durrani
et al. (2011) defined four translation operations:
Generate(X,Y), Continue Source Concept, Gener-
ate Source Only (X) and Generate Identical, as
well as three reordering operations: Insert Gap,
Jump Back(W) and Jump Forward. These oper-
ations are described as follows.
</bodyText>
<listItem confidence="0.998707235294118">
• Generate(X,Y) make the words in Y and the
first word in X added to target and source
string respectively.
• Continue Source Concept adds the word in
the queue from Generate(X,Y) to the source
string.
• Generate Source Only (X) puts X in the
source string at the current position.
• Generate Identical generates the same word
for both sides.
• Insert Gap inserts a gap in the source side for
future use.
• Jump Back (W) makes the position for trans-
lation be the Wth closest gap to the current
position.
• Jump Forward moves the position to the in-
dex after the right-most source word.
</listItem>
<page confidence="0.991951">
137
</page>
<table confidence="0.9996097">
Systems Tuning Set newstest 2013
Baseline – 24.1
+FDA – 24.2
+LRMs 24.0 25.4
+OSM 24.4 26.2
+LM Interpolation 24.6 26.4
+Factored Model – 25.9
+Sparse Feature 25.6 25.9
+TM Combination 24.1 25.4
+OSM Interpolation 24.4 26.0
</table>
<tableCaption confidence="0.950105">
Table 2: Preliminary results on tuning set and test set (newstest 2013). All scores on test set are case-
sensitive BLEU[%] scores. And scores on tuning set are case-insensitive BLEU[%] directly from tuning
result. Baseline uses all the data from newstest 2008-2012 for tuning.
</tableCaption>
<table confidence="0.999551428571429">
Systems Tuning Set (uncased) newstest 2013
Baseline+FDA – 24.2
+wLRM 23.8 25.1
+pLRM 23.9 25.2
+hLRM 24.0 25.4
+pLRM 23.8 25.1
+hLRM 23.7 25.2
</table>
<tableCaption confidence="0.999623">
Table 3: System BLEU[%] scores when different LRMs are adopted.
</tableCaption>
<bodyText confidence="0.711168">
The probability of an operation sequence O =
</bodyText>
<equation confidence="0.98197125">
(o1o2 ··· oJ) is:
J
p(O) = p(oj|oj−n+1 ··· oj−1) (1)
j=1
</equation>
<bodyText confidence="0.999967571428572">
where n indicates the number of previous opera-
tions used.
In this paper we train a 9-gram OSM on train-
ing data and integrate this model directly into log-
linear framework (OSM is now available to use
in Moses). Our experiment shows OSM improves
our system by about 0.8 BLEU (see Table 2).
</bodyText>
<subsectionHeader confidence="0.988777">
3.3 Language Model Interpolation
</subsectionHeader>
<bodyText confidence="0.9959485625">
In our baseline, Language Model (LM) is trained
on all the monolingual data provided. In this sec-
tion, we try to build a large language model by in-
cluding data from English Gigaword fifth edition
(only taking partial data with size of 1.6G), En-
glish side of UN corpus and English side of 109
French-English corpus. Instead of training a s-
ingle model on all data, we interpolate language
models trained on each subset (monolingual data
provided is splitted into three parts: News 2007-
2013, Europarl and News Commentary) by tuning
weights to minimize perplexity of language model
measured on the target side of development set.
In our experiment, after interpolation, the lan-
guage model doesn’t get a much lower perplexity,
but it slightly improves the system, as shown in
</bodyText>
<tableCaption confidence="0.565583">
Table 2.
</tableCaption>
<subsectionHeader confidence="0.964686">
3.4 Other Tries
</subsectionHeader>
<bodyText confidence="0.9999456">
In addition to the techniques mentioned above, we
also try some other approaches. Unfortunately al-
l of these methods described in this section are
non-effective in our experiments. The results are
shown in Table 2.
</bodyText>
<listItem confidence="0.761572083333333">
• Factored Model (Koehn and Hoang, 2007):
We tried to integrate a target POS factored
model into our system with a 9-gram POS
language model to address the problem of
word selection and word order. But ex-
periment doesn’t show improvement. The
English POS is from Stanford POS Tagger
(Toutanova et al., 2003).
• Translation Model Combination: In this ex-
periment, we try to use the method of (Sen-
nrich, 2012) to combine phrase tables or re-
ordering tables from different subsets of data
</listItem>
<page confidence="0.994637">
138
</page>
<bodyText confidence="0.999795727272727">
to minimize perplexity measured on develop-
ment set. We try to split the training data in
two ways. One is according to data source,
resulting in three subsets: Europarl, News
Commentary and Common Crawl. Another
one is to use data selection. We use FDA to
select 200K sentence pairs as in-domain data
and the rest as out-domain data. Unfortunate-
ly both experiments failed. In Table 2, we on-
ly report results of phrase table combination
on FDA-based data sets.
</bodyText>
<listItem confidence="0.7840795">
• OSM Interpolation: Since OSM in our sys-
tem could be taken as a special language
</listItem>
<bodyText confidence="0.948633857142857">
model, we try to use the idea of interpolation
similar with language model to make OSM
adapted to some data. Training data are s-
plitted into two subsets with FDA. We train
9-gram OSM on each subsets and interpolate
them according to OSM trained on the devel-
opment set.
</bodyText>
<listItem confidence="0.892267">
• Sparse Features: For each source phrase,
</listItem>
<bodyText confidence="0.6282991875">
there is usually more than one corresponding
translation option. Each different translation
may be optimal in different contexts. Thus
in our systems, similar to (He et al., 2008)
which proposed a Maximum Entropy-based
rule selection for the hierarchical phrase-
based model, features which describe the
context of phrases, are designed to select the
right translation. But different with (He et
al., 2008), we use sparse features to mod-
el the context. And instead of using syn-
tactic POS, we adopt independent POS-like
features: cluster ID of word. In our experi-
ment mkcls was used to cluster words into 50
groups. And all features are generalized to
cluster ID.
</bodyText>
<sectionHeader confidence="0.996703" genericHeader="method">
4 Submission
</sectionHeader>
<bodyText confidence="0.997721538461539">
Based on our preliminary experiments in the sec-
tion above, we use LRMs, OSM and LM inter-
polation in our final system for newstest 2014.
But as we find that Language Models trained on
UN corpus and 109 French-English corpus have
a very high perplexity and in order to speed up
the translation by reducing the model size, in this
section, we interpolate only three language model-
s from monolingual data provided, English Giga-
word fifth edition and target side of training data.
In addition, we also try some different methods for
final submission. And the results are shown in Ta-
ble 4.
</bodyText>
<listItem confidence="0.9979445">
• Development Set Selection: Instead of using
FDA which is dependent on test set, we use
the method of (Nadejde et al., 2013) to se-
lect tuning set from newstest 2008-2013 for
the final system. We only keep 2K sentences
which have more than 30 words and higher
BLEU score. The experiment result is shown
in Table 4 ( The system is indicated as Base-
line).
•
</listItem>
<bodyText confidence="0.9594244">
Pre-processing: In our preliminary exper-
iments, sentences are tokenized without
changing hyphen. Thus we build another sys-
tem where all the hyphens are tokenized ag-
gressively.
</bodyText>
<listItem confidence="0.939006166666667">
• SyMGIZA++: Better alignment could lead to
better translation. So we carry out some ex-
periments on SyMGIZA++ aligner (Junczys-
Dowmunt and Sza, 2012), which modifies the
original IBM/GIZA++ word alignment mod-
els to allow to update the symmetrized mod-
els between chosen iterations of the original
training algorithms. Experiment shows this
new alignment improves translation quality.
• Multi-alignment Selection: We also try to use
multi-alignment selection (Tu et al., 2012)
to generate a ”better” alignment from three
alignmens: MGIZA++ with function grow-
diag-final-and, SyMGIZA++ with function
grow-diag-final-and and fast alignment (Dy-
er et al., 2013). Although this method show
comparable or better result on development
set, it fails on test set.
</listItem>
<bodyText confidence="0.999990111111111">
Since we build a few systems with different
setting on Moses phrase-based model, a straight-
forward thinking is to obtain the better transla-
tion from several different translation systems. So
we use system combination (Heafield and Lavie,
2010) on the 1-best outputs of three systems (in-
dicated with ∗ in table 4). And this results in our
best system so far, as shown in Table 4. In our final
submission, this result is taken as primary.
</bodyText>
<sectionHeader confidence="0.995813" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9922995">
This paper describes our submitted system to
WMT 2014 in detail. This system is based on
</bodyText>
<page confidence="0.997187">
139
</page>
<table confidence="0.999589125">
Systems Tuning Set newstest 2014
Baseline* 34.2 25.6
+SyMGIZA++* 34.3 26.0
+Multi-Alignment Selection 34.4 25.6
+Hyphen-Splitted 33.9 25.9
+SyMGIZA++* 34.0 26.0
+Multi-Alignment Selection 34.0 25.7
System Combination – 26.5
</table>
<tableCaption confidence="0.69827125">
Table 4: Experiment results on newstest 2014. We report case-sensitive BLEU[%] score on test set and
case-insensitive BLEU[%] on tuning set which is directly from tuning result. Baseline is the phrase-based
system with LRMs, OSM and LM interpolation on smaller datasets, tuned with selected development set.
Systems indicated with * are used for system combination.
</tableCaption>
<bodyText confidence="0.919570833333333">
Moses phrase-based model, and integrates Lexi-
calized Reordering Models, Operation Sequence
Model and Language Model interpolation. Al-
so system combination is used on several system-
s which have different pre-processing and align-
ment.
</bodyText>
<sectionHeader confidence="0.985582" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999917571428571">
This work is supported by EC Marie-Curie initial
training Network EXPERT (EXPloiting Empiri-
cal appRoaches to Translation) project (http:
//expert-itn.eu). Thanks to Johannes Lev-
eling for his help on German compound splitting.
And thanks to Jia Xu and Jian Zhang for their ad-
vice and help on this paper and experiments.
</bodyText>
<sectionHeader confidence="0.990862" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996901935483871">
Amittai Axelrod, Ra Birch Mayne, Chris Callison-
burch, Miles Osborne, and David Talbot. 2005. Ed-
inburgh system description for the 2005 iwslt speech
translation evaluation. In Proceedings of the Inter-
national Workshop on Spoken Language Translation
(IWSLT).
Ergun Bic¸ici and Deniz Yuret. 2014. Optimizing in-
stance selection for statistical machine translation
with feature decay algorithms. IEEE/ACM Transac-
tions On Audio, Speech, and Language Processing
(TASLP).
Stanley F. Chen and Joshua Goodman. 1996. An em-
pirical study of smoothing techniques for language
modeling. In Proceedings of the 34th Annual Meet-
ing on Association for Computational Linguistics,
ACL ’96, pages 310–318, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, NAA-
CL HLT ’12, pages 427–436, Stroudsburg, PA, US-
A. Association for Computational Linguistics.
Nadir Durrani, Helmut Schmid, and Alexander Fraser.
2011. A joint sequence translation model with in-
tegrated reordering. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies - Vol-
ume 1, HLT ’11, pages 1045–1054, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of ibm model 2. In Proceedings of NAACL.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 848–856, Honolulu, Hawaii, October. As-
sociation for Computational Linguistics.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ’08, pages 49–
57, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving statistical machine translation using lexical-
ized rule selection. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (Coling 2008), pages 321–328, Manchester, UK,
August. Coling 2008 Organizing Committee.
Kenneth Heafield and Alon Lavie. 2010. Combining
machine translation output with open source: The
Carnegie Mellon multi-engine machine translation
scheme. The Prague Bulletin of Mathematical Lin-
guistics, 93:27–36, January.
Marcin Junczys-Dowmunt and Arkadiusz Sza. 2012.
Symgiza++: Symmetrized word alignment models
for statistical machine translation. In Pascal Bouvry,
MieczysawA. Kopotek, Franck Leprvost, Magorza-
ta Marciniak, Agnieszka Mykowiecka, and Henryk
</reference>
<page confidence="0.97217">
140
</page>
<reference confidence="0.999832263157895">
Rybiski, editors, Security and Intelligent Informa-
tion Systems, volume 7053 of Lecture Notes in Com-
puter Science, pages 379–390. Springer Berlin Hei-
delberg.
Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 868–876.
Philipp Koehn and Kevin Knight. 2003. Empirical
methods for compound splitting. In Proceedings of
the Tenth Conference on European Chapter of the
Association for Computational Linguistics - Volume
1, EACL ’03, pages 187–193, Stroudsburg, PA, US-
A. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertol-
di, Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 177–180, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Maria Nadejde, Philip Williams, and Philipp Koehn.
2013. Edinburgh’s syntax-based machine transla-
tion systems. In Proceedings of the Eighth Work-
shop on Statistical Machine Translation, pages 170–
176, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Rico Sennrich. 2012. Perplexity minimization for
translation model domain adaptation in statistical
machine translation. In Proceedings of the 13th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 539–549,
Avignon, France, April. Association for Computa-
tional Linguistics.
Nakatani Shuyo. 2010. Language detection library for
java.
Andreas Stolcke. 2002. Srilm – an extensible language
modeling toolkit. In Proceedings of the Internation-
al Conference Spoken Language Processing, pages
901–904, Denver, CO.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology
- Volume 1, NAACL ’03, pages 173–180, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Zhaopeng Tu, Yang Liu, Yifan He, Josef van Genabith,
Qun Liu, and Shouxun Lin. 2012. Combining mul-
tiple alignments to improve machine translation. In
COLING (Posters), pages 1249–1260.
</reference>
<page confidence="0.998259">
141
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.597490">
<title confidence="0.974158666666667">The DCU-ICTCAS MT system at WMT 2014 on Translation Task Xiaofeng Santiago Cort´es</title>
<author confidence="0.999757">Andy Qun</author>
<affiliation confidence="0.944483">Centre for Global Intelligent Content, School of Dublin City University, Dublin 9, Laboratory of Intelligent Information Processing, Institute of Computing Chinese Academy of Sciences, Beijing,</affiliation>
<email confidence="0.978855">xiejun@ict.ac.cn</email>
<abstract confidence="0.985951666666667">This paper describes the DCU submission to WMT 2014 on German-English translation task. Our system uses phrasebased translation model with several popular techniques, including Lexicalized Reordering Model, Operation Sequence Model and Language Model interpolation. Our final submission is the result of system combination on several systems which have different pre-processing and alignments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amittai Axelrod</author>
<author>Ra Birch Mayne</author>
<author>Chris Callisonburch</author>
<author>Miles Osborne</author>
<author>David Talbot</author>
</authors>
<title>Edinburgh system description for the 2005 iwslt speech translation evaluation.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation (IWSLT).</booktitle>
<contexts>
<context position="1328" citStr="Axelrod et al., 2005" startWordPosition="184" endWordPosition="188">e Model and Language Model interpolation. Our final submission is the result of system combination on several systems which have different pre-processing and alignments. 1 Introduction On the German-English translation task of WMT 2014, we submitted a system which is built with Moses phrase-based model (Koehn et al., 2007). For system training, we use all provided German-English parallel data, and conducted several pre-processing steps to clean the data. In addition, in order to improve the translation quality, we adopted some popular techniques, including three Lexicalized Reordering Models (Axelrod et al., 2005; Galley and Manning, 2008), a 9- gram Operation Sequence Model (Durrani et al., 2011) and Language Model interpolation on several datasets. And then we use system combination on several systems with different settings to produce the final outputs. Our phrase-based systems are tuned with k-best MIRA (Cherry and Foster, 2012) on development set. We set the maximum iteration to be 25. The Language Models in our systems are trained with SRILM (Stolcke, 2002). We trained Corpus Filtered Out (%) Bilingual 7.17 Monolingual (English) 1.05 Table 1: Results of language detection: percentage of filtered</context>
</contexts>
<marker>Axelrod, Mayne, Callisonburch, Osborne, Talbot, 2005</marker>
<rawString>Amittai Axelrod, Ra Birch Mayne, Chris Callisonburch, Miles Osborne, and David Talbot. 2005. Edinburgh system description for the 2005 iwslt speech translation evaluation. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ergun Bic¸ici</author>
<author>Deniz Yuret</author>
</authors>
<title>Optimizing instance selection for statistical machine translation with feature decay algorithms.</title>
<date>2014</date>
<journal>IEEE/ACM Transactions On Audio, Speech, and Language Processing (TASLP).</journal>
<marker>Bic¸ici, Yuret, 2014</marker>
<rawString>Ergun Bic¸ici and Deniz Yuret. 2014. Optimizing instance selection for statistical machine translation with feature decay algorithms. IEEE/ACM Transactions On Audio, Speech, and Language Processing (TASLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting on Association for Computational Linguistics, ACL ’96,</booktitle>
<pages>310--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2010" citStr="Chen and Goodman, 1996" startWordPosition="292" endWordPosition="295">odel (Durrani et al., 2011) and Language Model interpolation on several datasets. And then we use system combination on several systems with different settings to produce the final outputs. Our phrase-based systems are tuned with k-best MIRA (Cherry and Foster, 2012) on development set. We set the maximum iteration to be 25. The Language Models in our systems are trained with SRILM (Stolcke, 2002). We trained Corpus Filtered Out (%) Bilingual 7.17 Monolingual (English) 1.05 Table 1: Results of language detection: percentage of filtered out sentences a 5-gram model with Kneser-Ney discounting (Chen and Goodman, 1996). In the next sections, we will describe our system in detail. In section 2, we will explain our preprocessing steps on corpus. Then in section 3, we will describe some techniques we have tried for this task and the experiment results. In section 4, our final configuration for submitted system will be presented. And we conclude in the last section. 2 Pre-processing We use all the training data for German-English translation, including Europarl, News Commentary and Common Crawl. The first thing we noticed is that some Non-German and Non-English sentences are included in our training data. So we</context>
</contexts>
<marker>Chen, Goodman, 1996</marker>
<rawString>Stanley F. Chen and Joshua Goodman. 1996. An empirical study of smoothing techniques for language modeling. In Proceedings of the 34th Annual Meeting on Association for Computational Linguistics, ACL ’96, pages 310–318, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>George Foster</author>
</authors>
<title>Batch tuning strategies for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12,</booktitle>
<pages>427--436</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1654" citStr="Cherry and Foster, 2012" startWordPosition="237" endWordPosition="240">7). For system training, we use all provided German-English parallel data, and conducted several pre-processing steps to clean the data. In addition, in order to improve the translation quality, we adopted some popular techniques, including three Lexicalized Reordering Models (Axelrod et al., 2005; Galley and Manning, 2008), a 9- gram Operation Sequence Model (Durrani et al., 2011) and Language Model interpolation on several datasets. And then we use system combination on several systems with different settings to produce the final outputs. Our phrase-based systems are tuned with k-best MIRA (Cherry and Foster, 2012) on development set. We set the maximum iteration to be 25. The Language Models in our systems are trained with SRILM (Stolcke, 2002). We trained Corpus Filtered Out (%) Bilingual 7.17 Monolingual (English) 1.05 Table 1: Results of language detection: percentage of filtered out sentences a 5-gram model with Kneser-Ney discounting (Chen and Goodman, 1996). In the next sections, we will describe our system in detail. In section 2, we will explain our preprocessing steps on corpus. Then in section 3, we will describe some techniques we have tried for this task and the experiment results. In secti</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12, pages 427–436, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadir Durrani</author>
<author>Helmut Schmid</author>
<author>Alexander Fraser</author>
</authors>
<title>A joint sequence translation model with integrated reordering.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>1045--1054</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1414" citStr="Durrani et al., 2011" startWordPosition="199" endWordPosition="202">m combination on several systems which have different pre-processing and alignments. 1 Introduction On the German-English translation task of WMT 2014, we submitted a system which is built with Moses phrase-based model (Koehn et al., 2007). For system training, we use all provided German-English parallel data, and conducted several pre-processing steps to clean the data. In addition, in order to improve the translation quality, we adopted some popular techniques, including three Lexicalized Reordering Models (Axelrod et al., 2005; Galley and Manning, 2008), a 9- gram Operation Sequence Model (Durrani et al., 2011) and Language Model interpolation on several datasets. And then we use system combination on several systems with different settings to produce the final outputs. Our phrase-based systems are tuned with k-best MIRA (Cherry and Foster, 2012) on development set. We set the maximum iteration to be 25. The Language Models in our systems are trained with SRILM (Stolcke, 2002). We trained Corpus Filtered Out (%) Bilingual 7.17 Monolingual (English) 1.05 Table 1: Results of language detection: percentage of filtered out sentences a 5-gram model with Kneser-Ney discounting (Chen and Goodman, 1996). In</context>
<context position="5879" citStr="Durrani et al., 2011" startWordPosition="905" endWordPosition="908">ble 2, we could see that LRMs significantly improves the translation. Figure 1: Occurrence of a swap according to the three orientation models: word-based, phrasebased, and hierarchical. Black squares represent word alignments, and gray squares represent blocks identified by phrase-extract. In (a), block bz = (ez, fa,z) is recognized as a swap according to all three models. In (b), bz is not recognized as a swap by the word-based model. In (c), bz is recognized as a swap only by the hierarchical model. (Galley and Manning, 2008) 3.2 Operation Sequence Model The Operation Sequence Model (OSM) (Durrani et al., 2011) explains the translation procedure as a linear sequence of operations which generates source and target sentences in parallel. Durrani et al. (2011) defined four translation operations: Generate(X,Y), Continue Source Concept, Generate Source Only (X) and Generate Identical, as well as three reordering operations: Insert Gap, Jump Back(W) and Jump Forward. These operations are described as follows. • Generate(X,Y) make the words in Y and the first word in X added to target and source string respectively. • Continue Source Concept adds the word in the queue from Generate(X,Y) to the source stri</context>
</contexts>
<marker>Durrani, Schmid, Fraser, 2011</marker>
<rawString>Nadir Durrani, Helmut Schmid, and Alexander Fraser. 2011. A joint sequence translation model with integrated reordering. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 1045–1054, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Victor Chahuneau</author>
<author>Noah A Smith</author>
</authors>
<title>A simple, fast, and effective reparameterization of ibm model 2.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="12798" citStr="Dyer et al., 2013" startWordPosition="2071" endWordPosition="2075"> lead to better translation. So we carry out some experiments on SyMGIZA++ aligner (JunczysDowmunt and Sza, 2012), which modifies the original IBM/GIZA++ word alignment models to allow to update the symmetrized models between chosen iterations of the original training algorithms. Experiment shows this new alignment improves translation quality. • Multi-alignment Selection: We also try to use multi-alignment selection (Tu et al., 2012) to generate a ”better” alignment from three alignmens: MGIZA++ with function growdiag-final-and, SyMGIZA++ with function grow-diag-final-and and fast alignment (Dyer et al., 2013). Although this method show comparable or better result on development set, it fails on test set. Since we build a few systems with different setting on Moses phrase-based model, a straightforward thinking is to obtain the better translation from several different translation systems. So we use system combination (Heafield and Lavie, 2010) on the 1-best outputs of three systems (indicated with ∗ in table 4). And this results in our best system so far, as shown in Table 4. In our final submission, this result is taken as primary. 5 Conclusion This paper describes our submitted system to WMT 201</context>
</contexts>
<marker>Dyer, Chahuneau, Smith, 2013</marker>
<rawString>Chris Dyer, Victor Chahuneau, and Noah A. Smith. 2013. A simple, fast, and effective reparameterization of ibm model 2. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>A simple and effective hierarchical phrase reordering model.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>848--856</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="1355" citStr="Galley and Manning, 2008" startWordPosition="189" endWordPosition="192">odel interpolation. Our final submission is the result of system combination on several systems which have different pre-processing and alignments. 1 Introduction On the German-English translation task of WMT 2014, we submitted a system which is built with Moses phrase-based model (Koehn et al., 2007). For system training, we use all provided German-English parallel data, and conducted several pre-processing steps to clean the data. In addition, in order to improve the translation quality, we adopted some popular techniques, including three Lexicalized Reordering Models (Axelrod et al., 2005; Galley and Manning, 2008), a 9- gram Operation Sequence Model (Durrani et al., 2011) and Language Model interpolation on several datasets. And then we use system combination on several systems with different settings to produce the final outputs. Our phrase-based systems are tuned with k-best MIRA (Cherry and Foster, 2012) on development set. We set the maximum iteration to be 25. The Language Models in our systems are trained with SRILM (Stolcke, 2002). We trained Corpus Filtered Out (%) Bilingual 7.17 Monolingual (English) 1.05 Table 1: Results of language detection: percentage of filtered out sentences a 5-gram mod</context>
<context position="5047" citStr="Galley and Manning, 2008" startWordPosition="775" endWordPosition="778">gs are mostly default values in Moses. 3.1 Lexicalized Reordering Model German and English have different word order which brings a challenge in German-English machine translation. In our system, we adopt three Lexicalized Reordering Models (LRMs) for addressing this problem. They are word-based LRM (wLRM), phrase-based LRM (pLRM) and hierarchal LRM (hLRM). These three models have different effect on the translation. Word-based and phrase-based LRMs are focus on local reordering phenomenon, while hierarchical LRM could be applied into longer reordering problem. Figure 1 shows the differences (Galley and Manning, 2008). And Table 3 shows effectiveness of different LRMs. In our system based on Moses, we use wbe-msd-bidirectional-fe, phrase-msd-bidirectional-fe and hier-mslr-bidirectional-fe to specify these three LRMs. From Table 2, we could see that LRMs significantly improves the translation. Figure 1: Occurrence of a swap according to the three orientation models: word-based, phrasebased, and hierarchical. Black squares represent word alignments, and gray squares represent blocks identified by phrase-extract. In (a), block bz = (ez, fa,z) is recognized as a swap according to all three models. In (b), bz i</context>
</contexts>
<marker>Galley, Manning, 2008</marker>
<rawString>Michel Galley and Christopher D. Manning. 2008. A simple and effective hierarchical phrase reordering model. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 848–856, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4360" citStr="Gao and Vogel, 2008" startWordPosition="675" endWordPosition="678">ts, we take newstest 2013 as our test data and newstest 2008-2012 as our development data. In total, we have more than 10,000 sentences for tuning. The tuning step would be very time-consuming if we use them all. So in this section, we use Feature Decay Algorithm (FDA) (Bic¸ici and Yuret, 2014) to select 2000 sentences as our development set. Table 2 shows that system performance does not increase with larger tuning set and the system using only 2K sentences selected by FDA is better than the baseline tuned with all the development data. In this section, alignment model is trained by MGIZA++ (Gao and Vogel, 2008) with grow-diag-final-and heuristic function. And other settings are mostly default values in Moses. 3.1 Lexicalized Reordering Model German and English have different word order which brings a challenge in German-English machine translation. In our system, we adopt three Lexicalized Reordering Models (LRMs) for addressing this problem. They are word-based LRM (wLRM), phrase-based LRM (pLRM) and hierarchal LRM (hLRM). These three models have different effect on the translation. Word-based and phrase-based LRMs are focus on local reordering phenomenon, while hierarchical LRM could be applied in</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08, pages 49– 57, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongjun He</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Improving statistical machine translation using lexicalized rule selection.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>321--328</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="10534" citStr="He et al., 2008" startWordPosition="1698" endWordPosition="1701"> table combination on FDA-based data sets. • OSM Interpolation: Since OSM in our system could be taken as a special language model, we try to use the idea of interpolation similar with language model to make OSM adapted to some data. Training data are splitted into two subsets with FDA. We train 9-gram OSM on each subsets and interpolate them according to OSM trained on the development set. • Sparse Features: For each source phrase, there is usually more than one corresponding translation option. Each different translation may be optimal in different contexts. Thus in our systems, similar to (He et al., 2008) which proposed a Maximum Entropy-based rule selection for the hierarchical phrasebased model, features which describe the context of phrases, are designed to select the right translation. But different with (He et al., 2008), we use sparse features to model the context. And instead of using syntactic POS, we adopt independent POS-like features: cluster ID of word. In our experiment mkcls was used to cluster words into 50 groups. And all features are generalized to cluster ID. 4 Submission Based on our preliminary experiments in the section above, we use LRMs, OSM and LM interpolation in our f</context>
</contexts>
<marker>He, Liu, Lin, 2008</marker>
<rawString>Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Improving statistical machine translation using lexicalized rule selection. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 321–328, Manchester, UK, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Alon Lavie</author>
</authors>
<title>Combining machine translation output with open source: The Carnegie Mellon multi-engine machine translation scheme.</title>
<date>2010</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>93--27</pages>
<contexts>
<context position="13139" citStr="Heafield and Lavie, 2010" startWordPosition="2126" endWordPosition="2129">ion quality. • Multi-alignment Selection: We also try to use multi-alignment selection (Tu et al., 2012) to generate a ”better” alignment from three alignmens: MGIZA++ with function growdiag-final-and, SyMGIZA++ with function grow-diag-final-and and fast alignment (Dyer et al., 2013). Although this method show comparable or better result on development set, it fails on test set. Since we build a few systems with different setting on Moses phrase-based model, a straightforward thinking is to obtain the better translation from several different translation systems. So we use system combination (Heafield and Lavie, 2010) on the 1-best outputs of three systems (indicated with ∗ in table 4). And this results in our best system so far, as shown in Table 4. In our final submission, this result is taken as primary. 5 Conclusion This paper describes our submitted system to WMT 2014 in detail. This system is based on 139 Systems Tuning Set newstest 2014 Baseline* 34.2 25.6 +SyMGIZA++* 34.3 26.0 +Multi-Alignment Selection 34.4 25.6 +Hyphen-Splitted 33.9 25.9 +SyMGIZA++* 34.0 26.0 +Multi-Alignment Selection 34.0 25.7 System Combination – 26.5 Table 4: Experiment results on newstest 2014. We report case-sensitive BLEU[</context>
</contexts>
<marker>Heafield, Lavie, 2010</marker>
<rawString>Kenneth Heafield and Alon Lavie. 2010. Combining machine translation output with open source: The Carnegie Mellon multi-engine machine translation scheme. The Prague Bulletin of Mathematical Linguistics, 93:27–36, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcin Junczys-Dowmunt</author>
<author>Arkadiusz Sza</author>
</authors>
<title>Symgiza++: Symmetrized word alignment models for statistical machine translation.</title>
<date>2012</date>
<journal>In Pascal Bouvry, MieczysawA. Kopotek, Franck Leprvost, Magorzata Marciniak, Agnieszka Mykowiecka, and Henryk</journal>
<marker>Junczys-Dowmunt, Sza, 2012</marker>
<rawString>Marcin Junczys-Dowmunt and Arkadiusz Sza. 2012. Symgiza++: Symmetrized word alignment models for statistical machine translation. In Pascal Bouvry, MieczysawA. Kopotek, Franck Leprvost, Magorzata Marciniak, Agnieszka Mykowiecka, and Henryk</rawString>
</citation>
<citation valid="false">
<authors>
<author>editors Rybiski</author>
</authors>
<title>Security and Intelligent Information Systems,</title>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>7053</volume>
<pages>379--390</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Rybiski, </marker>
<rawString>Rybiski, editors, Security and Intelligent Information Systems, volume 7053 of Lecture Notes in Computer Science, pages 379–390. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868--876</pages>
<contexts>
<context position="9053" citStr="Koehn and Hoang, 2007" startWordPosition="1441" endWordPosition="1444">ata provided is splitted into three parts: News 2007- 2013, Europarl and News Commentary) by tuning weights to minimize perplexity of language model measured on the target side of development set. In our experiment, after interpolation, the language model doesn’t get a much lower perplexity, but it slightly improves the system, as shown in Table 2. 3.4 Other Tries In addition to the techniques mentioned above, we also try some other approaches. Unfortunately all of these methods described in this section are non-effective in our experiments. The results are shown in Table 2. • Factored Model (Koehn and Hoang, 2007): We tried to integrate a target POS factored model into our system with a 9-gram POS language model to address the problem of word selection and word order. But experiment doesn’t show improvement. The English POS is from Stanford POS Tagger (Toutanova et al., 2003). • Translation Model Combination: In this experiment, we try to use the method of (Sennrich, 2012) to combine phrase tables or reordering tables from different subsets of data 138 to minimize perplexity measured on development set. We try to split the training data in two ways. One is according to data source, resulting in three s</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868–876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In Proceedings of the Tenth Conference on European Chapter of the Association for Computational Linguistics - Volume 1, EACL ’03,</booktitle>
<pages>187--193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Empirical methods for compound splitting. In Proceedings of the Tenth Conference on European Chapter of the Association for Computational Linguistics - Volume 1, EACL ’03, pages 187–193, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1032" citStr="Koehn et al., 2007" startWordPosition="138" endWordPosition="141">aofengwu,scortes,away,qliu}@computing.dcu.ie xiejun@ict.ac.cn Abstract This paper describes the DCU submission to WMT 2014 on German-English translation task. Our system uses phrasebased translation model with several popular techniques, including Lexicalized Reordering Model, Operation Sequence Model and Language Model interpolation. Our final submission is the result of system combination on several systems which have different pre-processing and alignments. 1 Introduction On the German-English translation task of WMT 2014, we submitted a system which is built with Moses phrase-based model (Koehn et al., 2007). For system training, we use all provided German-English parallel data, and conducted several pre-processing steps to clean the data. In addition, in order to improve the translation quality, we adopted some popular techniques, including three Lexicalized Reordering Models (Axelrod et al., 2005; Galley and Manning, 2008), a 9- gram Operation Sequence Model (Durrani et al., 2011) and Language Model interpolation on several datasets. And then we use system combination on several systems with different settings to produce the final outputs. Our phrase-based systems are tuned with k-best MIRA (Ch</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 177–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Nadejde</author>
<author>Philip Williams</author>
<author>Philipp Koehn</author>
</authors>
<title>Edinburgh’s syntax-based machine translation systems.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<pages>170--176</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="11738" citStr="Nadejde et al., 2013" startWordPosition="1906" endWordPosition="1909">polation in our final system for newstest 2014. But as we find that Language Models trained on UN corpus and 109 French-English corpus have a very high perplexity and in order to speed up the translation by reducing the model size, in this section, we interpolate only three language models from monolingual data provided, English Gigaword fifth edition and target side of training data. In addition, we also try some different methods for final submission. And the results are shown in Table 4. • Development Set Selection: Instead of using FDA which is dependent on test set, we use the method of (Nadejde et al., 2013) to select tuning set from newstest 2008-2013 for the final system. We only keep 2K sentences which have more than 30 words and higher BLEU score. The experiment result is shown in Table 4 ( The system is indicated as Baseline). • Pre-processing: In our preliminary experiments, sentences are tokenized without changing hyphen. Thus we build another system where all the hyphens are tokenized aggressively. • SyMGIZA++: Better alignment could lead to better translation. So we carry out some experiments on SyMGIZA++ aligner (JunczysDowmunt and Sza, 2012), which modifies the original IBM/GIZA++ word</context>
</contexts>
<marker>Nadejde, Williams, Koehn, 2013</marker>
<rawString>Maria Nadejde, Philip Williams, and Philipp Koehn. 2013. Edinburgh’s syntax-based machine translation systems. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 170– 176, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rico Sennrich</author>
</authors>
<title>Perplexity minimization for translation model domain adaptation in statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>539--549</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Avignon, France,</location>
<contexts>
<context position="9419" citStr="Sennrich, 2012" startWordPosition="1506" endWordPosition="1508">ition to the techniques mentioned above, we also try some other approaches. Unfortunately all of these methods described in this section are non-effective in our experiments. The results are shown in Table 2. • Factored Model (Koehn and Hoang, 2007): We tried to integrate a target POS factored model into our system with a 9-gram POS language model to address the problem of word selection and word order. But experiment doesn’t show improvement. The English POS is from Stanford POS Tagger (Toutanova et al., 2003). • Translation Model Combination: In this experiment, we try to use the method of (Sennrich, 2012) to combine phrase tables or reordering tables from different subsets of data 138 to minimize perplexity measured on development set. We try to split the training data in two ways. One is according to data source, resulting in three subsets: Europarl, News Commentary and Common Crawl. Another one is to use data selection. We use FDA to select 200K sentence pairs as in-domain data and the rest as out-domain data. Unfortunately both experiments failed. In Table 2, we only report results of phrase table combination on FDA-based data sets. • OSM Interpolation: Since OSM in our system could be take</context>
</contexts>
<marker>Sennrich, 2012</marker>
<rawString>Rico Sennrich. 2012. Perplexity minimization for translation model domain adaptation in statistical machine translation. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 539–549, Avignon, France, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nakatani Shuyo</author>
</authors>
<title>Language detection library for java.</title>
<date>2010</date>
<contexts>
<context position="2649" citStr="Shuyo, 2010" startWordPosition="400" endWordPosition="401">will describe our system in detail. In section 2, we will explain our preprocessing steps on corpus. Then in section 3, we will describe some techniques we have tried for this task and the experiment results. In section 4, our final configuration for submitted system will be presented. And we conclude in the last section. 2 Pre-processing We use all the training data for German-English translation, including Europarl, News Commentary and Common Crawl. The first thing we noticed is that some Non-German and Non-English sentences are included in our training data. So we apply Language Detection (Shuyo, 2010) for both monolingual and bilingual corpora. For monolingual data (only including English sentences in our task), we filter out sentences which are detected as other language with probability more than 0.999995. And for bilingual data, A sentence pair is filtered out if the language detector detects a different language with probability more than 0.999995 on either the source or the target. The filtering results are given in Table 1. In our experiment, German compound words are splitted based on frequency (Koehn and 136 Proceedings of the Ninth Workshop on Statistical Machine Translation, page</context>
</contexts>
<marker>Shuyo, 2010</marker>
<rawString>Nakatani Shuyo. 2010. Language detection library for java.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="1787" citStr="Stolcke, 2002" startWordPosition="262" endWordPosition="263">ition, in order to improve the translation quality, we adopted some popular techniques, including three Lexicalized Reordering Models (Axelrod et al., 2005; Galley and Manning, 2008), a 9- gram Operation Sequence Model (Durrani et al., 2011) and Language Model interpolation on several datasets. And then we use system combination on several systems with different settings to produce the final outputs. Our phrase-based systems are tuned with k-best MIRA (Cherry and Foster, 2012) on development set. We set the maximum iteration to be 25. The Language Models in our systems are trained with SRILM (Stolcke, 2002). We trained Corpus Filtered Out (%) Bilingual 7.17 Monolingual (English) 1.05 Table 1: Results of language detection: percentage of filtered out sentences a 5-gram model with Kneser-Ney discounting (Chen and Goodman, 1996). In the next sections, we will describe our system in detail. In section 2, we will explain our preprocessing steps on corpus. Then in section 3, we will describe some techniques we have tried for this task and the experiment results. In section 4, our final configuration for submitted system will be presented. And we conclude in the last section. 2 Pre-processing We use al</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm – an extensible language modeling toolkit. In Proceedings of the International Conference Spoken Language Processing, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03,</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9320" citStr="Toutanova et al., 2003" startWordPosition="1487" endWordPosition="1490">t a much lower perplexity, but it slightly improves the system, as shown in Table 2. 3.4 Other Tries In addition to the techniques mentioned above, we also try some other approaches. Unfortunately all of these methods described in this section are non-effective in our experiments. The results are shown in Table 2. • Factored Model (Koehn and Hoang, 2007): We tried to integrate a target POS factored model into our system with a 9-gram POS language model to address the problem of word selection and word order. But experiment doesn’t show improvement. The English POS is from Stanford POS Tagger (Toutanova et al., 2003). • Translation Model Combination: In this experiment, we try to use the method of (Sennrich, 2012) to combine phrase tables or reordering tables from different subsets of data 138 to minimize perplexity measured on development set. We try to split the training data in two ways. One is according to data source, resulting in three subsets: Europarl, News Commentary and Common Crawl. Another one is to use data selection. We use FDA to select 200K sentence pairs as in-domain data and the rest as out-domain data. Unfortunately both experiments failed. In Table 2, we only report results of phrase t</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03, pages 173–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhaopeng Tu</author>
<author>Yang Liu</author>
<author>Yifan He</author>
<author>Josef van Genabith</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Combining multiple alignments to improve machine translation.</title>
<date>2012</date>
<booktitle>In COLING (Posters),</booktitle>
<pages>1249--1260</pages>
<marker>Tu, Liu, He, van Genabith, Liu, Lin, 2012</marker>
<rawString>Zhaopeng Tu, Yang Liu, Yifan He, Josef van Genabith, Qun Liu, and Shouxun Lin. 2012. Combining multiple alignments to improve machine translation. In COLING (Posters), pages 1249–1260.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>