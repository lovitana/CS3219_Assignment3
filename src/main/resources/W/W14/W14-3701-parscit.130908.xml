<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003452">
<title confidence="0.990891">
Normalized Entity Graph for Computing Local Coherence
</title>
<author confidence="0.899344">
Mohsen Mesgar and Michael Strube
</author>
<affiliation confidence="0.852136">
Heidelberg Institute for Theoretical Studies gGmbH
</affiliation>
<address confidence="0.7185285">
Schloss-Wolfsbrunnenweg 35
69118 Heidelberg, Germany
</address>
<email confidence="0.791365">
(mohsen.mesgar|michael.strube)@h-its.org
</email>
<sectionHeader confidence="0.989274" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999842222222222">
Guinaudeau and Strube (2013) introduce a
graph based model to compute local en-
tity coherence. We propose a computa-
tionally efficient normalization method for
these graphs and then evaluate it on three
tasks: sentence ordering, summary coher-
ence rating and readability assessment. In
all tasks normalization improves the re-
sults.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997038724137931">
Guinaudeau and Strube (2013) introduce a graph
based model (henceforth called entity graph) to
compute local entity coherence. Despite being un-
supervised, the entity graph performs on par with
Barzilay and Lapata’s (2005; 2008) supervised en-
tity grid on the tasks of sentence ordering, sum-
mary coherence rating and readability assessment.
The entity graph also overcomes shortcomings of
the entity grid with regard to computational com-
plexity, data sparsity and domain dependence.
The entity graph is a bipartite graph where one
set of nodes represents entities and the other set
of nodes represents the sentences of a document.
Guinaudeau and Strube (2013) apply a one mode
projection on sentence nodes (Newman, 2010) and
then compute the average out-degree of sentence
nodes to determine how coherent a document is.
They describe variants of their entity graph which
take the number of shared entities between sen-
tences and their grammatical functions into ac-
count thus resulting in weighted bipartite graphs
and weighted one mode projections. Here, we
propose to normalize weights for the entity graph.
Normalization allows to include distance between
mentions of the same entity, which improves the
performance on all three tasks thus confirming re-
search in related areas which states that normaliz-
ing weights leads to better performance (Zhou et
al., 2008; Zweig and Kaufmann, 2011).
</bodyText>
<sectionHeader confidence="0.971975" genericHeader="method">
2 The Entity Graph
</sectionHeader>
<bodyText confidence="0.99993">
The entity graph (Guinaudeau and Strube, 2013),
G = (V, E), represents the relations between sen-
tences and entities in a text, where node set V con-
tains all sentences and entities in a text and E is
the set of all edges between sentences and enti-
ties. Let function w(si, ej) indicate the weight of
an edge which connects sentence si and entity ej.
If w(si, ej) = 1, then this edge indicates that there
is a mention of ej in sentence si. In order to real-
ize the insight from Grosz et al. (1995) that certain
syntactic roles are more important than others, the
syntactic role of ej in si can be mapped to an inte-
ger value (Guinaudeau and Strube, 2013):
</bodyText>
<equation confidence="0.921714666666667">
3 if ej is subject in si
w(si, ej) = 2 if ej is object in si
1 otherwise
</equation>
<figureCaption confidence="0.990034333333333">
Figure 1 illustrates a weighted entity graph for
three sentences.
Figure 1: Weighted entity graph
</figureCaption>
<bodyText confidence="0.999938">
Three types of one-mode projections capture
relations between sentences, PU, PW and PAcc.
PU creates an edge between two sentences if they
share at least one entity. PW captures the intu-
ition that the connection between two sentences
is stronger the more entities they share by means
of weighted edges, where the weights equal the
number of entities shared by sentences (Newman,
2004). The third type of projection, PAcc, inte-
grates syntactic information in the edge weights
calculated by the following formula:
</bodyText>
<equation confidence="0.949995413793103">
�Wik = w(e, si) · w(e, sk) .
e∈Eik
S1 S2 S3
1 3
2 3
2 1 1
1
3
1 1 1
1
e1 e2 e3 e4 e5 e6 e7 e8 e9 e10
1
Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 1–5,
October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
Figure 2 shows the three kinds of one-mode pro-
jections used in the entity graph.
S1 S2
1
1
S1 S2
2
1
S3
S3
S1 S2 S3
1
7
1 2 1
7 7
</equation>
<figureCaption confidence="0.837681">
Figure 3: Normalized entity graph
</figureCaption>
<figure confidence="0.9944169">
6
1
6
3
9
S1 S2
4
S3
2 3
6 8
2 1 1
8
1
3
7
8 8 8
7
e1 e2 e3 e4 e5 e6 e7 e8 e9 e10
P PW P
U Acc
</figure>
<figureCaption confidence="0.999525">
Figure 2: One-mode projections
</figureCaption>
<bodyText confidence="0.999982285714286">
While the entity grid (Barzilay and Lapata,
2008) uses information about sentences which do
not share entities by means of the “- -” transition,
the entity graph cannot employ this negative in-
formation. Here, we propose a normalization for
the entity graph and its corresponding one-mode
projections which is based on the relative impor-
tance of entities and, in turn, the relative impor-
tance of sentences. Including negative informa-
tion allows to normalize the importance of entities
according to sentence length (measured in terms
of entity mentions), and hence to capture distance
information between mentions of the same entity.
This brings the entity graph closer to Stoddard’s
(1991, p.30) notion of cohesion: “The relative co-
hesiveness of a text depends on the number of co-
hesive ties [...] and on the distance between the
nodes and their associated cohesive elements.” By
using this information, edge weights are set less
arbitrary which leads to the more sound method
and higher performance in all tasks.
</bodyText>
<sectionHeader confidence="0.991001" genericHeader="method">
3 Normalized Entity Graph
</sectionHeader>
<bodyText confidence="0.999967">
The entity graph weighs edges by the number of
entities sentences share (PW) and which syntactic
functions the entities occupy (PAcc). Here we nor-
malize the weights by the number of entities in a
sentence. This takes negative information into ac-
count as entities which do not occur in other sen-
tences also count. Hence normalization captures
the relative importance of entities as well as the
relative importance of sentences.
We follow Newman (2004) by applying node
degree normalization. For PW, we divide the
weight of each edge by the degree of the corre-
sponding sentence node. If a sentence contains
many entities, then the amount of information
each entity contributes is reduced. Assume ksik
as the number of entities in sentence si. The im-
portance of entity ej for si is
For PAcc we divide the weight of each edge by the
sum of all edges’ weights of a sentence. This gives
the importance of each entity in a sentence relative
to the sentence’s other entities (see Figure 3).
</bodyText>
<equation confidence="0.995026">
w(si, ej)
Imp(si, ej) =
</equation>
<bodyText confidence="0.997678166666667">
For also normalizing the one-mode projection
we introduce a virtual node TC capturing the
textual content of all sentences (inspired by the
graph based information retrieval model of Rode
(2008)). The virtual node TC is connected to all
sentences (see Figure 4).
</bodyText>
<figureCaption confidence="0.994694">
Figure 4: Entity graph with virtual node
</figureCaption>
<bodyText confidence="0.995450333333333">
Rode (2008) uses the following formula to com-
pute weights on the edges between the sentence
nodes and TC:
</bodyText>
<equation confidence="0.984853">
Score(si|T C)
w(si, T C) = E st Score(st|T C) ,
</equation>
<bodyText confidence="0.992064272727272">
where the function Score(si|TC) is the number
of entities in si which have overlap with TC. This
value is equal to the degree of each sentence.
Since we are interested in local coherence, we
restrict TC to pairs of sentences (See Figure 5).
Subsequently, instead of w(si,TC), we use the
notation lwsj
si (local weight of sentence si accord-
ing to sentence sj).
We define the normalized one-mode projection
as follows:
</bodyText>
<equation confidence="0.995090625">
e1 e2 e3 e4 e5 e6 e7 e8 e9 e10
S1 S2 S3
TC
E ee∈Entities w(si, ee ) .
Wsij=Ee∈Esij 1 (lw3z ·Imp(si,e))+(lw3� ·Imp(sj,e)) } .
1
Imp(si, ej) =
ksik .
</equation>
<page confidence="0.981333">
2
</page>
<figureCaption confidence="0.999016">
Figure 5: Restricted TC for a pair of sentences
</figureCaption>
<bodyText confidence="0.911864875">
Similar to Rode (2008), we use the product of
lwsj
si and Imp(si, e) to approximate the salience
of entity e in sentence si. This prevents the model
to get biased by the length of sentences.
This method can be applied to graphs with
edges weighted according to syntactic role (PA,,).
To compute the connection’s strength of a pair of
sentences we follow Yang and Knoke’s (2001) ap-
proach: The path length in a weighted graph is the
sum of the edge weights in the path. In our case,
each path is defined between a pair of sentences
of the entity graph, so the number of edges of all
paths are equal to two. Figure 6 shows the nor-
malized projections where the weights have been
computed by the above formula.
</bodyText>
<equation confidence="0.592388">
P P P
U W Acc
</equation>
<figureCaption confidence="0.994282">
Figure 6: Normalized projections
</figureCaption>
<sectionHeader confidence="0.999289" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999893846153846">
We compare the normalized entity graph with the
entity graph on all tasks, Guinaudeau and Strube
(2013) compared their work with the entity grid
(Barzilay and Lapata, 2008; Elsner and Charniak,
2011): sentence ordering, summary coherence rat-
ing and readability assessment. Following Guin-
audeau and Strube (2013) we test statistical sig-
nificance with the Student’s t-test and Bonferroni
correction, to check whether the best result (bold
value in the tables) is significantly different from
the results of the entity graph and the normalized
entity graph. Diacritics ** indicate significance
level 0.01, * indicates significance level 0.05.
</bodyText>
<table confidence="0.9996565">
Acc F
Random 0.496 0.496
B&amp;L 0.877 0.877
E&amp;C 0.915 0.915
Entity graph, G&amp;S
PU, Dist 0.830 0.830**
PW, Dist 0.871 0.871
PAcc, Dist 0.889 0.889
Normalized entity graph
PU, Dist 0.830 0.830**
PW, Dist 0.886 0.886
PAcc, Dist 0.909 0.909
</table>
<tableCaption confidence="0.993307">
Table 1: Discrimination, baselines and entity
graph vs. normalized entity graph
</tableCaption>
<subsectionHeader confidence="0.998025">
4.1 Sentence Ordering
</subsectionHeader>
<bodyText confidence="0.99956032">
This task consists of two subtasks: discrimina-
tion and insertion. In both subtasks we evaluate
whether our model can distinguish between the
correct order of sentences in a document and an
incorrect one. Experimental setup and data fol-
low Guinaudeau and Strube (2013) (61 documents
from the English test part of the CoNLL 2012
shared task (Pradhan et al., 2012)).
For discrimination we use 20 permutations of
each text. Table 1 shows the results. Results
for Guinaudeau and Strube (2013), G&amp;S, are re-
produced, results for Barzilay and Lapata (2008),
B&amp;L, and Elsner and Charniak (2011), E&amp;C, were
reproduced by Guinaudeau and Strube (2013).
The unweighted graph, PU, does not need nor-
malization. Hence the results for the entity graph
and the normalized entity graph are identical. Nor-
malization improves the results for the weighted
graphs PW and PA,, with PA,, outperforming
B&amp;L considerably and closely approaching E&amp;L.
Sentence insertion is more difficult than dis-
crimination. Following Elsner and Charniak
(2011), we use two measures for evaluation: Ac-
curacy (Acc.) and the average proportion of cor-
rect insertions per document (Ins.).
</bodyText>
<table confidence="0.996052272727273">
Acc. Ins.
Random 0.028 0.071
E&amp;C 0.068 0.167
Entity graph, G&amp;S
PU, Dist 0.062** 0.101 **
PW, Dist 0.075 0.114 **
PAcc, Dist 0.071 0.102 **
Normalized entity graph
PU, Dist 0.062** 0.101 **
PW, Dist 0.085 0.154
PAcc, Dist 0.077 0.157
</table>
<tableCaption confidence="0.9796595">
Table 2: Insertion, baselines and entity graph vs.
normalized entity graph
</tableCaption>
<figure confidence="0.92931585">
e1 e2 e3 e4 e5 e6 e7
� � �
Si Sj
RTC
2
8
S1 S2
4
8
27
64
S1 S2
23
56
1
S1 S2
1
S3
S3
S3
</figure>
<page confidence="0.955552">
3
</page>
<table confidence="0.9905365">
Acc. F
B&amp;L 0.833
Entity graph, G&amp;S
PU 0.800 0.815
PW 0.613 0.613*
PAcc 0.700 0.704
Normalized entity graph
PU 0.800 0.815
PW 0.775 0.775
PAcc 0.788 0.788
</table>
<tableCaption confidence="0.88589">
Table 3: Summary Coherence Rating, B&amp;L and
entity graph vs. normalized entity graph
</tableCaption>
<table confidence="0.99976925">
Acc. F
S&amp;O 0.786
B&amp;L 0.509
B&amp;L + S&amp;O 0.888
Entity graph, G&amp;S
PU, Dist 0.589 0.589**
PW, Dist 0.570 0.570**
PAcc, Dist 0.766 0.766**
Normalized entity graph
PU, Dist 0.589 0.589**
PW, Dist 0.897 0.897
PAcc, Dist 0.850 0.850
</table>
<tableCaption confidence="0.9788575">
Table 4: Readability assessment, baselines and en-
tity graph vs. normalized entity graph
</tableCaption>
<bodyText confidence="0.903182375">
Table 2 shows that the normalized entity graph
outperforms the entity graph for PW and PAcc
(again, no difference for PU). The normalized
entity graph outperforms E&amp;C in Acc. and ap-
proaches it in Ins. The high value for Ins. shows
that if the normalized entity graph makes false de-
cisions they are closer to the original ordering than
the mistakes of the entity graph.
</bodyText>
<subsectionHeader confidence="0.991855">
4.2 Summary Coherence Rating
</subsectionHeader>
<bodyText confidence="0.999955166666667">
We follow Barzilay and Lapata (2008) for evalu-
ating whether the normalized entity graph can de-
cide whether automatic or human summaries are
more coherent (80 pairs of summaries extracted
from DUC 2003). Human coherence scores are as-
sociated with each pair of summarized documents
(Barzilay and Lapata, 2008).
Table 3 displays reported results of B&amp;L and
reproduced results of the entity graph and our nor-
malized entity graph. Normalizing significantly
improves the results for PW and PAcc. PU is still
slightly better than both, but in contrast to the en-
tity graph, this difference is not statistically signif-
icant. We believe that better weighting schemes
based on linguistic insights eventually will outper-
form PU and B&amp;L (left for future work). Distance
information always degrades the results for this
task (see Guinaudeau and Strube (2013)).
</bodyText>
<subsectionHeader confidence="0.995719">
4.3 Readability Assessment
</subsectionHeader>
<bodyText confidence="0.9993973">
Readability assessment aims to distinguish texts
which are difficult to read from texts which are
easier to read. In experiments, Barzilay and La-
pata (2008) assume that articles taken from Ency-
clopedia Britannica are more difficult to read (less
coherent) than the corresponding articles from En-
cyclopedia Britannica Elementary, its version for
children. We follow them with regard to data (107
article pairs), experimental setup and evaluation.
Table 4 compares reported results by Schwarm
and Ostendorf (2005), S&amp;O, Barzilay and Lapata
(2008), B&amp;L, a combined method, B&amp;L + S&amp;O,
reproduced results for the entity graph, G&amp;S, and
our normalized entity graph. Distance information
always improves the results.
Sentences in the Britannica Elementary are
simpler and shorter than in the Encyclopedia Bri-
tannica. The entity graph does not take into ac-
count the effect of entities not shared between sen-
tences while the normalized entity graph assigns a
lower weight if there are more of these entities.
Hence, Britannica Elementary receives a higher
cohesion score than Encyclopedia Britannica in
our model. Adding grammatical information, does
not help, because of the influence of the number
of entities (shared and not shared) outweighs the
influence of syntactic roles. The normalized en-
tity graph (PW, Dist) does not only outperform
the entity graph (significantly) and B&amp;L but also
S&amp;O and the combination B&amp;L + S&amp;O.
</bodyText>
<sectionHeader confidence="0.998903" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9995197">
We proposed a normalization method for the en-
tity graph (Guinaudeau and Strube, 2013). We
compared our model to the entity graph and
to the entity grid (Barzilay and Lapata, 2008)
and showed that normalization improves the re-
sults significantly in most tasks. Future work
will include adding more linguistic information,
stronger weighting schemes and application to
other readability datasets (Pitler and Nenkova,
2008; De Clercq et al., 2014).
</bodyText>
<sectionHeader confidence="0.998304" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9863115">
This work has been funded by the Klaus Tschira
Foundation, Heidelberg, Germany. The first au-
thor has been supported by a Heidelberg Institute
for Theoretical Studies Ph.D. scholarship.
</bodyText>
<page confidence="0.996848">
4
</page>
<sectionHeader confidence="0.982479" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997473880597015">
Regina Barzilay and Mirella Lapata. 2005. Model-
ing local coherence: An entity-based approach. In
Proceedings of the 43rd Annual Meeting of the As-
sociation for Computational Linguistics, Ann Arbor,
Mich., 25–30 June 2005, pages 141–148.
Regina Barzilay and Mirella Lapata. 2008. Modeling
local coherence: An entity-based approach. Compu-
tational Linguistics, 34(1):1–34.
Orph´ee De Clercq, V´eronique Hoste, Bart Desmet,
Philip Van Oosten, Martine De Cock, and Lieve
Macken. 2014. Using the crowd for readability pre-
diction. Natural Language Engineering, 20(3):293–
325.
Micha Elsner and Eugene Charniak. 2011. Extending
the entity grid with entity-specific features. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 2: Short
Papers), Portland, Oreg., 19–24 June 2011, pages
125–129.
Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-
stein. 1995. Centering: A framework for model-
ing the local coherence of discourse. Computational
Linguistics, 21(2):203–225.
Camille Guinaudeau and Michael Strube. 2013.
Graph-based local coherence modeling. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), Sofia, Bulgaria, 4–9 August 2013, pages 93–
103.
Mark E.J. Newman. 2004. Analysis of weighted net-
works. Physical Review E, 70(5):056131.
Mark E.J. Newman. 2010. Networks: An Introduction.
Oxford University Press, New York, N.Y.
Emily Pitler and Ani Nenkova. 2008. Revisiting
readability: A unified framework for predicting text
quality. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Pro-
cessing, Waikiki, Honolulu, Hawaii, 25–27 October
2008, pages 186–195.
Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. CoNLL-
2012 Shared Task: Modeling multilingual unre-
stricted coreference in OntoNotes. In Proceedings
of the Shared Task of the 16th Conference on Com-
putational Natural Language Learning, Jeju Island,
Korea, 12–14 July 2012, pages 1–40.
Henning Rode. 2008. From document to entity re-
trieval: Improving precision and performance offo-
cused text search. Ph.D. thesis, Enschede, June.
Sarah E. Schwarm and Mari Ostendorf. 2005. Reading
level assessment using support vector machines and
statistical language models. In Proceedings of the
43rd Annual Meeting of the Association for Compu-
tational Linguistics, Ann Arbor, Mich., 25–30 June
2005, pages 523–530.
Sally Stoddard. 1991. Text and Texture: Patterns of
Cohesion. Ablex, Norwood, N.J.
Song Yang and David Knoke. 2001. Optimal connec-
tions: Strength and distance in valued graphs. Social
networks, 23(4):285–295.
Tao Zhou, Jie Ren, Mat´uˇs Medo, and Yi-Cheng Zhang.
2008. Bipartite network projection and personal rec-
ommendation. Physical Review E, 76(4). 046115.
Katharina A. Zweig and Michael Kaufmann. 2011. A
systematic approach to the one-mode projection of
bipartite graphs. Social Network Analysis and Min-
ing, 1:187–218.
</reference>
<page confidence="0.994337">
5
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.282948">
<title confidence="0.993789">Normalized Entity Graph for Computing Local Coherence</title>
<author confidence="0.543221">Mesgar</author>
<affiliation confidence="0.533608">Heidelberg Institute for Theoretical Studies Schloss-Wolfsbrunnenweg</affiliation>
<address confidence="0.998806">69118 Heidelberg, Germany</address>
<email confidence="0.999047">(mohsen.mesgar|michael.strube)@h-its.org</email>
<abstract confidence="0.9894868">Guinaudeau and Strube (2013) introduce a graph based model to compute local entity coherence. We propose a computationally efficient normalization method for these graphs and then evaluate it on three tasks: sentence ordering, summary coherence rating and readability assessment. In all tasks normalization improves the results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>141--148</pages>
<location>Ann Arbor, Mich.,</location>
<marker>Barzilay, Lapata, 2005</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2005. Modeling local coherence: An entity-based approach. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor, Mich., 25–30 June 2005, pages 141–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="3958" citStr="Barzilay and Lapata, 2008" startWordPosition="685" endWordPosition="688">= w(e, si) · w(e, sk) . e∈Eik S1 S2 S3 1 3 2 3 2 1 1 1 3 1 1 1 1 e1 e2 e3 e4 e5 e6 e7 e8 e9 e10 1 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 1–5, October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 2 shows the three kinds of one-mode projections used in the entity graph. S1 S2 1 1 S1 S2 2 1 S3 S3 S1 S2 S3 1 7 1 2 1 7 7 Figure 3: Normalized entity graph 6 1 6 3 9 S1 S2 4 S3 2 3 6 8 2 1 1 8 1 3 7 8 8 8 7 e1 e2 e3 e4 e5 e6 e7 e8 e9 e10 P PW P U Acc Figure 2: One-mode projections While the entity grid (Barzilay and Lapata, 2008) uses information about sentences which do not share entities by means of the “- -” transition, the entity graph cannot employ this negative information. Here, we propose a normalization for the entity graph and its corresponding one-mode projections which is based on the relative importance of entities and, in turn, the relative importance of sentences. Including negative information allows to normalize the importance of entities according to sentence length (measured in terms of entity mentions), and hence to capture distance information between mentions of the same entity. This brings the e</context>
<context position="7966" citStr="Barzilay and Lapata, 2008" startWordPosition="1383" endWordPosition="1386">trength of a pair of sentences we follow Yang and Knoke’s (2001) approach: The path length in a weighted graph is the sum of the edge weights in the path. In our case, each path is defined between a pair of sentences of the entity graph, so the number of edges of all paths are equal to two. Figure 6 shows the normalized projections where the weights have been computed by the above formula. P P P U W Acc Figure 6: Normalized projections 4 Experiments We compare the normalized entity graph with the entity graph on all tasks, Guinaudeau and Strube (2013) compared their work with the entity grid (Barzilay and Lapata, 2008; Elsner and Charniak, 2011): sentence ordering, summary coherence rating and readability assessment. Following Guinaudeau and Strube (2013) we test statistical significance with the Student’s t-test and Bonferroni correction, to check whether the best result (bold value in the tables) is significantly different from the results of the entity graph and the normalized entity graph. Diacritics ** indicate significance level 0.01, * indicates significance level 0.05. Acc F Random 0.496 0.496 B&amp;L 0.877 0.877 E&amp;C 0.915 0.915 Entity graph, G&amp;S PU, Dist 0.830 0.830** PW, Dist 0.871 0.871 PAcc, Dist 0</context>
<context position="9318" citStr="Barzilay and Lapata (2008)" startWordPosition="1596" endWordPosition="1599"> baselines and entity graph vs. normalized entity graph 4.1 Sentence Ordering This task consists of two subtasks: discrimination and insertion. In both subtasks we evaluate whether our model can distinguish between the correct order of sentences in a document and an incorrect one. Experimental setup and data follow Guinaudeau and Strube (2013) (61 documents from the English test part of the CoNLL 2012 shared task (Pradhan et al., 2012)). For discrimination we use 20 permutations of each text. Table 1 shows the results. Results for Guinaudeau and Strube (2013), G&amp;S, are reproduced, results for Barzilay and Lapata (2008), B&amp;L, and Elsner and Charniak (2011), E&amp;C, were reproduced by Guinaudeau and Strube (2013). The unweighted graph, PU, does not need normalization. Hence the results for the entity graph and the normalized entity graph are identical. Normalization improves the results for the weighted graphs PW and PA,, with PA,, outperforming B&amp;L considerably and closely approaching E&amp;L. Sentence insertion is more difficult than discrimination. Following Elsner and Charniak (2011), we use two measures for evaluation: Accuracy (Acc.) and the average proportion of correct insertions per document (Ins.). Acc. In</context>
<context position="11292" citStr="Barzilay and Lapata (2008)" startWordPosition="1942" endWordPosition="1945">.766 0.766** Normalized entity graph PU, Dist 0.589 0.589** PW, Dist 0.897 0.897 PAcc, Dist 0.850 0.850 Table 4: Readability assessment, baselines and entity graph vs. normalized entity graph Table 2 shows that the normalized entity graph outperforms the entity graph for PW and PAcc (again, no difference for PU). The normalized entity graph outperforms E&amp;C in Acc. and approaches it in Ins. The high value for Ins. shows that if the normalized entity graph makes false decisions they are closer to the original ordering than the mistakes of the entity graph. 4.2 Summary Coherence Rating We follow Barzilay and Lapata (2008) for evaluating whether the normalized entity graph can decide whether automatic or human summaries are more coherent (80 pairs of summaries extracted from DUC 2003). Human coherence scores are associated with each pair of summarized documents (Barzilay and Lapata, 2008). Table 3 displays reported results of B&amp;L and reproduced results of the entity graph and our normalized entity graph. Normalizing significantly improves the results for PW and PAcc. PU is still slightly better than both, but in contrast to the entity graph, this difference is not statistically significant. We believe that bett</context>
<context position="12674" citStr="Barzilay and Lapata (2008)" startWordPosition="2156" endWordPosition="2159">ults for this task (see Guinaudeau and Strube (2013)). 4.3 Readability Assessment Readability assessment aims to distinguish texts which are difficult to read from texts which are easier to read. In experiments, Barzilay and Lapata (2008) assume that articles taken from Encyclopedia Britannica are more difficult to read (less coherent) than the corresponding articles from Encyclopedia Britannica Elementary, its version for children. We follow them with regard to data (107 article pairs), experimental setup and evaluation. Table 4 compares reported results by Schwarm and Ostendorf (2005), S&amp;O, Barzilay and Lapata (2008), B&amp;L, a combined method, B&amp;L + S&amp;O, reproduced results for the entity graph, G&amp;S, and our normalized entity graph. Distance information always improves the results. Sentences in the Britannica Elementary are simpler and shorter than in the Encyclopedia Britannica. The entity graph does not take into account the effect of entities not shared between sentences while the normalized entity graph assigns a lower weight if there are more of these entities. Hence, Britannica Elementary receives a higher cohesion score than Encyclopedia Britannica in our model. Adding grammatical information, does no</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computational Linguistics, 34(1):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Orph´ee De Clercq</author>
<author>V´eronique Hoste</author>
<author>Bart Desmet</author>
<author>Philip Van Oosten</author>
<author>Martine De Cock</author>
<author>Lieve Macken</author>
</authors>
<title>Using the crowd for readability prediction.</title>
<date>2014</date>
<journal>Natural Language Engineering,</journal>
<volume>20</volume>
<issue>3</issue>
<pages>325</pages>
<marker>De Clercq, Hoste, Desmet, Van Oosten, De Cock, Macken, 2014</marker>
<rawString>Orph´ee De Clercq, V´eronique Hoste, Bart Desmet, Philip Van Oosten, Martine De Cock, and Lieve Macken. 2014. Using the crowd for readability prediction. Natural Language Engineering, 20(3):293– 325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Eugene Charniak</author>
</authors>
<title>Extending the entity grid with entity-specific features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>125--129</pages>
<location>Portland, Oreg.,</location>
<contexts>
<context position="7994" citStr="Elsner and Charniak, 2011" startWordPosition="1387" endWordPosition="1390">ces we follow Yang and Knoke’s (2001) approach: The path length in a weighted graph is the sum of the edge weights in the path. In our case, each path is defined between a pair of sentences of the entity graph, so the number of edges of all paths are equal to two. Figure 6 shows the normalized projections where the weights have been computed by the above formula. P P P U W Acc Figure 6: Normalized projections 4 Experiments We compare the normalized entity graph with the entity graph on all tasks, Guinaudeau and Strube (2013) compared their work with the entity grid (Barzilay and Lapata, 2008; Elsner and Charniak, 2011): sentence ordering, summary coherence rating and readability assessment. Following Guinaudeau and Strube (2013) we test statistical significance with the Student’s t-test and Bonferroni correction, to check whether the best result (bold value in the tables) is significantly different from the results of the entity graph and the normalized entity graph. Diacritics ** indicate significance level 0.01, * indicates significance level 0.05. Acc F Random 0.496 0.496 B&amp;L 0.877 0.877 E&amp;C 0.915 0.915 Entity graph, G&amp;S PU, Dist 0.830 0.830** PW, Dist 0.871 0.871 PAcc, Dist 0.889 0.889 Normalized entity</context>
<context position="9355" citStr="Elsner and Charniak (2011)" startWordPosition="1602" endWordPosition="1605">lized entity graph 4.1 Sentence Ordering This task consists of two subtasks: discrimination and insertion. In both subtasks we evaluate whether our model can distinguish between the correct order of sentences in a document and an incorrect one. Experimental setup and data follow Guinaudeau and Strube (2013) (61 documents from the English test part of the CoNLL 2012 shared task (Pradhan et al., 2012)). For discrimination we use 20 permutations of each text. Table 1 shows the results. Results for Guinaudeau and Strube (2013), G&amp;S, are reproduced, results for Barzilay and Lapata (2008), B&amp;L, and Elsner and Charniak (2011), E&amp;C, were reproduced by Guinaudeau and Strube (2013). The unweighted graph, PU, does not need normalization. Hence the results for the entity graph and the normalized entity graph are identical. Normalization improves the results for the weighted graphs PW and PA,, with PA,, outperforming B&amp;L considerably and closely approaching E&amp;L. Sentence insertion is more difficult than discrimination. Following Elsner and Charniak (2011), we use two measures for evaluation: Accuracy (Acc.) and the average proportion of correct insertions per document (Ins.). Acc. Ins. Random 0.028 0.071 E&amp;C 0.068 0.167</context>
</contexts>
<marker>Elsner, Charniak, 2011</marker>
<rawString>Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), Portland, Oreg., 19–24 June 2011, pages 125–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="2486" citStr="Grosz et al. (1995)" startWordPosition="390" endWordPosition="393">states that normalizing weights leads to better performance (Zhou et al., 2008; Zweig and Kaufmann, 2011). 2 The Entity Graph The entity graph (Guinaudeau and Strube, 2013), G = (V, E), represents the relations between sentences and entities in a text, where node set V contains all sentences and entities in a text and E is the set of all edges between sentences and entities. Let function w(si, ej) indicate the weight of an edge which connects sentence si and entity ej. If w(si, ej) = 1, then this edge indicates that there is a mention of ej in sentence si. In order to realize the insight from Grosz et al. (1995) that certain syntactic roles are more important than others, the syntactic role of ej in si can be mapped to an integer value (Guinaudeau and Strube, 2013): 3 if ej is subject in si w(si, ej) = 2 if ej is object in si 1 otherwise Figure 1 illustrates a weighted entity graph for three sentences. Figure 1: Weighted entity graph Three types of one-mode projections capture relations between sentences, PU, PW and PAcc. PU creates an edge between two sentences if they share at least one entity. PW captures the intuition that the connection between two sentences is stronger the more entities they sh</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Camille Guinaudeau</author>
<author>Michael Strube</author>
</authors>
<title>Graph-based local coherence modeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>93--103</pages>
<location>Sofia, Bulgaria, 4–9</location>
<contexts>
<context position="1242" citStr="Guinaudeau and Strube (2013)" startWordPosition="175" endWordPosition="178">introduce a graph based model (henceforth called entity graph) to compute local entity coherence. Despite being unsupervised, the entity graph performs on par with Barzilay and Lapata’s (2005; 2008) supervised entity grid on the tasks of sentence ordering, summary coherence rating and readability assessment. The entity graph also overcomes shortcomings of the entity grid with regard to computational complexity, data sparsity and domain dependence. The entity graph is a bipartite graph where one set of nodes represents entities and the other set of nodes represents the sentences of a document. Guinaudeau and Strube (2013) apply a one mode projection on sentence nodes (Newman, 2010) and then compute the average out-degree of sentence nodes to determine how coherent a document is. They describe variants of their entity graph which take the number of shared entities between sentences and their grammatical functions into account thus resulting in weighted bipartite graphs and weighted one mode projections. Here, we propose to normalize weights for the entity graph. Normalization allows to include distance between mentions of the same entity, which improves the performance on all three tasks thus confirming researc</context>
<context position="2642" citStr="Guinaudeau and Strube, 2013" startWordPosition="418" endWordPosition="421">naudeau and Strube, 2013), G = (V, E), represents the relations between sentences and entities in a text, where node set V contains all sentences and entities in a text and E is the set of all edges between sentences and entities. Let function w(si, ej) indicate the weight of an edge which connects sentence si and entity ej. If w(si, ej) = 1, then this edge indicates that there is a mention of ej in sentence si. In order to realize the insight from Grosz et al. (1995) that certain syntactic roles are more important than others, the syntactic role of ej in si can be mapped to an integer value (Guinaudeau and Strube, 2013): 3 if ej is subject in si w(si, ej) = 2 if ej is object in si 1 otherwise Figure 1 illustrates a weighted entity graph for three sentences. Figure 1: Weighted entity graph Three types of one-mode projections capture relations between sentences, PU, PW and PAcc. PU creates an edge between two sentences if they share at least one entity. PW captures the intuition that the connection between two sentences is stronger the more entities they share by means of weighted edges, where the weights equal the number of entities shared by sentences (Newman, 2004). The third type of projection, PAcc, integ</context>
<context position="7898" citStr="Guinaudeau and Strube (2013)" startWordPosition="1372" endWordPosition="1375">ghted according to syntactic role (PA,,). To compute the connection’s strength of a pair of sentences we follow Yang and Knoke’s (2001) approach: The path length in a weighted graph is the sum of the edge weights in the path. In our case, each path is defined between a pair of sentences of the entity graph, so the number of edges of all paths are equal to two. Figure 6 shows the normalized projections where the weights have been computed by the above formula. P P P U W Acc Figure 6: Normalized projections 4 Experiments We compare the normalized entity graph with the entity graph on all tasks, Guinaudeau and Strube (2013) compared their work with the entity grid (Barzilay and Lapata, 2008; Elsner and Charniak, 2011): sentence ordering, summary coherence rating and readability assessment. Following Guinaudeau and Strube (2013) we test statistical significance with the Student’s t-test and Bonferroni correction, to check whether the best result (bold value in the tables) is significantly different from the results of the entity graph and the normalized entity graph. Diacritics ** indicate significance level 0.01, * indicates significance level 0.05. Acc F Random 0.496 0.496 B&amp;L 0.877 0.877 E&amp;C 0.915 0.915 Entity</context>
<context position="9257" citStr="Guinaudeau and Strube (2013)" startWordPosition="1586" endWordPosition="1589">ist 0.886 0.886 PAcc, Dist 0.909 0.909 Table 1: Discrimination, baselines and entity graph vs. normalized entity graph 4.1 Sentence Ordering This task consists of two subtasks: discrimination and insertion. In both subtasks we evaluate whether our model can distinguish between the correct order of sentences in a document and an incorrect one. Experimental setup and data follow Guinaudeau and Strube (2013) (61 documents from the English test part of the CoNLL 2012 shared task (Pradhan et al., 2012)). For discrimination we use 20 permutations of each text. Table 1 shows the results. Results for Guinaudeau and Strube (2013), G&amp;S, are reproduced, results for Barzilay and Lapata (2008), B&amp;L, and Elsner and Charniak (2011), E&amp;C, were reproduced by Guinaudeau and Strube (2013). The unweighted graph, PU, does not need normalization. Hence the results for the entity graph and the normalized entity graph are identical. Normalization improves the results for the weighted graphs PW and PA,, with PA,, outperforming B&amp;L considerably and closely approaching E&amp;L. Sentence insertion is more difficult than discrimination. Following Elsner and Charniak (2011), we use two measures for evaluation: Accuracy (Acc.) and the average </context>
<context position="12100" citStr="Guinaudeau and Strube (2013)" startWordPosition="2071" endWordPosition="2074">ce scores are associated with each pair of summarized documents (Barzilay and Lapata, 2008). Table 3 displays reported results of B&amp;L and reproduced results of the entity graph and our normalized entity graph. Normalizing significantly improves the results for PW and PAcc. PU is still slightly better than both, but in contrast to the entity graph, this difference is not statistically significant. We believe that better weighting schemes based on linguistic insights eventually will outperform PU and B&amp;L (left for future work). Distance information always degrades the results for this task (see Guinaudeau and Strube (2013)). 4.3 Readability Assessment Readability assessment aims to distinguish texts which are difficult to read from texts which are easier to read. In experiments, Barzilay and Lapata (2008) assume that articles taken from Encyclopedia Britannica are more difficult to read (less coherent) than the corresponding articles from Encyclopedia Britannica Elementary, its version for children. We follow them with regard to data (107 article pairs), experimental setup and evaluation. Table 4 compares reported results by Schwarm and Ostendorf (2005), S&amp;O, Barzilay and Lapata (2008), B&amp;L, a combined method, </context>
</contexts>
<marker>Guinaudeau, Strube, 2013</marker>
<rawString>Camille Guinaudeau and Michael Strube. 2013. Graph-based local coherence modeling. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Sofia, Bulgaria, 4–9 August 2013, pages 93– 103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark E J Newman</author>
</authors>
<title>Analysis of weighted networks. Physical Review E,</title>
<date>2004</date>
<contexts>
<context position="3199" citStr="Newman, 2004" startWordPosition="517" endWordPosition="518">mapped to an integer value (Guinaudeau and Strube, 2013): 3 if ej is subject in si w(si, ej) = 2 if ej is object in si 1 otherwise Figure 1 illustrates a weighted entity graph for three sentences. Figure 1: Weighted entity graph Three types of one-mode projections capture relations between sentences, PU, PW and PAcc. PU creates an edge between two sentences if they share at least one entity. PW captures the intuition that the connection between two sentences is stronger the more entities they share by means of weighted edges, where the weights equal the number of entities shared by sentences (Newman, 2004). The third type of projection, PAcc, integrates syntactic information in the edge weights calculated by the following formula: �Wik = w(e, si) · w(e, sk) . e∈Eik S1 S2 S3 1 3 2 3 2 1 1 1 3 1 1 1 1 e1 e2 e3 e4 e5 e6 e7 e8 e9 e10 1 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 1–5, October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 2 shows the three kinds of one-mode projections used in the entity graph. S1 S2 1 1 S1 S2 2 1 S3 S3 S1 S2 S3 1 7 1 2 1 7 7 Figure 3: Normalized entity graph 6 1 6 3 9 S1 S2 </context>
<context position="5398" citStr="Newman (2004)" startWordPosition="920" endWordPosition="921">By using this information, edge weights are set less arbitrary which leads to the more sound method and higher performance in all tasks. 3 Normalized Entity Graph The entity graph weighs edges by the number of entities sentences share (PW) and which syntactic functions the entities occupy (PAcc). Here we normalize the weights by the number of entities in a sentence. This takes negative information into account as entities which do not occur in other sentences also count. Hence normalization captures the relative importance of entities as well as the relative importance of sentences. We follow Newman (2004) by applying node degree normalization. For PW, we divide the weight of each edge by the degree of the corresponding sentence node. If a sentence contains many entities, then the amount of information each entity contributes is reduced. Assume ksik as the number of entities in sentence si. The importance of entity ej for si is For PAcc we divide the weight of each edge by the sum of all edges’ weights of a sentence. This gives the importance of each entity in a sentence relative to the sentence’s other entities (see Figure 3). w(si, ej) Imp(si, ej) = For also normalizing the one-mode projectio</context>
</contexts>
<marker>Newman, 2004</marker>
<rawString>Mark E.J. Newman. 2004. Analysis of weighted networks. Physical Review E, 70(5):056131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark E J Newman</author>
</authors>
<title>Networks: An Introduction.</title>
<date>2010</date>
<publisher>Oxford University Press,</publisher>
<location>New York, N.Y.</location>
<contexts>
<context position="1303" citStr="Newman, 2010" startWordPosition="187" endWordPosition="188">cal entity coherence. Despite being unsupervised, the entity graph performs on par with Barzilay and Lapata’s (2005; 2008) supervised entity grid on the tasks of sentence ordering, summary coherence rating and readability assessment. The entity graph also overcomes shortcomings of the entity grid with regard to computational complexity, data sparsity and domain dependence. The entity graph is a bipartite graph where one set of nodes represents entities and the other set of nodes represents the sentences of a document. Guinaudeau and Strube (2013) apply a one mode projection on sentence nodes (Newman, 2010) and then compute the average out-degree of sentence nodes to determine how coherent a document is. They describe variants of their entity graph which take the number of shared entities between sentences and their grammatical functions into account thus resulting in weighted bipartite graphs and weighted one mode projections. Here, we propose to normalize weights for the entity graph. Normalization allows to include distance between mentions of the same entity, which improves the performance on all three tasks thus confirming research in related areas which states that normalizing weights lead</context>
</contexts>
<marker>Newman, 2010</marker>
<rawString>Mark E.J. Newman. 2010. Networks: An Introduction. Oxford University Press, New York, N.Y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Revisiting readability: A unified framework for predicting text quality.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>186--195</pages>
<location>Waikiki, Honolulu, Hawaii,</location>
<marker>Pitler, Nenkova, 2008</marker>
<rawString>Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, Waikiki, Honolulu, Hawaii, 25–27 October 2008, pages 186–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Alessandro Moschitti</author>
<author>Nianwen Xue</author>
<author>Olga Uryupina</author>
<author>Yuchen Zhang</author>
</authors>
<title>CoNLL2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes.</title>
<date>2012</date>
<booktitle>In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning,</booktitle>
<pages>1--40</pages>
<location>Jeju Island,</location>
<contexts>
<context position="9131" citStr="Pradhan et al., 2012" startWordPosition="1566" endWordPosition="1569">PU, Dist 0.830 0.830** PW, Dist 0.871 0.871 PAcc, Dist 0.889 0.889 Normalized entity graph PU, Dist 0.830 0.830** PW, Dist 0.886 0.886 PAcc, Dist 0.909 0.909 Table 1: Discrimination, baselines and entity graph vs. normalized entity graph 4.1 Sentence Ordering This task consists of two subtasks: discrimination and insertion. In both subtasks we evaluate whether our model can distinguish between the correct order of sentences in a document and an incorrect one. Experimental setup and data follow Guinaudeau and Strube (2013) (61 documents from the English test part of the CoNLL 2012 shared task (Pradhan et al., 2012)). For discrimination we use 20 permutations of each text. Table 1 shows the results. Results for Guinaudeau and Strube (2013), G&amp;S, are reproduced, results for Barzilay and Lapata (2008), B&amp;L, and Elsner and Charniak (2011), E&amp;C, were reproduced by Guinaudeau and Strube (2013). The unweighted graph, PU, does not need normalization. Hence the results for the entity graph and the normalized entity graph are identical. Normalization improves the results for the weighted graphs PW and PA,, with PA,, outperforming B&amp;L considerably and closely approaching E&amp;L. Sentence insertion is more difficult t</context>
</contexts>
<marker>Pradhan, Moschitti, Xue, Uryupina, Zhang, 2012</marker>
<rawString>Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. CoNLL2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes. In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning, Jeju Island, Korea, 12–14 July 2012, pages 1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henning Rode</author>
</authors>
<title>From document to entity retrieval: Improving precision and performance offocused text search.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<location>Enschede,</location>
<contexts>
<context position="6149" citStr="Rode (2008)" startWordPosition="1051" endWordPosition="1052">tence contains many entities, then the amount of information each entity contributes is reduced. Assume ksik as the number of entities in sentence si. The importance of entity ej for si is For PAcc we divide the weight of each edge by the sum of all edges’ weights of a sentence. This gives the importance of each entity in a sentence relative to the sentence’s other entities (see Figure 3). w(si, ej) Imp(si, ej) = For also normalizing the one-mode projection we introduce a virtual node TC capturing the textual content of all sentences (inspired by the graph based information retrieval model of Rode (2008)). The virtual node TC is connected to all sentences (see Figure 4). Figure 4: Entity graph with virtual node Rode (2008) uses the following formula to compute weights on the edges between the sentence nodes and TC: Score(si|T C) w(si, T C) = E st Score(st|T C) , where the function Score(si|TC) is the number of entities in si which have overlap with TC. This value is equal to the degree of each sentence. Since we are interested in local coherence, we restrict TC to pairs of sentences (See Figure 5). Subsequently, instead of w(si,TC), we use the notation lwsj si (local weight of sentence si acc</context>
</contexts>
<marker>Rode, 2008</marker>
<rawString>Henning Rode. 2008. From document to entity retrieval: Improving precision and performance offocused text search. Ph.D. thesis, Enschede, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah E Schwarm</author>
<author>Mari Ostendorf</author>
</authors>
<title>Reading level assessment using support vector machines and statistical language models.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>523--530</pages>
<location>Ann Arbor, Mich.,</location>
<contexts>
<context position="12641" citStr="Schwarm and Ostendorf (2005)" startWordPosition="2151" endWordPosition="2154">information always degrades the results for this task (see Guinaudeau and Strube (2013)). 4.3 Readability Assessment Readability assessment aims to distinguish texts which are difficult to read from texts which are easier to read. In experiments, Barzilay and Lapata (2008) assume that articles taken from Encyclopedia Britannica are more difficult to read (less coherent) than the corresponding articles from Encyclopedia Britannica Elementary, its version for children. We follow them with regard to data (107 article pairs), experimental setup and evaluation. Table 4 compares reported results by Schwarm and Ostendorf (2005), S&amp;O, Barzilay and Lapata (2008), B&amp;L, a combined method, B&amp;L + S&amp;O, reproduced results for the entity graph, G&amp;S, and our normalized entity graph. Distance information always improves the results. Sentences in the Britannica Elementary are simpler and shorter than in the Encyclopedia Britannica. The entity graph does not take into account the effect of entities not shared between sentences while the normalized entity graph assigns a lower weight if there are more of these entities. Hence, Britannica Elementary receives a higher cohesion score than Encyclopedia Britannica in our model. Adding</context>
</contexts>
<marker>Schwarm, Ostendorf, 2005</marker>
<rawString>Sarah E. Schwarm and Mari Ostendorf. 2005. Reading level assessment using support vector machines and statistical language models. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor, Mich., 25–30 June 2005, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sally Stoddard</author>
</authors>
<title>Text and Texture: Patterns of Cohesion. Ablex,</title>
<date>1991</date>
<location>Norwood, N.J.</location>
<marker>Stoddard, 1991</marker>
<rawString>Sally Stoddard. 1991. Text and Texture: Patterns of Cohesion. Ablex, Norwood, N.J.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Yang</author>
<author>David Knoke</author>
</authors>
<title>Optimal connections: Strength and distance in valued graphs. Social networks,</title>
<date>2001</date>
<pages>23--4</pages>
<marker>Yang, Knoke, 2001</marker>
<rawString>Song Yang and David Knoke. 2001. Optimal connections: Strength and distance in valued graphs. Social networks, 23(4):285–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Zhou</author>
<author>Jie Ren</author>
<author>Mat´uˇs Medo</author>
<author>Yi-Cheng Zhang</author>
</authors>
<title>Bipartite network projection and personal recommendation. Physical Review E,</title>
<date>2008</date>
<volume>76</volume>
<issue>4</issue>
<pages>046115</pages>
<contexts>
<context position="1945" citStr="Zhou et al., 2008" startWordPosition="286" endWordPosition="289">rage out-degree of sentence nodes to determine how coherent a document is. They describe variants of their entity graph which take the number of shared entities between sentences and their grammatical functions into account thus resulting in weighted bipartite graphs and weighted one mode projections. Here, we propose to normalize weights for the entity graph. Normalization allows to include distance between mentions of the same entity, which improves the performance on all three tasks thus confirming research in related areas which states that normalizing weights leads to better performance (Zhou et al., 2008; Zweig and Kaufmann, 2011). 2 The Entity Graph The entity graph (Guinaudeau and Strube, 2013), G = (V, E), represents the relations between sentences and entities in a text, where node set V contains all sentences and entities in a text and E is the set of all edges between sentences and entities. Let function w(si, ej) indicate the weight of an edge which connects sentence si and entity ej. If w(si, ej) = 1, then this edge indicates that there is a mention of ej in sentence si. In order to realize the insight from Grosz et al. (1995) that certain syntactic roles are more important than other</context>
</contexts>
<marker>Zhou, Ren, Medo, Zhang, 2008</marker>
<rawString>Tao Zhou, Jie Ren, Mat´uˇs Medo, and Yi-Cheng Zhang. 2008. Bipartite network projection and personal recommendation. Physical Review E, 76(4). 046115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina A Zweig</author>
<author>Michael Kaufmann</author>
</authors>
<title>A systematic approach to the one-mode projection of bipartite graphs. Social Network Analysis and Mining,</title>
<date>2011</date>
<pages>1--187</pages>
<contexts>
<context position="1972" citStr="Zweig and Kaufmann, 2011" startWordPosition="290" endWordPosition="293">sentence nodes to determine how coherent a document is. They describe variants of their entity graph which take the number of shared entities between sentences and their grammatical functions into account thus resulting in weighted bipartite graphs and weighted one mode projections. Here, we propose to normalize weights for the entity graph. Normalization allows to include distance between mentions of the same entity, which improves the performance on all three tasks thus confirming research in related areas which states that normalizing weights leads to better performance (Zhou et al., 2008; Zweig and Kaufmann, 2011). 2 The Entity Graph The entity graph (Guinaudeau and Strube, 2013), G = (V, E), represents the relations between sentences and entities in a text, where node set V contains all sentences and entities in a text and E is the set of all edges between sentences and entities. Let function w(si, ej) indicate the weight of an edge which connects sentence si and entity ej. If w(si, ej) = 1, then this edge indicates that there is a mention of ej in sentence si. In order to realize the insight from Grosz et al. (1995) that certain syntactic roles are more important than others, the syntactic role of ej</context>
</contexts>
<marker>Zweig, Kaufmann, 2011</marker>
<rawString>Katharina A. Zweig and Michael Kaufmann. 2011. A systematic approach to the one-mode projection of bipartite graphs. Social Network Analysis and Mining, 1:187–218.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>