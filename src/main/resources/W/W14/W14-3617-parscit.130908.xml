<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000278">
<title confidence="0.986154">
Automatic Correction of Arabic Text: a Cascaded Approach
</title>
<author confidence="0.998742">
Hamdy Mubarak, Kareem Darwish
</author>
<affiliation confidence="0.7817345">
Qatar Computing Research Institute
Qatar Foundation
</affiliation>
<email confidence="0.998522">
{hmubarak,kdarwish}@qf.org.qa
</email>
<sectionHeader confidence="0.994793" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906777777778">
This paper describes the error correction model that
we used for the Automatic Correction of Arabic Text
shared task. We employed two correction mod-
els, namely a character-level model and a case-
specific model, and two punctuation recovery mod-
els, namely a simple statistical model and a CRF
model. Our results on the development set suggest
that using a cascaded correction model yields the
best results.
</bodyText>
<sectionHeader confidence="0.998425" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999931095238095">
In This paper, we describe our system for auto-
matic Arabic error correction shared task (QALB-
2014 Shared Task on Automatic Correction of Ara-
bic) as part of the Arabic NLP workshop (Mohit
et al., 2014). Our system is composed of two main
steps. The first involves correcting word level er-
rors, and the second pertains to performing punctu-
ation recovery. For word level correction, we used
two approaches, namely: 1) a statistical character
level transformation model that is aided by a lan-
guage model (LM) to handle letter insertions, dele-
tions, and substitutions and word merges; and 2) a
case-specific system that is aided by a LM to han-
dle specific error types such as dialectal word sub-
stitutions and word splits. For punctuation recovery,
we used two approaches, namely a simple statistical
word-based system, and a conditional random fields
(CRF) sequence labeler (Lafferty et al., 2001) that
attempts to recover punctuation based on POS and
word sequences. We performed all experiments on
the QALB dataset (Zaghouani et al., 2014).
</bodyText>
<sectionHeader confidence="0.951217" genericHeader="method">
2 Word Error Correction
</sectionHeader>
<bodyText confidence="0.9994035">
In this section we describe two approaches for word
correction. The first approach involves using a char-
acter level model, and the second handles specific
correction cases.
</bodyText>
<subsectionHeader confidence="0.805161">
2.1 Character-level Correction Model
</subsectionHeader>
<bodyText confidence="0.999962444444445">
For the character level model, we treated correction
as a Transliteration Mining (TM) task. In TM, a
sequence in a source alphabet is used to find the
most similar sequence in a lexicon that is written
in a target alphabet. TM has been fairly well stud-
ied with multiple evaluation campaigns such as the
Named Entities Workshop (NEWS) (Zhang et al.,
2011; Zhang et al., 2012). In our work, we adopted
a TM system to find corrections appearing in a large
Arabic corpus. The system involved learning char-
acter (or character-sequence) level mappings be-
tween erroneous words and their correct counter-
parts. Given the character mappings between the
erroneous and correct words, we used a generative
model that attempts to generate all possible map-
pings of a source word while restricting the out-
put to words in the target language (El-Kahki et
al., 2011; Noeman and Madkour, 2010). Specifi-
cally, we used the baseline system of El-Kahky et
al. (2011). To train character-level mappings, we
extracted all the parallel word-pairs in the original
(uncorrected) and corrected versions in the training
set. If a word in the original version of the training
set was actually correct, the word would be mapped
to itself. We then aligned the parallel word pairs at
character level using GIZA++ (Och and Ney, 2003),
and symmetrized the alignments using grow-diag-
</bodyText>
<page confidence="0.975146">
132
</page>
<bodyText confidence="0.917230538461538">
Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 132–136,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
final-and heuristic (Koehn et al., 2007). In all, we
aligned a little over one million word pairs. As in the
baseline of El-Kahki et al. (2011), given a possibly
misspelled word worg, we produced all its possible
segmentations along with their associated mappings
that we learned during alignment. Valid target se-
quences were retained and sorted by the product of
the constituent mapping probabilities. The top n (we
picked n = 10) candidates, wtrg1..n with the highest
probability were generated. Using Bayes rule, we
computed:
</bodyText>
<equation confidence="0.992833">
argmax p(wtrgi|worg) = p(worg|wtrgi)p(wtrgi)
wtrgi∈1..n
(1)
</equation>
<bodyText confidence="0.997645818181818">
where p(worg|wtrgi) is the posterior probability of
mapping, which is computed as the product of the
mappings required to generate worg from wtrgi,
and p(wtrgi) is the prior probability of the word.
Then we used a trigram LM to pick the most likely
candidate in context. We used a linear combination
of the the character-level transformation probability
and the LM probability using the following formula:
score = Alog(ProbLM) + (1 − A)log(Probchar)
We built the lexicon from a set of 234,638 Aljazeera
articles1 that span 10 years and all of Arabic
Wikipedia. We also built a trigram language
model on the same corpus. The combined corpus
contains 576 million tokens including 1.6 million
unique ones. Spelling mistakes in Aljazeera arti-
cles (Mubarak et al., 2010) and Wikipedia were
infrequent.
We varied the value of A between 0 and 1 with in-
crements of 0.1 and found that the values 0.6 and 0.7
yielded the best results. This indicates that LM prob-
ability is more important than character-mapping
probability.
</bodyText>
<subsectionHeader confidence="0.991879">
2.2 Case-specific Correction
</subsectionHeader>
<bodyText confidence="0.99988">
In this method we attempted to address specific
types of errors that are potentially difficult for the
character-based model to handle. Some of these er-
rors include dialectal words and words that were er-
roneously split. Before applying any correction, we
consulted a bigram LM that was trained the afore-
mentioned set of Aljazeera articles. The following
</bodyText>
<footnote confidence="0.640201">
1http://www.aljazeera.net
</footnote>
<bodyText confidence="0.605161">
cases are handled (in order):
</bodyText>
<listItem confidence="0.7978349">
• Switching from English punctuations to Arabic
ones, namely changing: “?” → “?” and “,” → “,”.
• Handling common dialectal words and common
word-level mistakes. An example dialectal word is
úÎË@ (Ally)2 (meaning “this” or “that”) which could
�
be mapped to ø
.aË@ (Al*y) , ú
~æË@ (Alty) or �K
YË@
</listItem>
<bodyText confidence="0.822775833333333">
(Al*yn). An example of a common mistake is ZA &amp;3@
éÊË@ (An$A’ Allh) (meaning “God willing”) which is
corrected to éÊË@ ZAƒY v@ (&gt;n $A’ Allh). The sen-
tence is scored with and without the word replace-
ment, and the replacement is done if it yields higher
LM probability.
</bodyText>
<listItem confidence="0.9536851875">
• Handling errors pertaining to the different forms
of alef, alef maqsoura and ya, and ta marbouta
and ha (Nizar Habash, 2010). We reimplemented
the baseline system in (Moussa et al., 2012) where
words are normalized and the different possible de-
normalized forms are scored in context using the
LM. We also added the following cases, namely at-
tempting to replace: 9 (&amp;) with ð 9 (&amp;w) or ñ�K
(}w); and S (}) with Zø� (y’) or vice versa (ex:
€ðQÓ (mr&amp;s) → €ððQÓ (mr&amp;ws)).
�
• Handling merges and splits. Often words are
concatenated erroneously. Thus, we attempted to
split all words that were at least 5 letters long af-
ter letters that don’t change their shapes when they
are connected to the letters following them, namely
</listItem>
<bodyText confidence="0.986380666666667">
different alef forms, X (d), X� (*),P (r), P (z), ð (w), -è
(p), and ø (Y) (ex: A JK.PAK� (yArbnA) → A�JK.P AK� (yA
rbnA)). If the bigram was observed in the LM and
the LM score was higher (in context) than when they
were concatenated, then the word was split. Con-
versely, some words were split in the middle. We
attempted to merge every two words in sequence.
If the LM score was higher (in context) after the
merge, then the two words would be merged (ex:
</bodyText>
<footnote confidence="0.88128">
2Buckwalter transiteration
</footnote>
<page confidence="0.990241">
133
</page>
<listItem confidence="0.895086">
v@ PA’z@ (AntSAr At) → v@PA’Z@ (AntSArAt)).
• Removing repeated letters. Often people repeat
letters, particularly long vowels, for emphasis as in
�
@@@Q��J�J�J� k @ (&gt;xyyyyrAAA) (meaning “at last”). We
corrected for elongation in a manner similar to that
of Darwish et al. (Darwish et al., 2012). When a
long vowel are repeated, we replaced it with a either
the vowel (ex. @Q~
g@) (&gt;xyrA) or the vowel with one
repetition (ex. @Q��J_ �k�@) (&gt;xyyrA) and scored using
the LM. If a repeated alef appeared in the beginning
of the word, we attempted to replace it with alef lam
(ex. &amp;quot;èPA .ok@@ (AAHDArp) → SPA mÌ @ (AlHDArp)
(meaning “civilization”)). A trailing alef-hamza-
alef sequence was replaced by alef-hamza (ex. @ ZAÖÞ...
(smA’A) → ZAÖÞ... (smA’) (meaning “sky”)).
• Correcting out-of-vocabulary words. For words
that were not observed in the LM, we attempted the
following corrections: 1) replacing phonetically or
</listItem>
<bodyText confidence="0.808415846153846">
visually confusable letters, namely • (D) and
(Z), X (d) and X� (*), and X� (*) and s; (z) (ex: ¡�A£�
(ZAbT) → ¡jA “� (DAbT)) 2) removing the letters
H. (b) and X (d) that are added to verbs in present
tense in some dialects (ex: I. :ºJ�K. (byktb) → I. &amp;quot;JºK�
(yktb)); 3) replacing the letters h(H) and è (h),
which are added in some dialects to indicate future
tense, with € (s) (ex: H. Qå:J
k (Hy$rb) → H. Qå:J�ƒ
(sy$rb)); and 4) replacing a leading ÈAë (hAl) with
either È@ @�Yë (h*A Al) or È@ è 11 (h*h Al) (ex.
H. A:ºËAë (hAlktAb) → H. A:ºË@ @.aë (h*A AlktAb))
and the leading ÈA« (EAl) with È@ úÎ« (ElY Al) (ex.
</bodyText>
<equation confidence="0.951842">
•P �
BA« (EAl&gt;rD) → voP�B@ úÎ«(ElY Al&gt;rD)).
</equation>
<bodyText confidence="0.924284">
After replacement, the LM was always consulted.
</bodyText>
<subsectionHeader confidence="0.996257">
2.3 Correction Results
</subsectionHeader>
<bodyText confidence="0.520341">
Table 1 reports on the results of performing both cor-
rection methods on the development set. Also, since
</bodyText>
<table confidence="0.9971508">
Method F-measure
Character-level 0.574
Case-specific 0.587
Character-level → Case-specific 0.615
Case-specific → Character-level 0.603
</table>
<tableCaption confidence="0.997764">
Table 1: The correction results using the character-level
model, case-specific correction, or their cascades.
</tableCaption>
<bodyText confidence="0.999762166666667">
the case-specific corrections handle cases that were
not handled by the character-level model, we at-
tempted to cascade both methods together. It seems
that when applying the character-level model first
followed by the case-specific correction yielded the
best results.
</bodyText>
<sectionHeader confidence="0.969621" genericHeader="method">
3 Punctuation Recovery
</sectionHeader>
<bodyText confidence="0.999941333333333">
In this section, we describe two methods for punc-
tuation recovery. The first is a simple word-based
model and the other is a CRF based model.
</bodyText>
<subsectionHeader confidence="0.998889">
3.1 Simple Statistical Model
</subsectionHeader>
<bodyText confidence="0.999952875">
In this approach, we identified words that were pre-
ceded or followed by punctuations in the training
set. If a word was preceded or followed by a par-
ticular punctuation mark more than 40% of the time,
then we automatically placed the punctuation before
or after the word in the dev set. Also, if a sentence
did not have a period at the end of it, we added a
period.
</bodyText>
<subsectionHeader confidence="0.985133">
3.2 CRF Model
</subsectionHeader>
<bodyText confidence="0.997914583333333">
In this approach we trained a CRF sequence labeling
to attempt to recover punctuation. CRF combines
state and transition level features making it a pos-
sibly better choice than an HMM or a simple clas-
sifier. We used the CRF++ implementation3 of the
sequence labeler. We trained the labeler on the train-
ing part of the QALB dataset. We used the following
features:
Word features: the current word, the previous and
next words, and the two previous and two next
words.
Part-of-speech (POS) tags: the POS of the current
</bodyText>
<footnote confidence="0.95632">
3 http://crfpp.googlecode.com/svn/trunk/
doc/index.html
</footnote>
<page confidence="0.988645">
134
</page>
<table confidence="0.999616333333333">
Method Precision Recall F-measure
Stat model 0.306 0.153 0.204
CRF model 0.373 0.141 0.204
</table>
<tableCaption confidence="0.8755635">
Table 2: The punctuation recovery results using the sim-
ple statistical model and the CRF model.
</tableCaption>
<table confidence="0.9997604">
Method F-measure
Stat model (before correction) 0.593
Stat model (after correction) 0.614
CRF model (before correction) 0.607
CRF model (after correction) 0.615
</table>
<tableCaption confidence="0.9824385">
Table 3: Cascaded correction (Character-level → Case-
specific) combined with punctuation recovery.
</tableCaption>
<bodyText confidence="0.9587765">
word and the POS of the two previous and two fol-
lowing words.
</bodyText>
<subsectionHeader confidence="0.999199">
3.3 Punctuation Recovery Results
</subsectionHeader>
<bodyText confidence="0.916226">
Table 2 reports on the results of using the two differ-
ent methods for punctuation recovery. Note that no
other correction is applied.
</bodyText>
<sectionHeader confidence="0.984829" genericHeader="method">
4 Combining Correction with Punctuation
Recovery
</sectionHeader>
<bodyText confidence="0.999936111111111">
Given that cascading both correction models yielded
the best results, we attempted to combine the cas-
caded correction model with the two punctuation re-
covery methods. We tried to put punctuation recov-
ery before and after correction. Table 3 summarizes
the results. As the results suggest, combining cor-
rection with punctuation recovery had a negative ef-
fect on overall F-measure. This requires further in-
vestigation.
</bodyText>
<sectionHeader confidence="0.9989705" genericHeader="method">
5 Official Shared Task Experiments and
Results
</sectionHeader>
<bodyText confidence="0.999186">
For the official submissions to the shared task, we
submitted 3 runs as follows:
</bodyText>
<listItem confidence="0.985652333333333">
1. QCRI-1: character-level correction, then case-
based correction.
2. QCRI-2: case-based correction, then statistical
punctuation recovery
3. QCRI-3: exactly like 2, but preceded also by
statistical punctuation recovery
</listItem>
<table confidence="0.9997005">
Run Precision Recall F-measure
QCRI-1 0.717 0.5686 0.6343
QCRI-2 0.6286 0.6032 0.6157
QCRI-3 0.6066 0.5928 0.5996
</table>
<tableCaption confidence="0.9892525">
Table 4: Official Results.
Table 4 reports on the officially submitted results
against the test set. It seems that our attempts to add
punctuation recovery worsened results.
</tableCaption>
<sectionHeader confidence="0.997151" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999935142857143">
In this paper, we presented automatic approaches
for correcting Arabic text and punctuation recovery.
Our results on the development set shows that using
a cascaded approach that involves a character-level
model and another model that handles specific errors
yields the best results. Incorporating punctuation re-
covery did not improve correction.
</bodyText>
<sectionHeader confidence="0.998337" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999612689655172">
Kareem Darwish, Walid Magdy, and Ahmed Mourad.
2012. Language processing for arabic microblog re-
trieval. Proceedings of the 21st ACM international
conference on Information and knowledge manage-
ment. ACM, 2012.
Ali El-Kahky, Kareem Darwish, Ahmed Saad Aldein,
Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed
Ammar. 2001. Improved transliteration mining using
graph reinforcement. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, pp. 1384-1393, 2011.
Nizar Habash. 2010. Introduction to Arabic natural lan-
guage processing. Synthesis Lectures on Human Lan-
guage Technologies 3.1 (2010): 1-187
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, Evan Herbst, Moses: Open Source Toolkit
for Statistical Machine Translation, Annual Meeting of
the Association for Computational Linguistics (ACL),
demonstration session, Prague, Czech Republic, June
2007.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data, In Proc. of ICML,
pp.282-289, 2001.
Behrang Mohit, Alla Rozovskaya, Nizar Habash, Wajdi
Zaghouani, and Ossama Obeid, 2014. The First QALB
</reference>
<page confidence="0.985064">
135
</page>
<reference confidence="0.999740548387097">
Shared Task on Automatic Text Correction for Arabic.
In Proceedings of EMNLP workshop on Arabic Natu-
ral Language Processing. Doha, Qatar.
Mohammed Moussa, Mohamed Waleed Fakhr, and Ka-
reem Darwish. 2012. Statistical denormalization for
Arabic Text. In Empirical Methods in Natural Lan-
guage Processing, pp. 228. 2012.
Hamdy Mubarak, Ahmed Metwali, Mostafa Ramadan.
2010. Spelling Mistakes in Arabic Newspapers. Arabic
Language and Scientific Researches conference, Fac-
ulty of Arts, Ain Shams University, Cairo, Egypt
Sara Noeman and Amgad Madkour. 2010. Language In-
dependent Transliteration Mining System Using Finite
State Automata Framework. ACL NEWS workshop
2010.
Franz J. Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, Vol. 1(29), 2003.
Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-
sama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura
Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014.
Large Scale Arabic Error Annotation: Guidelines and
Framework. In Proceedings of the Ninth International
Conference on Language Resources and Evaluation
(LREC14), Reykjavik, Iceland.
Min Zhang, A Kumaran, Haizhou Li. 2011. Whitepaper
of NEWS 2012 Shared Task on Machine Translitera-
tion. IJCNLP-2011 NEWS workshop.
Min Zhang, Haizhou Li, Ming Liu, A Kumaran. 2012.
Whitepaper of NEWS 2012 Shared Task on Machine
Transliteration. ACL-2012 NEWS workshop.
</reference>
<page confidence="0.998801">
136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.568546">
<title confidence="0.999695">Automatic Correction of Arabic Text: a Cascaded Approach</title>
<author confidence="0.97732">Hamdy Mubarak</author>
<author confidence="0.97732">Kareem</author>
<affiliation confidence="0.992769">Qatar Computing Research</affiliation>
<address confidence="0.583724">Qatar</address>
<abstract confidence="0.9993874">This paper describes the error correction model that we used for the Automatic Correction of Arabic Text shared task. We employed two correction models, namely a character-level model and a casespecific model, and two punctuation recovery models, namely a simple statistical model and a CRF model. Our results on the development set suggest that using a cascaded correction model yields the best results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
<author>Walid Magdy</author>
<author>Ahmed Mourad</author>
</authors>
<title>Language processing for arabic microblog retrieval.</title>
<date>2012</date>
<booktitle>Proceedings of the 21st ACM international conference on Information and knowledge management. ACM,</booktitle>
<contexts>
<context position="7516" citStr="Darwish et al., 2012" startWordPosition="1234" endWordPosition="1237"> the LM score was higher (in context) than when they were concatenated, then the word was split. Conversely, some words were split in the middle. We attempted to merge every two words in sequence. If the LM score was higher (in context) after the merge, then the two words would be merged (ex: 2Buckwalter transiteration 133 v@ PA’z@ (AntSAr At) → v@PA’Z@ (AntSArAt)). • Removing repeated letters. Often people repeat letters, particularly long vowels, for emphasis as in � @@@Q��J�J�J� k @ (&gt;xyyyyrAAA) (meaning “at last”). We corrected for elongation in a manner similar to that of Darwish et al. (Darwish et al., 2012). When a long vowel are repeated, we replaced it with a either the vowel (ex. @Q~ g@) (&gt;xyrA) or the vowel with one repetition (ex. @Q��J_ �k�@) (&gt;xyyrA) and scored using the LM. If a repeated alef appeared in the beginning of the word, we attempted to replace it with alef lam (ex. &amp;quot;èPA .ok@@ (AAHDArp) → SPA mÌ @ (AlHDArp) (meaning “civilization”)). A trailing alef-hamzaalef sequence was replaced by alef-hamza (ex. @ ZAÖÞ... (smA’A) → ZAÖÞ... (smA’) (meaning “sky”)). • Correcting out-of-vocabulary words. For words that were not observed in the LM, we attempted the following corrections: 1) rep</context>
</contexts>
<marker>Darwish, Magdy, Mourad, 2012</marker>
<rawString>Kareem Darwish, Walid Magdy, and Ahmed Mourad. 2012. Language processing for arabic microblog retrieval. Proceedings of the 21st ACM international conference on Information and knowledge management. ACM, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali El-Kahky</author>
<author>Kareem Darwish</author>
</authors>
<title>Ahmed Saad Aldein, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1384--1393</pages>
<marker>El-Kahky, Darwish, 2001</marker>
<rawString>Ali El-Kahky, Kareem Darwish, Ahmed Saad Aldein, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar. 2001. Improved transliteration mining using graph reinforcement. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1384-1393, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic natural language processing.</title>
<date>2010</date>
<journal>Synthesis Lectures on Human Language Technologies</journal>
<volume>3</volume>
<pages>1--187</pages>
<contexts>
<context position="6134" citStr="Habash, 2010" startWordPosition="990" endWordPosition="991">” and “,” → “,”. • Handling common dialectal words and common word-level mistakes. An example dialectal word is úÎË@ (Ally)2 (meaning “this” or “that”) which could � be mapped to ø .aË@ (Al*y) , ú ~æË@ (Alty) or �K YË@ (Al*yn). An example of a common mistake is ZA &amp;3@ éÊË@ (An$A’ Allh) (meaning “God willing”) which is corrected to éÊË@ ZAƒY v@ (&gt;n $A’ Allh). The sentence is scored with and without the word replacement, and the replacement is done if it yields higher LM probability. • Handling errors pertaining to the different forms of alef, alef maqsoura and ya, and ta marbouta and ha (Nizar Habash, 2010). We reimplemented the baseline system in (Moussa et al., 2012) where words are normalized and the different possible denormalized forms are scored in context using the LM. We also added the following cases, namely attempting to replace: 9 (&amp;) with ð 9 (&amp;w) or ñ�K (}w); and S (}) with Zø� (y’) or vice versa (ex: €ðQÓ (mr&amp;s) → €ððQÓ (mr&amp;ws)). � • Handling merges and splits. Often words are concatenated erroneously. Thus, we attempted to split all words that were at least 5 letters long after letters that don’t change their shapes when they are connected to the letters following them, namely dif</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic natural language processing. Synthesis Lectures on Human Language Technologies 3.1 (2010): 1-187</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<date>2007</date>
<booktitle>Open Source Toolkit for Statistical Machine Translation, Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst, Moses:</location>
<contexts>
<context position="3440" citStr="Koehn et al., 2007" startWordPosition="545" endWordPosition="548">in character-level mappings, we extracted all the parallel word-pairs in the original (uncorrected) and corrected versions in the training set. If a word in the original version of the training set was actually correct, the word would be mapped to itself. We then aligned the parallel word pairs at character level using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag132 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 132–136, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics final-and heuristic (Koehn et al., 2007). In all, we aligned a little over one million word pairs. As in the baseline of El-Kahki et al. (2011), given a possibly misspelled word worg, we produced all its possible segmentations along with their associated mappings that we learned during alignment. Valid target sequences were retained and sorted by the product of the constituent mapping probabilities. The top n (we picked n = 10) candidates, wtrg1..n with the highest probability were generated. Using Bayes rule, we computed: argmax p(wtrgi|worg) = p(worg|wtrgi)p(wtrgi) wtrgi∈1..n (1) where p(worg|wtrgi) is the posterior probability of</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst, Moses: Open Source Toolkit for Statistical Machine Translation, Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data,</title>
<date>2001</date>
<booktitle>In Proc. of ICML,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="1490" citStr="Lafferty et al., 2001" startWordPosition="232" endWordPosition="235">ing word level errors, and the second pertains to performing punctuation recovery. For word level correction, we used two approaches, namely: 1) a statistical character level transformation model that is aided by a language model (LM) to handle letter insertions, deletions, and substitutions and word merges; and 2) a case-specific system that is aided by a LM to handle specific error types such as dialectal word substitutions and word splits. For punctuation recovery, we used two approaches, namely a simple statistical word-based system, and a conditional random fields (CRF) sequence labeler (Lafferty et al., 2001) that attempts to recover punctuation based on POS and word sequences. We performed all experiments on the QALB dataset (Zaghouani et al., 2014). 2 Word Error Correction In this section we describe two approaches for word correction. The first approach involves using a character level model, and the second handles specific correction cases. 2.1 Character-level Correction Model For the character level model, we treated correction as a Transliteration Mining (TM) task. In TM, a sequence in a source alphabet is used to find the most similar sequence in a lexicon that is written in a target alphab</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data, In Proc. of ICML, pp.282-289, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Mohit</author>
<author>Alla Rozovskaya</author>
<author>Nizar Habash</author>
<author>Wajdi Zaghouani</author>
<author>Ossama Obeid</author>
</authors>
<date>2014</date>
<booktitle>The First QALB Shared Task on Automatic Text Correction for Arabic. In Proceedings of EMNLP workshop on Arabic Natural Language Processing.</booktitle>
<location>Doha, Qatar.</location>
<contexts>
<context position="798" citStr="Mohit et al., 2014" startWordPosition="120" endWordPosition="123">his paper describes the error correction model that we used for the Automatic Correction of Arabic Text shared task. We employed two correction models, namely a character-level model and a casespecific model, and two punctuation recovery models, namely a simple statistical model and a CRF model. Our results on the development set suggest that using a cascaded correction model yields the best results. 1 Introduction In This paper, we describe our system for automatic Arabic error correction shared task (QALB2014 Shared Task on Automatic Correction of Arabic) as part of the Arabic NLP workshop (Mohit et al., 2014). Our system is composed of two main steps. The first involves correcting word level errors, and the second pertains to performing punctuation recovery. For word level correction, we used two approaches, namely: 1) a statistical character level transformation model that is aided by a language model (LM) to handle letter insertions, deletions, and substitutions and word merges; and 2) a case-specific system that is aided by a LM to handle specific error types such as dialectal word substitutions and word splits. For punctuation recovery, we used two approaches, namely a simple statistical word-</context>
</contexts>
<marker>Mohit, Rozovskaya, Habash, Zaghouani, Obeid, 2014</marker>
<rawString>Behrang Mohit, Alla Rozovskaya, Nizar Habash, Wajdi Zaghouani, and Ossama Obeid, 2014. The First QALB Shared Task on Automatic Text Correction for Arabic. In Proceedings of EMNLP workshop on Arabic Natural Language Processing. Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammed Moussa</author>
<author>Mohamed Waleed Fakhr</author>
<author>Kareem Darwish</author>
</authors>
<title>Statistical denormalization for Arabic Text.</title>
<date>2012</date>
<booktitle>In Empirical Methods in Natural Language Processing,</booktitle>
<pages>228</pages>
<contexts>
<context position="6197" citStr="Moussa et al., 2012" startWordPosition="998" endWordPosition="1001">ommon word-level mistakes. An example dialectal word is úÎË@ (Ally)2 (meaning “this” or “that”) which could � be mapped to ø .aË@ (Al*y) , ú ~æË@ (Alty) or �K YË@ (Al*yn). An example of a common mistake is ZA &amp;3@ éÊË@ (An$A’ Allh) (meaning “God willing”) which is corrected to éÊË@ ZAƒY v@ (&gt;n $A’ Allh). The sentence is scored with and without the word replacement, and the replacement is done if it yields higher LM probability. • Handling errors pertaining to the different forms of alef, alef maqsoura and ya, and ta marbouta and ha (Nizar Habash, 2010). We reimplemented the baseline system in (Moussa et al., 2012) where words are normalized and the different possible denormalized forms are scored in context using the LM. We also added the following cases, namely attempting to replace: 9 (&amp;) with ð 9 (&amp;w) or ñ�K (}w); and S (}) with Zø� (y’) or vice versa (ex: €ðQÓ (mr&amp;s) → €ððQÓ (mr&amp;ws)). � • Handling merges and splits. Often words are concatenated erroneously. Thus, we attempted to split all words that were at least 5 letters long after letters that don’t change their shapes when they are connected to the letters following them, namely different alef forms, X (d), X� (*),P (r), P (z), ð (w), -è (p), a</context>
</contexts>
<marker>Moussa, Fakhr, Darwish, 2012</marker>
<rawString>Mohammed Moussa, Mohamed Waleed Fakhr, and Kareem Darwish. 2012. Statistical denormalization for Arabic Text. In Empirical Methods in Natural Language Processing, pp. 228. 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamdy Mubarak</author>
<author>Ahmed Metwali</author>
<author>Mostafa Ramadan</author>
</authors>
<title>Spelling Mistakes in Arabic Newspapers. Arabic Language and Scientific Researches conference, Faculty of Arts,</title>
<date>2010</date>
<institution>Shams University,</institution>
<location>Ain</location>
<contexts>
<context position="4754" citStr="Mubarak et al., 2010" startWordPosition="755" endWordPosition="758">gi, and p(wtrgi) is the prior probability of the word. Then we used a trigram LM to pick the most likely candidate in context. We used a linear combination of the the character-level transformation probability and the LM probability using the following formula: score = Alog(ProbLM) + (1 − A)log(Probchar) We built the lexicon from a set of 234,638 Aljazeera articles1 that span 10 years and all of Arabic Wikipedia. We also built a trigram language model on the same corpus. The combined corpus contains 576 million tokens including 1.6 million unique ones. Spelling mistakes in Aljazeera articles (Mubarak et al., 2010) and Wikipedia were infrequent. We varied the value of A between 0 and 1 with increments of 0.1 and found that the values 0.6 and 0.7 yielded the best results. This indicates that LM probability is more important than character-mapping probability. 2.2 Case-specific Correction In this method we attempted to address specific types of errors that are potentially difficult for the character-based model to handle. Some of these errors include dialectal words and words that were erroneously split. Before applying any correction, we consulted a bigram LM that was trained the aforementioned set of Al</context>
</contexts>
<marker>Mubarak, Metwali, Ramadan, 2010</marker>
<rawString>Hamdy Mubarak, Ahmed Metwali, Mostafa Ramadan. 2010. Spelling Mistakes in Arabic Newspapers. Arabic Language and Scientific Researches conference, Faculty of Arts, Ain Shams University, Cairo, Egypt</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Noeman</author>
<author>Amgad Madkour</author>
</authors>
<title>Language Independent Transliteration Mining System Using Finite State Automata Framework.</title>
<date>2010</date>
<booktitle>ACL NEWS workshop</booktitle>
<contexts>
<context position="2744" citStr="Noeman and Madkour, 2010" startWordPosition="438" endWordPosition="441">tudied with multiple evaluation campaigns such as the Named Entities Workshop (NEWS) (Zhang et al., 2011; Zhang et al., 2012). In our work, we adopted a TM system to find corrections appearing in a large Arabic corpus. The system involved learning character (or character-sequence) level mappings between erroneous words and their correct counterparts. Given the character mappings between the erroneous and correct words, we used a generative model that attempts to generate all possible mappings of a source word while restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Specifically, we used the baseline system of El-Kahky et al. (2011). To train character-level mappings, we extracted all the parallel word-pairs in the original (uncorrected) and corrected versions in the training set. If a word in the original version of the training set was actually correct, the word would be mapped to itself. We then aligned the parallel word pairs at character level using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag132 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 132–136, October 25, 2014, Doha, </context>
</contexts>
<marker>Noeman, Madkour, 2010</marker>
<rawString>Sara Noeman and Amgad Madkour. 2010. Language Independent Transliteration Mining System Using Finite State Automata Framework. ACL NEWS workshop 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>1</volume>
<issue>29</issue>
<contexts>
<context position="3168" citStr="Och and Ney, 2003" startWordPosition="508" endWordPosition="511">a generative model that attempts to generate all possible mappings of a source word while restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Specifically, we used the baseline system of El-Kahky et al. (2011). To train character-level mappings, we extracted all the parallel word-pairs in the original (uncorrected) and corrected versions in the training set. If a word in the original version of the training set was actually correct, the word would be mapped to itself. We then aligned the parallel word pairs at character level using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag132 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 132–136, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics final-and heuristic (Koehn et al., 2007). In all, we aligned a little over one million word pairs. As in the baseline of El-Kahki et al. (2011), given a possibly misspelled word worg, we produced all its possible segmentations along with their associated mappings that we learned during alignment. Valid target sequences were retained and sorted by the product of the </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, Vol. 1(29), 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wajdi Zaghouani</author>
</authors>
<title>Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC14),</booktitle>
<location>Reykjavik, Iceland.</location>
<marker>Zaghouani, 2014</marker>
<rawString>Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014. Large Scale Arabic Error Annotation: Guidelines and Framework. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC14), Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>A Kumaran</author>
<author>Haizhou Li</author>
</authors>
<date>2011</date>
<booktitle>Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. IJCNLP-2011 NEWS workshop.</booktitle>
<contexts>
<context position="2223" citStr="Zhang et al., 2011" startWordPosition="352" endWordPosition="355">aset (Zaghouani et al., 2014). 2 Word Error Correction In this section we describe two approaches for word correction. The first approach involves using a character level model, and the second handles specific correction cases. 2.1 Character-level Correction Model For the character level model, we treated correction as a Transliteration Mining (TM) task. In TM, a sequence in a source alphabet is used to find the most similar sequence in a lexicon that is written in a target alphabet. TM has been fairly well studied with multiple evaluation campaigns such as the Named Entities Workshop (NEWS) (Zhang et al., 2011; Zhang et al., 2012). In our work, we adopted a TM system to find corrections appearing in a large Arabic corpus. The system involved learning character (or character-sequence) level mappings between erroneous words and their correct counterparts. Given the character mappings between the erroneous and correct words, we used a generative model that attempts to generate all possible mappings of a source word while restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Specifically, we used the baseline system of El-Kahky et al. (2011). To train</context>
</contexts>
<marker>Zhang, Kumaran, Li, 2011</marker>
<rawString>Min Zhang, A Kumaran, Haizhou Li. 2011. Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. IJCNLP-2011 NEWS workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Haizhou Li</author>
<author>Ming Liu</author>
<author>A Kumaran</author>
</authors>
<date>2012</date>
<booktitle>Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. ACL-2012 NEWS workshop.</booktitle>
<contexts>
<context position="2244" citStr="Zhang et al., 2012" startWordPosition="356" endWordPosition="359">l., 2014). 2 Word Error Correction In this section we describe two approaches for word correction. The first approach involves using a character level model, and the second handles specific correction cases. 2.1 Character-level Correction Model For the character level model, we treated correction as a Transliteration Mining (TM) task. In TM, a sequence in a source alphabet is used to find the most similar sequence in a lexicon that is written in a target alphabet. TM has been fairly well studied with multiple evaluation campaigns such as the Named Entities Workshop (NEWS) (Zhang et al., 2011; Zhang et al., 2012). In our work, we adopted a TM system to find corrections appearing in a large Arabic corpus. The system involved learning character (or character-sequence) level mappings between erroneous words and their correct counterparts. Given the character mappings between the erroneous and correct words, we used a generative model that attempts to generate all possible mappings of a source word while restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Specifically, we used the baseline system of El-Kahky et al. (2011). To train character-level mapp</context>
</contexts>
<marker>Zhang, Li, Liu, Kumaran, 2012</marker>
<rawString>Min Zhang, Haizhou Li, Ming Liu, A Kumaran. 2012. Whitepaper of NEWS 2012 Shared Task on Machine Transliteration. ACL-2012 NEWS workshop.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>