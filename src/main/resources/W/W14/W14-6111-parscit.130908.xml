<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.028372">
<title confidence="0.9967375">
Introducing the SPMRL 2014 Shared Task on Parsing
Morphologically-Rich Languages
</title>
<author confidence="0.935965">
Djam´e Seddah Sandra K¨ubler Reut Tsarfaty
</author>
<affiliation confidence="0.854532">
INRIA &amp; Univ. Paris Sorbonne Indiana University Weizman Institute
</affiliation>
<address confidence="0.819719">
Paris, France Bloomington, IN, USA Rehovot, Israel
</address>
<email confidence="0.998741">
djame.seddah@paris-sorbonne.fr skuebler@indiana.edu reut.tsarfaty@weizmann.ac.il
</email>
<sectionHeader confidence="0.999563" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999735571428572">
This first joint meeting on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis
of Non-Canonical English (SPMRL-SANCL) featured a shared task on statistical parsing of morpholog-
ically rich languages (SPMRL). The goal of the shared task is to allow to train and test different partic-
ipating systems on comparable data sets, thus providing an objective measure of comparison between
state-of-the-art parsing systems on data data sets from a range of different languages. This 2014 SPMRL
shared task is a continuation and extension of the SPMRL shared task, which was co-located with the
SPMRL meeting at EMNLP 2013 (Seddah et al., 2013).
This paper provides a short overview of the 2014 SPMRL shared task goals, data sets, and evaluation
setup. Since the SPMRL 2014 largely builds on the infrastructure established for the SPMRL 2013
shared task, we start by reviewing the previous shared task (§2) and then proceed to the 2014 SPMRL
evaluation settings (§3), data sets (§4), and a task summary (§5). Due to organizational constraints,
this overview is published prior to the submission of all system test runs, and a more detailed overview
including the description of participating systems and the analysis of their results will follow as part of
(Seddah et al., 2014), once the shared task is completed.
</bodyText>
<sectionHeader confidence="0.982254" genericHeader="method">
2 The SPMRL Shared Task 2013
</sectionHeader>
<bodyText confidence="0.94884335">
The SPMRL Shared Task 2013 (Seddah et al., 2013) was organized with the goal of providing standard
data sets, streamlined evaluation metrics, and a set of strong baselines for parsing morphologically rich
languages (MRLs). The goals were both to provide a focal point for researchers interested in parsing
MRLs and consequently to advance the state of the art in this area of research.
The shared task focused on parsing nine morphologically rich languages, from different typological
language families, in both a constituent-based and a dependency-based format. The set of nine typolog-
ically diverse languages comprised data sets for Arabic, Basque, French, German, Hebrew, Hungarian,
Korean, Polish, and Swedish. Compared to previous multilingual shared tasks (Buchholz and Marsi,
2006; Nivre et al., 2007), the SPMRL shared task targeted parsing in realistic evaluation scenarios, in
which the analysis of morphologically ambiguous input tokens is not known in advance. An additional
novelty of the SPMRL shared task is that it allowed for both a dependency-based and a constituent-
based parse representation. This setting relied on an intricate and careful data preparation process which
ensured consistency between the constituent and the dependency version by aligning the two representa-
tion types at the token level and at the level of part-of-speech tags. For all languages, we provided two
versions of the data sets: an all data set, identical in size to the one made available by the individual
treebank providers, and a small data set, with a training set of 5,000 sentences, and a test set of about 500
sentences. Controlling the set sizes across languages allows us to level the playing field across languages
and treebanks.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
</bodyText>
<page confidence="0.967946">
103
</page>
<subsectionHeader confidence="0.559254">
First Joint Workshop on Statistical Parsing of Morphologically Rich Languages
and Syntactic Analysis of Non-Canonical Languages, pages 103–109 Dublin, Ireland, August 23-29 2014.
</subsectionHeader>
<bodyText confidence="0.999990846153846">
The shared task also advanced the state of the art by introducing different levels of complexity in
parsing. In general, parsing is reduced to the parsing proper step, assuming gold segmentation of the
text into sentences and words as well as gold POS tags and morphological analyses. This is a serious
simplification of the task since especially in Semitic languages, the segmentation into input tokens is a
task that is best performed in combination with parsing because of the ambiguities involved.
The shared task deviated from this standard configuration by adding conditions in which more realistic
settings were given: In the gold setting, unambiguous gold morphological segmentation, POS tags, and
morphological features for each input token were given. In the predicted setting, disambiguated morpho-
logical segmentation was provided, but the POS tags and morphological features for each input segment
were not. In the raw setting, there was no gold information, i.e., morphological segmentation, POS tags
and morphological features for each input token had to be predicted as part of the parsing task. To lower
the entry cost, participants were provided with reasonable baseline (if not state-of-the-art) morphological
predictions (either disambiguated – in most cases– or ambiguous prediction in lattice forms).
As a consequence of the raw scenario, it was not possible to (only) rely on the accepted parsing met-
rics, labeled bracket evaluation via EVALB1 (Black et al., 1991), Leaf-Ancestor (Sampson and Babarczy,
2003) for constituents and CONLL X’s Labeled/Unlabeled Attachment Score for dependencies (Buch-
holz and Marsi, 2006). When the segmentation of words into input tokens is not given, there may be
discrepancies on the lexical levels, which neither EVALB and LEAF-ANCESTOR nor LAS/UAS are pre-
pared to handle. Thus, we also used TedEval, a distance-based metric that evaluates a morphosyntactic
structure as a complete whole (Tsarfaty et al., 2012b). Note that given the workload brought to the par-
ticipants, we did not try to enforce function label evaluation for constituent parsing. We hope that further
shared tasks will try to generalize such an evaluation. Indeed, having predicted function labels would
ease labeled TEDEVAL evaluation and favor a full parsing chain evaluation. Nevertheless, the choice of
TEDEVAL allowed us to go beyond the standard cross-parser evaluation within one setting and approach
cross-framework (constituent vs. dependency (Tsarfaty et al., 2012a)) and cross-language evaluation,
thus pushing the envelope on parsing evaluation. Additionally, we performed a specialized evaluation of
multi-word expressions in the French treebank.
The SPMRL Shared Task 2013 featured seven teams who approached the dependency parsing task
and one team that approached constituent parsing. The best performing system (Bj¨orkelund et al., 2013)
in either framework consisted of an ensemble system, combining several dependency parsers or sev-
eral instantiations of a PCFG-LA parser by a (re-)ranker, both on top of state-of-the-art morphological
analyses. The results show that parser combination helps to reach a robust performance across lan-
guages. However, the integration of morphological analysis into the parsing needs to be investigated
thoroughly, and new, morphologically aware approaches are needed. The cross-parser, cross-scenario,
and cross-framework evaluation protocols show that performance on gold morphological input is signif-
icantly higher than that in more realistic scenarios, and more training data is beneficial. Additionally,
differences between dependency and constituents are smaller than previously assumed, and languages
which are typologically farthest from English, such as Semitic and Asian languages, are still amongst
the hardest to parse, regardless of the parsing method used.
</bodyText>
<sectionHeader confidence="0.989604" genericHeader="method">
3 SPMRL 2014 Parsing Scenarios
</sectionHeader>
<bodyText confidence="0.999841">
As in the previous edition, this year, we consider three parsing scenarios, depending on how much of the
morphological information is provided. The scenarios are listed below, in increasing order of difficulty.
</bodyText>
<listItem confidence="0.997147333333333">
• Gold: In this scenario, the parser is provided with unambiguous gold morphological segmentation,
POS tags, and morphological features for each input token.
• Predicted: In this scenario, the parser is provided with disambiguated morphological segmentation.
However, the POS tags and morphological features for each input segment are unknown.
• Raw: In this scenario, the parser is provided with morphologically ambiguous input. The morpho-
logical segmentation, POS tags, and morphological features for each input token are unknown.
</listItem>
<footnote confidence="0.978357">
1We extended the usualEVALB to penalize unparsed sentences.
</footnote>
<page confidence="0.994627">
104
</page>
<bodyText confidence="0.610199">
Scenario Segmentation PoS+Feat. Tree
</bodyText>
<equation confidence="0.9848115">
Gold ✓ ✓ –
Predicted ✓ 1-best –
Raw (1-best) 1-best 1-best –
Raw (all) – – –
</equation>
<tableCaption confidence="0.844994">
Table 1: A summary of the parsing and evaluation scenarios. ✓ depicts gold information, – depicts
unknown information, to be predicted by the system.
</tableCaption>
<bodyText confidence="0.981309333333333">
The Predicted and Raw scenarios require predicting morphological analyses. This may be done using
a language-specific morphological analyzer, or it may be done jointly with parsing. We provide inputs
that support these different scenarios:
</bodyText>
<listItem confidence="0.976356166666667">
• Predicted: Gold treebank segmentation is given to the parser. The POS tags assignment and mor-
phological features are automatically predicted by the parser or by an external resource.
• Raw (1-best): The 1-best segmentation and POS tags assignment is predicted by an external re-
source and given to the parser.
• Raw (all): All possible segmentations and POS tags are specified by an external resource. The
parser selects jointly a segmentation and a tree.
</listItem>
<bodyText confidence="0.827853666666667">
An overview of all scenarios is shown in table 1. For languages in which terminals equal tokens, only
Gold and Predicted scenarios are considered. For the Semitic languages, we further provide input for
both Raw (1-best) and Raw (all) scenarios.2
</bodyText>
<sectionHeader confidence="0.98668" genericHeader="method">
4 SPMRL 2014 Data Sets
</sectionHeader>
<bodyText confidence="0.99996875">
The main innovation of the SPMRL 2014 shared task with respect to the previous edition is the availabil-
ity of additional, unannotated data, for the purpose of semi-supervised training. This section provides
a description of the unlabeled-data preparation that is required in the context of parsing MRLs, and the
core labeled data that is used in conjunction with it.
</bodyText>
<subsectionHeader confidence="0.979635">
4.1 SPMRL Unlabeled Data Set
</subsectionHeader>
<bodyText confidence="0.999962588235294">
One of the common problems when dealing with morphologically rich languages (MRLs) is lexical data
sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c).
The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL
data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown
et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito
and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for
Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing
German (Rehbein, 2011), and more recently, the use of word embeddings led to some promising results
for some MRLs (Cirik and S¸ensoy, 2013).
By releasing large, unlabeled data sets and by providing accurate pre-annotation in a format directly
compatible with models trained on the SPMRL Shared Task treebanks, we hope to foster the development
of interesting and feature-rich parsing models that build on larger, morphologically rich, lexicons. Table
2 presents basic facts about the data sets. Details on the unlabeled data and their pre-annotations will
be provided in (Seddah et al., 2014). Note that we could not ensure the same volume of data for all
languages, nor we could run the same parser, or morphology prediction, on all data. Potential future work
could focus on ensuring a stricter level of comparability of these data or on investigating the feasibility
of such a normalization of procedures.
</bodyText>
<footnote confidence="0.966674">
2The raw Arabic lattices were made available later than the other data. They are now included in the shared task release.
</footnote>
<page confidence="0.967136">
105
</page>
<table confidence="0.9999484">
Language Source (main) type size (tree tokens) morph parsed
Arabic news domain news 120M ✓* ✓*
Basque web balanced 150M ✓ ✓
French news domain newswire 120M ✓+mwe ✓*
German Wikipedia wiki (edited) 205M ✓ ✓
Hebrew Wikipedia wiki (edited) 160M ✓ ✓
Hungarian news domain newswire 100M ✓ ✓
Korean news domain newswire 40M ✓ ✓*
Polish Wikipedia wiki (edited) 100M ✓ ✓
Swedish PAROLE balanced 24M ✓ ✓
</table>
<tableCaption confidence="0.998234">
Table 2: Unlabeled data set properties.*: made available mid-july
</tableCaption>
<subsectionHeader confidence="0.897341">
4.2 SPMRL Core Labeled Data Set
</subsectionHeader>
<bodyText confidence="0.999942541666667">
In order to provide a faithful evaluation of the impact of these additional sets of unlabeled data, we used
the exact same data sets for training and testing as in the previous edition. Specifically, we used an Arabic
data set, originally provided by the LDC (Maamouri et al., 2004), in a dependency form, derived from the
Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) and in a constituency instance,
following the Stanford pre-processing scheme (Green and Manning, 2010) and extended according to the
SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et
al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both
instances could be aligned at the token level. Regarding French, we used a new instance of the French
Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the
morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as
Constant et al. (2013). The German data are based on the Tiger corpus (Brants et al., 2002), and converted
to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the
Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn
aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in
order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8.
The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010),
while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to
dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in
(Woli´nski et al., 2011; ´Swidzi´nski and Woli´nski, 2010; Wr´oblewska, 2012). Compared to the last year’s
edition, we added explicit feature names in the relevant data fields. The Swedish data originate from
(Nivre et al., 2006), we added function labels extracted from the original Swedish XML data. Note
that in addition to constituency and dependency versions, the Polish, German and Swedish data sets are
also available in the Tiger XML format (Mengel and Lezius, 2000), allowing a direct representation of
discontinuous structures in their phrase-based structures.
</bodyText>
<sectionHeader confidence="0.997767" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99965">
At the time of writing this short introduction, the shared task is ongoing, and neither results nor the final
submitting teams are known. At this point, we can say that 15 teams registered for the 2014 shared
task edition, indicating an increased awareness of and continued interest in the topic of the shared task.
Results, cross-parser and cross-data analysis, and shared task description papers will be made available
at http://www.spmrl.org/spmrl2014-sharedtask.html.
</bodyText>
<sectionHeader confidence="0.996457" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999925">
We would like to express our gratitude to the original treebank labeled and unlabeled data contribu-
tors for the considerable time they devoted to our shared task. Namely, Arabic: Nizar Habash, Ryan
Roth (Columbia University); Spence Green (Stanford University) , Ann Bies, Seth Kulick, Mohamed
Maamouri (the Linguistic Data Consortium) ; Basque: Koldo Gojenola, Iakes Goenaga (University of
the Basque Country) ; French: Marie Candito (Univ. Paris 7 &amp; Inria), Djam´e Seddah (Univ. Paris
Sorbonne &amp; Inria) , Matthieu Constant (Univ. Marne la Vall´ee) ; German: Wolfgang Seeker (IMS
</bodyText>
<page confidence="0.99679">
106
</page>
<bodyText confidence="0.986511444444444">
Stuttgart), Wolfgang Maier (Univ. of Dusseldorf), Yannick Versley (Univ. of Tuebingen) ; Hebrew:
Yoav Goldberg (Bar Ilan Univ.), Reut Tsarfaty (Weizmann Institute of Science) ; Hungarian: Rich`ard
Farkas, Veronika Vincze (Univ. of Szeged) ; Korean: Jinho D. Choi (Univ. of Massachusetts Amherst),
Jungyeul Park (Kaist); Polish: Adam Przepi´orkowski, Marcin Woli´nski, Alina Wr´oblewska (Institute
of Computer Science, Polish Academy of Sciences) ; Swedish: Joakim Nivre (Uppsala Univ.), Marco
Kuhlmann (Link¨oping University).
We gratefully acknowledge the contribution of Spr˚akbanken and the University of Gothenburg for
providing the PAROLE corpus. We are also very grateful to the Philosophical Faculty of the Heinrich-
Heine Universit¨at D¨usseldorf for hosting the shared task data via their dokuwiki.
</bodyText>
<sectionHeader confidence="0.991191" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999034358974359">
Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel. 2003. Building a treebank for French. In Anne Abeill´e,
editor, Treebanks. Kluwer, Dordrecht.
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. D´ıaz de Ilarraza, A. Garmendia, and M. Oronoz. 2003.
Construction of a Basque dependency treebank. In Proceedings of the Second Workshop on Treebanks and
Linguistic Theories, pages 201–204, V¨axj¨o, Sweden.
Anders Bj¨orkelund, Ozlem Cetinoglu, Rich´ard Farkas, Thomas Mueller, and Wolfgang Seeker. 2013. (Re)ranking
meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task. In Proceedings of the Fourth
Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 134–144, Seattle, WA.
Ezra Black, Steven Abney, Dan Flickinger, Claudia Gdaniec, Ralph Grishman, Philip Harrison, Donald Hindle,
Robert Ingria, Frederick Jelinek, Judith Klavans, Mark Liberman, Mitchell Marcus, Salim Roukos, Beatrice
Santorini, and Tomek Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage
of English grammars. In Proceedings of the DARPA Speech and Natural Language Workshop 1991, pages
306–311, Pacific Grove, CA.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER treebank.
In Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT), pages 24–41, Sozopol,
Bulgaria.
Peter F. Brown, Vincent J. Della, Peter V. Desouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Class-based
n-gram models of natural language. Computational Linguistics, 18(4):467–479.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceed-
ings of CoNLL, pages 149–164, New York, NY.
Marie Candito and Benoit Crabb´e. 2009. Improving generative statistical parsing with semi-supervised word
clustering. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages
138–141, Paris, France.
Marie Candito and Djam´e Seddah. 2010. Parsing word clusters. In Proceedings of the NAACL/HLT Workshop on
Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), Los Angeles, CA.
Key-sun Choi, Young S. Han, Young G. Han, and Oh W. Kwon. 1994. KAIST Tree Bank Project for Korean:
Present and Future Development. In In Proceedings of the International Workshop on Sharable Natural Lan-
guage Resources, pages 7–14, Nara, Japan.
Jinho D. Choi. 2013. Preparing Korean data for the shared task on parsing morphologically rich languages.
arXiv:1309.1649.
Volkan Cirik and H¨usn¨u S¸ensoy. 2013. The AI-KU system at the SPMRL 2013 shared task: Unsupervised features
for dependency parsing. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich
Languages, pages 68–75, Seattle, WA.
Matthieu Constant, Marie Candito, and Djam´e Seddah. 2013. The LIGM-Alpage architecture for the SPMRL
2013 shared task: Multiword expression analysis and dependency parsing. In Proceedings of the Fourth Work-
shop on Statistical Parsing of Morphologically-Rich Languages, pages 46–52, Seattle, WA.
D´ora Csendes, J´anos Csirik, Tibor Gyim´othy, and Andr´as Kocsor. 2005. The Szeged treebank. In Proceedings
of the 8th International Conference on Text, Speech and Dialogue (TSD), Lecture Notes in Computer Science,
pages 123–132, Berlin / Heidelberg. Springer.
</reference>
<page confidence="0.993172">
107
</page>
<reference confidence="0.9967175">
Yoav Goldberg, Reut Tsarfaty, Meni Adler, and Michael Elhadad. 2009. Enhancing unlexicalized parsing per-
formance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities.
In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL), pages 327–335, Athens,
Greece.
Yoav Goldberg. 2011. Automatic syntactic processing of Modern Hebrew. Ph.D. thesis, Ben Gurion University of
the Negev.
Spence Green and Christopher D. Manning. 2010. Better Arabic parsing: Baselines, evaluations, and analysis. In
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 394–402,
Beijing, China.
Nizar Habash and Ryan Roth. 2009. CATiB: The Columbia Arabic Treebank. In Proceedings of ACL-IJCNLP,
pages 221–224, Suntec, Singapore.
Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syntactic Annotation in the Columbia Arabic Treebank. In
Proceedings of MEDAR International Conference on Arabic Language Resources and Tools, Cairo, Egypt.
Nizar Habash. 2008. Four techniques for online handling of out-of-vocabulary words in Arabic-English statistical
machine translation. In Proceedings of ACL-08: HLT, Short Papers, pages 57–60, Columbus, OH.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic treebank: Build-
ing a large-scale annotated Arabic corpus. In Proceedings of NEMLAR International Conference on Arabic
Language Resources and Tools, pages 102–109, Cairo, Egypt.
Andreas Mengel and Wolfgang Lezius. 2000. An XML-based encoding format for syntactically annotated cor-
pora. In Proceedings of the Second International Conference on Language Resources and Engineering (LREC
2000), pages 121–126, Athens, Greece.
Joakim Nivre, Jens Nilsson, and Johan Hall. 2006. Talbanken05: A Swedish treebank with phrase structure and
dependency annotation. In Proceedings of LREC, pages 1392–1395, Genoa, Italy.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session
of EMNLP-CoNLL 2007, pages 915–932, Prague, Czech Republic.
Ines Rehbein. 2011. Data point selection for self-training. In Proceedings of the Second Workshop on Statistical
Parsing of Morphologically Rich Languages, pages 62–67, Dublin, Ireland.
Geoffrey Sampson and Anna Babarczy. 2003. A test of the leaf-ancestor metric for parse accuracy. Natural
Language Engineering, 9(04):365–380.
Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho D. Choi, Rich´ard Farkas, Jennifer Foster, Iakes
Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolf-
gang Maier, Joakim Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika
Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Clergerie. 2013. Overview of the
SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages. In Pro-
ceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 146–182,
Seattle, WA.
Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho Choi, Matthieu Constant, Rich´ard Farkas,
Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang
Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze,
Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Cl´ergerie. 2014. Overview of the spmrl 2014
shared task on parsing morphologically rich languages. In Notes of the SPMRL 2014 Shared Task on Parsing
Morphologically-Rich Languages, Dublin, Ireland.
Wolfgang Seeker and Jonas Kuhn. 2012. Making Ellipses Explicit in Dependency Conversion for a German
Treebank. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages
3132–3139, Istanbul, Turkey.
Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altmann, and Noa Nativ. 2001. Building a tree-bank of Modern
Hebrew text. Traitement Automatique des Langues, 42:347–380.
Marek ´Swidzi´nski and Marcin Woli´nski. 2010. Towards a bank of constituent parse trees for Polish. In Proceed-
ings of Text, Speech and Dialogue, pages 197–204, Brno, Czech Republic.
</reference>
<page confidence="0.986859">
108
</page>
<reference confidence="0.998974210526316">
Reut Tsarfaty, Djame Seddah, Yoav Goldberg, Sandra K¨ubler, Marie Candito, Jennifer Foster, Yannick Versley,
Ines Rehbein, and Lamia Tounsi. 2010. Statistical parsing for morphologically rich language (SPMRL): What,
how and whither. In Proceedings of the First workshop on Statistical Parsing of Morphologically Rich Lan-
guages (SPMRL), Los Angeles, CA.
Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2012a. Cross-framework evaluation for statistical parsing.
In Proceeding of EACL, Avignon, France.
Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2012b. Joint evaluation for segmentation and parsing. In
Proceedings of ACL, Jeju, Korea.
Reut Tsarfaty, Djam´e Seddah, Sandra K¨ubler, and Joakim Nivre. 2012c. Parsing morphologically rich languages:
Introduction to the special issue. Computational Linguistics, 39(1):15–22.
Reut Tsarfaty. 2010. Relational-Realizational Parsing. Ph.D. thesis, University of Amsterdam.
Reut Tsarfaty. 2013. A unified morpho-syntactic scheme of Stanford dependencies. In Proceedings ofACL, Sofia,
Bulgaria.
Veronika Vincze, D´ora Szauter, Attila Alm´asi, Gy¨orgy M´ora, Zolt´an Alexin, and J´anos Csirik. 2010. Hungarian
Dependency Treebank. In Proceedings of LREC, Valletta, Malta.
Marcin Woli´nski, Katarzyna Głowi´nska, and Marek ´Swidzi´nski. 2011. A preliminary version of Składnica—a
treebank of Polish. In Proceedings of the 5th Language &amp; Technology Conference, pages 299–303, Pozna´n,
Poland.
Alina Wr´oblewska. 2012. Polish Dependency Bank. Linguistic Issues in Language Technology, 7(1):1–15.
</reference>
<page confidence="0.998954">
109
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.793999">
<title confidence="0.9943485">Introducing the SPMRL 2014 Shared Task on Morphologically-Rich Languages</title>
<author confidence="0.873255">Djam´e Seddah Sandra K¨ubler Reut Tsarfaty</author>
<affiliation confidence="0.999253">INRIA &amp; Univ. Paris Sorbonne Indiana University Weizman Institute</affiliation>
<address confidence="0.998739">Paris, France Bloomington, IN, USA Rehovot, Israel</address>
<email confidence="0.919376">djame.seddah@paris-sorbonne.frskuebler@indiana.edureut.tsarfaty@weizmann.ac.il</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Cl´ement</author>
<author>Franc¸ois Toussenel</author>
</authors>
<title>Building a treebank for French.</title>
<date>2003</date>
<editor>In Anne Abeill´e, editor, Treebanks.</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel. 2003. Building a treebank for French. In Anne Abeill´e, editor, Treebanks. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>M J Aranzabe</author>
<author>J M Arriola</author>
<author>A Atutxa</author>
<author>A D´ıaz de Ilarraza</author>
<author>A Garmendia</author>
<author>M Oronoz</author>
</authors>
<title>Construction of a Basque dependency treebank.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second Workshop on Treebanks and Linguistic Theories,</booktitle>
<pages>201--204</pages>
<location>V¨axj¨o,</location>
<marker>Aduriz, Aranzabe, Arriola, Atutxa, de Ilarraza, Garmendia, Oronoz, 2003</marker>
<rawString>I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. D´ıaz de Ilarraza, A. Garmendia, and M. Oronoz. 2003. Construction of a Basque dependency treebank. In Proceedings of the Second Workshop on Treebanks and Linguistic Theories, pages 201–204, V¨axj¨o, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Ozlem Cetinoglu</author>
<author>Rich´ard Farkas</author>
<author>Thomas Mueller</author>
<author>Wolfgang Seeker</author>
</authors>
<title>(Re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>134--144</pages>
<location>Seattle, WA.</location>
<marker>Bj¨orkelund, Cetinoglu, Farkas, Mueller, Seeker, 2013</marker>
<rawString>Anders Bj¨orkelund, Ozlem Cetinoglu, Rich´ard Farkas, Thomas Mueller, and Wolfgang Seeker. 2013. (Re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 134–144, Seattle, WA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ezra Black</author>
<author>Steven Abney</author>
<author>Dan Flickinger</author>
<author>Claudia Gdaniec</author>
<author>Ralph Grishman</author>
<author>Philip Harrison</author>
<author>Donald Hindle</author>
<author>Robert Ingria</author>
<author>Frederick Jelinek</author>
<author>Judith Klavans</author>
<author>Mark Liberman</author>
<author>Mitchell Marcus</author>
<author>Salim Roukos</author>
<author>Beatrice Santorini</author>
<author>Tomek Strzalkowski</author>
</authors>
<title>A procedure for quantitatively comparing the syntactic coverage of English grammars.</title>
<date>1991</date>
<booktitle>In Proceedings of the DARPA Speech and Natural Language Workshop</booktitle>
<pages>306--311</pages>
<location>Pacific Grove, CA.</location>
<contexts>
<context position="5314" citStr="Black et al., 1991" startWordPosition="801" endWordPosition="804">phological features for each input segment were not. In the raw setting, there was no gold information, i.e., morphological segmentation, POS tags and morphological features for each input token had to be predicted as part of the parsing task. To lower the entry cost, participants were provided with reasonable baseline (if not state-of-the-art) morphological predictions (either disambiguated – in most cases– or ambiguous prediction in lattice forms). As a consequence of the raw scenario, it was not possible to (only) rely on the accepted parsing metrics, labeled bracket evaluation via EVALB1 (Black et al., 1991), Leaf-Ancestor (Sampson and Babarczy, 2003) for constituents and CONLL X’s Labeled/Unlabeled Attachment Score for dependencies (Buchholz and Marsi, 2006). When the segmentation of words into input tokens is not given, there may be discrepancies on the lexical levels, which neither EVALB and LEAF-ANCESTOR nor LAS/UAS are prepared to handle. Thus, we also used TedEval, a distance-based metric that evaluates a morphosyntactic structure as a complete whole (Tsarfaty et al., 2012b). Note that given the workload brought to the participants, we did not try to enforce function label evaluation for co</context>
</contexts>
<marker>Black, Abney, Flickinger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, Liberman, Marcus, Roukos, Santorini, Strzalkowski, 1991</marker>
<rawString>Ezra Black, Steven Abney, Dan Flickinger, Claudia Gdaniec, Ralph Grishman, Philip Harrison, Donald Hindle, Robert Ingria, Frederick Jelinek, Judith Klavans, Mark Liberman, Mitchell Marcus, Salim Roukos, Beatrice Santorini, and Tomek Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage of English grammars. In Proceedings of the DARPA Speech and Natural Language Workshop 1991, pages 306–311, Pacific Grove, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The TIGER treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>24--41</pages>
<location>Sozopol, Bulgaria.</location>
<contexts>
<context position="13517" citStr="Brants et al., 2002" startWordPosition="2074" endWordPosition="2077"> according to the SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as Constant et al. (2013). The German data are based on the Tiger corpus (Brants et al., 2002), and converted to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the Korean data originate from the Kaist Treebank (Choi et al., 1994) whi</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER treebank. In Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT), pages 24–41, Sozopol, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della</author>
<author>Peter V Desouza</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="10571" citStr="Brown et al., 1992" startWordPosition="1596" endWordPosition="1599"> description of the unlabeled-data preparation that is required in the context of parsing MRLs, and the core labeled data that is used in conjunction with it. 4.1 SPMRL Unlabeled Data Set One of the common problems when dealing with morphologically rich languages (MRLs) is lexical data sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c). The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing German (Rehbein, 2011), and more recently, the use of word embeddings led to some promising results for some MRLs (Cirik and S¸ensoy, 2013). By releasing large, unlabeled data sets and by providing accurate pre-annotation in a format directly compatible with models trained on the SPMRL Shared Task treebanks,</context>
</contexts>
<marker>Brown, Della, Desouza, Lai, Mercer, 1992</marker>
<rawString>Peter F. Brown, Vincent J. Della, Peter V. Desouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>149--164</pages>
<location>New York, NY.</location>
<contexts>
<context position="2483" citStr="Buchholz and Marsi, 2006" startWordPosition="369" endWordPosition="372">aselines for parsing morphologically rich languages (MRLs). The goals were both to provide a focal point for researchers interested in parsing MRLs and consequently to advance the state of the art in this area of research. The shared task focused on parsing nine morphologically rich languages, from different typological language families, in both a constituent-based and a dependency-based format. The set of nine typologically diverse languages comprised data sets for Arabic, Basque, French, German, Hebrew, Hungarian, Korean, Polish, and Swedish. Compared to previous multilingual shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007), the SPMRL shared task targeted parsing in realistic evaluation scenarios, in which the analysis of morphologically ambiguous input tokens is not known in advance. An additional novelty of the SPMRL shared task is that it allowed for both a dependency-based and a constituentbased parse representation. This setting relied on an intricate and careful data preparation process which ensured consistency between the constituent and the dependency version by aligning the two representation types at the token level and at the level of part-of-speech tags. For all languages, we pr</context>
<context position="5468" citStr="Buchholz and Marsi, 2006" startWordPosition="820" endWordPosition="824">nd morphological features for each input token had to be predicted as part of the parsing task. To lower the entry cost, participants were provided with reasonable baseline (if not state-of-the-art) morphological predictions (either disambiguated – in most cases– or ambiguous prediction in lattice forms). As a consequence of the raw scenario, it was not possible to (only) rely on the accepted parsing metrics, labeled bracket evaluation via EVALB1 (Black et al., 1991), Leaf-Ancestor (Sampson and Babarczy, 2003) for constituents and CONLL X’s Labeled/Unlabeled Attachment Score for dependencies (Buchholz and Marsi, 2006). When the segmentation of words into input tokens is not given, there may be discrepancies on the lexical levels, which neither EVALB and LEAF-ANCESTOR nor LAS/UAS are prepared to handle. Thus, we also used TedEval, a distance-based metric that evaluates a morphosyntactic structure as a complete whole (Tsarfaty et al., 2012b). Note that given the workload brought to the participants, we did not try to enforce function label evaluation for constituent parsing. We hope that further shared tasks will try to generalize such an evaluation. Indeed, having predicted function labels would ease labele</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL, pages 149–164, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabb´e</author>
</authors>
<title>Improving generative statistical parsing with semi-supervised word clustering.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>138--141</pages>
<location>Paris, France.</location>
<marker>Candito, Crabb´e, 2009</marker>
<rawString>Marie Candito and Benoit Crabb´e. 2009. Improving generative statistical parsing with semi-supervised word clustering. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 138–141, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Djam´e Seddah</author>
</authors>
<title>Parsing word clusters.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL/HLT Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010),</booktitle>
<location>Los Angeles, CA.</location>
<contexts>
<context position="10702" citStr="Candito and Seddah, 2010" startWordPosition="1618" endWordPosition="1621">t is used in conjunction with it. 4.1 SPMRL Unlabeled Data Set One of the common problems when dealing with morphologically rich languages (MRLs) is lexical data sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c). The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing German (Rehbein, 2011), and more recently, the use of word embeddings led to some promising results for some MRLs (Cirik and S¸ensoy, 2013). By releasing large, unlabeled data sets and by providing accurate pre-annotation in a format directly compatible with models trained on the SPMRL Shared Task treebanks, we hope to foster the development of interesting and feature-rich parsing models that build on larger, morphologically rich, lexic</context>
</contexts>
<marker>Candito, Seddah, 2010</marker>
<rawString>Marie Candito and Djam´e Seddah. 2010. Parsing word clusters. In Proceedings of the NAACL/HLT Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Key-sun Choi</author>
<author>Young S Han</author>
<author>Young G Han</author>
<author>Oh W Kwon</author>
</authors>
<title>KAIST Tree Bank Project for Korean: Present and Future Development. In</title>
<date>1994</date>
<booktitle>In Proceedings of the International Workshop on Sharable Natural Language Resources,</booktitle>
<pages>7--14</pages>
<location>Nara, Japan.</location>
<contexts>
<context position="14113" citStr="Choi et al., 1994" startWordPosition="2169" endWordPosition="2172"> (Brants et al., 2002), and converted to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in (Woli´nski et al., 2011; ´Swidzi´nski and Woli´nski, 2010; Wr´oblewska, 2012). Compared to the last year’s edition, we added explicit feature names in the relevant data fields. The Swedish data originate from (Nivre et al., 2006), we added function labels extracted from the original Swedish XML data. Note that in addition to constituency and dependency versions, the Polish, German and Swedish data sets are also available in the Tiger XML format (Mengel and Lezius, 2000), all</context>
</contexts>
<marker>Choi, Han, Han, Kwon, 1994</marker>
<rawString>Key-sun Choi, Young S. Han, Young G. Han, and Oh W. Kwon. 1994. KAIST Tree Bank Project for Korean: Present and Future Development. In In Proceedings of the International Workshop on Sharable Natural Language Resources, pages 7–14, Nara, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinho D Choi</author>
</authors>
<title>Preparing Korean data for the shared task on parsing morphologically rich languages.</title>
<date>2013</date>
<pages>1309--1649</pages>
<contexts>
<context position="14188" citStr="Choi (2013)" startWordPosition="2184" endWordPosition="2185">ker and Kuhn, 2012). The Hebrew data set is based on the Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in (Woli´nski et al., 2011; ´Swidzi´nski and Woli´nski, 2010; Wr´oblewska, 2012). Compared to the last year’s edition, we added explicit feature names in the relevant data fields. The Swedish data originate from (Nivre et al., 2006), we added function labels extracted from the original Swedish XML data. Note that in addition to constituency and dependency versions, the Polish, German and Swedish data sets are also available in the Tiger XML format (Mengel and Lezius, 2000), allowing a direct representation of discontinuous structures in their phrase-b</context>
</contexts>
<marker>Choi, 2013</marker>
<rawString>Jinho D. Choi. 2013. Preparing Korean data for the shared task on parsing morphologically rich languages. arXiv:1309.1649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Volkan Cirik</author>
<author>H¨usn¨u S¸ensoy</author>
</authors>
<title>The AI-KU system at the SPMRL 2013 shared task: Unsupervised features for dependency parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>68--75</pages>
<location>Seattle, WA.</location>
<marker>Cirik, S¸ensoy, 2013</marker>
<rawString>Volkan Cirik and H¨usn¨u S¸ensoy. 2013. The AI-KU system at the SPMRL 2013 shared task: Unsupervised features for dependency parsing. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 68–75, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthieu Constant</author>
<author>Marie Candito</author>
<author>Djam´e Seddah</author>
</authors>
<title>The LIGM-Alpage architecture for the SPMRL 2013 shared task: Multiword expression analysis and dependency parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>46--52</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="13448" citStr="Constant et al. (2013)" startWordPosition="2061" endWordPosition="2064">e Stanford pre-processing scheme (Green and Manning, 2010) and extended according to the SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as Constant et al. (2013). The German data are based on the Tiger corpus (Brants et al., 2002), and converted to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the </context>
</contexts>
<marker>Constant, Candito, Seddah, 2013</marker>
<rawString>Matthieu Constant, Marie Candito, and Djam´e Seddah. 2013. The LIGM-Alpage architecture for the SPMRL 2013 shared task: Multiword expression analysis and dependency parsing. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 46–52, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D´ora Csendes</author>
<author>J´anos Csirik</author>
<author>Tibor Gyim´othy</author>
<author>Andr´as Kocsor</author>
</authors>
<title>The Szeged treebank.</title>
<date>2005</date>
<booktitle>In Proceedings of the 8th International Conference on Text, Speech and Dialogue (TSD), Lecture Notes in Computer Science,</booktitle>
<pages>123--132</pages>
<publisher>Springer.</publisher>
<location>Berlin / Heidelberg.</location>
<marker>Csendes, Csirik, Gyim´othy, Kocsor, 2005</marker>
<rawString>D´ora Csendes, J´anos Csirik, Tibor Gyim´othy, and Andr´as Kocsor. 2005. The Szeged treebank. In Proceedings of the 8th International Conference on Text, Speech and Dialogue (TSD), Lecture Notes in Computer Science, pages 123–132, Berlin / Heidelberg. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Reut Tsarfaty</author>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL),</booktitle>
<pages>327--335</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="10815" citStr="Goldberg et al., 2009" startWordPosition="1634" endWordPosition="1637">gically rich languages (MRLs) is lexical data sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c). The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing German (Rehbein, 2011), and more recently, the use of word embeddings led to some promising results for some MRLs (Cirik and S¸ensoy, 2013). By releasing large, unlabeled data sets and by providing accurate pre-annotation in a format directly compatible with models trained on the SPMRL Shared Task treebanks, we hope to foster the development of interesting and feature-rich parsing models that build on larger, morphologically rich, lexicons. Table 2 presents basic facts about the data sets. Details on the unlabeled data and their pre-annotations wi</context>
</contexts>
<marker>Goldberg, Tsarfaty, Adler, Elhadad, 2009</marker>
<rawString>Yoav Goldberg, Reut Tsarfaty, Meni Adler, and Michael Elhadad. 2009. Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities. In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL), pages 327–335, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
</authors>
<title>Automatic syntactic processing of Modern Hebrew.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>Ben Gurion University of the Negev.</institution>
<contexts>
<context position="13705" citStr="Goldberg (2011)" startWordPosition="2106" endWordPosition="2107">-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as Constant et al. (2013). The German data are based on the Tiger corpus (Brants et al., 2002), and converted to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in (Woli´nski et al., 2011; ´Swidzi´nski and Woli´nski, 2010; Wr´oblewska,</context>
</contexts>
<marker>Goldberg, 2011</marker>
<rawString>Yoav Goldberg. 2011. Automatic syntactic processing of Modern Hebrew. Ph.D. thesis, Ben Gurion University of the Negev.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Christopher D Manning</author>
</authors>
<title>Better Arabic parsing: Baselines, evaluations, and analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>394--402</pages>
<location>Beijing, China.</location>
<contexts>
<context position="12884" citStr="Green and Manning, 2010" startWordPosition="1972" endWordPosition="1975">Swedish PAROLE balanced 24M ✓ ✓ Table 2: Unlabeled data set properties.*: made available mid-july 4.2 SPMRL Core Labeled Data Set In order to provide a faithful evaluation of the impact of these additional sets of unlabeled data, we used the exact same data sets for training and testing as in the previous edition. Specifically, we used an Arabic data set, originally provided by the LDC (Maamouri et al., 2004), in a dependency form, derived from the Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) and in a constituency instance, following the Stanford pre-processing scheme (Green and Manning, 2010) and extended according to the SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as Constant et al. (2013). The German data are based on the T</context>
</contexts>
<marker>Green, Manning, 2010</marker>
<rawString>Spence Green and Christopher D. Manning. 2010. Better Arabic parsing: Baselines, evaluations, and analysis. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 394–402, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
</authors>
<title>CATiB: The Columbia Arabic Treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<pages>221--224</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="12759" citStr="Habash and Roth, 2009" startWordPosition="1954" endWordPosition="1957"> ✓ ✓ Hungarian news domain newswire 100M ✓ ✓ Korean news domain newswire 40M ✓ ✓* Polish Wikipedia wiki (edited) 100M ✓ ✓ Swedish PAROLE balanced 24M ✓ ✓ Table 2: Unlabeled data set properties.*: made available mid-july 4.2 SPMRL Core Labeled Data Set In order to provide a faithful evaluation of the impact of these additional sets of unlabeled data, we used the exact same data sets for training and testing as in the previous edition. Specifically, we used an Arabic data set, originally provided by the LDC (Maamouri et al., 2004), in a dependency form, derived from the Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) and in a constituency instance, following the Stanford pre-processing scheme (Green and Manning, 2010) and extended according to the SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both insta</context>
</contexts>
<marker>Habash, Roth, 2009</marker>
<rawString>Nizar Habash and Ryan Roth. 2009. CATiB: The Columbia Arabic Treebank. In Proceedings of ACL-IJCNLP, pages 221–224, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Reem Faraj</author>
<author>Ryan Roth</author>
</authors>
<title>Syntactic Annotation in the Columbia Arabic Treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools,</booktitle>
<location>Cairo, Egypt.</location>
<contexts>
<context position="12781" citStr="Habash et al., 2009" startWordPosition="1958" endWordPosition="1961">ain newswire 100M ✓ ✓ Korean news domain newswire 40M ✓ ✓* Polish Wikipedia wiki (edited) 100M ✓ ✓ Swedish PAROLE balanced 24M ✓ ✓ Table 2: Unlabeled data set properties.*: made available mid-july 4.2 SPMRL Core Labeled Data Set In order to provide a faithful evaluation of the impact of these additional sets of unlabeled data, we used the exact same data sets for training and testing as in the previous edition. Specifically, we used an Arabic data set, originally provided by the LDC (Maamouri et al., 2004), in a dependency form, derived from the Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) and in a constituency instance, following the Stanford pre-processing scheme (Green and Manning, 2010) and extended according to the SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both instances. Predicted MWEs w</context>
</contexts>
<marker>Habash, Faraj, Roth, 2009</marker>
<rawString>Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syntactic Annotation in the Columbia Arabic Treebank. In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Four techniques for online handling of out-of-vocabulary words in Arabic-English statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<pages>57--60</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="10780" citStr="Habash, 2008" startWordPosition="1630" endWordPosition="1631">when dealing with morphologically rich languages (MRLs) is lexical data sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c). The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing German (Rehbein, 2011), and more recently, the use of word embeddings led to some promising results for some MRLs (Cirik and S¸ensoy, 2013). By releasing large, unlabeled data sets and by providing accurate pre-annotation in a format directly compatible with models trained on the SPMRL Shared Task treebanks, we hope to foster the development of interesting and feature-rich parsing models that build on larger, morphologically rich, lexicons. Table 2 presents basic facts about the data sets. Details on the unlabele</context>
</contexts>
<marker>Habash, 2008</marker>
<rawString>Nizar Habash. 2008. Four techniques for online handling of out-of-vocabulary words in Arabic-English statistical machine translation. In Proceedings of ACL-08: HLT, Short Papers, pages 57–60, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Wigdan Mekki</author>
</authors>
<title>The Penn Arabic treebank: Building a large-scale annotated Arabic corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of NEMLAR International Conference on Arabic Language Resources and Tools,</booktitle>
<pages>102--109</pages>
<location>Cairo, Egypt.</location>
<contexts>
<context position="12672" citStr="Maamouri et al., 2004" startWordPosition="1940" endWordPosition="1943">20M ✓+mwe ✓* German Wikipedia wiki (edited) 205M ✓ ✓ Hebrew Wikipedia wiki (edited) 160M ✓ ✓ Hungarian news domain newswire 100M ✓ ✓ Korean news domain newswire 40M ✓ ✓* Polish Wikipedia wiki (edited) 100M ✓ ✓ Swedish PAROLE balanced 24M ✓ ✓ Table 2: Unlabeled data set properties.*: made available mid-july 4.2 SPMRL Core Labeled Data Set In order to provide a faithful evaluation of the impact of these additional sets of unlabeled data, we used the exact same data sets for training and testing as in the previous edition. Specifically, we used an Arabic data set, originally provided by the LDC (Maamouri et al., 2004), in a dependency form, derived from the Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) and in a constituency instance, following the Stanford pre-processing scheme (Green and Manning, 2010) and extended according to the SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-w</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic treebank: Building a large-scale annotated Arabic corpus. In Proceedings of NEMLAR International Conference on Arabic Language Resources and Tools, pages 102–109, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Mengel</author>
<author>Wolfgang Lezius</author>
</authors>
<title>An XML-based encoding format for syntactically annotated corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second International Conference on Language Resources and Engineering (LREC</booktitle>
<pages>121--126</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="14708" citStr="Mengel and Lezius, 2000" startWordPosition="2264" endWordPosition="2267"> Treebank (Choi et al., 1994) which was converted to dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in (Woli´nski et al., 2011; ´Swidzi´nski and Woli´nski, 2010; Wr´oblewska, 2012). Compared to the last year’s edition, we added explicit feature names in the relevant data fields. The Swedish data originate from (Nivre et al., 2006), we added function labels extracted from the original Swedish XML data. Note that in addition to constituency and dependency versions, the Polish, German and Swedish data sets are also available in the Tiger XML format (Mengel and Lezius, 2000), allowing a direct representation of discontinuous structures in their phrase-based structures. 5 Conclusion At the time of writing this short introduction, the shared task is ongoing, and neither results nor the final submitting teams are known. At this point, we can say that 15 teams registered for the 2014 shared task edition, indicating an increased awareness of and continued interest in the topic of the shared task. Results, cross-parser and cross-data analysis, and shared task description papers will be made available at http://www.spmrl.org/spmrl2014-sharedtask.html. Acknowledgments We</context>
</contexts>
<marker>Mengel, Lezius, 2000</marker>
<rawString>Andreas Mengel and Wolfgang Lezius. 2000. An XML-based encoding format for syntactically annotated corpora. In Proceedings of the Second International Conference on Language Resources and Engineering (LREC 2000), pages 121–126, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
</authors>
<title>Talbanken05: A Swedish treebank with phrase structure and dependency annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>1392--1395</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="14463" citStr="Nivre et al., 2006" startWordPosition="2225" endWordPosition="2228">o match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in (Woli´nski et al., 2011; ´Swidzi´nski and Woli´nski, 2010; Wr´oblewska, 2012). Compared to the last year’s edition, we added explicit feature names in the relevant data fields. The Swedish data originate from (Nivre et al., 2006), we added function labels extracted from the original Swedish XML data. Note that in addition to constituency and dependency versions, the Polish, German and Swedish data sets are also available in the Tiger XML format (Mengel and Lezius, 2000), allowing a direct representation of discontinuous structures in their phrase-based structures. 5 Conclusion At the time of writing this short introduction, the shared task is ongoing, and neither results nor the final submitting teams are known. At this point, we can say that 15 teams registered for the 2014 shared task edition, indicating an increase</context>
</contexts>
<marker>Nivre, Nilsson, Hall, 2006</marker>
<rawString>Joakim Nivre, Jens Nilsson, and Johan Hall. 2006. Talbanken05: A Swedish treebank with phrase structure and dependency annotation. In Proceedings of LREC, pages 1392–1395, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007,</booktitle>
<pages>915--932</pages>
<location>Prague, Czech Republic.</location>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Rehbein</author>
</authors>
<title>Data point selection for self-training.</title>
<date>2011</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Parsing of Morphologically Rich Languages,</booktitle>
<pages>62--67</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="10884" citStr="Rehbein, 2011" startWordPosition="1644" endWordPosition="1645">l of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c). The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing German (Rehbein, 2011), and more recently, the use of word embeddings led to some promising results for some MRLs (Cirik and S¸ensoy, 2013). By releasing large, unlabeled data sets and by providing accurate pre-annotation in a format directly compatible with models trained on the SPMRL Shared Task treebanks, we hope to foster the development of interesting and feature-rich parsing models that build on larger, morphologically rich, lexicons. Table 2 presents basic facts about the data sets. Details on the unlabeled data and their pre-annotations will be provided in (Seddah et al., 2014). Note that we could not ensur</context>
</contexts>
<marker>Rehbein, 2011</marker>
<rawString>Ines Rehbein. 2011. Data point selection for self-training. In Proceedings of the Second Workshop on Statistical Parsing of Morphologically Rich Languages, pages 62–67, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Sampson</author>
<author>Anna Babarczy</author>
</authors>
<title>A test of the leaf-ancestor metric for parse accuracy.</title>
<date>2003</date>
<journal>Natural Language Engineering,</journal>
<volume>9</volume>
<issue>04</issue>
<contexts>
<context position="5358" citStr="Sampson and Babarczy, 2003" startWordPosition="806" endWordPosition="809">egment were not. In the raw setting, there was no gold information, i.e., morphological segmentation, POS tags and morphological features for each input token had to be predicted as part of the parsing task. To lower the entry cost, participants were provided with reasonable baseline (if not state-of-the-art) morphological predictions (either disambiguated – in most cases– or ambiguous prediction in lattice forms). As a consequence of the raw scenario, it was not possible to (only) rely on the accepted parsing metrics, labeled bracket evaluation via EVALB1 (Black et al., 1991), Leaf-Ancestor (Sampson and Babarczy, 2003) for constituents and CONLL X’s Labeled/Unlabeled Attachment Score for dependencies (Buchholz and Marsi, 2006). When the segmentation of words into input tokens is not given, there may be discrepancies on the lexical levels, which neither EVALB and LEAF-ANCESTOR nor LAS/UAS are prepared to handle. Thus, we also used TedEval, a distance-based metric that evaluates a morphosyntactic structure as a complete whole (Tsarfaty et al., 2012b). Note that given the workload brought to the participants, we did not try to enforce function label evaluation for constituent parsing. We hope that further shar</context>
</contexts>
<marker>Sampson, Babarczy, 2003</marker>
<rawString>Geoffrey Sampson and Anna Babarczy. 2003. A test of the leaf-ancestor metric for parse accuracy. Natural Language Engineering, 9(04):365–380.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djam´e Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra K¨ubler</author>
<author>Marie Candito</author>
<author>Jinho D Choi</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Clergerie.</title>
<date>2013</date>
<journal>Overview of the SPMRL</journal>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>146--182</pages>
<location>Seattle, WA.</location>
<marker>Seddah, Tsarfaty, K¨ubler, Candito, Choi, Farkas, Foster, 2013</marker>
<rawString>Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho D. Choi, Rich´ard Farkas, Jennifer Foster, Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Clergerie. 2013. Overview of the SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 146–182, Seattle, WA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djam´e Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra K¨ubler</author>
<author>Marie Candito</author>
<author>Jinho Choi</author>
<author>Matthieu Constant</author>
<author>Rich´ard Farkas</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Cl´ergerie.</title>
<date>2014</date>
<booktitle>In Notes of the SPMRL 2014 Shared Task on Parsing Morphologically-Rich Languages,</booktitle>
<location>Dublin,</location>
<marker>Seddah, Tsarfaty, K¨ubler, Candito, Choi, Constant, Farkas, 2014</marker>
<rawString>Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho Choi, Matthieu Constant, Rich´ard Farkas, Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Cl´ergerie. 2014. Overview of the spmrl 2014 shared task on parsing morphologically rich languages. In Notes of the SPMRL 2014 Shared Task on Parsing Morphologically-Rich Languages, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Seeker</author>
<author>Jonas Kuhn</author>
</authors>
<title>Making Ellipses Explicit in Dependency Conversion for a German Treebank.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation,</booktitle>
<pages>3132--3139</pages>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="13596" citStr="Seeker and Kuhn, 2012" startWordPosition="2085" endWordPosition="2088">ue, the data was provided by Aduriz et al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both instances could be aligned at the token level. Regarding French, we used a new instance of the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as Constant et al. (2013). The German data are based on the Tiger corpus (Brants et al., 2002), and converted to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to dependency for the SPMRL shared task by Choi (2013). The Po</context>
</contexts>
<marker>Seeker, Kuhn, 2012</marker>
<rawString>Wolfgang Seeker and Jonas Kuhn. 2012. Making Ellipses Explicit in Dependency Conversion for a German Treebank. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 3132–3139, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalil Sima’an</author>
<author>Alon Itai</author>
<author>Yoad Winter</author>
<author>Alon Altmann</author>
<author>Noa Nativ</author>
</authors>
<title>Building a tree-bank of Modern Hebrew text. Traitement Automatique des Langues,</title>
<date>2001</date>
<pages>42--347</pages>
<marker>Sima’an, Itai, Winter, Altmann, Nativ, 2001</marker>
<rawString>Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altmann, and Noa Nativ. 2001. Building a tree-bank of Modern Hebrew text. Traitement Automatique des Langues, 42:347–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marek ´Swidzi´nski</author>
<author>Marcin Woli´nski</author>
</authors>
<title>Towards a bank of constituent parse trees for Polish.</title>
<date>2010</date>
<booktitle>In Proceedings of Text, Speech and Dialogue,</booktitle>
<pages>197--204</pages>
<location>Brno, Czech Republic.</location>
<marker>´Swidzi´nski, Woli´nski, 2010</marker>
<rawString>Marek ´Swidzi´nski and Marcin Woli´nski. 2010. Towards a bank of constituent parse trees for Polish. In Proceedings of Text, Speech and Dialogue, pages 197–204, Brno, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Djame Seddah</author>
<author>Yoav Goldberg</author>
<author>Sandra K¨ubler</author>
<author>Marie Candito</author>
<author>Jennifer Foster</author>
<author>Yannick Versley</author>
<author>Ines Rehbein</author>
<author>Lamia Tounsi</author>
</authors>
<title>Statistical parsing for morphologically rich language (SPMRL): What, how and whither.</title>
<date>2010</date>
<booktitle>In Proceedings of the First workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL),</booktitle>
<location>Los Angeles, CA.</location>
<marker>Tsarfaty, Seddah, Goldberg, K¨ubler, Candito, Foster, Versley, Rehbein, Tounsi, 2010</marker>
<rawString>Reut Tsarfaty, Djame Seddah, Yoav Goldberg, Sandra K¨ubler, Marie Candito, Jennifer Foster, Yannick Versley, Ines Rehbein, and Lamia Tounsi. 2010. Statistical parsing for morphologically rich language (SPMRL): What, how and whither. In Proceedings of the First workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL), Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Joakim Nivre</author>
<author>Evelina Andersson</author>
</authors>
<title>Cross-framework evaluation for statistical parsing.</title>
<date>2012</date>
<booktitle>In Proceeding of EACL,</booktitle>
<location>Avignon, France.</location>
<contexts>
<context position="5794" citStr="Tsarfaty et al., 2012" startWordPosition="873" endWordPosition="876"> raw scenario, it was not possible to (only) rely on the accepted parsing metrics, labeled bracket evaluation via EVALB1 (Black et al., 1991), Leaf-Ancestor (Sampson and Babarczy, 2003) for constituents and CONLL X’s Labeled/Unlabeled Attachment Score for dependencies (Buchholz and Marsi, 2006). When the segmentation of words into input tokens is not given, there may be discrepancies on the lexical levels, which neither EVALB and LEAF-ANCESTOR nor LAS/UAS are prepared to handle. Thus, we also used TedEval, a distance-based metric that evaluates a morphosyntactic structure as a complete whole (Tsarfaty et al., 2012b). Note that given the workload brought to the participants, we did not try to enforce function label evaluation for constituent parsing. We hope that further shared tasks will try to generalize such an evaluation. Indeed, having predicted function labels would ease labeled TEDEVAL evaluation and favor a full parsing chain evaluation. Nevertheless, the choice of TEDEVAL allowed us to go beyond the standard cross-parser evaluation within one setting and approach cross-framework (constituent vs. dependency (Tsarfaty et al., 2012a)) and cross-language evaluation, thus pushing the envelope on par</context>
<context position="10344" citStr="Tsarfaty et al., 2012" startWordPosition="1559" endWordPosition="1562">SPMRL 2014 Data Sets The main innovation of the SPMRL 2014 shared task with respect to the previous edition is the availability of additional, unannotated data, for the purpose of semi-supervised training. This section provides a description of the unlabeled-data preparation that is required in the context of parsing MRLs, and the core labeled data that is used in conjunction with it. 4.1 SPMRL Unlabeled Data Set One of the common problems when dealing with morphologically rich languages (MRLs) is lexical data sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c). The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing German (Rehbein, 2011), and more recently, the use of word embeddings led to some </context>
</contexts>
<marker>Tsarfaty, Nivre, Andersson, 2012</marker>
<rawString>Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2012a. Cross-framework evaluation for statistical parsing. In Proceeding of EACL, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Joakim Nivre</author>
<author>Evelina Andersson</author>
</authors>
<title>Joint evaluation for segmentation and parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL, Jeju,</booktitle>
<contexts>
<context position="5794" citStr="Tsarfaty et al., 2012" startWordPosition="873" endWordPosition="876"> raw scenario, it was not possible to (only) rely on the accepted parsing metrics, labeled bracket evaluation via EVALB1 (Black et al., 1991), Leaf-Ancestor (Sampson and Babarczy, 2003) for constituents and CONLL X’s Labeled/Unlabeled Attachment Score for dependencies (Buchholz and Marsi, 2006). When the segmentation of words into input tokens is not given, there may be discrepancies on the lexical levels, which neither EVALB and LEAF-ANCESTOR nor LAS/UAS are prepared to handle. Thus, we also used TedEval, a distance-based metric that evaluates a morphosyntactic structure as a complete whole (Tsarfaty et al., 2012b). Note that given the workload brought to the participants, we did not try to enforce function label evaluation for constituent parsing. We hope that further shared tasks will try to generalize such an evaluation. Indeed, having predicted function labels would ease labeled TEDEVAL evaluation and favor a full parsing chain evaluation. Nevertheless, the choice of TEDEVAL allowed us to go beyond the standard cross-parser evaluation within one setting and approach cross-framework (constituent vs. dependency (Tsarfaty et al., 2012a)) and cross-language evaluation, thus pushing the envelope on par</context>
<context position="10344" citStr="Tsarfaty et al., 2012" startWordPosition="1559" endWordPosition="1562">SPMRL 2014 Data Sets The main innovation of the SPMRL 2014 shared task with respect to the previous edition is the availability of additional, unannotated data, for the purpose of semi-supervised training. This section provides a description of the unlabeled-data preparation that is required in the context of parsing MRLs, and the core labeled data that is used in conjunction with it. 4.1 SPMRL Unlabeled Data Set One of the common problems when dealing with morphologically rich languages (MRLs) is lexical data sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c). The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito and Crabb´e, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing German (Rehbein, 2011), and more recently, the use of word embeddings led to some </context>
</contexts>
<marker>Tsarfaty, Nivre, Andersson, 2012</marker>
<rawString>Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2012b. Joint evaluation for segmentation and parsing. In Proceedings of ACL, Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Djam´e Seddah</author>
<author>Sandra K¨ubler</author>
<author>Joakim Nivre</author>
</authors>
<title>Parsing morphologically rich languages: Introduction to the special issue.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<tech>Ph.D. thesis,</tech>
<volume>39</volume>
<issue>1</issue>
<institution>University of Amsterdam.</institution>
<marker>Tsarfaty, Seddah, K¨ubler, Nivre, 2012</marker>
<rawString>Reut Tsarfaty, Djam´e Seddah, Sandra K¨ubler, and Joakim Nivre. 2012c. Parsing morphologically rich languages: Introduction to the special issue. Computational Linguistics, 39(1):15–22. Reut Tsarfaty. 2010. Relational-Realizational Parsing. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
</authors>
<title>A unified morpho-syntactic scheme of Stanford dependencies.</title>
<date>2013</date>
<booktitle>In Proceedings ofACL,</booktitle>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="13822" citStr="Tsarfaty, 2013" startWordPosition="2122" endWordPosition="2123">the French Treebank (Abeill´e et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as Constant et al. (2013). The German data are based on the Tiger corpus (Brants et al., 2002), and converted to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the Modern Hebrew Treebank (Sima’an et al., 2001), with the Goldberg (2011) dependency version, in turn aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8. The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010), while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in (Woli´nski et al., 2011; ´Swidzi´nski and Woli´nski, 2010; Wr´oblewska, 2012). Compared to the last year’s edition, we added explicit feature names in the relevant data fields. The Swedish</context>
</contexts>
<marker>Tsarfaty, 2013</marker>
<rawString>Reut Tsarfaty. 2013. A unified morpho-syntactic scheme of Stanford dependencies. In Proceedings ofACL, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
</authors>
<title>D´ora Szauter, Attila Alm´asi, Gy¨orgy M´ora, Zolt´an Alexin, and J´anos Csirik.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Valletta,</location>
<marker>Vincze, 2010</marker>
<rawString>Veronika Vincze, D´ora Szauter, Attila Alm´asi, Gy¨orgy M´ora, Zolt´an Alexin, and J´anos Csirik. 2010. Hungarian Dependency Treebank. In Proceedings of LREC, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcin Woli´nski</author>
<author>Katarzyna Głowi´nska</author>
<author>Marek ´Swidzi´nski</author>
</authors>
<title>A preliminary version of Składnica—a treebank of Polish.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th Language &amp; Technology Conference,</booktitle>
<pages>299--303</pages>
<location>Pozna´n,</location>
<marker>Woli´nski, Głowi´nska, ´Swidzi´nski, 2011</marker>
<rawString>Marcin Woli´nski, Katarzyna Głowi´nska, and Marek ´Swidzi´nski. 2011. A preliminary version of Składnica—a treebank of Polish. In Proceedings of the 5th Language &amp; Technology Conference, pages 299–303, Pozna´n, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Wr´oblewska</author>
</authors>
<title>Polish Dependency Bank.</title>
<date>2012</date>
<journal>Linguistic Issues in Language Technology,</journal>
<volume>7</volume>
<issue>1</issue>
<marker>Wr´oblewska, 2012</marker>
<rawString>Alina Wr´oblewska. 2012. Polish Dependency Bank. Linguistic Issues in Language Technology, 7(1):1–15.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>