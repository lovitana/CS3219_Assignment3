<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000040">
<title confidence="0.979074">
Aspect-Level Sentiment Analysis in Czech
</title>
<author confidence="0.997177">
Josef Steinberger
</author>
<affiliation confidence="0.9928025">
Department of Computer
Science and Engineering,
Faculty of Applied Sciences,
University of West Bohemia,
</affiliation>
<address confidence="0.95628">
Univerzitn´ı 8, 306 14 Plzeˇn
Czech Republic
</address>
<email confidence="0.995181">
jstein@kiv.zcu.cz
</email>
<author confidence="0.606676">
Tom´aˇs Brychcin
</author>
<affiliation confidence="0.87200375">
NTIS – New Technologies
for the Information Society,
Faculty of Applied Sciences,
University of West Bohemia,
</affiliation>
<address confidence="0.9573485">
Univerzitn´ı 8, 306 14 Plzeˇn
Czech Republic
</address>
<email confidence="0.996889">
brychcin@kiv.zcu.cz
</email>
<author confidence="0.892996">
Michal Konkol
</author>
<affiliation confidence="0.93263575">
NTIS – New Technologies
for the Information Society,
Faculty of Applied Sciences,
University of West Bohemia,
</affiliation>
<address confidence="0.9551935">
Univerzitn´ı 8, 306 14 Plzeˇn
Czech Republic
</address>
<email confidence="0.995058">
konkol@kiv.zcu.cz
</email>
<sectionHeader confidence="0.993728" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999738777777778">
This paper presents a pioneering re-
search on aspect-level sentiment analysis
in Czech. The main contribution of the
paper is the newly created Czech aspect-
level sentiment corpus, based on data from
restaurant reviews. We annotated the cor-
pus with two variants of aspect-level senti-
ment – aspect terms and aspect categories.
The corpus consists of 1,244 sentences and
1,824 annotated aspects and is freely avail-
able to the research community. Further-
more, we propose a baseline system based
on supervised machine learning. Our
system detects the aspect terms with F-
measure 68.65% and their polarities with
accuracy 66.27%. The categories are rec-
ognized with F-measure 74.02% and their
polarities with accuracy 66.61%.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963291666667">
The interest in sentiment analysis (SA) is increas-
ing with the amount of easily accessible content on
the web, especially from the social media. Sen-
timent polarity is one of the critical information
needed for many analysis of the data. Its use
ranges from analysing product reviews (Stepanov
and Riccardi, 2011) to predicting sales and stock
markets using social media monitoring (Yu et al.,
2013).
The majority of current approaches tries to de-
tect the overall polarity of a sentence (or a docu-
ment) regardless of the target entities (e.g., restau-
rants, laptops) and their aspects (e.g., food, price,
battery, screen). By contrast, the aspect-driven
sentiment analysis identifies the aspects of a given
target entity and estimates the sentiment polarity
for each mentioned aspect. This opens up com-
pletely new possibilities how to analyse the data.
The most of the research in automatic sentiment
analysis has been devoted to English. There were
several attempts in Czech (Steinberger et al., 2011;
Veselovsk´a, 2012; Habernal et al., 2013; Brychc´ın
and Habernal, 2013), but all were focused on the
global (sentence- or document-level) sentiment.
Although Czech is not a widely-spoken language
on the global scale, it is in many ways similar
to other Slavic languages and their speakers al-
together represent an important group. The rich
morphology and the free word order also makes it
interesting from the linguistic perspective.
Our main goal is the creation of a aspect-level
corpus as there is no such resource for Czech.
We would like to support the beginning of aspect-
level sentiment analysis for Czech and a human-
annotated corpus is the first step in this direc-
tion. In addition, we want to provide results of
a baseline system (based on machine leaning tech-
niques). This creates an easily reproducible start-
ing point and allows anyone to quickly join the re-
search of this task.
The rest of the paper is organised as follows.
Section 2 is devoted to related work. It covers the
aspect-level SA and sentiment analysis in Czech.
Then we introduce the aspect-level architecture
(Section 3) used for both the annotation of the cor-
pus (Section 4) and for the automatic supervised
approach (Section 5). In Section 6 we sumarize
our contribution and reveal our future plans.
</bodyText>
<sectionHeader confidence="0.999621" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999878818181818">
The impact of SA can be seen in many practical
applications, The users’ opinions are mostly ex-
tracted either on a certain polarity scale, or binary
(positive, negative). From the point of view of
the granularity, the polarity has been assigned to
a document or to a sentence. However, classify-
ing opinions at the document level or the sentence
level is often insufficient for applications because
they do not identify opinion targets or assign sen-
timents to such targets (Liu, 2012). Even if we
recognize the target entity (as the entity-centered
</bodyText>
<page confidence="0.980481">
24
</page>
<bodyText confidence="0.987455666666667">
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 24–30,
Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics
approaches do (e.g. Steinberger et al. (2011)), a
positive opinion about the entity does not mean
that the author has positive opinions about all as-
pects of the entity. Aspect-based sentiment analy-
sis, which has been also called ‘feature-based’ (Hu
and Liu, 2004), goes even deeper as it attempts to
identify (and assign the polarity to) aspects of the
target entity within a sentence (Hajmohammadi et
al., 2012). Whenever we talk about an aspect,
we must know which entity it belongs to. In the
further discussion, we often omit the entity as we
analysed restaurant reviews and thus our target en-
tities are the reviewed restaurants.
</bodyText>
<subsectionHeader confidence="0.997897">
2.1 Aspect-based sentiment analysis
</subsectionHeader>
<bodyText confidence="0.999791666666667">
The aspect scenario can be decomposed into two
tasks: aspect extraction and aspect sentiment clas-
sification (Liu, 2012).
</bodyText>
<subsectionHeader confidence="0.857689">
2.1.1 Aspect extraction
</subsectionHeader>
<bodyText confidence="0.999867829268292">
The task of aspect extraction, which can also be
seen as an information extraction task, is to detect
aspects that have been evaluated. For example, in
the sentence, The voice quality of this phone is
amazing, the aspect is voice quality of the entity
represented by this phone.
The basic approach is finding frequent nouns
and noun phrases. In (Liu et al., 2005), a specific
method based on a sequential learning method was
proposed to extract aspects from pros and cons,
Blair-Goldensohn et al. (2008) refined the frequent
noun and noun phrase approach by considering
mainly those noun phrases that are in sentiment-
bearing sentences or in some syntactic patterns
which indicate sentiments. Moghaddam and Ester
(2010) augmented the frequency-based approach
with an additional pattern-based filter to remove
some non-aspect terms. Long et al. (2010) ex-
tracted aspects (nouns) based on frequency and in-
formation distance.
Using supervised learning is another option.
Aspect extraction can be seen as a special case
of the general information extraction problem.
The most dominant methods are based on sequen-
tial learning. Since these are supervised tech-
niques, they need manually labeled data for train-
ing. One needs to manually annotate aspects
and non-aspects in a corpus. The current state-
of-the-art sequential learning methods are Hid-
den Markov Models (HMM) (Rabiner, 2010) and
Conditional Random Fields (CRF) (Lafferty et al.,
2001).
The last group of methods use topic models
(Mei et al., 2007; Titov and McDonald, 2008;
Blei et al., 2003). There are two main basic mod-
els, pLSA (Probabilistic Latent Semantic Analy-
sis) (Hofmann, 1999) and LDA (Latent Dirichlet
allocation) (Blei et al., 2003). In the SA context,
one can design a joint model to model both senti-
ment words and topics at the same time, due to the
observation that every opinion has a target.
</bodyText>
<subsectionHeader confidence="0.9779">
2.1.2 Aspect sentiment classification
</subsectionHeader>
<bodyText confidence="0.999990740740741">
This task is to determine whether the opinions on
different aspects are positive, negative, or neutral.
The classification approaches can be divided to
supervised learning approaches and lexicon-based
approaches. Supervised learning performs bet-
ter in a particular application domain but it has
difficulty to scale up to a large number of do-
mains. Lexicon-based techniques often lose the
fight against the learning but they are suitable for
open-domain applications (Liu, 2012).
The key issue for learning methods is to de-
termine the scope of each sentiment expression,
i.e., whether it covers the aspect of interest in the
sentence. In (Jiang et al., 2011), a dependency
parser was used to generate a set of aspect de-
pendent features for classification. A related ap-
proach was also used in (Boiy and Moens, 2009),
which weights each feature based on the position
of the feature relative to the target aspect in the
parse tree.
Lexicon-based approaches use a list of senti-
ment phrases as the core resource. The method
in (Ding et al., 2008) has four steps to assign
a polarity to an aspect: mark sentiment words
and phrases, apply sentiment shifters, handle but-
clauses and aggregate opinions using an aggrega-
tion function (e.g. Hu and Liu (2004)).
</bodyText>
<subsectionHeader confidence="0.999991">
2.2 Sentiment analysis for Czech
</subsectionHeader>
<bodyText confidence="0.999946583333333">
Pilot study of Czech sentiment analysis was shown
in (Steinberger et al., 2012) where sentiment dic-
tionaries for many languages (including Czech)
were created using semi-automatic “triangulation”
method.
Veselovsk´a (2012) created a small corpus con-
taining polarity categories for 410 news sentences
and used the Naive Bayes and lexicon-based clas-
sifiers.
Three large labeled corpora (10k Facebook
posts, 90k movie reviews, and 130k product
reviews) were introduced in (Habernal et al.,
</bodyText>
<page confidence="0.9879">
25
</page>
<bodyText confidence="0.999859307692308">
2013).Authors also evaluate three different classi-
fiers, namely Naive Bayes, SVM (Support Vector
Machines) and Maximum Entropy on these data.
Recently, Habernal and Brychcin (2013) experi-
mented with building word clusters, obtained from
semantic spaces created on unlabeled data, as an
additional source of information to tackle the high
flection issue in Czech.
These results were later outperformed by
another unsupervised extension (Brychcin and
Habernal, 2013), where the global target context
was shown to be very useful source of informa-
tion.
</bodyText>
<sectionHeader confidence="0.993508" genericHeader="method">
3 The task definition
</sectionHeader>
<bodyText confidence="0.999994363636364">
The aspect-level sentiment analysis firstly identi-
fies the aspects of the target entity and then assigns
a polarity to each aspect. There are several ways
to define aspects and polarities. We use the defini-
tion based on the Semeval2014’s Aspect-based SA
task, which distinguishes two types of aspect-level
sentiment – aspect terms and aspect categories.
The task is decomposed into the following 4
subtasks. We briefly describe each subtask and
give some examples of source sentences and the
expected results of the subtask.
</bodyText>
<subsectionHeader confidence="0.999661">
3.1 Subtask 1: Aspect term extraction
</subsectionHeader>
<bodyText confidence="0.936362538461538">
Given a set of sentences with pre-identified enti-
ties (e.g., restaurants), the task is to identify the
aspect terms present in the sentence and return a
list containing all the distinct aspect terms. An as-
pect term names a particular aspect of the target
entity.
Examples:
Dˇeti dostaly naprosto krvav´e maso.
(They brought a totally bloody meat to the kids.)
maso (meat)
Tlaˇcenka se rozpadla, pol´evka uˇsla.
(The porkpie broke down, the soup was ok.)
Tlaˇcenka (porkpie), pol´evka (soup)
</bodyText>
<subsectionHeader confidence="0.999576">
3.2 Subtask 2: Aspect term polarity
</subsectionHeader>
<bodyText confidence="0.85559725">
For a given set of aspect terms within a sentence,
the task is to determine the polarity of each aspect
term: positive, negative, neutral or bipolar (i.e.,
both positive and negative).
Examples:
Dˇeti dostaly naprosto krvav´e maso.
(They brought a totally bloody meat to the kids.)
maso (meat): negative
Tlaˇcenka se rozpadla, pol´evka uˇsla.
(The porkpie broke down, the soup was ok.)
Tlaˇcenka (porkpie): negative, pol´evka (soup):
positive
</bodyText>
<subsectionHeader confidence="0.999181">
3.3 Subtask 3: Aspect category detection
</subsectionHeader>
<bodyText confidence="0.7514505625">
Given a predefined set of aspect categories (e.g.,
price, food), the task is to identify the aspect cat-
egories discussed in a given sentence. Aspect cat-
egories are typically coarser than the aspect terms
of Subtask 1, and they do not necessarily occur as
terms in the given sentence.
For example, given the set of aspect categories
food, service, price, ambience:
Pˇrivitala n´as velmi pˇr´ıjemn´a servirka, ale tak´e
mistnost s oˇsuntˇel´ym n´abytkem.
(We found a very nice waitress but also a room
with time-worn furniture.)
service, ambience
Tlaˇcenka se rozpadla, pol´evka uˇsla.
(The porkpie broke down, the soup was ok.)
food
</bodyText>
<subsectionHeader confidence="0.93427">
3.4 Subtask 4: Aspect category polarity
</subsectionHeader>
<bodyText confidence="0.775765384615385">
Given a set of pre-identified aspect categories
(e.g., food, price ), the task is to determine the
polarity (positive, negative, neutral or bipolar) of
each aspect category.
Examples:
Pˇrivitala n´as velmi pˇr´ıjemn´a servirka, ale tak´e
mistnost s oˇsuntˇel´ym n´abytkem.
(We found a very nice waitress but also a room
with time-worn furniture.)
service: positive, ambience: negative
Tlaˇcenka se rozpadla, pol´evka uˇsla.
(The porkpie broke down, the soup was ok.)
food: bipolar
</bodyText>
<sectionHeader confidence="0.964659" genericHeader="method">
4 Building the aspect-level corpus
</sectionHeader>
<bodyText confidence="0.999819444444444">
Aspect-level annotations are strictly connected to
the analysed domain. As our final goal is going
multilingual, we work on the domains selected for
the Semeval2014’s Aspect-based SA task (restau-
rants, laptop) which will allow us to compare ap-
proaches for both English and Czech on the same
domains.
We started with the restaurants and in the future,
we would also like to cover the laptops.
</bodyText>
<page confidence="0.978925">
26
</page>
<bodyText confidence="0.9999494">
We downloaded restaurant reviews from www.
nejezto.cz. Ten restaurants with the largest
number of reviews were selected. The reviews
were splitted into sentences. Average number of
sentences per restaurant was 223.
</bodyText>
<subsectionHeader confidence="0.955008">
4.1 Guidelines
</subsectionHeader>
<bodyText confidence="0.9991876">
The purpose of this annotation was to detect as-
pects and their sentiment polarity within sen-
tences. The target entities were particular restau-
rants. For a given restaurant, the annotator had
following tasks:
</bodyText>
<listItem confidence="0.9903692">
1. Identify irrelevant sentences: Sentences
that do not contain any information rele-
vant to the topic of restaurants. They were
later filtered out of the corpus. Example:
Ur´aˇzet nˇekoho pro jeho n´azor je ned˚ustojn´e
dospˇel´eho ˇclovˇeka. (Offencing somebody for
his opinion is discreditable for an adult.)
2. Identify aspect terms: Single or multiword
terms naming particular aspects of the target
entity. These are either full nominal phrases
(ˇsp(z a restovan´e brambory – skewer with
fried potatoes) or verbs (stoj(– priced). Ref-
erences, names or pronouns should not be an-
notated.
3. Aspect term polarity: Each aspect term has
to be assigned one of the following polarities
based on the sentiment that is expressed in the
sentence about it: positive, negative, bipo-
lar (both positive and negative sentiment) and
neutral (neither positive nor negative senti-
ment).
4. Aspect category: The task of the annotator is
to identify the aspect categories discussed in
a sentence given the following five aspect cat-
egories: food, service, price, ambience, gen-
eral (sentences mentioning the restaurant as
a whole). Example: Celkovˇe doporuˇcuji a
vr´at(m se tam – Overall I would recommend
it and go back again. general.
5. Aspect category polarity: Each aspect cat-
egory discussed by a particular sentence has
to be assigned one of the following polarities
based on the sentiment that is expressed in the
sentence about it: positive, negative, bipolar,
neutral.
</listItem>
<subsectionHeader confidence="0.997782">
4.2 Annotation statistics
</subsectionHeader>
<bodyText confidence="0.960310666666667">
Three native Czech speakers annotated in total
1,532 sentences. 18.8% of the sentences were
marked as irrelevant, leaving 1,244 sentences for
further analysis. Their average agreement for the
task of aspect terms’ identification was 82.6%
(measured by F-measure). Only strict matches
were considered correct. In the case of identi-
fying the categories, their average agreement (F-
measure) was 91.8%. The annotators agreed on
85.5% (accuracy) in the task of assigning polarity
to terms and on 82.4% (accuracy) in the case of
the category polarity assignment. It corresponds
to Cohen’s of 0.762, resp. 0.711, which rep-
resents a substantial agreement level (Pustejovsky
and Stubbs, 2013), therefore the task can be con-
sidered as well-defined.
There were several reasons of disagreement.
The annotators did not always itentify the same
terms, mainly in the cases with general meaning.
In the case of polarity, the annotators did not agree
on the most difficult cases to which bipolar class
could be assigned:
Trochu pˇresolen´a om´aˇcka, ale jinak luxus.
(Too salted sauce, but luxury otherwise.)
food: bipolar vs. positive
The cases, on which the two annotators did not
agree, were judged by the third super-annotator
and golden standard data were created. The final
dataset1 contains 1244 sentences. The sentences
contain 1824 annotated aspect terms (679 positive,
725 negative, 403 neutral, 17 bipolar) and 1365
categories (521 positive, 569 negative, 246 neu-
tral, 28 bipolar).
</bodyText>
<sectionHeader confidence="0.990066" genericHeader="method">
5 Results of the supervised approach
</sectionHeader>
<subsectionHeader confidence="0.887609">
5.1 Overview
</subsectionHeader>
<bodyText confidence="0.998996666666667">
We use machine learning approach in all subtasks.
For aspect term extraction we use Conditional
Random Fields (CRF). For the other three tasks
we use the Maximum Entropy classifier. We use
the Brainy2 implementation of these algorithms.
During the data preprocessing, we use simple
word tokenizer based on regular expressions. All
tokens are lowercased for tasks 3 and 4. Due to the
complex morphology of Czech we also use the un-
</bodyText>
<footnote confidence="0.994396">
1We will provide the dataset at http://liks.fav.
zcu.cz/sentiment.
2Available at http://home.zcu.cz/˜konkol/
brainy.php
</footnote>
<page confidence="0.999146">
27
</page>
<bodyText confidence="0.9986963">
supervised stemmer called HPS3, that has already
proved to be useful in sentiment analysis (Haber-
nal et al., 2013; Habernal and Brychc´ın, 2013;
Brychc´ın and Habernal, 2013).
All particular subtasks share following features:
Bag of words: The occurrence of a word.
Bag of bigrams: The occurrence of a bigram.
Bag of stems: The occurrence of a stem.
Bag of stem bigrams: The occurrence of a
stem bigram.
</bodyText>
<subsectionHeader confidence="0.998488">
5.2 Aspect term extraction
</subsectionHeader>
<bodyText confidence="0.999921538461538">
The system for aspect term extraction is based on
CRF. The choice of CRF is based on a current state
of the art in named entity recognition (see for ex-
ample (Konkol and Konop´ık, 2013)) as it is a very
similar task. We use the BIO (Ramshaw and Mar-
cus, 1999) model to represent aspect terms. In ad-
dition to the previously mentioned features we use
affixes and learned dictionaries. Affixes are sim-
ply prefixes and suffixes of length 2 to 4. Learned
dictionaries are phrases that are aspect terms in the
training data.
Our system achieved 58.14 precision, 83.80 re-
call and 68.65 F-measure.
</bodyText>
<subsectionHeader confidence="0.993213">
5.3 Aspect term polarity
</subsectionHeader>
<bodyText confidence="0.999997642857143">
During the detection of the aspect term polarities,
the words affecting the sentiment of the aspect
term are assumed to be close in most of cases.
Thus we use a small window (10 words in both
directions) around the target aspect term. We as-
sume the further the word or bigram is from the
target aspect term, the lower impact it has on sen-
timent label. To model this assumption we use
a weight for each word and bigram feature taken
from the Gaussian distribution according to dis-
tance from aspect term. The mean is set to 0 and
variance is optimized on training data. The classi-
fier uses only the features presented in section 5.1.
The results are presented in table 1.
</bodyText>
<subsectionHeader confidence="0.998555">
5.4 Aspect category detection
</subsectionHeader>
<bodyText confidence="0.99408225">
Aspect category detection is based on the Maxi-
mum Entropy classifiers. We use one binary clas-
sifier for each category. Each classifier then de-
cides whether the sentence has the given category
</bodyText>
<footnote confidence="0.967873">
3Available at http://liks.fav.zcu.cz/HPS.
</footnote>
<tableCaption confidence="0.998505">
Table 1: Aspect term polarity results. , and
</tableCaption>
<bodyText confidence="0.6964375">
denote the precision, recall and F-measure.
The results are expressed by percentages.
label [%] [%] [%]
negative 76.41 63.31 69.25
neutral 33.75 50.18 40.36
positive 74.78 76.82 75.78
</bodyText>
<sectionHeader confidence="0.37535" genericHeader="method">
Accuracy: 66.27%
</sectionHeader>
<bodyText confidence="0.87342575">
or not. For this task we use only the bag of stems
and Tf-Idf features.
Our system achieved 68.71 precision, 80.21 re-
call and 74.02 F-measure.
</bodyText>
<subsectionHeader confidence="0.994835">
5.5 Aspect category polarity
</subsectionHeader>
<bodyText confidence="0.9998673">
For the category polarity detection we use the
same features as for aspect term polarity detec-
tion. However in this case, we always take the
whole sentence into account. We cannot take a
limited window as we do not know where exactly
the category is mentioned in the sentence. More-
over, it can be at several positions. To distinguish
between different categories we use multiple Max-
imum Entropy classifiers, one for each category.
The results are shown in table 2.
</bodyText>
<tableCaption confidence="0.894113">
Table 2: Aspect category polarity results. ,
</tableCaption>
<bodyText confidence="0.985189714285714">
and denote the precision, recall and F-
measure. The results are expressed by percent-
ages.
label [%] [%] [%]
negative 74.07 66.04 69.83
neutral 37.80 46.73 41.80
positive 72.12 75.30 73.67
</bodyText>
<sectionHeader confidence="0.824295" genericHeader="method">
Accuracy: 66.61%
</sectionHeader>
<subsectionHeader confidence="0.983454">
5.6 Discussion
</subsectionHeader>
<bodyText confidence="0.999936916666667">
In section 5 we described our system for aspect-
level sentiment analysis and showed the results.
We do not use any language-dependent features,
everything is learned from the training data. It is
thus possible to say that our system is both lan-
guage and domain independent, i.e. the system is
able to work for any domain or language, if the
training data are provided.
From another perspective, the already trained
model is language and domain dependent (i.e. the
model trained on restaurant domain probably will
not perform well on laptop domain). The depen-
</bodyText>
<page confidence="0.996427">
28
</page>
<bodyText confidence="0.990007588235294">
dence on the domain has multiple reasons. First,
the categories are defined strictly for one domain
(e.g. food, price, etc.). Second, many words can
have different sentiment polarity in different do-
mains.
In general, the sentiment analysis deals with
many problems. These problems are much more
evident for Czech as a representative of language
with rich morphology and also with almost free
word order. Here are two examples, where our
system wrongly estimate the sentiment label.
Na nic si nejde stˇeˇzovat.
(There is nothing to complain about.)
general: positive
The sentence contains words that frequently oc-
cur in negative reviews: nic - nothing, stˇeˇzovat -
complain; but the sentence is positive.
</bodyText>
<construct confidence="0.442036">
O tˇech labuˇznick´ych a delikatesnich z´aˇzitcich si
ˇclovˇek pouze pˇreˇcte, ale realita je jin´a.
(One can only read about these gourmand and de-
licious experiences, but the reality is completely
different.)
</construct>
<bodyText confidence="0.981039833333333">
food: negative
Sentence contains words like labuˇznick´ych -
gourmand and delikatesnich - delicious that are
strictly positive, but in this context it is mentioned
negatively.
As we already said, this is the pilot study of
aspect-level sentiment analysis in Czech. Several
studies about sentence-level sentiment analysis of
Czech have been already published, and thus it
is worth comparing how these two tasks differ in
terms of difficulty. Note that the aspect-level sen-
timent analysis has to deal with multiple aspects
and categories in a given sentence, and thus it is
apparently a much more difficult task.
We believe the results of (Brychc´ın and Haber-
nal, 2013) on Czech movie reviews dataset can be
a comparable example of sentence-level sentiment
analysis as they also distinguish 3 sentiment labels
(positive, negative and neutral) and the data are
taken from a closed domain (movies). Their best
result (given by the model with all extensions) is
81.53%. Our best results are 66.27% and 66.61%
for aspect and category polarity detection, respec-
tively.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999969666666667">
The aspect level sentiment analysis has not been
studied for Czech yet. The main reason for this is
the lack of annotated data. In this paper, we create
a high quality gold data for this task, we describe
our approach to their annotation and discuss their
properties. Corpus is available for free at http:
//liks.fav.zcu.cz/sentiment.
We also propose a baseline model based on
state-of-the-art supervised machine learning tech-
niques. Our system is language and domain inde-
pendent, i.e. it can be easily trained on data from
another domain or language. It achieved 68.65%
F-measure in the aspect term detection, 74.02% F-
measure in the aspect category assigning, 66.27%
accuracy in the aspect term polarity classification,
and 66.61% accuracy in the aspect category polar-
ity classification.
In the future, we would like to continue the
aspect-level research direction in three ways. We
would like to extend the currently created restau-
rant reviews’ corpus, to add the second (laptop’s)
domain to the corpus, and finally, to experiment
with extensions to the baseline system. As the
corpus for the Semeval2014 aspect-based SA task
contains review sentences from the same domains,
we will be able to compare the results of the sys-
tem cross-lingually.
</bodyText>
<sectionHeader confidence="0.997475" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999156625">
This work was supported by grant no. SGS-
2013-029 Advanced computing and information
systems, by the European Regional Development
Fund (ERDF), by project “NTIS - New Tech-
nologies for Information Society”, European Cen-
tre of Excellence, CZ.1.05/1.1.00/02.0090, and by
project MediaGist, EU’s FP7 People Programme
(Marie Curie Actions), no 630786.
</bodyText>
<sectionHeader confidence="0.99857" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.776504571428571">
Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDon-
ald, Tyler Neylon, George Reis, and Jeff Reynar.
2008. Building a sentiment summarizer for lo-
cal service reviews. In Proceedings of WWW-2008
workshop on NLP in the Information Explosion Era.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Erik Boiy and Marie-Francine Moens. 2009. A
machine learning approach to sentiment analysis
in multilingual web texts. Information retrieval,
12(5):526–558.
Tom´aˇs Brychc´ın and Ivan Habernal. 2013. Unsuper-
vised improving of sentiment analysis using global
</reference>
<page confidence="0.994168">
29
</page>
<reference confidence="0.999250055555556">
target context. In Proceedings of the International
Conference Recent Advances in Natural Language
Processing RANLP 2013, pages 122–128, Hissar,
Bulgaria, September. Incoma Ltd. Shoumen, Bul-
garia.
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining.
In Proceedings of the Conference on Web Search and
Web Data Mining.
Ivan Habernal and Tom´a&amp;quot;s Brychc´ın. 2013. Semantic
spaces for sentiment analysis. In Text, Speech and
Dialogue, volume 8082 of Lecture Notes in Com-
puter Science, pages 482–489, Berlin Heidelberg.
Springer.
Ivan Habernal, Tom´a&amp;quot;s Pt´a&amp;quot;cek, and Josef Steinberger.
2013. Sentiment analysis in czech social media us-
ing supervised machine learning. In Proceedings of
the 4th Workshop on Computational Approaches to
Subjectivity, Sentiment and Social Media Analysis,
pages 65–74, Atlanta, Georgia, June. Association
for Computational Linguistics.
Mohammad Sadegh Hajmohammadi, Roliana Ibrahim,
and Zulaiha Ali Othman. 2012. Opinion mining and
sentiment analysis: A survey. International Journal
of Computers &amp; Technology, 2(3).
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of Conference on Uncer-
tainty in Artificial Intelligence.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ’04, pages
168–177, New York, NY, USA. ACM.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
timent classification. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics.
Michal Konkol and Miloslav Konop´ık. 2013. Crf-
based czech named entity recognizer and consolida-
tion of czech ner research. In Ivan Habernal and
V´aclav Matou&amp;quot;sek, editors, Text, Speech and Dia-
logue, volume 8082 of Lecture Notes in Computer
Science, pages 153–160. Springer Berlin Heidel-
berg.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of International Con-
ference on Machine Learning.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: Analyzing and comparing opin-
ions on the web. In Proceedings of International
Conference on World Wide Web.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan &amp; Claypool Publishers.
Chong Long, Jie Zhang, and Xiaoyan Zhu. 2010. A
review selection approach for accurate feature rating
estimation. In Proceedings of Coling 2010: Poster
Volume.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment mix-
ture: modeling facets and opinions in weblogs. In
Proceedings of International Conference on World
Wide Web.
Samaneh Moghaddam and Martin Ester. 2010. Opin-
ion digger: an unsupervised opinion miner from
unstructured product reviews. In Proceeding of
the ACM conference on Information and knowledge
management.
James Pustejovsky and Amber Stubbs. 2013. Natural
Language Annotation for Machine Learning. OR-
eilly Media, Sebastopol, CA 95472.
Lawrence Rabiner. 2010. A tutorial on hidden markov
models and selected applications in speech recogni-
tion. In Proceedings of the IEEE, pages 257–286.
Lance A Ramshaw and Mitchell P Marcus. 1999. Text
chunking using transformation-based learning. In
Natural language processing using very large cor-
pora, pages 157–176. Springer.
J. Steinberger, P. Lenkova, M. Kabadjov, R. Stein-
berger, and E. van der Goot. 2011. Multilingual
entity-centered sentiment analysis evaluated by par-
allel corpora. In Proceedings of the 8th Interna-
tional Conference Recent Advances in Natural Lan-
guage Processing, RANLP’11, pages 770–775.
J. Steinberger, M. Ebrahim, Ehrmann M., A. Hur-
riyetoglu, M. Kabadjov, P. Lenkova, R. Steinberger,
H. Tanev, S. Vzquez, and V. Zavarella. 2012. Cre-
ating sentiment dictionaries via triangulation. Deci-
sion Support Systems, 53:689–694.
E.A. Stepanov and G. Riccardi. 2011. Detecting gen-
eral opinions from customer surveys. In Data Min-
ing Workshops (ICDMW), 2011 IEEE 11th Interna-
tional Conference on, pages 115–122.
Ivan Titov and Ryan McDonald. 2008. Modeling on-
line reviews with multi-grain topic models. In Pro-
ceedings of International Conference on World Wide
Web.
Kate&amp;quot;rina Veselovsk´a. 2012. Sentence-level sentiment
analysis in czech. In Proceedings of the 2nd Interna-
tional Conference on Web Intelligence, Mining and
Semantics. ACM.
Liang-Chih Yu, Jheng-Long Wu, Pei-Chann Chang,
and Hsuan-Shou Chu. 2013. Using a contextual en-
tropy model to expand emotion words and their in-
tensity for the sentiment classification of stock mar-
ket news. Knowledge Based Syst, 41:89–97, March.
</reference>
<page confidence="0.99879">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000339">
<title confidence="0.988008">Aspect-Level Sentiment Analysis in Czech</title>
<author confidence="0.992448">Josef</author>
<affiliation confidence="0.99892975">Department of Science and Faculty of Applied University of West</affiliation>
<address confidence="0.378658">Univerzitn´ı 8, 306 14 Czech</address>
<email confidence="0.646596">jstein@kiv.zcu.cz</email>
<title confidence="0.687911333333333">Tom´aˇs NTIS – New for the Information</title>
<affiliation confidence="0.9208165">Faculty of Applied University of West</affiliation>
<address confidence="0.3709295">Univerzitn´ı 8, 306 14 Czech</address>
<email confidence="0.761549">brychcin@kiv.zcu.cz</email>
<author confidence="0.822879">Michal</author>
<affiliation confidence="0.665816">NTIS – New for the Information Faculty of Applied University of West</affiliation>
<address confidence="0.400217">Univerzitn´ı 8, 306 14 Czech</address>
<email confidence="0.897233">konkol@kiv.zcu.cz</email>
<abstract confidence="0.957517105263158">This paper presents a pioneering research on aspect-level sentiment analysis in Czech. The main contribution of the paper is the newly created Czech aspectlevel sentiment corpus, based on data from restaurant reviews. We annotated the corpus with two variants of aspect-level sentiment – aspect terms and aspect categories. The corpus consists of 1,244 sentences and 1,824 annotated aspects and is freely available to the research community. Furthermore, we propose a baseline system based on supervised machine learning. Our system detects the aspect terms with Fmeasure 68.65% and their polarities with accuracy 66.27%. The categories are recognized with F-measure 74.02% and their polarities with accuracy 66.61%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
<author>Tyler Neylon</author>
<author>George Reis</author>
<author>Jeff Reynar</author>
</authors>
<title>Building a sentiment summarizer for local service reviews.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era.</booktitle>
<contexts>
<context position="5725" citStr="Blair-Goldensohn et al. (2008)" startWordPosition="906" endWordPosition="909">o can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). 2.1.1 Aspect extraction The task of aspect extraction, which can also be seen as an information extraction task, is to detect aspects that have been evaluated. For example, in the sentence, The voice quality of this phone is amazing, the aspect is voice quality of the entity represented by this phone. The basic approach is finding frequent nouns and noun phrases. In (Liu et al., 2005), a specific method based on a sequential learning method was proposed to extract aspects from pros and cons, Blair-Goldensohn et al. (2008) refined the frequent noun and noun phrase approach by considering mainly those noun phrases that are in sentimentbearing sentences or in some syntactic patterns which indicate sentiments. Moghaddam and Ester (2010) augmented the frequency-based approach with an additional pattern-based filter to remove some non-aspect terms. Long et al. (2010) extracted aspects (nouns) based on frequency and information distance. Using supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on seq</context>
</contexts>
<marker>Blair-Goldensohn, Hannan, McDonald, Neylon, Reis, Reynar, 2008</marker>
<rawString>Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDonald, Tyler Neylon, George Reis, and Jeff Reynar. 2008. Building a sentiment summarizer for local service reviews. In Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="6766" citStr="Blei et al., 2003" startWordPosition="1067" endWordPosition="1070"> supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learning methods are Hidden Markov Models (HMM) (Rabiner, 2010) and Conditional Random Fields (CRF) (Lafferty et al., 2001). The last group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). There are two main basic models, pLSA (Probabilistic Latent Semantic Analysis) (Hofmann, 1999) and LDA (Latent Dirichlet allocation) (Blei et al., 2003). In the SA context, one can design a joint model to model both sentiment words and topics at the same time, due to the observation that every opinion has a target. 2.1.2 Aspect sentiment classification This task is to determine whether the opinions on different aspects are positive, negative, or neutral. The classification approaches can be divided to supervised learning approaches and lexicon-based approaches. Supervised learning performs b</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Boiy</author>
<author>Marie-Francine Moens</author>
</authors>
<title>A machine learning approach to sentiment analysis in multilingual web texts. Information retrieval,</title>
<date>2009</date>
<pages>12--5</pages>
<contexts>
<context position="7936" citStr="Boiy and Moens, 2009" startWordPosition="1258" endWordPosition="1261">on-based approaches. Supervised learning performs better in a particular application domain but it has difficulty to scale up to a large number of domains. Lexicon-based techniques often lose the fight against the learning but they are suitable for open-domain applications (Liu, 2012). The key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect of interest in the sentence. In (Jiang et al., 2011), a dependency parser was used to generate a set of aspect dependent features for classification. A related approach was also used in (Boiy and Moens, 2009), which weights each feature based on the position of the feature relative to the target aspect in the parse tree. Lexicon-based approaches use a list of sentiment phrases as the core resource. The method in (Ding et al., 2008) has four steps to assign a polarity to an aspect: mark sentiment words and phrases, apply sentiment shifters, handle butclauses and aggregate opinions using an aggregation function (e.g. Hu and Liu (2004)). 2.2 Sentiment analysis for Czech Pilot study of Czech sentiment analysis was shown in (Steinberger et al., 2012) where sentiment dictionaries for many languages (inc</context>
</contexts>
<marker>Boiy, Moens, 2009</marker>
<rawString>Erik Boiy and Marie-Francine Moens. 2009. A machine learning approach to sentiment analysis in multilingual web texts. Information retrieval, 12(5):526–558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom´aˇs Brychc´ın</author>
<author>Ivan Habernal</author>
</authors>
<title>Unsupervised improving of sentiment analysis using global target context.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013,</booktitle>
<pages>122--128</pages>
<publisher>Incoma Ltd. Shoumen,</publisher>
<location>Hissar, Bulgaria,</location>
<marker>Brychc´ın, Habernal, 2013</marker>
<rawString>Tom´aˇs Brychc´ın and Ivan Habernal. 2013. Unsupervised improving of sentiment analysis using global target context. In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013, pages 122–128, Hissar, Bulgaria, September. Incoma Ltd. Shoumen, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Web Search and Web Data Mining.</booktitle>
<contexts>
<context position="8163" citStr="Ding et al., 2008" startWordPosition="1298" endWordPosition="1301">y are suitable for open-domain applications (Liu, 2012). The key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect of interest in the sentence. In (Jiang et al., 2011), a dependency parser was used to generate a set of aspect dependent features for classification. A related approach was also used in (Boiy and Moens, 2009), which weights each feature based on the position of the feature relative to the target aspect in the parse tree. Lexicon-based approaches use a list of sentiment phrases as the core resource. The method in (Ding et al., 2008) has four steps to assign a polarity to an aspect: mark sentiment words and phrases, apply sentiment shifters, handle butclauses and aggregate opinions using an aggregation function (e.g. Hu and Liu (2004)). 2.2 Sentiment analysis for Czech Pilot study of Czech sentiment analysis was shown in (Steinberger et al., 2012) where sentiment dictionaries for many languages (including Czech) were created using semi-automatic “triangulation” method. Veselovsk´a (2012) created a small corpus containing polarity categories for 410 news sentences and used the Naive Bayes and lexicon-based classifiers. Thr</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In Proceedings of the Conference on Web Search and Web Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Habernal</author>
<author>Tom´as Brychc´ın</author>
</authors>
<title>Semantic spaces for sentiment analysis.</title>
<date>2013</date>
<booktitle>In Text, Speech and Dialogue,</booktitle>
<volume>8082</volume>
<pages>482--489</pages>
<publisher>Springer.</publisher>
<location>Berlin Heidelberg.</location>
<marker>Habernal, Brychc´ın, 2013</marker>
<rawString>Ivan Habernal and Tom´a&amp;quot;s Brychc´ın. 2013. Semantic spaces for sentiment analysis. In Text, Speech and Dialogue, volume 8082 of Lecture Notes in Computer Science, pages 482–489, Berlin Heidelberg. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Habernal</author>
<author>Tom´as Pt´acek</author>
<author>Josef Steinberger</author>
</authors>
<title>Sentiment analysis in czech social media using supervised machine learning.</title>
<date>2013</date>
<booktitle>In Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,</booktitle>
<pages>65--74</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<marker>Habernal, Pt´acek, Steinberger, 2013</marker>
<rawString>Ivan Habernal, Tom´a&amp;quot;s Pt´a&amp;quot;cek, and Josef Steinberger. 2013. Sentiment analysis in czech social media using supervised machine learning. In Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 65–74, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Sadegh Hajmohammadi</author>
<author>Roliana Ibrahim</author>
<author>Zulaiha Ali Othman</author>
</authors>
<title>Opinion mining and sentiment analysis: A survey.</title>
<date>2012</date>
<journal>International Journal of Computers &amp; Technology,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="4819" citStr="Hajmohammadi et al., 2012" startWordPosition="758" endWordPosition="761">ceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 24–30, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics approaches do (e.g. Steinberger et al. (2011)), a positive opinion about the entity does not mean that the author has positive opinions about all aspects of the entity. Aspect-based sentiment analysis, which has been also called ‘feature-based’ (Hu and Liu, 2004), goes even deeper as it attempts to identify (and assign the polarity to) aspects of the target entity within a sentence (Hajmohammadi et al., 2012). Whenever we talk about an aspect, we must know which entity it belongs to. In the further discussion, we often omit the entity as we analysed restaurant reviews and thus our target entities are the reviewed restaurants. 2.1 Aspect-based sentiment analysis The aspect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). 2.1.1 Aspect extraction The task of aspect extraction, which can also be seen as an information extraction task, is to detect aspects that have been evaluated. For example, in the sentence, The voice quality of this phone</context>
</contexts>
<marker>Hajmohammadi, Ibrahim, Othman, 2012</marker>
<rawString>Mohammad Sadegh Hajmohammadi, Roliana Ibrahim, and Zulaiha Ali Othman. 2012. Opinion mining and sentiment analysis: A survey. International Journal of Computers &amp; Technology, 2(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="6862" citStr="Hofmann, 1999" startWordPosition="1084" endWordPosition="1085">al information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learning methods are Hidden Markov Models (HMM) (Rabiner, 2010) and Conditional Random Fields (CRF) (Lafferty et al., 2001). The last group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). There are two main basic models, pLSA (Probabilistic Latent Semantic Analysis) (Hofmann, 1999) and LDA (Latent Dirichlet allocation) (Blei et al., 2003). In the SA context, one can design a joint model to model both sentiment words and topics at the same time, due to the observation that every opinion has a target. 2.1.2 Aspect sentiment classification This task is to determine whether the opinions on different aspects are positive, negative, or neutral. The classification approaches can be divided to supervised learning approaches and lexicon-based approaches. Supervised learning performs better in a particular application domain but it has difficulty to scale up to a large number of </context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4670" citStr="Hu and Liu, 2004" startWordPosition="733" endWordPosition="736">tify opinion targets or assign sentiments to such targets (Liu, 2012). Even if we recognize the target entity (as the entity-centered 24 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 24–30, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics approaches do (e.g. Steinberger et al. (2011)), a positive opinion about the entity does not mean that the author has positive opinions about all aspects of the entity. Aspect-based sentiment analysis, which has been also called ‘feature-based’ (Hu and Liu, 2004), goes even deeper as it attempts to identify (and assign the polarity to) aspects of the target entity within a sentence (Hajmohammadi et al., 2012). Whenever we talk about an aspect, we must know which entity it belongs to. In the further discussion, we often omit the entity as we analysed restaurant reviews and thus our target entities are the reviewed restaurants. 2.1 Aspect-based sentiment analysis The aspect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). 2.1.1 Aspect extraction The task of aspect extraction, which can also be</context>
<context position="8368" citStr="Hu and Liu (2004)" startWordPosition="1332" endWordPosition="1335">ence. In (Jiang et al., 2011), a dependency parser was used to generate a set of aspect dependent features for classification. A related approach was also used in (Boiy and Moens, 2009), which weights each feature based on the position of the feature relative to the target aspect in the parse tree. Lexicon-based approaches use a list of sentiment phrases as the core resource. The method in (Ding et al., 2008) has four steps to assign a polarity to an aspect: mark sentiment words and phrases, apply sentiment shifters, handle butclauses and aggregate opinions using an aggregation function (e.g. Hu and Liu (2004)). 2.2 Sentiment analysis for Czech Pilot study of Czech sentiment analysis was shown in (Steinberger et al., 2012) where sentiment dictionaries for many languages (including Czech) were created using semi-automatic “triangulation” method. Veselovsk´a (2012) created a small corpus containing polarity categories for 410 news sentences and used the Naive Bayes and lexicon-based classifiers. Three large labeled corpora (10k Facebook posts, 90k movie reviews, and 130k product reviews) were introduced in (Habernal et al., 25 2013).Authors also evaluate three different classifiers, namely Naive Baye</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7780" citStr="Jiang et al., 2011" startWordPosition="1230" endWordPosition="1233">opinions on different aspects are positive, negative, or neutral. The classification approaches can be divided to supervised learning approaches and lexicon-based approaches. Supervised learning performs better in a particular application domain but it has difficulty to scale up to a large number of domains. Lexicon-based techniques often lose the fight against the learning but they are suitable for open-domain applications (Liu, 2012). The key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect of interest in the sentence. In (Jiang et al., 2011), a dependency parser was used to generate a set of aspect dependent features for classification. A related approach was also used in (Boiy and Moens, 2009), which weights each feature based on the position of the feature relative to the target aspect in the parse tree. Lexicon-based approaches use a list of sentiment phrases as the core resource. The method in (Ding et al., 2008) has four steps to assign a polarity to an aspect: mark sentiment words and phrases, apply sentiment shifters, handle butclauses and aggregate opinions using an aggregation function (e.g. Hu and Liu (2004)). 2.2 Senti</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Konkol</author>
<author>Miloslav Konop´ık</author>
</authors>
<title>Crfbased czech named entity recognizer and consolidation of czech ner research.</title>
<date>2013</date>
<booktitle>In Ivan Habernal and V´aclav Matou&amp;quot;sek, editors, Text, Speech and Dialogue,</booktitle>
<volume>8082</volume>
<pages>153--160</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Konkol, Konop´ık, 2013</marker>
<rawString>Michal Konkol and Miloslav Konop´ık. 2013. Crfbased czech named entity recognizer and consolidation of czech ner research. In Ivan Habernal and V´aclav Matou&amp;quot;sek, editors, Text, Speech and Dialogue, volume 8082 of Lecture Notes in Computer Science, pages 153–160. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>Proceedings of International Conference on Machine Learning.</booktitle>
<contexts>
<context position="6658" citStr="Lafferty et al., 2001" startWordPosition="1047" endWordPosition="1050">on-aspect terms. Long et al. (2010) extracted aspects (nouns) based on frequency and information distance. Using supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learning methods are Hidden Markov Models (HMM) (Rabiner, 2010) and Conditional Random Fields (CRF) (Lafferty et al., 2001). The last group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). There are two main basic models, pLSA (Probabilistic Latent Semantic Analysis) (Hofmann, 1999) and LDA (Latent Dirichlet allocation) (Blei et al., 2003). In the SA context, one can design a joint model to model both sentiment words and topics at the same time, due to the observation that every opinion has a target. 2.1.2 Aspect sentiment classification This task is to determine whether the opinions on different aspects are positive, negative, or neutral. The classification approaches c</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: Analyzing and comparing opinions on the web. In</title>
<date>2005</date>
<booktitle>Proceedings of International Conference on World Wide Web.</booktitle>
<contexts>
<context position="5585" citStr="Liu et al., 2005" startWordPosition="884" endWordPosition="887">urant reviews and thus our target entities are the reviewed restaurants. 2.1 Aspect-based sentiment analysis The aspect scenario can be decomposed into two tasks: aspect extraction and aspect sentiment classification (Liu, 2012). 2.1.1 Aspect extraction The task of aspect extraction, which can also be seen as an information extraction task, is to detect aspects that have been evaluated. For example, in the sentence, The voice quality of this phone is amazing, the aspect is voice quality of the entity represented by this phone. The basic approach is finding frequent nouns and noun phrases. In (Liu et al., 2005), a specific method based on a sequential learning method was proposed to extract aspects from pros and cons, Blair-Goldensohn et al. (2008) refined the frequent noun and noun phrase approach by considering mainly those noun phrases that are in sentimentbearing sentences or in some syntactic patterns which indicate sentiments. Moghaddam and Ester (2010) augmented the frequency-based approach with an additional pattern-based filter to remove some non-aspect terms. Long et al. (2010) extracted aspects (nouns) based on frequency and information distance. Using supervised learning is another optio</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: Analyzing and comparing opinions on the web. In Proceedings of International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="4122" citStr="Liu, 2012" startWordPosition="653" endWordPosition="654">utomatic supervised approach (Section 5). In Section 6 we sumarize our contribution and reveal our future plans. 2 Related work The impact of SA can be seen in many practical applications, The users’ opinions are mostly extracted either on a certain polarity scale, or binary (positive, negative). From the point of view of the granularity, the polarity has been assigned to a document or to a sentence. However, classifying opinions at the document level or the sentence level is often insufficient for applications because they do not identify opinion targets or assign sentiments to such targets (Liu, 2012). Even if we recognize the target entity (as the entity-centered 24 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 24–30, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics approaches do (e.g. Steinberger et al. (2011)), a positive opinion about the entity does not mean that the author has positive opinions about all aspects of the entity. Aspect-based sentiment analysis, which has been also called ‘feature-based’ (Hu and Liu, 2004), goes even deeper as it attempts to identify (and a</context>
<context position="7600" citStr="Liu, 2012" startWordPosition="1200" endWordPosition="1201">ent words and topics at the same time, due to the observation that every opinion has a target. 2.1.2 Aspect sentiment classification This task is to determine whether the opinions on different aspects are positive, negative, or neutral. The classification approaches can be divided to supervised learning approaches and lexicon-based approaches. Supervised learning performs better in a particular application domain but it has difficulty to scale up to a large number of domains. Lexicon-based techniques often lose the fight against the learning but they are suitable for open-domain applications (Liu, 2012). The key issue for learning methods is to determine the scope of each sentiment expression, i.e., whether it covers the aspect of interest in the sentence. In (Jiang et al., 2011), a dependency parser was used to generate a set of aspect dependent features for classification. A related approach was also used in (Boiy and Moens, 2009), which weights each feature based on the position of the feature relative to the target aspect in the parse tree. Lexicon-based approaches use a list of sentiment phrases as the core resource. The method in (Ding et al., 2008) has four steps to assign a polarity </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chong Long</author>
<author>Jie Zhang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>A review selection approach for accurate feature rating estimation.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling 2010: Poster Volume.</booktitle>
<contexts>
<context position="6071" citStr="Long et al. (2010)" startWordPosition="956" endWordPosition="959">uality of the entity represented by this phone. The basic approach is finding frequent nouns and noun phrases. In (Liu et al., 2005), a specific method based on a sequential learning method was proposed to extract aspects from pros and cons, Blair-Goldensohn et al. (2008) refined the frequent noun and noun phrase approach by considering mainly those noun phrases that are in sentimentbearing sentences or in some syntactic patterns which indicate sentiments. Moghaddam and Ester (2010) augmented the frequency-based approach with an additional pattern-based filter to remove some non-aspect terms. Long et al. (2010) extracted aspects (nouns) based on frequency and information distance. Using supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learning methods are Hidden Markov Models (HMM) (Rabiner, 2010) and Conditional Random Fields (CRF) (Lafferty et al., 2001). The last gr</context>
</contexts>
<marker>Long, Zhang, Zhu, 2010</marker>
<rawString>Chong Long, Jie Zhang, and Xiaoyan Zhu. 2010. A review selection approach for accurate feature rating estimation. In Proceedings of Coling 2010: Poster Volume.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of International Conference on World Wide Web.</booktitle>
<contexts>
<context position="6720" citStr="Mei et al., 2007" startWordPosition="1059" endWordPosition="1062">on frequency and information distance. Using supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learning methods are Hidden Markov Models (HMM) (Rabiner, 2010) and Conditional Random Fields (CRF) (Lafferty et al., 2001). The last group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). There are two main basic models, pLSA (Probabilistic Latent Semantic Analysis) (Hofmann, 1999) and LDA (Latent Dirichlet allocation) (Blei et al., 2003). In the SA context, one can design a joint model to model both sentiment words and topics at the same time, due to the observation that every opinion has a target. 2.1.2 Aspect sentiment classification This task is to determine whether the opinions on different aspects are positive, negative, or neutral. The classification approaches can be divided to supervised learning approaches and lexicon-ba</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>Opinion digger: an unsupervised opinion miner from unstructured product reviews.</title>
<date>2010</date>
<booktitle>In Proceeding of the ACM conference on Information and knowledge management.</booktitle>
<contexts>
<context position="5940" citStr="Moghaddam and Ester (2010)" startWordPosition="938" endWordPosition="941">to detect aspects that have been evaluated. For example, in the sentence, The voice quality of this phone is amazing, the aspect is voice quality of the entity represented by this phone. The basic approach is finding frequent nouns and noun phrases. In (Liu et al., 2005), a specific method based on a sequential learning method was proposed to extract aspects from pros and cons, Blair-Goldensohn et al. (2008) refined the frequent noun and noun phrase approach by considering mainly those noun phrases that are in sentimentbearing sentences or in some syntactic patterns which indicate sentiments. Moghaddam and Ester (2010) augmented the frequency-based approach with an additional pattern-based filter to remove some non-aspect terms. Long et al. (2010) extracted aspects (nouns) based on frequency and information distance. Using supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learn</context>
</contexts>
<marker>Moghaddam, Ester, 2010</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2010. Opinion digger: an unsupervised opinion miner from unstructured product reviews. In Proceeding of the ACM conference on Information and knowledge management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Amber Stubbs</author>
</authors>
<title>Natural Language Annotation for Machine Learning. OReilly</title>
<date>2013</date>
<pages>95472</pages>
<location>Media, Sebastopol, CA</location>
<contexts>
<context position="15227" citStr="Pustejovsky and Stubbs, 2013" startWordPosition="2393" endWordPosition="2396">sentences. 18.8% of the sentences were marked as irrelevant, leaving 1,244 sentences for further analysis. Their average agreement for the task of aspect terms’ identification was 82.6% (measured by F-measure). Only strict matches were considered correct. In the case of identifying the categories, their average agreement (Fmeasure) was 91.8%. The annotators agreed on 85.5% (accuracy) in the task of assigning polarity to terms and on 82.4% (accuracy) in the case of the category polarity assignment. It corresponds to Cohen’s of 0.762, resp. 0.711, which represents a substantial agreement level (Pustejovsky and Stubbs, 2013), therefore the task can be considered as well-defined. There were several reasons of disagreement. The annotators did not always itentify the same terms, mainly in the cases with general meaning. In the case of polarity, the annotators did not agree on the most difficult cases to which bipolar class could be assigned: Trochu pˇresolen´a om´aˇcka, ale jinak luxus. (Too salted sauce, but luxury otherwise.) food: bipolar vs. positive The cases, on which the two annotators did not agree, were judged by the third super-annotator and golden standard data were created. The final dataset1 contains 12</context>
</contexts>
<marker>Pustejovsky, Stubbs, 2013</marker>
<rawString>James Pustejovsky and Amber Stubbs. 2013. Natural Language Annotation for Machine Learning. OReilly Media, Sebastopol, CA 95472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>2010</date>
<booktitle>In Proceedings of the IEEE,</booktitle>
<pages>257--286</pages>
<contexts>
<context position="6598" citStr="Rabiner, 2010" startWordPosition="1040" endWordPosition="1041"> an additional pattern-based filter to remove some non-aspect terms. Long et al. (2010) extracted aspects (nouns) based on frequency and information distance. Using supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learning methods are Hidden Markov Models (HMM) (Rabiner, 2010) and Conditional Random Fields (CRF) (Lafferty et al., 2001). The last group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). There are two main basic models, pLSA (Probabilistic Latent Semantic Analysis) (Hofmann, 1999) and LDA (Latent Dirichlet allocation) (Blei et al., 2003). In the SA context, one can design a joint model to model both sentiment words and topics at the same time, due to the observation that every opinion has a target. 2.1.2 Aspect sentiment classification This task is to determine whether the opinions on different aspects are pos</context>
</contexts>
<marker>Rabiner, 2010</marker>
<rawString>Lawrence Rabiner. 2010. A tutorial on hidden markov models and selected applications in speech recognition. In Proceedings of the IEEE, pages 257–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning. In Natural language processing using very large corpora,</title>
<date>1999</date>
<pages>157--176</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="17310" citStr="Ramshaw and Marcus, 1999" startWordPosition="2730" endWordPosition="2734">seful in sentiment analysis (Habernal et al., 2013; Habernal and Brychc´ın, 2013; Brychc´ın and Habernal, 2013). All particular subtasks share following features: Bag of words: The occurrence of a word. Bag of bigrams: The occurrence of a bigram. Bag of stems: The occurrence of a stem. Bag of stem bigrams: The occurrence of a stem bigram. 5.2 Aspect term extraction The system for aspect term extraction is based on CRF. The choice of CRF is based on a current state of the art in named entity recognition (see for example (Konkol and Konop´ık, 2013)) as it is a very similar task. We use the BIO (Ramshaw and Marcus, 1999) model to represent aspect terms. In addition to the previously mentioned features we use affixes and learned dictionaries. Affixes are simply prefixes and suffixes of length 2 to 4. Learned dictionaries are phrases that are aspect terms in the training data. Our system achieved 58.14 precision, 83.80 recall and 68.65 F-measure. 5.3 Aspect term polarity During the detection of the aspect term polarities, the words affecting the sentiment of the aspect term are assumed to be close in most of cases. Thus we use a small window (10 words in both directions) around the target aspect term. We assume</context>
</contexts>
<marker>Ramshaw, Marcus, 1999</marker>
<rawString>Lance A Ramshaw and Mitchell P Marcus. 1999. Text chunking using transformation-based learning. In Natural language processing using very large corpora, pages 157–176. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Steinberger</author>
<author>P Lenkova</author>
<author>M Kabadjov</author>
<author>R Steinberger</author>
<author>E van der Goot</author>
</authors>
<title>Multilingual entity-centered sentiment analysis evaluated by parallel corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of the 8th International Conference Recent Advances in Natural Language Processing, RANLP’11,</booktitle>
<pages>770--775</pages>
<marker>Steinberger, Lenkova, Kabadjov, Steinberger, van der Goot, 2011</marker>
<rawString>J. Steinberger, P. Lenkova, M. Kabadjov, R. Steinberger, and E. van der Goot. 2011. Multilingual entity-centered sentiment analysis evaluated by parallel corpora. In Proceedings of the 8th International Conference Recent Advances in Natural Language Processing, RANLP’11, pages 770–775.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Steinberger</author>
<author>M Ebrahim</author>
<author>M Ehrmann</author>
<author>A Hurriyetoglu</author>
<author>M Kabadjov</author>
<author>P Lenkova</author>
<author>R Steinberger</author>
<author>H Tanev</author>
<author>S Vzquez</author>
<author>V Zavarella</author>
</authors>
<title>Creating sentiment dictionaries via triangulation. Decision Support Systems,</title>
<date>2012</date>
<pages>53--689</pages>
<contexts>
<context position="8483" citStr="Steinberger et al., 2012" startWordPosition="1350" endWordPosition="1353">for classification. A related approach was also used in (Boiy and Moens, 2009), which weights each feature based on the position of the feature relative to the target aspect in the parse tree. Lexicon-based approaches use a list of sentiment phrases as the core resource. The method in (Ding et al., 2008) has four steps to assign a polarity to an aspect: mark sentiment words and phrases, apply sentiment shifters, handle butclauses and aggregate opinions using an aggregation function (e.g. Hu and Liu (2004)). 2.2 Sentiment analysis for Czech Pilot study of Czech sentiment analysis was shown in (Steinberger et al., 2012) where sentiment dictionaries for many languages (including Czech) were created using semi-automatic “triangulation” method. Veselovsk´a (2012) created a small corpus containing polarity categories for 410 news sentences and used the Naive Bayes and lexicon-based classifiers. Three large labeled corpora (10k Facebook posts, 90k movie reviews, and 130k product reviews) were introduced in (Habernal et al., 25 2013).Authors also evaluate three different classifiers, namely Naive Bayes, SVM (Support Vector Machines) and Maximum Entropy on these data. Recently, Habernal and Brychcin (2013) experime</context>
</contexts>
<marker>Steinberger, Ebrahim, Ehrmann, Hurriyetoglu, Kabadjov, Lenkova, Steinberger, Tanev, Vzquez, Zavarella, 2012</marker>
<rawString>J. Steinberger, M. Ebrahim, Ehrmann M., A. Hurriyetoglu, M. Kabadjov, P. Lenkova, R. Steinberger, H. Tanev, S. Vzquez, and V. Zavarella. 2012. Creating sentiment dictionaries via triangulation. Decision Support Systems, 53:689–694.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Stepanov</author>
<author>G Riccardi</author>
</authors>
<title>Detecting general opinions from customer surveys.</title>
<date>2011</date>
<booktitle>In Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on,</booktitle>
<pages>115--122</pages>
<contexts>
<context position="1659" citStr="Stepanov and Riccardi, 2011" startWordPosition="244" endWordPosition="247">o the research community. Furthermore, we propose a baseline system based on supervised machine learning. Our system detects the aspect terms with Fmeasure 68.65% and their polarities with accuracy 66.27%. The categories are recognized with F-measure 74.02% and their polarities with accuracy 66.61%. 1 Introduction The interest in sentiment analysis (SA) is increasing with the amount of easily accessible content on the web, especially from the social media. Sentiment polarity is one of the critical information needed for many analysis of the data. Its use ranges from analysing product reviews (Stepanov and Riccardi, 2011) to predicting sales and stock markets using social media monitoring (Yu et al., 2013). The majority of current approaches tries to detect the overall polarity of a sentence (or a document) regardless of the target entities (e.g., restaurants, laptops) and their aspects (e.g., food, price, battery, screen). By contrast, the aspect-driven sentiment analysis identifies the aspects of a given target entity and estimates the sentiment polarity for each mentioned aspect. This opens up completely new possibilities how to analyse the data. The most of the research in automatic sentiment analysis has </context>
</contexts>
<marker>Stepanov, Riccardi, 2011</marker>
<rawString>E.A. Stepanov and G. Riccardi. 2011. Detecting general opinions from customer surveys. In Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on, pages 115–122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of International Conference on World Wide Web.</booktitle>
<contexts>
<context position="6746" citStr="Titov and McDonald, 2008" startWordPosition="1063" endWordPosition="1066">nformation distance. Using supervised learning is another option. Aspect extraction can be seen as a special case of the general information extraction problem. The most dominant methods are based on sequential learning. Since these are supervised techniques, they need manually labeled data for training. One needs to manually annotate aspects and non-aspects in a corpus. The current stateof-the-art sequential learning methods are Hidden Markov Models (HMM) (Rabiner, 2010) and Conditional Random Fields (CRF) (Lafferty et al., 2001). The last group of methods use topic models (Mei et al., 2007; Titov and McDonald, 2008; Blei et al., 2003). There are two main basic models, pLSA (Probabilistic Latent Semantic Analysis) (Hofmann, 1999) and LDA (Latent Dirichlet allocation) (Blei et al., 2003). In the SA context, one can design a joint model to model both sentiment words and topics at the same time, due to the observation that every opinion has a target. 2.1.2 Aspect sentiment classification This task is to determine whether the opinions on different aspects are positive, negative, or neutral. The classification approaches can be divided to supervised learning approaches and lexicon-based approaches. Supervised</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In Proceedings of International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina Veselovsk´a</author>
</authors>
<title>Sentence-level sentiment analysis in czech.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics.</booktitle>
<publisher>ACM.</publisher>
<marker>Veselovsk´a, 2012</marker>
<rawString>Kate&amp;quot;rina Veselovsk´a. 2012. Sentence-level sentiment analysis in czech. In Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang-Chih Yu</author>
<author>Jheng-Long Wu</author>
<author>Pei-Chann Chang</author>
<author>Hsuan-Shou Chu</author>
</authors>
<title>Using a contextual entropy model to expand emotion words and their intensity for the sentiment classification of stock market news. Knowledge Based Syst,</title>
<date>2013</date>
<pages>41--89</pages>
<contexts>
<context position="1745" citStr="Yu et al., 2013" startWordPosition="258" endWordPosition="261">arning. Our system detects the aspect terms with Fmeasure 68.65% and their polarities with accuracy 66.27%. The categories are recognized with F-measure 74.02% and their polarities with accuracy 66.61%. 1 Introduction The interest in sentiment analysis (SA) is increasing with the amount of easily accessible content on the web, especially from the social media. Sentiment polarity is one of the critical information needed for many analysis of the data. Its use ranges from analysing product reviews (Stepanov and Riccardi, 2011) to predicting sales and stock markets using social media monitoring (Yu et al., 2013). The majority of current approaches tries to detect the overall polarity of a sentence (or a document) regardless of the target entities (e.g., restaurants, laptops) and their aspects (e.g., food, price, battery, screen). By contrast, the aspect-driven sentiment analysis identifies the aspects of a given target entity and estimates the sentiment polarity for each mentioned aspect. This opens up completely new possibilities how to analyse the data. The most of the research in automatic sentiment analysis has been devoted to English. There were several attempts in Czech (Steinberger et al., 201</context>
</contexts>
<marker>Yu, Wu, Chang, Chu, 2013</marker>
<rawString>Liang-Chih Yu, Jheng-Long Wu, Pei-Chann Chang, and Hsuan-Shou Chu. 2013. Using a contextual entropy model to expand emotion words and their intensity for the sentiment classification of stock market news. Knowledge Based Syst, 41:89–97, March.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>