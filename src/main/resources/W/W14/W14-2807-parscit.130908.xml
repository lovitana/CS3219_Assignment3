<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000155">
<title confidence="0.9909475">
Rules, Analogy, and Social Factors codetermine past-tense formation
patterns in English
</title>
<author confidence="0.996848">
P´eter Ricz
</author>
<affiliation confidence="0.996647666666667">
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
</affiliation>
<email confidence="0.672131">
peter.racz@
</email>
<author confidence="0.990061">
Clay Beckner
</author>
<affiliation confidence="0.7064976">
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
clayton.beckner@
canterbury.ac.nz
</affiliation>
<author confidence="0.929246">
Jennifer B. Hay
</author>
<affiliation confidence="0.988760666666667">
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
</affiliation>
<email confidence="0.708056">
jen.hay@
</email>
<author confidence="0.96741">
Janet B. Pierrehumbert
</author>
<affiliation confidence="0.9966404">
Department of Linguistics / NICO
Northwestern University.
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
</affiliation>
<email confidence="0.997865">
jbp@northwestern.edu
</email>
<sectionHeader confidence="0.993886" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999900894736842">
We investigate past-tense formation pref-
erences for five irregular English verb
classes. We gathered data on a large scale
using a nonce probe study implemented on
Amazon Mechanical Turk. We compare
a Minimal Generalization Learner (which
infers stochastic rules) with a General-
ized Context Model (which evaluates new
items via analogy with existing items) as
models of participant choices. Overall,
the GCM is a better predictor, but the
the MGL provides some additional pre-
dictive power. Because variation across
speakers is greater than variation across
items, we also explore individual-level
factors as predictors. Females exhibited
significantly more categorical choices than
males, a finding that can be related to re-
sults in sociolinguistics.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997193220339">
In this report, we present a psycholinguistic study
of English past tense categories, using a nonce-
probe experiment implemented on Amazon Me-
chanical Turk. The English past tense has been
a testing-ground for a wide range of theories
and predictions in psycholinguistics, including the
processes of acquisition, the nature of lexical rep-
resentation, and the representation of inflectional
patterns as rules or as generalizations over spe-
cific items (Bybee and Slobin, 1982a; Rumelhart
and McClelland, 1985; McClelland and Patterson,
2002; Albright and Hayes, 2003).
The present study investigates the factors in-
fluencing patterns of preferred past tense forms
for particular verb classes. English past tenses
are not merely a memorized list, but rather, verb
categories can shrink, or expand to include new
items. In everyday speech, there is evidence of
ongoing influences from multiple verb classes, as
verbs exhibit variation and slowly shift in their us-
age (dived vs. dove, sneaked vs. snuck), (Haber,
1976; Bybee and Moder, 1983).
Given that speakers can adapt their verbal cate-
gories to new situations, what is the best represen-
tation for the relevant morphological generaliza-
tions? In analogical models, the focus is on exist-
ing stored items in memory. The acceptability of
a candidate past tense formation pattern for a par-
ticular candidate item is determined by patterns of
similarity to stored items. Morphological innova-
tion and productivity arises from generalizations
over existing forms in the lexicon. To account for a
speech error such as glew as the past tense of glow
(Bybee and Slobin, 1982a), an analogical explana-
tion would highlight the close similarity between
glow and the present tense forms blow, throw,
know, which provide the basis for an analogy with
the past forms blew, threw, knew. Of particular
interest is the Generalized Context Model (GCM)
(Nosofsky, 1990; Albright and Hayes, 2003), an
analogical model which assesses a category’s suit-
ability to a target item on the basis of feature-
based similarities summed over category items,
in addition to the category’s size. It has already
been successfully applied to model regular and ir-
regular patterns in Arabic morphology (Dawdy-
Hesterberg and Pierrehumbert, 2014).
Rule-based approaches propose more abstract
representations of generalizations. Originally pro-
posed to handle broadly applicable default pat-
terns, (such as ‘add -ed to express the past
tense’), rule-based approaches have recently been
extended to incorporate multiple stochastic rules.
Albright and Hayes (2003) assign scores to mor-
phological rules by training a Minimal General-
ization Learner (MGL) over a dataset, an algo-
rithm that iterates over pairs of words in the lexi-
con, hypothesizing generalizations conservatively
on the basis of any phonological features that are
</bodyText>
<page confidence="0.986685">
55
</page>
<note confidence="0.7872315">
Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 55–63,
Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999681769230769">
shared across the words. A rule is scored accord-
ing to how many items it applies to in the lexi-
con, weighted against cases in which the inferred
phonological context is present but the rule fails
to apply. The resulting system consists of a cat-
alog of weighted natural class-based generaliza-
tions which compete with one another, and which
are more or less likely to apply in various phono-
logical contexts (for regular as well as irregular
verbs). Albright and Hayes argue that the MGL
outperforms the GCM in predicting participant be-
havior in a nonce-verb production task they con-
ducted.
</bodyText>
<sectionHeader confidence="0.997571" genericHeader="introduction">
2 Experiment
</sectionHeader>
<bodyText confidence="0.999983304347826">
We collected a large amount of data on irregular
past tense formation in English with a nonce probe
test, a classic method for exploring the produc-
tivity of inflectional morphology (Berko, 1958).
Earlier studies used 30 or fewer participants per
condition (Bybee and Slobin, 1982a; Albright and
Hayes, 2003). By using Amazon Mechanical
Turk, a burgeoning forum for psycholinguistic re-
search (Munro et al., 2010), we were able to re-
cruit a large number of participants and explore
the role of individual-level factors in the choice
of morphological patterns. Moreover, we tested
participant preferences across a large dataset (316
nonce verbs) based on broad phonological sam-
pling within verb classes, allowing for repeated
trials across similar items for each participant.
Participants in our online study were presented
with a forced choice task in which they had to pick
either the regular or the irregular past tense form
for an English nonce verb, presented in a carrier
sentence. This was followed by a vocabulary task
in which participants had to rate the familiarity of
English nouns.
</bodyText>
<subsectionHeader confidence="0.984087">
2.1 Stimuli
</subsectionHeader>
<bodyText confidence="0.999943315789474">
We set up five categories of irregular past tense
formation based on phonological form of the
present tense verb, and its corresponding candi-
date tense past forms. Each category exhibits
phonological variability within the category, while
also allowing for a specific phonological descrip-
tion. We avoided ‘miscellaneous’ verb classes, as
well as wholly idiosyncratic patterns (such as go–
went). Moreover, we are particularly interested
in morphological classes which are known to dis-
play some indeterminacy (Haber, 1976), i.e., those
classes which display some regular/irregular vari-
ation (dived vs. dove), due to the ready availabil-
ity of multiple generalizations. The literature con-
tains various taxonomies of English irregular verb
classes (Bybee and Slobin, 1982a), but our current
classification mostly represents a subset of the de-
tailed verb classes outlined by Moder (1992).
The five categories of interest are as follows.
</bodyText>
<listItem confidence="0.990693592592593">
• SANG. Verbs that form the past tense with a
vowel change from [I] to [w] (e.g. sing–sang,
sink–sank, swim–swam).
• BURNT. Verbs that form the past tense by
adding a [t], with no change in the stem vowel
(e.g. burn–burnt, spill–spilt, learn–learnt).
These items constitute a distinct set from reg-
ular English pasts such as boss–bossed which
are articulated with a [t] allomorph, insofar as
the burnt verb bases actually end in a voiced
consonant but are nonetheless affixed with a
voiceless stop.
• KEPT. Verbs that form the past tense by
adding a final [t] and changing the stem
vowel from [i] to [e] (e.g. keep–kept, mean–
meant, feel–felt ).
• DROVE. Verbs that form the past tense with
a vowel change from [aI] or [i] to [oU] (e.g.
drive–drove, weave–wove, ride–rode).
• CUT. No-change past tense verbs, that is,
verbs the past tense form of which is identi-
cal to their present tense form. (e.g. cut–cut,
cost–cost, hurt–hurt). Verb bases in this class
end in sounds that are already associated with
the English past tense ([t] or [d]) (Bybee
and Slobin, 1982a), although the nonce verb
bases in the present study all end in [t].
</listItem>
<bodyText confidence="0.999962153846154">
We generated nonce verb forms by combining
the category-specific restrictions spelled out above
on the stem with a set of syllable onsets that oc-
cur in English. Using CELEX (Baayen et al.,
1993), we then filtered the orthographic and pho-
netic transcriptions of the nonce stems, as well as
the resulting past tense forms, to exclude real En-
glish words. Two native speakers checked the final
list to remove additional real words that were not
filtered out via the CELEX database (e.g., slang
and informal terms). All our verb forms were
monosyllabic– as are almost all English irregular
verbs in general. The method used to generate the
</bodyText>
<page confidence="0.99435">
56
</page>
<bodyText confidence="0.9981454">
stimuli means that some nonce forms looked more
similar to real English verbs than others. This way
we can tell whether similarities to a single form
will strongly influence people’s behavior in the
case where the nonce form is highly similar to a
single real form.
The sang and cut categories consist of 60
forms. The burnt category has 40, drove has 76,
and kept has 80. The total number of nonce verbs
is 316.
</bodyText>
<subsectionHeader confidence="0.998335">
2.2 Setup
</subsectionHeader>
<bodyText confidence="0.99997662962963">
The experiment consisted of a forced choice task,
in which participants had to pick a regular or ir-
regular past tense form for each verb. Verbs were
presented one at a time, visually, in a carrier sen-
tence of the form ‘I really like to VERB. Yester-
day, I .’. Two buttons were presented under the
carrier sentence, one with the regular past tense,
adding -ed, and one with the irregular past tense.
The irregular past tense was always the dominant
pattern for the category. (So, for cut, it was identi-
cal to the present tense, etc.) The order of the two
buttons was randomized for each verb. Each verb
was presented once and the order of verbs was ran-
domized for each participant.
The experiment was appended by a word fa-
miliarity rating task. The rating task was based
on Frisch and Brea-Spahn (2010). It consisted of
50 nouns of varying familiarity, as well as 10 ex-
tremely common nouns and 10 nonce words. The
70 words were presented in a random order. The
participant had to select, on a scale of 1-5, how
familiar the given word was. Incorrect answers to
the extremely common nouns and the nonce words
were used as an exclusion criterion. Answers for
the other items were used as an index of vocabu-
lary level, which is predicted to affect morpholog-
ical choices in both the GCM and MGL models.
</bodyText>
<subsectionHeader confidence="0.996258">
2.3 Participants
</subsectionHeader>
<bodyText confidence="0.9996764">
111 people took part in the experiment on Amazon
Mechanical Turk during the course of two days.
51 were women, 60 were men, and 1 did not spec-
ify. The age range of the participants was 20-65,
and the mean age was 34. All participants were
native speakers of American English. Participants
were paid three dollars. We excluded ten partici-
pants from the analysis because they failed to dif-
ferentiate familiar from unfamiliar words in the
vocabulary test.
</bodyText>
<table confidence="0.928645333333333">
Category Experiment Nonce Examples
drove 0.52 skride: skrode, skrided
sang 0.58 sking: skang, skinged
kept 0.59 skeep: skept, skeeped
burnt 0.67 skurn: skurnt, skurned
cut 0.83 skast: skast, skasted
</table>
<tableCaption confidence="0.973668">
Table 1: Categories and mean regularization rat-
ings.
</tableCaption>
<subsectionHeader confidence="0.767815">
2.4 Results
</subsectionHeader>
<bodyText confidence="0.999965875">
The nonce verb categories have different rates of
regular vs. irregular usage, as can be seen in Ta-
ble 1. The Experiment column shows the mean
regularization rates of the categories in our exper-
iment. The drove class was regularized the least
often, and the cut class the most often, with a con-
siderable difference between the two.
The trends across verb classes are similar to
those of Moder’s (1992) nonce experiment. Note
in particular the high regularization rate (83%) of
the no-change class of verbs (cut). A search of
CELEX indicates that no-change [t]-final verbs
are quite widespread in English, represented by
more than 30 types. Yet based on nonce responses,
the English no-change pattern is not very prone to
being applied to novel items. This finding matches
observations by Bybee (1982b) that the no-change
verb class has been on the decline in English, as
evident from increasing regularization. One note-
worthy feature of the cut-type verbs is that the
phonological shape of the base is a quite unreliable
indicator of verb class. That is to say, there are
many [t]- final verb stems which typically take the
regular -ed suffix (e.g., gritted, salted, blasted, and
these provide counterexamples to the no-change
pattern (cf. Moder (1992) on cue validity).
We fit a simple stepwise logistic mixed-effects
regression model to the results with a maximal
random effects structure, using regularization of
individual verb form (yes or no) as an outcome
variable and category as predictor. This model
confirms the general finding that there is signif-
icant variation across the verb classes. (Signifi-
cance values reported are based on difference with
the sang class.) The cut class shows the highest
rate of regularization (p&lt;0.001), followed by the
burnt class (p&lt;0.01). It is followed by the sang
and kept classes (these two do not differ signifi-
cantly). The drove class shows the lowest rate of
regularization (p&lt;0.01).
</bodyText>
<page confidence="0.990946">
57
</page>
<bodyText confidence="0.92125">
Participant gender, age, and vocabulary size are
not significant predictors of regularization in the
simple logistic mixed effects model. However an
examination of the data (Figure 1) reveals that for
each verb class, variation across subjects is consid-
erably greater than variation across items. This ob-
servation suggests that individual traits may play
a role in morphological choices in a way that the
simple model fails to capture. We will return
to this issue after presenting the GCM and MGL
model fits, and will find in the end that gender does
affect response patterns.
burnt cut drove kept sang
category
burnt cut drove kept sang
category
</bodyText>
<figureCaption confidence="0.93441925">
Figure 1: Across-item variation in regularization
rates across category (above). Across-subject vari-
ation in regularization rates across category (be-
low).
</figureCaption>
<sectionHeader confidence="0.97488" genericHeader="method">
3 Algorithmic Learning Models
</sectionHeader>
<bodyText confidence="0.999807">
We now turn our attention from the baseline ef-
fects of category variables, to investigate the pre-
dictions of particular algorithmic learning models
that provide alternate representations for general-
izations on the basis of similarity. Our analyses fo-
cus on the predictions of the Minimal Generaliza-
tion Learner and the Generalized Context Model
(Albright and Hayes, 2003; Nosofsky, 1990).
</bodyText>
<subsectionHeader confidence="0.999678">
3.1 The two models
</subsectionHeader>
<bodyText confidence="0.999727875">
The Minimal Generalization Learner (MGL) (Al-
bright and Hayes, 2002; Albright and Hayes,
2003) is an algorithm for inferring stochastic
morphophonological generalizations over a set of
training items (e.g., paired present and past tense
forms). For each pair of items in the lexicon, the
learner maximally aligns wordforms and analyzes
shared phonetic features, thereby merging word-
specific rules (ring/rang and stink/stank) into rules
that express the most general applicable environ-
ment: [I] → [w] / [+coronal, + cont] [N].
Each rule inferred in this way is then fur-
ther generalized on the basis of more compar-
isons; for instance, taking note of swim/swam ex-
pands the [I] → [w] rule to specify that it oc-
curs before all [+nasal] consonants. The algorithm
thus infers a set of natural-class based generaliza-
tions, which are weighted by comparing the num-
ber of hits for the past tense pattern (ring/rang,
drink/drank, sing/sang, stink/stank, swim/swam,
etc.) divided by the number of cases in which the
alternation fails to apply although it could apply
(thus tallying exceptions such as think and blink).
This appproach favors generalizations that cover
many cases, but penalizes those that are too broad
because their phonetic environments encompass
many exceptions. The MGL reliability metric is
further adjusted to a confidence score, in which
generalizations that apply to a smaller number of
word types are penalized.
Note that the MGL algorithm automatically
groups together items on the basis of shared
phonological properties; thus, monosyllabic verbs
are most likely to form strong generalizations with
other monosyllabic verbs. Attempts to merge
diverse wordforms under a single generalization
would be more likely to incur penalties (i.e., ex-
ceptions). This feature of the MGL is impor-
tant for comparing with the methods of the GCM
(see below). Both algorithms allow for category-
</bodyText>
<figure confidence="0.97058775">
mean rate of regularization
0.4 0.6 0.8
●
items
mean rate of regularization
0.0 0.2 0.4 0.6 0.8 1.0
●
subjects
</figure>
<page confidence="0.994557">
58
</page>
<bodyText confidence="0.999795421568628">
specific similarities to play a role.
The Minimal Generalization Learner is imple-
mented here from materials made available by Al-
bright and Hayes (2003), including their Segmen-
tal Similarity Calculator based on Frisch et al.
(2004). The MGL is trained on regular and irreg-
ular English verbs with a minimum frequency cut-
off of 10 in COBUILD (Baayen et al., 1993), and
excluding prefixed verb forms, thus encompassing
4253 past/present verb transcriptions. The MGL is
implemented here with its default settings, which
includes a lower 75% confidence interval for pur-
poses of adjusting the reliability score.
The Generalized Context Model (GCM) is an
instance-based model of categorization. To as-
sign category membership to a novel instance, it
first calculates its similarity to instances in pre-
existing categories. Then, it selects the category
with members that are most similar to the novel
instance (Nosofsky, 1990). Our implementation
of the GCM has three notable aspects to it.
First, we used the GCM to categorize our nonce
verb stimuli, basing the categories on real English
verb types extracted from CELEX (as with the
MGL). Second, we used the same segmental sim-
ilarity calculator developed and used by Albright
and Hayes and used by the Minimal Generaliza-
tion Learner to calculate the similarity of phoneti-
cally transcribed word forms to each other, so that
we could take the phonetic similarity of speech
sounds into account instead of calculating simi-
larity between word forms based on edit distance
alone. We did not weight parts of the word forms
differently, because there is evidence that although
past tense formation in English is predominantly
driven by similarities in word endings, onsets also
play a role. (cf. the predominance of s+stop on-
sets in irregular verbs forming the past tense with
a vowel change, e.g. sing, sink, etc.) (Bybee and
Moder, 1983).
Third, our implementation of the GCM re-
flected the structure of the task. Recall from Sec-
tion 2 that participants were presented with the
stems of the nonce verbs in a sequence and had to
pick either a regular or an irregular past tense form
for them. The irregular past tense form was pre-
determined by category, so that, for a given verb,
the participants could only choose between the
regular past tense form or the irregular past tense
form we assigned to the verb. (So, for instance,
for spling, they could choose either splinged or
splang, but not splung or splingt, etc.) For a given
category (such as sang verbs), the GCM had a
choice between two sets. The irregular set con-
sisted of verb types in CELEX that form their past
tense according to the pattern captured by the cat-
egory (such as an [I]–[w] alternation). The regular
set consisted of verb types that have a stem that
matches the category (such as ‘monosyllabic and
stem vowel [I]’) but have a regular past tense. The
model calculated the similarity of a given nonce
verb to these two sets (depending on its category).
In this paper, we report on category weights as-
signed to the regular category, which are compa-
rable with both the results of the Minimal Gener-
alization Learner and the rate of regularization in
our experiment. We only used monosyllabic verbs
in identifying relevant matches, for regular as well
as irregular items.
Values reported here were generated with no
frequency cutoff. Alternate runs with the fre-
quency threshold enforced produce no change in
the model. The model is run with the default pa-
rameter settings of s = 0.3, p = 1 with respect
to calculating the weighted similarities between
items. When p is set to 1, as here, the similar-
ity function is exponential, rather than Gaussian.
The weighting parameters controls the tradeoff in
the relative importance of the size of the verb cat-
egory (the ’gang size’) vs. the amount of similar-
ity (measured via edit distance between phonolog-
ical forms) (Nosofsky, 1990; Nakisa et al., 2001;
Albright and Hayes, 2003; Dawdy-Hesterberg and
Pierrehumbert, 2014).
Figure 2 shows three plots. The first one de-
picts the relationship between the predictions of
the GCM (regular category weight) and experi-
mental ratings (mean participant regularization)
for individual verb types used in the experiment.
The Spearman rank correlation is highly signifi-
cant (rho = 0.497, p &lt; 0.001). The second one
depicts the relationship between the MGL model
predictions (reliability rating of the regular form)
and mean participant regularization in the exper-
iment. The Spearman rank correlation between
these variables is highly significant (rho = 0.393,
p &lt; 0.001). The predictions of the two models are
z-scored to allow for comparability. The third plot
shows the relationship between the predictions of
the GCM and the MGL for individual verb types
in the experiment. The Spearman rank correla-
tion between these variables is highly significant
</bodyText>
<page confidence="0.995224">
59
</page>
<table confidence="0.960624333333333">
CATEGORY GCM MGL
SANG 0.65 0.55
CUT 0.18 -0.19
DROVE 0.37 0.64
KEPT 0.52 0.18
BURNT 0.48 0.24
ALL 0.5 0.39
●
Ratings vs. GCM
</table>
<figure confidence="0.937352137681159">
●
●
●
● ●
●
●●●●●●
● ●● ● ● ● ●
●●
●●
●
●●●
● ●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
average regularity in experiment
0.4 0.5 0.6 0.7 0.8 0.9
●
●
● ● ● ●
●
●
●
● ●
● ●
●●●●●
●
●
● ●
● ●● ●●● ● ● ● ●
● ● ●●
● ● ● ●
● ● ● ● ●
● ● ● ●
● ●● ● ●●
● ● ● ● ● ● ● ● ● ●
● ●
● ● ● ● ●● ● ● ●
● ● ● ● ●
● ● ● ●
● ● ● ● ● ● ●
● ● ● ● ●● ● ● ●
● ● ●
● ● ●
●
●
●●
●
● ●
●
●
● ●● ●
● ● ●●●
●●
Table 2: Correlations table: Spearman’s rank cor-
relations between mean regularization in the ex-
periment and the predictions of the two models
●
●●
● ● ● ●
● ● ●
●
●
● ●
●
●
●
● ● ●
●● ●● ●
● ●
●
● ● ●
● ● ● ●
● ●
●
●
●
● ●
●●
●
●
●
●
●
●●
●
●
● ●
● ●
●●
●
●
● ●●
●
●
●● ● ●
●
●
● ●
●
●
● ● ●
●
●●●●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
● ● ●
● ●
●
●
●
</figure>
<bodyText confidence="0.991364571428571">
(rho = 0.347, p &lt; 0.001), but the correlation is
far from perfect. Comparing the overall correla-
tions and patterns in Figure 2, it appears that the
GCM is doing a better job of predicting the varia-
tion across items than the MGL is. We now turn to
an examination of the predictions within our verb
classes.
</bodyText>
<figure confidence="0.94774109375">
−3 −2 −1 0 1
predicted regularity
●
Ratings vs. MGL●
● ● ● ● ●
● ●
● ● ● ● ●
● ● ●
● ● ● ●
● ●
●
●
●
●
●
●
● ● ●
●
● ●
average regularity in experiment
0.4 0.5 0.6 0.7 0.8 0.9
●●
●
●●
●
●
● ● ● ● ●
● ● ● ● ●
● ●
● ● ● ● ●
● ● ● ●
3.2 Model comparisons within verb class
</figure>
<bodyText confidence="0.9964504">
Table 2 shows Spearman rank correlations be-
tween mean regularization in the experiment and
the predictions of the two models for the five verb
categories. Overall, GCM does abetter job. The
no-change (cut) verb class is especially illustra-
tive of the differences between the two models.
Note that the MGL is negatively correlated with
our experimental data for this category. As noted
above, this verb class appears to be strikingly non-
productive; participants display a strong prefer-
ence for regularizing a wide range of t-final forms.
The MGL underestimates the regularization of
nonce verbs that resemble cut and hit, while over-
estimating the regularization of forms like vurt,
slurt, plurt. The no-change irregular form of such
verbs must be modeled on a pattern with a sole En-
glish exemplar (hurt–hurt), and the Minimal Gen-
eralization model (in contrast with the GCM) is
swayed very little in such cases. This is one of sev-
eral cases where the GCM predicts subject pref-
erences better than the MGL does, seemingly be-
cause the irregular form requires modeling a re-
sponse on a sole exemplar.
There is one verb category where the MGL out-
performs the GCM: the drove class. Here, the
MGL does especially well because it makes an ac-
curate prediction about one subcategory of items:
nonce verbs like quine and sline are regularized by
participants (quined,slined) more often than other
members of the drove class. Here, it seems that
</bodyText>
<figure confidence="0.99944798139535">
●
●
● ● ● ●
● ● ● ●
●
● ● ●
● ● ●
●
●
●
●
●
●
●
●●
●
●●●●●
●
●
● ●
●
●
● ●
●
●●
●
● ● ● ● ● ●
● ● ● ● ●
●
●
● ● ●
● ● ● ●
●
●
●
●
●
●
●
●
●
●
●
●
●●
● ● ● ●
● ● ● ● ● ● ● ● ● ● ●
● ●
● ● ●
●
●
●
● ● ● ●
●
●●
●●●
●
●
●
●●●
●
●
●
● ● ● ● ● ● ● ●
●
●
●●
●
●
●
●
−3 −2 −1 0 1
predicted regularity
●
●
●
●
●
● ●
●
●
●
●
●
● GCM vs. MGL●
● ●
●
●●
●
●
●
●
●
●
●
●
●
● ●
● ● ●
●
●
● ●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
● ●
● ●
●
●●
●
●
●
●
●
●
●●
●
●●
●
● ●
●
●
●
●
●
●
GCM
−3 −2 −1 0 1
●
●
●
●
●
●
● ●
●
●
●
● ● ●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
−3 −2 −1 0 1
MGL
</figure>
<figureCaption confidence="0.9849158">
Figure 2: Above: experimental ratings versus
GCM predictions. Middle: experimental ratings
versus MGL predictions. Below: MGL predic-
tions vs. GCM predictions. (With lowess lines
added.)
</figureCaption>
<page confidence="0.99244">
60
</page>
<bodyText confidence="0.999701829268293">
the irregular past would need to be modeled on
one closely-related English item (shine–shone),
but similar English verbs offer many exceptions
to any abstract generalization (line–lined, mine–
mined, whine–whined, not to mention the transi-
tive verb shine–shined). Such a situation causes
the MGL to correctly classify all -ine final verbs as
highly prone to regularization, because -ine/-one
type irregulars are all dispreferred in the experi-
ment. However, the GCM makes a wide range of
predictions for these stimuli on the basis of differ-
ent segmental similarities with training items (e.g.,
based on the syllable onsets).
On the whole, comparing the two models on the
verb classes suggests that analogy to individual in-
stances is a better approximation of the behavior
of our subjects than recourse to abstract general-
izations. It is true, however, that both the GCM
and the MGL each only explain a part of the ob-
served variance. In order to test whether the two
models contribute differently to explaining partic-
ipant behavior in our dataset, we fitted a simple
stepwise logistic mixed-effects regression model
on the results with maximal random effects struc-
ture, using regularization on the individual verb
form (yes or no) as an outcome variable. Instead
of verb category, we used the GCM and the MGL
regularization rates as predictors. Both predictors
are significant. An analysis of variance test reveals
that the regression model that includes the predic-
tions of both categorization models provides a sig-
nificantly better fit than the models including ei-
ther alone. We tested nonlinear effects of MGL
and GCM, using restricted cubic splines, but non-
linearity did not significantly improve the model.
Participant age and gender are not significant. Vo-
cabulary size explains some variation, though does
not quite meet the threshold of .05 for significance.
The interaction of GCM predictions and partici-
pant gender, however, is significant. The model
coefficients can be seen in Table 3.
</bodyText>
<subsectionHeader confidence="0.94107">
3.3 Individual-level factors
</subsectionHeader>
<bodyText confidence="0.999484">
As both MGL and GCM make reference to exist-
ing patterns in the lexicon, we hypothesized that
the precise size and contents of an individual’s vo-
cabulary is likely to produce individual variation
in terms of the lexical support available for cer-
tain patterns. Individuals with higher vocabulary
scores may be more likely to have robust stored
instances of irregular, lower frequency, minority
</bodyText>
<table confidence="0.999053142857143">
Predictor b z sig.
(Intercept) 0.71 4.5 ***
MGL 12.4 3.38 ***
GCM 1.11 5.05 ***
gender (male) -0.02 -0.07 (n.s.)
vocabulary -0.25 -1.77 .
GCM: gender (male) 0.47 2.12 *
</table>
<tableCaption confidence="0.9063005">
Table 3: Effects of rules vs. analogy in the regres-
sion model
</tableCaption>
<bodyText confidence="0.9997834">
past tense patterns. We might therefore predict
that they are more accepting of irregular realiza-
tions. This is, to some degree, confirmed by the
strength of vocabulary as a predictor of regulariza-
tion in our final model. A potential interaction of
vocabulary size and the two models of past tense
formation is that these models likely have differ-
ent predictions when trained on vocabulary sets of
various sizes – this is a clear direction of future
research.
We also tested the effects of participant gender,
as women have been reported to be more biased
towards more standard language (Labov, 2001).
This would mean that conformity to speech com-
munity standards in whether a form is irregular
or regular (essentially, getting it ‘right’) could be
highly valued by women. Consistent with this
observation, we find a significant interaction be-
tween GCM and participant gender. Females show
a steeper slope for the GCM than the males do.
When there is low analogical support for regular-
ization, females have a tendency to prefer irregular
forms more than males do, but this difference is re-
versed for items where the GCM provides strong
support for the regular. In that case, females prefer
regular forms more than males do. To put it differ-
ently, females categorize the verb forms more in
our dataset than the males do.
It is interesting to note that our results differ
from Hartshorne and Ullman’s (2006) child data
on real English verbs. They found more over-
regularization for girls than for boys. The mecha-
nism they suggest relies on girls having more pre-
cocious verbal ability, as is commonly reported.
These results may seem hard to reconcile, since
the adult women in our study did not regularize
more than men (there was no significant overall
effect of gender), nor did they have larger vocab-
ularies, as measured by our vocabulary inventory.
However, they are compatible if we assume that
</bodyText>
<page confidence="0.997137">
61
</page>
<bodyText confidence="0.999949428571429">
the real verbal lexicon is rather well learned by
adulthood (as reflected in the weakness of vocab-
ulary level as a statistical predictor in our model)
and that the gender difference we observed taps
the social factors mentioned by Labov, which are
learned gradually during childhood and adoles-
cence.
</bodyText>
<sectionHeader confidence="0.999747" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999975615384615">
Our results suggest that both the GCM and MGL
models contribute important insights into factors
underpinning perceived wellformedness. Individ-
uals are heavily influenced by the combined ana-
logical force of existing lexical forms. They gen-
eralize over items. However, they also, it appears,
generalize over these generalizations - forming
more abstract ‘rules’ or associations that operate in
parallel with the token-based analogical processes.
While this seems to be the interpretation that is
pointed to by this current data set, verification of
the joint role of these types of processes clearly
requires a lot more explicit testing in different and
varied data sets, including real verbs in addition to
nonce forms. Recent models in phonological pro-
cessing and speech perception certainly point to a
hybrid model, in which instance-based processing
and reasoning sits alongside more abstract struc-
tures, and in which both types of processes may
be jointly operative – with the balance affected by
many factors including the particular nature of the
task at hand (Pierrehumbert, 2006). Indeed, we
would predict that it should be possible to design
morphological tasks which more readily tap into
purely analogical processes, or into more abstract
generalizations.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9906747">
This project was made possible through a grant
from the John Templeton Foundation. The opin-
ions expressed in this publication are those of the
authors and do not necessarily reflect the views of
the John Templeton Foundation. Hay and Beckner
were also supported by a Rutherford Discovery
Fellowship awarded to Hay. The authors would
like to thank Adam Albright, Patrick LaShell,
Chun Liang Chan, and Lisa Garnard Dawdy-
Hesterberg. All faults remain ours.
</bodyText>
<sectionHeader confidence="0.989538" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998663057692308">
Adam Albright and Bruce Hayes. 2002. Modeling En-
glish past tense intuitions with minimal generaliza-
tion. In Proceedings of the ACL-02 workshop on
Morphological and phonological learning-Volume
6, pages 58–69. Association for Computational Lin-
guistics.
Adam Albright and Bruce Hayes. 2003. Rules
vs. analogy in English past tenses: A computa-
tional/experimental study. Cognition, 90(2):119–
161.
R Harald Baayen, Richard Piepenbrock, and Rijn van
H. 1993. The CELEX lexical data base on CD-
ROM.
Jean Berko. 1958. The child’s learning of English mor-
phology. Word, 14:150–177.
Joan L Bybee and Carol Lynn Moder. 1983. Mor-
phological classes as natural categories. Language,
pages 251–270.
Joan L Bybee and Dan I Slobin. 1982a. Rules and
schemas in the development and use of the English
past tense. Language, pages 265–289.
Joan L Bybee and Dan I Slobin. 1982b. Why small
children cannot change language on their own: Sug-
gestions from the English past tense. In Papers from
the 5th international conference on historical lin-
guistics, volume 21.
Lisa Garnand Dawdy-Hesterberg and Janet B Pierre-
humbert. 2014. Learnability and generalisation of
Arabic broken plural nouns. Language, Cognition
and Neuroscience, (ahead-of-print):1–15.
Stefan A Frisch and Maria R Brea-Spahn. 2010.
Metalinguistic judgments of phonotactics by mono-
linguals and bilinguals. Laboratory Phonology,
1(2):345–360.
Stefan Frisch, Michael Broe, and Janet Pierrehumbert.
2004. Similarity avoidance and the OCP. Natural
Language and Linguistic Theory, 22:179–228.
Lyn R Haber. 1976. Leaped and leapt: a theoretical
account of linguistic variation. Foundations of Lan-
guage, pages 211–238.
Joshua K Hartshorne and Michael T Ullman. 2006.
Why girls say holded more than boys. Developmen-
tal Science, 9(1):21–32.
William Labov. 2001. Principles of linguistic change
Volume 2: Social factors. Blackwell.
James L McClelland and Karalyn Patterson. 2002.
Rules or connections in past-tense inflections: What
does the evidence rule out? Trends in cognitive sci-
ences, 6(11):465–472.
Carol Lynn Moder. 1992. Productivity and categoriza-
tion in morphological classes. Ph.D. thesis, State
University of New York at Buffalo.
</reference>
<page confidence="0.981895">
62
</page>
<reference confidence="0.9985414">
Robert Munro, Steven Bethard, Victor Kuperman,
Vicky Tzuyin Lai, Robin Melnick, Christopher
Potts, Tyler Schnoebelen, and Harry Tily. 2010.
Crowdsourcing and language studies: the new gen-
eration of linguistic data. In Proceedings of the
NAACL HLT 2010 Workshop on Creating Speech
and Language Data with Amazon’s Mechanical
Turk, pages 122–130. Association for Computa-
tional Linguistics.
Ramin C. Nakisa, Kim Plunkett, and Ulrike Hahn.
2001. A cross-linguistic comparison of single and
dual-route models of inflectional morphology. Peter
Broeder, &amp; Jaap Murre, Models of Language Acqui-
sition: Inductive and Deductive Approaches, pages
201–222.
Robert M Nosofsky. 1990. Relations between
exemplar-similarity and likelihood models of clas-
sification. Journal of Mathematical Psychology,
34(4):393–418.
Janet B Pierrehumbert. 2006. The next toolkit. Jour-
nal of Phonetics, 34(4):516–530.
David E Rumelhart and James L McClelland. 1985.
On learning the past tenses of English verbs. Insti-
tute for Cognitive Science, University of California,
San Diego.
</reference>
<page confidence="0.99946">
63
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.141294">
<title confidence="0.8983445">Rules, Analogy, and Social Factors codetermine past-tense patterns in English</title>
<author confidence="0.994495">P´eter Ricz</author>
<affiliation confidence="0.882967">New Zealand Institute Language Brain and University of Canterbury</affiliation>
<email confidence="0.92522">peter.racz@</email>
<author confidence="0.998869">Clay Beckner</author>
<affiliation confidence="0.879405333333333">New Zealand Institute Language Brain and University of Canterbury</affiliation>
<email confidence="0.924749">canterbury.ac.nz</email>
<author confidence="0.999694">Jennifer B Hay</author>
<affiliation confidence="0.874391666666667">New Zealand Institute Language Brain and University of Canterbury</affiliation>
<email confidence="0.941741">jen.hay@</email>
<author confidence="0.998501">Janet B Pierrehumbert</author>
<affiliation confidence="0.985485">Department of Linguistics /</affiliation>
<title confidence="0.67542">Northwestern New Zealand Institute</title>
<author confidence="0.748368">Language Brain</author>
<affiliation confidence="0.999748">University of Canterbury</affiliation>
<email confidence="0.999819">jbp@northwestern.edu</email>
<abstract confidence="0.9985579">We investigate past-tense formation preferences for five irregular English verb classes. We gathered data on a large scale using a nonce probe study implemented on Amazon Mechanical Turk. We compare a Minimal Generalization Learner (which infers stochastic rules) with a Generalized Context Model (which evaluates new items via analogy with existing items) as models of participant choices. Overall, the GCM is a better predictor, but the the MGL provides some additional predictive power. Because variation across speakers is greater than variation across items, we also explore individual-level factors as predictors. Females exhibited significantly more categorical choices than males, a finding that can be related to results in sociolinguistics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>glish past tense intuitions with minimal generalization.</title>
<booktitle>In Proceedings of the ACL-02 workshop on Morphological and phonological learning-Volume 6,</booktitle>
<pages>58--69</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker></marker>
<rawString>glish past tense intuitions with minimal generalization. In Proceedings of the ACL-02 workshop on Morphological and phonological learning-Volume 6, pages 58–69. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Albright</author>
<author>Bruce Hayes</author>
</authors>
<title>Rules vs. analogy in English past tenses: A computational/experimental study.</title>
<date>2003</date>
<journal>Cognition,</journal>
<volume>90</volume>
<issue>2</issue>
<pages>161</pages>
<contexts>
<context position="1944" citStr="Albright and Hayes, 2003" startWordPosition="272" endWordPosition="275">can be related to results in sociolinguistics. 1 Introduction In this report, we present a psycholinguistic study of English past tense categories, using a nonceprobe experiment implemented on Amazon Mechanical Turk. The English past tense has been a testing-ground for a wide range of theories and predictions in psycholinguistics, including the processes of acquisition, the nature of lexical representation, and the representation of inflectional patterns as rules or as generalizations over specific items (Bybee and Slobin, 1982a; Rumelhart and McClelland, 1985; McClelland and Patterson, 2002; Albright and Hayes, 2003). The present study investigates the factors influencing patterns of preferred past tense forms for particular verb classes. English past tenses are not merely a memorized list, but rather, verb categories can shrink, or expand to include new items. In everyday speech, there is evidence of ongoing influences from multiple verb classes, as verbs exhibit variation and slowly shift in their usage (dived vs. dove, sneaked vs. snuck), (Haber, 1976; Bybee and Moder, 1983). Given that speakers can adapt their verbal categories to new situations, what is the best representation for the relevant morpho</context>
<context position="3298" citStr="Albright and Hayes, 2003" startWordPosition="489" endWordPosition="492">past tense formation pattern for a particular candidate item is determined by patterns of similarity to stored items. Morphological innovation and productivity arises from generalizations over existing forms in the lexicon. To account for a speech error such as glew as the past tense of glow (Bybee and Slobin, 1982a), an analogical explanation would highlight the close similarity between glow and the present tense forms blow, throw, know, which provide the basis for an analogy with the past forms blew, threw, knew. Of particular interest is the Generalized Context Model (GCM) (Nosofsky, 1990; Albright and Hayes, 2003), an analogical model which assesses a category’s suitability to a target item on the basis of featurebased similarities summed over category items, in addition to the category’s size. It has already been successfully applied to model regular and irregular patterns in Arabic morphology (DawdyHesterberg and Pierrehumbert, 2014). Rule-based approaches propose more abstract representations of generalizations. Originally proposed to handle broadly applicable default patterns, (such as ‘add -ed to express the past tense’), rule-based approaches have recently been extended to incorporate multiple st</context>
<context position="5279" citStr="Albright and Hayes, 2003" startWordPosition="800" endWordPosition="803">neralizations which compete with one another, and which are more or less likely to apply in various phonological contexts (for regular as well as irregular verbs). Albright and Hayes argue that the MGL outperforms the GCM in predicting participant behavior in a nonce-verb production task they conducted. 2 Experiment We collected a large amount of data on irregular past tense formation in English with a nonce probe test, a classic method for exploring the productivity of inflectional morphology (Berko, 1958). Earlier studies used 30 or fewer participants per condition (Bybee and Slobin, 1982a; Albright and Hayes, 2003). By using Amazon Mechanical Turk, a burgeoning forum for psycholinguistic research (Munro et al., 2010), we were able to recruit a large number of participants and explore the role of individual-level factors in the choice of morphological patterns. Moreover, we tested participant preferences across a large dataset (316 nonce verbs) based on broad phonological sampling within verb classes, allowing for repeated trials across similar items for each participant. Participants in our online study were presented with a forced choice task in which they had to pick either the regular or the irregula</context>
<context position="14372" citStr="Albright and Hayes, 2003" startWordPosition="2308" endWordPosition="2311">urnt cut drove kept sang category burnt cut drove kept sang category Figure 1: Across-item variation in regularization rates across category (above). Across-subject variation in regularization rates across category (below). 3 Algorithmic Learning Models We now turn our attention from the baseline effects of category variables, to investigate the predictions of particular algorithmic learning models that provide alternate representations for generalizations on the basis of similarity. Our analyses focus on the predictions of the Minimal Generalization Learner and the Generalized Context Model (Albright and Hayes, 2003; Nosofsky, 1990). 3.1 The two models The Minimal Generalization Learner (MGL) (Albright and Hayes, 2002; Albright and Hayes, 2003) is an algorithm for inferring stochastic morphophonological generalizations over a set of training items (e.g., paired present and past tense forms). For each pair of items in the lexicon, the learner maximally aligns wordforms and analyzes shared phonetic features, thereby merging wordspecific rules (ring/rang and stink/stank) into rules that express the most general applicable environment: [I] → [w] / [+coronal, + cont] [N]. Each rule inferred in this way is the</context>
<context position="16565" citStr="Albright and Hayes (2003)" startWordPosition="2655" endWordPosition="2659">ies; thus, monosyllabic verbs are most likely to form strong generalizations with other monosyllabic verbs. Attempts to merge diverse wordforms under a single generalization would be more likely to incur penalties (i.e., exceptions). This feature of the MGL is important for comparing with the methods of the GCM (see below). Both algorithms allow for categorymean rate of regularization 0.4 0.6 0.8 ● items mean rate of regularization 0.0 0.2 0.4 0.6 0.8 1.0 ● subjects 58 specific similarities to play a role. The Minimal Generalization Learner is implemented here from materials made available by Albright and Hayes (2003), including their Segmental Similarity Calculator based on Frisch et al. (2004). The MGL is trained on regular and irregular English verbs with a minimum frequency cutoff of 10 in COBUILD (Baayen et al., 1993), and excluding prefixed verb forms, thus encompassing 4253 past/present verb transcriptions. The MGL is implemented here with its default settings, which includes a lower 75% confidence interval for purposes of adjusting the reliability score. The Generalized Context Model (GCM) is an instance-based model of categorization. To assign category membership to a novel instance, it first calc</context>
<context position="20340" citStr="Albright and Hayes, 2003" startWordPosition="3293" endWordPosition="3296">generated with no frequency cutoff. Alternate runs with the frequency threshold enforced produce no change in the model. The model is run with the default parameter settings of s = 0.3, p = 1 with respect to calculating the weighted similarities between items. When p is set to 1, as here, the similarity function is exponential, rather than Gaussian. The weighting parameters controls the tradeoff in the relative importance of the size of the verb category (the ’gang size’) vs. the amount of similarity (measured via edit distance between phonological forms) (Nosofsky, 1990; Nakisa et al., 2001; Albright and Hayes, 2003; Dawdy-Hesterberg and Pierrehumbert, 2014). Figure 2 shows three plots. The first one depicts the relationship between the predictions of the GCM (regular category weight) and experimental ratings (mean participant regularization) for individual verb types used in the experiment. The Spearman rank correlation is highly significant (rho = 0.497, p &lt; 0.001). The second one depicts the relationship between the MGL model predictions (reliability rating of the regular form) and mean participant regularization in the experiment. The Spearman rank correlation between these variables is highly signif</context>
</contexts>
<marker>Albright, Hayes, 2003</marker>
<rawString>Adam Albright and Bruce Hayes. 2003. Rules vs. analogy in English past tenses: A computational/experimental study. Cognition, 90(2):119– 161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Harald Baayen</author>
<author>Richard Piepenbrock</author>
<author>Rijn van H</author>
</authors>
<title>The CELEX lexical data base on CDROM.</title>
<date>1993</date>
<marker>Baayen, Piepenbrock, van H, 1993</marker>
<rawString>R Harald Baayen, Richard Piepenbrock, and Rijn van H. 1993. The CELEX lexical data base on CDROM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Berko</author>
</authors>
<title>The child’s learning of English morphology.</title>
<date>1958</date>
<pages>14--150</pages>
<publisher>Word,</publisher>
<contexts>
<context position="5166" citStr="Berko, 1958" startWordPosition="785" endWordPosition="786">e rule fails to apply. The resulting system consists of a catalog of weighted natural class-based generalizations which compete with one another, and which are more or less likely to apply in various phonological contexts (for regular as well as irregular verbs). Albright and Hayes argue that the MGL outperforms the GCM in predicting participant behavior in a nonce-verb production task they conducted. 2 Experiment We collected a large amount of data on irregular past tense formation in English with a nonce probe test, a classic method for exploring the productivity of inflectional morphology (Berko, 1958). Earlier studies used 30 or fewer participants per condition (Bybee and Slobin, 1982a; Albright and Hayes, 2003). By using Amazon Mechanical Turk, a burgeoning forum for psycholinguistic research (Munro et al., 2010), we were able to recruit a large number of participants and explore the role of individual-level factors in the choice of morphological patterns. Moreover, we tested participant preferences across a large dataset (316 nonce verbs) based on broad phonological sampling within verb classes, allowing for repeated trials across similar items for each participant. Participants in our o</context>
</contexts>
<marker>Berko, 1958</marker>
<rawString>Jean Berko. 1958. The child’s learning of English morphology. Word, 14:150–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan L Bybee</author>
<author>Carol Lynn Moder</author>
</authors>
<title>Morphological classes as natural categories. Language,</title>
<date>1983</date>
<pages>251--270</pages>
<contexts>
<context position="2414" citStr="Bybee and Moder, 1983" startWordPosition="347" endWordPosition="350"> generalizations over specific items (Bybee and Slobin, 1982a; Rumelhart and McClelland, 1985; McClelland and Patterson, 2002; Albright and Hayes, 2003). The present study investigates the factors influencing patterns of preferred past tense forms for particular verb classes. English past tenses are not merely a memorized list, but rather, verb categories can shrink, or expand to include new items. In everyday speech, there is evidence of ongoing influences from multiple verb classes, as verbs exhibit variation and slowly shift in their usage (dived vs. dove, sneaked vs. snuck), (Haber, 1976; Bybee and Moder, 1983). Given that speakers can adapt their verbal categories to new situations, what is the best representation for the relevant morphological generalizations? In analogical models, the focus is on existing stored items in memory. The acceptability of a candidate past tense formation pattern for a particular candidate item is determined by patterns of similarity to stored items. Morphological innovation and productivity arises from generalizations over existing forms in the lexicon. To account for a speech error such as glew as the past tense of glow (Bybee and Slobin, 1982a), an analogical explana</context>
<context position="18288" citStr="Bybee and Moder, 1983" startWordPosition="2936" endWordPosition="2939"> Generalization Learner to calculate the similarity of phonetically transcribed word forms to each other, so that we could take the phonetic similarity of speech sounds into account instead of calculating similarity between word forms based on edit distance alone. We did not weight parts of the word forms differently, because there is evidence that although past tense formation in English is predominantly driven by similarities in word endings, onsets also play a role. (cf. the predominance of s+stop onsets in irregular verbs forming the past tense with a vowel change, e.g. sing, sink, etc.) (Bybee and Moder, 1983). Third, our implementation of the GCM reflected the structure of the task. Recall from Section 2 that participants were presented with the stems of the nonce verbs in a sequence and had to pick either a regular or an irregular past tense form for them. The irregular past tense form was predetermined by category, so that, for a given verb, the participants could only choose between the regular past tense form or the irregular past tense form we assigned to the verb. (So, for instance, for spling, they could choose either splinged or splang, but not splung or splingt, etc.) For a given category</context>
</contexts>
<marker>Bybee, Moder, 1983</marker>
<rawString>Joan L Bybee and Carol Lynn Moder. 1983. Morphological classes as natural categories. Language, pages 251–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan L Bybee</author>
<author>Dan I Slobin</author>
</authors>
<title>Rules and schemas in the development and use of the English past tense. Language,</title>
<date>1982</date>
<pages>265--289</pages>
<contexts>
<context position="1852" citStr="Bybee and Slobin, 1982" startWordPosition="260" endWordPosition="263">ors. Females exhibited significantly more categorical choices than males, a finding that can be related to results in sociolinguistics. 1 Introduction In this report, we present a psycholinguistic study of English past tense categories, using a nonceprobe experiment implemented on Amazon Mechanical Turk. The English past tense has been a testing-ground for a wide range of theories and predictions in psycholinguistics, including the processes of acquisition, the nature of lexical representation, and the representation of inflectional patterns as rules or as generalizations over specific items (Bybee and Slobin, 1982a; Rumelhart and McClelland, 1985; McClelland and Patterson, 2002; Albright and Hayes, 2003). The present study investigates the factors influencing patterns of preferred past tense forms for particular verb classes. English past tenses are not merely a memorized list, but rather, verb categories can shrink, or expand to include new items. In everyday speech, there is evidence of ongoing influences from multiple verb classes, as verbs exhibit variation and slowly shift in their usage (dived vs. dove, sneaked vs. snuck), (Haber, 1976; Bybee and Moder, 1983). Given that speakers can adapt their </context>
<context position="5251" citStr="Bybee and Slobin, 1982" startWordPosition="796" endWordPosition="799">ed natural class-based generalizations which compete with one another, and which are more or less likely to apply in various phonological contexts (for regular as well as irregular verbs). Albright and Hayes argue that the MGL outperforms the GCM in predicting participant behavior in a nonce-verb production task they conducted. 2 Experiment We collected a large amount of data on irregular past tense formation in English with a nonce probe test, a classic method for exploring the productivity of inflectional morphology (Berko, 1958). Earlier studies used 30 or fewer participants per condition (Bybee and Slobin, 1982a; Albright and Hayes, 2003). By using Amazon Mechanical Turk, a burgeoning forum for psycholinguistic research (Munro et al., 2010), we were able to recruit a large number of participants and explore the role of individual-level factors in the choice of morphological patterns. Moreover, we tested participant preferences across a large dataset (316 nonce verbs) based on broad phonological sampling within verb classes, allowing for repeated trials across similar items for each participant. Participants in our online study were presented with a forced choice task in which they had to pick either</context>
<context position="6843" citStr="Bybee and Slobin, 1982" startWordPosition="1041" endWordPosition="1044"> tense past forms. Each category exhibits phonological variability within the category, while also allowing for a specific phonological description. We avoided ‘miscellaneous’ verb classes, as well as wholly idiosyncratic patterns (such as go– went). Moreover, we are particularly interested in morphological classes which are known to display some indeterminacy (Haber, 1976), i.e., those classes which display some regular/irregular variation (dived vs. dove), due to the ready availability of multiple generalizations. The literature contains various taxonomies of English irregular verb classes (Bybee and Slobin, 1982a), but our current classification mostly represents a subset of the detailed verb classes outlined by Moder (1992). The five categories of interest are as follows. • SANG. Verbs that form the past tense with a vowel change from [I] to [w] (e.g. sing–sang, sink–sank, swim–swam). • BURNT. Verbs that form the past tense by adding a [t], with no change in the stem vowel (e.g. burn–burnt, spill–spilt, learn–learnt). These items constitute a distinct set from regular English pasts such as boss–bossed which are articulated with a [t] allomorph, insofar as the burnt verb bases actually end in a voice</context>
<context position="8072" citStr="Bybee and Slobin, 1982" startWordPosition="1252" endWordPosition="1255">nant but are nonetheless affixed with a voiceless stop. • KEPT. Verbs that form the past tense by adding a final [t] and changing the stem vowel from [i] to [e] (e.g. keep–kept, mean– meant, feel–felt ). • DROVE. Verbs that form the past tense with a vowel change from [aI] or [i] to [oU] (e.g. drive–drove, weave–wove, ride–rode). • CUT. No-change past tense verbs, that is, verbs the past tense form of which is identical to their present tense form. (e.g. cut–cut, cost–cost, hurt–hurt). Verb bases in this class end in sounds that are already associated with the English past tense ([t] or [d]) (Bybee and Slobin, 1982a), although the nonce verb bases in the present study all end in [t]. We generated nonce verb forms by combining the category-specific restrictions spelled out above on the stem with a set of syllable onsets that occur in English. Using CELEX (Baayen et al., 1993), we then filtered the orthographic and phonetic transcriptions of the nonce stems, as well as the resulting past tense forms, to exclude real English words. Two native speakers checked the final list to remove additional real words that were not filtered out via the CELEX database (e.g., slang and informal terms). All our verb forms</context>
</contexts>
<marker>Bybee, Slobin, 1982</marker>
<rawString>Joan L Bybee and Dan I Slobin. 1982a. Rules and schemas in the development and use of the English past tense. Language, pages 265–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan L Bybee</author>
<author>Dan I Slobin</author>
</authors>
<title>Why small children cannot change language on their own: Suggestions from the English past tense.</title>
<date>1982</date>
<booktitle>In Papers from the 5th international conference on historical linguistics,</booktitle>
<volume>21</volume>
<contexts>
<context position="1852" citStr="Bybee and Slobin, 1982" startWordPosition="260" endWordPosition="263">ors. Females exhibited significantly more categorical choices than males, a finding that can be related to results in sociolinguistics. 1 Introduction In this report, we present a psycholinguistic study of English past tense categories, using a nonceprobe experiment implemented on Amazon Mechanical Turk. The English past tense has been a testing-ground for a wide range of theories and predictions in psycholinguistics, including the processes of acquisition, the nature of lexical representation, and the representation of inflectional patterns as rules or as generalizations over specific items (Bybee and Slobin, 1982a; Rumelhart and McClelland, 1985; McClelland and Patterson, 2002; Albright and Hayes, 2003). The present study investigates the factors influencing patterns of preferred past tense forms for particular verb classes. English past tenses are not merely a memorized list, but rather, verb categories can shrink, or expand to include new items. In everyday speech, there is evidence of ongoing influences from multiple verb classes, as verbs exhibit variation and slowly shift in their usage (dived vs. dove, sneaked vs. snuck), (Haber, 1976; Bybee and Moder, 1983). Given that speakers can adapt their </context>
<context position="5251" citStr="Bybee and Slobin, 1982" startWordPosition="796" endWordPosition="799">ed natural class-based generalizations which compete with one another, and which are more or less likely to apply in various phonological contexts (for regular as well as irregular verbs). Albright and Hayes argue that the MGL outperforms the GCM in predicting participant behavior in a nonce-verb production task they conducted. 2 Experiment We collected a large amount of data on irregular past tense formation in English with a nonce probe test, a classic method for exploring the productivity of inflectional morphology (Berko, 1958). Earlier studies used 30 or fewer participants per condition (Bybee and Slobin, 1982a; Albright and Hayes, 2003). By using Amazon Mechanical Turk, a burgeoning forum for psycholinguistic research (Munro et al., 2010), we were able to recruit a large number of participants and explore the role of individual-level factors in the choice of morphological patterns. Moreover, we tested participant preferences across a large dataset (316 nonce verbs) based on broad phonological sampling within verb classes, allowing for repeated trials across similar items for each participant. Participants in our online study were presented with a forced choice task in which they had to pick either</context>
<context position="6843" citStr="Bybee and Slobin, 1982" startWordPosition="1041" endWordPosition="1044"> tense past forms. Each category exhibits phonological variability within the category, while also allowing for a specific phonological description. We avoided ‘miscellaneous’ verb classes, as well as wholly idiosyncratic patterns (such as go– went). Moreover, we are particularly interested in morphological classes which are known to display some indeterminacy (Haber, 1976), i.e., those classes which display some regular/irregular variation (dived vs. dove), due to the ready availability of multiple generalizations. The literature contains various taxonomies of English irregular verb classes (Bybee and Slobin, 1982a), but our current classification mostly represents a subset of the detailed verb classes outlined by Moder (1992). The five categories of interest are as follows. • SANG. Verbs that form the past tense with a vowel change from [I] to [w] (e.g. sing–sang, sink–sank, swim–swam). • BURNT. Verbs that form the past tense by adding a [t], with no change in the stem vowel (e.g. burn–burnt, spill–spilt, learn–learnt). These items constitute a distinct set from regular English pasts such as boss–bossed which are articulated with a [t] allomorph, insofar as the burnt verb bases actually end in a voice</context>
<context position="8072" citStr="Bybee and Slobin, 1982" startWordPosition="1252" endWordPosition="1255">nant but are nonetheless affixed with a voiceless stop. • KEPT. Verbs that form the past tense by adding a final [t] and changing the stem vowel from [i] to [e] (e.g. keep–kept, mean– meant, feel–felt ). • DROVE. Verbs that form the past tense with a vowel change from [aI] or [i] to [oU] (e.g. drive–drove, weave–wove, ride–rode). • CUT. No-change past tense verbs, that is, verbs the past tense form of which is identical to their present tense form. (e.g. cut–cut, cost–cost, hurt–hurt). Verb bases in this class end in sounds that are already associated with the English past tense ([t] or [d]) (Bybee and Slobin, 1982a), although the nonce verb bases in the present study all end in [t]. We generated nonce verb forms by combining the category-specific restrictions spelled out above on the stem with a set of syllable onsets that occur in English. Using CELEX (Baayen et al., 1993), we then filtered the orthographic and phonetic transcriptions of the nonce stems, as well as the resulting past tense forms, to exclude real English words. Two native speakers checked the final list to remove additional real words that were not filtered out via the CELEX database (e.g., slang and informal terms). All our verb forms</context>
</contexts>
<marker>Bybee, Slobin, 1982</marker>
<rawString>Joan L Bybee and Dan I Slobin. 1982b. Why small children cannot change language on their own: Suggestions from the English past tense. In Papers from the 5th international conference on historical linguistics, volume 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Garnand Dawdy-Hesterberg</author>
<author>Janet B Pierrehumbert</author>
</authors>
<title>Learnability and generalisation of Arabic broken plural nouns. Language, Cognition and Neuroscience,</title>
<date>2014</date>
<contexts>
<context position="20383" citStr="Dawdy-Hesterberg and Pierrehumbert, 2014" startWordPosition="3297" endWordPosition="3300">y cutoff. Alternate runs with the frequency threshold enforced produce no change in the model. The model is run with the default parameter settings of s = 0.3, p = 1 with respect to calculating the weighted similarities between items. When p is set to 1, as here, the similarity function is exponential, rather than Gaussian. The weighting parameters controls the tradeoff in the relative importance of the size of the verb category (the ’gang size’) vs. the amount of similarity (measured via edit distance between phonological forms) (Nosofsky, 1990; Nakisa et al., 2001; Albright and Hayes, 2003; Dawdy-Hesterberg and Pierrehumbert, 2014). Figure 2 shows three plots. The first one depicts the relationship between the predictions of the GCM (regular category weight) and experimental ratings (mean participant regularization) for individual verb types used in the experiment. The Spearman rank correlation is highly significant (rho = 0.497, p &lt; 0.001). The second one depicts the relationship between the MGL model predictions (reliability rating of the regular form) and mean participant regularization in the experiment. The Spearman rank correlation between these variables is highly significant (rho = 0.393, p &lt; 0.001). The predict</context>
</contexts>
<marker>Dawdy-Hesterberg, Pierrehumbert, 2014</marker>
<rawString>Lisa Garnand Dawdy-Hesterberg and Janet B Pierrehumbert. 2014. Learnability and generalisation of Arabic broken plural nouns. Language, Cognition and Neuroscience, (ahead-of-print):1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan A Frisch</author>
<author>Maria R Brea-Spahn</author>
</authors>
<title>Metalinguistic judgments of phonotactics by monolinguals and bilinguals.</title>
<date>2010</date>
<journal>Laboratory Phonology,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="10004" citStr="Frisch and Brea-Spahn (2010)" startWordPosition="1595" endWordPosition="1598">, visually, in a carrier sentence of the form ‘I really like to VERB. Yesterday, I .’. Two buttons were presented under the carrier sentence, one with the regular past tense, adding -ed, and one with the irregular past tense. The irregular past tense was always the dominant pattern for the category. (So, for cut, it was identical to the present tense, etc.) The order of the two buttons was randomized for each verb. Each verb was presented once and the order of verbs was randomized for each participant. The experiment was appended by a word familiarity rating task. The rating task was based on Frisch and Brea-Spahn (2010). It consisted of 50 nouns of varying familiarity, as well as 10 extremely common nouns and 10 nonce words. The 70 words were presented in a random order. The participant had to select, on a scale of 1-5, how familiar the given word was. Incorrect answers to the extremely common nouns and the nonce words were used as an exclusion criterion. Answers for the other items were used as an index of vocabulary level, which is predicted to affect morphological choices in both the GCM and MGL models. 2.3 Participants 111 people took part in the experiment on Amazon Mechanical Turk during the course of </context>
</contexts>
<marker>Frisch, Brea-Spahn, 2010</marker>
<rawString>Stefan A Frisch and Maria R Brea-Spahn. 2010. Metalinguistic judgments of phonotactics by monolinguals and bilinguals. Laboratory Phonology, 1(2):345–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Frisch</author>
<author>Michael Broe</author>
<author>Janet Pierrehumbert</author>
</authors>
<date>2004</date>
<booktitle>Similarity avoidance and the OCP. Natural Language and Linguistic Theory,</booktitle>
<pages>22--179</pages>
<contexts>
<context position="16644" citStr="Frisch et al. (2004)" startWordPosition="2668" endWordPosition="2671">her monosyllabic verbs. Attempts to merge diverse wordforms under a single generalization would be more likely to incur penalties (i.e., exceptions). This feature of the MGL is important for comparing with the methods of the GCM (see below). Both algorithms allow for categorymean rate of regularization 0.4 0.6 0.8 ● items mean rate of regularization 0.0 0.2 0.4 0.6 0.8 1.0 ● subjects 58 specific similarities to play a role. The Minimal Generalization Learner is implemented here from materials made available by Albright and Hayes (2003), including their Segmental Similarity Calculator based on Frisch et al. (2004). The MGL is trained on regular and irregular English verbs with a minimum frequency cutoff of 10 in COBUILD (Baayen et al., 1993), and excluding prefixed verb forms, thus encompassing 4253 past/present verb transcriptions. The MGL is implemented here with its default settings, which includes a lower 75% confidence interval for purposes of adjusting the reliability score. The Generalized Context Model (GCM) is an instance-based model of categorization. To assign category membership to a novel instance, it first calculates its similarity to instances in preexisting categories. Then, it selects </context>
</contexts>
<marker>Frisch, Broe, Pierrehumbert, 2004</marker>
<rawString>Stefan Frisch, Michael Broe, and Janet Pierrehumbert. 2004. Similarity avoidance and the OCP. Natural Language and Linguistic Theory, 22:179–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lyn R Haber</author>
</authors>
<title>Leaped and leapt: a theoretical account of linguistic variation. Foundations of Language,</title>
<date>1976</date>
<pages>211--238</pages>
<contexts>
<context position="2390" citStr="Haber, 1976" startWordPosition="345" endWordPosition="346">s rules or as generalizations over specific items (Bybee and Slobin, 1982a; Rumelhart and McClelland, 1985; McClelland and Patterson, 2002; Albright and Hayes, 2003). The present study investigates the factors influencing patterns of preferred past tense forms for particular verb classes. English past tenses are not merely a memorized list, but rather, verb categories can shrink, or expand to include new items. In everyday speech, there is evidence of ongoing influences from multiple verb classes, as verbs exhibit variation and slowly shift in their usage (dived vs. dove, sneaked vs. snuck), (Haber, 1976; Bybee and Moder, 1983). Given that speakers can adapt their verbal categories to new situations, what is the best representation for the relevant morphological generalizations? In analogical models, the focus is on existing stored items in memory. The acceptability of a candidate past tense formation pattern for a particular candidate item is determined by patterns of similarity to stored items. Morphological innovation and productivity arises from generalizations over existing forms in the lexicon. To account for a speech error such as glew as the past tense of glow (Bybee and Slobin, 1982a</context>
<context position="6597" citStr="Haber, 1976" startWordPosition="1007" endWordPosition="1008">ulary task in which participants had to rate the familiarity of English nouns. 2.1 Stimuli We set up five categories of irregular past tense formation based on phonological form of the present tense verb, and its corresponding candidate tense past forms. Each category exhibits phonological variability within the category, while also allowing for a specific phonological description. We avoided ‘miscellaneous’ verb classes, as well as wholly idiosyncratic patterns (such as go– went). Moreover, we are particularly interested in morphological classes which are known to display some indeterminacy (Haber, 1976), i.e., those classes which display some regular/irregular variation (dived vs. dove), due to the ready availability of multiple generalizations. The literature contains various taxonomies of English irregular verb classes (Bybee and Slobin, 1982a), but our current classification mostly represents a subset of the detailed verb classes outlined by Moder (1992). The five categories of interest are as follows. • SANG. Verbs that form the past tense with a vowel change from [I] to [w] (e.g. sing–sang, sink–sank, swim–swam). • BURNT. Verbs that form the past tense by adding a [t], with no change in</context>
</contexts>
<marker>Haber, 1976</marker>
<rawString>Lyn R Haber. 1976. Leaped and leapt: a theoretical account of linguistic variation. Foundations of Language, pages 211–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua K Hartshorne</author>
<author>Michael T Ullman</author>
</authors>
<title>Why girls say holded more than boys.</title>
<date>2006</date>
<journal>Developmental Science,</journal>
<volume>9</volume>
<issue>1</issue>
<marker>Hartshorne, Ullman, 2006</marker>
<rawString>Joshua K Hartshorne and Michael T Ullman. 2006. Why girls say holded more than boys. Developmental Science, 9(1):21–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Labov</author>
</authors>
<title>Principles of linguistic change Volume 2: Social factors.</title>
<date>2001</date>
<publisher>Blackwell.</publisher>
<contexts>
<context position="28196" citStr="Labov, 2001" startWordPosition="4964" endWordPosition="4965">ssion model past tense patterns. We might therefore predict that they are more accepting of irregular realizations. This is, to some degree, confirmed by the strength of vocabulary as a predictor of regularization in our final model. A potential interaction of vocabulary size and the two models of past tense formation is that these models likely have different predictions when trained on vocabulary sets of various sizes – this is a clear direction of future research. We also tested the effects of participant gender, as women have been reported to be more biased towards more standard language (Labov, 2001). This would mean that conformity to speech community standards in whether a form is irregular or regular (essentially, getting it ‘right’) could be highly valued by women. Consistent with this observation, we find a significant interaction between GCM and participant gender. Females show a steeper slope for the GCM than the males do. When there is low analogical support for regularization, females have a tendency to prefer irregular forms more than males do, but this difference is reversed for items where the GCM provides strong support for the regular. In that case, females prefer regular fo</context>
</contexts>
<marker>Labov, 2001</marker>
<rawString>William Labov. 2001. Principles of linguistic change Volume 2: Social factors. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James L McClelland</author>
<author>Karalyn Patterson</author>
</authors>
<title>Rules or connections in past-tense inflections: What does the evidence rule out? Trends in cognitive sciences,</title>
<date>2002</date>
<pages>6--11</pages>
<contexts>
<context position="1917" citStr="McClelland and Patterson, 2002" startWordPosition="268" endWordPosition="271">ices than males, a finding that can be related to results in sociolinguistics. 1 Introduction In this report, we present a psycholinguistic study of English past tense categories, using a nonceprobe experiment implemented on Amazon Mechanical Turk. The English past tense has been a testing-ground for a wide range of theories and predictions in psycholinguistics, including the processes of acquisition, the nature of lexical representation, and the representation of inflectional patterns as rules or as generalizations over specific items (Bybee and Slobin, 1982a; Rumelhart and McClelland, 1985; McClelland and Patterson, 2002; Albright and Hayes, 2003). The present study investigates the factors influencing patterns of preferred past tense forms for particular verb classes. English past tenses are not merely a memorized list, but rather, verb categories can shrink, or expand to include new items. In everyday speech, there is evidence of ongoing influences from multiple verb classes, as verbs exhibit variation and slowly shift in their usage (dived vs. dove, sneaked vs. snuck), (Haber, 1976; Bybee and Moder, 1983). Given that speakers can adapt their verbal categories to new situations, what is the best representat</context>
</contexts>
<marker>McClelland, Patterson, 2002</marker>
<rawString>James L McClelland and Karalyn Patterson. 2002. Rules or connections in past-tense inflections: What does the evidence rule out? Trends in cognitive sciences, 6(11):465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Lynn Moder</author>
</authors>
<title>Productivity and categorization in morphological classes.</title>
<date>1992</date>
<tech>Ph.D. thesis,</tech>
<institution>State University of New York at Buffalo.</institution>
<contexts>
<context position="6958" citStr="Moder (1992)" startWordPosition="1061" endWordPosition="1062">onological description. We avoided ‘miscellaneous’ verb classes, as well as wholly idiosyncratic patterns (such as go– went). Moreover, we are particularly interested in morphological classes which are known to display some indeterminacy (Haber, 1976), i.e., those classes which display some regular/irregular variation (dived vs. dove), due to the ready availability of multiple generalizations. The literature contains various taxonomies of English irregular verb classes (Bybee and Slobin, 1982a), but our current classification mostly represents a subset of the detailed verb classes outlined by Moder (1992). The five categories of interest are as follows. • SANG. Verbs that form the past tense with a vowel change from [I] to [w] (e.g. sing–sang, sink–sank, swim–swam). • BURNT. Verbs that form the past tense by adding a [t], with no change in the stem vowel (e.g. burn–burnt, spill–spilt, learn–learnt). These items constitute a distinct set from regular English pasts such as boss–bossed which are articulated with a [t] allomorph, insofar as the burnt verb bases actually end in a voiced consonant but are nonetheless affixed with a voiceless stop. • KEPT. Verbs that form the past tense by adding a f</context>
<context position="12487" citStr="Moder (1992)" startWordPosition="2014" endWordPosition="2015">Yet based on nonce responses, the English no-change pattern is not very prone to being applied to novel items. This finding matches observations by Bybee (1982b) that the no-change verb class has been on the decline in English, as evident from increasing regularization. One noteworthy feature of the cut-type verbs is that the phonological shape of the base is a quite unreliable indicator of verb class. That is to say, there are many [t]- final verb stems which typically take the regular -ed suffix (e.g., gritted, salted, blasted, and these provide counterexamples to the no-change pattern (cf. Moder (1992) on cue validity). We fit a simple stepwise logistic mixed-effects regression model to the results with a maximal random effects structure, using regularization of individual verb form (yes or no) as an outcome variable and category as predictor. This model confirms the general finding that there is significant variation across the verb classes. (Significance values reported are based on difference with the sang class.) The cut class shows the highest rate of regularization (p&lt;0.001), followed by the burnt class (p&lt;0.01). It is followed by the sang and kept classes (these two do not differ sig</context>
</contexts>
<marker>Moder, 1992</marker>
<rawString>Carol Lynn Moder. 1992. Productivity and categorization in morphological classes. Ph.D. thesis, State University of New York at Buffalo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vicky Tzuyin Lai</author>
<author>Robin Melnick</author>
<author>Christopher Potts</author>
<author>Tyler Schnoebelen</author>
<author>Harry Tily</author>
</authors>
<title>Crowdsourcing and language studies: the new generation of linguistic data.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk,</booktitle>
<pages>122--130</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Lai, Melnick, Potts, Schnoebelen, Tily, 2010</marker>
<rawString>Vicky Tzuyin Lai, Robin Melnick, Christopher Potts, Tyler Schnoebelen, and Harry Tily. 2010. Crowdsourcing and language studies: the new generation of linguistic data. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 122–130. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramin C Nakisa</author>
<author>Kim Plunkett</author>
<author>Ulrike Hahn</author>
</authors>
<title>A cross-linguistic comparison of single and dual-route models of inflectional morphology. Peter Broeder, &amp; Jaap Murre, Models of Language Acquisition: Inductive and Deductive Approaches,</title>
<date>2001</date>
<pages>201--222</pages>
<contexts>
<context position="20314" citStr="Nakisa et al., 2001" startWordPosition="3289" endWordPosition="3292">s reported here were generated with no frequency cutoff. Alternate runs with the frequency threshold enforced produce no change in the model. The model is run with the default parameter settings of s = 0.3, p = 1 with respect to calculating the weighted similarities between items. When p is set to 1, as here, the similarity function is exponential, rather than Gaussian. The weighting parameters controls the tradeoff in the relative importance of the size of the verb category (the ’gang size’) vs. the amount of similarity (measured via edit distance between phonological forms) (Nosofsky, 1990; Nakisa et al., 2001; Albright and Hayes, 2003; Dawdy-Hesterberg and Pierrehumbert, 2014). Figure 2 shows three plots. The first one depicts the relationship between the predictions of the GCM (regular category weight) and experimental ratings (mean participant regularization) for individual verb types used in the experiment. The Spearman rank correlation is highly significant (rho = 0.497, p &lt; 0.001). The second one depicts the relationship between the MGL model predictions (reliability rating of the regular form) and mean participant regularization in the experiment. The Spearman rank correlation between these </context>
</contexts>
<marker>Nakisa, Plunkett, Hahn, 2001</marker>
<rawString>Ramin C. Nakisa, Kim Plunkett, and Ulrike Hahn. 2001. A cross-linguistic comparison of single and dual-route models of inflectional morphology. Peter Broeder, &amp; Jaap Murre, Models of Language Acquisition: Inductive and Deductive Approaches, pages 201–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Nosofsky</author>
</authors>
<title>Relations between exemplar-similarity and likelihood models of classification.</title>
<date>1990</date>
<journal>Journal of Mathematical Psychology,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="3271" citStr="Nosofsky, 1990" startWordPosition="487" endWordPosition="488"> of a candidate past tense formation pattern for a particular candidate item is determined by patterns of similarity to stored items. Morphological innovation and productivity arises from generalizations over existing forms in the lexicon. To account for a speech error such as glew as the past tense of glow (Bybee and Slobin, 1982a), an analogical explanation would highlight the close similarity between glow and the present tense forms blow, throw, know, which provide the basis for an analogy with the past forms blew, threw, knew. Of particular interest is the Generalized Context Model (GCM) (Nosofsky, 1990; Albright and Hayes, 2003), an analogical model which assesses a category’s suitability to a target item on the basis of featurebased similarities summed over category items, in addition to the category’s size. It has already been successfully applied to model regular and irregular patterns in Arabic morphology (DawdyHesterberg and Pierrehumbert, 2014). Rule-based approaches propose more abstract representations of generalizations. Originally proposed to handle broadly applicable default patterns, (such as ‘add -ed to express the past tense’), rule-based approaches have recently been extended</context>
<context position="14389" citStr="Nosofsky, 1990" startWordPosition="2312" endWordPosition="2313">ategory burnt cut drove kept sang category Figure 1: Across-item variation in regularization rates across category (above). Across-subject variation in regularization rates across category (below). 3 Algorithmic Learning Models We now turn our attention from the baseline effects of category variables, to investigate the predictions of particular algorithmic learning models that provide alternate representations for generalizations on the basis of similarity. Our analyses focus on the predictions of the Minimal Generalization Learner and the Generalized Context Model (Albright and Hayes, 2003; Nosofsky, 1990). 3.1 The two models The Minimal Generalization Learner (MGL) (Albright and Hayes, 2002; Albright and Hayes, 2003) is an algorithm for inferring stochastic morphophonological generalizations over a set of training items (e.g., paired present and past tense forms). For each pair of items in the lexicon, the learner maximally aligns wordforms and analyzes shared phonetic features, thereby merging wordspecific rules (ring/rang and stink/stank) into rules that express the most general applicable environment: [I] → [w] / [+coronal, + cont] [N]. Each rule inferred in this way is then further general</context>
<context position="17330" citStr="Nosofsky, 1990" startWordPosition="2778" endWordPosition="2779">mum frequency cutoff of 10 in COBUILD (Baayen et al., 1993), and excluding prefixed verb forms, thus encompassing 4253 past/present verb transcriptions. The MGL is implemented here with its default settings, which includes a lower 75% confidence interval for purposes of adjusting the reliability score. The Generalized Context Model (GCM) is an instance-based model of categorization. To assign category membership to a novel instance, it first calculates its similarity to instances in preexisting categories. Then, it selects the category with members that are most similar to the novel instance (Nosofsky, 1990). Our implementation of the GCM has three notable aspects to it. First, we used the GCM to categorize our nonce verb stimuli, basing the categories on real English verb types extracted from CELEX (as with the MGL). Second, we used the same segmental similarity calculator developed and used by Albright and Hayes and used by the Minimal Generalization Learner to calculate the similarity of phonetically transcribed word forms to each other, so that we could take the phonetic similarity of speech sounds into account instead of calculating similarity between word forms based on edit distance alone.</context>
<context position="20293" citStr="Nosofsky, 1990" startWordPosition="3287" endWordPosition="3288">lar items. Values reported here were generated with no frequency cutoff. Alternate runs with the frequency threshold enforced produce no change in the model. The model is run with the default parameter settings of s = 0.3, p = 1 with respect to calculating the weighted similarities between items. When p is set to 1, as here, the similarity function is exponential, rather than Gaussian. The weighting parameters controls the tradeoff in the relative importance of the size of the verb category (the ’gang size’) vs. the amount of similarity (measured via edit distance between phonological forms) (Nosofsky, 1990; Nakisa et al., 2001; Albright and Hayes, 2003; Dawdy-Hesterberg and Pierrehumbert, 2014). Figure 2 shows three plots. The first one depicts the relationship between the predictions of the GCM (regular category weight) and experimental ratings (mean participant regularization) for individual verb types used in the experiment. The Spearman rank correlation is highly significant (rho = 0.497, p &lt; 0.001). The second one depicts the relationship between the MGL model predictions (reliability rating of the regular form) and mean participant regularization in the experiment. The Spearman rank corre</context>
</contexts>
<marker>Nosofsky, 1990</marker>
<rawString>Robert M Nosofsky. 1990. Relations between exemplar-similarity and likelihood models of classification. Journal of Mathematical Psychology, 34(4):393–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet B Pierrehumbert</author>
</authors>
<title>The next toolkit.</title>
<date>2006</date>
<journal>Journal of Phonetics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="30896" citStr="Pierrehumbert, 2006" startWordPosition="5402" endWordPosition="5403"> the interpretation that is pointed to by this current data set, verification of the joint role of these types of processes clearly requires a lot more explicit testing in different and varied data sets, including real verbs in addition to nonce forms. Recent models in phonological processing and speech perception certainly point to a hybrid model, in which instance-based processing and reasoning sits alongside more abstract structures, and in which both types of processes may be jointly operative – with the balance affected by many factors including the particular nature of the task at hand (Pierrehumbert, 2006). Indeed, we would predict that it should be possible to design morphological tasks which more readily tap into purely analogical processes, or into more abstract generalizations. Acknowledgments This project was made possible through a grant from the John Templeton Foundation. The opinions expressed in this publication are those of the authors and do not necessarily reflect the views of the John Templeton Foundation. Hay and Beckner were also supported by a Rutherford Discovery Fellowship awarded to Hay. The authors would like to thank Adam Albright, Patrick LaShell, Chun Liang Chan, and Lisa</context>
</contexts>
<marker>Pierrehumbert, 2006</marker>
<rawString>Janet B Pierrehumbert. 2006. The next toolkit. Journal of Phonetics, 34(4):516–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David E Rumelhart</author>
<author>James L McClelland</author>
</authors>
<title>On learning the past tenses of English verbs.</title>
<date>1985</date>
<institution>Institute for Cognitive Science, University of California,</institution>
<location>San Diego.</location>
<contexts>
<context position="1885" citStr="Rumelhart and McClelland, 1985" startWordPosition="264" endWordPosition="267">gnificantly more categorical choices than males, a finding that can be related to results in sociolinguistics. 1 Introduction In this report, we present a psycholinguistic study of English past tense categories, using a nonceprobe experiment implemented on Amazon Mechanical Turk. The English past tense has been a testing-ground for a wide range of theories and predictions in psycholinguistics, including the processes of acquisition, the nature of lexical representation, and the representation of inflectional patterns as rules or as generalizations over specific items (Bybee and Slobin, 1982a; Rumelhart and McClelland, 1985; McClelland and Patterson, 2002; Albright and Hayes, 2003). The present study investigates the factors influencing patterns of preferred past tense forms for particular verb classes. English past tenses are not merely a memorized list, but rather, verb categories can shrink, or expand to include new items. In everyday speech, there is evidence of ongoing influences from multiple verb classes, as verbs exhibit variation and slowly shift in their usage (dived vs. dove, sneaked vs. snuck), (Haber, 1976; Bybee and Moder, 1983). Given that speakers can adapt their verbal categories to new situatio</context>
</contexts>
<marker>Rumelhart, McClelland, 1985</marker>
<rawString>David E Rumelhart and James L McClelland. 1985. On learning the past tenses of English verbs. Institute for Cognitive Science, University of California, San Diego.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>