<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000392">
<title confidence="0.998167">
Aided Diagnosis of Dementia Type through Computer-Based Analysis
of Spontaneous Speech
</title>
<author confidence="0.730677">
William Jarrold Bart Peintner David Wilkins
</author>
<affiliation confidence="0.24791">
Nuance Communications1 Soshoma1 Language &amp; Linguistic Consulting
</affiliation>
<email confidence="0.803629">
william.jarrold@gmail.com bpeintner@gmail.com wilkinsdavidp@gmail.com
</email>
<author confidence="0.99142">
Dimitra Vergryi and Colleen Richey Maria Luisa Gorno-Tempini and Jennifer Ogar
</author>
<affiliation confidence="0.997549">
SRI International University of California, San Francisco
</affiliation>
<email confidence="0.979023">
dverg@speech.sri.com, {marilu|jogar}@memory.ucsf.edu
colleen.richey@sri.com
</email>
<sectionHeader confidence="0.993223" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999968961538461">
This pilot study evaluates the ability of machined
learned algorithms to assist with the differential
diagnosis of dementia subtypes based on brief (&lt;
10 min) spontaneous speech samples. We ana-
lyzedrecordings of a brief spontaneous speech
sample from 48 participants from 5 different
groups: 4 types of dementia plus healthy con-
trols. Recordings were analyzed using a speech
recognition system optimized for speaker-
independent spontaneous speech. Lexical and
acoustic features were automatically extracted.
The resulting feature profiles were used as input
to a machine learning system that was trained to
identify the diagnosis assigned to each research
participant. Between groups lexical and acoustic
differences features were detected in accordance
with expectations from prior research literature
suggesting that classifications were based on fea-
tures consistent with human-observed sympto-
matology. Machine learning algorithms were
able to identify participants&apos; diagnostic group
with accuracy comparable to existing diagnostic
methods in use today. Results suggest this clini-
cal speech analytic approach offers promise as an
additional, objective and easily obtained source
of diagnostic information for clinicians.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99940675">
Accurately differentiating certain neurodegenera-
tive disorders such as Alzheimer’s Disease (AD)
and variants of Fronto-temporal Lobar Degener-
ation (FTLD) is extremely difficult (Varma et
al., 1999). Differential diagnosis is often left to
tertiary care settings (e.g. Research I Universities
with medical schools). While the most definitive
diagnosis is made post-mortem using brain tissue
</bodyText>
<sectionHeader confidence="0.451409" genericHeader="method">
1 Research conducted while at SRI International
</sectionHeader>
<bodyText confidence="0.999952">
samples, the treatment and prognostic implica-
tions of living patients are often determined in
large part on the basis of language assessment.
Although language is clearly not the exclusive
diagnostic factor for AD, existing literature sug-
gests it is an important one. Studies show sig-
nificant differences in the written language abili-
ties of AD patients and healthy older adults (Pes-
tell et al., 2008 and Platel et al., 1993). The
speech of patients with AD is partly character-
ized by word-finding difficulties, smaller vocab-
ularies, and problems with semantic processing
(Forbes at el., 2002). These symptoms appear
early in the disease’s progression, however lan-
guage assessment of AD patients can fail to iden-
tify early symptoms that family members report
to be present in their conversations (Crockford
and Lesser, 1994).
FTLD has a prevalence similar to AD in patients
under the age of 65 years (Mendez at el., 1993).
Misdiagnosis of FTLD is common Mendez at el.,
1993). Three variants are defined by the widely
adopted Neary criteria (Neary at el., 1998); one
with altered social conduct, the behavioral vari-
ant of frontotemporal dementia (bvFTD); the
second characterized by a deterioration of con-
ceptual-semantic knowledge, semantic dementia
(SD); and the third marked by a disorder of ex-
pressive language fluency, progressive non-
fluent aphasia (PNFA).
Clinicians diagnose using a wide array of evi-
dence including patient history, imaging and
neuropsychological assessment in which speech
and language diagnostics feature prominently. In
AD, cognitive disturbance is a required diagnos-
tic feature and language impairment one several
sufficient signs of such impairment. In the case
</bodyText>
<page confidence="0.976317">
27
</page>
<bodyText confidence="0.986549594202899">
Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 27–37,
Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics
of SD and PNFA, changes in speech and lan-
guage are core diagnostic features, with changes
in lexical content features being highly diagnos-
tic of SD, and changes in the acoustic properties
of speech being highly diagnostic of PNFA.
Even in bvFTD, where changes in social behav-
ior are the defining features, analysis of lan-
guage-based differences is important, because
language is an essential mediator of social be-
havior. To be sure, the clinician does not diag-
nose exclusively on language features -- patient
history, imaging, memory functioning and more
play a role. However, language does feature
prominently in the differential diagnosis of AD,
FTLD and its three subtypes. For this reason,
computerized analysis of speech may offer an
important aid to the clinical diagnosis of these
syndromes.
Prior work in clinical speech analytics supports
the possibility of computer-based diagnosis of
dementia related syndromes. Singh (2001) de-
scribes a means of quantifying the degree of
speech deficits derived from human transcrip-
tions of the speech of patient with AD. Machine
Learning has already been applied to distinguish
AD from controls using human transcribed spon-
taneous speech (Thomas at el., 2005). Abel et al.
(2009) applied a connectionist net that models
patient speech errors (naming and repetition dis-
orders) to the problem of diagnosis. Tur et al.
(2010) have shown the ability to automatically
score patient speech from a story recall and pic-
ture description task that is on par with human
performance. Lehr et al. (2012) have developed a
system that automatically transcribes and scores
patient speech obtained during the story recall
portion of the Wechsler Logical Memory test.
The evaluation demonstrated it could distinguish
mild cognition impairment from typical controls
at performance level comparable to human scor-
ers.
Our work builds upon these prior studies along a
number of dimensions. First, we distinguish be-
tween a wider array of dementia subtypes, i.e.
not only AD vs controls, but also the three sub-
types of FTLD. Second, we use not just lexical
features but also acoustic/prosodic related fea-
tures. Third, in order to shed light on the opaque
“black box” nature of many machine-learned
classifiers, we identify relationships between
model features and symptoms from the clinical
literature. Fourth, our approach can claim to be
more ecologically valid because it analyzes spon-
taneous speech as input rather than recall of a
remembered passage. Fifth, we do not require
human transcription - a labor-intensive step that
hinders broader use in a clinical setting. Sixth we
provide a comparison of our system performance
against benchmarks obtained from practicing
clinicians. Our paper is the first we know of to
exhibit all of the above properties.
In sum we used computational techniques to ana-
lyze acoustic and lexical features of the speech of
patients with AD and FTLD variants, and we
investigated whether models derived from these
features via machine learning could accurately
identify a patient’s diagnosis.
</bodyText>
<sectionHeader confidence="0.99791" genericHeader="method">
2 METHOD
</sectionHeader>
<subsectionHeader confidence="0.99993">
2.1 Participant Recruitment and Diagnosis
</subsectionHeader>
<bodyText confidence="0.999897066666667">
We obtained spontaneous speech data from 9
controls, 9 AD patients and 30 FTLD patients—9
with frontotemporal dementia (bvFTD), 13 with
semantic dementia (SD), and 8 with progressive
nonfluent aphasia (PNFA). Table 1 shows demo-
graphic information.
Data were collected in an ongoing series of NIH-
funded studies being performed at the UCSF
Memory and Aging Center. Patients were diag-
nosed by expert clinicians at the center by apply-
ing current clinical criteria. Patients underwent
detailed standard speech and language, cognitive,
emotional, genetic, pathological, and neuroimag-
ing evaluations. Age-matched healthy controls
were community volunteers obtained by SRI In-
</bodyText>
<table confidence="0.990864666666667">
bvFTD PNFA SD AD Controls
Male/Female 5/4 1/7 6/7 5/4 3/6
Age 63.00(8.25) 62.88(7.75) 65.23(6.61) 59.11(7.47) 61.7(6.0)
Education * 17.33(1.73) 16.13(2.30) 16.45(2.54) 15.44(2.30) 17.27(2.1)
MMSE 24.4(5.85) 22.0(9.34) 17.09(8.15) 18.67(7.53) Not Adminis-
tered
</table>
<tableCaption confidence="0.999934">
Table 1. Demographic information for participants
</tableCaption>
<page confidence="0.993193">
28
</page>
<figure confidence="0.999820105263158">
Microphone
Subject
audio
recordings
Speech to Text
Human
Transcriptionist
Automatic
Speech
Analysis
(ASA)
Automatic
Transcription
(AT)
Human
Transcription
(HT)
Acoustic
Feature
Extractor
Acoustic Feature Extraction (AFE)
Lexical Feature Extraction (LFE)
POS
tagger
LIWC
Acoustic
feature profile
LIWC feature
profile
POS feature
profile
Training Data Labels
(Each participant’s
Diagnosis)
Disease Identifying
Model
Machine
Learning
</figure>
<figureCaption confidence="0.806788714285714">
Figure 1. System Information Flow and Evaluation. Participant speech is subjected to automatic
speech analysis of two kinds: Acoustic Feature Extraction (AFE) and Lexical Feature Extraction
(LFE). Feature selection (not shown) is explained in Sects 2.3 and 2.6. Each machine learning algo-
rithm produces a classification model based on labeled training data. All models used both acoustic
and lexical features. Each such disease identifying model is evaluated against held-out training data
(not shown). To measure sensitivity to ASR error, half of these models were based on lexical features
derived from automatic transcription (AT), the other half from human transcription (HT).
</figureCaption>
<bodyText confidence="0.997928">
ternational and were paid $10 for their participa-
tion.
</bodyText>
<subsectionHeader confidence="0.999397">
2.2 Speech Samples
</subsectionHeader>
<bodyText confidence="0.999988">
Speech samples were recordings of Part 1 of the
Western Aphasia Battery (Kertesz, 1980). Partic-
ipants are administered a semi-structured inter-
view (e.g., questions such as “How are you?”)
and asked to describe a drawn picture of a picnic
scene. The resulting 3 to 5 minutes of speech was
recorded via wireless lapel microphones. Con-
trols were recorded via digital audio recorder
sampling at 48 kHz, 16 bit PCM, and later down-
sampled to 16 kHz for use with the speech rec-
ognizer. Digital audio was down-sampled at 16
kHz, 16 bit PCM. Recordings were manually
segmented in order to separate the interviewee’s
voice from the interviewer’s. Only patient
speech segments were subject to analysis
</bodyText>
<subsectionHeader confidence="0.996459">
2.3 Procedure
</subsectionHeader>
<bodyText confidence="0.999980323529412">
To tackle speech-based diagnosis of AD, bvFTD,
SD and PNFA, we employ several types of com-
puter-based analyses (see Figure 1). Audio re-
cordings were processed via the Meeting Under-
standing system (Stolcke at el., 2007), which was
custom-tailored to recognize speaker-
independent, multi-person speech. First, using
this system we perform acoustic-level feature
extraction (AFE), which obtains measures the
duration of consonants, vowels, pauses, and oth-
er acoustic-phonetic categories. In parallel, we
perform a lexical feature extraction (LFE) on
transcripts of participant speech producing pro-
files of each speaker’s language use. This profile
characterizes frequencies of different types of
words Ð e.g. frequency of nouns, verbs, function
words, words about emotion, etc. Ð present in a
language sample along ~100 dimensions.
Next, The AFE and LFE profiles are combined
to form one large vector of features that collec-
tively characterize the speaker. Feature selection
is applied to select the most informative features.
For feature selection, we performed a one-way
ANOVA on each extracted feature to determine
which features were significantly related to a
diagnostic category using the Benjamini-
Hochberg adjustment for multiple comparisons.
The vector of selected features for the speech
samples in the training set is taken as input to
machine learning. Based on these data machine
learning automatically induces a diagnostic mod-
el that should predict any speaker’s diagnosis
based the AFE and LFE profiles of his or her
speech sample.
</bodyText>
<page confidence="0.991691">
29
</page>
<bodyText confidence="0.99992332">
The performance of a learned diagnostic model
is measured in terms of ability to generalize to
cases that it has not been trained on is measured
by feeding test set cases – i.e. cases that have not
been a part of the training set. We compared the
accuracy of the machine learning induced algo-
rithms with accuracy studies of traditional diag-
nostic methods in the literature.
In addition to the above, as part of a desire to
achieve insight into the way these models were
functioning, we sought verification that a differ-
ences in feature profiles as a function of diagnos-
tic group correspond meaningfully to existing
expectations derived from the literature. To do
so, we formed and tested several predictions
about specific feature differences based on the
clinical literature (see Hypotheses below).
Finally, we wanted to determine how sensitive
the feature differences and classification models
were to speech recognition error. To do so we
tested each hypothesis on both the human and
automatic transcriptions. In addition, we learned
a set of models based on automatic transcriptions
and a second set of models based on human tran-
scriptions and compared accuracies.
</bodyText>
<subsectionHeader confidence="0.998323">
2.4 Acoustic Feature Extraction
</subsectionHeader>
<bodyText confidence="0.99999275">
We used the automatic speech recognition (ASR)
system to extract a set of acoustic-level features
corresponding to the overall rate, plus the mean
and standard deviation of (a) pause lengths and
(b) hypothesized phoneme durations. For each
speech sample, the speech rate as well as the
mean and standard deviation of the duration of
pauses, vowels, and consonants were comput-
ed. The SRI speech processing system also fur-
ther identified consonant classes based on man-
ner features (e.g., fricative, stop, etc. É) voic-
ing features (voiced, voiceless) and measured the
mean and standard deviation of the duration of
these classes. Our Automatic Speech Analysis
system produced 41 different duration-based
measures extracted from the speech stream.
</bodyText>
<subsectionHeader confidence="0.996957">
2.5 Lexical Feature Extraction (LFE)
</subsectionHeader>
<bodyText confidence="0.999965185185185">
For each transcript we performed two types of
computer-based lexical analysis. The first deter-
mined frequencies of 14 different parts of speech
(e.g. nouns, verbs, pronouns etc.) using an auto-
matic part-of-speech (POS) tagger. The second
involved Dr. Pennebaker’s Linguistic Inquiry
and Word Count (LIWC) software (Pennebaker,
et al 2001), which determines word frequencies
organized into 81 categories, such as psychologi-
cal processes (e.g., emotional or cognitive) and
linguistic dimensions (e.g. function words, verb
tenses, negations).
To measure sensitivity to speech to text error,
each ANOVA was performed twice, once for the
“ground truth” human transcriptions (HT) and
once for the automatic transcriptions (AT). Dur-
ing hypothesis testing, statistical significance of
each pair of AT versus HT based LFEs (i.e.,
“ground truth”) was compared. Additionally
different models were learned, half using HT the
other half using AT. To test for lexical-level dif-
ferences between diagnostic categories, we per-
formed a one-way ANOVA for each of the 95
LFE features (e.g. frequency of nouns) in which
diagnosis was the independent variable and the
given feature’s frequency was the dependent var-
iable.
</bodyText>
<subsectionHeader confidence="0.98314">
2.6 Machine Learning
</subsectionHeader>
<bodyText confidence="0.995141607142857">
We assessed how well a variety of machine
learning algorithms predicted a patient’s diagno-
sis, using his or her combined AFE and LFE pro-
file. Evaluation was conducted using five-fold
cross-validation over the set of patients, with
each “fold” consisting of two phases: a training
phase, where the feature profiles and diagnoses
from 4/5ths of the subjects are used to select fea-
tures and then train the given learning algorithm,
and a test phase where the trained learner is giv-
en just the feature profiles of the remaining pa-
tients, and attempts to predict their diagnoses.
This procedure is executed five times, each time
using different sets of subjects for the train and
test phases, with overall accuracy being the aver-
age performance on the test subjects, across all
five folds. We applied three learning methods,
(1) logistic regression, a statistical learning tech-
nique for determining categorical outcomes, (2)
Multi-Layered Perceptrons, an artificial intelli-
gence (AI) learning method that roughly mimics
biological neural networks, and (3) decision
trees, another AI technique which induces sets of
rules used to predict outcomes. All three are
commonly used machine learning techniques,
and for this study we used implementations
available in Weka, an off-the-shelf machine
learning toolkit (Witten and Frank, 2005).
</bodyText>
<subsectionHeader confidence="0.880725">
2.7 Hypotheses
</subsectionHeader>
<bodyText confidence="0.978567333333333">
Machine learned classification models can be
difficult to understand and often used merely as
black boxes. To address this issue, we tried to
</bodyText>
<page confidence="0.991767">
30
</page>
<bodyText confidence="0.999778867924528">
draw a meaningful link between certain features
and diagnosis. In particular, we formed and test-
ed several hypotheses based on expectations de-
rived from clinical literature. We used all the
data (rather than one of the training folds) to test
these hypotheses.
The hypotheses about the lexical features are as
follows. First, based on (Forbes at el., 2002) we
predicted that AD patients use more pronouns,
verbs, and adjectives and fewer nouns than con-
trols (H1).
In SD, one sees decreased lexical access to con-
crete concepts, so patients tend to use fewer
nouns (H2). To compensate for such difficulties
with word retrieval, they also use more pronouns
(H3). This gives the impression of empty or cir-
cumlocutory speech. For example, rather than
saying “The boy is flying a kite,” a SD patient
would be more prone to say “He is flying that.”
(Grossman and Ash, 2004).
In PNFA, one sees fewer verbs (H4) (Grossman
and Ash, 2004). In addition, PNFA patients of-
ten exhibit agrammatism. Such speech is simpli-
fied and ungrammatical and involves fewer func-
tion words, for example “give cupcake” or “wa-
ter now”. Thus (H5) is that the speech of pa-
tients with PNFA will have fewer function words
(H5) (Saffran at el., 1989). These hypotheses,
along with whether each was supported by our
analyses, are listed in Table 2 in Results.
The first acoustic hypothesis about acoustic fea-
tures (H6) is related to the Neary criteria (Neary
et al., 1998), which notes that PNFA is character-
ized by non-fluent spontaneous speech (among
other required features). Additionally, patients in
this group have significant apraxia of speech
(Gorno-Tempini at el., 2004). Signs of this con-
dition difficulty include articulatory groping –
i.e. where the mouth searches for the correct con-
figurations. Such trial and error speech often
sounds “robotic” and can involve sounds that
may be held out longer. Thus, given the duration
features that are generally associated with aprax-
ia of speech (Samuel at el., 1996; Edythe at el.,
1996; Ballard and Robin, 2002), we hypothesize
that PNFA patients would exhibit significantly
longer vowel and consonant durations than con-
trols (H6).
The second acoustic feature hypothesis (H7) is
based on the fact that in the Neary criteria (Neary
at el., 1998) pressured speech is a supportive
(but not a core) diagnostic feature of both SD
and bvFTD. In pressured speech one sees rapid
</bodyText>
<table confidence="0.8812236875">
Figures (see
Supported in Supported in LFE
Hypothesis and source LFE of HT? or AFE of AT? Supplementary
Materials)
H1. AD patients use more Yes, but only Yes, significant for Figure 3
pronouns, verbs, and adjectives significant for nouns, pronouns,
and fewer nouns than controls nouns and adjectives
(Forbes at el., 2002)
H2. SD patients use fewer nouns Yes Yes, but not
(Grossman and Ash, 2004) significant vs PNFA Figure 3
H3. SD patients use more Partial: SD sig. &gt;
pronouns (Grossman and Ash, Yes Figure 3
2004) CNTRL only
H4. Lower verb frequency in Yes, but only
PNFA (Grossman and Ash, 2004) No Figure 3
significant vs. SD
</table>
<listItem confidence="0.495958125">
H5. Fewer function words in Yes, but only
Yes significant vs SD Figure 3
PNFA (Saffran at el., 1989)
H6. PNFA patients would exhibit
longer vowel and consonant N/A Yes Figure 2
durations
H7. SD and bvFTD patients have N/A Yes Figure 2
shorter pauses than controls.
</listItem>
<tableCaption confidence="0.920987">
Table 2. Hypotheses extracted from literature and whether our measures—based on human transcripts
(HT) and automatic transcripts (AT)—support them [Hypotheses 1-5 relate to Lexical Feature Ex-
traction; Hypotheses 6-7 relate to Acoustic Level Analyses]
</tableCaption>
<page confidence="0.999712">
31
</page>
<bodyText confidence="0.9968912">
“flight of ideas” speech. We would thus expect
some patients in these conditions to exhibit press
of speech, and so hypothesize that the mean du-
ration of pauses should be significantly less than
controls (H7).
</bodyText>
<sectionHeader confidence="0.999841" genericHeader="method">
3 RESULTS
</sectionHeader>
<bodyText confidence="0.991249833333333">
Results suggest that analyses at the lexical and
acoustic levels are capable of detecting differ-
ences in accordance with expectations of prior
research. Additionally, machine-learning algo-
rithms predict clinical diagnosis surprisingly
well.
</bodyText>
<subsectionHeader confidence="0.995256">
3.1 Results: Acoustic-Level Hypotheses
</subsectionHeader>
<bodyText confidence="0.999928714285715">
For each measure, we performed an ANOVA
with respect to diagnosis and found that 25 out of
41 measures were significant at the (Benjamini-
Hochberg multiple comparison adjusted) 0.05
level. Hypotheses 7 and 8 in Table 2 and Figure
2 in Supplementary Materials deal specifically
with AFE measures. These show that PNFA pa-
tients do exhibit significantly longer vowel and
consonant durations, as the literature linking
PNFA with apraxia of speech would predict. Fur-
thermore, SD and bvFTD patients have signifi-
cantly shorter pauses than controls, which is con-
sistent with the hypothesis that some patients
with these diagnoses exhibit press of speech.
</bodyText>
<subsectionHeader confidence="0.99826">
3.2 Results: Lexical-Level Hypotheses
</subsectionHeader>
<bodyText confidence="0.999129153846154">
There were several lexical-level differences be-
tween diagnostic groups. We checked for signifi-
cant differences (hereafter, “significant fea-
tures”) with respect to diagnosis while using the
Benjamini-Hochberg test for multiple compari-
sons (Benjamini and Hochberg, 1995). (We use
this adjustment for all multiple comparisons).
There were several more lexical level differences
based on the HTs than one would predict by
chance. For example, 11 of the 14 POS features
were significant (p ≤ .05) including verbs, nouns,
adjectives and adverbs. For LIWC features, 22 of
81 features were statistically significant at the p
</bodyText>
<table confidence="0.998034793103448">
(A) (B) (C) (D)
FTLD vs AD vs SD FTLD vs AD AD vs Controls
AD vs vs PNFA
Controls vs bvFTD
vs Control
1. Random diagnosis 33% 20% 50% 50%
2. Naïve learner (always picks 63% 27% 77% 50%
largest class in training set)
3. Our method 80% 61% 88% 88%
Sens/Spec AD K = .64 /Spec AD .83/.90
.58/0.77 Sens/Spec Controls
Sens/Spec FTLD .92/.86
.95/.89
4. Radiologists in Klšppel at 69% 89% Sensi/Spec AD
el. (2008) using MRI data Sens/Spec AD .88/.90
.64/.71
Frontal Behavioral 75%
5. Inventory in Blair at el.
(2007)
6. Neuropsychiatric inventory 54%
in Blair at el. (2007).
7. NINCDS-ARDA criteria in K — .36 − .65
Lopez at el. (1990)
8. DSM-III criteria in Kukull K — .55
at el. (1990)
9. NINCDS criteria in Kukull K = .64
at el. (1990)
10. ECRDC criteria in Kukull at K = .37
el. (1990)
</table>
<tableCaption confidence="0.958158">
Table 3. Accuracy, sensitivity and specificity for Layered Perceptron learned models for FTLD subtypes.
(Accuracy of a random and naïve learner id 33% and 43% respectively)
</tableCaption>
<page confidence="0.999087">
32
</page>
<bodyText confidence="0.99992375">
&lt;= 0.05 level, with p ≤ 0.005 for 17 of them. As
to the question of whether the profile differences
correspond meaningfully to existing literature,
Table 2 shows which literature-generated hy-
potheses were supported. See Figure 3 in Sup-
plementary Materials which show the means and
standard error for each diagnostic class on a par-
ticular feature.
</bodyText>
<subsectionHeader confidence="0.996541">
3.3 Machine Learning Results
</subsectionHeader>
<bodyText confidence="0.999983111111111">
Using cross-validation, we tested the ability of
machine learning methods to produce algorithms
that could synthesize lexical-level and acoustic-
level profiles and then identify the clinician di-
agnosis.
We tried several different machine-learning algo-
rithms and found that performance was roughly
the same. See Table 3 for the performance of the
Multi-layered Perceptron algorithm, which was
slightly superior. Performance was measured
across several different diagnostic problems
(e.g., FTLD vs AD vs Controls (Column A), AD
vs Controls (Column D), etc.). For purposes of
rough comparison, Table 3 also provides diag-
nostic performance of other methods, including
radiologists using MRI data.
In evaluating machine learning results, we
wished to compare model performance against
various benchmarks. The two easiest such
benchmark are random guessing (see Table 3
Row 1: given N diagnostic alternatives, one has a
1 / N chance of correctly guessing) and naïve
learner guessing, (see Table 3 Row 2) which
always chooses the most frequent (i.e., modal)
diagnosis found in the training sample. The row
labeled “Our method” corresponds to the accura-
cy of models generated from lexical and acoustic
features using AT. For this case, HT results dif-
fers from AT in accuracy by only 2-3% for all
prediction problems. Note that our method is at
least equal to the accuracies, sensitivities, speci-
ficities, and kappa’s of the other clinical bench-
marks in most cases. See Table 4, which shows
the performance on distinguishing FTLD sub-
types. For more detail on machine learning re-
sults see Peintner et al (2008).
</bodyText>
<sectionHeader confidence="0.999872" genericHeader="method">
4 DISCUSSION
</sectionHeader>
<bodyText confidence="0.999986946428572">
The accuracy of the best machine learned diag-
nostic model was 88% in the binary classifica-
tions of AD versus FTLD, and AD versus Con-
trols (Table 3). Acoustic and lexical level differ-
ences are detectable despite the present level of
ASA inaccuracy. Although diagnosis should
never be made on the basis of one source of in-
formation, our pilot data show that automatic
computer-based analyses of spontaneous speech
show promise as diagnostic aids by detecting the
at times subtle differences that characterize these
neurodegenerative disorders.
Inferences drawn from these results are subject
to a variety of assumptions and limitations. Per-
haps the biggest limitation is the small number of
research participants. Larger samples will be
needed in order to make valid generalizations to
the population. Small samples increase the prob-
ability of Type I and II Errors and decrease pow-
er in testing for normality. That said, many of
our hypothesized linguistic differences based on
prior research were confirmed. Additionally,
low N in each group entailed that test sets in each
fold were small. Though it is remarkable in our
pilot study that we obtained classification accu-
racy on par with clinical judgment, a larger sam-
ple size is required to make a rigorously valid
claim about on par accuracy.
Statistically minded readers may question our
use of parametric statistics (ANOVA) in feature
selection because we have not tested the normali-
ty assumption. There are too few observations in
each group to test for normality of residuals with
any power. In future work with a larger sample
we should perform such a test. Alternatively, on
the present data we could use the non-parametric
Kruskal-Wallis test as a stand in for ANOVA.
Additionally, such readers may question our use
of the Benjamini-Hochberg (BH) adjustment
which controls false discovery rate over a more
stringent correction for familywise error rate
such as Bonferoni or Holm. Our rationale was
that an occasional false positive (5% if we have a
5% false positive rate) among our total set of
positives isn’t a big concern. As our focal aim
was machine learning, scientific discovery, was a
secondary concern. Thus, we were less interest-
ed in the question “was there any difference be-
tween the groups&amp;quot;. We were more interested in
which features showed a difference. Better to
have a small proportion of false positives than to
miss true positives. In addition, because the false
negative rate criterion is less stringent about false
positives, the BH procedure tends to have greater
power than multiple comparison approaches that
control the familywise error rate.
</bodyText>
<page confidence="0.997994">
33
</page>
<bodyText confidence="0.939557219512195">
The success of our methods is surprising given
(1) we have performed no customization of “off
the shelf” LFE and machine learning techniques;
(2) models were trained on a relatively small
number of subjects; (3) speech samples were
short (3-5 minutes). Larger speech samples, larg-
er N and more tailored tools (e.g. language mod-
els) will enable lower word error rate, higher ac-
curacy and finer discrimination amongst and
within diagnostic types. It also suggests that this
can be accomplished without training the system
to the voice of each subject.
The results also draw significance because the
overall approach may be applied to other neuro-
logical or psychological disorders. Many such
disorders have characteristic lexical or acoustic
profiles. For example, Jarrold (2011) and Stir-
man et al (2001) have shown that depression is
associated with high frequencies of first person
words (I, me, I’ve) and lower frequencies of so-
cial and second person words (us,we). Sanchez
et al (2011) and Keskinpala (2007) have shown
acoustic prosodic features indicative of depres-
sion or suicide risk. Our results suggest a very
similar study design can be applied to detect the-
se kinds of depression related lexical and acous-
tic/prosodic profiles.
Our results suggest we may be able train the
models to assess specific highly diagnostic lan-
guage symptoms – such as fluency, circumlocu-
tion, and apraxia of speech. This can be particu-
larly important where the inter-rater reliability of
given symptoms is poor. We believe that poor
inter-rater reliability is mainly caused by the ina-
bility to precisely delineate the objective charac-
teristics of these symptoms. Assuming we can
get a range of values that characterize a given
symptom, we can apply machine learning to
identify symptoms in addition to diagnosis.
We view the methods described as analogous to
EKG. The EKG trace affords a more quantita-
</bodyText>
<figure confidence="0.6823215">
Accuracy bvFTD PNFA SD
(Sens/Specif)
63% .51 / .58 .54 / .76 /
.72 .62
</figure>
<tableCaption confidence="0.84874625">
Table 4. Accuracy, sensitivity and specificity for
Lay-ered Perceptron learned models for FTLD
subtypes. (Accuracy of a random and naïve
learner id 33% and 43% respectively)
</tableCaption>
<bodyText confidence="0.999985902439025">
tive and objective picture of cardiac functioning
which complements the stethoscope. Analogous-
ly, if scaled-up studies can demonstrate adequate
diagnostic accuracy results, then computationally
extracted lexico-acoustic profiles may someday
augment information provided by current speech
and language diagnostic methods which are cur-
rently based substantially on subjective clinical
judgment. As modern EKG’s provide automatic
interpretation, our analysis suggests that classifi-
cation of speech as AD-like or FTLD-like may
be possible. The competent physician never re-
lies only the automated diagnosis provided by
EKG but also interprets a profile of measures in
the context of clinical observation. Our assump-
tion is that the methods outlined above should be
used in a way analogously to the EKG.
The results of our hypothesis testing show that
differences in feature profiles are generally con-
sistent with what we would expect from the clin-
ical literature. This may be the first of several
steps required to provide assurance to clinicians
who would prefer to trust a model that had
somewhat transparent features to the opaque
“black box” models that are often learned. Es-
tablishing trust of clinicians is required for wide
scale adoption and future work should build on
these results.
Our pilot data suggest this approach provides
diagnoses of comparable accuracy to other more
time intensive or more invasive methods (e.g.
neuropsychological testing or imaging). This is a
fast, inexpensive, and non-invasive means of
obtaining diagnostically useful information. Thus
the tool may show most promise as a screening
tool to decide which patients need deeper evalua-
tion. Additionally, it may provide objective and
quantifiable measures of speech and language
symptomatology – a kind of symptomatology for
which there are few objective, quantifiable
measures.
</bodyText>
<sectionHeader confidence="0.99896" genericHeader="method">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.998920444444444">
Clinical speech analytics applied to spontaneous
speech can detect distinguish between AD,
bvFTD, SD PNFA and healthy control groups
via lexico-acoustic profiles. Diagnostic accuracy
is comparable to other clinical data sources de-
spite speech sample brevity. Accuracy levels
suggest the approach offers promise as an addi-
tional, objective and easily obtained source of
diagnostic information for clinicians.
</bodyText>
<page confidence="0.997461">
34
</page>
<sectionHeader confidence="0.840635" genericHeader="method">
Reference
</sectionHeader>
<reference confidence="0.997448754716981">
Varma A.R., Snowden J.S., Lloyd J.J., Talbot P.R.,
Mann D.M.A., Neary D. 1999. Evaluation of the
NINCDS-ADRDA criteria in the differentiation of
Alzheimer’s disease and frontotemporal dementia,
Journal of Neurology, Neurosurgery and Psychia-
try, 66: 184-188.
Klšppel, S., Stonnington, C.M., Barnes, J., Chen, F.,
Chu, C., Good, C.D., Mader, I., Mitchell, L.A., Pa-
tel, A.C., Roberts, C.C., Fox, N.C., Jack, R. Jr,
Ashburner, J., Frackowiak , RS. 2008. Accuracy of
dementia diagnosis: a direct comparison between
radiologists and a computerized method, Brain,
131(11): 2969–2974.
S. Pestell, M. Shanks, J. Warrington, and A. Venneri.
2000. Quality of spelling breakdown in Alzheimer&apos;s
disease is independent of disease progression,
Journal of Clinical and Experimental Neuropsy-
chology, volume 22, pages 599–612.
H. Platel, J. Lambert, F. Eustache, B. Cadet, M. Dary,
F. Viader, and B. Lechevalier. 1993. Character-
stics and evolution of writing impairment in Alz-
heimer&apos;s disease, Journal of Clinical and Experi-
mental Neuropsychology, volume 22, pages 599–
612.
K. Forbes, A. Venneri, and M. Shanks. 2002. Distinct
patterns of spontaneous speech deterioration: an
early predictor of Alzheimer&apos;s disease, Brain and
Cognition, volume 48(2-3): 356–61.
C. Crockford and R. Lesser. 1994. Assessing func-
tional communication in aphasia: Clinical utility
and time demands of three methods, European
Journal of Disorders of Communication, volume
29: 165–182.
Thomas, V., Keselj, N., Cercone, K., Rockwood, E.
2005. Automatic detection and rating of dementia
of Alzheimer type through lexical analysis of spon-
taneous speech, IEEE International Conference on
Mechatronics and Automation.
Mendez, M.F., Selwood, A., Mastri, A.R., Frey, W.H.
1993. 2nd, Pick&apos;s disease versus Alzheimer&apos;s dis-
ease: A comparison of clinical characteristics,
Neurology, 43(2): 289–92.
Neary, D., Snowden, J.S., Gustafson, L., Passant, U.,
Stuss, D., Black, S., Freedman, M., Kertesz, A.,
Robert, H., Albert, M., Boone, K., Miller, B.L.,
Cummings, J., Benson, D.F. 1998. Frontotemporal
lobar degeneration: A consensus on clinical diag-
nostic criteria, Neurology, 51(6): 1546–54.
Davies, R.R., Hodges, J.R., Kril, J.J., et al. 2005. The
pathological basis of semantic dementia. Brain,
128(9): 1984–95.
Josephs, K.A., Duffy, J.R., Strand, E.A., et al. 2006.
Clinicopathological and imaging correlates of
progressive aphasia and apraxia of speech. Brain,
129(6): 1385–98.
Bright, P., Moss, H. E., Stamatakis, E. A., &amp; Tyler, L.
K. 2008. Longitudinal studies of semantic demen-
tia: The relationship between structural and func-
tional changes over time, Neuropsychologia, 46:
2177-2188.
S. Singh, R. Bucks, and J. Cuerden. 2001. Evaluation
of an objective technique for analysing temporal
variables in DAT spontaneous speech, Aphasiolo-
gy, volume 15(6): 571–584.
Stefanie Abel, Walter Huber, Gary S. Dell. 2009.
Connectionist diagnosis of lexical disorders in
aphasia, Aphasiology, volume 23.
Dilek Hakkani-Tür, Dimitra Vergyri, Gškhan Tür.
2010. Speech-based automated cognitive status as-
sessment. Interspeech 2010: pages 258-261.
Maider Lehr, Emily T. Prud’hommeaux, Izhak
Shafran and Brian Roark. 2012. Fully Automated
Neuropsychological Assessment for Detecting Mild
Cognitive Impairment. In Proceedings of Inter-
speech.
Kertesz, A. 1980. Western Aphasia Battery, London,
Ontario: University of Western Ontario Press.
Stolcke, A., Boakye, K., Cetin, ...., Janin, A.,
Magimai-Doss, M., Wooters, C., Zheng, J. 2007.
The SRI-ICSI Spring 2007 meeting and lecture
recognition system, Proc. NIST 2007 Rich Tran-
scription Workshop.
Pennebaker, J.W., Francis, M.E., Booth, R.J. 2001.
Linguistic Inquiry and Word Count (LIWC):
LIWC2001, Mahwah, NJ: Erlbaum Publishers.
Toutanova, K., Klein, D., Manning, C., Singer, Y.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network, in Proceedings of
HLT-NAACL 2003, pages 252–259.
Grossman, M., Ash, S. 2004. Primary Progressive
Aphasia: A Review, Neurocase, 10(1): 3–18.
Gorno-Tempini, M.L, Dronkers, N.F., Rankin, K.P.,
Ogar, J.M., La Phengrasamy, B.A., Rosen, H.J.,
Johnson, J.K., Weiner, M.W., Miller, B.L, Cogni-
tion and Anatomy in three variants of primary pro-
gressive aphasia, Annals of Neurology, 2004. 55:
335–346.
Samuel A. K. Seddoh, Donald A. Robin, Hyun-Sub
Sim, Carlin Hageman, Jerald B. Moon, John W.
Folkins. 1996. Speech Timing in Apraxia of Speech
versus Conduction Aphasia, Journal of Speech and
Hearing Research, 39: 590–603.
Edythe A. Strand, E.A., McNeil, M.R. 1996. Effects
of Length and Linguistic Complexity on Temporal
Acoustic Measures in Apraxia of Speech, Journal
of Speech and Hearing Research, 39: 1018–33.
</reference>
<page confidence="0.999606">
35
</page>
<bodyText confidence="0.9984">
among depressed subjects using mel-frequency
cepstrum coefficients and cross validation tech-
nique. MAVEBA 2007: 157-160
</bodyText>
<reference confidence="0.999536236363636">
Kirrie J. Ballarrd, Ph.D., and Donald A. Robin. 2002.
Assessment of AOS for Treatment Planning, Semi-
nars in Speech and Language, 23(4): 281–291.
Witten, I.H., Frank, E. 2005. Data mining: Practical
machine learning tools and techniques, San Fran-
cisco: Morgan Kaufmann. Second edition.
Benjamini, Y., Hochberg Y. 1995. Controlling the
False Discover Rate: A Practical and Powerful
Approach to Multiple Testing, Journal of the Royal
Statistical Society. Series B (Methodological),
57(1): 289–300.
Saffran, E.M., Berndt, R.S., Schwartz, M.F. 1989. The
quantitative analysis of agrammatic production:
procedure and data, Brain and Language, 37(3):
440–79.
Blair, M., Kertesz, A., Davis-Faroque, N., Hsiung,
G.Y.R., Black, S.E., Bouchard, R.W., Gauthier, S.,
Guzman, D.A., Hogan, D.B., Rockwood, K.,
Feldman. H. 2007. Behavioural Measures in Fron-
totemporal Lobar Dementia and Other Dementias:
The Utility of the Frontal Behavioural Inventory
and the Neuropsychiatric Inventory in a National
Cohort Study, Dementia and Geriatric Cognitive
Disorder, 23: 406-15
Lopez, O. L., Swihart, A. A., Becker, J. T., Reinmuth,
O. M., Reynolds, C. F., Rezek, D. L., Daly, F. L.
1990. Reliability of NINCDS-ADRDA clinical cri-
teria for the diagnosis of Alzheimer&apos;s disease, Neu-
rology, 40: 1517
Kukull, W. A., Larson, E. B., Reifler, B. V., Lampe,
T. H., Yerby, M., Hughes, J. 1990. Interrater reli-
ability of Alzheimer&apos;s disease diagnosis, Neurolo-
gy, 40(2): 257-60
Peintner, B., Jarrold, W, Vergyri, D., Richey, C.,
Gorno Tempini, M., and Ogar, J. 2008. Learning
Diagnostic Models Using Speech and Language
Measures, 30th Annual International IEEE EMBS
Conference, August 20-24, Vancouver, British Co-
lumbia, Canada.
Jarrold, W., Javitz, H.S., Krasnow, R., Peintner, B.,
Yeh E., Swan, G.E. (2011) Depression and Self-
Focused Language in Structured Interviews with
Older Adults Psychological Reports
Oct;109(2):686-700.
Stirman, S.W., &amp; Pennebaker, J.W. (2001). Word use
in the poetry of suicidal and non-suicidal poets.
Psychosomatic Medicine 63, 517-522.
Michelle Hewlett Sanchez, Dimitra Vergyri, Luciana
Ferrer,,Colleen Richey, Pablo Garcia, Bruce
Knoth, William Jarrold: Using Prosodic and Spec-
tral Features in Detecting Depression in Elderly-
Males. INTERSPEECH 2011: 3001-3004
H. Kaymaz Keskinpala, T. Yingthawornsuk, D.
Mitchell Wilkes, Richard G. Shiavi, R. M. Salo-
mon: Distinguishing high risk suicidal subjects
</reference>
<page confidence="0.998438">
36
</page>
<sectionHeader confidence="0.766306" genericHeader="method">
Supplementary Materials
</sectionHeader>
<figureCaption confidence="0.9999545">
Figure 2. Vowel, consonant, and pause
Figure 3. Verb, adjective, pronoun, noun and function word frequencies (111, 112, 113, 114, 115)
</figureCaption>
<figure confidence="0.999587208333333">
0.40
0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00
Vowel duration Consonant duration Pause/Spurt
SD AD PNFA FTD CTRL
40%
80%
70%
60%
50%
30%
20%
10%
0%
Verbs(HT) Verbs(AT) Adjectives(HT) Adjectives(AT) Pronouns(HT) Pronouns(AT) Nouns(HT) Nouns(AT) Function
SD AD PNFA FTD CTRL
Words(HT) Words(AT)
Function
</figure>
<page confidence="0.979453">
37
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.573257">
<title confidence="0.98153">Aided Diagnosis of Dementia Type through Computer-Based Analysis of Spontaneous Speech</title>
<author confidence="0.99632">William Jarrold Bart Peintner David Wilkins</author>
<affiliation confidence="0.861445">amp; Linguistic</affiliation>
<email confidence="0.983823">william.jarrold@gmail.combpeintner@gmail.comwilkinsdavidp@gmail.com</email>
<author confidence="0.997504">Vergryi Richey Maria Luisa Gorno-Tempini Ogar</author>
<affiliation confidence="0.991825">SRI International University of California, San Francisco</affiliation>
<email confidence="0.865612">dverg@speech.sri.com,colleen.richey@sri.com</email>
<abstract confidence="0.998850518518518">This pilot study evaluates the ability of machined learned algorithms to assist with the differential diagnosis of dementia subtypes based on brief (&lt; 10 min) spontaneous speech samples. We analyzedrecordings of a brief spontaneous speech sample from 48 participants from 5 different groups: 4 types of dementia plus healthy controls. Recordings were analyzed using a speech recognition system optimized for speakerindependent spontaneous speech. Lexical and acoustic features were automatically extracted. The resulting feature profiles were used as input to a machine learning system that was trained to identify the diagnosis assigned to each research participant. Between groups lexical and acoustic differences features were detected in accordance with expectations from prior research literature suggesting that classifications were based on features consistent with human-observed symptomatology. Machine learning algorithms were able to identify participants&apos; diagnostic group with accuracy comparable to existing diagnostic methods in use today. Results suggest this clinical speech analytic approach offers promise as an additional, objective and easily obtained source of diagnostic information for clinicians.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A R Varma</author>
<author>J S Snowden</author>
<author>J J Lloyd</author>
<author>P R Talbot</author>
<author>D M A Mann</author>
<author>D Neary</author>
</authors>
<title>Evaluation of the NINCDS-ADRDA criteria in the differentiation of Alzheimer’s disease and frontotemporal dementia,</title>
<date>1999</date>
<journal>Journal of Neurology, Neurosurgery and Psychiatry,</journal>
<volume>66</volume>
<pages>184--188</pages>
<contexts>
<context position="1922" citStr="Varma et al., 1999" startWordPosition="244" endWordPosition="247">at classifications were based on features consistent with human-observed symptomatology. Machine learning algorithms were able to identify participants&apos; diagnostic group with accuracy comparable to existing diagnostic methods in use today. Results suggest this clinical speech analytic approach offers promise as an additional, objective and easily obtained source of diagnostic information for clinicians. 1 Introduction Accurately differentiating certain neurodegenerative disorders such as Alzheimer’s Disease (AD) and variants of Fronto-temporal Lobar Degeneration (FTLD) is extremely difficult (Varma et al., 1999). Differential diagnosis is often left to tertiary care settings (e.g. Research I Universities with medical schools). While the most definitive diagnosis is made post-mortem using brain tissue 1 Research conducted while at SRI International samples, the treatment and prognostic implications of living patients are often determined in large part on the basis of language assessment. Although language is clearly not the exclusive diagnostic factor for AD, existing literature suggests it is an important one. Studies show significant differences in the written language abilities of AD patients and h</context>
</contexts>
<marker>Varma, Snowden, Lloyd, Talbot, Mann, Neary, 1999</marker>
<rawString>Varma A.R., Snowden J.S., Lloyd J.J., Talbot P.R., Mann D.M.A., Neary D. 1999. Evaluation of the NINCDS-ADRDA criteria in the differentiation of Alzheimer’s disease and frontotemporal dementia, Journal of Neurology, Neurosurgery and Psychiatry, 66: 184-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Klšppel</author>
<author>C M Stonnington</author>
<author>J Barnes</author>
<author>F Chen</author>
<author>C Chu</author>
<author>C D Good</author>
<author>I Mader</author>
<author>L A Mitchell</author>
<author>A C Patel</author>
<author>C C Roberts</author>
<author>N C Fox</author>
<author>R Jr Jack</author>
<author>J Ashburner</author>
<author>Frackowiak</author>
</authors>
<title>Accuracy of dementia diagnosis: a direct comparison between radiologists and a computerized method,</title>
<date>2008</date>
<journal>Brain,</journal>
<volume>131</volume>
<issue>11</issue>
<pages>2969--2974</pages>
<marker>Klšppel, Stonnington, Barnes, Chen, Chu, Good, Mader, Mitchell, Patel, Roberts, Fox, Jack, Ashburner, Frackowiak, 2008</marker>
<rawString>Klšppel, S., Stonnington, C.M., Barnes, J., Chen, F., Chu, C., Good, C.D., Mader, I., Mitchell, L.A., Patel, A.C., Roberts, C.C., Fox, N.C., Jack, R. Jr, Ashburner, J., Frackowiak , RS. 2008. Accuracy of dementia diagnosis: a direct comparison between radiologists and a computerized method, Brain, 131(11): 2969–2974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pestell</author>
<author>M Shanks</author>
<author>J Warrington</author>
<author>A Venneri</author>
</authors>
<title>Quality of spelling breakdown in Alzheimer&apos;s disease is independent of disease progression,</title>
<date>2000</date>
<journal>Journal of Clinical and Experimental Neuropsychology,</journal>
<volume>22</volume>
<pages>599--612</pages>
<marker>Pestell, Shanks, Warrington, Venneri, 2000</marker>
<rawString>S. Pestell, M. Shanks, J. Warrington, and A. Venneri. 2000. Quality of spelling breakdown in Alzheimer&apos;s disease is independent of disease progression, Journal of Clinical and Experimental Neuropsychology, volume 22, pages 599–612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Platel</author>
<author>J Lambert</author>
<author>F Eustache</author>
<author>B Cadet</author>
<author>M Dary</author>
<author>F Viader</author>
<author>B Lechevalier</author>
</authors>
<title>Characterstics and evolution of writing impairment in Alzheimer&apos;s disease,</title>
<date>1993</date>
<journal>Journal of Clinical and Experimental Neuropsychology,</journal>
<volume>22</volume>
<pages>599--612</pages>
<contexts>
<context position="2588" citStr="Platel et al., 1993" startWordPosition="348" endWordPosition="351">iary care settings (e.g. Research I Universities with medical schools). While the most definitive diagnosis is made post-mortem using brain tissue 1 Research conducted while at SRI International samples, the treatment and prognostic implications of living patients are often determined in large part on the basis of language assessment. Although language is clearly not the exclusive diagnostic factor for AD, existing literature suggests it is an important one. Studies show significant differences in the written language abilities of AD patients and healthy older adults (Pestell et al., 2008 and Platel et al., 1993). The speech of patients with AD is partly characterized by word-finding difficulties, smaller vocabularies, and problems with semantic processing (Forbes at el., 2002). These symptoms appear early in the disease’s progression, however language assessment of AD patients can fail to identify early symptoms that family members report to be present in their conversations (Crockford and Lesser, 1994). FTLD has a prevalence similar to AD in patients under the age of 65 years (Mendez at el., 1993). Misdiagnosis of FTLD is common Mendez at el., 1993). Three variants are defined by the widely adopted </context>
</contexts>
<marker>Platel, Lambert, Eustache, Cadet, Dary, Viader, Lechevalier, 1993</marker>
<rawString>H. Platel, J. Lambert, F. Eustache, B. Cadet, M. Dary, F. Viader, and B. Lechevalier. 1993. Characterstics and evolution of writing impairment in Alzheimer&apos;s disease, Journal of Clinical and Experimental Neuropsychology, volume 22, pages 599– 612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes</author>
<author>A Venneri</author>
<author>M Shanks</author>
</authors>
<title>Distinct patterns of spontaneous speech deterioration: an early predictor of Alzheimer&apos;s disease,</title>
<date>2002</date>
<journal>Brain and Cognition,</journal>
<volume>volume</volume>
<pages>48--2</pages>
<marker>Forbes, Venneri, Shanks, 2002</marker>
<rawString>K. Forbes, A. Venneri, and M. Shanks. 2002. Distinct patterns of spontaneous speech deterioration: an early predictor of Alzheimer&apos;s disease, Brain and Cognition, volume 48(2-3): 356–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Crockford</author>
<author>R Lesser</author>
</authors>
<title>Assessing functional communication in aphasia: Clinical utility and time demands of three methods,</title>
<date>1994</date>
<journal>European Journal of Disorders of Communication,</journal>
<volume>29</volume>
<pages>165--182</pages>
<contexts>
<context position="2987" citStr="Crockford and Lesser, 1994" startWordPosition="409" endWordPosition="412">ic factor for AD, existing literature suggests it is an important one. Studies show significant differences in the written language abilities of AD patients and healthy older adults (Pestell et al., 2008 and Platel et al., 1993). The speech of patients with AD is partly characterized by word-finding difficulties, smaller vocabularies, and problems with semantic processing (Forbes at el., 2002). These symptoms appear early in the disease’s progression, however language assessment of AD patients can fail to identify early symptoms that family members report to be present in their conversations (Crockford and Lesser, 1994). FTLD has a prevalence similar to AD in patients under the age of 65 years (Mendez at el., 1993). Misdiagnosis of FTLD is common Mendez at el., 1993). Three variants are defined by the widely adopted Neary criteria (Neary at el., 1998); one with altered social conduct, the behavioral variant of frontotemporal dementia (bvFTD); the second characterized by a deterioration of conceptual-semantic knowledge, semantic dementia (SD); and the third marked by a disorder of expressive language fluency, progressive nonfluent aphasia (PNFA). Clinicians diagnose using a wide array of evidence including pa</context>
</contexts>
<marker>Crockford, Lesser, 1994</marker>
<rawString>C. Crockford and R. Lesser. 1994. Assessing functional communication in aphasia: Clinical utility and time demands of three methods, European Journal of Disorders of Communication, volume 29: 165–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Thomas</author>
<author>N Keselj</author>
<author>K Cercone</author>
<author>E Rockwood</author>
</authors>
<title>Automatic detection and rating of dementia of Alzheimer type through lexical analysis of spontaneous speech,</title>
<date>2005</date>
<booktitle>IEEE International Conference on Mechatronics and Automation.</booktitle>
<marker>Thomas, Keselj, Cercone, Rockwood, 2005</marker>
<rawString>Thomas, V., Keselj, N., Cercone, K., Rockwood, E. 2005. Automatic detection and rating of dementia of Alzheimer type through lexical analysis of spontaneous speech, IEEE International Conference on Mechatronics and Automation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Mendez</author>
<author>A Selwood</author>
<author>A R Mastri</author>
<author>W H Frey</author>
</authors>
<title>2nd, Pick&apos;s disease versus Alzheimer&apos;s disease: A comparison of clinical characteristics,</title>
<date>1993</date>
<journal>Neurology,</journal>
<volume>43</volume>
<issue>2</issue>
<pages>289--92</pages>
<marker>Mendez, Selwood, Mastri, Frey, 1993</marker>
<rawString>Mendez, M.F., Selwood, A., Mastri, A.R., Frey, W.H. 1993. 2nd, Pick&apos;s disease versus Alzheimer&apos;s disease: A comparison of clinical characteristics, Neurology, 43(2): 289–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Neary</author>
<author>J S Snowden</author>
<author>L Gustafson</author>
<author>U Passant</author>
<author>D Stuss</author>
<author>S Black</author>
<author>M Freedman</author>
<author>A Kertesz</author>
<author>H Robert</author>
<author>M Albert</author>
<author>K Boone</author>
<author>B L Miller</author>
<author>J Cummings</author>
<author>D F Benson</author>
</authors>
<title>Frontotemporal lobar degeneration: A consensus on clinical diagnostic criteria,</title>
<date>1998</date>
<journal>Neurology,</journal>
<volume>51</volume>
<issue>6</issue>
<pages>1546--54</pages>
<contexts>
<context position="17707" citStr="Neary et al., 1998" startWordPosition="2686" endWordPosition="2689"> say “He is flying that.” (Grossman and Ash, 2004). In PNFA, one sees fewer verbs (H4) (Grossman and Ash, 2004). In addition, PNFA patients often exhibit agrammatism. Such speech is simplified and ungrammatical and involves fewer function words, for example “give cupcake” or “water now”. Thus (H5) is that the speech of patients with PNFA will have fewer function words (H5) (Saffran at el., 1989). These hypotheses, along with whether each was supported by our analyses, are listed in Table 2 in Results. The first acoustic hypothesis about acoustic features (H6) is related to the Neary criteria (Neary et al., 1998), which notes that PNFA is characterized by non-fluent spontaneous speech (among other required features). Additionally, patients in this group have significant apraxia of speech (Gorno-Tempini at el., 2004). Signs of this condition difficulty include articulatory groping – i.e. where the mouth searches for the correct configurations. Such trial and error speech often sounds “robotic” and can involve sounds that may be held out longer. Thus, given the duration features that are generally associated with apraxia of speech (Samuel at el., 1996; Edythe at el., 1996; Ballard and Robin, 2002), we h</context>
</contexts>
<marker>Neary, Snowden, Gustafson, Passant, Stuss, Black, Freedman, Kertesz, Robert, Albert, Boone, Miller, Cummings, Benson, 1998</marker>
<rawString>Neary, D., Snowden, J.S., Gustafson, L., Passant, U., Stuss, D., Black, S., Freedman, M., Kertesz, A., Robert, H., Albert, M., Boone, K., Miller, B.L., Cummings, J., Benson, D.F. 1998. Frontotemporal lobar degeneration: A consensus on clinical diagnostic criteria, Neurology, 51(6): 1546–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R R Davies</author>
<author>J R Hodges</author>
<author>J J Kril</author>
</authors>
<title>The pathological basis of semantic dementia.</title>
<date>2005</date>
<journal>Brain,</journal>
<volume>128</volume>
<issue>9</issue>
<pages>1984--95</pages>
<marker>Davies, Hodges, Kril, 2005</marker>
<rawString>Davies, R.R., Hodges, J.R., Kril, J.J., et al. 2005. The pathological basis of semantic dementia. Brain, 128(9): 1984–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Josephs</author>
<author>J R Duffy</author>
<author>E A Strand</author>
</authors>
<title>Clinicopathological and imaging correlates of progressive aphasia and apraxia of speech.</title>
<date>2006</date>
<journal>Brain,</journal>
<volume>129</volume>
<issue>6</issue>
<pages>1385--98</pages>
<marker>Josephs, Duffy, Strand, 2006</marker>
<rawString>Josephs, K.A., Duffy, J.R., Strand, E.A., et al. 2006. Clinicopathological and imaging correlates of progressive aphasia and apraxia of speech. Brain, 129(6): 1385–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bright</author>
<author>H E Moss</author>
<author>E A Stamatakis</author>
<author>L K Tyler</author>
</authors>
<title>Longitudinal studies of semantic dementia: The relationship between structural and functional changes over time,</title>
<date>2008</date>
<journal>Neuropsychologia,</journal>
<volume>46</volume>
<pages>2177--2188</pages>
<marker>Bright, Moss, Stamatakis, Tyler, 2008</marker>
<rawString>Bright, P., Moss, H. E., Stamatakis, E. A., &amp; Tyler, L. K. 2008. Longitudinal studies of semantic dementia: The relationship between structural and functional changes over time, Neuropsychologia, 46: 2177-2188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Singh</author>
<author>R Bucks</author>
<author>J Cuerden</author>
</authors>
<title>Evaluation of an objective technique for analysing temporal variables in DAT spontaneous speech, Aphasiology,</title>
<date>2001</date>
<volume>15</volume>
<issue>6</issue>
<pages>571--584</pages>
<marker>Singh, Bucks, Cuerden, 2001</marker>
<rawString>S. Singh, R. Bucks, and J. Cuerden. 2001. Evaluation of an objective technique for analysing temporal variables in DAT spontaneous speech, Aphasiology, volume 15(6): 571–584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefanie Abel</author>
<author>Walter Huber</author>
<author>Gary S Dell</author>
</authors>
<title>Connectionist diagnosis of lexical disorders in aphasia, Aphasiology,</title>
<date>2009</date>
<volume>23</volume>
<contexts>
<context position="5290" citStr="Abel et al. (2009)" startWordPosition="762" endWordPosition="765">tly in the differential diagnosis of AD, FTLD and its three subtypes. For this reason, computerized analysis of speech may offer an important aid to the clinical diagnosis of these syndromes. Prior work in clinical speech analytics supports the possibility of computer-based diagnosis of dementia related syndromes. Singh (2001) describes a means of quantifying the degree of speech deficits derived from human transcriptions of the speech of patient with AD. Machine Learning has already been applied to distinguish AD from controls using human transcribed spontaneous speech (Thomas at el., 2005). Abel et al. (2009) applied a connectionist net that models patient speech errors (naming and repetition disorders) to the problem of diagnosis. Tur et al. (2010) have shown the ability to automatically score patient speech from a story recall and picture description task that is on par with human performance. Lehr et al. (2012) have developed a system that automatically transcribes and scores patient speech obtained during the story recall portion of the Wechsler Logical Memory test. The evaluation demonstrated it could distinguish mild cognition impairment from typical controls at performance level comparable </context>
</contexts>
<marker>Abel, Huber, Dell, 2009</marker>
<rawString>Stefanie Abel, Walter Huber, Gary S. Dell. 2009. Connectionist diagnosis of lexical disorders in aphasia, Aphasiology, volume 23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dilek Hakkani-Tür</author>
</authors>
<title>Dimitra Vergyri, Gškhan Tür.</title>
<date>2010</date>
<pages>258--261</pages>
<marker>Hakkani-Tür, 2010</marker>
<rawString>Dilek Hakkani-Tür, Dimitra Vergyri, Gškhan Tür. 2010. Speech-based automated cognitive status assessment. Interspeech 2010: pages 258-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maider Lehr</author>
<author>Emily T Prud’hommeaux</author>
<author>Izhak Shafran</author>
<author>Brian Roark</author>
</authors>
<title>Fully Automated Neuropsychological Assessment for Detecting Mild Cognitive Impairment.</title>
<date>2012</date>
<booktitle>In Proceedings of Interspeech.</booktitle>
<marker>Lehr, Prud’hommeaux, Shafran, Roark, 2012</marker>
<rawString>Maider Lehr, Emily T. Prud’hommeaux, Izhak Shafran and Brian Roark. 2012. Fully Automated Neuropsychological Assessment for Detecting Mild Cognitive Impairment. In Proceedings of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kertesz</author>
</authors>
<title>Western Aphasia Battery,</title>
<date>1980</date>
<publisher>Press.</publisher>
<institution>University of Western Ontario</institution>
<location>London, Ontario:</location>
<contexts>
<context position="9417" citStr="Kertesz, 1980" startWordPosition="1375" endWordPosition="1376">s explained in Sects 2.3 and 2.6. Each machine learning algorithm produces a classification model based on labeled training data. All models used both acoustic and lexical features. Each such disease identifying model is evaluated against held-out training data (not shown). To measure sensitivity to ASR error, half of these models were based on lexical features derived from automatic transcription (AT), the other half from human transcription (HT). ternational and were paid $10 for their participation. 2.2 Speech Samples Speech samples were recordings of Part 1 of the Western Aphasia Battery (Kertesz, 1980). Participants are administered a semi-structured interview (e.g., questions such as “How are you?”) and asked to describe a drawn picture of a picnic scene. The resulting 3 to 5 minutes of speech was recorded via wireless lapel microphones. Controls were recorded via digital audio recorder sampling at 48 kHz, 16 bit PCM, and later downsampled to 16 kHz for use with the speech recognizer. Digital audio was down-sampled at 16 kHz, 16 bit PCM. Recordings were manually segmented in order to separate the interviewee’s voice from the interviewer’s. Only patient speech segments were subject to analy</context>
</contexts>
<marker>Kertesz, 1980</marker>
<rawString>Kertesz, A. 1980. Western Aphasia Battery, London, Ontario: University of Western Ontario Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Janin</author>
<author>M Magimai-Doss</author>
<author>C Wooters</author>
<author>J Zheng</author>
</authors>
<title>meeting and lecture recognition system,</title>
<date>2007</date>
<booktitle>Proc. NIST</booktitle>
<publisher>The SRI-ICSI Spring</publisher>
<marker>Janin, Magimai-Doss, Wooters, Zheng, 2007</marker>
<rawString>Stolcke, A., Boakye, K., Cetin, ...., Janin, A., Magimai-Doss, M., Wooters, C., Zheng, J. 2007. The SRI-ICSI Spring 2007 meeting and lecture recognition system, Proc. NIST 2007 Rich Transcription Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Pennebaker</author>
<author>M E Francis</author>
<author>R J Booth</author>
</authors>
<date>2001</date>
<booktitle>Linguistic Inquiry and Word Count (LIWC): LIWC2001,</booktitle>
<publisher>Erlbaum Publishers.</publisher>
<location>Mahwah, NJ:</location>
<contexts>
<context position="13900" citStr="Pennebaker, et al 2001" startWordPosition="2075" endWordPosition="2078"> stop, etc. É) voicing features (voiced, voiceless) and measured the mean and standard deviation of the duration of these classes. Our Automatic Speech Analysis system produced 41 different duration-based measures extracted from the speech stream. 2.5 Lexical Feature Extraction (LFE) For each transcript we performed two types of computer-based lexical analysis. The first determined frequencies of 14 different parts of speech (e.g. nouns, verbs, pronouns etc.) using an automatic part-of-speech (POS) tagger. The second involved Dr. Pennebaker’s Linguistic Inquiry and Word Count (LIWC) software (Pennebaker, et al 2001), which determines word frequencies organized into 81 categories, such as psychological processes (e.g., emotional or cognitive) and linguistic dimensions (e.g. function words, verb tenses, negations). To measure sensitivity to speech to text error, each ANOVA was performed twice, once for the “ground truth” human transcriptions (HT) and once for the automatic transcriptions (AT). During hypothesis testing, statistical significance of each pair of AT versus HT based LFEs (i.e., “ground truth”) was compared. Additionally different models were learned, half using HT the other half using AT. To t</context>
</contexts>
<marker>Pennebaker, Francis, Booth, 2001</marker>
<rawString>Pennebaker, J.W., Francis, M.E., Booth, R.J. 2001. Linguistic Inquiry and Word Count (LIWC): LIWC2001, Mahwah, NJ: Erlbaum Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network,</title>
<date>2003</date>
<booktitle>in Proceedings of HLT-NAACL</booktitle>
<pages>252--259</pages>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Toutanova, K., Klein, D., Manning, C., Singer, Y. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network, in Proceedings of HLT-NAACL 2003, pages 252–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Grossman</author>
<author>S Ash</author>
</authors>
<title>Primary Progressive Aphasia:</title>
<date>2004</date>
<journal>A Review, Neurocase,</journal>
<volume>10</volume>
<issue>1</issue>
<pages>3--18</pages>
<contexts>
<context position="17138" citStr="Grossman and Ash, 2004" startWordPosition="2588" endWordPosition="2591">these hypotheses. The hypotheses about the lexical features are as follows. First, based on (Forbes at el., 2002) we predicted that AD patients use more pronouns, verbs, and adjectives and fewer nouns than controls (H1). In SD, one sees decreased lexical access to concrete concepts, so patients tend to use fewer nouns (H2). To compensate for such difficulties with word retrieval, they also use more pronouns (H3). This gives the impression of empty or circumlocutory speech. For example, rather than saying “The boy is flying a kite,” a SD patient would be more prone to say “He is flying that.” (Grossman and Ash, 2004). In PNFA, one sees fewer verbs (H4) (Grossman and Ash, 2004). In addition, PNFA patients often exhibit agrammatism. Such speech is simplified and ungrammatical and involves fewer function words, for example “give cupcake” or “water now”. Thus (H5) is that the speech of patients with PNFA will have fewer function words (H5) (Saffran at el., 1989). These hypotheses, along with whether each was supported by our analyses, are listed in Table 2 in Results. The first acoustic hypothesis about acoustic features (H6) is related to the Neary criteria (Neary et al., 1998), which notes that PNFA is char</context>
<context position="19056" citStr="Grossman and Ash, 2004" startWordPosition="2904" endWordPosition="2907">acoustic feature hypothesis (H7) is based on the fact that in the Neary criteria (Neary at el., 1998) pressured speech is a supportive (but not a core) diagnostic feature of both SD and bvFTD. In pressured speech one sees rapid Figures (see Supported in Supported in LFE Hypothesis and source LFE of HT? or AFE of AT? Supplementary Materials) H1. AD patients use more Yes, but only Yes, significant for Figure 3 pronouns, verbs, and adjectives significant for nouns, pronouns, and fewer nouns than controls nouns and adjectives (Forbes at el., 2002) H2. SD patients use fewer nouns Yes Yes, but not (Grossman and Ash, 2004) significant vs PNFA Figure 3 H3. SD patients use more Partial: SD sig. &gt; pronouns (Grossman and Ash, Yes Figure 3 2004) CNTRL only H4. Lower verb frequency in Yes, but only PNFA (Grossman and Ash, 2004) No Figure 3 significant vs. SD H5. Fewer function words in Yes, but only Yes significant vs SD Figure 3 PNFA (Saffran at el., 1989) H6. PNFA patients would exhibit longer vowel and consonant N/A Yes Figure 2 durations H7. SD and bvFTD patients have N/A Yes Figure 2 shorter pauses than controls. Table 2. Hypotheses extracted from literature and whether our measures—based on human transcripts (H</context>
</contexts>
<marker>Grossman, Ash, 2004</marker>
<rawString>Grossman, M., Ash, S. 2004. Primary Progressive Aphasia: A Review, Neurocase, 10(1): 3–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M L Gorno-Tempini</author>
<author>N F Dronkers</author>
<author>K P Rankin</author>
<author>J M Ogar</author>
<author>La Phengrasamy</author>
<author>B A Rosen</author>
<author>H J Johnson</author>
<author>J K Weiner</author>
<author>M W Miller</author>
<author>B L</author>
</authors>
<title>Cognition and Anatomy in three variants of primary progressive aphasia, Annals of Neurology,</title>
<date>2004</date>
<volume>55</volume>
<pages>335--346</pages>
<marker>Gorno-Tempini, Dronkers, Rankin, Ogar, Phengrasamy, Rosen, Johnson, Weiner, Miller, L, 2004</marker>
<rawString>Gorno-Tempini, M.L, Dronkers, N.F., Rankin, K.P., Ogar, J.M., La Phengrasamy, B.A., Rosen, H.J., Johnson, J.K., Weiner, M.W., Miller, B.L, Cognition and Anatomy in three variants of primary progressive aphasia, Annals of Neurology, 2004. 55: 335–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel A K Seddoh</author>
<author>Donald A Robin</author>
<author>Hyun-Sub Sim</author>
<author>Carlin Hageman</author>
<author>Jerald B Moon</author>
<author>John W Folkins</author>
</authors>
<title>Speech Timing in Apraxia of Speech versus Conduction Aphasia,</title>
<date>1996</date>
<journal>Journal of Speech and Hearing Research,</journal>
<volume>39</volume>
<pages>590--603</pages>
<marker>Seddoh, Robin, Sim, Hageman, Moon, Folkins, 1996</marker>
<rawString>Samuel A. K. Seddoh, Donald A. Robin, Hyun-Sub Sim, Carlin Hageman, Jerald B. Moon, John W. Folkins. 1996. Speech Timing in Apraxia of Speech versus Conduction Aphasia, Journal of Speech and Hearing Research, 39: 590–603.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edythe A Strand</author>
<author>E A McNeil</author>
<author>M R</author>
</authors>
<title>Effects of Length and Linguistic Complexity on Temporal Acoustic Measures in Apraxia of Speech,</title>
<date>1996</date>
<journal>Journal of Speech and Hearing Research,</journal>
<volume>39</volume>
<pages>1018--33</pages>
<marker>Strand, McNeil, R, 1996</marker>
<rawString>Edythe A. Strand, E.A., McNeil, M.R. 1996. Effects of Length and Linguistic Complexity on Temporal Acoustic Measures in Apraxia of Speech, Journal of Speech and Hearing Research, 39: 1018–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kirrie J Ballarrd</author>
<author>Donald A Robin</author>
</authors>
<date>2002</date>
<booktitle>Assessment of AOS for Treatment Planning, Seminars in Speech and Language,</booktitle>
<volume>23</volume>
<issue>4</issue>
<pages>281--291</pages>
<marker>Ballarrd, Robin, 2002</marker>
<rawString>Kirrie J. Ballarrd, Ph.D., and Donald A. Robin. 2002. Assessment of AOS for Treatment Planning, Seminars in Speech and Language, 23(4): 281–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data mining: Practical machine learning tools and techniques,</title>
<date>2005</date>
<publisher>Morgan Kaufmann.</publisher>
<location>San Francisco:</location>
<note>Second edition.</note>
<contexts>
<context position="16110" citStr="Witten and Frank, 2005" startWordPosition="2415" endWordPosition="2418">uracy being the average performance on the test subjects, across all five folds. We applied three learning methods, (1) logistic regression, a statistical learning technique for determining categorical outcomes, (2) Multi-Layered Perceptrons, an artificial intelligence (AI) learning method that roughly mimics biological neural networks, and (3) decision trees, another AI technique which induces sets of rules used to predict outcomes. All three are commonly used machine learning techniques, and for this study we used implementations available in Weka, an off-the-shelf machine learning toolkit (Witten and Frank, 2005). 2.7 Hypotheses Machine learned classification models can be difficult to understand and often used merely as black boxes. To address this issue, we tried to 30 draw a meaningful link between certain features and diagnosis. In particular, we formed and tested several hypotheses based on expectations derived from clinical literature. We used all the data (rather than one of the training folds) to test these hypotheses. The hypotheses about the lexical features are as follows. First, based on (Forbes at el., 2002) we predicted that AD patients use more pronouns, verbs, and adjectives and fewer </context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Witten, I.H., Frank, E. 2005. Data mining: Practical machine learning tools and techniques, San Francisco: Morgan Kaufmann. Second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Benjamini</author>
<author>Y Hochberg</author>
</authors>
<title>Controlling the False Discover Rate: A Practical and Powerful Approach to Multiple Testing,</title>
<date>1995</date>
<journal>Journal of the Royal Statistical Society. Series B (Methodological),</journal>
<volume>57</volume>
<issue>1</issue>
<pages>289--300</pages>
<contexts>
<context position="21262" citStr="Benjamini and Hochberg, 1995" startWordPosition="3245" endWordPosition="3248">s do exhibit significantly longer vowel and consonant durations, as the literature linking PNFA with apraxia of speech would predict. Furthermore, SD and bvFTD patients have significantly shorter pauses than controls, which is consistent with the hypothesis that some patients with these diagnoses exhibit press of speech. 3.2 Results: Lexical-Level Hypotheses There were several lexical-level differences between diagnostic groups. We checked for significant differences (hereafter, “significant features”) with respect to diagnosis while using the Benjamini-Hochberg test for multiple comparisons (Benjamini and Hochberg, 1995). (We use this adjustment for all multiple comparisons). There were several more lexical level differences based on the HTs than one would predict by chance. For example, 11 of the 14 POS features were significant (p ≤ .05) including verbs, nouns, adjectives and adverbs. For LIWC features, 22 of 81 features were statistically significant at the p (A) (B) (C) (D) FTLD vs AD vs SD FTLD vs AD AD vs Controls AD vs vs PNFA Controls vs bvFTD vs Control 1. Random diagnosis 33% 20% 50% 50% 2. Naïve learner (always picks 63% 27% 77% 50% largest class in training set) 3. Our method 80% 61% 88% 88% Sens/</context>
</contexts>
<marker>Benjamini, Hochberg, 1995</marker>
<rawString>Benjamini, Y., Hochberg Y. 1995. Controlling the False Discover Rate: A Practical and Powerful Approach to Multiple Testing, Journal of the Royal Statistical Society. Series B (Methodological), 57(1): 289–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Saffran</author>
<author>R S Berndt</author>
<author>M F Schwartz</author>
</authors>
<title>The quantitative analysis of agrammatic production: procedure and data,</title>
<date>1989</date>
<journal>Brain and Language,</journal>
<volume>37</volume>
<issue>3</issue>
<pages>440--79</pages>
<marker>Saffran, Berndt, Schwartz, 1989</marker>
<rawString>Saffran, E.M., Berndt, R.S., Schwartz, M.F. 1989. The quantitative analysis of agrammatic production: procedure and data, Brain and Language, 37(3): 440–79.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H</author>
</authors>
<date>2007</date>
<booktitle>Behavioural Measures in Frontotemporal Lobar Dementia and Other Dementias: The Utility of the Frontal Behavioural Inventory and the Neuropsychiatric Inventory in a National Cohort Study, Dementia and Geriatric Cognitive Disorder,</booktitle>
<volume>23</volume>
<pages>406--15</pages>
<marker>H, 2007</marker>
<rawString>Blair, M., Kertesz, A., Davis-Faroque, N., Hsiung, G.Y.R., Black, S.E., Bouchard, R.W., Gauthier, S., Guzman, D.A., Hogan, D.B., Rockwood, K., Feldman. H. 2007. Behavioural Measures in Frontotemporal Lobar Dementia and Other Dementias: The Utility of the Frontal Behavioural Inventory and the Neuropsychiatric Inventory in a National Cohort Study, Dementia and Geriatric Cognitive Disorder, 23: 406-15</rawString>
</citation>
<citation valid="true">
<authors>
<author>O L Lopez</author>
<author>A A Swihart</author>
<author>J T Becker</author>
<author>O M Reinmuth</author>
<author>C F Reynolds</author>
<author>D L Rezek</author>
<author>F L Daly</author>
</authors>
<title>Reliability of NINCDS-ADRDA clinical criteria for the diagnosis of Alzheimer&apos;s disease,</title>
<date>1990</date>
<journal>Neurology,</journal>
<volume>40</volume>
<pages>1517</pages>
<marker>Lopez, Swihart, Becker, Reinmuth, Reynolds, Rezek, Daly, 1990</marker>
<rawString>Lopez, O. L., Swihart, A. A., Becker, J. T., Reinmuth, O. M., Reynolds, C. F., Rezek, D. L., Daly, F. L. 1990. Reliability of NINCDS-ADRDA clinical criteria for the diagnosis of Alzheimer&apos;s disease, Neurology, 40: 1517</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Kukull</author>
<author>E B Larson</author>
<author>B V Reifler</author>
<author>T H Lampe</author>
<author>M Yerby</author>
<author>J Hughes</author>
</authors>
<title>Interrater reliability of Alzheimer&apos;s disease diagnosis,</title>
<date>1990</date>
<journal>Neurology,</journal>
<volume>40</volume>
<issue>2</issue>
<pages>257--60</pages>
<marker>Kukull, Larson, Reifler, Lampe, Yerby, Hughes, 1990</marker>
<rawString>Kukull, W. A., Larson, E. B., Reifler, B. V., Lampe, T. H., Yerby, M., Hughes, J. 1990. Interrater reliability of Alzheimer&apos;s disease diagnosis, Neurology, 40(2): 257-60</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Peintner</author>
<author>W Jarrold</author>
<author>D Vergyri</author>
<author>C Richey</author>
<author>Gorno Tempini</author>
<author>M</author>
<author>J Ogar</author>
</authors>
<title>Learning Diagnostic Models Using Speech and Language Measures,</title>
<date>2008</date>
<booktitle>30th Annual International IEEE EMBS Conference,</booktitle>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="24544" citStr="Peintner et al (2008)" startWordPosition="3792" endWordPosition="3795">see Table 3 Row 2) which always chooses the most frequent (i.e., modal) diagnosis found in the training sample. The row labeled “Our method” corresponds to the accuracy of models generated from lexical and acoustic features using AT. For this case, HT results differs from AT in accuracy by only 2-3% for all prediction problems. Note that our method is at least equal to the accuracies, sensitivities, specificities, and kappa’s of the other clinical benchmarks in most cases. See Table 4, which shows the performance on distinguishing FTLD subtypes. For more detail on machine learning results see Peintner et al (2008). 4 DISCUSSION The accuracy of the best machine learned diagnostic model was 88% in the binary classifications of AD versus FTLD, and AD versus Controls (Table 3). Acoustic and lexical level differences are detectable despite the present level of ASA inaccuracy. Although diagnosis should never be made on the basis of one source of information, our pilot data show that automatic computer-based analyses of spontaneous speech show promise as diagnostic aids by detecting the at times subtle differences that characterize these neurodegenerative disorders. Inferences drawn from these results are sub</context>
</contexts>
<marker>Peintner, Jarrold, Vergyri, Richey, Tempini, M, Ogar, 2008</marker>
<rawString>Peintner, B., Jarrold, W, Vergyri, D., Richey, C., Gorno Tempini, M., and Ogar, J. 2008. Learning Diagnostic Models Using Speech and Language Measures, 30th Annual International IEEE EMBS Conference, August 20-24, Vancouver, British Columbia, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Jarrold</author>
<author>H S Javitz</author>
<author>R Krasnow</author>
<author>B Peintner</author>
<author>E Yeh</author>
<author>G E Swan</author>
</authors>
<title>Depression and SelfFocused Language in Structured Interviews with Older Adults Psychological Reports Oct;109(2):686-700.</title>
<date>2011</date>
<marker>Jarrold, Javitz, Krasnow, Peintner, Yeh, Swan, 2011</marker>
<rawString>Jarrold, W., Javitz, H.S., Krasnow, R., Peintner, B., Yeh E., Swan, G.E. (2011) Depression and SelfFocused Language in Structured Interviews with Older Adults Psychological Reports Oct;109(2):686-700.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S W Stirman</author>
<author>J W Pennebaker</author>
</authors>
<title>Word use in the poetry of suicidal and non-suicidal poets.</title>
<date>2001</date>
<journal>Psychosomatic Medicine</journal>
<volume>63</volume>
<pages>517--522</pages>
<marker>Stirman, Pennebaker, 2001</marker>
<rawString>Stirman, S.W., &amp; Pennebaker, J.W. (2001). Word use in the poetry of suicidal and non-suicidal poets. Psychosomatic Medicine 63, 517-522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michelle Hewlett Sanchez</author>
<author>Dimitra Vergyri</author>
<author>Luciana Ferrer</author>
</authors>
<title>William Jarrold: Using Prosodic and Spectral Features in Detecting Depression in ElderlyMales. INTERSPEECH</title>
<date>2011</date>
<pages>3001--3004</pages>
<contexts>
<context position="28174" citStr="Sanchez et al (2011)" startWordPosition="4380" endWordPosition="4383"> higher accuracy and finer discrimination amongst and within diagnostic types. It also suggests that this can be accomplished without training the system to the voice of each subject. The results also draw significance because the overall approach may be applied to other neurological or psychological disorders. Many such disorders have characteristic lexical or acoustic profiles. For example, Jarrold (2011) and Stirman et al (2001) have shown that depression is associated with high frequencies of first person words (I, me, I’ve) and lower frequencies of social and second person words (us,we). Sanchez et al (2011) and Keskinpala (2007) have shown acoustic prosodic features indicative of depression or suicide risk. Our results suggest a very similar study design can be applied to detect these kinds of depression related lexical and acoustic/prosodic profiles. Our results suggest we may be able train the models to assess specific highly diagnostic language symptoms – such as fluency, circumlocution, and apraxia of speech. This can be particularly important where the inter-rater reliability of given symptoms is poor. We believe that poor inter-rater reliability is mainly caused by the inability to precise</context>
</contexts>
<marker>Sanchez, Vergyri, Ferrer, 2011</marker>
<rawString>Michelle Hewlett Sanchez, Dimitra Vergyri, Luciana Ferrer,,Colleen Richey, Pablo Garcia, Bruce Knoth, William Jarrold: Using Prosodic and Spectral Features in Detecting Depression in ElderlyMales. INTERSPEECH 2011: 3001-3004</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Kaymaz Keskinpala</author>
<author>T Yingthawornsuk</author>
<author>D Mitchell Wilkes</author>
<author>Richard G Shiavi</author>
<author>R M Salomon</author>
</authors>
<title>Distinguishing high risk suicidal subjects</title>
<marker>Keskinpala, Yingthawornsuk, Wilkes, Shiavi, Salomon, </marker>
<rawString>H. Kaymaz Keskinpala, T. Yingthawornsuk, D. Mitchell Wilkes, Richard G. Shiavi, R. M. Salomon: Distinguishing high risk suicidal subjects</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>