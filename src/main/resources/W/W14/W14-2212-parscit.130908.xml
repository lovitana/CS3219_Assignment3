<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.276407">
<title confidence="0.98454">
Short-term projects, long-term benefits:
Four student NLP projects for low-resource languages
</title>
<author confidence="0.985407">
Alexis Palmer and Michaela Regneri
</author>
<affiliation confidence="0.9970345">
Department of Computational Linguistics
Saarland University
</affiliation>
<address confidence="0.63048">
Saarbr¨ucken, Germany
</address>
<email confidence="0.998581">
{apalmer,regneri}@coli.uni-saarland.de
</email>
<sectionHeader confidence="0.997385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99986280952381">
This paper describes a local effort to
bridge the gap between computational and
documentary linguistics by teaching stu-
dents and young researchers in computa-
tional linguistics about doing research and
developing systems for low-resource lan-
guages. We describe four student software
projects developed within one semester.
The projects range from a front-end for
building small-vocabulary speech recogni-
tion systems, to a broad-coverage (more
than 1000 languages) language identifi-
cation system, to language-specific sys-
tems: a lemmatizer for the Mayan lan-
guage Uspanteko and named entity recog-
nition systems for both Slovak and Per-
sian. Teaching efforts such as these are an
excellent way to develop not only tools for
low-resource languages, but also computa-
tional linguists well-equipped to work on
endangered and low-resource languages.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977369565217">
There is a strong argument to be made for bring-
ing together computational and documentary lin-
guistics in order to support the documentation and
description of endangered languages (Abney and
Bird, 2010; Bird, 2009). Documentation, de-
scription, and revitalization work for endangered
languages, as well as efforts to produce digi-
tal and machine-readable resources for languages
currently lacking such data, benefit from techno-
logical support in many different ways. Here we
focus on support via (a) tools facilitating more effi-
cient development of resources, with easy learning
curves, and (b) linguistic analysis tools.
Various meetings and workshops in recent years
have helped to bring the two fields closer to-
gether, but a sizeable gap remains. We’ve come
far enough to, for example, have a relevant work-
shop at a major computational linguistics confer-
ence, but not so far that issues around language en-
dangerment are well-known to even a large subset
of the computational linguistics community. One
way to get computational linguists thinking about
issues related to endangered languages is for them
to get their hands dirty – to work directly on re-
lated projects. In this paper we describe our own
local effort to bridge this gap: a course for Mas-
ter’s and Bachelor’s students in computational lin-
guistics in which small teams of students each pro-
duced working, non-trivial natural language pro-
cessing (NLP) tools for low-resource languages
(LRLs) over the span of a single semester. The
individual projects are described in Section 3.
Such a course benefits the students in a num-
ber of ways. They get hands-on experience in
system building, they learn about a new subfield
within computational linguistics, with a different
set of concerns (some of these are discussed in
Section 2), and, in some cases, they get the op-
portunity to develop tools for their own native lan-
guages. From the perspective of computational
work on endangered languages, the positive out-
comes are not only a new set of NLP tools, but
also a group of students and young researchers
armed with experience working on low-resource
languages and better equipped to take on similar
projects in the future.
</bodyText>
<sectionHeader confidence="0.946414" genericHeader="method">
2 Teaching NLP for LRLs
</sectionHeader>
<bodyText confidence="0.999426111111111">
Working on LRLs from a computational perspec-
tive requires training beyond the typical compu-
tational linguistics curriculum. It is not the case
that the most widely-used methods from computa-
tional linguistics can be straightforwardly adapted
for any arbitrarily-selected language. Thus an im-
portant part of our teaching agenda in this context
is to familiarize students with the challenges inher-
ent to NLP for LRLs as well as some of the main
</bodyText>
<page confidence="0.95219">
86
</page>
<bodyText confidence="0.996147154929578">
Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 86–90,
Baltimore, Maryland, USA, 26 June 2014. c�2014 Association for Computational Linguistics
approaches for addressing these same challenges.
This section briefly surveys some of the relevant
issues, with pointers to representative studies.
The first and most obvious concern is data spar-
sity. Many of the most successful and widely-
taught methods and models in computational lin-
guistics rely on either large amounts of labeled
data or massive amounts of unlabeled data. Meth-
ods and models explicitly addressing LRLs need
to maximize the utility of available data. Ap-
proaches for addressing data sparsity range from
data collection proposals (Abney and Bird, 2010)
to leveraging high-resource languages (Xia and
Lewis, 2007) to maximizing annotation effort
(Garrette and Baldridge, 2013). A second con-
cern is model suitability. Many existing models
in computational linguistics implicitly encode or
expect characteristics of high-resource languages
(Bender, 2011); for example, much work on com-
putational syntax uses models that exploit linear
ordering of elements in utterances. Such models
are not straightforwardly applicable for languages
with free or flexible word order, nor for highly
agglutinative languages where, for example, com-
plete utterances are encoded as single words. Ap-
proaches to this issues include adaptation of mod-
els using linguistic knowledge and/or universals
(Boonkwan and Steedman, 2011; Naseem et al.,
2010). The third issue to note is the difficulty
of evaluation. The output of systems or tools
performing automated analysis are predictions of
analyses for new data; these predictions must
be evaluated against a ground truth or human-
supplied analysis of the same data. Evaluation
is difficult in the low-resource setting, both be-
cause of limited availability of expert-labeled data
and because, in some cases, the ground truth
isn’t known, or analyses are shifting as knowledge
about the language develops.
We began the course with a discussion of these
issues, as well as an introduction to a range of ex-
isting tools, projects and resources. We did not
explicitly teach programming skills in the course,
but we also did not require extensive program-
ming background. Rather, we aimed to balance
the teams such that each contained a mix of back-
grounds: a bit more than half of the students
had previous experience with software develop-
ment, and the rest had at least taken one intro-
ductory programming course. The projects were
scoped such that there were clear ways for stu-
dents without programming experience to con-
tribute. For example, in some cases, students with
extensive background in linguistics performed lin-
guistic analysis of the data which informed the de-
sign of the system.
Evaluation of students was designed to empha-
size three objectives: production of a working sys-
tem, communication of challenges faced and so-
lutions to those challenges, and personal devel-
opment of professionally-relevant skills. Students
were graded on their weekly progress (more detail
in Section 3), one 15-20 minute talk per student,
individual written reports detailing specific contri-
butions to the project, and a conference-style end-
of-semester poster and demo session. Systems
were required to be working and demonstratable
both at the midway point of the semester (as a sim-
plified prototype) and at the end of the semester.
</bodyText>
<sectionHeader confidence="0.97874" genericHeader="method">
3 Four projects in four months
</sectionHeader>
<bodyText confidence="0.9999921">
The course described here (“NLP tools for Low-
Resource Languages”) was offered as part of the
regular curriculum for undergraduate and gradu-
ate students in the Computational Linguistics de-
partment at Saarland University. We started with
10 students and formed four teams (based on pref-
erences for general topics and programming lan-
guages). The teams could choose their own project
or select from a set of proposed topics.
During the teaching period, we regularly moni-
tored the student’s progress by using some meth-
ods of agile software development.1 For each
weekly meeting, each team had to set three goals
which constituted their homework. Goals could be
minor tasks (fixing a certain bug), bigger chunks
(choosing and implementing a strategy for data
standardization) or course requirements (prepar-
ing a talk). Not fulfilling a (project-related) goal
was acceptable, but students had to analyze why
they missed the goal and to learn from the experi-
ence. They were expected over the course of the
semester to become better both at setting reach-
able goals and at estimating how long they would
need to meet each goal. Under this obligation to
make continuous, weekly progress, each team had
a working system within three months. At the end
of month four, systems were suitable for demon-
stration at the poster session.
The projects differ according to their scopes and
goals, as well as their immediate practical utility.
</bodyText>
<footnote confidence="0.986812">
1http://en.wikipedia.org/wiki/Agile_software_development
</footnote>
<page confidence="0.998843">
87
</page>
<bodyText confidence="0.9999635">
One project (3.1) makes previous research accessi-
ble to users by developing an easy-to-use frontend;
a second project (3.2) aims to extend the num-
ber of languages addressed for an existing multi-
lingual classification task; and the remaining two
(3.3 and 3.4) implement language-specific solu-
tions for individual language processing tasks. We
additionally required that each project be open-
source; the public code repositories are linked in
the respective sections.
</bodyText>
<subsectionHeader confidence="0.995049">
3.1 Small-vocabulary ASR for any language
</subsectionHeader>
<bodyText confidence="0.999890052631579">
This project2 builds on existing research for small-
vocabulary (up to roughly 100 distinct words)
speech recognition. Such technology is desirable
for, among other things, developing speech inter-
faces to mobile applications (e.g. to deliver med-
ical information or weather reports; see Sherwani
(2009)), but dedicated speech recognition engines
are available only for a relatively small number
of languages. For small-vocabulary applications,
though, an existing recognizer for a high-resource
language can be used to do recognition in the tar-
get language, given a pronunciation lexicon map-
ping the relevant target language words into se-
quences of sounds in the high-resource language.
This project produces the required lexicon.
Building on the algorithms developed by Qiao
et al. (2010) and Chan and Rosenfeld (2012), two
students developed an easy-to-use interface that
allows a user with no knowledge of speech tech-
nologies to build and test a system to recognize
words spoken in the target language. In its cur-
rent implementation, the system uses the English-
language recognizer from the freely-available Mi-
crosoft Speech Platform;3 for this reason, the sys-
tem is available for Windows only. To build a rec-
ognizer for a target language, a user needs only
to specify a written form and upload one or more
audio samples for each word in the vocabulary;
generally, the more audio samples per word, the
better the performance. The students additionally
implemented a built-in recorder; this means a user
can spontaneously make recordings for the desired
words. Finally, the system includes implementa-
tions of two different variants of the algorithm and
an evaluation module, thus facilitating use for both
research and development purposes.
The main challenges for this project involved
managing the interaction between the algorithm
</bodyText>
<footnote confidence="0.990012">
2https://github.com/lex4all/lex4all
3http://msdn.microsoft.com/en-us/library/hh361572
</footnote>
<bodyText confidence="0.999785">
and the Microsoft speech recognition platform, as
well as getting familiar with development in Win-
dows. The practical utility of this project is imme-
diately evident: any user with a Windows machine
can install the necessary components and have a
working small-vocabulary recognizer within sev-
eral hours. Of course, more time and data may
be required to improve performance of the rec-
ognizer, which currently reaches in the mid-70s
with five audio samples per word. These results,
as well as further details about the system (includ-
ing where to download the code, and discussion
of substituting other high-resource language rec-
ognizers), are described in Vakil et al. (2014).
</bodyText>
<subsectionHeader confidence="0.997679">
3.2 Language ID for many languages
</subsectionHeader>
<bodyText confidence="0.999965529411765">
This project4 addresses the task of language iden-
tification. Given a string of text in an arbitrary lan-
guage, can we train a system to recognize what
language the text is written in? Excellent classifi-
cation rates have been achieved in previous work,
but for a relatively small number of languages, and
the task becomes noticeably more difficult as the
number of languages increases (Baldwin and Lui,
2010; Lui and Baldwin, 2012, for example). With
few exceptions (Brown, 2013; Xia et al., 2010; Xia
et al., 2009), existing systems have only attempted
to distinguish between fewer than 200 of the thou-
sands of written languages currently in use. This
team of three students aimed to expand coverage
of language identification systems as much as pos-
sible given existing sources of data.
To do this, they first needed to gather and stan-
dardize data from various sources. They targeted
three sources of data: the Universal Declaration
of Human Rights, Wikipedia,5 ODIN (Lewis and
Xia, 2010), and some portions of the data avail-
able from Omniglot.5 The challenges faced by this
group lay primarily in two areas: issues involv-
ing data and those involving classification. In the
first area, they encountered expected and well-
known issues such as clean-up and standardization
of data, dealing with encoding issues, and manag-
ing large amounts of data. The second set of chal-
lenges have to do with the high degree of skew
in the data collected. Though their system covers
over 1000 languages, the amount of data per lan-
guage ranges from a single sentence to hundreds
of thousands of words. Along the way, the stu-
dents realized that this collection of data in a stan-
</bodyText>
<footnote confidence="0.999808">
4https://github.com/alvations/SeedLing
5http://www.wikipedia.com,http://www.omniglot.com
</footnote>
<page confidence="0.999373">
88
</page>
<bodyText confidence="0.999971166666667">
dard, machine-readable form is useful for many
other purposes. The corpus and how to access it
are described in Emerson et al. (2014). A second
paper presenting the language identification re-
sults (including those for low-resource languages)
is planned for later this year.
</bodyText>
<subsectionHeader confidence="0.999199">
3.3 A lemmatizer for Uspanteko
</subsectionHeader>
<bodyText confidence="0.999994461538461">
The third project6 involved implementing a lem-
matizer for the Mayan language Uspanteko. Us-
ing data that had been cleaned, standardized (as
described in Palmer et al. (2010)), and made avail-
able through the Archive of Indigenous Languages
of Latin America,7 these three students imple-
mented a tool to identify the citation form for in-
flected word forms in texts. The lemmatization
algorithm is based on longest common substring
matching: the closest match for an inflected form
is returned as the lemma. Additionally, a table for
irregular verb inflections was generated using the
annotated source corpus (roughly 50,000 words)
and an Uspanteko-Spanish dictionary (Can Pix-
abaj et al., 2007), to map inflected forms translated
with the same Spanish morpheme.
This group more than any other faced the chal-
lenge of evaluation. Not all lemmas covered in
the texts appear in the dictionary, and the Uspan-
teko texts, though fully analyzed with morphologi-
cal segmentation and glossing, part of speech tags,
and translation into Spanish, do not include cita-
tion forms. Manual evaluation of 100 sentences,
for which a linguist on the team with knowledge
of Spanish determined citation forms, showed ac-
curacy of 59% for the lemmatization algorithm.
</bodyText>
<subsectionHeader confidence="0.711415">
3.4 NER for Slovak &amp; Persian
</subsectionHeader>
<bodyText confidence="0.999963230769231">
Finally, the fourth project8 (two students) chose
to tackle the task of named entity recognition
(NER): identifying instances of named entities
(NEs, e.g. people, locations, geopolitical entities)
in texts and associating them with appropriate la-
bels. The students developed a single platform to
do NER in both Slovak and Persian, their native
languages. The approach is primarily based on us-
ing gazetteers (for person names and locations), as
well as regular expressions (for temporal expres-
sions). The students collected the gazeteers for the
two languages as part of the project. Their sys-
tem builds on a modular design; one can swap out
</bodyText>
<footnote confidence="0.999395666666667">
6https://code.google.com/p/mayan-lemmatizer/
7http://www.ailla.utexas.org
8https://code.google.com/p/named\-entity\-tagger/
</footnote>
<bodyText confidence="0.999926884615385">
gazetteers and a few language-specific heuristic
components to perform NER in a new language.
In this project, resource acquisition and evalua-
tion were the main challenges. The students used
some existing resources for both languages, but
also devoted quite some time to producing new
gazetteers. For Slovak, additional challenges were
presented by the language’s large number of in-
flectional cases and resulting variability in form.
For example, some inflected forms used to re-
fer to people from a given location are string-
identical to the names of the locations with a dif-
ferent case inflection. In Persian, the main chal-
lenges were detection of word boundaries (many
names are multi-word expressions) and frequent
NE/proper noun ambiguities. For evaluation, the
students hand-labeled over 35,000 words of Slo-
vak (with 545 NE instances) and about 600 para-
graphs of Persian data (306 NE instances). Perfor-
mace varies across named entity category: tempo-
ral expression matching is most reliable (f-score
0.96 for Slovak, 0.89 for Persion), followed by
locations (0.78 Slovak, 0.92 Persian) and person
names (0.63 Slovak, 0.87 Persian). Note that for
Persian, only NEs with correctly matched bound-
aries are counted (which are 50% for persons).
</bodyText>
<sectionHeader confidence="0.996908" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999361428571429">
In this paper we have presented four student soft-
ware projects, each one addressing a different
NLP task relevant for one or more low-resource
languages. The successful outcomes of the four
projects show that much progress can be made
even with limited time and limited prior expe-
rience developing such systems. Local teach-
ing efforts such as these can be highly success-
ful in building a group of young researchers who
are both familiar with issues surrounding low-
resource and endangered languages and prepared
to do research and development in this area in the
future. We think of this as planting seeds for an
early harvest: with one semester’s combined effort
between instructors and students, we reap the re-
wards of both new tools and new researchers who
can continue to work on closing the gap between
computational and documentary linguistics.
Course materials are publicly available from the
course homepage,9 and from the project reposito-
ries linked from the descriptions in Section 3.
</bodyText>
<footnote confidence="0.95955">
9http://www.coli.uni-saarland.de/courses/cl4lrl-swp/
</footnote>
<page confidence="0.999618">
89
</page>
<sectionHeader confidence="0.99851" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999641583333334">
First of all, we want to thank the students who par-
ticipated in our course and put so much effort and
passion in their projects. They are (in alphabeti-
cal order): Christine Bocionek, Guy Emerson, Su-
sanne Fertmann, Liesa Heuschkel, Omid Moradi-
annasab, Michal Petko, Maximilian Paulus, Alek-
sandra Piwowarek, Liling Tan and Anjana Vakil.
Further, we want to thank the anonymous review-
ers for their helpful comments. The second author
was funded by the Cluster of Excellence “Multi-
modal Computing and Interaction” in the German
Excellence Initiative.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999152034090909">
Steven Abney and Steven Bird. 2010. The Human
Language Project: Building a universal corpus of the
world’s languages. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics, pages 88–97. Association for Computa-
tional Linguistics.
Timothy Baldwin and Marco Lui. 2010. Language
identification: The long and the short of the matter.
In Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter of
the Association for Computational Linguistics, HLT
’10, pages 229–237, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Emily M Bender. 2011. On achieving and evaluating
language-independence in NLP. Linguistic Issues in
Language Technology, 6(3):1–26.
Steven Bird. 2009. Natural language processing
and linguistic fieldwork. Computational Linguis-
tics, 35(3):469–474.
Prachya Boonkwan and Mark Steedman. 2011. Gram-
mar induction from text using small syntactic proto-
types. In IJCNLP, pages 438–446.
Ralf D Brown. 2013. Selecting and weighting n-grams
to identify 1100 languages. In Text, Speech, and Di-
alogue, pages 475–483. Springer.
Telma Angelina Can Pixabaj, Oxlajuuj Keej Maya’
Ajtz’iib’ (Group) Staff, and Centro Educativo y Cul-
tural Maya Staff. 2007. Jkemiix yalaj li uspanteko.
Cholsamaj Fundacion, Guatemala.
Hao Yee Chan and Roni Rosenfeld. 2012. Discrimi-
native pronunciation learning for speech recognition
for resource scarce languages. In Proceedings of the
2nd ACM Symposium on Computing for Develop-
ment, page 12. ACM.
Guy Emerson, Liling Tan, Susanne Fertmann, Alexis
Palmer, and Michaela Regneri. 2014. SeedLing:
Building and using a seed corpus for the Human
Language Project. In Proceedings ofACL Workshop
on the use of computational methods in the study of
endangered languages (ComputEL).
Dan Garrette and Jason Baldridge. 2013. Learning a
part-of-speech tagger from two hours of annotation.
In Proceedings of NAACL-HLT, pages 138–147.
William D Lewis and Fei Xia. 2010. Developing
ODIN: A multilingual repository of annotated lan-
guage data for hundreds of the world’s languages.
Literary and Linguistic Computing, 25(3):303–319.
Marco Lui and Timothy Baldwin. 2012. Langid.py:
An off-the-shelf language identification tool. In
Proceedings of the ACL 2012 System Demonstra-
tions, ACL ’12, pages 25–30, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Tahira Naseem, Harr Chen, Regina Barzilay, and Mark
Johnson. 2010. Using universal linguistic knowl-
edge to guide grammar induction. In Proceedings of
the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1234–1244. Asso-
ciation for Computational Linguistics.
Alexis Palmer, Taesun Moon, Jason Baldridge, Katrin
Erk, Eric Campbell, and Telma Can. 2010. Compu-
tational strategies for reducing annotation effort in
language documentation. Linguistic Issues in Lan-
guage Technology, 3.
Fang Qiao, Jahanzeb Sherwani, and Roni Rosenfeld.
2010. Small-vocabulary speech recognition for
resource-scarce languages. In Proceedings of the
First ACM Symposium on Computing for Develop-
ment, page 3. ACM.
Jahanzeb Sherwani. 2009. Speech interfaces for in-
formation access by low literate users. Ph.D. thesis,
SRI International.
Anjana Vakil, Max Paulus, Alexis Palmer, and
Michaela Regneri. 2014. lex4all: A language-
independent tool for building and evaluating pronun-
ciation lexicons for small-vocabulary speech recog-
nition. In Proceedings of ACL2014 Demo Session.
Fei Xia and William Lewis. 2007. Multilingual struc-
tural projection across interlinear text. In Proceed-
ings of HLT/NAACL 2007, Rochester, NY.
Fei Xia, William D Lewis, and Hoifung Poon. 2009.
Language ID in the context of harvesting language
data off the web. In Proceedings of the 12th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, pages 870–878. Associ-
ation for Computational Linguistics.
Fei Xia, Carrie Lewis, and William D Lewis. 2010.
The problems of language identification within
hugely multilingual data sets. In LREC.
</reference>
<page confidence="0.998603">
90
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.444955">
<title confidence="0.983632">Short-term projects, long-term benefits: Four student NLP projects for low-resource languages</title>
<author confidence="0.999394">Alexis Palmer</author>
<author confidence="0.999394">Michaela</author>
<affiliation confidence="0.999353">Department of Computational</affiliation>
<address confidence="0.547185">Saarland</address>
<email confidence="0.750755">Saarbr¨ucken,</email>
<abstract confidence="0.999122954545455">This paper describes a local effort to bridge the gap between computational and documentary linguistics by teaching students and young researchers in computational linguistics about doing research and developing systems for low-resource languages. We describe four student software projects developed within one semester. The projects range from a front-end for building small-vocabulary speech recognition systems, to a broad-coverage (more than 1000 languages) language identification system, to language-specific systems: a lemmatizer for the Mayan language Uspanteko and named entity recognition systems for both Slovak and Persian. Teaching efforts such as these are an excellent way to develop not only tools for low-resource languages, but also computational linguists well-equipped to work on endangered and low-resource languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
<author>Steven Bird</author>
</authors>
<title>The Human Language Project: Building a universal corpus of the world’s languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>88--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1315" citStr="Abney and Bird, 2010" startWordPosition="180" endWordPosition="183">(more than 1000 languages) language identification system, to language-specific systems: a lemmatizer for the Mayan language Uspanteko and named entity recognition systems for both Slovak and Persian. Teaching efforts such as these are an excellent way to develop not only tools for low-resource languages, but also computational linguists well-equipped to work on endangered and low-resource languages. 1 Introduction There is a strong argument to be made for bringing together computational and documentary linguistics in order to support the documentation and description of endangered languages (Abney and Bird, 2010; Bird, 2009). Documentation, description, and revitalization work for endangered languages, as well as efforts to produce digital and machine-readable resources for languages currently lacking such data, benefit from technological support in many different ways. Here we focus on support via (a) tools facilitating more efficient development of resources, with easy learning curves, and (b) linguistic analysis tools. Various meetings and workshops in recent years have helped to bring the two fields closer together, but a sizeable gap remains. We’ve come far enough to, for example, have a relevan</context>
<context position="4543" citStr="Abney and Bird, 2010" startWordPosition="699" endWordPosition="702">. c�2014 Association for Computational Linguistics approaches for addressing these same challenges. This section briefly surveys some of the relevant issues, with pointers to representative studies. The first and most obvious concern is data sparsity. Many of the most successful and widelytaught methods and models in computational linguistics rely on either large amounts of labeled data or massive amounts of unlabeled data. Methods and models explicitly addressing LRLs need to maximize the utility of available data. Approaches for addressing data sparsity range from data collection proposals (Abney and Bird, 2010) to leveraging high-resource languages (Xia and Lewis, 2007) to maximizing annotation effort (Garrette and Baldridge, 2013). A second concern is model suitability. Many existing models in computational linguistics implicitly encode or expect characteristics of high-resource languages (Bender, 2011); for example, much work on computational syntax uses models that exploit linear ordering of elements in utterances. Such models are not straightforwardly applicable for languages with free or flexible word order, nor for highly agglutinative languages where, for example, complete utterances are enco</context>
</contexts>
<marker>Abney, Bird, 2010</marker>
<rawString>Steven Abney and Steven Bird. 2010. The Human Language Project: Building a universal corpus of the world’s languages. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 88–97. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Marco Lui</author>
</authors>
<title>Language identification: The long and the short of the matter.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>229--237</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12280" citStr="Baldwin and Lui, 2010" startWordPosition="1902" endWordPosition="1905">ther details about the system (including where to download the code, and discussion of substituting other high-resource language recognizers), are described in Vakil et al. (2014). 3.2 Language ID for many languages This project4 addresses the task of language identification. Given a string of text in an arbitrary language, can we train a system to recognize what language the text is written in? Excellent classification rates have been achieved in previous work, but for a relatively small number of languages, and the task becomes noticeably more difficult as the number of languages increases (Baldwin and Lui, 2010; Lui and Baldwin, 2012, for example). With few exceptions (Brown, 2013; Xia et al., 2010; Xia et al., 2009), existing systems have only attempted to distinguish between fewer than 200 of the thousands of written languages currently in use. This team of three students aimed to expand coverage of language identification systems as much as possible given existing sources of data. To do this, they first needed to gather and standardize data from various sources. They targeted three sources of data: the Universal Declaration of Human Rights, Wikipedia,5 ODIN (Lewis and Xia, 2010), and some portion</context>
</contexts>
<marker>Baldwin, Lui, 2010</marker>
<rawString>Timothy Baldwin and Marco Lui. 2010. Language identification: The long and the short of the matter. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 229–237, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
</authors>
<title>On achieving and evaluating language-independence in NLP.</title>
<date>2011</date>
<journal>Linguistic Issues in Language Technology,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="4842" citStr="Bender, 2011" startWordPosition="740" endWordPosition="741">d models in computational linguistics rely on either large amounts of labeled data or massive amounts of unlabeled data. Methods and models explicitly addressing LRLs need to maximize the utility of available data. Approaches for addressing data sparsity range from data collection proposals (Abney and Bird, 2010) to leveraging high-resource languages (Xia and Lewis, 2007) to maximizing annotation effort (Garrette and Baldridge, 2013). A second concern is model suitability. Many existing models in computational linguistics implicitly encode or expect characteristics of high-resource languages (Bender, 2011); for example, much work on computational syntax uses models that exploit linear ordering of elements in utterances. Such models are not straightforwardly applicable for languages with free or flexible word order, nor for highly agglutinative languages where, for example, complete utterances are encoded as single words. Approaches to this issues include adaptation of models using linguistic knowledge and/or universals (Boonkwan and Steedman, 2011; Naseem et al., 2010). The third issue to note is the difficulty of evaluation. The output of systems or tools performing automated analysis are pred</context>
</contexts>
<marker>Bender, 2011</marker>
<rawString>Emily M Bender. 2011. On achieving and evaluating language-independence in NLP. Linguistic Issues in Language Technology, 6(3):1–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
</authors>
<title>Natural language processing and linguistic fieldwork.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="1328" citStr="Bird, 2009" startWordPosition="184" endWordPosition="185">ges) language identification system, to language-specific systems: a lemmatizer for the Mayan language Uspanteko and named entity recognition systems for both Slovak and Persian. Teaching efforts such as these are an excellent way to develop not only tools for low-resource languages, but also computational linguists well-equipped to work on endangered and low-resource languages. 1 Introduction There is a strong argument to be made for bringing together computational and documentary linguistics in order to support the documentation and description of endangered languages (Abney and Bird, 2010; Bird, 2009). Documentation, description, and revitalization work for endangered languages, as well as efforts to produce digital and machine-readable resources for languages currently lacking such data, benefit from technological support in many different ways. Here we focus on support via (a) tools facilitating more efficient development of resources, with easy learning curves, and (b) linguistic analysis tools. Various meetings and workshops in recent years have helped to bring the two fields closer together, but a sizeable gap remains. We’ve come far enough to, for example, have a relevant workshop at</context>
</contexts>
<marker>Bird, 2009</marker>
<rawString>Steven Bird. 2009. Natural language processing and linguistic fieldwork. Computational Linguistics, 35(3):469–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prachya Boonkwan</author>
<author>Mark Steedman</author>
</authors>
<title>Grammar induction from text using small syntactic prototypes.</title>
<date>2011</date>
<booktitle>In IJCNLP,</booktitle>
<pages>438--446</pages>
<contexts>
<context position="5292" citStr="Boonkwan and Steedman, 2011" startWordPosition="805" endWordPosition="808">). A second concern is model suitability. Many existing models in computational linguistics implicitly encode or expect characteristics of high-resource languages (Bender, 2011); for example, much work on computational syntax uses models that exploit linear ordering of elements in utterances. Such models are not straightforwardly applicable for languages with free or flexible word order, nor for highly agglutinative languages where, for example, complete utterances are encoded as single words. Approaches to this issues include adaptation of models using linguistic knowledge and/or universals (Boonkwan and Steedman, 2011; Naseem et al., 2010). The third issue to note is the difficulty of evaluation. The output of systems or tools performing automated analysis are predictions of analyses for new data; these predictions must be evaluated against a ground truth or humansupplied analysis of the same data. Evaluation is difficult in the low-resource setting, both because of limited availability of expert-labeled data and because, in some cases, the ground truth isn’t known, or analyses are shifting as knowledge about the language develops. We began the course with a discussion of these issues, as well as an introd</context>
</contexts>
<marker>Boonkwan, Steedman, 2011</marker>
<rawString>Prachya Boonkwan and Mark Steedman. 2011. Grammar induction from text using small syntactic prototypes. In IJCNLP, pages 438–446.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf D Brown</author>
</authors>
<title>Selecting and weighting n-grams to identify 1100 languages.</title>
<date>2013</date>
<booktitle>In Text, Speech, and Dialogue,</booktitle>
<pages>475--483</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="12351" citStr="Brown, 2013" startWordPosition="1915" endWordPosition="1916">on of substituting other high-resource language recognizers), are described in Vakil et al. (2014). 3.2 Language ID for many languages This project4 addresses the task of language identification. Given a string of text in an arbitrary language, can we train a system to recognize what language the text is written in? Excellent classification rates have been achieved in previous work, but for a relatively small number of languages, and the task becomes noticeably more difficult as the number of languages increases (Baldwin and Lui, 2010; Lui and Baldwin, 2012, for example). With few exceptions (Brown, 2013; Xia et al., 2010; Xia et al., 2009), existing systems have only attempted to distinguish between fewer than 200 of the thousands of written languages currently in use. This team of three students aimed to expand coverage of language identification systems as much as possible given existing sources of data. To do this, they first needed to gather and standardize data from various sources. They targeted three sources of data: the Universal Declaration of Human Rights, Wikipedia,5 ODIN (Lewis and Xia, 2010), and some portions of the data available from Omniglot.5 The challenges faced by this gr</context>
</contexts>
<marker>Brown, 2013</marker>
<rawString>Ralf D Brown. 2013. Selecting and weighting n-grams to identify 1100 languages. In Text, Speech, and Dialogue, pages 475–483. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Telma Angelina Can Pixabaj</author>
</authors>
<title>Oxlajuuj Keej Maya’ Ajtz’iib’ (Group) Staff, and Centro Educativo y Cultural Maya Staff.</title>
<date>2007</date>
<marker>Pixabaj, 2007</marker>
<rawString>Telma Angelina Can Pixabaj, Oxlajuuj Keej Maya’ Ajtz’iib’ (Group) Staff, and Centro Educativo y Cultural Maya Staff. 2007. Jkemiix yalaj li uspanteko. Cholsamaj Fundacion, Guatemala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Yee Chan</author>
<author>Roni Rosenfeld</author>
</authors>
<title>Discriminative pronunciation learning for speech recognition for resource scarce languages.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2nd ACM Symposium on Computing for Development,</booktitle>
<pages>12</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="10063" citStr="Chan and Rosenfeld (2012)" startWordPosition="1557" endWordPosition="1560">terfaces to mobile applications (e.g. to deliver medical information or weather reports; see Sherwani (2009)), but dedicated speech recognition engines are available only for a relatively small number of languages. For small-vocabulary applications, though, an existing recognizer for a high-resource language can be used to do recognition in the target language, given a pronunciation lexicon mapping the relevant target language words into sequences of sounds in the high-resource language. This project produces the required lexicon. Building on the algorithms developed by Qiao et al. (2010) and Chan and Rosenfeld (2012), two students developed an easy-to-use interface that allows a user with no knowledge of speech technologies to build and test a system to recognize words spoken in the target language. In its current implementation, the system uses the Englishlanguage recognizer from the freely-available Microsoft Speech Platform;3 for this reason, the system is available for Windows only. To build a recognizer for a target language, a user needs only to specify a written form and upload one or more audio samples for each word in the vocabulary; generally, the more audio samples per word, the better the perf</context>
</contexts>
<marker>Chan, Rosenfeld, 2012</marker>
<rawString>Hao Yee Chan and Roni Rosenfeld. 2012. Discriminative pronunciation learning for speech recognition for resource scarce languages. In Proceedings of the 2nd ACM Symposium on Computing for Development, page 12. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy Emerson</author>
<author>Liling Tan</author>
<author>Susanne Fertmann</author>
<author>Alexis Palmer</author>
<author>Michaela Regneri</author>
</authors>
<title>SeedLing: Building and using a seed corpus for the Human Language Project.</title>
<date>2014</date>
<booktitle>In Proceedings ofACL Workshop on the use of computational methods in the study of endangered languages (ComputEL).</booktitle>
<contexts>
<context position="13756" citStr="Emerson et al. (2014)" startWordPosition="2141" endWordPosition="2144">dization of data, dealing with encoding issues, and managing large amounts of data. The second set of challenges have to do with the high degree of skew in the data collected. Though their system covers over 1000 languages, the amount of data per language ranges from a single sentence to hundreds of thousands of words. Along the way, the students realized that this collection of data in a stan4https://github.com/alvations/SeedLing 5http://www.wikipedia.com,http://www.omniglot.com 88 dard, machine-readable form is useful for many other purposes. The corpus and how to access it are described in Emerson et al. (2014). A second paper presenting the language identification results (including those for low-resource languages) is planned for later this year. 3.3 A lemmatizer for Uspanteko The third project6 involved implementing a lemmatizer for the Mayan language Uspanteko. Using data that had been cleaned, standardized (as described in Palmer et al. (2010)), and made available through the Archive of Indigenous Languages of Latin America,7 these three students implemented a tool to identify the citation form for inflected word forms in texts. The lemmatization algorithm is based on longest common substring m</context>
</contexts>
<marker>Emerson, Tan, Fertmann, Palmer, Regneri, 2014</marker>
<rawString>Guy Emerson, Liling Tan, Susanne Fertmann, Alexis Palmer, and Michaela Regneri. 2014. SeedLing: Building and using a seed corpus for the Human Language Project. In Proceedings ofACL Workshop on the use of computational methods in the study of endangered languages (ComputEL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Garrette</author>
<author>Jason Baldridge</author>
</authors>
<title>Learning a part-of-speech tagger from two hours of annotation.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>138--147</pages>
<contexts>
<context position="4666" citStr="Garrette and Baldridge, 2013" startWordPosition="715" endWordPosition="718">iefly surveys some of the relevant issues, with pointers to representative studies. The first and most obvious concern is data sparsity. Many of the most successful and widelytaught methods and models in computational linguistics rely on either large amounts of labeled data or massive amounts of unlabeled data. Methods and models explicitly addressing LRLs need to maximize the utility of available data. Approaches for addressing data sparsity range from data collection proposals (Abney and Bird, 2010) to leveraging high-resource languages (Xia and Lewis, 2007) to maximizing annotation effort (Garrette and Baldridge, 2013). A second concern is model suitability. Many existing models in computational linguistics implicitly encode or expect characteristics of high-resource languages (Bender, 2011); for example, much work on computational syntax uses models that exploit linear ordering of elements in utterances. Such models are not straightforwardly applicable for languages with free or flexible word order, nor for highly agglutinative languages where, for example, complete utterances are encoded as single words. Approaches to this issues include adaptation of models using linguistic knowledge and/or universals (B</context>
</contexts>
<marker>Garrette, Baldridge, 2013</marker>
<rawString>Dan Garrette and Jason Baldridge. 2013. Learning a part-of-speech tagger from two hours of annotation. In Proceedings of NAACL-HLT, pages 138–147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William D Lewis</author>
<author>Fei Xia</author>
</authors>
<title>Developing ODIN: A multilingual repository of annotated language data for hundreds of the world’s languages. Literary and Linguistic Computing,</title>
<date>2010</date>
<contexts>
<context position="12862" citStr="Lewis and Xia, 2010" startWordPosition="1998" endWordPosition="2001">uages increases (Baldwin and Lui, 2010; Lui and Baldwin, 2012, for example). With few exceptions (Brown, 2013; Xia et al., 2010; Xia et al., 2009), existing systems have only attempted to distinguish between fewer than 200 of the thousands of written languages currently in use. This team of three students aimed to expand coverage of language identification systems as much as possible given existing sources of data. To do this, they first needed to gather and standardize data from various sources. They targeted three sources of data: the Universal Declaration of Human Rights, Wikipedia,5 ODIN (Lewis and Xia, 2010), and some portions of the data available from Omniglot.5 The challenges faced by this group lay primarily in two areas: issues involving data and those involving classification. In the first area, they encountered expected and wellknown issues such as clean-up and standardization of data, dealing with encoding issues, and managing large amounts of data. The second set of challenges have to do with the high degree of skew in the data collected. Though their system covers over 1000 languages, the amount of data per language ranges from a single sentence to hundreds of thousands of words. Along </context>
</contexts>
<marker>Lewis, Xia, 2010</marker>
<rawString>William D Lewis and Fei Xia. 2010. Developing ODIN: A multilingual repository of annotated language data for hundreds of the world’s languages. Literary and Linguistic Computing, 25(3):303–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>Langid.py: An off-the-shelf language identification tool.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations, ACL ’12,</booktitle>
<pages>25--30</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12303" citStr="Lui and Baldwin, 2012" startWordPosition="1906" endWordPosition="1909">system (including where to download the code, and discussion of substituting other high-resource language recognizers), are described in Vakil et al. (2014). 3.2 Language ID for many languages This project4 addresses the task of language identification. Given a string of text in an arbitrary language, can we train a system to recognize what language the text is written in? Excellent classification rates have been achieved in previous work, but for a relatively small number of languages, and the task becomes noticeably more difficult as the number of languages increases (Baldwin and Lui, 2010; Lui and Baldwin, 2012, for example). With few exceptions (Brown, 2013; Xia et al., 2010; Xia et al., 2009), existing systems have only attempted to distinguish between fewer than 200 of the thousands of written languages currently in use. This team of three students aimed to expand coverage of language identification systems as much as possible given existing sources of data. To do this, they first needed to gather and standardize data from various sources. They targeted three sources of data: the Universal Declaration of Human Rights, Wikipedia,5 ODIN (Lewis and Xia, 2010), and some portions of the data available</context>
</contexts>
<marker>Lui, Baldwin, 2012</marker>
<rawString>Marco Lui and Timothy Baldwin. 2012. Langid.py: An off-the-shelf language identification tool. In Proceedings of the ACL 2012 System Demonstrations, ACL ’12, pages 25–30, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Harr Chen</author>
<author>Regina Barzilay</author>
<author>Mark Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1234--1244</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5314" citStr="Naseem et al., 2010" startWordPosition="809" endWordPosition="812">suitability. Many existing models in computational linguistics implicitly encode or expect characteristics of high-resource languages (Bender, 2011); for example, much work on computational syntax uses models that exploit linear ordering of elements in utterances. Such models are not straightforwardly applicable for languages with free or flexible word order, nor for highly agglutinative languages where, for example, complete utterances are encoded as single words. Approaches to this issues include adaptation of models using linguistic knowledge and/or universals (Boonkwan and Steedman, 2011; Naseem et al., 2010). The third issue to note is the difficulty of evaluation. The output of systems or tools performing automated analysis are predictions of analyses for new data; these predictions must be evaluated against a ground truth or humansupplied analysis of the same data. Evaluation is difficult in the low-resource setting, both because of limited availability of expert-labeled data and because, in some cases, the ground truth isn’t known, or analyses are shifting as knowledge about the language develops. We began the course with a discussion of these issues, as well as an introduction to a range of e</context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1234–1244. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Palmer</author>
<author>Taesun Moon</author>
<author>Jason Baldridge</author>
</authors>
<title>Katrin Erk, Eric Campbell, and Telma Can.</title>
<date>2010</date>
<journal>Linguistic Issues in Language Technology,</journal>
<volume>3</volume>
<contexts>
<context position="14100" citStr="Palmer et al. (2010)" startWordPosition="2194" endWordPosition="2197">nts realized that this collection of data in a stan4https://github.com/alvations/SeedLing 5http://www.wikipedia.com,http://www.omniglot.com 88 dard, machine-readable form is useful for many other purposes. The corpus and how to access it are described in Emerson et al. (2014). A second paper presenting the language identification results (including those for low-resource languages) is planned for later this year. 3.3 A lemmatizer for Uspanteko The third project6 involved implementing a lemmatizer for the Mayan language Uspanteko. Using data that had been cleaned, standardized (as described in Palmer et al. (2010)), and made available through the Archive of Indigenous Languages of Latin America,7 these three students implemented a tool to identify the citation form for inflected word forms in texts. The lemmatization algorithm is based on longest common substring matching: the closest match for an inflected form is returned as the lemma. Additionally, a table for irregular verb inflections was generated using the annotated source corpus (roughly 50,000 words) and an Uspanteko-Spanish dictionary (Can Pixabaj et al., 2007), to map inflected forms translated with the same Spanish morpheme. This group more</context>
</contexts>
<marker>Palmer, Moon, Baldridge, 2010</marker>
<rawString>Alexis Palmer, Taesun Moon, Jason Baldridge, Katrin Erk, Eric Campbell, and Telma Can. 2010. Computational strategies for reducing annotation effort in language documentation. Linguistic Issues in Language Technology, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fang Qiao</author>
<author>Jahanzeb Sherwani</author>
<author>Roni Rosenfeld</author>
</authors>
<title>Small-vocabulary speech recognition for resource-scarce languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the First ACM Symposium on Computing for Development,</booktitle>
<pages>3</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="10033" citStr="Qiao et al. (2010)" startWordPosition="1552" endWordPosition="1555">s, developing speech interfaces to mobile applications (e.g. to deliver medical information or weather reports; see Sherwani (2009)), but dedicated speech recognition engines are available only for a relatively small number of languages. For small-vocabulary applications, though, an existing recognizer for a high-resource language can be used to do recognition in the target language, given a pronunciation lexicon mapping the relevant target language words into sequences of sounds in the high-resource language. This project produces the required lexicon. Building on the algorithms developed by Qiao et al. (2010) and Chan and Rosenfeld (2012), two students developed an easy-to-use interface that allows a user with no knowledge of speech technologies to build and test a system to recognize words spoken in the target language. In its current implementation, the system uses the Englishlanguage recognizer from the freely-available Microsoft Speech Platform;3 for this reason, the system is available for Windows only. To build a recognizer for a target language, a user needs only to specify a written form and upload one or more audio samples for each word in the vocabulary; generally, the more audio samples</context>
</contexts>
<marker>Qiao, Sherwani, Rosenfeld, 2010</marker>
<rawString>Fang Qiao, Jahanzeb Sherwani, and Roni Rosenfeld. 2010. Small-vocabulary speech recognition for resource-scarce languages. In Proceedings of the First ACM Symposium on Computing for Development, page 3. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jahanzeb Sherwani</author>
</authors>
<title>Speech interfaces for information access by low literate users.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>SRI International.</institution>
<contexts>
<context position="9546" citStr="Sherwani (2009)" startWordPosition="1481" endWordPosition="1482">ltilingual classification task; and the remaining two (3.3 and 3.4) implement language-specific solutions for individual language processing tasks. We additionally required that each project be opensource; the public code repositories are linked in the respective sections. 3.1 Small-vocabulary ASR for any language This project2 builds on existing research for smallvocabulary (up to roughly 100 distinct words) speech recognition. Such technology is desirable for, among other things, developing speech interfaces to mobile applications (e.g. to deliver medical information or weather reports; see Sherwani (2009)), but dedicated speech recognition engines are available only for a relatively small number of languages. For small-vocabulary applications, though, an existing recognizer for a high-resource language can be used to do recognition in the target language, given a pronunciation lexicon mapping the relevant target language words into sequences of sounds in the high-resource language. This project produces the required lexicon. Building on the algorithms developed by Qiao et al. (2010) and Chan and Rosenfeld (2012), two students developed an easy-to-use interface that allows a user with no knowle</context>
</contexts>
<marker>Sherwani, 2009</marker>
<rawString>Jahanzeb Sherwani. 2009. Speech interfaces for information access by low literate users. Ph.D. thesis, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anjana Vakil</author>
<author>Max Paulus</author>
<author>Alexis Palmer</author>
<author>Michaela Regneri</author>
</authors>
<title>lex4all: A languageindependent tool for building and evaluating pronunciation lexicons for small-vocabulary speech recognition.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL2014 Demo Session.</booktitle>
<contexts>
<context position="11838" citStr="Vakil et al. (2014)" startWordPosition="1828" endWordPosition="1831"> as getting familiar with development in Windows. The practical utility of this project is immediately evident: any user with a Windows machine can install the necessary components and have a working small-vocabulary recognizer within several hours. Of course, more time and data may be required to improve performance of the recognizer, which currently reaches in the mid-70s with five audio samples per word. These results, as well as further details about the system (including where to download the code, and discussion of substituting other high-resource language recognizers), are described in Vakil et al. (2014). 3.2 Language ID for many languages This project4 addresses the task of language identification. Given a string of text in an arbitrary language, can we train a system to recognize what language the text is written in? Excellent classification rates have been achieved in previous work, but for a relatively small number of languages, and the task becomes noticeably more difficult as the number of languages increases (Baldwin and Lui, 2010; Lui and Baldwin, 2012, for example). With few exceptions (Brown, 2013; Xia et al., 2010; Xia et al., 2009), existing systems have only attempted to distingu</context>
</contexts>
<marker>Vakil, Paulus, Palmer, Regneri, 2014</marker>
<rawString>Anjana Vakil, Max Paulus, Alexis Palmer, and Michaela Regneri. 2014. lex4all: A languageindependent tool for building and evaluating pronunciation lexicons for small-vocabulary speech recognition. In Proceedings of ACL2014 Demo Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>William Lewis</author>
</authors>
<title>Multilingual structural projection across interlinear text.</title>
<date>2007</date>
<booktitle>In Proceedings of HLT/NAACL 2007,</booktitle>
<location>Rochester, NY.</location>
<contexts>
<context position="4603" citStr="Xia and Lewis, 2007" startWordPosition="707" endWordPosition="710"> for addressing these same challenges. This section briefly surveys some of the relevant issues, with pointers to representative studies. The first and most obvious concern is data sparsity. Many of the most successful and widelytaught methods and models in computational linguistics rely on either large amounts of labeled data or massive amounts of unlabeled data. Methods and models explicitly addressing LRLs need to maximize the utility of available data. Approaches for addressing data sparsity range from data collection proposals (Abney and Bird, 2010) to leveraging high-resource languages (Xia and Lewis, 2007) to maximizing annotation effort (Garrette and Baldridge, 2013). A second concern is model suitability. Many existing models in computational linguistics implicitly encode or expect characteristics of high-resource languages (Bender, 2011); for example, much work on computational syntax uses models that exploit linear ordering of elements in utterances. Such models are not straightforwardly applicable for languages with free or flexible word order, nor for highly agglutinative languages where, for example, complete utterances are encoded as single words. Approaches to this issues include adapt</context>
</contexts>
<marker>Xia, Lewis, 2007</marker>
<rawString>Fei Xia and William Lewis. 2007. Multilingual structural projection across interlinear text. In Proceedings of HLT/NAACL 2007, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>William D Lewis</author>
<author>Hoifung Poon</author>
</authors>
<title>Language ID in the context of harvesting language data off the web.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>870--878</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12388" citStr="Xia et al., 2009" startWordPosition="1921" endWordPosition="1924">esource language recognizers), are described in Vakil et al. (2014). 3.2 Language ID for many languages This project4 addresses the task of language identification. Given a string of text in an arbitrary language, can we train a system to recognize what language the text is written in? Excellent classification rates have been achieved in previous work, but for a relatively small number of languages, and the task becomes noticeably more difficult as the number of languages increases (Baldwin and Lui, 2010; Lui and Baldwin, 2012, for example). With few exceptions (Brown, 2013; Xia et al., 2010; Xia et al., 2009), existing systems have only attempted to distinguish between fewer than 200 of the thousands of written languages currently in use. This team of three students aimed to expand coverage of language identification systems as much as possible given existing sources of data. To do this, they first needed to gather and standardize data from various sources. They targeted three sources of data: the Universal Declaration of Human Rights, Wikipedia,5 ODIN (Lewis and Xia, 2010), and some portions of the data available from Omniglot.5 The challenges faced by this group lay primarily in two areas: issue</context>
</contexts>
<marker>Xia, Lewis, Poon, 2009</marker>
<rawString>Fei Xia, William D Lewis, and Hoifung Poon. 2009. Language ID in the context of harvesting language data off the web. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 870–878. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Carrie Lewis</author>
<author>William D Lewis</author>
</authors>
<title>The problems of language identification within hugely multilingual data sets.</title>
<date>2010</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="12369" citStr="Xia et al., 2010" startWordPosition="1917" endWordPosition="1920">uting other high-resource language recognizers), are described in Vakil et al. (2014). 3.2 Language ID for many languages This project4 addresses the task of language identification. Given a string of text in an arbitrary language, can we train a system to recognize what language the text is written in? Excellent classification rates have been achieved in previous work, but for a relatively small number of languages, and the task becomes noticeably more difficult as the number of languages increases (Baldwin and Lui, 2010; Lui and Baldwin, 2012, for example). With few exceptions (Brown, 2013; Xia et al., 2010; Xia et al., 2009), existing systems have only attempted to distinguish between fewer than 200 of the thousands of written languages currently in use. This team of three students aimed to expand coverage of language identification systems as much as possible given existing sources of data. To do this, they first needed to gather and standardize data from various sources. They targeted three sources of data: the Universal Declaration of Human Rights, Wikipedia,5 ODIN (Lewis and Xia, 2010), and some portions of the data available from Omniglot.5 The challenges faced by this group lay primarily </context>
</contexts>
<marker>Xia, Lewis, Lewis, 2010</marker>
<rawString>Fei Xia, Carrie Lewis, and William D Lewis. 2010. The problems of language identification within hugely multilingual data sets. In LREC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>