<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000086">
<title confidence="0.9978725">
Improving Readability of Swedish Electronic Health Records
through Lexical Simplification: First Results
</title>
<author confidence="0.998014">
Gintar˙e Grigonyt˙ea, Maria Kvistbc, Sumithra Velupillaib, Mats Wir´ena
</author>
<affiliation confidence="0.999739333333333">
aDepartment of Linguistics, Stockholm University, Sweden
bDepartment of Computer and Systems Sciences, Stockholm University, Sweden
cDepartment of Learning, Informatics, Management and Ethics, Karolinska Institutet, Sweden
</affiliation>
<email confidence="0.9810485">
gintare@ling.su.se, maria.kvist@karolinska.se,
sumithra@dsv.su.se, mats.wiren@ling.su.se
</email>
<sectionHeader confidence="0.993768" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998803">
This paper describes part of an ongo-
ing effort to improve the readability of
Swedish electronic health records (EHRs).
An EHR contains systematic documenta-
tion of a single patient’s medical history
across time, entered by healthcare pro-
fessionals with the purpose of enabling
safe and informed care. Linguistically,
medical records exemplify a highly spe-
cialised domain, which can be superfi-
cially characterised as having telegraphic
sentences involving displaced or missing
words, abundant abbreviations, spelling
variations including misspellings, and ter-
minology. We report results on lexical
simplification of Swedish EHRs, by which
we mean detecting the unknown, out-of-
dictionary words and trying to resolve
them either as compounded known words,
abbreviations or misspellings.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999992943396227">
An electronic health record (EHR; Swedish: pa-
tientjournal) contains systematic documentation
of a single patient’s medical history across time,
entered by healthcare professionals with the pur-
pose of enabling safe and informed care. The
value of EHRs is further increased by the fact that
they provide a source of information for statis-
tics and research, and a documentation for the pa-
tient through the Swedish Patient Data Act. EHRs
collect information from a range of sources, such
as administration of drugs and therapies, test re-
sults, preoperative notes, operative notes, progress
notes, discharge notes, etc.
EHRs contain both structured parts (such as
details about the patient, lab results, diagnostic
codes, etc.) and unstructured parts (in the form of
free text). The free-text part of EHRs is referred
to as clinical text, as opposed to the kind of gen-
eral medical text found in medical journals, books
or web pages containing information about health
care. Clinical texts have many subdomains de-
pending on the medical speciality of the writer and
the intended reader. There are more formal kinds
of EHRs, such as discharge summaries and radiol-
ogy reports, directed to other physicians, and more
informal kinds such as daily notes, produced by
nurses and physicians (as memory notes for them-
selves or for the team). In spite of the Patient Data
Act, the patient is seldom seen as a receiver or
reader of the document.
Linguistically, health records exemplify a
highly specialised domain, which can be super-
ficially characterised as having telegraphic sen-
tences involving displaced or missing words,
abundant abbreviations, undisputed misspellings,
spelling variation which may or may not amount to
misspellings depending on the degree of prescrip-
tivism, and terminology. While this specialised
style has evolved as an efficient means of com-
munication between healthcare professionals, it
presents formidable challenges for laymen trying
to decode it.
In spite of this, there has been no previous work
on the problem of automatically improving the
readability of Swedish EHRs. As an initial at-
tempt in this direction, we provide an automatic
approach to the problem of lexical simplification,
by which we mean detecting the unknown, out of
dictionary words and trying to resolve them either
as compounds generated from known words, as
abbreviations or as misspellings. As an additional
result, we obtain a distribution of how prevalent
these problems are in the clinical domain.
</bodyText>
<sectionHeader confidence="0.858858" genericHeader="introduction">
2 Lexical challenges to readability of
EHRs
</sectionHeader>
<bodyText confidence="0.972916">
A major reason for the obstacles to readability of
EHRs for laymen stems from the fact that they
</bodyText>
<page confidence="0.986219">
74
</page>
<note confidence="0.9940725">
Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 74–83,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999542044444445">
are written under time pressure by professionals,
for professionals (Kvist et al., 2011). This re-
sults in a telegraphic style, with omissions, ab-
breviations and misspellings, as reported for sev-
eral languages including Swedish, Finnish, En-
glish, French, Hungarian and German (Laippala
et al., 2009; Friedman et al., 2002; Hag`ege et
al., 2011; Surj´an and H´eja, 2003; Bretschneider et
al., 2013). The omitted words are often subjects,
verbs, prepositions and articles (Friedman et al.,
2002; Bretschneider et al., 2013).
Unsurprisingly, medical terminology abounds
in EHRs. What makes this problem an even
greater obstacle to readability is that many medical
terms (and their inflections) originate from Latin
or Greek. Different languages have adapted these
terms differently (Bretschneider et al., 2013). The
Swedish medical terminology went through a
change during the 1990s due to a swedification
of diagnostic expressions performed in the 1987
update of the Swedish version of ICD, the Inter-
national Classification of Diseases1. For this ver-
sion, the Swedish National Board of Health and
Welfare decided to partly change the terminology
of traditional Latin- and Greek-rooted words to a
spelling compatible to Swedish spelling rules, as
well as abandoning the original rules for inflec-
tion (Smedby, 1991). In this spelling reform, c
and ch pronounced as k was changed to k, ph was
changed to f, th to t, and oe was changed to e.
For example, the technical term for cholecsystitis
(inflammation of the gall bladder) is spelled kole-
cystit in contemporary Swedish, thus following the
convention of changing ch to k and removing the
Latin ending of -is. The results2 of exact match-
ing to kolecystit (English: cholecystitis) and some
presumed spelling variants clearly demonstrate the
slow progress (Table 1).
As medical literature is predominantly written
in English nowadays, physicians increasingly get
exposed to the English spelling of Latin and Greek
words rather than the Swedish one. This has re-
sulted in a multitude of alternate spellings of sev-
eral medical terms. For example, tachycardia
(rapid heart) is correctly spelled takykardi, but is
</bodyText>
<footnote confidence="0.995971375">
1http://www.who.int/classifications/
icd/en/
2Based on a subset of the Stockholm Electronic Pa-
tient Record Corpus (Dalianis et al., 2012) of 100,000 daily
notes (DAY) written by physicians of varying disciplines (4
mill. tokens) and 435,000 radiology reports (X-RAY) writ-
ten by radiologists (20 mill. tokens). KORP: http://
spraakbanken.gu.se/korp/
</footnote>
<table confidence="0.98989975">
Term KORP DAY X-RAY
kolecystit 51 48 84
colecystit 0 1 8
cholecystit 4 88 1613
</table>
<tableCaption confidence="0.998702">
Table 1: Alternate spellings of the Swedish
</tableCaption>
<bodyText confidence="0.962719190476191">
medical term kolecystit (eng. cholecystitis) in
the Swedish corpus collection Korp, daily notes
(DAY) and radiology reports (X-RAY), respec-
tively. Correct spelling in bold.
also frequently found as tachycardi, tachykardi,
and takycardi (Kvist et al., 2011). A similar
French study found this kind of spelling variation
to be abundant as well (Ruch et al., 2003).
EHRs also contain neologisms. These are often
verbs, typically describing events relating to the
patient in active form, such as ”the patient is in-
farcting” (Swedish: patienten infarcerar) instead
of the unintentional ”the patient is having a my-
ocardial infarction”. Similar phenomena are de-
scribed by Josefsson (1999).
Abbreviations and acronyms in EHRs can fol-
low standardised writing rules or be ad hoc (Liu
et al., 2001). They are often domain-specific
and may be found in medical dictionaries such
as MeSH3 and Snomed CT4. For instance, 18 of
the 100 most common words in Swedish radiol-
ogy reports were abbreviations, and 10 of them
were domain-specific (Kvist and Velupillai, 2013).
Because many medical terms are multiword ex-
pressions that are repeated frequently in a pa-
tient’s EHR, the use of acronyms is very common.
Skeppstedt et al. (2012) showed that 14% of di-
agnostic expressions were abbreviated in Swedish
clinical text.
Abbreviations are often ambiguous. As an
example, 33% of the short abbreviations in the
UMLS terminology are ambiguous (Liu et al.,
2001). Pakhomov et al. (2005) found that the ab-
breviation RA had more than 20 expansions in the
UMLS terminology alone. Furthermore, a certain
word or expression can be shortened in several dif-
ferent ways. For instance, in a Swedish intensive
care unit, the drug Noradrenalin was creatively
written in 60 different ways by the nurses (Allvin
et al., 2011).
It should be noted that speech recognition, al-
though common in many hospitals around the
</bodyText>
<footnote confidence="0.9999355">
3www.ncbi.nlm.nih.gov
4http://www.ihtsdo.org/
</footnote>
<page confidence="0.999387">
75
</page>
<bodyText confidence="0.999956875">
world, has not been introduced in Sweden, and
many physicians and all nurses type the notes
themselves. This is one explanation to the vari-
ation with respect to abbreviations.
User studies have shown that the greatest bar-
riers for patients lie mainly in the frequent use
of abbreviations, jargon and technical terminol-
ogy (Pyper et al., 2004; Keselman et al., 2007;
Adnan et al., 2010). The most common com-
prehension errors made by laymen concern clini-
cal concepts, medical terminology and medication
names. Furthermore, there are great challenges for
higher-level processing like syntax and semantics
(Meystre et al., 2008; Wu et al., 2013). The re-
search presented in this paper focuses on lexical
simplification of clinical text.
</bodyText>
<sectionHeader confidence="0.999376" genericHeader="method">
3 Related research
</sectionHeader>
<bodyText confidence="0.999992454545454">
We are aware of several efforts to construct au-
tomated text simplification tools for clinical text
in English (Kandula et al., 2010; Patrick et al.,
2010). For Swedish, there are few studies on med-
ical language from a readability perspective. Borin
et al. (2009) present a thorough investigation on
Swedish (and English) medical language, but EHR
texts are explicitly not included. This section sum-
marizes research on Swedish (clinical) text with
respect to lexical simplification by handling of ab-
breviations, terminology and spelling correction.
</bodyText>
<subsectionHeader confidence="0.999455">
3.1 Abbreviation detection
</subsectionHeader>
<bodyText confidence="0.999919692307692">
Abbreviation identification in English biomedical
and clinical texts has been studied extensively (e.g.
Xu et al. (2007), Liu et al. (2001)). For detec-
tion of Swedish medical abbreviations, there are
fewer studies. Dann´ells (2006) reports detection
of acronyms in medical journal text with 98% re-
call and 94% precision by using part of speech
information and heuristic rules. Clinical Swedish
presents greater problems than medical texts, be-
cause of ad hoc abbreviations and noisier text. By
using lexicons and a few heuristic rules, Isenius et
al. (2012) report the best F-score of 79% for ab-
breviation detection in clinical Swedish.
</bodyText>
<subsectionHeader confidence="0.999745">
3.2 Compound splitting
</subsectionHeader>
<bodyText confidence="0.999963352941176">
Good compound analysis is critical especially for
languages whose orthographies concatenate com-
pound components. Swedish is among those lan-
guages, in which every such concatenation thus
corresponds to a word. The most common ap-
proach to compound splitting is to base it on a lex-
icon providing restrictions on how different word
forms can be used for generating compounds. For
example, Sj¨obergh and Kann (2006) used a lex-
icon derived from SAOL (the Swedish Academy
word list), and ¨Ostling and Wir´en (2013) used the
SALDO lexicon of Swedish morphology (Borin
and Forsberg, 2009). With this kind of approach,
compound splitting is usually very reliable for
genres like newspaper text, with typical accuracies
for Swedish around 97%, but performs poorer in
domain specific genres.
</bodyText>
<subsectionHeader confidence="0.997867">
3.3 Terminology detection
</subsectionHeader>
<bodyText confidence="0.999976647058824">
The detection of English medical terminology is
a widely researched area. An example of term
detection in English clinical texts is Wang and
Patrick (2009) work based on rule-based and ma-
chine learning methods, reporting 84% precision.
For Swedish clinical text, Kokkinakis and
Thurin (2007) have employed domain terminol-
ogy matching and reached 98% precision and 87%
recall in detecting terms of disorders. Using sim-
ilar approaches, Skeppstedt et al. (2012), reached
75% precision and 55% recall in detecting terms
of disorders. With a machine learning based ap-
proach, improved results were obtained: 80%
precision, 82% recall (Skeppstedt et al., 2014).
Skeppstedt et al. (2012) have also demonstrated
the negative influence of abbreviations and mul-
tiword expressions in their findings.
</bodyText>
<subsectionHeader confidence="0.997613">
3.4 Spelling correction
</subsectionHeader>
<bodyText confidence="0.999665111111111">
A system for general spelling correction of
Swedish is described by Kann et al. (1998), but
we are not aware of any previous work related to
spelling correction of Swedish clinical text. An
example of spelling correction of clinical text for
other languages is Tolentino et al. (2007), who use
several algorithms for word similarity detection,
including phonological homonym lookup and n-
grams for contextual disambiguation. They report
a precision of 64% on English medical texts. An-
other example is Patrick et al. (2010) and Patrick
and Nguyen (2011), who combine a mixture of
generation of spelling candidates based on ortho-
graphic and phonological edit distance, and a 2-
word window of contextual information for rank-
ing the spelling candidates resulting in an accuracy
of 84% on English patient records. Sikl´oski et al.
(2013) use a statistical machine translation model
</bodyText>
<page confidence="0.971006">
76
</page>
<figureCaption confidence="0.8628385">
Figure 1: Distribution of 100 PR dataset sentences by length (number of sentences on the y-axis and
number of tokens on the x-axis).
</figureCaption>
<bodyText confidence="0.985508">
(with 3-grams) for spelling correction, achieving
88% accuracy on Hungarian medical texts.
</bodyText>
<sectionHeader confidence="0.992831" genericHeader="method">
4 Experimental data
</sectionHeader>
<bodyText confidence="0.999925173913043">
This study uses clinical notes5 from the Stockholm
Electronic Patient Record corpus containing more
than 600,000 patients of all ages from more than
500 health units during 2006–2013 (Dalianis et al.,
2012).
A randomly selected subset of 100 daily notes
from different EHRs written by physicians be-
tween 2009–2010 was used as a gold standard
dataset for evaluating abbreviation detection, com-
pound splitting and spelling corrections. This 100
daily notes dataset contains 433 sentences and
3,888 tokens, as determined by Stagger (¨Ostling,
2013), a Swedish tokenizer and POS tagger. The
majority of sentences contain between 4–11 to-
kens (see Figure 1.)
The text snippet in Figure 2 provides an illus-
trative example of the characteristics of a health
record. What is immediately striking is the num-
ber of misspellings, abbreviations, compounds and
words of foreign origin. But also the syntax is
peculiar, alternating between telegraphic clauses
with implicit arguments, and long sentences with
complex embeddings.
</bodyText>
<footnote confidence="0.941723">
5Approved by the Regional Ethical Review Board in
Stockholm (Etikpr¨ovningsn¨amnden i Stockholm), permis-
sion number 2012/2028-31/5
</footnote>
<sectionHeader confidence="0.980546" genericHeader="method">
5 Lexical normalization of EHRs
</sectionHeader>
<bodyText confidence="0.999926956521739">
Normalization of lexis in clinical text relies heav-
ily on the lookup in available lexicons, corpora and
domain terminologies. Although these resources
usually cover the majority of words (i.e. tokens)
in texts, however due to the ever evolving lan-
guage and knowledge inside the domain, medi-
cal texts, when analysed with the NLP tools, also
contain unknown6 words. These remaining words
that are not covered by any lexicon, or corpora re-
source, can be misspellings, abbreviations, com-
pounds (new word formations), words in foreign
languages (Latin, Greek, English), or new terms.
Our approach to dealing with unknown words
combines a rule-based abbreviation detection and
Swedish statistical language model-based com-
pound analysis and misspelling resolution.
The following sections describe three methods
that are applied in a pipeline manner. That is, first,
all known abbreviations are detected and marked;
second the unknown words are checked whether
they are compounds; finally, for the remaining un-
known words, context dependent word corrections
are made.
</bodyText>
<subsectionHeader confidence="0.994288">
5.1 Detecting abbreviations
</subsectionHeader>
<bodyText confidence="0.99051325">
This section describes the heuristics and lexi-
con lookup-based abbreviation detection method.
The Swedish Clinical Abbreviation and Medi-
cal Terminology Matcher (SCATM) is based on
</bodyText>
<footnote confidence="0.998317">
6By unknown words we mean words that cannot be
looked up in available lexical resources or linguistically ana-
lyzed by POS tokenizer.
</footnote>
<page confidence="0.996565">
77
</page>
<figureCaption confidence="0.9836055">
Figure 2: Characteristics of a health record: misspellings (underline), abbreviations (bold), compounds
(italic) and words of foreign origin (red).
</figureCaption>
<bodyText confidence="0.996697111111111">
SCAN (Isenius et al., 2012). The SCATM method
uses domain-adapted Stagger ( ¨Ostling, 2013)
for the tokenization and POS-tagging of text.
The adapted version of Stagger handles clinical-
specific7 abbreviations from three domains, i.e. ra-
diology, emergency, and dietology. SCATM also
uses several lexicons to determine whether a word
is a common word (in total 122,847 in the lexi-
con), an abbreviation (in total 7,455 in the lexi-
con), a medical term (in total 17,380 in the lexi-
con), or a name (both first and last names, in total
404,899 in the lexicon). All words that are at most
6 characters long, or contains the characters ”-”
and/or ”.” are checked against these lexicons in a
specific order in order to determine whether it is
an abbreviation or not.
The SCATM method uses various lexicons8 of
Swedish medical terms, Swedish abbreviations,
</bodyText>
<footnote confidence="0.597335416666667">
7Abbreviations that do not follow conventional orthogra-
phy styles, e.g. a typical abbreviation p.g.a. (en. due to) can
have the following variants p g a, pga, p. G. A., p. gr. a.
8the sources of lexicons are: anatomin.se,
neuro.ki.se smittskyddsinstitutet.se,
medicinskordbok.se, runeberg.org, g3.
spraakdata.gu.se/saob, sv.wikipedia.org/
wiki/Lista_ver_frkortningar, karolinska.
se/Karolinska-Universitetslaboratoriet/
Sidor-om-PTA/Analysindex-alla-enheter/
Forkortningar/ and the list of Swedish names (Carlsson
and Dalianis, 2010).
</footnote>
<bodyText confidence="0.766366">
Swedish words and Swedish names (first and last).
</bodyText>
<subsectionHeader confidence="0.99621">
5.2 Compound splitting
</subsectionHeader>
<bodyText confidence="0.9812904375">
For compound splitting, we use a collection of lex-
ical resources, the core of which is a full-form
dictionary produced by Nordisk spr˚akteknologi
holding AS (NST), comprising 927,000 en-
tries9. In addition, various resources from the
medical domain have been mined for vocab-
ulary: Swedish SNOMED10 terminology, the
L¨akartidningen medical journal11 corpus, and
Swedish Web health-care guides/manuals12.
A refinement of the basic lexicon-driven tech-
nique described in the related research section is
that our compound splitting makes use of contex-
tual disambiguation. As the example of hj¨arteko
illustrates, this compound can be hypothetically
split into13:
hj¨art+eko (en. cardiac+echo)
</bodyText>
<footnote confidence="0.997757909090909">
9Available at: www.nb.no/Tilbud/Forske/
Spraakbanken/Tilgjengelege-ressursar/
Leksikalske-ressursar
10www.socialstyrelsen.se/
nationellehalsa/nationelltfacksprak/
11http://spraakbanken.gu.se/eng/
research/infrastructure/korp
12www.1177.se and www.vardguiden.se
13Korp (http://spraakbanken.gu.se/korp) is a collection of
Swedish corpora, comprising 1,784,019,272 tokens, as of
January 2014.
</footnote>
<page confidence="0.989739">
78
</page>
<figure confidence="0.594337153846154">
KORP freq.: 642 + 5,669
hj¨arte+ko (en. beloved+cow)
KORP freq.: 8 + 8,597
For choosing the most likely composition in the
given context, we use the Stockholm Language
Model with Entropy (SLME) ( ¨Ostling, 2012)
which is a simple n-gram language model.
The max probability defines the correct word
formation constituents:
hj¨art+eko 2.3e-04
hj¨arte+ko 5.1e-07
The SMLE is described in the following section.
5.3 Misspelling detection
</figure>
<figureCaption confidence="0.25867725">
The unknown words that are not abbreviations or
compounds can very likely be misspellings. Mis-
spellings can be a result of typing errors or the lack
of knowledge of the correct spelling.
</figureCaption>
<bodyText confidence="0.964406761904762">
Our approach to clinical Swedish misspellings
is based on the best practices of spell checkers
for Indo-European languages, namely the phonetic
similarity key method combined with a method
to measure proximity between the strings. In
our spelling correction method, the Edit distance
(Levenshtein, 1966) algorithm is used to measure
the proximity of orthographically possible can-
didates. The Soundex algorithm (Knuth, 1973)
shortlists the spelling candidates which are phono-
logically closest to the misspelled word. Further,
the spelling correction candidates are analyzed in
a context by using the SLME n-gram model.
The SLME employs the Google Web 1T 5-
gram, 10 European Languages, Version 1, dataset
for Swedish, which is the largest publically avail-
able Swedish data resource. The SLME is a sim-
ple n-gram language model, based on the Stupid
Backoff Model (Brants et al., 2007). The n-gram
language model calculates the probability of a
word in a given context:
</bodyText>
<figure confidence="0.638878">
L L i−1 L Pˆ (wi|wi−1
P(w1 ) = i=1 P (wi|w1 ) ≈ i=1 i−n+1)
(1)
</figure>
<bodyText confidence="0.832519">
The maximum-likelihood probability estimates
for the n-grams are calculated by their relative fre-
quencies:
</bodyText>
<equation confidence="0.994276125">
i−1 i (2)
r(wi|wi−n+1) = f(wi−n+1)
i−1
f(wi−n+1)
The smoothing is used when the complete n-
1
gram is not found. If r(wi−i−n+1) is not found,
i−1 i−1
</equation>
<bodyText confidence="0.931444666666667">
then the model looks for r(wi−n+2) , r(wi−n+3),
and so on. The Stupid backoff (Brants et al.,
2007) smoothing method uses relative frequencies
instead of normalized probabilities and context-
dependent discounting. Equation (3) shows how
score S is calculated:
</bodyText>
<equation confidence="0.9957445">
i−1
S(wi|wi−k+1) =
</equation>
<bodyText confidence="0.9988032">
The backoff parameter α is set to 0.4, which was
heuristically determined by (Brants et al., 2007).
The recursion stops when the score for the last
context word is calculated. N is the size of the
corpus.
</bodyText>
<equation confidence="0.9803385">
S(wi) = f(wi) (4)
N
</equation>
<bodyText confidence="0.991823181818182">
The SLME n-gram model calculates the
probability of a word in a given context:
p(word|context). The following example14
shows the case of spelling correction:
Original:
Vpl p˚a onsdag. UK tortdag.
(en. Vpl on wednesday. UK thsday.)
torgdag (en. marketday): 4.2e-10
torsdag (en. Thursday): 1.1e-06
Corrected:
Vpl p˚a onsdag. UK torsdag.
</bodyText>
<sectionHeader confidence="0.994362" genericHeader="evaluation">
6 Experiments and results
</sectionHeader>
<bodyText confidence="0.937094285714286">
Our approach to lexical normalization was
tested against a gold standard, namely, the 100
EHR daily notes dataset. The dataset was anno-
tated for abbreviations, compounds including ab-
breviations and misspellings by a physician.
We carried out the following experiments (see
Table 2):
</bodyText>
<footnote confidence="0.748949">
1. SCATM to mark abbreviations and terms;
14Vpl stands for V˚ardplanering (en. planning for care), UK
stands for utskrivningsklar (en. ready for discharge).
</footnote>
<equation confidence="0.907639384615385">
{
=
i−1
i−k+1)
i−1
αS(wi|wi−k+2) otherwise
i
iff(wi−k+1)) &gt; 0
(3)
f(w
f(w
i
i−k+1)
</equation>
<page confidence="0.994536">
79
</page>
<table confidence="0.999671230769231">
Method Lexical normalization task Gold- Precision, % Recall, %
standard,
occurences
SCATM 1 Abbreviation detection 550 91.1 81.0
SCATM 1a Abbreviations included in 78 89.74 46.15
compounds only
NoCM 1 Out-of-dictionary compound 97 83.5 -
splitting
NoCM 1a Out-of-dictionary com- 44 59.1 -
pounds which include
abbreviations
NoCM 2 Spelling correction 41 54.8 63.12
SCATM+NoCM Spelling correction 41 83.87 76.2
</table>
<tableCaption confidence="0.998643">
Table 2: Results of lexical normalization.
</tableCaption>
<listItem confidence="0.999177666666667">
2. NoCM (lexical normalization of compounds
and misspellings as described in sections
5.2 and 5.3) to resolve compounds and mis-
spellings;
3. The combined experiment SCATM+NoCM
to resolve misspellings.
</listItem>
<bodyText confidence="0.99998368">
The last experimental setting was designed as a
solution to deal with compounds that include ab-
breviations. Marking abbreviations prior to the
spelling correction can help to reduce the number
of false positives.
The 433 sentences contained a total of 550 ab-
breviations (78 of these were constituents of com-
pound words), and 41 misspellings of which 13
were misspelled words containing abbreviations.
Due to the tokenization errors, a few sentence
boundaries were detected incorrectly, e.g. inter-
rupted dates and abbreviations. Because of this
some abbreviations were separated into different
sentences and thus added to false negatives and
false positives.
The first experiment (SCATM 1 and 1a) of de-
tecting abbreviations achieved both high precision
and recall. As a special case of demonstrating the
source of errors (see SCATM 1a) is the evaluation
of detecting abbreviations which are part of com-
pounds only. The low recall is due to the design of
the SCATM which does not handle words longer
than 6 characters, thus resulting in compounded
abbreviations like k¨arlkir or ¨overvak to go unde-
tected.
The evaluation of the second experiment
(NoCM 1, 1a and 2) showed that the majority
of out-of-dictionary compounds was resolved cor-
rectly (NoCM 1) and reached 83.5% precision.
Errors mainly occurred due to spelling candi-
date ranking, e.g. even+tull instead of eventuell
and compounds containing abbreviations and mis-
spelled words. As a special case of demonstrating
the source of errors of the latter (see NoCM 1a) is
the evaluation of those compounds15 only which
contain abbreviations. The task of spelling correc-
tion (NoCM 2) performed poorly, reaching only
54.8% precision. This can be explained by failing
to resolve misspellings in compounds where ab-
breviations are compounded together with a mis-
spelled words, e.g. aciklocvirkonc (aciklovir kon-
centrate).
The third experiment (SCATM+NoCM) com-
bined abbreviation detection followed by the out-
of-dictionary word normalization (spelling cor-
rection and compound splitting). This setting
helped to resolve the earlier source of errors, i.e.
words that contain both misspelling(s) and abbre-
viation(s). The overall precision of spelling cor-
rection is 83.87%.
</bodyText>
<sectionHeader confidence="0.993935" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999966285714286">
Our attempt to address the problem of lexical sim-
plification, and, in the long run, improve readabil-
ity of Swedish EHRs, by automatically detecting
and resolving out of dictionary words, achieves
91.1% (abbreviations), 83.5% (compound split-
ting) and 83.87% (spelling correction) precision,
respectively. These results are comparable to those
</bodyText>
<footnote confidence="0.667013">
15This number of compounds is derived from the number
of abbreviations included in compounds (from SCATM 1a)
by selecting only those out-of -dictionary words which do not
contain punctuation.
</footnote>
<page confidence="0.996851">
80
</page>
<bodyText confidence="0.999864892857143">
reported in similar studies on English and Hungar-
ian patient records (Patrick et al., 2010; Sikl´osi et
al., 2013).
Furthermore, the analysis of the gold standard
data revealed that around 14% of all words in
Swedish EHRs are abbreviations. More specifi-
cally, 2% of all the words are compounds includ-
ing abbreviations. In contrast, and somewhat un-
expectedly, only 1% are misspellings. This dis-
tribution result is an important finding for future
studies in lexical simplification and readability
studies of EHRs, as it might be useful for inform-
ing automatic processing approaches.
We draw two conclusions from this study. First,
to advance research into the field of readability
of EHRs, and thus to develop suitable readability
measures it is necessary to begin by taking these
findings into account and by relating abbrevia-
tions, spelling variation, misspellings, compounds
and terminology to reading comprehension.
Second, as a future guideline for the overall
pipeline for detecting and resolving unknown, out-
of-dictionary words, we suggest handling abbrevi-
ations in a first step, and then taking care of mis-
spellings and potential compounds. The most ur-
gent area for future improvement of the method is
to handle compound words containing both abbre-
viations and misspellings.
</bodyText>
<sectionHeader confidence="0.974535" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9996945">
The authors wish to thank the anonymous review-
ers for valuable feedback. Maria Kvist and Sum-
ithra Velupillai were in part funded by the V˚ardal
Foundation, Sumithra also by the Swedish Re-
search Council and the Swedish Fulbright com-
mission. We thank Robert ¨Ostling who pro-
vided the POS tagger and the Stockholm Lan-
guage Model with Entropy.
</bodyText>
<sectionHeader confidence="0.997099" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995753205882353">
M. Adnan, J. Warren, and M. Orr. 2010. Assess-
ing text characteristics of electronic discharge sum-
maries and their implications for patient readabil-
ity. In Proceedings of the Fourth Australasian Work-
shop on Health Informatics and Knowledge Man-
agement - Volume 108, HIKM ’10, pages 77–84,
Darlinghurst, Australia, Australia. Australian Com-
puter Society, Inc.
H. Allvin, E. Carlsson, H. Dalianis, R. Danielsson-
Ojala, V. Daudaravicius, M. Hassel, D. Kokki-
nakis, H. Lundgren-Laine, G.H. Nilsson, Ø. Nytrø,
S. Salanter¨a, M. Skeppstedt, H. Suominen, and
S. Velupillai. 2011. Characteristics of Finnish and
Swedish intensive care nursing narratives: a com-
parative analysis to support the development of clin-
ical language technologies. Journal of Biomedical
Semantics, 2(Suppl 3):S1, doi:10.1186/2041-1480-
2-S3-S1, July.
L. Borin and M. Forsberg. 2009. All in the family: A
comparison of SALDO and WordNet. In Proceed-
ings of the Nodalida 2009 Workshop on WordNets
and other Lexical Semantic Resources, pages 7–12.
NEALT.
L. Borin, N. Grabar, M. Gronostaj, C. Hallett, D. Hard-
castle, D. Kokkinakis, S. Williams, and A. Willis.
2009. Semantic Mining Deliverable D27.2: Em-
powering the patient with language technology.
Technical report, Semantic Mining (NOE 507505).
T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean.
2007. Large language models in machine transla-
tion. In In Proceedings of the 2007 Joint Conference
EMNLP-CoNLL, pages 858–867.
C. Bretschneider, S. Zillner, and M. Hammon. 2013.
Identifying pathological findings in German radiol-
ogy reports using a syntacto-semantic parsing ap-
proach. In Proceedings of the 2013 Workshop on
Biomedical Natural Language Processing (BioNLP
2013). ACL.
E. Carlsson and H. Dalianis. 2010. Influence of Mod-
ule Order on Rule-Based De-identification of Per-
sonal Names in Electronic Patient Records Writ-
ten in Swedish. In Proceedings of the Seventh In-
ternational Conference on Language Resources and
Evaluation, LREC 2010, pages 3071–3075, Valletta,
Malta, May 19–21.
H. Dalianis, M. Hassel, A. Henriksson, and M. Skepp-
stedt. 2012. Stockholm EPR Corpus: A Clinical
Database Used to Improve Health Care. In Pierre
Nugues, editor, Proc. 4th SLTC, 2012, pages 17–18,
Lund, October 25-26.
D. Dann´ells. 2006. Automatic acronym recognition.
In Proceedings of the 11th conference on European
chapter of the Association for Computational Lin-
guistics (EACL).
C. Friedman, P. Kra, and A. Rzhetsky. 2002. Two
biomedical sublanguages: a description based on the
theories of Zellig Harris. Journal of Biomedical In-
formatics, 35(4):222–235.
C. Hag`ege, P. Marchal, Q. Gicquel, S. Darmoni,
S. Pereira, and M. Metzger. 2011. Linguistic
and temporal processing for discovering hospital ac-
quired infection from patient records. In Proceed-
ings of the ECAI 2010 Conference on Knowledge
Representation for Health-care, KR4HC’10, pages
70–84, Berlin, Heidelberg. Springer-Verlag.
N. Isenius, S. Velupillai, and M. Kvist. 2012. Initial
results in the development of scan: a swedish clini-
cal abbreviation normalizer. In Proceedings of the
</reference>
<page confidence="0.995215">
81
</page>
<reference confidence="0.995859037735849">
CLEF 2012 Workshop on Cross-Language Evalu-
ation of Methods, Applications, and Resources for
eHealth Document Analysis - CLEFeHealth2012,
Rome, Italy, September. CLEF.
G. Josefsson. 1999. Fifeber eller tempa? Nigra
tankar om agentivitet i medicinskt facksprik.
S. Kandula, D. Curtis, and Q. Zeng-Treitler. 2010. A
Semantic and Syntactic Text Simplification Tool for
Health Content. In Proc AMIA 2010, pages 366–
370.
V. Kann, R. Domeij, J. Hollman, and M. Tillenius.
1998. Implementation Aspects and Applications of
a Spelling Correction Algorithm.. Technical Report
TRITA-NA-9813, NADA, KTH.
A. Keselman, L. Slaughter, CA. Smith, H. Kim, G. Di-
vita, A. Browne, and et al. 2007. Towards
consumer-friendly PHRs: patients experience with
reviewing their health records. In AMIA Annu Symp
Proc 2007, pages 399–403.
D. E. Knuth, 1973. The Art of Computer Program-
ming: Volume 3, Sorting and Searching, pages 391–
392. Addison-Wesley.
D. Kokkinakis and A. Thurin. 2007. Identifica-
tion of Entity References in Hospital Discharge Let-
ters. In Proceedings of the 16th Nordic Conference
of Computational Linguistics (NODALIDA) 2007,
pages 329–332, Tartu, Estonia.
M. Kvist and S. Velupillai. 2013. Professional
Language in Swedish Radiology Reports – Char-
acterization for Patient-Adapted Text Simplifica-
tion. In Proceedings of the Scandinavian Con-
ference on Health Informatics 2013, Copenhagen,
Denmark, August. Link¨oping University Electronic
Press, Link¨opings universitet.
M. Kvist, M. Skeppstedt, S. Velupillai, and H. Dalianis.
2011. Modeling human comprehension of swedish
medical records for intelligent access and summa-
rization systems, a physician’s perspective. In Proc.
9th Scandinavian Conference on Health Informat-
ics, SHI, Oslo, August.
V. Laippala, F. Ginter, S. Pyysalo, and T. Salakoski.
2009. Towards automated processing of clinical
Finnish: Sublanguage analysis and a rule-based
parser. Int journal of medical informatics, 78:e7–
e12.
VI Levenshtein. 1966. Binary Codes Capable of Cor-
recting Deletions, Insertions and Reversals. Soviet
Physics Doklady, 10:707–710.
H. Liu, Y. A. Lussier, and C. Friedman. 2001. Disam-
biguating Ambiguous Biomedical Terms in Biomed-
ical Narrative Text: An Unsupervised Method.
Journal of Biomedical Informatics, 34:249–261.
S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler,
and John E. Hurdle. 2008. Extracting informa-
tion from textual documents in the electronic health
record: a review of recent research. IMIA Yearbook
of Medical Informatics 2008. 47 Suppl 1:138-154.
R. ¨Ostling and M. Wir´en, 2013. Compounding in
a Swedish Blog Corpus, pages 45–63. Stockholm
Studies in Modern Philology. New series 16. Stock-
holm university.
R. ¨Ostling. 2012.
http://www.ling.su.se/english/nlp/tools/slme/stockholm-
language-model-with-entropy-slme-1.101098 .
R. ¨Ostling. 2013. Stagger: an Open-Source Part of
Speech Tagger for Swedish. Northern European
Journal of Language Technology, 3:1–18.
S. Pakhomov, T. Pedersen, and C. G. Chute. 2005. Ab-
breviation and Acronym Disambiguation in Clinical
Discourse. In Proc AMIA 2005, pages 589–593.
J. Patrick and D. Nguyen. 2011. Automated Proof
Reading of Clinical Notes. In Helena Hong Gao
and Minghui Dong, editors, PACLIC, pages 303–
312. Digital Enhancement of Cognitive Develop-
ment, Waseda University.
J. Patrick, M. Sabbagh, S. Jain, and H. Zheng. 2010.
Spelling correction in Clinical Notes with Emphasis
on First Suggestion Accuracy. In 2nd Workshop on
Building and Evaluating Resources for Biomedical
Text Mining, pages 2–8.
C. Pyper, J. Amery, M. Watson, and C. Crook. 2004.
Patients experiences when accessing their on-line
electronic patient records in primary care. The
British Journal of General Practice, 54:38–43.
P. Ruch, R. Baud, and A. Geissb¨uhler. 2003. Using
lexical disambiguation and named-entity recogni-
tion to improve spelling correction in the electronic
patient record. Artificial Intelligence in Medicine,
29(1-2):169–184.
B. Sikl´osi, A. Nov´ak, and G. Pr´osz´eky, 2013. Context-
Aware Correction of Spelling Errors in Hungar-
ian Medical Documents, pages 248–259. Number
Lecture Notes in Computer Science 7978. Springer
Berlin Heidelberg.
J. Sj¨obergh and V. Kann. 2006. Vad kan statistik
avsl¨oja om svenska sammans¨attningar? Spr˚ak och
stil, 1:199–214.
M. Skeppstedt, M. Kvist, and H Dalianis. 2012.
Rule-based Entity Recognition and Coverage of
SNOMED CT in Swedish Clinical Text. In Pro-
ceedings of the Eighth International Conference on
Language Resources and Evaluation, LREC 2012,
pages 1250–1257, Istanbul, Turkey, May 23–25.
M. Skeppstedt, M. Kvist, G. H. Nilsson, and H. Dalia-
nis. 2014. Automatic recognition of disorders,
findings, pharmaceuticals and body structures from
</reference>
<page confidence="0.980767">
82
</page>
<reference confidence="0.99916971875">
clinical text: An annotation and machine learn-
ing study. Journal of Biomedical Informatics,
http://dx.doi.org/10.1016/j.jbi.2014.01.012.
B. Smedby. 1991. Medicinens Spr˚ak: spr˚aket
i sjukdomsklassifikationen – mer konsekvent
f¨orsvenskning efterstr¨avas [Language of Medicine:
the language of diagnose classification - more
consequent Swedification sought]. L¨akartidningen,
pages 1519–1520.
G. Surj´an and G. H´eja. 2003. About the language of
Hungarian discharge reports. Stud Health Technol
Inform, 95:869–873.
H. D. Tolentino, M. D. Matters, W. Walop, B. Law,
W. Tong, F. Liu, P. A. Fontelo, K. Kohl, and D. C.
Payne. 2007. A UMLS-based spell checker for nat-
ural language processing in vaccine safety. BMC
Med. Inf. &amp; Decision Making, 7.
Y. Wang and J. Patrick. 2009. Cascading classifiers for
named entity recognition in clinical notes. In Pro-
ceedings of the Workshop on Biomedical Informa-
tion Extraction, WBIE ’09, pages 42–49, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
D. T. Y. Wu, D. A. Hanauer, Q. Mei, P. M. Clark,
L. C. An, J. Lei, J. Proulx, Q. Zeng-Treitler, and
K. Zheng. 2013. Applying Multiple Methods to As-
sess the Readability of a Large Corpus of Medical
Documents. Stud Health Technol Inform, 192:647–
651.
H. Xu, P. D. Stetson, and C. Friedman. 2007. A Study
of Abbreviations in Clinical Notes. In Proc AMIA
2007, pages 821–825.
</reference>
<page confidence="0.999313">
83
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.661996">
<title confidence="0.996647">Improving Readability of Swedish Electronic Health through Lexical Simplification: First Results</title>
<author confidence="0.999289">Maria Sumithra Mats</author>
<affiliation confidence="0.973408333333333">of Linguistics, Stockholm University, of Computer and Systems Sciences, Stockholm University, of Learning, Informatics, Management and Ethics, Karolinska Institutet,</affiliation>
<email confidence="0.8658915">gintare@ling.su.se,sumithra@dsv.su.se,mats.wiren@ling.su.se</email>
<abstract confidence="0.997907142857143">This paper describes part of an ongoing effort to improve the readability of Swedish electronic health records (EHRs). An EHR contains systematic documentation of a single patient’s medical history across time, entered by healthcare professionals with the purpose of enabling safe and informed care. Linguistically, medical records exemplify a highly specialised domain, which can be superficially characterised as having telegraphic sentences involving displaced or missing words, abundant abbreviations, spelling variations including misspellings, and terminology. We report results on lexical simplification of Swedish EHRs, by which we mean detecting the unknown, out-ofdictionary words and trying to resolve them either as compounded known words, abbreviations or misspellings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Adnan</author>
<author>J Warren</author>
<author>M Orr</author>
</authors>
<title>Assessing text characteristics of electronic discharge summaries and their implications for patient readability.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourth Australasian Workshop on Health Informatics and Knowledge Management - Volume 108, HIKM ’10,</booktitle>
<pages>77--84</pages>
<publisher>Australian Computer Society, Inc.</publisher>
<location>Darlinghurst, Australia, Australia.</location>
<contexts>
<context position="9093" citStr="Adnan et al., 2010" startWordPosition="1386" endWordPosition="1389">g Noradrenalin was creatively written in 60 different ways by the nurses (Allvin et al., 2011). It should be noted that speech recognition, although common in many hospitals around the 3www.ncbi.nlm.nih.gov 4http://www.ihtsdo.org/ 75 world, has not been introduced in Sweden, and many physicians and all nurses type the notes themselves. This is one explanation to the variation with respect to abbreviations. User studies have shown that the greatest barriers for patients lie mainly in the frequent use of abbreviations, jargon and technical terminology (Pyper et al., 2004; Keselman et al., 2007; Adnan et al., 2010). The most common comprehension errors made by laymen concern clinical concepts, medical terminology and medication names. Furthermore, there are great challenges for higher-level processing like syntax and semantics (Meystre et al., 2008; Wu et al., 2013). The research presented in this paper focuses on lexical simplification of clinical text. 3 Related research We are aware of several efforts to construct automated text simplification tools for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability pers</context>
</contexts>
<marker>Adnan, Warren, Orr, 2010</marker>
<rawString>M. Adnan, J. Warren, and M. Orr. 2010. Assessing text characteristics of electronic discharge summaries and their implications for patient readability. In Proceedings of the Fourth Australasian Workshop on Health Informatics and Knowledge Management - Volume 108, HIKM ’10, pages 77–84, Darlinghurst, Australia, Australia. Australian Computer Society, Inc.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Allvin</author>
<author>E Carlsson</author>
<author>H Dalianis</author>
<author>R DanielssonOjala</author>
<author>V Daudaravicius</author>
<author>M Hassel</author>
<author>D Kokkinakis</author>
<author>H Lundgren-Laine</author>
<author>G H Nilsson</author>
<author>Ø Nytrø</author>
<author>S Salanter¨a</author>
<author>M Skeppstedt</author>
<author>H Suominen</author>
<author>S Velupillai</author>
</authors>
<title>Characteristics of Finnish and Swedish intensive care nursing narratives: a comparative analysis to support the development of clinical language technologies.</title>
<date>2011</date>
<journal>Journal of Biomedical Semantics,</journal>
<volume>2</volume>
<pages>10--1186</pages>
<marker>Allvin, Carlsson, Dalianis, DanielssonOjala, Daudaravicius, Hassel, Kokkinakis, Lundgren-Laine, Nilsson, Nytrø, Salanter¨a, Skeppstedt, Suominen, Velupillai, 2011</marker>
<rawString>H. Allvin, E. Carlsson, H. Dalianis, R. DanielssonOjala, V. Daudaravicius, M. Hassel, D. Kokkinakis, H. Lundgren-Laine, G.H. Nilsson, Ø. Nytrø, S. Salanter¨a, M. Skeppstedt, H. Suominen, and S. Velupillai. 2011. Characteristics of Finnish and Swedish intensive care nursing narratives: a comparative analysis to support the development of clinical language technologies. Journal of Biomedical Semantics, 2(Suppl 3):S1, doi:10.1186/2041-1480-2-S3-S1, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Borin</author>
<author>M Forsberg</author>
</authors>
<title>All in the family: A comparison of SALDO and WordNet.</title>
<date>2009</date>
<booktitle>In Proceedings of the Nodalida 2009 Workshop on WordNets and other Lexical Semantic Resources,</booktitle>
<pages>7--12</pages>
<publisher>NEALT.</publisher>
<contexts>
<context position="11272" citStr="Borin and Forsberg, 2009" startWordPosition="1724" endWordPosition="1727">n in clinical Swedish. 3.2 Compound splitting Good compound analysis is critical especially for languages whose orthographies concatenate compound components. Swedish is among those languages, in which every such concatenation thus corresponds to a word. The most common approach to compound splitting is to base it on a lexicon providing restrictions on how different word forms can be used for generating compounds. For example, Sj¨obergh and Kann (2006) used a lexicon derived from SAOL (the Swedish Academy word list), and ¨Ostling and Wir´en (2013) used the SALDO lexicon of Swedish morphology (Borin and Forsberg, 2009). With this kind of approach, compound splitting is usually very reliable for genres like newspaper text, with typical accuracies for Swedish around 97%, but performs poorer in domain specific genres. 3.3 Terminology detection The detection of English medical terminology is a widely researched area. An example of term detection in English clinical texts is Wang and Patrick (2009) work based on rule-based and machine learning methods, reporting 84% precision. For Swedish clinical text, Kokkinakis and Thurin (2007) have employed domain terminology matching and reached 98% precision and 87% recal</context>
</contexts>
<marker>Borin, Forsberg, 2009</marker>
<rawString>L. Borin and M. Forsberg. 2009. All in the family: A comparison of SALDO and WordNet. In Proceedings of the Nodalida 2009 Workshop on WordNets and other Lexical Semantic Resources, pages 7–12. NEALT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Borin</author>
<author>N Grabar</author>
<author>M Gronostaj</author>
<author>C Hallett</author>
<author>D Hardcastle</author>
<author>D Kokkinakis</author>
<author>S Williams</author>
<author>A Willis</author>
</authors>
<title>Semantic Mining Deliverable D27.2: Empowering the patient with language technology.</title>
<date>2009</date>
<tech>Technical report, Semantic Mining (NOE 507505).</tech>
<contexts>
<context position="9721" citStr="Borin et al. (2009)" startWordPosition="1485" endWordPosition="1488">t common comprehension errors made by laymen concern clinical concepts, medical terminology and medication names. Furthermore, there are great challenges for higher-level processing like syntax and semantics (Meystre et al., 2008; Wu et al., 2013). The research presented in this paper focuses on lexical simplification of clinical text. 3 Related research We are aware of several efforts to construct automated text simplification tools for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability perspective. Borin et al. (2009) present a thorough investigation on Swedish (and English) medical language, but EHR texts are explicitly not included. This section summarizes research on Swedish (clinical) text with respect to lexical simplification by handling of abbreviations, terminology and spelling correction. 3.1 Abbreviation detection Abbreviation identification in English biomedical and clinical texts has been studied extensively (e.g. Xu et al. (2007), Liu et al. (2001)). For detection of Swedish medical abbreviations, there are fewer studies. Dann´ells (2006) reports detection of acronyms in medical journal text w</context>
</contexts>
<marker>Borin, Grabar, Gronostaj, Hallett, Hardcastle, Kokkinakis, Williams, Willis, 2009</marker>
<rawString>L. Borin, N. Grabar, M. Gronostaj, C. Hallett, D. Hardcastle, D. Kokkinakis, S. Williams, and A. Willis. 2009. Semantic Mining Deliverable D27.2: Empowering the patient with language technology. Technical report, Semantic Mining (NOE 507505).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>A C Popat</author>
<author>P Xu</author>
<author>F J Och</author>
<author>J Dean</author>
</authors>
<title>Large language models in machine translation. In</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference EMNLP-CoNLL,</booktitle>
<pages>858--867</pages>
<contexts>
<context position="20200" citStr="Brants et al., 2007" startWordPosition="3037" endWordPosition="3040">hod, the Edit distance (Levenshtein, 1966) algorithm is used to measure the proximity of orthographically possible candidates. The Soundex algorithm (Knuth, 1973) shortlists the spelling candidates which are phonologically closest to the misspelled word. Further, the spelling correction candidates are analyzed in a context by using the SLME n-gram model. The SLME employs the Google Web 1T 5- gram, 10 European Languages, Version 1, dataset for Swedish, which is the largest publically available Swedish data resource. The SLME is a simple n-gram language model, based on the Stupid Backoff Model (Brants et al., 2007). The n-gram language model calculates the probability of a word in a given context: L L i−1 L Pˆ (wi|wi−1 P(w1 ) = i=1 P (wi|w1 ) ≈ i=1 i−n+1) (1) The maximum-likelihood probability estimates for the n-grams are calculated by their relative frequencies: i−1 i (2) r(wi|wi−n+1) = f(wi−n+1) i−1 f(wi−n+1) The smoothing is used when the complete n1 gram is not found. If r(wi−i−n+1) is not found, i−1 i−1 then the model looks for r(wi−n+2) , r(wi−n+3), and so on. The Stupid backoff (Brants et al., 2007) smoothing method uses relative frequencies instead of normalized probabilities and contextdepende</context>
</contexts>
<marker>Brants, Popat, Xu, Och, Dean, 2007</marker>
<rawString>T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean. 2007. Large language models in machine translation. In In Proceedings of the 2007 Joint Conference EMNLP-CoNLL, pages 858–867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bretschneider</author>
<author>S Zillner</author>
<author>M Hammon</author>
</authors>
<title>Identifying pathological findings in German radiology reports using a syntacto-semantic parsing approach.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="4552" citStr="Bretschneider et al., 2013" startWordPosition="671" endWordPosition="674"> 74 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 74–83, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics are written under time pressure by professionals, for professionals (Kvist et al., 2011). This results in a telegraphic style, with omissions, abbreviations and misspellings, as reported for several languages including Swedish, Finnish, English, French, Hungarian and German (Laippala et al., 2009; Friedman et al., 2002; Hag`ege et al., 2011; Surj´an and H´eja, 2003; Bretschneider et al., 2013). The omitted words are often subjects, verbs, prepositions and articles (Friedman et al., 2002; Bretschneider et al., 2013). Unsurprisingly, medical terminology abounds in EHRs. What makes this problem an even greater obstacle to readability is that many medical terms (and their inflections) originate from Latin or Greek. Different languages have adapted these terms differently (Bretschneider et al., 2013). The Swedish medical terminology went through a change during the 1990s due to a swedification of diagnostic expressions performed in the 1987 update of the Swedish version of ICD, the Inte</context>
</contexts>
<marker>Bretschneider, Zillner, Hammon, 2013</marker>
<rawString>C. Bretschneider, S. Zillner, and M. Hammon. 2013. Identifying pathological findings in German radiology reports using a syntacto-semantic parsing approach. In Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013). ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Carlsson</author>
<author>H Dalianis</author>
</authors>
<title>Influence of Module Order on Rule-Based De-identification of Personal Names in Electronic Patient Records Written in Swedish.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation, LREC 2010,</booktitle>
<pages>3071--3075</pages>
<location>Valletta, Malta,</location>
<contexts>
<context position="17543" citStr="Carlsson and Dalianis, 2010" startWordPosition="2666" endWordPosition="2669"> not. The SCATM method uses various lexicons8 of Swedish medical terms, Swedish abbreviations, 7Abbreviations that do not follow conventional orthography styles, e.g. a typical abbreviation p.g.a. (en. due to) can have the following variants p g a, pga, p. G. A., p. gr. a. 8the sources of lexicons are: anatomin.se, neuro.ki.se smittskyddsinstitutet.se, medicinskordbok.se, runeberg.org, g3. spraakdata.gu.se/saob, sv.wikipedia.org/ wiki/Lista_ver_frkortningar, karolinska. se/Karolinska-Universitetslaboratoriet/ Sidor-om-PTA/Analysindex-alla-enheter/ Forkortningar/ and the list of Swedish names (Carlsson and Dalianis, 2010). Swedish words and Swedish names (first and last). 5.2 Compound splitting For compound splitting, we use a collection of lexical resources, the core of which is a full-form dictionary produced by Nordisk spr˚akteknologi holding AS (NST), comprising 927,000 entries9. In addition, various resources from the medical domain have been mined for vocabulary: Swedish SNOMED10 terminology, the L¨akartidningen medical journal11 corpus, and Swedish Web health-care guides/manuals12. A refinement of the basic lexicon-driven technique described in the related research section is that our compound splitting</context>
</contexts>
<marker>Carlsson, Dalianis, 2010</marker>
<rawString>E. Carlsson and H. Dalianis. 2010. Influence of Module Order on Rule-Based De-identification of Personal Names in Electronic Patient Records Written in Swedish. In Proceedings of the Seventh International Conference on Language Resources and Evaluation, LREC 2010, pages 3071–3075, Valletta, Malta, May 19–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dalianis</author>
<author>M Hassel</author>
<author>A Henriksson</author>
<author>M Skeppstedt</author>
</authors>
<title>Stockholm EPR Corpus: A Clinical Database Used to Improve Health Care. In</title>
<date>2012</date>
<booktitle>Proc. 4th SLTC, 2012,</booktitle>
<pages>17--18</pages>
<editor>Pierre Nugues, editor,</editor>
<location>Lund,</location>
<contexts>
<context position="6446" citStr="Dalianis et al., 2012" startWordPosition="964" endWordPosition="967"> of exact matching to kolecystit (English: cholecystitis) and some presumed spelling variants clearly demonstrate the slow progress (Table 1). As medical literature is predominantly written in English nowadays, physicians increasingly get exposed to the English spelling of Latin and Greek words rather than the Swedish one. This has resulted in a multitude of alternate spellings of several medical terms. For example, tachycardia (rapid heart) is correctly spelled takykardi, but is 1http://www.who.int/classifications/ icd/en/ 2Based on a subset of the Stockholm Electronic Patient Record Corpus (Dalianis et al., 2012) of 100,000 daily notes (DAY) written by physicians of varying disciplines (4 mill. tokens) and 435,000 radiology reports (X-RAY) written by radiologists (20 mill. tokens). KORP: http:// spraakbanken.gu.se/korp/ Term KORP DAY X-RAY kolecystit 51 48 84 colecystit 0 1 8 cholecystit 4 88 1613 Table 1: Alternate spellings of the Swedish medical term kolecystit (eng. cholecystitis) in the Swedish corpus collection Korp, daily notes (DAY) and radiology reports (X-RAY), respectively. Correct spelling in bold. also frequently found as tachycardi, tachykardi, and takycardi (Kvist et al., 2011). A simil</context>
<context position="13641" citStr="Dalianis et al., 2012" startWordPosition="2091" endWordPosition="2094">tion for ranking the spelling candidates resulting in an accuracy of 84% on English patient records. Sikl´oski et al. (2013) use a statistical machine translation model 76 Figure 1: Distribution of 100 PR dataset sentences by length (number of sentences on the y-axis and number of tokens on the x-axis). (with 3-grams) for spelling correction, achieving 88% accuracy on Hungarian medical texts. 4 Experimental data This study uses clinical notes5 from the Stockholm Electronic Patient Record corpus containing more than 600,000 patients of all ages from more than 500 health units during 2006–2013 (Dalianis et al., 2012). A randomly selected subset of 100 daily notes from different EHRs written by physicians between 2009–2010 was used as a gold standard dataset for evaluating abbreviation detection, compound splitting and spelling corrections. This 100 daily notes dataset contains 433 sentences and 3,888 tokens, as determined by Stagger (¨Ostling, 2013), a Swedish tokenizer and POS tagger. The majority of sentences contain between 4–11 tokens (see Figure 1.) The text snippet in Figure 2 provides an illustrative example of the characteristics of a health record. What is immediately striking is the number of mi</context>
</contexts>
<marker>Dalianis, Hassel, Henriksson, Skeppstedt, 2012</marker>
<rawString>H. Dalianis, M. Hassel, A. Henriksson, and M. Skeppstedt. 2012. Stockholm EPR Corpus: A Clinical Database Used to Improve Health Care. In Pierre Nugues, editor, Proc. 4th SLTC, 2012, pages 17–18, Lund, October 25-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dann´ells</author>
</authors>
<title>Automatic acronym recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th conference on European chapter of the Association for Computational Linguistics (EACL).</booktitle>
<marker>Dann´ells, 2006</marker>
<rawString>D. Dann´ells. 2006. Automatic acronym recognition. In Proceedings of the 11th conference on European chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>P Kra</author>
<author>A Rzhetsky</author>
</authors>
<title>Two biomedical sublanguages: a description based on the theories of Zellig Harris.</title>
<date>2002</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="4476" citStr="Friedman et al., 2002" startWordPosition="659" endWordPosition="662">tacles to readability of EHRs for laymen stems from the fact that they 74 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 74–83, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics are written under time pressure by professionals, for professionals (Kvist et al., 2011). This results in a telegraphic style, with omissions, abbreviations and misspellings, as reported for several languages including Swedish, Finnish, English, French, Hungarian and German (Laippala et al., 2009; Friedman et al., 2002; Hag`ege et al., 2011; Surj´an and H´eja, 2003; Bretschneider et al., 2013). The omitted words are often subjects, verbs, prepositions and articles (Friedman et al., 2002; Bretschneider et al., 2013). Unsurprisingly, medical terminology abounds in EHRs. What makes this problem an even greater obstacle to readability is that many medical terms (and their inflections) originate from Latin or Greek. Different languages have adapted these terms differently (Bretschneider et al., 2013). The Swedish medical terminology went through a change during the 1990s due to a swedification of diagnostic expr</context>
</contexts>
<marker>Friedman, Kra, Rzhetsky, 2002</marker>
<rawString>C. Friedman, P. Kra, and A. Rzhetsky. 2002. Two biomedical sublanguages: a description based on the theories of Zellig Harris. Journal of Biomedical Informatics, 35(4):222–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hag`ege</author>
<author>P Marchal</author>
<author>Q Gicquel</author>
<author>S Darmoni</author>
<author>S Pereira</author>
<author>M Metzger</author>
</authors>
<title>Linguistic and temporal processing for discovering hospital acquired infection from patient records.</title>
<date>2011</date>
<booktitle>In Proceedings of the ECAI 2010 Conference on Knowledge Representation for Health-care, KR4HC’10,</booktitle>
<pages>70--84</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Hag`ege, Marchal, Gicquel, Darmoni, Pereira, Metzger, 2011</marker>
<rawString>C. Hag`ege, P. Marchal, Q. Gicquel, S. Darmoni, S. Pereira, and M. Metzger. 2011. Linguistic and temporal processing for discovering hospital acquired infection from patient records. In Proceedings of the ECAI 2010 Conference on Knowledge Representation for Health-care, KR4HC’10, pages 70–84, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Isenius</author>
<author>S Velupillai</author>
<author>M Kvist</author>
</authors>
<title>Initial results in the development of scan: a swedish clinical abbreviation normalizer.</title>
<date>2012</date>
<booktitle>In Proceedings of the CLEF 2012 Workshop on Cross-Language Evaluation of Methods, Applications, and Resources for eHealth Document Analysis - CLEFeHealth2012,</booktitle>
<publisher>CLEF.</publisher>
<location>Rome, Italy,</location>
<contexts>
<context position="10590" citStr="Isenius et al. (2012)" startWordPosition="1615" endWordPosition="1618"> terminology and spelling correction. 3.1 Abbreviation detection Abbreviation identification in English biomedical and clinical texts has been studied extensively (e.g. Xu et al. (2007), Liu et al. (2001)). For detection of Swedish medical abbreviations, there are fewer studies. Dann´ells (2006) reports detection of acronyms in medical journal text with 98% recall and 94% precision by using part of speech information and heuristic rules. Clinical Swedish presents greater problems than medical texts, because of ad hoc abbreviations and noisier text. By using lexicons and a few heuristic rules, Isenius et al. (2012) report the best F-score of 79% for abbreviation detection in clinical Swedish. 3.2 Compound splitting Good compound analysis is critical especially for languages whose orthographies concatenate compound components. Swedish is among those languages, in which every such concatenation thus corresponds to a word. The most common approach to compound splitting is to base it on a lexicon providing restrictions on how different word forms can be used for generating compounds. For example, Sj¨obergh and Kann (2006) used a lexicon derived from SAOL (the Swedish Academy word list), and ¨Ostling and Wir</context>
<context position="16191" citStr="Isenius et al., 2012" startWordPosition="2470" endWordPosition="2473">are compounds; finally, for the remaining unknown words, context dependent word corrections are made. 5.1 Detecting abbreviations This section describes the heuristics and lexicon lookup-based abbreviation detection method. The Swedish Clinical Abbreviation and Medical Terminology Matcher (SCATM) is based on 6By unknown words we mean words that cannot be looked up in available lexical resources or linguistically analyzed by POS tokenizer. 77 Figure 2: Characteristics of a health record: misspellings (underline), abbreviations (bold), compounds (italic) and words of foreign origin (red). SCAN (Isenius et al., 2012). The SCATM method uses domain-adapted Stagger ( ¨Ostling, 2013) for the tokenization and POS-tagging of text. The adapted version of Stagger handles clinicalspecific7 abbreviations from three domains, i.e. radiology, emergency, and dietology. SCATM also uses several lexicons to determine whether a word is a common word (in total 122,847 in the lexicon), an abbreviation (in total 7,455 in the lexicon), a medical term (in total 17,380 in the lexicon), or a name (both first and last names, in total 404,899 in the lexicon). All words that are at most 6 characters long, or contains the characters </context>
</contexts>
<marker>Isenius, Velupillai, Kvist, 2012</marker>
<rawString>N. Isenius, S. Velupillai, and M. Kvist. 2012. Initial results in the development of scan: a swedish clinical abbreviation normalizer. In Proceedings of the CLEF 2012 Workshop on Cross-Language Evaluation of Methods, Applications, and Resources for eHealth Document Analysis - CLEFeHealth2012, Rome, Italy, September. CLEF.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Josefsson</author>
</authors>
<title>Fifeber eller tempa? Nigra tankar om agentivitet i medicinskt facksprik.</title>
<date>1999</date>
<contexts>
<context position="7462" citStr="Josefsson (1999)" startWordPosition="1121" endWordPosition="1122">s collection Korp, daily notes (DAY) and radiology reports (X-RAY), respectively. Correct spelling in bold. also frequently found as tachycardi, tachykardi, and takycardi (Kvist et al., 2011). A similar French study found this kind of spelling variation to be abundant as well (Ruch et al., 2003). EHRs also contain neologisms. These are often verbs, typically describing events relating to the patient in active form, such as ”the patient is infarcting” (Swedish: patienten infarcerar) instead of the unintentional ”the patient is having a myocardial infarction”. Similar phenomena are described by Josefsson (1999). Abbreviations and acronyms in EHRs can follow standardised writing rules or be ad hoc (Liu et al., 2001). They are often domain-specific and may be found in medical dictionaries such as MeSH3 and Snomed CT4. For instance, 18 of the 100 most common words in Swedish radiology reports were abbreviations, and 10 of them were domain-specific (Kvist and Velupillai, 2013). Because many medical terms are multiword expressions that are repeated frequently in a patient’s EHR, the use of acronyms is very common. Skeppstedt et al. (2012) showed that 14% of diagnostic expressions were abbreviated in Swed</context>
</contexts>
<marker>Josefsson, 1999</marker>
<rawString>G. Josefsson. 1999. Fifeber eller tempa? Nigra tankar om agentivitet i medicinskt facksprik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kandula</author>
<author>D Curtis</author>
<author>Q Zeng-Treitler</author>
</authors>
<title>A Semantic and Syntactic Text Simplification Tool for Health Content.</title>
<date>2010</date>
<booktitle>In Proc AMIA 2010,</booktitle>
<pages>366--370</pages>
<contexts>
<context position="9590" citStr="Kandula et al., 2010" startWordPosition="1463" endWordPosition="1466">uent use of abbreviations, jargon and technical terminology (Pyper et al., 2004; Keselman et al., 2007; Adnan et al., 2010). The most common comprehension errors made by laymen concern clinical concepts, medical terminology and medication names. Furthermore, there are great challenges for higher-level processing like syntax and semantics (Meystre et al., 2008; Wu et al., 2013). The research presented in this paper focuses on lexical simplification of clinical text. 3 Related research We are aware of several efforts to construct automated text simplification tools for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability perspective. Borin et al. (2009) present a thorough investigation on Swedish (and English) medical language, but EHR texts are explicitly not included. This section summarizes research on Swedish (clinical) text with respect to lexical simplification by handling of abbreviations, terminology and spelling correction. 3.1 Abbreviation detection Abbreviation identification in English biomedical and clinical texts has been studied extensively (e.g. Xu et al. (2007), Liu et al. (2001)). For detection </context>
</contexts>
<marker>Kandula, Curtis, Zeng-Treitler, 2010</marker>
<rawString>S. Kandula, D. Curtis, and Q. Zeng-Treitler. 2010. A Semantic and Syntactic Text Simplification Tool for Health Content. In Proc AMIA 2010, pages 366– 370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Kann</author>
<author>R Domeij</author>
<author>J Hollman</author>
<author>M Tillenius</author>
</authors>
<title>Implementation Aspects and Applications of a Spelling Correction Algorithm..</title>
<date>1998</date>
<tech>Technical Report TRITA-NA-9813, NADA, KTH.</tech>
<contexts>
<context position="12397" citStr="Kann et al. (1998)" startWordPosition="1895" endWordPosition="1898">urin (2007) have employed domain terminology matching and reached 98% precision and 87% recall in detecting terms of disorders. Using similar approaches, Skeppstedt et al. (2012), reached 75% precision and 55% recall in detecting terms of disorders. With a machine learning based approach, improved results were obtained: 80% precision, 82% recall (Skeppstedt et al., 2014). Skeppstedt et al. (2012) have also demonstrated the negative influence of abbreviations and multiword expressions in their findings. 3.4 Spelling correction A system for general spelling correction of Swedish is described by Kann et al. (1998), but we are not aware of any previous work related to spelling correction of Swedish clinical text. An example of spelling correction of clinical text for other languages is Tolentino et al. (2007), who use several algorithms for word similarity detection, including phonological homonym lookup and ngrams for contextual disambiguation. They report a precision of 64% on English medical texts. Another example is Patrick et al. (2010) and Patrick and Nguyen (2011), who combine a mixture of generation of spelling candidates based on orthographic and phonological edit distance, and a 2- word window</context>
</contexts>
<marker>Kann, Domeij, Hollman, Tillenius, 1998</marker>
<rawString>V. Kann, R. Domeij, J. Hollman, and M. Tillenius. 1998. Implementation Aspects and Applications of a Spelling Correction Algorithm.. Technical Report TRITA-NA-9813, NADA, KTH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kim Smith</author>
<author>G Divita</author>
<author>A Browne</author>
</authors>
<title>Towards consumer-friendly PHRs: patients experience with reviewing their health records.</title>
<date>2007</date>
<booktitle>In AMIA Annu Symp Proc</booktitle>
<pages>399--403</pages>
<marker>Smith, Divita, Browne, 2007</marker>
<rawString>A. Keselman, L. Slaughter, CA. Smith, H. Kim, G. Divita, A. Browne, and et al. 2007. Towards consumer-friendly PHRs: patients experience with reviewing their health records. In AMIA Annu Symp Proc 2007, pages 399–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Knuth</author>
</authors>
<title>The Art of Computer Programming: Volume 3, Sorting and Searching,</title>
<date>1973</date>
<pages>391--392</pages>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="19742" citStr="Knuth, 1973" startWordPosition="2964" endWordPosition="2965">n The unknown words that are not abbreviations or compounds can very likely be misspellings. Misspellings can be a result of typing errors or the lack of knowledge of the correct spelling. Our approach to clinical Swedish misspellings is based on the best practices of spell checkers for Indo-European languages, namely the phonetic similarity key method combined with a method to measure proximity between the strings. In our spelling correction method, the Edit distance (Levenshtein, 1966) algorithm is used to measure the proximity of orthographically possible candidates. The Soundex algorithm (Knuth, 1973) shortlists the spelling candidates which are phonologically closest to the misspelled word. Further, the spelling correction candidates are analyzed in a context by using the SLME n-gram model. The SLME employs the Google Web 1T 5- gram, 10 European Languages, Version 1, dataset for Swedish, which is the largest publically available Swedish data resource. The SLME is a simple n-gram language model, based on the Stupid Backoff Model (Brants et al., 2007). The n-gram language model calculates the probability of a word in a given context: L L i−1 L Pˆ (wi|wi−1 P(w1 ) = i=1 P (wi|w1 ) ≈ i=1 i−n+1</context>
</contexts>
<marker>Knuth, 1973</marker>
<rawString>D. E. Knuth, 1973. The Art of Computer Programming: Volume 3, Sorting and Searching, pages 391– 392. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kokkinakis</author>
<author>A Thurin</author>
</authors>
<title>Identification of Entity References in Hospital Discharge Letters.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th Nordic Conference of Computational Linguistics (NODALIDA)</booktitle>
<pages>329--332</pages>
<location>Tartu, Estonia.</location>
<contexts>
<context position="11790" citStr="Kokkinakis and Thurin (2007)" startWordPosition="1802" endWordPosition="1805"> list), and ¨Ostling and Wir´en (2013) used the SALDO lexicon of Swedish morphology (Borin and Forsberg, 2009). With this kind of approach, compound splitting is usually very reliable for genres like newspaper text, with typical accuracies for Swedish around 97%, but performs poorer in domain specific genres. 3.3 Terminology detection The detection of English medical terminology is a widely researched area. An example of term detection in English clinical texts is Wang and Patrick (2009) work based on rule-based and machine learning methods, reporting 84% precision. For Swedish clinical text, Kokkinakis and Thurin (2007) have employed domain terminology matching and reached 98% precision and 87% recall in detecting terms of disorders. Using similar approaches, Skeppstedt et al. (2012), reached 75% precision and 55% recall in detecting terms of disorders. With a machine learning based approach, improved results were obtained: 80% precision, 82% recall (Skeppstedt et al., 2014). Skeppstedt et al. (2012) have also demonstrated the negative influence of abbreviations and multiword expressions in their findings. 3.4 Spelling correction A system for general spelling correction of Swedish is described by Kann et al.</context>
</contexts>
<marker>Kokkinakis, Thurin, 2007</marker>
<rawString>D. Kokkinakis and A. Thurin. 2007. Identification of Entity References in Hospital Discharge Letters. In Proceedings of the 16th Nordic Conference of Computational Linguistics (NODALIDA) 2007, pages 329–332, Tartu, Estonia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kvist</author>
<author>S Velupillai</author>
</authors>
<title>Professional Language in Swedish Radiology Reports – Characterization for Patient-Adapted Text Simplification.</title>
<date>2013</date>
<booktitle>In Proceedings of the Scandinavian Conference on Health Informatics 2013,</booktitle>
<institution>Link¨oping University Electronic Press, Link¨opings universitet.</institution>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="7831" citStr="Kvist and Velupillai, 2013" startWordPosition="1181" endWordPosition="1184">ly describing events relating to the patient in active form, such as ”the patient is infarcting” (Swedish: patienten infarcerar) instead of the unintentional ”the patient is having a myocardial infarction”. Similar phenomena are described by Josefsson (1999). Abbreviations and acronyms in EHRs can follow standardised writing rules or be ad hoc (Liu et al., 2001). They are often domain-specific and may be found in medical dictionaries such as MeSH3 and Snomed CT4. For instance, 18 of the 100 most common words in Swedish radiology reports were abbreviations, and 10 of them were domain-specific (Kvist and Velupillai, 2013). Because many medical terms are multiword expressions that are repeated frequently in a patient’s EHR, the use of acronyms is very common. Skeppstedt et al. (2012) showed that 14% of diagnostic expressions were abbreviated in Swedish clinical text. Abbreviations are often ambiguous. As an example, 33% of the short abbreviations in the UMLS terminology are ambiguous (Liu et al., 2001). Pakhomov et al. (2005) found that the abbreviation RA had more than 20 expansions in the UMLS terminology alone. Furthermore, a certain word or expression can be shortened in several different ways. For instance</context>
</contexts>
<marker>Kvist, Velupillai, 2013</marker>
<rawString>M. Kvist and S. Velupillai. 2013. Professional Language in Swedish Radiology Reports – Characterization for Patient-Adapted Text Simplification. In Proceedings of the Scandinavian Conference on Health Informatics 2013, Copenhagen, Denmark, August. Link¨oping University Electronic Press, Link¨opings universitet.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kvist</author>
<author>M Skeppstedt</author>
<author>S Velupillai</author>
<author>H Dalianis</author>
</authors>
<title>Modeling human comprehension of swedish medical records for intelligent access and summarization systems, a physician’s perspective.</title>
<date>2011</date>
<booktitle>In Proc. 9th Scandinavian Conference on Health Informatics,</booktitle>
<location>SHI, Oslo,</location>
<contexts>
<context position="4244" citStr="Kvist et al., 2011" startWordPosition="623" endWordPosition="626">known words, as abbreviations or as misspellings. As an additional result, we obtain a distribution of how prevalent these problems are in the clinical domain. 2 Lexical challenges to readability of EHRs A major reason for the obstacles to readability of EHRs for laymen stems from the fact that they 74 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 74–83, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics are written under time pressure by professionals, for professionals (Kvist et al., 2011). This results in a telegraphic style, with omissions, abbreviations and misspellings, as reported for several languages including Swedish, Finnish, English, French, Hungarian and German (Laippala et al., 2009; Friedman et al., 2002; Hag`ege et al., 2011; Surj´an and H´eja, 2003; Bretschneider et al., 2013). The omitted words are often subjects, verbs, prepositions and articles (Friedman et al., 2002; Bretschneider et al., 2013). Unsurprisingly, medical terminology abounds in EHRs. What makes this problem an even greater obstacle to readability is that many medical terms (and their inflections</context>
<context position="7037" citStr="Kvist et al., 2011" startWordPosition="1052" endWordPosition="1055">rpus (Dalianis et al., 2012) of 100,000 daily notes (DAY) written by physicians of varying disciplines (4 mill. tokens) and 435,000 radiology reports (X-RAY) written by radiologists (20 mill. tokens). KORP: http:// spraakbanken.gu.se/korp/ Term KORP DAY X-RAY kolecystit 51 48 84 colecystit 0 1 8 cholecystit 4 88 1613 Table 1: Alternate spellings of the Swedish medical term kolecystit (eng. cholecystitis) in the Swedish corpus collection Korp, daily notes (DAY) and radiology reports (X-RAY), respectively. Correct spelling in bold. also frequently found as tachycardi, tachykardi, and takycardi (Kvist et al., 2011). A similar French study found this kind of spelling variation to be abundant as well (Ruch et al., 2003). EHRs also contain neologisms. These are often verbs, typically describing events relating to the patient in active form, such as ”the patient is infarcting” (Swedish: patienten infarcerar) instead of the unintentional ”the patient is having a myocardial infarction”. Similar phenomena are described by Josefsson (1999). Abbreviations and acronyms in EHRs can follow standardised writing rules or be ad hoc (Liu et al., 2001). They are often domain-specific and may be found in medical dictiona</context>
</contexts>
<marker>Kvist, Skeppstedt, Velupillai, Dalianis, 2011</marker>
<rawString>M. Kvist, M. Skeppstedt, S. Velupillai, and H. Dalianis. 2011. Modeling human comprehension of swedish medical records for intelligent access and summarization systems, a physician’s perspective. In Proc. 9th Scandinavian Conference on Health Informatics, SHI, Oslo, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Laippala</author>
<author>F Ginter</author>
<author>S Pyysalo</author>
<author>T Salakoski</author>
</authors>
<title>Towards automated processing of clinical Finnish: Sublanguage analysis and a rule-based parser. Int journal of medical informatics,</title>
<date>2009</date>
<pages>78--7</pages>
<contexts>
<context position="4453" citStr="Laippala et al., 2009" startWordPosition="655" endWordPosition="658">ajor reason for the obstacles to readability of EHRs for laymen stems from the fact that they 74 Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 74–83, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics are written under time pressure by professionals, for professionals (Kvist et al., 2011). This results in a telegraphic style, with omissions, abbreviations and misspellings, as reported for several languages including Swedish, Finnish, English, French, Hungarian and German (Laippala et al., 2009; Friedman et al., 2002; Hag`ege et al., 2011; Surj´an and H´eja, 2003; Bretschneider et al., 2013). The omitted words are often subjects, verbs, prepositions and articles (Friedman et al., 2002; Bretschneider et al., 2013). Unsurprisingly, medical terminology abounds in EHRs. What makes this problem an even greater obstacle to readability is that many medical terms (and their inflections) originate from Latin or Greek. Different languages have adapted these terms differently (Bretschneider et al., 2013). The Swedish medical terminology went through a change during the 1990s due to a swedifica</context>
</contexts>
<marker>Laippala, Ginter, Pyysalo, Salakoski, 2009</marker>
<rawString>V. Laippala, F. Ginter, S. Pyysalo, and T. Salakoski. 2009. Towards automated processing of clinical Finnish: Sublanguage analysis and a rule-based parser. Int journal of medical informatics, 78:e7– e12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Levenshtein</author>
</authors>
<title>Binary Codes Capable of Correcting Deletions, Insertions and Reversals. Soviet Physics Doklady,</title>
<date>1966</date>
<pages>10--707</pages>
<contexts>
<context position="19622" citStr="Levenshtein, 1966" startWordPosition="2947" endWordPosition="2948">n constituents: hj¨art+eko 2.3e-04 hj¨arte+ko 5.1e-07 The SMLE is described in the following section. 5.3 Misspelling detection The unknown words that are not abbreviations or compounds can very likely be misspellings. Misspellings can be a result of typing errors or the lack of knowledge of the correct spelling. Our approach to clinical Swedish misspellings is based on the best practices of spell checkers for Indo-European languages, namely the phonetic similarity key method combined with a method to measure proximity between the strings. In our spelling correction method, the Edit distance (Levenshtein, 1966) algorithm is used to measure the proximity of orthographically possible candidates. The Soundex algorithm (Knuth, 1973) shortlists the spelling candidates which are phonologically closest to the misspelled word. Further, the spelling correction candidates are analyzed in a context by using the SLME n-gram model. The SLME employs the Google Web 1T 5- gram, 10 European Languages, Version 1, dataset for Swedish, which is the largest publically available Swedish data resource. The SLME is a simple n-gram language model, based on the Stupid Backoff Model (Brants et al., 2007). The n-gram language </context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>VI Levenshtein. 1966. Binary Codes Capable of Correcting Deletions, Insertions and Reversals. Soviet Physics Doklady, 10:707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>Y A Lussier</author>
<author>C Friedman</author>
</authors>
<title>Disambiguating Ambiguous Biomedical Terms in Biomedical Narrative Text: An Unsupervised Method.</title>
<date>2001</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>34--249</pages>
<contexts>
<context position="7568" citStr="Liu et al., 2001" startWordPosition="1138" endWordPosition="1141">d. also frequently found as tachycardi, tachykardi, and takycardi (Kvist et al., 2011). A similar French study found this kind of spelling variation to be abundant as well (Ruch et al., 2003). EHRs also contain neologisms. These are often verbs, typically describing events relating to the patient in active form, such as ”the patient is infarcting” (Swedish: patienten infarcerar) instead of the unintentional ”the patient is having a myocardial infarction”. Similar phenomena are described by Josefsson (1999). Abbreviations and acronyms in EHRs can follow standardised writing rules or be ad hoc (Liu et al., 2001). They are often domain-specific and may be found in medical dictionaries such as MeSH3 and Snomed CT4. For instance, 18 of the 100 most common words in Swedish radiology reports were abbreviations, and 10 of them were domain-specific (Kvist and Velupillai, 2013). Because many medical terms are multiword expressions that are repeated frequently in a patient’s EHR, the use of acronyms is very common. Skeppstedt et al. (2012) showed that 14% of diagnostic expressions were abbreviated in Swedish clinical text. Abbreviations are often ambiguous. As an example, 33% of the short abbreviations in the</context>
<context position="10173" citStr="Liu et al. (2001)" startWordPosition="1549" endWordPosition="1552">t in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability perspective. Borin et al. (2009) present a thorough investigation on Swedish (and English) medical language, but EHR texts are explicitly not included. This section summarizes research on Swedish (clinical) text with respect to lexical simplification by handling of abbreviations, terminology and spelling correction. 3.1 Abbreviation detection Abbreviation identification in English biomedical and clinical texts has been studied extensively (e.g. Xu et al. (2007), Liu et al. (2001)). For detection of Swedish medical abbreviations, there are fewer studies. Dann´ells (2006) reports detection of acronyms in medical journal text with 98% recall and 94% precision by using part of speech information and heuristic rules. Clinical Swedish presents greater problems than medical texts, because of ad hoc abbreviations and noisier text. By using lexicons and a few heuristic rules, Isenius et al. (2012) report the best F-score of 79% for abbreviation detection in clinical Swedish. 3.2 Compound splitting Good compound analysis is critical especially for languages whose orthographies </context>
</contexts>
<marker>Liu, Lussier, Friedman, 2001</marker>
<rawString>H. Liu, Y. A. Lussier, and C. Friedman. 2001. Disambiguating Ambiguous Biomedical Terms in Biomedical Narrative Text: An Unsupervised Method. Journal of Biomedical Informatics, 34:249–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Meystre</author>
<author>G K Savova</author>
<author>K C Kipper-Schuler</author>
<author>John E Hurdle</author>
</authors>
<title>Extracting information from textual documents in the electronic health record: a review of recent research.</title>
<date>2008</date>
<journal>IMIA Yearbook of Medical Informatics</journal>
<pages>47--1</pages>
<contexts>
<context position="9331" citStr="Meystre et al., 2008" startWordPosition="1420" endWordPosition="1423">ld, has not been introduced in Sweden, and many physicians and all nurses type the notes themselves. This is one explanation to the variation with respect to abbreviations. User studies have shown that the greatest barriers for patients lie mainly in the frequent use of abbreviations, jargon and technical terminology (Pyper et al., 2004; Keselman et al., 2007; Adnan et al., 2010). The most common comprehension errors made by laymen concern clinical concepts, medical terminology and medication names. Furthermore, there are great challenges for higher-level processing like syntax and semantics (Meystre et al., 2008; Wu et al., 2013). The research presented in this paper focuses on lexical simplification of clinical text. 3 Related research We are aware of several efforts to construct automated text simplification tools for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability perspective. Borin et al. (2009) present a thorough investigation on Swedish (and English) medical language, but EHR texts are explicitly not included. This section summarizes research on Swedish (clinical) text with respect to lexical simpli</context>
</contexts>
<marker>Meystre, Savova, Kipper-Schuler, Hurdle, 2008</marker>
<rawString>S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler, and John E. Hurdle. 2008. Extracting information from textual documents in the electronic health record: a review of recent research. IMIA Yearbook of Medical Informatics 2008. 47 Suppl 1:138-154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R ¨Ostling</author>
<author>M Wir´en</author>
</authors>
<title>Compounding in a Swedish Blog Corpus,</title>
<date>2013</date>
<booktitle>Stockholm Studies in Modern Philology. New series 16.</booktitle>
<pages>45--63</pages>
<location>Stockholm university.</location>
<marker>¨Ostling, Wir´en, 2013</marker>
<rawString>R. ¨Ostling and M. Wir´en, 2013. Compounding in a Swedish Blog Corpus, pages 45–63. Stockholm Studies in Modern Philology. New series 16. Stockholm university.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R ¨Ostling</author>
</authors>
<date>2012</date>
<note>http://www.ling.su.se/english/nlp/tools/slme/stockholmlanguage-model-with-entropy-slme-1.101098 .</note>
<marker>¨Ostling, 2012</marker>
<rawString>R. ¨Ostling. 2012. http://www.ling.su.se/english/nlp/tools/slme/stockholmlanguage-model-with-entropy-slme-1.101098 .</rawString>
</citation>
<citation valid="true">
<authors>
<author>R ¨Ostling</author>
</authors>
<title>Stagger: an Open-Source Part of Speech Tagger for Swedish.</title>
<date>2013</date>
<journal>Northern European Journal of Language Technology,</journal>
<pages>3--1</pages>
<marker>¨Ostling, 2013</marker>
<rawString>R. ¨Ostling. 2013. Stagger: an Open-Source Part of Speech Tagger for Swedish. Northern European Journal of Language Technology, 3:1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pakhomov</author>
<author>T Pedersen</author>
<author>C G Chute</author>
</authors>
<title>Abbreviation and Acronym Disambiguation in Clinical Discourse.</title>
<date>2005</date>
<booktitle>In Proc AMIA</booktitle>
<pages>589--593</pages>
<contexts>
<context position="8242" citStr="Pakhomov et al. (2005)" startWordPosition="1248" endWordPosition="1251"> medical dictionaries such as MeSH3 and Snomed CT4. For instance, 18 of the 100 most common words in Swedish radiology reports were abbreviations, and 10 of them were domain-specific (Kvist and Velupillai, 2013). Because many medical terms are multiword expressions that are repeated frequently in a patient’s EHR, the use of acronyms is very common. Skeppstedt et al. (2012) showed that 14% of diagnostic expressions were abbreviated in Swedish clinical text. Abbreviations are often ambiguous. As an example, 33% of the short abbreviations in the UMLS terminology are ambiguous (Liu et al., 2001). Pakhomov et al. (2005) found that the abbreviation RA had more than 20 expansions in the UMLS terminology alone. Furthermore, a certain word or expression can be shortened in several different ways. For instance, in a Swedish intensive care unit, the drug Noradrenalin was creatively written in 60 different ways by the nurses (Allvin et al., 2011). It should be noted that speech recognition, although common in many hospitals around the 3www.ncbi.nlm.nih.gov 4http://www.ihtsdo.org/ 75 world, has not been introduced in Sweden, and many physicians and all nurses type the notes themselves. This is one explanation to the</context>
</contexts>
<marker>Pakhomov, Pedersen, Chute, 2005</marker>
<rawString>S. Pakhomov, T. Pedersen, and C. G. Chute. 2005. Abbreviation and Acronym Disambiguation in Clinical Discourse. In Proc AMIA 2005, pages 589–593.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Patrick</author>
<author>D Nguyen</author>
</authors>
<title>Automated Proof Reading of Clinical Notes.</title>
<date>2011</date>
<booktitle>In Helena Hong Gao and Minghui Dong,</booktitle>
<pages>303--312</pages>
<editor>editors, PACLIC,</editor>
<institution>Digital Enhancement of Cognitive Development, Waseda University.</institution>
<contexts>
<context position="12862" citStr="Patrick and Nguyen (2011)" startWordPosition="1969" endWordPosition="1972">ions and multiword expressions in their findings. 3.4 Spelling correction A system for general spelling correction of Swedish is described by Kann et al. (1998), but we are not aware of any previous work related to spelling correction of Swedish clinical text. An example of spelling correction of clinical text for other languages is Tolentino et al. (2007), who use several algorithms for word similarity detection, including phonological homonym lookup and ngrams for contextual disambiguation. They report a precision of 64% on English medical texts. Another example is Patrick et al. (2010) and Patrick and Nguyen (2011), who combine a mixture of generation of spelling candidates based on orthographic and phonological edit distance, and a 2- word window of contextual information for ranking the spelling candidates resulting in an accuracy of 84% on English patient records. Sikl´oski et al. (2013) use a statistical machine translation model 76 Figure 1: Distribution of 100 PR dataset sentences by length (number of sentences on the y-axis and number of tokens on the x-axis). (with 3-grams) for spelling correction, achieving 88% accuracy on Hungarian medical texts. 4 Experimental data This study uses clinical no</context>
</contexts>
<marker>Patrick, Nguyen, 2011</marker>
<rawString>J. Patrick and D. Nguyen. 2011. Automated Proof Reading of Clinical Notes. In Helena Hong Gao and Minghui Dong, editors, PACLIC, pages 303– 312. Digital Enhancement of Cognitive Development, Waseda University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Patrick</author>
<author>M Sabbagh</author>
<author>S Jain</author>
<author>H Zheng</author>
</authors>
<title>Spelling correction in Clinical Notes with Emphasis on First Suggestion Accuracy.</title>
<date>2010</date>
<booktitle>In 2nd Workshop on Building and Evaluating Resources for Biomedical Text Mining,</booktitle>
<pages>2--8</pages>
<contexts>
<context position="9613" citStr="Patrick et al., 2010" startWordPosition="1467" endWordPosition="1470">ons, jargon and technical terminology (Pyper et al., 2004; Keselman et al., 2007; Adnan et al., 2010). The most common comprehension errors made by laymen concern clinical concepts, medical terminology and medication names. Furthermore, there are great challenges for higher-level processing like syntax and semantics (Meystre et al., 2008; Wu et al., 2013). The research presented in this paper focuses on lexical simplification of clinical text. 3 Related research We are aware of several efforts to construct automated text simplification tools for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability perspective. Borin et al. (2009) present a thorough investigation on Swedish (and English) medical language, but EHR texts are explicitly not included. This section summarizes research on Swedish (clinical) text with respect to lexical simplification by handling of abbreviations, terminology and spelling correction. 3.1 Abbreviation detection Abbreviation identification in English biomedical and clinical texts has been studied extensively (e.g. Xu et al. (2007), Liu et al. (2001)). For detection of Swedish medical abbr</context>
<context position="12832" citStr="Patrick et al. (2010)" startWordPosition="1964" endWordPosition="1967">ive influence of abbreviations and multiword expressions in their findings. 3.4 Spelling correction A system for general spelling correction of Swedish is described by Kann et al. (1998), but we are not aware of any previous work related to spelling correction of Swedish clinical text. An example of spelling correction of clinical text for other languages is Tolentino et al. (2007), who use several algorithms for word similarity detection, including phonological homonym lookup and ngrams for contextual disambiguation. They report a precision of 64% on English medical texts. Another example is Patrick et al. (2010) and Patrick and Nguyen (2011), who combine a mixture of generation of spelling candidates based on orthographic and phonological edit distance, and a 2- word window of contextual information for ranking the spelling candidates resulting in an accuracy of 84% on English patient records. Sikl´oski et al. (2013) use a statistical machine translation model 76 Figure 1: Distribution of 100 PR dataset sentences by length (number of sentences on the y-axis and number of tokens on the x-axis). (with 3-grams) for spelling correction, achieving 88% accuracy on Hungarian medical texts. 4 Experimental da</context>
<context position="25501" citStr="Patrick et al., 2010" startWordPosition="3864" endWordPosition="3867">empt to address the problem of lexical simplification, and, in the long run, improve readability of Swedish EHRs, by automatically detecting and resolving out of dictionary words, achieves 91.1% (abbreviations), 83.5% (compound splitting) and 83.87% (spelling correction) precision, respectively. These results are comparable to those 15This number of compounds is derived from the number of abbreviations included in compounds (from SCATM 1a) by selecting only those out-of -dictionary words which do not contain punctuation. 80 reported in similar studies on English and Hungarian patient records (Patrick et al., 2010; Sikl´osi et al., 2013). Furthermore, the analysis of the gold standard data revealed that around 14% of all words in Swedish EHRs are abbreviations. More specifically, 2% of all the words are compounds including abbreviations. In contrast, and somewhat unexpectedly, only 1% are misspellings. This distribution result is an important finding for future studies in lexical simplification and readability studies of EHRs, as it might be useful for informing automatic processing approaches. We draw two conclusions from this study. First, to advance research into the field of readability of EHRs, an</context>
</contexts>
<marker>Patrick, Sabbagh, Jain, Zheng, 2010</marker>
<rawString>J. Patrick, M. Sabbagh, S. Jain, and H. Zheng. 2010. Spelling correction in Clinical Notes with Emphasis on First Suggestion Accuracy. In 2nd Workshop on Building and Evaluating Resources for Biomedical Text Mining, pages 2–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pyper</author>
<author>J Amery</author>
<author>M Watson</author>
<author>C Crook</author>
</authors>
<title>Patients experiences when accessing their on-line electronic patient records in primary care.</title>
<date>2004</date>
<journal>The British Journal of General Practice,</journal>
<pages>54--38</pages>
<contexts>
<context position="9049" citStr="Pyper et al., 2004" startWordPosition="1378" endWordPosition="1381">, in a Swedish intensive care unit, the drug Noradrenalin was creatively written in 60 different ways by the nurses (Allvin et al., 2011). It should be noted that speech recognition, although common in many hospitals around the 3www.ncbi.nlm.nih.gov 4http://www.ihtsdo.org/ 75 world, has not been introduced in Sweden, and many physicians and all nurses type the notes themselves. This is one explanation to the variation with respect to abbreviations. User studies have shown that the greatest barriers for patients lie mainly in the frequent use of abbreviations, jargon and technical terminology (Pyper et al., 2004; Keselman et al., 2007; Adnan et al., 2010). The most common comprehension errors made by laymen concern clinical concepts, medical terminology and medication names. Furthermore, there are great challenges for higher-level processing like syntax and semantics (Meystre et al., 2008; Wu et al., 2013). The research presented in this paper focuses on lexical simplification of clinical text. 3 Related research We are aware of several efforts to construct automated text simplification tools for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies</context>
</contexts>
<marker>Pyper, Amery, Watson, Crook, 2004</marker>
<rawString>C. Pyper, J. Amery, M. Watson, and C. Crook. 2004. Patients experiences when accessing their on-line electronic patient records in primary care. The British Journal of General Practice, 54:38–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ruch</author>
<author>R Baud</author>
<author>A Geissb¨uhler</author>
</authors>
<title>Using lexical disambiguation and named-entity recognition to improve spelling correction in the electronic patient record.</title>
<date>2003</date>
<journal>Artificial Intelligence in Medicine,</journal>
<pages>29--1</pages>
<marker>Ruch, Baud, Geissb¨uhler, 2003</marker>
<rawString>P. Ruch, R. Baud, and A. Geissb¨uhler. 2003. Using lexical disambiguation and named-entity recognition to improve spelling correction in the electronic patient record. Artificial Intelligence in Medicine, 29(1-2):169–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Sikl´osi</author>
<author>A Nov´ak</author>
<author>G Pr´osz´eky</author>
</authors>
<title>ContextAware Correction of Spelling Errors in Hungarian Medical Documents,</title>
<date>2013</date>
<booktitle>Number Lecture Notes in Computer Science</booktitle>
<pages>248--259</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Sikl´osi, Nov´ak, Pr´osz´eky, 2013</marker>
<rawString>B. Sikl´osi, A. Nov´ak, and G. Pr´osz´eky, 2013. ContextAware Correction of Spelling Errors in Hungarian Medical Documents, pages 248–259. Number Lecture Notes in Computer Science 7978. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sj¨obergh</author>
<author>V Kann</author>
</authors>
<title>Vad kan statistik avsl¨oja om svenska sammans¨attningar? Spr˚ak och stil,</title>
<date>2006</date>
<pages>1--199</pages>
<marker>Sj¨obergh, Kann, 2006</marker>
<rawString>J. Sj¨obergh and V. Kann. 2006. Vad kan statistik avsl¨oja om svenska sammans¨attningar? Spr˚ak och stil, 1:199–214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Skeppstedt</author>
<author>M Kvist</author>
<author>H Dalianis</author>
</authors>
<title>Rule-based Entity Recognition and Coverage of SNOMED CT in Swedish Clinical Text.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighth International Conference on Language Resources and Evaluation, LREC 2012,</booktitle>
<pages>1250--1257</pages>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="7995" citStr="Skeppstedt et al. (2012)" startWordPosition="1209" endWordPosition="1212">ent is having a myocardial infarction”. Similar phenomena are described by Josefsson (1999). Abbreviations and acronyms in EHRs can follow standardised writing rules or be ad hoc (Liu et al., 2001). They are often domain-specific and may be found in medical dictionaries such as MeSH3 and Snomed CT4. For instance, 18 of the 100 most common words in Swedish radiology reports were abbreviations, and 10 of them were domain-specific (Kvist and Velupillai, 2013). Because many medical terms are multiword expressions that are repeated frequently in a patient’s EHR, the use of acronyms is very common. Skeppstedt et al. (2012) showed that 14% of diagnostic expressions were abbreviated in Swedish clinical text. Abbreviations are often ambiguous. As an example, 33% of the short abbreviations in the UMLS terminology are ambiguous (Liu et al., 2001). Pakhomov et al. (2005) found that the abbreviation RA had more than 20 expansions in the UMLS terminology alone. Furthermore, a certain word or expression can be shortened in several different ways. For instance, in a Swedish intensive care unit, the drug Noradrenalin was creatively written in 60 different ways by the nurses (Allvin et al., 2011). It should be noted that s</context>
<context position="11957" citStr="Skeppstedt et al. (2012)" startWordPosition="1828" endWordPosition="1831">ery reliable for genres like newspaper text, with typical accuracies for Swedish around 97%, but performs poorer in domain specific genres. 3.3 Terminology detection The detection of English medical terminology is a widely researched area. An example of term detection in English clinical texts is Wang and Patrick (2009) work based on rule-based and machine learning methods, reporting 84% precision. For Swedish clinical text, Kokkinakis and Thurin (2007) have employed domain terminology matching and reached 98% precision and 87% recall in detecting terms of disorders. Using similar approaches, Skeppstedt et al. (2012), reached 75% precision and 55% recall in detecting terms of disorders. With a machine learning based approach, improved results were obtained: 80% precision, 82% recall (Skeppstedt et al., 2014). Skeppstedt et al. (2012) have also demonstrated the negative influence of abbreviations and multiword expressions in their findings. 3.4 Spelling correction A system for general spelling correction of Swedish is described by Kann et al. (1998), but we are not aware of any previous work related to spelling correction of Swedish clinical text. An example of spelling correction of clinical text for othe</context>
</contexts>
<marker>Skeppstedt, Kvist, Dalianis, 2012</marker>
<rawString>M. Skeppstedt, M. Kvist, and H Dalianis. 2012. Rule-based Entity Recognition and Coverage of SNOMED CT in Swedish Clinical Text. In Proceedings of the Eighth International Conference on Language Resources and Evaluation, LREC 2012, pages 1250–1257, Istanbul, Turkey, May 23–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Skeppstedt</author>
<author>M Kvist</author>
<author>G H Nilsson</author>
<author>H Dalianis</author>
</authors>
<title>Automatic recognition of disorders, findings, pharmaceuticals and body structures from clinical text: An annotation and machine learning study.</title>
<date>2014</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>10--1016</pages>
<contexts>
<context position="12152" citStr="Skeppstedt et al., 2014" startWordPosition="1858" endWordPosition="1861">cal terminology is a widely researched area. An example of term detection in English clinical texts is Wang and Patrick (2009) work based on rule-based and machine learning methods, reporting 84% precision. For Swedish clinical text, Kokkinakis and Thurin (2007) have employed domain terminology matching and reached 98% precision and 87% recall in detecting terms of disorders. Using similar approaches, Skeppstedt et al. (2012), reached 75% precision and 55% recall in detecting terms of disorders. With a machine learning based approach, improved results were obtained: 80% precision, 82% recall (Skeppstedt et al., 2014). Skeppstedt et al. (2012) have also demonstrated the negative influence of abbreviations and multiword expressions in their findings. 3.4 Spelling correction A system for general spelling correction of Swedish is described by Kann et al. (1998), but we are not aware of any previous work related to spelling correction of Swedish clinical text. An example of spelling correction of clinical text for other languages is Tolentino et al. (2007), who use several algorithms for word similarity detection, including phonological homonym lookup and ngrams for contextual disambiguation. They report a pre</context>
</contexts>
<marker>Skeppstedt, Kvist, Nilsson, Dalianis, 2014</marker>
<rawString>M. Skeppstedt, M. Kvist, G. H. Nilsson, and H. Dalianis. 2014. Automatic recognition of disorders, findings, pharmaceuticals and body structures from clinical text: An annotation and machine learning study. Journal of Biomedical Informatics, http://dx.doi.org/10.1016/j.jbi.2014.01.012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Smedby</author>
</authors>
<title>Medicinens Spr˚ak: spr˚aket i sjukdomsklassifikationen – mer konsekvent f¨orsvenskning efterstr¨avas [Language of Medicine: the language of diagnose classification - more consequent Swedification sought]. L¨akartidningen,</title>
<date>1991</date>
<pages>1519--1520</pages>
<contexts>
<context position="5466" citStr="Smedby, 1991" startWordPosition="810" endWordPosition="811">te from Latin or Greek. Different languages have adapted these terms differently (Bretschneider et al., 2013). The Swedish medical terminology went through a change during the 1990s due to a swedification of diagnostic expressions performed in the 1987 update of the Swedish version of ICD, the International Classification of Diseases1. For this version, the Swedish National Board of Health and Welfare decided to partly change the terminology of traditional Latin- and Greek-rooted words to a spelling compatible to Swedish spelling rules, as well as abandoning the original rules for inflection (Smedby, 1991). In this spelling reform, c and ch pronounced as k was changed to k, ph was changed to f, th to t, and oe was changed to e. For example, the technical term for cholecsystitis (inflammation of the gall bladder) is spelled kolecystit in contemporary Swedish, thus following the convention of changing ch to k and removing the Latin ending of -is. The results2 of exact matching to kolecystit (English: cholecystitis) and some presumed spelling variants clearly demonstrate the slow progress (Table 1). As medical literature is predominantly written in English nowadays, physicians increasingly get exp</context>
</contexts>
<marker>Smedby, 1991</marker>
<rawString>B. Smedby. 1991. Medicinens Spr˚ak: spr˚aket i sjukdomsklassifikationen – mer konsekvent f¨orsvenskning efterstr¨avas [Language of Medicine: the language of diagnose classification - more consequent Swedification sought]. L¨akartidningen, pages 1519–1520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Surj´an</author>
<author>G H´eja</author>
</authors>
<title>About the language of Hungarian discharge reports. Stud Health Technol Inform,</title>
<date>2003</date>
<pages>95--869</pages>
<marker>Surj´an, H´eja, 2003</marker>
<rawString>G. Surj´an and G. H´eja. 2003. About the language of Hungarian discharge reports. Stud Health Technol Inform, 95:869–873.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H D Tolentino</author>
<author>M D Matters</author>
<author>W Walop</author>
<author>B Law</author>
<author>W Tong</author>
<author>F Liu</author>
<author>P A Fontelo</author>
<author>K Kohl</author>
<author>D C Payne</author>
</authors>
<title>A UMLS-based spell checker for natural language processing in vaccine safety.</title>
<date>2007</date>
<journal>BMC Med. Inf. &amp; Decision Making,</journal>
<volume>7</volume>
<contexts>
<context position="12595" citStr="Tolentino et al. (2007)" startWordPosition="1928" endWordPosition="1931">recision and 55% recall in detecting terms of disorders. With a machine learning based approach, improved results were obtained: 80% precision, 82% recall (Skeppstedt et al., 2014). Skeppstedt et al. (2012) have also demonstrated the negative influence of abbreviations and multiword expressions in their findings. 3.4 Spelling correction A system for general spelling correction of Swedish is described by Kann et al. (1998), but we are not aware of any previous work related to spelling correction of Swedish clinical text. An example of spelling correction of clinical text for other languages is Tolentino et al. (2007), who use several algorithms for word similarity detection, including phonological homonym lookup and ngrams for contextual disambiguation. They report a precision of 64% on English medical texts. Another example is Patrick et al. (2010) and Patrick and Nguyen (2011), who combine a mixture of generation of spelling candidates based on orthographic and phonological edit distance, and a 2- word window of contextual information for ranking the spelling candidates resulting in an accuracy of 84% on English patient records. Sikl´oski et al. (2013) use a statistical machine translation model 76 Figu</context>
</contexts>
<marker>Tolentino, Matters, Walop, Law, Tong, Liu, Fontelo, Kohl, Payne, 2007</marker>
<rawString>H. D. Tolentino, M. D. Matters, W. Walop, B. Law, W. Tong, F. Liu, P. A. Fontelo, K. Kohl, and D. C. Payne. 2007. A UMLS-based spell checker for natural language processing in vaccine safety. BMC Med. Inf. &amp; Decision Making, 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wang</author>
<author>J Patrick</author>
</authors>
<title>Cascading classifiers for named entity recognition in clinical notes.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Biomedical Information Extraction, WBIE ’09,</booktitle>
<pages>42--49</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11654" citStr="Wang and Patrick (2009)" startWordPosition="1782" endWordPosition="1785">be used for generating compounds. For example, Sj¨obergh and Kann (2006) used a lexicon derived from SAOL (the Swedish Academy word list), and ¨Ostling and Wir´en (2013) used the SALDO lexicon of Swedish morphology (Borin and Forsberg, 2009). With this kind of approach, compound splitting is usually very reliable for genres like newspaper text, with typical accuracies for Swedish around 97%, but performs poorer in domain specific genres. 3.3 Terminology detection The detection of English medical terminology is a widely researched area. An example of term detection in English clinical texts is Wang and Patrick (2009) work based on rule-based and machine learning methods, reporting 84% precision. For Swedish clinical text, Kokkinakis and Thurin (2007) have employed domain terminology matching and reached 98% precision and 87% recall in detecting terms of disorders. Using similar approaches, Skeppstedt et al. (2012), reached 75% precision and 55% recall in detecting terms of disorders. With a machine learning based approach, improved results were obtained: 80% precision, 82% recall (Skeppstedt et al., 2014). Skeppstedt et al. (2012) have also demonstrated the negative influence of abbreviations and multiwor</context>
</contexts>
<marker>Wang, Patrick, 2009</marker>
<rawString>Y. Wang and J. Patrick. 2009. Cascading classifiers for named entity recognition in clinical notes. In Proceedings of the Workshop on Biomedical Information Extraction, WBIE ’09, pages 42–49, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D T Y Wu</author>
<author>D A Hanauer</author>
<author>Q Mei</author>
<author>P M Clark</author>
<author>L C An</author>
<author>J Lei</author>
<author>J Proulx</author>
<author>Q Zeng-Treitler</author>
<author>K Zheng</author>
</authors>
<title>Applying Multiple Methods to Assess the Readability of a Large Corpus of Medical Documents. Stud Health Technol Inform,</title>
<date>2013</date>
<pages>651</pages>
<contexts>
<context position="9349" citStr="Wu et al., 2013" startWordPosition="1424" endWordPosition="1427">duced in Sweden, and many physicians and all nurses type the notes themselves. This is one explanation to the variation with respect to abbreviations. User studies have shown that the greatest barriers for patients lie mainly in the frequent use of abbreviations, jargon and technical terminology (Pyper et al., 2004; Keselman et al., 2007; Adnan et al., 2010). The most common comprehension errors made by laymen concern clinical concepts, medical terminology and medication names. Furthermore, there are great challenges for higher-level processing like syntax and semantics (Meystre et al., 2008; Wu et al., 2013). The research presented in this paper focuses on lexical simplification of clinical text. 3 Related research We are aware of several efforts to construct automated text simplification tools for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability perspective. Borin et al. (2009) present a thorough investigation on Swedish (and English) medical language, but EHR texts are explicitly not included. This section summarizes research on Swedish (clinical) text with respect to lexical simplification by handli</context>
</contexts>
<marker>Wu, Hanauer, Mei, Clark, An, Lei, Proulx, Zeng-Treitler, Zheng, 2013</marker>
<rawString>D. T. Y. Wu, D. A. Hanauer, Q. Mei, P. M. Clark, L. C. An, J. Lei, J. Proulx, Q. Zeng-Treitler, and K. Zheng. 2013. Applying Multiple Methods to Assess the Readability of a Large Corpus of Medical Documents. Stud Health Technol Inform, 192:647– 651.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Xu</author>
<author>P D Stetson</author>
<author>C Friedman</author>
</authors>
<title>A Study of Abbreviations in Clinical Notes.</title>
<date>2007</date>
<booktitle>In Proc AMIA</booktitle>
<pages>821--825</pages>
<contexts>
<context position="10154" citStr="Xu et al. (2007)" startWordPosition="1545" endWordPosition="1548">s for clinical text in English (Kandula et al., 2010; Patrick et al., 2010). For Swedish, there are few studies on medical language from a readability perspective. Borin et al. (2009) present a thorough investigation on Swedish (and English) medical language, but EHR texts are explicitly not included. This section summarizes research on Swedish (clinical) text with respect to lexical simplification by handling of abbreviations, terminology and spelling correction. 3.1 Abbreviation detection Abbreviation identification in English biomedical and clinical texts has been studied extensively (e.g. Xu et al. (2007), Liu et al. (2001)). For detection of Swedish medical abbreviations, there are fewer studies. Dann´ells (2006) reports detection of acronyms in medical journal text with 98% recall and 94% precision by using part of speech information and heuristic rules. Clinical Swedish presents greater problems than medical texts, because of ad hoc abbreviations and noisier text. By using lexicons and a few heuristic rules, Isenius et al. (2012) report the best F-score of 79% for abbreviation detection in clinical Swedish. 3.2 Compound splitting Good compound analysis is critical especially for languages w</context>
</contexts>
<marker>Xu, Stetson, Friedman, 2007</marker>
<rawString>H. Xu, P. D. Stetson, and C. Friedman. 2007. A Study of Abbreviations in Clinical Notes. In Proc AMIA 2007, pages 821–825.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>