<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000505">
<title confidence="0.990293">
Towards Surface Realization with CCGs Induced from Dependencies
</title>
<author confidence="0.989349">
Michael White
</author>
<affiliation confidence="0.9466005">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.728358">
Columbus, OH 43210, USA
</address>
<email confidence="0.999314">
mwhite@ling.osu.edu
</email>
<sectionHeader confidence="0.993909" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999691857142857">
We present a novel algorithm for inducing
Combinatory Categorial Grammars from
dependency treebanks, along with initial
experiments showing that it can be used
to achieve competitive realization results
using an enhanced version of the surface
realization shared task data.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999486">
In the first surface realization shared task (Belz
et al., 2011), no grammar-based systems achieved
competitive results, as input conversion turned
out to be more difficult than anticipated. Since
then, Narayan &amp; Gardent (2012) have shown that
grammar-based systems can be substantially im-
proved with error mining techniques. In this pa-
per, inspired by recent work on converting depen-
dency treebanks (Ambati et al., 2013) and seman-
tic parsing (Kwiatkowksi et al., 2010; Artzi and
Zettlemoyer, 2013) with Combinatory Categorial
Grammar (CCG), we pursue the alternative strat-
egy of inducing a CCG from an enhanced version
of the shared task dependencies, with initial exper-
iments showing even better results.
A silver lining of the failure of grammar-based
systems in the shared task is that it revealed some
problems with the data. In particular, it became
evident that in cases where a constituent is an-
notated with multiple roles in the Penn Treebank
(PTB), the partial nature of Propbank annotation
and the restriction to syntactic dependency trees
meant that information was lost between the sur-
face and deep representations, leading grammar-
based systems to fail for good reason. For ex-
ample, Figure 1 shows that with free object rel-
atives, only one of the two roles played by how
much manufacturing strength is captured in the
deep representation, making it difficult to linearize
this phrase correctly. By contrast, Figure 2 (top)
</bodyText>
<figure confidence="0.429538">
!�
</figure>
<figureCaption confidence="0.997374">
Figure 1: Shared Task Input for Economists are
</figureCaption>
<bodyText confidence="0.847062125">
divided as to [how much manufacturing strength]i
�!&apos;�
they expect to see ti in September reports on indus-
$��)�,�����
trial production and capacity utilization , also due
��
tomorrow (wsj 2400.6, “deep” representation)
shows an experimental version of the shallow rep-
resentation intended to capture all the syntactic de-
pendencies in the PTB, including the additional
object role played by this phrase here.1 Includ-
ing all PTB syntactic dependencies in the shallow
representation makes it feasible to define a com-
patible CCG; at the bottom of the figure, a cor-
responding CCG derivation for these dependen-
cies is shown. In the next section, we present an
algorithm for inducing such derivations. In con-
trast to Ambati et al.’s (2013) approach, the algo-
rithm integrates the proposal of candidate lexical
categories with the derivational process, making it
possible to derive categories involving unsaturated
arguments, such as se,dcl\npx/(se,,to\npx); it also
makes greater use of unary type-changing rules,
as with Artzi &amp; Zettlemoyer’s (2013) approach.
</bodyText>
<footnote confidence="0.980768">
1Kudos to Richard Johansson for making these enhance-
ments available.
</footnote>
<figure confidence="0.998655666666666">
��
P
W
SBJ dmv
�
AM-CAU
Al
a�apm�
��
Al
��
Al
e&lt;cea
Al
A0 ..
AM- !C
A0
Al
~~~~
n gth
i.
~#
Al
Al
h-
man$%act$ring
repprt
A&amp;&apos;~
AM—P
Al
—h
Mpcem ,
��
</figure>
<page confidence="0.917127">
147
</page>
<bodyText confidence="0.940800166666667">
Proceedings of the 8th International Natural Language Generation Conference, pages 147–151,
Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics
Unlike their approach though, it works in a broad
coverage setting, and makes use of all the combi-
nators standardly used with CCG, including ones
for type-raising.
</bodyText>
<sectionHeader confidence="0.590726" genericHeader="introduction">
2 Inducing CCGs from Dependencies
</sectionHeader>
<bodyText confidence="0.999875230769231">
Pseudocode for the induction algorithm is given
in Figure 3. The algorithm takes as input a set
of training sentences with their gold standard de-
pendencies. We pre-processed the dependencies
to make coordinating conjunctions the head, and
to include features for zero-determiners. The algo-
rithm also makes use of a seed lexicon that spec-
ifies category projection by part of speech as well
as a handful of categories for function words. For
example, (1) shows how a tensed verb projects to
a finite clause category, while (2) shows the usual
CCG category for a determiner, which here intro-
duces a (NMOD) dependency.2
</bodyText>
<listItem confidence="0.9971765">
(1) expect �- s,,dcl @e(expect n (TENSE)pres)
(2) the �- np./n. @x((NMOD)(d n the))
</listItem>
<bodyText confidence="0.99992568">
The algorithm begins by instantiating the lexical
categories and type-changing rules that match the
input dependency graph, tracking the categories
in a map (edges) from nodes to edges (i.e., signs
with a coverage vector). It then recursively vis-
its each node in the primary dependency tree bot-
tom up (combineEdges), using a local chart (do-
Combos) at each step to combine categories for
adjacent phrases in all possible ways. Along the
way, it creates new categories (extendCats and co-
ordCats) and unary rules (applyNewUnary). For
example, when processing the node for expect in
Figure 2, the nodes for they and to are recursively
processed first, deriving the categories npw9 and
sw11 ,to\npw9 /npws for they and to see ..., respec-
tively. The initial category for expect is then ex-
tended as shown in (3), which allows for com-
position with to see ... (as well as with a cate-
gory for simple application). When there are co-
ordination relations for a coordinating conjunction
(or coordinating punctuation mark), the appropri-
ate category for combining like types is instead
constructed, as in (4). Additionally, for modifiers,
unary rules are instantiated and applied, e.g. the
rule for noun-noun compounds in (5).
</bodyText>
<footnote confidence="0.640555166666667">
2In the experiments reported here, we made use of only
six (non-trivial) hand-specified categories and two type-
changing rules; though we anticipate adding more initial cat-
egories to handle some currently problematic cases, the vast
majority of the categories in the resulting grammar can be
induced automatically.
</footnote>
<bodyText confidence="0.884421111111111">
Inputs Training set of sentences with dependencies. Initial
lexicon and rules. Argument and modifier relations. Deriva-
tion scoring metric. Maximum agenda size.
Definitions edges is a map from dependency graph nodes
to their edges, where an edge is a CCG sign together with a
coverage bitset; agenda is a priority queue of edges sorted
by the scoring metric; chart manages equivalence classes of
edges; see text for descriptions of auxiliary functions such as
extendCats and coordCats below.
</bodyText>
<subsectionHeader confidence="0.575398">
Algorithm
</subsectionHeader>
<bodyText confidence="0.7407465">
bestDerivs, lexcats, unaryRules +- 0
For each item in training set:
</bodyText>
<listItem confidence="0.995448107142857">
1. edges[node] +- instCats(node), ruleInsts[node] +- in-
stRules(node), for node in input graph
2. combineEdges(root), with root of input graph
3. bestEdge +- unpack(edges[root]); bestDerivs ++-
bestEdge.sign; lexcats ++- abstractedCats(bestEdge),
unaryRules ++- abstractedRules(bestEdge), if best-
Edge complete
def combineEdges(node):
1. combineEdges(child) for child in node.kids
2. edges[node] ++- coordCats(node) if node has co-
ord relations, otherwise edges[node] +- extend-
Cats(node,rels) for argument rels
3. agenda +- edges[node]; agenda ++- edges[child] for
child in node.kids; chart +- 0
4. While agenda not empty:
(a) next +- agenda.pop
(b) chart ++- next
(c) doCombos(next), unless next packed into an ex-
isting chart item
5. edges[node] +- chart edges for node filtered for maxi-
mal input coverage
def doCombos(next):
1. agenda ++- applyUnary(next), if next is for node
2. For item in chart:
(a) agenda ++- applyBinary(next,item), if next is ad-
jacent to item
(b) agenda ++- applyNewUnary(next,item), if next
connected to item by a modifier relation
</listItem>
<subsubsectionHeader confidence="0.613575">
Outputs bestDerivs, lexcats, unaryRules
</subsubsectionHeader>
<figureCaption confidence="0.995668">
Figure 3: CCG Induction Algorithm
</figureCaption>
<page confidence="0.883446">
148
</page>
<figure confidence="0.9777661">
economists are divided as to how much manufacturing strength they expect to see in ... .
... September reports on industrial production and capacity utilization , also due tomorrow
t h ch an t en th the expect t ee
pp/np s n np s \np/(s \np) s \np/(s \np) s \np/np
&gt;�
\ n/n s/(s\np) s \np/np
n s \np/np
&gt; &gt;s
np/(s/np)/n s /np
&gt;
np/(s/np) &gt;
&gt;
np
pp
ept ep t n nd t a p d ct n and capac t t at n
np n pp/np n np\⇤np/⇤np n n
n/n n/n n/n
&gt; &gt; &gt;
n n n
np np
&gt;
&lt;
&gt;
np\⇤np
np
pp
n\n
&lt;
n
np
</figure>
<figureCaption confidence="0.975438">
Figure 2: Augmented Syntactic Dependencies with Corresponding CCG Derivation (dashed dependen-
</figureCaption>
<figure confidence="0.996527">
gueamp
cies indicate relations from additional parents beyond those in the primary tree structure)
root
pmod
nmod
obj
subj
obj
vc
adv
pmod
amod
nmod sub
subj
sbj
oprd im loc pmod
p
pmod
tmp
amod
coord2
nmod
nmod
nmod
nmod
coord1
appo
p
pmod
&gt;s
&gt;s
</figure>
<page confidence="0.99625">
149
</page>
<bodyText confidence="0.9998172">
At the end of the recursion, the lexical cate-
gories and type-changing rules are extracted from
the highest-scoring derivation and added to the
output sets, after first replacing indices such as w10
with variables.
</bodyText>
<sectionHeader confidence="0.995805" genericHeader="background">
3 Experiments and Future Work
</sectionHeader>
<bodyText confidence="0.999996944444444">
We ran the induction algorithm over the stan-
dard PTB training sections (02–21), recovering
complete derivations more than 90% of the time
for most sections. Robust treatment of coordina-
tion, including argument cluster coordination and
gapping, remains a known issue; other causes of
derivation failures remain to be investigated. To
select preferred derivations, we used a complex-
ity metric that simply counts the number of steps
and the number of slashes in the categories. We
then trained a generative syntactic model (Hock-
enmaier and Steedman, 2002) and used it along
with a composite language model to generate n-
best realizations for reranking (White and Rajku-
mar, 2012), additionally using a large-scale (giga-
word) language model. Development and test re-
sults appear in Table 1. Perhaps because of the
expanded use of type-changing rules with sim-
ple lexical categories, the generative model and
hypertagger (Espinosa et al., 2008) performed
worse than expected. Combining the generative
syntactic model and composite language model
(GEN) with equal weight yielded a devtest BLEU
score of only 0.4513, while discriminatively train-
ing the generative component models (GLOBAL)
increased the score to 0.7679. Using all fea-
tures increased the score to 0.8083, while dou-
bling the beam size (ALL+) pushed the score to
0.8210, indicating that search errors may be an
issue. Ablation results show that leaving out
the large-scale language model (NO-BIGLM) and
dependency-ordering features (NO-DEPORD) sub-
stantially drops the score.3 Focusing only on
the 80.5% of the sentences for which a complete
derivation was found (COMPLETE) yielded a score
of 0.8668. By comparison, realization with the
</bodyText>
<footnote confidence="0.846093">
3All differences were statistically significant at p &lt; 0.01
with paired bootstrap resampling (Koehn, 2004).
</footnote>
<table confidence="0.999864294117647">
Model Exact Complete BLEU
Sect 00 2.4 79.5 0.4513
GEN 29.7 79.0 0.7679
GLOBAL
NO-BIGLM 29.1 78.2 0.7757
NO-DEPORD 34.3 77.9 0.7956
ALL 35.8 78.4 0.8083
ALL+ 36.4 80.5 0.8210
COMPLETE 44.4 - 0.8668
NATIVE 48.0 88.7 0.8793
Sect 23
GEN 2.8 80.3 0.4560
GLOBAL 31.3 78.5 0.7675
ALL 37.6 77.2 0.8083
ALL+ 38.1 80.4 0.8260
COMPLETE 47.0 - 0.8743
NATIVE 46.4 86.4 0.8694
</table>
<tableCaption confidence="0.998956">
Table 1: Development set (Section 00) &amp; test set
</tableCaption>
<bodyText confidence="0.9908335">
(Section 23) results, including exact match and
complete derivation percentages and BLEU scores
native OpenCCG inputs (and the large-scale LM)
on all sentences (NATIVE) yields a score more
than five BLEU points higher, despite using in-
puts with more semantically-oriented relations and
leaving out many function words, indicating that
there is likely substantial room for improvement
in the pre-processing and grammar induction pro-
cess. Towards that end, we tried selecting the best
derivations using several rounds of Viterbi EM
with the generative syntactic model, but doing so
did not improve realization quality.
A similar pattern is seen in the Section 23 re-
sults, with a competitive BLEU score of 0.8260
with the expanded beam, much higher than
Narayan &amp; Gardent’s (2012) score of 0.675 with
38.8% coverage, the best previous score with a
grammar-based system. This score still trails the
shared task scores of the top statistical dependency
realizers by several points (STUMABA-S at 0.8911
and DCU at 0.8575), though it exceeds the score of
a purpose-built system using no external resources
(ATT at 0.6701). In future work, we hope to close
the gap with the top systems by integrating an im-
proved ranking model into the induction process
and resolving the remaining representational is-
sues with problematic constructions.
</bodyText>
<sectionHeader confidence="0.998845" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.940526">
Thanks to the anonymous reviewers, Richard Johansson and
the University of Sydney Schwa Lab for helpful comments
and discussion. This work was supported in part by NSF
grants IIS-1143635 and IIS-1319318.
</bodyText>
<figure confidence="0.9989275">
(3) expect �- sw10 ,dcl\npw9 /(sw11 ,to\npw9 ) :
@w10(expect n (TENSE)pres n
(SUBJ)wg n (OPRED)w11)
(4) and �- npw19 \∗npw18 /∗npw21 :
@w1s(and n (COORD1)w1a n (COORD2)w21)
(5) nw20 �* nw21 /nw21 : @w21((NMOD)w20)
</figure>
<page confidence="0.982368">
150
</page>
<sectionHeader confidence="0.994349" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999899678571428">
Bharat Ram Ambati, Tejaswini Deoskar, and Mark
Steedman. 2013. Using CCG categories to improve
Hindi dependency parsing. In Proc. ACL.
Yoav Artzi and Luke Zettlemoyer. 2013. Weakly su-
pervised learning of semantic parsers for mapping
instructions to actions. TACL, 1:49–62.
Anja Belz, Michael White, Dominic Espinosa, Eric
Kow, Deirdre Hogan, and Amanda Stent. 2011. The
first surface realisation shared task: Overview and
evaluation results. In Proc. ENLG.
Dominic Espinosa, Michael White, and Dennis Mehay.
2008. Hypertagging: Supertagging for surface real-
ization with CCG. In Proc. ACL.
Julia Hockenmaier and Mark Steedman. 2002. Gen-
erative models for statistical parsing with Combina-
tory Categorial Grammar. In Proc. ACL.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proc. EMNLP.
Tom Kwiatkowksi, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing probabilis-
tic CCG grammars from logical form with higher-
order unification. In Proc. EMNLP.
Shashi Narayan and Claire Gardent. 2012. Error min-
ing with suspicion trees: Seeing the forest for the
trees. In Proc. COLING.
Michael White and Rajakrishnan Rajkumar. 2012.
Minimal dependency length in realization ranking.
In Proc. EMNLP.
</reference>
<page confidence="0.998351">
151
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.989045">
<title confidence="0.999965">Towards Surface Realization with CCGs Induced from Dependencies</title>
<author confidence="0.999992">Michael White</author>
<affiliation confidence="0.999783">Department of Linguistics The Ohio State University</affiliation>
<address confidence="0.999975">Columbus, OH 43210, USA</address>
<email confidence="0.999823">mwhite@ling.osu.edu</email>
<abstract confidence="0.998710125">We present a novel algorithm for inducing Combinatory Categorial Grammars from dependency treebanks, along with initial experiments showing that it can be used to achieve competitive realization results using an enhanced version of the surface realization shared task data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bharat Ram Ambati</author>
<author>Tejaswini Deoskar</author>
<author>Mark Steedman</author>
</authors>
<title>Using CCG categories to improve Hindi dependency parsing.</title>
<date>2013</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="893" citStr="Ambati et al., 2013" startWordPosition="125" endWordPosition="128">treebanks, along with initial experiments showing that it can be used to achieve competitive realization results using an enhanced version of the surface realization shared task data. 1 Introduction In the first surface realization shared task (Belz et al., 2011), no grammar-based systems achieved competitive results, as input conversion turned out to be more difficult than anticipated. Since then, Narayan &amp; Gardent (2012) have shown that grammar-based systems can be substantially improved with error mining techniques. In this paper, inspired by recent work on converting dependency treebanks (Ambati et al., 2013) and semantic parsing (Kwiatkowksi et al., 2010; Artzi and Zettlemoyer, 2013) with Combinatory Categorial Grammar (CCG), we pursue the alternative strategy of inducing a CCG from an enhanced version of the shared task dependencies, with initial experiments showing even better results. A silver lining of the failure of grammar-based systems in the shared task is that it revealed some problems with the data. In particular, it became evident that in cases where a constituent is annotated with multiple roles in the Penn Treebank (PTB), the partial nature of Propbank annotation and the restriction </context>
</contexts>
<marker>Ambati, Deoskar, Steedman, 2013</marker>
<rawString>Bharat Ram Ambati, Tejaswini Deoskar, and Mark Steedman. 2013. Using CCG categories to improve Hindi dependency parsing. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Weakly supervised learning of semantic parsers for mapping instructions to actions.</title>
<date>2013</date>
<tech>TACL,</tech>
<pages>1--49</pages>
<contexts>
<context position="970" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="137" endWordPosition="140"> to achieve competitive realization results using an enhanced version of the surface realization shared task data. 1 Introduction In the first surface realization shared task (Belz et al., 2011), no grammar-based systems achieved competitive results, as input conversion turned out to be more difficult than anticipated. Since then, Narayan &amp; Gardent (2012) have shown that grammar-based systems can be substantially improved with error mining techniques. In this paper, inspired by recent work on converting dependency treebanks (Ambati et al., 2013) and semantic parsing (Kwiatkowksi et al., 2010; Artzi and Zettlemoyer, 2013) with Combinatory Categorial Grammar (CCG), we pursue the alternative strategy of inducing a CCG from an enhanced version of the shared task dependencies, with initial experiments showing even better results. A silver lining of the failure of grammar-based systems in the shared task is that it revealed some problems with the data. In particular, it became evident that in cases where a constituent is annotated with multiple roles in the Penn Treebank (PTB), the partial nature of Propbank annotation and the restriction to syntactic dependency trees meant that information was lost between the sur</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Yoav Artzi and Luke Zettlemoyer. 2013. Weakly supervised learning of semantic parsers for mapping instructions to actions. TACL, 1:49–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
<author>Michael White</author>
<author>Dominic Espinosa</author>
<author>Eric Kow</author>
<author>Deirdre Hogan</author>
<author>Amanda Stent</author>
</authors>
<title>The first surface realisation shared task: Overview and evaluation results.</title>
<date>2011</date>
<booktitle>In Proc. ENLG.</booktitle>
<marker>Belz, White, Espinosa, Kow, Hogan, Stent, 2011</marker>
<rawString>Anja Belz, Michael White, Dominic Espinosa, Eric Kow, Deirdre Hogan, and Amanda Stent. 2011. The first surface realisation shared task: Overview and evaluation results. In Proc. ENLG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Espinosa</author>
<author>Michael White</author>
<author>Dennis Mehay</author>
</authors>
<title>Hypertagging: Supertagging for surface realization with CCG. In</title>
<date>2008</date>
<booktitle>Proc. ACL.</booktitle>
<contexts>
<context position="9544" citStr="Espinosa et al., 2008" startWordPosition="1539" endWordPosition="1542">be investigated. To select preferred derivations, we used a complexity metric that simply counts the number of steps and the number of slashes in the categories. We then trained a generative syntactic model (Hockenmaier and Steedman, 2002) and used it along with a composite language model to generate nbest realizations for reranking (White and Rajkumar, 2012), additionally using a large-scale (gigaword) language model. Development and test results appear in Table 1. Perhaps because of the expanded use of type-changing rules with simple lexical categories, the generative model and hypertagger (Espinosa et al., 2008) performed worse than expected. Combining the generative syntactic model and composite language model (GEN) with equal weight yielded a devtest BLEU score of only 0.4513, while discriminatively training the generative component models (GLOBAL) increased the score to 0.7679. Using all features increased the score to 0.8083, while doubling the beam size (ALL+) pushed the score to 0.8210, indicating that search errors may be an issue. Ablation results show that leaving out the large-scale language model (NO-BIGLM) and dependency-ordering features (NO-DEPORD) substantially drops the score.3 Focusi</context>
</contexts>
<marker>Espinosa, White, Mehay, 2008</marker>
<rawString>Dominic Espinosa, Michael White, and Dennis Mehay. 2008. Hypertagging: Supertagging for surface realization with CCG. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Generative models for statistical parsing with Combinatory Categorial Grammar. In</title>
<date>2002</date>
<booktitle>Proc. ACL.</booktitle>
<contexts>
<context position="9161" citStr="Hockenmaier and Steedman, 2002" startWordPosition="1477" endWordPosition="1481">st replacing indices such as w10 with variables. 3 Experiments and Future Work We ran the induction algorithm over the standard PTB training sections (02–21), recovering complete derivations more than 90% of the time for most sections. Robust treatment of coordination, including argument cluster coordination and gapping, remains a known issue; other causes of derivation failures remain to be investigated. To select preferred derivations, we used a complexity metric that simply counts the number of steps and the number of slashes in the categories. We then trained a generative syntactic model (Hockenmaier and Steedman, 2002) and used it along with a composite language model to generate nbest realizations for reranking (White and Rajkumar, 2012), additionally using a large-scale (gigaword) language model. Development and test results appear in Table 1. Perhaps because of the expanded use of type-changing rules with simple lexical categories, the generative model and hypertagger (Espinosa et al., 2008) performed worse than expected. Combining the generative syntactic model and composite language model (GEN) with equal weight yielded a devtest BLEU score of only 0.4513, while discriminatively training the generative</context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2002. Generative models for statistical parsing with Combinatory Categorial Grammar. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="10404" citStr="Koehn, 2004" startWordPosition="1670" endWordPosition="1671">eased the score to 0.7679. Using all features increased the score to 0.8083, while doubling the beam size (ALL+) pushed the score to 0.8210, indicating that search errors may be an issue. Ablation results show that leaving out the large-scale language model (NO-BIGLM) and dependency-ordering features (NO-DEPORD) substantially drops the score.3 Focusing only on the 80.5% of the sentences for which a complete derivation was found (COMPLETE) yielded a score of 0.8668. By comparison, realization with the 3All differences were statistically significant at p &lt; 0.01 with paired bootstrap resampling (Koehn, 2004). Model Exact Complete BLEU Sect 00 2.4 79.5 0.4513 GEN 29.7 79.0 0.7679 GLOBAL NO-BIGLM 29.1 78.2 0.7757 NO-DEPORD 34.3 77.9 0.7956 ALL 35.8 78.4 0.8083 ALL+ 36.4 80.5 0.8210 COMPLETE 44.4 - 0.8668 NATIVE 48.0 88.7 0.8793 Sect 23 GEN 2.8 80.3 0.4560 GLOBAL 31.3 78.5 0.7675 ALL 37.6 77.2 0.8083 ALL+ 38.1 80.4 0.8260 COMPLETE 47.0 - 0.8743 NATIVE 46.4 86.4 0.8694 Table 1: Development set (Section 00) &amp; test set (Section 23) results, including exact match and complete derivation percentages and BLEU scores native OpenCCG inputs (and the large-scale LM) on all sentences (NATIVE) yields a score mo</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowksi</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Inducing probabilistic CCG grammars from logical form with higherorder unification.</title>
<date>2010</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="940" citStr="Kwiatkowksi et al., 2010" startWordPosition="133" endWordPosition="136">howing that it can be used to achieve competitive realization results using an enhanced version of the surface realization shared task data. 1 Introduction In the first surface realization shared task (Belz et al., 2011), no grammar-based systems achieved competitive results, as input conversion turned out to be more difficult than anticipated. Since then, Narayan &amp; Gardent (2012) have shown that grammar-based systems can be substantially improved with error mining techniques. In this paper, inspired by recent work on converting dependency treebanks (Ambati et al., 2013) and semantic parsing (Kwiatkowksi et al., 2010; Artzi and Zettlemoyer, 2013) with Combinatory Categorial Grammar (CCG), we pursue the alternative strategy of inducing a CCG from an enhanced version of the shared task dependencies, with initial experiments showing even better results. A silver lining of the failure of grammar-based systems in the shared task is that it revealed some problems with the data. In particular, it became evident that in cases where a constituent is annotated with multiple roles in the Penn Treebank (PTB), the partial nature of Propbank annotation and the restriction to syntactic dependency trees meant that inform</context>
</contexts>
<marker>Kwiatkowksi, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Tom Kwiatkowksi, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing probabilistic CCG grammars from logical form with higherorder unification. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shashi Narayan</author>
<author>Claire Gardent</author>
</authors>
<title>Error mining with suspicion trees: Seeing the forest for the trees. In</title>
<date>2012</date>
<booktitle>Proc. COLING.</booktitle>
<contexts>
<context position="699" citStr="Narayan &amp; Gardent (2012)" startWordPosition="94" endWordPosition="97">te Department of Linguistics The Ohio State University Columbus, OH 43210, USA mwhite@ling.osu.edu Abstract We present a novel algorithm for inducing Combinatory Categorial Grammars from dependency treebanks, along with initial experiments showing that it can be used to achieve competitive realization results using an enhanced version of the surface realization shared task data. 1 Introduction In the first surface realization shared task (Belz et al., 2011), no grammar-based systems achieved competitive results, as input conversion turned out to be more difficult than anticipated. Since then, Narayan &amp; Gardent (2012) have shown that grammar-based systems can be substantially improved with error mining techniques. In this paper, inspired by recent work on converting dependency treebanks (Ambati et al., 2013) and semantic parsing (Kwiatkowksi et al., 2010; Artzi and Zettlemoyer, 2013) with Combinatory Categorial Grammar (CCG), we pursue the alternative strategy of inducing a CCG from an enhanced version of the shared task dependencies, with initial experiments showing even better results. A silver lining of the failure of grammar-based systems in the shared task is that it revealed some problems with the da</context>
</contexts>
<marker>Narayan, Gardent, 2012</marker>
<rawString>Shashi Narayan and Claire Gardent. 2012. Error mining with suspicion trees: Seeing the forest for the trees. In Proc. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
<author>Rajakrishnan Rajkumar</author>
</authors>
<title>Minimal dependency length in realization ranking.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="9283" citStr="White and Rajkumar, 2012" startWordPosition="1498" endWordPosition="1502">PTB training sections (02–21), recovering complete derivations more than 90% of the time for most sections. Robust treatment of coordination, including argument cluster coordination and gapping, remains a known issue; other causes of derivation failures remain to be investigated. To select preferred derivations, we used a complexity metric that simply counts the number of steps and the number of slashes in the categories. We then trained a generative syntactic model (Hockenmaier and Steedman, 2002) and used it along with a composite language model to generate nbest realizations for reranking (White and Rajkumar, 2012), additionally using a large-scale (gigaword) language model. Development and test results appear in Table 1. Perhaps because of the expanded use of type-changing rules with simple lexical categories, the generative model and hypertagger (Espinosa et al., 2008) performed worse than expected. Combining the generative syntactic model and composite language model (GEN) with equal weight yielded a devtest BLEU score of only 0.4513, while discriminatively training the generative component models (GLOBAL) increased the score to 0.7679. Using all features increased the score to 0.8083, while doubling</context>
</contexts>
<marker>White, Rajkumar, 2012</marker>
<rawString>Michael White and Rajakrishnan Rajkumar. 2012. Minimal dependency length in realization ranking. In Proc. EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>