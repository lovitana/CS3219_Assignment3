<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.083999">
<title confidence="0.991319">
Improving Word Alignment using Word Similarity
</title>
<author confidence="0.99803">
Theerawat Songyot David Chiang†
</author>
<affiliation confidence="0.9989745">
Dept of Computer Science Dept of Computer Science and Engineering
University of Southern California University of Notre Dame
</affiliation>
<email confidence="0.996661">
songyot@usc.edu dchiang@nd.edu
</email>
<sectionHeader confidence="0.997356" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999871692307692">
We show that semantic relationships can
be used to improve word alignment, in ad-
dition to the lexical and syntactic features
that are typically used. In this paper, we
present a method based on a neural net-
work to automatically derive word simi-
larity from monolingual data. We present
an extension to word alignment models
that exploits word similarity. Our exper-
iments, in both large-scale and resource-
limited settings, show improvements in
word alignment tasks as well as translation
tasks.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998953366666667">
Word alignment is an essential step for learn-
ing translation rules in statistical machine trans-
lation. The task is to find word-level transla-
tion correspondences in parallel text. Formally,
given a source sentence e consisting of words
e1, e2, ... , el and a target sentence f consisting
of words f1, f2, ... , fm, we want to infer an
alignment a, a sequence of indices a1, a2,... , am
which indicates, for each target word fi, the corre-
sponding source word eai or a null word. Machine
translation systems, including state-of-the-art sys-
tems, then use the word-aligned corpus to extract
translation rules.
The most widely used methods, the IBM mod-
els (Brown et al., 1993) and HMM (Vogel et al.,
1996), define a probability distribution p(f, a I e)
that models how each target word fi is gener-
ated from a source word eai with respect to an
alignment a. The models, however, tend to mis-
align low-frequency words as they have insuffi-
cient training samples. The problem can get worse
in low-resource languages. Two branches of re-
search have tried to alleviate the problem. The
†Most of the work reported here was performed while the
second author was at the University of Southern California.
first branch relies solely on the parallel data; how-
ever, additional assumptions about the data are re-
quired. This includes, but is not limited to, ap-
plying prior distributions (Mermer and Sarac¸lar,
2011; Vaswani et al., 2012) or smoothing tech-
niques (Zhang and Chiang, 2014). The other
branch uses information learned from monolin-
gual data, which is generally easier to acquire than
parallel data. Previous work in this branch mostly
involves applying syntactic constraints (Yamada
and Knight, 2001; Cherry and Lin, 2006; Wang
and Zong, 2013) and syntactic features (Toutanova
et al., 2002) into the models. The use of syntac-
tic relationships can, however, be limited between
historically unrelated language pairs.
Our motivation lies in the fact that a meaningful
sentence is not merely a grammatically structured
sentence; its semantics can provide insightful in-
formation for the task. For example, suppose that
the models are uncertain about aligning e to f. If
the models are informed that e is semantically re-
lated to e0, f is semantically related to f0, and f0 is
a translation of e0, it should intuitively increase the
probability that f is a translation of e. Our work
focuses on using such a semantic relationship, in
particular, word similarity, to improve word align-
ments.
In this paper, we propose a method to learn sim-
ilar words from monolingual data (Section 2) and
an extension to word alignment models in which
word similarity can be incorporated (Section 3).
We demonstrate its application in word alignment
and translation (Section 4) and then briefly discuss
the novelty of our work in comparison to other
methods (Section 5).
</bodyText>
<sectionHeader confidence="0.955136" genericHeader="method">
2 Learning word similarity
</sectionHeader>
<bodyText confidence="0.9843175">
Given a word w, we want to learn a word simi-
larity model p(w0 I w) of what words w0 might
be used in place of w. Word similarity can be
used to improve word alignment, as in this pa-
</bodyText>
<page confidence="0.876119">
1840
</page>
<bodyText confidence="0.976001615384615">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1840–1845,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
per, but can potentially be useful for other nat-
ural language processing tasks as well. Such a
model might be obtained from a monolingual the-
saurus, in which humans manually provide sub-
jective evaluation for word similarity probabilities,
but an automatic method would be preferable. In
this section, we present a direct formulation of the
word similarity model, which can automatically be
trained from monolingual data, and then consider
a more practical variant, which we adopt in our
experiments.
</bodyText>
<subsectionHeader confidence="0.989282">
2.1 Model
</subsectionHeader>
<bodyText confidence="0.997685333333333">
Given an arbitrary word type w, we define a word
similarity model p(w0  |w) for all word types w0
in the vocabulary V as
</bodyText>
<equation confidence="0.9878325">
p(w0  |w) = 1: p(c  |w) p(w0  |c)
c
</equation>
<bodyText confidence="0.99962424137931">
where c is a word context represented by a se-
quence w1, w2,. . . , w2n consisting of n word to-
kens on the left and n word tokens on the right
of w, excluding w. The submodel p(c  |w) can
be a categorical distribution. However, modeling
the word context model, p(w0  |c), as a categori-
cal distribution would cause severe overfitting, be-
cause the number of all possible contexts is |V |2n,
which is exponential in the length of the context.
We therefore parameterize it using a feedforward
neural network as shown in Figure 1, since the
structure has been shown to be effective for lan-
guage modeling (Bengio et al., 2006; Vaswani et
al., 2013). The input to the network is a one-hot
representation of each word in c, where the spe-
cial symbols &lt;s&gt;, &lt;/s&gt;, &lt;unk&gt; are reserved for
sentence beginning, sentence ending, and words
not in the vocabulary. There is an output node
for each w0 ∈ V , whose activation is p(w0  |c).
Following Bengio et al. (2006), the network uses
a shared linear projection matrix to the input em-
bedding layer, which allows information sharing
among the context words and also substantially
reduces the number of parameters. The input em-
bedding layer has a dimensionality of 150 for each
input word. The network uses two hidden layers
with 1,000 and 150 rectified linear units, respec-
tively, and a softmax output layer. We arbitrarily
use n = 5 throughout this paper.
</bodyText>
<subsectionHeader confidence="0.994027">
2.2 Training
</subsectionHeader>
<bodyText confidence="0.983626">
We extract training data by either collecting or
sampling the target words w ∈ V and their word
</bodyText>
<figureCaption confidence="0.998327">
Figure 1: The structure of the word context model
</figureCaption>
<bodyText confidence="0.998237333333333">
contexts from monolingual data. The submodel
p(c  |w) can be independently trained easily by
maximum likelihood estimation, while the word
context model p(w0  |c) may be difficult to train at
scale. We follow previous work (Mnih and Teh,
2012; Vaswani et al., 2013) in adopting noise-
contrastive estimation (Gutmann and Hyv¨arinen,
2010), a fast and simple training algorithm that
scales independently of the vocabulary size.
</bodyText>
<subsectionHeader confidence="0.999464">
2.3 Model variants
</subsectionHeader>
<bodyText confidence="0.9999785">
The above formulation of the word similarity
model can be interpreted as a mixture model in
which w0 is similar to w if any of the context prob-
abilities agrees. However, to guard against false
positives, we can alternatively reformulate it as a
product of experts (Hinton, 1999),
</bodyText>
<equation confidence="0.9985555">
1 1:
p(w0  |w) = Z(w) exp p(c  |w) log p(w0 |c)
</equation>
<bodyText confidence="0.999962153846154">
where Z(w) is a normalization constant. Under
this model, w0 is similar to w if all of the context
probabilities agree. Both methods produce reason-
ably good word similarity; however, in practice,
the latter performs better.
Since most of the p(w0  |w) will be close
to zero, for computational efficiency, we can se-
lect the k most similar words and renormalize
the probabilities. Table 1 shows some examples
learned from the 402M-word Xinhua portion of
the English Gigaword corpus (LDC2007T07), us-
ing a vocabulary V of the 30,000 most frequent
words. We set k = 5 for illustration purposes.
</bodyText>
<sectionHeader confidence="0.993902" genericHeader="method">
3 Word alignment model
</sectionHeader>
<bodyText confidence="0.995754">
In this section, we present our word alignment
models by extending the standard IBM models.
</bodyText>
<figure confidence="0.995005571428572">
output
. . .
layer
hidden layer 2 . . .
hidden layer 1 . . .
input
embeddings
. . . . . .
. . .
w1 w2n
input
word
. . . . . .
c
</figure>
<page confidence="0.894893">
1841
</page>
<table confidence="0.983105833333333">
p(w0  |country) p(w0  |region) p(w0  |area)
country 0.8363 region 0.8338 area 0.8551
region 0.0558 area 0.0760 region 0.0524
nation 0.0522 country 0.0524 zone 0.0338
world 0.0282 province 0.0195 city 0.0326
city 0.0273 city 0.0181 areas 0.0258
</table>
<tableCaption confidence="0.999874">
Table 1: Examples of word similarity
</tableCaption>
<bodyText confidence="0.999777571428571">
The method can easily be applied to other related
models, for example, the log-linear reparameteri-
zation of Model 2 by Dyer et al. (2013). Basically,
all the IBM models involve modeling lexical trans-
lation probabilities p(f  |e) which are parameter-
ized as categorical distributions. IBM Model 1, for
instance, is defined as
</bodyText>
<equation confidence="0.995551666666667">
m m
p(f, a  |e) a p(fi  |eai) = t(fi  |eai)
i=1 i=1
</equation>
<bodyText confidence="0.999877166666667">
where each t(f  |e) denotes the model parameters
directly corresponding to p(f  |e). Models 2–5
and the HMM-based model introduce additional
components in order to capture word ordering and
word fertility. However, they have p(f  |e) in
common.
</bodyText>
<subsectionHeader confidence="0.998388">
3.1 Model
</subsectionHeader>
<bodyText confidence="0.999933">
To incorporate word similarity in word alignment
models, we redefine the lexical translation proba-
bilities as
</bodyText>
<equation confidence="0.9239625">
p(f  |e) = 1: p(e0  |e)t(f0  |e0) p(f  |f0)
e&apos;,f&apos;
</equation>
<bodyText confidence="0.999791">
for all f, e, including words not in the vocabulary.
While the factor p(e0  |e) can be directly computed
by the word similarity model, the factor p(f  |f0)
can be problematic because it vanishes for f out
of vocabulary. One possible solution would be to
use Bayes’ rule
</bodyText>
<equation confidence="0.9931925">
p(f  |f0) = p(f0  |f)p(f)
p(f0)
</equation>
<bodyText confidence="0.999808454545454">
where p(f0  |f) is computed by the word similar-
ity model. However, we find that this is prone to
numerical instability and other complications. In
our experiments, we tried the simpler assumption
that p(f  |f0) Pz� p(f0  |f), with the rationale that
both probabilities are measures of word similarity,
which is intuitively a symmetric relation. We also
compared the performance of both methods. Ta-
ble 2 shows that this simple solution works as well
as the more exact method of using Bayes’ rule. We
describe the experiment details in Section 4.
</bodyText>
<table confidence="0.9998395">
Model F1 BLEU
Test 1 Test 2
Chinese-English
Bayes’ rule 75.7 30.0 27.0
Symmetry assumption 75.3 29.9 27.0
Arabic-English
Bayes’ rule 70.4 37.9 36.7
Symmetry assumption 69.5 38.2 36.8
</table>
<tableCaption confidence="0.999556">
Table 2: Assuming that word similarity is sym-
</tableCaption>
<bodyText confidence="0.8187605">
metric, i.e. p(f  |f0) Pz� p(f0  |f), works as well
as computing p(f  |f0) using Bayes’ rule.
</bodyText>
<subsectionHeader confidence="0.999045">
3.2 Re-estimating word similarity
</subsectionHeader>
<bodyText confidence="0.999532666666667">
Depending on the quality of word similarity and
the distribution of words in the parallel data, ap-
plying word similarity directly to the model could
lead to an undesirable effect where similar but not
interchangeable words rank in the top of the trans-
lation probabilities. On the other hand, if we set
</bodyText>
<equation confidence="0.999958">
p(e0  |e) = 1[e0 = e]
p(f0  |f) = 1[f0 = f]
</equation>
<bodyText confidence="0.9999842">
where 1 denotes the indicator function, the model
reduces to the standard IBM models. To get the
best of both worlds, we smooth the two models
together so that we rely more on word similarity
for rare words and less for frequent words
</bodyText>
<equation confidence="0.9995875">
˜p(w0  |w) = count(w)1[w0 = w] + α p(w0  |w)
count(w) + α
</equation>
<bodyText confidence="0.998742818181818">
This can be thought of as similar to Witten-Bell
smoothing, or adding α pseudocounts distributed
according to our p(w0  |w). The hyperparame-
ter α controls how much influence our word sim-
ilarity model has. We investigated the effect of α
by varying this hyperparameter in our word align-
ment experiments whose details are described in
Section 4. Figure 2 shows that performance of the
model, as measured by F1 score, is rather insensi-
tive to the choice of α. We used a value of 40 in
our experiments.
</bodyText>
<subsectionHeader confidence="0.991799">
3.3 Training
</subsectionHeader>
<bodyText confidence="0.99993075">
Our word alignment models can be trained in the
same way as the IBM models using the Expec-
tation Maximization (EM) algorithm to maximize
the likelihood of the parallel data. Our extension
only introduces an additional time complexity on
the order of O(k2) on top of the base models,
where k is the number of word types used to es-
timate the full-vocabulary word similarity models.
</bodyText>
<page confidence="0.978736">
1842
</page>
<figure confidence="0.849359">
Value of α
</figure>
<figureCaption confidence="0.982731">
Figure 2: Alignment F1 is fairly insensitive to α
over a large range of values
</figureCaption>
<bodyText confidence="0.99987">
The larger the value of k is, the closer to the full-
vocabulary models our estimations are. In prac-
tice, a small value of k seems to be effective since
p(w&apos; I w) is negligibly small for most w&apos;.
</bodyText>
<sectionHeader confidence="0.999927" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999845">
4.1 Alignment experiments
</subsectionHeader>
<bodyText confidence="0.999963863636363">
We conducted word alignment experiments
on 2 language pairs: Chinese-English and
Arabic-English. For Chinese-English, we used
9.5M+12.3M words of parallel text from the
NIST 2009 constrained task1 and evaluated
on 39.6k+50.9k words of hand-aligned data
(LDC2010E63, LDC2010E37). For Arabic-
English, we used 4.2M+5.4M words of parallel
text from the NIST 2009 constrained task2
and evaluated on 10.7k+15.1k words of hand-
aligned data (LDC2006E86). To demonstrate
performance under resource-limited settings,
we additionally experimented on only the first
eighth of the full data, specifically, 1.2M+1.6M
words for Chinese-English and 1.0M+1.4M
words for Arabic-English. We trained word
similarity models on the Xinhua portions of
English Gigaword (LDC2007T07), Chinese
Gigaword (LDC2007T38), and Arabic Gigaword
(LDC2011T1), which are 402M, 323M, and
125M words, respectively. The vocabulary V was
the 30,000 most frequent words from each corpus
</bodyText>
<footnote confidence="0.939371875">
1Catalog numbers: LDC2003E07, LDC2003E14,
LDC2005E83, LDC2005T06, LDC2006E24, LDC2006E34,
LDC2006E85, LDC2006E86, LDC2006E92, and
LDC2006E93.
2Excluding: United Nations proceedings (LDC2004E13),
ISI Automatically Extracted Parallel Text (LDC2007E08),
and Ummah newswire text (LDC2004T18)
Source word frequency
</footnote>
<figureCaption confidence="0.996529666666667">
Figure 3: F1 scores for words binned by fre-
quency. Our model gives the largest improvements
for the lowest-frequency words.
</figureCaption>
<bodyText confidence="0.999800045454545">
and the k = 10 most similar words were used.
We modified GIZA++ (Och and Ney, 2003) to
incorporate word similarity. For all experiments,
we used the default configuration of GIZA++: 5
iterations each of IBM Model 1, 2, HMM, 3 and
4. We aligned the parallel texts in both forward
and backward directions and symmetrized them
using grow-diag-final-and (Koehn et al., 2005).
We evaluated alignment quality using precision,
recall, and F1.
The results in Table 3 suggest that our modeling
approach produces better word alignments. We
found that our models not only learned smoother
translation models for low frequency words but
also ranked the conditional probabilities more ac-
curately with respect to the correct translations.
To illustrate this, we categorized the alignment
links from the Chinese-English low-resource ex-
periment into bins with respect to the English
source word frequency and individually evaluated
them. As shown in Figure 3, the gain for low fre-
quency words is particularly large.
</bodyText>
<subsectionHeader confidence="0.993936">
4.2 Translation experiments
</subsectionHeader>
<bodyText confidence="0.999992666666667">
We also ran end-to-end translation experiments.
For both languages, we used subsets of the NIST
2004 and 2006 test sets as development data. We
used two different data sets as test data: different
subsets of the NIST 2004 and 2006 test sets (called
Test 1) and the NIST 2008 test sets (called Test 2).
We trained a 5-gram language model on the Xin-
hua portion of English Gigaword (LDC2007T07).
We used the Moses toolkit (Koehn et al., 2007) to
</bodyText>
<figure confidence="0.997190258064516">
0 10 20 30 40 50 60
F1 (%)
76
74
72
70
68
66
Chinese-English
Arabic-English
1-10 11-20 21-30 31-40 41-50 51-60
80
70
60
50
40
30
38.1
58.5
Baseline
Our model
52.4
63.7
56.9
66.3 66.4
55.4
59.5
71.5
70.5
60.1
F1 (%)
</figure>
<page confidence="0.898577">
1843
</page>
<table confidence="0.999617333333333">
Model Precision Recall F1 BLEU METEOR
Test 1 Test 2 Test 1 Test 2
Chinese-English
Baseline 65.2 76.9 70.6 29.4 26.7 29.7 28.5
Our model 71.4 79.7 75.3 29.9 27.0 30.0 28.8
Baseline (resource-limited) 56.1 68.1 61.5 23.6 20.3 26.0 24.4
Our model (resource-limited) 66.5 74.4 70.2 24.7 21.6 26.8 25.6
Arabic-English
Baseline 56.1 79.0 65.6 37.7 36.2 31.1 30.9
Our model 60.0 82.4 69.5 38.2 36.8 31.6 31.4
Baseline (resource-limited) 56.7 76.1 65.0 34.1 33.0 27.9 27.7
Our model (resource-limited) 59.4 80.7 68.4 35.0 33.8 28.7 28.6
</table>
<tableCaption confidence="0.999959">
Table 3: Experimental results. Our model improves alignments and translations on both language pairs.
</tableCaption>
<bodyText confidence="0.999712789473684">
build a hierarchical phrase-based translation sys-
tem (Chiang, 2007) trained using MIRA (Chiang,
2012). Then, we evaluated the translation qual-
ity using BLEU (Papineni et al., 2002) and ME-
TEOR (Denkowski and Lavie, 2014), and per-
formed significance testing using bootstrap resam-
pling (Koehn, 2004) with 1,000 samples.
Under the resource-limited settings, our meth-
ods consistently show 1.1–1.3 BLEU (0.8–1.2
METEOR) improvements on Chinese-English and
0.8–0.9 BLEU (0.8–0.9 METEOR) improvements
on Arabic-English, as shown in Table 3. These im-
provements are statistically significant (p &lt; 0.01).
On the full data, our method improves Chinese-
English translation by 0.3–0.5 BLEU (0.3 ME-
TEOR), which is unfortunately not statistically
significant, and Arabic-English translation by 0.5–
0.6 BLEU (0.5 METEOR), which is statistically
significant (p &lt; 0.01).
</bodyText>
<sectionHeader confidence="0.999941" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.999938611111111">
Most previous work on word alignment problems
uses morphosyntactic-semantic features, for ex-
ample, word stems, content words, orthography
(De Gispert et al., 2006; Hermjakob, 2009). A
variety of log-linear models have been proposed to
incorporate these features (Dyer et al., 2011; Berg-
Kirkpatrick et al., 2010). These approaches usu-
ally require numerical optimization for discrimi-
native training as well as language-specific engi-
neering and may limit their applications to mor-
phologically rich languages.
A more semantic approach resorts to training
word alignments on semantic word classes (Ma
et al., 2011). However, the resulting alignments
are only used to supplement the word alignments
learned on lexical words. To our knowledge, our
work, which directly incorporates semantic rela-
tionships in word alignment models, is novel.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9998316">
We have presented methods to extract word simi-
larity from monolingual data and apply it to word
alignment models. Our method can learn simi-
lar words and word similarity probabilities, which
can be used inside any probability model and in
many natural language processing tasks. We have
demonstrated its effectiveness in statistical ma-
chine translation. The enhanced models can sig-
nificantly improve alignment quality as well as
translation quality.
</bodyText>
<sectionHeader confidence="0.99863" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999948714285714">
We express our appreciation to Ashish Vaswani
for his advice and assistance. We also thank Hui
Zhang, Tomer Levinboim, Qing Dou, Aliya Deri
for helpful discussions and the anonymous review-
ers for their insightful critiques. This research was
supported in part by DOI/IBC grant D12AP00225
and a Google Research Award to Chiang.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.984319166666667">
Yoshua Bengio, Holger Schwenk, Jean-S´ebastien
Sen´ecal, Fr´ederic Morin, and Jean-Luc Gauvain.
2006. Neural probabilistic language models. In
Innovations in Machine Learning, pages 137–186.
Springer.
Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e,
John DeNero, and Dan Klein. 2010. Painless un-
supervised learning with features. In Proceedings of
HLT NAACL, pages 582–590.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
</reference>
<page confidence="0.951097">
1844
</page>
<reference confidence="0.999487558823529">
Parameter estimation. Computational Linguistics,
19(2):263–311.
Colin Cherry and Dekang Lin. 2006. Soft syntac-
tic constraints for word alignment through discrim-
inative training. In Proceedings of COLING/ACL,
pages 105–112.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201–228.
David Chiang. 2012. Hope and fear for discriminative
training of statistical translation models. Journal of
Machine Learning Research, 13(1):1159–1187.
Adri`a De Gispert, Deepa Gupta, Maja Popovi´c, Patrik
Lambert, Jose B. Mari˜no, Marcello Federico, Her-
mann Ney, and Rafael Banchs. 2006. Improving
statistical word alignments with morpho-syntactic
transformations. In Advances in Natural Language
Processing, pages 368–379. Springer.
Michael Denkowski and Alon Lavie. 2014. Meteor
universal: Language specific translation evaluation
for any target language. In Proceedings of the EACL
2014 Workshop on Statistical Machine Translation.
Chris Dyer, Jonathan Clark, Alon Lavie, and Noah A.
Smith. 2011. Unsupervised word alignment with
arbitrary features. In Proceedings ofACL: HLT, vol-
ume 1, pages 409–419.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of IBM Model 2. In Proceedings of NAACL-
HLT, pages 644–648.
Michael Gutmann and Aapo Hyv¨arinen. 2010. Noise-
contrastive estimation: A new estimation princi-
ple for unnormalized statistical models. In Inter-
national Conference on Artificial Intelligence and
Statistics (AI-STATS), pages 297–304.
Ulf Hermjakob. 2009. Improved word alignment with
statistics and linguistic heuristics. In Proceedings of
EMNLP, volume 1, pages 229–237.
Geoffrey E. Hinton. 1999. Products of experts. In
International Conference on Artificial Neural Net-
works, volume 1, pages 1–6.
Philipp Koehn, Amittai Axelrod, Chris Callison-Burch,
Miles Osborne, and David Talbot. 2005. Ed-
inburgh system description for the 2005 IWSLT
speech translation evaluation. In Proceedings of the
International Workshop on Spoken Language Trans-
lation (IWSLT).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings ofACL: Interactive Poster and Demon-
stration Sessions, pages 177–180.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP.
Jeff Ma, Spyros Matsoukas, and Richard Schwartz.
2011. Improving low-resource statistical machine
translation with a novel semantic word clustering al-
gorithm. In Proceedings of MT Summit.
Cos¸kun Mermer and Murat Sarac¸lar. 2011. Bayesian
word alignment for statistical machine translation.
In Proceedings ofACL: HLT, volume 2, pages 182–
187.
Andriy Mnih and Yee Whye Teh. 2012. A fast and
simple algorithm for training neural probabilistic
language models. In Proceedings of ICML.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational linguistics, 29(1):19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
ofACL, pages 311–318.
Kristina Toutanova, H. Tolga Ilhan, and Christopher D.
Manning. 2002. Extensions to HMM-based sta-
tistical word alignment models. In Proceedings of
EMNLP, pages 87–94.
Ashish Vaswani, Liang Huang, and David Chiang.
2012. Smaller alignment models for better trans-
lations: unsupervised word alignment with the to-
norm. In Proceedings ofACL, volume 1, pages 311–
319.
Ashish Vaswani, Yinggong Zhao, Victoria Fossum, and
David Chiang. 2013. Decoding with large-scale
neural language models improves translation. In
Proceedings of EMNLP.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical
translation. In Proceedings of COLING, volume 2,
pages 836–841.
Zhiguo Wang and Chengqing Zong. 2013. Large-
scale word alignment using soft dependency cohe-
sion constraints. Transactions of the Association for
Computational Linguistics, 1(6):291–300.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings
ofACL, pages 523–530.
Hui Zhang and David Chiang. 2014. Kneser-Ney
smoothing on expected counts. In Proceedings of
ACL.
</reference>
<page confidence="0.99313">
1845
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.938857">
<title confidence="0.998958">Improving Word Alignment using Word Similarity</title>
<author confidence="0.987454">Songyot David</author>
<affiliation confidence="0.998086">Dept of Computer Science Dept of Computer Science and Engineering University of Southern California University of Notre Dame</affiliation>
<email confidence="0.999058">songyot@usc.edudchiang@nd.edu</email>
<abstract confidence="0.996772">We show that semantic relationships can be used to improve word alignment, in addition to the lexical and syntactic features that are typically used. In this paper, we present a method based on a neural network to automatically derive word similarity from monolingual data. We present an extension to word alignment models that exploits word similarity. Our experiments, in both large-scale and resourcelimited settings, show improvements in word alignment tasks as well as translation tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>Holger Schwenk</author>
<author>Jean-S´ebastien Sen´ecal</author>
<author>Fr´ederic Morin</author>
<author>Jean-Luc Gauvain</author>
</authors>
<title>Neural probabilistic language models.</title>
<date>2006</date>
<booktitle>In Innovations in Machine Learning,</booktitle>
<pages>137--186</pages>
<publisher>Springer.</publisher>
<marker>Bengio, Schwenk, Sen´ecal, Morin, Gauvain, 2006</marker>
<rawString>Yoshua Bengio, Holger Schwenk, Jean-S´ebastien Sen´ecal, Fr´ederic Morin, and Jean-Luc Gauvain. 2006. Neural probabilistic language models. In Innovations in Machine Learning, pages 137–186. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proceedings of HLT NAACL,</booktitle>
<pages>582--590</pages>
<marker>Berg-Kirkpatrick, Bouchard-Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Proceedings of HLT NAACL, pages 582–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1423" citStr="Brown et al., 1993" startWordPosition="225" endWordPosition="228">nslation rules in statistical machine translation. The task is to find word-level translation correspondences in parallel text. Formally, given a source sentence e consisting of words e1, e2, ... , el and a target sentence f consisting of words f1, f2, ... , fm, we want to infer an alignment a, a sequence of indices a1, a2,... , am which indicates, for each target word fi, the corresponding source word eai or a null word. Machine translation systems, including state-of-the-art systems, then use the word-aligned corpus to extract translation rules. The most widely used methods, the IBM models (Brown et al., 1993) and HMM (Vogel et al., 1996), define a probability distribution p(f, a I e) that models how each target word fi is generated from a source word eai with respect to an alignment a. The models, however, tend to misalign low-frequency words as they have insufficient training samples. The problem can get worse in low-resource languages. Two branches of research have tried to alleviate the problem. The †Most of the work reported here was performed while the second author was at the University of Southern California. first branch relies solely on the parallel data; however, additional assumptions a</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft syntactic constraints for word alignment through discriminative training.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL,</booktitle>
<pages>105--112</pages>
<contexts>
<context position="2463" citStr="Cherry and Lin, 2006" startWordPosition="397" endWordPosition="400">reported here was performed while the second author was at the University of Southern California. first branch relies solely on the parallel data; however, additional assumptions about the data are required. This includes, but is not limited to, applying prior distributions (Mermer and Sarac¸lar, 2011; Vaswani et al., 2012) or smoothing techniques (Zhang and Chiang, 2014). The other branch uses information learned from monolingual data, which is generally easier to acquire than parallel data. Previous work in this branch mostly involves applying syntactic constraints (Yamada and Knight, 2001; Cherry and Lin, 2006; Wang and Zong, 2013) and syntactic features (Toutanova et al., 2002) into the models. The use of syntactic relationships can, however, be limited between historically unrelated language pairs. Our motivation lies in the fact that a meaningful sentence is not merely a grammatically structured sentence; its semantics can provide insightful information for the task. For example, suppose that the models are uncertain about aligning e to f. If the models are informed that e is semantically related to e0, f is semantically related to f0, and f0 is a translation of e0, it should intuitively increas</context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. 2006. Soft syntactic constraints for word alignment through discriminative training. In Proceedings of COLING/ACL, pages 105–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="15682" citStr="Chiang, 2007" startWordPosition="2628" endWordPosition="2629">eline 65.2 76.9 70.6 29.4 26.7 29.7 28.5 Our model 71.4 79.7 75.3 29.9 27.0 30.0 28.8 Baseline (resource-limited) 56.1 68.1 61.5 23.6 20.3 26.0 24.4 Our model (resource-limited) 66.5 74.4 70.2 24.7 21.6 26.8 25.6 Arabic-English Baseline 56.1 79.0 65.6 37.7 36.2 31.1 30.9 Our model 60.0 82.4 69.5 38.2 36.8 31.6 31.4 Baseline (resource-limited) 56.7 76.1 65.0 34.1 33.0 27.9 27.7 Our model (resource-limited) 59.4 80.7 68.4 35.0 33.8 28.7 28.6 Table 3: Experimental results. Our model improves alignments and translations on both language pairs. build a hierarchical phrase-based translation system (Chiang, 2007) trained using MIRA (Chiang, 2012). Then, we evaluated the translation quality using BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014), and performed significance testing using bootstrap resampling (Koehn, 2004) with 1,000 samples. Under the resource-limited settings, our methods consistently show 1.1–1.3 BLEU (0.8–1.2 METEOR) improvements on Chinese-English and 0.8–0.9 BLEU (0.8–0.9 METEOR) improvements on Arabic-English, as shown in Table 3. These improvements are statistically significant (p &lt; 0.01). On the full data, our method improves ChineseEnglish translation by 0.3–0</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hope and fear for discriminative training of statistical translation models.</title>
<date>2012</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="15716" citStr="Chiang, 2012" startWordPosition="2633" endWordPosition="2634">7 28.5 Our model 71.4 79.7 75.3 29.9 27.0 30.0 28.8 Baseline (resource-limited) 56.1 68.1 61.5 23.6 20.3 26.0 24.4 Our model (resource-limited) 66.5 74.4 70.2 24.7 21.6 26.8 25.6 Arabic-English Baseline 56.1 79.0 65.6 37.7 36.2 31.1 30.9 Our model 60.0 82.4 69.5 38.2 36.8 31.6 31.4 Baseline (resource-limited) 56.7 76.1 65.0 34.1 33.0 27.9 27.7 Our model (resource-limited) 59.4 80.7 68.4 35.0 33.8 28.7 28.6 Table 3: Experimental results. Our model improves alignments and translations on both language pairs. build a hierarchical phrase-based translation system (Chiang, 2007) trained using MIRA (Chiang, 2012). Then, we evaluated the translation quality using BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014), and performed significance testing using bootstrap resampling (Koehn, 2004) with 1,000 samples. Under the resource-limited settings, our methods consistently show 1.1–1.3 BLEU (0.8–1.2 METEOR) improvements on Chinese-English and 0.8–0.9 BLEU (0.8–0.9 METEOR) improvements on Arabic-English, as shown in Table 3. These improvements are statistically significant (p &lt; 0.01). On the full data, our method improves ChineseEnglish translation by 0.3–0.5 BLEU (0.3 METEOR), which is unf</context>
</contexts>
<marker>Chiang, 2012</marker>
<rawString>David Chiang. 2012. Hope and fear for discriminative training of statistical translation models. Journal of Machine Learning Research, 13(1):1159–1187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adri`a De Gispert</author>
<author>Deepa Gupta</author>
<author>Maja Popovi´c</author>
<author>Patrik Lambert</author>
<author>Jose B Mari˜no</author>
<author>Marcello Federico</author>
<author>Hermann Ney</author>
<author>Rafael Banchs</author>
</authors>
<title>Improving statistical word alignments with morpho-syntactic transformations.</title>
<date>2006</date>
<booktitle>In Advances in Natural Language Processing,</booktitle>
<pages>368--379</pages>
<publisher>Springer.</publisher>
<marker>De Gispert, Gupta, Popovi´c, Lambert, Mari˜no, Federico, Ney, Banchs, 2006</marker>
<rawString>Adri`a De Gispert, Deepa Gupta, Maja Popovi´c, Patrik Lambert, Jose B. Mari˜no, Marcello Federico, Hermann Ney, and Rafael Banchs. 2006. Improving statistical word alignments with morpho-syntactic transformations. In Advances in Natural Language Processing, pages 368–379. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Alon Lavie</author>
</authors>
<title>Meteor universal: Language specific translation evaluation for any target language.</title>
<date>2014</date>
<booktitle>In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="15834" citStr="Denkowski and Lavie, 2014" startWordPosition="2651" endWordPosition="2654">26.0 24.4 Our model (resource-limited) 66.5 74.4 70.2 24.7 21.6 26.8 25.6 Arabic-English Baseline 56.1 79.0 65.6 37.7 36.2 31.1 30.9 Our model 60.0 82.4 69.5 38.2 36.8 31.6 31.4 Baseline (resource-limited) 56.7 76.1 65.0 34.1 33.0 27.9 27.7 Our model (resource-limited) 59.4 80.7 68.4 35.0 33.8 28.7 28.6 Table 3: Experimental results. Our model improves alignments and translations on both language pairs. build a hierarchical phrase-based translation system (Chiang, 2007) trained using MIRA (Chiang, 2012). Then, we evaluated the translation quality using BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014), and performed significance testing using bootstrap resampling (Koehn, 2004) with 1,000 samples. Under the resource-limited settings, our methods consistently show 1.1–1.3 BLEU (0.8–1.2 METEOR) improvements on Chinese-English and 0.8–0.9 BLEU (0.8–0.9 METEOR) improvements on Arabic-English, as shown in Table 3. These improvements are statistically significant (p &lt; 0.01). On the full data, our method improves ChineseEnglish translation by 0.3–0.5 BLEU (0.3 METEOR), which is unfortunately not statistically significant, and Arabic-English translation by 0.5– 0.6 BLEU (0.5 METEOR), which is stati</context>
</contexts>
<marker>Denkowski, Lavie, 2014</marker>
<rawString>Michael Denkowski and Alon Lavie. 2014. Meteor universal: Language specific translation evaluation for any target language. In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Jonathan Clark</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Unsupervised word alignment with arbitrary features.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL: HLT,</booktitle>
<volume>1</volume>
<pages>409--419</pages>
<contexts>
<context position="16762" citStr="Dyer et al., 2011" startWordPosition="2785" endWordPosition="2788">3. These improvements are statistically significant (p &lt; 0.01). On the full data, our method improves ChineseEnglish translation by 0.3–0.5 BLEU (0.3 METEOR), which is unfortunately not statistically significant, and Arabic-English translation by 0.5– 0.6 BLEU (0.5 METEOR), which is statistically significant (p &lt; 0.01). 5 Related work Most previous work on word alignment problems uses morphosyntactic-semantic features, for example, word stems, content words, orthography (De Gispert et al., 2006; Hermjakob, 2009). A variety of log-linear models have been proposed to incorporate these features (Dyer et al., 2011; BergKirkpatrick et al., 2010). These approaches usually require numerical optimization for discriminative training as well as language-specific engineering and may limit their applications to morphologically rich languages. A more semantic approach resorts to training word alignments on semantic word classes (Ma et al., 2011). However, the resulting alignments are only used to supplement the word alignments learned on lexical words. To our knowledge, our work, which directly incorporates semantic relationships in word alignment models, is novel. 6 Conclusion We have presented methods to extr</context>
</contexts>
<marker>Dyer, Clark, Lavie, Smith, 2011</marker>
<rawString>Chris Dyer, Jonathan Clark, Alon Lavie, and Noah A. Smith. 2011. Unsupervised word alignment with arbitrary features. In Proceedings ofACL: HLT, volume 1, pages 409–419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Victor Chahuneau</author>
<author>Noah A Smith</author>
</authors>
<title>A simple, fast, and effective reparameterization of IBM Model 2.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACLHLT,</booktitle>
<pages>644--648</pages>
<contexts>
<context position="8225" citStr="Dyer et al. (2013)" startWordPosition="1395" endWordPosition="1398">esent our word alignment models by extending the standard IBM models. output . . . layer hidden layer 2 . . . hidden layer 1 . . . input embeddings . . . . . . . . . w1 w2n input word . . . . . . c 1841 p(w0 |country) p(w0 |region) p(w0 |area) country 0.8363 region 0.8338 area 0.8551 region 0.0558 area 0.0760 region 0.0524 nation 0.0522 country 0.0524 zone 0.0338 world 0.0282 province 0.0195 city 0.0326 city 0.0273 city 0.0181 areas 0.0258 Table 1: Examples of word similarity The method can easily be applied to other related models, for example, the log-linear reparameterization of Model 2 by Dyer et al. (2013). Basically, all the IBM models involve modeling lexical translation probabilities p(f |e) which are parameterized as categorical distributions. IBM Model 1, for instance, is defined as m m p(f, a |e) a p(fi |eai) = t(fi |eai) i=1 i=1 where each t(f |e) denotes the model parameters directly corresponding to p(f |e). Models 2–5 and the HMM-based model introduce additional components in order to capture word ordering and word fertility. However, they have p(f |e) in common. 3.1 Model To incorporate word similarity in word alignment models, we redefine the lexical translation probabilities as p(f</context>
</contexts>
<marker>Dyer, Chahuneau, Smith, 2013</marker>
<rawString>Chris Dyer, Victor Chahuneau, and Noah A. Smith. 2013. A simple, fast, and effective reparameterization of IBM Model 2. In Proceedings of NAACLHLT, pages 644–648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gutmann</author>
<author>Aapo Hyv¨arinen</author>
</authors>
<title>Noisecontrastive estimation: A new estimation principle for unnormalized statistical models.</title>
<date>2010</date>
<booktitle>In International Conference on Artificial Intelligence and Statistics (AI-STATS),</booktitle>
<pages>297--304</pages>
<marker>Gutmann, Hyv¨arinen, 2010</marker>
<rawString>Michael Gutmann and Aapo Hyv¨arinen. 2010. Noisecontrastive estimation: A new estimation principle for unnormalized statistical models. In International Conference on Artificial Intelligence and Statistics (AI-STATS), pages 297–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Hermjakob</author>
</authors>
<title>Improved word alignment with statistics and linguistic heuristics.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<volume>1</volume>
<pages>229--237</pages>
<contexts>
<context position="16662" citStr="Hermjakob, 2009" startWordPosition="2771" endWordPosition="2772">hinese-English and 0.8–0.9 BLEU (0.8–0.9 METEOR) improvements on Arabic-English, as shown in Table 3. These improvements are statistically significant (p &lt; 0.01). On the full data, our method improves ChineseEnglish translation by 0.3–0.5 BLEU (0.3 METEOR), which is unfortunately not statistically significant, and Arabic-English translation by 0.5– 0.6 BLEU (0.5 METEOR), which is statistically significant (p &lt; 0.01). 5 Related work Most previous work on word alignment problems uses morphosyntactic-semantic features, for example, word stems, content words, orthography (De Gispert et al., 2006; Hermjakob, 2009). A variety of log-linear models have been proposed to incorporate these features (Dyer et al., 2011; BergKirkpatrick et al., 2010). These approaches usually require numerical optimization for discriminative training as well as language-specific engineering and may limit their applications to morphologically rich languages. A more semantic approach resorts to training word alignments on semantic word classes (Ma et al., 2011). However, the resulting alignments are only used to supplement the word alignments learned on lexical words. To our knowledge, our work, which directly incorporates seman</context>
</contexts>
<marker>Hermjakob, 2009</marker>
<rawString>Ulf Hermjakob. 2009. Improved word alignment with statistics and linguistic heuristics. In Proceedings of EMNLP, volume 1, pages 229–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey E Hinton</author>
</authors>
<title>Products of experts.</title>
<date>1999</date>
<booktitle>In International Conference on Artificial Neural Networks,</booktitle>
<volume>1</volume>
<pages>1--6</pages>
<contexts>
<context position="6925" citStr="Hinton, 1999" startWordPosition="1161" endWordPosition="1162">ood estimation, while the word context model p(w0 |c) may be difficult to train at scale. We follow previous work (Mnih and Teh, 2012; Vaswani et al., 2013) in adopting noisecontrastive estimation (Gutmann and Hyv¨arinen, 2010), a fast and simple training algorithm that scales independently of the vocabulary size. 2.3 Model variants The above formulation of the word similarity model can be interpreted as a mixture model in which w0 is similar to w if any of the context probabilities agrees. However, to guard against false positives, we can alternatively reformulate it as a product of experts (Hinton, 1999), 1 1: p(w0 |w) = Z(w) exp p(c |w) log p(w0 |c) where Z(w) is a normalization constant. Under this model, w0 is similar to w if all of the context probabilities agree. Both methods produce reasonably good word similarity; however, in practice, the latter performs better. Since most of the p(w0 |w) will be close to zero, for computational efficiency, we can select the k most similar words and renormalize the probabilities. Table 1 shows some examples learned from the 402M-word Xinhua portion of the English Gigaword corpus (LDC2007T07), using a vocabulary V of the 30,000 most frequent words. We </context>
</contexts>
<marker>Hinton, 1999</marker>
<rawString>Geoffrey E. Hinton. 1999. Products of experts. In International Conference on Artificial Neural Networks, volume 1, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Amittai Axelrod</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
<author>David Talbot</author>
</authors>
<title>Edinburgh system description for the 2005 IWSLT speech translation evaluation.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation (IWSLT).</booktitle>
<contexts>
<context position="13663" citStr="Koehn et al., 2005" startWordPosition="2290" endWordPosition="2293">2004E13), ISI Automatically Extracted Parallel Text (LDC2007E08), and Ummah newswire text (LDC2004T18) Source word frequency Figure 3: F1 scores for words binned by frequency. Our model gives the largest improvements for the lowest-frequency words. and the k = 10 most similar words were used. We modified GIZA++ (Och and Ney, 2003) to incorporate word similarity. For all experiments, we used the default configuration of GIZA++: 5 iterations each of IBM Model 1, 2, HMM, 3 and 4. We aligned the parallel texts in both forward and backward directions and symmetrized them using grow-diag-final-and (Koehn et al., 2005). We evaluated alignment quality using precision, recall, and F1. The results in Table 3 suggest that our modeling approach produces better word alignments. We found that our models not only learned smoother translation models for low frequency words but also ranked the conditional probabilities more accurately with respect to the correct translations. To illustrate this, we categorized the alignment links from the Chinese-English low-resource experiment into bins with respect to the English source word frequency and individually evaluated them. As shown in Figure 3, the gain for low frequency</context>
</contexts>
<marker>Koehn, Axelrod, Callison-Burch, Osborne, Talbot, 2005</marker>
<rawString>Philipp Koehn, Amittai Axelrod, Chris Callison-Burch, Miles Osborne, and David Talbot. 2005. Edinburgh system description for the 2005 IWSLT speech translation evaluation. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL: Interactive Poster and Demonstration Sessions,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra</location>
<contexts>
<context position="14760" citStr="Koehn et al., 2007" startWordPosition="2467" endWordPosition="2470">ect to the English source word frequency and individually evaluated them. As shown in Figure 3, the gain for low frequency words is particularly large. 4.2 Translation experiments We also ran end-to-end translation experiments. For both languages, we used subsets of the NIST 2004 and 2006 test sets as development data. We used two different data sets as test data: different subsets of the NIST 2004 and 2006 test sets (called Test 1) and the NIST 2008 test sets (called Test 2). We trained a 5-gram language model on the Xinhua portion of English Gigaword (LDC2007T07). We used the Moses toolkit (Koehn et al., 2007) to 0 10 20 30 40 50 60 F1 (%) 76 74 72 70 68 66 Chinese-English Arabic-English 1-10 11-20 21-30 31-40 41-50 51-60 80 70 60 50 40 30 38.1 58.5 Baseline Our model 52.4 63.7 56.9 66.3 66.4 55.4 59.5 71.5 70.5 60.1 F1 (%) 1843 Model Precision Recall F1 BLEU METEOR Test 1 Test 2 Test 1 Test 2 Chinese-English Baseline 65.2 76.9 70.6 29.4 26.7 29.7 28.5 Our model 71.4 79.7 75.3 29.9 27.0 30.0 28.8 Baseline (resource-limited) 56.1 68.1 61.5 23.6 20.3 26.0 24.4 Our model (resource-limited) 66.5 74.4 70.2 24.7 21.6 26.8 25.6 Arabic-English Baseline 56.1 79.0 65.6 37.7 36.2 31.1 30.9 Our model 60.0 82.4</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings ofACL: Interactive Poster and Demonstration Sessions, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="15911" citStr="Koehn, 2004" startWordPosition="2664" endWordPosition="2665">seline 56.1 79.0 65.6 37.7 36.2 31.1 30.9 Our model 60.0 82.4 69.5 38.2 36.8 31.6 31.4 Baseline (resource-limited) 56.7 76.1 65.0 34.1 33.0 27.9 27.7 Our model (resource-limited) 59.4 80.7 68.4 35.0 33.8 28.7 28.6 Table 3: Experimental results. Our model improves alignments and translations on both language pairs. build a hierarchical phrase-based translation system (Chiang, 2007) trained using MIRA (Chiang, 2012). Then, we evaluated the translation quality using BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014), and performed significance testing using bootstrap resampling (Koehn, 2004) with 1,000 samples. Under the resource-limited settings, our methods consistently show 1.1–1.3 BLEU (0.8–1.2 METEOR) improvements on Chinese-English and 0.8–0.9 BLEU (0.8–0.9 METEOR) improvements on Arabic-English, as shown in Table 3. These improvements are statistically significant (p &lt; 0.01). On the full data, our method improves ChineseEnglish translation by 0.3–0.5 BLEU (0.3 METEOR), which is unfortunately not statistically significant, and Arabic-English translation by 0.5– 0.6 BLEU (0.5 METEOR), which is statistically significant (p &lt; 0.01). 5 Related work Most previous work on word al</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Ma</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Improving low-resource statistical machine translation with a novel semantic word clustering algorithm.</title>
<date>2011</date>
<booktitle>In Proceedings of MT Summit.</booktitle>
<contexts>
<context position="17091" citStr="Ma et al., 2011" startWordPosition="2834" endWordPosition="2837">d work Most previous work on word alignment problems uses morphosyntactic-semantic features, for example, word stems, content words, orthography (De Gispert et al., 2006; Hermjakob, 2009). A variety of log-linear models have been proposed to incorporate these features (Dyer et al., 2011; BergKirkpatrick et al., 2010). These approaches usually require numerical optimization for discriminative training as well as language-specific engineering and may limit their applications to morphologically rich languages. A more semantic approach resorts to training word alignments on semantic word classes (Ma et al., 2011). However, the resulting alignments are only used to supplement the word alignments learned on lexical words. To our knowledge, our work, which directly incorporates semantic relationships in word alignment models, is novel. 6 Conclusion We have presented methods to extract word similarity from monolingual data and apply it to word alignment models. Our method can learn similar words and word similarity probabilities, which can be used inside any probability model and in many natural language processing tasks. We have demonstrated its effectiveness in statistical machine translation. The enhan</context>
</contexts>
<marker>Ma, Matsoukas, Schwartz, 2011</marker>
<rawString>Jeff Ma, Spyros Matsoukas, and Richard Schwartz. 2011. Improving low-resource statistical machine translation with a novel semantic word clustering algorithm. In Proceedings of MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cos¸kun Mermer</author>
<author>Murat Sarac¸lar</author>
</authors>
<title>Bayesian word alignment for statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL: HLT,</booktitle>
<volume>2</volume>
<pages>182--187</pages>
<marker>Mermer, Sarac¸lar, 2011</marker>
<rawString>Cos¸kun Mermer and Murat Sarac¸lar. 2011. Bayesian word alignment for statistical machine translation. In Proceedings ofACL: HLT, volume 2, pages 182– 187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andriy Mnih</author>
<author>Yee Whye Teh</author>
</authors>
<title>A fast and simple algorithm for training neural probabilistic language models.</title>
<date>2012</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="6445" citStr="Mnih and Teh, 2012" startWordPosition="1082" endWordPosition="1085">r has a dimensionality of 150 for each input word. The network uses two hidden layers with 1,000 and 150 rectified linear units, respectively, and a softmax output layer. We arbitrarily use n = 5 throughout this paper. 2.2 Training We extract training data by either collecting or sampling the target words w ∈ V and their word Figure 1: The structure of the word context model contexts from monolingual data. The submodel p(c |w) can be independently trained easily by maximum likelihood estimation, while the word context model p(w0 |c) may be difficult to train at scale. We follow previous work (Mnih and Teh, 2012; Vaswani et al., 2013) in adopting noisecontrastive estimation (Gutmann and Hyv¨arinen, 2010), a fast and simple training algorithm that scales independently of the vocabulary size. 2.3 Model variants The above formulation of the word similarity model can be interpreted as a mixture model in which w0 is similar to w if any of the context probabilities agrees. However, to guard against false positives, we can alternatively reformulate it as a product of experts (Hinton, 1999), 1 1: p(w0 |w) = Z(w) exp p(c |w) log p(w0 |c) where Z(w) is a normalization constant. Under this model, w0 is similar </context>
</contexts>
<marker>Mnih, Teh, 2012</marker>
<rawString>Andriy Mnih and Yee Whye Teh. 2012. A fast and simple algorithm for training neural probabilistic language models. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="13376" citStr="Och and Ney, 2003" startWordPosition="2244" endWordPosition="2247">, and 125M words, respectively. The vocabulary V was the 30,000 most frequent words from each corpus 1Catalog numbers: LDC2003E07, LDC2003E14, LDC2005E83, LDC2005T06, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E86, LDC2006E92, and LDC2006E93. 2Excluding: United Nations proceedings (LDC2004E13), ISI Automatically Extracted Parallel Text (LDC2007E08), and Ummah newswire text (LDC2004T18) Source word frequency Figure 3: F1 scores for words binned by frequency. Our model gives the largest improvements for the lowest-frequency words. and the k = 10 most similar words were used. We modified GIZA++ (Och and Ney, 2003) to incorporate word similarity. For all experiments, we used the default configuration of GIZA++: 5 iterations each of IBM Model 1, 2, HMM, 3 and 4. We aligned the parallel texts in both forward and backward directions and symmetrized them using grow-diag-final-and (Koehn et al., 2005). We evaluated alignment quality using precision, recall, and F1. The results in Table 3 suggest that our modeling approach produces better word alignments. We found that our models not only learned smoother translation models for low frequency words but also ranked the conditional probabilities more accurately </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="15795" citStr="Papineni et al., 2002" startWordPosition="2644" endWordPosition="2647">-limited) 56.1 68.1 61.5 23.6 20.3 26.0 24.4 Our model (resource-limited) 66.5 74.4 70.2 24.7 21.6 26.8 25.6 Arabic-English Baseline 56.1 79.0 65.6 37.7 36.2 31.1 30.9 Our model 60.0 82.4 69.5 38.2 36.8 31.6 31.4 Baseline (resource-limited) 56.7 76.1 65.0 34.1 33.0 27.9 27.7 Our model (resource-limited) 59.4 80.7 68.4 35.0 33.8 28.7 28.6 Table 3: Experimental results. Our model improves alignments and translations on both language pairs. build a hierarchical phrase-based translation system (Chiang, 2007) trained using MIRA (Chiang, 2012). Then, we evaluated the translation quality using BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014), and performed significance testing using bootstrap resampling (Koehn, 2004) with 1,000 samples. Under the resource-limited settings, our methods consistently show 1.1–1.3 BLEU (0.8–1.2 METEOR) improvements on Chinese-English and 0.8–0.9 BLEU (0.8–0.9 METEOR) improvements on Arabic-English, as shown in Table 3. These improvements are statistically significant (p &lt; 0.01). On the full data, our method improves ChineseEnglish translation by 0.3–0.5 BLEU (0.3 METEOR), which is unfortunately not statistically significant, and Arabic-English translation by 0.5</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings ofACL, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>H Tolga Ilhan</author>
<author>Christopher D Manning</author>
</authors>
<title>Extensions to HMM-based statistical word alignment models.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>87--94</pages>
<contexts>
<context position="2533" citStr="Toutanova et al., 2002" startWordPosition="408" endWordPosition="411">ersity of Southern California. first branch relies solely on the parallel data; however, additional assumptions about the data are required. This includes, but is not limited to, applying prior distributions (Mermer and Sarac¸lar, 2011; Vaswani et al., 2012) or smoothing techniques (Zhang and Chiang, 2014). The other branch uses information learned from monolingual data, which is generally easier to acquire than parallel data. Previous work in this branch mostly involves applying syntactic constraints (Yamada and Knight, 2001; Cherry and Lin, 2006; Wang and Zong, 2013) and syntactic features (Toutanova et al., 2002) into the models. The use of syntactic relationships can, however, be limited between historically unrelated language pairs. Our motivation lies in the fact that a meaningful sentence is not merely a grammatically structured sentence; its semantics can provide insightful information for the task. For example, suppose that the models are uncertain about aligning e to f. If the models are informed that e is semantically related to e0, f is semantically related to f0, and f0 is a translation of e0, it should intuitively increase the probability that f is a translation of e. Our work focuses on us</context>
</contexts>
<marker>Toutanova, Ilhan, Manning, 2002</marker>
<rawString>Kristina Toutanova, H. Tolga Ilhan, and Christopher D. Manning. 2002. Extensions to HMM-based statistical word alignment models. In Proceedings of EMNLP, pages 87–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Vaswani</author>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Smaller alignment models for better translations: unsupervised word alignment with the tonorm.</title>
<date>2012</date>
<booktitle>In Proceedings ofACL,</booktitle>
<volume>1</volume>
<pages>311--319</pages>
<contexts>
<context position="2168" citStr="Vaswani et al., 2012" startWordPosition="352" endWordPosition="355">d from a source word eai with respect to an alignment a. The models, however, tend to misalign low-frequency words as they have insufficient training samples. The problem can get worse in low-resource languages. Two branches of research have tried to alleviate the problem. The †Most of the work reported here was performed while the second author was at the University of Southern California. first branch relies solely on the parallel data; however, additional assumptions about the data are required. This includes, but is not limited to, applying prior distributions (Mermer and Sarac¸lar, 2011; Vaswani et al., 2012) or smoothing techniques (Zhang and Chiang, 2014). The other branch uses information learned from monolingual data, which is generally easier to acquire than parallel data. Previous work in this branch mostly involves applying syntactic constraints (Yamada and Knight, 2001; Cherry and Lin, 2006; Wang and Zong, 2013) and syntactic features (Toutanova et al., 2002) into the models. The use of syntactic relationships can, however, be limited between historically unrelated language pairs. Our motivation lies in the fact that a meaningful sentence is not merely a grammatically structured sentence; </context>
</contexts>
<marker>Vaswani, Huang, Chiang, 2012</marker>
<rawString>Ashish Vaswani, Liang Huang, and David Chiang. 2012. Smaller alignment models for better translations: unsupervised word alignment with the tonorm. In Proceedings ofACL, volume 1, pages 311– 319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Vaswani</author>
<author>Yinggong Zhao</author>
<author>Victoria Fossum</author>
<author>David Chiang</author>
</authors>
<title>Decoding with large-scale neural language models improves translation.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="5300" citStr="Vaswani et al., 2013" startWordPosition="885" endWordPosition="888">context represented by a sequence w1, w2,. . . , w2n consisting of n word tokens on the left and n word tokens on the right of w, excluding w. The submodel p(c |w) can be a categorical distribution. However, modeling the word context model, p(w0 |c), as a categorical distribution would cause severe overfitting, because the number of all possible contexts is |V |2n, which is exponential in the length of the context. We therefore parameterize it using a feedforward neural network as shown in Figure 1, since the structure has been shown to be effective for language modeling (Bengio et al., 2006; Vaswani et al., 2013). The input to the network is a one-hot representation of each word in c, where the special symbols &lt;s&gt;, &lt;/s&gt;, &lt;unk&gt; are reserved for sentence beginning, sentence ending, and words not in the vocabulary. There is an output node for each w0 ∈ V , whose activation is p(w0 |c). Following Bengio et al. (2006), the network uses a shared linear projection matrix to the input embedding layer, which allows information sharing among the context words and also substantially reduces the number of parameters. The input embedding layer has a dimensionality of 150 for each input word. The network uses two h</context>
</contexts>
<marker>Vaswani, Zhao, Fossum, Chiang, 2013</marker>
<rawString>Ashish Vaswani, Yinggong Zhao, Victoria Fossum, and David Chiang. 2013. Decoding with large-scale neural language models improves translation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING,</booktitle>
<volume>2</volume>
<pages>836--841</pages>
<contexts>
<context position="1452" citStr="Vogel et al., 1996" startWordPosition="231" endWordPosition="234"> machine translation. The task is to find word-level translation correspondences in parallel text. Formally, given a source sentence e consisting of words e1, e2, ... , el and a target sentence f consisting of words f1, f2, ... , fm, we want to infer an alignment a, a sequence of indices a1, a2,... , am which indicates, for each target word fi, the corresponding source word eai or a null word. Machine translation systems, including state-of-the-art systems, then use the word-aligned corpus to extract translation rules. The most widely used methods, the IBM models (Brown et al., 1993) and HMM (Vogel et al., 1996), define a probability distribution p(f, a I e) that models how each target word fi is generated from a source word eai with respect to an alignment a. The models, however, tend to misalign low-frequency words as they have insufficient training samples. The problem can get worse in low-resource languages. Two branches of research have tried to alleviate the problem. The †Most of the work reported here was performed while the second author was at the University of Southern California. first branch relies solely on the parallel data; however, additional assumptions about the data are required. T</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of COLING, volume 2, pages 836–841.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiguo Wang</author>
<author>Chengqing Zong</author>
</authors>
<title>Largescale word alignment using soft dependency cohesion constraints.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>1</volume>
<issue>6</issue>
<contexts>
<context position="2485" citStr="Wang and Zong, 2013" startWordPosition="401" endWordPosition="404">ormed while the second author was at the University of Southern California. first branch relies solely on the parallel data; however, additional assumptions about the data are required. This includes, but is not limited to, applying prior distributions (Mermer and Sarac¸lar, 2011; Vaswani et al., 2012) or smoothing techniques (Zhang and Chiang, 2014). The other branch uses information learned from monolingual data, which is generally easier to acquire than parallel data. Previous work in this branch mostly involves applying syntactic constraints (Yamada and Knight, 2001; Cherry and Lin, 2006; Wang and Zong, 2013) and syntactic features (Toutanova et al., 2002) into the models. The use of syntactic relationships can, however, be limited between historically unrelated language pairs. Our motivation lies in the fact that a meaningful sentence is not merely a grammatically structured sentence; its semantics can provide insightful information for the task. For example, suppose that the models are uncertain about aligning e to f. If the models are informed that e is semantically related to e0, f is semantically related to f0, and f0 is a translation of e0, it should intuitively increase the probability that</context>
</contexts>
<marker>Wang, Zong, 2013</marker>
<rawString>Zhiguo Wang and Chengqing Zong. 2013. Largescale word alignment using soft dependency cohesion constraints. Transactions of the Association for Computational Linguistics, 1(6):291–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntaxbased statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="2441" citStr="Yamada and Knight, 2001" startWordPosition="393" endWordPosition="396">m. The †Most of the work reported here was performed while the second author was at the University of Southern California. first branch relies solely on the parallel data; however, additional assumptions about the data are required. This includes, but is not limited to, applying prior distributions (Mermer and Sarac¸lar, 2011; Vaswani et al., 2012) or smoothing techniques (Zhang and Chiang, 2014). The other branch uses information learned from monolingual data, which is generally easier to acquire than parallel data. Previous work in this branch mostly involves applying syntactic constraints (Yamada and Knight, 2001; Cherry and Lin, 2006; Wang and Zong, 2013) and syntactic features (Toutanova et al., 2002) into the models. The use of syntactic relationships can, however, be limited between historically unrelated language pairs. Our motivation lies in the fact that a meaningful sentence is not merely a grammatically structured sentence; its semantics can provide insightful information for the task. For example, suppose that the models are uncertain about aligning e to f. If the models are informed that e is semantically related to e0, f is semantically related to f0, and f0 is a translation of e0, it shou</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntaxbased statistical translation model. In Proceedings ofACL, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zhang</author>
<author>David Chiang</author>
</authors>
<title>Kneser-Ney smoothing on expected counts.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2217" citStr="Zhang and Chiang, 2014" startWordPosition="360" endWordPosition="363">gnment a. The models, however, tend to misalign low-frequency words as they have insufficient training samples. The problem can get worse in low-resource languages. Two branches of research have tried to alleviate the problem. The †Most of the work reported here was performed while the second author was at the University of Southern California. first branch relies solely on the parallel data; however, additional assumptions about the data are required. This includes, but is not limited to, applying prior distributions (Mermer and Sarac¸lar, 2011; Vaswani et al., 2012) or smoothing techniques (Zhang and Chiang, 2014). The other branch uses information learned from monolingual data, which is generally easier to acquire than parallel data. Previous work in this branch mostly involves applying syntactic constraints (Yamada and Knight, 2001; Cherry and Lin, 2006; Wang and Zong, 2013) and syntactic features (Toutanova et al., 2002) into the models. The use of syntactic relationships can, however, be limited between historically unrelated language pairs. Our motivation lies in the fact that a meaningful sentence is not merely a grammatically structured sentence; its semantics can provide insightful information </context>
</contexts>
<marker>Zhang, Chiang, 2014</marker>
<rawString>Hui Zhang and David Chiang. 2014. Kneser-Ney smoothing on expected counts. In Proceedings of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>