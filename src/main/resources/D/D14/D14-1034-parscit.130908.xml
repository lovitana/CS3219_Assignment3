<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.996856">
An Unsupervised Model for Instance Level Subcategorization Acquisition
</title>
<author confidence="0.942282">
Simon Baker Roi Reichart Anna Korhonen
</author>
<affiliation confidence="0.9304045">
Computer Laboratory Technion, IIT Computer Laboratory
University of Cambridge Haifa, Israel University of Cambridge
</affiliation>
<email confidence="0.989042">
sb895@cam.ac.uk roiri@ie.technion.ac.il alk23@cam.ac.uk
</email>
<sectionHeader confidence="0.99363" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999848086956522">
Most existing systems for subcategoriza-
tion frame (SCF) acquisition rely on su-
pervised parsing and infer SCF distribu-
tions at type, rather than instance level.
These systems suffer from poor portability
across domains and their benefit for NLP
tasks that involve sentence-level process-
ing is limited. We propose a new unsuper-
vised, Markov Random Field-based model
for SCF acquisition which is designed
to address these problems. The system
relies on supervised POS tagging rather
than parsing, and is capable of learning
SCFs at instance level. We perform eval-
uation against gold standard data which
shows that our system outperforms several
supervised and type-level SCF baselines.
We also conduct task-based evaluation in
the context of verb similarity prediction,
demonstrating that a vector space model
based on our SCFs substantially outper-
forms a lexical model and a model based
on a supervised parser 1.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999520555555556">
Subcategorization frame (SCF) acquisition in-
volves identifying the arguments of a predicate
and generalizing about its syntactic frames,
where each frame specifies the syntactic type and
number of arguments permitted by the predicate.
For example, in sentences (1)-(3) the verb distin-
guish takes three different frames, the difference
between which is not evident when considering
the phrase structure categorization:
</bodyText>
<listItem confidence="0.94721">
(1) Direct Transitive: [They]NP [distin-
guished]VP [the mast]NP [of [ships on the
horizon ]NP ]PP .
</listItem>
<footnote confidence="0.902264">
1The verb similarity dataset used for the evaluation of our
model is publicly available at ie.technion.ac.il/∼roiri/.
</footnote>
<listItem confidence="0.9992285">
(2) Indirect Transitive: [They]NP [distin-
guished]VP [between [me and you]ADVP ]PP .
(3) Ditransitive: [They]NP [distinguished]VP
[him]NP [from [the other boys]NP ]PP.
</listItem>
<bodyText confidence="0.999909513513513">
As SCFs describe the syntactic realization of
the verbal predicate-argument structure, they are
highly valuable for a variety of NLP tasks. For
example, verb subcategorization information has
proven useful for tasks such as parsing (Carroll
and Fang, 2004; Arun and Keller, 2005; Cholakov
and van Noord, 2010), semantic role labeling
(Bharati et al., 2005; Moschitti and Basili, 2005),
verb clustering, (Schulte im Walde, 2006; Sun
and Korhonen, 2011) and machine translation (hye
Han et al., 2000; Hajiˇc et al., 2002; Weller et al.,
2013).
SCF induction is challenging. The argument-
adjunct distinction is difficult even for humans,
and is further complicated by the fact that both ar-
guments and adjuncts can appear frequently in po-
tential argument head positions (Korhonen et al.,
2000). SCFs are also highly sensitive to domain
variation so that both the frames themselves and
their probabilities vary depending on the meaning
and behavior of predicates in the domain in ques-
tion (e.g. (Roland and Jurafsky, 1998; Lippincott
et al., 2010; Rimell et al., 2013), Section 4).
Because of the strong impact of domain vari-
ation, SCF information is best acquired automat-
ically. Existing data-driven SCF induction sys-
tems, however, do not port well between do-
mains. Most existing systems rely on hand-
written rules (Briscoe and Carroll, 1997; Korho-
nen, 2002; Preiss et al., 2007) or simple co-
occurrence statistics (O’Donovan et al., 2005;
Chesley and Salmon-Alt, 2006; Ienco et al., 2008;
Messiant et al., 2008; Lenci et al., 2008; Al-
tamirano and Alonso i Alemany, 2010; Kawa-
hara and Kurohashi, 2010) applied to the gram-
matical dependency output of supervised statisti-
cal parsers. Even the handful of recent systems
</bodyText>
<page confidence="0.958652">
278
</page>
<note confidence="0.9148325">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.991994246376812">
that use modern machine learning techniques (De-
bowski, 2009; Lippincott et al., 2012; Van de
Cruys et al., 2012; Reichart and Korhonen, 2013)
use supervised parsers to pre-process the data2.
Supervised parsers are notoriously sensitive to
domain variation (Lease and Charniak, 2005). As
annotation of data for each new domain is un-
realistic, current SCF systems suffer from poor
portability. This problem is compounded for
the many systems that employ manually devel-
oped SCF rules because rules are inherently ig-
norant to domain-specific preferences. The few
SCF studies that focused on specific domains (e.g.
biomedicine) have reported poor performance due
to these reasons (Rimell et al., 2013).
Another limitation of most current SCF systems
is that they produce a type-level SCF lexicon (i.e.
a lexicon which lists, for a given predicate, dif-
ferent SCF types with their relative frequencies).
Such a lexicon provides a useful high-level pro-
file of the syntactic behavior of the predicate in
question, but is less useful for downstream NLP
tasks (e.g. information extraction, parsing, ma-
chine translation) that involve sentence processing
and can therefore benefit from SCF information
at instance level. Sentences (1)-(3) demonstrate
this limitation - a prior distribution over the pos-
sible syntactic frames of distinguish provides only
a weak signal to a sentence level NLP application
that needs to infer the verbal argument structure of
its input sentences.
We propose a new unsupervised model for SCF
induction which addresses these problems with
existing systems. Our model does not use a parser
or hand-written rules, only a part-of-speech (POS)
tagger is utilizes in order to produce features for
machine learning. While POS taggers are also
sensitive to domain variation, they can be adapted
to domains more easily than parsers because they
require much smaller amounts of annotated data
(Lease and Charniak, 2005; Ringger et al., 2007).
However, as we demonstrate in our experiments,
domain adaptation of POS tagging may not even
be necessary to obtain good results on the SCF ac-
quisition task.
Our model, based on the Markov Random Field
(MRF) framework, performs instance-based SCF
learning. It encodes syntactic similarities among
verb instances across different verb types (derived
2(Lippincott et al., 2012) does not use a parser, but the
syntactic frames induced by the system do not capture sets of
arguments for verbs, so are not SCFs in a traditional sense.
from a lexical and POS-based feature representa-
tion of verb instances) as well as prior beliefs on
the tendencies of specific instances of the same
verb type to take the same SCF.
We evaluate our model against corpora anno-
tated with verb instance SCFs (Quochi et al.,
2012). In addition, following the Levin verb
clustering tradition (Levin, 1993) which ties verb
meanings with their syntactic properties, we eval-
uate the semantic predictive power of our clusters.
In the former evaluation, our model outperforms a
number of strong baselines, including supervised
and type-level ones, achieving an accuracy of up
to 69.2%. In the latter evaluation a vector space
model that utilized our induced SCFs substantially
outperforms the output of a type-level SCF system
that uses the fully trained Stanford parser.
</bodyText>
<sectionHeader confidence="0.995667" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.9990681">
Several SCF acquisition systems are available for
English (O’Donovan et al., 2005; Preiss et al.,
2007; Lippincott et al., 2012; Van de Cruys et
al., 2012; Reichart and Korhonen, 2013) and other
languages, including French (Messiant, 2008),
Italian (Lenci et al., 2008), Turkish (Uzun et al.,
2008), Japanese (Kawahara and Kurohashi, 2010)
and Chinese (Han et al., 2008). The promi-
nent input to these systems are grammatical re-
lations (GRs) which express binary dependen-
cies between words (e.g. direct and indirect ob-
jects, various types of complements and conjunc-
tions). These are generated by some parsers (e.g.
(Briscoe et al., 2006)) and can be extracted from
the output of others (De-Marneffe et al., 2006).
Two representative systems for English are the
Cambridge system (Preiss et al., 2007) and the
BioLexicon system which was used to acquire a
substantial lexicon for biomedicine (Venturi et al.,
2009). These systems extract GRs at the verb in-
stance level from the output of a parser: the RASP
general-language unlexicalized parser3 (Briscoe et
al., 2006) and the lexicalized Enju parser tuned to
the biomedical domain (Miyao and Tsujii, 2005),
respectively. They generate potential SCFs by
mapping GRs to a predefined SCF inventory us-
ing a set of manually developed rules (the Cam-
bridge system) or by simply considering the sets
of GRs including verbs in question as potential
SCFs (BioLexicon). Finally, a type level lexicon
</bodyText>
<footnote confidence="0.9927">
3A so-called unlexicalized parser is a parser trained with-
out explicit SCF annotations.
</footnote>
<page confidence="0.99844">
279
</page>
<bodyText confidence="0.999871803278689">
is built through noisy frame filtering (based on
frequencies or on external resources and annota-
tions), which aims to remove errors from parsing
and argument-adjunct distinction. Clearly, these
systems require extensive manual work: a-priori
definition of an SCF inventory and rules, manu-
ally annotated sentences for training a supervised
parser, SCF annotations for parser lexicalization,
and manually developed resources for optimal fil-
tering.
A number of recent works have applied mod-
ern machine learning techniques to SCF induc-
tion, including point-wise co-occurrence of ar-
guments (Debowski, 2009), a Bayesian network
model (Lippincott et al., 2012), multi-way tensor
factorization (Van de Cruys et al., 2012) and De-
terminantal Point Processes (DPPs) -based clus-
tering (Reichart and Korhonen, 2013). However,
all of these systems induce type-level SCF lexi-
cons and, except from the system of (Lippincott et
al., 2012) that is not capable of learning traditional
SCFs, they all rely on supervised parsers.
Our new system differs from previous ones in
a number of respects. First, in contrast to most
previous systems, our system provides SCF anal-
ysis for each verb instance in its sentential con-
text, yielding more precise SCF information for
systems benefiting from instance-based analysis.
Secondly, it addresses SCF induction as an unsu-
pervised clustering problem, avoiding the use of
supervised parsing or any of the sources of man-
ual supervision used in previous works. Our sys-
tem relies on POS tags - however, we show that it
is not necessary to train a tagger with in-domain
data to obtain good performance on this task, and
therefore our approach provides a more domain-
independent solution to SCF acquisition.
We employ POS-tagging instead of unsuper-
vised parsing for two main reasons. First, while
a major progress has been made on unsupervised
parsing (e.g. (Cohen and Smith, 2009; Berg-
Kirkpatrick et al., 2010)), the performance is still
considerably behind that of supervised parsing.
For example, the state-of-the-art discriminative
model of (Berg-Kirkpatrick et al., 2010) achieves
only 63% directed arc accuracy for WSJ sentences
of up to 10 words, compared to more than 95%
obtained with supervised parsers. Second, current
unsupervised parsers produce unlabeled structures
which are substantially less useful for SCF acqui-
sition than labeled structures produced by super-
vised parsers (e.g. grammatical relations).
Finally, a number of recent works addressed re-
lated tasks such as argument role clustering for
SRL (Lang and Lapata, 2011a; Lang and Lapata,
2011b; Titvo and Klementiev, 2012) in an unsu-
pervised manner. While these works differ from
ours in the task (clustering arguments rather than
verbs) and the level of supervision (applying a su-
pervised parser), like us they analyze the verb ar-
gument structure at the instance level.
</bodyText>
<sectionHeader confidence="0.991738" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999986727272727">
We address SCF induction as an unsupervised
verb instance clustering problem. Given a set of
plain sentences, our algorithm aims to cluster the
verb instances in its input into syntactic clusters
that strongly correlate with SCFs. In this sec-
tion we introduce a Markov Random Field (MRF)
model for this task: Section 3.1 describes our
model’s structure, components and objective; Sec-
tion 3.2 describes the model potentials and the
knowledge they encode; and Section 3.3 describes
how clusters are induced from the model.
</bodyText>
<subsectionHeader confidence="0.999961">
3.1 Model Structure
</subsectionHeader>
<bodyText confidence="0.999841961538462">
We implement our model in the MRF framework
(Koller and Friedman, 2009). This enables us to
encode the two main sources of information that
govern SCF selection in verb instances: (1) At
the sentential context, the verbal syntactic frame
is encoded through syntactic features. Verb in-
stances with similar feature representations should
therefore take the same syntactic frame; and (2)
At the global context, per verb type SCF distribu-
tions tend to be Zipfian (Korhonen et al., 2000).
Instances of the same verb type should therefore
be biased to take the same syntactic frame.
Given a collection of plain input sentences, we
denote the number of verb instances in the col-
lection with n, and the number of data-dependent
equivalence classes (ECs) with K (see below for
their definition), and define an undirected graphi-
cal model (MRF), G = (V, E, L). We define the
vertex set as V = X U C, with X = {xi, ... , xn}
consisting of one vertex for every verb instance in
the input collection, and C = {c1 ... cK} consist-
ing of one vertex for each data-dependent EC. The
set of labels used by the model, L, corresponds to
the syntactic frames taken by the verbs in the in-
put data. The edge set E is defined through the
model’s potentials that are described below.
</bodyText>
<page confidence="0.988922">
280
</page>
<bodyText confidence="0.999968151515152">
We encode information in the model through
three main sets of potentials: one set of single-
ton potentials - defined over individual model ver-
texes, and two sets of pairwise potentials - defined
between pairs of vertexes. The first set consists of
a singleton potential for each vertex in the model.
Reflecting the Zipfian distribution of SCFs across
the instances of the same verb type, these poten-
tials encourage the model to assign such verb in-
stances to the same frame (cluster). The infor-
mation encoded in these potentials is induced via
a pre-processing clustering step. The second set
consists of a pairwise potential for each pair of ver-
texes xi, xj E X - that is, for each verb instance
pair in the input, across verb types. These poten-
tials encode the belief, computed as feature-based
similarity (see below), that their verb instance ar-
guments implement the same SCF.
Finally, potentials from the last set bias the
model to assign the same SCF to high cardinal-
ity sets of cross-type verb instances based on their
syntactic context. While these are pairwise poten-
tials defined between verb instance vertexes (X)
and EC vertexes (C), they are designed so that
they bias the assignment of all verb instance ver-
texes that are connected to the same EC vertex to-
wards the same frame assignment (l E L). The
two types of pairwise potentials complement each
other by modeling syntactic similarities among
verb instance pairs, as well as among higher cardi-
nality verb instance sets.
The resulted maximum aposteriori problem
(MAP) takes the following form:
</bodyText>
<equation confidence="0.999724666666667">
MAP(V) = arg max Xn Bi(xi) + Xn n Bi,j(xi, xj)+
x,c∈V i=1 i=1 X
j=1
Xn K Oi,j(xi, cj) · I(xi ∈ ECj) + XK K ξi,j(ci, cj)
i=1 X i=1 X
j=1 j=1
</equation>
<bodyText confidence="0.999742391304348">
where the predicate I(xi E ECj) returns 1 if
the i-th verb instance belongs the j-th equivalence
class and 0 otherwise. The S pairwise potentials
defined between EC vertexes are very simple po-
tentials designed to promise different assignments
for each pair of EC vertexes. They do so by assign-
ing a −oc score to assignments where their argu-
ment vertexes take the same frame and a 0 other-
wise. In the rest of this section we do not get back
to this simple set of potentials.
A graphical illustration of the model is given
in Figure 1. Note that we could have selected a
richer model structure, for example, by defining
a similarity potential over all verb instance ver-
texes that share an equivalence class. However, as
the figure demonstrates, even the structure of the
pruned version of our model (see Section 3.3) usu-
ally contains cycles, which makes inference NP-
hard (Shimony, 1994). Our design choices aim to
balance between the expressivity of the model and
the complexity of inference. In Section 3.3 we de-
scribe the LP relaxation algorithm we use for in-
ference.
</bodyText>
<figureCaption confidence="0.916451">
Figure 1: A graphical illustration of our model
</figureCaption>
<bodyText confidence="0.952166333333333">
(after pruning, see Sec. 3.3) for twenty verb in-
stances (|X |= 20), each represented with a black
vertex, and two equivalence classes (ECs), each
represented with a gray vertex (|C |= 2). Solid
lines represent edges (and θi,j pairwise potentials)
between verb instance vertexes. Dashed lines rep-
resent edges between verb instance vertexes and
EC vertexes (φi,j pairwise potentials) or between
EC vertexes (Si,j pairwise potentials) .
</bodyText>
<subsectionHeader confidence="0.999021">
3.2 Potentials and Encoded Knowledge
</subsectionHeader>
<bodyText confidence="0.996014727272727">
Pairwise Syntactic Similarity Potentials. The
pairwise syntactic similarity potentials are defined
for each pair of verb instance vertexes, xi, xj E X.
They are designed to encourage the model to as-
sign verb instances with similar fine-grained fea-
ture representations to the same frame (l E L)
and verb instances with dissimilar representations
to different frames. For this aim, for every verb
pair i, j with feature representation vectors vi, vj
and verb instance vertexes xi, xj E X, we define
the following potential function:
</bodyText>
<equation confidence="0.565541">
r λ(vi, vj) if l1 = l2 1
</equation>
<bodyText confidence="0.981914333333333">
l 0 otherwise J
Where l1, l2 E L are label pairs and A is a verb
instance similarity function. Below we describe
the feature representation and the A function.
The verb instance feature representation is de-
fined through the following process. For each
</bodyText>
<equation confidence="0.996838">
C1 C2
Bi,j(xi = l1, xj = l2) =
</equation>
<page confidence="0.975851">
281
</page>
<bodyText confidence="0.999843028571429">
word instance in the input sentences we first build
a basic feature representation (see below). Then,
for each verb instance we construct a final fea-
ture representation defined to be the concatena-
tion of that verb’s basic feature representation with
the basic representations of the words in a size
2 window around the represented verb. The fi-
nal feature representation for the i-th verb in-
stance in our dataset is therefore defined to be
vi = [w_2, w_1, vbi, w+1, w+2], where w_k and
w+k are the basic feature representations of the
words in distance −k or +k from the i-th verb in-
stance in its sentence, and vbi is the basic feature
representation of that verb instance.
Our basic feature representation is inspired
from the feature representation of the MST parser
(McDonald et al., 2005) except that in the parser
the features represent a directed edge in the com-
plete directed graph defined over the words in a
sentence that is to be parsed, while our features are
generated for word n-grams. Particularly, our fea-
ture set is a concatenation of two sets derived from
the MST set described in Table 1 of (McDonald et
al., 2005) in the following way: (1) In both sets the
parent word in the parser’s set is replaced with the
represented word; (2) In one set every child word
in the parser’s set is replaced by the word to the
left of the represented word and in the other set it
is replaced by the word to its right. This choice of
features allows us to take advantage of a provably
useful syntactic feature representation without the
application of any parse tree annotation or parser.
We compute the similarity between the syntac-
tic environments of two verb instances, i, j, using
the following equation:
</bodyText>
<equation confidence="0.562271">
A(vi, vj) = W · cos(vi, vj) − S
</equation>
<bodyText confidence="0.967072714285714">
Where W is a hyperparameter designed to bias
verb instances of the same verb type towards the
same frame. Practically, W was tuned to be 3 for
instances of the same type, and 1 otherwise 4.
While the cosine function is the standard mea-
sure of similarity between two vectors, its val-
ues are in the [0, 1] range. In the MRF modeling
framework, however, we must encode a negative
pairwise potential value between two vertexes in
order to encourage the model to assign different
labels (frames) to them. We therefore added the
positive hyperparameter S which was tuned, with-
4All hyperparameters that require gold-standard annota-
tion for tuning, were tuned using held-out data (Section 4).
out access to gold standard manual annotations, so
that there is an even number of negative and pos-
itive pairwise syntactic similarity potentials after
the model is pruned (see Section 3.3) 5.
Type Level Singleton Potentials. The goal of
these potentials is to bias verb instances of the
same type to be assigned to the same syntactic
frame while still keeping the instance based nature
of our algorithm. For this aim, we applied Algo-
rithm 1 for pre-clustering of the verb instances and
encoded the induced clusters into the local poten-
tials of the corresponding x E X vertexes. For
every x E X the singleton potential is therefore
defined to be:
</bodyText>
<equation confidence="0.9404235">
�B, (x, = l) = F · max a if l is induced by Algorithm 1 l
0 otherwise J
</equation>
<bodyText confidence="0.996921121212122">
where max A is the maximum A score across all
verb instance pairs in the model and F = 0.2 is a
hyperparamter.
Algorithm 1 has two hyperparameters: T and
M, the first is a similarity cut-off value used to de-
termine the initial set of clusters, while the second
is used to determine whether two clusters are simi-
lar enough to be merged. We tuned these hyperpa-
rameters, without manually annotated data, so that
the number of clusters induced by this algorithm
will be equal to the number of gold standard SCFs.
T was tuned so that the first part of the algorithm
generates an excessive number of clusters, and M
was then tuned so that these clusters are merged to
the desired number of clusters.
The A function, used to measure the similar-
ity between two verbs, is designed to bias the in-
stances of the same verb type to have a higher sim-
ilarity score. Algorithm 1 therefore tends to assign
such instances to the same cluster. In our experi-
ments that was always the case for this algorithm.
High Cardinality Verb Sets Potentials. This
set of potentials aims to bias larger sets of verb
instances to share the same SCF. It is inspired by
(Rush et al., 2012) who demonstrated, that syn-
tactic structures that appear at the same syntac-
tic context, in terms of the surrounding POS tags,
tend to manifest similar syntactic behavior. While
they demonstrated the usefulness of their method
for dependency parsing and POS tagging, we im-
plement it for higher level SCFs.
We identified syntactic contexts that imply simi-
lar SCFs for verb instances appearing inside them.
</bodyText>
<footnote confidence="0.9930615">
5The values in practice are S = 0.43 for labour legislation
and S = 0.38 for environment.
</footnote>
<page confidence="0.987473">
282
</page>
<bodyText confidence="0.7924144">
Algorithm 1 Verb instance pre-clustering algo-
rithm. λˆ is the average λ score between the mem-
bers of its cluster arguments. T and M are hyper-
parametes tuned without access to gold standard
data.
</bodyText>
<table confidence="0.803393">
Require: K = 0
for all x E X do
for all k E K do
for all u E k do
if a(vx, vu) &gt; T then
k=kU{x}
Go to next x
end if
end for
end for
k1 = {x}
K=KUk1
end for
for all k1, k2 E K: k1 =� k2 do
if ˆa(k1, k2) &gt; M then
Merge (k1, k2)
</table>
<tableCaption confidence="0.450181">
end if
end for
</tableCaption>
<bodyText confidence="0.999009428571429">
Contexts are characterized by the coarse POS tag
to the left and to the right of the verb instance.
While the number of context sets is bounded only
by the number of frames our model is designed
to induce, in practice we found that defining two
equivalence sets led to the best performance gain,
and the sets we used are presented in Table 1.
In order to encode this information into our
MRF, each set of syntactic contexts is associated
with an equivalence class (EC) vertex c ∈ C and
the verb instance vertexes of all verbs that appear
in a context from that set are connected with an
edge to c. The pairwise potential between a vertex
x ∈ X and its equivalence class is defined to be:
</bodyText>
<equation confidence="0.82360275">
φi,j(xi = l1,cj = l2) = 0 otherwise J
U if l1 = l2 1
U = 10 is a hyperparameter that strongly biases x
vertexes to get the same SCF as their EC vertex.
</equation>
<subsectionHeader confidence="0.99542">
3.3 Verb Cluster Induction
</subsectionHeader>
<bodyText confidence="0.999913777777778">
In this section we describe how we induce verb
instance clusters from our model. This process
is based on the following three steps: (1) Graph
pruning; (2) Induction of an Ensemble of approx-
imate MAP inference solutions in the resulted
graphical model; and, (3) Induction of a final clus-
tering solution based on the ensemble created at
step 2. Below we explain the necessity of each of
these steps and provide the algorithmic details.
</bodyText>
<table confidence="0.998020333333333">
EC-1 EC-2
Left Right Left Right
, D V T
N D R T
V . N D
R D R N
</table>
<tableCaption confidence="0.997663">
Table 1: POS contexts indicative for the syntactic
</tableCaption>
<bodyText confidence="0.988018076923077">
frame of the verb instance they surround. D: de-
terminer, N: noun, V: verb, T: the preposition ’to’
(which has its own POS tag in the WSJ POS tag set
which we use), R: adverb. EC-1 and EC-2 stand
for the first and second equivalence class respec-
tively. In addition, the following contexts where
associated with both ECs: (T, D), (T, N), (N, N)
and (V, I) where I stands for a preposition.
Graph Pruning. The edge set of our model
consists of an edge for every pair of verb in-
stance vertexes and of the edges that connect verb
instance vertexes and equivalence class vertexes.
This results in a large tree-width graph which sub-
stantially complicates MRF inference. To alleviate
this we prune all edges with a positive score lower
than p+ and all edges with a negative score higher
than p−, where p+ and p− are manually tuned hy-
perparametes 6.
MAP Inference. For most reasonable values of
p+ and p− our graph still contains cycles even af-
ter it is pruned, which makes inference NP-hard
(Shimony, 1994). Yet, thanks to our choice of an
edge-factorized model, there are various approxi-
mate inference algorithms suitable for our case.
We applied the message passing algorithm for
linear-programming (LP) relaxation of the MAP
assignment (MPLP, (Sontag et al., 2008)). LP re-
laxation algorithms for the MAP problem define
an upper bound on the original objective which
takes the form of a linear program. Consequently,
a minimum of this upper bound can be found us-
ing standard LP solvers or, more efficiently, using
specialized message passing algorithms (Yanover
et al., 2006). The MPLP algorithm described in
(Sontag et al., 2008) is appealing in that it itera-
tively computes tighter upper bounds on the MAP
objective (for details see their paper).
Cluster Ensemble Generation and a Final
Solution. As our MAP objective is non-convex,
</bodyText>
<footnote confidence="0.992557333333333">
6The values used in practice are p+ = 0.28, p_ = −0.17
for the labour legislation dataset, and p+ = 0.25, p_ =
−0.20 for the environment set.
</footnote>
<page confidence="0.998892">
283
</page>
<bodyText confidence="0.98087546875">
the convergent point of an optimization algorithm
applied to it is highly sensitive to its initializa-
tion. To avoid convergence to arbitrary local max-
ima which may be of poor quality, we turn to a
perturbation protocol where we repeatedly intro-
duce random noise to the MRF’s potential func-
tions and then compute the approximate MAP so-
lution of the resulted model using the MPLP algo-
rithm. Noising was done by adding an c term to
the lambda values described in section 3.2 7. This
protocol results in a set of cluster (label) assign-
ments for the involved verb instances, which we
treat as an ensemble of experts from which a final,
high quality, solution is to be induced.
The basic idea in ensemble learning is that if
several experts independently cluster together two
verb instances, our belief that these verbs belong
in the same cluster should increase. (Reichart et
al., 2012) implemented this idea through the k-
way normalized cut clustering algorithm (Yu and
Shi, 2003). Its input is an undirected graph Gˆ =
(Vˆ, ˆE, Wˆ) where Vˆ is the set of vertexes, Eˆ is
the set of edges and Wˆ is a non-negative and sym-
metric edge weight matrix. To apply this model
to our task, we construct the input graph Gˆ from
the labelings (frame assignments) contained in the
ensemble. The graph vertexes Vˆ correspond to the
verb instances and the (i, j)-th entry of the matrix
Wˆ is the number of ensemble members that assign
the same label to the i-th and j-th verb instances.
For A, B ⊆ Vˆ define:
ing by ˆcij. Then
</bodyText>
<equation confidence="0.97248">
= argmin
c∗
ˆciE Cˆ
</equation>
<bodyText confidence="0.852657666666667">
eigenvalues an
d eigenvectors computations re-
quired by traditional approaches.
</bodyText>
<equation confidence="0.99624325">
k Vˆ−ˆcij)
j=1
links(A, B) = � Wˆ(i, j)
iEA,jEB
</equation>
<bodyText confidence="0.725766">
d B is defined to be:
of A an
</bodyText>
<equation confidence="0.953825">
links(A, B)
NormLinkRatio(A, B) =
</equation>
<bodyText confidence="0.650959">
terings of
that consist of k clusters by
=
...
an
</bodyText>
<equation confidence="0.95062075">
Vˆ
Cˆ
{ ˆc1,
ˆct}
</equation>
<bodyText confidence="0.9646669">
d the j-th cluster of the i-th cluster-
ing it to 1% of
vj). This value was tuned, without
access to gold standard manual annotations, so that there is
an even number of negative an
cos(vi,
d positive pairwise syntactic
similarity potentials after the model is pruned (Section 3.3).
links(A, Vˆ)
Using this definition, the normalized link ratio
The k-way normalized cut problem is to mini-
mize the links that leave a cluster relative to the
total weight of the cluster. Denote the set of clus-
7e was accepted by first sampling a number in the [0, 1]
range using the Java psuodorandom generator and then scal-
NormLinkRatio( ˆcij,
The algorithm of (Yu and Shi, 2003) solves this
problem very efficiently as it avoids the heavy
4 Experiments and Results
Our model is unique compared to existing systems
in two respects. First, it does not utilize supervi-
sion in the form of either a supervised syntactic
parser and/or manually crafted SCF rules. Conse-
quently, it induces unnamed frames (clusters) that
are not directly comparable to the named frames
induced by previous systems. Second, it induces
syntactic frames at the verb instance, rather than
type, level. Evaluation, and especially comparison
to previous work, is therefore challenging.
We therefore evaluate our system in two ways.
First, we compare its output, as well as the output
of a number of clustering baselines, to the gold
standard annotation of corpora from two differ-
ent domains (the only publicly available ones with
instance level SCF annotation, to the best of our
knowledge). Second, in order to compare the out-
put of our system to a rule-based SCF system that
utilizes a supervised syntactic parser, we turn to
a task-based evaluation. We aim to predict the
degree of similarity between verb pairs and, fol-
lowing (Pado and Lapata, 2007) , we do so using
a syntactic-based vector space model (VSM). We
construct three VSMs - (a) one that derives fea-
tures from our clusters; (b) one whose features
come from the output of astate-of-the-art verb
type level, rule based, SCF system (Reichart and
Korhonen, 2013) that uses a modern parser (Klein
and Manning, 2003); and (c) a standard lexical
VSM. Below we show that our system compares
favorably in both evaluations.
Data. We experimented with two datasets taken
from different domains: labor legislation and en-
vironment (Quochi et al., 2012). These datasets
were created through web crawling followed by
domain filtering. Each sentence in both datasets
may contain multiple verbs but only one target
verb has been manually annotated with a SCF.
The labour legislation domain dataset contains
4415 annotated verb instances (an
d hence also
</bodyText>
<page confidence="0.994847">
284
</page>
<bodyText confidence="0.99998432">
sentences) of 117 types, and the environmental
domain dataset contains 4503 annotated verb in-
stances of 116 types. In both datasets no verb type
accounts for more than 4% of the instances and
only up to 35 verb types account for 1% of the
instances or more. The lexical difference between
the corpora is substantial: they share only 42 anno-
tated verb types in total, of which only 2 verb types
(responsible for 4.1% and 5.2% of the instances in
the environment and labor legislation domains re-
spectively) belong to the 20 most frequent types
(responsible for 37.9% and 46.85% of the verb in-
stances in the respective domains) of each corpus.
The 29 members of the SCF inventory are de-
tailed in (Quochi et al., 2012). Table 2, presenting
the distribution of the 5 highest frequency frames
in each corpus, demonstrates that, in addition to
the significant lexical difference, the corpora differ
to some extent in their syntactic properties. This is
reflected by the substantially different frequencies
of the ”dobj:iobj-prep:su” and ”dobj:su” frames.
As a pre-processing step we first POS tagged
the datasets with the Stanford tagger (Toutanova
et al., 2003) trained on the standard POS training
sections of the WSJ PennTreebank corpus.
</bodyText>
<subsectionHeader confidence="0.987555">
4.1 Evaluation Against SCF Gold Standard
</subsectionHeader>
<bodyText confidence="0.999984693333334">
Experimental Protocol The computational com-
plexity of our algorithm does not allow us to run it
on thousands of verb instances in a feasible time.
We therefore repeatedly sampled 5% of the sen-
tences from each dataset, ran our algorithm as well
as the baselines (see below) and report the average
performance of each method. The number of rep-
etitions was 40 and samples were drawn from a
uniform distribution while still promising that the
distribution of gold standard SCFs in each sam-
ple is identical to their distribution in the entire
dataset. Before running this protocol, 5% of each
corpus was kept as held-out data on which hyper-
parameter tuning was performed.
Evaluation Measures and Baselines. We com-
pare our system’s output to instance-level gold
standard annotation. We use standard measures
for clustering evaluation, one measure from each
of the two leading measure types: the V measure
(Rosenberg and Hirschberg, 2007), which is an in-
formation theoretic measure, and greedy many-to-
one accuracy, which is a mapping-based measure.
For the latter, each induced cluster is first mapped
to the gold SCF frame that annotates the highest
number of verb instances this induced cluster also
annotates and then a standard instance-level accu-
racy score is computed (see, e.g., (Reichart and
Rappoport, 2009)). Both measures scale from 100
(perfect match with gold standard) to 0 (no match).
As mentioned above, comparing the perfor-
mance of our system with respect to a gold stan-
dard to the performance of previous type-level
systems that used hand-crafted rules and/or su-
pervised syntactic parsers would be challenging.
We therefore compare our model to the follow-
ing baselines: (a) The most frequent class (MFC)
baseline which assigns all verb instances with the
SCF that is the most frequent one in the gold stan-
dard annotation of the data; (b) The Random base-
line which simply assigns every verb instance with
a randomly selected SCF; (c) Algorithm 1 of sec-
tion 3.2 which generates unsupervised verb in-
stance clustering such that verb instances of the
same type are assigned to the same cluster; and
(d) Finally, we also compare our model against
versions where everything is kept fixed, except a
subset of potentials which is omitted. This enables
us to study the intricacies of our model and the rel-
ative importance of its components. For all mod-
els, the number of induced clusters is equal to the
number of SCFs in the gold standard.
Results Table 3 presents the results, demon-
strating that our full model substantially outper-
forms all baselines. For the first two simple heuris-
tic baselines (MFC and Random) the margin is
higher than 20% for both the greedy M-1 mapping
measure and the V measure. Note tat the V score
of the MFC baseline is 0 by definition, as it as-
signs all items to the same cluster. The poor per-
formance of these simple baselines is an indication
of the difficulty of our task.
Recall that the type level clustering induced by
Algorithm 1 is the main source of type level in-
formation our model utilizes (through its single-
ton potentials). The comparison to the output of
this algorithm (the Type Pre-clustering baseline)
therefore shows the quality of the instance level
refinement our model provides. As seen in table 3,
our model outperforms this baseline by 6.9% for
the M-1 measure and 5.2% for the V measure.
In order to compare our model to its compo-
nents we exclude either the EC potentials (φ and
ξ) only (Model - EC), or the EC and the singleton
potentials (θi, Model - EC - Type pre-clustering).
The results show that our model gains much more
</bodyText>
<page confidence="0.994756">
285
</page>
<table confidence="0.998480142857143">
Environment Labour Legislation
SCF Frequency SCF Frequency
dobj:su 46% dobj:su 39%
su 9% dobj:iobj-prep:su 15%
iobj-prep:su 8% su 10%
dobj:iobj-prep:su 6% su:xcompto-vbare 8%
su:xcompto-vbare 6% iobj-prep:su 7%
</table>
<tableCaption confidence="0.983028">
Table 2: Top 5 most frequent SCFs for the Environment and Labour Legislation datasets used in our
experiments.
</tableCaption>
<table confidence="0.9993356">
Environment Labour Legislation
M-1 V M-1 V
Full Model 66.4 57.3 69.2 55.6
Baselines
MFC 46.2 0 39.4 0
Random 34.6 28.1 36.5 27.8
Type Pre-clustering 60.1 52.1 62.3 51.4
Model Components
Model - EC 64.9 56.2 67.4 54.6
Model - EC - Type pre-clustering 48.3 48.9 45.7 44.7
</table>
<tableCaption confidence="0.76764225">
Table 3: Results for our full model, the baselines (Type Pre-clustering: the pre-clustering algorithm
(Algorithm 1 of section 3.2), MFC: the most frequent class (SCF) in the gold standard annotation and
Random: random SCF assignment) and the model components. The full model outperforms all other
models across measures and datasets.
</tableCaption>
<bodyText confidence="0.999825857142857">
from the type level information encoded through
the singleton potentials than from the EC poten-
tials. Yet, EC potentials do lead to an improvement
of up to 1.5% in M-1 and up to 1.1% in V and are
therefore responsible for up to 26.1% and 21.2%
of the improvement over the type pre-clustering
baseline in terms of M-1 and V, respectively.
</bodyText>
<subsectionHeader confidence="0.998779">
4.2 Task Based Evaluation
</subsectionHeader>
<bodyText confidence="0.999972625">
We next evaluate our model in the context of vec-
tor space modeling for verb similarity prediction
(Turney and Pantel, 2010). Since most previous
word similarity works used noun datasets, we con-
structed a new verb pair dataset, following the pro-
tocol used in the collection of the wordSimilarity-
353 dataset (Finkelstein et al., 2002).
Our dataset consists of 143 verb pairs, con-
structed from 122 unique verb lemma types. The
participating verbs appear ≥ 10 times in the con-
catenation of the labour legislation and the envi-
ronment datasets. Only pairs of verbs that were
considered at least remotely similar by human
judges (independent of those that provided the
similarity scores) were included. A similarity
score between 1 and 10 was assigned to each pair
by 10 native English speaking annotators and were
then averaged in order to get a unique pair score.
Our first baseline is a standard VSM based on
lexical collocations. In this model features corre-
spond to the number of collocations inside a size
2 window of the represented verb with each of the
5000 most frequent nouns in the Google n-gram
corpus (Goldberg and Orwant, 2013). Since our
corpora are limited in size, we use the collocation
counts from the Google corpus.
We used our model to generate a vector repre-
sentation of each verb in the following way. We
run the model 5000 times, each time over a set of
verbs consisting of one instance of each of the 122
verb types participating in the verb similarity set.
The output of each such run is transformed to a
binary vector for each participating verb, where
all coordinates are assigned the value of 0, ex-
cept from the one that corresponds to the cluster to
which the verb was assigned which has the value
of 1. The final vector representation is a concate-
nation of the 5000 binary vectors. Note that for
this task we did not use the graph cut algorithm to
generate a final clustering from the multiple MRF
</bodyText>
<page confidence="0.991964">
286
</page>
<bodyText confidence="0.9999716">
runs. Instead we concatenated the output of all
these runs into one feature representation that fa-
cilitates similarity prediction. For our model we
estimated the verb pair similarity using the Tani-
mato similarity score for binary vectors:
</bodyText>
<equation confidence="0.82504725">
�
T (X, Y ) = i
Xi ∧ Yi
Ei xi ∨ Yi
</equation>
<bodyText confidence="0.999996029411765">
For the baseline model, where the features are
collocation counts, we used the standard cosine
similarity.
Our second baseline is identical to our model,
except that: (a) the data is parsed with the Stan-
ford parser (version 3.3.0, (Klein and Manning,
2003)) which was trained with sections 2-21 of the
WSJ corpus; (b) the phrase structure output of the
parser is transformed to the CoNLL dependency
format using the official CoNLL 2007 conversion
script (Johansson and Nugues, 2007); and then (c)
the SCF of each verb instance is inferred using the
rule-based system used by (Reichart and Korho-
nen, 2013). The vector space representation for
each verb is then created using the process we de-
scribed for our model and the same holds for vec-
tor comparison. This baseline allows direct com-
parison of frames induced by our SCF model with
those derived from a supervised parser’s output.
We computed the Pearson correlation between
the scores of each of the models and the human
scores. The results demonstrate the superiority
of our model in predicting verb similarity: the
correlation of our model with the human scores
is 0.642 while the correlation of the lexical col-
location baseline is 0.522 and that of the super-
vised parser baseline is only 0.266. The results
indicate that in addition to their good alignment
with SCFs, our clusters are also highly useful for
verb meaning representation. This is in line with
the verb clustering theory of the Levin tradition
(Levin, 1993) which ties verb meaning with their
syntactic properties. We consider this an intrigu-
ing direction of future work.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999839375">
We presented an MRF-based unsupervised model
for SCF acquisition which produces verb instance
level SCFs as output. As opposed to previous sys-
tems for the task, our model uses only a POS tag-
ger, avoiding the need for a statistical parser or
manually crafted rules. The model is particularly
valuable for NLP tasks benefiting from SCFs that
are applied across text domains, and for the many
tasks that involve sentence-level processing.
Our results show that the accuracy of the model
is promising, both when compared against gold
standard annotations and when evaluated in the
context of a task. In the future we intend to im-
prove our model by encoding additional informa-
tion in it. We will also adapt it to a multilingual
setup, aiming to model a wide range of languages.
</bodyText>
<sectionHeader confidence="0.997394" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.994331666666667">
The first author is supported by the Common-
wealth Scholarship Commission (CSC) and the
Cambridge Trust.
</bodyText>
<sectionHeader confidence="0.998109" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.984829382352941">
Ivana Romina Altamirano and Laura Alonso i Ale-
many. 2010. IRASubcat, a highly customizable,
language independent tool for the acquisition of ver-
bal subcategorization information from corpus. In
Proceedings of the NAACL 2010 Workshop on Com-
putational Approaches to Languages of the Ameri-
cas.
Abhishek Arun and Frank Keller. 2005. Lexicalization
in crosslinguistic probabilistic parsing: The case of
french. In Proceedings of ACL-05.
Taylor Berg-Kirkpatrick, Alexander Bouchard-Cote,
John DeNero, and Dan Klein. 2010. Painless un-
supervised learning with features. In Proceedings of
NAACL-HLT-10.
Akshar Bharati, Sriram Venkatapathy, and Prashanth
Reddy. 2005. Inferring semantic roles using sub-
categorization frames and maximum entropy model.
In Proceedings of CoNLL-05.
Ted Briscoe and John Carroll. 1997. Automatic ex-
traction of subcategorization from corpora. In Pro-
ceedings of ANLP-97.
Ted Briscoe, John Carroll, and Rebecca Watson. 2006.
The second release of the rasp system. In Proceed-
ings of ACL-COLING-06.
John Carroll and Alex Fang. 2004. The automatic ac-
quisition of verb subcategorisations and their impact
on the performance of an HPSG parser. In Proceed-
ings of IJCNLP-04.
Paula Chesley and Susanne Salmon-Alt. 2006. Au-
tomatic extraction of subcategorization frames for
french. In Proceedings of LREC-06.
Kostadin Cholakov and Gertjan van Noord. 2010. Us-
ing unknown word techniques to learn known words.
In Proceedings of EMNLP-10.
</reference>
<page confidence="0.983942">
287
</page>
<reference confidence="0.999047384615385">
Shay Cohen and Noah Smith. 2009. Shared logistic
normal distributions for soft parameter tying in un-
supervised grammar induction. In Proceedings of
NAACL-HLT-09.
Marie-Catherine De-Marneffe, Bill Maccartney, and
Christopher Manning. 2006. Generating typed de-
pendency parses from phrase structure parses. In
Proceedings of LREC-06.
Lukasz Debowski. 2009. Valence extraction using EM
selection and co-occurrence matrices. Proceedins of
LREC-09.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ei-
tan Ruppin. 2002. Placing search in context: The
concept revisited. ACM Transactions on Informa-
tion Systems, 20:116–131.
Yoav Goldberg and Jon Orwant. 2013. A dataset of
syntactic-ngrams over time from a very large corpus
of english books. In Proceedings of (*SEM)-13. As-
sociation for Computational Linguistics.
Jan Hajiˇc, Martin mejrek, Bonnie Dorr, Yuan Ding, Ja-
son Eisner, Daniel Gildea, Terry Koo, Kristen Par-
ton, Gerald Penn, Dragomir Radev, and Owen Ram-
bow. 2002. Natural language generation in the con-
text of machine translation. Technical report, Cen-
ter for Language and Speech Processing, Johns Hop-
kins University, Baltimore. Summer Workshop Final
Report.
Chung hye Han, Benoit Lavoie, Martha Palmer, Owen
Rambow, Richard Kittredge, Tanya Korelsky, and
Myunghee Kim. 2000. Handling structural diver-
gences and recovering dropped arguments in a ko-
rean/english machine translation system. In Pro-
ceedings of the AMTA-00.
Dino Ienco, Serena Villata, and Cristina Bosco. 2008.
Automatic extraction of subcategorization frames
for italian. In Proceedings of LREC-08.
Richard Johansson and Pierre Nugues. 2007. Ex-
tended constituent-to-dependency conversion for en-
glish. In Proceedings of NODALIDA-07.
Daisuke Kawahara and Sadao Kurohashi. 2010. Ac-
quiring reliable predicate-argument structures from
raw corpora for case frame compilation. In Proceed-
ings of LREC-10.
Dan Klein and Christopher Manning. 2003. Accurate
unlexicalized parsing. In Proceedings of ACL-03.
Daphne Koller and Nir Friedman. 2009. Probabilistic
graphical models: principles and techniques. The
MIT Press.
Anna Korhonen, Genevieve Gorrell, and Diana Mc-
Carthy. 2000. Statistical filtering and subcate-
gorization frame acquisition. In Proceedings of
EMNLP-00.
Anna Korhonen. 2002. Semantically motivated sub-
categorization acquisition. In Proceedings of the
ACL-02 workshop on Unsupervised lexical acquisi-
tion.
Joel Lang and Mirella Lapata. 2011a. Unsupervised
semantic role induction via split-merge clustering.
In Proceedings ofACL-11.
Joel Lang and Mirella Lapata. 2011b. Unsupervised
semantic role induction with graph partitioning. In
Proceedings of EMNLP-11.
Matthew Lease and Eugene Charniak. 2005. Parsing
biomedical literature. In Proceedings of IJCNLP-
05.
Alessandro Lenci, Barbara Mcgillivray, Simonetta
Montemagni, and Vito Pirrelli. 2008. Unsupervised
acquisition of verb subcategorization frames from
shallow-parsed corpora. In Proceedings of LREC-
08.
Beth Levin. 1993. English verb classes and alterna-
tions: A preliminary investigation. Chicago, IL.
Tom Lippincott, Anna Korhonen, and Diarmuid Os-
eaghdha. 2010. Exploring subdomain variation in
biomedical language. BMC Bioinformatics.
Tom Lippincott, Aanna Korhonen, and Diarmuid Os-
eaghdha. 2012. Learning syntactic verb frames us-
ing graphical models. In Proceedings of ACL-12.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005. Online large-margin training of de-
pendency parsers. In Proceedings of ACL-05.
Cedric Messiant, Anna Korhonen, and Thierry
Poibeau. 2008. LexSchem: A large subcategoriza-
tion lexicon for French verbs. In Proceedings of
LREC-08.
Cedric Messiant. 2008. A subcategorization acquis-
tion system for french verbs. In Proceedings of
ACL08-SRW.
Yusuke Miyao and Junichi Tsujii. 2005. Probabilistic
disambiguaton models for wide-coverage hpsg pars-
ing. In Proceedings of ACL-05.
Alessandro Moschitti and Roberto Basili. 2005. Verb
subcategorization kernels for automatic semantic la-
beling. In Proceedings of the ACL-SIGLEX Work-
shop on Deep Lexical Acquisition.
Ruth O’Donovan, Michael Burke, Aoife Cahill, Josef
van Genabith, and Andy Way. 2005. Large-scale
induction and evaluation of lexical resources from
the penn-ii and penn-iii treebanks. Computational
Linguistics, 31:328–365.
Sebastian Pado and Mirella Lapata. 2007.
Dependency-based construction of semantic space
models. Computational Linguistics, 33:161–199.
</reference>
<page confidence="0.967904">
288
</page>
<reference confidence="0.999831482352941">
Judita Preiss, Ted Briscoe, and Anna Korhonen. 2007.
A system for large-scale acquisition of verbal, nom-
inal and adjectival subcategorization frames from
corpora. In Proceedings of ACL-07.
Valeria Quochi, Francesca Frontini, Roberto Bartolini,
Olivier Hamon, Marc Poch, Muntsa Padr, Nuria Bel,
Gregor Thurmair, Antonio Toral, and Amir Kam-
ram. 2012. Third evaluation report. evaluation of
panacea v3 and produced resources. Technical re-
port.
Roi Reichart and Anna Korhonen. 2013. Improved
lexical acquisition through dpp-based verb cluster-
ing. In Proceedings ofACL-13.
Roi Reichart and Ari Rappoport. 2009. The nvi
clustering evaluation measure. In Proceedings of
CoNLL-09.
Roi Reichart, Gal Elidan, and Ari Rappoport. 2012. A
diverse dirichlet process ensemble for unsupervised
induction of syntactic categories. In Proceedings of
COLING-12.
Laura Rimell, Thomas Lippincott, Karin Verspoor, He-
len Johnson, and Anna Korhonen. 2013. Acqui-
sition and evaluation of verb subcategorization re-
sources for biomedicine. Journal of Biomedical In-
formatics, 46:228–237.
Eric Ringger, Peter McClanahan, Robbie Haertel,
George Busby, Marc Carmen, James Carroll, Kevin
Seppi, and Deryle Lonsdale. 2007. Active learning
for part-of-speech tagging: Accelerating corpus an-
notation. In Proceedings of the ACL-07 Linguistic
Annotation Workshop.
Douglas Roland and Daniel Jurafsky. 1998. subcate-
gorization frequencies are affected by corpus choice.
In Proceedings of ACL-98.
Andrew Rosenberg and Julia Hirschberg. 2007. V
measure: a conditional entropybased external cluster
evaluation measure. In Proceedings of EMNLP-07.
Alexander Rush, Roi Reichart, Michael Collins, and
Amir Globerson. 2012. Improved parsing and pos
tagging using inter-sentence consistency constraints.
In Proceedings of EMNLP-12.
Sabine Schulte im Walde. 2006. Experiments on
the automatic induction of german semantic verb
classes. Computational Linguistics, 32(2):159–194.
Solomon Shimony. 1994. Finding the maps for belief
networks is np-hard. Artificial Intelligence, 68:399–
310.
David Sontag, Talya Meltzer, Amir Globerson, Tommi
Jaakkola, and Yair Weiss. 2008. Tightening lp re-
laxations for map using message passing. In Pro-
ceedings of UAI-08.
Lin Sun and Anna Korhonen. 2011. Hierarchical verb
clustering using graph factorization. In Proceedings
of EMNLP-11.
Ivan Titvo and Alexandre Klementiev. 2012. A
bayesian approach to unsupervised semantic role in-
duction. In Proceedings of EMNLP-12.
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of NAACL-03.
Peter Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of se-
mantics. Journal of artificial intelligence research,
37:141–188.
Tim Van de Cruys, Laura Rimell, Thierry Poibeau, and
Anna Korhonen. 2012. Multi-way tensor factor-
ization for unsupervised lexical acquisition. In Pro-
ceedings of COLING-12.
Giulia Venturi, Simonetta Montemagni, Simone
Marchi, Yutaka Sasaki, Paul Thompson, John Mc-
Naught, and Sophia Ananiadou. 2009. Bootstrap-
ping a verb lexicon for biomedical information ex-
traction. Computational Linguistics and Intelligent
Text Processing, 5449:137–148.
Marion Weller, Alexander Fraser, and Sabine Schulte
im Walde. 2013. Using subcategorization knowl-
edge to improve case prediction for translation to
german. In Proceedings of ACL-13.
Chen Yanover, Talya Meltzer, and Yair Weiss. 2006.
Linear programming relazations and belief pro-
pogataion an empitical study. JMLR Special Issue
on Machine Learning and Large Scale Optimization.
Stella Yu and Jianbo Shi. 2003. Multiclass spectral
clustering. In Proceedings of ICCV-13.
</reference>
<page confidence="0.998642">
289
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.411830">
<title confidence="0.999906">An Unsupervised Model for Instance Level Subcategorization Acquisition</title>
<author confidence="0.999967">Simon Baker Roi Reichart Anna Korhonen</author>
<affiliation confidence="0.9998185">Computer Laboratory Technion, IIT Computer Laboratory University of Cambridge Haifa, Israel University of</affiliation>
<email confidence="0.838742">sb895@cam.ac.ukroiri@ie.technion.ac.ilalk23@cam.ac.uk</email>
<abstract confidence="0.999626652173913">Most existing systems for subcategorization frame (SCF) acquisition rely on supervised parsing and infer SCF distributions at type, rather than instance level. These systems suffer from poor portability across domains and their benefit for NLP tasks that involve sentence-level processing is limited. We propose a new unsupervised, Markov Random Field-based model for SCF acquisition which is designed to address these problems. The system relies on supervised POS tagging rather than parsing, and is capable of learning SCFs at instance level. We perform evaluation against gold standard data which shows that our system outperforms several supervised and type-level SCF baselines. We also conduct task-based evaluation in the context of verb similarity prediction, demonstrating that a vector space model based on our SCFs substantially outperforms a lexical model and a model based</abstract>
<intro confidence="0.494868">a supervised parser</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Ivana Romina Altamirano and Laura Alonso i Alemany.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL 2010 Workshop on Computational Approaches to Languages of the Americas.</booktitle>
<marker>2010</marker>
<rawString>Ivana Romina Altamirano and Laura Alonso i Alemany. 2010. IRASubcat, a highly customizable, language independent tool for the acquisition of verbal subcategorization information from corpus. In Proceedings of the NAACL 2010 Workshop on Computational Approaches to Languages of the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abhishek Arun</author>
<author>Frank Keller</author>
</authors>
<title>Lexicalization in crosslinguistic probabilistic parsing: The case of french.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05.</booktitle>
<contexts>
<context position="2297" citStr="Arun and Keller, 2005" startWordPosition="327" endWordPosition="330">ished]VP [the mast]NP [of [ships on the horizon ]NP ]PP . 1The verb similarity dataset used for the evaluation of our model is publicly available at ie.technion.ac.il/∼roiri/. (2) Indirect Transitive: [They]NP [distinguished]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves an</context>
</contexts>
<marker>Arun, Keller, 2005</marker>
<rawString>Abhishek Arun and Frank Keller. 2005. Lexicalization in crosslinguistic probabilistic parsing: The case of french. In Proceedings of ACL-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexander Bouchard-Cote</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL-HLT-10.</booktitle>
<contexts>
<context position="10850" citStr="Berg-Kirkpatrick et al., 2010" startWordPosition="1673" endWordPosition="1676">in previous works. Our system relies on POS tags - however, we show that it is not necessary to train a tagger with in-domain data to obtain good performance on this task, and therefore our approach provides a more domainindependent solution to SCF acquisition. We employ POS-tagging instead of unsupervised parsing for two main reasons. First, while a major progress has been made on unsupervised parsing (e.g. (Cohen and Smith, 2009; BergKirkpatrick et al., 2010)), the performance is still considerably behind that of supervised parsing. For example, the state-of-the-art discriminative model of (Berg-Kirkpatrick et al., 2010) achieves only 63% directed arc accuracy for WSJ sentences of up to 10 words, compared to more than 95% obtained with supervised parsers. Second, current unsupervised parsers produce unlabeled structures which are substantially less useful for SCF acquisition than labeled structures produced by supervised parsers (e.g. grammatical relations). Finally, a number of recent works addressed related tasks such as argument role clustering for SRL (Lang and Lapata, 2011a; Lang and Lapata, 2011b; Titvo and Klementiev, 2012) in an unsupervised manner. While these works differ from ours in the task (clus</context>
</contexts>
<marker>Berg-Kirkpatrick, Bouchard-Cote, DeNero, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexander Bouchard-Cote, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Proceedings of NAACL-HLT-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
<author>Sriram Venkatapathy</author>
<author>Prashanth Reddy</author>
</authors>
<title>Inferring semantic roles using subcategorization frames and maximum entropy model.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL-05.</booktitle>
<contexts>
<context position="2374" citStr="Bharati et al., 2005" startWordPosition="339" endWordPosition="342"> dataset used for the evaluation of our model is publicly available at ie.technion.ac.il/∼roiri/. (2) Indirect Transitive: [They]NP [distinguished]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicate</context>
</contexts>
<marker>Bharati, Venkatapathy, Reddy, 2005</marker>
<rawString>Akshar Bharati, Sriram Venkatapathy, and Prashanth Reddy. 2005. Inferring semantic roles using subcategorization frames and maximum entropy model. In Proceedings of CoNLL-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Automatic extraction of subcategorization from corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP-97.</booktitle>
<contexts>
<context position="3354" citStr="Briscoe and Carroll, 1997" startWordPosition="497" endWordPosition="500">appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine lea</context>
</contexts>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Ted Briscoe and John Carroll. 1997. Automatic extraction of subcategorization from corpora. In Proceedings of ANLP-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the rasp system.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL-COLING-06.</booktitle>
<contexts>
<context position="7868" citStr="Briscoe et al., 2006" startWordPosition="1207" endWordPosition="1210">uisition systems are available for English (O’Donovan et al., 2005; Preiss et al., 2007; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) and other languages, including French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Uzun et al., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss et al., 2007) and the BioLexicon system which was used to acquire a substantial lexicon for biomedicine (Venturi et al., 2009). These systems extract GRs at the verb instance level from the output of a parser: the RASP general-language unlexicalized parser3 (Briscoe et al., 2006) and the lexicalized Enju parser tuned to the biomedical domain (Miyao and Tsujii, 2005), respectively. They generate potential SCFs by mapping GRs to a predefined SCF inv</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the rasp system. In Proceedings of ACL-COLING-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Alex Fang</author>
</authors>
<title>The automatic acquisition of verb subcategorisations and their impact on the performance of an HPSG parser.</title>
<date>2004</date>
<booktitle>In Proceedings of IJCNLP-04.</booktitle>
<contexts>
<context position="2274" citStr="Carroll and Fang, 2004" startWordPosition="323" endWordPosition="326">tive: [They]NP [distinguished]VP [the mast]NP [of [ships on the horizon ]NP ]PP . 1The verb similarity dataset used for the evaluation of our model is publicly available at ie.technion.ac.il/∼roiri/. (2) Indirect Transitive: [They]NP [distinguished]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both t</context>
</contexts>
<marker>Carroll, Fang, 2004</marker>
<rawString>John Carroll and Alex Fang. 2004. The automatic acquisition of verb subcategorisations and their impact on the performance of an HPSG parser. In Proceedings of IJCNLP-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula Chesley</author>
<author>Susanne Salmon-Alt</author>
</authors>
<title>Automatic extraction of subcategorization frames for french.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC-06.</booktitle>
<contexts>
<context position="3480" citStr="Chesley and Salmon-Alt, 2006" startWordPosition="517" endWordPosition="520">riation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervi</context>
</contexts>
<marker>Chesley, Salmon-Alt, 2006</marker>
<rawString>Paula Chesley and Susanne Salmon-Alt. 2006. Automatic extraction of subcategorization frames for french. In Proceedings of LREC-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kostadin Cholakov</author>
<author>Gertjan van Noord</author>
</authors>
<title>Using unknown word techniques to learn known words.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP-10.</booktitle>
<marker>Cholakov, van Noord, 2010</marker>
<rawString>Kostadin Cholakov and Gertjan van Noord. 2010. Using unknown word techniques to learn known words. In Proceedings of EMNLP-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay Cohen</author>
<author>Noah Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL-HLT-09.</booktitle>
<contexts>
<context position="10654" citStr="Cohen and Smith, 2009" startWordPosition="1647" endWordPosition="1650">stance-based analysis. Secondly, it addresses SCF induction as an unsupervised clustering problem, avoiding the use of supervised parsing or any of the sources of manual supervision used in previous works. Our system relies on POS tags - however, we show that it is not necessary to train a tagger with in-domain data to obtain good performance on this task, and therefore our approach provides a more domainindependent solution to SCF acquisition. We employ POS-tagging instead of unsupervised parsing for two main reasons. First, while a major progress has been made on unsupervised parsing (e.g. (Cohen and Smith, 2009; BergKirkpatrick et al., 2010)), the performance is still considerably behind that of supervised parsing. For example, the state-of-the-art discriminative model of (Berg-Kirkpatrick et al., 2010) achieves only 63% directed arc accuracy for WSJ sentences of up to 10 words, compared to more than 95% obtained with supervised parsers. Second, current unsupervised parsers produce unlabeled structures which are substantially less useful for SCF acquisition than labeled structures produced by supervised parsers (e.g. grammatical relations). Finally, a number of recent works addressed related tasks s</context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay Cohen and Noah Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proceedings of NAACL-HLT-09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De-Marneffe</author>
<author>Bill Maccartney</author>
<author>Christopher Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC-06.</booktitle>
<contexts>
<context position="7943" citStr="De-Marneffe et al., 2006" startWordPosition="1220" endWordPosition="1223">iss et al., 2007; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) and other languages, including French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Uzun et al., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss et al., 2007) and the BioLexicon system which was used to acquire a substantial lexicon for biomedicine (Venturi et al., 2009). These systems extract GRs at the verb instance level from the output of a parser: the RASP general-language unlexicalized parser3 (Briscoe et al., 2006) and the lexicalized Enju parser tuned to the biomedical domain (Miyao and Tsujii, 2005), respectively. They generate potential SCFs by mapping GRs to a predefined SCF inventory using a set of manually developed rules (the Cambridge system) or by</context>
</contexts>
<marker>De-Marneffe, Maccartney, Manning, 2006</marker>
<rawString>Marie-Catherine De-Marneffe, Bill Maccartney, and Christopher Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lukasz Debowski</author>
</authors>
<title>Valence extraction using EM selection and co-occurrence matrices. Proceedins of LREC-09.</title>
<date>2009</date>
<contexts>
<context position="3986" citStr="Debowski, 2009" startWordPosition="595" endWordPosition="597">Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Supervised parsers are notoriously sensitive to domain variation (Lease and Charniak, 2005). As annotation of data for each new domain is unrealistic, current SCF systems suffer from poor portability. This problem is compounded for the many systems that employ manually developed SCF rules because rules are inherently ignorant to domain-specific preferences. The few SCF studies that focused on specific domains (e.g. biomedicine) have reported poor performance due t</context>
<context position="9362" citStr="Debowski, 2009" startWordPosition="1439" endWordPosition="1440">otations. 279 is built through noisy frame filtering (based on frequencies or on external resources and annotations), which aims to remove errors from parsing and argument-adjunct distinction. Clearly, these systems require extensive manual work: a-priori definition of an SCF inventory and rules, manually annotated sentences for training a supervised parser, SCF annotations for parser lexicalization, and manually developed resources for optimal filtering. A number of recent works have applied modern machine learning techniques to SCF induction, including point-wise co-occurrence of arguments (Debowski, 2009), a Bayesian network model (Lippincott et al., 2012), multi-way tensor factorization (Van de Cruys et al., 2012) and Determinantal Point Processes (DPPs) -based clustering (Reichart and Korhonen, 2013). However, all of these systems induce type-level SCF lexicons and, except from the system of (Lippincott et al., 2012) that is not capable of learning traditional SCFs, they all rely on supervised parsers. Our new system differs from previous ones in a number of respects. First, in contrast to most previous systems, our system provides SCF analysis for each verb instance in its sentential contex</context>
</contexts>
<marker>Debowski, 2009</marker>
<rawString>Lukasz Debowski. 2009. Valence extraction using EM selection and co-occurrence matrices. Proceedins of LREC-09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Finkelstein</author>
<author>Evgeniy Gabrilovich</author>
<author>Yossi Matias</author>
<author>Ehud Rivlin</author>
<author>Zach Solan</author>
<author>Gadi Wolfman</author>
<author>Eitan Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2002</date>
<journal>ACM Transactions on Information Systems,</journal>
<pages>20--116</pages>
<contexts>
<context position="37110" citStr="Finkelstein et al., 2002" startWordPosition="6239" endWordPosition="6242">s than from the EC potentials. Yet, EC potentials do lead to an improvement of up to 1.5% in M-1 and up to 1.1% in V and are therefore responsible for up to 26.1% and 21.2% of the improvement over the type pre-clustering baseline in terms of M-1 and V, respectively. 4.2 Task Based Evaluation We next evaluate our model in the context of vector space modeling for verb similarity prediction (Turney and Pantel, 2010). Since most previous word similarity works used noun datasets, we constructed a new verb pair dataset, following the protocol used in the collection of the wordSimilarity353 dataset (Finkelstein et al., 2002). Our dataset consists of 143 verb pairs, constructed from 122 unique verb lemma types. The participating verbs appear ≥ 10 times in the concatenation of the labour legislation and the environment datasets. Only pairs of verbs that were considered at least remotely similar by human judges (independent of those that provided the similarity scores) were included. A similarity score between 1 and 10 was assigned to each pair by 10 native English speaking annotators and were then averaged in order to get a unique pair score. Our first baseline is a standard VSM based on lexical collocations. In th</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2002</marker>
<rawString>Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eitan Ruppin. 2002. Placing search in context: The concept revisited. ACM Transactions on Information Systems, 20:116–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Jon Orwant</author>
</authors>
<title>A dataset of syntactic-ngrams over time from a very large corpus of english books.</title>
<date>2013</date>
<booktitle>In Proceedings of (*SEM)-13. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="37913" citStr="Goldberg and Orwant, 2013" startWordPosition="6376" endWordPosition="6379">and the environment datasets. Only pairs of verbs that were considered at least remotely similar by human judges (independent of those that provided the similarity scores) were included. A similarity score between 1 and 10 was assigned to each pair by 10 native English speaking annotators and were then averaged in order to get a unique pair score. Our first baseline is a standard VSM based on lexical collocations. In this model features correspond to the number of collocations inside a size 2 window of the represented verb with each of the 5000 most frequent nouns in the Google n-gram corpus (Goldberg and Orwant, 2013). Since our corpora are limited in size, we use the collocation counts from the Google corpus. We used our model to generate a vector representation of each verb in the following way. We run the model 5000 times, each time over a set of verbs consisting of one instance of each of the 122 verb types participating in the verb similarity set. The output of each such run is transformed to a binary vector for each participating verb, where all coordinates are assigned the value of 0, except from the one that corresponds to the cluster to which the verb was assigned which has the value of 1. The fin</context>
</contexts>
<marker>Goldberg, Orwant, 2013</marker>
<rawString>Yoav Goldberg and Jon Orwant. 2013. A dataset of syntactic-ngrams over time from a very large corpus of english books. In Proceedings of (*SEM)-13. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Martin mejrek</author>
<author>Bonnie Dorr</author>
<author>Yuan Ding</author>
<author>Jason Eisner</author>
<author>Daniel Gildea</author>
<author>Terry Koo</author>
<author>Kristen Parton</author>
<author>Gerald Penn</author>
<author>Dragomir Radev</author>
<author>Owen Rambow</author>
</authors>
<title>Natural language generation in the context of machine translation.</title>
<date>2002</date>
<tech>Technical report,</tech>
<institution>Center for Language and Speech Processing, Johns Hopkins University, Baltimore. Summer Workshop Final Report.</institution>
<marker>Hajiˇc, mejrek, Dorr, Ding, Eisner, Gildea, Koo, Parton, Penn, Radev, Rambow, 2002</marker>
<rawString>Jan Hajiˇc, Martin mejrek, Bonnie Dorr, Yuan Ding, Jason Eisner, Daniel Gildea, Terry Koo, Kristen Parton, Gerald Penn, Dragomir Radev, and Owen Rambow. 2002. Natural language generation in the context of machine translation. Technical report, Center for Language and Speech Processing, Johns Hopkins University, Baltimore. Summer Workshop Final Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung hye Han</author>
<author>Benoit Lavoie</author>
<author>Martha Palmer</author>
<author>Owen Rambow</author>
<author>Richard Kittredge</author>
<author>Tanya Korelsky</author>
<author>Myunghee Kim</author>
</authors>
<title>Handling structural divergences and recovering dropped arguments in a korean/english machine translation system.</title>
<date>2000</date>
<booktitle>In Proceedings of the AMTA-00.</booktitle>
<contexts>
<context position="2516" citStr="Han et al., 2000" startWordPosition="361" endWordPosition="364">]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong</context>
</contexts>
<marker>Han, Lavoie, Palmer, Rambow, Kittredge, Korelsky, Kim, 2000</marker>
<rawString>Chung hye Han, Benoit Lavoie, Martha Palmer, Owen Rambow, Richard Kittredge, Tanya Korelsky, and Myunghee Kim. 2000. Handling structural divergences and recovering dropped arguments in a korean/english machine translation system. In Proceedings of the AMTA-00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dino Ienco</author>
<author>Serena Villata</author>
<author>Cristina Bosco</author>
</authors>
<title>Automatic extraction of subcategorization frames for italian.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC-08.</booktitle>
<contexts>
<context position="3500" citStr="Ienco et al., 2008" startWordPosition="521" endWordPosition="524">s themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-p</context>
</contexts>
<marker>Ienco, Villata, Bosco, 2008</marker>
<rawString>Dino Ienco, Serena Villata, and Cristina Bosco. 2008. Automatic extraction of subcategorization frames for italian. In Proceedings of LREC-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Extended constituent-to-dependency conversion for english.</title>
<date>2007</date>
<booktitle>In Proceedings of NODALIDA-07.</booktitle>
<contexts>
<context position="39461" citStr="Johansson and Nugues, 2007" startWordPosition="6651" endWordPosition="6654">. For our model we estimated the verb pair similarity using the Tanimato similarity score for binary vectors: � T (X, Y ) = i Xi ∧ Yi Ei xi ∨ Yi For the baseline model, where the features are collocation counts, we used the standard cosine similarity. Our second baseline is identical to our model, except that: (a) the data is parsed with the Stanford parser (version 3.3.0, (Klein and Manning, 2003)) which was trained with sections 2-21 of the WSJ corpus; (b) the phrase structure output of the parser is transformed to the CoNLL dependency format using the official CoNLL 2007 conversion script (Johansson and Nugues, 2007); and then (c) the SCF of each verb instance is inferred using the rule-based system used by (Reichart and Korhonen, 2013). The vector space representation for each verb is then created using the process we described for our model and the same holds for vector comparison. This baseline allows direct comparison of frames induced by our SCF model with those derived from a supervised parser’s output. We computed the Pearson correlation between the scores of each of the models and the human scores. The results demonstrate the superiority of our model in predicting verb similarity: the correlation </context>
</contexts>
<marker>Johansson, Nugues, 2007</marker>
<rawString>Richard Johansson and Pierre Nugues. 2007. Extended constituent-to-dependency conversion for english. In Proceedings of NODALIDA-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Acquiring reliable predicate-argument structures from raw corpora for case frame compilation.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC-10.</booktitle>
<contexts>
<context position="3613" citStr="Kawahara and Kurohashi, 2010" startWordPosition="540" endWordPosition="544">omain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Supervised parsers are notoriously sensitive to domain variation (Lease and Charniak, 2005). As</context>
<context position="7571" citStr="Kawahara and Kurohashi, 2010" startWordPosition="1158" endWordPosition="1161">elines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser. 2 Previous Work Several SCF acquisition systems are available for English (O’Donovan et al., 2005; Preiss et al., 2007; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) and other languages, including French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Uzun et al., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss et al., 2007) and the BioLexicon system which was used to acquire a substantial lexicon for biomedicine (Venturi et al., 2009). These systems extract GRs </context>
</contexts>
<marker>Kawahara, Kurohashi, 2010</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2010. Acquiring reliable predicate-argument structures from raw corpora for case frame compilation. In Proceedings of LREC-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL-03.</booktitle>
<contexts>
<context position="30095" citStr="Klein and Manning, 2003" startWordPosition="5070" endWordPosition="5073">otation, to the best of our knowledge). Second, in order to compare the output of our system to a rule-based SCF system that utilizes a supervised syntactic parser, we turn to a task-based evaluation. We aim to predict the degree of similarity between verb pairs and, following (Pado and Lapata, 2007) , we do so using a syntactic-based vector space model (VSM). We construct three VSMs - (a) one that derives features from our clusters; (b) one whose features come from the output of astate-of-the-art verb type level, rule based, SCF system (Reichart and Korhonen, 2013) that uses a modern parser (Klein and Manning, 2003); and (c) a standard lexical VSM. Below we show that our system compares favorably in both evaluations. Data. We experimented with two datasets taken from different domains: labor legislation and environment (Quochi et al., 2012). These datasets were created through web crawling followed by domain filtering. Each sentence in both datasets may contain multiple verbs but only one target verb has been manually annotated with a SCF. The labour legislation domain dataset contains 4415 annotated verb instances (an d hence also 284 sentences) of 117 types, and the environmental domain dataset contain</context>
<context position="39235" citStr="Klein and Manning, 2003" startWordPosition="6615" endWordPosition="6618"> did not use the graph cut algorithm to generate a final clustering from the multiple MRF 286 runs. Instead we concatenated the output of all these runs into one feature representation that facilitates similarity prediction. For our model we estimated the verb pair similarity using the Tanimato similarity score for binary vectors: � T (X, Y ) = i Xi ∧ Yi Ei xi ∨ Yi For the baseline model, where the features are collocation counts, we used the standard cosine similarity. Our second baseline is identical to our model, except that: (a) the data is parsed with the Stanford parser (version 3.3.0, (Klein and Manning, 2003)) which was trained with sections 2-21 of the WSJ corpus; (b) the phrase structure output of the parser is transformed to the CoNLL dependency format using the official CoNLL 2007 conversion script (Johansson and Nugues, 2007); and then (c) the SCF of each verb instance is inferred using the rule-based system used by (Reichart and Korhonen, 2013). The vector space representation for each verb is then created using the process we described for our model and the same holds for vector comparison. This baseline allows direct comparison of frames induced by our SCF model with those derived from a s</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daphne Koller</author>
<author>Nir Friedman</author>
</authors>
<title>Probabilistic graphical models: principles and techniques.</title>
<date>2009</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="12239" citStr="Koller and Friedman, 2009" startWordPosition="1894" endWordPosition="1897">evel. 3 Model We address SCF induction as an unsupervised verb instance clustering problem. Given a set of plain sentences, our algorithm aims to cluster the verb instances in its input into syntactic clusters that strongly correlate with SCFs. In this section we introduce a Markov Random Field (MRF) model for this task: Section 3.1 describes our model’s structure, components and objective; Section 3.2 describes the model potentials and the knowledge they encode; and Section 3.3 describes how clusters are induced from the model. 3.1 Model Structure We implement our model in the MRF framework (Koller and Friedman, 2009). This enables us to encode the two main sources of information that govern SCF selection in verb instances: (1) At the sentential context, the verbal syntactic frame is encoded through syntactic features. Verb instances with similar feature representations should therefore take the same syntactic frame; and (2) At the global context, per verb type SCF distributions tend to be Zipfian (Korhonen et al., 2000). Instances of the same verb type should therefore be biased to take the same syntactic frame. Given a collection of plain input sentences, we denote the number of verb instances in the col</context>
</contexts>
<marker>Koller, Friedman, 2009</marker>
<rawString>Daphne Koller and Nir Friedman. 2009. Probabilistic graphical models: principles and techniques. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Genevieve Gorrell</author>
<author>Diana McCarthy</author>
</authors>
<title>Statistical filtering and subcategorization frame acquisition.</title>
<date>2000</date>
<booktitle>In Proceedings of EMNLP-00.</booktitle>
<contexts>
<context position="2807" citStr="Korhonen et al., 2000" startWordPosition="408" endWordPosition="411">orization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooc</context>
<context position="12650" citStr="Korhonen et al., 2000" startWordPosition="1960" endWordPosition="1963"> the model potentials and the knowledge they encode; and Section 3.3 describes how clusters are induced from the model. 3.1 Model Structure We implement our model in the MRF framework (Koller and Friedman, 2009). This enables us to encode the two main sources of information that govern SCF selection in verb instances: (1) At the sentential context, the verbal syntactic frame is encoded through syntactic features. Verb instances with similar feature representations should therefore take the same syntactic frame; and (2) At the global context, per verb type SCF distributions tend to be Zipfian (Korhonen et al., 2000). Instances of the same verb type should therefore be biased to take the same syntactic frame. Given a collection of plain input sentences, we denote the number of verb instances in the collection with n, and the number of data-dependent equivalence classes (ECs) with K (see below for their definition), and define an undirected graphical model (MRF), G = (V, E, L). We define the vertex set as V = X U C, with X = {xi, ... , xn} consisting of one vertex for every verb instance in the input collection, and C = {c1 ... cK} consisting of one vertex for each data-dependent EC. The set of labels used</context>
</contexts>
<marker>Korhonen, Gorrell, McCarthy, 2000</marker>
<rawString>Anna Korhonen, Genevieve Gorrell, and Diana McCarthy. 2000. Statistical filtering and subcategorization frame acquisition. In Proceedings of EMNLP-00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
</authors>
<title>Semantically motivated subcategorization acquisition.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition.</booktitle>
<contexts>
<context position="3370" citStr="Korhonen, 2002" startWordPosition="501" endWordPosition="503">ial argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>Anna Korhonen. 2002. Semantically motivated subcategorization acquisition. In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Lang</author>
<author>Mirella Lapata</author>
</authors>
<title>Unsupervised semantic role induction via split-merge clustering.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL-11.</booktitle>
<contexts>
<context position="11316" citStr="Lang and Lapata, 2011" startWordPosition="1744" endWordPosition="1747">formance is still considerably behind that of supervised parsing. For example, the state-of-the-art discriminative model of (Berg-Kirkpatrick et al., 2010) achieves only 63% directed arc accuracy for WSJ sentences of up to 10 words, compared to more than 95% obtained with supervised parsers. Second, current unsupervised parsers produce unlabeled structures which are substantially less useful for SCF acquisition than labeled structures produced by supervised parsers (e.g. grammatical relations). Finally, a number of recent works addressed related tasks such as argument role clustering for SRL (Lang and Lapata, 2011a; Lang and Lapata, 2011b; Titvo and Klementiev, 2012) in an unsupervised manner. While these works differ from ours in the task (clustering arguments rather than verbs) and the level of supervision (applying a supervised parser), like us they analyze the verb argument structure at the instance level. 3 Model We address SCF induction as an unsupervised verb instance clustering problem. Given a set of plain sentences, our algorithm aims to cluster the verb instances in its input into syntactic clusters that strongly correlate with SCFs. In this section we introduce a Markov Random Field (MRF) m</context>
</contexts>
<marker>Lang, Lapata, 2011</marker>
<rawString>Joel Lang and Mirella Lapata. 2011a. Unsupervised semantic role induction via split-merge clustering. In Proceedings ofACL-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Lang</author>
<author>Mirella Lapata</author>
</authors>
<title>Unsupervised semantic role induction with graph partitioning.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP-11.</booktitle>
<contexts>
<context position="11316" citStr="Lang and Lapata, 2011" startWordPosition="1744" endWordPosition="1747">formance is still considerably behind that of supervised parsing. For example, the state-of-the-art discriminative model of (Berg-Kirkpatrick et al., 2010) achieves only 63% directed arc accuracy for WSJ sentences of up to 10 words, compared to more than 95% obtained with supervised parsers. Second, current unsupervised parsers produce unlabeled structures which are substantially less useful for SCF acquisition than labeled structures produced by supervised parsers (e.g. grammatical relations). Finally, a number of recent works addressed related tasks such as argument role clustering for SRL (Lang and Lapata, 2011a; Lang and Lapata, 2011b; Titvo and Klementiev, 2012) in an unsupervised manner. While these works differ from ours in the task (clustering arguments rather than verbs) and the level of supervision (applying a supervised parser), like us they analyze the verb argument structure at the instance level. 3 Model We address SCF induction as an unsupervised verb instance clustering problem. Given a set of plain sentences, our algorithm aims to cluster the verb instances in its input into syntactic clusters that strongly correlate with SCFs. In this section we introduce a Markov Random Field (MRF) m</context>
</contexts>
<marker>Lang, Lapata, 2011</marker>
<rawString>Joel Lang and Mirella Lapata. 2011b. Unsupervised semantic role induction with graph partitioning. In Proceedings of EMNLP-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Lease</author>
<author>Eugene Charniak</author>
</authors>
<title>Parsing biomedical literature.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP05.</booktitle>
<contexts>
<context position="4209" citStr="Lease and Charniak, 2005" startWordPosition="627" endWordPosition="630">Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Supervised parsers are notoriously sensitive to domain variation (Lease and Charniak, 2005). As annotation of data for each new domain is unrealistic, current SCF systems suffer from poor portability. This problem is compounded for the many systems that employ manually developed SCF rules because rules are inherently ignorant to domain-specific preferences. The few SCF studies that focused on specific domains (e.g. biomedicine) have reported poor performance due to these reasons (Rimell et al., 2013). Another limitation of most current SCF systems is that they produce a type-level SCF lexicon (i.e. a lexicon which lists, for a given predicate, different SCF types with their relative</context>
<context position="5852" citStr="Lease and Charniak, 2005" startWordPosition="884" endWordPosition="887">tic frames of distinguish provides only a weak signal to a sentence level NLP application that needs to infer the verbal argument structure of its input sentences. We propose a new unsupervised model for SCF induction which addresses these problems with existing systems. Our model does not use a parser or hand-written rules, only a part-of-speech (POS) tagger is utilizes in order to produce features for machine learning. While POS taggers are also sensitive to domain variation, they can be adapted to domains more easily than parsers because they require much smaller amounts of annotated data (Lease and Charniak, 2005; Ringger et al., 2007). However, as we demonstrate in our experiments, domain adaptation of POS tagging may not even be necessary to obtain good results on the SCF acquisition task. Our model, based on the Markov Random Field (MRF) framework, performs instance-based SCF learning. It encodes syntactic similarities among verb instances across different verb types (derived 2(Lippincott et al., 2012) does not use a parser, but the syntactic frames induced by the system do not capture sets of arguments for verbs, so are not SCFs in a traditional sense. from a lexical and POS-based feature represen</context>
</contexts>
<marker>Lease, Charniak, 2005</marker>
<rawString>Matthew Lease and Eugene Charniak. 2005. Parsing biomedical literature. In Proceedings of IJCNLP05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Lenci</author>
<author>Barbara Mcgillivray</author>
<author>Simonetta Montemagni</author>
<author>Vito Pirrelli</author>
</authors>
<title>Unsupervised acquisition of verb subcategorization frames from shallow-parsed corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC08.</booktitle>
<contexts>
<context position="3543" citStr="Lenci et al., 2008" startWordPosition="529" endWordPosition="532">epending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Supervised parsers are no</context>
<context position="7501" citStr="Lenci et al., 2008" startWordPosition="1148" endWordPosition="1151">mer evaluation, our model outperforms a number of strong baselines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser. 2 Previous Work Several SCF acquisition systems are available for English (O’Donovan et al., 2005; Preiss et al., 2007; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) and other languages, including French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Uzun et al., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss et al., 2007) and the BioLexicon system which was used to acquire a substantial lexi</context>
</contexts>
<marker>Lenci, Mcgillivray, Montemagni, Pirrelli, 2008</marker>
<rawString>Alessandro Lenci, Barbara Mcgillivray, Simonetta Montemagni, and Vito Pirrelli. 2008. Unsupervised acquisition of verb subcategorization frames from shallow-parsed corpora. In Proceedings of LREC08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English verb classes and alternations: A preliminary investigation.</title>
<date>1993</date>
<location>Chicago, IL.</location>
<contexts>
<context position="6754" citStr="Levin, 1993" startWordPosition="1034" endWordPosition="1035">es syntactic similarities among verb instances across different verb types (derived 2(Lippincott et al., 2012) does not use a parser, but the syntactic frames induced by the system do not capture sets of arguments for verbs, so are not SCFs in a traditional sense. from a lexical and POS-based feature representation of verb instances) as well as prior beliefs on the tendencies of specific instances of the same verb type to take the same SCF. We evaluate our model against corpora annotated with verb instance SCFs (Quochi et al., 2012). In addition, following the Levin verb clustering tradition (Levin, 1993) which ties verb meanings with their syntactic properties, we evaluate the semantic predictive power of our clusters. In the former evaluation, our model outperforms a number of strong baselines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser. 2 Previous Work Several SCF acquisition systems are available for English (O’Donovan et al., 2005; Preiss et al., 2007; Lippincott et al.,</context>
<context position="40456" citStr="Levin, 1993" startWordPosition="6822" endWordPosition="6823"> parser’s output. We computed the Pearson correlation between the scores of each of the models and the human scores. The results demonstrate the superiority of our model in predicting verb similarity: the correlation of our model with the human scores is 0.642 while the correlation of the lexical collocation baseline is 0.522 and that of the supervised parser baseline is only 0.266. The results indicate that in addition to their good alignment with SCFs, our clusters are also highly useful for verb meaning representation. This is in line with the verb clustering theory of the Levin tradition (Levin, 1993) which ties verb meaning with their syntactic properties. We consider this an intriguing direction of future work. 5 Conclusions We presented an MRF-based unsupervised model for SCF acquisition which produces verb instance level SCFs as output. As opposed to previous systems for the task, our model uses only a POS tagger, avoiding the need for a statistical parser or manually crafted rules. The model is particularly valuable for NLP tasks benefiting from SCFs that are applied across text domains, and for the many tasks that involve sentence-level processing. Our results show that the accuracy </context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English verb classes and alternations: A preliminary investigation. Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Lippincott</author>
<author>Anna Korhonen</author>
<author>Diarmuid Oseaghdha</author>
</authors>
<title>Exploring subdomain variation in biomedical language.</title>
<date>2010</date>
<journal>BMC Bioinformatics.</journal>
<contexts>
<context position="3059" citStr="Lippincott et al., 2010" startWordPosition="449" endWordPosition="452">lde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output </context>
</contexts>
<marker>Lippincott, Korhonen, Oseaghdha, 2010</marker>
<rawString>Tom Lippincott, Anna Korhonen, and Diarmuid Oseaghdha. 2010. Exploring subdomain variation in biomedical language. BMC Bioinformatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Lippincott</author>
<author>Aanna Korhonen</author>
<author>Diarmuid Oseaghdha</author>
</authors>
<title>Learning syntactic verb frames using graphical models.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL-12.</booktitle>
<contexts>
<context position="4011" citStr="Lippincott et al., 2012" startWordPosition="598" endWordPosition="601">007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Supervised parsers are notoriously sensitive to domain variation (Lease and Charniak, 2005). As annotation of data for each new domain is unrealistic, current SCF systems suffer from poor portability. This problem is compounded for the many systems that employ manually developed SCF rules because rules are inherently ignorant to domain-specific preferences. The few SCF studies that focused on specific domains (e.g. biomedicine) have reported poor performance due to these reasons (Rimell e</context>
<context position="6252" citStr="Lippincott et al., 2012" startWordPosition="945" endWordPosition="948">es for machine learning. While POS taggers are also sensitive to domain variation, they can be adapted to domains more easily than parsers because they require much smaller amounts of annotated data (Lease and Charniak, 2005; Ringger et al., 2007). However, as we demonstrate in our experiments, domain adaptation of POS tagging may not even be necessary to obtain good results on the SCF acquisition task. Our model, based on the Markov Random Field (MRF) framework, performs instance-based SCF learning. It encodes syntactic similarities among verb instances across different verb types (derived 2(Lippincott et al., 2012) does not use a parser, but the syntactic frames induced by the system do not capture sets of arguments for verbs, so are not SCFs in a traditional sense. from a lexical and POS-based feature representation of verb instances) as well as prior beliefs on the tendencies of specific instances of the same verb type to take the same SCF. We evaluate our model against corpora annotated with verb instance SCFs (Quochi et al., 2012). In addition, following the Levin verb clustering tradition (Levin, 1993) which ties verb meanings with their syntactic properties, we evaluate the semantic predictive pow</context>
<context position="9414" citStr="Lippincott et al., 2012" startWordPosition="1445" endWordPosition="1448">filtering (based on frequencies or on external resources and annotations), which aims to remove errors from parsing and argument-adjunct distinction. Clearly, these systems require extensive manual work: a-priori definition of an SCF inventory and rules, manually annotated sentences for training a supervised parser, SCF annotations for parser lexicalization, and manually developed resources for optimal filtering. A number of recent works have applied modern machine learning techniques to SCF induction, including point-wise co-occurrence of arguments (Debowski, 2009), a Bayesian network model (Lippincott et al., 2012), multi-way tensor factorization (Van de Cruys et al., 2012) and Determinantal Point Processes (DPPs) -based clustering (Reichart and Korhonen, 2013). However, all of these systems induce type-level SCF lexicons and, except from the system of (Lippincott et al., 2012) that is not capable of learning traditional SCFs, they all rely on supervised parsers. Our new system differs from previous ones in a number of respects. First, in contrast to most previous systems, our system provides SCF analysis for each verb instance in its sentential context, yielding more precise SCF information for systems</context>
</contexts>
<marker>Lippincott, Korhonen, Oseaghdha, 2012</marker>
<rawString>Tom Lippincott, Aanna Korhonen, and Diarmuid Oseaghdha. 2012. Learning syntactic verb frames using graphical models. In Proceedings of ACL-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05.</booktitle>
<contexts>
<context position="18347" citStr="McDonald et al., 2005" startWordPosition="2956" endWordPosition="2959">defined to be the concatenation of that verb’s basic feature representation with the basic representations of the words in a size 2 window around the represented verb. The final feature representation for the i-th verb instance in our dataset is therefore defined to be vi = [w_2, w_1, vbi, w+1, w+2], where w_k and w+k are the basic feature representations of the words in distance −k or +k from the i-th verb instance in its sentence, and vbi is the basic feature representation of that verb instance. Our basic feature representation is inspired from the feature representation of the MST parser (McDonald et al., 2005) except that in the parser the features represent a directed edge in the complete directed graph defined over the words in a sentence that is to be parsed, while our features are generated for word n-grams. Particularly, our feature set is a concatenation of two sets derived from the MST set described in Table 1 of (McDonald et al., 2005) in the following way: (1) In both sets the parent word in the parser’s set is replaced with the represented word; (2) In one set every child word in the parser’s set is replaced by the word to the left of the represented word and in the other set it is replac</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of ACL-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cedric Messiant</author>
<author>Anna Korhonen</author>
<author>Thierry Poibeau</author>
</authors>
<title>LexSchem: A large subcategorization lexicon for French verbs.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC-08.</booktitle>
<contexts>
<context position="3523" citStr="Messiant et al., 2008" startWordPosition="525" endWordPosition="528">ir probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Super</context>
</contexts>
<marker>Messiant, Korhonen, Poibeau, 2008</marker>
<rawString>Cedric Messiant, Anna Korhonen, and Thierry Poibeau. 2008. LexSchem: A large subcategorization lexicon for French verbs. In Proceedings of LREC-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cedric Messiant</author>
</authors>
<title>A subcategorization acquistion system for french verbs.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL08-SRW.</booktitle>
<contexts>
<context position="7471" citStr="Messiant, 2008" startWordPosition="1145" endWordPosition="1146">f our clusters. In the former evaluation, our model outperforms a number of strong baselines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser. 2 Previous Work Several SCF acquisition systems are available for English (O’Donovan et al., 2005; Preiss et al., 2007; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) and other languages, including French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Uzun et al., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss et al., 2007) and the BioLexicon system which was used</context>
</contexts>
<marker>Messiant, 2008</marker>
<rawString>Cedric Messiant. 2008. A subcategorization acquistion system for french verbs. In Proceedings of ACL08-SRW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Junichi Tsujii</author>
</authors>
<title>Probabilistic disambiguaton models for wide-coverage hpsg parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05.</booktitle>
<contexts>
<context position="8385" citStr="Miyao and Tsujii, 2005" startWordPosition="1290" endWordPosition="1293">s types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss et al., 2007) and the BioLexicon system which was used to acquire a substantial lexicon for biomedicine (Venturi et al., 2009). These systems extract GRs at the verb instance level from the output of a parser: the RASP general-language unlexicalized parser3 (Briscoe et al., 2006) and the lexicalized Enju parser tuned to the biomedical domain (Miyao and Tsujii, 2005), respectively. They generate potential SCFs by mapping GRs to a predefined SCF inventory using a set of manually developed rules (the Cambridge system) or by simply considering the sets of GRs including verbs in question as potential SCFs (BioLexicon). Finally, a type level lexicon 3A so-called unlexicalized parser is a parser trained without explicit SCF annotations. 279 is built through noisy frame filtering (based on frequencies or on external resources and annotations), which aims to remove errors from parsing and argument-adjunct distinction. Clearly, these systems require extensive manu</context>
</contexts>
<marker>Miyao, Tsujii, 2005</marker>
<rawString>Yusuke Miyao and Junichi Tsujii. 2005. Probabilistic disambiguaton models for wide-coverage hpsg parsing. In Proceedings of ACL-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Verb subcategorization kernels for automatic semantic labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition.</booktitle>
<contexts>
<context position="2403" citStr="Moschitti and Basili, 2005" startWordPosition="343" endWordPosition="346">evaluation of our model is publicly available at ie.technion.ac.il/∼roiri/. (2) Indirect Transitive: [They]NP [distinguished]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (</context>
</contexts>
<marker>Moschitti, Basili, 2005</marker>
<rawString>Alessandro Moschitti and Roberto Basili. 2005. Verb subcategorization kernels for automatic semantic labeling. In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruth O’Donovan</author>
<author>Michael Burke</author>
<author>Aoife Cahill</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Large-scale induction and evaluation of lexical resources from the penn-ii and penn-iii treebanks.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<pages>31--328</pages>
<marker>O’Donovan, Burke, Cahill, van Genabith, Way, 2005</marker>
<rawString>Ruth O’Donovan, Michael Burke, Aoife Cahill, Josef van Genabith, and Andy Way. 2005. Large-scale induction and evaluation of lexical resources from the penn-ii and penn-iii treebanks. Computational Linguistics, 31:328–365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pado</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<pages>33--161</pages>
<contexts>
<context position="29772" citStr="Pado and Lapata, 2007" startWordPosition="5015" endWordPosition="5018">comparison to previous work, is therefore challenging. We therefore evaluate our system in two ways. First, we compare its output, as well as the output of a number of clustering baselines, to the gold standard annotation of corpora from two different domains (the only publicly available ones with instance level SCF annotation, to the best of our knowledge). Second, in order to compare the output of our system to a rule-based SCF system that utilizes a supervised syntactic parser, we turn to a task-based evaluation. We aim to predict the degree of similarity between verb pairs and, following (Pado and Lapata, 2007) , we do so using a syntactic-based vector space model (VSM). We construct three VSMs - (a) one that derives features from our clusters; (b) one whose features come from the output of astate-of-the-art verb type level, rule based, SCF system (Reichart and Korhonen, 2013) that uses a modern parser (Klein and Manning, 2003); and (c) a standard lexical VSM. Below we show that our system compares favorably in both evaluations. Data. We experimented with two datasets taken from different domains: labor legislation and environment (Quochi et al., 2012). These datasets were created through web crawli</context>
</contexts>
<marker>Pado, Lapata, 2007</marker>
<rawString>Sebastian Pado and Mirella Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33:161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judita Preiss</author>
<author>Ted Briscoe</author>
<author>Anna Korhonen</author>
</authors>
<title>A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-07.</booktitle>
<contexts>
<context position="3392" citStr="Preiss et al., 2007" startWordPosition="504" endWordPosition="507">d positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lipp</context>
<context position="7334" citStr="Preiss et al., 2007" startWordPosition="1122" endWordPosition="1125">verb clustering tradition (Levin, 1993) which ties verb meanings with their syntactic properties, we evaluate the semantic predictive power of our clusters. In the former evaluation, our model outperforms a number of strong baselines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser. 2 Previous Work Several SCF acquisition systems are available for English (O’Donovan et al., 2005; Preiss et al., 2007; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) and other languages, including French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Uzun et al., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et a</context>
</contexts>
<marker>Preiss, Briscoe, Korhonen, 2007</marker>
<rawString>Judita Preiss, Ted Briscoe, and Anna Korhonen. 2007. A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora. In Proceedings of ACL-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valeria Quochi</author>
<author>Francesca Frontini</author>
<author>Roberto Bartolini</author>
<author>Olivier Hamon</author>
<author>Marc Poch</author>
<author>Muntsa Padr</author>
<author>Nuria Bel</author>
<author>Gregor Thurmair</author>
<author>Antonio Toral</author>
<author>Amir Kamram</author>
</authors>
<title>Third evaluation report. evaluation of panacea v3 and produced resources.</title>
<date>2012</date>
<tech>Technical report.</tech>
<contexts>
<context position="6680" citStr="Quochi et al., 2012" startWordPosition="1022" endWordPosition="1025">arkov Random Field (MRF) framework, performs instance-based SCF learning. It encodes syntactic similarities among verb instances across different verb types (derived 2(Lippincott et al., 2012) does not use a parser, but the syntactic frames induced by the system do not capture sets of arguments for verbs, so are not SCFs in a traditional sense. from a lexical and POS-based feature representation of verb instances) as well as prior beliefs on the tendencies of specific instances of the same verb type to take the same SCF. We evaluate our model against corpora annotated with verb instance SCFs (Quochi et al., 2012). In addition, following the Levin verb clustering tradition (Levin, 1993) which ties verb meanings with their syntactic properties, we evaluate the semantic predictive power of our clusters. In the former evaluation, our model outperforms a number of strong baselines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser. 2 Previous Work Several SCF acquisition systems are available fo</context>
<context position="30324" citStr="Quochi et al., 2012" startWordPosition="5106" endWordPosition="5109">similarity between verb pairs and, following (Pado and Lapata, 2007) , we do so using a syntactic-based vector space model (VSM). We construct three VSMs - (a) one that derives features from our clusters; (b) one whose features come from the output of astate-of-the-art verb type level, rule based, SCF system (Reichart and Korhonen, 2013) that uses a modern parser (Klein and Manning, 2003); and (c) a standard lexical VSM. Below we show that our system compares favorably in both evaluations. Data. We experimented with two datasets taken from different domains: labor legislation and environment (Quochi et al., 2012). These datasets were created through web crawling followed by domain filtering. Each sentence in both datasets may contain multiple verbs but only one target verb has been manually annotated with a SCF. The labour legislation domain dataset contains 4415 annotated verb instances (an d hence also 284 sentences) of 117 types, and the environmental domain dataset contains 4503 annotated verb instances of 116 types. In both datasets no verb type accounts for more than 4% of the instances and only up to 35 verb types account for 1% of the instances or more. The lexical difference between the corpo</context>
</contexts>
<marker>Quochi, Frontini, Bartolini, Hamon, Poch, Padr, Bel, Thurmair, Toral, Kamram, 2012</marker>
<rawString>Valeria Quochi, Francesca Frontini, Roberto Bartolini, Olivier Hamon, Marc Poch, Muntsa Padr, Nuria Bel, Gregor Thurmair, Antonio Toral, and Amir Kamram. 2012. Third evaluation report. evaluation of panacea v3 and produced resources. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Anna Korhonen</author>
</authors>
<title>Improved lexical acquisition through dpp-based verb clustering.</title>
<date>2013</date>
<booktitle>In Proceedings ofACL-13.</booktitle>
<contexts>
<context position="4068" citStr="Reichart and Korhonen, 2013" startWordPosition="608" endWordPosition="611"> al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statistical parsers. Even the handful of recent systems 278 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 278–289, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics that use modern machine learning techniques (Debowski, 2009; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Supervised parsers are notoriously sensitive to domain variation (Lease and Charniak, 2005). As annotation of data for each new domain is unrealistic, current SCF systems suffer from poor portability. This problem is compounded for the many systems that employ manually developed SCF rules because rules are inherently ignorant to domain-specific preferences. The few SCF studies that focused on specific domains (e.g. biomedicine) have reported poor performance due to these reasons (Rimell et al., 2013). Another limitation of most current SCF syst</context>
<context position="7416" citStr="Reichart and Korhonen, 2013" startWordPosition="1136" endWordPosition="1139">ir syntactic properties, we evaluate the semantic predictive power of our clusters. In the former evaluation, our model outperforms a number of strong baselines, including supervised and type-level ones, achieving an accuracy of up to 69.2%. In the latter evaluation a vector space model that utilized our induced SCFs substantially outperforms the output of a type-level SCF system that uses the fully trained Stanford parser. 2 Previous Work Several SCF acquisition systems are available for English (O’Donovan et al., 2005; Preiss et al., 2007; Lippincott et al., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) and other languages, including French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Uzun et al., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss</context>
<context position="9563" citStr="Reichart and Korhonen, 2013" startWordPosition="1467" endWordPosition="1470">ion. Clearly, these systems require extensive manual work: a-priori definition of an SCF inventory and rules, manually annotated sentences for training a supervised parser, SCF annotations for parser lexicalization, and manually developed resources for optimal filtering. A number of recent works have applied modern machine learning techniques to SCF induction, including point-wise co-occurrence of arguments (Debowski, 2009), a Bayesian network model (Lippincott et al., 2012), multi-way tensor factorization (Van de Cruys et al., 2012) and Determinantal Point Processes (DPPs) -based clustering (Reichart and Korhonen, 2013). However, all of these systems induce type-level SCF lexicons and, except from the system of (Lippincott et al., 2012) that is not capable of learning traditional SCFs, they all rely on supervised parsers. Our new system differs from previous ones in a number of respects. First, in contrast to most previous systems, our system provides SCF analysis for each verb instance in its sentential context, yielding more precise SCF information for systems benefiting from instance-based analysis. Secondly, it addresses SCF induction as an unsupervised clustering problem, avoiding the use of supervised </context>
<context position="30043" citStr="Reichart and Korhonen, 2013" startWordPosition="5061" endWordPosition="5064">only publicly available ones with instance level SCF annotation, to the best of our knowledge). Second, in order to compare the output of our system to a rule-based SCF system that utilizes a supervised syntactic parser, we turn to a task-based evaluation. We aim to predict the degree of similarity between verb pairs and, following (Pado and Lapata, 2007) , we do so using a syntactic-based vector space model (VSM). We construct three VSMs - (a) one that derives features from our clusters; (b) one whose features come from the output of astate-of-the-art verb type level, rule based, SCF system (Reichart and Korhonen, 2013) that uses a modern parser (Klein and Manning, 2003); and (c) a standard lexical VSM. Below we show that our system compares favorably in both evaluations. Data. We experimented with two datasets taken from different domains: labor legislation and environment (Quochi et al., 2012). These datasets were created through web crawling followed by domain filtering. Each sentence in both datasets may contain multiple verbs but only one target verb has been manually annotated with a SCF. The labour legislation domain dataset contains 4415 annotated verb instances (an d hence also 284 sentences) of 117</context>
<context position="39583" citStr="Reichart and Korhonen, 2013" startWordPosition="6672" endWordPosition="6676"> = i Xi ∧ Yi Ei xi ∨ Yi For the baseline model, where the features are collocation counts, we used the standard cosine similarity. Our second baseline is identical to our model, except that: (a) the data is parsed with the Stanford parser (version 3.3.0, (Klein and Manning, 2003)) which was trained with sections 2-21 of the WSJ corpus; (b) the phrase structure output of the parser is transformed to the CoNLL dependency format using the official CoNLL 2007 conversion script (Johansson and Nugues, 2007); and then (c) the SCF of each verb instance is inferred using the rule-based system used by (Reichart and Korhonen, 2013). The vector space representation for each verb is then created using the process we described for our model and the same holds for vector comparison. This baseline allows direct comparison of frames induced by our SCF model with those derived from a supervised parser’s output. We computed the Pearson correlation between the scores of each of the models and the human scores. The results demonstrate the superiority of our model in predicting verb similarity: the correlation of our model with the human scores is 0.642 while the correlation of the lexical collocation baseline is 0.522 and that of</context>
</contexts>
<marker>Reichart, Korhonen, 2013</marker>
<rawString>Roi Reichart and Anna Korhonen. 2013. Improved lexical acquisition through dpp-based verb clustering. In Proceedings ofACL-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Ari Rappoport</author>
</authors>
<title>The nvi clustering evaluation measure.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL-09.</booktitle>
<contexts>
<context position="33210" citStr="Reichart and Rappoport, 2009" startWordPosition="5575" endWordPosition="5578">asures and Baselines. We compare our system’s output to instance-level gold standard annotation. We use standard measures for clustering evaluation, one measure from each of the two leading measure types: the V measure (Rosenberg and Hirschberg, 2007), which is an information theoretic measure, and greedy many-toone accuracy, which is a mapping-based measure. For the latter, each induced cluster is first mapped to the gold SCF frame that annotates the highest number of verb instances this induced cluster also annotates and then a standard instance-level accuracy score is computed (see, e.g., (Reichart and Rappoport, 2009)). Both measures scale from 100 (perfect match with gold standard) to 0 (no match). As mentioned above, comparing the performance of our system with respect to a gold standard to the performance of previous type-level systems that used hand-crafted rules and/or supervised syntactic parsers would be challenging. We therefore compare our model to the following baselines: (a) The most frequent class (MFC) baseline which assigns all verb instances with the SCF that is the most frequent one in the gold standard annotation of the data; (b) The Random baseline which simply assigns every verb instance</context>
</contexts>
<marker>Reichart, Rappoport, 2009</marker>
<rawString>Roi Reichart and Ari Rappoport. 2009. The nvi clustering evaluation measure. In Proceedings of CoNLL-09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Gal Elidan</author>
<author>Ari Rappoport</author>
</authors>
<title>A diverse dirichlet process ensemble for unsupervised induction of syntactic categories.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING-12.</booktitle>
<contexts>
<context position="27063" citStr="Reichart et al., 2012" startWordPosition="4539" endWordPosition="4542">se to the MRF’s potential functions and then compute the approximate MAP solution of the resulted model using the MPLP algorithm. Noising was done by adding an c term to the lambda values described in section 3.2 7. This protocol results in a set of cluster (label) assignments for the involved verb instances, which we treat as an ensemble of experts from which a final, high quality, solution is to be induced. The basic idea in ensemble learning is that if several experts independently cluster together two verb instances, our belief that these verbs belong in the same cluster should increase. (Reichart et al., 2012) implemented this idea through the kway normalized cut clustering algorithm (Yu and Shi, 2003). Its input is an undirected graph Gˆ = (Vˆ, ˆE, Wˆ) where Vˆ is the set of vertexes, Eˆ is the set of edges and Wˆ is a non-negative and symmetric edge weight matrix. To apply this model to our task, we construct the input graph Gˆ from the labelings (frame assignments) contained in the ensemble. The graph vertexes Vˆ correspond to the verb instances and the (i, j)-th entry of the matrix Wˆ is the number of ensemble members that assign the same label to the i-th and j-th verb instances. For A, B ⊆ Vˆ</context>
</contexts>
<marker>Reichart, Elidan, Rappoport, 2012</marker>
<rawString>Roi Reichart, Gal Elidan, and Ari Rappoport. 2012. A diverse dirichlet process ensemble for unsupervised induction of syntactic categories. In Proceedings of COLING-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Rimell</author>
<author>Thomas Lippincott</author>
<author>Karin Verspoor</author>
<author>Helen Johnson</author>
<author>Anna Korhonen</author>
</authors>
<title>Acquisition and evaluation of verb subcategorization resources for biomedicine.</title>
<date>2013</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>46--228</pages>
<contexts>
<context position="3081" citStr="Rimell et al., 2013" startWordPosition="453" endWordPosition="456">en, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the grammatical dependency output of supervised statisti</context>
<context position="4623" citStr="Rimell et al., 2013" startWordPosition="692" endWordPosition="695">l., 2012; Van de Cruys et al., 2012; Reichart and Korhonen, 2013) use supervised parsers to pre-process the data2. Supervised parsers are notoriously sensitive to domain variation (Lease and Charniak, 2005). As annotation of data for each new domain is unrealistic, current SCF systems suffer from poor portability. This problem is compounded for the many systems that employ manually developed SCF rules because rules are inherently ignorant to domain-specific preferences. The few SCF studies that focused on specific domains (e.g. biomedicine) have reported poor performance due to these reasons (Rimell et al., 2013). Another limitation of most current SCF systems is that they produce a type-level SCF lexicon (i.e. a lexicon which lists, for a given predicate, different SCF types with their relative frequencies). Such a lexicon provides a useful high-level profile of the syntactic behavior of the predicate in question, but is less useful for downstream NLP tasks (e.g. information extraction, parsing, machine translation) that involve sentence processing and can therefore benefit from SCF information at instance level. Sentences (1)-(3) demonstrate this limitation - a prior distribution over the possible s</context>
</contexts>
<marker>Rimell, Lippincott, Verspoor, Johnson, Korhonen, 2013</marker>
<rawString>Laura Rimell, Thomas Lippincott, Karin Verspoor, Helen Johnson, and Anna Korhonen. 2013. Acquisition and evaluation of verb subcategorization resources for biomedicine. Journal of Biomedical Informatics, 46:228–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Ringger</author>
<author>Peter McClanahan</author>
<author>Robbie Haertel</author>
<author>George Busby</author>
<author>Marc Carmen</author>
<author>James Carroll</author>
<author>Kevin Seppi</author>
<author>Deryle Lonsdale</author>
</authors>
<title>Active learning for part-of-speech tagging: Accelerating corpus annotation.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-07 Linguistic Annotation Workshop.</booktitle>
<contexts>
<context position="5875" citStr="Ringger et al., 2007" startWordPosition="888" endWordPosition="891">provides only a weak signal to a sentence level NLP application that needs to infer the verbal argument structure of its input sentences. We propose a new unsupervised model for SCF induction which addresses these problems with existing systems. Our model does not use a parser or hand-written rules, only a part-of-speech (POS) tagger is utilizes in order to produce features for machine learning. While POS taggers are also sensitive to domain variation, they can be adapted to domains more easily than parsers because they require much smaller amounts of annotated data (Lease and Charniak, 2005; Ringger et al., 2007). However, as we demonstrate in our experiments, domain adaptation of POS tagging may not even be necessary to obtain good results on the SCF acquisition task. Our model, based on the Markov Random Field (MRF) framework, performs instance-based SCF learning. It encodes syntactic similarities among verb instances across different verb types (derived 2(Lippincott et al., 2012) does not use a parser, but the syntactic frames induced by the system do not capture sets of arguments for verbs, so are not SCFs in a traditional sense. from a lexical and POS-based feature representation of verb instance</context>
</contexts>
<marker>Ringger, McClanahan, Haertel, Busby, Carmen, Carroll, Seppi, Lonsdale, 2007</marker>
<rawString>Eric Ringger, Peter McClanahan, Robbie Haertel, George Busby, Marc Carmen, James Carroll, Kevin Seppi, and Deryle Lonsdale. 2007. Active learning for part-of-speech tagging: Accelerating corpus annotation. In Proceedings of the ACL-07 Linguistic Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Roland</author>
<author>Daniel Jurafsky</author>
</authors>
<title>subcategorization frequencies are affected by corpus choice.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL-98.</booktitle>
<contexts>
<context position="3034" citStr="Roland and Jurafsky, 1998" startWordPosition="445" endWordPosition="448"> clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF information is best acquired automatically. Existing data-driven SCF induction systems, however, do not port well between domains. Most existing systems rely on handwritten rules (Briscoe and Carroll, 1997; Korhonen, 2002; Preiss et al., 2007) or simple cooccurrence statistics (O’Donovan et al., 2005; Chesley and Salmon-Alt, 2006; Ienco et al., 2008; Messiant et al., 2008; Lenci et al., 2008; Altamirano and Alonso i Alemany, 2010; Kawahara and Kurohashi, 2010) applied to the gramm</context>
</contexts>
<marker>Roland, Jurafsky, 1998</marker>
<rawString>Douglas Roland and Daniel Jurafsky. 1998. subcategorization frequencies are affected by corpus choice. In Proceedings of ACL-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Rosenberg</author>
<author>Julia Hirschberg</author>
</authors>
<title>V measure: a conditional entropybased external cluster evaluation measure.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-07.</booktitle>
<contexts>
<context position="32832" citStr="Rosenberg and Hirschberg, 2007" startWordPosition="5515" endWordPosition="5518">ormance of each method. The number of repetitions was 40 and samples were drawn from a uniform distribution while still promising that the distribution of gold standard SCFs in each sample is identical to their distribution in the entire dataset. Before running this protocol, 5% of each corpus was kept as held-out data on which hyperparameter tuning was performed. Evaluation Measures and Baselines. We compare our system’s output to instance-level gold standard annotation. We use standard measures for clustering evaluation, one measure from each of the two leading measure types: the V measure (Rosenberg and Hirschberg, 2007), which is an information theoretic measure, and greedy many-toone accuracy, which is a mapping-based measure. For the latter, each induced cluster is first mapped to the gold SCF frame that annotates the highest number of verb instances this induced cluster also annotates and then a standard instance-level accuracy score is computed (see, e.g., (Reichart and Rappoport, 2009)). Both measures scale from 100 (perfect match with gold standard) to 0 (no match). As mentioned above, comparing the performance of our system with respect to a gold standard to the performance of previous type-level syst</context>
</contexts>
<marker>Rosenberg, Hirschberg, 2007</marker>
<rawString>Andrew Rosenberg and Julia Hirschberg. 2007. V measure: a conditional entropybased external cluster evaluation measure. In Proceedings of EMNLP-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Rush</author>
<author>Roi Reichart</author>
<author>Michael Collins</author>
<author>Amir Globerson</author>
</authors>
<title>Improved parsing and pos tagging using inter-sentence consistency constraints.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-12.</booktitle>
<contexts>
<context position="21856" citStr="Rush et al., 2012" startWordPosition="3590" endWordPosition="3593">st part of the algorithm generates an excessive number of clusters, and M was then tuned so that these clusters are merged to the desired number of clusters. The A function, used to measure the similarity between two verbs, is designed to bias the instances of the same verb type to have a higher similarity score. Algorithm 1 therefore tends to assign such instances to the same cluster. In our experiments that was always the case for this algorithm. High Cardinality Verb Sets Potentials. This set of potentials aims to bias larger sets of verb instances to share the same SCF. It is inspired by (Rush et al., 2012) who demonstrated, that syntactic structures that appear at the same syntactic context, in terms of the surrounding POS tags, tend to manifest similar syntactic behavior. While they demonstrated the usefulness of their method for dependency parsing and POS tagging, we implement it for higher level SCFs. We identified syntactic contexts that imply similar SCFs for verb instances appearing inside them. 5The values in practice are S = 0.43 for labour legislation and S = 0.38 for environment. 282 Algorithm 1 Verb instance pre-clustering algorithm. λˆ is the average λ score between the members of i</context>
</contexts>
<marker>Rush, Reichart, Collins, Globerson, 2012</marker>
<rawString>Alexander Rush, Roi Reichart, Michael Collins, and Amir Globerson. 2012. Improved parsing and pos tagging using inter-sentence consistency constraints. In Proceedings of EMNLP-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Experiments on the automatic induction of german semantic verb classes.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>2</issue>
<contexts>
<context position="2445" citStr="Walde, 2006" startWordPosition="351" endWordPosition="352">on.ac.il/∼roiri/. (2) Indirect Transitive: [They]NP [distinguished]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincot</context>
</contexts>
<marker>Walde, 2006</marker>
<rawString>Sabine Schulte im Walde. 2006. Experiments on the automatic induction of german semantic verb classes. Computational Linguistics, 32(2):159–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Solomon Shimony</author>
</authors>
<title>Finding the maps for belief networks is np-hard.</title>
<date>1994</date>
<journal>Artificial Intelligence,</journal>
<volume>68</volume>
<pages>310</pages>
<contexts>
<context position="16010" citStr="Shimony, 1994" startWordPosition="2562" endWordPosition="2563">s. They do so by assigning a −oc score to assignments where their argument vertexes take the same frame and a 0 otherwise. In the rest of this section we do not get back to this simple set of potentials. A graphical illustration of the model is given in Figure 1. Note that we could have selected a richer model structure, for example, by defining a similarity potential over all verb instance vertexes that share an equivalence class. However, as the figure demonstrates, even the structure of the pruned version of our model (see Section 3.3) usually contains cycles, which makes inference NPhard (Shimony, 1994). Our design choices aim to balance between the expressivity of the model and the complexity of inference. In Section 3.3 we describe the LP relaxation algorithm we use for inference. Figure 1: A graphical illustration of our model (after pruning, see Sec. 3.3) for twenty verb instances (|X |= 20), each represented with a black vertex, and two equivalence classes (ECs), each represented with a gray vertex (|C |= 2). Solid lines represent edges (and θi,j pairwise potentials) between verb instance vertexes. Dashed lines represent edges between verb instance vertexes and EC vertexes (φi,j pairwis</context>
<context position="25205" citStr="Shimony, 1994" startWordPosition="4228" endWordPosition="4229">on. Graph Pruning. The edge set of our model consists of an edge for every pair of verb instance vertexes and of the edges that connect verb instance vertexes and equivalence class vertexes. This results in a large tree-width graph which substantially complicates MRF inference. To alleviate this we prune all edges with a positive score lower than p+ and all edges with a negative score higher than p−, where p+ and p− are manually tuned hyperparametes 6. MAP Inference. For most reasonable values of p+ and p− our graph still contains cycles even after it is pruned, which makes inference NP-hard (Shimony, 1994). Yet, thanks to our choice of an edge-factorized model, there are various approximate inference algorithms suitable for our case. We applied the message passing algorithm for linear-programming (LP) relaxation of the MAP assignment (MPLP, (Sontag et al., 2008)). LP relaxation algorithms for the MAP problem define an upper bound on the original objective which takes the form of a linear program. Consequently, a minimum of this upper bound can be found using standard LP solvers or, more efficiently, using specialized message passing algorithms (Yanover et al., 2006). The MPLP algorithm describe</context>
</contexts>
<marker>Shimony, 1994</marker>
<rawString>Solomon Shimony. 1994. Finding the maps for belief networks is np-hard. Artificial Intelligence, 68:399– 310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Sontag</author>
<author>Talya Meltzer</author>
<author>Amir Globerson</author>
<author>Tommi Jaakkola</author>
<author>Yair Weiss</author>
</authors>
<title>Tightening lp relaxations for map using message passing.</title>
<date>2008</date>
<booktitle>In Proceedings of UAI-08.</booktitle>
<contexts>
<context position="25466" citStr="Sontag et al., 2008" startWordPosition="4265" endWordPosition="4268">plicates MRF inference. To alleviate this we prune all edges with a positive score lower than p+ and all edges with a negative score higher than p−, where p+ and p− are manually tuned hyperparametes 6. MAP Inference. For most reasonable values of p+ and p− our graph still contains cycles even after it is pruned, which makes inference NP-hard (Shimony, 1994). Yet, thanks to our choice of an edge-factorized model, there are various approximate inference algorithms suitable for our case. We applied the message passing algorithm for linear-programming (LP) relaxation of the MAP assignment (MPLP, (Sontag et al., 2008)). LP relaxation algorithms for the MAP problem define an upper bound on the original objective which takes the form of a linear program. Consequently, a minimum of this upper bound can be found using standard LP solvers or, more efficiently, using specialized message passing algorithms (Yanover et al., 2006). The MPLP algorithm described in (Sontag et al., 2008) is appealing in that it iteratively computes tighter upper bounds on the MAP objective (for details see their paper). Cluster Ensemble Generation and a Final Solution. As our MAP objective is non-convex, 6The values used in practice a</context>
</contexts>
<marker>Sontag, Meltzer, Globerson, Jaakkola, Weiss, 2008</marker>
<rawString>David Sontag, Talya Meltzer, Amir Globerson, Tommi Jaakkola, and Yair Weiss. 2008. Tightening lp relaxations for map using message passing. In Proceedings of UAI-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Hierarchical verb clustering using graph factorization.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP-11.</booktitle>
<contexts>
<context position="2470" citStr="Sun and Korhonen, 2011" startWordPosition="353" endWordPosition="356">ri/. (2) Indirect Transitive: [They]NP [distinguished]VP [between [me and you]ADVP ]PP . (3) Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et</context>
</contexts>
<marker>Sun, Korhonen, 2011</marker>
<rawString>Lin Sun and Anna Korhonen. 2011. Hierarchical verb clustering using graph factorization. In Proceedings of EMNLP-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titvo</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A bayesian approach to unsupervised semantic role induction.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-12.</booktitle>
<contexts>
<context position="11370" citStr="Titvo and Klementiev, 2012" startWordPosition="1752" endWordPosition="1755">pervised parsing. For example, the state-of-the-art discriminative model of (Berg-Kirkpatrick et al., 2010) achieves only 63% directed arc accuracy for WSJ sentences of up to 10 words, compared to more than 95% obtained with supervised parsers. Second, current unsupervised parsers produce unlabeled structures which are substantially less useful for SCF acquisition than labeled structures produced by supervised parsers (e.g. grammatical relations). Finally, a number of recent works addressed related tasks such as argument role clustering for SRL (Lang and Lapata, 2011a; Lang and Lapata, 2011b; Titvo and Klementiev, 2012) in an unsupervised manner. While these works differ from ours in the task (clustering arguments rather than verbs) and the level of supervision (applying a supervised parser), like us they analyze the verb argument structure at the instance level. 3 Model We address SCF induction as an unsupervised verb instance clustering problem. Given a set of plain sentences, our algorithm aims to cluster the verb instances in its input into syntactic clusters that strongly correlate with SCFs. In this section we introduce a Markov Random Field (MRF) model for this task: Section 3.1 describes our model’s </context>
</contexts>
<marker>Titvo, Klementiev, 2012</marker>
<rawString>Ivan Titvo and Alexandre Klementiev. 2012. A bayesian approach to unsupervised semantic role induction. In Proceedings of EMNLP-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-03.</booktitle>
<contexts>
<context position="31781" citStr="Toutanova et al., 2003" startWordPosition="5345" endWordPosition="5348">ent types (responsible for 37.9% and 46.85% of the verb instances in the respective domains) of each corpus. The 29 members of the SCF inventory are detailed in (Quochi et al., 2012). Table 2, presenting the distribution of the 5 highest frequency frames in each corpus, demonstrates that, in addition to the significant lexical difference, the corpora differ to some extent in their syntactic properties. This is reflected by the substantially different frequencies of the ”dobj:iobj-prep:su” and ”dobj:su” frames. As a pre-processing step we first POS tagged the datasets with the Stanford tagger (Toutanova et al., 2003) trained on the standard POS training sections of the WSJ PennTreebank corpus. 4.1 Evaluation Against SCF Gold Standard Experimental Protocol The computational complexity of our algorithm does not allow us to run it on thousands of verb instances in a feasible time. We therefore repeatedly sampled 5% of the sentences from each dataset, ran our algorithm as well as the baselines (see below) and report the average performance of each method. The number of repetitions was 40 and samples were drawn from a uniform distribution while still promising that the distribution of gold standard SCFs in eac</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of NAACL-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of artificial intelligence research,</journal>
<pages>37--141</pages>
<contexts>
<context position="36901" citStr="Turney and Pantel, 2010" startWordPosition="6205" endWordPosition="6208">n and Random: random SCF assignment) and the model components. The full model outperforms all other models across measures and datasets. from the type level information encoded through the singleton potentials than from the EC potentials. Yet, EC potentials do lead to an improvement of up to 1.5% in M-1 and up to 1.1% in V and are therefore responsible for up to 26.1% and 21.2% of the improvement over the type pre-clustering baseline in terms of M-1 and V, respectively. 4.2 Task Based Evaluation We next evaluate our model in the context of vector space modeling for verb similarity prediction (Turney and Pantel, 2010). Since most previous word similarity works used noun datasets, we constructed a new verb pair dataset, following the protocol used in the collection of the wordSimilarity353 dataset (Finkelstein et al., 2002). Our dataset consists of 143 verb pairs, constructed from 122 unique verb lemma types. The participating verbs appear ≥ 10 times in the concatenation of the labour legislation and the environment datasets. Only pairs of verbs that were considered at least remotely similar by human judges (independent of those that provided the similarity scores) were included. A similarity score between </context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of artificial intelligence research, 37:141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Van de Cruys</author>
<author>Laura Rimell</author>
<author>Thierry Poibeau</author>
<author>Anna Korhonen</author>
</authors>
<title>Multi-way tensor factorization for unsupervised lexical acquisition.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING-12.</booktitle>
<marker>Van de Cruys, Rimell, Poibeau, Korhonen, 2012</marker>
<rawString>Tim Van de Cruys, Laura Rimell, Thierry Poibeau, and Anna Korhonen. 2012. Multi-way tensor factorization for unsupervised lexical acquisition. In Proceedings of COLING-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giulia Venturi</author>
<author>Simonetta Montemagni</author>
<author>Simone Marchi</author>
<author>Yutaka Sasaki</author>
<author>Paul Thompson</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Bootstrapping a verb lexicon for biomedical information extraction.</title>
<date>2009</date>
<booktitle>Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>5449--137</pages>
<contexts>
<context position="8143" citStr="Venturi et al., 2009" startWordPosition="1251" endWordPosition="1254">., 2008), Japanese (Kawahara and Kurohashi, 2010) and Chinese (Han et al., 2008). The prominent input to these systems are grammatical relations (GRs) which express binary dependencies between words (e.g. direct and indirect objects, various types of complements and conjunctions). These are generated by some parsers (e.g. (Briscoe et al., 2006)) and can be extracted from the output of others (De-Marneffe et al., 2006). Two representative systems for English are the Cambridge system (Preiss et al., 2007) and the BioLexicon system which was used to acquire a substantial lexicon for biomedicine (Venturi et al., 2009). These systems extract GRs at the verb instance level from the output of a parser: the RASP general-language unlexicalized parser3 (Briscoe et al., 2006) and the lexicalized Enju parser tuned to the biomedical domain (Miyao and Tsujii, 2005), respectively. They generate potential SCFs by mapping GRs to a predefined SCF inventory using a set of manually developed rules (the Cambridge system) or by simply considering the sets of GRs including verbs in question as potential SCFs (BioLexicon). Finally, a type level lexicon 3A so-called unlexicalized parser is a parser trained without explicit SCF</context>
</contexts>
<marker>Venturi, Montemagni, Marchi, Sasaki, Thompson, McNaught, Ananiadou, 2009</marker>
<rawString>Giulia Venturi, Simonetta Montemagni, Simone Marchi, Yutaka Sasaki, Paul Thompson, John McNaught, and Sophia Ananiadou. 2009. Bootstrapping a verb lexicon for biomedical information extraction. Computational Linguistics and Intelligent Text Processing, 5449:137–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marion Weller</author>
<author>Alexander Fraser</author>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Using subcategorization knowledge to improve case prediction for translation to german.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL-13.</booktitle>
<contexts>
<context position="2559" citStr="Weller et al., 2013" startWordPosition="369" endWordPosition="372"> Ditransitive: [They]NP [distinguished]VP [him]NP [from [the other boys]NP ]PP. As SCFs describe the syntactic realization of the verbal predicate-argument structure, they are highly valuable for a variety of NLP tasks. For example, verb subcategorization information has proven useful for tasks such as parsing (Carroll and Fang, 2004; Arun and Keller, 2005; Cholakov and van Noord, 2010), semantic role labeling (Bharati et al., 2005; Moschitti and Basili, 2005), verb clustering, (Schulte im Walde, 2006; Sun and Korhonen, 2011) and machine translation (hye Han et al., 2000; Hajiˇc et al., 2002; Weller et al., 2013). SCF induction is challenging. The argumentadjunct distinction is difficult even for humans, and is further complicated by the fact that both arguments and adjuncts can appear frequently in potential argument head positions (Korhonen et al., 2000). SCFs are also highly sensitive to domain variation so that both the frames themselves and their probabilities vary depending on the meaning and behavior of predicates in the domain in question (e.g. (Roland and Jurafsky, 1998; Lippincott et al., 2010; Rimell et al., 2013), Section 4). Because of the strong impact of domain variation, SCF informatio</context>
</contexts>
<marker>Weller, Fraser, Walde, 2013</marker>
<rawString>Marion Weller, Alexander Fraser, and Sabine Schulte im Walde. 2013. Using subcategorization knowledge to improve case prediction for translation to german. In Proceedings of ACL-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yanover</author>
<author>Talya Meltzer</author>
<author>Yair Weiss</author>
</authors>
<title>Linear programming relazations and belief propogataion an empitical study.</title>
<date>2006</date>
<journal>JMLR Special Issue on Machine Learning and Large Scale Optimization.</journal>
<contexts>
<context position="25776" citStr="Yanover et al., 2006" startWordPosition="4316" endWordPosition="4319">ned, which makes inference NP-hard (Shimony, 1994). Yet, thanks to our choice of an edge-factorized model, there are various approximate inference algorithms suitable for our case. We applied the message passing algorithm for linear-programming (LP) relaxation of the MAP assignment (MPLP, (Sontag et al., 2008)). LP relaxation algorithms for the MAP problem define an upper bound on the original objective which takes the form of a linear program. Consequently, a minimum of this upper bound can be found using standard LP solvers or, more efficiently, using specialized message passing algorithms (Yanover et al., 2006). The MPLP algorithm described in (Sontag et al., 2008) is appealing in that it iteratively computes tighter upper bounds on the MAP objective (for details see their paper). Cluster Ensemble Generation and a Final Solution. As our MAP objective is non-convex, 6The values used in practice are p+ = 0.28, p_ = −0.17 for the labour legislation dataset, and p+ = 0.25, p_ = −0.20 for the environment set. 283 the convergent point of an optimization algorithm applied to it is highly sensitive to its initialization. To avoid convergence to arbitrary local maxima which may be of poor quality, we turn to</context>
</contexts>
<marker>Yanover, Meltzer, Weiss, 2006</marker>
<rawString>Chen Yanover, Talya Meltzer, and Yair Weiss. 2006. Linear programming relazations and belief propogataion an empitical study. JMLR Special Issue on Machine Learning and Large Scale Optimization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stella Yu</author>
<author>Jianbo Shi</author>
</authors>
<title>Multiclass spectral clustering.</title>
<date>2003</date>
<booktitle>In Proceedings of ICCV-13.</booktitle>
<contexts>
<context position="27157" citStr="Yu and Shi, 2003" startWordPosition="4554" endWordPosition="4557">odel using the MPLP algorithm. Noising was done by adding an c term to the lambda values described in section 3.2 7. This protocol results in a set of cluster (label) assignments for the involved verb instances, which we treat as an ensemble of experts from which a final, high quality, solution is to be induced. The basic idea in ensemble learning is that if several experts independently cluster together two verb instances, our belief that these verbs belong in the same cluster should increase. (Reichart et al., 2012) implemented this idea through the kway normalized cut clustering algorithm (Yu and Shi, 2003). Its input is an undirected graph Gˆ = (Vˆ, ˆE, Wˆ) where Vˆ is the set of vertexes, Eˆ is the set of edges and Wˆ is a non-negative and symmetric edge weight matrix. To apply this model to our task, we construct the input graph Gˆ from the labelings (frame assignments) contained in the ensemble. The graph vertexes Vˆ correspond to the verb instances and the (i, j)-th entry of the matrix Wˆ is the number of ensemble members that assign the same label to the i-th and j-th verb instances. For A, B ⊆ Vˆ define: ing by ˆcij. Then = argmin c∗ ˆciE Cˆ eigenvalues an d eigenvectors computations requ</context>
<context position="28628" citStr="Yu and Shi, 2003" startWordPosition="4828" endWordPosition="4831">it to 1% of vj). This value was tuned, without access to gold standard manual annotations, so that there is an even number of negative an cos(vi, d positive pairwise syntactic similarity potentials after the model is pruned (Section 3.3). links(A, Vˆ) Using this definition, the normalized link ratio The k-way normalized cut problem is to minimize the links that leave a cluster relative to the total weight of the cluster. Denote the set of clus7e was accepted by first sampling a number in the [0, 1] range using the Java psuodorandom generator and then scalNormLinkRatio( ˆcij, The algorithm of (Yu and Shi, 2003) solves this problem very efficiently as it avoids the heavy 4 Experiments and Results Our model is unique compared to existing systems in two respects. First, it does not utilize supervision in the form of either a supervised syntactic parser and/or manually crafted SCF rules. Consequently, it induces unnamed frames (clusters) that are not directly comparable to the named frames induced by previous systems. Second, it induces syntactic frames at the verb instance, rather than type, level. Evaluation, and especially comparison to previous work, is therefore challenging. We therefore evaluate o</context>
</contexts>
<marker>Yu, Shi, 2003</marker>
<rawString>Stella Yu and Jianbo Shi. 2003. Multiclass spectral clustering. In Proceedings of ICCV-13.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>