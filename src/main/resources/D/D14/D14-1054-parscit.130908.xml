<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.9993255">
A Joint Segmentation and Classification Framework
for Sentiment Analysis
</title>
<author confidence="0.998157">
Duyu Tang\∗, Furu Wei‡, Bing Qin\, Li Dong]∗, Ting Liu\, Ming Zhou‡
</author>
<affiliation confidence="0.90379575">
\Research Center for Social Computing and Information Retrieval,
Harbin Institute of Technology, China
‡Microsoft Research, Beijing, China
]Beihang University, Beijing, China
</affiliation>
<email confidence="0.913877">
\1dytang, qinb, tliu}@ir.hit.edu.cn
‡1fuwei, mingzhou}@microsoft.com ]donglixp@gmail.com
</email>
<sectionHeader confidence="0.997336" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999949275862069">
In this paper, we propose a joint segmenta-
tion and classification framework for sen-
timent analysis. Existing sentiment clas-
sification algorithms typically split a sen-
tence as a word sequence, which does not
effectively handle the inconsistent senti-
ment polarity between a phrase and the
words it contains, such as “not bad” and
“a great deal of”. We address this issue
by developing a joint segmentation and
classification framework (JSC), which si-
multaneously conducts sentence segmen-
tation and sentence-level sentiment classi-
fication. Specifically, we use a log-linear
model to score each segmentation candi-
date, and exploit the phrasal information
of top-ranked segmentations as features to
build the sentiment classifier. A marginal
log-likelihood objective function is de-
vised for the segmentation model, which
is optimized for enhancing the sentiment
classification performance. The joint mod-
el is trained only based on the annotat-
ed sentiment polarity of sentences, with-
out any segmentation annotations. Experi-
ments on a benchmark Twitter sentimen-
t classification dataset in SemEval 2013
show that, our joint model performs com-
parably with the state-of-the-art methods.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998486734693877">
Sentiment classification, which classifies the senti-
ment polarity of a sentence (or document) as posi-
tive or negative, is a major research direction in the
field of sentiment analysis (Pang and Lee, 2008;
Liu, 2012; Feldman, 2013). Majority of existing
approaches follow Pang et al. (2002) and treat sen-
∗ This work was partly done when the first and fourth
authors were visiting Microsoft Research.
timent classification as a special case of text cate-
gorization task. Under this perspective, previous
studies typically use pipelined methods with two
steps. They first produce sentence segmentation-
s with separate text analyzers (Choi and Cardie,
2008; Nakagawa et al., 2010; Socher et al., 2013b)
or bag-of-words (Paltoglou and Thelwall, 2010;
Maas et al., 2011). Then, feature learning and sen-
timent classification algorithms take the segmenta-
tion results as inputs to build the sentiment classi-
fier (Socher et al., 2011; Kalchbrenner et al., 2014;
Dong et al., 2014).
The major disadvantage of a pipelined method
is the problem of error propagation, since sen-
tence segmentation errors cannot be corrected by
the sentiment classification model. A typical kind
of error is caused by the polarity inconsistency be-
tween a phrase and the words it contains, such
as (not bad, bad) and (a great deal of, great).
The segmentations based on bag-of-words or syn-
tactic chunkers are not effective enough to han-
dle the polarity inconsistency phenomenons. The
reason lies in that bag-of-words segmentations re-
gard each word as a separate unit, which losses
the word order and does not capture the phrasal
information. The segmentations based on syntac-
tic chunkers typically aim to identify noun group-
s, verb groups or named entities from a sentence.
However, many sentiment indicators are phrases
constituted of adjectives, negations, adverbs or id-
ioms (Liu, 2012; Mohammad et al., 2013a), which
are splitted by syntactic chunkers. Besides, a bet-
ter approach would be to utilize the sentiment in-
formation to improve the segmentor. Accordingly,
the sentiment-specific segmentor will enhance the
performance of sentiment classification in turn.
In this paper, we propose a joint segmentation
and classification framework (JSC) for sentimen-
t analysis, which simultaneous conducts sentence
segmentation and sentence-level sentiment clas-
sification. The framework is illustrated in Fig-
</bodyText>
<page confidence="0.976215">
477
</page>
<note confidence="0.9473865">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 477–487,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figure confidence="0.99760621875">
that is not bad
that is not bad that is not bad
that is not bad
that is not bad
Polarity: +1
Input
CG
Segmentations
SC
Polarity Update
-1
-1
+1
+1
&lt;+1,-1&gt; NO
&lt;+1,-1&gt; NO
&lt;+1,+1&gt; YES
&lt;+1,+1&gt; YES
SEG
Rank
SEG
0.6
0.4
2.3
1.6
Update
0.6
0.4
2.3
1.6
SC
Top K
</figure>
<figureCaption confidence="0.866853">
Figure 1: The joint segmentation and classification framework (JSC) for sentiment classification. CG
represents the candidate generation model, SC means the sentiment classification model and SEG stands
for the segmentation ranking model. Down Arrow means the use of a specified model, and Up Arrow
indicates the update of a model.
</figureCaption>
<bodyText confidence="0.99716968">
ure 1. We develop (1) a candidate generation mod-
el to generate the segmentation candidates of a
sentence, (2) a segmentation ranking model to s-
core each segmentation candidate of a given sen-
tence, and (3) a classification model to predic-
t the sentiment polarity of each segmentation. The
phrasal information of top-ranked candidates from
the segmentation model are utilized as features to
build the sentiment classifier. In turn, the predict-
ed sentiment polarity of segmentation candidates
from classification model are leveraged to update
the segmentor. We score each segmentation can-
didate with a log-linear model, and optimize the
segmentor with a marginal log-likelihood objec-
tive. We train the joint model from sentences an-
notated only with sentiment polarity, without any
segmentation annotations.
We evaluate the effectiveness of our joint mod-
el on a benchmark Twitter sentiment classifica-
tion dataset in SemEval 2013. Results show that
the joint model performs comparably with state-
of-the-art methods, and consistently outperforms
pipeline methods in various experiment settings.
The main contributions of the work presented in
this paper are as follows.
</bodyText>
<listItem confidence="0.99630575">
• To our knowledge, this is the first work that
automatically produces sentence segmenta-
tion for sentiment classification within a joint
framework.
• We show that the joint model yields com-
parable performance with the state-of-the-art
methods on the benchmark Twitter sentiment
classification datasets in SemEval 2013.
</listItem>
<sectionHeader confidence="0.999662" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999886757575758">
Existing approaches for sentiment classification
are dominated by two mainstream directions.
Lexicon-based approaches (Turney, 2002; Ding
et al., 2008; Taboada et al., 2011; Thelwall et
al., 2012) typically utilize a lexicon of sentiment
words, each of which is annotated with the sen-
timent polarity or sentiment strength. Linguis-
tic rules such as intensifications and negations are
usually incorporated to aggregate the sentimen-
t polarity of sentences (or documents). Corpus-
based methods treat sentiment classification as a
special case of text categorization task (Pang et al.,
2002). They mostly build the sentiment classifier
from sentences (or documents) with manually an-
notated sentiment polarity or distantly-supervised
corpora collected by sentiment signals like emoti-
cons (Go et al., 2009; Pak and Paroubek, 2010;
Kouloumpis et al., 2011; Zhao et al., 2012).
Majority of existing approaches follow Pang et
al. (2002) and employ corpus-based method for
sentiment classification. Pang et al. (2002) pi-
oneer to treat the sentiment classification of re-
views as a special case of text categorization prob-
lem and first investigate machine learning meth-
ods. They employ Naive Bayes, Maximum En-
tropy and Support Vector Machines (SVM) with a
diverse set of features. In their experiments, the
best performance is achieved by SVM with bag-
of-words feature. Under this perspective, many s-
tudies focus on designing or learning effective fea-
tures to obtain better classification performance.
On movie or product reviews, Wang and Man-
ning (2012) present NBSVM, which trades-off
</bodyText>
<page confidence="0.998062">
478
</page>
<bodyText confidence="0.999954739130435">
between Naive Bayes and NB-feature enhanced
SVM. Kim and Zhai (2009) and Paltoglou and
Thelwall (2010) learn the feature weights by in-
vestigating variants weighting functions from In-
formation Retrieval. Nakagawa et al. (2010) uti-
lize dependency trees, polarity-shifting rules and
conditional random fields (Lafferty et al., 2001)
with hidden variables to compute the documen-
t feature. On Twitter, Mohammad et al. (2013b)
develop a state-of-the-art Twitter sentiment classi-
fier in SemEval 2013, using a variety of sentiment
lexicons and hand-crafted features.
With the revival of deep learning (representa-
tion learning (Hinton and Salakhutdinov, 2006;
Bengio et al., 2013; Jones, 2014)), more recen-
t studies focus on learning the low-dimensional,
dense and real-valued vector as text features for
sentiment classification. Glorot et al. (2011) inves-
tigate Stacked Denoising Autoencoders to learn
document vector for domain adaptation in sen-
timent classification. Yessenalina and Cardie
(2011) represent each word as a matrix and
compose words using iterated matrix multipli-
cation. Socher et al. propose Recursive Au-
toencoder (RAE) (2011), Matrix-Vector Recursive
Neural Network (MV-RNN) (2012) and Recur-
sive Neural Tensor Network (RNTN) (2013b) to
learn the composition of variable-length phrases
based on the representation of its children. To
learn the sentence representation, Kalchbrenner et
al. (2014) exploit Dynamic Convolutional Neu-
ral Network and Le and Mikolov (2014) inves-
tigate Paragraph Vector. To learn word vectors
for sentiment analysis, Maas et al. (2011) propose
a probabilistic document model following Blei et
al. (2003), Labutov and Lipson (2013) re-embed
words from existing word embeddings and Tang
et al. (2014b) develop three neural networks to
learn word vectors from tweets containing posi-
tive/negative emoticons.
Unlike most previous corpus-based algorithms
that build sentiment classifier based on splitting a
sentence as a word sequence, we produce sentence
segmentations automatically within a joint frame-
work, and conduct sentiment classification based
on the segmentation results.
</bodyText>
<sectionHeader confidence="0.993321" genericHeader="method">
3 The Proposed Approach
</sectionHeader>
<bodyText confidence="0.999945444444444">
In this section, we first give the task definition
of two tasks, namely sentiment classification and
sentence segmentation. Then, we present the
overview of the proposed joint segmentation and
classification model (JSC) for sentiment analysis.
The segmentation candidate generation model and
the segmentation ranking model are described in
Section 4. The details of the sentiment classifica-
tion model are presented in Section 5.
</bodyText>
<subsectionHeader confidence="0.998811">
3.1 Task Definition
</subsectionHeader>
<bodyText confidence="0.999872692307692">
The task of sentiment classification has been well
formalized in previous studies (Pang and Lee,
2008; Liu, 2012). The objective is to identify the
sentiment polarity of a sentence (or document) as
positive or negative 1.
The task of sentence segmentation aims to s-
plit a sentence into a sequence of exclusive part-
s, each of which is a basic computational unit of
the sentence. An example is illustrated in Table 1.
The original text “that is not bad” is segmented
as “[that] [is] [not bad]”. The segmentation re-
sult is composed of three basic computational u-
nits, namely [that], [is] and [not bad].
</bodyText>
<tableCaption confidence="0.980962">
Table 1: Example for sentence segmentation.
</tableCaption>
<subsectionHeader confidence="0.978004">
3.2 Joint Model (JSC)
</subsectionHeader>
<bodyText confidence="0.9991435">
The overview of the proposed joint segmentation
and classification model (JSC) for sentiment anal-
ysis is illustrated in Figure 1. The intuitions of the
joint model are two-folds:
</bodyText>
<listItem confidence="0.98204325">
• The segmentation results have a strong influ-
ence on the sentiment classification perfor-
mance, since they are the inputs of the sen-
timent classification model.
• The usefulness of a segmentation can be
judged by whether the sentiment classifier
can use it to predict the correct sentence po-
larity.
</listItem>
<bodyText confidence="0.999606">
Based on the mutual influence observation, we
formalize the joint model in Algorithm 1. The in-
puts contain two parts, training data and feature
extractors. Each sentence si in the training data
</bodyText>
<footnote confidence="0.974308">
1In this paper, the sentiment polarity of a sentence is not
relevant to the target (or aspect) it contains (Hu and Liu, 2004;
Jiang et al., 2011; Mitchell et al., 2013).
</footnote>
<figure confidence="0.994477125">
Type
Sample
Sentence
Segmentation
Basic units
that is not bad
[that] [is] [not bad]
[that], [is], [not bad]
</figure>
<page confidence="0.99293">
479
</page>
<bodyText confidence="0.877258857142857">
Algorithm 1 The joint segmentation and classifi-
cation framework (JSC) for sentiment analysis
Input:
training data: T = [si, polgi ], 1 ≤ i ≤ |T |
segmentation feature extractor: sfe(·)
classification feature extractor: cfe(·)
Output:
</bodyText>
<listItem confidence="0.926908">
sentiment classifier: SC
segmentation ranking model: SEG
1: Generate segmentation candidates Ωi for each
sentence si in T, 1 ≤ i ≤ |T |
2: Initialize sentiment classifier SC(0) based on
</listItem>
<equation confidence="0.9240725">
cfe(Qi�), randomize j E [1, �QiJ], 1 &lt; i &lt;
ITI — —
</equation>
<listItem confidence="0.998259736842105">
3: Randomly initialize the segmentation ranking
model SEG(0)
4: for r ← 1 ... R do
5: Predict the sentiment polarity poli for Ωi
based on SC(r−1) and cfe(Ωi·)
6: Update the segmentation model SEG(r)
with SEG(r−1) and [Ωi, sfe(Ωi·),
poli·, polgi ], 1 ≤ i ≤ |T |
7: for i ← 1 ... |T |do
8: Calculate the segmentation score for Ωi·
based on SEG(r) and sfe(Ωi·)
9: Select the top-ranked K segmentation
candidates Ωi. from Ωi
10: end for
11: Train the sentiment classifier SC(r) with
cfe(Ωi.), 1 ≤ i ≤ |T|
12: end for
13: SC ← SC(R)
14: SEG ← SEG(R)
</listItem>
<bodyText confidence="0.962419441860465">
T is annotated only with its gold sentiment po-
larity polgi , without any segmentation annotation-
s. There are two feature extractors for the task
of sentence segmentation (sfe(·)) and sentiment
classification (cfe(·)), respectively. The output-
s of the joint model are the segmentation ranking
model SEG and the sentiment classifier SC.
In Algorithm 1, we first generate segmentation
candidates Ωi for each sentence si in the training
set (line 1). Each Ωi contains no less than one
segmentation candidates. We randomly select one
segmentation result from each Ωi and utilize their
classification features to initialize the sentimen-
t classifier SC(0) (line 2). We randomly initialize
the segmentation model SEG(0) (line 3). Subse-
quently, we iteratively train the segmentation mod-
el SEG(r) and sentiment classifier SC(r) in a join-
t manner (line 4-12). At each iteration, we pre-
dict the sentiment polarity of each segmentation
candidate Ωi· with the current sentiment classifi-
er SC(r−1) (line 5), and then leverage them to up-
date the segmentation model SEG(r) (line 6). Af-
terwards, we utilize the recently updated segmen-
tation ranking model SEG(r) to update the senti-
ment classifier SC(r) (line 7-11). We extract the
segmentation features for each segmentation can-
didate Ωi·, and employ them to calculate the seg-
mentation score (line 8). The top-ranked K seg-
mentation results Ωi. of each sentence si is select-
ed (line 9), and further used to train the sentimen-
t classifier SC(r) (line 11). Finally, after training
R iterations, we dump the segmentation ranking
model SEG(R) and sentiment classifier SC(R) in
the last iteration as outputs (line 13-14).
At training time, we train the segmentation
model and classification model from sentences
with manually annotated sentiment polarity. At
prediction time, given a test sentence, we gener-
ate its segmentation candidates, and then calculate
segmentation score for each candidate. Afterward-
s, we select the top-ranked K candidates and vote
their predicted sentiment polarity from sentiment
classifier as the final result.
</bodyText>
<sectionHeader confidence="0.998104" genericHeader="method">
4 Segmentation Model
</sectionHeader>
<bodyText confidence="0.9999162">
In this section, we present details of the segmenta-
tion candidate generation model (Section 4.1), the
segmentation ranking model (Section 4.2) and the
feature description for segmentation ranking mod-
el (Section 4.3).
</bodyText>
<subsectionHeader confidence="0.999079">
4.1 Segmentation Candidate Generation
</subsectionHeader>
<bodyText confidence="0.999931384615385">
In this subsection, we describe the strategy to gen-
erate segmentation candidates for each sentence.
Since the segmentation results have an exponen-
tial search space in the number of words in a
sentence, we approximate the computation using
beam search with constrains on a phrase table,
which is induced from massive corpora.
Many studies have been previously proposed to
recognize phrases in the text. However, it is out
of scope of this work to compare them. We ex-
ploit a data-driven approach given by Mikolov et
al. (2013), which identifies phrases based on the
occurrence frequency of unigrams and bigrams,
</bodyText>
<equation confidence="0.999777">
freq(wi,wj) = freq(wi, wj) − δ
freq(wi) × freq(wj) (1)
</equation>
<page confidence="0.927844">
480
</page>
<bodyText confidence="0.9985274375">
where S is a discounting coefficient that prevents
too many phrases consisting of very infrequen-
t words. We run 2-4 times over the corpora to get
longer phrases containing more words. We em-
pirically set S as 10 in our experiment. We use
the default frequency threshold (value=5) in the
word2vec toolkit 2 to select bi-terms.
Given a sentence, we initialize the beam of each
index with the current word, and sequentially add
phrases into the beam if the new phrase is con-
tained in the phrase table. At each index of a sen-
tence, we rank the segmentation candidates by the
inverted number of items within a segmentation,
and save the top-ranked N segmentation candi-
dates into the beam. An example of the generated
segmentation candidates is given in Table 2.
</bodyText>
<table confidence="0.981606714285714">
Type Sample
Sentence that is not bad
Phrase Table [is not], [not bad], [is not bad]
Segmentations [that] [is not bad]
[that] [is not] [bad]
[that] [is] [not bad]
[that] [is] [not] [bad]
</table>
<tableCaption confidence="0.965966">
Table 2: Example for segmentation candidate gen-
eration.
</tableCaption>
<subsectionHeader confidence="0.984263">
4.2 Segmentation Ranking Model
</subsectionHeader>
<bodyText confidence="0.997641538461538">
The objective of the segmentation ranking model
is to assign a scalar to each segmentation candi-
date, which indicates the usefulness of the seg-
mentation result for sentiment classification. In
this subsection, we describe a log-linear model to
calculate the segmentation score. To effectively
train the segmentation ranking model, we devise a
marginal log-likelihood as the optimization objec-
tive.
Given a segmentation candidate Qij of the sen-
tence si, we calculate the segmentation score
for Qij with a log-linear model, as given in Equa-
tion 2.
</bodyText>
<equation confidence="0.9934525">
Oij = exp(b + � sfeijk - wk) (2)
k
</equation>
<bodyText confidence="0.9997738">
where Oij is the segmentation score of Qij; sfeijk
is the k-th segmentation feature of Qij; w and b are
the parameters of the segmentation ranking model.
During training, given a sentence si and its gold
sentiment polarity polgi , the optimization objec-
</bodyText>
<footnote confidence="0.985227">
2Available at https://code.google.com/p/word2vec/
</footnote>
<bodyText confidence="0.857328285714286">
tive of the segmentation ranking model is to max-
imize the segmentation scores of the hit candi-
dates, whose predicted sentiment polarity equal-
s to the gold polarity of sentence polp. The loss
i
function of the segmentation model is given in E-
quation 3.
</bodyText>
<equation confidence="0.975846666666667">
� j∈Hi Oij
log( ) + λ ||w ||22 (3)
Ej,∈Ai Oij,
</equation>
<bodyText confidence="0.999373333333333">
where T is the training data; Ai represents all the
segmentation candidates of sentence si; Hi mean-
s the hit candidates of si; λ is the weight of the
L2-norm regularization factor. We train the seg-
mentation model with L-BFGS (Liu and Nocedal,
1989), running over the complete training data.
</bodyText>
<subsectionHeader confidence="0.97281">
4.3 Feature
</subsectionHeader>
<bodyText confidence="0.999961333333333">
We design two kinds of features for sentence seg-
mentation, namely the phrase-embedding feature
and the segmentation-specific feature. The final
feature representation of each segmentation is the
concatenation of these two features. It is worth
noting that, the phrase-embedding feature is used
in both sentence segmentation and sentiment clas-
sification.
Segmentation-Specific Feature We empirically
design four segmentation-specific features to re-
flect the information of each segmentation, as list-
ed in Table 3.
Phrase-Embedding Feature We leverage
phrase embedding to generate the features of
segmentation candidates for both sentence seg-
mentation and sentiment classification. The
reason is that, in both tasks, the basic compu-
tational units of each segmentation candidate
might be words or phrases of variable length.
Under this scenario, phrase embedding is highly
suitable as it is capable to represent phrases with
different length into a consistent distributed vector
space (Mikolov et al., 2013). For each phrase,
phrase embedding is a dense, real-valued and
continuous vector. After the phrase embedding is
trained, the nearest neighbors in the embedding
space are favored to have similar grammatical us-
ages and semantic meanings. The effectiveness of
phrase embedding has been verified for building
large-scale sentiment lexicon (Tang et al., 2014a)
and machine translation (Zhang et al., 2014).
We learn phrase embedding with Skip-Gram
model (Mikolov et al., 2013), which is the state-of-
</bodyText>
<equation confidence="0.997407">
loss = − � |T|
i=1
</equation>
<page confidence="0.956615">
481
</page>
<bodyText confidence="0.931207166666666">
Feature
Feature Description
the number of basic computation units in the segmentation candidate
the ratio of units’ number in a candidate to the length of original sentence
the difference between sentence length and the number of basic computational units
the number of basic component units composed of more than two words
</bodyText>
<table confidence="0.7132305">
#unit
#unit / #word
#word − #unit
#unit &gt; 2
</table>
<tableCaption confidence="0.994239">
Table 3: Segmentation-specific features for segmentation ranking.
</tableCaption>
<bodyText confidence="0.960847076923077">
Feature Feature Description
All-Caps the number of words with all characters in upper case
Emoticon the presence of positive (or negative) emoticons, whether the last unit is emoticon
Hashtag the number of hashtag
Elongated units the number of basic computational containing elongated words (with one character
repeated more than two times), such as gooood
Sentiment lexicon the number of sentiment words, the score of last sentiment words, the total sentiment
score and the maximal sentiment score for each lexicon
Negation the number of negations as individual units in a segmentation
Bag-of-Units an extension of bag-of-word for a segmentation
Punctuation the number of contiguous sequences of dot, question mark and exclamation mark.
Cluster the presence of units from each of the 1,000 clusters from Twitter NLP tool (Gimpel
et al., 2011)
</bodyText>
<tableCaption confidence="0.80519">
Table 4: Classification-specific features for sentiment classification.
</tableCaption>
<bodyText confidence="0.999931857142857">
the-art phrase embedding learning algorithm. We
compose the representation (or feature) of a seg-
mentation candidate from the embedding of the
basic computational units (words or phrases) it
contains. In this paper, we explore min, max and
average convolution functions, which have been
used as simple and effective methods for composi-
tion learning in vector-based semantics (Mitchell
and Lapata, 2010; Collobert et al., 2011; Socher et
al., 2013a; Shen et al., 2014; Tang et al., 2014b),
to calculate the representation of a segmentation
candidate. The final phrase-embedding feature is
the concatenation of vectors derived from different
convolutional functions, as given in Equation 4,
</bodyText>
<equation confidence="0.7505555">
pf(seg) = [pfmax(seg),pfmin(seg),pfavg(seg)]
(4)
</equation>
<bodyText confidence="0.99715">
where pf(seg) is the representation of the given
segmentation; pfx(seg) is the result of the con-
volutional function x E {min, max, avg}. Each
convolutional function pfx(·) conducts the matrix-
vector operation of x on the sequence represented
by columns in the lookup table of phrase embed-
ding. The output of pfx(·) is calculated as
</bodyText>
<equation confidence="0.994743">
pfx(seg) = θx(Lph)seg (5)
</equation>
<bodyText confidence="0.99958625">
where θx is the convolutional function of pfx;
(Lph)seg is the concatenated column vectors of
the basic computational units in the segmentation;
Lph is the lookup table of phrase embedding.
</bodyText>
<sectionHeader confidence="0.999568" genericHeader="method">
5 Classification Model
</sectionHeader>
<bodyText confidence="0.980516">
For sentiment classification, we follow the su-
pervised learning framework (Pang et al., 2002)
and build the classifier from sentences with man-
ually labelled sentiment polarity. We extend the
state-of-the-art hand-crafted features in SemEval
2013 (Mohammad et al., 2013b), and design the
classification-specific features for each segmenta-
tion. The detailed feature description is given in
Table 4.
</bodyText>
<sectionHeader confidence="0.998914" genericHeader="evaluation">
6 Experiment
</sectionHeader>
<bodyText confidence="0.999933666666667">
In this section, we conduct experiments to evaluate
the effectiveness of the joint model. We describe
the experiment settings and the result analysis.
</bodyText>
<subsectionHeader confidence="0.965336">
6.1 Dataset and Experiment Settings
</subsectionHeader>
<bodyText confidence="0.999966428571429">
We conduct sentiment classification of tweets on a
benchmark Twitter sentiment classification dataset
in SemEval 2013. We run 2-class (positive vs neg-
ative) classification as sentence segmentation has a
great influence on the positive/negative polarity of
tweets due to the polarity inconsistency between a
phrase and its constitutes, such as (not bad, bad).
</bodyText>
<page confidence="0.997198">
482
</page>
<bodyText confidence="0.99572725">
We leave 3-class classification (positive, negative,
neutral) and fine-grained classification (very neg-
ative, negative, neutral, positive, very positive) in
the future work.
</bodyText>
<table confidence="0.99907075">
Positive Negative Total
Train 2,642 994 3,636
Dev 408 219 627
Test 1,570 601 2,171
</table>
<tableCaption confidence="0.98883">
Table 5: Statistics of the SemEval 2013 Twitter
</tableCaption>
<bodyText confidence="0.974860095238095">
sentiment classification dataset (positive vs nega-
tive).
The statistics of our dataset crawled from Se-
mEval 2013 are given in Table 5. The evalua-
tion metric is the macro-F1 of sentiment classifi-
cation. We train the joint model on the training
set, tune parameters on the dev set and evaluate
on the test set. We train the sentiment classifier
with LibLinear (Fan et al., 2008) and utilize exist-
ing sentiment lexicons 3 to extract classification-
specific features. We randomly crawl 100M tweets
from February 1st, 2013 to April 30th, 2013 with
Twitter API, and use them to learn the phrase em-
bedding with Skip-Gram 4. The vocabulary size
of the phrase embedding is 926K, from unigram
to 5-gram. The parameter -c in SVM is tuned on
the dev-set in both baseline and our method. We
run the L-BFGS for 50 iterations, and set the reg-
ularization factor A as 0.003. The beam size N of
the candidate generation model and the top-ranked
segmentation number K are tuned on the dev-set.
</bodyText>
<subsectionHeader confidence="0.859473">
6.2 Baseline Methods
</subsectionHeader>
<bodyText confidence="0.9984315">
We compare the proposed joint model with the fol-
lowing sentiment classification algorithms:
</bodyText>
<listItem confidence="0.997683444444444">
• DistSuper: We collect 10M balanced tweets
selected by positive and negative emoticons 5 as
training data, and build classifier using the Lib-
Linear and ngram features (Go et al., 2009; Zhao
et al., 2012).
• SVM: The n-gram features and Support Vec-
tor Machine are widely-used baseline methods to
build sentiment classifiers (Pang et al., 2002). We
use LibLinear to train the SVM classifier.
</listItem>
<footnote confidence="0.990145625">
3In this work, we use HL (Hu and Liu, 2004), M-
PQA (Wilson et al., 2005), NRC Emotion Lexicon (Moham-
mad and Turney, 2012), NRC Hashtag Lexicon and Senti-
ment140Lexicon (Mohammad et al., 2013b).
4https://code.google.com/p/word2vec/
5We use the emoticons selected by Hu et al. (2013). The
positive emoticons are :) : ) :-) :D =), and the negative emoti-
cons are :( : ( :-( .
</footnote>
<listItem confidence="0.99973052631579">
• NBSVM: NBSVM (Wang and Manning,
2012) trades-off between Naive Bayes and NB-
features enhanced SVM. We use NBSVM-bi be-
cause it performs best on sentiment classification
of reviews.
• RAE: Recursive Autoencoder (Socher et al.,
2011) has been proven effective for sentiment clas-
sification by learning sentence representation. We
train the RAE using the pre-trained phrase embed-
ding learned from 100M tweets.
• SentiStrength: Thelwall et al. (2012) build a
lexicon-based classifier which uses linguistic rules
to detect the sentiment strength of tweets.
• SSWE,,: Tang et al. (2014b) propose to learn
sentiment-specific word embedding (SSWE) from
10M tweets collected by emoticons. They apply
SSWE as features for Twitter sentiment classifica-
tion.
• NRC: NRC builds the state-of-the-art system
</listItem>
<bodyText confidence="0.8470576">
in SemEval 2013 Twitter Sentiment Classifica-
tion Track, incorporating diverse sentiment lexi-
cons and hand-crafted features (Mohammad et al.,
2013b). We re-implement this system because the
codes are not publicly available. We do not di-
rectly report their results in the evaluation task,
as our training and development sets are smaller
than their dataset. In NRC + PF, We concatenate
the NRC features and the phrase embeddings fea-
ture (PF), and build the sentiment classifier with
LibLinear.
Except for DistSuper, other baseline method-
s are conducted in a supervised manner. We do
not compare with RNTN (Socher et al., 2013b) be-
cause the tweets in our dataset do not have accu-
rately parsed results. Another reason is that, due to
the differences between domains, the performance
of RNTN trained on movie reviews might be de-
creased if directly applied on the tweets (Xiao et
al., 2013).
</bodyText>
<subsectionHeader confidence="0.953003">
6.3 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.999918333333333">
Table 6 shows the macro-F1 of the baseline sys-
tems as well as our joint model (JSC) on senti-
ment classification of tweets (positive vs negative).
As is shown in Table 6, distant supervision is
relatively weak because the noisy-labeled tweets
are treated as the gold standard, which decreases
the performance of sentiment classifier. The result
of bag-of-unigram feature (74.50%) is not satisfied
as it losses the word order and does not well cap-
</bodyText>
<page confidence="0.998546">
483
</page>
<table confidence="0.99959675">
Method Macro-F1
DistSuper + unigram 61.74
DistSuper + 5-gram 63.92
SVM + unigram 74.50
SVM + 5-gram 74.97
Recursive Autoencoder 75.42
NBSVM 75.28
SentiStrength 73.23
SSWE,, 84.98
NRC (Top System in SemEval 2013) 84.73
NRC + PF 84.75
JSC 85.51
</table>
<tableCaption confidence="0.9352985">
Table 6: Macro-F1 for positive vs negative classi-
fication of tweets.
</tableCaption>
<bodyText confidence="0.999920217391305">
ture the semantic meaning of phrases. The integra-
tion of high-order n-ngram (up to 5-gram) does not
achieve significant improvement (+0.47%). The
reason is that, if a sentence contains a bigram “not
bad”, they will use “bad” and “not bad” as par-
allel features, which confuses the sentiment clas-
sification model. NBSVM and Recursive Autoen-
coder perform comparatively and have a big gap
in comparison with JSC. In RAE, the representa-
tion of a sentence is composed from the represen-
tation of words it contains. Accordingly, “great”
in “a great deal of” also contributes to the final
sentence representation via composition function.
JSC automatically conducts sentence segmenta-
tion by considering the sentiment polarity of sen-
tence, and utilize the phrasal information from the
segmentations. Ideally, JSC regards phrases like
“not bad” and “a great deal of” as basic compu-
tational units, and yields better classification per-
formance. JSC (85.51%) performs slightly better
than the state-of-the-art systems (SSWE,,, 84.98%;
NRC+PF, 84.75%), which verifies its effective-
ness.
</bodyText>
<subsectionHeader confidence="0.999917">
6.4 Comparing Joint and Pipelined Models
</subsectionHeader>
<bodyText confidence="0.98354615625">
We compare the proposed joint model with
pipelined methods on Twitter sentiment classifi-
cation with different feature sets. Figure 2 gives
the experiment results. The tick [A, B] on x-
axis means the use of A as segmentation feature
and the use of B as classification feature. PF
represents the phrase-embedding feature; SF and
CF stand for the segmentation-specific feature and
classification-specific feature, respectively. We
use the bag-of-word segmentation result to build
sentiment classier in Pipeline 1, and use the seg-
mentation candidate with maximum phrase num-
ber in Pipeline 2.
Figure 2: Macro-F1 for positive vs negative classi-
fication of tweets with joint and pipelined models.
From Figure 2, we find that the joint model
consistently outperforms pipelined baseline meth-
ods in all feature settings. The reason is that
the pipelined methods suffer from error propaga-
tion, since the errors from linguistic-driven and
bag-of-word segmentations cannot be corrected by
the sentiment classification model. Besides, tra-
ditional segmentors do not update the segmenta-
tion model with the sentiment information of tex-
t. Unlike pipelined methods, the joint model is
capable to address these problems by optimizing
the segmentation model with the classification re-
sults in a joint framework, which yields better
performance on sentiment classification. We also
find that Pipeline 2 always outperforms Pipeline
1, which indicates the usefulness of phrase-based
segmentation for sentiment classification.
</bodyText>
<subsectionHeader confidence="0.997608">
6.5 Effect of the beam size N
</subsectionHeader>
<bodyText confidence="0.999966764705882">
We investigate the influence of beam size N,
which is the maximum number of segmentation
candidates of a sentence. In this part, we clamp the
feature set as [PF+SF, PF+CF], and vary the beam
size N in [1,2,4,8,16,32,64]. The experiment re-
sults of macro-F1 on the development set are il-
lustrated in Figure 3 (a). The time cost of each
training iteration is given in Figure 3 (b).
From Figure 3 (a), we can see that when larg-
er beam size is considered, the classification per-
formance is improved. When beam size is 1, the
model stands for the greedy search with the bag-
of-words segmentation. When the beam size is s-
mall, such as 2, beam search losses many phrasal
information of sentences and thus the improve-
ment is not significant. The performance remains
steady when beam size is larger than 16. From
</bodyText>
<figure confidence="0.996791214285714">
[PF, PF] [PF+SF, PF] [PF, PF+CF] [PF+SF, PF+CF]
Macro−F1
0.86
0.84
0.82
0.78
0.76
0.74
0.72
0.8
0.7
Pipeline 1
Pipeline 2
Joint
</figure>
<page confidence="0.671457">
484
</page>
<figure confidence="0.973684">
(a) Macro-F1 score for senti- (b) Time cost (seconds) of
</figure>
<figureCaption confidence="0.5868153">
ment classification. each training iteration.
Figure 3: Sentiment classification of tweets with
different beam size N.
Figure 3 (b), we can find that the runtime of each
training iteration increases with larger beam size.
It is intuitive as the joint model with larger beam
considers more segmentation results, which in-
creases the training time of the segmentation mod-
el. We set beam size as 16 after parameter learn-
ing.
</figureCaption>
<subsectionHeader confidence="0.964029">
6.6 Effect of the top-ranked segmentation
</subsectionHeader>
<bodyText confidence="0.945896142857143">
number K
We investigate how the top-ranked segmentation
number K affects the performance of sentimen-
t classification. In this part, we set the feature as
[PF+SF, PF+CF], and the beam size as 16. The
results of macro-F1 on the development set are il-
lustrated in Figure 4.
</bodyText>
<subsectionHeader confidence="0.852157">
Top−ranked candidate number
</subsectionHeader>
<figureCaption confidence="0.9407675">
Figure 4: Sentiment classification of tweets with
different top-ranked segmentation number K.
</figureCaption>
<bodyText confidence="0.999132181818182">
From Figure 4, we find that the classification
performance increases with K being larger. The
reason is that when a larger K is used, (1) at train-
ing time, the sentiment classifier is built by using
more phrasal information from multiple segmen-
tations, which benefits from the ensembles; (2) at
test time, the joint model considers several top-
ranked segmentations and get the final sentiment
polarity through voting. The performance remain-
s stable when K is larger than 7, as the phrasal
information has been mostly covered.
</bodyText>
<sectionHeader confidence="0.990507" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99997">
In this paper, we develop a joint segmentation
and classification framework (JSC) for sentiment
analysis. Unlike existing sentiment classification
algorithms that build sentiment classifier based
on the segmentation results from bag-of-words or
separate segmentors, the proposed joint model si-
multaneously conducts sentence segmentation and
sentiment classification. We introduce a marginal
log-likelihood function to optimize the segmenta-
tion model, and effectively train the joint mod-
el from sentences annotated only with sentiment
polarity, without segmentation annotations of sen-
tences. The effectiveness of the joint model has
been verified by applying it on the benchmark
dataset of Twitter sentiment classification in Se-
mEval 2013. Results show that, the joint model
performs comparably with state-of-the-art meth-
ods, and outperforms pipelined methods in various
settings. In the future, we plan to apply the join-
t model on other domains, such as movie/product
reviews.
</bodyText>
<sectionHeader confidence="0.996921" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998569">
We thank Nan Yang, Yajuan Duan, Yaming
Sun and Meishan Zhang for their helpful dis-
cussions. We thank the anonymous reviewers
for their insightful comments and feedbacks on
this work. This research was partly supported
by National Natural Science Foundation of Chi-
na (No.61133012, No.61273321, No.61300113).
The contact author of this paper, according to the
meaning given to this role by Harbin Institute of
Technology, is Bing Qin.
</bodyText>
<sectionHeader confidence="0.999" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997224357142857">
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
2013. Representation learning: A review and new
perspectives. IEEE Trans. Pattern Analysis and Ma-
chine Intelligence.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. the Journal of ma-
chine Learning research, 3:993–1022.
Yejin Choi and Claire Cardie. 2008. Learning with
compositional semantics as structural inference for
subsentential sentiment analysis. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, pages 793–801.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
</reference>
<figure confidence="0.998255">
0.86
120
32 64
1 2 4 8 16
Beam Size
Beam Size
0.82
Runtime (Second)
100
80
60
40
20
0
1 2 4 8 16 32 64
0.81
0.85
Macro−F1
0.84
0.83
1 3 5 7 9 11 13 15
Macro−F1
0.86
0.85
0.84
0.83
0.82
</figure>
<page confidence="0.99306">
485
</page>
<reference confidence="0.999411858490566">
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12:2493–2537.
Xiaowen Ding, Bing Liu, and Philip S Yu. 2008. A
holistic lexicon-based approach to opinion mining.
In Proceedings of the International Conference on
Web Search and Data Mining, pages 231–240.
Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming
Zhou, and Ke Xu. 2014. Adaptive recursive neural
network for target-dependent twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 49–54.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A
library for large linear classification. The Journal of
Machine Learning Research, 9:1871–1874.
Ronen Feldman. 2013. Techniques and application-
s for sentiment analysis. Communications of the
ACM, 56(4):82–89.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: Annotation, features, and experiments.
In Proceedings of the Annual Meeting of the Associ-
ation for Computational Linguistics, pages 42–47.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Domain adaptation for large-scale sentiment
classification: A deep learning approach. Proceed-
ings of International Conference on Machine Learn-
ing.
Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
CS224N Project Report, Stanford, pages 1–12.
G.E. Hinton and R.R. Salakhutdinov. 2006. Reduc-
ing the dimensionality of data with neural networks.
Science, 313(5786):504–507.
Ming Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 168–177.
Xia Hu, Jiliang Tang, Huiji Gao, and Huan Liu.
2013. Unsupervised sentiment analysis with emo-
tional signals. In Proceedings of the International
World Wide Web Conference, pages 607–618.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
timent classification. The Proceeding of Annual
Meeting of the Association for Computational Lin-
guistics.
Nicola Jones. 2014. Computer science: The learning
machines. Nature, 505(7482):146.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A sentence model based on convolu-
tional neural networks. In Procedding of the 52th
Annual Meeting of Association for Computational
Linguistics.
Hyun Duk Kim and ChengXiang Zhai. 2009. Gener-
ating comparative summaries of contradictory opin-
ions in text. In Proceedings of CIKM 2009. ACM.
Efthymios Kouloumpis, Theresa Wilson, and Johanna
Moore. 2011. Twitter sentiment analysis: The good
the bad and the omg! In The International AAAI
Conference on Weblogs and Social Media.
Igor Labutov and Hod Lipson. 2013. Re-embedding
words. In Annual Meeting of the Association for
Computational Linguistics.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of international con-
ference on Machine learning. ACM.
Quoc Le and Tomas Mikolov. 2014. Distributed repre-
sentations of sentences and documents. Proceedings
of International Conference on Machine Learning.
Dong C Liu and Jorge Nocedal. 1989. On the limited
memory bfgs method for large scale optimization.
Mathematical programming, 45(1-3):503–528.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Andrew L Maas, Raymond E Daly, Peter T Pham, Dan
Huang, Andrew Y Ng, and Christopher Potts. 2011.
Learning word vectors for sentiment analysis. In
Proceedings of the Annual Meeting of the Associ-
ation for Computational Linguistics.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. Conference on Neural Information Processing
Systems.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.
Margaret Mitchell, Jacqui Aguilar, Theresa Wilson,
and Benjamin Van Durme. 2013. Open domain tar-
geted sentiment. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1643–1654.
Saif M Mohammad and Peter D Turney. 2012. Crowd-
sourcing a word–emotion association lexicon. Com-
putational Intelligence.
Saif M Mohammad, Bonnie J Dorr, Graeme Hirst, and
Peter D Turney. 2013a. Computing lexical contrast.
Computational Linguistics, 39(3):555–590.
</reference>
<page confidence="0.988505">
486
</page>
<reference confidence="0.995183788990825">
Saif M Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013b. Nrc-canada: Building the state-of-
the-art in sentiment analysis of tweets. Proceedings
of the International Workshop on Semantic Evalua-
tion.
Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classifica-
tion using crfs with hidden variables. In Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 786–794.
Alexander Pak and Patrick Paroubek. 2010. Twitter as
a corpus for sentiment analysis and opinion mining.
In Proceedings of Language Resources and Evalua-
tion Conference, volume 2010.
Georgios Paltoglou and Mike Thelwall. 2010. A s-
tudy of information retrieval weighting schemes for
sentiment analysis. In Proceedings of Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 1386–1395.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 79–86.
Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng,
and Gr´egoire Mesnil. 2014. Learning semantic rep-
resentations using convolutional neural networks for
web search. In Proceedings of the companion publi-
cation of the 23rd international conference on World
wide web companion, pages 373–374.
Richard Socher, J. Pennington, E.H. Huang, A.Y. Ng,
and C.D. Manning. 2011. Semi-supervised recur-
sive autoencoders for predicting sentiment distribu-
tions. In Conference on Empirical Methods in Nat-
ural Language Processing, pages 151–161.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic Com-
positionality Through Recursive Matrix-Vector S-
paces. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing.
Richard Socher, Danqi Chen, Christopher D Manning,
and Andrew Y Ng. 2013a. Reasoning with neu-
ral tensor networks for knowledge base completion.
The Conference on Neural Information Processing
Systems.
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Ng, and
Christopher Potts. 2013b. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In Conference on Empirical Methods in Nat-
ural Language Processing, pages 1631–1642.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional linguistics, 37(2):267–307.
Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and
Ting Liu. 2014a. Building large-scale twitter-
specific sentiment lexicon : A representation learn-
ing approach. In Proceedings of COLING 2014,
the 25th International Conference on Computation-
al Linguistics, pages 172–182.
Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014b. Learning sentiment-
specific word embedding for twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 1555–1565.
Mike Thelwall, Kevan Buckley, and Georgios Pal-
toglou. 2012. Sentiment strength detection for the
social web. Journal of the American Society for In-
formation Science and Technology, 63(1):163–173.
Peter D Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 417–424.
Sida Wang and Christopher D Manning. 2012. Base-
lines and bigrams: Simple, good sentiment and topic
classification. In Proceedings of the Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 90–94.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 347–354.
Min Xiao, Feipeng Zhao, and Yuhong Guo. 2013.
Learning latent word representations for domain
adaptation using supervised word clustering. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 152–
162, October.
Ainur Yessenalina and Claire Cardie. 2011. Compo-
sitional matrix-space models for sentiment analysis.
In Proceedings of Conference on Empirical Methods
in Natural Language Processing, pages 172–182.
Jiajun Zhang, Shujie Liu, Mu Li, Ming Zhou, and
Chengqing Zong. 2014. Bilingually-constrained
phrase embeddings for machine translation. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 111–121.
Jichang Zhao, Li Dong, Junjie Wu, and Ke Xu. 2012.
Moodlens: an emoticon-based sentiment analysis
system for chinese tweets. In Proceedings of the
18th ACM SIGKDD international conference on
Knowledge discovery and data mining.
</reference>
<page confidence="0.996985">
487
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.744615">
<title confidence="0.99965">A Joint Segmentation and Classification for Sentiment Analysis</title>
<author confidence="0.985202">Furu Bing Li Ting Ming</author>
<affiliation confidence="0.99943">Center for Social Computing and Information Harbin Institute of Technology,</affiliation>
<address confidence="0.875037">Research, Beijing, University, Beijing,</address>
<email confidence="0.991539">qinb,</email>
<abstract confidence="0.9984502">In this paper, we propose a joint segmentation and classification framework for sentiment analysis. Existing sentiment classification algorithms typically split a sentence as a word sequence, which does not effectively handle the inconsistent sentiment polarity between a phrase and the it contains, such as and great deal We address this issue by developing a joint segmentation and framework which simultaneously conducts sentence segmentation and sentence-level sentiment classification. Specifically, we use a log-linear model to score each segmentation candidate, and exploit the phrasal information of top-ranked segmentations as features to build the sentiment classifier. A marginal log-likelihood objective function is devised for the segmentation model, which is optimized for enhancing the sentiment classification performance. The joint model is trained only based on the annotated sentiment polarity of sentences, without any segmentation annotations. Experiments on a benchmark Twitter sentiment classification dataset in SemEval 2013 show that, our joint model performs comparably with the state-of-the-art methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>Aaron Courville</author>
<author>Pascal Vincent</author>
</authors>
<title>Representation learning: A review and new perspectives.</title>
<date>2013</date>
<journal>IEEE Trans. Pattern Analysis and Machine Intelligence.</journal>
<contexts>
<context position="8500" citStr="Bengio et al., 2013" startWordPosition="1287" endWordPosition="1290">m and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition o</context>
</contexts>
<marker>Bengio, Courville, Vincent, 2013</marker>
<rawString>Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE Trans. Pattern Analysis and Machine Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>the Journal of machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="9469" citStr="Blei et al. (2003)" startWordPosition="1428" endWordPosition="1431">ix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabilistic document model following Blei et al. (2003), Labutov and Lipson (2013) re-embed words from existing word embeddings and Tang et al. (2014b) develop three neural networks to learn word vectors from tweets containing positive/negative emoticons. Unlike most previous corpus-based algorithms that build sentiment classifier based on splitting a sentence as a word sequence, we produce sentence segmentations automatically within a joint framework, and conduct sentiment classification based on the segmentation results. 3 The Proposed Approach In this section, we first give the task definition of two tasks, namely sentiment classification and s</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Learning with compositional semantics as structural inference for subsentential sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>793--801</pages>
<contexts>
<context position="2256" citStr="Choi and Cardie, 2008" startWordPosition="325" endWordPosition="328">ch classifies the sentiment polarity of a sentence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contai</context>
</contexts>
<marker>Choi, Cardie, 2008</marker>
<rawString>Yejin Choi and Claire Cardie. 2008. Learning with compositional semantics as structural inference for subsentential sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 793–801.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, </marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa.</rawString>
</citation>
<citation valid="true">
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="8672" citStr="(2011)" startWordPosition="1315" endWordPosition="1315">pendency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural</context>
</contexts>
<marker>2011</marker>
<rawString>2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Web Search and Data Mining,</booktitle>
<pages>231--240</pages>
<contexts>
<context position="6404" citStr="Ding et al., 2008" startWordPosition="967" endWordPosition="970">performs pipeline methods in various experiment settings. The main contributions of the work presented in this paper are as follows. • To our knowledge, this is the first work that automatically produces sentence segmentation for sentiment classification within a joint framework. • We show that the joint model yields comparable performance with the state-of-the-art methods on the benchmark Twitter sentiment classification datasets in SemEval 2013. 2 Related Work Existing approaches for sentiment classification are dominated by two mainstream directions. Lexicon-based approaches (Turney, 2002; Ding et al., 2008; Taboada et al., 2011; Thelwall et al., 2012) typically utilize a lexicon of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by se</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S Yu. 2008. A holistic lexicon-based approach to opinion mining. In Proceedings of the International Conference on Web Search and Data Mining, pages 231–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Dong</author>
<author>Furu Wei</author>
<author>Chuanqi Tan</author>
<author>Duyu Tang</author>
<author>Ming Zhou</author>
<author>Ke Xu</author>
</authors>
<title>Adaptive recursive neural network for target-dependent twitter sentiment classification.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="2574" citStr="Dong et al., 2014" startWordPosition="376" endWordPosition="379">fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-words or syntactic chunkers are not effective enough to handle the polarity inconsistency phenomenons. The reason lies in that bag-of-words segmentations regard each word as a separate unit, which losses the word order and does</context>
</contexts>
<marker>Dong, Wei, Tan, Tang, Zhou, Xu, 2014</marker>
<rawString>Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming Zhou, and Ke Xu. 2014. Adaptive recursive neural network for target-dependent twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="24397" citStr="Fan et al., 2008" startWordPosition="3808" endWordPosition="3811">d fine-grained classification (very negative, negative, neutral, positive, very positive) in the future work. Positive Negative Total Train 2,642 994 3,636 Dev 408 219 627 Test 1,570 601 2,171 Table 5: Statistics of the SemEval 2013 Twitter sentiment classification dataset (positive vs negative). The statistics of our dataset crawled from SemEval 2013 are given in Table 5. The evaluation metric is the macro-F1 of sentiment classification. We train the joint model on the training set, tune parameters on the dev set and evaluate on the test set. We train the sentiment classifier with LibLinear (Fan et al., 2008) and utilize existing sentiment lexicons 3 to extract classificationspecific features. We randomly crawl 100M tweets from February 1st, 2013 to April 30th, 2013 with Twitter API, and use them to learn the phrase embedding with Skip-Gram 4. The vocabulary size of the phrase embedding is 926K, from unigram to 5-gram. The parameter -c in SVM is tuned on the dev-set in both baseline and our method. We run the L-BFGS for 50 iterations, and set the regularization factor A as 0.003. The beam size N of the candidate generation model and the top-ranked segmentation number K are tuned on the dev-set. 6.</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. The Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
</authors>
<title>Techniques and applications for sentiment analysis.</title>
<date>2013</date>
<journal>Communications of the ACM,</journal>
<volume>56</volume>
<issue>4</issue>
<contexts>
<context position="1836" citStr="Feldman, 2013" startWordPosition="262" endWordPosition="263">, which is optimized for enhancing the sentiment classification performance. The joint model is trained only based on the annotated sentiment polarity of sentences, without any segmentation annotations. Experiments on a benchmark Twitter sentiment classification dataset in SemEval 2013 show that, our joint model performs comparably with the state-of-the-art methods. 1 Introduction Sentiment classification, which classifies the sentiment polarity of a sentence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms tak</context>
</contexts>
<marker>Feldman, 2013</marker>
<rawString>Ronen Feldman. 2013. Techniques and applications for sentiment analysis. Communications of the ACM, 56(4):82–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>42--47</pages>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Glorot</author>
<author>Antoine Bordes</author>
<author>Yoshua Bengio</author>
</authors>
<title>Domain adaptation for large-scale sentiment classification: A deep learning approach.</title>
<date>2011</date>
<booktitle>Proceedings of International Conference on Machine Learning.</booktitle>
<contexts>
<context position="8672" citStr="Glorot et al. (2011)" startWordPosition="1312" endWordPosition="1315">10) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural</context>
</contexts>
<marker>Glorot, Bordes, Bengio, 2011</marker>
<rawString>Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Domain adaptation for large-scale sentiment classification: A deep learning approach. Proceedings of International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision. CS224N Project Report,</title>
<date>2009</date>
<pages>1--12</pages>
<location>Stanford,</location>
<contexts>
<context position="7051" citStr="Go et al., 2009" startWordPosition="1064" endWordPosition="1067"> et al., 2012) typically utilize a lexicon of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by sentiment signals like emoticons (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Zhao et al., 2012). Majority of existing approaches follow Pang et al. (2002) and employ corpus-based method for sentiment classification. Pang et al. (2002) pioneer to treat the sentiment classification of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus</context>
<context position="25292" citStr="Go et al., 2009" startWordPosition="3960" endWordPosition="3963">ing is 926K, from unigram to 5-gram. The parameter -c in SVM is tuned on the dev-set in both baseline and our method. We run the L-BFGS for 50 iterations, and set the regularization factor A as 0.003. The beam size N of the candidate generation model and the top-ranked segmentation number K are tuned on the dev-set. 6.2 Baseline Methods We compare the proposed joint model with the following sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang an</context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford, pages 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Hinton</author>
<author>R R Salakhutdinov</author>
</authors>
<title>Reducing the dimensionality of data with neural networks.</title>
<date>2006</date>
<journal>Science,</journal>
<volume>313</volume>
<issue>5786</issue>
<contexts>
<context position="8479" citStr="Hinton and Salakhutdinov, 2006" startWordPosition="1283" endWordPosition="1286"> and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to le</context>
</contexts>
<marker>Hinton, Salakhutdinov, 2006</marker>
<rawString>G.E. Hinton and R.R. Salakhutdinov. 2006. Reducing the dimensionality of data with neural networks. Science, 313(5786):504–507.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="11878" citStr="Hu and Liu, 2004" startWordPosition="1811" endWordPosition="1814"> The segmentation results have a strong influence on the sentiment classification performance, since they are the inputs of the sentiment classification model. • The usefulness of a segmentation can be judged by whether the sentiment classifier can use it to predict the correct sentence polarity. Based on the mutual influence observation, we formalize the joint model in Algorithm 1. The inputs contain two parts, training data and feature extractors. Each sentence si in the training data 1In this paper, the sentiment polarity of a sentence is not relevant to the target (or aspect) it contains (Hu and Liu, 2004; Jiang et al., 2011; Mitchell et al., 2013). Type Sample Sentence Segmentation Basic units that is not bad [that] [is] [not bad] [that], [is], [not bad] 479 Algorithm 1 The joint segmentation and classification framework (JSC) for sentiment analysis Input: training data: T = [si, polgi ], 1 ≤ i ≤ |T | segmentation feature extractor: sfe(·) classification feature extractor: cfe(·) Output: sentiment classifier: SC segmentation ranking model: SEG 1: Generate segmentation candidates Ωi for each sentence si in T, 1 ≤ i ≤ |T | 2: Initialize sentiment classifier SC(0) based on cfe(Qi�), randomize j </context>
<context position="25542" citStr="Hu and Liu, 2004" startWordPosition="4004" endWordPosition="4007">el and the top-ranked segmentation number K are tuned on the dev-set. 6.2 Baseline Methods We compare the proposed joint model with the following sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment c</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Ming Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xia Hu</author>
<author>Jiliang Tang</author>
<author>Huiji Gao</author>
<author>Huan Liu</author>
</authors>
<title>Unsupervised sentiment analysis with emotional signals.</title>
<date>2013</date>
<booktitle>In Proceedings of the International World Wide Web Conference,</booktitle>
<pages>607--618</pages>
<contexts>
<context position="25778" citStr="Hu et al. (2013)" startWordPosition="4039" endWordPosition="4042">y positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStrength: Thelwall et al. (2012) build a lexicon-based classifier which uses linguistic rules to</context>
</contexts>
<marker>Hu, Tang, Gao, Liu, 2013</marker>
<rawString>Xia Hu, Jiliang Tang, Huiji Gao, and Huan Liu. 2013. Unsupervised sentiment analysis with emotional signals. In Proceedings of the International World Wide Web Conference, pages 607–618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification. The Proceeding of Annual Meeting of the Association for Computational Linguistics.</title>
<date>2011</date>
<contexts>
<context position="11898" citStr="Jiang et al., 2011" startWordPosition="1815" endWordPosition="1818">results have a strong influence on the sentiment classification performance, since they are the inputs of the sentiment classification model. • The usefulness of a segmentation can be judged by whether the sentiment classifier can use it to predict the correct sentence polarity. Based on the mutual influence observation, we formalize the joint model in Algorithm 1. The inputs contain two parts, training data and feature extractors. Each sentence si in the training data 1In this paper, the sentiment polarity of a sentence is not relevant to the target (or aspect) it contains (Hu and Liu, 2004; Jiang et al., 2011; Mitchell et al., 2013). Type Sample Sentence Segmentation Basic units that is not bad [that] [is] [not bad] [that], [is], [not bad] 479 Algorithm 1 The joint segmentation and classification framework (JSC) for sentiment analysis Input: training data: T = [si, polgi ], 1 ≤ i ≤ |T | segmentation feature extractor: sfe(·) classification feature extractor: cfe(·) Output: sentiment classifier: SC segmentation ranking model: SEG 1: Generate segmentation candidates Ωi for each sentence si in T, 1 ≤ i ≤ |T | 2: Initialize sentiment classifier SC(0) based on cfe(Qi�), randomize j E [1, �QiJ], 1 &lt; i &lt;</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment classification. The Proceeding of Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Jones</author>
</authors>
<title>Computer science: The learning machines.</title>
<date>2014</date>
<journal>Nature,</journal>
<volume>505</volume>
<issue>7482</issue>
<contexts>
<context position="8514" citStr="Jones, 2014" startWordPosition="1291" endWordPosition="1292"> Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-len</context>
</contexts>
<marker>Jones, 2014</marker>
<rawString>Nicola Jones. 2014. Computer science: The learning machines. Nature, 505(7482):146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A sentence model based on convolutional neural networks.</title>
<date>2014</date>
<booktitle>In Procedding of the 52th Annual Meeting of Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2554" citStr="Kalchbrenner et al., 2014" startWordPosition="372" endWordPosition="375">ly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-words or syntactic chunkers are not effective enough to handle the polarity inconsistency phenomenons. The reason lies in that bag-of-words segmentations regard each word as a separate unit, which losses the</context>
<context position="9235" citStr="Kalchbrenner et al. (2014)" startWordPosition="1392" endWordPosition="1395">ext features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabilistic document model following Blei et al. (2003), Labutov and Lipson (2013) re-embed words from existing word embeddings and Tang et al. (2014b) develop three neural networks to learn word vectors from tweets containing positive/negative emoticons. Unlike most previous corpus-based algorithms that build sentiment classifier based on splitting a sentence as a word sequence, we produce sentence segmentations auto</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A sentence model based on convolutional neural networks. In Procedding of the 52th Annual Meeting of Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyun Duk Kim</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Generating comparative summaries of contradictory opinions in text.</title>
<date>2009</date>
<booktitle>In Proceedings of CIKM</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="7898" citStr="Kim and Zhai (2009)" startWordPosition="1199" endWordPosition="1202">e sentiment classification of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learning effective features to obtain better classification performance. On movie or product reviews, Wang and Manning (2012) present NBSVM, which trades-off 478 between Naive Bayes and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 20</context>
</contexts>
<marker>Kim, Zhai, 2009</marker>
<rawString>Hyun Duk Kim and ChengXiang Zhai. 2009. Generating comparative summaries of contradictory opinions in text. In Proceedings of CIKM 2009. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efthymios Kouloumpis</author>
<author>Theresa Wilson</author>
<author>Johanna Moore</author>
</authors>
<title>Twitter sentiment analysis: The good the bad and the omg!</title>
<date>2011</date>
<booktitle>In The International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="7100" citStr="Kouloumpis et al., 2011" startWordPosition="1072" endWordPosition="1075">n of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by sentiment signals like emoticons (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Zhao et al., 2012). Majority of existing approaches follow Pang et al. (2002) and employ corpus-based method for sentiment classification. Pang et al. (2002) pioneer to treat the sentiment classification of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learning effective features to o</context>
</contexts>
<marker>Kouloumpis, Wilson, Moore, 2011</marker>
<rawString>Efthymios Kouloumpis, Theresa Wilson, and Johanna Moore. 2011. Twitter sentiment analysis: The good the bad and the omg! In The International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Labutov</author>
<author>Hod Lipson</author>
</authors>
<title>Re-embedding words.</title>
<date>2013</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9496" citStr="Labutov and Lipson (2013)" startWordPosition="1432" endWordPosition="1435"> using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabilistic document model following Blei et al. (2003), Labutov and Lipson (2013) re-embed words from existing word embeddings and Tang et al. (2014b) develop three neural networks to learn word vectors from tweets containing positive/negative emoticons. Unlike most previous corpus-based algorithms that build sentiment classifier based on splitting a sentence as a word sequence, we produce sentence segmentations automatically within a joint framework, and conduct sentiment classification based on the segmentation results. 3 The Proposed Approach In this section, we first give the task definition of two tasks, namely sentiment classification and sentence segmentation. Then,</context>
</contexts>
<marker>Labutov, Lipson, 2013</marker>
<rawString>Igor Labutov and Hod Lipson. 2013. Re-embedding words. In Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of international conference on Machine learning.</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="8159" citStr="Lafferty et al., 2001" startWordPosition="1236" endWordPosition="1239">ents, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learning effective features to obtain better classification performance. On movie or product reviews, Wang and Manning (2012) present NBSVM, which trades-off 478 between Naive Bayes and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptat</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of international conference on Machine learning. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quoc Le and Tomas Mikolov</author>
</authors>
<title>Distributed representations of sentences and documents.</title>
<date>2014</date>
<booktitle>Proceedings of International Conference on Machine Learning.</booktitle>
<contexts>
<context position="9306" citStr="Mikolov (2014)" startWordPosition="1405" endWordPosition="1406"> Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabilistic document model following Blei et al. (2003), Labutov and Lipson (2013) re-embed words from existing word embeddings and Tang et al. (2014b) develop three neural networks to learn word vectors from tweets containing positive/negative emoticons. Unlike most previous corpus-based algorithms that build sentiment classifier based on splitting a sentence as a word sequence, we produce sentence segmentations automatically within a joint framework, and conduct sentiment classificatio</context>
</contexts>
<marker>Mikolov, 2014</marker>
<rawString>Quoc Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents. Proceedings of International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory bfgs method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical programming,</booktitle>
<pages>45--1</pages>
<contexts>
<context position="18522" citStr="Liu and Nocedal, 1989" startWordPosition="2918" endWordPosition="2921"> , the optimization objec2Available at https://code.google.com/p/word2vec/ tive of the segmentation ranking model is to maximize the segmentation scores of the hit candidates, whose predicted sentiment polarity equals to the gold polarity of sentence polp. The loss i function of the segmentation model is given in Equation 3. � j∈Hi Oij log( ) + λ ||w ||22 (3) Ej,∈Ai Oij, where T is the training data; Ai represents all the segmentation candidates of sentence si; Hi means the hit candidates of si; λ is the weight of the L2-norm regularization factor. We train the segmentation model with L-BFGS (Liu and Nocedal, 1989), running over the complete training data. 4.3 Feature We design two kinds of features for sentence segmentation, namely the phrase-embedding feature and the segmentation-specific feature. The final feature representation of each segmentation is the concatenation of these two features. It is worth noting that, the phrase-embedding feature is used in both sentence segmentation and sentiment classification. Segmentation-Specific Feature We empirically design four segmentation-specific features to reflect the information of each segmentation, as listed in Table 3. Phrase-Embedding Feature We leve</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C Liu and Jorge Nocedal. 1989. On the limited memory bfgs method for large scale optimization. Mathematical programming, 45(1-3):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="1820" citStr="Liu, 2012" startWordPosition="260" endWordPosition="261">ation model, which is optimized for enhancing the sentiment classification performance. The joint model is trained only based on the annotated sentiment polarity of sentences, without any segmentation annotations. Experiments on a benchmark Twitter sentiment classification dataset in SemEval 2013 show that, our joint model performs comparably with the state-of-the-art methods. 1 Introduction Sentiment classification, which classifies the sentiment polarity of a sentence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classificatio</context>
<context position="3457" citStr="Liu, 2012" startWordPosition="520" endWordPosition="521">t contains, such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-words or syntactic chunkers are not effective enough to handle the polarity inconsistency phenomenons. The reason lies in that bag-of-words segmentations regard each word as a separate unit, which losses the word order and does not capture the phrasal information. The segmentations based on syntactic chunkers typically aim to identify noun groups, verb groups or named entities from a sentence. However, many sentiment indicators are phrases constituted of adjectives, negations, adverbs or idioms (Liu, 2012; Mohammad et al., 2013a), which are splitted by syntactic chunkers. Besides, a better approach would be to utilize the sentiment information to improve the segmentor. Accordingly, the sentiment-specific segmentor will enhance the performance of sentiment classification in turn. In this paper, we propose a joint segmentation and classification framework (JSC) for sentiment analysis, which simultaneous conducts sentence segmentation and sentence-level sentiment classification. The framework is illustrated in Fig477 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Proc</context>
<context position="10529" citStr="Liu, 2012" startWordPosition="1584" endWordPosition="1585">e segmentation results. 3 The Proposed Approach In this section, we first give the task definition of two tasks, namely sentiment classification and sentence segmentation. Then, we present the overview of the proposed joint segmentation and classification model (JSC) for sentiment analysis. The segmentation candidate generation model and the segmentation ranking model are described in Section 4. The details of the sentiment classification model are presented in Section 5. 3.1 Task Definition The task of sentiment classification has been well formalized in previous studies (Pang and Lee, 2008; Liu, 2012). The objective is to identify the sentiment polarity of a sentence (or document) as positive or negative 1. The task of sentence segmentation aims to split a sentence into a sequence of exclusive parts, each of which is a basic computational unit of the sentence. An example is illustrated in Table 1. The original text “that is not bad” is segmented as “[that] [is] [not bad]”. The segmentation result is composed of three basic computational units, namely [that], [is] and [not bad]. Table 1: Example for sentence segmentation. 3.2 Joint Model (JSC) The overview of the proposed joint segmentation</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew L Maas</author>
<author>Raymond E Daly</author>
<author>Peter T Pham</author>
<author>Dan Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Learning word vectors for sentiment analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2368" citStr="Maas et al., 2011" startWordPosition="343" endWordPosition="346">tion in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-words or syntactic ch</context>
<context position="9401" citStr="Maas et al. (2011)" startWordPosition="1418" endWordPosition="1421">ication. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabilistic document model following Blei et al. (2003), Labutov and Lipson (2013) re-embed words from existing word embeddings and Tang et al. (2014b) develop three neural networks to learn word vectors from tweets containing positive/negative emoticons. Unlike most previous corpus-based algorithms that build sentiment classifier based on splitting a sentence as a word sequence, we produce sentence segmentations automatically within a joint framework, and conduct sentiment classification based on the segmentation results. 3 The Proposed Approach In this section, we first give the</context>
</contexts>
<marker>Maas, Daly, Pham, Huang, Ng, Potts, 2011</marker>
<rawString>Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<date>2013</date>
<booktitle>Distributed representations of words and phrases and their compositionality. Conference on Neural Information Processing Systems.</booktitle>
<contexts>
<context position="15917" citStr="Mikolov et al. (2013)" startWordPosition="2475" endWordPosition="2478"> description for segmentation ranking model (Section 4.3). 4.1 Segmentation Candidate Generation In this subsection, we describe the strategy to generate segmentation candidates for each sentence. Since the segmentation results have an exponential search space in the number of words in a sentence, we approximate the computation using beam search with constrains on a phrase table, which is induced from massive corpora. Many studies have been previously proposed to recognize phrases in the text. However, it is out of scope of this work to compare them. We exploit a data-driven approach given by Mikolov et al. (2013), which identifies phrases based on the occurrence frequency of unigrams and bigrams, freq(wi,wj) = freq(wi, wj) − δ freq(wi) × freq(wj) (1) 480 where S is a discounting coefficient that prevents too many phrases consisting of very infrequent words. We run 2-4 times over the corpora to get longer phrases containing more words. We empirically set S as 10 in our experiment. We use the default frequency threshold (value=5) in the word2vec toolkit 2 to select bi-terms. Given a sentence, we initialize the beam of each index with the current word, and sequentially add phrases into the beam if the ne</context>
<context position="19581" citStr="Mikolov et al., 2013" startWordPosition="3071" endWordPosition="3074"> We empirically design four segmentation-specific features to reflect the information of each segmentation, as listed in Table 3. Phrase-Embedding Feature We leverage phrase embedding to generate the features of segmentation candidates for both sentence segmentation and sentiment classification. The reason is that, in both tasks, the basic computational units of each segmentation candidate might be words or phrases of variable length. Under this scenario, phrase embedding is highly suitable as it is capable to represent phrases with different length into a consistent distributed vector space (Mikolov et al., 2013). For each phrase, phrase embedding is a dense, real-valued and continuous vector. After the phrase embedding is trained, the nearest neighbors in the embedding space are favored to have similar grammatical usages and semantic meanings. The effectiveness of phrase embedding has been verified for building large-scale sentiment lexicon (Tang et al., 2014a) and machine translation (Zhang et al., 2014). We learn phrase embedding with Skip-Gram model (Mikolov et al., 2013), which is the state-ofloss = − � |T| i=1 481 Feature Feature Description the number of basic computation units in the segmentat</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed representations of words and phrases and their compositionality. Conference on Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="21849" citStr="Mitchell and Lapata, 2010" startWordPosition="3418" endWordPosition="3421">es of dot, question mark and exclamation mark. Cluster the presence of units from each of the 1,000 clusters from Twitter NLP tool (Gimpel et al., 2011) Table 4: Classification-specific features for sentiment classification. the-art phrase embedding learning algorithm. We compose the representation (or feature) of a segmentation candidate from the embedding of the basic computational units (words or phrases) it contains. In this paper, we explore min, max and average convolution functions, which have been used as simple and effective methods for composition learning in vector-based semantics (Mitchell and Lapata, 2010; Collobert et al., 2011; Socher et al., 2013a; Shen et al., 2014; Tang et al., 2014b), to calculate the representation of a segmentation candidate. The final phrase-embedding feature is the concatenation of vectors derived from different convolutional functions, as given in Equation 4, pf(seg) = [pfmax(seg),pfmin(seg),pfavg(seg)] (4) where pf(seg) is the representation of the given segmentation; pfx(seg) is the result of the convolutional function x E {min, max, avg}. Each convolutional function pfx(·) conducts the matrixvector operation of x on the sequence represented by columns in the look</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Mitchell</author>
<author>Jacqui Aguilar</author>
<author>Theresa Wilson</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Open domain targeted sentiment.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1643--1654</pages>
<marker>Mitchell, Aguilar, Wilson, Van Durme, 2013</marker>
<rawString>Margaret Mitchell, Jacqui Aguilar, Theresa Wilson, and Benjamin Van Durme. 2013. Open domain targeted sentiment. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1643–1654.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Crowdsourcing a word–emotion association lexicon.</title>
<date>2012</date>
<journal>Computational Intelligence.</journal>
<contexts>
<context position="25619" citStr="Mohammad and Turney, 2012" startWordPosition="4017" endWordPosition="4021">. 6.2 Baseline Methods We compare the proposed joint model with the following sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the</context>
</contexts>
<marker>Mohammad, Turney, 2012</marker>
<rawString>Saif M Mohammad and Peter D Turney. 2012. Crowdsourcing a word–emotion association lexicon. Computational Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Bonnie J Dorr</author>
<author>Graeme Hirst</author>
<author>Peter D Turney</author>
</authors>
<date>2013</date>
<booktitle>Computing lexical contrast. Computational Linguistics,</booktitle>
<pages>39--3</pages>
<contexts>
<context position="3480" citStr="Mohammad et al., 2013" startWordPosition="522" endWordPosition="525"> such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-words or syntactic chunkers are not effective enough to handle the polarity inconsistency phenomenons. The reason lies in that bag-of-words segmentations regard each word as a separate unit, which losses the word order and does not capture the phrasal information. The segmentations based on syntactic chunkers typically aim to identify noun groups, verb groups or named entities from a sentence. However, many sentiment indicators are phrases constituted of adjectives, negations, adverbs or idioms (Liu, 2012; Mohammad et al., 2013a), which are splitted by syntactic chunkers. Besides, a better approach would be to utilize the sentiment information to improve the segmentor. Accordingly, the sentiment-specific segmentor will enhance the performance of sentiment classification in turn. In this paper, we propose a joint segmentation and classification framework (JSC) for sentiment analysis, which simultaneous conducts sentence segmentation and sentence-level sentiment classification. The framework is illustrated in Fig477 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4</context>
<context position="8248" citStr="Mohammad et al. (2013" startWordPosition="1251" endWordPosition="1254">tive, many studies focus on designing or learning effective features to obtain better classification performance. On movie or product reviews, Wang and Manning (2012) present NBSVM, which trades-off 478 between Naive Bayes and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a m</context>
<context position="23024" citStr="Mohammad et al., 2013" startWordPosition="3596" endWordPosition="3599">he sequence represented by columns in the lookup table of phrase embedding. The output of pfx(·) is calculated as pfx(seg) = θx(Lph)seg (5) where θx is the convolutional function of pfx; (Lph)seg is the concatenated column vectors of the basic computational units in the segmentation; Lph is the lookup table of phrase embedding. 5 Classification Model For sentiment classification, we follow the supervised learning framework (Pang et al., 2002) and build the classifier from sentences with manually labelled sentiment polarity. We extend the state-of-the-art hand-crafted features in SemEval 2013 (Mohammad et al., 2013b), and design the classification-specific features for each segmentation. The detailed feature description is given in Table 4. 6 Experiment In this section, we conduct experiments to evaluate the effectiveness of the joint model. We describe the experiment settings and the result analysis. 6.1 Dataset and Experiment Settings We conduct sentiment classification of tweets on a benchmark Twitter sentiment classification dataset in SemEval 2013. We run 2-class (positive vs negative) classification as sentence segmentation has a great influence on the positive/negative polarity of tweets due to t</context>
<context position="25687" citStr="Mohammad et al., 2013" startWordPosition="4028" endWordPosition="4031">wing sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStren</context>
</contexts>
<marker>Mohammad, Dorr, Hirst, Turney, 2013</marker>
<rawString>Saif M Mohammad, Bonnie J Dorr, Graeme Hirst, and Peter D Turney. 2013a. Computing lexical contrast. Computational Linguistics, 39(3):555–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>Nrc-canada: Building the state-ofthe-art in sentiment analysis of tweets.</title>
<date>2013</date>
<booktitle>Proceedings of the International Workshop on Semantic Evaluation.</booktitle>
<contexts>
<context position="3480" citStr="Mohammad et al., 2013" startWordPosition="522" endWordPosition="525"> such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-words or syntactic chunkers are not effective enough to handle the polarity inconsistency phenomenons. The reason lies in that bag-of-words segmentations regard each word as a separate unit, which losses the word order and does not capture the phrasal information. The segmentations based on syntactic chunkers typically aim to identify noun groups, verb groups or named entities from a sentence. However, many sentiment indicators are phrases constituted of adjectives, negations, adverbs or idioms (Liu, 2012; Mohammad et al., 2013a), which are splitted by syntactic chunkers. Besides, a better approach would be to utilize the sentiment information to improve the segmentor. Accordingly, the sentiment-specific segmentor will enhance the performance of sentiment classification in turn. In this paper, we propose a joint segmentation and classification framework (JSC) for sentiment analysis, which simultaneous conducts sentence segmentation and sentence-level sentiment classification. The framework is illustrated in Fig477 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4</context>
<context position="8248" citStr="Mohammad et al. (2013" startWordPosition="1251" endWordPosition="1254">tive, many studies focus on designing or learning effective features to obtain better classification performance. On movie or product reviews, Wang and Manning (2012) present NBSVM, which trades-off 478 between Naive Bayes and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a m</context>
<context position="23024" citStr="Mohammad et al., 2013" startWordPosition="3596" endWordPosition="3599">he sequence represented by columns in the lookup table of phrase embedding. The output of pfx(·) is calculated as pfx(seg) = θx(Lph)seg (5) where θx is the convolutional function of pfx; (Lph)seg is the concatenated column vectors of the basic computational units in the segmentation; Lph is the lookup table of phrase embedding. 5 Classification Model For sentiment classification, we follow the supervised learning framework (Pang et al., 2002) and build the classifier from sentences with manually labelled sentiment polarity. We extend the state-of-the-art hand-crafted features in SemEval 2013 (Mohammad et al., 2013b), and design the classification-specific features for each segmentation. The detailed feature description is given in Table 4. 6 Experiment In this section, we conduct experiments to evaluate the effectiveness of the joint model. We describe the experiment settings and the result analysis. 6.1 Dataset and Experiment Settings We conduct sentiment classification of tweets on a benchmark Twitter sentiment classification dataset in SemEval 2013. We run 2-class (positive vs negative) classification as sentence segmentation has a great influence on the positive/negative polarity of tweets due to t</context>
<context position="25687" citStr="Mohammad et al., 2013" startWordPosition="4028" endWordPosition="4031">wing sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStren</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif M Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013b. Nrc-canada: Building the state-ofthe-art in sentiment analysis of tweets. Proceedings of the International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
<author>Kentaro Inui</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using crfs with hidden variables.</title>
<date>2010</date>
<booktitle>In Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>786--794</pages>
<contexts>
<context position="2279" citStr="Nakagawa et al., 2010" startWordPosition="329" endWordPosition="332">ment polarity of a sentence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, b</context>
<context position="8055" citStr="Nakagawa et al. (2010)" startWordPosition="1222" endWordPosition="1225">ayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learning effective features to obtain better classification performance. On movie or product reviews, Wang and Manning (2012) present NBSVM, which trades-off 478 between Naive Bayes and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glo</context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi. 2010. Dependency tree-based sentiment classification using crfs with hidden variables. In Conference of the North American Chapter of the Association for Computational Linguistics, pages 786–794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter as a corpus for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In Proceedings of Language Resources and Evaluation Conference,</booktitle>
<volume>volume</volume>
<contexts>
<context position="7075" citStr="Pak and Paroubek, 2010" startWordPosition="1068" endWordPosition="1071">pically utilize a lexicon of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by sentiment signals like emoticons (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Zhao et al., 2012). Majority of existing approaches follow Pang et al. (2002) and employ corpus-based method for sentiment classification. Pang et al. (2002) pioneer to treat the sentiment classification of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learnin</context>
</contexts>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek. 2010. Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings of Language Resources and Evaluation Conference, volume 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgios Paltoglou</author>
<author>Mike Thelwall</author>
</authors>
<title>A study of information retrieval weighting schemes for sentiment analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1386--1395</pages>
<contexts>
<context position="2348" citStr="Paltoglou and Thelwall, 2010" startWordPosition="339" endWordPosition="342">ive, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-w</context>
<context position="7932" citStr="Paltoglou and Thelwall (2010)" startWordPosition="1204" endWordPosition="1207">on of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learning effective features to obtain better classification performance. On movie or product reviews, Wang and Manning (2012) present NBSVM, which trades-off 478 between Naive Bayes and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent stu</context>
</contexts>
<marker>Paltoglou, Thelwall, 2010</marker>
<rawString>Georgios Paltoglou and Mike Thelwall. 2010. A study of information retrieval weighting schemes for sentiment analysis. In Proceedings of Annual Meeting of the Association for Computational Linguistics, pages 1386–1395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="1809" citStr="Pang and Lee, 2008" startWordPosition="256" endWordPosition="259">ised for the segmentation model, which is optimized for enhancing the sentiment classification performance. The joint model is trained only based on the annotated sentiment polarity of sentences, without any segmentation annotations. Experiments on a benchmark Twitter sentiment classification dataset in SemEval 2013 show that, our joint model performs comparably with the state-of-the-art methods. 1 Introduction Sentiment classification, which classifies the sentiment polarity of a sentence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment cl</context>
<context position="10517" citStr="Pang and Lee, 2008" startWordPosition="1580" endWordPosition="1583">fication based on the segmentation results. 3 The Proposed Approach In this section, we first give the task definition of two tasks, namely sentiment classification and sentence segmentation. Then, we present the overview of the proposed joint segmentation and classification model (JSC) for sentiment analysis. The segmentation candidate generation model and the segmentation ranking model are described in Section 4. The details of the sentiment classification model are presented in Section 5. 3.1 Task Definition The task of sentiment classification has been well formalized in previous studies (Pang and Lee, 2008; Liu, 2012). The objective is to identify the sentiment polarity of a sentence (or document) as positive or negative 1. The task of sentence segmentation aims to split a sentence into a sequence of exclusive parts, each of which is a basic computational unit of the sentence. An example is illustrated in Table 1. The original text “that is not bad” is segmented as “[that] [is] [not bad]”. The segmentation result is composed of three basic computational units, namely [that], [is] and [not bad]. Table 1: Example for sentence segmentation. 3.2 Joint Model (JSC) The overview of the proposed joint </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="1895" citStr="Pang et al. (2002)" startWordPosition="269" endWordPosition="272">fication performance. The joint model is trained only based on the annotated sentiment polarity of sentences, without any segmentation annotations. Experiments on a benchmark Twitter sentiment classification dataset in SemEval 2013 show that, our joint model performs comparably with the state-of-the-art methods. 1 Introduction Sentiment classification, which classifies the sentiment polarity of a sentence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment</context>
<context position="6839" citStr="Pang et al., 2002" startWordPosition="1034" endWordPosition="1037"> in SemEval 2013. 2 Related Work Existing approaches for sentiment classification are dominated by two mainstream directions. Lexicon-based approaches (Turney, 2002; Ding et al., 2008; Taboada et al., 2011; Thelwall et al., 2012) typically utilize a lexicon of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by sentiment signals like emoticons (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Zhao et al., 2012). Majority of existing approaches follow Pang et al. (2002) and employ corpus-based method for sentiment classification. Pang et al. (2002) pioneer to treat the sentiment classification of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, </context>
<context position="22849" citStr="Pang et al., 2002" startWordPosition="3571" endWordPosition="3574">ven segmentation; pfx(seg) is the result of the convolutional function x E {min, max, avg}. Each convolutional function pfx(·) conducts the matrixvector operation of x on the sequence represented by columns in the lookup table of phrase embedding. The output of pfx(·) is calculated as pfx(seg) = θx(Lph)seg (5) where θx is the convolutional function of pfx; (Lph)seg is the concatenated column vectors of the basic computational units in the segmentation; Lph is the lookup table of phrase embedding. 5 Classification Model For sentiment classification, we follow the supervised learning framework (Pang et al., 2002) and build the classifier from sentences with manually labelled sentiment polarity. We extend the state-of-the-art hand-crafted features in SemEval 2013 (Mohammad et al., 2013b), and design the classification-specific features for each segmentation. The detailed feature description is given in Table 4. 6 Experiment In this section, we conduct experiments to evaluate the effectiveness of the joint model. We describe the experiment settings and the result analysis. 6.1 Dataset and Experiment Settings We conduct sentiment classification of tweets on a benchmark Twitter sentiment classification da</context>
<context position="25451" citStr="Pang et al., 2002" startWordPosition="3986" endWordPosition="3989">nd set the regularization factor A as 0.003. The beam size N of the candidate generation model and the top-ranked segmentation number K are tuned on the dev-set. 6.2 Baseline Methods We compare the proposed joint model with the following sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. •</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yelong Shen</author>
<author>Xiaodong He</author>
<author>Jianfeng Gao</author>
<author>Li Deng</author>
<author>Gr´egoire Mesnil</author>
</authors>
<title>Learning semantic representations using convolutional neural networks for web search.</title>
<date>2014</date>
<booktitle>In Proceedings of the companion publication of the 23rd international conference on World wide web companion,</booktitle>
<pages>373--374</pages>
<contexts>
<context position="21914" citStr="Shen et al., 2014" startWordPosition="3430" endWordPosition="3433">its from each of the 1,000 clusters from Twitter NLP tool (Gimpel et al., 2011) Table 4: Classification-specific features for sentiment classification. the-art phrase embedding learning algorithm. We compose the representation (or feature) of a segmentation candidate from the embedding of the basic computational units (words or phrases) it contains. In this paper, we explore min, max and average convolution functions, which have been used as simple and effective methods for composition learning in vector-based semantics (Mitchell and Lapata, 2010; Collobert et al., 2011; Socher et al., 2013a; Shen et al., 2014; Tang et al., 2014b), to calculate the representation of a segmentation candidate. The final phrase-embedding feature is the concatenation of vectors derived from different convolutional functions, as given in Equation 4, pf(seg) = [pfmax(seg),pfmin(seg),pfavg(seg)] (4) where pf(seg) is the representation of the given segmentation; pfx(seg) is the result of the convolutional function x E {min, max, avg}. Each convolutional function pfx(·) conducts the matrixvector operation of x on the sequence represented by columns in the lookup table of phrase embedding. The output of pfx(·) is calculated </context>
</contexts>
<marker>Shen, He, Gao, Deng, Mesnil, 2014</marker>
<rawString>Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Gr´egoire Mesnil. 2014. Learning semantic representations using convolutional neural networks for web search. In Proceedings of the companion publication of the 23rd international conference on World wide web companion, pages 373–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>J Pennington</author>
<author>E H Huang</author>
<author>A Y Ng</author>
<author>C D Manning</author>
</authors>
<title>Semi-supervised recursive autoencoders for predicting sentiment distributions.</title>
<date>2011</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>151--161</pages>
<contexts>
<context position="2527" citStr="Socher et al., 2011" startWordPosition="368" endWordPosition="371">n∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, bad) and (a great deal of, great). The segmentations based on bag-of-words or syntactic chunkers are not effective enough to handle the polarity inconsistency phenomenons. The reason lies in that bag-of-words segmentations regard each word as a sepa</context>
<context position="26100" citStr="Socher et al., 2011" startWordPosition="4097" endWordPosition="4100">he SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStrength: Thelwall et al. (2012) build a lexicon-based classifier which uses linguistic rules to detect the sentiment strength of tweets. • SSWE,,: Tang et al. (2014b) propose to learn sentiment-specific word embedding (SSWE) from 10M tweets collected by emoticons. They apply SSWE as features for Twitter sentiment classification. • NRC: NRC builds the state-of-the-art system in SemEval 2013 Twitter Sentiment Classi</context>
</contexts>
<marker>Socher, Pennington, Huang, Ng, Manning, 2011</marker>
<rawString>Richard Socher, J. Pennington, E.H. Huang, A.Y. Ng, and C.D. Manning. 2011. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Conference on Empirical Methods in Natural Language Processing, pages 151–161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic Compositionality Through Recursive Matrix-Vector Spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic Compositionality Through Recursive Matrix-Vector Spaces. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Danqi Chen</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Reasoning with neural tensor networks for knowledge base completion.</title>
<date>2013</date>
<booktitle>The Conference on Neural Information Processing Systems.</booktitle>
<contexts>
<context position="2300" citStr="Socher et al., 2013" startWordPosition="333" endWordPosition="336">ence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, bad) and (a great deal</context>
<context position="21894" citStr="Socher et al., 2013" startWordPosition="3426" endWordPosition="3429">ter the presence of units from each of the 1,000 clusters from Twitter NLP tool (Gimpel et al., 2011) Table 4: Classification-specific features for sentiment classification. the-art phrase embedding learning algorithm. We compose the representation (or feature) of a segmentation candidate from the embedding of the basic computational units (words or phrases) it contains. In this paper, we explore min, max and average convolution functions, which have been used as simple and effective methods for composition learning in vector-based semantics (Mitchell and Lapata, 2010; Collobert et al., 2011; Socher et al., 2013a; Shen et al., 2014; Tang et al., 2014b), to calculate the representation of a segmentation candidate. The final phrase-embedding feature is the concatenation of vectors derived from different convolutional functions, as given in Equation 4, pf(seg) = [pfmax(seg),pfmin(seg),pfavg(seg)] (4) where pf(seg) is the representation of the given segmentation; pfx(seg) is the result of the convolutional function x E {min, max, avg}. Each convolutional function pfx(·) conducts the matrixvector operation of x on the sequence represented by columns in the lookup table of phrase embedding. The output of p</context>
<context position="27283" citStr="Socher et al., 2013" startWordPosition="4280" endWordPosition="4283">emEval 2013 Twitter Sentiment Classification Track, incorporating diverse sentiment lexicons and hand-crafted features (Mohammad et al., 2013b). We re-implement this system because the codes are not publicly available. We do not directly report their results in the evaluation task, as our training and development sets are smaller than their dataset. In NRC + PF, We concatenate the NRC features and the phrase embeddings feature (PF), and build the sentiment classifier with LibLinear. Except for DistSuper, other baseline methods are conducted in a supervised manner. We do not compare with RNTN (Socher et al., 2013b) because the tweets in our dataset do not have accurately parsed results. Another reason is that, due to the differences between domains, the performance of RNTN trained on movie reviews might be decreased if directly applied on the tweets (Xiao et al., 2013). 6.3 Results and Analysis Table 6 shows the macro-F1 of the baseline systems as well as our joint model (JSC) on sentiment classification of tweets (positive vs negative). As is shown in Table 6, distant supervision is relatively weak because the noisy-labeled tweets are treated as the gold standard, which decreases the performance of s</context>
</contexts>
<marker>Socher, Chen, Manning, Ng, 2013</marker>
<rawString>Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Y Ng. 2013a. Reasoning with neural tensor networks for knowledge base completion. The Conference on Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1631--1642</pages>
<contexts>
<context position="2300" citStr="Socher et al., 2013" startWordPosition="333" endWordPosition="336">ence (or document) as positive or negative, is a major research direction in the field of sentiment analysis (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). Majority of existing approaches follow Pang et al. (2002) and treat sen∗ This work was partly done when the first and fourth authors were visiting Microsoft Research. timent classification as a special case of text categorization task. Under this perspective, previous studies typically use pipelined methods with two steps. They first produce sentence segmentations with separate text analyzers (Choi and Cardie, 2008; Nakagawa et al., 2010; Socher et al., 2013b) or bag-of-words (Paltoglou and Thelwall, 2010; Maas et al., 2011). Then, feature learning and sentiment classification algorithms take the segmentation results as inputs to build the sentiment classifier (Socher et al., 2011; Kalchbrenner et al., 2014; Dong et al., 2014). The major disadvantage of a pipelined method is the problem of error propagation, since sentence segmentation errors cannot be corrected by the sentiment classification model. A typical kind of error is caused by the polarity inconsistency between a phrase and the words it contains, such as (not bad, bad) and (a great deal</context>
<context position="21894" citStr="Socher et al., 2013" startWordPosition="3426" endWordPosition="3429">ter the presence of units from each of the 1,000 clusters from Twitter NLP tool (Gimpel et al., 2011) Table 4: Classification-specific features for sentiment classification. the-art phrase embedding learning algorithm. We compose the representation (or feature) of a segmentation candidate from the embedding of the basic computational units (words or phrases) it contains. In this paper, we explore min, max and average convolution functions, which have been used as simple and effective methods for composition learning in vector-based semantics (Mitchell and Lapata, 2010; Collobert et al., 2011; Socher et al., 2013a; Shen et al., 2014; Tang et al., 2014b), to calculate the representation of a segmentation candidate. The final phrase-embedding feature is the concatenation of vectors derived from different convolutional functions, as given in Equation 4, pf(seg) = [pfmax(seg),pfmin(seg),pfavg(seg)] (4) where pf(seg) is the representation of the given segmentation; pfx(seg) is the result of the convolutional function x E {min, max, avg}. Each convolutional function pfx(·) conducts the matrixvector operation of x on the sequence represented by columns in the lookup table of phrase embedding. The output of p</context>
<context position="27283" citStr="Socher et al., 2013" startWordPosition="4280" endWordPosition="4283">emEval 2013 Twitter Sentiment Classification Track, incorporating diverse sentiment lexicons and hand-crafted features (Mohammad et al., 2013b). We re-implement this system because the codes are not publicly available. We do not directly report their results in the evaluation task, as our training and development sets are smaller than their dataset. In NRC + PF, We concatenate the NRC features and the phrase embeddings feature (PF), and build the sentiment classifier with LibLinear. Except for DistSuper, other baseline methods are conducted in a supervised manner. We do not compare with RNTN (Socher et al., 2013b) because the tweets in our dataset do not have accurately parsed results. Another reason is that, due to the differences between domains, the performance of RNTN trained on movie reviews might be decreased if directly applied on the tweets (Xiao et al., 2013). 6.3 Results and Analysis Table 6 shows the macro-F1 of the baseline systems as well as our joint model (JSC) on sentiment classification of tweets (positive vs negative). As is shown in Table 6, distant supervision is relatively weak because the noisy-labeled tweets are treated as the gold standard, which decreases the performance of s</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013b. Recursive deep models for semantic compositionality over a sentiment treebank. In Conference on Empirical Methods in Natural Language Processing, pages 1631–1642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational linguistics,</journal>
<pages>37--2</pages>
<contexts>
<context position="6426" citStr="Taboada et al., 2011" startWordPosition="971" endWordPosition="974">ethods in various experiment settings. The main contributions of the work presented in this paper are as follows. • To our knowledge, this is the first work that automatically produces sentence segmentation for sentiment classification within a joint framework. • We show that the joint model yields comparable performance with the state-of-the-art methods on the benchmark Twitter sentiment classification datasets in SemEval 2013. 2 Related Work Existing approaches for sentiment classification are dominated by two mainstream directions. Lexicon-based approaches (Turney, 2002; Ding et al., 2008; Taboada et al., 2011; Thelwall et al., 2012) typically utilize a lexicon of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by sentiment signals like e</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duyu Tang</author>
<author>Furu Wei</author>
<author>Bing Qin</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
</authors>
<title>Building large-scale twitterspecific sentiment lexicon : A representation learning approach.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics,</booktitle>
<pages>172--182</pages>
<contexts>
<context position="9563" citStr="Tang et al. (2014" startWordPosition="1443" endWordPosition="1446">encoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabilistic document model following Blei et al. (2003), Labutov and Lipson (2013) re-embed words from existing word embeddings and Tang et al. (2014b) develop three neural networks to learn word vectors from tweets containing positive/negative emoticons. Unlike most previous corpus-based algorithms that build sentiment classifier based on splitting a sentence as a word sequence, we produce sentence segmentations automatically within a joint framework, and conduct sentiment classification based on the segmentation results. 3 The Proposed Approach In this section, we first give the task definition of two tasks, namely sentiment classification and sentence segmentation. Then, we present the overview of the proposed joint segmentation and cla</context>
<context position="19935" citStr="Tang et al., 2014" startWordPosition="3124" endWordPosition="3127">its of each segmentation candidate might be words or phrases of variable length. Under this scenario, phrase embedding is highly suitable as it is capable to represent phrases with different length into a consistent distributed vector space (Mikolov et al., 2013). For each phrase, phrase embedding is a dense, real-valued and continuous vector. After the phrase embedding is trained, the nearest neighbors in the embedding space are favored to have similar grammatical usages and semantic meanings. The effectiveness of phrase embedding has been verified for building large-scale sentiment lexicon (Tang et al., 2014a) and machine translation (Zhang et al., 2014). We learn phrase embedding with Skip-Gram model (Mikolov et al., 2013), which is the state-ofloss = − � |T| i=1 481 Feature Feature Description the number of basic computation units in the segmentation candidate the ratio of units’ number in a candidate to the length of original sentence the difference between sentence length and the number of basic computational units the number of basic component units composed of more than two words #unit #unit / #word #word − #unit #unit &gt; 2 Table 3: Segmentation-specific features for segmentation ranking. Fe</context>
<context position="21933" citStr="Tang et al., 2014" startWordPosition="3434" endWordPosition="3437">e 1,000 clusters from Twitter NLP tool (Gimpel et al., 2011) Table 4: Classification-specific features for sentiment classification. the-art phrase embedding learning algorithm. We compose the representation (or feature) of a segmentation candidate from the embedding of the basic computational units (words or phrases) it contains. In this paper, we explore min, max and average convolution functions, which have been used as simple and effective methods for composition learning in vector-based semantics (Mitchell and Lapata, 2010; Collobert et al., 2011; Socher et al., 2013a; Shen et al., 2014; Tang et al., 2014b), to calculate the representation of a segmentation candidate. The final phrase-embedding feature is the concatenation of vectors derived from different convolutional functions, as given in Equation 4, pf(seg) = [pfmax(seg),pfmin(seg),pfavg(seg)] (4) where pf(seg) is the representation of the given segmentation; pfx(seg) is the result of the convolutional function x E {min, max, avg}. Each convolutional function pfx(·) conducts the matrixvector operation of x on the sequence represented by columns in the lookup table of phrase embedding. The output of pfx(·) is calculated as pfx(seg) = θx(Lp</context>
<context position="26447" citStr="Tang et al. (2014" startWordPosition="4150" endWordPosition="4153">he negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStrength: Thelwall et al. (2012) build a lexicon-based classifier which uses linguistic rules to detect the sentiment strength of tweets. • SSWE,,: Tang et al. (2014b) propose to learn sentiment-specific word embedding (SSWE) from 10M tweets collected by emoticons. They apply SSWE as features for Twitter sentiment classification. • NRC: NRC builds the state-of-the-art system in SemEval 2013 Twitter Sentiment Classification Track, incorporating diverse sentiment lexicons and hand-crafted features (Mohammad et al., 2013b). We re-implement this system because the codes are not publicly available. We do not directly report their results in the evaluation task, as our training and development sets are smaller than their dataset. In NRC + PF, We concatenate the</context>
</contexts>
<marker>Tang, Wei, Qin, Zhou, Liu, 2014</marker>
<rawString>Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting Liu. 2014a. Building large-scale twitterspecific sentiment lexicon : A representation learning approach. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics, pages 172–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duyu Tang</author>
<author>Furu Wei</author>
<author>Nan Yang</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
<author>Bing Qin</author>
</authors>
<title>Learning sentimentspecific word embedding for twitter sentiment classification.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1555--1565</pages>
<contexts>
<context position="9563" citStr="Tang et al. (2014" startWordPosition="1443" endWordPosition="1446">encoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabilistic document model following Blei et al. (2003), Labutov and Lipson (2013) re-embed words from existing word embeddings and Tang et al. (2014b) develop three neural networks to learn word vectors from tweets containing positive/negative emoticons. Unlike most previous corpus-based algorithms that build sentiment classifier based on splitting a sentence as a word sequence, we produce sentence segmentations automatically within a joint framework, and conduct sentiment classification based on the segmentation results. 3 The Proposed Approach In this section, we first give the task definition of two tasks, namely sentiment classification and sentence segmentation. Then, we present the overview of the proposed joint segmentation and cla</context>
<context position="19935" citStr="Tang et al., 2014" startWordPosition="3124" endWordPosition="3127">its of each segmentation candidate might be words or phrases of variable length. Under this scenario, phrase embedding is highly suitable as it is capable to represent phrases with different length into a consistent distributed vector space (Mikolov et al., 2013). For each phrase, phrase embedding is a dense, real-valued and continuous vector. After the phrase embedding is trained, the nearest neighbors in the embedding space are favored to have similar grammatical usages and semantic meanings. The effectiveness of phrase embedding has been verified for building large-scale sentiment lexicon (Tang et al., 2014a) and machine translation (Zhang et al., 2014). We learn phrase embedding with Skip-Gram model (Mikolov et al., 2013), which is the state-ofloss = − � |T| i=1 481 Feature Feature Description the number of basic computation units in the segmentation candidate the ratio of units’ number in a candidate to the length of original sentence the difference between sentence length and the number of basic computational units the number of basic component units composed of more than two words #unit #unit / #word #word − #unit #unit &gt; 2 Table 3: Segmentation-specific features for segmentation ranking. Fe</context>
<context position="21933" citStr="Tang et al., 2014" startWordPosition="3434" endWordPosition="3437">e 1,000 clusters from Twitter NLP tool (Gimpel et al., 2011) Table 4: Classification-specific features for sentiment classification. the-art phrase embedding learning algorithm. We compose the representation (or feature) of a segmentation candidate from the embedding of the basic computational units (words or phrases) it contains. In this paper, we explore min, max and average convolution functions, which have been used as simple and effective methods for composition learning in vector-based semantics (Mitchell and Lapata, 2010; Collobert et al., 2011; Socher et al., 2013a; Shen et al., 2014; Tang et al., 2014b), to calculate the representation of a segmentation candidate. The final phrase-embedding feature is the concatenation of vectors derived from different convolutional functions, as given in Equation 4, pf(seg) = [pfmax(seg),pfmin(seg),pfavg(seg)] (4) where pf(seg) is the representation of the given segmentation; pfx(seg) is the result of the convolutional function x E {min, max, avg}. Each convolutional function pfx(·) conducts the matrixvector operation of x on the sequence represented by columns in the lookup table of phrase embedding. The output of pfx(·) is calculated as pfx(seg) = θx(Lp</context>
<context position="26447" citStr="Tang et al. (2014" startWordPosition="4150" endWordPosition="4153">he negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStrength: Thelwall et al. (2012) build a lexicon-based classifier which uses linguistic rules to detect the sentiment strength of tweets. • SSWE,,: Tang et al. (2014b) propose to learn sentiment-specific word embedding (SSWE) from 10M tweets collected by emoticons. They apply SSWE as features for Twitter sentiment classification. • NRC: NRC builds the state-of-the-art system in SemEval 2013 Twitter Sentiment Classification Track, incorporating diverse sentiment lexicons and hand-crafted features (Mohammad et al., 2013b). We re-implement this system because the codes are not publicly available. We do not directly report their results in the evaluation task, as our training and development sets are smaller than their dataset. In NRC + PF, We concatenate the</context>
</contexts>
<marker>Tang, Wei, Yang, Zhou, Liu, Qin, 2014</marker>
<rawString>Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin. 2014b. Learning sentimentspecific word embedding for twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1555–1565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Paltoglou</author>
</authors>
<title>Sentiment strength detection for the social web.</title>
<date>2012</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>63</volume>
<issue>1</issue>
<contexts>
<context position="6450" citStr="Thelwall et al., 2012" startWordPosition="975" endWordPosition="978">riment settings. The main contributions of the work presented in this paper are as follows. • To our knowledge, this is the first work that automatically produces sentence segmentation for sentiment classification within a joint framework. • We show that the joint model yields comparable performance with the state-of-the-art methods on the benchmark Twitter sentiment classification datasets in SemEval 2013. 2 Related Work Existing approaches for sentiment classification are dominated by two mainstream directions. Lexicon-based approaches (Turney, 2002; Ding et al., 2008; Taboada et al., 2011; Thelwall et al., 2012) typically utilize a lexicon of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by sentiment signals like emoticons (Go et al., 200</context>
<context position="26314" citStr="Thelwall et al. (2012)" startWordPosition="4129" endWordPosition="4132">https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStrength: Thelwall et al. (2012) build a lexicon-based classifier which uses linguistic rules to detect the sentiment strength of tweets. • SSWE,,: Tang et al. (2014b) propose to learn sentiment-specific word embedding (SSWE) from 10M tweets collected by emoticons. They apply SSWE as features for Twitter sentiment classification. • NRC: NRC builds the state-of-the-art system in SemEval 2013 Twitter Sentiment Classification Track, incorporating diverse sentiment lexicons and hand-crafted features (Mohammad et al., 2013b). We re-implement this system because the codes are not publicly available. We do not directly report their</context>
</contexts>
<marker>Thelwall, Buckley, Paltoglou, 2012</marker>
<rawString>Mike Thelwall, Kevan Buckley, and Georgios Paltoglou. 2012. Sentiment strength detection for the social web. Journal of the American Society for Information Science and Technology, 63(1):163–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="6385" citStr="Turney, 2002" startWordPosition="965" endWordPosition="966">nsistently outperforms pipeline methods in various experiment settings. The main contributions of the work presented in this paper are as follows. • To our knowledge, this is the first work that automatically produces sentence segmentation for sentiment classification within a joint framework. • We show that the joint model yields comparable performance with the state-of-the-art methods on the benchmark Twitter sentiment classification datasets in SemEval 2013. 2 Related Work Existing approaches for sentiment classification are dominated by two mainstream directions. Lexicon-based approaches (Turney, 2002; Ding et al., 2008; Taboada et al., 2011; Thelwall et al., 2012) typically utilize a lexicon of sentiment words, each of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corp</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proceedings of Annual Meeting of the Association for Computational Linguistics, pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sida Wang</author>
<author>Christopher D Manning</author>
</authors>
<title>Baselines and bigrams: Simple, good sentiment and topic classification.</title>
<date>2012</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>90--94</pages>
<contexts>
<context position="7793" citStr="Wang and Manning (2012)" startWordPosition="1182" endWordPosition="1186">l. (2002) and employ corpus-based method for sentiment classification. Pang et al. (2002) pioneer to treat the sentiment classification of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learning effective features to obtain better classification performance. On movie or product reviews, Wang and Manning (2012) present NBSVM, which trades-off 478 between Naive Bayes and NB-feature enhanced SVM. Kim and Zhai (2009) and Paltoglou and Thelwall (2010) learn the feature weights by investigating variants weighting functions from Information Retrieval. Nakagawa et al. (2010) utilize dependency trees, polarity-shifting rules and conditional random fields (Lafferty et al., 2001) with hidden variables to compute the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With</context>
<context position="25908" citStr="Wang and Manning, 2012" startWordPosition="4067" endWordPosition="4070">., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning sentence representation. We train the RAE using the pre-trained phrase embedding learned from 100M tweets. • SentiStrength: Thelwall et al. (2012) build a lexicon-based classifier which uses linguistic rules to detect the sentiment strength of tweets. • SSWE,,: Tang et al. (2014b) propose to learn sentiment-specific word embedding (SSWE) </context>
</contexts>
<marker>Wang, Manning, 2012</marker>
<rawString>Sida Wang and Christopher D Manning. 2012. Baselines and bigrams: Simple, good sentiment and topic classification. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 90–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="25570" citStr="Wilson et al., 2005" startWordPosition="4010" endWordPosition="4013">mentation number K are tuned on the dev-set. 6.2 Baseline Methods We compare the proposed joint model with the following sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) trades-off between Naive Bayes and NBfeatures enhanced SVM. We use NBSVM-bi because it performs best on sentiment classification of reviews. • RAE: Recursive Autoencoder (Socher et al., 2011) has been proven effective for sentiment classification by learning se</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 347–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Xiao</author>
<author>Feipeng Zhao</author>
<author>Yuhong Guo</author>
</authors>
<title>Learning latent word representations for domain adaptation using supervised word clustering.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>152--162</pages>
<contexts>
<context position="27544" citStr="Xiao et al., 2013" startWordPosition="4326" endWordPosition="4329">the evaluation task, as our training and development sets are smaller than their dataset. In NRC + PF, We concatenate the NRC features and the phrase embeddings feature (PF), and build the sentiment classifier with LibLinear. Except for DistSuper, other baseline methods are conducted in a supervised manner. We do not compare with RNTN (Socher et al., 2013b) because the tweets in our dataset do not have accurately parsed results. Another reason is that, due to the differences between domains, the performance of RNTN trained on movie reviews might be decreased if directly applied on the tweets (Xiao et al., 2013). 6.3 Results and Analysis Table 6 shows the macro-F1 of the baseline systems as well as our joint model (JSC) on sentiment classification of tweets (positive vs negative). As is shown in Table 6, distant supervision is relatively weak because the noisy-labeled tweets are treated as the gold standard, which decreases the performance of sentiment classifier. The result of bag-of-unigram feature (74.50%) is not satisfied as it losses the word order and does not well cap483 Method Macro-F1 DistSuper + unigram 61.74 DistSuper + 5-gram 63.92 SVM + unigram 74.50 SVM + 5-gram 74.97 Recursive Autoenco</context>
</contexts>
<marker>Xiao, Zhao, Guo, 2013</marker>
<rawString>Min Xiao, Feipeng Zhao, and Yuhong Guo. 2013. Learning latent word representations for domain adaptation using supervised word clustering. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 152– 162, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ainur Yessenalina</author>
<author>Claire Cardie</author>
</authors>
<title>Compositional matrix-space models for sentiment analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>172--182</pages>
<contexts>
<context position="8821" citStr="Yessenalina and Cardie (2011)" startWordPosition="1332" endWordPosition="1335"> the document feature. On Twitter, Mohammad et al. (2013b) develop a state-of-the-art Twitter sentiment classifier in SemEval 2013, using a variety of sentiment lexicons and hand-crafted features. With the revival of deep learning (representation learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2013; Jones, 2014)), more recent studies focus on learning the low-dimensional, dense and real-valued vector as text features for sentiment classification. Glorot et al. (2011) investigate Stacked Denoising Autoencoders to learn document vector for domain adaptation in sentiment classification. Yessenalina and Cardie (2011) represent each word as a matrix and compose words using iterated matrix multiplication. Socher et al. propose Recursive Autoencoder (RAE) (2011), Matrix-Vector Recursive Neural Network (MV-RNN) (2012) and Recursive Neural Tensor Network (RNTN) (2013b) to learn the composition of variable-length phrases based on the representation of its children. To learn the sentence representation, Kalchbrenner et al. (2014) exploit Dynamic Convolutional Neural Network and Le and Mikolov (2014) investigate Paragraph Vector. To learn word vectors for sentiment analysis, Maas et al. (2011) propose a probabili</context>
</contexts>
<marker>Yessenalina, Cardie, 2011</marker>
<rawString>Ainur Yessenalina and Claire Cardie. 2011. Compositional matrix-space models for sentiment analysis. In Proceedings of Conference on Empirical Methods in Natural Language Processing, pages 172–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiajun Zhang</author>
<author>Shujie Liu</author>
<author>Mu Li</author>
<author>Ming Zhou</author>
<author>Chengqing Zong</author>
</authors>
<title>Bilingually-constrained phrase embeddings for machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>111--121</pages>
<contexts>
<context position="19982" citStr="Zhang et al., 2014" startWordPosition="3131" endWordPosition="3134">ords or phrases of variable length. Under this scenario, phrase embedding is highly suitable as it is capable to represent phrases with different length into a consistent distributed vector space (Mikolov et al., 2013). For each phrase, phrase embedding is a dense, real-valued and continuous vector. After the phrase embedding is trained, the nearest neighbors in the embedding space are favored to have similar grammatical usages and semantic meanings. The effectiveness of phrase embedding has been verified for building large-scale sentiment lexicon (Tang et al., 2014a) and machine translation (Zhang et al., 2014). We learn phrase embedding with Skip-Gram model (Mikolov et al., 2013), which is the state-ofloss = − � |T| i=1 481 Feature Feature Description the number of basic computation units in the segmentation candidate the ratio of units’ number in a candidate to the length of original sentence the difference between sentence length and the number of basic computational units the number of basic component units composed of more than two words #unit #unit / #word #word − #unit #unit &gt; 2 Table 3: Segmentation-specific features for segmentation ranking. Feature Feature Description All-Caps the number o</context>
</contexts>
<marker>Zhang, Liu, Li, Zhou, Zong, 2014</marker>
<rawString>Jiajun Zhang, Shujie Liu, Mu Li, Ming Zhou, and Chengqing Zong. 2014. Bilingually-constrained phrase embeddings for machine translation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 111–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jichang Zhao</author>
<author>Li Dong</author>
<author>Junjie Wu</author>
<author>Ke Xu</author>
</authors>
<title>Moodlens: an emoticon-based sentiment analysis system for chinese tweets.</title>
<date>2012</date>
<booktitle>In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining.</booktitle>
<contexts>
<context position="7120" citStr="Zhao et al., 2012" startWordPosition="1076" endWordPosition="1079">h of which is annotated with the sentiment polarity or sentiment strength. Linguistic rules such as intensifications and negations are usually incorporated to aggregate the sentiment polarity of sentences (or documents). Corpusbased methods treat sentiment classification as a special case of text categorization task (Pang et al., 2002). They mostly build the sentiment classifier from sentences (or documents) with manually annotated sentiment polarity or distantly-supervised corpora collected by sentiment signals like emoticons (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Zhao et al., 2012). Majority of existing approaches follow Pang et al. (2002) and employ corpus-based method for sentiment classification. Pang et al. (2002) pioneer to treat the sentiment classification of reviews as a special case of text categorization problem and first investigate machine learning methods. They employ Naive Bayes, Maximum Entropy and Support Vector Machines (SVM) with a diverse set of features. In their experiments, the best performance is achieved by SVM with bagof-words feature. Under this perspective, many studies focus on designing or learning effective features to obtain better classif</context>
<context position="25312" citStr="Zhao et al., 2012" startWordPosition="3964" endWordPosition="3967"> unigram to 5-gram. The parameter -c in SVM is tuned on the dev-set in both baseline and our method. We run the L-BFGS for 50 iterations, and set the regularization factor A as 0.003. The beam size N of the candidate generation model and the top-ranked segmentation number K are tuned on the dev-set. 6.2 Baseline Methods We compare the proposed joint model with the following sentiment classification algorithms: • DistSuper: We collect 10M balanced tweets selected by positive and negative emoticons 5 as training data, and build classifier using the LibLinear and ngram features (Go et al., 2009; Zhao et al., 2012). • SVM: The n-gram features and Support Vector Machine are widely-used baseline methods to build sentiment classifiers (Pang et al., 2002). We use LibLinear to train the SVM classifier. 3In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion Lexicon (Mohammad and Turney, 2012), NRC Hashtag Lexicon and Sentiment140Lexicon (Mohammad et al., 2013b). 4https://code.google.com/p/word2vec/ 5We use the emoticons selected by Hu et al. (2013). The positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( . • NBSVM: NBSVM (Wang and Manning, 2012) tra</context>
</contexts>
<marker>Zhao, Dong, Wu, Xu, 2012</marker>
<rawString>Jichang Zhao, Li Dong, Junjie Wu, and Ke Xu. 2012. Moodlens: an emoticon-based sentiment analysis system for chinese tweets. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>