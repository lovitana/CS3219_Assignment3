<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9989575">
Automatic Inference of the Tense of Chinese Events Using Implicit
Linguistic Information
</title>
<author confidence="0.992508">
Yuchen Zhang
</author>
<affiliation confidence="0.963844">
Brandeis University
</affiliation>
<address confidence="0.8980375">
415 South Street
Waltham, MA
</address>
<email confidence="0.995442">
yuchenz@brandeis.edu
</email>
<sectionHeader confidence="0.984751" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988782608696">
We address the problem of automatically
inferring the tense of events in Chinese
text. We use a new corpus annotated with
Chinese semantic tense information and
other implicit Chinese linguistic informa-
tion using a “distant annotation” method.
We propose three improvements over a rel-
atively strong baseline method – a statisti-
cal learning method with extensive feature
engineering. First, we add two sources
of implicit linguistic information as fea-
tures – eventuality type and modality of
an event, which are also inferred automat-
ically. Second, we perform joint learning
on semantic tense, eventuality type, and
modality of an event. Third, we train arti-
ficial neural network models for this prob-
lem and compare its performance with
feature-based approaches. Experimental
results show considerable improvements
on Chinese tense inference. Our best per-
formance reaches 68.6% in accuracy, out-
performing a strong baseline method.
</bodyText>
<sectionHeader confidence="0.992546" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999983">
As a language with no grammatical tense, Chinese
does not encode the temporal location of an event
directly in a verb, while in English, the grammati-
cal tense of a verb is a strong indicator of the tem-
poral location of an event. In this paper we ad-
dress the problem of inferring the semantic tense,
or the temporal location of an event (e.g., present,
past, future) in Chinese text. The semantic tense is
defined relative to the utterance time or document
creation time, and it does not always agree with
the grammatical tense in languages like English
where there is grammatical tense. Inferring se-
mantic tense potentially benefits natural language
processing tasks such as Machine Translation and
</bodyText>
<note confidence="0.97946675">
Nianwen Xue
Brandeis University
415 South Street
Waltham, MA
</note>
<email confidence="0.64359">
xuen@brandeis.edu
</email>
<note confidence="0.659370333333333">
Information Extraction (Xue, 2008; Reichart and
Rappoport, 2010; Ye et al., 2006; Ye, 2007; Liu et
al., 2011), but previous work has shown that auto-
</note>
<bodyText confidence="0.999432421052632">
matic inference of the semantic tense of events in
Chinese is a very challenging task (Xue, 2008; Ye
et al., 2006; Liu et al., 2011).
There are at least two reasons why this is a dif-
ficult problem. First, since Chinese does not have
grammatical tense which could serve as an impor-
tant clue when annotating the semantic tense of
an event, generating consistent annotation for Chi-
nese semantic tense has proved to be a challenge.
Xue and Zhang (2014) use a “distant annotation”
method to address this problem. They take advan-
tage of an English-Chinese parallel corpus with
manual word alignments (Li et al., 2012) , and per-
form annotation on the English side, which pro-
vides more explicit information such as grammati-
cal tense that helps annotators decide the appropri-
ate semantic tense. The annotations are then pro-
jected to the Chinese side via the word alignments.
They show consistent annotation agreements on
semantic tense. Second, the lack of grammatical
tense also makes automatic inference of Chinese
semantic tense challenging since the grammatical
tense would be an important source of information
for predicting the semantic tense. Previous work
has shown that it is very difficult to achieve high
accuracy using standard machine learning tech-
niques such as Maximum Entropy and Conditional
Random Field classifiers combined with extensive
feature engineering.
We address these challenges in two ways. First
of all, we take advantage of the newly annotated
corpus described in (Xue and Zhang, 2014) in
which semantic tense is annotated together with
eventuality type and modality using the distant an-
notation method. This makes it possible to use
these two additional sources of information to help
predict tense. Eventuality type and modality are
intricately tied to tense. For example, Smith and
</bodyText>
<page confidence="0.454183">
1902
</page>
<note confidence="0.9727625">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1902–1911,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999982486486487">
Erbaugh (2005) show that states by default hold in
the present but (episodic) events occur by default
in the past. This means knowing the eventuality
type of an event would help determine the tense.
Eventuality type and modality are also annotated
on the English side and then projected onto the
Chinese side via manual word alignments, taking
advantage of the rich morphosyntactic clues in En-
glish. High inter-annotator agreement scores are
also reported on eventuality type and modality.
We experimented with two ways of using even-
tuality type and modality information. In the first
approach, we first train statistical machine learn-
ing models to predict eventuality type and modal-
ity and then use these two sources of information
as features to predict semantic tense. In the sec-
ond approach we trained joint learning models be-
tween semantic tense and eventuality type, and be-
tween semantic tense and modality. We show both
approaches improve the tense inference accuracy
over a baseline where these two sources of infor-
mation are not used. Second, in our statistical
machine learning experiments on tense inference
using feature engineering, we find that the design
of feature templates has great influence on the re-
sults. So in order to explore more possible feature
combinations and mitigate the feature engineering
work, we apply artificial neural network models to
this problem. This shows improvements on tense
inference accuracy as well in some of the experi-
ment settings.
The rest of the paper is organized as follows.
Section 2 discusses related work in automatic
tense inference. Section 3 briefly introduces the
distant annotation method. In section 4, we de-
scribe our experiments and analyze the experimen-
tal results. We conclude this paper in section 7.
</bodyText>
<sectionHeader confidence="0.999443" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999687031746032">
Inferring the semantic tense of events in Chinese
text is not a new topic. There have been several
attempts at it, yet high accuracy in this task has
proved to be elusive. Using a corpus with tense
annotated directly in Chinese text, Xue (2008) per-
formed extensive feature engineering in a machine
learning framework to address this problem. They
used both local lexical features and structured fea-
tures extracted from manually annotated syntactic
parsing trees. In our baseline method, we adopt
most of their features as the baseline, only on a
new corpus in which semantic tenses are not an-
notated directly on Chinese events but projected
from annotations from the English side of a par-
allel Chinese-English corpus. In our experiments,
we also use structural features extracted from au-
tomatic parse trees, so our experimental settings
are more realistic.
Ye et al. (2006) took a similar approach in
which they predict tense with feature engineering
in a statistical learning framework. They also used
a Chinese-English parallel corpus and projected
tense for English events onto Chinese events via
human alignments. The main difference between
their data and ours is that they used the gram-
matical tense of the English events, while we use
human-annotated semantic tense which we believe
are more “transferrable” across languages as it
is free of the language-specific idiosyncrasies of
grammatical tense. In addition, they also used hu-
man annotated linguistic information as “latent”
features in their work, which are similar to our
implicit linguistic features. However, the “latent”
features that they used in their system are human-
annotated, while the eventuality type and modality
features in our system are predicted automatically.
Another difference is that they ignored events that
are not verbs. For example, they excluded ver-
bal expressions in Chinese that are translated into
nominal phrases in English. In contrast, we kept
all events in our data, and they can be realized as
verbs, nouns, as well as words in other parts of
speech. We performed separate experiments on
events realized as verbal expressions and events
not in verbal expressions to investigate their im-
pact on semantic tense inference.
Liu et al. (2011) introduced more global fea-
tures in a machine learning framework, and on
top of that proposed an iterative learning algorithm
which better handles noisy data, but they also ig-
nored events that are not realized as verbal ex-
pressions, or events that are verbal expressions but
have more than one verb in them. They mainly
focused on events that are one-verb expressions.
In a similar work on inferring tense in English
text, Reichart and Rappoport (2010) aimed at in-
ferring fine-grained semantic tenses for events in
English. They introduced a fine-grained sense tax-
onomy for tense in a more general Tense Sense
Disambiguation (TSD) task to annotate and dis-
ambiguate semantic tenses. The underlying senses
include “things that are always true”, “general and
repeated actions and habits”, “plans, expectations
</bodyText>
<page confidence="0.427136">
1903
</page>
<bodyText confidence="0.9997652">
and hopes”, etc., which encode a combination of
tense, eventuality type and modality. In the corpus
that we use, the same information is organized in
a more structured manner along three dimensions
– semantic tense, eventuality type, and modality.
</bodyText>
<sectionHeader confidence="0.984042" genericHeader="method">
3 Distant Annotation
</sectionHeader>
<bodyText confidence="0.99990084">
Figure 1 shows the distant annotation procedure
from (Xue and Zhang, 2014). Starting with a
word-aligned parallel English-Chinese corpus, all
sentences are part-of-speech (POS) tagged first
and then all verb instances in the English text as
well as expressions aligned with verb instances
on the Chinese side are targeted for annotation.
As we will show in Section 4, these expressions
include verbs as well as nouns, prepositions and
word sequences “headed” by a verb. We consider
those expressions as events. Annotators work only
on the English side and tag every event with a
pre-defined semantic tense label. These labels are
then projected from the English side to the Chi-
nese side via word alignments. The resulting cor-
pus contains events annotated with semantic tense
labels in both languages. Categories for seman-
tic tense are “Past”, “Present”, “Future”, “Relative
Past”, “Relative Present”, “Relative Future”, and
“None”.
Events annotated with relative tenses are also
linked to another event that serves as the tempo-
ral reference for the event in question. In some
cases the relative tense can be resolved to an ab-
solute tense. For example, if an event is anno-
tated with a “relative past” tense to a reference
event that is annotated with a present tense, then
the semantic tense of that event can resolve to an
absolute “past” tense. In other cases, they can
not be resolved. For example, if an event is la-
beled with a “relative future” tense and the refer-
ence event has a past tense, then its tense cannot
be resolved to an absolute tense, which is defined
with regard to the utterance time or document cre-
ation time. In our work, where possible, we re-
solve these links and keep only absolute tense la-
bels. For events with relative tenses that can not
be resolved (i.e. events which are “Relative Fu-
ture” to “Past” events, or events which are “Rela-
tive Past” to “Future” events), we use “None” as
the default label.
Eventuality type and modality are labeled in the
same way as auxiliary annotation that can help
with the inference of tense. Labels for eventual-
ity type include “Episodic”, “Habitual”, “State”,
“Progressive”, “Completed”, and “None”. Labels
for modality are “Actual”, “Intended”, “Hypothet-
ical”, “Modalized”, and “None”. Readers are ref-
ered to (Xue and Zhang, 2014) for detailed expla-
nations of each label.
</bodyText>
<figureCaption confidence="0.998449">
Figure 1: Distant annotation procedure.
</figureCaption>
<bodyText confidence="0.997404444444444">
As we mentioned in Section 2, in this corpus
not only verbs but also their counterparts on the
opposite language are considered as events, yield-
ing events that may not be verbs. For example,
in the following sentence pair (1), the Chinese
verb (VV) “f 1J,ffl” is aligned with an English noun
(NN) “use”. In the sentence pair (2), the English
verb (VBG) “opening” is aligned with an Chinese
noun (NN) “)FSC”.
</bodyText>
<listItem confidence="0.65058475">
(1) Statistics show that , in the past five years ,
Guangxi’s foreign trade and its use of foreign
investments has expanded rapidly.
��������������% ��
*pf 1J,ffl(li4yong4)
(2) Beihai has already become a bright star aris-
ing from China’s policy of opening up to the
outside world.
</listItem>
<equation confidence="0.6245125">
J M EhAt,rPQ3% ff)W(kai1fang4) rP
��������
</equation>
<bodyText confidence="0.999633">
In this corpus, events could be either one verb,
or a verb compound, or a verb sequence “headed”
by a verb, or even nouns and words of other parts
of speech.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999263">
4.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999466">
Xue and Zhang (2014) annotated semantic tense,
eventuality type and modality on top of the Par-
allel Aligned Treebank (Li et al., 2012), a corpus
</bodyText>
<page confidence="0.536248">
1904
</page>
<bodyText confidence="0.977763826086957">
of word-aligned Chinese-English sentences tree-
banked based on the Penn TreeBank (Marcus et
al., 1993) and the Chinese TreeBank (Xue et al.,
2005) standards. Human annotation of tense is
performed on the newswire and webblog sections
of this corpus. They report that the average pair-
wise agreement among three annotators consis-
tently stays above 80% and the average Kappa
score consistently exceeds 70%, indicating reli-
able annotation.
Apart from using the entire corpus, we also con-
ducted experiments on three different subsets of
the corpus. An examination of the data indicates
that newswire data is grammatically more for-
mal and complete than webblog data, so we also
conducted separate experiments on newswire data
only. Considering that the diversity of the parts
of speech of the events may affect the inference
accuracy and that most of our features extracted
from the parse trees assume that our events being
verbs, we also conducted experiments exclusively
on “v events”. “v events” consist of two parts.
One part is events that are realized as a single word
and the word is a verb; the other one is events
which have multiple words but there is only one
verb among them. In the latter case, we stripped
off words tagged with other parts of speech and
only keep the verbs as events. This makes it more
effective to use features from previous work that
are designed for single verbs. One such feature is
the aspect marker. Distinctions between newswire
and webblog data and between v events and other
events are further explored in Section 5.1 and Sec-
tion 5.2. Table 1 presents the statistics for each
subset of the experimental data.
dataset # of v events # of all events
nw 6,686 8,268
all 17,153 20,885
Table 1: Statistics of four subsets of the annotated
corpus (Chinese side). “nw” denotes the newswire
data. “v events” denotes events that consist of or
can be reduced to only a single verb.
For each subset, randomly selected 80% were
used as the training set, while 10% were used as
the development set and 10% were used as the test
set.
</bodyText>
<subsectionHeader confidence="0.966273">
4.2 Baseline
</subsectionHeader>
<bodyText confidence="0.999725178571429">
Based on previous approaches on Chinese tense
inference, we used a Maximum Entropy model
with extensive feature engineering as our baseline
method. We use the implementation of the Maxi-
mum Entropy algorithm in Mallet 1 for our exper-
iments. The corpus is parsed using the Berkeley
Parser for the purpose of extracting structure fea-
tures. Since the Parallel Alignment TreeBank is
a subset of the Chinese TreeBank (CTB) 8.0, we
automatically parsed the CTB 8.0 by doing a 10-
fold cross validation. The bracketing F-score is
80.5%. Feature extractions are performed on the
automatic parse trees. Adopted features include
previous word and its POS tag, next word and
its POS tag, aspect marker following the event,
—following the event, the governing verb of the
event, the character string of the main verb in the
previous clause that is coordinated with the clause
the event is in, whether the event is in quote, and
left modifiers of the event including head of adver-
bial phrases, temporal noun phrases, prepositional
phrases, localizer phrases, as well as subordinat-
ing clauses. Readers are referred to (Xue, 2008)
for details of these features. Since in this corpus
an event can span over more than one verb, we
also use the character string and the POS string of
the entire event instead of one word and one POS
tag as features.
</bodyText>
<listItem confidence="0.942512142857143">
• The character string of an event – it could
be one or more words. In our corpus, only
69.7% events consist of single word (e.g. “9
R”, “live”), the other 30.3% of the events are
expressed with two or more words (e.g. “�
&amp;+-f”, “have caused”).
• The POS string of an event – it could be
</listItem>
<bodyText confidence="0.7512895">
verbs, nouns, or POS sequences of other
word sequences. Table 2 shows the top ten
POS tag or POS tag sequences with example
word or word sequences.
Other features that we used in the baseline sys-
tem are as follows.
</bodyText>
<listItem confidence="0.9908335">
• DEC – if the word immediately following an
event has the POS tag “DEC”, use its charac-
ter string as a feature. In most cases, “DEC”
is the POS tag for “�” when it used as a com-
plementizer marking the boundary in a rela-
tive clause. This feature implies that an event
</listItem>
<footnote confidence="0.687446">
1http://mallet.cs.umass.edu/
</footnote>
<table confidence="0.994447">
1905
POS freq examples
VV 48.2% 9R(live)
NN 5.8% )TR(opening)
VC 5.2% A(is)
VV+AS 5.2% A+T(have caused)
VV+DEC 3.2% VPP_+R`, (isolated)
AD+VV 3.0% 1Er±_+ a(is suggesting)
VA 3.0% -k(is big)
AD 2.0% C N(seemed)
VE 1.9% (there is)
P 1.8% @149(according to)
</table>
<tableCaption confidence="0.971286">
Table 2: Frequencies and examples of the ten most
</tableCaption>
<bodyText confidence="0.8038014">
frequent POS tag or POS tag sequences for events
in our corpus.
is inside a relative clause modifying a noun
phrase and it is more often stative than even-
tive.
</bodyText>
<listItem confidence="0.8453166">
• Determiners – we find the subject of an event
from its parse tree and extract the determiner
of the subject, if there is one, as a fea-
ture. This feature indicates different types
of agents, and different types of agents of-
</listItem>
<bodyText confidence="0.95026">
ten signal different types of events. For ex-
ample, individual agents tend to perform one-
time episodic actions which are by default lo-
cated in the past or described by a state in
the present, while multiple agents tend to in-
volved in habitual actions that spans over a
long period of time.
Baseline results are reported in Table 5 and Ta-
ble 6, in MaxEnt b rows.
</bodyText>
<subsectionHeader confidence="0.9921915">
4.3 Eventuality Type and Modality as
Features
</subsectionHeader>
<bodyText confidence="0.999738466666667">
Xue and Zhang (2014) reports that gold eventual-
ity type and modality labels significantly help the
inference of tense in Chinese, improving the ac-
curacy by more than 20%. However, it is unreal-
istic to expect to have human annotated eventual-
ity type and modality labels in a random new data
set if we want to use these two sources of implicit
linguistic information in any Chinese text. So we
trained statistical learning models to automatically
extract these two labels. We trained Maximum En-
tropy models and ran a 10-fold cross validation on
the entire corpus in order to get automatic labels
for every event. Feature used for labeling modal-
ity are as follows. Table 3 shows the average ac-
curacies for automatic modality labeling.
</bodyText>
<listItem confidence="0.994162428571429">
• The character string of an event.
• The POS string of an event.
• The character string of an event’s governing
verb and its POS tag.
• Whether the event is in a conditional clause.
If an event is in a subtree with the func-
tional tag “CND”, return “True”; otherwise,
return “False”. This feature indicates that the
event’s modality label is “Hypothetical”.
• Whether the event is in a purpose or reason
clause. If an event is in a subtree with the
functional tag “PRP”, return “True”; other-
wise, return “False” as a feature. This feature
indicates the event’s modality label is “In-
tended”.
• Whether the event string is the start of a sen-
tence. If an event is the start of a sentence, re-
turn “True”; otherwise, return “False”. Sen-
tences that start with an event is often impera-
tive, and the event generally has “modalized”
modality label.
</listItem>
<table confidence="0.97911">
dataset v events all events
nw 81.1% 81.2%
all 75.4% 76.4%
</table>
<tableCaption confidence="0.9305675">
Table 3: Average modality labeling accuracy, us-
ing a 10-fold cross validation.
</tableCaption>
<bodyText confidence="0.999820923076923">
Statistics show that the five labels for modality
have a skewed distribution in this corpus. Among
all events, 67.3% of them fall in the “Actual” cat-
egory, while the events of all the other categories
are around or less than 10%. Similar distributions
are found in all four subsets of the data. Still, com-
pared with always choosing the most frequent la-
bel (around 67% accuracy), we still get a big im-
provement from our statistical model, even though
only a very simple set of features are used.
Features used for labeling eventuality type are
as follows. Table 4 shows the average accuracies
for automatic eventuality type labeling.
</bodyText>
<listItem confidence="0.97791175">
• The character string of an event.
• The POS string of an event.
1906
• Adverbs on the left that modifies the event.
• Aspect marker following the event
• Whether the event is Inside a relative clause.
If an event is in a CP subtree with the word
“,” and POS tag “DEC” as its last node,
return “True”; otherwise, return “False”.
Events in relative clauses modifying a noun
phrase and tend to be more often stative than
eventive.
</listItem>
<table confidence="0.968293">
dataset v events all events
nw 68.7% 67.7%
all 65.3% 65.1%
</table>
<tableCaption confidence="0.879219">
Table 4: Average automatic eventuality type label-
ing accuracy using a 10-fold cross validation.
</tableCaption>
<bodyText confidence="0.999817214285714">
The six labels of eventuality type are also dis-
tributed unevenly. The first group of columns in
Figure 3 shows the distribution of all events. Over
65% of events are either “Episodic” or “State”,
while the other types of events are less than 15%.
There are two categories that are even less than
5%. However, even though we only use some sim-
ple features, our model still beats the most fre-
quent label baseline (around 35% accuracy) by a
big margin, as shown in Table 4.
Tense inference accuracies using automatic
eventuality type and/or modality features are re-
ported in Table 5 and Table 6, in MaxEnt e, Max-
Ent m, and MaxEnt em rows.
</bodyText>
<subsectionHeader confidence="0.998332">
4.4 Joint Learning
</subsectionHeader>
<bodyText confidence="0.999928">
Apart from using eventuality type and modality la-
bels as features, we also conducted joint learning
experiments on them. Joint learning are applied
on 1) tense and eventuality type, and 2) tense and
modality. Features used are the union of the two
sets of features in inferring each single label. Max-
Ent jle and MaxEnt jlm rows in Table 5 and Table
6 present the experimental results on joint learn-
ing.
</bodyText>
<subsectionHeader confidence="0.991317">
4.5 Artificial Neural Network
</subsectionHeader>
<bodyText confidence="0.99999">
For each of the experiments using the maximum
entropy algorithm, we conducted a neural network
experiment using the same setting in order to ex-
plore more possible feature combinations and mit-
igate the feature engineering work. We convert
the features in each of our tense inference meth-
ods into feature vectors. If a feature is not a word,
we use a one-hot representation for that feature (a
vector with all 0s except for a 1 at the place of the
feature’s index in our feature lexicon). If a feature
is a word, we convert it into a word embedding. To
get a dictionary of word embeddings, we use the
word2vec tool 2 (Mikolov et al., 2013) and train it
on the Chinese Gigaword corpus (LDC2003T09).
For each word embedding, a 300-dimensional vec-
tor is used. Artificial neural networks are built us-
ing the theano package 3 (Bergstra et al., 2010).
We use 5000 hidden units for all networks and set
the learning rate α = 0.01. Experimental results
are presented in the ANN rows of Tables 5 and 6.
</bodyText>
<sectionHeader confidence="0.999129" genericHeader="evaluation">
5 Results Analysis
</sectionHeader>
<bodyText confidence="0.99999115625">
A comparison of the baseline accuracy for the four
different subsets of the data shows that (1) tense
inference is slightly better on v events than on all
events, but the difference is not substantial; and
(2) tense inference on newswire data performs bet-
ter than on all data by around 8% on v events and
around 5% on all events, verifying our assump-
tion that automatic tense inference is easier on
newswire data than webblog data. Although our
experiments are performed on different data sets
from that of previous work, our baseline method
still shows strong results compared with previous
work (Xue, 2008; Ye et al., 2006; Liu et al., 2011).
Adding automatic eventuality type and modal-
ity labels as features for semantic tense inference
leads to improvements over the baseline on all four
data subsets. In fact they provide considerable
improvements (around 2% increase) on newswire
v events dataset. MaxEnt e rows report results
when only automatic eventuality type is added
as a feature, and MaxEnt m rows report results
when only automatic modality is added as a fea-
ture. They both outperform (or, in several datasets,
match) the baseline results on all datasets. Max-
Ent em rows report results when both automatic
linguistic labels are added as features, and they
show further improvements over when only one
source of information is used. Analysis of the
results shows again that tense inference accuracy
is higher than webblog data under this experi-
ment condition. The results also show that after
adding eventuality type and modality as features,
</bodyText>
<footnote confidence="0.9858415">
2http://code.google.com/p/word2vec/
3http://deeplearning.net/software/theano/
</footnote>
<table confidence="0.982349764705882">
1907
method all data nw data
MaxEnt b 58.9% 66.8%
MaxEnt e 59.5% 67.9%
MaxEnt m 59.5% 67.1%
MaxEnt em 59.6% 68.6%
MaxEnt jle 59.6% 63.5%
MaxEnt jlm 60.5% 66.9%
MaxEnt ge 74.6% 77.4%
MaxEnt gm 66.6% 70.0%
MaxEnt gem 76.2% 76.9%
ANN b 63.4% 67.2%
ANN e 62.6% 66.1%
ANN m 63.4% 59.8%
ANN em 59.7% 68.3%
ANN jle 62.7% 64.5%
ANN jlm 62.0% 65.6%
</table>
<tableCaption confidence="0.990688333333333">
Table 5: Accuracy of tense inference on v events.
Best performances for each group of methods are
in bold.
</tableCaption>
<table confidence="0.999768625">
method all data nw data
MaxEnt b 59.7% 65.1%
MaxEnt e 59.9% 65.1%
MaxEnt m 59.9% 65.4%
MaxEnt em 59.9% 65.5%
MaxEnt jle 59.7% 62.7%
MaxEnt jlm 60.4% 65.6%
MaxEnt ge 75.3% 76.1%
MaxEnt gm 67.1% 69.0%
MaxEnt gem 76.2% 75.9%
ANN b 63.0% 64.0%
ANN e 63.2% 66.9%
ANN m 60.1% 64.7%
ANN em 57.8% 66.1%
ANN jle 61.4% 63.0%
ANN jlm 62.9% 63.5%
</table>
<tableCaption confidence="0.992556">
Table 6: Accuracy of tense inference on all events.
</tableCaption>
<bodyText confidence="0.985094977777778">
Best performances for each group of methods are
in bold.
the improvements on v events (0.7% and 1.8%)
are much bigger than that on all events (0.2% and
0.4%), regardless of the data genre (newswire or
weblog).
In order to test the potential for these two new
features, we also conducted experiments using
gold eventuality type and/or modality labels as
features for the Maximum Entropy models (Table
5 and Table 6, MaxEnt ge, MaxEnt gm, and Max-
Ent gem rows.). They outperform our best Max-
Ent results by around 10% on newswire data and
around 15% on all data, indicating strong poten-
tials for more accurately classified automatic even-
tuality type and modality labels.
Results also show that joint learning with
modality proves to be working better than the
baseline (Table 5 and Table 6, MaxEnt jle, Max-
Ent jlm). In fact, on the datasets with all events,
joint learning with modality produces the highest
accuracy among all approaches. However, joint
learning with eventuality is even worse than the
baseline. One possible explanation is that the
lower eventuality type classification accuracy af-
fects the tense inference accuracy. We also believe
there is still room for improvement with features
tuned for the joint learning model. Simply adding
the features may not be the best strategy.
On the entire dataset, regardless of v events or
other events, results of the neural network models
show improvements over the maximum entropy
models under most experimental conditions. A
clear trend is that artificial neural networks help
more on all data than on newswire data only, in-
dicating greater potentials of the neural network
models to select and combine features with care-
fully trained parameters, given noisier but larger
training sets.
Experimental results also show significant dif-
ferences in accuracy between newswire data and
webblog data, and smaller but still recognizable
difference between v events and all events. There-
fore, we specifically look into distinctions be-
tween these data sets.
</bodyText>
<subsectionHeader confidence="0.986121">
5.1 Newswire Data vs. Webblog Data
</subsectionHeader>
<bodyText confidence="0.999872266666667">
Considering the big gap in accuracy between
newswire and webblog data in our baseline results,
we delve deeper into the data and found several
major distinctions between these two domains that
might have contributed to the rather significant dif-
ference in performance on tense inference. First,
we look into the word frequency distribution of the
two datasets. Here by “word” we mean the char-
acter string of an event. We find that both datasets
have a small portion of words with high frequen-
cies, but the webblog dataset contains much more
low-frequent words than the newswire dataset. In
Figure 2, the x-axis shows possible frequencies of
words and the y-axis shows the number of words at
a particular frequency. It can be seen that the num-
</bodyText>
<page confidence="0.578295">
1908
</page>
<bodyText confidence="0.980996692307692">
ber of words that appear only once in the webblog
dataset is about three times as large as that in the
newswire dataset. The entire newswire dataset has
a vocabulary of only 2671 entries, while the web-
blog dataset has a vocabulary size of 6117. This
greatly reduces the coverage of features extracted
from the training dataset on the events in the test
dataset.
Second, webblog data contains more events
that are “inherently” ambiguous on temporal lo-
cation. Among four possible labels for tense
in this corpus, “None” is for events whose tem-
poral locations are not clear even to human an-
notators. Statistics show that in webblog data
about 13.4% of the events are tagged as “None”,
while in newswire data only around 6.7% are
“None”. Another piece of evidence showing web-
blog data is harder to process is the different inter-
annotator agreement scores for tense annotation
on newswire and webblog data reported by (Xue
and Zhang, 2014). Newswire data has a 89.0%
agreement score and a 84.9% kappa score, while
webblog data only has a 81.0% agreement score
and a 72.7% kappa. Third, automatic parse trees
for newswire data is also more accurate than that
for webblog data. The bracketing F-score of au-
tomatically parsed newswire data is 83.0% while
it is only 80.4% for weblog data. Moreover, sen-
tences in newswire data are more grammatically
complete. Analysis shows that webblog data has
more dropped constituents in sentences. There
are around 40.5% sentences in newswire data that
have nominal empty categories, while in webblog
data the number is 48.1%. Dropped constituents
affect the structures of parse trees and some of
the features, which can affect tense inference ac-
curacy.
Figure 2: Word frequency distribution in newswire
and webblog datasets.
</bodyText>
<subsectionHeader confidence="0.975925">
5.2 V events vs. All Events
</subsectionHeader>
<bodyText confidence="0.999922034482759">
In our definition, v events are (1) events that are
single verbs (example 1, 3, 7, 9 in Table 2), and
(2) events that are multi-word sequences but only
one word among them is a verb and any non-verb
words are stripped off (verbs in example 4, 5, 6
in Table 2). Conversely, events that do not fall into
this definition include (1) events that have no verbs
in their surface form (example 2, 8, 10 in Table 2),
and (2) events that have more than one verb in their
surface form (e.g. “&apos;P+)At, (shi3+cheng2wei2)”,
VV+VV, “make it become”). So from the point
of view of a statistical learning algorithm, ev-
ery v event has one and only one verb. This
makes sure that all features that we used are ap-
plicable to v events. For other events, however,
some features may be not applicable. For ex-
ample, for an event which has a nominal expres-
sion, aspect marker, DER, and DEC features are
all “None” because these features are only appli-
cable to verbs. Another major distinction between
v events and “other events” is that the distributions
of eventuality type labels on them are very differ-
ent, presented in the second and third groups of
columns in Figure 3. There is a rather high per-
centage of “State” among “other events” and very
low percentage of “Completed” and “None”. The
highly uneven distribution of eventuality type la-
bels make it less effective as a feature for tense
inference.
</bodyText>
<figureCaption confidence="0.641461">
Figure 3: Statistics of eventuality types on differ-
ent events.
</figureCaption>
<bodyText confidence="0.999968875">
We also find that, on newswire datasets, max-
imum entropy models and neural network mod-
els do not show much difference in performance.
To understand this result better, we plot learn-
ing curves of the artificial neural network model,
trained and tested on newswire v events dataset.
In Figure 4, the black line represents the error rate
on training set, and the grey line represents the er-
</bodyText>
<figure confidence="0.992848">
5000
4500
nw dataset
4000
wb dataset
3500
1500
1000
500
0
1 2 3 4 5 6 7 8 9 10
word frequency
word count
3000
2500
2000
50.0%
45.0%
40.0%
35.0%
30.0%
25.0%
20.0%
15.0%
10.0%
5.0%
0.0%
State
Episodic
Habitual
Progressive
Completed
None
all events v_events other events
1909
</figure>
<bodyText confidence="0.925972272727273">
ror rate on test set. As the size of training data
grows, the error rate on the training set gets larger
because with more training examples the training
set becomes noisier and it gets harder to model all
samples with the same number of features; and the
error rate on the test set gets smaller because a big-
ger training set reduces the data sparsity and trains
the parameters better. Both lines end at a rather
high error rate (around 30%, i.e. only around 70%
in accuracy) which means the current network is
general enough to cover most cases in the test set,
but it is under-fitting the training data. The cur-
rent model is not specific enough to better cap-
ture the fine distinctions between the tense cat-
egories. The black line being not very smooth
is also understandable, given that there are only
around 6000 training examples in the newswire
v events dataset.
ningcur vesof t heartifi cia lneura ln etworkmo
d el,tra inedandt
e stedo nnewswir
ev eventsdataset.
</bodyText>
<subsectionHeader confidence="0.667588">
6ErrorAnalysis
</subsectionHeader>
<bodyText confidence="0.969089071428572">
et abetterunderstanding oftheuse In order tog
ytype andmodality, welookintothe ofeve ntua lit
reacherrortype ingreaterdetail. error ratesfo
a”stands for“Past”, “Pre”isshort InTable7,“P
t”,“Fu” isfor“Future”,and “No” is for“ Pres en
eacherrortype,theleft-handside “None”. For is thegold- stan
da rdt ense,an dthe righ t-hand sideis the w ron glya
ssigne dl abe l.Statis t icsare col- lect edon the
new s wire veve nts datatests et.Ta -ble 7 compare
sth e differe nterro rty pes betwee nt hebasel
ine meth odand the Max Ent e mmethod, th e be sta ppro
a c h forthisda tas et.Wec an see that (1)“Presen
t”and “Pa st” is themo stf req uentlyconfu sedt ens
epair,an d(2)eventua lity typeandmodal ityinform
</bodyText>
<table confidence="0.9184972">
s s i fi
ati onhelp disamb iguate“P res ent”an d“P ast”ev
ent sg reatly, andreduc etheer ro rsduetomi s- clas
sifyi ng “Past”as“F ut ure”, o r“ Fu-ture”as
“Pres ent” ,or“No n e”as“P re
sen t ”. error typeM
ax E ntb MaxE ntem
Pre→P a 11. 7%1 1
.2%Pa → Pre 9.8%
9.2%Pa → Fu 2 .5%2
.3%No→ Pa 2. 0%2.
0%Fu→ Pre1 .9%1
.6%Pre → Fu 1 .4%1
.4 %Fu → Pa 1 .4%1
.4 %No → Pre 1.6%
1.2%No → Fu 0 .5%0
.5 %Pa → No .3%0
.3%
Pre → No0.2%0.2%
Fu→ No0.0% 0.0%T abl e7:Tensei
</table>
<bodyText confidence="0.989432166666667">
nfere nceer ro rratesfo r differ ente rror
types on newswirev ev en tst estset.A c lo serex
aminat ion of thesen ten cesin which eventsa reas
sign e dth ewron g t enser ev ealst ha t“Pre →
Pa ”erroris prone to o ccu roneven tsin relativ e
clau ses. The C hinese verb i mpl iesap as tepisodi c
event,w hilet he eventisa ctuall ya p rese ntstateo
rha bitualevent.Asa go od exa mp le,the“e ((s he
ng1chan 3)”even t i n Sente nc e(3)is w ron glyl
abeled as “Past” b yM axEnt bbut co r-rect ly clas
sifiedas“Pre sent ”byMaxEnt e mwi theventu ali tyty
pe“Ha bitu al”andmoda lity ta g“A c-tual” (theunde
rl ine dpartint heChines es en tenc eisth erel ativ
ecl a use) .Itisa lsofo un dthatm ost“ Pa→ Pre”
errorsoc cu r o neventstha t are m orestative .Iti sr
easona blesincec la ssifier ste ndtoas si gn“Prese
nt”to st atesan d“ Past” to ep isodice vent s.Ma
xEntemmana ge dtoco rrectso mewith“epis odic”
as their correct eventualitytype. 3 ) ����������(sheng1chan3)(
At �present �����
the Pu Kang 2•mpany
&apos; whiAt present , the PuKangCompany ,whi c
hpr oducest hevacc i neinthis zo ne ,ha sa l
readyfo rmed a pro duct i onsca leo f5mil lion
dosesper ye ar,whichhas greatsig-ni fica nce inef
fec t ivelycon t
tis A epidemic.
ro lli ngthehepati-
surprised to seethat over 2% “Past” We arealso
ed as “Future” evnts, events re ranking cla
</bodyText>
<figure confidence="0.994444266666667">
40.0%
35.0%
30.0%
25.0%
20.0%
15.0%
10.0%
5.0%
0.0%
Err
rdra
ofgtra i n ingrdata trai nt te sttFigure 4:Lear
tage
Perc
1910
</figure>
<bodyText confidence="0.997592933333333">
third among all error types. This mistake seems
very unlikely, but it is still possible when per-
forming tense inference on a language with no
grammatical tense at all. Take the following sen-
tence pair (4) as an example. In the Chinese sen-
tence, MaxEnt b classifies “¨º(tao3lun4)” as
“Future” because there is no grammatical indica-
tor in the Chinese sentence implying that the “dis-
cussion” has already happened and it is reason-
able to assume the “discussion” is in the near fu-
ture. However, with eventuality type “Episodic”
and modality label “Actual”, MaxEnt em classi-
fies it as “Past” correctly, because episodic events
tend to occur in the past and future events tend to
get “Intended” or “Hypothetical” modality labels.
</bodyText>
<equation confidence="0.662706666666667">
(4) ��ô�����“���������
��aP� kN¨º(tao3lun4) $11Áäô
�®��������”�
</equation>
<bodyText confidence="0.99938625">
He also said, the French government “even
directed its representative not to vote Yes
when the Security Council discussed the res-
olution on sanctions on Cuba”.
</bodyText>
<sectionHeader confidence="0.979569" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999971176470588">
In this paper, we address the problem of automatic
inference of Chinese semantic tense. We took ad-
vantage of a new corpus annotated with rich lin-
guistic information, and experimented with three
approaches. In the first approach, we use two
sources of implicit linguistic information, even-
tuality type and modality, automatically derived,
as features in tense inference. We then conducted
joint learning on tense and each of these two infor-
mation types. Finally, we experimented with using
artificial neural networks to train models for tense
prediction. All three approaches outperformed a
strong baseline, a maximum entropy model with
extensive engineering. Our future work will in-
clude exploring ways to improve automatic even-
tuality type and modality labeling accuracy to fur-
ther improve tense inference accuracy.
</bodyText>
<sectionHeader confidence="0.997137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999198625">
We would like to thank the three anonymous re-
viewers for their suggestions and comments. This
work is supported by the National Science Foun-
dation via Grant No. 0910532 entitled “Richer
Representations for Machine Translation”. All
views expressed in this paper are those of the au-
thors and do not necessarily represent the view of
the National Science Foundation.
</bodyText>
<sectionHeader confidence="0.994052" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999878574074074">
James Bergstra, Olivier Breuleux, Fr´ed´eric Bastien,
Pascal Lamblin, Razvan Pascanu, Guillaume Des-
jardins, Joseph Turian, David Warde-Farley, and
Yoshua Bengio. 2010. Theano: a CPU and
GPU math expression compiler. In Proceedings
of the Python for Scientific Computing Conference
(SciPy), June. Oral Presentation.
Xuansong Li, Stephanie Strassel, Stephen Grimes, Safa
Ismael, Mohamed Maamouri, Ann Bies, and Nian-
wen Xue. 2012. Parallel Aligned Treebanks at
LDC: New Challenges Interfacing Existing Infras-
tructures. In Proceedings of LREC-2012, Istanbul,
Turkey.
Feifan Liu, Fei Liu, and Yang Liu. 2011. Learning
from chinese-english parallel data for chinese tense
prediction. In Proceedings of the 5th International
Conference on Natural Language Processing, pages
1116–1124, November.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of english: The penn treebank. Computa-
tional Linguistics, 19(2):313–330.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. In Proceedings of Workshop
at ICLR.
Roi Reichart and Ari Rappoport. 2010. Tense sense
disambiguation: A new syntactic polysemy task.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
325–334, Cambridge, MA, October. Association for
Computational Linguistics.
Carlota S. Smith and Mary Erbaugh. 2005. Tempo-
ral interpretation in Mandarin Chinese. Linguistics,
43(4):713–756.
Nianwen Xue and Yuchen Zhang. 2014. Buy one get
one free: Distant annotation of chinese tense, event
type, and modality. In Proceedings of LREC-2014,
Reykjavik, Iceland.
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005. The Penn Chinese TreeBank: Phrase
Structure Annotation of a Large Corpus. Natural
Language Engineering, 11(2):207–238.
Nianwen Xue. 2008. Automatic Inference of the Tem-
poral Location of Situations in Chinese Text. In
EMNLP-2008, Honolulu, Hawaii.
Yang Ye, Victoria Li Fossum, and Steven Abney. 2006.
Latent features in automatic tense translation be-
tween Chinese and English. In The Proceedings
of the 5th SIGHAN Workshop on Chinese Language
Processing, Sydney, Australia.
Yang Ye. 2007. Automatic Tense and Aspect Trans-
lation between Chinese and English. Ph.D. thesis,
University of Michigan.
</reference>
<page confidence="0.788011">
1911
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.200290">
<title confidence="0.999411">Automatic Inference of the Tense of Chinese Events Using Linguistic Information</title>
<author confidence="0.55949">Yuchen</author>
<affiliation confidence="0.433399">Brandeis</affiliation>
<address confidence="0.814065">415 South</address>
<affiliation confidence="0.582612">Waltham,</affiliation>
<email confidence="0.999898">yuchenz@brandeis.edu</email>
<abstract confidence="0.9989885">We address the problem of automatically inferring the tense of events in Chinese text. We use a new corpus annotated with Chinese semantic tense information and other implicit Chinese linguistic information using a “distant annotation” method. We propose three improvements over a relatively strong baseline method – a statistical learning method with extensive feature engineering. First, we add two sources of implicit linguistic information as features – eventuality type and modality of an event, which are also inferred automatically. Second, we perform joint learning on semantic tense, eventuality type, and modality of an event. Third, we train artificial neural network models for this problem and compare its performance with feature-based approaches. Experimental results show considerable improvements on Chinese tense inference. Our best performance reaches 68.6% in accuracy, outperforming a strong baseline method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Bergstra</author>
<author>Olivier Breuleux</author>
<author>Fr´ed´eric Bastien</author>
<author>Pascal Lamblin</author>
<author>Razvan Pascanu</author>
<author>Guillaume Desjardins</author>
<author>Joseph Turian</author>
<author>David Warde-Farley</author>
<author>Yoshua Bengio</author>
</authors>
<title>Theano: a CPU and GPU math expression compiler.</title>
<date>2010</date>
<booktitle>In Proceedings of the Python for Scientific Computing Conference (SciPy),</booktitle>
<tech>Oral Presentation.</tech>
<contexts>
<context position="22764" citStr="Bergstra et al., 2010" startWordPosition="3819" endWordPosition="3822"> work. We convert the features in each of our tense inference methods into feature vectors. If a feature is not a word, we use a one-hot representation for that feature (a vector with all 0s except for a 1 at the place of the feature’s index in our feature lexicon). If a feature is a word, we convert it into a word embedding. To get a dictionary of word embeddings, we use the word2vec tool 2 (Mikolov et al., 2013) and train it on the Chinese Gigaword corpus (LDC2003T09). For each word embedding, a 300-dimensional vector is used. Artificial neural networks are built using the theano package 3 (Bergstra et al., 2010). We use 5000 hidden units for all networks and set the learning rate α = 0.01. Experimental results are presented in the ANN rows of Tables 5 and 6. 5 Results Analysis A comparison of the baseline accuracy for the four different subsets of the data shows that (1) tense inference is slightly better on v events than on all events, but the difference is not substantial; and (2) tense inference on newswire data performs better than on all data by around 8% on v events and around 5% on all events, verifying our assumption that automatic tense inference is easier on newswire data than webblog data.</context>
</contexts>
<marker>Bergstra, Breuleux, Bastien, Lamblin, Pascanu, Desjardins, Turian, Warde-Farley, Bengio, 2010</marker>
<rawString>James Bergstra, Olivier Breuleux, Fr´ed´eric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. 2010. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy), June. Oral Presentation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuansong Li</author>
<author>Stephanie Strassel</author>
<author>Stephen Grimes</author>
<author>Safa Ismael</author>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Nianwen Xue</author>
</authors>
<title>Parallel Aligned Treebanks at LDC: New Challenges Interfacing Existing Infrastructures.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC-2012,</booktitle>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="2663" citStr="Li et al., 2012" startWordPosition="421" endWordPosition="424"> automatic inference of the semantic tense of events in Chinese is a very challenging task (Xue, 2008; Ye et al., 2006; Liu et al., 2011). There are at least two reasons why this is a difficult problem. First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge. Xue and Zhang (2014) use a “distant annotation” method to address this problem. They take advantage of an English-Chinese parallel corpus with manual word alignments (Li et al., 2012) , and perform annotation on the English side, which provides more explicit information such as grammatical tense that helps annotators decide the appropriate semantic tense. The annotations are then projected to the Chinese side via the word alignments. They show consistent annotation agreements on semantic tense. Second, the lack of grammatical tense also makes automatic inference of Chinese semantic tense challenging since the grammatical tense would be an important source of information for predicting the semantic tense. Previous work has shown that it is very difficult to achieve high acc</context>
<context position="12598" citStr="Li et al., 2012" startWordPosition="2029" endWordPosition="2032">five years , Guangxi’s foreign trade and its use of foreign investments has expanded rapidly. ��������������% �� *pf 1J,ffl(li4yong4) (2) Beihai has already become a bright star arising from China’s policy of opening up to the outside world. J M EhAt,rPQ3% ff)W(kai1fang4) rP �������� In this corpus, events could be either one verb, or a verb compound, or a verb sequence “headed” by a verb, or even nouns and words of other parts of speech. 4 Experiments 4.1 Experimental Setting Xue and Zhang (2014) annotated semantic tense, eventuality type and modality on top of the Parallel Aligned Treebank (Li et al., 2012), a corpus 1904 of word-aligned Chinese-English sentences treebanked based on the Penn TreeBank (Marcus et al., 1993) and the Chinese TreeBank (Xue et al., 2005) standards. Human annotation of tense is performed on the newswire and webblog sections of this corpus. They report that the average pairwise agreement among three annotators consistently stays above 80% and the average Kappa score consistently exceeds 70%, indicating reliable annotation. Apart from using the entire corpus, we also conducted experiments on three different subsets of the corpus. An examination of the data indicates that</context>
</contexts>
<marker>Li, Strassel, Grimes, Ismael, Maamouri, Bies, Xue, 2012</marker>
<rawString>Xuansong Li, Stephanie Strassel, Stephen Grimes, Safa Ismael, Mohamed Maamouri, Ann Bies, and Nianwen Xue. 2012. Parallel Aligned Treebanks at LDC: New Challenges Interfacing Existing Infrastructures. In Proceedings of LREC-2012, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feifan Liu</author>
<author>Fei Liu</author>
<author>Yang Liu</author>
</authors>
<title>Learning from chinese-english parallel data for chinese tense prediction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Conference on Natural Language Processing,</booktitle>
<pages>1116--1124</pages>
<contexts>
<context position="2013" citStr="Liu et al., 2011" startWordPosition="308" endWordPosition="311">nferring the semantic tense, or the temporal location of an event (e.g., present, past, future) in Chinese text. The semantic tense is defined relative to the utterance time or document creation time, and it does not always agree with the grammatical tense in languages like English where there is grammatical tense. Inferring semantic tense potentially benefits natural language processing tasks such as Machine Translation and Nianwen Xue Brandeis University 415 South Street Waltham, MA xuen@brandeis.edu Information Extraction (Xue, 2008; Reichart and Rappoport, 2010; Ye et al., 2006; Ye, 2007; Liu et al., 2011), but previous work has shown that automatic inference of the semantic tense of events in Chinese is a very challenging task (Xue, 2008; Ye et al., 2006; Liu et al., 2011). There are at least two reasons why this is a difficult problem. First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge. Xue and Zhang (2014) use a “distant annotation” method to address this problem. They take advantage of an English-Chinese parallel co</context>
<context position="8078" citStr="Liu et al. (2011)" startWordPosition="1279" endWordPosition="1282">heir system are humanannotated, while the eventuality type and modality features in our system are predicted automatically. Another difference is that they ignored events that are not verbs. For example, they excluded verbal expressions in Chinese that are translated into nominal phrases in English. In contrast, we kept all events in our data, and they can be realized as verbs, nouns, as well as words in other parts of speech. We performed separate experiments on events realized as verbal expressions and events not in verbal expressions to investigate their impact on semantic tense inference. Liu et al. (2011) introduced more global features in a machine learning framework, and on top of that proposed an iterative learning algorithm which better handles noisy data, but they also ignored events that are not realized as verbal expressions, or events that are verbal expressions but have more than one verb in them. They mainly focused on events that are one-verb expressions. In a similar work on inferring tense in English text, Reichart and Rappoport (2010) aimed at inferring fine-grained semantic tenses for events in English. They introduced a fine-grained sense taxonomy for tense in a more general Te</context>
<context position="23576" citStr="Liu et al., 2011" startWordPosition="3963" endWordPosition="3966">ne accuracy for the four different subsets of the data shows that (1) tense inference is slightly better on v events than on all events, but the difference is not substantial; and (2) tense inference on newswire data performs better than on all data by around 8% on v events and around 5% on all events, verifying our assumption that automatic tense inference is easier on newswire data than webblog data. Although our experiments are performed on different data sets from that of previous work, our baseline method still shows strong results compared with previous work (Xue, 2008; Ye et al., 2006; Liu et al., 2011). Adding automatic eventuality type and modality labels as features for semantic tense inference leads to improvements over the baseline on all four data subsets. In fact they provide considerable improvements (around 2% increase) on newswire v events dataset. MaxEnt e rows report results when only automatic eventuality type is added as a feature, and MaxEnt m rows report results when only automatic modality is added as a feature. They both outperform (or, in several datasets, match) the baseline results on all datasets. MaxEnt em rows report results when both automatic linguistic labels are a</context>
</contexts>
<marker>Liu, Liu, Liu, 2011</marker>
<rawString>Feifan Liu, Fei Liu, and Yang Liu. 2011. Learning from chinese-english parallel data for chinese tense prediction. In Proceedings of the 5th International Conference on Natural Language Processing, pages 1116–1124, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="12715" citStr="Marcus et al., 1993" startWordPosition="2047" endWordPosition="2050">*pf 1J,ffl(li4yong4) (2) Beihai has already become a bright star arising from China’s policy of opening up to the outside world. J M EhAt,rPQ3% ff)W(kai1fang4) rP �������� In this corpus, events could be either one verb, or a verb compound, or a verb sequence “headed” by a verb, or even nouns and words of other parts of speech. 4 Experiments 4.1 Experimental Setting Xue and Zhang (2014) annotated semantic tense, eventuality type and modality on top of the Parallel Aligned Treebank (Li et al., 2012), a corpus 1904 of word-aligned Chinese-English sentences treebanked based on the Penn TreeBank (Marcus et al., 1993) and the Chinese TreeBank (Xue et al., 2005) standards. Human annotation of tense is performed on the newswire and webblog sections of this corpus. They report that the average pairwise agreement among three annotators consistently stays above 80% and the average Kappa score consistently exceeds 70%, indicating reliable annotation. Apart from using the entire corpus, we also conducted experiments on three different subsets of the corpus. An examination of the data indicates that newswire data is grammatically more formal and complete than webblog data, so we also conducted separate experiments</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<booktitle>In Proceedings of Workshop at ICLR.</booktitle>
<contexts>
<context position="22559" citStr="Mikolov et al., 2013" startWordPosition="3785" endWordPosition="3788">experiments using the maximum entropy algorithm, we conducted a neural network experiment using the same setting in order to explore more possible feature combinations and mitigate the feature engineering work. We convert the features in each of our tense inference methods into feature vectors. If a feature is not a word, we use a one-hot representation for that feature (a vector with all 0s except for a 1 at the place of the feature’s index in our feature lexicon). If a feature is a word, we convert it into a word embedding. To get a dictionary of word embeddings, we use the word2vec tool 2 (Mikolov et al., 2013) and train it on the Chinese Gigaword corpus (LDC2003T09). For each word embedding, a 300-dimensional vector is used. Artificial neural networks are built using the theano package 3 (Bergstra et al., 2010). We use 5000 hidden units for all networks and set the learning rate α = 0.01. Experimental results are presented in the ANN rows of Tables 5 and 6. 5 Results Analysis A comparison of the baseline accuracy for the four different subsets of the data shows that (1) tense inference is slightly better on v events than on all events, but the difference is not substantial; and (2) tense inference </context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. In Proceedings of Workshop at ICLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Ari Rappoport</author>
</authors>
<title>Tense sense disambiguation: A new syntactic polysemy task.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>325--334</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="1967" citStr="Reichart and Rappoport, 2010" startWordPosition="298" endWordPosition="301">on of an event. In this paper we address the problem of inferring the semantic tense, or the temporal location of an event (e.g., present, past, future) in Chinese text. The semantic tense is defined relative to the utterance time or document creation time, and it does not always agree with the grammatical tense in languages like English where there is grammatical tense. Inferring semantic tense potentially benefits natural language processing tasks such as Machine Translation and Nianwen Xue Brandeis University 415 South Street Waltham, MA xuen@brandeis.edu Information Extraction (Xue, 2008; Reichart and Rappoport, 2010; Ye et al., 2006; Ye, 2007; Liu et al., 2011), but previous work has shown that automatic inference of the semantic tense of events in Chinese is a very challenging task (Xue, 2008; Ye et al., 2006; Liu et al., 2011). There are at least two reasons why this is a difficult problem. First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge. Xue and Zhang (2014) use a “distant annotation” method to address this problem. They ta</context>
<context position="8530" citStr="Reichart and Rappoport (2010)" startWordPosition="1355" endWordPosition="1358">med separate experiments on events realized as verbal expressions and events not in verbal expressions to investigate their impact on semantic tense inference. Liu et al. (2011) introduced more global features in a machine learning framework, and on top of that proposed an iterative learning algorithm which better handles noisy data, but they also ignored events that are not realized as verbal expressions, or events that are verbal expressions but have more than one verb in them. They mainly focused on events that are one-verb expressions. In a similar work on inferring tense in English text, Reichart and Rappoport (2010) aimed at inferring fine-grained semantic tenses for events in English. They introduced a fine-grained sense taxonomy for tense in a more general Tense Sense Disambiguation (TSD) task to annotate and disambiguate semantic tenses. The underlying senses include “things that are always true”, “general and repeated actions and habits”, “plans, expectations 1903 and hopes”, etc., which encode a combination of tense, eventuality type and modality. In the corpus that we use, the same information is organized in a more structured manner along three dimensions – semantic tense, eventuality type, and mo</context>
</contexts>
<marker>Reichart, Rappoport, 2010</marker>
<rawString>Roi Reichart and Ari Rappoport. 2010. Tense sense disambiguation: A new syntactic polysemy task. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 325–334, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlota S Smith</author>
<author>Mary Erbaugh</author>
</authors>
<title>Temporal interpretation in Mandarin Chinese.</title>
<date>2005</date>
<journal>Linguistics,</journal>
<volume>43</volume>
<issue>4</issue>
<marker>Smith, Erbaugh, 2005</marker>
<rawString>Carlota S. Smith and Mary Erbaugh. 2005. Temporal interpretation in Mandarin Chinese. Linguistics, 43(4):713–756.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Yuchen Zhang</author>
</authors>
<title>Buy one get one free: Distant annotation of chinese tense, event type, and modality.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC-2014,</booktitle>
<location>Reykjavik, Iceland.</location>
<contexts>
<context position="2500" citStr="Xue and Zhang (2014)" startWordPosition="395" endWordPosition="398">m, MA xuen@brandeis.edu Information Extraction (Xue, 2008; Reichart and Rappoport, 2010; Ye et al., 2006; Ye, 2007; Liu et al., 2011), but previous work has shown that automatic inference of the semantic tense of events in Chinese is a very challenging task (Xue, 2008; Ye et al., 2006; Liu et al., 2011). There are at least two reasons why this is a difficult problem. First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge. Xue and Zhang (2014) use a “distant annotation” method to address this problem. They take advantage of an English-Chinese parallel corpus with manual word alignments (Li et al., 2012) , and perform annotation on the English side, which provides more explicit information such as grammatical tense that helps annotators decide the appropriate semantic tense. The annotations are then projected to the Chinese side via the word alignments. They show consistent annotation agreements on semantic tense. Second, the lack of grammatical tense also makes automatic inference of Chinese semantic tense challenging since the gra</context>
<context position="9233" citStr="Xue and Zhang, 2014" startWordPosition="1463" endWordPosition="1466">uced a fine-grained sense taxonomy for tense in a more general Tense Sense Disambiguation (TSD) task to annotate and disambiguate semantic tenses. The underlying senses include “things that are always true”, “general and repeated actions and habits”, “plans, expectations 1903 and hopes”, etc., which encode a combination of tense, eventuality type and modality. In the corpus that we use, the same information is organized in a more structured manner along three dimensions – semantic tense, eventuality type, and modality. 3 Distant Annotation Figure 1 shows the distant annotation procedure from (Xue and Zhang, 2014). Starting with a word-aligned parallel English-Chinese corpus, all sentences are part-of-speech (POS) tagged first and then all verb instances in the English text as well as expressions aligned with verb instances on the Chinese side are targeted for annotation. As we will show in Section 4, these expressions include verbs as well as nouns, prepositions and word sequences “headed” by a verb. We consider those expressions as events. Annotators work only on the English side and tag every event with a pre-defined semantic tense label. These labels are then projected from the English side to the </context>
<context position="11453" citStr="Xue and Zhang, 2014" startWordPosition="1833" endWordPosition="1836">se links and keep only absolute tense labels. For events with relative tenses that can not be resolved (i.e. events which are “Relative Future” to “Past” events, or events which are “Relative Past” to “Future” events), we use “None” as the default label. Eventuality type and modality are labeled in the same way as auxiliary annotation that can help with the inference of tense. Labels for eventuality type include “Episodic”, “Habitual”, “State”, “Progressive”, “Completed”, and “None”. Labels for modality are “Actual”, “Intended”, “Hypothetical”, “Modalized”, and “None”. Readers are refered to (Xue and Zhang, 2014) for detailed explanations of each label. Figure 1: Distant annotation procedure. As we mentioned in Section 2, in this corpus not only verbs but also their counterparts on the opposite language are considered as events, yielding events that may not be verbs. For example, in the following sentence pair (1), the Chinese verb (VV) “f 1J,ffl” is aligned with an English noun (NN) “use”. In the sentence pair (2), the English verb (VBG) “opening” is aligned with an Chinese noun (NN) “)FSC”. (1) Statistics show that , in the past five years , Guangxi’s foreign trade and its use of foreign investments</context>
<context position="17927" citStr="Xue and Zhang (2014)" startWordPosition="2966" endWordPosition="2969">ject of an event from its parse tree and extract the determiner of the subject, if there is one, as a feature. This feature indicates different types of agents, and different types of agents often signal different types of events. For example, individual agents tend to perform onetime episodic actions which are by default located in the past or described by a state in the present, while multiple agents tend to involved in habitual actions that spans over a long period of time. Baseline results are reported in Table 5 and Table 6, in MaxEnt b rows. 4.3 Eventuality Type and Modality as Features Xue and Zhang (2014) reports that gold eventuality type and modality labels significantly help the inference of tense in Chinese, improving the accuracy by more than 20%. However, it is unrealistic to expect to have human annotated eventuality type and modality labels in a random new data set if we want to use these two sources of implicit linguistic information in any Chinese text. So we trained statistical learning models to automatically extract these two labels. We trained Maximum Entropy models and ran a 10-fold cross validation on the entire corpus in order to get automatic labels for every event. Feature u</context>
<context position="29118" citStr="Xue and Zhang, 2014" startWordPosition="4887" endWordPosition="4890">ning dataset on the events in the test dataset. Second, webblog data contains more events that are “inherently” ambiguous on temporal location. Among four possible labels for tense in this corpus, “None” is for events whose temporal locations are not clear even to human annotators. Statistics show that in webblog data about 13.4% of the events are tagged as “None”, while in newswire data only around 6.7% are “None”. Another piece of evidence showing webblog data is harder to process is the different interannotator agreement scores for tense annotation on newswire and webblog data reported by (Xue and Zhang, 2014). Newswire data has a 89.0% agreement score and a 84.9% kappa score, while webblog data only has a 81.0% agreement score and a 72.7% kappa. Third, automatic parse trees for newswire data is also more accurate than that for webblog data. The bracketing F-score of automatically parsed newswire data is 83.0% while it is only 80.4% for weblog data. Moreover, sentences in newswire data are more grammatically complete. Analysis shows that webblog data has more dropped constituents in sentences. There are around 40.5% sentences in newswire data that have nominal empty categories, while in webblog dat</context>
</contexts>
<marker>Xue, Zhang, 2014</marker>
<rawString>Nianwen Xue and Yuchen Zhang. 2014. Buy one get one free: Distant annotation of chinese tense, event type, and modality. In Proceedings of LREC-2014, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The Penn Chinese TreeBank: Phrase Structure Annotation of a Large Corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="12759" citStr="Xue et al., 2005" startWordPosition="2055" endWordPosition="2058">ome a bright star arising from China’s policy of opening up to the outside world. J M EhAt,rPQ3% ff)W(kai1fang4) rP �������� In this corpus, events could be either one verb, or a verb compound, or a verb sequence “headed” by a verb, or even nouns and words of other parts of speech. 4 Experiments 4.1 Experimental Setting Xue and Zhang (2014) annotated semantic tense, eventuality type and modality on top of the Parallel Aligned Treebank (Li et al., 2012), a corpus 1904 of word-aligned Chinese-English sentences treebanked based on the Penn TreeBank (Marcus et al., 1993) and the Chinese TreeBank (Xue et al., 2005) standards. Human annotation of tense is performed on the newswire and webblog sections of this corpus. They report that the average pairwise agreement among three annotators consistently stays above 80% and the average Kappa score consistently exceeds 70%, indicating reliable annotation. Apart from using the entire corpus, we also conducted experiments on three different subsets of the corpus. An examination of the data indicates that newswire data is grammatically more formal and complete than webblog data, so we also conducted separate experiments on newswire data only. Considering that the</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha Palmer. 2005. The Penn Chinese TreeBank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Automatic Inference of the Temporal Location of Situations in Chinese Text.</title>
<date>2008</date>
<booktitle>In EMNLP-2008,</booktitle>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="1937" citStr="Xue, 2008" startWordPosition="296" endWordPosition="297">oral location of an event. In this paper we address the problem of inferring the semantic tense, or the temporal location of an event (e.g., present, past, future) in Chinese text. The semantic tense is defined relative to the utterance time or document creation time, and it does not always agree with the grammatical tense in languages like English where there is grammatical tense. Inferring semantic tense potentially benefits natural language processing tasks such as Machine Translation and Nianwen Xue Brandeis University 415 South Street Waltham, MA xuen@brandeis.edu Information Extraction (Xue, 2008; Reichart and Rappoport, 2010; Ye et al., 2006; Ye, 2007; Liu et al., 2011), but previous work has shown that automatic inference of the semantic tense of events in Chinese is a very challenging task (Xue, 2008; Ye et al., 2006; Liu et al., 2011). There are at least two reasons why this is a difficult problem. First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge. Xue and Zhang (2014) use a “distant annotation” method to</context>
<context position="6089" citStr="Xue (2008)" startWordPosition="967" endWordPosition="968"> inference accuracy as well in some of the experiment settings. The rest of the paper is organized as follows. Section 2 discusses related work in automatic tense inference. Section 3 briefly introduces the distant annotation method. In section 4, we describe our experiments and analyze the experimental results. We conclude this paper in section 7. 2 Related Work Inferring the semantic tense of events in Chinese text is not a new topic. There have been several attempts at it, yet high accuracy in this task has proved to be elusive. Using a corpus with tense annotated directly in Chinese text, Xue (2008) performed extensive feature engineering in a machine learning framework to address this problem. They used both local lexical features and structured features extracted from manually annotated syntactic parsing trees. In our baseline method, we adopt most of their features as the baseline, only on a new corpus in which semantic tenses are not annotated directly on Chinese events but projected from annotations from the English side of a parallel Chinese-English corpus. In our experiments, we also use structural features extracted from automatic parse trees, so our experimental settings are mor</context>
<context position="15794" citStr="Xue, 2008" startWordPosition="2571" endWordPosition="2572">keting F-score is 80.5%. Feature extractions are performed on the automatic parse trees. Adopted features include previous word and its POS tag, next word and its POS tag, aspect marker following the event, —following the event, the governing verb of the event, the character string of the main verb in the previous clause that is coordinated with the clause the event is in, whether the event is in quote, and left modifiers of the event including head of adverbial phrases, temporal noun phrases, prepositional phrases, localizer phrases, as well as subordinating clauses. Readers are referred to (Xue, 2008) for details of these features. Since in this corpus an event can span over more than one verb, we also use the character string and the POS string of the entire event instead of one word and one POS tag as features. • The character string of an event – it could be one or more words. In our corpus, only 69.7% events consist of single word (e.g. “9 R”, “live”), the other 30.3% of the events are expressed with two or more words (e.g. “� &amp;+-f”, “have caused”). • The POS string of an event – it could be verbs, nouns, or POS sequences of other word sequences. Table 2 shows the top ten POS tag or PO</context>
<context position="23540" citStr="Xue, 2008" startWordPosition="3957" endWordPosition="3958">s A comparison of the baseline accuracy for the four different subsets of the data shows that (1) tense inference is slightly better on v events than on all events, but the difference is not substantial; and (2) tense inference on newswire data performs better than on all data by around 8% on v events and around 5% on all events, verifying our assumption that automatic tense inference is easier on newswire data than webblog data. Although our experiments are performed on different data sets from that of previous work, our baseline method still shows strong results compared with previous work (Xue, 2008; Ye et al., 2006; Liu et al., 2011). Adding automatic eventuality type and modality labels as features for semantic tense inference leads to improvements over the baseline on all four data subsets. In fact they provide considerable improvements (around 2% increase) on newswire v events dataset. MaxEnt e rows report results when only automatic eventuality type is added as a feature, and MaxEnt m rows report results when only automatic modality is added as a feature. They both outperform (or, in several datasets, match) the baseline results on all datasets. MaxEnt em rows report results when bo</context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. 2008. Automatic Inference of the Temporal Location of Situations in Chinese Text. In EMNLP-2008, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
<author>Victoria Li Fossum</author>
<author>Steven Abney</author>
</authors>
<title>Latent features in automatic tense translation between Chinese and English.</title>
<date>2006</date>
<booktitle>In The Proceedings of the 5th SIGHAN Workshop on Chinese Language Processing,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="1984" citStr="Ye et al., 2006" startWordPosition="302" endWordPosition="305">we address the problem of inferring the semantic tense, or the temporal location of an event (e.g., present, past, future) in Chinese text. The semantic tense is defined relative to the utterance time or document creation time, and it does not always agree with the grammatical tense in languages like English where there is grammatical tense. Inferring semantic tense potentially benefits natural language processing tasks such as Machine Translation and Nianwen Xue Brandeis University 415 South Street Waltham, MA xuen@brandeis.edu Information Extraction (Xue, 2008; Reichart and Rappoport, 2010; Ye et al., 2006; Ye, 2007; Liu et al., 2011), but previous work has shown that automatic inference of the semantic tense of events in Chinese is a very challenging task (Xue, 2008; Ye et al., 2006; Liu et al., 2011). There are at least two reasons why this is a difficult problem. First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge. Xue and Zhang (2014) use a “distant annotation” method to address this problem. They take advantage of a</context>
<context position="6718" citStr="Ye et al. (2006)" startWordPosition="1065" endWordPosition="1068">tensive feature engineering in a machine learning framework to address this problem. They used both local lexical features and structured features extracted from manually annotated syntactic parsing trees. In our baseline method, we adopt most of their features as the baseline, only on a new corpus in which semantic tenses are not annotated directly on Chinese events but projected from annotations from the English side of a parallel Chinese-English corpus. In our experiments, we also use structural features extracted from automatic parse trees, so our experimental settings are more realistic. Ye et al. (2006) took a similar approach in which they predict tense with feature engineering in a statistical learning framework. They also used a Chinese-English parallel corpus and projected tense for English events onto Chinese events via human alignments. The main difference between their data and ours is that they used the grammatical tense of the English events, while we use human-annotated semantic tense which we believe are more “transferrable” across languages as it is free of the language-specific idiosyncrasies of grammatical tense. In addition, they also used human annotated linguistic informatio</context>
<context position="23557" citStr="Ye et al., 2006" startWordPosition="3959" endWordPosition="3962">son of the baseline accuracy for the four different subsets of the data shows that (1) tense inference is slightly better on v events than on all events, but the difference is not substantial; and (2) tense inference on newswire data performs better than on all data by around 8% on v events and around 5% on all events, verifying our assumption that automatic tense inference is easier on newswire data than webblog data. Although our experiments are performed on different data sets from that of previous work, our baseline method still shows strong results compared with previous work (Xue, 2008; Ye et al., 2006; Liu et al., 2011). Adding automatic eventuality type and modality labels as features for semantic tense inference leads to improvements over the baseline on all four data subsets. In fact they provide considerable improvements (around 2% increase) on newswire v events dataset. MaxEnt e rows report results when only automatic eventuality type is added as a feature, and MaxEnt m rows report results when only automatic modality is added as a feature. They both outperform (or, in several datasets, match) the baseline results on all datasets. MaxEnt em rows report results when both automatic ling</context>
</contexts>
<marker>Ye, Fossum, Abney, 2006</marker>
<rawString>Yang Ye, Victoria Li Fossum, and Steven Abney. 2006. Latent features in automatic tense translation between Chinese and English. In The Proceedings of the 5th SIGHAN Workshop on Chinese Language Processing, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
</authors>
<title>Automatic Tense and Aspect Translation between Chinese and English.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Michigan.</institution>
<contexts>
<context position="1994" citStr="Ye, 2007" startWordPosition="306" endWordPosition="307">oblem of inferring the semantic tense, or the temporal location of an event (e.g., present, past, future) in Chinese text. The semantic tense is defined relative to the utterance time or document creation time, and it does not always agree with the grammatical tense in languages like English where there is grammatical tense. Inferring semantic tense potentially benefits natural language processing tasks such as Machine Translation and Nianwen Xue Brandeis University 415 South Street Waltham, MA xuen@brandeis.edu Information Extraction (Xue, 2008; Reichart and Rappoport, 2010; Ye et al., 2006; Ye, 2007; Liu et al., 2011), but previous work has shown that automatic inference of the semantic tense of events in Chinese is a very challenging task (Xue, 2008; Ye et al., 2006; Liu et al., 2011). There are at least two reasons why this is a difficult problem. First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge. Xue and Zhang (2014) use a “distant annotation” method to address this problem. They take advantage of an English-</context>
</contexts>
<marker>Ye, 2007</marker>
<rawString>Yang Ye. 2007. Automatic Tense and Aspect Translation between Chinese and English. Ph.D. thesis, University of Michigan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>