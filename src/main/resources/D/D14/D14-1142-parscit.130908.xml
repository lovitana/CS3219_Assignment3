<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000123">
<title confidence="0.985047">
Can characters reveal your native language? A language-independent
approach to native language identification
</title>
<author confidence="0.994779">
Radu Tudor Ionescu*, Marius Popescu*, Aoife Cahill†
</author>
<affiliation confidence="0.9997465">
*University of Bucharest
Department of Computer Science
</affiliation>
<address confidence="0.985248">
14 Academiei, Bucharest, Romania
</address>
<email confidence="0.9929015">
raducu.ionescu@gmail.com
popescunmarius@gmail.com
</email>
<sectionHeader confidence="0.997311" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947892857143">
A common approach in text mining tasks
such as text categorization, authorship
identification or plagiarism detection is to
rely on features like words, part-of-speech
tags, stems, or some other high-level lin-
guistic features. In this work, an approach
that uses character n-grams as features is
proposed for the task of native language
identification. Instead of doing standard
feature selection, the proposed approach
combines several string kernels using mul-
tiple kernel learning. Kernel Ridge Re-
gression and Kernel Discriminant Analy-
sis are independently used in the learning
stage. The empirical results obtained in all
the experiments conducted in this work in-
dicate that the proposed approach achieves
state of the art performance in native lan-
guage identification, reaching an accuracy
that is 1.7% above the top scoring system
of the 2013 NLI Shared Task. Further-
more, the proposed approach has an im-
portant advantage in that it is language in-
dependent and linguistic theory neutral. In
the cross-corpus experiment, the proposed
approach shows that it can also be topic
independent, improving the state of the art
system by 32.3%.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999442857142857">
Using words as basic units is natural in textual
analysis tasks such as text categorization, author-
ship identification or plagiarism detection. Per-
haps surprisingly, recent results indicate that meth-
ods handling the text at the character level can
also be very effective (Lodhi et al., 2002; Sander-
son and Guenter, 2006; Popescu and Dinu, 2007;
</bodyText>
<subsectionHeader confidence="0.311504">
†Educational Testing Service
</subsectionHeader>
<address confidence="0.5613265">
660 Rosedale Rd
Princeton, NJ 08541, USA
</address>
<email confidence="0.96672">
acahill@ets.org
</email>
<bodyText confidence="0.999527358974359">
Grozea et al., 2009; Popescu, 2011; Popescu and
Grozea, 2012). By disregarding features of natu-
ral language such as words, phrases, or meaning,
an approach that works at the character level has
an important advantage in that it is language inde-
pendent and linguistic theory neutral. This paper
presents a state of the art machine learning system
for native language identification that works at the
character level. The proposed system is inspired
by the system of Popescu and Ionescu (2013), but
includes some variations and improvements. A
major improvement is that several string kernels
are combined via multiple kernel learning (Shawe-
Taylor and Cristianini, 2004). Despite the fact that
the (histogram) intersection kernel is very popular
in computer vision (Maji et al., 2008; Vedaldi and
Zisserman, 2010), it has never been used before in
text mining. In this work, the intersection kernel is
used for the first time in a text categorization task,
alone and in combination with other kernels. The
intersection kernel lies somewhere in the middle
between the kernel that takes into account only the
presence of n-grams and the kernel based on the
frequency of n-grams (p-spectrum string kernel).
Two kernel classifiers are proposed for the
learning task, namely Kernel Ridge Regression
(KRR) and Kernel Discriminant Analysis (KDA).
The KDA classifier is able to avoid the class-
masking problem (Hastie and Tibshirani, 2003),
which may often arise in the context of native
language identification. Several experiments are
conducted to evaluate the performance of the ap-
proach proposed in this work. While multiple ker-
nel learning seems to produce a more robust sys-
tem, the two kernel classifiers obtained mixed re-
sults in the experiments. Overall, the empirical re-
sults indicate that the approach proposed in this
paper achieves state of the art performance in na-
tive language identification, while being both lan-
</bodyText>
<page confidence="0.743388">
1363
</page>
<note confidence="0.8945925">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1363–1373,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999716">
guage independent and linguistic theory neutral.
Furthermore, the approach based on string kernels
does not need any expert knowledge of words or
phrases in the language.
The paper is organized as follows. Related
work is presented in Section 2. Section 3 presents
several similarity measures for strings, including
string kernels and Local Rank Distance. The
learning methods used in the experiments are de-
scribed in Section 4. Section 5 presents details
about the experiments. Finally, the conclusions are
drawn in Section 6.
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.986541">
2.1 Native Language Identification
</subsectionHeader>
<bodyText confidence="0.999996194444444">
The goal of automatic native language identifica-
tion (NLI) is to determine the native language of
a language learner, based on a piece of writing in
a foreign language. This can provide useful in-
formation in forensic linguistic tasks (Estival et
al., 2007) or could be used in an educational set-
ting to provide contrastive feedback to language
learners. Most research has focused on identify-
ing the native language of English language learn-
ers, though there have been some efforts recently
to identify the native language of writing in other
languages (Malmasi and Dras, 2014).
In general most approaches to NLI have used
multi-way classification with SVMs or similar
models along with a range of linguistic features.
The seminal paper by Koppel et al. (2005) intro-
duced some of the best-performing features: char-
acter, word and part-of-speech n-grams along with
features inspired by the work in the area of second-
language acquisition such as spelling and gram-
matical errors. In 2013, Tetreault et al. (2013) or-
ganized the first shared task in the field. This al-
lowed researchers to compare approaches for the
first time on a specifically designed NLI corpus
that was much larger than previously available
data sets. In the shared task, 29 teams submit-
ted results for the test set, and one of the most
successful aspects of the competition was that it
drew submissions from teams working in a variety
of research fields. The submitted systems utilized
a wide range of machine learning approaches,
combined with several innovative feature contri-
butions. The best performing system achieved an
overall accuracy of 83.6% on the 11-way classifi-
cation of the test set, although there was no signif-
icant difference between the top teams.
</bodyText>
<subsectionHeader confidence="0.8744105">
2.2 Methods that Work at the Character
Level
</subsectionHeader>
<bodyText confidence="0.99929706122449">
In recent years, methods of handling text at
the character level have demonstrated impres-
sive performance levels in various text analy-
sis tasks (Lodhi et al., 2002; Sanderson and
Guenter, 2006; Popescu and Dinu, 2007; Grozea
et al., 2009; Popescu, 2011; Popescu and Grozea,
2012). Lodhi et al. (2002) used string kernels
for document categorization with very good re-
sults. String kernels were also successfully used in
authorship identification (Sanderson and Guenter,
2006; Popescu and Dinu, 2007; Popescu and
Grozea, 2012). For example, the system described
in (Popescu and Grozea, 2012) ranked first in most
problems and overall in the PAN 2012 Traditional
Authorship Attribution tasks.
Using string kernels makes the corresponding
learning method completely language indepen-
dent, because the texts will be treated as sequences
of symbols (strings). Methods working at the
word level or above very often restrict their feature
space according to theoretical or empirical princi-
ples. For instance, they select only features that re-
flect various types of spelling errors or only some
type of words, such as function words. These fea-
tures prove to be very effective for specific tasks,
but it is possible that other good features also ex-
ist. String kernels embed the texts in a very large
feature space, given by all the substrings of length
p, and leave it to the learning algorithm to select
important features for the specific task, by highly
weighting these features. It is important to note
that this approach is also linguistic theory neutral,
since it disregards any features of natural language
such as words, phrases, or meaning. On the other
hand, a method that considers words as features
cannot be completely language independent, since
the definition of a word is necessarily language-
specific. For example, a method that uses only
function words as features is not completely lan-
guage independent because it needs a list of func-
tion words which is specific to a language. When
features such as part-of-speech tags are used, as
in the work of Jarvis et al. (2013), the method re-
lies on a part-of-speech tagger which might not be
available (yet) for some languages. Furthermore,
a way to segment a text into words is not an easy
task for some languages, such as Chinese.
Character n-grams are used by some of the sys-
tems developed for native language identification.
</bodyText>
<page confidence="0.991633">
1364
</page>
<bodyText confidence="0.999995318181818">
In work where feature ablation results have been
reported, the performance with only character n-
gram features was modest compared to other types
of features (Tetreault et al., 2012). Initially, most
work limited the character features to unigrams,
bigrams and trigrams, perhaps because longer n-
grams were considered too expensive to compute
or unlikely to improve performance. However,
some of the top systems in the 2013 NLI Shared
Task were based on longer character n-grams,
up to 9-grams (Jarvis et al., 2013; Popescu and
Ionescu, 2013). The results presented in this work
are obtained using a range of 5–8 n-grams. Com-
bining all 5–8 n-grams would generate millions
of features, which are indeed expensive to com-
pute and represent. The key to avoiding the com-
putation of such a large number of features lies
in using the dual representation provided by the
string kernel. String kernel similarity matrices can
be computed much faster and are extremely useful
when the number of samples is much lower than
the number of features.
</bodyText>
<sectionHeader confidence="0.974729" genericHeader="method">
3 Similarity Measures for Strings
</sectionHeader>
<subsectionHeader confidence="0.999848">
3.1 String Kernels
</subsectionHeader>
<bodyText confidence="0.998989882352941">
The kernel function gives kernel methods the
power to naturally handle input data that is not
in the form of numerical vectors, e.g. strings.
The kernel function captures the intuitive notion
of similarity between objects in a specific domain
and can be any function defined on the respec-
tive domain that is symmetric and positive definite.
For strings, many such kernel functions exist with
various applications in computational biology and
computational linguistics (Shawe-Taylor and Cris-
tianini, 2004).
Perhaps one of the most natural ways to mea-
sure the similarity of two strings is to count how
many substrings of length p the two strings have
in common. This gives rise to the p-spectrum ker-
nel. Formally, for two strings over an alphabet E,
s, t E E∗, the p-spectrum kernel is defined as:
</bodyText>
<equation confidence="0.981727">
kp(s, t) = � numv(s) · numv(t),
vEEP
</equation>
<bodyText confidence="0.998001">
where numv(s) is the number of occurrences of
string v as a substring in s.1 The feature map de-
</bodyText>
<footnote confidence="0.98101775">
1Note that the notion of substring requires contiguity.
Shawe-Taylor and Cristianini (2004) discuss the ambiguity
between the terms substring and subsequence across differ-
ent domains: biology, computer science.
</footnote>
<bodyText confidence="0.9988221">
fined by this kernel associates a vector of dimen-
sion |E|p containing the histogram of frequencies
of all its substrings of length p (p-grams) with each
string.
A variant of this kernel can be obtained if the
embedding feature map is modified to associate a
vector of dimension |E|p containing the presence
bits (instead of frequencies) of all its substrings of
length p with each string. Thus, the character p-
grams presence bits kernel is obtained:
</bodyText>
<equation confidence="0.9929905">
�k0/1 p(s, t) = inv(s) · inv(t),
vEEP
</equation>
<bodyText confidence="0.998798666666667">
where inv(s) is 1 if string v occurs as a substring
in s, and 0 otherwise.
In computer vision, the (histogram) intersec-
tion kernel has successfully been used for object
class recognition from images (Maji et al., 2008;
Vedaldi and Zisserman, 2010). In this paper, the
intersection kernel is used for the first time as a
kernel for strings. The intersection string kernel is
defined as follows:
</bodyText>
<equation confidence="0.9954165">
k∩p (s, t) = � min{numv(s), numv(t)},
vEEP
</equation>
<bodyText confidence="0.9999755">
where numv(s) is the number of occurrences of
string v as a substring in s.
For the p-spectrum kernel, the frequency of a p-
gram has a very significant contribution to the ker-
nel, since it considers the product of such frequen-
cies. On the other hand, the frequency of a p-gram
is completely disregarded in the p-grams presence
bits kernel. The intersection kernel lies some-
where in the middle between the p-grams presence
bits kernel and p-spectrum kernel, in the sense that
the frequency of a p-gram has a moderate contri-
bution to the intersection kernel. More precisely,
the following inequality that describes the relation
between the three kernels holds:
</bodyText>
<equation confidence="0.696054">
k0/1 p(s, t) &lt; k∩p (s, t) &lt; kp(s, t).
</equation>
<bodyText confidence="0.9999002">
What is actually more interesting is that the inter-
section kernel assigns a high score to a p-gram if it
has a high frequency in both strings, since it con-
siders the minimum of the two frequencies. The
p-spectrum kernel assigns a high score even when
the p-gram has a high frequency in only one of
the two strings. Thus, the intersection kernel cap-
tures something about the correlation between the
p-gram frequencies in the two strings, which may
lead to a more sensitive similarity between strings.
</bodyText>
<page confidence="0.641323">
1365
</page>
<equation confidence="0.789833">
ˆk∩p (s, t) = �k∩ p (s, s) · k∩p (t, t) .
</equation>
<bodyText confidence="0.9998375625">
Taking into account p-grams of different length
and summing up the corresponding kernels, new
kernels, termed blended spectrum kernels, can be
obtained.
The string kernel implicitly embeds the texts
in a high dimensional feature space. Then, a
kernel-based learning algorithm implicitly assigns
a weight to each feature, thus selecting the fea-
tures that are important for the discrimination task.
For example, in the case of text categorization
the learning algorithm enhances the features rep-
resenting stems of content words (Lodhi et al.,
2002), while in the case of authorship identifica-
tion the same learning algorithm enhances the fea-
tures representing function words (Popescu and
Dinu, 2007).
</bodyText>
<subsectionHeader confidence="0.999394">
3.2 Local Rank Distance
</subsectionHeader>
<bodyText confidence="0.998348642857143">
A recently introduced distance measure, termed
Local Rank Distance (Ionescu, 2013), comes from
the idea of better adapting rank distance (Dinu,
2003) to string data, in order to capture a bet-
ter similarity between strings, such as DNA se-
quences or text. Local Rank Distance (LRD) has
already shown promising results in computational
biology (Ionescu, 2013) and native language iden-
tification (Popescu and Ionescu, 2013).
In order to describe LRD, the following nota-
tions are defined. Given a string x over an al-
phabet E, and a character a ∈ E, the length of
x is denoted by |x|. Strings are considered to
be indexed starting from position 1, that is x =
</bodyText>
<equation confidence="0.7457225">
x[1]x[2] · · · x[|x|]. Moreover, x[i : j] denotes its
substring x[i]x[i + 1] · · · x[j − 1].
</equation>
<bodyText confidence="0.91693835483871">
Local Rank Distance is inspired by rank dis-
tance (Dinu, 2003), the main differences being
that it uses p-grams instead of single charac-
ters, and that it matches each p-gram in the first
string with the nearest equal p-gram in the second
string. Given a fixed integer p ≥ 1, a thresh-
old m ≥ 1, and two strings x and y over E,
the Local Rank Distance between x and y, de-
noted by ALRD(x, y), is defined through the fol-
lowing algorithmic process. For each position i in
x (1 ≤ i ≤ |x |− p + 1), the algorithm searches for
that position j in y (1 ≤ j ≤ |y |− p+ 1) such that
x[i : i + p] = y[j : j + p] and |i−j |is minimized.
If j exists and |i − j |&lt; m, then the offset |i − j|
is added to the Local Rank Distance. Otherwise,
the maximal offset m is added to the Local Rank
Distance. An important remark is that LRD does
not impose any mathematically developed global
constraints, such as matching the i-th occurrence
of a p-gram in x with the i-th occurrence of that
same p-gram in y. Instead, it is focused on the lo-
cal phenomenon, and tries to pair equal p-grams at
a minimum offset. To ensure that LRD is a (sym-
metric) distance function, the algorithm also has
to sum up the offsets obtained from the above pro-
cess by exchanging x and y. LRD can be formally
defined as follows.
Definition 1 Let x, y ∈ E∗ be two strings, and let
p ≥ 1 and m ≥ 1 be two fixed integer values. The
Local Rank Distance between x and y is defined
as:
</bodyText>
<equation confidence="0.454755">
ALRD(x, y) = Aleft(x, y) + A,ight(x, y),
</equation>
<bodyText confidence="0.82579">
where Aleft(x, y) and A,ight(x, y) are defined as
follows:
</bodyText>
<equation confidence="0.9987105">
1 ≤ i ≤ |x |− p + 1 and
y[j : j + p] = x[i : i + p]} ∪ {m}.
</equation>
<bodyText confidence="0.994743307692307">
Interestingly, the search for matching p-grams is
limited within a window of fixed size. The size of
this window is determined by the maximum offset
parameter m. This parameter must be set a priori
and should be proportional to the size of the alpha-
bet, the p-grams, and to the lengths of the strings.
The following example offers a better under-
standing of how LRD actually works. LRD is
computed between two strings using 2-grams.
Example 1 Given two strings x = abcaa and
y = cabca, a fixed maximal offset m = 3, and
Normalized versions of these kernels ensure a
fair comparison of strings of different lengths:
</bodyText>
<equation confidence="0.995652625">
kp(s, t)
ˆkp(s, t) = lkp(s, s) · kp(t, t),
0/1
kp0/1(s t) = kp (s, t)
�,
kp/1(s, s) · k0/1
p (t, t)
k∩p (s, t)
Aleft(x, y) = |X|−p+1 min{|i − j |such that
�
i=1
1 ≤ j ≤ |y |− p + 1 and
x[i : i + p] = y[j : j + p]} ∪ {m},
A,ight(x, y) = |Y|−p+1 min{|j − i |such that
�
j=1
</equation>
<page confidence="0.904413">
1366
</page>
<bodyText confidence="0.8964425">
a fixed size of p-grams p = 2, Aleft and Aright
are computed as follows:
</bodyText>
<equation confidence="0.987757714285714">
Aleft(x,y) = |1 − 2 |+ |2 − 3|
+ |3 − 4 |+ 3 = 6,
Aright(x, y) = |1 − 3 |+ |2 − 1|
+ |3 − 2 |+ |4 − 3 |= 5.
By summing up the two partial sums, Local Rank
Distance is obtained
ALRD(x, y) = Aleft(x, y) + Aright(x, y) = 11.
</equation>
<bodyText confidence="0.999732454545455">
The maximum LRD value between two strings
can be computed as the product between the max-
imum offset m and the number of pairs of com-
pared p-grams. Thus, LRD can be normalized
to a value in the [0, 1] interval. By normalizing,
LRD becomes a dissimilarity measure. LRD can
be also used as a kernel, since kernel methods are
based on similarity. The classical way to transform
a distance or dissimilarity measure into a simi-
larity measure is by using the Gaussian-like ker-
nel (Shawe-Taylor and Cristianini, 2004):
</bodyText>
<equation confidence="0.906848">
ALRD(s, t)
2σ2 ,
</equation>
<bodyText confidence="0.999976833333333">
where s and t are two strings and p is the p-grams
length. The parameter σ is usually chosen so that
values of ˆk(s, t) are well scaled. In the above
equation, ALRD is already normalized to a value
in the [0, 1] interval to ensure a fair comparison of
strings of different length.
</bodyText>
<sectionHeader confidence="0.999722" genericHeader="method">
4 Learning Methods
</sectionHeader>
<bodyText confidence="0.999834333333333">
Kernel-based learning algorithms work by embed-
ding the data into a Hilbert feature space, and
searching for linear relations in that space. The
embedding is performed implicitly, that is by spec-
ifying the inner product between each pair of
points rather than by giving their coordinates ex-
plicitly. More precisely, a kernel matrix that con-
tains the pairwise similarities between every pair
of training samples is used in the learning stage
to assign a vector of weights to the training sam-
ples. Let α denote this weight vector. In the test
stage, the pairwise similarities between a test sam-
ple x and all the training samples are computed.
Then, the following binary classification function
assigns a positive or a negative label to the test
</bodyText>
<equation confidence="0.93026425">
sample:
n
g(x) = αi · k(x, xi),
i=1
</equation>
<bodyText confidence="0.993374">
where x is the test sample, n is the number of
training samples, X = {x1, x2, ..., xn} is the set
of training samples, k is a kernel function, and αi
is the weight assigned to the training sample xi.
In the primal form, the same binary classification
function can be expressed as:
</bodyText>
<equation confidence="0.963167">
g(x) = hw, xi,
</equation>
<bodyText confidence="0.99990425">
where h·, ·i denotes the scalar product, x ∈ Rm is
the test sample represented as a vector of features,
and w ∈ Rm is a vector of feature weights that can
be computed as follows:
</bodyText>
<equation confidence="0.995498">
n
w = αi · xi,
i=1
</equation>
<bodyText confidence="0.999976933333333">
given that the kernel function k can be expressed
as a scalar product between samples.
The advantage of using the dual representation
induced by the kernel function becomes clear if
the dimension of the feature space m is taken
into consideration. Since string kernels are based
on character n-grams, the feature space is indeed
very high. For instance, using 5-grams based only
on the 26 letters of the English alphabet will re-
sult in a feature space of 265 = 11, 881, 376 fea-
tures. However, in the experiments presented in
this work the feature space includes 5-grams along
with 6-grams, 7-grams and 8-grams. As long as
the number of samples n is not greater than the
number of features m, it is more efficient to use
the dual representation given by the kernel matrix.
This fact is also known as the kernel trick (Shawe-
Taylor and Cristianini, 2004).
Various kernel methods differ in the way they
learn to separate the samples. In the case of binary
classification problems, kernel-based learning al-
gorithms look for a discriminant function, a func-
tion that assigns +1 to examples belonging to one
class and −1 to examples belonging to the other
class. For the NLI experiments, two binary kernel
classifiers are used, namely the SVM (Cortes and
Vapnik, 1995), and the KRR. Support Vector Ma-
chines try to find the vector of weights that defines
the hyperplane that maximally separates the im-
ages in the Hilbert space of the training examples
</bodyText>
<equation confidence="0.9904965">
ˆkLRD
p (s, t) = e
</equation>
<page confidence="0.916955">
1367
</page>
<bodyText confidence="0.99993175">
belonging to the two classes. Kernel Ridge Re-
gression selects the vector of weights that simulta-
neously has small empirical error and small norm
in the Reproducing Kernel Hilbert Space gener-
ated by the kernel function. More details about
SVM and KRR can be found in (Shawe-Taylor and
Cristianini, 2004). The important fact is that the
above optimization problems are solved in such a
way that the coordinates of the embedded points
are not needed, only their pairwise inner products
which in turn are given by the kernel function.
SVM and KRR produce binary classifiers, but
native language identification is usually a multi-
class classification problem. There are many ap-
proaches for combining binary classifiers to solve
multi-class problems. Typically, the multi-class
problem is broken down into multiple binary clas-
sification problems using common decomposing
schemes such as: one-versus-all and one-versus-
one. There are also kernel methods that take the
multi-class nature of the problem directly into ac-
count, e.g. Kernel Discriminant Analysis. The
KDA classifier is able to improve accuracy by
avoiding the masking problem (Hastie and Tib-
shirani, 2003). In the case of multi-class native
language identification, the masking problem may
appear when non-native English speakers have ac-
quired, as the second language, a different lan-
guage to English. For example, an essay written in
English produced by a French native speaker that
is also proficient in German, could be identified as
either French or German.
</bodyText>
<sectionHeader confidence="0.999943" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.995099">
5.1 Data Sets Description
</subsectionHeader>
<bodyText confidence="0.999180142857143">
In this paper, experiments are carried out on three
datasets: a modified version of the ICLEv2 cor-
pus (Granger et al., 2009), the ETS Corpus of
Non-Native Written English, or TOEFL11 (Blan-
chard et al., 2013), and the TOEFL11-Big corpus
as used by Tetreault et al. (2012). A summary of
the corpora is given in Table 1.
</bodyText>
<table confidence="0.9944245">
Corpus Languages Documents
ICLE 7 770
TOEFL11 11 12,100
TOEFL11-Big 11 87,502
</table>
<tableCaption confidence="0.9704835">
Table 1: Summary of corpora used in the experi-
ments.
</tableCaption>
<bodyText confidence="0.996124925">
The ICLEv2 is a corpus of essays written by
highly-proficient non-native college-level students
of English. For many years this was the standard
corpus used in the task of native language identi-
fication. However, the corpus was originally col-
lected for the purpose of corpus linguistic inves-
tigations, and because of this contains some id-
iosyncrasies that make it problematic for the task
of NLI (Brooke and Hirst, 2012). Therefore, a
modified version of the corpus that has been nor-
malized as much as possible for topic and charac-
ter encoding (Tetreault et al., 2012) is used. This
version of the corpus contains 110 essays each for
7 native languages: Bulgarian, Chinese, Czech,
French, Japanese, Russian and Spanish.
The ETS Corpus of Non-Native Written English
(TOEFL11) was first introduced by Tetreault et al.
(2012) and extended for the 2013 Native Language
Identification Shared Task (Tetreault et al., 2013).
It was designed to overcome many of the short-
comings identified with using the ICLEv2 corpus
for this task. The TOEFL11 corpus contains a
balanced distribution of essays per prompt (topic)
per native language. It also contains information
about the language proficiency of each writer. The
corpus contains essays written by speakers of the
following 11 languages: Arabic, Chinese, French,
German, Hindi, Italian, Japanese, Korean, Span-
ish, Telugu and Turkish. For the shared task, the
12,100 essays were split into 9,900 for training,
1,100 for development and 1,100 for testing.
Tetreault et al. (2012) present a corpus,
TOEFL11-Big, to investigate the performance of
their NLI system on a very large data set. This
data set contains the same languages as TOEFL11,
but with no overlap in content. It contains a total
of over 87 thousand essays written to a total of
76 different prompts. The distribution of L1 per
prompt is not as even as for TOEFL11, though all
topics are represented for all L1s.
</bodyText>
<subsectionHeader confidence="0.9961225">
5.2 Parameter Tuning and Implementation
Choices
</subsectionHeader>
<bodyText confidence="0.999973555555556">
In the string kernels approach proposed in this
work, documents or essays from this corpus are
treated as strings. Therefore, the notions of string
or document is used interchangeably throughout
this work. Because the approach works at the char-
acter level, there is no need to split the texts into
words, or to do any NLP-specific preprocessing.
The only editing done to the texts was the replac-
ing of sequences of consecutive space characters
</bodyText>
<page confidence="0.985323">
1368
</page>
<bodyText confidence="0.999357202702703">
(space, tab, new line, and so on) with a single
space character. This normalization was needed in
order to prevent the artificial increase or decrease
of the similarity between texts, as a result of differ-
ent spacing. All uppercase letters were converted
to the corresponding lowercase ones.
A series of preliminary experiments were con-
ducted in order to select the best-performing learn-
ing method. In these experiments the string ker-
nel was fixed to the p-spectrum normalized ker-
nel of length 5 (ˆk5), because the goal was to se-
lect the best learning method, and not to find the
best kernel. The following learning methods were
evaluated: one-versus-one SVM, one-versus-all
SVM, one-versus-one KRR, one-versus-all KRR,
and KDA. A 10-fold cross-validation procedure
was carried out on the TOEFL11 training set to
evaluate the classifiers. The preliminary results in-
dicate that the one-versus-all KRR and the KDA
classifiers produce the best results. Therefore,
they are selected for the remaining experiments.
Another set of preliminary experiments were
performed to determine the range of n-grams that
gives the most accurate results on a 10-fold cross-
validation procedure carried out on the TOEFL11
training set. All the n-grams in the range 2-10
were evaluated. Furthermore, experiments with
different blended kernels were conducted to see
whether combining n-grams of different lengths
could improve the accuracy. The best results were
obtained when all the n-grams with the length in
the range 5-8 were used. Other authors (Bykh
and Meurers, 2012; Popescu and Ionescu, 2013)
also report better results by using n-grams with
the length in a range, rather than using n-grams
of fixed length. Consequently, the results reported
in this work are based on blended string kernels
based on 5-8 n-grams.
Some preliminary experiments were also per-
formed to establish the type of kernel to be used,
namely the blended p-spectrum kernel ( ˆk5−8), the
blended p-grams presence bits kernel ( ˆk0/1
5−8), the
ˆk∩5−8), or the
kernel based on LRD (ˆkLRD
5−8 .). These different
kernel representations are obtained from the same
data. The idea of combining all these kernels is
natural when one wants to improve the perfor-
mance of a classifier. When multiple kernels are
combined, the features are actually embedded in
a higher-dimensional space. As a consequence,
the search space of linear patterns grows, which
helps the classifier to select a better discriminant
function. The most natural way of combining two
kernels is to sum them up. Summing up kernels
or kernel matrices is equivalent to feature vector
concatenation. Another option is to combine ker-
nels by kernel alignment (Cristianini et al., 2001).
Instead of simply summing kernels, kernel align-
ment assigns weights for each of the two kernels
based on how well they are aligned with the ideal
kernel Y Y 0 obtained from training labels. The ker-
nels were evaluated alone and in various combina-
tions. The best kernels are the blended p-grams
presence bits kernel and the blended p-grams in-
tersection kernel. The best kernel combinations
include the blended p-grams presence bits kernel,
the blended p-grams intersection kernel and the
kernel based on LRD. Since the kernel based on
LRD is slightly slower than the other string ker-
nels, the kernel combinations that include it were
only evaluated on the TOEFL11 corpus and on the
ICLE corpus.
</bodyText>
<subsectionHeader confidence="0.987703">
5.3 Experiment on TOEFL11 Corpus
</subsectionHeader>
<bodyText confidence="0.99969825">
This section describes the results on the TOEFL11
corpus. Thus, results for the 2013 Closed NLI
Shared Task are also included. In the closed shared
task the goal is to predict the native language of
testing examples, restricted to learning only from
the training and the development data. The ad-
ditional information from prompts or the English
language proficiency level were not used in the
proposed approach.
The regularization parameters were tuned on the
development set. In this case, the systems were
trained on the entire training set. A 10-fold cross-
validation (CV) procedure was done on the train-
ing and the development sets. The folds were pro-
vided along with the TOEFL11 corpus. Finally,
the results of the proposed systems are also re-
ported on the NLI Shared Task test set. For test-
ing, the systems were trained on both the training
set and the development set. The results are sum-
marized in Table 2.
The results presented in Table 2 show that string
kernels can reach state of the art accuracy levels
for this task. Overall, it seems that KDA is able
to obtain better results than KRR. The intersection
kernel alone is able to obtain slightly better results
than the presence bits kernel. The kernel based on
LRD gives significantly lower accuracy rates, but
it is able to improve the performance when it is
</bodyText>
<table confidence="0.976198051282051">
blended p-grams intersection kernel (
1369
Method Development 10-fold CV Test
Ensemble model (Tetreault et al., 2012) - 80.9% -
KRR and string kernels (Popescu and Ionescu, 2013) - 82.6% 82.7%
SVM and word features (Jarvis et al., 2013) - 84.5% 83.6%
KRR and ˆk0/1 85.4% 82.5% 82.0%
5−8 84.9% 82.2% 82.6%
KRR and ˆk∩ 78.7% 77.1% 77.5%
5−8 85.7% 82.6% 82.7%
KRR and ˆkLRD 84.9% 82.2% 82.0%
5−8 85.5% 82.6% 82.5%
KRR and ˆk0/1 85.5% 82.6% 82.5%
5−8 + ˆkLRD
5−8
KRR and k5 8 +ˆkSRa
KRR and ˆk, a + ˆk∩
5−8
KRR and a1ˆk0/1
5−8 + a2ˆk∩
5−8
KDA and ˆk0/1 86.2% 83.6% 83.6%
5−8 85.2% 83.5% 84.6%
KDA and ˆk∩ 79.7% 78.5% 79.2%
5−8 87.1% 84.0% 84.7%
KDA and ˆkLRD 85.8% 83.4% 83.9%
5−8 86.4% 84.1% 85.0%
KDA and ˆk0/1 86.5% 84.1% 85.3%
5−8 + ˆkLRD 87.0% 84.1% 84.8%
5−8
KDA and k5 8 +ˆkSRa
KDA and ˆk, a + ˆk∩
5−8
KDA and a1ˆk0/1
5−8 + a2ˆk∩
5−8
KDA and ˆk0/1
5−8 + ˆk∩5−8 + ˆkLRD
5−8
</table>
<tableCaption confidence="0.744555">
Table 2: Accuracy rates on TOEFL11 corpus of various classification systems based on string kernels
compared with other state of the art approaches. The best accuracy rates on each set of experiments are
highlighted in bold. The weights a1 and a2 from the weighted sums of kernels are computed by kernel
alignment.
</tableCaption>
<bodyText confidence="0.999894171428571">
combined with the blended p-grams presence bits
kernel. In fact, most of the kernel combinations
give better results than each of their components.
The best kernel combination is that of the pres-
ence bits kernel and the intersection kernel. Re-
sults are quite similar when they are combined ei-
ther by summing them up or by kernel alignment.
The best performance on the test set (85.3%) is ob-
tained by the system that combines these two ker-
nels via kernel alignment and learns using KDA.
This system is 1.7% better than the state of the art
system of Jarvis et al. (2013) based on SVM and
word features, this being the top scoring system in
the NLI 2013 Shared Task. It is also 2.6% better
than the state of the art system based on string ker-
nels of Popescu and Ionescu (2013). On the cross
validation procedure, there are three systems that
reach the accuracy rate of 84.1%. All of them are
based on KDA and various kernel combinations.
The greatest accuracy rate of 84.1% reported for
the cross validation procedure is 3.2% above the
state of the art system of Tetreault et al. (2012) and
0.4% below the top scoring system of Jarvis et al.
(2013). The empirical results obtained in this ex-
periment demonstrate that the approach proposed
in this paper can reach state of the art accuracy
levels. It is worth mentioning that a significance
test performed by the organizers of the NLI 2013
Shared Task showed that the top systems that par-
ticipated in the competition are not essentially dif-
ferent. Further experiments on the ICLE corpus
and on the TOEFL11-Big corpus are conducted to
determine whether the approach proposed in this
paper is significantly better than other state of the
art approaches.
</bodyText>
<subsectionHeader confidence="0.99655">
5.4 Experiment on ICLE Corpus
</subsectionHeader>
<bodyText confidence="0.999984238095238">
The results on the ICLE corpus using a 5-fold
cross validation procedure are summarized in Ta-
ble 3. To adequately compare the results with a
state of the art system, the same 5-fold cross val-
idation procedure used by Tetreault et al. (2012)
was also used in this experiment. Table 3 shows
that the results obtained by the presence bits kernel
and by the intersection kernel are systematically
better than the state of the art system of Tetreault
et al. (2012). While both KRR and KDA produce
accuracy rates that are better than the state of the
art accuracy rate, it seems that KRR is slightly bet-
ter in this experiment. Again, the idea of com-
bining kernels seems to produce more robust sys-
tems. The best systems are based on combin-
ing the presence bits kernel either with the kernel
based on LRD or the intersection kernel. Over-
all, the reported accuracy rates are higher than the
state of the art accuracy rate. The best perfor-
mance (91.3%) is achieved by the KRR classifier
based on combining the presence bits kernel with
</bodyText>
<page confidence="0.960337">
1370
</page>
<table confidence="0.99877340625">
Method 5-fold CV
Ensemble model (Tetreault et al., 2012) 90.1%
KRR and ˆk0/1 91.2%
5−8 90.5%
KRR and ˆk∩ 81.8%
5−8 91.3%
KRR and ˆk5Ra 90.1%
KRR and ˆk, a + ˆkLRD 90.9%
5−8 90.6%
KRR and ˆk∩5−8 + ˆkLRD
5−8
KRR and ˆk0/1
5−8 + ˆk∩
5−8
KRR and ˆk0/1
5−8 + ˆk∩5−8 + ˆkLRD
5−8
KDA and ˆk0/1 90.5%
5−8 90.5%
KDA and ˆk∩ 82.3%
5−8 90.8%
KDA and ˆkLRD 90.4%
5−8 91.0%
KDA and ˆk5− a +k5Ra 90.8%
KDAand ˆk∩5−8 + ˆkLRD
5−8
KDA and ˆk0/1
5−8 + ˆk∩
5−8
KDA and ˆk0/1
5−8 + ˆk∩5−8 + ˆkLRD
5−8
</table>
<tableCaption confidence="0.999255">
Table 3: Accuracy rates on ICLE corpus of vari-
</tableCaption>
<bodyText confidence="0.975974565217391">
ous classification systems based on string kernels
compared with a state of the art approach. The ac-
curacy rates are reported for the same 5-fold CV
procedure as in (Tetreault et al., 2012). The best
accuracy rate is highlighted in bold.
the kernel based on LRD. This represents an 1.2%
improvement over the state of the art accuracy rate
of Tetreault et al. (2012). Two more systems are
able to obtain accuracy rates greater than 91.0%.
These are the KRR classifier based on the presence
bits kernel (91.2%) and the KDA classifier based
on the sum of the presence bits kernel and the in-
tersection kernel (91.0%). The overall results on
the ICLE corpus show that the string kernels ap-
proach can reach state of the art accuracy levels.
It is worth mentioning the purpose of this experi-
ment was to use the same approach determined to
work well in the TOEFL11 corpus. To serve this
purpose, the range of n-grams was not tuned on
this data set. Furthermore, other classifiers were
not tested in this experiment. Nevertheless, better
results can probably be obtained by adding these
aspects into the equation.
</bodyText>
<subsectionHeader confidence="0.891533">
5.5 Cross-corpus Experiment
</subsectionHeader>
<bodyText confidence="0.999955555555555">
In this experiment, various systems based on KRR
or KDA are trained on the TOEFL11 corpus and
tested on the TOEFL11-Big corpus. The kernel
based on LRD was not included in this experiment
since it is more computationally expensive. There-
fore, only the presence bits kernel and the intersec-
tion kernel were evaluated on the TOEFL11-Big
corpus. The results are summarized in Table 4.
The same regularization parameters determined to
</bodyText>
<table confidence="0.995179727272727">
Method Test
Ensemble model (Tetreault et al., 2012) 35.4%
KRR and ˆk0/1 66.7%
5−8 67.2%
KRR and ˆk∩ 67.7%
5−8 67.7%
KRR and ˆk0/1
5−8 + ˆk∩
5−8
KRR and a1ˆk0/1
5−8 + a2ˆk∩
5−8
KDA and ˆk0/1 65.6%
5−8 65.7%
KDA and ˆk∩ 66.2%
5−8 66.2%
KDA and ˆk0/1
5−8 + ˆk∩
5−8
KDA and a1ˆk0/1
5−8 + a2ˆk∩
5−8
</table>
<tableCaption confidence="0.997358">
Table 4: Accuracy rates on TOEFL11-Big corpus
</tableCaption>
<bodyText confidence="0.991300615384616">
of various classification systems based on string
kernels compared with a state of the art approach.
The systems are trained on the TOEFL11 corpus
and tested on the TOEFL11-Big corpus. The best
accuracy rate is highlighted in bold. The weights
a1 and a2 from the weighted sums of kernels are
computed by kernel alignment.
work well on the TOEFL11 development set were
used.
The most interesting fact is that all the proposed
systems are at least 30% better than the state of the
art system. Considering that the TOEFL11-Big
corpus contains 87 thousand samples, the 30% im-
provement is significant without any doubt. Div-
ing into details, it can be observed that the results
obtained by KRR are higher than those obtained
by KDA. However, both methods perform very
well compared to the state of the art. Again, kernel
combinations are better than each of their individ-
ual kernels alone.
It is important to mention that the significant
performance increase is not due to the learning
method (KRR or KDA), but rather due to the string
kernels that work at the character level. It is not
only the case that string kernels are language in-
dependent, but for the same reasons they can also
be topic independent. Since the topics (prompts)
from TOEFL11 are different from the topics from
TOEFL11-Big, it becomes clear that a method
that uses words as features is strongly affected,
since the distribution of words per topic can be
completely different. But mistakes that reveal the
native language can be captured by character n-
grams that can appear more often even in differ-
ent topics. The results indicate that this is also
the case of the approach based on string kernels,
which seems to be more robust to such topic vari-
ations of the data set. The best system has an ac-
curacy rate that is 32.3% better than the state of
</bodyText>
<page confidence="0.972338">
1371
</page>
<bodyText confidence="0.99993125">
the art system of Tetreault et al. (2012). Overall,
the empirical results indicate that the string ker-
nels approach can achieve significantly better re-
sults than other state of the art approaches.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9999952">
A language-independent approach to native lan-
guage identification was presented in this paper.
The system works at the character level, mak-
ing the approach completely language indepen-
dent and linguistic theory neutral. The results ob-
tained in all the three experiments were very good.
The best system presented in this work is based on
combining the intersection and the presence string
kernels by kernel alignment and on deciding the
class label either with KDA or KRR. The best sys-
tem is 1.7% above the top scoring system of the
2013 NLI Shared Task. Furthermore, it has an im-
pressive generalization capacity, achieving results
that are 30% higher than the state of the art method
in the cross-corpus experiment.
Despite the fact that the approach based on
string kernels performed so well, it remains to be
further investigated why this is the case and why
such a simple approach can compete with far more
complex approaches that take words, lemmas,
syntactic information, or even semantics into ac-
count. It seems that there are generalizations to the
kinds of mistakes that certain non-native English
speakers make that can be captured by n-grams
of different lengths. Interestingly, using a range
of n-grams generates a large number of features
including (but not limited to) stop words, stems
of content words, word suffixes, entire words, and
even n-grams of short words. Rather than doing
feature selection before the training step, which
is the usual NLP approach, the kernel classifier
selects the most relevant features during training.
With enough training samples, the kernel classi-
fier does a better job of selecting the right features
from a very high feature space. This may be one
reason for why the string kernel approach works
so well. To gain additional insights into why this
technique is working well, the features selected
by the classifier as being more discriminating can
be analyzed in future work. This analysis would
also offer some information about localized lan-
guage transfer effects, since the features used by
the proposed model are n-grams of lengths 5 to
8. As mentioned before, the features captured by
the model typically include stems, function words,
word prefixes and suffixes, which have the poten-
tial to generalize over purely word-based features.
These features would offer insights into two kinds
of language transfer effects, namely word choice
(lexical transfer) and morphological differences.
</bodyText>
<sectionHeader confidence="0.998643" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999981666666667">
The authors would like to thank Beata Beigman
Klebanov, Nitin Madnani and Xinhao Wang from
ETS for their helpful comments and suggestions.
The author also thank the anonymous reviewers
for their valuable insights which lead to improve-
ments in the presentation of this work.
</bodyText>
<sectionHeader confidence="0.999627" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999303108108108">
Daniel Blanchard, Joel Tetreault, Derrick Higgins,
Aoife Cahill, and Martin Chodorow. 2013.
TOEFL11: A Corpus of Non-Native English. Tech-
nical report, Educational Testing Service Research
Report No. RR–13–24.
Julian Brooke and Graeme Hirst. 2012. Robust, Lex-
icalized Native Language Identification. Proceed-
ings of COLING 2012, pages 391–408, December.
Serhiy Bykh and Detmar Meurers. 2012. Native Lan-
guage Identification using Recurring n-grams – In-
vestigating Abstraction and Domain Dependence.
Proceedings of COLING 2012, pages 425–440, De-
cember.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
Vector Networks. Machine Learning, 20(3):273–
297.
Nello Cristianini, John Shawe-Taylor, Andr´e Elisseeff,
and Jaz S. Kandola. 2001. On kernel-target align-
ment. Proceedings of NIPS, pages 367–373, De-
cember.
Liviu P. Dinu. 2003. On the classification and aggre-
gation of hierarchies with different constitutive ele-
ments. Fundamenta Informaticae, 55(1):39–50.
Dominique Estival, Tanja Gaustad, Son-Bao Pham,
Will Radford, and Ben Hutchinson. 2007. Author
profiling for English emails. Proceedings of PA-
CLING, pages 263–272.
Sylviane Granger, Estelle Dagneaux, and Fanny Me-
unier. 2009. The International Corpus of
Learner English: Handbook and CD-ROM, version
2. Presses Universitaires de Louvain, Louvain-la-
Neuve, Belgium.
Cristian Grozea, Christian Gehl, and Marius Popescu.
2009. ENCOPLOT: Pairwise Sequence Matching
in Linear Time Applied to Plagiarism Detection. In
3rd PAN Workshop. Uncovering Plagiarism, Author-
ship, and Social Software Misuse, page 10.
</reference>
<page confidence="0.85441">
1372
</page>
<reference confidence="0.99977862295082">
Trevor Hastie and Robert Tibshirani. 2003. The El-
ements of Statistical Learning. Springer, corrected
edition, July.
Radu Tudor Ionescu. 2013. Local Rank Distance.
Proceedings of SYNASC, pages 221–228.
Scott Jarvis, Yves Bestgen, and Steve Pepper. 2013.
Maximizing classification accuracy in native lan-
guage identification. Proceedings of the Eighth
Workshop on Innovative Use of NLP for Building
Educational Applications, pages 111–118, June.
Moshe Koppel, Jonathan Schler, and Kfir Zigdon.
2005. Automatically Determining an Anonymous
Author’s Native Language. Proceedings of ISI,
pages 209–217.
Huma Lodhi, Craig Saunders, John Shawe-Taylor,
Nello Cristianini, and Christopher J. C. H. Watkins.
2002. Text classification using string kernels. Jour-
nal of Machine Learning Research, 2:419–444.
Subhransu Maji, Alexander C. Berg, and Jitendra Ma-
lik. 2008. Classification using intersection kernel
support vector machines is efficient. Proceedings of
CVPR.
Shervin Malmasi and Mark Dras. 2014. Chinese Na-
tive Language Identification. Proceedings of EACL,
2:95–99, April.
Marius Popescu and Liviu P. Dinu. 2007. Kernel meth-
ods and string kernels for authorship identification:
The federalist papers case. Proceedings of RANLP,
September.
Marius Popescu and Cristian Grozea. 2012. Ker-
nel methods and string kernels for authorship analy-
sis. CLEF (Online Working Notes/Labs/Workshop),
September.
Marius Popescu and Radu Tudor Ionescu. 2013. The
Story of the Characters, the DNA and the Native
Language. Proceedings of the Eighth Workshop on
Innovative Use of NLP for Building Educational Ap-
plications, pages 270–278, June.
Marius Popescu. 2011. Studying translationese at the
character level. Proceedings of RANLP, pages 634–
639, September.
Conrad Sanderson and Simon Guenter. 2006. Short
text authorship attribution via sequence kernels,
markov chains and author unmasking: An investiga-
tion. Proceedings of EMNLP, pages 482–491, July.
John Shawe-Taylor and Nello Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press.
Joel Tetreault, Daniel Blanchard, Aoife Cahill, and
Martin Chodorow. 2012. Native Tongues, Lost and
Found: Resources and Empirical Evaluations in Na-
tive Language Identification. Proceedings of COL-
ING 2012, pages 2585–2602, December.
Joel Tetreault, Daniel Blanchard, and Aoife Cahill.
2013. A report on the first native language identifi-
cation shared task. Proceedings of the Eighth Work-
shop on Innovative Use of NLP for Building Educa-
tional Applications, pages 48–57, June.
Andrea Vedaldi and Andrew Zisserman. 2010. Effi-
cient additive kernels via explicit feature maps. Pro-
ceedings of CVPR, pages 3539–3546.
</reference>
<page confidence="0.984755">
1373
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.591765">
<title confidence="0.9444375">Can characters reveal your native language? A approach to native language identification</title>
<author confidence="0.998622">Tudor Marius Aoife</author>
<affiliation confidence="0.9715855">of Bucharest Department of Computer Science</affiliation>
<address confidence="0.999584">14 Academiei, Bucharest, Romania</address>
<email confidence="0.9965315">raducu.ionescu@gmail.compopescunmarius@gmail.com</email>
<abstract confidence="0.999423142857143">A common approach in text mining tasks such as text categorization, authorship identification or plagiarism detection is to rely on features like words, part-of-speech tags, stems, or some other high-level linguistic features. In this work, an approach uses character as features is proposed for the task of native language identification. Instead of doing standard feature selection, the proposed approach combines several string kernels using multiple kernel learning. Kernel Ridge Regression and Kernel Discriminant Analysis are independently used in the learning stage. The empirical results obtained in all the experiments conducted in this work indicate that the proposed approach achieves state of the art performance in native language identification, reaching an accuracy is the top scoring system of the 2013 NLI Shared Task. Furthermore, the proposed approach has an important advantage in that it is language independent and linguistic theory neutral. In the cross-corpus experiment, the proposed approach shows that it can also be topic independent, improving the state of the art</abstract>
<intro confidence="0.712821">by</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Daniel Blanchard</author>
<author>Joel Tetreault</author>
</authors>
<location>Derrick Higgins,</location>
<marker>Blanchard, Tetreault, </marker>
<rawString>Daniel Blanchard, Joel Tetreault, Derrick Higgins,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Martin Chodorow</author>
</authors>
<title>TOEFL11: A Corpus of Non-Native English.</title>
<date>2013</date>
<tech>Technical report, Educational Testing Service Research Report No. RR–13–24.</tech>
<marker>Cahill, Chodorow, 2013</marker>
<rawString>Aoife Cahill, and Martin Chodorow. 2013. TOEFL11: A Corpus of Non-Native English. Technical report, Educational Testing Service Research Report No. RR–13–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Brooke</author>
<author>Graeme Hirst</author>
</authors>
<title>Robust, Lexicalized Native Language Identification.</title>
<date>2012</date>
<booktitle>Proceedings of COLING 2012,</booktitle>
<pages>391--408</pages>
<contexts>
<context position="23383" citStr="Brooke and Hirst, 2012" startWordPosition="3992" endWordPosition="3995"> Tetreault et al. (2012). A summary of the corpora is given in Table 1. Corpus Languages Documents ICLE 7 770 TOEFL11 11 12,100 TOEFL11-Big 11 87,502 Table 1: Summary of corpora used in the experiments. The ICLEv2 is a corpus of essays written by highly-proficient non-native college-level students of English. For many years this was the standard corpus used in the task of native language identification. However, the corpus was originally collected for the purpose of corpus linguistic investigations, and because of this contains some idiosyncrasies that make it problematic for the task of NLI (Brooke and Hirst, 2012). Therefore, a modified version of the corpus that has been normalized as much as possible for topic and character encoding (Tetreault et al., 2012) is used. This version of the corpus contains 110 essays each for 7 native languages: Bulgarian, Chinese, Czech, French, Japanese, Russian and Spanish. The ETS Corpus of Non-Native Written English (TOEFL11) was first introduced by Tetreault et al. (2012) and extended for the 2013 Native Language Identification Shared Task (Tetreault et al., 2013). It was designed to overcome many of the shortcomings identified with using the ICLEv2 corpus for this </context>
</contexts>
<marker>Brooke, Hirst, 2012</marker>
<rawString>Julian Brooke and Graeme Hirst. 2012. Robust, Lexicalized Native Language Identification. Proceedings of COLING 2012, pages 391–408, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serhiy Bykh</author>
<author>Detmar Meurers</author>
</authors>
<title>Native Language Identification using Recurring n-grams – Investigating Abstraction and Domain Dependence.</title>
<date>2012</date>
<booktitle>Proceedings of COLING 2012,</booktitle>
<pages>425--440</pages>
<contexts>
<context position="26930" citStr="Bykh and Meurers, 2012" startWordPosition="4560" endWordPosition="4563">ce the best results. Therefore, they are selected for the remaining experiments. Another set of preliminary experiments were performed to determine the range of n-grams that gives the most accurate results on a 10-fold crossvalidation procedure carried out on the TOEFL11 training set. All the n-grams in the range 2-10 were evaluated. Furthermore, experiments with different blended kernels were conducted to see whether combining n-grams of different lengths could improve the accuracy. The best results were obtained when all the n-grams with the length in the range 5-8 were used. Other authors (Bykh and Meurers, 2012; Popescu and Ionescu, 2013) also report better results by using n-grams with the length in a range, rather than using n-grams of fixed length. Consequently, the results reported in this work are based on blended string kernels based on 5-8 n-grams. Some preliminary experiments were also performed to establish the type of kernel to be used, namely the blended p-spectrum kernel ( ˆk5−8), the blended p-grams presence bits kernel ( ˆk0/1 5−8), the ˆk∩5−8), or the kernel based on LRD (ˆkLRD 5−8 .). These different kernel representations are obtained from the same data. The idea of combining all th</context>
</contexts>
<marker>Bykh, Meurers, 2012</marker>
<rawString>Serhiy Bykh and Detmar Meurers. 2012. Native Language Identification using Recurring n-grams – Investigating Abstraction and Domain Dependence. Proceedings of COLING 2012, pages 425–440, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>SupportVector Networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<volume>20</volume>
<issue>3</issue>
<pages>297</pages>
<contexts>
<context position="20751" citStr="Cortes and Vapnik, 1995" startWordPosition="3562" endWordPosition="3565">samples n is not greater than the number of features m, it is more efficient to use the dual representation given by the kernel matrix. This fact is also known as the kernel trick (ShaweTaylor and Cristianini, 2004). Various kernel methods differ in the way they learn to separate the samples. In the case of binary classification problems, kernel-based learning algorithms look for a discriminant function, a function that assigns +1 to examples belonging to one class and −1 to examples belonging to the other class. For the NLI experiments, two binary kernel classifiers are used, namely the SVM (Cortes and Vapnik, 1995), and the KRR. Support Vector Machines try to find the vector of weights that defines the hyperplane that maximally separates the images in the Hilbert space of the training examples ˆkLRD p (s, t) = e 1367 belonging to the two classes. Kernel Ridge Regression selects the vector of weights that simultaneously has small empirical error and small norm in the Reproducing Kernel Hilbert Space generated by the kernel function. More details about SVM and KRR can be found in (Shawe-Taylor and Cristianini, 2004). The important fact is that the above optimization problems are solved in such a way that </context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. SupportVector Networks. Machine Learning, 20(3):273– 297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>John Shawe-Taylor</author>
<author>Andr´e Elisseeff</author>
<author>Jaz S Kandola</author>
</authors>
<title>On kernel-target alignment.</title>
<date>2001</date>
<booktitle>Proceedings of NIPS,</booktitle>
<pages>367--373</pages>
<contexts>
<context position="28077" citStr="Cristianini et al., 2001" startWordPosition="4747" endWordPosition="4750"> representations are obtained from the same data. The idea of combining all these kernels is natural when one wants to improve the performance of a classifier. When multiple kernels are combined, the features are actually embedded in a higher-dimensional space. As a consequence, the search space of linear patterns grows, which helps the classifier to select a better discriminant function. The most natural way of combining two kernels is to sum them up. Summing up kernels or kernel matrices is equivalent to feature vector concatenation. Another option is to combine kernels by kernel alignment (Cristianini et al., 2001). Instead of simply summing kernels, kernel alignment assigns weights for each of the two kernels based on how well they are aligned with the ideal kernel Y Y 0 obtained from training labels. The kernels were evaluated alone and in various combinations. The best kernels are the blended p-grams presence bits kernel and the blended p-grams intersection kernel. The best kernel combinations include the blended p-grams presence bits kernel, the blended p-grams intersection kernel and the kernel based on LRD. Since the kernel based on LRD is slightly slower than the other string kernels, the kernel </context>
</contexts>
<marker>Cristianini, Shawe-Taylor, Elisseeff, Kandola, 2001</marker>
<rawString>Nello Cristianini, John Shawe-Taylor, Andr´e Elisseeff, and Jaz S. Kandola. 2001. On kernel-target alignment. Proceedings of NIPS, pages 367–373, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liviu P Dinu</author>
</authors>
<title>On the classification and aggregation of hierarchies with different constitutive elements.</title>
<date>2003</date>
<journal>Fundamenta Informaticae,</journal>
<volume>55</volume>
<issue>1</issue>
<contexts>
<context position="14017" citStr="Dinu, 2003" startWordPosition="2260" endWordPosition="2261">ning algorithm implicitly assigns a weight to each feature, thus selecting the features that are important for the discrimination task. For example, in the case of text categorization the learning algorithm enhances the features representing stems of content words (Lodhi et al., 2002), while in the case of authorship identification the same learning algorithm enhances the features representing function words (Popescu and Dinu, 2007). 3.2 Local Rank Distance A recently introduced distance measure, termed Local Rank Distance (Ionescu, 2013), comes from the idea of better adapting rank distance (Dinu, 2003) to string data, in order to capture a better similarity between strings, such as DNA sequences or text. Local Rank Distance (LRD) has already shown promising results in computational biology (Ionescu, 2013) and native language identification (Popescu and Ionescu, 2013). In order to describe LRD, the following notations are defined. Given a string x over an alphabet E, and a character a ∈ E, the length of x is denoted by |x|. Strings are considered to be indexed starting from position 1, that is x = x[1]x[2] · · · x[|x|]. Moreover, x[i : j] denotes its substring x[i]x[i + 1] · · · x[j − 1]. Lo</context>
</contexts>
<marker>Dinu, 2003</marker>
<rawString>Liviu P. Dinu. 2003. On the classification and aggregation of hierarchies with different constitutive elements. Fundamenta Informaticae, 55(1):39–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominique Estival</author>
<author>Tanja Gaustad</author>
<author>Son-Bao Pham</author>
<author>Will Radford</author>
<author>Ben Hutchinson</author>
</authors>
<title>Author profiling for English emails.</title>
<date>2007</date>
<booktitle>Proceedings of PACLING,</booktitle>
<pages>263--272</pages>
<contexts>
<context position="4848" citStr="Estival et al., 2007" startWordPosition="739" endWordPosition="742"> work is presented in Section 2. Section 3 presents several similarity measures for strings, including string kernels and Local Rank Distance. The learning methods used in the experiments are described in Section 4. Section 5 presents details about the experiments. Finally, the conclusions are drawn in Section 6. 2 Related Work 2.1 Native Language Identification The goal of automatic native language identification (NLI) is to determine the native language of a language learner, based on a piece of writing in a foreign language. This can provide useful information in forensic linguistic tasks (Estival et al., 2007) or could be used in an educational setting to provide contrastive feedback to language learners. Most research has focused on identifying the native language of English language learners, though there have been some efforts recently to identify the native language of writing in other languages (Malmasi and Dras, 2014). In general most approaches to NLI have used multi-way classification with SVMs or similar models along with a range of linguistic features. The seminal paper by Koppel et al. (2005) introduced some of the best-performing features: character, word and part-of-speech n-grams alon</context>
</contexts>
<marker>Estival, Gaustad, Pham, Radford, Hutchinson, 2007</marker>
<rawString>Dominique Estival, Tanja Gaustad, Son-Bao Pham, Will Radford, and Ben Hutchinson. 2007. Author profiling for English emails. Proceedings of PACLING, pages 263–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylviane Granger</author>
<author>Estelle Dagneaux</author>
<author>Fanny Meunier</author>
</authors>
<date>2009</date>
<booktitle>The International Corpus of Learner English: Handbook and CD-ROM, version 2. Presses Universitaires de Louvain,</booktitle>
<location>Louvain-laNeuve, Belgium.</location>
<contexts>
<context position="22638" citStr="Granger et al., 2009" startWordPosition="3867" endWordPosition="3870">classifier is able to improve accuracy by avoiding the masking problem (Hastie and Tibshirani, 2003). In the case of multi-class native language identification, the masking problem may appear when non-native English speakers have acquired, as the second language, a different language to English. For example, an essay written in English produced by a French native speaker that is also proficient in German, could be identified as either French or German. 5 Experiments 5.1 Data Sets Description In this paper, experiments are carried out on three datasets: a modified version of the ICLEv2 corpus (Granger et al., 2009), the ETS Corpus of Non-Native Written English, or TOEFL11 (Blanchard et al., 2013), and the TOEFL11-Big corpus as used by Tetreault et al. (2012). A summary of the corpora is given in Table 1. Corpus Languages Documents ICLE 7 770 TOEFL11 11 12,100 TOEFL11-Big 11 87,502 Table 1: Summary of corpora used in the experiments. The ICLEv2 is a corpus of essays written by highly-proficient non-native college-level students of English. For many years this was the standard corpus used in the task of native language identification. However, the corpus was originally collected for the purpose of corpus </context>
</contexts>
<marker>Granger, Dagneaux, Meunier, 2009</marker>
<rawString>Sylviane Granger, Estelle Dagneaux, and Fanny Meunier. 2009. The International Corpus of Learner English: Handbook and CD-ROM, version 2. Presses Universitaires de Louvain, Louvain-laNeuve, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Grozea</author>
<author>Christian Gehl</author>
<author>Marius Popescu</author>
</authors>
<title>ENCOPLOT: Pairwise Sequence Matching in Linear Time Applied to Plagiarism Detection.</title>
<date>2009</date>
<booktitle>In 3rd PAN Workshop. Uncovering Plagiarism, Authorship, and Social Software Misuse,</booktitle>
<pages>10</pages>
<contexts>
<context position="1915" citStr="Grozea et al., 2009" startWordPosition="280" endWordPosition="283">utral. In the cross-corpus experiment, the proposed approach shows that it can also be topic independent, improving the state of the art system by 32.3%. 1 Introduction Using words as basic units is natural in textual analysis tasks such as text categorization, authorship identification or plagiarism detection. Perhaps surprisingly, recent results indicate that methods handling the text at the character level can also be very effective (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some variations and improvements. A major improvement is that several string kernels are combined via multiple ke</context>
<context position="6606" citStr="Grozea et al., 2009" startWordPosition="1028" endWordPosition="1031">riety of research fields. The submitted systems utilized a wide range of machine learning approaches, combined with several innovative feature contributions. The best performing system achieved an overall accuracy of 83.6% on the 11-way classification of the test set, although there was no significant difference between the top teams. 2.2 Methods that Work at the Character Level In recent years, methods of handling text at the character level have demonstrated impressive performance levels in various text analysis tasks (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). Lodhi et al. (2002) used string kernels for document categorization with very good results. String kernels were also successfully used in authorship identification (Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Popescu and Grozea, 2012). For example, the system described in (Popescu and Grozea, 2012) ranked first in most problems and overall in the PAN 2012 Traditional Authorship Attribution tasks. Using string kernels makes the corresponding learning method completely language independent, because the texts will be treated as sequences of sym</context>
</contexts>
<marker>Grozea, Gehl, Popescu, 2009</marker>
<rawString>Cristian Grozea, Christian Gehl, and Marius Popescu. 2009. ENCOPLOT: Pairwise Sequence Matching in Linear Time Applied to Plagiarism Detection. In 3rd PAN Workshop. Uncovering Plagiarism, Authorship, and Social Software Misuse, page 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Hastie</author>
<author>Robert Tibshirani</author>
</authors>
<title>The Elements of Statistical Learning.</title>
<date>2003</date>
<publisher>Springer,</publisher>
<note>corrected edition,</note>
<contexts>
<context position="3324" citStr="Hastie and Tibshirani, 2003" startWordPosition="502" endWordPosition="505">rman, 2010), it has never been used before in text mining. In this work, the intersection kernel is used for the first time in a text categorization task, alone and in combination with other kernels. The intersection kernel lies somewhere in the middle between the kernel that takes into account only the presence of n-grams and the kernel based on the frequency of n-grams (p-spectrum string kernel). Two kernel classifiers are proposed for the learning task, namely Kernel Ridge Regression (KRR) and Kernel Discriminant Analysis (KDA). The KDA classifier is able to avoid the classmasking problem (Hastie and Tibshirani, 2003), which may often arise in the context of native language identification. Several experiments are conducted to evaluate the performance of the approach proposed in this work. While multiple kernel learning seems to produce a more robust system, the two kernel classifiers obtained mixed results in the experiments. Overall, the empirical results indicate that the approach proposed in this paper achieves state of the art performance in native language identification, while being both lan1363 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1363</context>
<context position="22117" citStr="Hastie and Tibshirani, 2003" startWordPosition="3781" endWordPosition="3785">SVM and KRR produce binary classifiers, but native language identification is usually a multiclass classification problem. There are many approaches for combining binary classifiers to solve multi-class problems. Typically, the multi-class problem is broken down into multiple binary classification problems using common decomposing schemes such as: one-versus-all and one-versusone. There are also kernel methods that take the multi-class nature of the problem directly into account, e.g. Kernel Discriminant Analysis. The KDA classifier is able to improve accuracy by avoiding the masking problem (Hastie and Tibshirani, 2003). In the case of multi-class native language identification, the masking problem may appear when non-native English speakers have acquired, as the second language, a different language to English. For example, an essay written in English produced by a French native speaker that is also proficient in German, could be identified as either French or German. 5 Experiments 5.1 Data Sets Description In this paper, experiments are carried out on three datasets: a modified version of the ICLEv2 corpus (Granger et al., 2009), the ETS Corpus of Non-Native Written English, or TOEFL11 (Blanchard et al., 2</context>
</contexts>
<marker>Hastie, Tibshirani, 2003</marker>
<rawString>Trevor Hastie and Robert Tibshirani. 2003. The Elements of Statistical Learning. Springer, corrected edition, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Tudor Ionescu</author>
</authors>
<title>Local Rank Distance.</title>
<date>2013</date>
<booktitle>Proceedings of SYNASC,</booktitle>
<pages>221--228</pages>
<contexts>
<context position="2387" citStr="Ionescu (2013)" startWordPosition="358" endWordPosition="359">enter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some variations and improvements. A major improvement is that several string kernels are combined via multiple kernel learning (ShaweTaylor and Cristianini, 2004). Despite the fact that the (histogram) intersection kernel is very popular in computer vision (Maji et al., 2008; Vedaldi and Zisserman, 2010), it has never been used before in text mining. In this work, the intersection kernel is used for the first time in a text categorization task, alone and in combination with other kernels. The intersection kernel lies somewhere in the middle between the kernel that takes into acc</context>
<context position="9292" citStr="Ionescu, 2013" startWordPosition="1467" endWordPosition="1468">by some of the systems developed for native language identification. 1364 In work where feature ablation results have been reported, the performance with only character ngram features was modest compared to other types of features (Tetreault et al., 2012). Initially, most work limited the character features to unigrams, bigrams and trigrams, perhaps because longer ngrams were considered too expensive to compute or unlikely to improve performance. However, some of the top systems in the 2013 NLI Shared Task were based on longer character n-grams, up to 9-grams (Jarvis et al., 2013; Popescu and Ionescu, 2013). The results presented in this work are obtained using a range of 5–8 n-grams. Combining all 5–8 n-grams would generate millions of features, which are indeed expensive to compute and represent. The key to avoiding the computation of such a large number of features lies in using the dual representation provided by the string kernel. String kernel similarity matrices can be computed much faster and are extremely useful when the number of samples is much lower than the number of features. 3 Similarity Measures for Strings 3.1 String Kernels The kernel function gives kernel methods the power to </context>
<context position="13950" citStr="Ionescu, 2013" startWordPosition="2249" endWordPosition="2250">e texts in a high dimensional feature space. Then, a kernel-based learning algorithm implicitly assigns a weight to each feature, thus selecting the features that are important for the discrimination task. For example, in the case of text categorization the learning algorithm enhances the features representing stems of content words (Lodhi et al., 2002), while in the case of authorship identification the same learning algorithm enhances the features representing function words (Popescu and Dinu, 2007). 3.2 Local Rank Distance A recently introduced distance measure, termed Local Rank Distance (Ionescu, 2013), comes from the idea of better adapting rank distance (Dinu, 2003) to string data, in order to capture a better similarity between strings, such as DNA sequences or text. Local Rank Distance (LRD) has already shown promising results in computational biology (Ionescu, 2013) and native language identification (Popescu and Ionescu, 2013). In order to describe LRD, the following notations are defined. Given a string x over an alphabet E, and a character a ∈ E, the length of x is denoted by |x|. Strings are considered to be indexed starting from position 1, that is x = x[1]x[2] · · · x[|x|]. Moreo</context>
<context position="26958" citStr="Ionescu, 2013" startWordPosition="4566" endWordPosition="4567"> are selected for the remaining experiments. Another set of preliminary experiments were performed to determine the range of n-grams that gives the most accurate results on a 10-fold crossvalidation procedure carried out on the TOEFL11 training set. All the n-grams in the range 2-10 were evaluated. Furthermore, experiments with different blended kernels were conducted to see whether combining n-grams of different lengths could improve the accuracy. The best results were obtained when all the n-grams with the length in the range 5-8 were used. Other authors (Bykh and Meurers, 2012; Popescu and Ionescu, 2013) also report better results by using n-grams with the length in a range, rather than using n-grams of fixed length. Consequently, the results reported in this work are based on blended string kernels based on 5-8 n-grams. Some preliminary experiments were also performed to establish the type of kernel to be used, namely the blended p-spectrum kernel ( ˆk5−8), the blended p-grams presence bits kernel ( ˆk0/1 5−8), the ˆk∩5−8), or the kernel based on LRD (ˆkLRD 5−8 .). These different kernel representations are obtained from the same data. The idea of combining all these kernels is natural when </context>
<context position="30304" citStr="Ionescu, 2013" startWordPosition="5126" endWordPosition="5127"> are summarized in Table 2. The results presented in Table 2 show that string kernels can reach state of the art accuracy levels for this task. Overall, it seems that KDA is able to obtain better results than KRR. The intersection kernel alone is able to obtain slightly better results than the presence bits kernel. The kernel based on LRD gives significantly lower accuracy rates, but it is able to improve the performance when it is blended p-grams intersection kernel ( 1369 Method Development 10-fold CV Test Ensemble model (Tetreault et al., 2012) - 80.9% - KRR and string kernels (Popescu and Ionescu, 2013) - 82.6% 82.7% SVM and word features (Jarvis et al., 2013) - 84.5% 83.6% KRR and ˆk0/1 85.4% 82.5% 82.0% 5−8 84.9% 82.2% 82.6% KRR and ˆk∩ 78.7% 77.1% 77.5% 5−8 85.7% 82.6% 82.7% KRR and ˆkLRD 84.9% 82.2% 82.0% 5−8 85.5% 82.6% 82.5% KRR and ˆk0/1 85.5% 82.6% 82.5% 5−8 + ˆkLRD 5−8 KRR and k5 8 +ˆkSRa KRR and ˆk, a + ˆk∩ 5−8 KRR and a1ˆk0/1 5−8 + a2ˆk∩ 5−8 KDA and ˆk0/1 86.2% 83.6% 83.6% 5−8 85.2% 83.5% 84.6% KDA and ˆk∩ 79.7% 78.5% 79.2% 5−8 87.1% 84.0% 84.7% KDA and ˆkLRD 85.8% 83.4% 83.9% 5−8 86.4% 84.1% 85.0% KDA and ˆk0/1 86.5% 84.1% 85.3% 5−8 + ˆkLRD 87.0% 84.1% 84.8% 5−8 KDA and k5 8 +ˆkS</context>
<context position="32091" citStr="Ionescu (2013)" startWordPosition="5464" endWordPosition="5465">nel combination is that of the presence bits kernel and the intersection kernel. Results are quite similar when they are combined either by summing them up or by kernel alignment. The best performance on the test set (85.3%) is obtained by the system that combines these two kernels via kernel alignment and learns using KDA. This system is 1.7% better than the state of the art system of Jarvis et al. (2013) based on SVM and word features, this being the top scoring system in the NLI 2013 Shared Task. It is also 2.6% better than the state of the art system based on string kernels of Popescu and Ionescu (2013). On the cross validation procedure, there are three systems that reach the accuracy rate of 84.1%. All of them are based on KDA and various kernel combinations. The greatest accuracy rate of 84.1% reported for the cross validation procedure is 3.2% above the state of the art system of Tetreault et al. (2012) and 0.4% below the top scoring system of Jarvis et al. (2013). The empirical results obtained in this experiment demonstrate that the approach proposed in this paper can reach state of the art accuracy levels. It is worth mentioning that a significance test performed by the organizers of </context>
</contexts>
<marker>Ionescu, 2013</marker>
<rawString>Radu Tudor Ionescu. 2013. Local Rank Distance. Proceedings of SYNASC, pages 221–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Jarvis</author>
<author>Yves Bestgen</author>
<author>Steve Pepper</author>
</authors>
<title>Maximizing classification accuracy in native language identification.</title>
<date>2013</date>
<booktitle>Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>111--118</pages>
<contexts>
<context position="8444" citStr="Jarvis et al. (2013)" startWordPosition="1326" endWordPosition="1329"> these features. It is important to note that this approach is also linguistic theory neutral, since it disregards any features of natural language such as words, phrases, or meaning. On the other hand, a method that considers words as features cannot be completely language independent, since the definition of a word is necessarily languagespecific. For example, a method that uses only function words as features is not completely language independent because it needs a list of function words which is specific to a language. When features such as part-of-speech tags are used, as in the work of Jarvis et al. (2013), the method relies on a part-of-speech tagger which might not be available (yet) for some languages. Furthermore, a way to segment a text into words is not an easy task for some languages, such as Chinese. Character n-grams are used by some of the systems developed for native language identification. 1364 In work where feature ablation results have been reported, the performance with only character ngram features was modest compared to other types of features (Tetreault et al., 2012). Initially, most work limited the character features to unigrams, bigrams and trigrams, perhaps because longer</context>
<context position="30362" citStr="Jarvis et al., 2013" startWordPosition="5135" endWordPosition="5138"> Table 2 show that string kernels can reach state of the art accuracy levels for this task. Overall, it seems that KDA is able to obtain better results than KRR. The intersection kernel alone is able to obtain slightly better results than the presence bits kernel. The kernel based on LRD gives significantly lower accuracy rates, but it is able to improve the performance when it is blended p-grams intersection kernel ( 1369 Method Development 10-fold CV Test Ensemble model (Tetreault et al., 2012) - 80.9% - KRR and string kernels (Popescu and Ionescu, 2013) - 82.6% 82.7% SVM and word features (Jarvis et al., 2013) - 84.5% 83.6% KRR and ˆk0/1 85.4% 82.5% 82.0% 5−8 84.9% 82.2% 82.6% KRR and ˆk∩ 78.7% 77.1% 77.5% 5−8 85.7% 82.6% 82.7% KRR and ˆkLRD 84.9% 82.2% 82.0% 5−8 85.5% 82.6% 82.5% KRR and ˆk0/1 85.5% 82.6% 82.5% 5−8 + ˆkLRD 5−8 KRR and k5 8 +ˆkSRa KRR and ˆk, a + ˆk∩ 5−8 KRR and a1ˆk0/1 5−8 + a2ˆk∩ 5−8 KDA and ˆk0/1 86.2% 83.6% 83.6% 5−8 85.2% 83.5% 84.6% KDA and ˆk∩ 79.7% 78.5% 79.2% 5−8 87.1% 84.0% 84.7% KDA and ˆkLRD 85.8% 83.4% 83.9% 5−8 86.4% 84.1% 85.0% KDA and ˆk0/1 86.5% 84.1% 85.3% 5−8 + ˆkLRD 87.0% 84.1% 84.8% 5−8 KDA and k5 8 +ˆkSRa KDA and ˆk, a + ˆk∩ 5−8 KDA and a1ˆk0/1 5−8 + a2ˆk∩ 5−8</context>
<context position="31886" citStr="Jarvis et al. (2013)" startWordPosition="5422" endWordPosition="5425"> sums of kernels are computed by kernel alignment. combined with the blended p-grams presence bits kernel. In fact, most of the kernel combinations give better results than each of their components. The best kernel combination is that of the presence bits kernel and the intersection kernel. Results are quite similar when they are combined either by summing them up or by kernel alignment. The best performance on the test set (85.3%) is obtained by the system that combines these two kernels via kernel alignment and learns using KDA. This system is 1.7% better than the state of the art system of Jarvis et al. (2013) based on SVM and word features, this being the top scoring system in the NLI 2013 Shared Task. It is also 2.6% better than the state of the art system based on string kernels of Popescu and Ionescu (2013). On the cross validation procedure, there are three systems that reach the accuracy rate of 84.1%. All of them are based on KDA and various kernel combinations. The greatest accuracy rate of 84.1% reported for the cross validation procedure is 3.2% above the state of the art system of Tetreault et al. (2012) and 0.4% below the top scoring system of Jarvis et al. (2013). The empirical results</context>
</contexts>
<marker>Jarvis, Bestgen, Pepper, 2013</marker>
<rawString>Scott Jarvis, Yves Bestgen, and Steve Pepper. 2013. Maximizing classification accuracy in native language identification. Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 111–118, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel</author>
<author>Jonathan Schler</author>
<author>Kfir Zigdon</author>
</authors>
<title>Automatically Determining an Anonymous Author’s Native Language.</title>
<date>2005</date>
<booktitle>Proceedings of ISI,</booktitle>
<pages>209--217</pages>
<contexts>
<context position="5351" citStr="Koppel et al. (2005)" startWordPosition="821" endWordPosition="824">riting in a foreign language. This can provide useful information in forensic linguistic tasks (Estival et al., 2007) or could be used in an educational setting to provide contrastive feedback to language learners. Most research has focused on identifying the native language of English language learners, though there have been some efforts recently to identify the native language of writing in other languages (Malmasi and Dras, 2014). In general most approaches to NLI have used multi-way classification with SVMs or similar models along with a range of linguistic features. The seminal paper by Koppel et al. (2005) introduced some of the best-performing features: character, word and part-of-speech n-grams along with features inspired by the work in the area of secondlanguage acquisition such as spelling and grammatical errors. In 2013, Tetreault et al. (2013) organized the first shared task in the field. This allowed researchers to compare approaches for the first time on a specifically designed NLI corpus that was much larger than previously available data sets. In the shared task, 29 teams submitted results for the test set, and one of the most successful aspects of the competition was that it drew su</context>
</contexts>
<marker>Koppel, Schler, Zigdon, 2005</marker>
<rawString>Moshe Koppel, Jonathan Schler, and Kfir Zigdon. 2005. Automatically Determining an Anonymous Author’s Native Language. Proceedings of ISI, pages 209–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huma Lodhi</author>
<author>Craig Saunders</author>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
<author>Christopher J C H Watkins</author>
</authors>
<title>Text classification using string kernels.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--419</pages>
<contexts>
<context position="1755" citStr="Lodhi et al., 2002" startWordPosition="256" endWordPosition="259">g system of the 2013 NLI Shared Task. Furthermore, the proposed approach has an important advantage in that it is language independent and linguistic theory neutral. In the cross-corpus experiment, the proposed approach shows that it can also be topic independent, improving the state of the art system by 32.3%. 1 Introduction Using words as basic units is natural in textual analysis tasks such as text categorization, authorship identification or plagiarism detection. Perhaps surprisingly, recent results indicate that methods handling the text at the character level can also be very effective (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the syst</context>
<context position="6532" citStr="Lodhi et al., 2002" startWordPosition="1016" endWordPosition="1019">f the competition was that it drew submissions from teams working in a variety of research fields. The submitted systems utilized a wide range of machine learning approaches, combined with several innovative feature contributions. The best performing system achieved an overall accuracy of 83.6% on the 11-way classification of the test set, although there was no significant difference between the top teams. 2.2 Methods that Work at the Character Level In recent years, methods of handling text at the character level have demonstrated impressive performance levels in various text analysis tasks (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). Lodhi et al. (2002) used string kernels for document categorization with very good results. String kernels were also successfully used in authorship identification (Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Popescu and Grozea, 2012). For example, the system described in (Popescu and Grozea, 2012) ranked first in most problems and overall in the PAN 2012 Traditional Authorship Attribution tasks. Using string kernels makes the corresponding learning method completely l</context>
<context position="13691" citStr="Lodhi et al., 2002" startWordPosition="2209" endWordPosition="2212">milarity between strings. 1365 ˆk∩p (s, t) = �k∩ p (s, s) · k∩p (t, t) . Taking into account p-grams of different length and summing up the corresponding kernels, new kernels, termed blended spectrum kernels, can be obtained. The string kernel implicitly embeds the texts in a high dimensional feature space. Then, a kernel-based learning algorithm implicitly assigns a weight to each feature, thus selecting the features that are important for the discrimination task. For example, in the case of text categorization the learning algorithm enhances the features representing stems of content words (Lodhi et al., 2002), while in the case of authorship identification the same learning algorithm enhances the features representing function words (Popescu and Dinu, 2007). 3.2 Local Rank Distance A recently introduced distance measure, termed Local Rank Distance (Ionescu, 2013), comes from the idea of better adapting rank distance (Dinu, 2003) to string data, in order to capture a better similarity between strings, such as DNA sequences or text. Local Rank Distance (LRD) has already shown promising results in computational biology (Ionescu, 2013) and native language identification (Popescu and Ionescu, 2013). In</context>
</contexts>
<marker>Lodhi, Saunders, Shawe-Taylor, Cristianini, Watkins, 2002</marker>
<rawString>Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Christopher J. C. H. Watkins. 2002. Text classification using string kernels. Journal of Machine Learning Research, 2:419–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Subhransu Maji</author>
<author>Alexander C Berg</author>
<author>Jitendra Malik</author>
</authors>
<title>Classification using intersection kernel support vector machines is efficient.</title>
<date>2008</date>
<booktitle>Proceedings of CVPR.</booktitle>
<contexts>
<context position="2677" citStr="Maji et al., 2008" startWordPosition="399" endWordPosition="402">ks at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some variations and improvements. A major improvement is that several string kernels are combined via multiple kernel learning (ShaweTaylor and Cristianini, 2004). Despite the fact that the (histogram) intersection kernel is very popular in computer vision (Maji et al., 2008; Vedaldi and Zisserman, 2010), it has never been used before in text mining. In this work, the intersection kernel is used for the first time in a text categorization task, alone and in combination with other kernels. The intersection kernel lies somewhere in the middle between the kernel that takes into account only the presence of n-grams and the kernel based on the frequency of n-grams (p-spectrum string kernel). Two kernel classifiers are proposed for the learning task, namely Kernel Ridge Regression (KRR) and Kernel Discriminant Analysis (KDA). The KDA classifier is able to avoid the cla</context>
<context position="11682" citStr="Maji et al., 2008" startWordPosition="1867" endWordPosition="1870">requencies of all its substrings of length p (p-grams) with each string. A variant of this kernel can be obtained if the embedding feature map is modified to associate a vector of dimension |E|p containing the presence bits (instead of frequencies) of all its substrings of length p with each string. Thus, the character pgrams presence bits kernel is obtained: �k0/1 p(s, t) = inv(s) · inv(t), vEEP where inv(s) is 1 if string v occurs as a substring in s, and 0 otherwise. In computer vision, the (histogram) intersection kernel has successfully been used for object class recognition from images (Maji et al., 2008; Vedaldi and Zisserman, 2010). In this paper, the intersection kernel is used for the first time as a kernel for strings. The intersection string kernel is defined as follows: k∩p (s, t) = � min{numv(s), numv(t)}, vEEP where numv(s) is the number of occurrences of string v as a substring in s. For the p-spectrum kernel, the frequency of a pgram has a very significant contribution to the kernel, since it considers the product of such frequencies. On the other hand, the frequency of a p-gram is completely disregarded in the p-grams presence bits kernel. The intersection kernel lies somewhere in</context>
</contexts>
<marker>Maji, Berg, Malik, 2008</marker>
<rawString>Subhransu Maji, Alexander C. Berg, and Jitendra Malik. 2008. Classification using intersection kernel support vector machines is efficient. Proceedings of CVPR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shervin Malmasi</author>
<author>Mark Dras</author>
</authors>
<title>Chinese Native Language Identification.</title>
<date>2014</date>
<booktitle>Proceedings of EACL,</booktitle>
<pages>2--95</pages>
<contexts>
<context position="5168" citStr="Malmasi and Dras, 2014" startWordPosition="791" endWordPosition="794">elated Work 2.1 Native Language Identification The goal of automatic native language identification (NLI) is to determine the native language of a language learner, based on a piece of writing in a foreign language. This can provide useful information in forensic linguistic tasks (Estival et al., 2007) or could be used in an educational setting to provide contrastive feedback to language learners. Most research has focused on identifying the native language of English language learners, though there have been some efforts recently to identify the native language of writing in other languages (Malmasi and Dras, 2014). In general most approaches to NLI have used multi-way classification with SVMs or similar models along with a range of linguistic features. The seminal paper by Koppel et al. (2005) introduced some of the best-performing features: character, word and part-of-speech n-grams along with features inspired by the work in the area of secondlanguage acquisition such as spelling and grammatical errors. In 2013, Tetreault et al. (2013) organized the first shared task in the field. This allowed researchers to compare approaches for the first time on a specifically designed NLI corpus that was much lar</context>
</contexts>
<marker>Malmasi, Dras, 2014</marker>
<rawString>Shervin Malmasi and Mark Dras. 2014. Chinese Native Language Identification. Proceedings of EACL, 2:95–99, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Popescu</author>
<author>Liviu P Dinu</author>
</authors>
<title>Kernel methods and string kernels for authorship identification: The federalist papers case.</title>
<date>2007</date>
<booktitle>Proceedings of RANLP,</booktitle>
<contexts>
<context position="1808" citStr="Popescu and Dinu, 2007" startWordPosition="265" endWordPosition="268">, the proposed approach has an important advantage in that it is language independent and linguistic theory neutral. In the cross-corpus experiment, the proposed approach shows that it can also be topic independent, improving the state of the art system by 32.3%. 1 Introduction Using words as basic units is natural in textual analysis tasks such as text categorization, authorship identification or plagiarism detection. Perhaps surprisingly, recent results indicate that methods handling the text at the character level can also be very effective (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some v</context>
<context position="6585" citStr="Popescu and Dinu, 2007" startWordPosition="1024" endWordPosition="1027">om teams working in a variety of research fields. The submitted systems utilized a wide range of machine learning approaches, combined with several innovative feature contributions. The best performing system achieved an overall accuracy of 83.6% on the 11-way classification of the test set, although there was no significant difference between the top teams. 2.2 Methods that Work at the Character Level In recent years, methods of handling text at the character level have demonstrated impressive performance levels in various text analysis tasks (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). Lodhi et al. (2002) used string kernels for document categorization with very good results. String kernels were also successfully used in authorship identification (Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Popescu and Grozea, 2012). For example, the system described in (Popescu and Grozea, 2012) ranked first in most problems and overall in the PAN 2012 Traditional Authorship Attribution tasks. Using string kernels makes the corresponding learning method completely language independent, because the texts will be treate</context>
<context position="13842" citStr="Popescu and Dinu, 2007" startWordPosition="2232" endWordPosition="2235">onding kernels, new kernels, termed blended spectrum kernels, can be obtained. The string kernel implicitly embeds the texts in a high dimensional feature space. Then, a kernel-based learning algorithm implicitly assigns a weight to each feature, thus selecting the features that are important for the discrimination task. For example, in the case of text categorization the learning algorithm enhances the features representing stems of content words (Lodhi et al., 2002), while in the case of authorship identification the same learning algorithm enhances the features representing function words (Popescu and Dinu, 2007). 3.2 Local Rank Distance A recently introduced distance measure, termed Local Rank Distance (Ionescu, 2013), comes from the idea of better adapting rank distance (Dinu, 2003) to string data, in order to capture a better similarity between strings, such as DNA sequences or text. Local Rank Distance (LRD) has already shown promising results in computational biology (Ionescu, 2013) and native language identification (Popescu and Ionescu, 2013). In order to describe LRD, the following notations are defined. Given a string x over an alphabet E, and a character a ∈ E, the length of x is denoted by </context>
</contexts>
<marker>Popescu, Dinu, 2007</marker>
<rawString>Marius Popescu and Liviu P. Dinu. 2007. Kernel methods and string kernels for authorship identification: The federalist papers case. Proceedings of RANLP, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Popescu</author>
<author>Cristian Grozea</author>
</authors>
<title>Kernel methods and string kernels for authorship analysis.</title>
<date>2012</date>
<journal>CLEF (Online Working Notes/Labs/Workshop),</journal>
<contexts>
<context position="1957" citStr="Popescu and Grozea, 2012" startWordPosition="286" endWordPosition="289">t, the proposed approach shows that it can also be topic independent, improving the state of the art system by 32.3%. 1 Introduction Using words as basic units is natural in textual analysis tasks such as text categorization, authorship identification or plagiarism detection. Perhaps surprisingly, recent results indicate that methods handling the text at the character level can also be very effective (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some variations and improvements. A major improvement is that several string kernels are combined via multiple kernel learning (ShaweTaylor and Cristianini</context>
<context position="6648" citStr="Popescu and Grozea, 2012" startWordPosition="1034" endWordPosition="1037">ted systems utilized a wide range of machine learning approaches, combined with several innovative feature contributions. The best performing system achieved an overall accuracy of 83.6% on the 11-way classification of the test set, although there was no significant difference between the top teams. 2.2 Methods that Work at the Character Level In recent years, methods of handling text at the character level have demonstrated impressive performance levels in various text analysis tasks (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). Lodhi et al. (2002) used string kernels for document categorization with very good results. String kernels were also successfully used in authorship identification (Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Popescu and Grozea, 2012). For example, the system described in (Popescu and Grozea, 2012) ranked first in most problems and overall in the PAN 2012 Traditional Authorship Attribution tasks. Using string kernels makes the corresponding learning method completely language independent, because the texts will be treated as sequences of symbols (strings). Methods working at the wor</context>
</contexts>
<marker>Popescu, Grozea, 2012</marker>
<rawString>Marius Popescu and Cristian Grozea. 2012. Kernel methods and string kernels for authorship analysis. CLEF (Online Working Notes/Labs/Workshop), September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Popescu</author>
<author>Radu Tudor Ionescu</author>
</authors>
<title>The Story of the Characters, the DNA and the Native Language.</title>
<date>2013</date>
<booktitle>Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>270--278</pages>
<contexts>
<context position="2387" citStr="Popescu and Ionescu (2013)" startWordPosition="356" endWordPosition="359">erson and Guenter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some variations and improvements. A major improvement is that several string kernels are combined via multiple kernel learning (ShaweTaylor and Cristianini, 2004). Despite the fact that the (histogram) intersection kernel is very popular in computer vision (Maji et al., 2008; Vedaldi and Zisserman, 2010), it has never been used before in text mining. In this work, the intersection kernel is used for the first time in a text categorization task, alone and in combination with other kernels. The intersection kernel lies somewhere in the middle between the kernel that takes into acc</context>
<context position="9292" citStr="Popescu and Ionescu, 2013" startWordPosition="1465" endWordPosition="1468">ms are used by some of the systems developed for native language identification. 1364 In work where feature ablation results have been reported, the performance with only character ngram features was modest compared to other types of features (Tetreault et al., 2012). Initially, most work limited the character features to unigrams, bigrams and trigrams, perhaps because longer ngrams were considered too expensive to compute or unlikely to improve performance. However, some of the top systems in the 2013 NLI Shared Task were based on longer character n-grams, up to 9-grams (Jarvis et al., 2013; Popescu and Ionescu, 2013). The results presented in this work are obtained using a range of 5–8 n-grams. Combining all 5–8 n-grams would generate millions of features, which are indeed expensive to compute and represent. The key to avoiding the computation of such a large number of features lies in using the dual representation provided by the string kernel. String kernel similarity matrices can be computed much faster and are extremely useful when the number of samples is much lower than the number of features. 3 Similarity Measures for Strings 3.1 String Kernels The kernel function gives kernel methods the power to </context>
<context position="14287" citStr="Popescu and Ionescu, 2013" startWordPosition="2301" endWordPosition="2304">ent words (Lodhi et al., 2002), while in the case of authorship identification the same learning algorithm enhances the features representing function words (Popescu and Dinu, 2007). 3.2 Local Rank Distance A recently introduced distance measure, termed Local Rank Distance (Ionescu, 2013), comes from the idea of better adapting rank distance (Dinu, 2003) to string data, in order to capture a better similarity between strings, such as DNA sequences or text. Local Rank Distance (LRD) has already shown promising results in computational biology (Ionescu, 2013) and native language identification (Popescu and Ionescu, 2013). In order to describe LRD, the following notations are defined. Given a string x over an alphabet E, and a character a ∈ E, the length of x is denoted by |x|. Strings are considered to be indexed starting from position 1, that is x = x[1]x[2] · · · x[|x|]. Moreover, x[i : j] denotes its substring x[i]x[i + 1] · · · x[j − 1]. Local Rank Distance is inspired by rank distance (Dinu, 2003), the main differences being that it uses p-grams instead of single characters, and that it matches each p-gram in the first string with the nearest equal p-gram in the second string. Given a fixed integer p ≥ 1</context>
<context position="26958" citStr="Popescu and Ionescu, 2013" startWordPosition="4564" endWordPosition="4567">refore, they are selected for the remaining experiments. Another set of preliminary experiments were performed to determine the range of n-grams that gives the most accurate results on a 10-fold crossvalidation procedure carried out on the TOEFL11 training set. All the n-grams in the range 2-10 were evaluated. Furthermore, experiments with different blended kernels were conducted to see whether combining n-grams of different lengths could improve the accuracy. The best results were obtained when all the n-grams with the length in the range 5-8 were used. Other authors (Bykh and Meurers, 2012; Popescu and Ionescu, 2013) also report better results by using n-grams with the length in a range, rather than using n-grams of fixed length. Consequently, the results reported in this work are based on blended string kernels based on 5-8 n-grams. Some preliminary experiments were also performed to establish the type of kernel to be used, namely the blended p-spectrum kernel ( ˆk5−8), the blended p-grams presence bits kernel ( ˆk0/1 5−8), the ˆk∩5−8), or the kernel based on LRD (ˆkLRD 5−8 .). These different kernel representations are obtained from the same data. The idea of combining all these kernels is natural when </context>
<context position="30304" citStr="Popescu and Ionescu, 2013" startWordPosition="5124" endWordPosition="5127"> The results are summarized in Table 2. The results presented in Table 2 show that string kernels can reach state of the art accuracy levels for this task. Overall, it seems that KDA is able to obtain better results than KRR. The intersection kernel alone is able to obtain slightly better results than the presence bits kernel. The kernel based on LRD gives significantly lower accuracy rates, but it is able to improve the performance when it is blended p-grams intersection kernel ( 1369 Method Development 10-fold CV Test Ensemble model (Tetreault et al., 2012) - 80.9% - KRR and string kernels (Popescu and Ionescu, 2013) - 82.6% 82.7% SVM and word features (Jarvis et al., 2013) - 84.5% 83.6% KRR and ˆk0/1 85.4% 82.5% 82.0% 5−8 84.9% 82.2% 82.6% KRR and ˆk∩ 78.7% 77.1% 77.5% 5−8 85.7% 82.6% 82.7% KRR and ˆkLRD 84.9% 82.2% 82.0% 5−8 85.5% 82.6% 82.5% KRR and ˆk0/1 85.5% 82.6% 82.5% 5−8 + ˆkLRD 5−8 KRR and k5 8 +ˆkSRa KRR and ˆk, a + ˆk∩ 5−8 KRR and a1ˆk0/1 5−8 + a2ˆk∩ 5−8 KDA and ˆk0/1 86.2% 83.6% 83.6% 5−8 85.2% 83.5% 84.6% KDA and ˆk∩ 79.7% 78.5% 79.2% 5−8 87.1% 84.0% 84.7% KDA and ˆkLRD 85.8% 83.4% 83.9% 5−8 86.4% 84.1% 85.0% KDA and ˆk0/1 86.5% 84.1% 85.3% 5−8 + ˆkLRD 87.0% 84.1% 84.8% 5−8 KDA and k5 8 +ˆkS</context>
<context position="32091" citStr="Popescu and Ionescu (2013)" startWordPosition="5462" endWordPosition="5465">The best kernel combination is that of the presence bits kernel and the intersection kernel. Results are quite similar when they are combined either by summing them up or by kernel alignment. The best performance on the test set (85.3%) is obtained by the system that combines these two kernels via kernel alignment and learns using KDA. This system is 1.7% better than the state of the art system of Jarvis et al. (2013) based on SVM and word features, this being the top scoring system in the NLI 2013 Shared Task. It is also 2.6% better than the state of the art system based on string kernels of Popescu and Ionescu (2013). On the cross validation procedure, there are three systems that reach the accuracy rate of 84.1%. All of them are based on KDA and various kernel combinations. The greatest accuracy rate of 84.1% reported for the cross validation procedure is 3.2% above the state of the art system of Tetreault et al. (2012) and 0.4% below the top scoring system of Jarvis et al. (2013). The empirical results obtained in this experiment demonstrate that the approach proposed in this paper can reach state of the art accuracy levels. It is worth mentioning that a significance test performed by the organizers of </context>
</contexts>
<marker>Popescu, Ionescu, 2013</marker>
<rawString>Marius Popescu and Radu Tudor Ionescu. 2013. The Story of the Characters, the DNA and the Native Language. Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 270–278, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Popescu</author>
</authors>
<title>Studying translationese at the character level.</title>
<date>2011</date>
<booktitle>Proceedings of RANLP,</booktitle>
<pages>634--639</pages>
<contexts>
<context position="1930" citStr="Popescu, 2011" startWordPosition="284" endWordPosition="285">orpus experiment, the proposed approach shows that it can also be topic independent, improving the state of the art system by 32.3%. 1 Introduction Using words as basic units is natural in textual analysis tasks such as text categorization, authorship identification or plagiarism detection. Perhaps surprisingly, recent results indicate that methods handling the text at the character level can also be very effective (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some variations and improvements. A major improvement is that several string kernels are combined via multiple kernel learning (</context>
<context position="6621" citStr="Popescu, 2011" startWordPosition="1032" endWordPosition="1033">lds. The submitted systems utilized a wide range of machine learning approaches, combined with several innovative feature contributions. The best performing system achieved an overall accuracy of 83.6% on the 11-way classification of the test set, although there was no significant difference between the top teams. 2.2 Methods that Work at the Character Level In recent years, methods of handling text at the character level have demonstrated impressive performance levels in various text analysis tasks (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). Lodhi et al. (2002) used string kernels for document categorization with very good results. String kernels were also successfully used in authorship identification (Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Popescu and Grozea, 2012). For example, the system described in (Popescu and Grozea, 2012) ranked first in most problems and overall in the PAN 2012 Traditional Authorship Attribution tasks. Using string kernels makes the corresponding learning method completely language independent, because the texts will be treated as sequences of symbols (strings).</context>
</contexts>
<marker>Popescu, 2011</marker>
<rawString>Marius Popescu. 2011. Studying translationese at the character level. Proceedings of RANLP, pages 634– 639, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Conrad Sanderson</author>
<author>Simon Guenter</author>
</authors>
<title>Short text authorship attribution via sequence kernels, markov chains and author unmasking: An investigation.</title>
<date>2006</date>
<booktitle>Proceedings of EMNLP,</booktitle>
<pages>482--491</pages>
<contexts>
<context position="1784" citStr="Sanderson and Guenter, 2006" startWordPosition="260" endWordPosition="264"> NLI Shared Task. Furthermore, the proposed approach has an important advantage in that it is language independent and linguistic theory neutral. In the cross-corpus experiment, the proposed approach shows that it can also be topic independent, improving the state of the art system by 32.3%. 1 Introduction Using words as basic units is natural in textual analysis tasks such as text categorization, authorship identification or plagiarism detection. Perhaps surprisingly, recent results indicate that methods handling the text at the character level can also be very effective (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; †Educational Testing Service 660 Rosedale Rd Princeton, NJ 08541, USA acahill@ets.org Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). By disregarding features of natural language such as words, phrases, or meaning, an approach that works at the character level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (20</context>
<context position="6561" citStr="Sanderson and Guenter, 2006" startWordPosition="1020" endWordPosition="1023">s that it drew submissions from teams working in a variety of research fields. The submitted systems utilized a wide range of machine learning approaches, combined with several innovative feature contributions. The best performing system achieved an overall accuracy of 83.6% on the 11-way classification of the test set, although there was no significant difference between the top teams. 2.2 Methods that Work at the Character Level In recent years, methods of handling text at the character level have demonstrated impressive performance levels in various text analysis tasks (Lodhi et al., 2002; Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Grozea et al., 2009; Popescu, 2011; Popescu and Grozea, 2012). Lodhi et al. (2002) used string kernels for document categorization with very good results. String kernels were also successfully used in authorship identification (Sanderson and Guenter, 2006; Popescu and Dinu, 2007; Popescu and Grozea, 2012). For example, the system described in (Popescu and Grozea, 2012) ranked first in most problems and overall in the PAN 2012 Traditional Authorship Attribution tasks. Using string kernels makes the corresponding learning method completely language independent, because </context>
</contexts>
<marker>Sanderson, Guenter, 2006</marker>
<rawString>Conrad Sanderson and Simon Guenter. 2006. Short text authorship attribution via sequence kernels, markov chains and author unmasking: An investigation. Proceedings of EMNLP, pages 482–491, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="10342" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="1633" endWordPosition="1637"> useful when the number of samples is much lower than the number of features. 3 Similarity Measures for Strings 3.1 String Kernels The kernel function gives kernel methods the power to naturally handle input data that is not in the form of numerical vectors, e.g. strings. The kernel function captures the intuitive notion of similarity between objects in a specific domain and can be any function defined on the respective domain that is symmetric and positive definite. For strings, many such kernel functions exist with various applications in computational biology and computational linguistics (Shawe-Taylor and Cristianini, 2004). Perhaps one of the most natural ways to measure the similarity of two strings is to count how many substrings of length p the two strings have in common. This gives rise to the p-spectrum kernel. Formally, for two strings over an alphabet E, s, t E E∗, the p-spectrum kernel is defined as: kp(s, t) = � numv(s) · numv(t), vEEP where numv(s) is the number of occurrences of string v as a substring in s.1 The feature map de1Note that the notion of substring requires contiguity. Shawe-Taylor and Cristianini (2004) discuss the ambiguity between the terms substring and subsequence across different d</context>
<context position="17900" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="3051" endWordPosition="3054">4 − 3 |= 5. By summing up the two partial sums, Local Rank Distance is obtained ALRD(x, y) = Aleft(x, y) + Aright(x, y) = 11. The maximum LRD value between two strings can be computed as the product between the maximum offset m and the number of pairs of compared p-grams. Thus, LRD can be normalized to a value in the [0, 1] interval. By normalizing, LRD becomes a dissimilarity measure. LRD can be also used as a kernel, since kernel methods are based on similarity. The classical way to transform a distance or dissimilarity measure into a similarity measure is by using the Gaussian-like kernel (Shawe-Taylor and Cristianini, 2004): ALRD(s, t) 2σ2 , where s and t are two strings and p is the p-grams length. The parameter σ is usually chosen so that values of ˆk(s, t) are well scaled. In the above equation, ALRD is already normalized to a value in the [0, 1] interval to ensure a fair comparison of strings of different length. 4 Learning Methods Kernel-based learning algorithms work by embedding the data into a Hilbert feature space, and searching for linear relations in that space. The embedding is performed implicitly, that is by specifying the inner product between each pair of points rather than by giving their coordi</context>
<context position="21260" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="3651" endWordPosition="3654"> to the other class. For the NLI experiments, two binary kernel classifiers are used, namely the SVM (Cortes and Vapnik, 1995), and the KRR. Support Vector Machines try to find the vector of weights that defines the hyperplane that maximally separates the images in the Hilbert space of the training examples ˆkLRD p (s, t) = e 1367 belonging to the two classes. Kernel Ridge Regression selects the vector of weights that simultaneously has small empirical error and small norm in the Reproducing Kernel Hilbert Space generated by the kernel function. More details about SVM and KRR can be found in (Shawe-Taylor and Cristianini, 2004). The important fact is that the above optimization problems are solved in such a way that the coordinates of the embedded points are not needed, only their pairwise inner products which in turn are given by the kernel function. SVM and KRR produce binary classifiers, but native language identification is usually a multiclass classification problem. There are many approaches for combining binary classifiers to solve multi-class problems. Typically, the multi-class problem is broken down into multiple binary classification problems using common decomposing schemes such as: one-versus-all and on</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Daniel Blanchard</author>
<author>Aoife Cahill</author>
<author>Martin Chodorow</author>
</authors>
<title>Native Tongues, Lost and Found: Resources and Empirical Evaluations in Native Language Identification.</title>
<date>2012</date>
<booktitle>Proceedings of COLING 2012,</booktitle>
<pages>2585--2602</pages>
<contexts>
<context position="8933" citStr="Tetreault et al., 2012" startWordPosition="1408" endWordPosition="1411">tion words which is specific to a language. When features such as part-of-speech tags are used, as in the work of Jarvis et al. (2013), the method relies on a part-of-speech tagger which might not be available (yet) for some languages. Furthermore, a way to segment a text into words is not an easy task for some languages, such as Chinese. Character n-grams are used by some of the systems developed for native language identification. 1364 In work where feature ablation results have been reported, the performance with only character ngram features was modest compared to other types of features (Tetreault et al., 2012). Initially, most work limited the character features to unigrams, bigrams and trigrams, perhaps because longer ngrams were considered too expensive to compute or unlikely to improve performance. However, some of the top systems in the 2013 NLI Shared Task were based on longer character n-grams, up to 9-grams (Jarvis et al., 2013; Popescu and Ionescu, 2013). The results presented in this work are obtained using a range of 5–8 n-grams. Combining all 5–8 n-grams would generate millions of features, which are indeed expensive to compute and represent. The key to avoiding the computation of such a</context>
<context position="22784" citStr="Tetreault et al. (2012)" startWordPosition="3892" endWordPosition="3895"> identification, the masking problem may appear when non-native English speakers have acquired, as the second language, a different language to English. For example, an essay written in English produced by a French native speaker that is also proficient in German, could be identified as either French or German. 5 Experiments 5.1 Data Sets Description In this paper, experiments are carried out on three datasets: a modified version of the ICLEv2 corpus (Granger et al., 2009), the ETS Corpus of Non-Native Written English, or TOEFL11 (Blanchard et al., 2013), and the TOEFL11-Big corpus as used by Tetreault et al. (2012). A summary of the corpora is given in Table 1. Corpus Languages Documents ICLE 7 770 TOEFL11 11 12,100 TOEFL11-Big 11 87,502 Table 1: Summary of corpora used in the experiments. The ICLEv2 is a corpus of essays written by highly-proficient non-native college-level students of English. For many years this was the standard corpus used in the task of native language identification. However, the corpus was originally collected for the purpose of corpus linguistic investigations, and because of this contains some idiosyncrasies that make it problematic for the task of NLI (Brooke and Hirst, 2012).</context>
<context position="24484" citStr="Tetreault et al. (2012)" startWordPosition="4165" endWordPosition="4168">ault et al., 2013). It was designed to overcome many of the shortcomings identified with using the ICLEv2 corpus for this task. The TOEFL11 corpus contains a balanced distribution of essays per prompt (topic) per native language. It also contains information about the language proficiency of each writer. The corpus contains essays written by speakers of the following 11 languages: Arabic, Chinese, French, German, Hindi, Italian, Japanese, Korean, Spanish, Telugu and Turkish. For the shared task, the 12,100 essays were split into 9,900 for training, 1,100 for development and 1,100 for testing. Tetreault et al. (2012) present a corpus, TOEFL11-Big, to investigate the performance of their NLI system on a very large data set. This data set contains the same languages as TOEFL11, but with no overlap in content. It contains a total of over 87 thousand essays written to a total of 76 different prompts. The distribution of L1 per prompt is not as even as for TOEFL11, though all topics are represented for all L1s. 5.2 Parameter Tuning and Implementation Choices In the string kernels approach proposed in this work, documents or essays from this corpus are treated as strings. Therefore, the notions of string or doc</context>
<context position="30243" citStr="Tetreault et al., 2012" startWordPosition="5113" endWordPosition="5116"> trained on both the training set and the development set. The results are summarized in Table 2. The results presented in Table 2 show that string kernels can reach state of the art accuracy levels for this task. Overall, it seems that KDA is able to obtain better results than KRR. The intersection kernel alone is able to obtain slightly better results than the presence bits kernel. The kernel based on LRD gives significantly lower accuracy rates, but it is able to improve the performance when it is blended p-grams intersection kernel ( 1369 Method Development 10-fold CV Test Ensemble model (Tetreault et al., 2012) - 80.9% - KRR and string kernels (Popescu and Ionescu, 2013) - 82.6% 82.7% SVM and word features (Jarvis et al., 2013) - 84.5% 83.6% KRR and ˆk0/1 85.4% 82.5% 82.0% 5−8 84.9% 82.2% 82.6% KRR and ˆk∩ 78.7% 77.1% 77.5% 5−8 85.7% 82.6% 82.7% KRR and ˆkLRD 84.9% 82.2% 82.0% 5−8 85.5% 82.6% 82.5% KRR and ˆk0/1 85.5% 82.6% 82.5% 5−8 + ˆkLRD 5−8 KRR and k5 8 +ˆkSRa KRR and ˆk, a + ˆk∩ 5−8 KRR and a1ˆk0/1 5−8 + a2ˆk∩ 5−8 KDA and ˆk0/1 86.2% 83.6% 83.6% 5−8 85.2% 83.5% 84.6% KDA and ˆk∩ 79.7% 78.5% 79.2% 5−8 87.1% 84.0% 84.7% KDA and ˆkLRD 85.8% 83.4% 83.9% 5−8 86.4% 84.1% 85.0% KDA and ˆk0/1 86.5% 84</context>
<context position="32401" citStr="Tetreault et al. (2012)" startWordPosition="5515" endWordPosition="5518">nt and learns using KDA. This system is 1.7% better than the state of the art system of Jarvis et al. (2013) based on SVM and word features, this being the top scoring system in the NLI 2013 Shared Task. It is also 2.6% better than the state of the art system based on string kernels of Popescu and Ionescu (2013). On the cross validation procedure, there are three systems that reach the accuracy rate of 84.1%. All of them are based on KDA and various kernel combinations. The greatest accuracy rate of 84.1% reported for the cross validation procedure is 3.2% above the state of the art system of Tetreault et al. (2012) and 0.4% below the top scoring system of Jarvis et al. (2013). The empirical results obtained in this experiment demonstrate that the approach proposed in this paper can reach state of the art accuracy levels. It is worth mentioning that a significance test performed by the organizers of the NLI 2013 Shared Task showed that the top systems that participated in the competition are not essentially different. Further experiments on the ICLE corpus and on the TOEFL11-Big corpus are conducted to determine whether the approach proposed in this paper is significantly better than other state of the a</context>
<context position="34133" citStr="Tetreault et al., 2012" startWordPosition="5815" endWordPosition="5818">le both KRR and KDA produce accuracy rates that are better than the state of the art accuracy rate, it seems that KRR is slightly better in this experiment. Again, the idea of combining kernels seems to produce more robust systems. The best systems are based on combining the presence bits kernel either with the kernel based on LRD or the intersection kernel. Overall, the reported accuracy rates are higher than the state of the art accuracy rate. The best performance (91.3%) is achieved by the KRR classifier based on combining the presence bits kernel with 1370 Method 5-fold CV Ensemble model (Tetreault et al., 2012) 90.1% KRR and ˆk0/1 91.2% 5−8 90.5% KRR and ˆk∩ 81.8% 5−8 91.3% KRR and ˆk5Ra 90.1% KRR and ˆk, a + ˆkLRD 90.9% 5−8 90.6% KRR and ˆk∩5−8 + ˆkLRD 5−8 KRR and ˆk0/1 5−8 + ˆk∩ 5−8 KRR and ˆk0/1 5−8 + ˆk∩5−8 + ˆkLRD 5−8 KDA and ˆk0/1 90.5% 5−8 90.5% KDA and ˆk∩ 82.3% 5−8 90.8% KDA and ˆkLRD 90.4% 5−8 91.0% KDA and ˆk5− a +k5Ra 90.8% KDAand ˆk∩5−8 + ˆkLRD 5−8 KDA and ˆk0/1 5−8 + ˆk∩ 5−8 KDA and ˆk0/1 5−8 + ˆk∩5−8 + ˆkLRD 5−8 Table 3: Accuracy rates on ICLE corpus of various classification systems based on string kernels compared with a state of the art approach. The accuracy rates are reported for</context>
<context position="36219" citStr="Tetreault et al., 2012" startWordPosition="6189" endWordPosition="6192">his experiment. Nevertheless, better results can probably be obtained by adding these aspects into the equation. 5.5 Cross-corpus Experiment In this experiment, various systems based on KRR or KDA are trained on the TOEFL11 corpus and tested on the TOEFL11-Big corpus. The kernel based on LRD was not included in this experiment since it is more computationally expensive. Therefore, only the presence bits kernel and the intersection kernel were evaluated on the TOEFL11-Big corpus. The results are summarized in Table 4. The same regularization parameters determined to Method Test Ensemble model (Tetreault et al., 2012) 35.4% KRR and ˆk0/1 66.7% 5−8 67.2% KRR and ˆk∩ 67.7% 5−8 67.7% KRR and ˆk0/1 5−8 + ˆk∩ 5−8 KRR and a1ˆk0/1 5−8 + a2ˆk∩ 5−8 KDA and ˆk0/1 65.6% 5−8 65.7% KDA and ˆk∩ 66.2% 5−8 66.2% KDA and ˆk0/1 5−8 + ˆk∩ 5−8 KDA and a1ˆk0/1 5−8 + a2ˆk∩ 5−8 Table 4: Accuracy rates on TOEFL11-Big corpus of various classification systems based on string kernels compared with a state of the art approach. The systems are trained on the TOEFL11 corpus and tested on the TOEFL11-Big corpus. The best accuracy rate is highlighted in bold. The weights a1 and a2 from the weighted sums of kernels are computed by kernel </context>
<context position="38368" citStr="Tetreault et al. (2012)" startWordPosition="6574" endWordPosition="6577">EFL11 are different from the topics from TOEFL11-Big, it becomes clear that a method that uses words as features is strongly affected, since the distribution of words per topic can be completely different. But mistakes that reveal the native language can be captured by character ngrams that can appear more often even in different topics. The results indicate that this is also the case of the approach based on string kernels, which seems to be more robust to such topic variations of the data set. The best system has an accuracy rate that is 32.3% better than the state of 1371 the art system of Tetreault et al. (2012). Overall, the empirical results indicate that the string kernels approach can achieve significantly better results than other state of the art approaches. 6 Conclusions A language-independent approach to native language identification was presented in this paper. The system works at the character level, making the approach completely language independent and linguistic theory neutral. The results obtained in all the three experiments were very good. The best system presented in this work is based on combining the intersection and the presence string kernels by kernel alignment and on deciding</context>
</contexts>
<marker>Tetreault, Blanchard, Cahill, Chodorow, 2012</marker>
<rawString>Joel Tetreault, Daniel Blanchard, Aoife Cahill, and Martin Chodorow. 2012. Native Tongues, Lost and Found: Resources and Empirical Evaluations in Native Language Identification. Proceedings of COLING 2012, pages 2585–2602, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Daniel Blanchard</author>
<author>Aoife Cahill</author>
</authors>
<title>A report on the first native language identification shared task.</title>
<date>2013</date>
<booktitle>Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>48--57</pages>
<contexts>
<context position="5600" citStr="Tetreault et al. (2013)" startWordPosition="861" endWordPosition="864">entifying the native language of English language learners, though there have been some efforts recently to identify the native language of writing in other languages (Malmasi and Dras, 2014). In general most approaches to NLI have used multi-way classification with SVMs or similar models along with a range of linguistic features. The seminal paper by Koppel et al. (2005) introduced some of the best-performing features: character, word and part-of-speech n-grams along with features inspired by the work in the area of secondlanguage acquisition such as spelling and grammatical errors. In 2013, Tetreault et al. (2013) organized the first shared task in the field. This allowed researchers to compare approaches for the first time on a specifically designed NLI corpus that was much larger than previously available data sets. In the shared task, 29 teams submitted results for the test set, and one of the most successful aspects of the competition was that it drew submissions from teams working in a variety of research fields. The submitted systems utilized a wide range of machine learning approaches, combined with several innovative feature contributions. The best performing system achieved an overall accuracy</context>
<context position="23879" citStr="Tetreault et al., 2013" startWordPosition="4071" endWordPosition="4074">gations, and because of this contains some idiosyncrasies that make it problematic for the task of NLI (Brooke and Hirst, 2012). Therefore, a modified version of the corpus that has been normalized as much as possible for topic and character encoding (Tetreault et al., 2012) is used. This version of the corpus contains 110 essays each for 7 native languages: Bulgarian, Chinese, Czech, French, Japanese, Russian and Spanish. The ETS Corpus of Non-Native Written English (TOEFL11) was first introduced by Tetreault et al. (2012) and extended for the 2013 Native Language Identification Shared Task (Tetreault et al., 2013). It was designed to overcome many of the shortcomings identified with using the ICLEv2 corpus for this task. The TOEFL11 corpus contains a balanced distribution of essays per prompt (topic) per native language. It also contains information about the language proficiency of each writer. The corpus contains essays written by speakers of the following 11 languages: Arabic, Chinese, French, German, Hindi, Italian, Japanese, Korean, Spanish, Telugu and Turkish. For the shared task, the 12,100 essays were split into 9,900 for training, 1,100 for development and 1,100 for testing. Tetreault et al. (</context>
</contexts>
<marker>Tetreault, Blanchard, Cahill, 2013</marker>
<rawString>Joel Tetreault, Daniel Blanchard, and Aoife Cahill. 2013. A report on the first native language identification shared task. Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 48–57, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Vedaldi</author>
<author>Andrew Zisserman</author>
</authors>
<title>Efficient additive kernels via explicit feature maps.</title>
<date>2010</date>
<booktitle>Proceedings of CVPR,</booktitle>
<pages>3539--3546</pages>
<contexts>
<context position="2707" citStr="Vedaldi and Zisserman, 2010" startWordPosition="403" endWordPosition="406"> level has an important advantage in that it is language independent and linguistic theory neutral. This paper presents a state of the art machine learning system for native language identification that works at the character level. The proposed system is inspired by the system of Popescu and Ionescu (2013), but includes some variations and improvements. A major improvement is that several string kernels are combined via multiple kernel learning (ShaweTaylor and Cristianini, 2004). Despite the fact that the (histogram) intersection kernel is very popular in computer vision (Maji et al., 2008; Vedaldi and Zisserman, 2010), it has never been used before in text mining. In this work, the intersection kernel is used for the first time in a text categorization task, alone and in combination with other kernels. The intersection kernel lies somewhere in the middle between the kernel that takes into account only the presence of n-grams and the kernel based on the frequency of n-grams (p-spectrum string kernel). Two kernel classifiers are proposed for the learning task, namely Kernel Ridge Regression (KRR) and Kernel Discriminant Analysis (KDA). The KDA classifier is able to avoid the classmasking problem (Hastie and </context>
<context position="11712" citStr="Vedaldi and Zisserman, 2010" startWordPosition="1871" endWordPosition="1874">ts substrings of length p (p-grams) with each string. A variant of this kernel can be obtained if the embedding feature map is modified to associate a vector of dimension |E|p containing the presence bits (instead of frequencies) of all its substrings of length p with each string. Thus, the character pgrams presence bits kernel is obtained: �k0/1 p(s, t) = inv(s) · inv(t), vEEP where inv(s) is 1 if string v occurs as a substring in s, and 0 otherwise. In computer vision, the (histogram) intersection kernel has successfully been used for object class recognition from images (Maji et al., 2008; Vedaldi and Zisserman, 2010). In this paper, the intersection kernel is used for the first time as a kernel for strings. The intersection string kernel is defined as follows: k∩p (s, t) = � min{numv(s), numv(t)}, vEEP where numv(s) is the number of occurrences of string v as a substring in s. For the p-spectrum kernel, the frequency of a pgram has a very significant contribution to the kernel, since it considers the product of such frequencies. On the other hand, the frequency of a p-gram is completely disregarded in the p-grams presence bits kernel. The intersection kernel lies somewhere in the middle between the p-gram</context>
</contexts>
<marker>Vedaldi, Zisserman, 2010</marker>
<rawString>Andrea Vedaldi and Andrew Zisserman. 2010. Efficient additive kernels via explicit feature maps. Proceedings of CVPR, pages 3539–3546.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>