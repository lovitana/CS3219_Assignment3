<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000091">
<title confidence="0.997494">
Beyond Parallel Data: Joint Word Alignment and Decipherment
Improves Machine Translation
</title>
<author confidence="0.998797">
Qing Dou , Ashish Vaswani, and Kevin Knight
</author>
<affiliation confidence="0.998806">
Information Sciences Institute
Department of Computer Science
University of Southern California
</affiliation>
<email confidence="0.997541">
{qdou,avaswani,knight}@isi.edu
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.977220416666666">
Inspired by previous work, where decipher-
ment is used to improve machine translation,
we propose a new idea to combine word align-
ment and decipherment into a single learning
process. We use EM to estimate the model pa-
rameters, not only to maximize the probabil-
ity of parallel corpus, but also the monolingual
corpus. We apply our approach to improve
Malagasy-English machine translation, where
only a small amount of parallel data is avail-
able. In our experiments, we observe gains of
0.9 to 2.1 B over a strong baseline.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999291741935484">
State-of-the-art machine translation (MT) systems ap-
ply statistical techniques to learn translation rules au-
tomatically from parallel data. However, this reliance
on parallel data seriously limits the scope of MT ap-
plication in the real world, as for many languages and
domains, there is not enough parallel data to train a de-
cent quality MT system.
However, compared with parallel data, there are
much larger amounts of non parallel data. The abil-
ity to learn a translation lexicon or even build a ma-
chine translation system using monolingual data helps
address the problems of insufficient parallel data. Ravi
and Knight (2011) are among the first to learn a full
MT system using only non parallel data through deci-
pherment. However, the performance of such systems
is much lower compared with those trained with par-
allel data. In another work, Klementiev et al. (2012)
show that, given a phrase table, it is possible to esti-
mate parameters for a phrase-based MT system from
non parallel data.
Given that we often have some parallel data, it is
more practical to improve a translation system trained
on parallel data by using additional non parallel data.
Rapp (1995) shows that with a seed lexicon, it is possi-
ble to induce new word level translations from non par-
allel data. Motivated by the idea that a translation lexi-
con induced from non parallel data can be used to trans-
late out of vocabulary words (OOV), a variety of prior
research has tried to build a translation lexicon from
non parallel or comparable data (Fung and Yee, 1998;
Koehn and Knight, 2002; Haghighi et al., 2008; Garera
</bodyText>
<figureCaption confidence="0.7102835">
Figure 1: Combine word alignment and decipherment
into a single learning process.
</figureCaption>
<bodyText confidence="0.999498653846154">
et al., 2009; Bergsma and Van Durme, 2011; Daum´e
and Jagarlamudi, 2011; Irvine and Callison-Burch,
2013b; Irvine and Callison-Burch, 2013a; Irvine et al.,
2013).
Lately, there has been increasing interest in learn-
ing translation lexicons from non parallel data with de-
cipherment techniques (Ravi and Knight, 2011; Dou
and Knight, 2012; Nuhn et al., 2012; Dou and Knight,
2013). Decipherment views one language as a cipher
for another and learns a translation lexicon that pro-
duces fluent text in the target (plaintext) language. Pre-
vious work has shown that decipherment not only helps
find translations for OOVs (Dou and Knight, 2012), but
also improves translations of observed words (Dou and
Knight, 2013).
We find that previous work using monolingual or
comparable data to improve quality of machine transla-
tion separates two learning tasks: first, translation rules
are learned from parallel data, and then the information
learned from parallel data is used to bootstrap learning
with non parallel data. Inspired by approaches where
joint inference reduces the problems of error propaga-
tion and improves system performance, we combine
the two separate learning processes into a single one,
as shown in Figure 1. The contributions of this work
are:
</bodyText>
<page confidence="0.938664">
557
</page>
<note confidence="0.890051">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 557–565,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<listItem confidence="0.986095833333334">
• We propose a new objective function for word
alignment that combines the process of word
alignment and decipherment into a single learning
task.
• In experiments, we find that the joint process out-
performs the previous pipeline approach, and ob-
</listItem>
<bodyText confidence="0.488924166666667">
serve B gains of 0.9 and 2.1 on two different
test sets.
• We release 15.3 million tokens of monolingual
Malagasy data from the web, as well as a small
Malagasy dependency tree bank containing 20k
tokens.
</bodyText>
<sectionHeader confidence="0.998225" genericHeader="introduction">
2 Joint Word Alignment and
Decipherment
</sectionHeader>
<subsectionHeader confidence="0.968839">
2.1 A New Objective Function
</subsectionHeader>
<bodyText confidence="0.999975260869565">
In previous work that uses monolingual data to im-
prove machine translation, a seed translation lexicon
learned from parallel data is used to find new transla-
tions through either word vector based approaches or
decipherment. In return, selection of a seed lexicon
needs to be careful as using a poor quality seed lexi-
con could hurt the downstream process. Evidence from
a number of previous work shows that a joint inference
process leads to better performance in both tasks (Jiang
et al., 2008; Zhang and Clark, 2008).
In the presence of parallel and monolingual data, we
would like the alignment and decipherment models to
benefit from each other. Since the decipherment and
word alignment models contain word-to-word transla-
tion probabilities t(f  |e), having them share these pa-
rameters during learning will allow us to pool infor-
mation from both data types. This leads us to de-
velop a new objective function that takes both learn-
ing processes into account. Given our parallel data,
(E1, F1), ... , (Em, Fm), ... , (EM, FM), and monolingual
data F1mono, ... , Fnmono, . . . , FNmono, we seek to maximize
the likelihood of both. Our new objective function is
defined as:
</bodyText>
<subsectionHeader confidence="0.9991">
2.2 Word Alignment
</subsectionHeader>
<bodyText confidence="0.998057454545455">
Given a source sentence F = f1,. . . , fj,...,fJ and a
target sentence E = e1,... , ei, ... , eI, word alignment
models describe the generative process employed to
produce the French sentence from the English sentence
through alignments a = a1,..., aj, ... , aJ.
The IBM models 1-2 (Brown et al., 1993) and the
HMM word alignment model (Vogel et al., 1996) use
two sets of parameters, distortion probabilities and
translation probabilities, to define the joint probabil-
ity of a target sentence and alignment given a source
sentence.
</bodyText>
<equation confidence="0.971189">
d(aj  |aj−1, j)t(fj  |eaj). (3)
</equation>
<bodyText confidence="0.997834181818182">
These alignment models share the same translation
probabilities t(fj  |eaj), but differ in their treatment of
the distortion probabilities d(aj  |aj−1, j). Brown et
al. (1993) introduce more advanced models for word
alignment, such as Model 3 and Model 4, which use
more parameters to describe the generative process. We
do not go into details of those models here and the
reader is referred to the paper describing them.
Under the Model 1-2 and HMM alignment models,
the probability of target sentence given source sentence
is:
</bodyText>
<equation confidence="0.876657">
d(aj  |aj−1, j)t(fj  |eaj).
</equation>
<bodyText confidence="0.9999886">
Let θ denote all the parameters of the word align-
ment model. Given a corpus of sentence pairs
(E1, F1), . . . , (Em, Fm), . . . , (EM, FM),the standard ap-
proach for training is to learn the maximum likelihood
estimate of the parameters, that is,
</bodyText>
<equation confidence="0.999712260869565">
log P(Fm  |Em)
log I Z P(Fm, a  |Em)J .
l a
J
H
j=1
P(F, a  |E) =
Z
P(F  |E) =
a
J
H
j=1
θ* = arg max
θ
M
Z
m=1
= arg max
θ
Fjoint = M log P(Fm  |Em) + α N log P(Fnmono) (1) We typically use the EM algorithm (Dempster et al.,
Z Z 1977), to carry out this optimization.
m=1 n=1
</equation>
<bodyText confidence="0.9953905">
The goal of training is to learn the parameters that
maximize this objective, that is
</bodyText>
<equation confidence="0.82801">
θ* = arg max Fjoint (2)
θ
</equation>
<bodyText confidence="0.999958666666667">
In the next two sections, we describe the word align-
ment and decipherment models, and present how they
are combined to perform joint optimization.
</bodyText>
<subsectionHeader confidence="0.994293">
2.3 Decipherment
</subsectionHeader>
<bodyText confidence="0.999861111111111">
Given a corpus of N foreign text sequences (cipher-
text), F1mono, ... , Fnmono, . . . , FNmono, decipherment finds
word-to-word translations that best describe the cipher-
text.
Knight et al. (2006) are the first to study several natu-
ral language decipherment problems with unsupervised
learning. Since then, there has been increasing interest
in improving decipherment techniques and its applica-
tion to machine translation (Ravi and Knight, 2011;
</bodyText>
<page confidence="0.995163">
558
</page>
<bodyText confidence="0.955828142857143">
Dou and Knight, 2012; Nuhn et al., 2012; Dou and
Knight, 2013; Nuhn et al., 2013).
In order to speed up decipherment, Dou and Knight
(2012) suggest that a frequency list of bigrams might
contain enough information for decipherment. Accord-
ing to them, a monolingual ciphertext bigram Fmono is
generated through the following generative story:
</bodyText>
<listItem confidence="0.9977865">
• Generate a sequence of two plaintext tokens e1e2
with probability P(e1e2) given by a language
model built from large numbers of plaintext bi-
grams.
• Substitute e1 with f1 and e2 with f2 with probabil-
ity t(f1|e1) · t(f2|e2).
</listItem>
<bodyText confidence="0.918102">
The probability of any cipher bigram F is:
</bodyText>
<equation confidence="0.985581833333333">
�P(Fmono) = P(e1e2) · t(f1|e1) · t(f2|e2) (4)
e1e2
And the probability of the corpus is:
N
P(corpus) = H P(Fn mono) (5) Figure 2: Joint Word Alignment and Decipherment
n=1 with EM
</equation>
<bodyText confidence="0.999944">
Given a plaintext bigram language model, the goal is
to manipulate t(f |e) to maximize P(corpus). Theoret-
ically, one can directly apply EM to solve the problem
(Knight et al., 2006). However, EM has time complex-
ity O(N·V2e) and space complexity O(Vf ·Ve), where Vf,
Ve are the sizes of ciphertext and plaintext vocabularies
respectively, and N is the number of cipher bigrams.
There have been previous attempts to make decipher-
ment faster. Ravi and Knight (2011) apply Bayesian
learning to reduce the space complexity. However,
Bayesian decipherment is still very slow with Gibbs
sampling (Geman and Geman, 1987). Dou and Knight
(2012) make sampling faster by introducing slice sam-
pling (Neal, 2000) to Bayesian decipherment. Besides
Bayesian decipherment, Nuhn et al. (2013) show that
beam search can be used to solve a very large 1:1 word
substitution cipher. In subsection 2.4.1, we describe
our approach that uses slice sampling to compute ex-
pected counts for decipherment in the EM algorithm.
</bodyText>
<subsectionHeader confidence="0.996985">
2.4 Joint Optimization
</subsectionHeader>
<bodyText confidence="0.99994484375">
We now describe our EM approach to learn the param-
eters that maximize Fjoint (equation 2), where the dis-
tortion probabilities, d(aj  |aj−1, j) in the word align-
ment model are only learned from parallel data, and
the translation probabilities, t(f  |e) are learned using
both parallel and non parallel data. The E step and M
step are illustrated in Figure 2.
Our algorithm starts with EM learning only on par-
allel data for a few iterations. When the joint inference
starts, we first compute expected counts from parallel
data and non parallel data using parameter values from
the last M step separately. Then, we add the expected
counts from both parallel data and non parallel data to-
gether with different weights for the two. Finally we
renormalize the translation table and distortion table to
update parameters in the new M step.
The E step for parallel part can be computed effi-
ciently using the forward-backward algorithm (Vogel et
al., 1996). However, as we pointed out in Section 2.3,
the E step for the non parallel part has a time com-
plexity of O(V2) with the forward-backward algorithm,
where V is the size of English vocabulary, and is usu-
ally very large. Previous work has tried to make de-
cipherment scalable (Ravi and Knight, 2011; Dou and
Knight, 2012; Nuhn et al., 2013; Ravi, 2013). How-
ever, all of them are designed for decipherment with ei-
ther Bayesian inference or beam search. In contrast, we
need an algorithm to make EM decipherment scalable.
To overcome this problem, we modify the slice sam-
pling (Neal, 2000) approach used by Dou and Knight
(2012) to compute expected counts from non parallel
data needed for the EM algorithm.
</bodyText>
<subsectionHeader confidence="0.476211">
2.4.1 Draw Samples with Slice Sampling
</subsectionHeader>
<bodyText confidence="0.9999369">
To start the sampling process, we initialize the first
sample by performing approximate Viterbi decoding
using results from the last EM iteration. For each for-
eign dependency bigram f1, f2, we find the top 50 can-
didates for f1 and f2 ranked by t(e |f ), and find the En-
glish sequence e1, e2 that maximizes t(e1|f1) · t(e2|f2) ·
P(e1, e2).
Suppose the derivation probability for current sam-
ple e current is P(e current), we use slice sampling to
draw a new sample in two steps:
</bodyText>
<listItem confidence="0.999960666666667">
• Select a threshold T uniformly between 0 and
P(e current).
• Draw a new sample e new uniformly from a pool
</listItem>
<page confidence="0.990471">
559
</page>
<bodyText confidence="0.992868466666667">
of candidates: {e new|P(e new) &gt; T}.
The first step is straightforward to implement. How-
ever, it is not trivial to implement the second step. We
adapt the idea from Dou and Knight (2012) for EM
learning.
Suppose our current sample e current contains En-
glish tokens ei−1, ei, and ei+1 at position i − 1, i, and
i+1 respectively, and fi be the foreign token at position
i. Using point-wise sampling, we draw a new sample
by changing token ei to a new token e0. Since the rest
of the sample remains the same, only the probability of
the trigram P(ei−1e0ei+1) (The probability is given by a
bigram language model.), and the channel model prob-
ability t(fi|e0) change. Therefore, the probability of a
sample is simplified as shown Equation 6.
</bodyText>
<equation confidence="0.999856">
P(ei−1e0ei+1) · t(fi|e0) (6)
</equation>
<bodyText confidence="0.998185692307692">
Remember that in slice sampling, a new sample is
drawn in two steps. For the first step, we choose a
threshold T uniformly between 0 and P(ei−1eiei+1) ·
t(fi|ei). We divide the second step into two cases based
on the observation that two types of samples are more
likely to have a probability higher than T (Dou and
Knight, 2012): (1) those whose trigram probability is
high, and (2) those whose channel model probability is
high. To find candidates that have high trigram proba-
bility, Dou and Knight (2012) build a top k sorted lists
ranked by P(ei−1e0ei+1), which can be pre-computed
off-line. Then, they test if the last item ek in the list
satisfies the following inequality:
</bodyText>
<equation confidence="0.998676">
P(ei−1ekei+1) · c &lt; T (7)
</equation>
<bodyText confidence="0.99978468">
where c is a small constant and is set to prior in their
work. In contrast, we choose c empirically as we do
not have a prior in our model. When the inequality in
Equation 7 is satisfied, a sample is drawn in the fol-
lowing way: Let set A = {e0|ei−1e0ei+1 · c &gt; T} and
set B = {e0|t(fi|e0) &gt; c}. Then we only need to sample
e0 uniformly from A ∪ B until P(ei−1e0ei+1) · t(fi|e0) is
greater than T. It is easy to prove that all other candi-
dates that are not in the sorted list and with t(fi|e0) ≤ c
have a upper bound probability: P(ei−1ekei+1)·c. There-
fore, they do not need to be considered.
Second, when the last item ek in the list does not
meet the condition in Equation 7, we keep drawing
samples e0 randomly until its probability is greater than
the threshold T.
As we mentioned before, the choice of the small con-
stant c is empirical. A large c reduces the number of
items in set B, but makes the condition P(ei−1ekei+1) ·
c &lt; T less likely to satisfy, which slows down the sam-
pling. On the contrary, a small c increases the number
of items in set B significantly as EM does not encour-
age a sparse distribution, which also slows down the
sampling. In our experiments, we set c to 0.001 based
on the speed of decipherment. Furthermore, to reduce
the size of set B, we rank all the candidate translations
</bodyText>
<table confidence="0.998941666666667">
Spanish English
Parallel 10.3k 9.9k
Non Parallel 80 million 400 million
</table>
<tableCaption confidence="0.998432">
Table 1: Size of parallel and non parallel data for word
alignment experiments (Measured in number of tokens)
</tableCaption>
<bodyText confidence="0.93575">
of fi by t(e0 |fi), then we add maximum the first 1000
candidates whose t(fi|e0) &gt;= c into set B. For the rest
of the candidates, we set t(fi|e0) to a value smaller than
c (0.00001 in experiments).
</bodyText>
<subsectionHeader confidence="0.736427">
2.4.2 Compute Expected Counts from Samples
</subsectionHeader>
<bodyText confidence="0.999512">
With the ability to draw samples efficiently for deci-
pherment using EM, we now describe how to compute
expected counts from those samples. Let f1, f2 be a
specific ciphertext bigram, N be the number of sam-
ples we want to use to compute expected counts, and
e1, e2 be one of the N samples. The expected counts
for pairs (f1, e1) and (f2, e2) are computed as:
</bodyText>
<equation confidence="0.9828265">
count(f1, f2)
N
</equation>
<bodyText confidence="0.999828">
where count(f1, f2) is count of the bigram, and α is the
weight for non parallel data as shown in Equation 1.
Expected counts collected for f1, f2 are accumulated
from each of its N samples. Finally, we collect ex-
pected counts using the same approach from each for-
eign bigram.
</bodyText>
<sectionHeader confidence="0.996549" genericHeader="method">
3 Word Alignment Experiments
</sectionHeader>
<bodyText confidence="0.999978">
In this section, we show that joint word alignment and
decipherment improves the quality of word alignment.
We choose to evaluate word alignment performance
for Spanish and English as manual gold alignments
are available. In experiments, our approach improves
alignment F score by as much as 8 points.
</bodyText>
<subsectionHeader confidence="0.995944">
3.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.998614055555555">
As shown in Table 1, we work with a small amount of
parallel, manually aligned Spanish-English data (Lam-
bert et al., 2005), and a much larger amount of mono-
lingual data.
The parallel data is extracted from Europarl, which
consists of articles from European parliament plenary
sessions. The monolingual data comes from English
and Spanish versions of Gigaword corpra containing
news articles from different news agencies.
We view Spanish as a cipher of English, and follow
the approach proposed by Dou and Knight (2013) to
extract dependency bigrams from parsed Spanish and
English monolingual data for decipherment. We only
keep bigrams where both tokens appear in the paral-
lel data. Then, we perform Spanish to English (En-
glish generating Spanish) word alignment and Span-
ish to English decipherment simultaneously with the
method discussed in section 2.
</bodyText>
<equation confidence="0.459541">
α ·
</equation>
<page confidence="0.984087">
560
</page>
<sectionHeader confidence="0.974897" genericHeader="method">
3.1.1 Results
</sectionHeader>
<bodyText confidence="0.999528952380953">
We align all 500 sentences in the parallel corpus, and
tune the decipherment weight (α) for Model 1 and
HMM using the last 100 sentences. The best weights
are 0.1 for Model 1, and 0.005 for HMM. We start with
Model 1 with only parallel data for 5 iterations, and
switch to the joint process for another 5 iterations with
Model 1 and 5 more iterations of HMM. In the end, we
use the first 100 sentence pairs of the corpus for evalu-
ation.
Figure 3 compares the learning curve of alignment
F-score between EM without decipherment (baseline)
and our joint word alignment and decipherment. From
the learning curve, we find that at the 6th iteration, 2
iterations after we start the joint process, alignment F-
score is improved from 34 to 43, and this improvement
is held through the rest of the Model 1 iterations. The
alignment model switches to HMM from the 11th iter-
ation, and at the 12th iteration, we see a sudden jump
in F-score for both the baseline and the joint approach.
We see consistent improvement of F-score till the end
of HMM iterations.
</bodyText>
<sectionHeader confidence="0.952016" genericHeader="method">
4 Improving Low Density Languages
Machine Translation with Joint Word
Alignment and Decipherment
</sectionHeader>
<bodyText confidence="0.9965956875">
In the previous section, we show that the joint word
alignment and decipherment process improves quality
of word alignment significantly for Spanish and En-
glish. In this section, we test our approach in a more
challenging setting: improving the quality of machine
translation in a real low density language setting.
In this task, our goal is to build a system to trans-
late Malagasy news into English. We have a small
amount of parallel data, and larger amounts of mono-
lingual data collected from online websites. We build a
dependency parser for Malagasy to parse the monolin-
gual data to perform dependency based decipherment
(Dou and Knight, 2013). In the end, we perform joint
word alignment and decipherment, and show that the
joint learning process improves B scores by up to
2.1 points over a phrase-based MT baseline.
</bodyText>
<subsectionHeader confidence="0.991745">
4.1 The Malagasy Language
</subsectionHeader>
<bodyText confidence="0.999504846153846">
Malagasy is the official language of Madagascar. It has
around 18 million native speakers. Although Mada-
gascar is an African country, Malagasy belongs to the
Malayo-Polynesian branch of the Austronesian lan-
guage family. Malagasy and English have very dif-
ferent word orders. First of all, in contrast to En-
glish, which has a subject-verb-object (SVO) word or-
der, Malagasy has a verb-object-subject (VOS) word
order. Besides that, Malagasy is a typical head ini-
tial language: Determiners precede nouns, while other
modifiers and relative clauses follow nouns (e.g. ny
“the” boky “book” mena “red”). The significant dif-
ferences in word order pose great challenges for both
</bodyText>
<table confidence="0.998013625">
Source Malagasy English
Parallel
Global Voices 2.0 million 1.8 million
Web News 2.2k 2.1k
Non Parallel
Gigaword N/A 2.4 billion
allAfrica N/A 396 million
Local News 15.3 million N/A
</table>
<tableCaption confidence="0.78645">
Table 2: Size of Malagasy and English data used in our
experiments (Measured in number of tokens)
machine translation and decipherment.
</tableCaption>
<subsectionHeader confidence="0.932469">
4.2 Data
</subsectionHeader>
<bodyText confidence="0.999764272727273">
Table 2 shows the data available to us in our experi-
ments. The majority of parallel text comes from Global
Voices1 (GV). The website contains international news
translated into different foreign languages. Besides
that, we also have a very small amount of parallel text
containing local web news, with English translations
provided by native speakers at the University of Texas,
Austin. The Malagasy side of this small parallel corpus
also has syntactical annotation, which is used to train a
very basic Malagasy part of speech tagger and depen-
dency parser.
We also have much larger amounts of non paral-
lel data for both languages. For Malagasy, we spent
two months manually collecting 15.3 million tokens of
news text from local news websites in Madagascar.2
We have released this data for future research use. For
English, we have 2.4 billion tokens from the Gigaword
corpus. Since the Malagasy monolingual data is col-
lected from local websites, it is reasonable to argue that
those data contain significant amount of information re-
lated to Africa. Therefore, we also collect 396 million
tokens of African news in English from allAfrica.com.
</bodyText>
<subsectionHeader confidence="0.999301">
4.3 Building A Dependency Parser for Malagasy
</subsectionHeader>
<bodyText confidence="0.9999768">
Since Malagasy and English have very different word
orders, we decide to apply dependency based decipher-
ment for the two languages as suggested by Dou and
Knight (2013). To extract dependency relations, we
need to parse monolingual data in Malagasy and En-
glish. For English, there are already many good parsers
available. In our experiments, we use Turbo parser
(Martins et al., 2013) trained on the English Penn Tree-
bank (Marcus et al., 1993) to parse all our English
monolingual data. However, there is no existing good
parser for Malagasy.
The quality of a dependency parser depends on the
amount of training data available. State-of-the-art En-
glish parsers are built from Penn Treebank, which con-
tains over 1 million tokens of annotated syntactical
</bodyText>
<footnote confidence="0.943662">
1globalvoicesonline.org
2aoraha.com, gazetiko.com, inovaovao.com,
expressmada.com, lakroa.com
</footnote>
<page confidence="0.995287">
561
</page>
<figureCaption confidence="0.9825405">
Figure 3: Learning curve showing our joint word alignment and decipherment approach improves word alignment
quality over the traditional EM without decipherment (Model 1: Iteration 1 to 10, HMM: Iteration 11 to 15)
</figureCaption>
<bodyText confidence="0.999754952380952">
trees. In contrast, the available data for training a Mala-
gasy parser is rather limited, with only 168 sentences,
and 2.8k tokens, as shown in Table 2. At the very be-
ginning, we use the last 120 sentences as training data
to train a part of speech (POS) tagger using a toolkit
provided by Garrette et al. (2013) and a dependency
parser with the Turbo parser. We test the performance
of the parser on the first 48 sentences and obtain 72.4%
accuracy.
One obvious way to improve tagging and parsing ac-
curacy is to get more annotated data. We find more data
with only part of speech tags containing 465 sentences
and 10k tokens released by (Garrette et al., 2013), and
add this data as extra training data for POS tagger.
Also, we download an online dictionary that contains
POS tags for over 60k Malagasy word types from mala-
gasyword.org. The dictionary is very helpful for tag-
ging words never seen in the training data.
It is natural to think that creation of annotated data
for training a POS tagger and a parser requires large
amounts of efforts from annotators who understand the
language well. However, we find that through the help
of parallel data and dictionaries, we are able to create
more annotated data by ourselves to improve tagging
and parsing accuracy. This idea is inspired by previ-
ous work that tries to learn a semi-supervised parser
by projecting dependency relations from one language
(with good dependency parsers) to another (Yarowsky
and Ngai, 2001; Ganchev et al., 2009). However, we
find those automatic approaches do not work well for
Malagasy.
To further expand our Malagasy training data, we
first use a POS tagger and parser with poor perfor-
mance to parse 788 sentences (20k tokens) on the
Malagasy side of the parallel corpus from Global
Voices. Then, we correct both the dependency links
and POS tags based on information from dictionaries3
and the English translation of the parsed sentence. We
spent 3 months to manually project English dependen-
cies to Malagasy and eventually improve test set pars-
ing accuracy from 72.4% to 80.0%. We also make this
data available for future research use.
</bodyText>
<subsectionHeader confidence="0.985079">
4.4 Machine Translation Experiments
</subsectionHeader>
<bodyText confidence="0.9999005">
In this section, we present the data used for our MT
experiments, and compare three different systems to
justify our joint word alignment and decipherment ap-
proach.
</bodyText>
<subsectionHeader confidence="0.524829">
4.4.1 Baseline Machine Translation System
</subsectionHeader>
<bodyText confidence="0.990929307692308">
We build a state-of-the-art phrase-based MT system,
PBMT, using Moses (Koehn et al., 2007). PBMT has 3
models: a translation model, a distortion model, and
a language model. We train the other models using
half of the Global Voices parallel data (the rest is re-
served for development and testing), and build a 5-
gram language model using 834 million tokens from
AFP section of English Gigaword, 396 million tokens
from allAfrica, and the English part of the parallel cor-
pus for training. For alignment, we run 10 iterations
of Model 1, and 5 iterations of HMM. We did not run
Model 3 and Model 4 as we see no improvements in
B scores from running those models. We do word
</bodyText>
<footnote confidence="0.775525">
3an online dictionary from malagasyword.org, as well as
a lexicon learned from the parallel data
</footnote>
<page confidence="0.994552">
562
</page>
<bodyText confidence="0.9999735">
alignment in two directions and use grow-diag-final-
and heuristic to obtain final alignment. During decod-
ing, we use 8 standard features in Moses to score a can-
didate translation: direct and inverse translation proba-
bilities, direct and inverse lexical weighting, a language
model score, a distortion score, phrase penalty, and
word penalty. The weights for the features are learned
on the tuning data using minimum error rate training
(MERT) (Och, 2003).
To compare with previous decipherment approach to
improve machine translation, we build a second base-
line system. We follow the work by Dou and Knight
(2013) to decipher Malagasy into English, and build a
translation lexicon Tdecipher from decipherment. To im-
prove machine translation, we simply use Tdecipher as
an additional parallel corpus. First, we filter Tdecipher
by keeping only translation pairs (f, e), where f is ob-
served in the Spanish part and e is observed in the En-
glish part of the parallel corpus. Then we append all
the Spanish and English words in the filtered Tdecipher
to the end of Spanish part and English part of the paral-
lel corpus respectively. The training and tuning process
is the same as the baseline machine translation system
PBMT. We call this system Decipher-Pipeline.
</bodyText>
<subsectionHeader confidence="0.952819">
4.4.2 Joint Word Alignment and Decipherment
for Machine Translation
</subsectionHeader>
<bodyText confidence="0.999979931034483">
When deciphering Malagasy to English, we extract
Malagasy dependency bigrams using all available
Malagasy monolingual data plus the Malagasy part of
the Global Voices parallel data, and extract English
dependency bigrams using 834 million tokens from
English Gigaword, and 396 million tokens from al-
lAfrica news to build an English dependency language
model. In the other direction, we extract English de-
pendency bigrams from English part of the entire paral-
lel corpus plus 9.7 million tokens from allAfrica news
4, and use 17.3 million tokens Malagasy monolingual
data (15.3 million from the web and 2.0 million from
Global Voices) to build a Malagasy dependency lan-
guage model. We require that all dependency bigrams
only contain words observed in the parallel data used
to train the baseline MT system.
During learning, we run Model 1 without decipher-
ment for 5 iterations. Then we perform joint word
alignment and decipherment for another 5 iterations
with Model 1 and 5 iterations with HMM. We tune
decipherment weights (α) for Model 1 and HMM us-
ing grid search against B score on a development
set. In the end, we only extract rules from one di-
rection P(EnglishlMalagasy), where the decipherment
weights for Model 1 and HMM are 0.5 and 0.005 re-
spectively. We chose this because we did not find any
benefits to tune the weights on each direction, and then
use grow-diag-final-end heuristic to form final align-
ments. We call this system Decipher-Joint.
</bodyText>
<footnote confidence="0.9682245">
4We do not find further B gains by using more English
monolingual data.
</footnote>
<table confidence="0.9995696">
Parallel
Malagasy English
Train (GV) 0.9 million 0.8 million
Tune (GV) 22.2k 20.2k
Test (GV) 23k 21k
Test (Web) 2.2k 2.1k
Non Parallel
Malagasy English
Gigaword N/A 834 million
Web 15.3 million 396 million
</table>
<tableCaption confidence="0.959885">
Table 3: Size of training, tuning, and testing data in
number of tokens (GV: Global Voices)
</tableCaption>
<subsectionHeader confidence="0.684121">
4.5 Results
</subsectionHeader>
<bodyText confidence="0.999855785714286">
We tune each system three times with MERT and
choose the best weights based on B scores on tuning
set.
Table 4 shows that while using a translation lexicon
learnt from decipherment does not improve the quality
of machine translation significantly, the joint approach
improves B score by 0.9 and 2.1 on Global Voices
test set and web news test set respectively. The results
show that the parsing quality correlates with gains in
B scores. Scores in the brackets in the last row of
the table are achieved using a dependency parser with
72.4% attachment accuracy, while scores outside the
brackets are obtained using a dependency parser with
80.0% attachment accuracy.
We analyze the results and find the gain mainly
comes from two parts. First, adding expected counts
from non parallel data makes the distribution of trans-
lation probabilities sparser in word alignment models.
The probabilities of translation pairs favored by both
parallel data and decipherment becomes higher. This
gain is consistent with previous observation where a
sparse prior is applied to EM to help improve word
alignment and machine translation (Vaswani et al.,
2012). Second, expected counts from decipherment
also help discover new translation pairs in the paral-
lel data for low frequency words, where those words
are either aligned to NULL or wrong translations in the
baseline.
</bodyText>
<sectionHeader confidence="0.98699" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999969333333333">
We propose a new objective function for word align-
ment to combine the process of word alignment and
decipherment into a single task. In, experiments, we
find that the joint process performs better than previous
pipeline approach, and observe B gains of 0.9 and
2.1 point on Global Voices and local web news test sets,
respectively. Finally, our research leads to the release
of 15.3 million tokens of monolingual Malagasy data
from the web as well as a small Malagasy dependency
tree bank containing 20k tokens.
Given the positive results we obtain by using the
joint approach to improve word alignment, we are in-
</bodyText>
<page confidence="0.995545">
563
</page>
<table confidence="0.99946975">
Decipherment System Tune (GV) Test (GV) Test (Web)
None PBMT (Baseline) 18.5 17.1 7.7
Separate Decipher-Pipeline 18.5 17.4 7.7
Joint Decipher-Joint 18.9 (18.7) 18.0 (17.7) 9.8 (8.5)
</table>
<tableCaption confidence="0.999234">
Table 4: Decipher-Pipeline does not show significant improvement over the baseline system. In contrast, Decipher-
</tableCaption>
<bodyText confidence="0.999703857142857">
Joint using joint word alignment and decipherment approach achieves a B gain of 0.9 and 2.1 on the Global
Voices test set and the web news test set, respectively. The results in brackets are obtained using a parser trained
with only 120 sentences. (GV: Global Voices)
spired to apply this approach to help find translations
for out of vocabulary words, and to explore other pos-
sible ways to improve machine translation with deci-
pherment.
</bodyText>
<sectionHeader confidence="0.999157" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999849">
This work was supported by NSF Grant 0904684 and
ARO grant W911NF-10-1-0533. The authors would
like to thank David Chiang, Malte Nuhn, Victoria Fos-
sum, Ashish Vaswani, Ulf Hermjakob, Yang Gao, and
Hui Zhang (in no particular order) for their comments
and suggestions.
</bodyText>
<sectionHeader confidence="0.983748" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.717532532467533">
Shane Bergsma and Benjamin Van Durme. 2011.
Learning bilingual lexicons using the visual similar-
ity of labeled web images. In Proceedings of the
Twenty-Second International Joint Conference on
Artificial Intelligence - Volume Three. AAAI Press.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The math-
ematics of statistical machine translation: Parameter
estimation. Computational Linguistics, 19:263–311.
Hal Daum´e, III and Jagadeesh Jagarlamudi. 2011. Do-
main adaptation for machine translation by mining
unseen words. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies. Associa-
tion for Computational Linguistics.
Arthur Dempster, Nan Laird, and Donald Rubin. 1977.
Maximum likelihood from incomplete data via the
EM algorithm. Computational Linguistics, 39(4):1–
38.
Qing Dou and Kevin Knight. 2012. Large scale deci-
pherment for out-of-domain machine translation. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning. Asso-
ciation for Computational Linguistics.
Qing Dou and Kevin Knight. 2013. Dependency-
based decipherment for resource-limited machine
translation. In Proceedings of the 2013 Conference
on Empirical Methods in Natural Language Process-
ing. Association for Computational Linguistics.
Pascale Fung and Lo Yuen Yee. 1998. An IR approach
for translating new words from nonparallel, compa-
rable texts. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Computa-
tional Linguistics - Volume 1. Association for Com-
putational Linguistics.
Kuzman Ganchev, Jennifer Gillenwater, and Ben
Taskar. 2009. Dependency grammar induction via
bitext projection constraints. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 1 - Volume 1. Association for Computational
Linguistics.
Nikesh Garera, Chris Callison-Burch, and David
Yarowsky. 2009. Improving translation lexicon in-
duction from monolingual corpora via dependency
contexts and part-of-speech equivalences. In Pro-
ceedings of the Thirteenth Conference on Computa-
tional Natural Language Learning. Association for
Computational Linguistics.
Dan Garrette, Jason Mielens, and Jason Baldridge.
2013. Real-world semi-supervised learning of pos-
taggers for low-resource languages. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers). Association for Computational Linguistics.
Stuart Geman and Donald Geman. 1987. Stochas-
tic relaxation, Gibbs distributions, and the Bayesian
restoration of images. In Readings in computer vi-
sion: issues, problems, principles, and paradigms.
Morgan Kaufmann Publishers Inc.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In Proceedings of ACL-
08: HLT. Association for Computational Linguis-
tics.
Ann Irvine and Chris Callison-Burch. 2013a. Com-
bining bilingual and comparable corpora for low re-
source machine translation. In Proceedings of the
Eighth Workshop on Statistical Machine Transla-
tion. Association for Computational Linguistics, Au-
gust.
Ann Irvine and Chris Callison-Burch. 2013b. Su-
pervised bilingual lexicon induction with multiple
monolingual signals. In Proceedings of the 2013
</bodyText>
<page confidence="0.994314">
564
</page>
<reference confidence="0.999504925925926">
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies. Association for Computa-
tional Linguistics.
Ann Irvine, Chris Quirk, and Hal Daume III. 2013.
Monolingual marginal matching for translation
model adaptation. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing. Association for Computational Linguistics.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L¨u.
2008. A cascaded linear model for joint Chinese
word segmentation and part-of-speech tagging. In
Proceedings ofACL-08: HLT. Association for Com-
putational Linguistics.
Alexandre Klementiev, Ann Irvine, Chris Callison-
Burch, and David Yarowsky. 2012. Toward statisti-
cal machine translation without parallel corpora. In
Proceedings of the 13th Conference of the European
Chapter of the Association for Computational Lin-
guistics. Association for Computational Linguistics.
Kevin Knight, Anish Nair, Nishit Rathod, and Kenji
Yamada. 2006. Unsupervised analysis for decipher-
ment problems. In Proceedings of the COLING/ACL
2006 Main Conference Poster Sessions. Association
for Computational Linguistics.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In
Proceedings of the ACL-02 Workshop on Unsuper-
vised Lexical Acquisition. Association for Computa-
tional Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions.
Association for Computational Linguistics.
Patrik Lambert, Adri´a De Gispert, Rafael Banchs, and
Jos´e B. Mari˜no. 2005. Guidelines for word align-
ment evaluation and manual alignment. Language
Resources and Evaluation, 39(4):267–285.
Mitchell Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2).
Andre Martins, Miguel Almeida, and Noah A. Smith.
2013. Turning on the Turbo: Fast third-order non-
projective Turbo parsers. In Proceedings of the 51st
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 2: Short Papers). Asso-
ciation for Computational Linguistics.
Radford Neal. 2000. Slice sampling. Annals of Statis-
tics, 31.
Malte Nuhn, Arne Mauser, and Hermann Ney. 2012.
Deciphering foreign language by combining lan-
guage models and context vectors. In Proceedings
of the 50th Annual Meeting of the Association for
Computational Linguistics: Long Papers - Volume
1. Association for Computational Linguistics.
Malte Nuhn, Julian Schamper, and Hermann Ney.
2013. Beam search for solving substitution ciphers.
In Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics. Associ-
ation for Computational Linguistics.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of Association for Compu-
tational Linguistics. Association for Computational
Linguistics.
Reinhard Rapp. 1995. Identifying word translations
in non-parallel texts. In Proceedings of the 33rd an-
nual meeting of Association for Computational Lin-
guistics. Association for Computational Linguistics.
Sujith Ravi and Kevin Knight. 2011. Deciphering for-
eign language. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies. Associa-
tion for Computational Linguistics.
Sujith Ravi. 2013. Scalable decipherment for machine
translation via hash sampling. In Proceedings of the
51th Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics.
Ashish Vaswani, Liang Huang, and David Chiang.
2012. Smaller alignment models for better trans-
lations: Unsupervised word alignment with the l0-
norm. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics: Long
Papers - Volume 1. Association for Computational
Linguistics.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical
translation. In Proceedings of the 16th Conference
on Computational Linguistics - Volume 2. Associa-
tion for Computational Linguistics.
David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual POS taggers and NP bracketers via robust
projection across aligned corpora. In Proceedings
of the Second Meeting of the North American Chap-
ter of the Association for Computational Linguistics
on Language Technologies. Association for Compu-
tational Linguistics.
Yue Zhang and Stephen Clark. 2008. Joint word seg-
mentation and POS tagging using a single percep-
tron. In Proceedings of ACL-08: HLT, Columbus,
Ohio. Association for Computational Linguistics.
</reference>
<page confidence="0.99849">
565
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.931117">
<title confidence="0.998594">Beyond Parallel Data: Joint Word Alignment and Improves Machine Translation</title>
<author confidence="0.951998">Ashish Vaswani</author>
<author confidence="0.951998">Kevin</author>
<affiliation confidence="0.992885666666667">Information Sciences Department of Computer University of Southern</affiliation>
<abstract confidence="0.998835461538462">Inspired by previous work, where decipherment is used to improve machine translation, we propose a new idea to combine word alignment and decipherment into a single learning process. We use EM to estimate the model parameters, not only to maximize the probability of parallel corpus, but also the monolingual corpus. We apply our approach to improve Malagasy-English machine translation, where only a small amount of parallel data is available. In our experiments, we observe gains of to B over a strong baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.</title>
<marker></marker>
<rawString>Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Irvine</author>
<author>Chris Quirk</author>
<author>Hal Daume</author>
</authors>
<title>Monolingual marginal matching for translation model adaptation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2645" citStr="Irvine et al., 2013" startWordPosition="426" endWordPosition="429"> induce new word level translations from non parallel data. Motivated by the idea that a translation lexicon induced from non parallel data can be used to translate out of vocabulary words (OOV), a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera Figure 1: Combine word alignment and decipherment into a single learning process. et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a; Irvine et al., 2013). Lately, there has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013). Decipherment views one language as a cipher for another and learns a translation lexicon that produces fluent text in the target (plaintext) language. Previous work has shown that decipherment not only helps find translations for OOVs (Dou and Knight, 2012), but also improves translations of observed words (Dou and Knight, 2013). We find that previous work using monolingual or co</context>
</contexts>
<marker>Irvine, Quirk, Daume, 2013</marker>
<rawString>Ann Irvine, Chris Quirk, and Hal Daume III. 2013. Monolingual marginal matching for translation model adaptation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
<author>Yajuan L¨u</author>
</authors>
<title>A cascaded linear model for joint Chinese word segmentation and part-of-speech tagging.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08: HLT. Association for Computational Linguistics.</booktitle>
<marker>Jiang, Huang, Liu, L¨u, 2008</marker>
<rawString>Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L¨u. 2008. A cascaded linear model for joint Chinese word segmentation and part-of-speech tagging. In Proceedings ofACL-08: HLT. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ann Irvine</author>
<author>Chris CallisonBurch</author>
<author>David Yarowsky</author>
</authors>
<title>Toward statistical machine translation without parallel corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1677" citStr="Klementiev et al. (2012)" startWordPosition="262" endWordPosition="265">for many languages and domains, there is not enough parallel data to train a decent quality MT system. However, compared with parallel data, there are much larger amounts of non parallel data. The ability to learn a translation lexicon or even build a machine translation system using monolingual data helps address the problems of insufficient parallel data. Ravi and Knight (2011) are among the first to learn a full MT system using only non parallel data through decipherment. However, the performance of such systems is much lower compared with those trained with parallel data. In another work, Klementiev et al. (2012) show that, given a phrase table, it is possible to estimate parameters for a phrase-based MT system from non parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel data by using additional non parallel data. Rapp (1995) shows that with a seed lexicon, it is possible to induce new word level translations from non parallel data. Motivated by the idea that a translation lexicon induced from non parallel data can be used to translate out of vocabulary words (OOV), a variety of prior research has tried to build a transla</context>
</contexts>
<marker>Klementiev, Irvine, CallisonBurch, Yarowsky, 2012</marker>
<rawString>Alexandre Klementiev, Ann Irvine, Chris CallisonBurch, and David Yarowsky. 2012. Toward statistical machine translation without parallel corpora. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Anish Nair</author>
<author>Nishit Rathod</author>
<author>Kenji Yamada</author>
</authors>
<title>Unsupervised analysis for decipherment problems.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7752" citStr="Knight et al. (2006)" startWordPosition="1305" endWordPosition="1308">int = M log P(Fm |Em) + α N log P(Fnmono) (1) We typically use the EM algorithm (Dempster et al., Z Z 1977), to carry out this optimization. m=1 n=1 The goal of training is to learn the parameters that maximize this objective, that is θ* = arg max Fjoint (2) θ In the next two sections, we describe the word alignment and decipherment models, and present how they are combined to perform joint optimization. 2.3 Decipherment Given a corpus of N foreign text sequences (ciphertext), F1mono, ... , Fnmono, . . . , FNmono, decipherment finds word-to-word translations that best describe the ciphertext. Knight et al. (2006) are the first to study several natural language decipherment problems with unsupervised learning. Since then, there has been increasing interest in improving decipherment techniques and its application to machine translation (Ravi and Knight, 2011; 558 Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013; Nuhn et al., 2013). In order to speed up decipherment, Dou and Knight (2012) suggest that a frequency list of bigrams might contain enough information for decipherment. According to them, a monolingual ciphertext bigram Fmono is generated through the following generative story: • Ge</context>
<context position="8978" citStr="Knight et al., 2006" startWordPosition="1509" endWordPosition="1512"> a sequence of two plaintext tokens e1e2 with probability P(e1e2) given by a language model built from large numbers of plaintext bigrams. • Substitute e1 with f1 and e2 with f2 with probability t(f1|e1) · t(f2|e2). The probability of any cipher bigram F is: �P(Fmono) = P(e1e2) · t(f1|e1) · t(f2|e2) (4) e1e2 And the probability of the corpus is: N P(corpus) = H P(Fn mono) (5) Figure 2: Joint Word Alignment and Decipherment n=1 with EM Given a plaintext bigram language model, the goal is to manipulate t(f |e) to maximize P(corpus). Theoretically, one can directly apply EM to solve the problem (Knight et al., 2006). However, EM has time complexity O(N·V2e) and space complexity O(Vf ·Ve), where Vf, Ve are the sizes of ciphertext and plaintext vocabularies respectively, and N is the number of cipher bigrams. There have been previous attempts to make decipherment faster. Ravi and Knight (2011) apply Bayesian learning to reduce the space complexity. However, Bayesian decipherment is still very slow with Gibbs sampling (Geman and Geman, 1987). Dou and Knight (2012) make sampling faster by introducing slice sampling (Neal, 2000) to Bayesian decipherment. Besides Bayesian decipherment, Nuhn et al. (2013) show </context>
</contexts>
<marker>Knight, Nair, Rathod, Yamada, 2006</marker>
<rawString>Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Yamada. 2006. Unsupervised analysis for decipherment problems. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2370" citStr="Koehn and Knight, 2002" startWordPosition="385" endWordPosition="388"> for a phrase-based MT system from non parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel data by using additional non parallel data. Rapp (1995) shows that with a seed lexicon, it is possible to induce new word level translations from non parallel data. Motivated by the idea that a translation lexicon induced from non parallel data can be used to translate out of vocabulary words (OOV), a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera Figure 1: Combine word alignment and decipherment into a single learning process. et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a; Irvine et al., 2013). Lately, there has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013). Decipherment views one language as a cipher for another and learns a translation lexicon that produces flue</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondˇrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions. Association for Computational Linguistics.</booktitle>
<location>Alexandra</location>
<contexts>
<context position="24883" citStr="Koehn et al., 2007" startWordPosition="4218" endWordPosition="4221"> on information from dictionaries3 and the English translation of the parsed sentence. We spent 3 months to manually project English dependencies to Malagasy and eventually improve test set parsing accuracy from 72.4% to 80.0%. We also make this data available for future research use. 4.4 Machine Translation Experiments In this section, we present the data used for our MT experiments, and compare three different systems to justify our joint word alignment and decipherment approach. 4.4.1 Baseline Machine Translation System We build a state-of-the-art phrase-based MT system, PBMT, using Moses (Koehn et al., 2007). PBMT has 3 models: a translation model, a distortion model, and a language model. We train the other models using half of the Global Voices parallel data (the rest is reserved for development and testing), and build a 5- gram language model using 834 million tokens from AFP section of English Gigaword, 396 million tokens from allAfrica, and the English part of the parallel corpus for training. For alignment, we run 10 iterations of Model 1, and 5 iterations of HMM. We did not run Model 3 and Model 4 as we see no improvements in B scores from running those models. We do word 3an online dictio</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrik Lambert</author>
<author>Adri´a De Gispert</author>
<author>Rafael Banchs</author>
<author>Jos´e B Mari˜no</author>
</authors>
<title>Guidelines for word alignment evaluation and manual alignment.</title>
<date>2005</date>
<journal>Language Resources and Evaluation,</journal>
<volume>39</volume>
<issue>4</issue>
<marker>Lambert, De Gispert, Banchs, Mari˜no, 2005</marker>
<rawString>Patrik Lambert, Adri´a De Gispert, Rafael Banchs, and Jos´e B. Mari˜no. 2005. Guidelines for word alignment evaluation and manual alignment. Language Resources and Evaluation, 39(4):267–285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="21805" citStr="Marcus et al., 1993" startWordPosition="3715" endWordPosition="3718">unt of information related to Africa. Therefore, we also collect 396 million tokens of African news in English from allAfrica.com. 4.3 Building A Dependency Parser for Malagasy Since Malagasy and English have very different word orders, we decide to apply dependency based decipherment for the two languages as suggested by Dou and Knight (2013). To extract dependency relations, we need to parse monolingual data in Malagasy and English. For English, there are already many good parsers available. In our experiments, we use Turbo parser (Martins et al., 2013) trained on the English Penn Treebank (Marcus et al., 1993) to parse all our English monolingual data. However, there is no existing good parser for Malagasy. The quality of a dependency parser depends on the amount of training data available. State-of-the-art English parsers are built from Penn Treebank, which contains over 1 million tokens of annotated syntactical 1globalvoicesonline.org 2aoraha.com, gazetiko.com, inovaovao.com, expressmada.com, lakroa.com 561 Figure 3: Learning curve showing our joint word alignment and decipherment approach improves word alignment quality over the traditional EM without decipherment (Model 1: Iteration 1 to 10, HM</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Miguel Almeida</author>
<author>Noah A Smith</author>
</authors>
<title>Turning on the Turbo: Fast third-order nonprojective Turbo parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</booktitle>
<volume>2</volume>
<institution>Short Papers). Association for Computational Linguistics.</institution>
<contexts>
<context position="21746" citStr="Martins et al., 2013" startWordPosition="3704" endWordPosition="3707"> reasonable to argue that those data contain significant amount of information related to Africa. Therefore, we also collect 396 million tokens of African news in English from allAfrica.com. 4.3 Building A Dependency Parser for Malagasy Since Malagasy and English have very different word orders, we decide to apply dependency based decipherment for the two languages as suggested by Dou and Knight (2013). To extract dependency relations, we need to parse monolingual data in Malagasy and English. For English, there are already many good parsers available. In our experiments, we use Turbo parser (Martins et al., 2013) trained on the English Penn Treebank (Marcus et al., 1993) to parse all our English monolingual data. However, there is no existing good parser for Malagasy. The quality of a dependency parser depends on the amount of training data available. State-of-the-art English parsers are built from Penn Treebank, which contains over 1 million tokens of annotated syntactical 1globalvoicesonline.org 2aoraha.com, gazetiko.com, inovaovao.com, expressmada.com, lakroa.com 561 Figure 3: Learning curve showing our joint word alignment and decipherment approach improves word alignment quality over the traditio</context>
</contexts>
<marker>Martins, Almeida, Smith, 2013</marker>
<rawString>Andre Martins, Miguel Almeida, and Noah A. Smith. 2013. Turning on the Turbo: Fast third-order nonprojective Turbo parsers. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford Neal</author>
</authors>
<title>Slice sampling.</title>
<date>2000</date>
<journal>Annals of Statistics,</journal>
<volume>31</volume>
<contexts>
<context position="9496" citStr="Neal, 2000" startWordPosition="1593" endWordPosition="1594">(corpus). Theoretically, one can directly apply EM to solve the problem (Knight et al., 2006). However, EM has time complexity O(N·V2e) and space complexity O(Vf ·Ve), where Vf, Ve are the sizes of ciphertext and plaintext vocabularies respectively, and N is the number of cipher bigrams. There have been previous attempts to make decipherment faster. Ravi and Knight (2011) apply Bayesian learning to reduce the space complexity. However, Bayesian decipherment is still very slow with Gibbs sampling (Geman and Geman, 1987). Dou and Knight (2012) make sampling faster by introducing slice sampling (Neal, 2000) to Bayesian decipherment. Besides Bayesian decipherment, Nuhn et al. (2013) show that beam search can be used to solve a very large 1:1 word substitution cipher. In subsection 2.4.1, we describe our approach that uses slice sampling to compute expected counts for decipherment in the EM algorithm. 2.4 Joint Optimization We now describe our EM approach to learn the parameters that maximize Fjoint (equation 2), where the distortion probabilities, d(aj |aj−1, j) in the word alignment model are only learned from parallel data, and the translation probabilities, t(f |e) are learned using both paral</context>
<context position="11348" citStr="Neal, 2000" startWordPosition="1909" endWordPosition="1910">rithm (Vogel et al., 1996). However, as we pointed out in Section 2.3, the E step for the non parallel part has a time complexity of O(V2) with the forward-backward algorithm, where V is the size of English vocabulary, and is usually very large. Previous work has tried to make decipherment scalable (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2013; Ravi, 2013). However, all of them are designed for decipherment with either Bayesian inference or beam search. In contrast, we need an algorithm to make EM decipherment scalable. To overcome this problem, we modify the slice sampling (Neal, 2000) approach used by Dou and Knight (2012) to compute expected counts from non parallel data needed for the EM algorithm. 2.4.1 Draw Samples with Slice Sampling To start the sampling process, we initialize the first sample by performing approximate Viterbi decoding using results from the last EM iteration. For each foreign dependency bigram f1, f2, we find the top 50 candidates for f1 and f2 ranked by t(e |f ), and find the English sequence e1, e2 that maximizes t(e1|f1) · t(e2|f2) · P(e1, e2). Suppose the derivation probability for current sample e current is P(e current), we use slice sampling </context>
</contexts>
<marker>Neal, 2000</marker>
<rawString>Radford Neal. 2000. Slice sampling. Annals of Statistics, 31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malte Nuhn</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Deciphering foreign language by combining language models and context vectors.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association</booktitle>
<contexts>
<context position="2838" citStr="Nuhn et al., 2012" startWordPosition="457" endWordPosition="460">a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera Figure 1: Combine word alignment and decipherment into a single learning process. et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a; Irvine et al., 2013). Lately, there has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013). Decipherment views one language as a cipher for another and learns a translation lexicon that produces fluent text in the target (plaintext) language. Previous work has shown that decipherment not only helps find translations for OOVs (Dou and Knight, 2012), but also improves translations of observed words (Dou and Knight, 2013). We find that previous work using monolingual or comparable data to improve quality of machine translation separates two learning tasks: first, translation rules are learned from parallel data, and then the information learned from parallel dat</context>
<context position="8045" citStr="Nuhn et al., 2012" startWordPosition="1350" endWordPosition="1353">be the word alignment and decipherment models, and present how they are combined to perform joint optimization. 2.3 Decipherment Given a corpus of N foreign text sequences (ciphertext), F1mono, ... , Fnmono, . . . , FNmono, decipherment finds word-to-word translations that best describe the ciphertext. Knight et al. (2006) are the first to study several natural language decipherment problems with unsupervised learning. Since then, there has been increasing interest in improving decipherment techniques and its application to machine translation (Ravi and Knight, 2011; 558 Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013; Nuhn et al., 2013). In order to speed up decipherment, Dou and Knight (2012) suggest that a frequency list of bigrams might contain enough information for decipherment. According to them, a monolingual ciphertext bigram Fmono is generated through the following generative story: • Generate a sequence of two plaintext tokens e1e2 with probability P(e1e2) given by a language model built from large numbers of plaintext bigrams. • Substitute e1 with f1 and e2 with f2 with probability t(f1|e1) · t(f2|e2). The probability of any cipher bigram F is: �P(Fmono) = P(e1e2) · t(f1|e</context>
</contexts>
<marker>Nuhn, Mauser, Ney, 2012</marker>
<rawString>Malte Nuhn, Arne Mauser, and Hermann Ney. 2012. Deciphering foreign language by combining language models and context vectors. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malte Nuhn</author>
<author>Julian Schamper</author>
<author>Hermann Ney</author>
</authors>
<title>Beam search for solving substitution ciphers.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8087" citStr="Nuhn et al., 2013" startWordPosition="1358" endWordPosition="1361">dels, and present how they are combined to perform joint optimization. 2.3 Decipherment Given a corpus of N foreign text sequences (ciphertext), F1mono, ... , Fnmono, . . . , FNmono, decipherment finds word-to-word translations that best describe the ciphertext. Knight et al. (2006) are the first to study several natural language decipherment problems with unsupervised learning. Since then, there has been increasing interest in improving decipherment techniques and its application to machine translation (Ravi and Knight, 2011; 558 Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013; Nuhn et al., 2013). In order to speed up decipherment, Dou and Knight (2012) suggest that a frequency list of bigrams might contain enough information for decipherment. According to them, a monolingual ciphertext bigram Fmono is generated through the following generative story: • Generate a sequence of two plaintext tokens e1e2 with probability P(e1e2) given by a language model built from large numbers of plaintext bigrams. • Substitute e1 with f1 and e2 with f2 with probability t(f1|e1) · t(f2|e2). The probability of any cipher bigram F is: �P(Fmono) = P(e1e2) · t(f1|e1) · t(f2|e2) (4) e1e2 And the probability</context>
<context position="9572" citStr="Nuhn et al. (2013)" startWordPosition="1601" endWordPosition="1604">em (Knight et al., 2006). However, EM has time complexity O(N·V2e) and space complexity O(Vf ·Ve), where Vf, Ve are the sizes of ciphertext and plaintext vocabularies respectively, and N is the number of cipher bigrams. There have been previous attempts to make decipherment faster. Ravi and Knight (2011) apply Bayesian learning to reduce the space complexity. However, Bayesian decipherment is still very slow with Gibbs sampling (Geman and Geman, 1987). Dou and Knight (2012) make sampling faster by introducing slice sampling (Neal, 2000) to Bayesian decipherment. Besides Bayesian decipherment, Nuhn et al. (2013) show that beam search can be used to solve a very large 1:1 word substitution cipher. In subsection 2.4.1, we describe our approach that uses slice sampling to compute expected counts for decipherment in the EM algorithm. 2.4 Joint Optimization We now describe our EM approach to learn the parameters that maximize Fjoint (equation 2), where the distortion probabilities, d(aj |aj−1, j) in the word alignment model are only learned from parallel data, and the translation probabilities, t(f |e) are learned using both parallel and non parallel data. The E step and M step are illustrated in Figure 2</context>
<context position="11100" citStr="Nuhn et al., 2013" startWordPosition="1865" endWordPosition="1868"> parallel data together with different weights for the two. Finally we renormalize the translation table and distortion table to update parameters in the new M step. The E step for parallel part can be computed efficiently using the forward-backward algorithm (Vogel et al., 1996). However, as we pointed out in Section 2.3, the E step for the non parallel part has a time complexity of O(V2) with the forward-backward algorithm, where V is the size of English vocabulary, and is usually very large. Previous work has tried to make decipherment scalable (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2013; Ravi, 2013). However, all of them are designed for decipherment with either Bayesian inference or beam search. In contrast, we need an algorithm to make EM decipherment scalable. To overcome this problem, we modify the slice sampling (Neal, 2000) approach used by Dou and Knight (2012) to compute expected counts from non parallel data needed for the EM algorithm. 2.4.1 Draw Samples with Slice Sampling To start the sampling process, we initialize the first sample by performing approximate Viterbi decoding using results from the last EM iteration. For each foreign dependency bigram f1, f2, we f</context>
</contexts>
<marker>Nuhn, Schamper, Ney, 2013</marker>
<rawString>Malte Nuhn, Julian Schamper, and Hermann Ney. 2013. Beam search for solving substitution ciphers. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26020" citStr="Och, 2003" startWordPosition="4414" endWordPosition="4415">ments in B scores from running those models. We do word 3an online dictionary from malagasyword.org, as well as a lexicon learned from the parallel data 562 alignment in two directions and use grow-diag-finaland heuristic to obtain final alignment. During decoding, we use 8 standard features in Moses to score a candidate translation: direct and inverse translation probabilities, direct and inverse lexical weighting, a language model score, a distortion score, phrase penalty, and word penalty. The weights for the features are learned on the tuning data using minimum error rate training (MERT) (Och, 2003). To compare with previous decipherment approach to improve machine translation, we build a second baseline system. We follow the work by Dou and Knight (2013) to decipher Malagasy into English, and build a translation lexicon Tdecipher from decipherment. To improve machine translation, we simply use Tdecipher as an additional parallel corpus. First, we filter Tdecipher by keeping only translation pairs (f, e), where f is observed in the Spanish part and e is observed in the English part of the parallel corpus. Then we append all the Spanish and English words in the filtered Tdecipher to the e</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Identifying word translations in non-parallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd annual meeting of Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1975" citStr="Rapp (1995)" startWordPosition="315" endWordPosition="316">ress the problems of insufficient parallel data. Ravi and Knight (2011) are among the first to learn a full MT system using only non parallel data through decipherment. However, the performance of such systems is much lower compared with those trained with parallel data. In another work, Klementiev et al. (2012) show that, given a phrase table, it is possible to estimate parameters for a phrase-based MT system from non parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel data by using additional non parallel data. Rapp (1995) shows that with a seed lexicon, it is possible to induce new word level translations from non parallel data. Motivated by the idea that a translation lexicon induced from non parallel data can be used to translate out of vocabulary words (OOV), a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera Figure 1: Combine word alignment and decipherment into a single learning process. et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Calliso</context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Reinhard Rapp. 1995. Identifying word translations in non-parallel texts. In Proceedings of the 33rd annual meeting of Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Deciphering foreign language.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<contexts>
<context position="1435" citStr="Ravi and Knight (2011)" startWordPosition="220" endWordPosition="223">f-the-art machine translation (MT) systems apply statistical techniques to learn translation rules automatically from parallel data. However, this reliance on parallel data seriously limits the scope of MT application in the real world, as for many languages and domains, there is not enough parallel data to train a decent quality MT system. However, compared with parallel data, there are much larger amounts of non parallel data. The ability to learn a translation lexicon or even build a machine translation system using monolingual data helps address the problems of insufficient parallel data. Ravi and Knight (2011) are among the first to learn a full MT system using only non parallel data through decipherment. However, the performance of such systems is much lower compared with those trained with parallel data. In another work, Klementiev et al. (2012) show that, given a phrase table, it is possible to estimate parameters for a phrase-based MT system from non parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel data by using additional non parallel data. Rapp (1995) shows that with a seed lexicon, it is possible to induce ne</context>
<context position="2797" citStr="Ravi and Knight, 2011" startWordPosition="449" endWordPosition="452"> to translate out of vocabulary words (OOV), a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera Figure 1: Combine word alignment and decipherment into a single learning process. et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a; Irvine et al., 2013). Lately, there has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013). Decipherment views one language as a cipher for another and learns a translation lexicon that produces fluent text in the target (plaintext) language. Previous work has shown that decipherment not only helps find translations for OOVs (Dou and Knight, 2012), but also improves translations of observed words (Dou and Knight, 2013). We find that previous work using monolingual or comparable data to improve quality of machine translation separates two learning tasks: first, translation rules are learned from parallel data, and then </context>
<context position="8000" citStr="Ravi and Knight, 2011" startWordPosition="1341" endWordPosition="1344"> Fjoint (2) θ In the next two sections, we describe the word alignment and decipherment models, and present how they are combined to perform joint optimization. 2.3 Decipherment Given a corpus of N foreign text sequences (ciphertext), F1mono, ... , Fnmono, . . . , FNmono, decipherment finds word-to-word translations that best describe the ciphertext. Knight et al. (2006) are the first to study several natural language decipherment problems with unsupervised learning. Since then, there has been increasing interest in improving decipherment techniques and its application to machine translation (Ravi and Knight, 2011; 558 Dou and Knight, 2012; Nuhn et al., 2012; Dou and Knight, 2013; Nuhn et al., 2013). In order to speed up decipherment, Dou and Knight (2012) suggest that a frequency list of bigrams might contain enough information for decipherment. According to them, a monolingual ciphertext bigram Fmono is generated through the following generative story: • Generate a sequence of two plaintext tokens e1e2 with probability P(e1e2) given by a language model built from large numbers of plaintext bigrams. • Substitute e1 with f1 and e2 with f2 with probability t(f1|e1) · t(f2|e2). The probability of any cip</context>
<context position="9259" citStr="Ravi and Knight (2011)" startWordPosition="1555" endWordPosition="1558">· t(f1|e1) · t(f2|e2) (4) e1e2 And the probability of the corpus is: N P(corpus) = H P(Fn mono) (5) Figure 2: Joint Word Alignment and Decipherment n=1 with EM Given a plaintext bigram language model, the goal is to manipulate t(f |e) to maximize P(corpus). Theoretically, one can directly apply EM to solve the problem (Knight et al., 2006). However, EM has time complexity O(N·V2e) and space complexity O(Vf ·Ve), where Vf, Ve are the sizes of ciphertext and plaintext vocabularies respectively, and N is the number of cipher bigrams. There have been previous attempts to make decipherment faster. Ravi and Knight (2011) apply Bayesian learning to reduce the space complexity. However, Bayesian decipherment is still very slow with Gibbs sampling (Geman and Geman, 1987). Dou and Knight (2012) make sampling faster by introducing slice sampling (Neal, 2000) to Bayesian decipherment. Besides Bayesian decipherment, Nuhn et al. (2013) show that beam search can be used to solve a very large 1:1 word substitution cipher. In subsection 2.4.1, we describe our approach that uses slice sampling to compute expected counts for decipherment in the EM algorithm. 2.4 Joint Optimization We now describe our EM approach to learn </context>
<context position="11059" citStr="Ravi and Knight, 2011" startWordPosition="1857" endWordPosition="1860">pected counts from both parallel data and non parallel data together with different weights for the two. Finally we renormalize the translation table and distortion table to update parameters in the new M step. The E step for parallel part can be computed efficiently using the forward-backward algorithm (Vogel et al., 1996). However, as we pointed out in Section 2.3, the E step for the non parallel part has a time complexity of O(V2) with the forward-backward algorithm, where V is the size of English vocabulary, and is usually very large. Previous work has tried to make decipherment scalable (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2013; Ravi, 2013). However, all of them are designed for decipherment with either Bayesian inference or beam search. In contrast, we need an algorithm to make EM decipherment scalable. To overcome this problem, we modify the slice sampling (Neal, 2000) approach used by Dou and Knight (2012) to compute expected counts from non parallel data needed for the EM algorithm. 2.4.1 Draw Samples with Slice Sampling To start the sampling process, we initialize the first sample by performing approximate Viterbi decoding using results from the last EM iteration. For ea</context>
</contexts>
<marker>Ravi, Knight, 2011</marker>
<rawString>Sujith Ravi and Kevin Knight. 2011. Deciphering foreign language. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
</authors>
<title>Scalable decipherment for machine translation via hash sampling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="11113" citStr="Ravi, 2013" startWordPosition="1869" endWordPosition="1870">ther with different weights for the two. Finally we renormalize the translation table and distortion table to update parameters in the new M step. The E step for parallel part can be computed efficiently using the forward-backward algorithm (Vogel et al., 1996). However, as we pointed out in Section 2.3, the E step for the non parallel part has a time complexity of O(V2) with the forward-backward algorithm, where V is the size of English vocabulary, and is usually very large. Previous work has tried to make decipherment scalable (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2013; Ravi, 2013). However, all of them are designed for decipherment with either Bayesian inference or beam search. In contrast, we need an algorithm to make EM decipherment scalable. To overcome this problem, we modify the slice sampling (Neal, 2000) approach used by Dou and Knight (2012) to compute expected counts from non parallel data needed for the EM algorithm. 2.4.1 Draw Samples with Slice Sampling To start the sampling process, we initialize the first sample by performing approximate Viterbi decoding using results from the last EM iteration. For each foreign dependency bigram f1, f2, we find the top 5</context>
</contexts>
<marker>Ravi, 2013</marker>
<rawString>Sujith Ravi. 2013. Scalable decipherment for machine translation via hash sampling. In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Vaswani</author>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Smaller alignment models for better translations: Unsupervised word alignment with the l0-norm.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association</booktitle>
<contexts>
<context position="29874" citStr="Vaswani et al., 2012" startWordPosition="5045" endWordPosition="5048"> parser with 72.4% attachment accuracy, while scores outside the brackets are obtained using a dependency parser with 80.0% attachment accuracy. We analyze the results and find the gain mainly comes from two parts. First, adding expected counts from non parallel data makes the distribution of translation probabilities sparser in word alignment models. The probabilities of translation pairs favored by both parallel data and decipherment becomes higher. This gain is consistent with previous observation where a sparse prior is applied to EM to help improve word alignment and machine translation (Vaswani et al., 2012). Second, expected counts from decipherment also help discover new translation pairs in the parallel data for low frequency words, where those words are either aligned to NULL or wrong translations in the baseline. 5 Conclusion and Future Work We propose a new objective function for word alignment to combine the process of word alignment and decipherment into a single task. In, experiments, we find that the joint process performs better than previous pipeline approach, and observe B gains of 0.9 and 2.1 point on Global Voices and local web news test sets, respectively. Finally, our research le</context>
</contexts>
<marker>Vaswani, Huang, Chiang, 2012</marker>
<rawString>Ashish Vaswani, Liang Huang, and David Chiang. 2012. Smaller alignment models for better translations: Unsupervised word alignment with the l0-norm. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th Conference on Computational Linguistics - Volume 2. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6003" citStr="Vogel et al., 1996" startWordPosition="984" endWordPosition="987">earning processes into account. Given our parallel data, (E1, F1), ... , (Em, Fm), ... , (EM, FM), and monolingual data F1mono, ... , Fnmono, . . . , FNmono, we seek to maximize the likelihood of both. Our new objective function is defined as: 2.2 Word Alignment Given a source sentence F = f1,. . . , fj,...,fJ and a target sentence E = e1,... , ei, ... , eI, word alignment models describe the generative process employed to produce the French sentence from the English sentence through alignments a = a1,..., aj, ... , aJ. The IBM models 1-2 (Brown et al., 1993) and the HMM word alignment model (Vogel et al., 1996) use two sets of parameters, distortion probabilities and translation probabilities, to define the joint probability of a target sentence and alignment given a source sentence. d(aj |aj−1, j)t(fj |eaj). (3) These alignment models share the same translation probabilities t(fj |eaj), but differ in their treatment of the distortion probabilities d(aj |aj−1, j). Brown et al. (1993) introduce more advanced models for word alignment, such as Model 3 and Model 4, which use more parameters to describe the generative process. We do not go into details of those models here and the reader is referred to </context>
<context position="10763" citStr="Vogel et al., 1996" startWordPosition="1803" endWordPosition="1806"> are illustrated in Figure 2. Our algorithm starts with EM learning only on parallel data for a few iterations. When the joint inference starts, we first compute expected counts from parallel data and non parallel data using parameter values from the last M step separately. Then, we add the expected counts from both parallel data and non parallel data together with different weights for the two. Finally we renormalize the translation table and distortion table to update parameters in the new M step. The E step for parallel part can be computed efficiently using the forward-backward algorithm (Vogel et al., 1996). However, as we pointed out in Section 2.3, the E step for the non parallel part has a time complexity of O(V2) with the forward-backward algorithm, where V is the size of English vocabulary, and is usually very large. Previous work has tried to make decipherment scalable (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2013; Ravi, 2013). However, all of them are designed for decipherment with either Bayesian inference or beam search. In contrast, we need an algorithm to make EM decipherment scalable. To overcome this problem, we modify the slice sampling (Neal, 2000) approach used </context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of the 16th Conference on Computational Linguistics - Volume 2. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="23898" citStr="Yarowsky and Ngai, 2001" startWordPosition="4059" endWordPosition="4062">nary is very helpful for tagging words never seen in the training data. It is natural to think that creation of annotated data for training a POS tagger and a parser requires large amounts of efforts from annotators who understand the language well. However, we find that through the help of parallel data and dictionaries, we are able to create more annotated data by ourselves to improve tagging and parsing accuracy. This idea is inspired by previous work that tries to learn a semi-supervised parser by projecting dependency relations from one language (with good dependency parsers) to another (Yarowsky and Ngai, 2001; Ganchev et al., 2009). However, we find those automatic approaches do not work well for Malagasy. To further expand our Malagasy training data, we first use a POS tagger and parser with poor performance to parse 788 sentences (20k tokens) on the Malagasy side of the parallel corpus from Global Voices. Then, we correct both the dependency links and POS tags based on information from dictionaries3 and the English translation of the parsed sentence. We spent 3 months to manually project English dependencies to Malagasy and eventually improve test set parsing accuracy from 72.4% to 80.0%. We als</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Joint word segmentation and POS tagging using a single perceptron.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio.</location>
<contexts>
<context position="4973" citStr="Zhang and Clark, 2008" startWordPosition="801" endWordPosition="804">cy tree bank containing 20k tokens. 2 Joint Word Alignment and Decipherment 2.1 A New Objective Function In previous work that uses monolingual data to improve machine translation, a seed translation lexicon learned from parallel data is used to find new translations through either word vector based approaches or decipherment. In return, selection of a seed lexicon needs to be careful as using a poor quality seed lexicon could hurt the downstream process. Evidence from a number of previous work shows that a joint inference process leads to better performance in both tasks (Jiang et al., 2008; Zhang and Clark, 2008). In the presence of parallel and monolingual data, we would like the alignment and decipherment models to benefit from each other. Since the decipherment and word alignment models contain word-to-word translation probabilities t(f |e), having them share these parameters during learning will allow us to pool information from both data types. This leads us to develop a new objective function that takes both learning processes into account. Given our parallel data, (E1, F1), ... , (Em, Fm), ... , (EM, FM), and monolingual data F1mono, ... , Fnmono, . . . , FNmono, we seek to maximize the likelih</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. Joint word segmentation and POS tagging using a single perceptron. In Proceedings of ACL-08: HLT, Columbus, Ohio. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>