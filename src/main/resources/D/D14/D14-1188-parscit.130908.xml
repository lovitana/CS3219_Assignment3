<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003453">
<title confidence="0.9972025">
Comparing Representations of Semantic Roles for
String-To-Tree Decoding
</title>
<author confidence="0.993433">
Marzieh Bazrafshan and Daniel Gildea
</author>
<affiliation confidence="0.9978345">
Department of Computer Science
University of Rochester
</affiliation>
<address confidence="0.316073">
Rochester, NY 14627
</address>
<sectionHeader confidence="0.96064" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998968125">
We introduce new features for incorpo-
rating semantic predicate-argument struc-
tures in machine translation (MT). The
methods focus on the completeness of the
semantic structures of the translations, as
well as the order of the translated seman-
tic roles. We experiment with translation
rules which contain the core arguments
for the predicates in the source side of a
MT system, and observe that using these
rules significantly improves the translation
quality. We also present a new semantic
feature that resembles a language model.
Our results show that the language model
feature can also significantly improve MT
results.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980274193548">
In recent years, there have been increasing ef-
forts to incorporate semantics in statistical ma-
chine translation (SMT), and the use of predicate-
argument structures has provided promising im-
provements in translation quality. Wu and Fung
(2009) showed that shallow semantic parsing can
improve the translation quality in a machine trans-
lation system. They introduced a two step model,
in which they used a semantic parser to rerank
the translation hypotheses of a phrase-based sys-
tem. Liu and Gildea (2010) used semantic fea-
tures for a tree-to-string syntax based SMT sys-
tem. Their features modeled deletion and reorder-
ing for source side semantic roles, and they im-
proved the translation quality. Xiong et al. (2012)
incorporated the semantic structures into phrase-
based SMT by adding syntactic and semantic fea-
tures to their translation model. They proposed
two discriminative models which included fea-
tures for predicate translation and argument re-
ordering from source to target side. Bazrafshan
and Gildea (2013) used semantic structures in
a string-to-tree translation system by extracting
translation rules enriched with semantic informa-
tion, and showed that this can improve the trans-
lation quality. Li et al. (2013) used predicate-
argument structure reordering models for hierar-
chical phrase-based translation, and they used lin-
guistically motivated constraints for phrase trans-
lation.
In this paper, we experiment with methods for
incorporating semantics in a string-to-tree MT
system. These methods are designed to model the
order of translation, as well as the completeness
of the semantic structures. We extract translation
rules that include the complete semantic structure
in the source side, and compare that with using
semantic rules for the target side predicates. We
present a method for modeling the order of seman-
tic role sequences that appear spread across multi-
ple syntax-based translation rules, in order to over-
come the problem that a rule representing the en-
tire semantic structure of a predicate is often too
large and too specific to apply to new sentences
during decoding. For this method, we compare the
verb-specific roles of PropBank and the more gen-
eral thematic roles of VerbNet.
These essential arguments of a verbal predicate
are called the core arguments. Standard syntax-
based MT is incapable of ensuring that the tar-
get translation includes all of the core arguments
of a predicate that appear in the source sentence.
To encourage the translation of the likely core ar-
guments, we follow the work of Bazrafshan and
Gildea (2013), who use special translation rules
with complete semantic structures of the predi-
cates in the target side of their MT system. Each
of these rules includes a predicate and all of its
core arguments. Instead of incorporating only the
target side semantic rules, we extract the special
rules for both the source and the target sides, and
compare the effectiveness of adding these rules to
</bodyText>
<page confidence="0.870352">
1786
</page>
<bodyText confidence="0.631192">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1786–1791,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</bodyText>
<equation confidence="0.962303571428571">
S-8
NP-7-ARG1 1 victimized by NP-7-ARG0 2
NP-7-ARG1 1 受 NP-7-ARG0 2
A → BC c0
[B, i, j] c1
[C, j, k] c2
[A, i, k] c0 + c1 + c2
</equation>
<figureCaption confidence="0.99566">
Figure 2: A deduction step in our baseline decoder
Figure 1: A complete semantic rule (Bazrafshan
and Gildea (2013)).
</figureCaption>
<bodyText confidence="0.99622147826087">
the system separately and simultaneously.
Besides the completeness of the arguments, it is
also important for the arguments to appear in the
correct order. Our second method is designed to
encourage correct order of translation for both the
core and the non-core roles in the target sentence.
We designed a new feature that resembles the lan-
guage model feature in a standard MT system. We
train a n-gram language model on sequences of se-
mantic roles, by treating the semantic roles as the
words in what we call the semantic language. Our
experimental results show that the language model
feature significantly improves translation quality.
Semantic Role Labeling (SRL): We use se-
mantic role labelers to annotate the training data
that we use to extract the translation rules. For tar-
get side SRL, the role labels are attached to the
nonterminal nodes in the syntactic parse of each
sentence. For source side SRL, the labels annotate
the spans from the source sentence that they cover.
We train our semantic role labeler using two differ-
ent standards: Propbank (Palmer et al., 2005) and
VerbNet (Kipper Schuler, 2005).
PropBank annotates the Penn Treebank with
predicate-argument structures.It use generic labels
(such as Arg0, Arg1, etc.) which are defined
specifically for each verb. We trained a semantic
role labeler on the annotated Penn Treebank data
and used the classifier to tag our training data.
VerbNet is a verb lexicon that categorizes En-
glish verbs into hierarchical classes, and annotates
them with thematic roles for the arguments that
they accept. Since the thematic roles use more
meaningful labels (e.g. Agent, Patient, etc.), a lan-
guage model trained on VerbNet labels may be
more likely to generalize across verbs than one
trained on PropBank labels. It may also provide
more information, since VerbNet has a larger set
of labels than PropBank. To train the semantic
role labeler on VerbNet, we used the mappings
provided by the SemLink project (Palmer, 2009)
to annotate the Penn Treebank with the VerbNet
roles. These mappings map the roles in PropBank
to the thematic roles of VerbNet. When there is no
mapping for a role, we keep the role from Prop-
bank.
</bodyText>
<sectionHeader confidence="0.836923" genericHeader="method">
2 Using Semantics in Machine
Translation
</sectionHeader>
<bodyText confidence="0.999749666666667">
In this section, we present our techniques for in-
corporating semantics in MT: source side semantic
rules, and the semantic language model.
</bodyText>
<subsectionHeader confidence="0.995599">
2.1 Source Side Semantic Rules
</subsectionHeader>
<bodyText confidence="0.999987066666667">
Bazrafshan and Gildea (2013) extracted transla-
tion rules that included a predicate and all of its
arguments from the target side, and added those
rules to the baseline rules of their string-to-tree
MT system. Figure 1 shows an example of such
rules, which we refer to as complete semantic
rules. The new rules encourage the decoder to
generate translations that include all of the seman-
tic roles that appear in the source sentence.
In this paper, we use the same idea to extract
rules from the semantic structures of the source
side. The complete semantic rules consist of the
smallest fragments of the combination of GHKM
(Galley et al., 2004) rules that include one pred-
icate and all of its core arguments that appear in
the sentence. Rather than keeping the predicate
and argument labels attached to the non-terminals,
we remove those labels from our extracted seman-
tic rules, to keep the non-terminals in the semantic
rules consistent with the non-terminals of the base-
line GHKM rules. This is also important when us-
ing both the source and the target semantic rules
(i.e. Chinese and English rules), as it has been
shown that there are cross lingual mismatches be-
tween Chinese and English semantic roles in bilin-
gual sentences (Fung et al., 2007).
We extract a complete semantic rule for each
verbal predicate of each sentence pair in the train-
ing data. To extract the target side complete se-
mantic rules, using the target side SRL anno-
</bodyText>
<page confidence="0.800575">
1787
</page>
<bodyText confidence="0.552025">
A → BC to space c0 (x1 x2 Destination)
</bodyText>
<equation confidence="0.97633825">
[B, i, j, (Agent,)] c1
[C, j, k, (PRED bring, Theme,)] c2
[A, i, k, (Agent, PRED bring,-*-, Theme, Destination)] c0 + c1 + c+
+ LMcost(Agent, PRED bring,-*-, Theme, Destination)
</equation>
<figureCaption confidence="0.997722">
Figure 3: A deduction step in the semantic language model method.
</figureCaption>
<bodyText confidence="0.999560242424243">
tated training data, we follow the general GHKM
method, and modify it to ensure that each fron-
tier node (Galley et al., 2004) in a rule includes ei-
ther all or none of the semantic role labels (i.e. the
predicate and all of its present core arguments) in
its descendants in the target side tree. The result-
ing rule then includes the predicate and all of its
arguments. We use the source side SRL annotated
training data to extract the source side semantic
rules. Since the annotations specify the spans of
the semantic roles, we extract the semantic rules
by ensuring that the span of the root (in the target
side) of the extracted rule covers all of the spans
of the roles in the predicate-argument structure.
The semantic rules are then used together with
the original GHKM rules. We add a binary feature
to distinguish the semantic rules from the rest. We
experiment with adding the semantic rules from
the source side, and compare that with adding se-
mantic rules of both the source and the target side.
In all of the experiments in this paper, we use
a string-to-tree decoder which uses a CYK style
parser (Yamada and Knight, 2002). Figure 2 de-
picts a deduction step in the baseline decoder. The
CFG rule in the first line is used to generate a
new item A with span (i, k) using items B and
C, which have spans (i, j) and (j, k) respectively.
The cost of each item is shown on the right. For
experimenting with complete semantic rules, in
addition having more rules, the only other modi-
fication made to the baseline system is extending
the feature vector to include the new feature. We
do not modify the decoder in any significant way.
</bodyText>
<subsectionHeader confidence="0.992718">
2.2 Semantic Language Model
</subsectionHeader>
<bodyText confidence="0.999991102040816">
The semantic language model is designed to en-
courage the correct order of translation for the se-
mantic roles. While the complete translation rules
of Section 2.1 contain the order of the translation
for core semantic roles, they do not include the
non-core semantic roles, that is, semantic roles
which are not essential for the verbal predicates,
but do contribute to the meaning of the predicate.
In addition, the semantic LM can help in cases
where no specific complete semantic rule can ap-
ply, which makes the system more flexible.
The semantic language model resembles a reg-
ular language model, but instead of words, it de-
fines a probability distribution over sequences of
semantic roles. For this method we also use a se-
mantic role labeler on our training data, and use
the labeled data to train a tri-gram semantic lan-
guage model.
The rules are extracted using the baseline rule
extraction method. As opposed to the previous
method, the rules for this method are not derived
by combining GHKM rules, but rather are reg-
ular GHKM rules which are annotated with se-
mantic roles. We make a new field in each rule
to keep the ordered list of the semantic roles in
that rule. We also include the nonterminals of the
right-hand-side of the rule in that ordered list, to
be able to substitute the semantic roles from the
input translation items in the correct order. The
decoder uses this new field to save the semantic
roles in the translation items, and propagates the
semantic LM states in the same way that the reg-
ular language model states are propagated by the
decoder.
We define a new feature for the semantic lan-
guage model, and score the semantic states in each
translation item, again analogously to a regular
language model. Figure 3 depicts how the de-
duction for this method is different from our base-
line. In this example, the semantic roles “Agent”,
“PRED bring” and “Theme” come from the input
items, and the role “Destination” (which tags the
terminals “to space”) comes from the translation
rule.
We stemmed the verbs for training this feature,
and also annotated our rules with stemmed verbal
predicates. The stemming helps the training since
the argument types of a verb are normally inde-
pendent of its inflected variants.
</bodyText>
<page confidence="0.975828">
1788
</page>
<table confidence="0.994438714285714">
avg. BLEU Score
dev test p-value
Baseline 26.01 25.00 -
Source 26.44 25.17 0.048
Source and target 26.39 25.63 &lt; 10−10
Propbank LM 26.38 25.08 0.108
VerbNet LM 26.58 25.23 0.025
</table>
<tableCaption confidence="0.999472">
Table 1: Comparisons of the methods with the
</tableCaption>
<bodyText confidence="0.71481925">
baseline. The BLEU scores are calculated on the
top 3 results from 15 runs MERT for each experi-
ments. The p-values are calculated by comparing
each method against the baseline system.
</bodyText>
<sectionHeader confidence="0.999768" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998439">
3.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9999854">
The data that we used for training the MT sys-
tem was a Chinese-English corpus derived from
newswire text from LDC.1 The data consists of
250K sentences, which is 6.3M words in the En-
glish side. Our language model was trained on
the English side of the entire data, which consisted
of 1.65M sentences (39.3M words). Our develop-
ment and test sets are from the newswire portion
of NIST evaluations (2004, 2005, 2006). We used
392 sentences for the development set and 428
sentences for the test set. These sentences have
lengths smaller than 30, and they each have 4 ref-
erence translations. We used our in-house string-
to-tree decoder that uses Earley parsing. Other
than the features that we presented for our new
methods, we used a set of nine standard features.
The rules for the baseline system were extracted
using the GHKM method. Our baseline GHKM
rules also include composed rules, where larger
rules are constructed by combining two levels of
the regular GHKM rules. We exclude any unary
rules (Chung et al., 2011), and only keep rules
that have scope up to 3 (Hopkins and Langmead,
2010). For the semantic language model, we used
the SRILM package (Stolcke, 2002) and trained
a tri-gram language model with the default Good-
Turing smoothing.
Our target side semantic role labeler uses a max-
imum entropy classifier to label parsed sentences.
We used Sections 02-22 of the Penn TreeBank to
</bodyText>
<footnote confidence="0.456338166666667">
1The data was randomly selected from the follow-
ing sources: LDC2006E86, LDC2006E93, LDC2002E18,
LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08,
LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26,
LDC2005E83, LDC2006E34, LDC2006E85, LDC2006E92,
LDC2006E24, LDC2006E92, LDC2006E24
</footnote>
<bodyText confidence="0.999918333333333">
train the labeler, and sections 24 and 23 for devel-
opment set and training set respectively. The la-
beler has a precision of 90% and a recall of 88%.
We used the Chinese semantic role labeler of Wu
and Palmer (2011) for source side SRL, which
uses the LIBLINEAR (Fan et al., 2008) as a classi-
fier. Minimum Error Rate Training (MERT) (Och,
2003) was used for tuning the feature weights.
For all of our experiments, we ran 15 instances
of MERT with random initial weight vectors, and
used the weights of the top 3 results on the de-
velopment set to test the systems on the test set.
We chose to use the top 3 runs (rather than the
best run) of each system to account for the insta-
bility of MERT (Clark et al., 2011). This method
is designed to reflect the average performance of
the MT system when trained with random restarts
of MERT: we wish to discount runs in which the
optimizer is stuck in a poor region of the weight
space, but also to average across several good runs
in order not to be mislead by the high variance of
the single best run. For each of our MT systems,
we merged the results of the top 3 runs on the test
set into one file, and ran a statistical significance
test, comparing it to the merged top 3 results from
our baseline system. The 3 runs were merged by
duplicating each run 3 times, and arranging them
in the file so that the significance testing compares
each run with all the runs of the baseline. We per-
formed significance testing using paired bootstrap
resampling (Koehn, 2004). The difference is con-
sidered statistically significant if p &lt; 0.05 using
1000 iterations of paired bootstrap resampling.
</bodyText>
<subsectionHeader confidence="0.957088">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999408125">
Our results are shown in Table 1. The second
and the third columns contain the average BLEU
score (Papineni et al., 2002) on the top three re-
sults on the development and test sets. The fourth
column is the p-value for statistical significance
testing against the baseline. The first row shows
the results for our baseline. The second row con-
tains the results for using the source (Chinese)
side complete semantic rules of Section 2.1, and
the third row is the results for combining both
the source and the target side complete semantic
rules. As noted before, in both of these experi-
ments we also use the regular GHKM rules. The
result show that the source side complete seman-
tic rules improve the system (p = 0.048), and as
we expected, combining the source and the tar-
</bodyText>
<page confidence="0.987158">
1789
</page>
<subsectionHeader confidence="0.885598">
Source Sentence 因此 , 保护 儿I 免 受 武装冲突 的伤害 是 Q际 社会 重要 的 职责 .
</subsectionHeader>
<bodyText confidence="0.896975666666667">
Reference therefore , it is the international community ’s responsibility to protect the children from harms resulted
from armed conflicts .
Baseline the armed conflicts will harm the importance of the international community the responsibilities. there-
fore , from child protection
Verbet LM therefore , the importance of the international community is to protect children from the harm affected
by the armed conflicts .
</bodyText>
<figure confidence="0.911475705882353">
Source Sentence 同 去* 的 会议 相比 , 今* 会议 的 火药 味 消失 T , W方 的 A* 在 靠近 .
Reference compared with last year ’s meeting, the smell of gunpowder has disappeared in this year ’s meeting and
the two sides ’ standpoints are getting closer.
Baseline disappears on gunpowder , near the stance of the two sides compared with last year ’s meeting , the
meeting of this year.
Verbet LM the smells of gunpowder has disappeared, the position in the two sides approach. compared with last
year ’s meeting, this meeting
(a) Comparison of the language model method (using VerbNet) and the baseline system.
Source Sentence 科学家 曾 大胆 预料 , i$ 艘 英Q 的 太空 船 可能 陷 在 坑 洞 中 .
Reference scientists have boldly predicted that the british spacecraft might have been stuck in a hole .
Baseline scientists boldly expected, this vessel uk may have in the space ship in hang tung .
Semantic Rules scientists have boldly expected this vessel and the possible settlement of the space ship in hang tung .
Source Sentence 美Q 政府 应 以 善意 对待 朝鲜 的 i$ 一 A* .
Reference the us government should show goodwills to north korea ’s stand.
Baseline this position of the government of the united states to goodwill toward the dprk .
Semantic Rules this position that the us government should use goodwill toward the dprk .
(b) Comparison of the experiments with source and target side semantic rules and the baseline system.
</figure>
<figureCaption confidence="0.999993">
Figure 4: Comparison of example translations from our semantic methods and the baseline system.
</figureCaption>
<bodyText confidence="0.999926066666667">
get side rules improves the system even more sig-
nificantly (p &lt; 10−10). To measure the effect
of combining the rules, in a separate experiment
we replicated the complete semantic rules exper-
iments of Bazrafshan and Gildea (2013), and ran
statistical significance tests comparing the combi-
nation of the source and target rules with using
only the source or the target semantic rules sep-
arately. The results showed that combining the se-
mantic rules outperforms both of the experiments
that used rules from only one side (with p &lt; 0.05
in both cases).
The results for the language model feature are
shown in the last two rows of the table. Us-
ing Propbank for language model training did not
change the system in any significant way (p =
0.108), but using VerbNet significantly improved
the results (p = 0.025). Figure 4(a) contains an
example comparing the baseline system with the
VerbNet language model. We can see how the
VerbNet language model helps the decoder trans-
late the argument in the correct order. The baseline
system has also generated the correct arguments,
but the output is in the wrong order. Figure 4(b)
compares the experiment with semantic rules of
both target and source side and the baseline sys-
tem. Translation of the word “use” by our seman-
tic rules is a good example showing how the de-
coder uses these semantic rules to generate a more
complete predicate-argument structure.
</bodyText>
<sectionHeader confidence="0.999685" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.99999075">
We experimented with two techniques for incor-
porating semantics in machine translation. The
models were designed to help the decoder trans-
late semantic roles in the correct order, as well
as generating complete predicate-argument struc-
tures. We observed that using a semantic lan-
guage model can significantly improve the trans-
lations, and help the decoder to generate the se-
mantic roles in the correct order. Adding transla-
tion rules with complete semantic structures also
improved our MT system. We experimented with
using source side complete semantic rules, as well
as using rules for both the source and the target
sides. Both of our experiments showed improve-
ments over the baseline, and as expected, the sec-
ond one had a higher improvement.
</bodyText>
<sectionHeader confidence="0.998389" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.913985">
Partially funded by NSF grant IIS-0910611.
</bodyText>
<page confidence="0.987558">
1790
</page>
<sectionHeader confidence="0.989415" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998656057471265">
Marzieh Bazrafshan and Daniel Gildea. 2013. Seman-
tic roles for string to tree machine translation. In
Association for Computational Linguistics (ACL-13)
short paper.
Tagyoung Chung, Licheng Fang, and Daniel Gildea.
2011. Issues concerning decoding with synchronous
context-free grammar. In Proceedings of the ACL
2011 Conference Short Papers, Portland, Oregon.
Association for Computational Linguistics.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis testing for
statistical machine translation: Controlling for opti-
mizer instability. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies: Short Pa-
pers - Volume 2, HLT ’11, pages 176–181, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A li-
brary for large linear classification. J. Mach. Learn.
Res., 9:1871–1874, June.
Pascale Fung, Zhaojun Wu, Yongsheng Yang, and
Dekai Wu. 2007. Learning Bilingual Seman-
tic Frames: Shallow Semantic Parsing vs. Seman-
tic Role Projection. In TMI-2007: Proceedings of
the 11 th International Conference on Theoretical
and Methodological Issues in Machine Translation,
Sk¨ovde, Sweden.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a translation
rule? In Proceedings of NAACL-04, pages 273–280,
Boston, MA.
Mark Hopkins and Greg Langmead. 2010. SCFG de-
coding without binarization. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 646–655, Cambridge,
MA, October.
Karin Kipper Schuler. 2005. VerbNet: A broad-
coverage, comprehensive verb lexicon. Ph.D. thesis,
University of Pennsylvania.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP, pages 388–395, Barcelona, Spain, July.
Junhui Li, Philip Resnik, and Hal Daum´e III. 2013.
Modeling syntactic and semantic structures in hier-
archical phrase-based translation. In HLT-NAACL,
pages 540–549.
Ding Liu and Daniel Gildea. 2010. Semantic role fea-
tures for machine translation. In COLING-10, Bei-
jing.
Franz Josef Och. 2003. Minimum error rate training
for statistical machine translation. In Proceedings
of ACL-03, pages 160–167, Sapporo, Japan.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.
Martha. Palmer. 2009. SemLink: Linking PropBank,
VerbNet and FrameNet. In Proceedings of the Gen-
erative Lexicon ConferenceGenLex-09, Pisa, Italy,
Sept.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evaluation of machine translation. In Proceedings
of ACL-02, pages 311–318, Philadelphia, PA.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In International Confer-
ence on Spoken Language Processing, volume 2,
pages 901–904.
Dekai Wu and Pascale Fung. 2009. Semantic roles for
smt: A hybrid two-pass model. In Proceedings of
the HLT-NAACL 2009: Short Papers, Boulder, Col-
orado.
Shumin Wu and Martha Palmer. 2011. Semantic map-
ping using automatic word alignment and seman-
tic role labeling. In Proceedings of the Fifth Work-
shop on Syntax, Semantics and Structure in Statisti-
cal Translation, SSST-5, pages 21–30, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Mod-
eling the translation of predicate-argument structure
for smt. In ACL (1), pages 902–911.
Kenji Yamada and Kevin Knight. 2002. A decoder
for syntax-based statistical MT. In Proceedings of
ACL-02, pages 303–310, Philadelphia, PA.
</reference>
<page confidence="0.992601">
1791
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.946543">
<title confidence="0.999012">Comparing Representations of Semantic Roles String-To-Tree Decoding</title>
<author confidence="0.978539">Bazrafshan</author>
<affiliation confidence="0.99979">Department of Computer University of</affiliation>
<address confidence="0.999061">Rochester, NY 14627</address>
<abstract confidence="0.998229235294118">We introduce new features for incorporating semantic predicate-argument structures in machine translation (MT). The methods focus on the completeness of the semantic structures of the translations, as well as the order of the translated semantic roles. We experiment with translation rules which contain the core arguments for the predicates in the source side of a MT system, and observe that using these rules significantly improves the translation quality. We also present a new semantic feature that resembles a language model. Our results show that the language model feature can also significantly improve MT results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marzieh Bazrafshan</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic roles for string to tree machine translation.</title>
<date>2013</date>
<booktitle>In Association for Computational Linguistics (ACL-13)</booktitle>
<pages>short paper.</pages>
<contexts>
<context position="1845" citStr="Bazrafshan and Gildea (2013)" startWordPosition="278" endWordPosition="281">which they used a semantic parser to rerank the translation hypotheses of a phrase-based system. Liu and Gildea (2010) used semantic features for a tree-to-string syntax based SMT system. Their features modeled deletion and reordering for source side semantic roles, and they improved the translation quality. Xiong et al. (2012) incorporated the semantic structures into phrasebased SMT by adding syntactic and semantic features to their translation model. They proposed two discriminative models which included features for predicate translation and argument reordering from source to target side. Bazrafshan and Gildea (2013) used semantic structures in a string-to-tree translation system by extracting translation rules enriched with semantic information, and showed that this can improve the translation quality. Li et al. (2013) used predicateargument structure reordering models for hierarchical phrase-based translation, and they used linguistically motivated constraints for phrase translation. In this paper, we experiment with methods for incorporating semantics in a string-to-tree MT system. These methods are designed to model the order of translation, as well as the completeness of the semantic structures. We e</context>
<context position="3392" citStr="Bazrafshan and Gildea (2013)" startWordPosition="524" endWordPosition="527">ome the problem that a rule representing the entire semantic structure of a predicate is often too large and too specific to apply to new sentences during decoding. For this method, we compare the verb-specific roles of PropBank and the more general thematic roles of VerbNet. These essential arguments of a verbal predicate are called the core arguments. Standard syntaxbased MT is incapable of ensuring that the target translation includes all of the core arguments of a predicate that appear in the source sentence. To encourage the translation of the likely core arguments, we follow the work of Bazrafshan and Gildea (2013), who use special translation rules with complete semantic structures of the predicates in the target side of their MT system. Each of these rules includes a predicate and all of its core arguments. Instead of incorporating only the target side semantic rules, we extract the special rules for both the source and the target sides, and compare the effectiveness of adding these rules to 1786 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1786–1791, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics S-8 NP-7-ARG</context>
<context position="6643" citStr="Bazrafshan and Gildea (2013)" startWordPosition="1063" endWordPosition="1066">e more information, since VerbNet has a larger set of labels than PropBank. To train the semantic role labeler on VerbNet, we used the mappings provided by the SemLink project (Palmer, 2009) to annotate the Penn Treebank with the VerbNet roles. These mappings map the roles in PropBank to the thematic roles of VerbNet. When there is no mapping for a role, we keep the role from Propbank. 2 Using Semantics in Machine Translation In this section, we present our techniques for incorporating semantics in MT: source side semantic rules, and the semantic language model. 2.1 Source Side Semantic Rules Bazrafshan and Gildea (2013) extracted translation rules that included a predicate and all of its arguments from the target side, and added those rules to the baseline rules of their string-to-tree MT system. Figure 1 shows an example of such rules, which we refer to as complete semantic rules. The new rules encourage the decoder to generate translations that include all of the semantic roles that appear in the source sentence. In this paper, we use the same idea to extract rules from the semantic structures of the source side. The complete semantic rules consist of the smallest fragments of the combination of GHKM (Gall</context>
<context position="18953" citStr="Bazrafshan and Gildea (2013)" startWordPosition="3216" endWordPosition="3219">rth korea ’s stand. Baseline this position of the government of the united states to goodwill toward the dprk . Semantic Rules this position that the us government should use goodwill toward the dprk . (b) Comparison of the experiments with source and target side semantic rules and the baseline system. Figure 4: Comparison of example translations from our semantic methods and the baseline system. get side rules improves the system even more significantly (p &lt; 10−10). To measure the effect of combining the rules, in a separate experiment we replicated the complete semantic rules experiments of Bazrafshan and Gildea (2013), and ran statistical significance tests comparing the combination of the source and target rules with using only the source or the target semantic rules separately. The results showed that combining the semantic rules outperforms both of the experiments that used rules from only one side (with p &lt; 0.05 in both cases). The results for the language model feature are shown in the last two rows of the table. Using Propbank for language model training did not change the system in any significant way (p = 0.108), but using VerbNet significantly improved the results (p = 0.025). Figure 4(a) contains</context>
</contexts>
<marker>Bazrafshan, Gildea, 2013</marker>
<rawString>Marzieh Bazrafshan and Daniel Gildea. 2013. Semantic roles for string to tree machine translation. In Association for Computational Linguistics (ACL-13) short paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tagyoung Chung</author>
<author>Licheng Fang</author>
<author>Daniel Gildea</author>
</authors>
<title>Issues concerning decoding with synchronous context-free grammar.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL 2011 Conference Short Papers,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon.</location>
<contexts>
<context position="13718" citStr="Chung et al., 2011" startWordPosition="2296" endWordPosition="2299">, 2005, 2006). We used 392 sentences for the development set and 428 sentences for the test set. These sentences have lengths smaller than 30, and they each have 4 reference translations. We used our in-house stringto-tree decoder that uses Earley parsing. Other than the features that we presented for our new methods, we used a set of nine standard features. The rules for the baseline system were extracted using the GHKM method. Our baseline GHKM rules also include composed rules, where larger rules are constructed by combining two levels of the regular GHKM rules. We exclude any unary rules (Chung et al., 2011), and only keep rules that have scope up to 3 (Hopkins and Langmead, 2010). For the semantic language model, we used the SRILM package (Stolcke, 2002) and trained a tri-gram language model with the default GoodTuring smoothing. Our target side semantic role labeler uses a maximum entropy classifier to label parsed sentences. We used Sections 02-22 of the Penn TreeBank to 1The data was randomly selected from the following sources: LDC2006E86, LDC2006E93, LDC2002E18, LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08, LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26, LDC2005E83, LDC2006E34, LDC2006E85</context>
</contexts>
<marker>Chung, Fang, Gildea, 2011</marker>
<rawString>Tagyoung Chung, Licheng Fang, and Daniel Gildea. 2011. Issues concerning decoding with synchronous context-free grammar. In Proceedings of the ACL 2011 Conference Short Papers, Portland, Oregon. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: Controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11,</booktitle>
<pages>176--181</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15078" citStr="Clark et al., 2011" startWordPosition="2524" endWordPosition="2527"> The labeler has a precision of 90% and a recall of 88%. We used the Chinese semantic role labeler of Wu and Palmer (2011) for source side SRL, which uses the LIBLINEAR (Fan et al., 2008) as a classifier. Minimum Error Rate Training (MERT) (Och, 2003) was used for tuning the feature weights. For all of our experiments, we ran 15 instances of MERT with random initial weight vectors, and used the weights of the top 3 results on the development set to test the systems on the test set. We chose to use the top 3 runs (rather than the best run) of each system to account for the instability of MERT (Clark et al., 2011). This method is designed to reflect the average performance of the MT system when trained with random restarts of MERT: we wish to discount runs in which the optimizer is stuck in a poor region of the weight space, but also to average across several good runs in order not to be mislead by the high variance of the single best run. For each of our MT systems, we merged the results of the top 3 runs on the test set into one file, and ran a statistical significance test, comparing it to the merged top 3 results from our baseline system. The 3 runs were merged by duplicating each run 3 times, and </context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11, pages 176–181, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>9--1871</pages>
<contexts>
<context position="14646" citStr="Fan et al., 2008" startWordPosition="2440" endWordPosition="2443">rsed sentences. We used Sections 02-22 of the Penn TreeBank to 1The data was randomly selected from the following sources: LDC2006E86, LDC2006E93, LDC2002E18, LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08, LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26, LDC2005E83, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006E24, LDC2006E92, LDC2006E24 train the labeler, and sections 24 and 23 for development set and training set respectively. The labeler has a precision of 90% and a recall of 88%. We used the Chinese semantic role labeler of Wu and Palmer (2011) for source side SRL, which uses the LIBLINEAR (Fan et al., 2008) as a classifier. Minimum Error Rate Training (MERT) (Och, 2003) was used for tuning the feature weights. For all of our experiments, we ran 15 instances of MERT with random initial weight vectors, and used the weights of the top 3 results on the development set to test the systems on the test set. We chose to use the top 3 runs (rather than the best run) of each system to account for the instability of MERT (Clark et al., 2011). This method is designed to reflect the average performance of the MT system when trained with random restarts of MERT: we wish to discount runs in which the optimizer</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. J. Mach. Learn. Res., 9:1871–1874, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Zhaojun Wu</author>
<author>Yongsheng Yang</author>
<author>Dekai Wu</author>
</authors>
<title>Learning Bilingual Semantic Frames: Shallow Semantic Parsing vs. Semantic Role Projection.</title>
<date>2007</date>
<booktitle>In TMI-2007: Proceedings of the 11 th International Conference on Theoretical and Methodological Issues in Machine Translation, Sk¨ovde,</booktitle>
<contexts>
<context position="7865" citStr="Fung et al., 2007" startWordPosition="1272" endWordPosition="1275">t al., 2004) rules that include one predicate and all of its core arguments that appear in the sentence. Rather than keeping the predicate and argument labels attached to the non-terminals, we remove those labels from our extracted semantic rules, to keep the non-terminals in the semantic rules consistent with the non-terminals of the baseline GHKM rules. This is also important when using both the source and the target semantic rules (i.e. Chinese and English rules), as it has been shown that there are cross lingual mismatches between Chinese and English semantic roles in bilingual sentences (Fung et al., 2007). We extract a complete semantic rule for each verbal predicate of each sentence pair in the training data. To extract the target side complete semantic rules, using the target side SRL anno1787 A → BC to space c0 (x1 x2 Destination) [B, i, j, (Agent,)] c1 [C, j, k, (PRED bring, Theme,)] c2 [A, i, k, (Agent, PRED bring,-*-, Theme, Destination)] c0 + c1 + c+ + LMcost(Agent, PRED bring,-*-, Theme, Destination) Figure 3: A deduction step in the semantic language model method. tated training data, we follow the general GHKM method, and modify it to ensure that each frontier node (Galley et al., 20</context>
</contexts>
<marker>Fung, Wu, Yang, Wu, 2007</marker>
<rawString>Pascale Fung, Zhaojun Wu, Yongsheng Yang, and Dekai Wu. 2007. Learning Bilingual Semantic Frames: Shallow Semantic Parsing vs. Semantic Role Projection. In TMI-2007: Proceedings of the 11 th International Conference on Theoretical and Methodological Issues in Machine Translation, Sk¨ovde, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proceedings of NAACL-04,</booktitle>
<pages>273--280</pages>
<location>Boston, MA.</location>
<contexts>
<context position="7259" citStr="Galley et al., 2004" startWordPosition="1169" endWordPosition="1172">013) extracted translation rules that included a predicate and all of its arguments from the target side, and added those rules to the baseline rules of their string-to-tree MT system. Figure 1 shows an example of such rules, which we refer to as complete semantic rules. The new rules encourage the decoder to generate translations that include all of the semantic roles that appear in the source sentence. In this paper, we use the same idea to extract rules from the semantic structures of the source side. The complete semantic rules consist of the smallest fragments of the combination of GHKM (Galley et al., 2004) rules that include one predicate and all of its core arguments that appear in the sentence. Rather than keeping the predicate and argument labels attached to the non-terminals, we remove those labels from our extracted semantic rules, to keep the non-terminals in the semantic rules consistent with the non-terminals of the baseline GHKM rules. This is also important when using both the source and the target semantic rules (i.e. Chinese and English rules), as it has been shown that there are cross lingual mismatches between Chinese and English semantic roles in bilingual sentences (Fung et al.,</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proceedings of NAACL-04, pages 273–280, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hopkins</author>
<author>Greg Langmead</author>
</authors>
<title>SCFG decoding without binarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>646--655</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="13792" citStr="Hopkins and Langmead, 2010" startWordPosition="2310" endWordPosition="2313">28 sentences for the test set. These sentences have lengths smaller than 30, and they each have 4 reference translations. We used our in-house stringto-tree decoder that uses Earley parsing. Other than the features that we presented for our new methods, we used a set of nine standard features. The rules for the baseline system were extracted using the GHKM method. Our baseline GHKM rules also include composed rules, where larger rules are constructed by combining two levels of the regular GHKM rules. We exclude any unary rules (Chung et al., 2011), and only keep rules that have scope up to 3 (Hopkins and Langmead, 2010). For the semantic language model, we used the SRILM package (Stolcke, 2002) and trained a tri-gram language model with the default GoodTuring smoothing. Our target side semantic role labeler uses a maximum entropy classifier to label parsed sentences. We used Sections 02-22 of the Penn TreeBank to 1The data was randomly selected from the following sources: LDC2006E86, LDC2006E93, LDC2002E18, LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08, LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26, LDC2005E83, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006E24, LDC2006E92, LDC2006E24 train the labeler, and se</context>
</contexts>
<marker>Hopkins, Langmead, 2010</marker>
<rawString>Mark Hopkins and Greg Langmead. 2010. SCFG decoding without binarization. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 646–655, Cambridge, MA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper Schuler</author>
</authors>
<title>VerbNet: A broadcoverage, comprehensive verb lexicon.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="5341" citStr="Schuler, 2005" startWordPosition="853" endWordPosition="854"> we call the semantic language. Our experimental results show that the language model feature significantly improves translation quality. Semantic Role Labeling (SRL): We use semantic role labelers to annotate the training data that we use to extract the translation rules. For target side SRL, the role labels are attached to the nonterminal nodes in the syntactic parse of each sentence. For source side SRL, the labels annotate the spans from the source sentence that they cover. We train our semantic role labeler using two different standards: Propbank (Palmer et al., 2005) and VerbNet (Kipper Schuler, 2005). PropBank annotates the Penn Treebank with predicate-argument structures.It use generic labels (such as Arg0, Arg1, etc.) which are defined specifically for each verb. We trained a semantic role labeler on the annotated Penn Treebank data and used the classifier to tag our training data. VerbNet is a verb lexicon that categorizes English verbs into hierarchical classes, and annotates them with thematic roles for the arguments that they accept. Since the thematic roles use more meaningful labels (e.g. Agent, Patient, etc.), a language model trained on VerbNet labels may be more likely to gener</context>
</contexts>
<marker>Schuler, 2005</marker>
<rawString>Karin Kipper Schuler. 2005. VerbNet: A broadcoverage, comprehensive verb lexicon. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>388--395</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="15872" citStr="Koehn, 2004" startWordPosition="2671" endWordPosition="2672"> poor region of the weight space, but also to average across several good runs in order not to be mislead by the high variance of the single best run. For each of our MT systems, we merged the results of the top 3 runs on the test set into one file, and ran a statistical significance test, comparing it to the merged top 3 results from our baseline system. The 3 runs were merged by duplicating each run 3 times, and arranging them in the file so that the significance testing compares each run with all the runs of the baseline. We performed significance testing using paired bootstrap resampling (Koehn, 2004). The difference is considered statistically significant if p &lt; 0.05 using 1000 iterations of paired bootstrap resampling. 3.2 Results Our results are shown in Table 1. The second and the third columns contain the average BLEU score (Papineni et al., 2002) on the top three results on the development and test sets. The fourth column is the p-value for statistical significance testing against the baseline. The first row shows the results for our baseline. The second row contains the results for using the source (Chinese) side complete semantic rules of Section 2.1, and the third row is the resul</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of EMNLP, pages 388–395, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhui Li</author>
<author>Philip Resnik</author>
<author>Hal Daum´e</author>
</authors>
<title>Modeling syntactic and semantic structures in hierarchical phrase-based translation.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>540--549</pages>
<marker>Li, Resnik, Daum´e, 2013</marker>
<rawString>Junhui Li, Philip Resnik, and Hal Daum´e III. 2013. Modeling syntactic and semantic structures in hierarchical phrase-based translation. In HLT-NAACL, pages 540–549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic role features for machine translation. In</title>
<date>2010</date>
<booktitle>COLING-10,</booktitle>
<location>Beijing.</location>
<contexts>
<context position="1335" citStr="Liu and Gildea (2010)" startWordPosition="199" endWordPosition="202">age model. Our results show that the language model feature can also significantly improve MT results. 1 Introduction In recent years, there have been increasing efforts to incorporate semantics in statistical machine translation (SMT), and the use of predicateargument structures has provided promising improvements in translation quality. Wu and Fung (2009) showed that shallow semantic parsing can improve the translation quality in a machine translation system. They introduced a two step model, in which they used a semantic parser to rerank the translation hypotheses of a phrase-based system. Liu and Gildea (2010) used semantic features for a tree-to-string syntax based SMT system. Their features modeled deletion and reordering for source side semantic roles, and they improved the translation quality. Xiong et al. (2012) incorporated the semantic structures into phrasebased SMT by adding syntactic and semantic features to their translation model. They proposed two discriminative models which included features for predicate translation and argument reordering from source to target side. Bazrafshan and Gildea (2013) used semantic structures in a string-to-tree translation system by extracting translation</context>
</contexts>
<marker>Liu, Gildea, 2010</marker>
<rawString>Ding Liu and Daniel Gildea. 2010. Semantic role features for machine translation. In COLING-10, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL-03,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="14710" citStr="Och, 2003" startWordPosition="2453" endWordPosition="2454">a was randomly selected from the following sources: LDC2006E86, LDC2006E93, LDC2002E18, LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08, LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26, LDC2005E83, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006E24, LDC2006E92, LDC2006E24 train the labeler, and sections 24 and 23 for development set and training set respectively. The labeler has a precision of 90% and a recall of 88%. We used the Chinese semantic role labeler of Wu and Palmer (2011) for source side SRL, which uses the LIBLINEAR (Fan et al., 2008) as a classifier. Minimum Error Rate Training (MERT) (Och, 2003) was used for tuning the feature weights. For all of our experiments, we ran 15 instances of MERT with random initial weight vectors, and used the weights of the top 3 results on the development set to test the systems on the test set. We chose to use the top 3 runs (rather than the best run) of each system to account for the instability of MERT (Clark et al., 2011). This method is designed to reflect the average performance of the MT system when trained with random restarts of MERT: we wish to discount runs in which the optimizer is stuck in a poor region of the weight space, but also to aver</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training for statistical machine translation. In Proceedings of ACL-03, pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="5306" citStr="Palmer et al., 2005" startWordPosition="846" endWordPosition="849">g the semantic roles as the words in what we call the semantic language. Our experimental results show that the language model feature significantly improves translation quality. Semantic Role Labeling (SRL): We use semantic role labelers to annotate the training data that we use to extract the translation rules. For target side SRL, the role labels are attached to the nonterminal nodes in the syntactic parse of each sentence. For source side SRL, the labels annotate the spans from the source sentence that they cover. We train our semantic role labeler using two different standards: Propbank (Palmer et al., 2005) and VerbNet (Kipper Schuler, 2005). PropBank annotates the Penn Treebank with predicate-argument structures.It use generic labels (such as Arg0, Arg1, etc.) which are defined specifically for each verb. We trained a semantic role labeler on the annotated Penn Treebank data and used the classifier to tag our training data. VerbNet is a verb lexicon that categorizes English verbs into hierarchical classes, and annotates them with thematic roles for the arguments that they accept. Since the thematic roles use more meaningful labels (e.g. Agent, Patient, etc.), a language model trained on VerbNet</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Palmer</author>
</authors>
<title>SemLink: Linking PropBank, VerbNet and FrameNet.</title>
<date>2009</date>
<booktitle>In Proceedings of the Generative Lexicon ConferenceGenLex-09,</booktitle>
<location>Pisa, Italy,</location>
<contexts>
<context position="6205" citStr="Palmer, 2009" startWordPosition="991" endWordPosition="992">e classifier to tag our training data. VerbNet is a verb lexicon that categorizes English verbs into hierarchical classes, and annotates them with thematic roles for the arguments that they accept. Since the thematic roles use more meaningful labels (e.g. Agent, Patient, etc.), a language model trained on VerbNet labels may be more likely to generalize across verbs than one trained on PropBank labels. It may also provide more information, since VerbNet has a larger set of labels than PropBank. To train the semantic role labeler on VerbNet, we used the mappings provided by the SemLink project (Palmer, 2009) to annotate the Penn Treebank with the VerbNet roles. These mappings map the roles in PropBank to the thematic roles of VerbNet. When there is no mapping for a role, we keep the role from Propbank. 2 Using Semantics in Machine Translation In this section, we present our techniques for incorporating semantics in MT: source side semantic rules, and the semantic language model. 2.1 Source Side Semantic Rules Bazrafshan and Gildea (2013) extracted translation rules that included a predicate and all of its arguments from the target side, and added those rules to the baseline rules of their string-</context>
</contexts>
<marker>Palmer, 2009</marker>
<rawString>Martha. Palmer. 2009. SemLink: Linking PropBank, VerbNet and FrameNet. In Proceedings of the Generative Lexicon ConferenceGenLex-09, Pisa, Italy, Sept.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-02,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="16128" citStr="Papineni et al., 2002" startWordPosition="2711" endWordPosition="2714">le, and ran a statistical significance test, comparing it to the merged top 3 results from our baseline system. The 3 runs were merged by duplicating each run 3 times, and arranging them in the file so that the significance testing compares each run with all the runs of the baseline. We performed significance testing using paired bootstrap resampling (Koehn, 2004). The difference is considered statistically significant if p &lt; 0.05 using 1000 iterations of paired bootstrap resampling. 3.2 Results Our results are shown in Table 1. The second and the third columns contain the average BLEU score (Papineni et al., 2002) on the top three results on the development and test sets. The fourth column is the p-value for statistical significance testing against the baseline. The first row shows the results for our baseline. The second row contains the results for using the source (Chinese) side complete semantic rules of Section 2.1, and the third row is the results for combining both the source and the target side complete semantic rules. As noted before, in both of these experiments we also use the regular GHKM rules. The result show that the source side complete semantic rules improve the system (p = 0.048), and</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of ACL-02, pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In International Conference on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<contexts>
<context position="13868" citStr="Stolcke, 2002" startWordPosition="2324" endWordPosition="2325">h have 4 reference translations. We used our in-house stringto-tree decoder that uses Earley parsing. Other than the features that we presented for our new methods, we used a set of nine standard features. The rules for the baseline system were extracted using the GHKM method. Our baseline GHKM rules also include composed rules, where larger rules are constructed by combining two levels of the regular GHKM rules. We exclude any unary rules (Chung et al., 2011), and only keep rules that have scope up to 3 (Hopkins and Langmead, 2010). For the semantic language model, we used the SRILM package (Stolcke, 2002) and trained a tri-gram language model with the default GoodTuring smoothing. Our target side semantic role labeler uses a maximum entropy classifier to label parsed sentences. We used Sections 02-22 of the Penn TreeBank to 1The data was randomly selected from the following sources: LDC2006E86, LDC2006E93, LDC2002E18, LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08, LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26, LDC2005E83, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006E24, LDC2006E92, LDC2006E24 train the labeler, and sections 24 and 23 for development set and training set respectively. The labe</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In International Conference on Spoken Language Processing, volume 2, pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Semantic roles for smt: A hybrid two-pass model.</title>
<date>2009</date>
<booktitle>In Proceedings of the HLT-NAACL 2009: Short Papers,</booktitle>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1073" citStr="Wu and Fung (2009)" startWordPosition="156" endWordPosition="159">ment with translation rules which contain the core arguments for the predicates in the source side of a MT system, and observe that using these rules significantly improves the translation quality. We also present a new semantic feature that resembles a language model. Our results show that the language model feature can also significantly improve MT results. 1 Introduction In recent years, there have been increasing efforts to incorporate semantics in statistical machine translation (SMT), and the use of predicateargument structures has provided promising improvements in translation quality. Wu and Fung (2009) showed that shallow semantic parsing can improve the translation quality in a machine translation system. They introduced a two step model, in which they used a semantic parser to rerank the translation hypotheses of a phrase-based system. Liu and Gildea (2010) used semantic features for a tree-to-string syntax based SMT system. Their features modeled deletion and reordering for source side semantic roles, and they improved the translation quality. Xiong et al. (2012) incorporated the semantic structures into phrasebased SMT by adding syntactic and semantic features to their translation model</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. 2009. Semantic roles for smt: A hybrid two-pass model. In Proceedings of the HLT-NAACL 2009: Short Papers, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shumin Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Semantic mapping using automatic word alignment and semantic role labeling.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, SSST-5,</booktitle>
<pages>21--30</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="14581" citStr="Wu and Palmer (2011)" startWordPosition="2428" endWordPosition="2431"> semantic role labeler uses a maximum entropy classifier to label parsed sentences. We used Sections 02-22 of the Penn TreeBank to 1The data was randomly selected from the following sources: LDC2006E86, LDC2006E93, LDC2002E18, LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08, LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26, LDC2005E83, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006E24, LDC2006E92, LDC2006E24 train the labeler, and sections 24 and 23 for development set and training set respectively. The labeler has a precision of 90% and a recall of 88%. We used the Chinese semantic role labeler of Wu and Palmer (2011) for source side SRL, which uses the LIBLINEAR (Fan et al., 2008) as a classifier. Minimum Error Rate Training (MERT) (Och, 2003) was used for tuning the feature weights. For all of our experiments, we ran 15 instances of MERT with random initial weight vectors, and used the weights of the top 3 results on the development set to test the systems on the test set. We chose to use the top 3 runs (rather than the best run) of each system to account for the instability of MERT (Clark et al., 2011). This method is designed to reflect the average performance of the MT system when trained with random </context>
</contexts>
<marker>Wu, Palmer, 2011</marker>
<rawString>Shumin Wu and Martha Palmer. 2011. Semantic mapping using automatic word alignment and semantic role labeling. In Proceedings of the Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, SSST-5, pages 21–30, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
<author>Haizhou Li</author>
</authors>
<title>Modeling the translation of predicate-argument structure for smt.</title>
<date>2012</date>
<journal>In ACL</journal>
<volume>1</volume>
<pages>902--911</pages>
<contexts>
<context position="1546" citStr="Xiong et al. (2012)" startWordPosition="234" endWordPosition="237">hine translation (SMT), and the use of predicateargument structures has provided promising improvements in translation quality. Wu and Fung (2009) showed that shallow semantic parsing can improve the translation quality in a machine translation system. They introduced a two step model, in which they used a semantic parser to rerank the translation hypotheses of a phrase-based system. Liu and Gildea (2010) used semantic features for a tree-to-string syntax based SMT system. Their features modeled deletion and reordering for source side semantic roles, and they improved the translation quality. Xiong et al. (2012) incorporated the semantic structures into phrasebased SMT by adding syntactic and semantic features to their translation model. They proposed two discriminative models which included features for predicate translation and argument reordering from source to target side. Bazrafshan and Gildea (2013) used semantic structures in a string-to-tree translation system by extracting translation rules enriched with semantic information, and showed that this can improve the translation quality. Li et al. (2013) used predicateargument structure reordering models for hierarchical phrase-based translation,</context>
</contexts>
<marker>Xiong, Zhang, Li, 2012</marker>
<rawString>Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Modeling the translation of predicate-argument structure for smt. In ACL (1), pages 902–911.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A decoder for syntax-based statistical MT.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-02,</booktitle>
<pages>303--310</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="9477" citStr="Yamada and Knight, 2002" startWordPosition="1560" endWordPosition="1563">emantic roles, we extract the semantic rules by ensuring that the span of the root (in the target side) of the extracted rule covers all of the spans of the roles in the predicate-argument structure. The semantic rules are then used together with the original GHKM rules. We add a binary feature to distinguish the semantic rules from the rest. We experiment with adding the semantic rules from the source side, and compare that with adding semantic rules of both the source and the target side. In all of the experiments in this paper, we use a string-to-tree decoder which uses a CYK style parser (Yamada and Knight, 2002). Figure 2 depicts a deduction step in the baseline decoder. The CFG rule in the first line is used to generate a new item A with span (i, k) using items B and C, which have spans (i, j) and (j, k) respectively. The cost of each item is shown on the right. For experimenting with complete semantic rules, in addition having more rules, the only other modification made to the baseline system is extending the feature vector to include the new feature. We do not modify the decoder in any significant way. 2.2 Semantic Language Model The semantic language model is designed to encourage the correct or</context>
</contexts>
<marker>Yamada, Knight, 2002</marker>
<rawString>Kenji Yamada and Kevin Knight. 2002. A decoder for syntax-based statistical MT. In Proceedings of ACL-02, pages 303–310, Philadelphia, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>