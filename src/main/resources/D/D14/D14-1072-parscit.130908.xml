<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000444">
<title confidence="0.986617">
Adding High-Precision Links to Wikipedia
</title>
<author confidence="0.994451">
Thanapon Noraset Chandra Bhagavatula Doug Downey
</author>
<affiliation confidence="0.991871">
Department of Electrical Engineering &amp; Computer Science
Northwestern University
</affiliation>
<address confidence="0.488877">
Evanston, IL 60208
</address>
<email confidence="0.997139">
{nor|csbhagav}@u.northwestern.edu, ddowney@eecs.northwestern.edu
</email>
<sectionHeader confidence="0.993833" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999951466666667">
Wikipedia’s link structure is a valuable
resource for natural language processing
tasks, but only a fraction of the concepts
mentioned in each article are annotated
with hyperlinks. In this paper, we study
how to augment Wikipedia with additional
high-precision links. We present 3W, a
system that identifies concept mentions in
Wikipedia text, and links each mention
to its referent page. 3W leverages
rich semantic information present in
Wikipedia to achieve high precision. Our
experiments demonstrate that 3W can add
an average of seven new links to each
Wikipedia article, at a precision of 0.98.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999716">
Wikipedia forms a valuable resource for
many Natural Language Processing and
Information Extraction tasks, such as Entity
Linking (Cucerzan, 2007; Han and Zhao,
2009), Ontology Construction (Wu and Weld,
2008; Syed et al., 2008) and Knowledge Base
Population (Hoffart et al., 2013; Lehmann et al.,
2013). Wikipedia’s links provide disambiguated
semantic information. For example, when a
system processes the text “Chicago was received
with critical acclaim” from an article, the system
does not need to infer the referent entity of
“Chicago” if the word is already hyperlinked to
the Wikipedia page of the Oscar-winning film.
Unfortunately, in Wikipedia only a fraction of the
phrases that can be linked are in fact annotated
with a hyperlink. This is due to Wikipedia’s
conventions of only linking to each concept once,
and only when the links have a certain level of
utility for human readers.1 We see this as an
</bodyText>
<footnote confidence="0.7618625">
1http://en.wikipedia.org/wiki/
Wikipedia:Manual_of_Style_(linking)
</footnote>
<bodyText confidence="0.999905078947368">
opportunity to improve Wikipedia as a resource
for NLP systems. Our experiments estimate that
as of September 2013, there were an average of
30 references to Wikipedia concepts left unlinked
within each of English Wikipedia’s four million
pages.
In this paper, our goal is to augment Wikipedia
with additional high-precision links, in order
to provide a new resource for systems that
use Wikipedia’s link structure as a foundation.
Identifying references to concepts (called
mentions) in text and linking them to Wikipedia
is a task known as Wikification. Wikification for
general text has been addressed in a wide variety
of recent work (Mihalcea and Csomai, 2007;
Milne and Witten, 2008b; McNamee and Dang,
2009; Ratinov et al., 2011). The major challenge
of this task is to resolve the ambiguity of phrases,
and recent work makes use of various kinds of
information found in the document to tackle
the challenge. In contrast to this body of work,
here we focus on the special case of Wikifying
Wikipedia articles, instead of general documents.
This gives us an advantage over general-text
systems due to Wikipedia’s rich content and
existing link structure.
We introduce 3W, a system that identifies
mentions within Wikipedia and links each
to its referent concept. We show how a
Wikipedia-specific Semantic Relatedness measure
that leverages the link structure of Wikipedia
(Milne and Witten, 2008b) allows 3W to be
radically more precise at high levels of yield when
compared to baseline Wikifiers that target general
text. Our experiment shows that 3W can add on
average seven new links per article at precision of
0.98, adding approximately 28 million new links
to 4 million articles across English Wikipedia.2
</bodyText>
<footnote confidence="0.9976465">
2http://websail.cs.northwestern.edu/
projects/3W
</footnote>
<page confidence="0.866837">
651
</page>
<note confidence="0.4777255">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 651–656,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.947162" genericHeader="method">
2 Problem Definition
</sectionHeader>
<bodyText confidence="0.992108214285714">
In this section, we define our link extraction task.
A link l is a pair of a surface form sl and a
concept tl. A surface form is a span of tokens
in an article, and the concept is a Wikipedia
article referred to by the surface form. For
existing hyperlinks, the surface form corresponds
to the anchor text and the concept is the link
target. For example, a hyperlink [[Chicago City
 |Chicago]] has surface form “Chicago City” and
referent concept Chicago.3 Given documents D =
{d1, ..., d|D|} and a set of links L = {l1, ..,l|L|} E
D, our goal is to generate a set of high-precision
links L* for D, distinct from L. In this paper, the
document set D consists of articles from English
Wikipedia, and L is the set of existing links on
Wikipedia.
The task can be divided into 3 steps. The first
step is to extract a set of potential mentions M =
{m1, .., m|M|} where m is, similar to l, a pair of
surface form sm and a set of candidate concepts
C(m) = {t1, ..., t|C(m)|}. For m having |C(m) |&gt;
1, we need to disambiguate it by selecting only
one target concept tm E C(m). Since the correct
concept may not exist in C(m) and the previous
step could output an incorrect concept, the final
step is to decide whether to link and include m in
L*. We describe the details of these steps in the
following section.
</bodyText>
<sectionHeader confidence="0.983373" genericHeader="method">
3 System Overview
</sectionHeader>
<bodyText confidence="0.9981965">
In this section, we describe in detail how 3W adds
high-precision links to Wikipedia.
</bodyText>
<subsectionHeader confidence="0.999819">
3.1 Mention Extraction
</subsectionHeader>
<bodyText confidence="0.999804166666667">
In this step, we are given a document d, and
the goal is to output a set of mentions M. Our
system finds a set of potential surface forms, sm,
by finding substrings in d that match the surface
form of some links in L. For example, from the
phrase “map of the United States on the wall”,
we can match 4 potential surface forms: “map”,
“United States”, “map of the United States”, and
“wall”. Notice that some of them are overlapping.
The system selects a non-overlapping subset of the
surface forms that maximizes the following score
function:
</bodyText>
<equation confidence="0.934517666666667">
T(sm)PL(sm) (1)
|C(m)|
3http://en.wikipedia.org/wiki/Chicago
</equation>
<bodyText confidence="0.999667538461539">
where PL(sm) is the probability that the text sm
is linked (that is, the fraction of the occurrences of
the string sm in the corpus that are hyperlinked),
T(sm) is the number of tokens in sm, and |C(m)|
is the number of candidate concepts. Intuitively,
we prefer a longer surface form that is frequently
linked and has a specific meaning. Furthermore,
we eliminate common surface forms (i.e. “wall”)
by requiring that PL(sm) exceed a threshold. In
the previous example, we are left with only “map
of the United States”.
Because Wikipedia’s concepts are largely noun
phrases, 3W only looks for surface forms from
top-level noun phrases generated by the Stanford
Parser (Socher et al., 2013). In addition, each
name entity (NE) (Finkel et al., 2005) is treated
as an atomic token, meaning that multi-word NEs
such as “California Institute of the Arts” will not
be broken into multiple surface forms.
Finally, the system pairs the result surface forms
with a set of candidate concepts, C(m), and
outputs a set of mentions. C(m) consists of those
concepts previously linked to the surface form in
L. For instance, the surface form “map of the
United States” has been linked to three distinct
concepts in English Wikipedia.
</bodyText>
<subsectionHeader confidence="0.998477">
3.2 Disambiguation
</subsectionHeader>
<bodyText confidence="0.9999724">
Given a set of mentions M from the previous
step, The next step is to select a concept t E
C(m) for each m E M. We take the common
approach of ranking the candidate concepts.
3W uses a machine learning model to perform
pair-wise ranking of t E C(m) and select the
top-ranked candidate concept. We refer to 3W’s
disambiguation component as the ranker. The
ranker requires a feature vector for each candidate
concept of a mention. The rest of this section
describes the features utilized by the ranker. The
first two feature groups are commonly used in
Wikification systems. The third feature group is
specifically designed for mentions in Wikipedia
articles.
</bodyText>
<subsectionHeader confidence="0.645047">
3.2.1 Prior Probability Features
</subsectionHeader>
<bodyText confidence="0.999622">
The conditional probability of a concept t given
mention surface sm, P(t|sm), is a common
feature used for disambiguation. It forms
a very strong Wikification baseline (∼ 86%
in micro-accuracy). This probability can be
estimated using Wikipedia links (L). In
addition, we use the external partition of the
</bodyText>
<equation confidence="0.919886">
�Score(M) =
mEM
</equation>
<page confidence="0.97631">
652
</page>
<bodyText confidence="0.860055333333333">
Google “Cross-Lingual Dictionary” described in
(Spitkovsky and Chang, 2012) to get the estimates
for the probability from links outside Wikipedia.
</bodyText>
<subsectionHeader confidence="0.794764">
3.2.2 Lexical Features
</subsectionHeader>
<bodyText confidence="0.9999322">
To make use of text around a mention m,
we create bag-of-word vectors of the mention’s
source document d(m), and of a set of words
surrounding the mention, referred to as the context
c(m). To compare with a concept, we also
create bag-of-word vectors of candidate concept’s
document d(t) and candidate concept’s context
c(t). We then compute cosine similarities between
the mention’s vectors for d(m) and c(m), with
the concept candidate vectors for d(t) and c(t) as
in the Illinois Wikifier (Ratinov et al., 2011). In
addition to similarities computed over the top-200
words (utilized in the Illinois Wikifier), we also
compute similarity features over vectors of all
words.
</bodyText>
<subsectionHeader confidence="0.611786">
3.2.3 Wikipedia-specific Features
</subsectionHeader>
<bodyText confidence="0.99999175">
Because the links in an article are often related
to one another, the existing links in a document
form valuable clues for disambiguating mentions
in the document. For each concept candidate
t E C(m), we compute a Semantic Relatedness
(SR) measure between t and each concept from
existing links in the source document. Our SR
measure is based on the proportion of shared
inlinks, as introduced by Milne and Witten
(2008b). However, because Milne and Witten
were focused on general text, they computed SR
only between t and the unambiguous mentions
(i.e. those m with |C(m) |= 1) identified
in the document. In our work, d(m) is a
Wikipedia article which is rich in existing links
to Wikipedia concepts, and we can compute
SR with all of them, resulting in a valuable
feature for disambiguation as illustrated in our
experiments. We use the SR implementation of
Hecht et al. (2012). It is a modified version of
Milne and Witten’s measure that emphasizes links
in Wikipedia article’s overview. In addition, we
add boolean features indicating whether sm or t
has already been linked in a document.
</bodyText>
<subsectionHeader confidence="0.754689">
3.2.4 Reranking
</subsectionHeader>
<bodyText confidence="0.999982666666667">
The millions of existing Wikipedia links in L form
a valuable source of training examples for our
ranker. However, simply training on the links
in L may result in poor performance, because
those links exhibit systematic differences from the
mentions in M that the ranker will be applied to.
The reason is that our mention extractor attempts
to populate M with all mentions, whereas
L which contains only the specific subset of
mentions that meet the hyperlinking conventions
of Wikipedia, As a result, the features for M
are distributed differently from those in L, and a
model trained on L may not might not perform
well on M. Our strategy is to leverage L to
train an initial ranker, and then hand-label a small
set of mentions from M to train a second-stage
re-ranker that takes the ranking output of the
initial ranker as a feature.
</bodyText>
<subsectionHeader confidence="0.989335">
3.3 Linker
</subsectionHeader>
<bodyText confidence="0.999988388888889">
Our linker is a binary classifier that decides
whether to include (link) each mention in M
to the final output L∗. Previous work has
typically used a linker to determine so-called NIL
mentions, where the referred-to concept is not
in the target knowledge base (e.g., in the TAC
KBP competition, half of the given mentions are
NIL (Ji and Grishman, 2011)). The purpose
of our linker is slightly different, because we
also use a linker to control the precision of our
output. We use a probabilistic linker that predicts
a confidence estimate that the mention with its
top-ranked candidate is correct. Our linker uses
the same features as the ranker and an additional
set of confidence signals: the number of times the
top candidate concept appears in L, and the score
difference between the top-ranked candidate and
the second-ranked candidate.
</bodyText>
<sectionHeader confidence="0.997727" genericHeader="method">
4 Experiments and Result
</sectionHeader>
<bodyText confidence="0.9990515">
In this section, we provide an evaluation of our
system and its subcomponents.
</bodyText>
<subsectionHeader confidence="0.993891">
4.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.999920636363636">
We trained our initial ranker models from 100,000
randomly selected existing links (L). These links
were excluded when building feature values (i.e.
the prior probability, or Semantic Relatedness).
We formed an evaluation set of new links by
applying our mention extractor to 2,000 randomly
selected articles, and then manually labeling 1,900
of the mentions with either the correct concept
or “no correct concept.” We trained and tested
our system on the evaluation set, using 10-fold
cross validation. For each fold, we partitioned data
</bodyText>
<page confidence="0.998699">
653
</page>
<table confidence="0.999677">
Model Acc Prec Recall F1
Prior 0.876 0.891 0.850 0.870
OnlyWikiLink 0.896 0.905 0.871 0.888
−Wiki
OnlyWikiLink 0.944 0.950 0.920 0.935
</table>
<tableCaption confidence="0.995514333333333">
Table 1: 10-fold cross validation performance of the initial
rankers by Accuracy (excluded ∅-candidate mentions), BOT
Precision, BOT Recall, BOT F1 on the 100,000 existing links.
</tableCaption>
<bodyText confidence="0.999566636363636">
into 3 parts. We used 760 mentions for training
the final ranker. The linker was trained with 950
mentions and we tested our system using the other
190 mentions. Previous work has used various ML
approaches for ranking, such as SVMs (Dredze et
al., 2010). We found logistic regression produces
similar accuracy to SVMs, but is faster for our
feature set. For the linker, we use an SVM with
probabilistic output (Wu et al., 2004; Chang and
Lin, 2011) to estimate a confidence score for each
output link.
</bodyText>
<sectionHeader confidence="0.653028" genericHeader="evaluation">
Precision
</sectionHeader>
<subsectionHeader confidence="0.963056">
4.2 Result
</subsectionHeader>
<bodyText confidence="0.999793965517241">
We first evaluate 3W’s mention extraction. From
the selected 2, 000 articles, the system extracted
59,454 mentions (-30/article), in addition to
the original 54,309 links (-27/article). From
the 1, 900 hand-labeled mentions, 1, 530 (80.5%)
were solvable in that 3W candidate set contained
the correct target.
As described in section 3.2.4, 3W employs
a 2-stage ranker. We first evaluate just the
initial ranker, using 10-fold cross validation
on 100,000 existing links. We show micro
accuracy and bag-of-title (BOT) performance
used by Milne and Witten (2008b) in Table
1. The ranker with all features (OnlyWikiLink)
outperforms the ranker without Wikipedia-specific
features (OnlyWikiLink−Wiki) by approximately
five points in F1. This demonstrates that
Wikipedia’s rich semantic content is helpful for
disambiguation.
Next, we evaluate our full system performance
(disambiguation and linking) over the
hand-labeled evaluation set. We experimented
with different configurations of the rankers and
linkers. Our Baseline system disambiguates
a mention m by selecting the most common
concept for the surface s(m). OnlyWikiLink
uses the ranker model trained on only Wikipedia
links, ignoring the labeled mentions. 3W is our
system using all features described in section 3.2,
</bodyText>
<table confidence="0.999338">
Model Acc Yield %Yield
Baseline 0.828 5 0.33%
OnlyWikiLink 0.705 150 9.80%
3W−Wiki 0.868 253 16.54%
3W 0.877 365 23.86%
</table>
<tableCaption confidence="0.7115398">
Table 2: 10-fold cross validation performance of the system
over 1,900 labeled mentions. Acc is disambiguation accuracy
of solvable mentions. Yield is the number of output new
mentions at precision ≥ 0.98, and %Yield is the percentage
of Yield over the solvable mentions (recall).
</tableCaption>
<figure confidence="0.946308818181818">
Precision Recall Comparisons
1
0.9
0.8
0.7
Baseline
OnlyWikiLinks
3W−Wiki
3W
0.50 0.2 0.4 0.6 0.8 1
Recall
</figure>
<figureCaption confidence="0.983828">
Figure 1: Plot between Precision and Recall of systems on
1,900 mentions from 10-fold cross validation.
</figureCaption>
<bodyText confidence="0.9739036">
and 3W−Wiki is 3W without Wikipedia-specific
features. The last two configurations are trained
using the labeled mentions.
Table 2 shows the disambiguation accuracy of
each system over the solvable mentions. Our final
system, 3W, has the best disambiguation accuracy.
To evaluate the linking performance, we select
the confidence threshold such that the system
outputs mentions with precision of &gt; 0.98. The
third column in Table 2 shows the yield, i.e. the
number of mentions output at precision 0.98. 3W
outputs the largest number of new links (365).
Nearly half (157) are new concepts that have not
been linked in the source article. We find that the
Rerank feature helps increase recall: without it,
the yield of 3W drops by 27%. Using %Yield,
we estimate that 3W will output 14, 000 new links
for the selected 2, 000 articles (-7/article), and
approximately 28 million new links across the 4
million articles of English Wikipedia.
Adjusting the confidence threshold allows
the system to trade off precision and recall.
Figure 1 shows a precision and recall curve.
3W and OnlyWikiLink are comparable for
0.6
</bodyText>
<page confidence="0.99781">
654
</page>
<bodyText confidence="0.9998186">
many high-precision points, but below 0.95
OnlyWikiLink’s precision drops quickly. Plots
that finish at higher rightmost points in the graph
indicate systems that achieve higher accuracy on
the complete evaluation set.
</bodyText>
<sectionHeader confidence="0.995154" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.997688666666667">
We presented 3W, a system that adds
high-precision links to Wikipedia. Whereas
many Wikification systems focus on general text,
3W is specialized toward Wikipedia articles.
We showed that leveraging the link structure of
Wikipedia provides advantages in disambiguation.
In experiments, 3W was shown to Wikipedia with
∼7 new links per article (an estimated 28m across
4 million Wikipedia articles) at high precision.
</bodyText>
<sectionHeader confidence="0.998511" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.993537333333333">
This work was supported in part by DARPA
contract D11AP00268 and the Allen Institute for
Artificial Intelligence.
</bodyText>
<sectionHeader confidence="0.997169" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996098012048192">
Chih-Chung Chang and Chih-Jen Lin. 2011.
LIBSVM: A library for support vector machines.
ACM Transactions on Intelligent Systems and
Technology, 2:27:1–27:27. Software available at
http://www.csie.ntu.edu.tw/˜cjlin/
libsvm.
Silviu Cucerzan. 2007. Large-scale named
entity disambiguation based on Wikipedia data.
In Proceedings of EMNLP-CoNLL 2007, pages
708–716.
Mark Dredze, Paul McNamee, Delip Rao, Adam
Gerber, and Tim Finin. 2010. Entity
disambiguation for knowledge base population. In
Proceedings of the 23rd International Conference
on Computational Linguistics, pages 277–285.
Association for Computational Linguistics.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local
information into information extraction systems
by gibbs sampling. In Proceedings of the 43rd
Annual Meeting on Association for Computational
Linguistics, pages 363–370. Association for
Computational Linguistics.
Xianpei Han and Jun Zhao. 2009. Named
entity disambiguation by leveraging wikipedia
semantic knowledge. In Proceedings of the 18th
ACM conference on Information and knowledge
management, pages 215–224. ACM.
Brent Hecht, Samuel H Carton, Mahmood Quaderi,
Johannes Sch¨oning, Martin Raubal, Darren Gergle,
and Doug Downey. 2012. Explanatory
semantic relatedness and explicit spatialization for
exploratory search. In Proceedings of the 35th
international ACM SIGIR conference on Research
and development in information retrieval, pages
415–424. ACM.
Johannes Hoffart, Fabian M Suchanek, Klaus
Berberich, and Gerhard Weikum. 2013. Yago2: A
spatially and temporally enhanced knowledge base
from wikipedia. Artificial Intelligence, 194:28–61.
Heng Ji and Ralph Grishman. 2011. Knowledge
base population: Successful approaches and
challenges. In Proceedings of the 49th Annual
Meeting of the Association for Computational
Linguistics: Human Language Technologies-Volume
1, pages 1148–1158. Association for Computational
Linguistics.
Jens Lehmann, Robert Isele, Max Jakob, Anja
Jentzsch, Dimitris Kontokostas, Pablo N Mendes,
Sebastian Hellmann, Mohamed Morsey, Patrick van
Kleef, S¨oren Auer, et al. 2013. Dbpedia-a
large-scale, multilingual knowledge base extracted
from wikipedia. Semantic Web Journal.
Paul McNamee and Hoa Trang Dang. 2009. Overview
of the tac 2009 knowledge base population track. In
Text Analysis Conference (TAC), volume 17, pages
111–113.
Rada Mihalcea and Andras Csomai. 2007. Wikify!:
linking documents to encyclopedic knowledge.
In Proceedings of the sixteenth ACM conference
on Conference on information and knowledge
management, pages 233–242. ACM.
David Milne and Ian H Witten. 2008b. Learning to
link with wikipedia. In Proceedings of the 17th
ACM conference on Information and knowledge
management, pages 509–518. ACM.
Lev Ratinov, Dan Roth, Doug Downey, and Mike
Anderson. 2011. Local and global algorithms for
disambiguation to wikipedia. In ACL.
Richard Socher, John Bauer, Christopher D Manning,
and Andrew Y Ng. 2013. Parsing with
compositional vector grammars. In In Proceedings
of the ACL conference. Citeseer.
Valentin I. Spitkovsky and Angel X. Chang. 2012.
A cross-lingual dictionary for english wikipedia
concepts. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Thierry Declerck, Mehmet Uur
Doan, Bente Maegaard, Joseph Mariani, Jan Odijk,
and Stelios Piperidis, editors, Proceedings of
the Eight International Conference on Language
Resources and Evaluation (LREC’12), Istanbul,
Turkey, may. European Language Resources
Association (ELRA).
</reference>
<page confidence="0.986063">
655
</page>
<reference confidence="0.998392090909091">
Zareen Saba Syed, Tim Finin, and Anupam Joshi.
2008. Wikipedia as an ontology for describing
documents. In ICWSM.
Fei Wu and Daniel S Weld. 2008. Automatically
refining the wikipedia infobox ontology. In
Proceedings of the 17th international conference on
World Wide Web, pages 635–644. ACM.
Ting-Fan Wu, Chih-Jen Lin, and Ruby C Weng. 2004.
Probability estimates for multi-class classification
by pairwise coupling. Journal of Machine Learning
Research, 5(975-1005):4.
</reference>
<page confidence="0.998906">
656
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.303377">
<title confidence="0.998426">Adding High-Precision Links to Wikipedia</title>
<author confidence="0.998004">Thanapon Noraset Chandra Bhagavatula Doug Downey</author>
<affiliation confidence="0.9368825">Department of Electrical Engineering &amp; Computer Northwestern</affiliation>
<address confidence="0.67192">Evanston, IL</address>
<email confidence="0.998328">ddowney@eecs.northwestern.edu</email>
<abstract confidence="0.997201066666667">Wikipedia’s link structure is a valuable resource for natural language processing tasks, but only a fraction of the concepts mentioned in each article are annotated with hyperlinks. In this paper, we study how to augment Wikipedia with additional links. We present a system that identifies concept mentions in Wikipedia text, and links each mention its referent page. rich semantic information present in Wikipedia to achieve high precision. Our demonstrate that add an average of seven new links to each</abstract>
<note confidence="0.538135">Wikipedia article, at a precision of 0.98.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<pages>2--27</pages>
<note>Software available at http://www.csie.ntu.edu.tw/˜cjlin/ libsvm.</note>
<contexts>
<context position="13250" citStr="Chang and Lin, 2011" startWordPosition="2159" endWordPosition="2162"> 10-fold cross validation performance of the initial rankers by Accuracy (excluded ∅-candidate mentions), BOT Precision, BOT Recall, BOT F1 on the 100,000 existing links. into 3 parts. We used 760 mentions for training the final ranker. The linker was trained with 950 mentions and we tested our system using the other 190 mentions. Previous work has used various ML approaches for ranking, such as SVMs (Dredze et al., 2010). We found logistic regression produces similar accuracy to SVMs, but is faster for our feature set. For the linker, we use an SVM with probabilistic output (Wu et al., 2004; Chang and Lin, 2011) to estimate a confidence score for each output link. Precision 4.2 Result We first evaluate 3W’s mention extraction. From the selected 2, 000 articles, the system extracted 59,454 mentions (-30/article), in addition to the original 54,309 links (-27/article). From the 1, 900 hand-labeled mentions, 1, 530 (80.5%) were solvable in that 3W candidate set contained the correct target. As described in section 3.2.4, 3W employs a 2-stage ranker. We first evaluate just the initial ranker, using 10-fold cross validation on 100,000 existing links. We show micro accuracy and bag-of-title (BOT) performan</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27. Software available at http://www.csie.ntu.edu.tw/˜cjlin/ libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on Wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL</booktitle>
<pages>708--716</pages>
<contexts>
<context position="1025" citStr="Cucerzan, 2007" startWordPosition="140" endWordPosition="141">le are annotated with hyperlinks. In this paper, we study how to augment Wikipedia with additional high-precision links. We present 3W, a system that identifies concept mentions in Wikipedia text, and links each mention to its referent page. 3W leverages rich semantic information present in Wikipedia to achieve high precision. Our experiments demonstrate that 3W can add an average of seven new links to each Wikipedia article, at a precision of 0.98. 1 Introduction Wikipedia forms a valuable resource for many Natural Language Processing and Information Extraction tasks, such as Entity Linking (Cucerzan, 2007; Han and Zhao, 2009), Ontology Construction (Wu and Weld, 2008; Syed et al., 2008) and Knowledge Base Population (Hoffart et al., 2013; Lehmann et al., 2013). Wikipedia’s links provide disambiguated semantic information. For example, when a system processes the text “Chicago was received with critical acclaim” from an article, the system does not need to infer the referent entity of “Chicago” if the word is already hyperlinked to the Wikipedia page of the Oscar-winning film. Unfortunately, in Wikipedia only a fraction of the phrases that can be linked are in fact annotated with a hyperlink. T</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on Wikipedia data. In Proceedings of EMNLP-CoNLL 2007, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Paul McNamee</author>
<author>Delip Rao</author>
<author>Adam Gerber</author>
<author>Tim Finin</author>
</authors>
<title>Entity disambiguation for knowledge base population.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>277--285</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="13055" citStr="Dredze et al., 2010" startWordPosition="2125" endWordPosition="2128"> validation. For each fold, we partitioned data 653 Model Acc Prec Recall F1 Prior 0.876 0.891 0.850 0.870 OnlyWikiLink 0.896 0.905 0.871 0.888 −Wiki OnlyWikiLink 0.944 0.950 0.920 0.935 Table 1: 10-fold cross validation performance of the initial rankers by Accuracy (excluded ∅-candidate mentions), BOT Precision, BOT Recall, BOT F1 on the 100,000 existing links. into 3 parts. We used 760 mentions for training the final ranker. The linker was trained with 950 mentions and we tested our system using the other 190 mentions. Previous work has used various ML approaches for ranking, such as SVMs (Dredze et al., 2010). We found logistic regression produces similar accuracy to SVMs, but is faster for our feature set. For the linker, we use an SVM with probabilistic output (Wu et al., 2004; Chang and Lin, 2011) to estimate a confidence score for each output link. Precision 4.2 Result We first evaluate 3W’s mention extraction. From the selected 2, 000 articles, the system extracted 59,454 mentions (-30/article), in addition to the original 54,309 links (-27/article). From the 1, 900 hand-labeled mentions, 1, 530 (80.5%) were solvable in that 3W candidate set contained the correct target. As described in secti</context>
</contexts>
<marker>Dredze, McNamee, Rao, Gerber, Finin, 2010</marker>
<rawString>Mark Dredze, Paul McNamee, Delip Rao, Adam Gerber, and Tim Finin. 2010. Entity disambiguation for knowledge base population. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 277–285. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6629" citStr="Finkel et al., 2005" startWordPosition="1069" endWordPosition="1072">rpus that are hyperlinked), T(sm) is the number of tokens in sm, and |C(m)| is the number of candidate concepts. Intuitively, we prefer a longer surface form that is frequently linked and has a specific meaning. Furthermore, we eliminate common surface forms (i.e. “wall”) by requiring that PL(sm) exceed a threshold. In the previous example, we are left with only “map of the United States”. Because Wikipedia’s concepts are largely noun phrases, 3W only looks for surface forms from top-level noun phrases generated by the Stanford Parser (Socher et al., 2013). In addition, each name entity (NE) (Finkel et al., 2005) is treated as an atomic token, meaning that multi-word NEs such as “California Institute of the Arts” will not be broken into multiple surface forms. Finally, the system pairs the result surface forms with a set of candidate concepts, C(m), and outputs a set of mentions. C(m) consists of those concepts previously linked to the surface form in L. For instance, the surface form “map of the United States” has been linked to three distinct concepts in English Wikipedia. 3.2 Disambiguation Given a set of mentions M from the previous step, The next step is to select a concept t E C(m) for each m E </context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363–370. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Jun Zhao</author>
</authors>
<title>Named entity disambiguation by leveraging wikipedia semantic knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management,</booktitle>
<pages>215--224</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1046" citStr="Han and Zhao, 2009" startWordPosition="142" endWordPosition="145"> with hyperlinks. In this paper, we study how to augment Wikipedia with additional high-precision links. We present 3W, a system that identifies concept mentions in Wikipedia text, and links each mention to its referent page. 3W leverages rich semantic information present in Wikipedia to achieve high precision. Our experiments demonstrate that 3W can add an average of seven new links to each Wikipedia article, at a precision of 0.98. 1 Introduction Wikipedia forms a valuable resource for many Natural Language Processing and Information Extraction tasks, such as Entity Linking (Cucerzan, 2007; Han and Zhao, 2009), Ontology Construction (Wu and Weld, 2008; Syed et al., 2008) and Knowledge Base Population (Hoffart et al., 2013; Lehmann et al., 2013). Wikipedia’s links provide disambiguated semantic information. For example, when a system processes the text “Chicago was received with critical acclaim” from an article, the system does not need to infer the referent entity of “Chicago” if the word is already hyperlinked to the Wikipedia page of the Oscar-winning film. Unfortunately, in Wikipedia only a fraction of the phrases that can be linked are in fact annotated with a hyperlink. This is due to Wikiped</context>
</contexts>
<marker>Han, Zhao, 2009</marker>
<rawString>Xianpei Han and Jun Zhao. 2009. Named entity disambiguation by leveraging wikipedia semantic knowledge. In Proceedings of the 18th ACM conference on Information and knowledge management, pages 215–224. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brent Hecht</author>
<author>Samuel H Carton</author>
<author>Mahmood Quaderi</author>
<author>Johannes Sch¨oning</author>
<author>Martin Raubal</author>
<author>Darren Gergle</author>
<author>Doug Downey</author>
</authors>
<title>Explanatory semantic relatedness and explicit spatialization for exploratory search.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>415--424</pages>
<publisher>ACM.</publisher>
<marker>Hecht, Carton, Quaderi, Sch¨oning, Raubal, Gergle, Downey, 2012</marker>
<rawString>Brent Hecht, Samuel H Carton, Mahmood Quaderi, Johannes Sch¨oning, Martin Raubal, Darren Gergle, and Doug Downey. 2012. Explanatory semantic relatedness and explicit spatialization for exploratory search. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, pages 415–424. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Fabian M Suchanek</author>
<author>Klaus Berberich</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago2: A spatially and temporally enhanced knowledge base from wikipedia.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--28</pages>
<contexts>
<context position="1160" citStr="Hoffart et al., 2013" startWordPosition="160" endWordPosition="163">nt 3W, a system that identifies concept mentions in Wikipedia text, and links each mention to its referent page. 3W leverages rich semantic information present in Wikipedia to achieve high precision. Our experiments demonstrate that 3W can add an average of seven new links to each Wikipedia article, at a precision of 0.98. 1 Introduction Wikipedia forms a valuable resource for many Natural Language Processing and Information Extraction tasks, such as Entity Linking (Cucerzan, 2007; Han and Zhao, 2009), Ontology Construction (Wu and Weld, 2008; Syed et al., 2008) and Knowledge Base Population (Hoffart et al., 2013; Lehmann et al., 2013). Wikipedia’s links provide disambiguated semantic information. For example, when a system processes the text “Chicago was received with critical acclaim” from an article, the system does not need to infer the referent entity of “Chicago” if the word is already hyperlinked to the Wikipedia page of the Oscar-winning film. Unfortunately, in Wikipedia only a fraction of the phrases that can be linked are in fact annotated with a hyperlink. This is due to Wikipedia’s conventions of only linking to each concept once, and only when the links have a certain level of utility for</context>
</contexts>
<marker>Hoffart, Suchanek, Berberich, Weikum, 2013</marker>
<rawString>Johannes Hoffart, Fabian M Suchanek, Klaus Berberich, and Gerhard Weikum. 2013. Yago2: A spatially and temporally enhanced knowledge base from wikipedia. Artificial Intelligence, 194:28–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Knowledge base population: Successful approaches and challenges.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1148--1158</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11329" citStr="Ji and Grishman, 2011" startWordPosition="1850" endWordPosition="1853">rained on L may not might not perform well on M. Our strategy is to leverage L to train an initial ranker, and then hand-label a small set of mentions from M to train a second-stage re-ranker that takes the ranking output of the initial ranker as a feature. 3.3 Linker Our linker is a binary classifier that decides whether to include (link) each mention in M to the final output L∗. Previous work has typically used a linker to determine so-called NIL mentions, where the referred-to concept is not in the target knowledge base (e.g., in the TAC KBP competition, half of the given mentions are NIL (Ji and Grishman, 2011)). The purpose of our linker is slightly different, because we also use a linker to control the precision of our output. We use a probabilistic linker that predicts a confidence estimate that the mention with its top-ranked candidate is correct. Our linker uses the same features as the ranker and an additional set of confidence signals: the number of times the top candidate concept appears in L, and the score difference between the top-ranked candidate and the second-ranked candidate. 4 Experiments and Result In this section, we provide an evaluation of our system and its subcomponents. 4.1 Ex</context>
</contexts>
<marker>Ji, Grishman, 2011</marker>
<rawString>Heng Ji and Ralph Grishman. 2011. Knowledge base population: Successful approaches and challenges. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1148–1158. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jens Lehmann</author>
<author>Robert Isele</author>
<author>Max Jakob</author>
</authors>
<title>Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes,</title>
<location>Sebastian Hellmann, Mohamed Morsey, Patrick van</location>
<marker>Lehmann, Isele, Jakob, </marker>
<rawString>Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick van</rawString>
</citation>
<citation valid="true">
<authors>
<author>S¨oren Auer Kleef</author>
</authors>
<title>Dbpedia-a large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web Journal.</title>
<date>2013</date>
<marker>Kleef, 2013</marker>
<rawString>Kleef, S¨oren Auer, et al. 2013. Dbpedia-a large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web Journal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac 2009 knowledge base population track.</title>
<date>2009</date>
<booktitle>In Text Analysis Conference (TAC),</booktitle>
<volume>17</volume>
<pages>111--113</pages>
<contexts>
<context position="2575" citStr="McNamee and Dang, 2009" startWordPosition="380" endWordPosition="383">at as of September 2013, there were an average of 30 references to Wikipedia concepts left unlinked within each of English Wikipedia’s four million pages. In this paper, our goal is to augment Wikipedia with additional high-precision links, in order to provide a new resource for systems that use Wikipedia’s link structure as a foundation. Identifying references to concepts (called mentions) in text and linking them to Wikipedia is a task known as Wikification. Wikification for general text has been addressed in a wide variety of recent work (Mihalcea and Csomai, 2007; Milne and Witten, 2008b; McNamee and Dang, 2009; Ratinov et al., 2011). The major challenge of this task is to resolve the ambiguity of phrases, and recent work makes use of various kinds of information found in the document to tackle the challenge. In contrast to this body of work, here we focus on the special case of Wikifying Wikipedia articles, instead of general documents. This gives us an advantage over general-text systems due to Wikipedia’s rich content and existing link structure. We introduce 3W, a system that identifies mentions within Wikipedia and links each to its referent concept. We show how a Wikipedia-specific Semantic Re</context>
</contexts>
<marker>McNamee, Dang, 2009</marker>
<rawString>Paul McNamee and Hoa Trang Dang. 2009. Overview of the tac 2009 knowledge base population track. In Text Analysis Conference (TAC), volume 17, pages 111–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>233--242</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2526" citStr="Mihalcea and Csomai, 2007" startWordPosition="372" endWordPosition="375">esource for NLP systems. Our experiments estimate that as of September 2013, there were an average of 30 references to Wikipedia concepts left unlinked within each of English Wikipedia’s four million pages. In this paper, our goal is to augment Wikipedia with additional high-precision links, in order to provide a new resource for systems that use Wikipedia’s link structure as a foundation. Identifying references to concepts (called mentions) in text and linking them to Wikipedia is a task known as Wikification. Wikification for general text has been addressed in a wide variety of recent work (Mihalcea and Csomai, 2007; Milne and Witten, 2008b; McNamee and Dang, 2009; Ratinov et al., 2011). The major challenge of this task is to resolve the ambiguity of phrases, and recent work makes use of various kinds of information found in the document to tackle the challenge. In contrast to this body of work, here we focus on the special case of Wikifying Wikipedia articles, instead of general documents. This gives us an advantage over general-text systems due to Wikipedia’s rich content and existing link structure. We introduce 3W, a system that identifies mentions within Wikipedia and links each to its referent conc</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 233–242. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>509--518</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2550" citStr="Milne and Witten, 2008" startWordPosition="376" endWordPosition="379">r experiments estimate that as of September 2013, there were an average of 30 references to Wikipedia concepts left unlinked within each of English Wikipedia’s four million pages. In this paper, our goal is to augment Wikipedia with additional high-precision links, in order to provide a new resource for systems that use Wikipedia’s link structure as a foundation. Identifying references to concepts (called mentions) in text and linking them to Wikipedia is a task known as Wikification. Wikification for general text has been addressed in a wide variety of recent work (Mihalcea and Csomai, 2007; Milne and Witten, 2008b; McNamee and Dang, 2009; Ratinov et al., 2011). The major challenge of this task is to resolve the ambiguity of phrases, and recent work makes use of various kinds of information found in the document to tackle the challenge. In contrast to this body of work, here we focus on the special case of Wikifying Wikipedia articles, instead of general documents. This gives us an advantage over general-text systems due to Wikipedia’s rich content and existing link structure. We introduce 3W, a system that identifies mentions within Wikipedia and links each to its referent concept. We show how a Wikip</context>
<context position="9436" citStr="Milne and Witten (2008" startWordPosition="1525" endWordPosition="1528">, 2011). In addition to similarities computed over the top-200 words (utilized in the Illinois Wikifier), we also compute similarity features over vectors of all words. 3.2.3 Wikipedia-specific Features Because the links in an article are often related to one another, the existing links in a document form valuable clues for disambiguating mentions in the document. For each concept candidate t E C(m), we compute a Semantic Relatedness (SR) measure between t and each concept from existing links in the source document. Our SR measure is based on the proportion of shared inlinks, as introduced by Milne and Witten (2008b). However, because Milne and Witten were focused on general text, they computed SR only between t and the unambiguous mentions (i.e. those m with |C(m) |= 1) identified in the document. In our work, d(m) is a Wikipedia article which is rich in existing links to Wikipedia concepts, and we can compute SR with all of them, resulting in a valuable feature for disambiguation as illustrated in our experiments. We use the SR implementation of Hecht et al. (2012). It is a modified version of Milne and Witten’s measure that emphasizes links in Wikipedia article’s overview. In addition, we add boolean</context>
<context position="13883" citStr="Milne and Witten (2008" startWordPosition="2256" endWordPosition="2259">e a confidence score for each output link. Precision 4.2 Result We first evaluate 3W’s mention extraction. From the selected 2, 000 articles, the system extracted 59,454 mentions (-30/article), in addition to the original 54,309 links (-27/article). From the 1, 900 hand-labeled mentions, 1, 530 (80.5%) were solvable in that 3W candidate set contained the correct target. As described in section 3.2.4, 3W employs a 2-stage ranker. We first evaluate just the initial ranker, using 10-fold cross validation on 100,000 existing links. We show micro accuracy and bag-of-title (BOT) performance used by Milne and Witten (2008b) in Table 1. The ranker with all features (OnlyWikiLink) outperforms the ranker without Wikipedia-specific features (OnlyWikiLink−Wiki) by approximately five points in F1. This demonstrates that Wikipedia’s rich semantic content is helpful for disambiguation. Next, we evaluate our full system performance (disambiguation and linking) over the hand-labeled evaluation set. We experimented with different configurations of the rankers and linkers. Our Baseline system disambiguates a mention m by selecting the most common concept for the surface s(m). OnlyWikiLink uses the ranker model trained on </context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H Witten. 2008b. Learning to link with wikipedia. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 509–518. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2598" citStr="Ratinov et al., 2011" startWordPosition="384" endWordPosition="387"> there were an average of 30 references to Wikipedia concepts left unlinked within each of English Wikipedia’s four million pages. In this paper, our goal is to augment Wikipedia with additional high-precision links, in order to provide a new resource for systems that use Wikipedia’s link structure as a foundation. Identifying references to concepts (called mentions) in text and linking them to Wikipedia is a task known as Wikification. Wikification for general text has been addressed in a wide variety of recent work (Mihalcea and Csomai, 2007; Milne and Witten, 2008b; McNamee and Dang, 2009; Ratinov et al., 2011). The major challenge of this task is to resolve the ambiguity of phrases, and recent work makes use of various kinds of information found in the document to tackle the challenge. In contrast to this body of work, here we focus on the special case of Wikifying Wikipedia articles, instead of general documents. This gives us an advantage over general-text systems due to Wikipedia’s rich content and existing link structure. We introduce 3W, a system that identifies mentions within Wikipedia and links each to its referent concept. We show how a Wikipedia-specific Semantic Relatedness measure that </context>
<context position="8821" citStr="Ratinov et al., 2011" startWordPosition="1427" endWordPosition="1430">Chang, 2012) to get the estimates for the probability from links outside Wikipedia. 3.2.2 Lexical Features To make use of text around a mention m, we create bag-of-word vectors of the mention’s source document d(m), and of a set of words surrounding the mention, referred to as the context c(m). To compare with a concept, we also create bag-of-word vectors of candidate concept’s document d(t) and candidate concept’s context c(t). We then compute cosine similarities between the mention’s vectors for d(m) and c(m), with the concept candidate vectors for d(t) and c(t) as in the Illinois Wikifier (Ratinov et al., 2011). In addition to similarities computed over the top-200 words (utilized in the Illinois Wikifier), we also compute similarity features over vectors of all words. 3.2.3 Wikipedia-specific Features Because the links in an article are often related to one another, the existing links in a document form valuable clues for disambiguating mentions in the document. For each concept candidate t E C(m), we compute a Semantic Relatedness (SR) measure between t and each concept from existing links in the source document. Our SR measure is based on the proportion of shared inlinks, as introduced by Milne a</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>John Bauer</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Parsing with compositional vector grammars. In</title>
<date>2013</date>
<booktitle>In Proceedings of the ACL conference. Citeseer.</booktitle>
<contexts>
<context position="6571" citStr="Socher et al., 2013" startWordPosition="1059" endWordPosition="1062">the fraction of the occurrences of the string sm in the corpus that are hyperlinked), T(sm) is the number of tokens in sm, and |C(m)| is the number of candidate concepts. Intuitively, we prefer a longer surface form that is frequently linked and has a specific meaning. Furthermore, we eliminate common surface forms (i.e. “wall”) by requiring that PL(sm) exceed a threshold. In the previous example, we are left with only “map of the United States”. Because Wikipedia’s concepts are largely noun phrases, 3W only looks for surface forms from top-level noun phrases generated by the Stanford Parser (Socher et al., 2013). In addition, each name entity (NE) (Finkel et al., 2005) is treated as an atomic token, meaning that multi-word NEs such as “California Institute of the Arts” will not be broken into multiple surface forms. Finally, the system pairs the result surface forms with a set of candidate concepts, C(m), and outputs a set of mentions. C(m) consists of those concepts previously linked to the surface form in L. For instance, the surface form “map of the United States” has been linked to three distinct concepts in English Wikipedia. 3.2 Disambiguation Given a set of mentions M from the previous step, T</context>
</contexts>
<marker>Socher, Bauer, Manning, Ng, 2013</marker>
<rawString>Richard Socher, John Bauer, Christopher D Manning, and Andrew Y Ng. 2013. Parsing with compositional vector grammars. In In Proceedings of the ACL conference. Citeseer.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Valentin I Spitkovsky</author>
<author>Angel X Chang</author>
</authors>
<title>A cross-lingual dictionary for english wikipedia concepts.</title>
<date>2012</date>
<booktitle>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Uur Doan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors,</editor>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="8212" citStr="Spitkovsky and Chang, 2012" startWordPosition="1328" endWordPosition="1331">he features utilized by the ranker. The first two feature groups are commonly used in Wikification systems. The third feature group is specifically designed for mentions in Wikipedia articles. 3.2.1 Prior Probability Features The conditional probability of a concept t given mention surface sm, P(t|sm), is a common feature used for disambiguation. It forms a very strong Wikification baseline (∼ 86% in micro-accuracy). This probability can be estimated using Wikipedia links (L). In addition, we use the external partition of the �Score(M) = mEM 652 Google “Cross-Lingual Dictionary” described in (Spitkovsky and Chang, 2012) to get the estimates for the probability from links outside Wikipedia. 3.2.2 Lexical Features To make use of text around a mention m, we create bag-of-word vectors of the mention’s source document d(m), and of a set of words surrounding the mention, referred to as the context c(m). To compare with a concept, we also create bag-of-word vectors of candidate concept’s document d(t) and candidate concept’s context c(t). We then compute cosine similarities between the mention’s vectors for d(m) and c(m), with the concept candidate vectors for d(t) and c(t) as in the Illinois Wikifier (Ratinov et a</context>
</contexts>
<marker>Spitkovsky, Chang, 2012</marker>
<rawString>Valentin I. Spitkovsky and Angel X. Chang. 2012. A cross-lingual dictionary for english wikipedia concepts. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Uur Doan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zareen Saba Syed</author>
<author>Tim Finin</author>
<author>Anupam Joshi</author>
</authors>
<title>Wikipedia as an ontology for describing documents.</title>
<date>2008</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="1108" citStr="Syed et al., 2008" startWordPosition="152" endWordPosition="155">dia with additional high-precision links. We present 3W, a system that identifies concept mentions in Wikipedia text, and links each mention to its referent page. 3W leverages rich semantic information present in Wikipedia to achieve high precision. Our experiments demonstrate that 3W can add an average of seven new links to each Wikipedia article, at a precision of 0.98. 1 Introduction Wikipedia forms a valuable resource for many Natural Language Processing and Information Extraction tasks, such as Entity Linking (Cucerzan, 2007; Han and Zhao, 2009), Ontology Construction (Wu and Weld, 2008; Syed et al., 2008) and Knowledge Base Population (Hoffart et al., 2013; Lehmann et al., 2013). Wikipedia’s links provide disambiguated semantic information. For example, when a system processes the text “Chicago was received with critical acclaim” from an article, the system does not need to infer the referent entity of “Chicago” if the word is already hyperlinked to the Wikipedia page of the Oscar-winning film. Unfortunately, in Wikipedia only a fraction of the phrases that can be linked are in fact annotated with a hyperlink. This is due to Wikipedia’s conventions of only linking to each concept once, and onl</context>
</contexts>
<marker>Syed, Finin, Joshi, 2008</marker>
<rawString>Zareen Saba Syed, Tim Finin, and Anupam Joshi. 2008. Wikipedia as an ontology for describing documents. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Automatically refining the wikipedia infobox ontology.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th international conference on World Wide Web,</booktitle>
<pages>635--644</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1088" citStr="Wu and Weld, 2008" startWordPosition="148" endWordPosition="151">w to augment Wikipedia with additional high-precision links. We present 3W, a system that identifies concept mentions in Wikipedia text, and links each mention to its referent page. 3W leverages rich semantic information present in Wikipedia to achieve high precision. Our experiments demonstrate that 3W can add an average of seven new links to each Wikipedia article, at a precision of 0.98. 1 Introduction Wikipedia forms a valuable resource for many Natural Language Processing and Information Extraction tasks, such as Entity Linking (Cucerzan, 2007; Han and Zhao, 2009), Ontology Construction (Wu and Weld, 2008; Syed et al., 2008) and Knowledge Base Population (Hoffart et al., 2013; Lehmann et al., 2013). Wikipedia’s links provide disambiguated semantic information. For example, when a system processes the text “Chicago was received with critical acclaim” from an article, the system does not need to infer the referent entity of “Chicago” if the word is already hyperlinked to the Wikipedia page of the Oscar-winning film. Unfortunately, in Wikipedia only a fraction of the phrases that can be linked are in fact annotated with a hyperlink. This is due to Wikipedia’s conventions of only linking to each c</context>
</contexts>
<marker>Wu, Weld, 2008</marker>
<rawString>Fei Wu and Daniel S Weld. 2008. Automatically refining the wikipedia infobox ontology. In Proceedings of the 17th international conference on World Wide Web, pages 635–644. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ting-Fan Wu</author>
<author>Chih-Jen Lin</author>
<author>Ruby C Weng</author>
</authors>
<title>Probability estimates for multi-class classification by pairwise coupling.</title>
<date>2004</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>5--975</pages>
<contexts>
<context position="13228" citStr="Wu et al., 2004" startWordPosition="2155" endWordPosition="2158">20 0.935 Table 1: 10-fold cross validation performance of the initial rankers by Accuracy (excluded ∅-candidate mentions), BOT Precision, BOT Recall, BOT F1 on the 100,000 existing links. into 3 parts. We used 760 mentions for training the final ranker. The linker was trained with 950 mentions and we tested our system using the other 190 mentions. Previous work has used various ML approaches for ranking, such as SVMs (Dredze et al., 2010). We found logistic regression produces similar accuracy to SVMs, but is faster for our feature set. For the linker, we use an SVM with probabilistic output (Wu et al., 2004; Chang and Lin, 2011) to estimate a confidence score for each output link. Precision 4.2 Result We first evaluate 3W’s mention extraction. From the selected 2, 000 articles, the system extracted 59,454 mentions (-30/article), in addition to the original 54,309 links (-27/article). From the 1, 900 hand-labeled mentions, 1, 530 (80.5%) were solvable in that 3W candidate set contained the correct target. As described in section 3.2.4, 3W employs a 2-stage ranker. We first evaluate just the initial ranker, using 10-fold cross validation on 100,000 existing links. We show micro accuracy and bag-of</context>
</contexts>
<marker>Wu, Lin, Weng, 2004</marker>
<rawString>Ting-Fan Wu, Chih-Jen Lin, and Ruby C Weng. 2004. Probability estimates for multi-class classification by pairwise coupling. Journal of Machine Learning Research, 5(975-1005):4.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>