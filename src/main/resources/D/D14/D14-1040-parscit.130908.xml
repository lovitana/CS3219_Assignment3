<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99918">
Probabilistic Models of Cross-Lingual Semantic Similarity in Context
Based on Latent Cross-Lingual Concepts Induced from Comparable Data
</title>
<author confidence="0.996035">
Ivan Vuli´c and Marie-Francine Moens
</author>
<affiliation confidence="0.999719">
Department of Computer Science
</affiliation>
<address confidence="0.678552">
KU Leuven, Belgium
</address>
<email confidence="0.997291">
{ivan.vulic|marie-francine.moens}@cs.kuleuven.be
</email>
<sectionHeader confidence="0.998587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999848458333333">
We propose the first probabilistic approach
to modeling cross-lingual semantic sim-
ilarity (CLSS) in context which requires
only comparable data. The approach re-
lies on an idea of projecting words and
sets of words into a shared latent semantic
space spanned by language-pair indepen-
dent latent semantic concepts (e.g., cross-
lingual topics obtained by a multilingual
topic model). These latent cross-lingual
concepts are induced from a comparable
corpus without any additional lexical re-
sources. Word meaning is represented as
a probability distribution over the latent
concepts, and a change in meaning is rep-
resented as a change in the distribution
over these latent concepts. We present new
models that modulate the isolated out-of-
context word representations with contex-
tual knowledge. Results on the task of
suggesting word translations in context for
3 language pairs reveal the utility of the
proposed contextualized models of cross-
lingual semantic similarity.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99986975">
Cross-lingual semantic similarity (CLSS) is a met-
ric that measures to which extent words (or more
generally, text units) describe similar semantic
concepts and convey similar meanings across lan-
guages. Models of cross-lingual similarity are typ-
ically used to automatically induce bilingual lexi-
cons and have found numerous applications in in-
formation retrieval (IR), statistical machine trans-
lation (SMT) and other natural language process-
ing (NLP) tasks. Within the IR framework, the
output of the CLSS models is a key resource in
the models of dictionary-based cross-lingual in-
formation retrieval (Ballesteros and Croft, 1997;
Lavrenko et al., 2002; Levow et al., 2005; Wang
and Oard, 2006) or may be utilized in query ex-
pansion in cross-lingual IR models (Adriani and
van Rijsbergen, 1999; Vuli´c et al., 2013). These
CLSS models may also be utilized as an addi-
tional source of knowledge in SMT systems (Och
and Ney, 2003; Wu et al., 2008). Additionally,
the models are a crucial component in the cross-
lingual tasks involving a sort of cross-lingual
knowledge transfer, where the knowledge about
utterances in one language may be transferred to
another. The utility of the transfer or annotation
projection by means of bilingual lexicons obtained
from the CLSS models has already been proven
in various tasks such as semantic role labeling
(Pad´o and Lapata, 2009; van der Plas et al., 2011),
parsing (Zhao et al., 2009; Durrett et al., 2012;
T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky
and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om
et al., 2013a; Ganchev and Das, 2013), verb clas-
sification (Merlo et al., 2002), inducing selectional
preferences (Peirsman and Pad´o, 2010), named
entity recognition (Kim et al., 2012), named en-
tity segmentation (Ganchev and Das, 2013), etc.
The models of cross-lingual semantic similar-
ity from parallel corpora rely on word alignment
models (Brown et al., 1993; Och and Ney, 2003),
but due to a relative scarceness of parallel texts for
many language pairs and domains, the models of
cross-lingual similarity from comparable corpora
have gained much attention recently.
All these models from parallel and compara-
ble corpora provide ranked lists of semantically
similar words in the target language in isolation
or invariably, that is, they do not explicitly iden-
</bodyText>
<page confidence="0.986258">
349
</page>
<note confidence="0.910693">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 349–362,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999846041666667">
tify and encode different senses of words. In
practice, it means that, given the sentence “The
coach of his team was not satisfied with the game
yesterday.”, these context-insensitive models of
similarity are not able to detect that the Spanish
word entrenador is more similar to the polyse-
mous word coach in the context of this sentence
than the Spanish word autocar, although auto-
car is listed as the most semantically similar word
to coach globally/invariably without any observed
context. In another example, while Spanish words
partido, encuentro, cerilla or correspondencia are
all highly similar to the ambiguous English word
match when observed in isolation, given the Span-
ish sentence ”She was unable to find a match in
her pocket to light up a cigarette.”, it is clear that
the strength of semantic similarity should change
in context as only cerilla exhibits a strong seman-
tic similarity to match within this particular sen-
tential context.
Following this intuition, in this paper we inves-
tigate models of cross-lingual semantic similarity
in context. The context-sensitive models of sim-
ilarity target to re-rank the lists of semantically
similar words based on the co-occurring contexts
of words. Unlike prior work (e.g., (Ng et al., 2003;
Prior et al., 2011; Apidianaki, 2011)), we explore
these models in a particularly difficult and min-
imalist setting that builds only on co-occurrence
counts and latent cross-lingual semantic concepts
induced directly from comparable corpora, and
which does not rely on any other resource (e.g.,
machine-readable dictionaries, parallel corpora,
explicit ontology and category knowledge). In
that respect, the work reported in this paper ex-
tends the current research on purely statistical
data-driven distributional models of cross-lingual
semantic similarity that are built upon the idea
of latent cross-lingual concepts (Haghighi et al.,
2008; Daum´e III and Jagarlamudi, 2011; Vuli´c et
al., 2011; Vuli´c and Moens, 2013) induced from
non-parallel data. While all the previous mod-
els in this framework are context-insensitive mod-
els of semantic similarity, we demonstrate how to
build context-aware models of semantic similarity
within the same probabilistic framework which re-
lies on the same shared set of latent concepts.
The main contributions of this paper are:
</bodyText>
<listItem confidence="0.936116090909091">
• We present a new probabilistic approach to
modeling cross-lingual semantic similarity in
context based on latent cross-lingual seman-
tic concepts induced from non-parallel data.
• We show how to use the models of cross-
lingual semantic similarity in the task of sug-
gesting word translations in context.
• We provide results for three language
pairs which demonstrate that contextualized
models of similarity significantly outscore
context-insensitive models.
</listItem>
<sectionHeader confidence="0.962858" genericHeader="introduction">
2 Towards Cross-Lingual Semantic
Similarity in Context
</sectionHeader>
<subsectionHeader confidence="0.792341">
Latent Cross-Lingual Concepts. Latent cross-
</subsectionHeader>
<bodyText confidence="0.99980828">
lingual concepts/senses may be interpreted as
language-independent semantic concepts present
in a multilingual corpus (e.g., document-aligned
Wikipedia articles in English, Spanish and Dutch)
that have their language-specific representations in
different languages. For instance, having a multi-
lingual collection in English, Spanish and Dutch,
and then discovering a latent semantic concept
on Soccer, that concept would be represented by
words (actually probabilities over words P(w|zk),
where w denotes a word, and zk denotes k-th
latent concept): {player, goal, coach, ... } in
English, bal´on (ball), futbolista (soccer player),
equipo (team), ... } in Spanish, and {wedstrijd
(match), elftal (soccer team), doelpunt (goal),... }
in Dutch. Given a multilingual corpus C, the goal
is to learn and extract a set Z of K latent cross-
lingual concepts {zi, ... , zK} that optimally de-
scribe the observed data, that is, the multilingual
corpus C. Extracting cross-lingual concepts ac-
tually implies learning per-document concept dis-
tributions for each document in the corpus, and
discovering language-specific representations of
these concepts given by per-concept word distri-
butions in each language.
</bodyText>
<equation confidence="0.984687">
Z = {zi, ... , zK} represents the set of K la-
</equation>
<bodyText confidence="0.998902923076923">
tent cross-lingual concepts present in the multilin-
gual corpus. These K semantic concepts actually
span a latent cross-lingual semantic space. Each
word w, irrespective of its actual language, may
be represented in that latent semantic space as a
K-dimensional vector, where each vector compo-
nent is a conditional concept score P(zk|w).
A number of models may be employed to in-
duce the latent concepts. For instance, one could
use cross-lingual Latent Semantic Indexing (Du-
mais et al., 1996), probabilistic Principal Compo-
nent Analysis (Tipping and Bishop, 1999), or a
probabilistic interpretation of non-negative matrix
</bodyText>
<page confidence="0.993983">
350
</page>
<bodyText confidence="0.979318851851852">
factorization (Lee and Seung, 1999; Gaussier and
Goutte, 2005; Ding et al., 2008) on concatenated
documents in aligned document pairs. Other more
recent models include matching canonical correla-
tion analysis (Haghighi et al., 2008; Daum´e III and
Jagarlamudi, 2011) and multilingual probabilistic
topic models (Ni et al., 2009; De Smet and Moens,
2009; Mimno et al., 2009; Boyd-Graber and Blei,
2009; Zhang et al., 2010; Fukumasu et al., 2012).
Due to its inherent language pair indepen-
dent nature and state-of-the-art performance in the
tasks such as bilingual lexicon extraction (Vuli´c et
al., 2011) and cross-lingual information retrieval
(Vuli´c et al., 2013), the description in this pa-
per relies on the multilingual probabilistic topic
modeling (MuPTM) framework. We draw a di-
rect parallel between latent cross-lingual concepts
and latent cross-lingual topics, and we present
the framework from the MuPTM perspective, but
the proposed framework is generic and allows the
usage of all other models that are able to com-
pute probability scores P(zk|w). These scores in
MuPTM are induced from their output language-
specific per-topic word distributions. The mul-
tilingual probabilistic topic models output prob-
ability scores P(wSi |zk) and P(wTj |zk) for each
wSi E V S and wTj E VT and each zk E
</bodyText>
<equation confidence="0.9869675">
Z, and it holds Ew S∈V S P(ws |zk) = 1 and
i
EwT ∈V T P(wj  |zk) = 1. The scores are then
vec(wS1 ) = [P(z1|wS1 ),..., P(zK|wS1 )] (1)
</equation>
<bodyText confidence="0.934760253521127">
Similarly, we are able to represent any target lan-
guage word wT2 in the same latent semantic space
by a K-dimensional vector with scores P(zk|wT2 ).
Each word regardless of its language is repre-
sented as a distribution over K latent concepts.
The similarity between wS1 and some word wT2 E
V T is then computed as the similarity between
their K-dimensional vector representations using
some of the standard similarity measures (e.g.,
the Kullback-Leibler or the Jensen-Shannon diver-
gence, the cosine measure). These methods use
only global co-occurrence statistics from the train-
ing set and do not take into account any contex-
tual information. They provide only out-of-context
word representations and are therefore able to de-
liver only context-insensitive models of similarity.
Defining Context. Given an occurrence of a
word wS1 , we build its context set Con(wS1 ) =
{cwS1 , ... , cwSr } that comprises r words from V S
that co-occur with wS1 in a defined contextual
scope or granularity. In this work we do not in-
vestigate the influence of the context scope (e.g.,
document-based, paragraph-based, window-based
contexts). Following the recent work from Huang
et al. (2012) in the monolingual setting, we
limit the contextual scope to the sentential context.
However, we emphasize that the proposed models
are designed to be fully functional regardless of
the actual chosen context granularity. e.g., when
operating in the sentential context, Con(wS1 ) con-
sists of words occurring in the same sentence with
the particular instance of wS1 . Following Mitchell
and Lapata (2008), for the sake of simplicity, we
impose the bag-of-words assumption, and do not
take into account the order of words in the context
set as well as context words’ dependency relations
to wS1 . Investigating different context types (e.g.,
dependency-based) is a subject of future work.
By using all words occurring with wS1 in a con-
text set (e.g., a sentence) to build the set Con(wS1 ),
we do not make any distinction between “infor-
mative and “uninformative” context words. How-
ever, some context words bear more contextual in-
formation about the observed word wS1 and are
stronger indicators of the correct word meaning in
that particular context. For instance, in the sen-
tence “The coach of his team was not satisfied
with the game yesterday”, words game and team
are strong clues that coach should be translated
as entrenador while the context word yesterday
does not bring any extra contextual information
that could resolve the ambiguity.
Therefore, in the final context set Con(wS1 ) it
is useful to retain only the context words that re-
j
used to compute scores P(zk|wSi ) and P(zk|wT j )
in order to represent words from the two different
languages in the same latent semantic space in a
uniform way.
Context-Insensitive Models of Similarity. With-
out observing any context, the standard models of
semantic word similarity that rely on the seman-
tic space spanned by latent cross-lingual concepts
in both monolingual (Dinu and Lapata, 2010a;
Dinu and Lapata, 2010b) and multilingual set-
tings (Vuli´c et al., 2011) typically proceed in the
following manner. Latent language-independent
concepts (e.g., cross-lingual topics or latent word
senses) are estimated on a large corpus. The
K-dimensional vector representation of the word
wS 1 E V S is:
</bodyText>
<page confidence="0.997199">
351
</page>
<bodyText confidence="0.99661195">
ally bring extra semantic information. We achieve
that by exploiting the same latent semantic space
to provide the similarity score between the ob-
served word wi and each word cws, i = 1, ... , r
from its context set Con(wi ). Each word cws
may be represented by its vector vec(cws) (see eq.
(1)) in the same latent semantic space, and there
we can compute the similarity between its vec-
tor and vec(wi ). We can then sort the similarity
scores for each cws and retain only the top scoring
M context words in the final set Con(wi ). The
procedure of context sorting and pruning should
improve the semantic cohesion between wi and
its context since only informative context features
are now present in Con(wi ), and we reduce the
noise coming from uninformative contextual fea-
tures that are not semantically related to wi . Other
options for the context sorting and pruning are
possible, but the main goal in this paper is to il-
lustrate the core utility of the procedure.
</bodyText>
<sectionHeader confidence="0.818764" genericHeader="method">
3 Cross-Lingual Semantic Similarity in
Context via Latent Concepts
</sectionHeader>
<bodyText confidence="0.999909541666667">
Representing Context. The probabilistic frame-
work that is supported by latent cross-lingual con-
cepts allows for having the K-dimensional vector
representations in the same latent semantic space
spanned by cross-lingual topics for: (1) Single
words regardless of their actual language, and (2)
Sets that comprise multiple words. Therefore, we
are able to project the observed source word, all
target words, and the context set of the observed
source word to the same latent semantic space
spanned by latent cross-lingual concepts.
Eq. (1) shows how to represent single words in
the latent semantic space. Now, we present a way
to address compositionality, that is, we show how
to build the same representations in the same latent
semantic space beyond the word level. We need to
compute a conditional concept distribution for the
context set Con(wi ), that is, we have to compute
the probability scores P(zk|Con(wi )) for each
zk E Z. Remember that the context Con(wi )
is actually a set of r (or M after pruning) words
Con(wi ) = {cwi , ... , cws}. Under the single-
topic assumption (Griffiths et al., 2007) and fol-
lowing Bayes’ rule, it holds:
</bodyText>
<equation confidence="0.999613142857143">
S P(Con(w1 )|zk)P(zk)
P(zk|Con(w1 )) = P(Con(wS1 ))
P(cwS1 ,... ,cwSr |zk)P(zk) =(2)
Pl=1 P(cwS1 , ... , cwSr |zl)P(zl)
Qrj=1 P(cwSj |zk)P(zk)
= (3)
Pl=1 Qjr=1 P(cwjS |zl)P(zl)
</equation>
<bodyText confidence="0.999921888888889">
Note that here we use a simplification where we
assume that all cwt E Con(wi ) are condition-
ally independent given zk. The assumption of the
conditional independence of unigrams is a stan-
dard heuristic applied in bag-of-words model in
NLP and IR (e.g., one may observe a direct anal-
ogy to probabilistic language models for IR where
the assumption of independence of query words
is imposed (Ponte and Croft, 1998; Hiemstra,
1998; Lavrenko and Croft, 2001)), but we have
to forewarn the reader that in general the equa-
tion P(cwi , ... , cws |zk) = H�=1 P(cw� |zk) is
not exact. However, by adopting the conditional
independence assumption, in case of the uniform
topic prior P(zk) (i.e., we assume that we do not
posses any prior knowledge about the importance
of latent cross-lingual concepts in a multilingual
corpus), eq. (3) may be further simplified:
</bodyText>
<equation confidence="0.998247333333333">
Qr j=1 P(cwS j |zk)
P(zk|Con(wS 1 )) ≈ PK Qr j=1 P(cwS j |zl) (4)
l=1
</equation>
<bodyText confidence="0.934074">
The representation of the context set in the latent
semantic space is then:
</bodyText>
<equation confidence="0.922403">
vec(Con(wS1 )) = [P(z1|Con(wS1 )), ... , P(zK|Con(wS1 ))]
</equation>
<bodyText confidence="0.999935347826087">
We can then compute the similarity between
words and sets of words given in the same latent
semantic space in a uniform way, irrespective of
their actual language. We use all these properties
when building our context-sensitive CLSS mod-
els.
One remark: As a by-product of our modeling
approach, by this procedure for computing repre-
sentations for sets of words, we have in fact paved
the way towards compositional cross-lingual mod-
els of similarity which rely on latent cross-lingual
concepts. Similar to compositional models in
monolingual settings (Mitchell and Lapata, 2010;
Rudolph and Giesbrecht, 2010; Baroni and Zam-
parelli, 2010; Socher et al., 2011; Grefenstette
and Sadrzadeh, 2011; Blacoe and Lapata, 2012;
Clarke, 2012; Socher et al., 2012) and multilingual
settings (Hermann and Blunsom, 2014; Koˇcisk´y
et al., 2014), the representation of a set of words
(e.g., a phrase or a sentence) is exactly the same
as the representation of a single word; it is simply
a K-dimensional real-valued vector. Our work on
inducing structured representations of words and
</bodyText>
<page confidence="0.991999">
352
</page>
<bodyText confidence="0.999554037037037">
text units beyond words is similar to (Klemen-
tiev et al., 2012; Hermann and Blunsom, 2014;
Koˇcisk´y et al., 2014), but unlike them, we do not
need high-quality sentence-aligned parallel data to
induce bilingual text representations. Moreover,
this work on compositionality in multilingual set-
tings is only preliminary (e.g., we treat phrases and
sentences as bags-of-words), and in future work
we will aim to include syntactic information in the
composition models as already done in monolin-
gual settings (Socher et al., 2012; Hermann and
Blunsom, 2013).
Intuition behind the Approach. Going back to
our novel CLSS models in context, these models
rely on the representations of words and their con-
texts in the same latent semantic space spanned by
latent cross-lingual concepts/topics. The models
differ in the way the contextual knowledge is fused
with the out-of-context word representations.
The key idea behind these models is to repre-
sent a word wS1 in the latent semantic space as a
distribution over the latent cross-lingual concepts,
but now with an additional modulation of the rep-
resentation after taking its local context into ac-
count. The modulated word representation in the
semantic space spanned by K latent cross-lingual
concepts is then:
</bodyText>
<equation confidence="0.97036">
vec(wS1 , Con(wS1 )) = [P&apos;(z1|wS1 ), ... , P&apos;(zK|wS1 )] (5)
</equation>
<bodyText confidence="0.95520719047619">
where P&apos;(zK|wS1 ) denotes the recalculated (or
modulated) probability score for the conditional
concept/topic distribution of wS1 after observing its
context Con(wS1 ). For an illustration of the key
idea, see fig. 1. The intuition is that the context
helps to disambiguate the true meaning of the oc-
currence of the word wS1 . In other words, after
observing the context of the word wS1 , fewer latent
cross-lingual concepts will share most of the prob-
ability mass in the modulated context-aware word
representation.
Model I: Direct-Fusion. The first approach
makes the conditional distribution over latent se-
mantic concepts directly dependent on both word
wS 1 and its context Con(wS1 ). The probability
score P&apos;(zk|wS1 ) from eq. (5) for each zk E i is
then given as P&apos;(zk|wS1 ) = P(zk|wS1 , Con(wS1 )).
We have to estimate the probability
P(zk|wS1 , Con(wS1 )), that is, the probability that
word wS1 is assigned to the latent concept/topic zk
given its context Con(wS1 ):
</bodyText>
<equation confidence="0.729125">
(zk, w )P(Con(w1 )|z
P(zk |wS1 , Con(wS1)) K1P k) (6)=El=1 P(zl,wS1 n(wi)|zl)
Since P(zk, wS1 ) = P(wS1 |zk)P(zk), if we closely
</equation>
<bodyText confidence="0.9932615">
follow the derivation from eq. (3) which shows
how to project context into the latent semantic
space (and again assume the uniform topic prior
P (zk)), we finally obtain the following formula:
</bodyText>
<equation confidence="0.9982145">
P&apos;(zk|wS P(wS1|zk) IIjr=1 P(cwSj |zk) (7)
El=1 P(wS1 |zl) IIrj=1 P(cw3flzl)
</equation>
<bodyText confidence="0.9976174">
The ranking of all words wT2 E VT according to
their similarity to wS1 may be computed by detect-
ing the similarity score between their representa-
tion in the K-dimensional latent semantic space
and the modulated source word representation as
given by eq. (5) and eq. (7) using any of the ex-
isting similarity functions (Lee, 1999; Cha, 2007).
The similarity score Sim(wS1 , wT2 , Con(wS1 )) be-
tween some wT2 E VT represented by its vector
vec(wT2 ) and the observed word wS1 given its con-
</bodyText>
<equation confidence="0.717253">
text Con(wS1 ) is computed as:
sim(wS1 , wT2 , Con(wS1 ))
= SF(vec(ws, Con(wS1 )), vec(w2)) (8)
</equation>
<bodyText confidence="0.9942995">
where SF denotes a similarity function. Words
are then ranked according to their respective sim-
ilarity scores and the best scoring candidate may
be selected as the best translation of an oc-
currence of the word wS1 given its local con-
text. Since the contextual knowledge is inte-
grated directly into the estimation of probability
P(zk|wS1 , Con(wS1 )), we name this context-aware
CLSS model the Direct-Fusion model.
Model II: Smoothed-Fusion. The next model
follows the modeling paradigm established within
the framework of language modeling (LM), where
the idea is to “back off” to a lower order N-
gram in case we do not possess any evidence
about a higher-order N-gram (Jurafsky and Mar-
tin, 2000). The idea now is to smooth the repre-
sentation of a word in the latent semantic space
induced only by the words in its local context
with the out-of-context type-based representation
of that word induced directly from a large training
corpus. In other words, the modulated probability
score P&apos;(zk|wS1 ) from eq. (5) is calculated as:
</bodyText>
<equation confidence="0.676896">
P&apos;(zk|wS1 ) = λ1P(zk|Con(wS1 )) + (1 − λ1)P(zk|wS1 ) (9)
</equation>
<bodyText confidence="0.9993394">
where λ1 is the interpolation parameter, P(zk|wS1 )
is the out-of-context conditional concept probabil-
ity score as in eq. (1), and P(zk|Con(wS1 )) is
given by eq. (3). This model compromises be-
tween the pure contextual word representation and
</bodyText>
<page confidence="0.9925">
353
</page>
<figure confidence="0.9983631">
z2
coach
autocar
coach
(ia isolatioa)
z3
autocar
ent?nador
1
coach
coach
z2
(coatextualized)
The coach of his team was not
satisfied with the game yesterday.
entynador
1
z3
K K
CONTEXT-INSENSITIVE CONTEXT-SENSITIVE
</figure>
<figureCaption confidence="0.998981">
Figure 1: An illustrative toy example of the main intuitions in our probabilistic framework for building
</figureCaption>
<bodyText confidence="0.997249333333333">
context sensitive models with only three latent cross-lingual concepts (axes z1, z2 and z3): A change
in meaning is reflected as a change in a probability distribution over latent cross-lingual concepts that
span a shared latent semantic space. A change in the probability distribution may then actually steer an
English word coach towards its correct (Spanish) meaning in context.
the out-of-context word representation. In cases
when the local context of word wS1 is informa-
tive enough, the factor P(zk|Con(wS1 )) is suffi-
cient to provide the ranking of terms in V T, that
is, to detect words that are semantically similar to
wS1 based on its context. However, if the context is
not reliable, we have to smooth the pure context-
based representation with the out-of-context word
representation (the factor P(zk|wS1 )). We call this
model the Smoothed-Fusion model.
The ranking of words wT2 ∈ V T then finally
proceeds in the same manner as in Direct-Fusion
following eq. (8), but now using eq. (9) for the
modulated probability scores P&apos;(zk|wS1 ).
Model III: Late-Fusion. The last model is con-
ceptually similar to Smoothed-Fusion, but it per-
forms smoothing at a later stage. It proceeds in
two steps: (1) Given a target word wT2 ∈ V T, the
model computes similarity scores separately be-
tween (i) the context set Con(wS1 ) and wT2 , and
(ii) the word wS1 in isolation and wT2 (again, on the
type level); (2) It linearly combines the obtained
similarity scores. More formally, we may write:
</bodyText>
<equation confidence="0.91009525">
Sim(ws , w2 , Con(ws ))
� ��
= λ2SF vec�Con(w� 1 )�, vec�w� 2
+ (1 − λ2)SF(vec(ws), vec(w2)) (10)
</equation>
<bodyText confidence="0.9950985">
where A2 is the interpolation parameter. Since
this model computes the similarity with each tar-
get word separately for the source word in isola-
tion and its local context, and combines the ob-
tained similarity scores after the computations,
this model is called Late-Fusion.
</bodyText>
<sectionHeader confidence="0.999373" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.991027620689655">
Evaluation Task: Suggesting Word Transla-
tions in Context. Given an occurrence of a pol-
ysemous word wS1 ∈ V S in the source language
LS with vocabulary V S, the task is to choose the
correct translation in the target language LT of
that particular occurrence of wS1 from the given
set T = {tT 1 , . .. , tTq }, T ⊆ VT, of its q possible
translations/meanings (i.e., its translation or sense
inventory). The task of suggesting a word trans-
lation in context may be interpreted as ranking the
q translations with respect to the observed local
context Con(wS1 ) of the occurrence of the word
wS1 . The best scoring translation candidate in the
ranked list is then the suggested correct translation
for that particular occurrence of wS1 after observ-
ing its local context Con(wS1 ).
Training Data. We use the following corpora for
inducing latent cross-lingual concepts/topics, i.e.,
for training our multilingual topic model: (i) a col-
lection of 13, 696 Spanish-English Wikipedia arti-
cle pairs (Wiki-ES-EN), (ii) a collection of 18, 898
Italian-English Wikipedia article pairs, (iii) a col-
lection of 7,612 Dutch-English Wikipedia arti-
cle pairs (Wiki-NL-EN), and (iv) the Wiki-NL-
EN corpus augmented with 6,206 Dutch-English
document pairs from Europarl (Koehn, 2005)
(Wiki+EP-NL-EN). The corpora were previously
used in (Vuli´c and Moens, 2013). No explicit use
is made of sentence-level alignments in Europarl.
</bodyText>
<page confidence="0.990073">
354
</page>
<table confidence="0.9760376">
Sentence in Italian Correct Translation (EN)
1. I primi calci furono prodotti in legno ma recentemente... stock
2. In caso di osteoporosi si verifica un eccesso di rilascio di calcio dallo scheletro... calcium
3. La crescita del calcio femminile professionistico ha visto il lancio di competizioni... football
4. Il calcio di questa pistola (Beretta Modello 21a, calibro .25) ha le guancette in materiale... stock
</table>
<tableCaption confidence="0.994956">
Table 1: Example sentences from our IT evaluation dataset with corresponding correct translations.
</tableCaption>
<figure confidence="0.700934515151515">
Spanish Italian Dutch
Ambiguous word Ambiguous word Ambiguous word
(Possible senses/translations) (Possible senses/translations) (Possible senses/translations)
1. estaci´on 1. raggio 1. toren
(station; season) (ray; radius; spoke) (rook; tower)
2. ensayo 2. accordo 2. beeld
(essay; rehearsal; trial) (chord; agreement) (image; statue)
3. n´ucleo 3. moto 3. blade
(core; kernel; nucleus) (motion; motorcycle) (blade; leaf; magazine)
4. vela 4. calcio 4.fusie
(sail; candle) (calcium; football; stock) (fusion; merger)
5. escudo 5. terra 5. stam
(escudo; escutcheon; shield) (earth; land) (stem; trunk; tribe)
6. papa 6. tavola 6. koper
(Pope; potato) (board; panel; table) (copper; buyer)
7. cola 7. campione 7. bloem
(glue; coke; tail; queue) (champion; sample) (flower; flour)
8. cometa 8. carta 8. spanning
(comet; kite) (card; paper; map) (voltage; tension; stress)
9. disco 9. piano 9. noot
(disco; discus; disk) (floor; plane; plan; piano) (note; nut)
10. banda 10. disco 10. akkoord
(band; gang; strip) (disco; discus; disk) (chord; agreement)
11. cinta 11. istruzione 11. munt
(ribbon; tape) (education; instruction) (coin; currency; mint)
12. banco 12. gabinetto 12. pool
(bank; bench; shoal) (cabinet; office; toilet) (pole; pool)
13. frente 13. torre 13. band
(forehead; front) (rook; tower) (band; tyre; tape)
14. fuga 14. campo 14. kern
(escape; fugue; leak) (camp; field) (core; kernel; nucleus)
15. gota 15. gomma 15. kop
(gout; drop) (rubber; gum; tyre) (cup; head)
</figure>
<tableCaption confidence="0.4904825">
Table 2: Sets of 15 ambiguous words in Spanish, Italian and Dutch from our test set accompanied by the
sets of their respective possible senses/translations in English.
</tableCaption>
<bodyText confidence="0.999909848484849">
All corpora are theme-aligned comparable cor-
pora, i.e, the aligned document pairs discuss sim-
ilar themes, but are in general not direct trans-
lations (except for Europarl). By training on
Wiki+EP-NL-EN we want to test how the training
corpus of higher quality affects the estimation of
latent cross-lingual concepts that span the shared
latent semantic space and, consequently, the over-
all results in the task of suggesting word transla-
tions in context. Following prior work (Koehn and
Knight, 2002; Haghighi et al., 2008; Prochasson
and Fung, 2011; Vuli´c and Moens, 2013), we re-
tain only nouns that occur at least 5 times in the
corpus. We record lemmatized word forms when
available, and original forms otherwise. We use
TreeTagger (Schmid, 1994) for POS tagging and
lemmatization.
Test Data. We have constructed test datasets in
Spanish (ES), Italian (IT) and Dutch (NL), where
the aim is to find their correct translation in En-
glish (EN) given the sentential context. We have
selected 15 polysemous nouns (see tab. 2 for
the list of nouns along with their possible transla-
tions) in each of the 3 languages, and have man-
ually extracted 24 sentences (not present in the
training data) for each noun that capture different
meanings of the noun from Wikipedia. In order
to construct datasets that are balanced across dif-
ferent possible translations of a noun, in case of
q different translation candidates in T for some
word wi , the dataset contains exactly 24/q sen-
tences for each translation from T . In total, we
have designed 360 sentences for each language
</bodyText>
<page confidence="0.995515">
355
</page>
<bodyText confidence="0.988922387755102">
pair (ES/IT/NL-EN), 1080 sentences in total.1. We
have used 5 extra nouns with 20 sentences each as
a development set to tune the parameters of our
models. As a by-product, we have built an initial
repository of ES/IT/NL ambiguous words. Tab.
1 presents a small sample from the IT evaluation
dataset, and illustrates the task of suggesting word
translations in context.
Evaluation Procedure. Our task is to present
the system a list of possible translations and let
the system decide a single most likely translation
given the word and its sentential context. Ground
truth thus contains one word, that is, one correct
translation for each sentence from the evaluation
dataset. We have manually annotated the correct
translation for the ground truth1 by inspecting the
discourse in Wikipedia articles and the interlingual
Wikipedia links. We measure the performance of
all models as Top 1 accuracy (Acc1) (Gaussier et
al., 2004; Tamura et al., 2012). It denotes the num-
ber of word instances from the evaluation dataset
whose top proposed candidate in the ranked list of
translation candidates from T is exactly the cor-
rect translation for that word instance as given by
ground truth over the total number of test word in-
stances (360 in each test dataset).
Parameters. We have tuned λ1 and λ2 on the de-
velopment sets. We set λ1 = λ2 = 0.9 for all
language pairs. We use sorted context sets (see
sect. 2) and perform a cut-off at M = 3 most de-
scriptive context words in the sorted context sets
for all models. In the following section we discuss
the utility of this context sorting and pruning, as
well as its influence on the overall results.
Inducing Latent Cross-Lingual Concepts. Our
context-aware models are generic and allow ex-
perimentations with different models that induce
latent cross-lingual semantic concepts. However,
in this particular work we present results obtained
by a multilingual probabilistic topic model called
bilingual LDA (Mimno et al., 2009; Ni et al.,
2009; De Smet and Moens, 2009). The BiLDA
model is a straightforward multilingual extension
of the standard LDA model (Blei et al., 2003).
For the details regarding the modeling, generative
story and training of the bilingual LDA model, we
refer the interested reader to the aforementioned
relevant literature.
We have used the Gibbs sampling procedure
</bodyText>
<footnote confidence="0.809296">
1Available at http://people.cs.kuleuven.be/
∼ivan.vulic/software/
</footnote>
<bodyText confidence="0.998793303030303">
(Geman and Geman, 1984) tailored for BiLDA
in particular for training and have experimented
with different number of topics K in the interval
300 − 2500. Here, we present only the results ob-
tained with K = 2000 for all language pairs which
also yielded the best or near-optimal performance
in (Dinu and Lapata, 2010b; Vuli´c et al., 2011).
Other parameters of the model are set to the typical
values according to Steyvers and Griffiths (2007):
α = 50/K and β = 0.01. 2
Models in Comparison. We test the performance
of our Direct-Fusion, Smoothed-Fusion and Late-
Fusion models, and compare their results with
the context-insensitive CLSS models described in
sect. 2 (No-Context). We provide results with
two different similarity functions: (1) We have
tested different SF-s (e.g., the Kullback-Leibler
and the Jensen-Shannon divergence, the cosine
measure) on the K-dimensional vector represen-
tations, and have detected that in general the best
scores are obtained with the Bhattacharyya coef-
ficient (BC) (Cha, 2007; Kazama et al., 2010),
(2) Another similarity method we use is the so-
called Cue method (Griffiths et al., 2007; Vuli´c
et al., 2011), which models the probability that
a target word tTi will be generated as an as-
sociation response given some cue source word
wS1 . In short, the method computes the score
P(tTi jwS1 ) = P(tTi jzk)P(zkjwS1 ). We can use
the scores P(tTi jwS1 ) obtained by inputting out-of-
context probability scores P(zkjwS1 ) or modulated
probability scores P&apos;(zkjwS1 ) to produce the rank-
ing of translation candidates.
</bodyText>
<sectionHeader confidence="0.999731" genericHeader="evaluation">
5 Results and Discussion
</sectionHeader>
<bodyText confidence="0.994807052631579">
The performance of all the models in comparison
is displayed in tab. 3. These results lead us to
several conclusions:
(i) All proposed context-sensitive CLSS models
suggesting word translations in context signifi-
cantly outperform context-insensitive CLSS mod-
els, which are able to produce only word trans-
lations in isolation. The improvements in re-
sults when taking context into account are ob-
2We are well aware that different hyper-parameter set-
tings (Asuncion et al., 2009; Lu et al., 2011), might have
influence on the quality of learned latent cross-lingual con-
cepts/topics and, consequently, the quality of latent semantic
space, but that analysis is not the focus of this work. Addi-
tionally, we perform semantic space pruning (Reisinger and
Mooney, 2010; Vuli´c and Moens, 2013). All computations
are performed over the best scoring 100 cross-lingual topics
according to their respective scores P(zk|wSi ) similarly to
(Vuli´c and Moens, 2013).
</bodyText>
<page confidence="0.997086">
356
</page>
<table confidence="0.9998465">
Direction: ES→EN IT→EN NL→EN (Wiki) NL→EN (Wiki+EP)
Model
Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1
(SF=BC) (SF=Cue) (SF=BC) (SF=Cue) (SF=BC) (SF=Cue) (SF=BC) (SF=Cue)
No-Context .406 .406 .408 .408 .433 .433 .433 .433
Direct-Fusion .617 .575 .714 .697 .603 .592 .606 .636
Smoothed-Fusion .664 .703* .731 .789* .669 .712* .692 .761*
Late-Fusion .675 .667 .742 .728 .667 .644 .683 .722
</table>
<tableCaption confidence="0.93734975">
Table 3: Results on the 3 evaluation datasets. Translation direction is ES/IT/NL→EN. The improvements
of all contextualized models over non-contextualized models are statistically significant according to a
chi-square statistical significance test (p&lt;0.05). The asterisk (*) denotes significant improvements of
Smoothed-Fusion over Late-Fusion using the same significance test.
</tableCaption>
<bodyText confidence="0.994405272727273">
served for all 3 language pairs. The large im-
provements in the results (i.e., we observe an aver-
age relative increase of 51.6% for the BC+Direct-
Fusion combination, 64.3% for BC+Smoothed-
Fusion, 64.9% for BC+Late-Fusion, 49.1% for
Cue+Direct-Fusion, 76.7% for Cue+Smoothed-
Fusion, and 64.5% for Cue+Late-Fusion) confirm
that the local context of a word is essential in ac-
quiring correct word translations for polysemous
words, as isolated non-contextualized word repre-
sentations are not sufficient.
</bodyText>
<listItem confidence="0.908694724137931">
(ii) The choice of a similarity function influences
the results. On average, the Cue method as SF out-
performs other standard similarity functions (e.g.,
Kullback-Leibler, Jensen-Shannon, cosine, BC) in
this evaluation task. However, it is again impor-
tant to state that regardless of the actual choice
of SF, context-aware models that modulate out-of-
context word representations using the knowledge
of local context outscore context-insensitive mod-
els that utilize non-modulated out-of-context rep-
resentations (with all other parameters equal).
(iii) The Direct-Fusion model, conceptually sim-
ilar to a model of word similarity in context in
monolingual settings (Dinu and Lapata, 2010a),
is outperformed by the other two context-sensitive
models. In Direct-Fusion, the observed word and
its context are modeled in the same fashion, that is,
the model does not distinguish between the word
and its surrounding context when it computes the
modulated probability scores P&apos;(zk|wS1 ) (see eq.
(7)). Unlike Direct-Fusion, the modeling assump-
tions of Smoothed-Fusion and Late-Fusion pro-
vide a clear distinction between the observed word
wS1 and its context Con(wS1 ) and combine the out-
of-context representation of wS1 and its contextual
knowledge into a smoothed LM-inspired proba-
bilistic model. As the results reveal, that strategy
leads to better overall scores. The best scores in
general are obtained by Smoothed-Fusion, but it
</listItem>
<bodyText confidence="0.98129895">
is also outperformed by Late-Fusion in several ex-
perimental runs where BC was used as SF. How-
ever, the difference in results between Smoothed-
Fusion and Late-Fusion in these experimental runs
is not statistically significant according to a chi-
squared significance test (p &lt; 0.05).
(iv) The results for Dutch-English are influenced
by the quality of training data. The performance
of our models of similarity is higher for models
that rely on latent-cross lingual topics estimated
from the data of higher quality (i.e., compare the
results when trained on Wiki and Wiki+EP in tab.
3). The overall quality of our models of similarity
is of course dependent on the quality of the latent
cross-lingual topics estimated from training data,
and the quality of these latent cross-lingual con-
cepts is further dependent on the quality of multi-
lingual training data. This finding is in line with
a similar finding reported for the task of bilingual
lexicon extraction (Vuli´c and Moens, 2013).
(v) Although Dutch is regarded as more similar
to English than Italian or Spanish, we do not ob-
serve any major increase in the results on both
test datasets for the English-Dutch language pair
compared to English-Spanish/Italian. That phe-
nomenon may be attributed to the difference in
size and quality of our training Wikipedia datasets.
Moreover, while the probabilistic framework pro-
posed in this chapter is completely language pair
agnostic as it does not make any language pair
dependent modeling assumptions, we acknowl-
edge the fact that all three language pairs com-
prise languages coming from the same phylum,
that is, the Indo-European language family. Future
extensions of our probabilistic modeling frame-
work also include porting the framework to other
more distant language pairs that do not share the
same roots nor the same alphabet (e.g., English-
Chinese/Hindi).
Analysis of Context Sorting and Pruning. We
</bodyText>
<page confidence="0.979409">
357
</page>
<figure confidence="0.976045666666667">
Accl
1 2 3 4 5 9 10 11
Size of the ranked context
</figure>
<figureCaption confidence="0.902840666666667">
Figure 2: The influence of the size of sorted con-
text on the accuracy of word translation in context.
The model is Cue+Smoothed-Fusion.
</figureCaption>
<bodyText confidence="0.9997432">
also investigate the utility of context sorting and
pruning, and its influence on the overall results
in our evaluation task. Therefore, we have con-
ducted experiments with sorted context sets that
were pruned at different positions, ranging from 1
(only the most similar word to wi in a sentence is
included in the context set Con(wi )) to All (all
words occurring in a same sentence with w1 are
included in Con(wi )). The monolingual similar-
ity between wi and each potential context word in
a sentence has been computed using BC on their
out-of-context representations in the latent seman-
tic space spanned by cross-lingual topics. Fig. 2
shows how the size of the sorted context influences
the overall results. The presented results have been
obtained by the Cue+Smoothed-Fusion combina-
tion, but a similar behavior is observed when em-
ploying other combinations.
Fig. 2 clearly indicates the importance of con-
text sorting and pruning. The procedure ensures
that only the most semantically similar words in a
given scope (e.g., a sentence) influence the choice
of a correct meaning. In other words, closely
semantically similar words in the same sentence
are more reliable indicators for the most probable
word meaning. They are more informative in mod-
ulating the out-of-context word representations in
context-sensitive similarity models. We observe
large improvements in scores when we retain only
the top M semantically similar words in the con-
text set (e.g., when M=5, the scores are 0.694,
0.758, 0.717, and 0.767 for ES-EN, IT-EN, NL-
EN (Wiki) and NL-EN (Wiki+EP), respectively;
while the same scores are 0.572, 0.703, 0.639 and
0.672 when M=All).
</bodyText>
<sectionHeader confidence="0.981155" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999910711111111">
We have proposed a new probabilistic approach to
modeling cross-lingual semantic similarity in con-
text, which relies only on co-occurrence counts
and latent cross-lingual concepts which can be es-
timated using only comparable data. The approach
is purely statistical and it does not make any ad-
ditional language-pair dependent assumptions; it
does not rely on a bilingual lexicon, orthographic
clues or predefined ontology/category knowledge,
and it does not require parallel data.
The key idea in the approach is to represent
words, regardless of their actual language, as dis-
tributions over the latent concepts, and both out-
of-context and contextualized word representa-
tions are then presented in the same latent space
spanned by the latent semantic concepts. A
change in word meaning after observing its con-
text is reflected in a change of its distribution
over the latent concepts. Results for three lan-
guage pairs have clearly shown the importance
of the newly developed modulated or “contextual-
ized” word representations in the task of suggest-
ing word translations in context.
We believe that the proposed framework is only
a start, as it ignites a series of new research ques-
tions and perspectives. One may further exam-
ine the influence of context scope (e.g., document-
based vs. sentence-based vs. window-based con-
texts), as well as context selection and aggregation
(see sect. 2) on the contextualized models. For
instance, similar to the model from O´ S´eaghdha
and Korhonen (2011) in the monolingual setting,
one may try to introduce dependency-based con-
texts (Pad´o and Lapata, 2007) and incorporate
the syntax-based knowledge in the context-aware
CLSS modeling. It is also worth studying other
models that induce latent semantic concepts from
multilingual data (see sect. 2) within this frame-
work of context-sensitive CLSS modeling. One
may also investigate a similar approach to context-
sensitive CLSS modeling that could operate with
explicitly defined concept categories (Gabrilovich
and Markovitch, 2007; Cimiano et al., 2009; Has-
san and Mihalcea, 2009; Hassan and Mihalcea,
2011; McCrae et al., 2013).
</bodyText>
<sectionHeader confidence="0.99172" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9980154">
We would like to thank the anonymous review-
ers for their comments and suggestions. This re-
search has been carried out in the framework of the
Smart Computer-Aided Translation Environment
(SCATE) project (IWT-SBO 130041).
</bodyText>
<figure confidence="0.9942184">
0. 5
0. 5
0.55
0.
0.
0.
ES-EN
IT-EN
N -EN ( )
N -EN ( E )
</figure>
<page confidence="0.991393">
358
</page>
<sectionHeader confidence="0.983585" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993302570093458">
Mirna Adriani and C. J. van Rijsbergen. 1999. Term
similarity-based query expansion for cross-language
information retrieval. In Proceedings of the 3rd Eu-
ropean Conference on Research and Advanced Tech-
nology for Digital Libraries (ECDL), pages 311–
322.
Marianna Apidianaki. 2011. Unsupervised cross-
lingual lexical substitution. In Proceedings of the 1st
Workshop on Unsupervised Learning in NLP, pages
13–23.
Arthur Asuncion, Max Welling, Padhraic Smyth, and
Yee Whye Teh. 2009. On smoothing and inference
for topic models. In Proceedings of the 25th Confer-
ence on Uncertainty in Artificial Intelligence (UAI),
pages 27–34.
Lisa Ballesteros and W. Bruce Croft. 1997. Phrasal
translation and query expansion techniques for
cross-language information retrieval. In Proceed-
ings of the 20th Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval (SIGIR), pages 84–91.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Represent-
ing adjective-noun constructions in semantic space.
In Proceedings of the 2010 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), pages 1183–1193.
William Blacoe and Mirella Lapata. 2012. A com-
parison of vector-based representations for seman-
tic composition. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 546–556.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Jordan Boyd-Graber and David M. Blei. 2009. Mul-
tilingual topic models for unaligned text. In Pro-
ceedings of the 25th Conference on Uncertainty in
Artificial Intelligence (UAI), pages 75–82.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics,
19(2):263–311.
Sung-Hyuk Cha. 2007. Comprehensive survey on dis-
tance/similarity measures between probability den-
sity functions. International Journal of Mathe-
matical Models and Methods in Applied Sciences,
1(4):300–307.
Philipp Cimiano, Antje Schultz, Sergej Sizov, Philipp
Sorg, and Steffen Staab. 2009. Explicit versus la-
tent concept models for cross-language information
retrieval. In Proceedings of the 21st International
Joint Conference on Artifical Intelligence (IJCAI),
pages 1513–1518.
Daoud Clarke. 2012. A context-theoretic frame-
work for compositionality in distributional seman-
tics. Computational Linguistics, 38(1):41–71.
Dipanjan Das and Slav Petrov. 2011. Unsuper-
vised part-of-speech tagging with bilingual graph-
based projections. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies (ACL-
HLT), pages 600–609.
Hal Daum´e III and Jagadeesh Jagarlamudi. 2011. Do-
main adaptation for machine translation by min-
ing unseen words. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies (ACL-
HLT), pages 407–412.
Wim De Smet and Marie-Francine Moens. 2009.
Cross-language linking of news stories on the Web
using interlingual topic modeling. In Proceedings of
the CIKM 2009 Workshop on Social Web Search and
Mining (SWSM@CIKM), pages 57–64.
Chris H. Q. Ding, Tao Li, and Wei Peng. 2008. On
the equivalence between non-negative matrix fac-
torization and probabilistic latent semantic index-
ing. Computational Statistics &amp; Data Analysis,
52(8):3913–3927.
Georgiana Dinu and Mirella Lapata. 2010a. Measur-
ing distributional similarity in context. In Proceed-
ings of the 2010 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
1162–1172.
Georgiana Dinu and Mirella Lapata. 2010b. Topic
models for meaning similarity in context. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics (COLING), pages 250–
258.
Susan T. Dumais, Thomas K. Landauer, and Michael
Littman. 1996. Automatic cross-linguistic infor-
mation retrieval using Latent Semantic Indexing.
In Proceedings of the SIGIR Workshop on Cross-
Linguistic Information Retrieval, pages 16–23.
Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syn-
tactic transfer using a bilingual lexicon. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 1–11.
Kosuke Fukumasu, Koji Eguchi, and Eric P. Xing.
2012. Symmetric correspondence topic models for
multilingual text analysis. In Procedings of the 25th
Annual Conference on Advances in Neural Informa-
tion Processing Systems (NIPS), pages 1295–1303.
</reference>
<page confidence="0.995434">
359
</page>
<reference confidence="0.984459963302752">
Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Computing semantic relatedness using Wikipedia-
based explicit semantic analysis. In Proceedings of
the 20th International Joint Conference on Artificial
Intelligence (IJCAI), pages 1606–1611.
Kuzman Ganchev and Dipanjan Das. 2013. Cross-
lingual discriminative learning of sequence models
with posterior regularization. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1996–2006.
´Eric Gaussier and Cyril Goutte. 2005. Relation be-
tween PLSA and NMF and implications. In Pro-
ceedings of the 28th Annual International ACM SI-
GIR Conference on Research and Development in
Information Retrieval (SIGIR), pages 601–602.
´Eric Gaussier, Jean-Michel Renders, Irina Matveeva,
Cyril Goutte, and Herv´e D´ejean. 2004. A geomet-
ric view on bilingual lexicon extraction from com-
parable corpora. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 526–533.
Stuart Geman and Donald Geman. 1984. Stochas-
tic relaxation, Gibbs distributions, and the Bayesian
restoration of images. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 6(6):721–741.
Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental support for a categorical composi-
tional distributional model of meaning. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
1394–1404.
Thomas L. Griffiths, Mark Steyvers, and Joshua B.
Tenenbaum. 2007. Topics in semantic representa-
tion. Psychological Review, 114(2):211–244.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In Proceedings of the
46th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies (ACL-HLT), pages 771–779.
Samer Hassan and Rada Mihalcea. 2009. Cross-
lingual semantic relatedness using encyclopedic
knowledge. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 1192–1201.
Samer Hassan and Rada Mihalcea. 2011. Semantic
relatedness using salient semantic analysis. In Pro-
ceedings of the 25th AAAI Conference on Artificial
Intelligence (AAAI), pages 884–889.
Karl Moritz Hermann and Phil Blunsom. 2013. The
role of syntax in vector space models of composi-
tional semantics. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 894–904.
Karl Moritz Hermann and Phil Blunsom. 2014. Mul-
tilingual models for compositional distributed se-
mantics. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 58–68.
Djoerd Hiemstra. 1998. A linguistically motivated
probabilistic model of information retrieval. In Pro-
ceedings of the 2nd European Conference on Re-
search and Advanced Technology for Digital Li-
braries (ECDL), pages 569–584.
Eric H. Huang, Richard Socher, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Improving word
representations via global context and multiple word
prototypes. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 873–882.
Daniel Jurafsky and James H. Martin. 2000. Speech
and Language Processing: An Introduction to Nat-
ural Language Processing, Computational Linguis-
tics, and Speech Recognition. Prentice Hall PTR.
Jun’ichi Kazama, Stijn De Saeger, Kow Kuroda,
Masaki Murata, and Kentaro Torisawa. 2010. A
Bayesian method for robust estimation of distribu-
tional similarities. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 247–256.
Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.
2012. Multilingual named entity recognition using
parallel data and metadata from Wikipedia. In Pro-
ceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
694–702.
Alexandre Klementiev, Ivan Titov, and Binod Bhat-
tarai. 2012. Inducing crosslingual distributed repre-
sentations of words. In Proceedings of the 24th In-
ternational Conference on Computational Linguis-
tics (COLING), pages 1459–1474.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In
Proceedings of the ACL Workshop on Unsupervised
Lexical Acquisition (ULA), pages 9–16.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of the
10th Machine Translation Summit (MT SUMMIT),
pages 79–86.
Tom´aˇs Koˇcisk´y, Karl Moritz Hermann, and Phil Blun-
som. 2014. Learning bilingual word representations
by marginalizing alignments. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 224–229.
Victor Lavrenko and W. Bruce Croft. 2001.
Relevance-based language models. In Proceedings
of the 24th Annual International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval (SIGIR), pages 120–127.
</reference>
<page confidence="0.992062">
360
</page>
<reference confidence="0.966058770642202">
Victor Lavrenko, Martin Choquette, and W. Bruce
Croft. 2002. Cross-lingual relevance models. In
Proceedings of the 25th Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval (SIGIR), pages 175–182.
Daniel D. Lee and H. Sebastian Seung. 1999. Al-
gorithms for non-negative matrix factorization. In
Proceedings of the 12th Conference on Advances
in Neural Information Processing Systems (NIPS),
pages 556–562.
Lillian Lee. 1999. Measures of distributional sim-
ilarity. In Proceedings of the 37th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 25–32.
Gina-Anne Levow, Douglas W. Oard, and Philip
Resnik. 2005. Dictionary-based techniques for
cross-language information retrieval. Information
Processing and Management, 41(3):523–547.
Yue Lu, Qiaozhu Mei, and Chengxiang Zhai. 2011.
Investigating task performance of probabilistic topic
models: An empirical study of PLSA and LDA. In-
formation Retrieval, 14(2):178–203.
John Philip McCrae, Philipp Cimiano, and Roman
Klinger. 2013. Orthonormal explicit topic analysis
for cross-lingual document matching. In Proceed-
ings of the 2013 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
1732–1740.
Paola Merlo, Suzanne Stevenson, Vivian Tsang, and
Gianluca Allaria. 2002. A multilingual paradigm
for automatic verb classification. In Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 207–214.
David Mimno, Hanna Wallach, Jason Naradowsky,
David A. Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 880–889.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 236–244.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.
Hwee Tou Ng, Bin Wang, and Yee Seng Chan. 2003.
Exploiting parallel texts for word sense disambigua-
tion: An empirical study. In Proceedings of the
41st Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 455–462.
Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.
2009. Mining multilingual topics from Wikipedia.
In Proceedings of the 18th International World Wide
Web Conference (WWW), pages 1155–1156.
Diarmuid O´ S´eaghdha and Anna Korhonen. 2011.
Probabilistic models of similarity in syntactic con-
text. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1047–1057.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Sebastian Pad´o and Mirella Lapata. 2007.
Dependency-based construction of semantic space
models. Computational Linguistics, 33(2):161–199.
Sebastian Pad´o and Mirella Lapata. 2009. Cross-
lingual annotation projection for semantic roles.
Journal of Artificial Intelligence Research, 36:307–
340.
Yves Peirsman and Sebastian Pad´o. 2010. Cross-
lingual induction of selectional preferences with
bilingual vector spaces. In Proceedings of the 11th
Meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (NAACL-HLT), pages 921–929.
Jay M. Ponte and W. Bruce Croft. 1998. A language
modeling approach to information retrieval. In Pro-
ceedings of the 21st Annual International ACM SI-
GIR Conference on Research and Development in
Information Retrieval (SIGIR), pages 275–281.
Anat Prior, Shuly Wintner, Brian MacWhinney, and
Alon Lavie. 2011. Translation ambiguity in and
out of context. Applied Psycholinguistics, 32(1):93–
111.
Emmanuel Prochasson and Pascale Fung. 2011. Rare
word translation extraction from aligned compara-
ble documents. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies (ACL-
HLT), pages 1327–1335.
Joseph Reisinger and Raymond J. Mooney. 2010.
A mixture model with sharing for lexical seman-
tics. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1173–1182.
Sebastian Rudolph and Eugenie Giesbrecht. 2010.
Compositional matrix-space models of language. In
Proceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
907–916.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing.
Richard Socher, Eric H. Huang, Jeffrey Pennington,
Andrew Y. Ng, and Christopher D. Manning. 2011.
Dynamic pooling and unfolding recursive autoen-
coders for paraphrase detection. In Proceedings of
the 24th Annual Conference on Advances in Neural
</reference>
<page confidence="0.980723">
361
</page>
<reference confidence="0.999313095238095">
Information Processing Systems (NIPS), pages 801–
809.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic com-
positionality through recursive matrix-vector spaces.
In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 1201–1211.
Mark Steyvers and Tom Griffiths. 2007. Probabilistic
topic models. Handbook of Latent Semantic Analy-
sis, 427(7):424–440.
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013a. Token and
type constraints for cross-lingual part-of-speech tag-
ging. Transactions of ACL, 1:1–12.
Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre.
2013b. Target language adaptation of discriminative
transfer parsers. In Proceedings of the 14th Meeting
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies (NAACL-HLT), pages 1061–1071.
Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.
2012. Bilingual lexicon extraction from compara-
ble corpora using label propagation. In Proceed-
ings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 24–36.
Michael E. Tipping and Christopher M. Bishop. 1999.
Mixtures of probabilistic principal component anal-
ysers. Neural Computation, 11(2):443–482.
Lonneke van der Plas, Paola Merlo, and James Hen-
derson. 2011. Scaling up automatic cross-lingual
semantic role annotation. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies
(ACL-HLT), pages 299–304.
Ivan Vuli´c and Marie-Francine Moens. 2013. Cross-
lingual semantic similarity of words as the similarity
of their semantic word responses. In Proceedings of
the 14th Meeting of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies (NAACL-HLT), pages
106–116.
Ivan Vuli´c, Wim De Smet, and Marie-Francine Moens.
2011. Identifying word translations from compara-
ble corpora using latent topic models. In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies (ACL-HLT), pages 479–484.
Ivan Vuli´c, Wim De Smet, and Marie-Francine Moens.
2013. Cross-language information retrieval models
based on latent topic models trained with document-
aligned comparable corpora. Information Retrieval,
16(3):331–368.
Jianqiang Wang and Douglas W. Oard. 2006. Com-
bining bidirectional translation and synonymy for
cross-language information retrieval. In Proceed-
ings of the 29th Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval (SIGIR), pages 202–209.
Hua Wu, Haifeng Wang, and Chengqing Zong. 2008.
Domain adaptation for statistical machine transla-
tion with domain dictionary and monolingual cor-
pora. In Proceedings of the 22nd International Con-
ference on Computational Linguistics (COLING),
pages 993–1000.
David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual POS taggers and NP bracketers via robust
projection across aligned corpora. In Proceedings
of the 2nd Meeting of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL), pages 200–207.
Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai.
2010. Cross-lingual latent topic extraction. In Pro-
ceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
1128–1137.
Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.
2009. Cross language dependency parsing using a
bilingual lexicon. In Proceedings of the 47th An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 55–63.
</reference>
<page confidence="0.99822">
362
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.617808">
<title confidence="0.999592">Probabilistic Models of Cross-Lingual Semantic Similarity in Based on Latent Cross-Lingual Concepts Induced from Comparable Data</title>
<author confidence="0.986915">Ivan Vuli´c</author>
<author confidence="0.986915">Marie-Francine</author>
<affiliation confidence="0.998534">Department of Computer</affiliation>
<address confidence="0.648273">KU Leuven,</address>
<abstract confidence="0.99853592">We propose the first probabilistic approach to modeling cross-lingual semantic similarity (CLSS) in context which requires only comparable data. The approach relies on an idea of projecting words and sets of words into a shared latent semantic space spanned by language-pair independent latent semantic concepts (e.g., crosslingual topics obtained by a multilingual topic model). These latent cross-lingual concepts are induced from a comparable corpus without any additional lexical resources. Word meaning is represented as a probability distribution over the latent concepts, and a change in meaning is represented as a change in the distribution over these latent concepts. We present new models that modulate the isolated out-ofcontext word representations with contextual knowledge. Results on the task of suggesting word translations in context for 3 language pairs reveal the utility of the proposed contextualized models of crosslingual semantic similarity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mirna Adriani</author>
<author>C J van Rijsbergen</author>
</authors>
<title>Term similarity-based query expansion for cross-language information retrieval.</title>
<date>1999</date>
<booktitle>In Proceedings of the 3rd European Conference on Research and Advanced Technology for Digital Libraries (ECDL),</booktitle>
<pages>311--322</pages>
<marker>Adriani, van Rijsbergen, 1999</marker>
<rawString>Mirna Adriani and C. J. van Rijsbergen. 1999. Term similarity-based query expansion for cross-language information retrieval. In Proceedings of the 3rd European Conference on Research and Advanced Technology for Digital Libraries (ECDL), pages 311– 322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marianna Apidianaki</author>
</authors>
<title>Unsupervised crosslingual lexical substitution.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st Workshop on Unsupervised Learning in NLP,</booktitle>
<pages>13--23</pages>
<contexts>
<context position="5060" citStr="Apidianaki, 2011" startWordPosition="778" endWordPosition="779">n the Spanish sentence ”She was unable to find a match in her pocket to light up a cigarette.”, it is clear that the strength of semantic similarity should change in context as only cerilla exhibits a strong semantic similarity to match within this particular sentential context. Following this intuition, in this paper we investigate models of cross-lingual semantic similarity in context. The context-sensitive models of similarity target to re-rank the lists of semantically similar words based on the co-occurring contexts of words. Unlike prior work (e.g., (Ng et al., 2003; Prior et al., 2011; Apidianaki, 2011)), we explore these models in a particularly difficult and minimalist setting that builds only on co-occurrence counts and latent cross-lingual semantic concepts induced directly from comparable corpora, and which does not rely on any other resource (e.g., machine-readable dictionaries, parallel corpora, explicit ontology and category knowledge). In that respect, the work reported in this paper extends the current research on purely statistical data-driven distributional models of cross-lingual semantic similarity that are built upon the idea of latent cross-lingual concepts (Haghighi et al., </context>
</contexts>
<marker>Apidianaki, 2011</marker>
<rawString>Marianna Apidianaki. 2011. Unsupervised crosslingual lexical substitution. In Proceedings of the 1st Workshop on Unsupervised Learning in NLP, pages 13–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Asuncion</author>
<author>Max Welling</author>
<author>Padhraic Smyth</author>
<author>Yee Whye Teh</author>
</authors>
<title>On smoothing and inference for topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI),</booktitle>
<pages>27--34</pages>
<contexts>
<context position="34156" citStr="Asuncion et al., 2009" startWordPosition="5504" endWordPosition="5507">obability scores P(zkjwS1 ) or modulated probability scores P&apos;(zkjwS1 ) to produce the ranking of translation candidates. 5 Results and Discussion The performance of all the models in comparison is displayed in tab. 3. These results lead us to several conclusions: (i) All proposed context-sensitive CLSS models suggesting word translations in context significantly outperform context-insensitive CLSS models, which are able to produce only word translations in isolation. The improvements in results when taking context into account are ob2We are well aware that different hyper-parameter settings (Asuncion et al., 2009; Lu et al., 2011), might have influence on the quality of learned latent cross-lingual concepts/topics and, consequently, the quality of latent semantic space, but that analysis is not the focus of this work. Additionally, we perform semantic space pruning (Reisinger and Mooney, 2010; Vuli´c and Moens, 2013). All computations are performed over the best scoring 100 cross-lingual topics according to their respective scores P(zk|wSi ) similarly to (Vuli´c and Moens, 2013). 356 Direction: ES→EN IT→EN NL→EN (Wiki) NL→EN (Wiki+EP) Model Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 (SF=BC) (SF=Cue) (SF=</context>
</contexts>
<marker>Asuncion, Welling, Smyth, Teh, 2009</marker>
<rawString>Arthur Asuncion, Max Welling, Padhraic Smyth, and Yee Whye Teh. 2009. On smoothing and inference for topic models. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI), pages 27–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Ballesteros</author>
<author>W Bruce Croft</author>
</authors>
<title>Phrasal translation and query expansion techniques for cross-language information retrieval.</title>
<date>1997</date>
<booktitle>In Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>84--91</pages>
<contexts>
<context position="1891" citStr="Ballesteros and Croft, 1997" startWordPosition="270" endWordPosition="273">Cross-lingual semantic similarity (CLSS) is a metric that measures to which extent words (or more generally, text units) describe similar semantic concepts and convey similar meanings across languages. Models of cross-lingual similarity are typically used to automatically induce bilingual lexicons and have found numerous applications in information retrieval (IR), statistical machine translation (SMT) and other natural language processing (NLP) tasks. Within the IR framework, the output of the CLSS models is a key resource in the models of dictionary-based cross-lingual information retrieval (Ballesteros and Croft, 1997; Lavrenko et al., 2002; Levow et al., 2005; Wang and Oard, 2006) or may be utilized in query expansion in cross-lingual IR models (Adriani and van Rijsbergen, 1999; Vuli´c et al., 2013). These CLSS models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilin</context>
</contexts>
<marker>Ballesteros, Croft, 1997</marker>
<rawString>Lisa Ballesteros and W. Bruce Croft. 1997. Phrasal translation and query expansion techniques for cross-language information retrieval. In Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 84–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1183--1193</pages>
<contexts>
<context position="17327" citStr="Baroni and Zamparelli, 2010" startWordPosition="2758" endWordPosition="2762">hen compute the similarity between words and sets of words given in the same latent semantic space in a uniform way, irrespective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality s</context>
</contexts>
<marker>Baroni, Zamparelli, 2010</marker>
<rawString>Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1183–1193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Blacoe</author>
<author>Mirella Lapata</author>
</authors>
<title>A comparison of vector-based representations for semantic composition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>546--556</pages>
<contexts>
<context position="17407" citStr="Blacoe and Lapata, 2012" startWordPosition="2771" endWordPosition="2774">semantic space in a uniform way, irrespective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned parallel data to induce bilingual text representations. Moreover</context>
</contexts>
<marker>Blacoe, Lapata, 2012</marker>
<rawString>William Blacoe and Mirella Lapata. 2012. A comparison of vector-based representations for semantic composition. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 546–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="31825" citStr="Blei et al., 2003" startWordPosition="5135" endWordPosition="5138">ll models. In the following section we discuss the utility of this context sorting and pruning, as well as its influence on the overall results. Inducing Latent Cross-Lingual Concepts. Our context-aware models are generic and allow experimentations with different models that induce latent cross-lingual semantic concepts. However, in this particular work we present results obtained by a multilingual probabilistic topic model called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). The BiLDA model is a straightforward multilingual extension of the standard LDA model (Blei et al., 2003). For the details regarding the modeling, generative story and training of the bilingual LDA model, we refer the interested reader to the aforementioned relevant literature. We have used the Gibbs sampling procedure 1Available at http://people.cs.kuleuven.be/ ∼ivan.vulic/software/ (Geman and Geman, 1984) tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 − 2500. Here, we present only the results obtained with K = 2000 for all language pairs which also yielded the best or near-optimal performance in (Dinu and Lapata, 2010b; </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordan Boyd-Graber</author>
<author>David M Blei</author>
</authors>
<title>Multilingual topic models for unaligned text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI),</booktitle>
<pages>75--82</pages>
<contexts>
<context position="8914" citStr="Boyd-Graber and Blei, 2009" startWordPosition="1349" endWordPosition="1352">pts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 2013), the description in this paper relies on the multilingual probabilistic topic modeling (MuPTM) framework. We draw a direct parallel between latent cross-lingual concepts and latent cross-lingual topics, and we present the framework from the MuPTM perspective, but the proposed framework is generic and allows the usage of all other mo</context>
</contexts>
<marker>Boyd-Graber, Blei, 2009</marker>
<rawString>Jordan Boyd-Graber and David M. Blei. 2009. Multilingual topic models for unaligned text. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI), pages 75–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="3172" citStr="Brown et al., 1993" startWordPosition="480" endWordPosition="483">oven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingual similarity from comparable corpora have gained much attention recently. All these models from parallel and comparable corpora provide ranked lists of semantically similar words in the target language in isolation or invariably, that is, they do not explicitly iden349 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 349–362, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sung-Hyuk Cha</author>
</authors>
<title>Comprehensive survey on distance/similarity measures between probability density functions.</title>
<date>2007</date>
<journal>International Journal of Mathematical Models and Methods in Applied Sciences,</journal>
<volume>1</volume>
<issue>4</issue>
<contexts>
<context position="20794" citStr="Cha, 2007" startWordPosition="3330" endWordPosition="3331">y follow the derivation from eq. (3) which shows how to project context into the latent semantic space (and again assume the uniform topic prior P (zk)), we finally obtain the following formula: P&apos;(zk|wS P(wS1|zk) IIjr=1 P(cwSj |zk) (7) El=1 P(wS1 |zl) IIrj=1 P(cw3flzl) The ranking of all words wT2 E VT according to their similarity to wS1 may be computed by detecting the similarity score between their representation in the K-dimensional latent semantic space and the modulated source word representation as given by eq. (5) and eq. (7) using any of the existing similarity functions (Lee, 1999; Cha, 2007). The similarity score Sim(wS1 , wT2 , Con(wS1 )) between some wT2 E VT represented by its vector vec(wT2 ) and the observed word wS1 given its context Con(wS1 ) is computed as: sim(wS1 , wT2 , Con(wS1 )) = SF(vec(ws, Con(wS1 )), vec(w2)) (8) where SF denotes a similarity function. Words are then ranked according to their respective similarity scores and the best scoring candidate may be selected as the best translation of an occurrence of the word wS1 given its local context. Since the contextual knowledge is integrated directly into the estimation of probability P(zk|wS1 , Con(wS1 )), we nam</context>
<context position="33120" citStr="Cha, 2007" startWordPosition="5335" endWordPosition="5336">rding to Steyvers and Griffiths (2007): α = 50/K and β = 0.01. 2 Models in Comparison. We test the performance of our Direct-Fusion, Smoothed-Fusion and LateFusion models, and compare their results with the context-insensitive CLSS models described in sect. 2 (No-Context). We provide results with two different similarity functions: (1) We have tested different SF-s (e.g., the Kullback-Leibler and the Jensen-Shannon divergence, the cosine measure) on the K-dimensional vector representations, and have detected that in general the best scores are obtained with the Bhattacharyya coefficient (BC) (Cha, 2007; Kazama et al., 2010), (2) Another similarity method we use is the socalled Cue method (Griffiths et al., 2007; Vuli´c et al., 2011), which models the probability that a target word tTi will be generated as an association response given some cue source word wS1 . In short, the method computes the score P(tTi jwS1 ) = P(tTi jzk)P(zkjwS1 ). We can use the scores P(tTi jwS1 ) obtained by inputting out-ofcontext probability scores P(zkjwS1 ) or modulated probability scores P&apos;(zkjwS1 ) to produce the ranking of translation candidates. 5 Results and Discussion The performance of all the models in c</context>
</contexts>
<marker>Cha, 2007</marker>
<rawString>Sung-Hyuk Cha. 2007. Comprehensive survey on distance/similarity measures between probability density functions. International Journal of Mathematical Models and Methods in Applied Sciences, 1(4):300–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Cimiano</author>
<author>Antje Schultz</author>
<author>Sergej Sizov</author>
<author>Philipp Sorg</author>
<author>Steffen Staab</author>
</authors>
<title>Explicit versus latent concept models for cross-language information retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st International Joint Conference on Artifical Intelligence (IJCAI),</booktitle>
<pages>1513--1518</pages>
<marker>Cimiano, Schultz, Sizov, Sorg, Staab, 2009</marker>
<rawString>Philipp Cimiano, Antje Schultz, Sergej Sizov, Philipp Sorg, and Steffen Staab. 2009. Explicit versus latent concept models for cross-language information retrieval. In Proceedings of the 21st International Joint Conference on Artifical Intelligence (IJCAI), pages 1513–1518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daoud Clarke</author>
</authors>
<title>A context-theoretic framework for compositionality in distributional semantics.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>1</issue>
<contexts>
<context position="17421" citStr="Clarke, 2012" startWordPosition="2775" endWordPosition="2776">rm way, irrespective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned parallel data to induce bilingual text representations. Moreover, this work on</context>
</contexts>
<marker>Clarke, 2012</marker>
<rawString>Daoud Clarke. 2012. A context-theoretic framework for compositionality in distributional semantics. Computational Linguistics, 38(1):41–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graphbased projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT),</booktitle>
<pages>600--609</pages>
<contexts>
<context position="2796" citStr="Das and Petrov, 2011" startWordPosition="423" endWordPosition="426">nd Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingual similarity from comparable corpora have gained much attention recently. All these mode</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graphbased projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT), pages 600–609.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Jagadeesh Jagarlamudi</author>
</authors>
<title>Domain adaptation for machine translation by mining unseen words.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT),</booktitle>
<pages>407--412</pages>
<marker>Daum´e, Jagarlamudi, 2011</marker>
<rawString>Hal Daum´e III and Jagadeesh Jagarlamudi. 2011. Domain adaptation for machine translation by mining unseen words. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT), pages 407–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wim De Smet</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Cross-language linking of news stories on the Web using interlingual topic modeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the CIKM 2009 Workshop on Social Web Search and Mining (SWSM@CIKM),</booktitle>
<pages>57--64</pages>
<marker>De Smet, Moens, 2009</marker>
<rawString>Wim De Smet and Marie-Francine Moens. 2009. Cross-language linking of news stories on the Web using interlingual topic modeling. In Proceedings of the CIKM 2009 Workshop on Social Web Search and Mining (SWSM@CIKM), pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris H Q Ding</author>
<author>Tao Li</author>
<author>Wei Peng</author>
</authors>
<title>On the equivalence between non-negative matrix factorization and probabilistic latent semantic indexing.</title>
<date>2008</date>
<journal>Computational Statistics &amp; Data Analysis,</journal>
<volume>52</volume>
<issue>8</issue>
<contexts>
<context position="8596" citStr="Ding et al., 2008" startWordPosition="1301" endWordPosition="1304">s actually span a latent cross-lingual semantic space. Each word w, irrespective of its actual language, may be represented in that latent semantic space as a K-dimensional vector, where each vector component is a conditional concept score P(zk|w). A number of models may be employed to induce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 2013), the description</context>
</contexts>
<marker>Ding, Li, Peng, 2008</marker>
<rawString>Chris H. Q. Ding, Tao Li, and Wei Peng. 2008. On the equivalence between non-negative matrix factorization and probabilistic latent semantic indexing. Computational Statistics &amp; Data Analysis, 52(8):3913–3927.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Dinu</author>
<author>Mirella Lapata</author>
</authors>
<title>Measuring distributional similarity in context.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1162--1172</pages>
<contexts>
<context position="12967" citStr="Dinu and Lapata, 2010" startWordPosition="2022" endWordPosition="2025">nador while the context word yesterday does not bring any extra contextual information that could resolve the ambiguity. Therefore, in the final context set Con(wS1 ) it is useful to retain only the context words that rej used to compute scores P(zk|wSi ) and P(zk|wT j ) in order to represent words from the two different languages in the same latent semantic space in a uniform way. Context-Insensitive Models of Similarity. Without observing any context, the standard models of semantic word similarity that rely on the semantic space spanned by latent cross-lingual concepts in both monolingual (Dinu and Lapata, 2010a; Dinu and Lapata, 2010b) and multilingual settings (Vuli´c et al., 2011) typically proceed in the following manner. Latent language-independent concepts (e.g., cross-lingual topics or latent word senses) are estimated on a large corpus. The K-dimensional vector representation of the word wS 1 E V S is: 351 ally bring extra semantic information. We achieve that by exploiting the same latent semantic space to provide the similarity score between the observed word wi and each word cws, i = 1, ... , r from its context set Con(wi ). Each word cws may be represented by its vector vec(cws) (see eq.</context>
<context position="32422" citStr="Dinu and Lapata, 2010" startWordPosition="5226" endWordPosition="5229">odel (Blei et al., 2003). For the details regarding the modeling, generative story and training of the bilingual LDA model, we refer the interested reader to the aforementioned relevant literature. We have used the Gibbs sampling procedure 1Available at http://people.cs.kuleuven.be/ ∼ivan.vulic/software/ (Geman and Geman, 1984) tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 − 2500. Here, we present only the results obtained with K = 2000 for all language pairs which also yielded the best or near-optimal performance in (Dinu and Lapata, 2010b; Vuli´c et al., 2011). Other parameters of the model are set to the typical values according to Steyvers and Griffiths (2007): α = 50/K and β = 0.01. 2 Models in Comparison. We test the performance of our Direct-Fusion, Smoothed-Fusion and LateFusion models, and compare their results with the context-insensitive CLSS models described in sect. 2 (No-Context). We provide results with two different similarity functions: (1) We have tested different SF-s (e.g., the Kullback-Leibler and the Jensen-Shannon divergence, the cosine measure) on the K-dimensional vector representations, and have detect</context>
<context position="36577" citStr="Dinu and Lapata, 2010" startWordPosition="5858" endWordPosition="5861">s. On average, the Cue method as SF outperforms other standard similarity functions (e.g., Kullback-Leibler, Jensen-Shannon, cosine, BC) in this evaluation task. However, it is again important to state that regardless of the actual choice of SF, context-aware models that modulate out-ofcontext word representations using the knowledge of local context outscore context-insensitive models that utilize non-modulated out-of-context representations (with all other parameters equal). (iii) The Direct-Fusion model, conceptually similar to a model of word similarity in context in monolingual settings (Dinu and Lapata, 2010a), is outperformed by the other two context-sensitive models. In Direct-Fusion, the observed word and its context are modeled in the same fashion, that is, the model does not distinguish between the word and its surrounding context when it computes the modulated probability scores P&apos;(zk|wS1 ) (see eq. (7)). Unlike Direct-Fusion, the modeling assumptions of Smoothed-Fusion and Late-Fusion provide a clear distinction between the observed word wS1 and its context Con(wS1 ) and combine the outof-context representation of wS1 and its contextual knowledge into a smoothed LM-inspired probabilistic m</context>
</contexts>
<marker>Dinu, Lapata, 2010</marker>
<rawString>Georgiana Dinu and Mirella Lapata. 2010a. Measuring distributional similarity in context. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1162–1172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Dinu</author>
<author>Mirella Lapata</author>
</authors>
<title>Topic models for meaning similarity in context.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>250--258</pages>
<contexts>
<context position="12967" citStr="Dinu and Lapata, 2010" startWordPosition="2022" endWordPosition="2025">nador while the context word yesterday does not bring any extra contextual information that could resolve the ambiguity. Therefore, in the final context set Con(wS1 ) it is useful to retain only the context words that rej used to compute scores P(zk|wSi ) and P(zk|wT j ) in order to represent words from the two different languages in the same latent semantic space in a uniform way. Context-Insensitive Models of Similarity. Without observing any context, the standard models of semantic word similarity that rely on the semantic space spanned by latent cross-lingual concepts in both monolingual (Dinu and Lapata, 2010a; Dinu and Lapata, 2010b) and multilingual settings (Vuli´c et al., 2011) typically proceed in the following manner. Latent language-independent concepts (e.g., cross-lingual topics or latent word senses) are estimated on a large corpus. The K-dimensional vector representation of the word wS 1 E V S is: 351 ally bring extra semantic information. We achieve that by exploiting the same latent semantic space to provide the similarity score between the observed word wi and each word cws, i = 1, ... , r from its context set Con(wi ). Each word cws may be represented by its vector vec(cws) (see eq.</context>
<context position="32422" citStr="Dinu and Lapata, 2010" startWordPosition="5226" endWordPosition="5229">odel (Blei et al., 2003). For the details regarding the modeling, generative story and training of the bilingual LDA model, we refer the interested reader to the aforementioned relevant literature. We have used the Gibbs sampling procedure 1Available at http://people.cs.kuleuven.be/ ∼ivan.vulic/software/ (Geman and Geman, 1984) tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 − 2500. Here, we present only the results obtained with K = 2000 for all language pairs which also yielded the best or near-optimal performance in (Dinu and Lapata, 2010b; Vuli´c et al., 2011). Other parameters of the model are set to the typical values according to Steyvers and Griffiths (2007): α = 50/K and β = 0.01. 2 Models in Comparison. We test the performance of our Direct-Fusion, Smoothed-Fusion and LateFusion models, and compare their results with the context-insensitive CLSS models described in sect. 2 (No-Context). We provide results with two different similarity functions: (1) We have tested different SF-s (e.g., the Kullback-Leibler and the Jensen-Shannon divergence, the cosine measure) on the K-dimensional vector representations, and have detect</context>
<context position="36577" citStr="Dinu and Lapata, 2010" startWordPosition="5858" endWordPosition="5861">s. On average, the Cue method as SF outperforms other standard similarity functions (e.g., Kullback-Leibler, Jensen-Shannon, cosine, BC) in this evaluation task. However, it is again important to state that regardless of the actual choice of SF, context-aware models that modulate out-ofcontext word representations using the knowledge of local context outscore context-insensitive models that utilize non-modulated out-of-context representations (with all other parameters equal). (iii) The Direct-Fusion model, conceptually similar to a model of word similarity in context in monolingual settings (Dinu and Lapata, 2010a), is outperformed by the other two context-sensitive models. In Direct-Fusion, the observed word and its context are modeled in the same fashion, that is, the model does not distinguish between the word and its surrounding context when it computes the modulated probability scores P&apos;(zk|wS1 ) (see eq. (7)). Unlike Direct-Fusion, the modeling assumptions of Smoothed-Fusion and Late-Fusion provide a clear distinction between the observed word wS1 and its context Con(wS1 ) and combine the outof-context representation of wS1 and its contextual knowledge into a smoothed LM-inspired probabilistic m</context>
</contexts>
<marker>Dinu, Lapata, 2010</marker>
<rawString>Georgiana Dinu and Mirella Lapata. 2010b. Topic models for meaning similarity in context. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING), pages 250– 258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>Michael Littman</author>
</authors>
<title>Automatic cross-linguistic information retrieval using Latent Semantic Indexing.</title>
<date>1996</date>
<booktitle>In Proceedings of the SIGIR Workshop on CrossLinguistic Information Retrieval,</booktitle>
<pages>16--23</pages>
<contexts>
<context position="8381" citStr="Dumais et al., 1996" startWordPosition="1270" endWordPosition="1274">tations of these concepts given by per-concept word distributions in each language. Z = {zi, ... , zK} represents the set of K latent cross-lingual concepts present in the multilingual corpus. These K semantic concepts actually span a latent cross-lingual semantic space. Each word w, irrespective of its actual language, may be represented in that latent semantic space as a K-dimensional vector, where each vector component is a conditional concept score P(zk|w). A number of models may be employed to induce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent l</context>
</contexts>
<marker>Dumais, Landauer, Littman, 1996</marker>
<rawString>Susan T. Dumais, Thomas K. Landauer, and Michael Littman. 1996. Automatic cross-linguistic information retrieval using Latent Semantic Indexing. In Proceedings of the SIGIR Workshop on CrossLinguistic Information Retrieval, pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Syntactic transfer using a bilingual lexicon.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>1--11</pages>
<contexts>
<context position="2708" citStr="Durrett et al., 2012" startWordPosition="409" endWordPosition="412">S models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingua</context>
</contexts>
<marker>Durrett, Pauls, Klein, 2012</marker>
<rawString>Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntactic transfer using a bilingual lexicon. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kosuke Fukumasu</author>
<author>Koji Eguchi</author>
<author>Eric P Xing</author>
</authors>
<title>Symmetric correspondence topic models for multilingual text analysis.</title>
<date>2012</date>
<booktitle>In Procedings of the 25th Annual Conference on Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>1295--1303</pages>
<contexts>
<context position="8958" citStr="Fukumasu et al., 2012" startWordPosition="1357" endWordPosition="1360">atent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 2013), the description in this paper relies on the multilingual probabilistic topic modeling (MuPTM) framework. We draw a direct parallel between latent cross-lingual concepts and latent cross-lingual topics, and we present the framework from the MuPTM perspective, but the proposed framework is generic and allows the usage of all other models that are able to compute probability sc</context>
</contexts>
<marker>Fukumasu, Eguchi, Xing, 2012</marker>
<rawString>Kosuke Fukumasu, Koji Eguchi, and Eric P. Xing. 2012. Symmetric correspondence topic models for multilingual text analysis. In Procedings of the 25th Annual Conference on Advances in Neural Information Processing Systems (NIPS), pages 1295–1303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using Wikipediabased explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<pages>1606--1611</pages>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using Wikipediabased explicit semantic analysis. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI), pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Dipanjan Das</author>
</authors>
<title>Crosslingual discriminative learning of sequence models with posterior regularization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1996--2006</pages>
<contexts>
<context position="2847" citStr="Ganchev and Das, 2013" startWordPosition="431" endWordPosition="434"> models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingual similarity from comparable corpora have gained much attention recently. All these models from parallel and comparable corpora provide ran</context>
</contexts>
<marker>Ganchev, Das, 2013</marker>
<rawString>Kuzman Ganchev and Dipanjan Das. 2013. Crosslingual discriminative learning of sequence models with posterior regularization. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1996–2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>´Eric Gaussier</author>
<author>Cyril Goutte</author>
</authors>
<title>Relation between PLSA and NMF and implications.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>601--602</pages>
<contexts>
<context position="8576" citStr="Gaussier and Goutte, 2005" startWordPosition="1297" endWordPosition="1300">s. These K semantic concepts actually span a latent cross-lingual semantic space. Each word w, irrespective of its actual language, may be represented in that latent semantic space as a K-dimensional vector, where each vector component is a conditional concept score P(zk|w). A number of models may be employed to induce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 20</context>
</contexts>
<marker>Gaussier, Goutte, 2005</marker>
<rawString>´Eric Gaussier and Cyril Goutte. 2005. Relation between PLSA and NMF and implications. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 601–602.</rawString>
</citation>
<citation valid="true">
<authors>
<author>´Eric Gaussier</author>
<author>Jean-Michel Renders</author>
<author>Irina Matveeva</author>
<author>Cyril Goutte</author>
<author>Herv´e D´ejean</author>
</authors>
<title>A geometric view on bilingual lexicon extraction from comparable corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>526--533</pages>
<marker>Gaussier, Renders, Matveeva, Goutte, D´ejean, 2004</marker>
<rawString>´Eric Gaussier, Jean-Michel Renders, Irina Matveeva, Cyril Goutte, and Herv´e D´ejean. 2004. A geometric view on bilingual lexicon extraction from comparable corpora. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 526–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Geman</author>
<author>Donald Geman</author>
</authors>
<title>Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images.</title>
<date>1984</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>6</volume>
<issue>6</issue>
<contexts>
<context position="32130" citStr="Geman and Geman, 1984" startWordPosition="5175" endWordPosition="5178">al semantic concepts. However, in this particular work we present results obtained by a multilingual probabilistic topic model called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). The BiLDA model is a straightforward multilingual extension of the standard LDA model (Blei et al., 2003). For the details regarding the modeling, generative story and training of the bilingual LDA model, we refer the interested reader to the aforementioned relevant literature. We have used the Gibbs sampling procedure 1Available at http://people.cs.kuleuven.be/ ∼ivan.vulic/software/ (Geman and Geman, 1984) tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 − 2500. Here, we present only the results obtained with K = 2000 for all language pairs which also yielded the best or near-optimal performance in (Dinu and Lapata, 2010b; Vuli´c et al., 2011). Other parameters of the model are set to the typical values according to Steyvers and Griffiths (2007): α = 50/K and β = 0.01. 2 Models in Comparison. We test the performance of our Direct-Fusion, Smoothed-Fusion and LateFusion models, and compare their results with the context-inse</context>
</contexts>
<marker>Geman, Geman, 1984</marker>
<rawString>Stuart Geman and Donald Geman. 1984. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6(6):721–741.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Grefenstette</author>
<author>Mehrnoosh Sadrzadeh</author>
</authors>
<title>Experimental support for a categorical compositional distributional model of meaning.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1394--1404</pages>
<contexts>
<context position="17382" citStr="Grefenstette and Sadrzadeh, 2011" startWordPosition="2767" endWordPosition="2770">of words given in the same latent semantic space in a uniform way, irrespective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned parallel data to induce bilingual text </context>
</contexts>
<marker>Grefenstette, Sadrzadeh, 2011</marker>
<rawString>Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011. Experimental support for a categorical compositional distributional model of meaning. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1394–1404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Topics in semantic representation.</title>
<date>2007</date>
<journal>Psychological Review,</journal>
<volume>114</volume>
<issue>2</issue>
<contexts>
<context position="15419" citStr="Griffiths et al., 2007" startWordPosition="2438" endWordPosition="2441">pace spanned by latent cross-lingual concepts. Eq. (1) shows how to represent single words in the latent semantic space. Now, we present a way to address compositionality, that is, we show how to build the same representations in the same latent semantic space beyond the word level. We need to compute a conditional concept distribution for the context set Con(wi ), that is, we have to compute the probability scores P(zk|Con(wi )) for each zk E Z. Remember that the context Con(wi ) is actually a set of r (or M after pruning) words Con(wi ) = {cwi , ... , cws}. Under the singletopic assumption (Griffiths et al., 2007) and following Bayes’ rule, it holds: S P(Con(w1 )|zk)P(zk) P(zk|Con(w1 )) = P(Con(wS1 )) P(cwS1 ,... ,cwSr |zk)P(zk) =(2) Pl=1 P(cwS1 , ... , cwSr |zl)P(zl) Qrj=1 P(cwSj |zk)P(zk) = (3) Pl=1 Qjr=1 P(cwjS |zl)P(zl) Note that here we use a simplification where we assume that all cwt E Con(wi ) are conditionally independent given zk. The assumption of the conditional independence of unigrams is a standard heuristic applied in bag-of-words model in NLP and IR (e.g., one may observe a direct analogy to probabilistic language models for IR where the assumption of independence of query words is impo</context>
<context position="33231" citStr="Griffiths et al., 2007" startWordPosition="5353" endWordPosition="5356"> performance of our Direct-Fusion, Smoothed-Fusion and LateFusion models, and compare their results with the context-insensitive CLSS models described in sect. 2 (No-Context). We provide results with two different similarity functions: (1) We have tested different SF-s (e.g., the Kullback-Leibler and the Jensen-Shannon divergence, the cosine measure) on the K-dimensional vector representations, and have detected that in general the best scores are obtained with the Bhattacharyya coefficient (BC) (Cha, 2007; Kazama et al., 2010), (2) Another similarity method we use is the socalled Cue method (Griffiths et al., 2007; Vuli´c et al., 2011), which models the probability that a target word tTi will be generated as an association response given some cue source word wS1 . In short, the method computes the score P(tTi jwS1 ) = P(tTi jzk)P(zkjwS1 ). We can use the scores P(tTi jwS1 ) obtained by inputting out-ofcontext probability scores P(zkjwS1 ) or modulated probability scores P&apos;(zkjwS1 ) to produce the ranking of translation candidates. 5 Results and Discussion The performance of all the models in comparison is displayed in tab. 3. These results lead us to several conclusions: (i) All proposed context-sensit</context>
</contexts>
<marker>Griffiths, Steyvers, Tenenbaum, 2007</marker>
<rawString>Thomas L. Griffiths, Mark Steyvers, and Joshua B. Tenenbaum. 2007. Topics in semantic representation. Psychological Review, 114(2):211–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT),</booktitle>
<pages>771--779</pages>
<contexts>
<context position="5664" citStr="Haghighi et al., 2008" startWordPosition="861" endWordPosition="864">Apidianaki, 2011)), we explore these models in a particularly difficult and minimalist setting that builds only on co-occurrence counts and latent cross-lingual semantic concepts induced directly from comparable corpora, and which does not rely on any other resource (e.g., machine-readable dictionaries, parallel corpora, explicit ontology and category knowledge). In that respect, the work reported in this paper extends the current research on purely statistical data-driven distributional models of cross-lingual semantic similarity that are built upon the idea of latent cross-lingual concepts (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Vuli´c et al., 2011; Vuli´c and Moens, 2013) induced from non-parallel data. While all the previous models in this framework are context-insensitive models of semantic similarity, we demonstrate how to build context-aware models of semantic similarity within the same probabilistic framework which relies on the same shared set of latent concepts. The main contributions of this paper are: • We present a new probabilistic approach to modeling cross-lingual semantic similarity in context based on latent cross-lingual semantic concepts induced from non-parallel d</context>
<context position="8745" citStr="Haghighi et al., 2008" startWordPosition="1322" endWordPosition="1325">c space as a K-dimensional vector, where each vector component is a conditional concept score P(zk|w). A number of models may be employed to induce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 2013), the description in this paper relies on the multilingual probabilistic topic modeling (MuPTM) framework. We draw a direct parallel between latent cross-lingual conc</context>
<context position="28664" citStr="Haghighi et al., 2008" startWordPosition="4603" endWordPosition="4606">om our test set accompanied by the sets of their respective possible senses/translations in English. All corpora are theme-aligned comparable corpora, i.e, the aligned document pairs discuss similar themes, but are in general not direct translations (except for Europarl). By training on Wiki+EP-NL-EN we want to test how the training corpus of higher quality affects the estimation of latent cross-lingual concepts that span the shared latent semantic space and, consequently, the overall results in the task of suggesting word translations in context. Following prior work (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we retain only nouns that occur at least 5 times in the corpus. We record lemmatized word forms when available, and original forms otherwise. We use TreeTagger (Schmid, 1994) for POS tagging and lemmatization. Test Data. We have constructed test datasets in Spanish (ES), Italian (IT) and Dutch (NL), where the aim is to find their correct translation in English (EN) given the sentential context. We have selected 15 polysemous nouns (see tab. 2 for the list of nouns along with their possible translations) in each of the 3 languages, and have </context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT), pages 771–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samer Hassan</author>
<author>Rada Mihalcea</author>
</authors>
<title>Crosslingual semantic relatedness using encyclopedic knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1192--1201</pages>
<marker>Hassan, Mihalcea, 2009</marker>
<rawString>Samer Hassan and Rada Mihalcea. 2009. Crosslingual semantic relatedness using encyclopedic knowledge. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1192–1201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samer Hassan</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semantic relatedness using salient semantic analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>884--889</pages>
<marker>Hassan, Mihalcea, 2011</marker>
<rawString>Samer Hassan and Rada Mihalcea. 2011. Semantic relatedness using salient semantic analysis. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI), pages 884–889.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Moritz Hermann</author>
<author>Phil Blunsom</author>
</authors>
<title>The role of syntax in vector space models of compositional semantics.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>894--904</pages>
<contexts>
<context position="18319" citStr="Hermann and Blunsom, 2013" startWordPosition="2915" endWordPosition="2918">ector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned parallel data to induce bilingual text representations. Moreover, this work on compositionality in multilingual settings is only preliminary (e.g., we treat phrases and sentences as bags-of-words), and in future work we will aim to include syntactic information in the composition models as already done in monolingual settings (Socher et al., 2012; Hermann and Blunsom, 2013). Intuition behind the Approach. Going back to our novel CLSS models in context, these models rely on the representations of words and their contexts in the same latent semantic space spanned by latent cross-lingual concepts/topics. The models differ in the way the contextual knowledge is fused with the out-of-context word representations. The key idea behind these models is to represent a word wS1 in the latent semantic space as a distribution over the latent cross-lingual concepts, but now with an additional modulation of the representation after taking its local context into account. The mo</context>
</contexts>
<marker>Hermann, Blunsom, 2013</marker>
<rawString>Karl Moritz Hermann and Phil Blunsom. 2013. The role of syntax in vector space models of compositional semantics. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), pages 894–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Moritz Hermann</author>
<author>Phil Blunsom</author>
</authors>
<title>Multilingual models for compositional distributed semantics.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>58--68</pages>
<contexts>
<context position="17496" citStr="Hermann and Blunsom, 2014" startWordPosition="2784" endWordPosition="2787">e properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned parallel data to induce bilingual text representations. Moreover, this work on compositionality in multilingual settings is only preliminary (e.g., we tr</context>
</contexts>
<marker>Hermann, Blunsom, 2014</marker>
<rawString>Karl Moritz Hermann and Phil Blunsom. 2014. Multilingual models for compositional distributed semantics. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 58–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djoerd Hiemstra</author>
</authors>
<title>A linguistically motivated probabilistic model of information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 2nd European Conference on Research and Advanced Technology for Digital Libraries (ECDL),</booktitle>
<pages>569--584</pages>
<contexts>
<context position="16061" citStr="Hiemstra, 1998" startWordPosition="2549" endWordPosition="2550">it holds: S P(Con(w1 )|zk)P(zk) P(zk|Con(w1 )) = P(Con(wS1 )) P(cwS1 ,... ,cwSr |zk)P(zk) =(2) Pl=1 P(cwS1 , ... , cwSr |zl)P(zl) Qrj=1 P(cwSj |zk)P(zk) = (3) Pl=1 Qjr=1 P(cwjS |zl)P(zl) Note that here we use a simplification where we assume that all cwt E Con(wi ) are conditionally independent given zk. The assumption of the conditional independence of unigrams is a standard heuristic applied in bag-of-words model in NLP and IR (e.g., one may observe a direct analogy to probabilistic language models for IR where the assumption of independence of query words is imposed (Ponte and Croft, 1998; Hiemstra, 1998; Lavrenko and Croft, 2001)), but we have to forewarn the reader that in general the equation P(cwi , ... , cws |zk) = H�=1 P(cw� |zk) is not exact. However, by adopting the conditional independence assumption, in case of the uniform topic prior P(zk) (i.e., we assume that we do not posses any prior knowledge about the importance of latent cross-lingual concepts in a multilingual corpus), eq. (3) may be further simplified: Qr j=1 P(cwS j |zk) P(zk|Con(wS 1 )) ≈ PK Qr j=1 P(cwS j |zl) (4) l=1 The representation of the context set in the latent semantic space is then: vec(Con(wS1 )) = [P(z1|Con(</context>
</contexts>
<marker>Hiemstra, 1998</marker>
<rawString>Djoerd Hiemstra. 1998. A linguistically motivated probabilistic model of information retrieval. In Proceedings of the 2nd European Conference on Research and Advanced Technology for Digital Libraries (ECDL), pages 569–584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric H Huang</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>873--882</pages>
<contexts>
<context position="11123" citStr="Huang et al. (2012)" startWordPosition="1717" endWordPosition="1720">tistics from the training set and do not take into account any contextual information. They provide only out-of-context word representations and are therefore able to deliver only context-insensitive models of similarity. Defining Context. Given an occurrence of a word wS1 , we build its context set Con(wS1 ) = {cwS1 , ... , cwSr } that comprises r words from V S that co-occur with wS1 in a defined contextual scope or granularity. In this work we do not investigate the influence of the context scope (e.g., document-based, paragraph-based, window-based contexts). Following the recent work from Huang et al. (2012) in the monolingual setting, we limit the contextual scope to the sentential context. However, we emphasize that the proposed models are designed to be fully functional regardless of the actual chosen context granularity. e.g., when operating in the sentential context, Con(wS1 ) consists of words occurring in the same sentence with the particular instance of wS1 . Following Mitchell and Lapata (2008), for the sake of simplicity, we impose the bag-of-words assumption, and do not take into account the order of words in the context set as well as context words’ dependency relations to wS1 . Inves</context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric H. Huang, Richard Socher, Christopher D. Manning, and Andrew Y. Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 873–882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition.</title>
<date>2000</date>
<publisher>Prentice Hall PTR.</publisher>
<contexts>
<context position="21732" citStr="Jurafsky and Martin, 2000" startWordPosition="3490" endWordPosition="3494">ng to their respective similarity scores and the best scoring candidate may be selected as the best translation of an occurrence of the word wS1 given its local context. Since the contextual knowledge is integrated directly into the estimation of probability P(zk|wS1 , Con(wS1 )), we name this context-aware CLSS model the Direct-Fusion model. Model II: Smoothed-Fusion. The next model follows the modeling paradigm established within the framework of language modeling (LM), where the idea is to “back off” to a lower order Ngram in case we do not possess any evidence about a higher-order N-gram (Jurafsky and Martin, 2000). The idea now is to smooth the representation of a word in the latent semantic space induced only by the words in its local context with the out-of-context type-based representation of that word induced directly from a large training corpus. In other words, the modulated probability score P&apos;(zk|wS1 ) from eq. (5) is calculated as: P&apos;(zk|wS1 ) = λ1P(zk|Con(wS1 )) + (1 − λ1)P(zk|wS1 ) (9) where λ1 is the interpolation parameter, P(zk|wS1 ) is the out-of-context conditional concept probability score as in eq. (1), and P(zk|Con(wS1 )) is given by eq. (3). This model compromises between the pure c</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Daniel Jurafsky and James H. Martin. 2000. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Prentice Hall PTR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Stijn De Saeger</author>
<author>Kow Kuroda</author>
<author>Masaki Murata</author>
<author>Kentaro Torisawa</author>
</authors>
<title>A Bayesian method for robust estimation of distributional similarities.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>247--256</pages>
<marker>Kazama, De Saeger, Kuroda, Murata, Torisawa, 2010</marker>
<rawString>Jun’ichi Kazama, Stijn De Saeger, Kow Kuroda, Masaki Murata, and Kentaro Torisawa. 2010. A Bayesian method for robust estimation of distributional similarities. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 247–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungchul Kim</author>
<author>Kristina Toutanova</author>
<author>Hwanjo Yu</author>
</authors>
<title>Multilingual named entity recognition using parallel data and metadata from Wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>694--702</pages>
<contexts>
<context position="2995" citStr="Kim et al., 2012" startWordPosition="452" endWordPosition="455">ne language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingual similarity from comparable corpora have gained much attention recently. All these models from parallel and comparable corpora provide ranked lists of semantically similar words in the target language in isolation or invariably, that is, they do not explicitly iden349 Proceedings of th</context>
</contexts>
<marker>Kim, Toutanova, Yu, 2012</marker>
<rawString>Sungchul Kim, Kristina Toutanova, and Hwanjo Yu. 2012. Multilingual named entity recognition using parallel data and metadata from Wikipedia. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 694–702.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ivan Titov</author>
<author>Binod Bhattarai</author>
</authors>
<title>Inducing crosslingual distributed representations of words.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1459--1474</pages>
<contexts>
<context position="17827" citStr="Klementiev et al., 2012" startWordPosition="2840" endWordPosition="2844">tional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned parallel data to induce bilingual text representations. Moreover, this work on compositionality in multilingual settings is only preliminary (e.g., we treat phrases and sentences as bags-of-words), and in future work we will aim to include syntactic information in the composition models as already done in monolingual settings (Socher et al., 2012; Hermann and Blunsom, 2013). Intuition behind the Approach. Going back to our novel CLSS models in context, these models rely on the re</context>
</contexts>
<marker>Klementiev, Titov, Bhattarai, 2012</marker>
<rawString>Alexandre Klementiev, Ivan Titov, and Binod Bhattarai. 2012. Inducing crosslingual distributed representations of words. In Proceedings of the 24th International Conference on Computational Linguistics (COLING), pages 1459–1474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Unsupervised Lexical Acquisition (ULA),</booktitle>
<pages>9--16</pages>
<contexts>
<context position="28641" citStr="Koehn and Knight, 2002" startWordPosition="4599" endWordPosition="4602">sh, Italian and Dutch from our test set accompanied by the sets of their respective possible senses/translations in English. All corpora are theme-aligned comparable corpora, i.e, the aligned document pairs discuss similar themes, but are in general not direct translations (except for Europarl). By training on Wiki+EP-NL-EN we want to test how the training corpus of higher quality affects the estimation of latent cross-lingual concepts that span the shared latent semantic space and, consequently, the overall results in the task of suggesting word translations in context. Following prior work (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we retain only nouns that occur at least 5 times in the corpus. We record lemmatized word forms when available, and original forms otherwise. We use TreeTagger (Schmid, 1994) for POS tagging and lemmatization. Test Data. We have constructed test datasets in Spanish (ES), Italian (IT) and Dutch (NL), where the aim is to find their correct translation in English (EN) given the sentential context. We have selected 15 polysemous nouns (see tab. 2 for the list of nouns along with their possible translations) in each of the</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of the ACL Workshop on Unsupervised Lexical Acquisition (ULA), pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Machine Translation Summit (MT SUMMIT),</booktitle>
<pages>79--86</pages>
<contexts>
<context position="25830" citStr="Koehn, 2005" startWordPosition="4178" endWordPosition="4179">ist is then the suggested correct translation for that particular occurrence of wS1 after observing its local context Con(wS1 ). Training Data. We use the following corpora for inducing latent cross-lingual concepts/topics, i.e., for training our multilingual topic model: (i) a collection of 13, 696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) a collection of 18, 898 Italian-English Wikipedia article pairs, (iii) a collection of 7,612 Dutch-English Wikipedia article pairs (Wiki-NL-EN), and (iv) the Wiki-NLEN corpus augmented with 6,206 Dutch-English document pairs from Europarl (Koehn, 2005) (Wiki+EP-NL-EN). The corpora were previously used in (Vuli´c and Moens, 2013). No explicit use is made of sentence-level alignments in Europarl. 354 Sentence in Italian Correct Translation (EN) 1. I primi calci furono prodotti in legno ma recentemente... stock 2. In caso di osteoporosi si verifica un eccesso di rilascio di calcio dallo scheletro... calcium 3. La crescita del calcio femminile professionistico ha visto il lancio di competizioni... football 4. Il calcio di questa pistola (Beretta Modello 21a, calibro .25) ha le guancette in materiale... stock Table 1: Example sentences from our </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of the 10th Machine Translation Summit (MT SUMMIT), pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom´aˇs Koˇcisk´y</author>
<author>Karl Moritz Hermann</author>
<author>Phil Blunsom</author>
</authors>
<title>Learning bilingual word representations by marginalizing alignments.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>224--229</pages>
<marker>Koˇcisk´y, Hermann, Blunsom, 2014</marker>
<rawString>Tom´aˇs Koˇcisk´y, Karl Moritz Hermann, and Phil Blunsom. 2014. Learning bilingual word representations by marginalizing alignments. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 224–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Lavrenko</author>
<author>W Bruce Croft</author>
</authors>
<title>Relevance-based language models.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>120--127</pages>
<contexts>
<context position="16088" citStr="Lavrenko and Croft, 2001" startWordPosition="2551" endWordPosition="2554">n(w1 )|zk)P(zk) P(zk|Con(w1 )) = P(Con(wS1 )) P(cwS1 ,... ,cwSr |zk)P(zk) =(2) Pl=1 P(cwS1 , ... , cwSr |zl)P(zl) Qrj=1 P(cwSj |zk)P(zk) = (3) Pl=1 Qjr=1 P(cwjS |zl)P(zl) Note that here we use a simplification where we assume that all cwt E Con(wi ) are conditionally independent given zk. The assumption of the conditional independence of unigrams is a standard heuristic applied in bag-of-words model in NLP and IR (e.g., one may observe a direct analogy to probabilistic language models for IR where the assumption of independence of query words is imposed (Ponte and Croft, 1998; Hiemstra, 1998; Lavrenko and Croft, 2001)), but we have to forewarn the reader that in general the equation P(cwi , ... , cws |zk) = H�=1 P(cw� |zk) is not exact. However, by adopting the conditional independence assumption, in case of the uniform topic prior P(zk) (i.e., we assume that we do not posses any prior knowledge about the importance of latent cross-lingual concepts in a multilingual corpus), eq. (3) may be further simplified: Qr j=1 P(cwS j |zk) P(zk|Con(wS 1 )) ≈ PK Qr j=1 P(cwS j |zl) (4) l=1 The representation of the context set in the latent semantic space is then: vec(Con(wS1 )) = [P(z1|Con(wS1 )), ... , P(zK|Con(wS1 </context>
</contexts>
<marker>Lavrenko, Croft, 2001</marker>
<rawString>Victor Lavrenko and W. Bruce Croft. 2001. Relevance-based language models. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 120–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Lavrenko</author>
<author>Martin Choquette</author>
<author>W Bruce Croft</author>
</authors>
<title>Cross-lingual relevance models.</title>
<date>2002</date>
<booktitle>In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>175--182</pages>
<contexts>
<context position="1914" citStr="Lavrenko et al., 2002" startWordPosition="274" endWordPosition="277">rity (CLSS) is a metric that measures to which extent words (or more generally, text units) describe similar semantic concepts and convey similar meanings across languages. Models of cross-lingual similarity are typically used to automatically induce bilingual lexicons and have found numerous applications in information retrieval (IR), statistical machine translation (SMT) and other natural language processing (NLP) tasks. Within the IR framework, the output of the CLSS models is a key resource in the models of dictionary-based cross-lingual information retrieval (Ballesteros and Croft, 1997; Lavrenko et al., 2002; Levow et al., 2005; Wang and Oard, 2006) or may be utilized in query expansion in cross-lingual IR models (Adriani and van Rijsbergen, 1999; Vuli´c et al., 2013). These CLSS models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained </context>
</contexts>
<marker>Lavrenko, Choquette, Croft, 2002</marker>
<rawString>Victor Lavrenko, Martin Choquette, and W. Bruce Croft. 2002. Cross-lingual relevance models. In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 175–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel D Lee</author>
<author>H Sebastian Seung</author>
</authors>
<title>Algorithms for non-negative matrix factorization.</title>
<date>1999</date>
<booktitle>In Proceedings of the 12th Conference on Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>556--562</pages>
<contexts>
<context position="8549" citStr="Lee and Seung, 1999" startWordPosition="1293" endWordPosition="1296">he multilingual corpus. These K semantic concepts actually span a latent cross-lingual semantic space. Each word w, irrespective of its actual language, may be represented in that latent semantic space as a K-dimensional vector, where each vector component is a conditional concept score P(zk|w). A number of models may be employed to induce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information r</context>
</contexts>
<marker>Lee, Seung, 1999</marker>
<rawString>Daniel D. Lee and H. Sebastian Seung. 1999. Algorithms for non-negative matrix factorization. In Proceedings of the 12th Conference on Advances in Neural Information Processing Systems (NIPS), pages 556–562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>25--32</pages>
<contexts>
<context position="20782" citStr="Lee, 1999" startWordPosition="3328" endWordPosition="3329">f we closely follow the derivation from eq. (3) which shows how to project context into the latent semantic space (and again assume the uniform topic prior P (zk)), we finally obtain the following formula: P&apos;(zk|wS P(wS1|zk) IIjr=1 P(cwSj |zk) (7) El=1 P(wS1 |zl) IIrj=1 P(cw3flzl) The ranking of all words wT2 E VT according to their similarity to wS1 may be computed by detecting the similarity score between their representation in the K-dimensional latent semantic space and the modulated source word representation as given by eq. (5) and eq. (7) using any of the existing similarity functions (Lee, 1999; Cha, 2007). The similarity score Sim(wS1 , wT2 , Con(wS1 )) between some wT2 E VT represented by its vector vec(wT2 ) and the observed word wS1 given its context Con(wS1 ) is computed as: sim(wS1 , wT2 , Con(wS1 )) = SF(vec(ws, Con(wS1 )), vec(w2)) (8) where SF denotes a similarity function. Words are then ranked according to their respective similarity scores and the best scoring candidate may be selected as the best translation of an occurrence of the word wS1 given its local context. Since the contextual knowledge is integrated directly into the estimation of probability P(zk|wS1 , Con(wS</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>Lillian Lee. 1999. Measures of distributional similarity. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL), pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gina-Anne Levow</author>
<author>Douglas W Oard</author>
<author>Philip Resnik</author>
</authors>
<title>Dictionary-based techniques for cross-language information retrieval.</title>
<date>2005</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>41--3</pages>
<contexts>
<context position="1934" citStr="Levow et al., 2005" startWordPosition="278" endWordPosition="281"> that measures to which extent words (or more generally, text units) describe similar semantic concepts and convey similar meanings across languages. Models of cross-lingual similarity are typically used to automatically induce bilingual lexicons and have found numerous applications in information retrieval (IR), statistical machine translation (SMT) and other natural language processing (NLP) tasks. Within the IR framework, the output of the CLSS models is a key resource in the models of dictionary-based cross-lingual information retrieval (Ballesteros and Croft, 1997; Lavrenko et al., 2002; Levow et al., 2005; Wang and Oard, 2006) or may be utilized in query expansion in cross-lingual IR models (Adriani and van Rijsbergen, 1999; Vuli´c et al., 2013). These CLSS models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models</context>
</contexts>
<marker>Levow, Oard, Resnik, 2005</marker>
<rawString>Gina-Anne Levow, Douglas W. Oard, and Philip Resnik. 2005. Dictionary-based techniques for cross-language information retrieval. Information Processing and Management, 41(3):523–547.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Qiaozhu Mei</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Investigating task performance of probabilistic topic models: An empirical study of PLSA and LDA.</title>
<date>2011</date>
<journal>Information Retrieval,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="34174" citStr="Lu et al., 2011" startWordPosition="5508" endWordPosition="5511">S1 ) or modulated probability scores P&apos;(zkjwS1 ) to produce the ranking of translation candidates. 5 Results and Discussion The performance of all the models in comparison is displayed in tab. 3. These results lead us to several conclusions: (i) All proposed context-sensitive CLSS models suggesting word translations in context significantly outperform context-insensitive CLSS models, which are able to produce only word translations in isolation. The improvements in results when taking context into account are ob2We are well aware that different hyper-parameter settings (Asuncion et al., 2009; Lu et al., 2011), might have influence on the quality of learned latent cross-lingual concepts/topics and, consequently, the quality of latent semantic space, but that analysis is not the focus of this work. Additionally, we perform semantic space pruning (Reisinger and Mooney, 2010; Vuli´c and Moens, 2013). All computations are performed over the best scoring 100 cross-lingual topics according to their respective scores P(zk|wSi ) similarly to (Vuli´c and Moens, 2013). 356 Direction: ES→EN IT→EN NL→EN (Wiki) NL→EN (Wiki+EP) Model Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 (SF=BC) (SF=Cue) (SF=BC) (SF=Cue) (SF=B</context>
</contexts>
<marker>Lu, Mei, Zhai, 2011</marker>
<rawString>Yue Lu, Qiaozhu Mei, and Chengxiang Zhai. 2011. Investigating task performance of probabilistic topic models: An empirical study of PLSA and LDA. Information Retrieval, 14(2):178–203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Philip McCrae</author>
<author>Philipp Cimiano</author>
<author>Roman Klinger</author>
</authors>
<title>Orthonormal explicit topic analysis for cross-lingual document matching.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1732--1740</pages>
<marker>McCrae, Cimiano, Klinger, 2013</marker>
<rawString>John Philip McCrae, Philipp Cimiano, and Roman Klinger. 2013. Orthonormal explicit topic analysis for cross-lingual document matching. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1732–1740.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
<author>Vivian Tsang</author>
<author>Gianluca Allaria</author>
</authors>
<title>A multilingual paradigm for automatic verb classification.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>207--214</pages>
<contexts>
<context position="2889" citStr="Merlo et al., 2002" startWordPosition="438" endWordPosition="441">ingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingual similarity from comparable corpora have gained much attention recently. All these models from parallel and comparable corpora provide ranked lists of semantically similar words in</context>
</contexts>
<marker>Merlo, Stevenson, Tsang, Allaria, 2002</marker>
<rawString>Paola Merlo, Suzanne Stevenson, Vivian Tsang, and Gianluca Allaria. 2002. A multilingual paradigm for automatic verb classification. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 207–214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna Wallach</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
<author>Andrew McCallum</author>
</authors>
<title>Polylingual topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>880--889</pages>
<contexts>
<context position="8886" citStr="Mimno et al., 2009" startWordPosition="1345" endWordPosition="1348">uce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 2013), the description in this paper relies on the multilingual probabilistic topic modeling (MuPTM) framework. We draw a direct parallel between latent cross-lingual concepts and latent cross-lingual topics, and we present the framework from the MuPTM perspective, but the proposed framework is generic and allo</context>
<context position="31675" citStr="Mimno et al., 2009" startWordPosition="5109" endWordPosition="5112">anguage pairs. We use sorted context sets (see sect. 2) and perform a cut-off at M = 3 most descriptive context words in the sorted context sets for all models. In the following section we discuss the utility of this context sorting and pruning, as well as its influence on the overall results. Inducing Latent Cross-Lingual Concepts. Our context-aware models are generic and allow experimentations with different models that induce latent cross-lingual semantic concepts. However, in this particular work we present results obtained by a multilingual probabilistic topic model called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). The BiLDA model is a straightforward multilingual extension of the standard LDA model (Blei et al., 2003). For the details regarding the modeling, generative story and training of the bilingual LDA model, we refer the interested reader to the aforementioned relevant literature. We have used the Gibbs sampling procedure 1Available at http://people.cs.kuleuven.be/ ∼ivan.vulic/software/ (Geman and Geman, 1984) tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 − 2500. Here, we prese</context>
</contexts>
<marker>Mimno, Wallach, Naradowsky, Smith, McCallum, 2009</marker>
<rawString>David Mimno, Hanna Wallach, Jason Naradowsky, David A. Smith, and Andrew McCallum. 2009. Polylingual topic models. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 880–889.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Vector-based models of semantic composition.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>236--244</pages>
<contexts>
<context position="11526" citStr="Mitchell and Lapata (2008)" startWordPosition="1780" endWordPosition="1783">fined contextual scope or granularity. In this work we do not investigate the influence of the context scope (e.g., document-based, paragraph-based, window-based contexts). Following the recent work from Huang et al. (2012) in the monolingual setting, we limit the contextual scope to the sentential context. However, we emphasize that the proposed models are designed to be fully functional regardless of the actual chosen context granularity. e.g., when operating in the sentential context, Con(wS1 ) consists of words occurring in the same sentence with the particular instance of wS1 . Following Mitchell and Lapata (2008), for the sake of simplicity, we impose the bag-of-words assumption, and do not take into account the order of words in the context set as well as context words’ dependency relations to wS1 . Investigating different context types (e.g., dependency-based) is a subject of future work. By using all words occurring with wS1 in a context set (e.g., a sentence) to build the set Con(wS1 ), we do not make any distinction between “informative and “uninformative” context words. However, some context words bear more contextual information about the observed word wS1 and are stronger indicators of the cor</context>
</contexts>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2008. Vector-based models of semantic composition. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL), pages 236–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="17268" citStr="Mitchell and Lapata, 2010" startWordPosition="2750" endWordPosition="2753">S1 )) = [P(z1|Con(wS1 )), ... , P(zK|Con(wS1 ))] We can then compute the similarity between words and sets of words given in the same latent semantic space in a uniform way, irrespective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Bin Wang</author>
<author>Yee Seng Chan</author>
</authors>
<title>Exploiting parallel texts for word sense disambiguation: An empirical study.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>455--462</pages>
<contexts>
<context position="5021" citStr="Ng et al., 2003" startWordPosition="770" endWordPosition="773">atch when observed in isolation, given the Spanish sentence ”She was unable to find a match in her pocket to light up a cigarette.”, it is clear that the strength of semantic similarity should change in context as only cerilla exhibits a strong semantic similarity to match within this particular sentential context. Following this intuition, in this paper we investigate models of cross-lingual semantic similarity in context. The context-sensitive models of similarity target to re-rank the lists of semantically similar words based on the co-occurring contexts of words. Unlike prior work (e.g., (Ng et al., 2003; Prior et al., 2011; Apidianaki, 2011)), we explore these models in a particularly difficult and minimalist setting that builds only on co-occurrence counts and latent cross-lingual semantic concepts induced directly from comparable corpora, and which does not rely on any other resource (e.g., machine-readable dictionaries, parallel corpora, explicit ontology and category knowledge). In that respect, the work reported in this paper extends the current research on purely statistical data-driven distributional models of cross-lingual semantic similarity that are built upon the idea of latent cr</context>
</contexts>
<marker>Ng, Wang, Chan, 2003</marker>
<rawString>Hwee Tou Ng, Bin Wang, and Yee Seng Chan. 2003. Exploiting parallel texts for word sense disambiguation: An empirical study. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 455–462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaochuan Ni</author>
<author>Jian-Tao Sun</author>
<author>Jian Hu</author>
<author>Zheng Chen</author>
</authors>
<title>Mining multilingual topics from Wikipedia.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th International World Wide Web Conference (WWW),</booktitle>
<pages>1155--1156</pages>
<contexts>
<context position="8841" citStr="Ni et al., 2009" startWordPosition="1336" endWordPosition="1339"> A number of models may be employed to induce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 2013), the description in this paper relies on the multilingual probabilistic topic modeling (MuPTM) framework. We draw a direct parallel between latent cross-lingual concepts and latent cross-lingual topics, and we present the framework from the MuPTM perspective, b</context>
<context position="31692" citStr="Ni et al., 2009" startWordPosition="5113" endWordPosition="5116">e sorted context sets (see sect. 2) and perform a cut-off at M = 3 most descriptive context words in the sorted context sets for all models. In the following section we discuss the utility of this context sorting and pruning, as well as its influence on the overall results. Inducing Latent Cross-Lingual Concepts. Our context-aware models are generic and allow experimentations with different models that induce latent cross-lingual semantic concepts. However, in this particular work we present results obtained by a multilingual probabilistic topic model called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). The BiLDA model is a straightforward multilingual extension of the standard LDA model (Blei et al., 2003). For the details regarding the modeling, generative story and training of the bilingual LDA model, we refer the interested reader to the aforementioned relevant literature. We have used the Gibbs sampling procedure 1Available at http://people.cs.kuleuven.be/ ∼ivan.vulic/software/ (Geman and Geman, 1984) tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 − 2500. Here, we present only the resul</context>
</contexts>
<marker>Ni, Sun, Hu, Chen, 2009</marker>
<rawString>Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen. 2009. Mining multilingual topics from Wikipedia. In Proceedings of the 18th International World Wide Web Conference (WWW), pages 1155–1156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Anna Korhonen</author>
</authors>
<title>Probabilistic models of similarity in syntactic context.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1047--1057</pages>
<marker>S´eaghdha, Korhonen, 2011</marker>
<rawString>Diarmuid O´ S´eaghdha and Anna Korhonen. 2011. Probabilistic models of similarity in syntactic context. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1047–1057.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="2188" citStr="Och and Ney, 2003" startWordPosition="324" endWordPosition="327"> found numerous applications in information retrieval (IR), statistical machine translation (SMT) and other natural language processing (NLP) tasks. Within the IR framework, the output of the CLSS models is a key resource in the models of dictionary-based cross-lingual information retrieval (Ballesteros and Croft, 1997; Lavrenko et al., 2002; Levow et al., 2005; Wang and Oard, 2006) or may be utilized in query expansion in cross-lingual IR models (Adriani and van Rijsbergen, 1999; Vuli´c et al., 2013). These CLSS models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petr</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Crosslingual annotation projection for semantic roles.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>36</volume>
<pages>340</pages>
<marker>Pad´o, Lapata, 2009</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2009. Crosslingual annotation projection for semantic roles. Journal of Artificial Intelligence Research, 36:307– 340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Peirsman</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Crosslingual induction of selectional preferences with bilingual vector spaces.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Meeting of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<pages>921--929</pages>
<marker>Peirsman, Pad´o, 2010</marker>
<rawString>Yves Peirsman and Sebastian Pad´o. 2010. Crosslingual induction of selectional preferences with bilingual vector spaces. In Proceedings of the 11th Meeting of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 921–929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay M Ponte</author>
<author>W Bruce Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>275--281</pages>
<contexts>
<context position="16045" citStr="Ponte and Croft, 1998" startWordPosition="2545" endWordPosition="2548">following Bayes’ rule, it holds: S P(Con(w1 )|zk)P(zk) P(zk|Con(w1 )) = P(Con(wS1 )) P(cwS1 ,... ,cwSr |zk)P(zk) =(2) Pl=1 P(cwS1 , ... , cwSr |zl)P(zl) Qrj=1 P(cwSj |zk)P(zk) = (3) Pl=1 Qjr=1 P(cwjS |zl)P(zl) Note that here we use a simplification where we assume that all cwt E Con(wi ) are conditionally independent given zk. The assumption of the conditional independence of unigrams is a standard heuristic applied in bag-of-words model in NLP and IR (e.g., one may observe a direct analogy to probabilistic language models for IR where the assumption of independence of query words is imposed (Ponte and Croft, 1998; Hiemstra, 1998; Lavrenko and Croft, 2001)), but we have to forewarn the reader that in general the equation P(cwi , ... , cws |zk) = H�=1 P(cw� |zk) is not exact. However, by adopting the conditional independence assumption, in case of the uniform topic prior P(zk) (i.e., we assume that we do not posses any prior knowledge about the importance of latent cross-lingual concepts in a multilingual corpus), eq. (3) may be further simplified: Qr j=1 P(cwS j |zk) P(zk|Con(wS 1 )) ≈ PK Qr j=1 P(cwS j |zl) (4) l=1 The representation of the context set in the latent semantic space is then: vec(Con(wS1</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Jay M. Ponte and W. Bruce Croft. 1998. A language modeling approach to information retrieval. In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 275–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anat Prior</author>
<author>Shuly Wintner</author>
<author>Brian MacWhinney</author>
<author>Alon Lavie</author>
</authors>
<title>Translation ambiguity in and out of context.</title>
<date>2011</date>
<journal>Applied Psycholinguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<pages>111</pages>
<contexts>
<context position="5041" citStr="Prior et al., 2011" startWordPosition="774" endWordPosition="777">d in isolation, given the Spanish sentence ”She was unable to find a match in her pocket to light up a cigarette.”, it is clear that the strength of semantic similarity should change in context as only cerilla exhibits a strong semantic similarity to match within this particular sentential context. Following this intuition, in this paper we investigate models of cross-lingual semantic similarity in context. The context-sensitive models of similarity target to re-rank the lists of semantically similar words based on the co-occurring contexts of words. Unlike prior work (e.g., (Ng et al., 2003; Prior et al., 2011; Apidianaki, 2011)), we explore these models in a particularly difficult and minimalist setting that builds only on co-occurrence counts and latent cross-lingual semantic concepts induced directly from comparable corpora, and which does not rely on any other resource (e.g., machine-readable dictionaries, parallel corpora, explicit ontology and category knowledge). In that respect, the work reported in this paper extends the current research on purely statistical data-driven distributional models of cross-lingual semantic similarity that are built upon the idea of latent cross-lingual concepts</context>
</contexts>
<marker>Prior, Wintner, MacWhinney, Lavie, 2011</marker>
<rawString>Anat Prior, Shuly Wintner, Brian MacWhinney, and Alon Lavie. 2011. Translation ambiguity in and out of context. Applied Psycholinguistics, 32(1):93– 111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Prochasson</author>
<author>Pascale Fung</author>
</authors>
<title>Rare word translation extraction from aligned comparable documents.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT),</booktitle>
<pages>1327--1335</pages>
<contexts>
<context position="28691" citStr="Prochasson and Fung, 2011" startWordPosition="4607" endWordPosition="4610">nied by the sets of their respective possible senses/translations in English. All corpora are theme-aligned comparable corpora, i.e, the aligned document pairs discuss similar themes, but are in general not direct translations (except for Europarl). By training on Wiki+EP-NL-EN we want to test how the training corpus of higher quality affects the estimation of latent cross-lingual concepts that span the shared latent semantic space and, consequently, the overall results in the task of suggesting word translations in context. Following prior work (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we retain only nouns that occur at least 5 times in the corpus. We record lemmatized word forms when available, and original forms otherwise. We use TreeTagger (Schmid, 1994) for POS tagging and lemmatization. Test Data. We have constructed test datasets in Spanish (ES), Italian (IT) and Dutch (NL), where the aim is to find their correct translation in English (EN) given the sentential context. We have selected 15 polysemous nouns (see tab. 2 for the list of nouns along with their possible translations) in each of the 3 languages, and have manually extracted 24 sente</context>
</contexts>
<marker>Prochasson, Fung, 2011</marker>
<rawString>Emmanuel Prochasson and Pascale Fung. 2011. Rare word translation extraction from aligned comparable documents. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT), pages 1327–1335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Reisinger</author>
<author>Raymond J Mooney</author>
</authors>
<title>A mixture model with sharing for lexical semantics.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1173--1182</pages>
<contexts>
<context position="34441" citStr="Reisinger and Mooney, 2010" startWordPosition="5549" endWordPosition="5552">d context-sensitive CLSS models suggesting word translations in context significantly outperform context-insensitive CLSS models, which are able to produce only word translations in isolation. The improvements in results when taking context into account are ob2We are well aware that different hyper-parameter settings (Asuncion et al., 2009; Lu et al., 2011), might have influence on the quality of learned latent cross-lingual concepts/topics and, consequently, the quality of latent semantic space, but that analysis is not the focus of this work. Additionally, we perform semantic space pruning (Reisinger and Mooney, 2010; Vuli´c and Moens, 2013). All computations are performed over the best scoring 100 cross-lingual topics according to their respective scores P(zk|wSi ) similarly to (Vuli´c and Moens, 2013). 356 Direction: ES→EN IT→EN NL→EN (Wiki) NL→EN (Wiki+EP) Model Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 Acc1 (SF=BC) (SF=Cue) (SF=BC) (SF=Cue) (SF=BC) (SF=Cue) (SF=BC) (SF=Cue) No-Context .406 .406 .408 .408 .433 .433 .433 .433 Direct-Fusion .617 .575 .714 .697 .603 .592 .606 .636 Smoothed-Fusion .664 .703* .731 .789* .669 .712* .692 .761* Late-Fusion .675 .667 .742 .728 .667 .644 .683 .722 Table 3: Results on t</context>
</contexts>
<marker>Reisinger, Mooney, 2010</marker>
<rawString>Joseph Reisinger and Raymond J. Mooney. 2010. A mixture model with sharing for lexical semantics. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1173–1182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Rudolph</author>
<author>Eugenie Giesbrecht</author>
</authors>
<title>Compositional matrix-space models of language.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>907--916</pages>
<contexts>
<context position="17298" citStr="Rudolph and Giesbrecht, 2010" startWordPosition="2754" endWordPosition="2757">.. , P(zK|Con(wS1 ))] We can then compute the similarity between words and sets of words given in the same latent semantic space in a uniform way, irrespective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, </context>
</contexts>
<marker>Rudolph, Giesbrecht, 2010</marker>
<rawString>Sebastian Rudolph and Eugenie Giesbrecht. 2010. Compositional matrix-space models of language. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 907–916.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="28892" citStr="Schmid, 1994" startWordPosition="4643" endWordPosition="4644"> translations (except for Europarl). By training on Wiki+EP-NL-EN we want to test how the training corpus of higher quality affects the estimation of latent cross-lingual concepts that span the shared latent semantic space and, consequently, the overall results in the task of suggesting word translations in context. Following prior work (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we retain only nouns that occur at least 5 times in the corpus. We record lemmatized word forms when available, and original forms otherwise. We use TreeTagger (Schmid, 1994) for POS tagging and lemmatization. Test Data. We have constructed test datasets in Spanish (ES), Italian (IT) and Dutch (NL), where the aim is to find their correct translation in English (EN) given the sentential context. We have selected 15 polysemous nouns (see tab. 2 for the list of nouns along with their possible translations) in each of the 3 languages, and have manually extracted 24 sentences (not present in the training data) for each noun that capture different meanings of the noun from Wikipedia. In order to construct datasets that are balanced across different possible translations</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Eric H Huang</author>
<author>Jeffrey Pennington</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Dynamic pooling and unfolding recursive autoencoders for paraphrase detection.</title>
<date>2011</date>
<booktitle>In Proceedings of the 24th Annual Conference on Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>801--809</pages>
<contexts>
<context position="17348" citStr="Socher et al., 2011" startWordPosition="2763" endWordPosition="2766">tween words and sets of words given in the same latent semantic space in a uniform way, irrespective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned paral</context>
</contexts>
<marker>Socher, Huang, Pennington, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Eric H. Huang, Jeffrey Pennington, Andrew Y. Ng, and Christopher D. Manning. 2011. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Proceedings of the 24th Annual Conference on Advances in Neural Information Processing Systems (NIPS), pages 801– 809.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1201--1211</pages>
<contexts>
<context position="17443" citStr="Socher et al., 2012" startWordPosition="2777" endWordPosition="2780">ective of their actual language. We use all these properties when building our context-sensitive CLSS models. One remark: As a by-product of our modeling approach, by this procedure for computing representations for sets of words, we have in fact paved the way towards compositional cross-lingual models of similarity which rely on latent cross-lingual concepts. Similar to compositional models in monolingual settings (Mitchell and Lapata, 2010; Rudolph and Giesbrecht, 2010; Baroni and Zamparelli, 2010; Socher et al., 2011; Grefenstette and Sadrzadeh, 2011; Blacoe and Lapata, 2012; Clarke, 2012; Socher et al., 2012) and multilingual settings (Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), the representation of a set of words (e.g., a phrase or a sentence) is exactly the same as the representation of a single word; it is simply a K-dimensional real-valued vector. Our work on inducing structured representations of words and 352 text units beyond words is similar to (Klementiev et al., 2012; Hermann and Blunsom, 2014; Koˇcisk´y et al., 2014), but unlike them, we do not need high-quality sentence-aligned parallel data to induce bilingual text representations. Moreover, this work on compositionality in m</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1201–1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Tom Griffiths</author>
</authors>
<date>2007</date>
<booktitle>Probabilistic topic models. Handbook of Latent Semantic Analysis,</booktitle>
<pages>427--7</pages>
<contexts>
<context position="32549" citStr="Steyvers and Griffiths (2007)" startWordPosition="5247" endWordPosition="5250">del, we refer the interested reader to the aforementioned relevant literature. We have used the Gibbs sampling procedure 1Available at http://people.cs.kuleuven.be/ ∼ivan.vulic/software/ (Geman and Geman, 1984) tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 − 2500. Here, we present only the results obtained with K = 2000 for all language pairs which also yielded the best or near-optimal performance in (Dinu and Lapata, 2010b; Vuli´c et al., 2011). Other parameters of the model are set to the typical values according to Steyvers and Griffiths (2007): α = 50/K and β = 0.01. 2 Models in Comparison. We test the performance of our Direct-Fusion, Smoothed-Fusion and LateFusion models, and compare their results with the context-insensitive CLSS models described in sect. 2 (No-Context). We provide results with two different similarity functions: (1) We have tested different SF-s (e.g., the Kullback-Leibler and the Jensen-Shannon divergence, the cosine measure) on the K-dimensional vector representations, and have detected that in general the best scores are obtained with the Bhattacharyya coefficient (BC) (Cha, 2007; Kazama et al., 2010), (2) A</context>
</contexts>
<marker>Steyvers, Griffiths, 2007</marker>
<rawString>Mark Steyvers and Tom Griffiths. 2007. Probabilistic topic models. Handbook of Latent Semantic Analysis, 427(7):424–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<journal>Transactions of ACL,</journal>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013a. Token and type constraints for cross-lingual part-of-speech tagging. Transactions of ACL, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Target language adaptation of discriminative transfer parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of the 14th Meeting of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<pages>1061--1071</pages>
<marker>T¨ackstr¨om, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre. 2013b. Target language adaptation of discriminative transfer parsers. In Proceedings of the 14th Meeting of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 1061–1071.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akihiro Tamura</author>
<author>Taro Watanabe</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Bilingual lexicon extraction from comparable corpora using label propagation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>24--36</pages>
<contexts>
<context position="30659" citStr="Tamura et al., 2012" startWordPosition="4936" endWordPosition="4939"> suggesting word translations in context. Evaluation Procedure. Our task is to present the system a list of possible translations and let the system decide a single most likely translation given the word and its sentential context. Ground truth thus contains one word, that is, one correct translation for each sentence from the evaluation dataset. We have manually annotated the correct translation for the ground truth1 by inspecting the discourse in Wikipedia articles and the interlingual Wikipedia links. We measure the performance of all models as Top 1 accuracy (Acc1) (Gaussier et al., 2004; Tamura et al., 2012). It denotes the number of word instances from the evaluation dataset whose top proposed candidate in the ranked list of translation candidates from T is exactly the correct translation for that word instance as given by ground truth over the total number of test word instances (360 in each test dataset). Parameters. We have tuned λ1 and λ2 on the development sets. We set λ1 = λ2 = 0.9 for all language pairs. We use sorted context sets (see sect. 2) and perform a cut-off at M = 3 most descriptive context words in the sorted context sets for all models. In the following section we discuss the u</context>
</contexts>
<marker>Tamura, Watanabe, Sumita, 2012</marker>
<rawString>Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita. 2012. Bilingual lexicon extraction from comparable corpora using label propagation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 24–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael E Tipping</author>
<author>Christopher M Bishop</author>
</authors>
<title>Mixtures of probabilistic principal component analysers.</title>
<date>1999</date>
<journal>Neural Computation,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="8452" citStr="Tipping and Bishop, 1999" startWordPosition="1280" endWordPosition="1283">in each language. Z = {zi, ... , zK} represents the set of K latent cross-lingual concepts present in the multilingual corpus. These K semantic concepts actually span a latent cross-lingual semantic space. Each word w, irrespective of its actual language, may be represented in that latent semantic space as a K-dimensional vector, where each vector component is a conditional concept score P(zk|w). A number of models may be employed to induce the latent concepts. For instance, one could use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the</context>
</contexts>
<marker>Tipping, Bishop, 1999</marker>
<rawString>Michael E. Tipping and Christopher M. Bishop. 1999. Mixtures of probabilistic principal component analysers. Neural Computation, 11(2):443–482.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lonneke van der Plas</author>
<author>Paola Merlo</author>
<author>James Henderson</author>
</authors>
<title>Scaling up automatic cross-lingual semantic role annotation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT),</booktitle>
<pages>299--304</pages>
<marker>van der Plas, Merlo, Henderson, 2011</marker>
<rawString>Lonneke van der Plas, Paola Merlo, and James Henderson. 2011. Scaling up automatic cross-lingual semantic role annotation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT), pages 299–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Vuli´c</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Crosslingual semantic similarity of words as the similarity of their semantic word responses.</title>
<date>2013</date>
<booktitle>In Proceedings of the 14th Meeting of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<pages>106--116</pages>
<marker>Vuli´c, Moens, 2013</marker>
<rawString>Ivan Vuli´c and Marie-Francine Moens. 2013. Crosslingual semantic similarity of words as the similarity of their semantic word responses. In Proceedings of the 14th Meeting of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 106–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Vuli´c</author>
<author>Wim De Smet</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Identifying word translations from comparable corpora using latent topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT),</booktitle>
<pages>479--484</pages>
<marker>Vuli´c, De Smet, Moens, 2011</marker>
<rawString>Ivan Vuli´c, Wim De Smet, and Marie-Francine Moens. 2011. Identifying word translations from comparable corpora using latent topic models. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT), pages 479–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Vuli´c</author>
<author>Wim De Smet</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Cross-language information retrieval models based on latent topic models trained with documentaligned comparable corpora.</title>
<date>2013</date>
<journal>Information Retrieval,</journal>
<volume>16</volume>
<issue>3</issue>
<marker>Vuli´c, De Smet, Moens, 2013</marker>
<rawString>Ivan Vuli´c, Wim De Smet, and Marie-Francine Moens. 2013. Cross-language information retrieval models based on latent topic models trained with documentaligned comparable corpora. Information Retrieval, 16(3):331–368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianqiang Wang</author>
<author>Douglas W Oard</author>
</authors>
<title>Combining bidirectional translation and synonymy for cross-language information retrieval.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>202--209</pages>
<contexts>
<context position="1956" citStr="Wang and Oard, 2006" startWordPosition="282" endWordPosition="285">ich extent words (or more generally, text units) describe similar semantic concepts and convey similar meanings across languages. Models of cross-lingual similarity are typically used to automatically induce bilingual lexicons and have found numerous applications in information retrieval (IR), statistical machine translation (SMT) and other natural language processing (NLP) tasks. Within the IR framework, the output of the CLSS models is a key resource in the models of dictionary-based cross-lingual information retrieval (Ballesteros and Croft, 1997; Lavrenko et al., 2002; Levow et al., 2005; Wang and Oard, 2006) or may be utilized in query expansion in cross-lingual IR models (Adriani and van Rijsbergen, 1999; Vuli´c et al., 2013). These CLSS models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been prov</context>
</contexts>
<marker>Wang, Oard, 2006</marker>
<rawString>Jianqiang Wang and Douglas W. Oard. 2006. Combining bidirectional translation and synonymy for cross-language information retrieval. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 202–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
<author>Chengqing Zong</author>
</authors>
<title>Domain adaptation for statistical machine translation with domain dictionary and monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>993--1000</pages>
<contexts>
<context position="2206" citStr="Wu et al., 2008" startWordPosition="328" endWordPosition="331">lications in information retrieval (IR), statistical machine translation (SMT) and other natural language processing (NLP) tasks. Within the IR framework, the output of the CLSS models is a key resource in the models of dictionary-based cross-lingual information retrieval (Ballesteros and Croft, 1997; Lavrenko et al., 2002; Levow et al., 2005; Wang and Oard, 2006) or may be utilized in query expansion in cross-lingual IR models (Adriani and van Rijsbergen, 1999; Vuli´c et al., 2013). These CLSS models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr</context>
</contexts>
<marker>Wu, Wang, Zong, 2008</marker>
<rawString>Hua Wu, Haifeng Wang, and Chengqing Zong. 2008. Domain adaptation for statistical machine translation with domain dictionary and monolingual corpora. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 993–1000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>200--207</pages>
<contexts>
<context position="2774" citStr="Yarowsky and Ngai, 2001" startWordPosition="419" endWordPosition="422">dge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingual similarity from comparable corpora have gained much attention re</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 200–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duo Zhang</author>
<author>Qiaozhu Mei</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Cross-lingual latent topic extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1128--1137</pages>
<contexts>
<context position="8934" citStr="Zhang et al., 2010" startWordPosition="1353" endWordPosition="1356"> use cross-lingual Latent Semantic Indexing (Dumais et al., 1996), probabilistic Principal Component Analysis (Tipping and Bishop, 1999), or a probabilistic interpretation of non-negative matrix 350 factorization (Lee and Seung, 1999; Gaussier and Goutte, 2005; Ding et al., 2008) on concatenated documents in aligned document pairs. Other more recent models include matching canonical correlation analysis (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) and multilingual probabilistic topic models (Ni et al., 2009; De Smet and Moens, 2009; Mimno et al., 2009; Boyd-Graber and Blei, 2009; Zhang et al., 2010; Fukumasu et al., 2012). Due to its inherent language pair independent nature and state-of-the-art performance in the tasks such as bilingual lexicon extraction (Vuli´c et al., 2011) and cross-lingual information retrieval (Vuli´c et al., 2013), the description in this paper relies on the multilingual probabilistic topic modeling (MuPTM) framework. We draw a direct parallel between latent cross-lingual concepts and latent cross-lingual topics, and we present the framework from the MuPTM perspective, but the proposed framework is generic and allows the usage of all other models that are able t</context>
</contexts>
<marker>Zhang, Mei, Zhai, 2010</marker>
<rawString>Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai. 2010. Cross-lingual latent topic extraction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1128–1137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Yan Song</author>
<author>Chunyu Kit</author>
<author>Guodong Zhou</author>
</authors>
<title>Cross language dependency parsing using a bilingual lexicon.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>55--63</pages>
<contexts>
<context position="2686" citStr="Zhao et al., 2009" startWordPosition="405" endWordPosition="408">., 2013). These CLSS models may also be utilized as an additional source of knowledge in SMT systems (Och and Ney, 2003; Wu et al., 2008). Additionally, the models are a crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a; Ganchev and Das, 2013), verb classification (Merlo et al., 2002), inducing selectional preferences (Peirsman and Pad´o, 2010), named entity recognition (Kim et al., 2012), named entity segmentation (Ganchev and Das, 2013), etc. The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (Brown et al., 1993; Och and Ney, 2003), but due to a relative scarceness of parallel texts for many language pairs and domains, the </context>
</contexts>
<marker>Zhao, Song, Kit, Zhou, 2009</marker>
<rawString>Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou. 2009. Cross language dependency parsing using a bilingual lexicon. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL), pages 55–63.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>