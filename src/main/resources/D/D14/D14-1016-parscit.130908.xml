<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000275">
<title confidence="0.9991425">
Transformation from Discontinuous to Continuous Word Alignment
Improves Translation Quality
</title>
<author confidence="0.998843">
Zhongjun He&apos; Hua Wu&apos; Haifeng Wang&apos; Ting Liu&apos;
</author>
<affiliation confidence="0.889688">
&apos; Baidu Inc., No. 10, Shangdi 10th Street, Beijing, 100085, China
&apos; Harbin Institute of Technology, Harbin, China
</affiliation>
<email confidence="0.9873035">
{hezhongjun,wu hua,wanghaifeng}@baidu.com
tliu@ir.hit.edu.cn
</email>
<sectionHeader confidence="0.993768" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99981416">
We present a novel approach to im-
prove word alignment for statistical ma-
chine translation (SMT). Conventional
word alignment methods allow discontin-
uous alignment, meaning that a source
(or target) word links to several target (or
source) words whose positions are dis-
continuous. However, we cannot extrac-
t phrase pairs from this kind of align-
ments as they break the alignment con-
sistency constraint. In this paper, we use
a weighted vote method to transform dis-
continuous word alignment to continuous
alignment, which enables SMT system-
s extract more phrase pairs. We carry
out experiments on large scale Chinese-
to-English and German-to-English trans-
lation tasks. Experimental results show
statistically significant improvements of
BLEU score in both cases over the base-
line systems. Our method produces a gain
of +1.68 BLEU on NIST OpenMT04 for
the phrase-based system, and a gain of
+1.28 BLEU on NIST OpenMT06 for the
hierarchical phrase-based system.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999823510638298">
Word alignment, indicating the correspondence
between the source and target words in bilingual
sentences, plays an important role in statistical
machine translation (SMT). Almost all of the SMT
models, not only phrase-based (Koehn et al.,
2003), but also syntax-based (Chiang, 2005; Liu
et al., 2006; Huang et al., 2006), derive translation
knowledge from large amount bilingual text anno-
tated with word alignment. Therefore, the quality
of the word alignment has big impact on the qual-
ity of translation output.
Word alignments are usually automatically ob-
tained from a large amount of bilingual training
corpus. The most widely used toolkit for word
alignment in SMT community is GIZA++ (Och
and Ney, 2004), which implements the well known
IBM models (Brown et al., 1993) and the HM-
M model (Vogel and Ney, 1996). Koehn et al.
(2003) proposed some heuristic methods (e.g. the
“grow-diag-final” method) to refine word align-
ments trained by GIZA++. Another group of word
alignment methods (Liu et al., 2005; Moore et
al., 2006; Riesa and Marcu, 2010) define feature
functions to describe word alignment. They need
manually aligned bilingual texts to train the mod-
el. However, the manually annotated data is too
expensive to be available for all languages. Al-
though these models reported high accuracy, the
GIZA++ and “grow-diag-final&apos; method are domi-
nant in practice.
However, automatic word alignments are usu-
ally very noisy. The example in Figure 1 shows
a Chinese and English sentence pair, with word
alignment automatically trained by GIZA++ and
the “grow-diag-final&apos; method. We find many er-
rors (dashed links) are caused by discontinuous
alignment (formal definition is described in Sec-
tion 2), a source (or target) word linking to sev-
eral discontinuous target (or source) words. This
kind of errors will result in the loss of many use-
ful phrase pairs that are learned based on bilingual
word alignment. Actually, according to the defini-
tion of phrases in a standard phrase-based model,
we cannot extract phrases from the discontinuous
alignment. The reason is that this kind of align-
ment break the alignment consistency constrain-
t (Koehn et al., 2003). For example, the Chi-
</bodyText>
<page confidence="0.942863">
147
</page>
<note confidence="0.5093185">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 147–152,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<table confidence="0.9027366">
1 2 3 4 5 6 7 8 9 10 11
XIM A �C R-111- R � axt � n [M* ��
meiguo shi shaoshu jige tou xia fandui piao de guojia zhiyi
The United States was among the handful of nations that cast a nay note
1 2 3 4 5 6 7 8 9 10 11 12 13 14
</table>
<figureCaption confidence="0.9936655">
Figure 1: An example of word alignment between a Chinese and English sentence pair. The dashed links
are incorrect alignments.
</figureCaption>
<bodyText confidence="0.999952125">
nese word “shi2”1 is aligned to the English words
“was4” and “that10”. However, these two English
words are discontinuous, and we cannot extract the
phrase pair “(shi, was)”.
In this paper, we propose a simple weighed vote
method to deal with the discontinuous word align-
ment. Firstly, we split the discontinuous align-
ment into several continuous alignment group-
s, and consider each continuous alignment group
as a bucket. Secondly, we vote for each buck-
et with alignment score measured by word trans-
lation probabilities. Finally, we select the buck-
et with the highest score as the final alignment.
The strength of our method is that we refine word
alignment without using any external knowledge,
as the word translation probabilities can be esti-
mated from the bilingual corpus with the original
word alignment.
We notice that the discontinuous alignment is
helpful for hierarchical phrase-based model, as the
model allows discontinuous phrases. Thus, for
the hierarchical phrase-based model, our method
may lost some discontinuous phrases. To solve
the problem, we keep the original discontinuous
alignment in the training corpus.
We carry out experiment with the state-of-the-
art phrase-based and hierarchical phrase-based
(Chiang, 2005) SMT systems implemented in
Moses (Koehn et al., 2007). Experiments on large
scale Chinese-to-English and German-to-English
translation tasks demonstrate significant improve-
ments in both cases over the baseline systems.
</bodyText>
<sectionHeader confidence="0.930824" genericHeader="method">
2 The Weighted Vote Method
</sectionHeader>
<bodyText confidence="0.996611">
To refine the discontinuous alignment, we propose
a weighted vote method to transform discontinu-
ous alignment to continuous alignment by discard-
ing noisy links. We split discontinuous alignment
</bodyText>
<footnote confidence="0.89185">
1The subscript denotes the word position.
</footnote>
<bodyText confidence="0.998874903225807">
into several continuous groups, and select the best
group with the highest score computed by word
translation probabilities as the final alignment.
For further understanding, we first describe
some definitions. Given a word-aligned sentence
pair (F1I , EJ1, A), an alignment set Aset(i) is the
set of target word positions that aligned to the
source word Fii : Aset(i) = {j|(i, j) ∈ A} (1)
For example, in Figure 1, the alignment set
for the Chinese word “shaoshu3” is Aset(3) =
{5, 7, 8,10}. We define an alignments-
pan Aspan(i) as [min(Aset(i)), max(Aset(i))].
Thus, the alignment span for the Chinese word
“shaoshu3” is Aspan(3) = [5,10].
The alignment for Fii is discontinuous if there
exist some target words in Aspan(i) linking to an-
other source word, i.e. ∃(i&apos;, j&apos;) ∈ A, where i&apos; =6 i,
j&apos; ∈ Aspan(i). Otherwise, the alignment is contin-
uous. According to the definition, the alignment
for “shaoshu3” is discontinuous. Because the tar-
get words “the6” and “nationsg” in the alignmen-
t span link to another Chinese words “deg” and
“guojia10”, respectively. For a target word Ejj , the
definition is similar.
If the alignment for Fii is discontinuous, we
can split the alignment span Aspan(i) = [j1, j2]
into m continuous spans {[jkp , jkq ]}, where k =
1, 2, ..., m, and jkp ,jkq ∈ [j1, j2]. Our goal is to se-
lect the best continuous span for the word Fii . To
do this, we score each continuous span with word
translation probabilities:
</bodyText>
<equation confidence="0.947020333333333">
S([jkp,jkq ]) = � q (Pr(Ejkt |Fi) + Pr(Fi|Ejkt))
t=p
(2)
where,
count(f, e) (3 )
Pr(f  |e) = E f, count(f&apos;, e)
</equation>
<page confidence="0.990394">
148
</page>
<figure confidence="0.99371275">
Task Src. Words Tgt. Words
Chinese-to-English 75M 78M
German-to- English 107M 113M
少数 shaoshu
0.1
0.5
0.2
0.1
</figure>
<figureCaption confidence="0.992552">
Figure 2: An example of weighted voted method
</figureCaption>
<bodyText confidence="0.568319333333333">
for selecting the best continuous alignment from
the discontinuous alignment. The heavy shading
area is selected as the final alignment.
</bodyText>
<equation confidence="0.9955335">
count(e, f) (4 )
Pr(e|f) f) = Ee, count(f, e&apos;)
</equation>
<bodyText confidence="0.999612733333333">
The word translation probabilities can be comput-
ed from the bilingual corpus with the initial word
alignment. Finally, we select the span with the
highest score as the final alignment, and discard
all other alignments.
We illustrate our method in Figure 2, which
shows the source word “shaoshu” and its align-
ment in Figure 1. We split the alignments into
three continuous alignment spans and compute s-
core for each span. Finally, the span with highest
score (heavy shading area) is selected as the final
alignment.
We conduct the procedure for each source and
target word, the improved alignment (solid links)
is shown in Figure 1.
</bodyText>
<sectionHeader confidence="0.99937" genericHeader="method">
3 Experiment
</sectionHeader>
<bodyText confidence="0.999488071428572">
To demonstrate the effect of the proposed method,
we use the state-of-the-art phrase-based system
and hierarchical phrase-based system implement-
ed in Moses (Koehn et al., 2007). The phrase-
based system uses continuous phrase pair as the
main translation knowledge. While the hierarchi-
cal phrase-based system uses both continuous and
discontinuous phrase pairs, which has an ability to
capture long distance phrase reordering.
we carried out experiments on two translation
tasks: the Chinese-to-English task comes from the
NIST Open MT Evaluation, and the German-to-
English task comes from the Workshop on Ma-
chine Translation (WMT) shared task.
</bodyText>
<subsectionHeader confidence="0.993852">
3.1 Training
</subsectionHeader>
<bodyText confidence="0.9988295">
The training data we used are listed in Table 1. For
the Chinese-English task, the bilingual data are s-
elected from LDC. We used NIST MT03 as the
development set and tested our system on NIST
MT evaluation sets from 2004 to 2008. For the
German-English task, the bilingual data are from
</bodyText>
<tableCaption confidence="0.997769">
Table 1: Bilingual data for our experiments.
</tableCaption>
<table confidence="0.9999">
System N04 N05 N06 N08
Baseline 34.53 33.02 30.43 23.29
Refined 36.21 33.99 31.59 24.36
</table>
<tableCaption confidence="0.51117">
Table 2: Chinese-to-English translation quality of
the phrase-based system.
</tableCaption>
<table confidence="0.999905333333333">
System W10 W11 W12 W13
Baseline 20.71 20.26 20.52 23.26
Refined 21.46 20.95 21.11 23.77
</table>
<tableCaption confidence="0.849812">
Table 3: German-to-English translation quality of
the phrase-based system.
</tableCaption>
<bodyText confidence="0.999481823529412">
the shared translation task 2013. We used WMT08
as the development set and tested our system on
WMT test sets from 2010 to 2013.
The baseline systems are trained on the training
corpus with initial word alignment, which was ob-
tained via GIZA++ and “grow-diag-final” method.
Based on the initial word alignment, we comput-
ed word translation probabilities and used the pro-
posed method to obtain a refined word alignment.
Then we used the refined word alignment to train
our SMT systems.
The translation results are evaluated by case-
insensitive BLEU-4 (Papineni et al., 2002).
The feature weights of the translation system
are tuned with the standard minimum-error-rate-
training (Och, 2003) to maximize the systems
BLEU score on the development set.
</bodyText>
<subsectionHeader confidence="0.6699085">
3.2 Results
3.2.1 Phrase-based System
</subsectionHeader>
<bodyText confidence="0.999680454545454">
Table 2 shows Chinese-to-English translation
quality of the phrase-based system. We ob-
served that our refined method significantly out-
performed the baseline word alignment on all test
sets. The improvements are ranged from 0.97 to
1.68 BLEU%.
Table 3 shows German-to-English translation
quality of the phrase-based system. The improve-
ments are ranged from 0.51 to 0.75 BLEU%.
These results demonstrate that the proposed
method improves the translation quality for
</bodyText>
<page confidence="0.998229">
149
</page>
<table confidence="0.967981857142857">
System N04 N05 N06 N08
Baseline 37.33 34.81 32.20 25.33
Refined 37.91 35.36 32.75 25.40
Combined 38.13 35.63 33.48 25.66
n LW At- RIt
dang shigu fasheng shi
when the accident happend
</table>
<tableCaption confidence="0.7560755">
Table 4: Chinese-to-English translation quality of
the hierarchical phrase-based system.
</tableCaption>
<table confidence="0.99983425">
System W10 W11 W12 W13
Baseline 21.22 19.77 20.53 23.51
Refined 21.34 20.64 20.88 23.82
Combined 21.65 20.87 21.16 24.04
</table>
<tableCaption confidence="0.9489155">
Table 5: German-to-English translation quality of
the hierarchical phrase-based system.
</tableCaption>
<bodyText confidence="0.998198">
phrase-based system. The reason is that by dis-
carding noisy word alignments from the discon-
tinuous alignments, the phrase pairs constrained
by the noisy alignments can be extracted. Thus the
system utilized more phrase pairs than the baseline
did.
</bodyText>
<subsectionHeader confidence="0.986027">
3.2.2 Hierarchical Phrase-based System
</subsectionHeader>
<bodyText confidence="0.982696074074074">
The hierarchical phrase-based system utilizes dis-
continuous phrase pairs for long distance phrase
reordering. Some of the discontinuous phrase
pairs are extracted from the discontinuous align-
ments. By transforming the discontinuous align-
ments to continuous alignments, on the one hand,
we may lost some discontinuous phrase pairs. On
the other hand, we may extract additional contin-
uous and discontinuous phrase pairs as the align-
ment restriction is loose.
See Figure 3 for illustration. From the initial
alignment, we can extract a hierarchical phrase
pair “(dang X1 shi, when X1)” from the discon-
tinuous alignment of the English word “when”.
However, the hierarchical phrase pair cannot be
extracted from our refined alignment, because our
method discards the link between the Chinese
word “dang” and the English word “when”. In-
stead, we can extract another hierarchical phrase
pair “(X1 shi, when X1)”.
Does our method still obtain improvements on
the hierarchical phrase-based system? Table 4 and
Table 5 shows Chinese-to-English and German-
to-English translation quality of the hierarchical
phrase-based system, respectively. For Chinese-
to-English translation, the refined alignment ob-
tained improvements ranged from 0.07 to 0.58
</bodyText>
<figureCaption confidence="0.615833666666667">
Figure 3: Example of word alignment between a
Chinese and English sentence pair. The dashed
initial link is discarded by our method.
</figureCaption>
<bodyText confidence="0.999919">
BLEU% on the test set ( the row “Refined”).
While for German-to-English translation, the im-
provements ranged from 0.12 to 0.59 BLEU% on
the test set (the row “Refined”).
We find that the improvements are less than
that of the phrase-based system. As discussed
above, our method may lost some hierarchical
phrase pairs that extracted from the discontinuous
alignments. To solve the problem, we combine 2
the initial alignments and the refined alignments
to train the SMT system. The results are shown
in the row “Combined” in Table 4 and Table 5.
For Chinese-to-English translation, we obtained
an improvements of 1.28 BLEU% on NIST06 over
the baseline. While for German-to-English trans-
lation, the greatest improvements is 1.10 BLEU%
on WMT11.
</bodyText>
<sectionHeader confidence="0.998803" genericHeader="method">
4 Analyses
</sectionHeader>
<bodyText confidence="0.999763857142857">
In order to further study the performance of the
proposed method, we analyze the word alignment
and the phrase table for Chinese-to-English trans-
lation. We find that our method improves the qual-
ity of word alignment. And as a result, more useful
phrase pairs are extracted from the refined word
alignment.
</bodyText>
<subsectionHeader confidence="0.99903">
4.1 Word Alignment
</subsectionHeader>
<bodyText confidence="0.9998742">
The Chinese-to-English training corpus contains
4.5M sentence pairs. By applying GIZA++ and
the “grow-diag-final” method, we obtained initial
alignments. We find that 4.0M (accounting for
89%) sentence pairs contain discontinuous align-
ments. We then used the proposed method to dis-
card noisy links. By doing this, the total links
between words in the training corpus are reduced
from 99.6M to 78.9M, indicating that 21% links
are discarded.
</bodyText>
<footnote confidence="0.953399">
2We do not perform combination for phrase-based sys-
tem, because the phrase table extracted from the initial align-
ment is a subset of that extracted from the refined alignment.
</footnote>
<page confidence="0.990734">
150
</page>
<table confidence="0.994418">
Alignment Precision Recall AER
Initial 62.94 89.55 26.07
Refined 73.43 87.82 20.01
</table>
<tableCaption confidence="0.9252985">
Table 6: Precision, Recall and AER on Chinese-
to-English alignment.
</tableCaption>
<table confidence="0.999233666666667">
Alignment StandPhr HierPhr
Initial 29M 86M
Refined 104M 436M
</table>
<tableCaption confidence="0.9965778">
Table 7: The phrase number extracted from the
initial and refined alignment for the hierarchical
phrase-based system on Chinese-to-English trans-
lation. StandPhr is standard phrase, HierPhr is hi-
erarchical phrase.
</tableCaption>
<table confidence="0.8164005">
Chinese English
meiguo The United States
guojia nations
piao note
</table>
<tableCaption confidence="0.972377">
Table 8: Phrase pairs extracted from the initial
alignment of Figure 1.
</tableCaption>
<subsectionHeader confidence="0.816714">
Chinese English
</subsectionHeader>
<bodyText confidence="0.978670666666667">
shi was
fandui piao a nay note
shaoshu jige the handful of
</bodyText>
<tableCaption confidence="0.9530925">
Table 9: Selected phrase pairs extracted from the
refined alignment of Figure 1.
</tableCaption>
<subsectionHeader confidence="0.715584">
Chinese English
</subsectionHeader>
<bodyText confidence="0.999947333333333">
We evaluated the alignment quality on 200 sen-
tence pairs. Results are shown in Table 6. It is
observed that our method improves the precision
and decreases the AER, while keeping a high re-
call. This means that our method effectively dis-
cards noisy links in the initial word alignments.
</bodyText>
<subsectionHeader confidence="0.99873">
4.2 Phrase Table
</subsectionHeader>
<bodyText confidence="0.936844966666667">
According to the standard definition of phrase in
SMT, phrase pairs cannot be extracted from the
discontinuous alignments. By transforming dis-
continuous alignments into continuous alignmen-
t, we can extract more phrase pairs. Table 7
shows the number of standard phrases and hier-
archical phrases extracted from the initial and re-
fined word alignments. We find that the number of
both phrases and hierarchical phrases grows heav-
ily. This is because that the word alignment con-
straint for phrase extraction is loosed by removing
noisy links. Although the phrase table becomes
larger, fortunately, there are some methods (John-
son et al., 2007; He et al., 2009) to prune phrase
table without hurting translation quality.
For further illustration, we compare the phrase
pairs extracted from the initial alignment and re-
fined alignment in Figure 1. From the initial align-
ments, we extracted only 3 standard phrase pairs
and no hierarchical phrase pairs (Table 8). After
discarding noisy alignments (dashed links) by us-
ing the proposed method, we extracted 21 standard
phrase pairs and 36 hierarchical phrases. Table 9
and Table 10 show selected phrase pairs and hier-
archical phrase pairs, respectively.
X1 zhiyi among X1
X1 de guojia nations that X1
X1 fandui piao X2 X2 X1 a nay note
Table 10: Selected hierarchical phrase pairs ex-
tracted from the refined alignment of Figure 1.
</bodyText>
<sectionHeader confidence="0.988691" genericHeader="evaluation">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999960555555556">
In this paper, we proposed a novel method to im-
prove word alignment for SMT. The method re-
fines initial word alignments by transforming dis-
continuous alignment to continuous alignment. As
a result, more useful phrase pairs are extracted
from the refined word alignment. Our method is
simple and efficient, since it uses only the word
translation probabilities obtained from the initial
alignments to discard noisy links. Our method
is independent of languages and can be applied
to most SMT models. Experimental results show
significantly improvements for the state-of-the-art
phrase-based and hierarchical phrase-based sys-
tems on all Chinese-to-English and German-to-
English translation tasks.
In the future, we will refine the method by con-
sidering neighbor words and alignments when dis-
carding noisy links.
</bodyText>
<sectionHeader confidence="0.945745" genericHeader="conclusions">
Acknowlegement
</sectionHeader>
<bodyText confidence="0.979513">
This paper is supported by the 973 program No.
2014CB340505. We would like to thank Xuan Liu
and the anonymous reviewers for their insightful
comments.
</bodyText>
<page confidence="0.997748">
151
</page>
<sectionHeader confidence="0.972619" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998030352112676">
Peter F. Brown, Stephen A. Della Pietra, Vincen-
t J. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics,
19(2):263–311.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 263–270.
Zhongjun He, Yao Meng, and Hao Yu. 2009. Dis-
carding monotone composed rule for hierarchical
phrase-based statistical machine translation. In Pro-
ceedings of the 3rd International Universal Commu-
nication Symposium, pages 25–29.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of the 7th Bienni-
al Conference of the Association for Machine Trans-
lation in the Americas.
Howard Johnson, Joel Martin, George Foster, and
Roland Kuhn. 2007. Improving translation quali-
ty by discarding most of the phrasetable. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 967–975, Prague, Czech Republic,
June.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of HLT-NAACL 2003, pages 127–133.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertol-
di, Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
ACL 2007 demonstration session.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Loglin-
ear models for word alignment. In Proceedings of
of ACL 2005, pages 459–466, Ann Arbor,Michigan,
June.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of the 44th Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 609–616.
Robert C. Moore, Wen tau Yih, and Andreas Bode.
2006. Improved discriminative bilingual word
alignment. In In Proceedings of COLING/ACL
2006, pages 513–520, Sydney, Australia, July.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. 30:417–449.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 311–318.
Jason Riesa and Daniel Marcu. 2010. Hierarchical
search forword alignment. In In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 157–166, Uppsala, Swe-
den, July.
Stephan Vogel and Hermann Ney. 1996. Hmm-based
word alignment in statistical translation. In Pro-
ceedings of COLING 1996, pages 836–841, Copen-
hagen, Danmark, August.
</reference>
<page confidence="0.998133">
152
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.551099">
<title confidence="0.905823">Transformation from Discontinuous to Continuous Word Improves Translation Quality</title>
<address confidence="0.724697">Inc., No. 10, Shangdi 10th Street, Beijing, 100085,</address>
<affiliation confidence="0.972285">Institute of Technology, Harbin,</affiliation>
<email confidence="0.986552">tliu@ir.hit.edu.cn</email>
<abstract confidence="0.999450230769231">We present a novel approach to improve word alignment for statistical machine translation (SMT). Conventional word alignment methods allow discontinuous alignment, meaning that a source (or target) word links to several target (or source) words whose positions are discontinuous. However, we cannot extract phrase pairs from this kind of alignments as they break the alignment consistency constraint. In this paper, we use a weighted vote method to transform discontinuous word alignment to continuous alignment, which enables SMT systems extract more phrase pairs. We carry out experiments on large scale Chineseto-English and German-to-English translation tasks. Experimental results show statistically significant improvements of BLEU score in both cases over the baseline systems. Our method produces a gain of +1.68 BLEU on NIST OpenMT04 for the phrase-based system, and a gain of +1.28 BLEU on NIST OpenMT06 for the hierarchical phrase-based system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="2065" citStr="Brown et al., 1993" startWordPosition="311" endWordPosition="314">ranslation (SMT). Almost all of the SMT models, not only phrase-based (Koehn et al., 2003), but also syntax-based (Chiang, 2005; Liu et al., 2006; Huang et al., 2006), derive translation knowledge from large amount bilingual text annotated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” method) to refine word alignments trained by GIZA++. Another group of word alignment methods (Liu et al., 2005; Moore et al., 2006; Riesa and Marcu, 2010) define feature functions to describe word alignment. They need manually aligned bilingual texts to train the model. However, the manually annotated data is too expensive to be available for all languages. Although these models reported high accuracy, the GIZA++ and “grow-diag-final&apos; method are dominant in practice. Howeve</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="1573" citStr="Chiang, 2005" startWordPosition="232" endWordPosition="233">glish translation tasks. Experimental results show statistically significant improvements of BLEU score in both cases over the baseline systems. Our method produces a gain of +1.68 BLEU on NIST OpenMT04 for the phrase-based system, and a gain of +1.28 BLEU on NIST OpenMT06 for the hierarchical phrase-based system. 1 Introduction Word alignment, indicating the correspondence between the source and target words in bilingual sentences, plays an important role in statistical machine translation (SMT). Almost all of the SMT models, not only phrase-based (Koehn et al., 2003), but also syntax-based (Chiang, 2005; Liu et al., 2006; Huang et al., 2006), derive translation knowledge from large amount bilingual text annotated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “gro</context>
<context position="5257" citStr="Chiang, 2005" startWordPosition="840" endWordPosition="841"> is that we refine word alignment without using any external knowledge, as the word translation probabilities can be estimated from the bilingual corpus with the original word alignment. We notice that the discontinuous alignment is helpful for hierarchical phrase-based model, as the model allows discontinuous phrases. Thus, for the hierarchical phrase-based model, our method may lost some discontinuous phrases. To solve the problem, we keep the original discontinuous alignment in the training corpus. We carry out experiment with the state-of-theart phrase-based and hierarchical phrase-based (Chiang, 2005) SMT systems implemented in Moses (Koehn et al., 2007). Experiments on large scale Chinese-to-English and German-to-English translation tasks demonstrate significant improvements in both cases over the baseline systems. 2 The Weighted Vote Method To refine the discontinuous alignment, we propose a weighted vote method to transform discontinuous alignment to continuous alignment by discarding noisy links. We split discontinuous alignment 1The subscript denotes the word position. into several continuous groups, and select the best group with the highest score computed by word translation probabi</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongjun He</author>
<author>Yao Meng</author>
<author>Hao Yu</author>
</authors>
<title>Discarding monotone composed rule for hierarchical phrase-based statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 3rd International Universal Communication Symposium,</booktitle>
<pages>25--29</pages>
<contexts>
<context position="16372" citStr="He et al., 2009" startWordPosition="2611" endWordPosition="2614">phrase in SMT, phrase pairs cannot be extracted from the discontinuous alignments. By transforming discontinuous alignments into continuous alignment, we can extract more phrase pairs. Table 7 shows the number of standard phrases and hierarchical phrases extracted from the initial and refined word alignments. We find that the number of both phrases and hierarchical phrases grows heavily. This is because that the word alignment constraint for phrase extraction is loosed by removing noisy links. Although the phrase table becomes larger, fortunately, there are some methods (Johnson et al., 2007; He et al., 2009) to prune phrase table without hurting translation quality. For further illustration, we compare the phrase pairs extracted from the initial alignment and refined alignment in Figure 1. From the initial alignments, we extracted only 3 standard phrase pairs and no hierarchical phrase pairs (Table 8). After discarding noisy alignments (dashed links) by using the proposed method, we extracted 21 standard phrase pairs and 36 hierarchical phrases. Table 9 and Table 10 show selected phrase pairs and hierarchical phrase pairs, respectively. X1 zhiyi among X1 X1 de guojia nations that X1 X1 fandui pia</context>
</contexts>
<marker>He, Meng, Yu, 2009</marker>
<rawString>Zhongjun He, Yao Meng, and Hao Yu. 2009. Discarding monotone composed rule for hierarchical phrase-based statistical machine translation. In Proceedings of the 3rd International Universal Communication Symposium, pages 25–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>Statistical syntax-directed translation with extended domain of locality.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Biennial Conference of the Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="1612" citStr="Huang et al., 2006" startWordPosition="238" endWordPosition="241">ental results show statistically significant improvements of BLEU score in both cases over the baseline systems. Our method produces a gain of +1.68 BLEU on NIST OpenMT04 for the phrase-based system, and a gain of +1.28 BLEU on NIST OpenMT06 for the hierarchical phrase-based system. 1 Introduction Word alignment, indicating the correspondence between the source and target words in bilingual sentences, plays an important role in statistical machine translation (SMT). Almost all of the SMT models, not only phrase-based (Koehn et al., 2003), but also syntax-based (Chiang, 2005; Liu et al., 2006; Huang et al., 2006), derive translation knowledge from large amount bilingual text annotated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” method) to refine word al</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proceedings of the 7th Biennial Conference of the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Johnson</author>
<author>Joel Martin</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Improving translation quality by discarding most of the phrasetable.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>967--975</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="16354" citStr="Johnson et al., 2007" startWordPosition="2606" endWordPosition="2610">tandard definition of phrase in SMT, phrase pairs cannot be extracted from the discontinuous alignments. By transforming discontinuous alignments into continuous alignment, we can extract more phrase pairs. Table 7 shows the number of standard phrases and hierarchical phrases extracted from the initial and refined word alignments. We find that the number of both phrases and hierarchical phrases grows heavily. This is because that the word alignment constraint for phrase extraction is loosed by removing noisy links. Although the phrase table becomes larger, fortunately, there are some methods (Johnson et al., 2007; He et al., 2009) to prune phrase table without hurting translation quality. For further illustration, we compare the phrase pairs extracted from the initial alignment and refined alignment in Figure 1. From the initial alignments, we extracted only 3 standard phrase pairs and no hierarchical phrase pairs (Table 8). After discarding noisy alignments (dashed links) by using the proposed method, we extracted 21 standard phrase pairs and 36 hierarchical phrases. Table 9 and Table 10 show selected phrase pairs and hierarchical phrase pairs, respectively. X1 zhiyi among X1 X1 de guojia nations tha</context>
</contexts>
<marker>Johnson, Martin, Foster, Kuhn, 2007</marker>
<rawString>Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 967–975, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<pages>127--133</pages>
<contexts>
<context position="1536" citStr="Koehn et al., 2003" startWordPosition="225" endWordPosition="228">rge scale Chineseto-English and German-to-English translation tasks. Experimental results show statistically significant improvements of BLEU score in both cases over the baseline systems. Our method produces a gain of +1.68 BLEU on NIST OpenMT04 for the phrase-based system, and a gain of +1.28 BLEU on NIST OpenMT06 for the hierarchical phrase-based system. 1 Introduction Word alignment, indicating the correspondence between the source and target words in bilingual sentences, plays an important role in statistical machine translation (SMT). Almost all of the SMT models, not only phrase-based (Koehn et al., 2003), but also syntax-based (Chiang, 2005; Liu et al., 2006; Huang et al., 2006), derive translation knowledge from large amount bilingual text annotated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed </context>
<context position="3448" citStr="Koehn et al., 2003" startWordPosition="536" endWordPosition="539"> GIZA++ and the “grow-diag-final&apos; method. We find many errors (dashed links) are caused by discontinuous alignment (formal definition is described in Section 2), a source (or target) word linking to several discontinuous target (or source) words. This kind of errors will result in the loss of many useful phrase pairs that are learned based on bilingual word alignment. Actually, according to the definition of phrases in a standard phrase-based model, we cannot extract phrases from the discontinuous alignment. The reason is that this kind of alignment break the alignment consistency constraint (Koehn et al., 2003). For example, the Chi147 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 147–152, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics 1 2 3 4 5 6 7 8 9 10 11 XIM A �C R-111- R � axt � n [M* �� meiguo shi shaoshu jige tou xia fandui piao de guojia zhiyi The United States was among the handful of nations that cast a nay note 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Figure 1: An example of word alignment between a Chinese and English sentence pair. The dashed links are incorrect alignments. nese word “shi2”1 is aligned </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL 2003, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="5311" citStr="Koehn et al., 2007" startWordPosition="847" endWordPosition="850">any external knowledge, as the word translation probabilities can be estimated from the bilingual corpus with the original word alignment. We notice that the discontinuous alignment is helpful for hierarchical phrase-based model, as the model allows discontinuous phrases. Thus, for the hierarchical phrase-based model, our method may lost some discontinuous phrases. To solve the problem, we keep the original discontinuous alignment in the training corpus. We carry out experiment with the state-of-theart phrase-based and hierarchical phrase-based (Chiang, 2005) SMT systems implemented in Moses (Koehn et al., 2007). Experiments on large scale Chinese-to-English and German-to-English translation tasks demonstrate significant improvements in both cases over the baseline systems. 2 The Weighted Vote Method To refine the discontinuous alignment, we propose a weighted vote method to transform discontinuous alignment to continuous alignment by discarding noisy links. We split discontinuous alignment 1The subscript denotes the word position. into several continuous groups, and select the best group with the highest score computed by word translation probabilities as the final alignment. For further understandi</context>
<context position="8453" citStr="Koehn et al., 2007" startWordPosition="1371" endWordPosition="1374">ther alignments. We illustrate our method in Figure 2, which shows the source word “shaoshu” and its alignment in Figure 1. We split the alignments into three continuous alignment spans and compute score for each span. Finally, the span with highest score (heavy shading area) is selected as the final alignment. We conduct the procedure for each source and target word, the improved alignment (solid links) is shown in Figure 1. 3 Experiment To demonstrate the effect of the proposed method, we use the state-of-the-art phrase-based system and hierarchical phrase-based system implemented in Moses (Koehn et al., 2007). The phrasebased system uses continuous phrase pair as the main translation knowledge. While the hierarchical phrase-based system uses both continuous and discontinuous phrase pairs, which has an ability to capture long distance phrase reordering. we carried out experiments on two translation tasks: the Chinese-to-English task comes from the NIST Open MT Evaluation, and the German-toEnglish task comes from the Workshop on Machine Translation (WMT) shared task. 3.1 Training The training data we used are listed in Table 1. For the Chinese-English task, the bilingual data are selected from LDC. </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL 2007 demonstration session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Loglinear models for word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of of ACL</booktitle>
<pages>459--466</pages>
<location>Ann Arbor,Michigan,</location>
<contexts>
<context position="2297" citStr="Liu et al., 2005" startWordPosition="350" endWordPosition="353">ated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” method) to refine word alignments trained by GIZA++. Another group of word alignment methods (Liu et al., 2005; Moore et al., 2006; Riesa and Marcu, 2010) define feature functions to describe word alignment. They need manually aligned bilingual texts to train the model. However, the manually annotated data is too expensive to be available for all languages. Although these models reported high accuracy, the GIZA++ and “grow-diag-final&apos; method are dominant in practice. However, automatic word alignments are usually very noisy. The example in Figure 1 shows a Chinese and English sentence pair, with word alignment automatically trained by GIZA++ and the “grow-diag-final&apos; method. We find many errors (dashe</context>
</contexts>
<marker>Liu, Liu, Lin, 2005</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2005. Loglinear models for word alignment. In Proceedings of of ACL 2005, pages 459–466, Ann Arbor,Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Treeto-string alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>609--616</pages>
<contexts>
<context position="1591" citStr="Liu et al., 2006" startWordPosition="234" endWordPosition="237">ion tasks. Experimental results show statistically significant improvements of BLEU score in both cases over the baseline systems. Our method produces a gain of +1.68 BLEU on NIST OpenMT04 for the phrase-based system, and a gain of +1.28 BLEU on NIST OpenMT06 for the hierarchical phrase-based system. 1 Introduction Word alignment, indicating the correspondence between the source and target words in bilingual sentences, plays an important role in statistical machine translation (SMT). Almost all of the SMT models, not only phrase-based (Koehn et al., 2003), but also syntax-based (Chiang, 2005; Liu et al., 2006; Huang et al., 2006), derive translation knowledge from large amount bilingual text annotated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” meth</context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2006. Treeto-string alignment template for statistical machine translation. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics, pages 609–616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
<author>Wen tau Yih</author>
<author>Andreas Bode</author>
</authors>
<title>Improved discriminative bilingual word alignment. In</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL 2006,</booktitle>
<pages>513--520</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="2317" citStr="Moore et al., 2006" startWordPosition="354" endWordPosition="357">gnment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” method) to refine word alignments trained by GIZA++. Another group of word alignment methods (Liu et al., 2005; Moore et al., 2006; Riesa and Marcu, 2010) define feature functions to describe word alignment. They need manually aligned bilingual texts to train the model. However, the manually annotated data is too expensive to be available for all languages. Although these models reported high accuracy, the GIZA++ and “grow-diag-final&apos; method are dominant in practice. However, automatic word alignments are usually very noisy. The example in Figure 1 shows a Chinese and English sentence pair, with word alignment automatically trained by GIZA++ and the “grow-diag-final&apos; method. We find many errors (dashed links) are caused </context>
</contexts>
<marker>Moore, Yih, Bode, 2006</marker>
<rawString>Robert C. Moore, Wen tau Yih, and Andreas Bode. 2006. Improved discriminative bilingual word alignment. In In Proceedings of COLING/ACL 2006, pages 513–520, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<pages>30--417</pages>
<contexts>
<context position="2000" citStr="Och and Ney, 2004" startWordPosition="300" endWordPosition="303">gual sentences, plays an important role in statistical machine translation (SMT). Almost all of the SMT models, not only phrase-based (Koehn et al., 2003), but also syntax-based (Chiang, 2005; Liu et al., 2006; Huang et al., 2006), derive translation knowledge from large amount bilingual text annotated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” method) to refine word alignments trained by GIZA++. Another group of word alignment methods (Liu et al., 2005; Moore et al., 2006; Riesa and Marcu, 2010) define feature functions to describe word alignment. They need manually aligned bilingual texts to train the model. However, the manually annotated data is too expensive to be available for all languages. Although these models reported high accuracy, the GIZ</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. 30:417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="10277" citStr="Och, 2003" startWordPosition="1663" endWordPosition="1664">ested our system on WMT test sets from 2010 to 2013. The baseline systems are trained on the training corpus with initial word alignment, which was obtained via GIZA++ and “grow-diag-final” method. Based on the initial word alignment, we computed word translation probabilities and used the proposed method to obtain a refined word alignment. Then we used the refined word alignment to train our SMT systems. The translation results are evaluated by caseinsensitive BLEU-4 (Papineni et al., 2002). The feature weights of the translation system are tuned with the standard minimum-error-ratetraining (Och, 2003) to maximize the systems BLEU score on the development set. 3.2 Results 3.2.1 Phrase-based System Table 2 shows Chinese-to-English translation quality of the phrase-based system. We observed that our refined method significantly outperformed the baseline word alignment on all test sets. The improvements are ranged from 0.97 to 1.68 BLEU%. Table 3 shows German-to-English translation quality of the phrase-based system. The improvements are ranged from 0.51 to 0.75 BLEU%. These results demonstrate that the proposed method improves the translation quality for 149 System N04 N05 N06 N08 Baseline 37</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="10163" citStr="Papineni et al., 2002" startWordPosition="1645" endWordPosition="1648">h translation quality of the phrase-based system. the shared translation task 2013. We used WMT08 as the development set and tested our system on WMT test sets from 2010 to 2013. The baseline systems are trained on the training corpus with initial word alignment, which was obtained via GIZA++ and “grow-diag-final” method. Based on the initial word alignment, we computed word translation probabilities and used the proposed method to obtain a refined word alignment. Then we used the refined word alignment to train our SMT systems. The translation results are evaluated by caseinsensitive BLEU-4 (Papineni et al., 2002). The feature weights of the translation system are tuned with the standard minimum-error-ratetraining (Och, 2003) to maximize the systems BLEU score on the development set. 3.2 Results 3.2.1 Phrase-based System Table 2 shows Chinese-to-English translation quality of the phrase-based system. We observed that our refined method significantly outperformed the baseline word alignment on all test sets. The improvements are ranged from 0.97 to 1.68 BLEU%. Table 3 shows German-to-English translation quality of the phrase-based system. The improvements are ranged from 0.51 to 0.75 BLEU%. These result</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Riesa</author>
<author>Daniel Marcu</author>
</authors>
<title>Hierarchical search forword alignment. In</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>157--166</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="2341" citStr="Riesa and Marcu, 2010" startWordPosition="358" endWordPosition="361">he quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” method) to refine word alignments trained by GIZA++. Another group of word alignment methods (Liu et al., 2005; Moore et al., 2006; Riesa and Marcu, 2010) define feature functions to describe word alignment. They need manually aligned bilingual texts to train the model. However, the manually annotated data is too expensive to be available for all languages. Although these models reported high accuracy, the GIZA++ and “grow-diag-final&apos; method are dominant in practice. However, automatic word alignments are usually very noisy. The example in Figure 1 shows a Chinese and English sentence pair, with word alignment automatically trained by GIZA++ and the “grow-diag-final&apos; method. We find many errors (dashed links) are caused by discontinuous alignme</context>
</contexts>
<marker>Riesa, Marcu, 2010</marker>
<rawString>Jason Riesa and Daniel Marcu. 2010. Hierarchical search forword alignment. In In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 157–166, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
</authors>
<title>Hmm-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>836--841</pages>
<location>Copenhagen, Danmark,</location>
<contexts>
<context position="2105" citStr="Vogel and Ney, 1996" startWordPosition="320" endWordPosition="323"> models, not only phrase-based (Koehn et al., 2003), but also syntax-based (Chiang, 2005; Liu et al., 2006; Huang et al., 2006), derive translation knowledge from large amount bilingual text annotated with word alignment. Therefore, the quality of the word alignment has big impact on the quality of translation output. Word alignments are usually automatically obtained from a large amount of bilingual training corpus. The most widely used toolkit for word alignment in SMT community is GIZA++ (Och and Ney, 2004), which implements the well known IBM models (Brown et al., 1993) and the HMM model (Vogel and Ney, 1996). Koehn et al. (2003) proposed some heuristic methods (e.g. the “grow-diag-final” method) to refine word alignments trained by GIZA++. Another group of word alignment methods (Liu et al., 2005; Moore et al., 2006; Riesa and Marcu, 2010) define feature functions to describe word alignment. They need manually aligned bilingual texts to train the model. However, the manually annotated data is too expensive to be available for all languages. Although these models reported high accuracy, the GIZA++ and “grow-diag-final&apos; method are dominant in practice. However, automatic word alignments are usually</context>
</contexts>
<marker>Vogel, Ney, 1996</marker>
<rawString>Stephan Vogel and Hermann Ney. 1996. Hmm-based word alignment in statistical translation. In Proceedings of COLING 1996, pages 836–841, Copenhagen, Danmark, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>