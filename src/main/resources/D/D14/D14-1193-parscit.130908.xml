<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005790">
<title confidence="0.983848">
Muli-label Text Categorization with Hidden Components
</title>
<author confidence="0.945201">
Li Li Longkai Zhang Houfeng Wang
</author>
<affiliation confidence="0.831484">
Key Laboratory of Computational Linguistics (Peking University) Ministry of Education, China
</affiliation>
<email confidence="0.987554">
li.l@pku.edu.cn, zhlongk@qq.com, wanghf@pku.edu.cn
</email>
<sectionHeader confidence="0.993758" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998714375">
Multi-label text categorization (MTC) is
supervised learning, where a documen-
t may be assigned with multiple categories
(labels) simultaneously. The labels in the
MTC are correlated and the correlation re-
sults in some hidden components, which
represent the ”share” variance of correlat-
ed labels. In this paper, we propose a
method with hidden components for MTC.
The proposed method employs PCA to
capture the hidden components, and incor-
porates them into a joint learning frame-
work to improve the performance. Experi-
ments with real-world data sets and evalu-
ation metrics validate the effectiveness of
the proposed method.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985046380952381">
Many real-world text categorization applications
are multi-label text categorization (Srivastava and
Zane-Ulman, 2005; Katakis et al., 2008; Rubin
et al., 2012; Nam et al., 2013), where a docu-
ments is usually assigned with multiple labels si-
multaneously. For example, as figure 1 shows,
a newspaper article concerning global warming
can be classified into two categories, Environmen-
t, and Science simultaneously. Let X = Rd
be the documents corpus, and Y = {0,1}m be
the label space with m labels. We denote by
{(x1,y1), (x2,y2), ..., (xn,yn)} the training set of
n documents. Each document is denoted by a vec-
tor xi = [xi,1, xi,2, ..., xi,d] of d dimensions. The
labeling of the i-th document is denoted by vector
yi = [yi,1, yi,2, ...,yi,m], where yil is 1 when the
i-th document has the l-th label and 0 otherwise.
The goal is to learn a function f : X → Y. Gener-
ally, we can assume f consists of m functions, one
for a label.
f = [f1, f2, ..., fm]
</bodyText>
<figureCaption confidence="0.978783333333333">
Figure 1: A newspaper article concerning global
warming can be classified into two categories, En-
vironment, and Science.
</figureCaption>
<bodyText confidence="0.99739452631579">
The labels in the MLC are correlated. For ex-
ample, a ”politics” document is likely to be an ”e-
conomic” document simultaneously, but likely not
to be a ”literature” document. According to the
latent variable model (Tabachnick et al., 2001),
the labels with correlation result in some hidden
components, which represent the ”share” variance
of correlated labels. Intuitively, if we can capture
and utilize these hidden components in MTC, the
performance will be improved. To implement this
idea, we propose a multi- label text categorization
method with hidden components, which employ
PCA to capture the hidden components, and then
incorporates these hidden components into a joint
learning framework. Experiments with various da-
ta sets and evaluation metrics validate the values
of our method. The research close to our work is
ML-LOC (Multi-Label learning using LOcal Cor-
relation) in (Huang and Zhou, 2012). The differ-
</bodyText>
<page confidence="0.885169">
1816
</page>
<bodyText confidence="0.925193714285714">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1816–1821,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
ences between ours and ML-LOC is that ML-LOC
employs the cluster method to gain the local cor-
relation, but we employ the PCA to obtain the hid-
den code. Meanwhile, ML-LOC uses the linear
programming in learning the local code, but we
employ the gradient descent method since we add
non-linear function to the hidden code.
The rest of this paper is organized as follows.
Section 2 presents the proposed method. We con-
duct experiments to demonstrate the effectiveness
of the proposed method in section 3. Section 4
concludes this paper.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="introduction">
2 Methodology
</sectionHeader>
<subsectionHeader confidence="0.9992025">
2.1 Capturing Hidden Component via
Principle Component Analysis
</subsectionHeader>
<bodyText confidence="0.999983133333334">
The first step of the proposed method is to capture
hidden components of training instances. Here we
employ Principal component analysis (PCA). This
is because PCA is a well-known statistical tool that
converts a set of observations of possibly correlat-
ed variables into a set of values of linearly uncorre-
lated variables called principle components. These
principle components represent the inner structure
of the correlated variables.
In this paper, we directly employ PCA to con-
vert labels of training instances into their principle
components, and take these principle components
as hidden components of training instances. We
denote by hi the hidden components of the i-th in-
stance captured by PCA.
</bodyText>
<subsectionHeader confidence="0.999238">
2.2 Joint Learning Framework
</subsectionHeader>
<bodyText confidence="0.998964125">
We expand the original feature representation of
the instance xi by its hidden component code vec-
tor ci. For simplicity, we use logistic regression as
the motivating example. Let wl denote weights in
the l-th function fl, consisting of two parts: 1) wi
is the part involving the instance features. 2) wcl
is the part involving the hidden component codes.
Hence fl is:
</bodyText>
<equation confidence="0.989341">
1
fl(x,c) = 1 + exp(−xTwi − cTwcl) (1)
</equation>
<bodyText confidence="0.999797923076923">
where C is the code vectors set of all training in-
stances.
The natural choice of the code vector c is h.
However, when testing an instance, the labeling is
unknown (exactly what we try to predict), conse-
quently we can not capture h with PCA to replace
the code vector c in the prediction function Eq.(1).
Therefore, we assume a linear transformation M
from the training instances to their independent
components, and use Mx as the approximate in-
dependent component. For numerical stability, we
add a non-linear function (e.g., the tanh function)
to Mx. This is formulated as follows.
</bodyText>
<equation confidence="0.946007">
c = tanh(Mx) (2)
</equation>
<bodyText confidence="0.999855333333333">
Aiming to the discrimination fitting and the in-
dependent components encoding, we optimize the
following optimization problem.
</bodyText>
<equation confidence="0.9983145">
`(xi,ci, yil, fl) + λ1Ω(f)
+λ2Z(C) (3)
</equation>
<bodyText confidence="0.999974333333333">
The first term of Eq.(3) is the loss function. `
is the loss function defined on the training data,
and W denotes all weights in the our model, i.e.,
w1, ...,wl, ...,wm. Since we utilize the logistic re-
gression in our model, the loss function is defined
as follows.
</bodyText>
<equation confidence="0.982212">
`(x,c, y, f)
= −ylnf(x,c) − (1 − y)ln(1 − f(x,c)) (4)
</equation>
<bodyText confidence="0.999690666666667">
The second term of Eq.(3) Ω is to punish the
model complexity, which we use the `2 regular-
ization term.
</bodyText>
<equation confidence="0.99509">
Ω(f) = �m ||wl||2. (5)
l=1
</equation>
<bodyText confidence="0.9992948">
The third term of Eq.(3) Z is to enforce the code
vector close to the independent component vector.
To obtain the goal, we use the least square error
between the code vector and the independent com-
ponent vector as the third regularized term.
</bodyText>
<equation confidence="0.992831333333333">
n
Z(C) = ||ci − hi||2. (6)
i=1
</equation>
<bodyText confidence="0.999765333333333">
By substituting the Eq.(5) and Eq.(6) into Eq.(3)
and changing c to tanh(Mx) (Eq.(2)), we obtain
the following optimization problem.
</bodyText>
<equation confidence="0.99706775">
(7)
`(xi, tanh(Mxi), yil,f)
+λ1 �m ||wl||2 + λ2 n ||Mxi − hi||2
l=1 i=1
n
i=1
min
W ,M
�m
l=1
n
i=1
min
W ,C
�m
l=1
</equation>
<page confidence="0.963168">
1817
</page>
<subsectionHeader confidence="0.989677">
2.3 Alternative Optimization method
</subsectionHeader>
<bodyText confidence="0.963460833333333">
We solve the optimization problem in Eq.(7) by
the alternative optimization method, which opti-
mize one group of the two parameters with the
other fixed. When the M fixed, the third term of
Eq.(7) is a constant and thus can be ignored, then
Eq.(7) can be rewritten as follows.
</bodyText>
<equation confidence="0.988277">
e(xi, tanh(Mxi), yil, fl)
||wl||2 (8)
</equation>
<bodyText confidence="0.6791165">
By decomposing Eq.(8) based on the label, the e-
quation Eq.(8) can be simplified to:
</bodyText>
<equation confidence="0.774086">
e(xi, tanh(Mxi), yil, fl) + A1||wl||2 (9)
</equation>
<bodyText confidence="0.986423833333333">
Eq.(9) is the standard logistic regression, which
has many efficient optimization algorithms.
When W fixed, the second term is constan-
t and can be omitted, then Ep.(7) can rewritten
to Eq.(10). We can apply the gradient descen-
t method to optimize this problem.
</bodyText>
<equation confidence="0.975064">
e(xi, tanh(Mxi), yil, fl)
||Mxi − hi||2
(10)
</equation>
<sectionHeader confidence="0.999833" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999296">
3.1 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.99994775">
Compared with the single-label classification, the
multi-label setting introduces the additional de-
grees of freedom, so that various multi-label eval-
uation metrics are requisite. We use three differen-
t multi-label evaluation metrics, include the ham-
ming loss evaluation metric.
The hamming loss is defined as the percentage
of the wrong labels to the total number of labels.
</bodyText>
<equation confidence="0.987498">
1
Hammingloss = |h(x)Ay |(11)
m
</equation>
<bodyText confidence="0.99998225">
where A denotes the symmetric difference of two
sets, equivalent to XOR operator in Boolean logic.
m denotes the label number.
The multi-label 0/1 loss, also known as subset
accuracy, is the exact match measure as it requires
any predicted set of labels h(x) to match the true
set of labels S exactly. The 0/1 loss is defined as
follows:
</bodyText>
<equation confidence="0.993054">
0/1loss = I(h(x) =� y) (12)
</equation>
<bodyText confidence="0.9999225">
Let aj and rj denote the precision and recall for
the j-th label. The macro-averaged F is a harmon-
ic mean between precision and recall, defined as
follows:
</bodyText>
<equation confidence="0.912801">
2 * aj * rj (13)
</equation>
<subsectionHeader confidence="0.9609">
3.2 Datasets
</subsectionHeader>
<bodyText confidence="0.959059380952381">
We perform experiments on three MTC data sets:
1) the first data set is slashdot (Read et al., 2011).
The slashdot data set is concerned about science
and technology news categorization, which pre-
dicts multiply labels given article titles and partial
blurbs mined from Slashdot.org. 2) the second da-
ta set is medical (Pestian et al., 2007). This data set
involves the assignment of ICD-9-CM codes to ra-
diology reports. 3) the third data set is tmc2007 (S-
rivastava and Zane-Ulman, 2005). It is concerned
about safety report categorization, which is to la-
bel aviation safety reports with respect to what
types of problems they describe. The characteris-
tics of them are shown in Table 1, where n denotes
the size of the data set, d denotes the dimension of
the document instance, and m denotes the number
of labels.
dataset n d m Lcard
slashdot 3782 1079 22 1.18
medical 978 1449 45 1.245
tmc2007 28596 500 22 2.16
</bodyText>
<tableCaption confidence="0.723924">
Table 1: Multi-label data sets and associated statis-
tics
</tableCaption>
<bodyText confidence="0.999676">
The measure label cardinality Lcard, which
is one of the standard measures of ”multi-label-
ness”, defined as follows, introduced in (T-
soumakas and Katakis, 2007).
</bodyText>
<equation confidence="0.984348666666667">
Pn Pm j=1 yi
i=1 j
Lcard(D) = n
</equation>
<bodyText confidence="0.9999665">
where D denotes the data set, lij denotes the j-th
label of the i-th instance in the data set.
</bodyText>
<equation confidence="0.670128857142857">
Xn
i=1
min
W
Xm
l=1
Xm
l=1
+A1
Xn
i=1
min
wl
Xn
i=1
min
M
Xm
l=1
Xn
i=1
+A2
1
F=
m
Xm
i=j
aj + rj
</equation>
<page confidence="0.957504">
1818
</page>
<subsectionHeader confidence="0.996035">
3.3 Compared to Baselines
</subsectionHeader>
<bodyText confidence="0.99999672">
To examine the values of the joint learning frame-
work, we compare our method to two baselines.
The baseline 1 eliminates the PCA, which just
adds an extra set of non-linear features. To im-
plement this baseline, we only need to set A2 = 0.
The baseline 2 eliminates the joint learning frame-
work. This baseline captures the hidden compo-
nent codes with PCA, trains a linear regression
model to fit the hidden component codes, and u-
tilizes the outputs of the linear regression model
as features.
For the proposed method, we set A1 = 0.001
and A2 = 0.1. For the baseline 2, we employ l-
ogistic regression with 0.001 E2 regularization as
the base classifier. Evaluations are done in ten-
fold cross validation. Note that all of them pro-
duce real-valued predictions. A threshold t needs
to be used to determine the final multi-label set y
such that lj E y where pj ≥ t. We select threshold
t, which makes the Lcard measure of predictions
for the training set is closest to the Lcard mea-
sure of the training set (Read et al., 2011). The
threshold t is determined as follows, where Dt is
the training set and a multi-label model Ht pre-
dicts for the training set under threshold t.
</bodyText>
<equation confidence="0.9954675">
t = argmin |Lcard(Dt) − Lcard(Ht(Dt)) |(14)
t∈[0,1]
</equation>
<bodyText confidence="0.999448375">
Table 2 reports our method wins over the base-
lines in terms of different evaluation metrics,
which shows the values of PCA and our join-
t learning framework. The hidden component code
only fits the hidden component in the baseline
method. The hidden component code obtains bal-
ance of fitting hidden component and fitting the
training data in the joint learning framework.
</bodyText>
<subsectionHeader confidence="0.996574">
3.4 Compared to Other Methods
</subsectionHeader>
<bodyText confidence="0.999971795454545">
We compare the proposed method to BR, C-
C (Read et al., 2011), RAKEL (Tsoumakas and
Vlahavas, 2007) and ML-KNN (Zhang and Zhou,
2007). entropy. ML-kNN is an adaption of kNN
algorithm for multilabel classification. methods.
Binary Revelance (BR) is a simple but effective
method that trains binary classifiers for each label
independently. BR has a low time complexity but
makes an arbitrary assumption that the labels are
independent from each other. CC organizes the
classifiers along a chain and take predictions pro-
duced by the former classifiers as features of the
latter classifiers. ML-kNN uses kNN algorithms
independently for each label with considering pri-
or probabilities. The Label Powerset (LP) method
models independencies among labels by treating
each label combination as a new class. LP con-
sumes too much time, since there are 2m label
combinations with m labels. RAndom K labEL
(RAKEL) is an ensemble method of LP. RAKEL
learns several LP models with random subsets of
size k from all labels, and then uses a vote process
to determine the final predictions.
For our proposed method, we employ the set-
up in subsection 3.3. We utilize logistic regression
with 0.001 E2 regularization as the base classifier
for BR, CC and RAKEL. For RAKEL, the num-
ber of ensemble is set to the number of label and
the size of the label subset is set to 3. For MLKN-
N, the number of neighbors used in the k-nearest
neighbor algorithm is set to 10 and the smooth pa-
rameter is set to 1. Evaluations are done in ten-
fold cross validation. We employ the threshold-
selection strategy introduced in subsection 3.3
Table 2 also reports the detailed results in terms
of different evaluation metrics. The mean metric
value and the standard deviation of each method
are listed for each data set. We see our proposed
method shows majorities of wining over the other
state-of-the-art methods nearly at all data sets un-
der hamming loss, 0/1 loss and macro f score. E-
specially, under the macro f score, the advantages
of our proposed method over the other methods are
very clear.
</bodyText>
<sectionHeader confidence="0.999607" genericHeader="method">
4 CONCLUSION
</sectionHeader>
<bodyText confidence="0.99988075">
Many real-world text categorization applications
are multi-label text categorization (MTC), where a
documents is usually assigned with multiple labels
simultaneously. The key challenge of MTC is the
label correlations among labels. In this paper, we
propose a MTC method via hidden components
to capture the label correlations. The proposed
method obtains hidden components via PCA and
incorporates them into a joint learning framework.
Experiments with various data sets and evaluation
metrics validate the effectiveness of the proposed
method.
</bodyText>
<sectionHeader confidence="0.975183" genericHeader="conclusions">
Acknowledge
</sectionHeader>
<bodyText confidence="0.999825">
We thank anonymous reviewers for their help-
ful comments and suggestions. This research
was partly supported by National High Tech-
</bodyText>
<page confidence="0.97516">
1819
</page>
<table confidence="0.999691962962963">
hamming,. Lower is better.
Dataset slashdot medical tmc2007
Proposed 0.044 f 0.004 0.010 f 0.002 0.056 f 0.002
Baseline1 0.046 f 0.003• 0.010 f 0.002 0.056 f 0.001
Baseline2 0.047 f 0.003• 0.011 f 0.001 0.059 f 0.001•
BR 0.058 f 0.003• 0.010 f 0.001 0.060 f 0.001•
CC 0.049 f 0.003• 0.010 f 0.001 0.058 f 0.001•
RAKEL 0.039 f 0.002◦ 0.011 f 0.002 0.057 f 0.001
MLKNN 0.067 f 0.003• 0.016 f 0.003• 0.070 f 0.002•
0/1 loss,. Lower is better.
Dataset slashdot medical tmc2007
Proposed 0.600 f 0.042 0.316 f 0.071 0.672 f 0.010
Baseline1 0.615 f 0.034• 0.324 f 0.058• 0.672 f 0.008
Baseline2 0.669 f 0.039• 0.354 f 0.062• 0.698 f 0.007•
BR 0.803 f 0.018• 0.337 f 0.063• 0.701 f 0.008•
CC 0.657 f 0.025• 0.337 f 0.064• 0.687 f 0.010•
RAKEL 0.686 f 0.024• 0.363 f 0.064• 0.682 f 0.009•
MLKNN 0.776 f 0.020• 0.491 f 0.083• 0.746 f 0.003•
F scorer. Larger is better.
Dataset slashdot medical tmc2007
Proposed 0.429 f 0.026 0.575 f 0.067 0.587 f 0.010
Baseline1 0.413 f 0.032• 0.547 f 0.056• 0.577 f 0.011
Baseline2 0.398 f 0.032• 0.561 f 0.052• 0.506 f 0.011•
BR 0.204 f 0.011• 0.501 f 0.058• 0.453 f 0.011•
CC 0.303 f 0.022• 0.510 f 0.052• 0.505 f 0.011•
RAKEL 0.349 f 0.023• 0.589 f 0.063◦ 0.555 f 0.011•
MLKNN 0.297 f 0.031• 0.410 f 0.064• 0.431 f 0.014•
</table>
<tableCaption confidence="0.998787">
Table 2: Performance (meanfstd.) of our method and baseline in terms of different evaluation metrics.
</tableCaption>
<reference confidence="0.94493275">
•/◦ indicates whether the proposed method is statistically superior/inferior to baseline (pairwise t-test at
5% significance level).
nology Research and Development Program of
China (863 Program) (No.2012AA011101), Na-
tional Natural Science Foundation of China
(No.91024009), Major National Social Science
Fund of China (No. 12&amp;ZD227). The contac-
t author of this paper, according to the meaning
given to this role by Key Laboratory of Computa-
tional Linguistics, Ministry of Education, School
of Electronics Engineering and Computer Science,
Peking University, is Houfeng Wang
</reference>
<sectionHeader confidence="0.952425" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997942142857143">
Sheng-Jun Huang and Zhi-Hua Zhou. 2012. Multi-
label learning by exploiting label correlations local-
ly. In AAAI.
Ioannis Katakis, Grigorios Tsoumakas, and Ioannis
Vlahavas. 2008. Multilabel text classification for
automated tag suggestion. In Proceedings of the
ECML/PKDD.
Jinseok Nam, Jungi Kim, Iryna Gurevych, and Jo-
hannes F¨urnkranz. 2013. Large-scale multi-label
text classification-revisiting neural networks. arXiv
preprint arXiv:1312.5419.
John P Pestian, Christopher Brew, Paweł Matykiewicz,
DJ Hovermale, Neil Johnson, K Bretonnel Cohen,
and Włodzisław Duch. 2007. A shared task involv-
ing multi-label classification of clinical free text. In
Proceedings of the Workshop on BioNLP 2007: Bio-
logical, Translational, and Clinical Language Pro-
cessing, pages 97–104. Association for Computa-
tional Linguistics.
Jesse Read, Bernhard Pfahringer, Geoff Holmes, and
Eibe Frank. 2011. Classifier chains for multi-label
classification. Machine learning, 85(3):333–359.
Timothy N Rubin, America Chambers, Padhraic S-
myth, and Mark Steyvers. 2012. Statistical topic
models for multi-label document classification. Ma-
chine Learning, 88(1-2):157–208.
Ashok N Srivastava and Brett Zane-Ulman. 2005. Dis-
covering recurring anomalies in text reports regard-
</reference>
<page confidence="0.784565">
1820
</page>
<reference confidence="0.998663666666667">
ing complex space systems. In Aerospace Confer-
ence, 2005 IEEE, pages 3853–3862. IEEE.
Barbara G Tabachnick, Linda S Fidell, et al. 2001. Us-
ing multivariate statistics.
Grigorios Tsoumakas and Ioannis Katakis. 2007.
Multi-label classification: An overview. Interna-
tional Journal of Data Warehousing and Mining (I-
JDWM), 3(3):1–13.
Grigorios Tsoumakas and Ioannis Vlahavas. 2007.
Random k-labelsets: An ensemble method for mul-
tilabel classification. Machine Learning: ECML
2007, pages 406–417.
Min-Ling Zhang and Zhi-Hua Zhou. 2007. Ml-knn: A
lazy learning approach to multi-label learning. Pat-
tern Recognition, 40(7):2038–2048.
</reference>
<page confidence="0.993434">
1821
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.263388">
<title confidence="0.999603">Muli-label Text Categorization with Hidden Components</title>
<author confidence="0.982168">Li Li Longkai Zhang Houfeng Wang</author>
<affiliation confidence="0.271804">Key Laboratory of Computational Linguistics (Peking University) Ministry of Education, China</affiliation>
<email confidence="0.951846">li.l@pku.edu.cn,zhlongk@qq.com,wanghf@pku.edu.cn</email>
<abstract confidence="0.999036176470588">Multi-label text categorization (MTC) is supervised learning, where a document may be assigned with multiple categories (labels) simultaneously. The labels in the MTC are correlated and the correlation results in some hidden components, which represent the ”share” variance of correlated labels. In this paper, we propose a method with hidden components for MTC. The proposed method employs PCA to capture the hidden components, and incorporates them into a joint learning framework to improve the performance. Experiments with real-world data sets and evaluation metrics validate the effectiveness of the proposed method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>indicates whether the proposed method is statistically superior/inferior to baseline (pairwise t-test at 5% significance level).</title>
<marker></marker>
<rawString>•/◦ indicates whether the proposed method is statistically superior/inferior to baseline (pairwise t-test at 5% significance level).</rawString>
</citation>
<citation valid="false">
<title>nology Research and Development Program of China (863 Program) (No.2012AA011101), National Natural Science Foundation of China (No.91024009), Major National Social Science Fund of China (No. 12&amp;ZD227). The contact author of this paper, according to the meaning given to this role by</title>
<institution>Key Laboratory of Computational Linguistics, Ministry of Education, School of Electronics Engineering and Computer Science, Peking University, is Houfeng Wang</institution>
<marker></marker>
<rawString>nology Research and Development Program of China (863 Program) (No.2012AA011101), National Natural Science Foundation of China (No.91024009), Major National Social Science Fund of China (No. 12&amp;ZD227). The contact author of this paper, according to the meaning given to this role by Key Laboratory of Computational Linguistics, Ministry of Education, School of Electronics Engineering and Computer Science, Peking University, is Houfeng Wang</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheng-Jun Huang</author>
<author>Zhi-Hua Zhou</author>
</authors>
<title>Multilabel learning by exploiting label correlations locally.</title>
<date>2012</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="2858" citStr="Huang and Zhou, 2012" startWordPosition="453" endWordPosition="456">den components, which represent the ”share” variance of correlated labels. Intuitively, if we can capture and utilize these hidden components in MTC, the performance will be improved. To implement this idea, we propose a multi- label text categorization method with hidden components, which employ PCA to capture the hidden components, and then incorporates these hidden components into a joint learning framework. Experiments with various data sets and evaluation metrics validate the values of our method. The research close to our work is ML-LOC (Multi-Label learning using LOcal Correlation) in (Huang and Zhou, 2012). The differ1816 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1816–1821, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics ences between ours and ML-LOC is that ML-LOC employs the cluster method to gain the local correlation, but we employ the PCA to obtain the hidden code. Meanwhile, ML-LOC uses the linear programming in learning the local code, but we employ the gradient descent method since we add non-linear function to the hidden code. The rest of this paper is organized as follows. Section 2 presents</context>
</contexts>
<marker>Huang, Zhou, 2012</marker>
<rawString>Sheng-Jun Huang and Zhi-Hua Zhou. 2012. Multilabel learning by exploiting label correlations locally. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Katakis</author>
</authors>
<title>Grigorios Tsoumakas, and Ioannis Vlahavas.</title>
<date>2008</date>
<booktitle>In Proceedings of the ECML/PKDD.</booktitle>
<marker>Katakis, 2008</marker>
<rawString>Ioannis Katakis, Grigorios Tsoumakas, and Ioannis Vlahavas. 2008. Multilabel text classification for automated tag suggestion. In Proceedings of the ECML/PKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinseok Nam</author>
<author>Jungi Kim</author>
<author>Iryna Gurevych</author>
<author>Johannes F¨urnkranz</author>
</authors>
<title>Large-scale multi-label text classification-revisiting neural networks. arXiv preprint arXiv:1312.5419.</title>
<date>2013</date>
<marker>Nam, Kim, Gurevych, F¨urnkranz, 2013</marker>
<rawString>Jinseok Nam, Jungi Kim, Iryna Gurevych, and Johannes F¨urnkranz. 2013. Large-scale multi-label text classification-revisiting neural networks. arXiv preprint arXiv:1312.5419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John P Pestian</author>
<author>Christopher Brew</author>
<author>Paweł Matykiewicz</author>
<author>DJ Hovermale</author>
<author>Neil Johnson</author>
<author>K Bretonnel Cohen</author>
<author>Włodzisław Duch</author>
</authors>
<title>A shared task involving multi-label classification of clinical free text.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing,</booktitle>
<pages>97--104</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8684" citStr="Pestian et al., 2007" startWordPosition="1443" endWordPosition="1446">e true set of labels S exactly. The 0/1 loss is defined as follows: 0/1loss = I(h(x) =� y) (12) Let aj and rj denote the precision and recall for the j-th label. The macro-averaged F is a harmonic mean between precision and recall, defined as follows: 2 * aj * rj (13) 3.2 Datasets We perform experiments on three MTC data sets: 1) the first data set is slashdot (Read et al., 2011). The slashdot data set is concerned about science and technology news categorization, which predicts multiply labels given article titles and partial blurbs mined from Slashdot.org. 2) the second data set is medical (Pestian et al., 2007). This data set involves the assignment of ICD-9-CM codes to radiology reports. 3) the third data set is tmc2007 (Srivastava and Zane-Ulman, 2005). It is concerned about safety report categorization, which is to label aviation safety reports with respect to what types of problems they describe. The characteristics of them are shown in Table 1, where n denotes the size of the data set, d denotes the dimension of the document instance, and m denotes the number of labels. dataset n d m Lcard slashdot 3782 1079 22 1.18 medical 978 1449 45 1.245 tmc2007 28596 500 22 2.16 Table 1: Multi-label data s</context>
</contexts>
<marker>Pestian, Brew, Matykiewicz, Hovermale, Johnson, Cohen, Duch, 2007</marker>
<rawString>John P Pestian, Christopher Brew, Paweł Matykiewicz, DJ Hovermale, Neil Johnson, K Bretonnel Cohen, and Włodzisław Duch. 2007. A shared task involving multi-label classification of clinical free text. In Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing, pages 97–104. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesse Read</author>
<author>Bernhard Pfahringer</author>
<author>Geoff Holmes</author>
<author>Eibe Frank</author>
</authors>
<title>Classifier chains for multi-label classification.</title>
<date>2011</date>
<booktitle>Machine learning,</booktitle>
<pages>85--3</pages>
<contexts>
<context position="8445" citStr="Read et al., 2011" startWordPosition="1405" endWordPosition="1408">erence of two sets, equivalent to XOR operator in Boolean logic. m denotes the label number. The multi-label 0/1 loss, also known as subset accuracy, is the exact match measure as it requires any predicted set of labels h(x) to match the true set of labels S exactly. The 0/1 loss is defined as follows: 0/1loss = I(h(x) =� y) (12) Let aj and rj denote the precision and recall for the j-th label. The macro-averaged F is a harmonic mean between precision and recall, defined as follows: 2 * aj * rj (13) 3.2 Datasets We perform experiments on three MTC data sets: 1) the first data set is slashdot (Read et al., 2011). The slashdot data set is concerned about science and technology news categorization, which predicts multiply labels given article titles and partial blurbs mined from Slashdot.org. 2) the second data set is medical (Pestian et al., 2007). This data set involves the assignment of ICD-9-CM codes to radiology reports. 3) the third data set is tmc2007 (Srivastava and Zane-Ulman, 2005). It is concerned about safety report categorization, which is to label aviation safety reports with respect to what types of problems they describe. The characteristics of them are shown in Table 1, where n denotes</context>
<context position="10752" citStr="Read et al., 2011" startWordPosition="1830" endWordPosition="1833">den component codes, and utilizes the outputs of the linear regression model as features. For the proposed method, we set A1 = 0.001 and A2 = 0.1. For the baseline 2, we employ logistic regression with 0.001 E2 regularization as the base classifier. Evaluations are done in tenfold cross validation. Note that all of them produce real-valued predictions. A threshold t needs to be used to determine the final multi-label set y such that lj E y where pj ≥ t. We select threshold t, which makes the Lcard measure of predictions for the training set is closest to the Lcard measure of the training set (Read et al., 2011). The threshold t is determined as follows, where Dt is the training set and a multi-label model Ht predicts for the training set under threshold t. t = argmin |Lcard(Dt) − Lcard(Ht(Dt)) |(14) t∈[0,1] Table 2 reports our method wins over the baselines in terms of different evaluation metrics, which shows the values of PCA and our joint learning framework. The hidden component code only fits the hidden component in the baseline method. The hidden component code obtains balance of fitting hidden component and fitting the training data in the joint learning framework. 3.4 Compared to Other Method</context>
</contexts>
<marker>Read, Pfahringer, Holmes, Frank, 2011</marker>
<rawString>Jesse Read, Bernhard Pfahringer, Geoff Holmes, and Eibe Frank. 2011. Classifier chains for multi-label classification. Machine learning, 85(3):333–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy N Rubin</author>
<author>America Chambers</author>
<author>Padhraic Smyth</author>
<author>Mark Steyvers</author>
</authors>
<title>Statistical topic models for multi-label document classification.</title>
<date>2012</date>
<booktitle>Machine Learning,</booktitle>
<pages>88--1</pages>
<contexts>
<context position="1037" citStr="Rubin et al., 2012" startWordPosition="143" endWordPosition="146">ed and the correlation results in some hidden components, which represent the ”share” variance of correlated labels. In this paper, we propose a method with hidden components for MTC. The proposed method employs PCA to capture the hidden components, and incorporates them into a joint learning framework to improve the performance. Experiments with real-world data sets and evaluation metrics validate the effectiveness of the proposed method. 1 Introduction Many real-world text categorization applications are multi-label text categorization (Srivastava and Zane-Ulman, 2005; Katakis et al., 2008; Rubin et al., 2012; Nam et al., 2013), where a documents is usually assigned with multiple labels simultaneously. For example, as figure 1 shows, a newspaper article concerning global warming can be classified into two categories, Environment, and Science simultaneously. Let X = Rd be the documents corpus, and Y = {0,1}m be the label space with m labels. We denote by {(x1,y1), (x2,y2), ..., (xn,yn)} the training set of n documents. Each document is denoted by a vector xi = [xi,1, xi,2, ..., xi,d] of d dimensions. The labeling of the i-th document is denoted by vector yi = [yi,1, yi,2, ...,yi,m], where yil is 1 </context>
</contexts>
<marker>Rubin, Chambers, Smyth, Steyvers, 2012</marker>
<rawString>Timothy N Rubin, America Chambers, Padhraic Smyth, and Mark Steyvers. 2012. Statistical topic models for multi-label document classification. Machine Learning, 88(1-2):157–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashok N Srivastava</author>
<author>Brett Zane-Ulman</author>
</authors>
<title>Discovering recurring anomalies in text reports regarding complex space systems.</title>
<date>2005</date>
<booktitle>In Aerospace Conference, 2005 IEEE,</booktitle>
<pages>3853--3862</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="995" citStr="Srivastava and Zane-Ulman, 2005" startWordPosition="135" endWordPosition="138">els) simultaneously. The labels in the MTC are correlated and the correlation results in some hidden components, which represent the ”share” variance of correlated labels. In this paper, we propose a method with hidden components for MTC. The proposed method employs PCA to capture the hidden components, and incorporates them into a joint learning framework to improve the performance. Experiments with real-world data sets and evaluation metrics validate the effectiveness of the proposed method. 1 Introduction Many real-world text categorization applications are multi-label text categorization (Srivastava and Zane-Ulman, 2005; Katakis et al., 2008; Rubin et al., 2012; Nam et al., 2013), where a documents is usually assigned with multiple labels simultaneously. For example, as figure 1 shows, a newspaper article concerning global warming can be classified into two categories, Environment, and Science simultaneously. Let X = Rd be the documents corpus, and Y = {0,1}m be the label space with m labels. We denote by {(x1,y1), (x2,y2), ..., (xn,yn)} the training set of n documents. Each document is denoted by a vector xi = [xi,1, xi,2, ..., xi,d] of d dimensions. The labeling of the i-th document is denoted by vector yi</context>
<context position="8830" citStr="Srivastava and Zane-Ulman, 2005" startWordPosition="1467" endWordPosition="1471">recall for the j-th label. The macro-averaged F is a harmonic mean between precision and recall, defined as follows: 2 * aj * rj (13) 3.2 Datasets We perform experiments on three MTC data sets: 1) the first data set is slashdot (Read et al., 2011). The slashdot data set is concerned about science and technology news categorization, which predicts multiply labels given article titles and partial blurbs mined from Slashdot.org. 2) the second data set is medical (Pestian et al., 2007). This data set involves the assignment of ICD-9-CM codes to radiology reports. 3) the third data set is tmc2007 (Srivastava and Zane-Ulman, 2005). It is concerned about safety report categorization, which is to label aviation safety reports with respect to what types of problems they describe. The characteristics of them are shown in Table 1, where n denotes the size of the data set, d denotes the dimension of the document instance, and m denotes the number of labels. dataset n d m Lcard slashdot 3782 1079 22 1.18 medical 978 1449 45 1.245 tmc2007 28596 500 22 2.16 Table 1: Multi-label data sets and associated statistics The measure label cardinality Lcard, which is one of the standard measures of ”multi-labelness”, defined as follows,</context>
</contexts>
<marker>Srivastava, Zane-Ulman, 2005</marker>
<rawString>Ashok N Srivastava and Brett Zane-Ulman. 2005. Discovering recurring anomalies in text reports regarding complex space systems. In Aerospace Conference, 2005 IEEE, pages 3853–3862. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara G Tabachnick</author>
<author>Linda S Fidell</author>
</authors>
<title>Using multivariate statistics.</title>
<date>2001</date>
<marker>Tabachnick, Fidell, 2001</marker>
<rawString>Barbara G Tabachnick, Linda S Fidell, et al. 2001. Using multivariate statistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grigorios Tsoumakas</author>
<author>Ioannis Katakis</author>
</authors>
<title>Multi-label classification: An overview.</title>
<date>2007</date>
<journal>International Journal of Data Warehousing and Mining (IJDWM),</journal>
<volume>3</volume>
<issue>3</issue>
<contexts>
<context position="9474" citStr="Tsoumakas and Katakis, 2007" startWordPosition="1579" endWordPosition="1583">d about safety report categorization, which is to label aviation safety reports with respect to what types of problems they describe. The characteristics of them are shown in Table 1, where n denotes the size of the data set, d denotes the dimension of the document instance, and m denotes the number of labels. dataset n d m Lcard slashdot 3782 1079 22 1.18 medical 978 1449 45 1.245 tmc2007 28596 500 22 2.16 Table 1: Multi-label data sets and associated statistics The measure label cardinality Lcard, which is one of the standard measures of ”multi-labelness”, defined as follows, introduced in (Tsoumakas and Katakis, 2007). Pn Pm j=1 yi i=1 j Lcard(D) = n where D denotes the data set, lij denotes the j-th label of the i-th instance in the data set. Xn i=1 min W Xm l=1 Xm l=1 +A1 Xn i=1 min wl Xn i=1 min M Xm l=1 Xn i=1 +A2 1 F= m Xm i=j aj + rj 1818 3.3 Compared to Baselines To examine the values of the joint learning framework, we compare our method to two baselines. The baseline 1 eliminates the PCA, which just adds an extra set of non-linear features. To implement this baseline, we only need to set A2 = 0. The baseline 2 eliminates the joint learning framework. This baseline captures the hidden component cod</context>
</contexts>
<marker>Tsoumakas, Katakis, 2007</marker>
<rawString>Grigorios Tsoumakas and Ioannis Katakis. 2007. Multi-label classification: An overview. International Journal of Data Warehousing and Mining (IJDWM), 3(3):1–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grigorios Tsoumakas</author>
<author>Ioannis Vlahavas</author>
</authors>
<title>Random k-labelsets: An ensemble method for multilabel classification. Machine Learning: ECML</title>
<date>2007</date>
<pages>406--417</pages>
<contexts>
<context position="11452" citStr="Tsoumakas and Vlahavas, 2007" startWordPosition="1950" endWordPosition="1953">t and a multi-label model Ht predicts for the training set under threshold t. t = argmin |Lcard(Dt) − Lcard(Ht(Dt)) |(14) t∈[0,1] Table 2 reports our method wins over the baselines in terms of different evaluation metrics, which shows the values of PCA and our joint learning framework. The hidden component code only fits the hidden component in the baseline method. The hidden component code obtains balance of fitting hidden component and fitting the training data in the joint learning framework. 3.4 Compared to Other Methods We compare the proposed method to BR, CC (Read et al., 2011), RAKEL (Tsoumakas and Vlahavas, 2007) and ML-KNN (Zhang and Zhou, 2007). entropy. ML-kNN is an adaption of kNN algorithm for multilabel classification. methods. Binary Revelance (BR) is a simple but effective method that trains binary classifiers for each label independently. BR has a low time complexity but makes an arbitrary assumption that the labels are independent from each other. CC organizes the classifiers along a chain and take predictions produced by the former classifiers as features of the latter classifiers. ML-kNN uses kNN algorithms independently for each label with considering prior probabilities. The Label Powers</context>
</contexts>
<marker>Tsoumakas, Vlahavas, 2007</marker>
<rawString>Grigorios Tsoumakas and Ioannis Vlahavas. 2007. Random k-labelsets: An ensemble method for multilabel classification. Machine Learning: ECML 2007, pages 406–417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Ling Zhang</author>
<author>Zhi-Hua Zhou</author>
</authors>
<title>Ml-knn: A lazy learning approach to multi-label learning.</title>
<date>2007</date>
<journal>Pattern Recognition,</journal>
<volume>40</volume>
<issue>7</issue>
<contexts>
<context position="11486" citStr="Zhang and Zhou, 2007" startWordPosition="1956" endWordPosition="1959">the training set under threshold t. t = argmin |Lcard(Dt) − Lcard(Ht(Dt)) |(14) t∈[0,1] Table 2 reports our method wins over the baselines in terms of different evaluation metrics, which shows the values of PCA and our joint learning framework. The hidden component code only fits the hidden component in the baseline method. The hidden component code obtains balance of fitting hidden component and fitting the training data in the joint learning framework. 3.4 Compared to Other Methods We compare the proposed method to BR, CC (Read et al., 2011), RAKEL (Tsoumakas and Vlahavas, 2007) and ML-KNN (Zhang and Zhou, 2007). entropy. ML-kNN is an adaption of kNN algorithm for multilabel classification. methods. Binary Revelance (BR) is a simple but effective method that trains binary classifiers for each label independently. BR has a low time complexity but makes an arbitrary assumption that the labels are independent from each other. CC organizes the classifiers along a chain and take predictions produced by the former classifiers as features of the latter classifiers. ML-kNN uses kNN algorithms independently for each label with considering prior probabilities. The Label Powerset (LP) method models independenci</context>
</contexts>
<marker>Zhang, Zhou, 2007</marker>
<rawString>Min-Ling Zhang and Zhi-Hua Zhou. 2007. Ml-knn: A lazy learning approach to multi-label learning. Pattern Recognition, 40(7):2038–2048.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>