<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000044">
<title confidence="0.994139">
Joint Inference for Knowledge Base Population
</title>
<author confidence="0.995603">
Liwei Chen1, Yansong Feng 1∗, Jinghui Mo1, Songfang Huang2, and Dongyan Zhao1
</author>
<affiliation confidence="0.8950415">
1ICST, Peking University, Beijing, China
2IBM China Research Lab, Beijing, China
</affiliation>
<email confidence="0.970461">
{chenliwei,fengyansong,mojinghui,zhaodongyan}@pku.edu.cn
huangsf@cn.ibm.com
</email>
<sectionHeader confidence="0.997256" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9992062">
Populating Knowledge Base (KB) with
new knowledge facts from reliable text re-
sources usually consists of linking name
mentions to KB entities and identifying
relationship between entity pairs. How-
ever, the task often suffers from errors
propagating from upstream entity linkers
to downstream relation extractors. In this
paper, we propose a novel joint infer-
ence framework to allow interactions be-
tween the two subtasks and find an opti-
mal assignment by addressing the coher-
ence among preliminary local predictions:
whether the types of entities meet the ex-
pectations of relations explicitly or implic-
itly, and whether the local predictions are
globally compatible. We further measure
the confidence of the extracted triples by
looking at the details of the complete ex-
traction process. Experiments show that
the proposed framework can significantly
reduce the error propagations thus obtain
more reliable facts, and outperforms com-
petitive baselines with state-of-the-art re-
lation extraction models.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998204339622641">
Recent advances in natural language processing
have made it possible to construct structured KBs
from online encyclopedia resources, at an un-
precedented scale and much more efficiently than
traditional manual edit. However, in those KBs,
entities which are popular to the community usu-
ally contain more knowledge facts, e.g., the bas-
ketball player LeBron James, the actor Nicholas
Cage, etc., while most other entities often have
fewer facts. On the other hand, knowledge facts
should be updated as the development of entities,
such as changes in the cabinet, a marriage event,
or an acquisition between two companies, etc.
In order to address the above issues, we could
consult populating existing KBs from reliable text
resources, e.g., newswire, which usually involves
enriching KBs with new entities and populating
KBs with new knowledge facts, in the form of
&lt;Entity, Relation, Entity&gt; triple. In this paper, we
will focus on the latter, identifying relationship be-
tween two existing KB entities. This task can be
intuitively considered in a pipeline paradigm, that
is, name mentions in the texts are first linked to
entities in the KB (entity linking, EL), and then
the relationship between them are identified (re-
lation extraction, RE). It is worth mentioning that
the first task EL is different from the task of named
entity recognition (NER) in traditional informa-
tion extraction (IE) tasks, where NER recognizes
and classifies the entity mentions (to several pre-
defined types) in the texts, but EL focuses on link-
ing the mentions to their corresponding entities in
the KB. Such pipeline systems often suffer from
errors propagating from upstream to downstream,
since only the local best results are selected to the
next step. One idea to solve the problem is to allow
interactions among the local predictions of both
subtasks and jointly select an optimal assignment
to eliminate possible errors in the pipeline.
Let us first look at an example. Suppose we are
extracting knowledge facts from two sentences in
Figure 1: in sentence [1], if we are more confi-
dent to extract the relation fb:org.headquarters1,
we will be then prompted to select Bryant Univer-
sity, which indeed favors the RE prediction that
requires an organization to be its subject. On
the other side, if we are sure to link to Kobe
Bryant in sentence [2], we will probably select
fb:pro athlete.teams, whose subject position ex-
pects an athlete, e.g., an NBA player. It is not dif-
ficult to see that the argument type expectations of
relations can encourage the two subtasks interact
with each other and select coherent predictions for
</bodyText>
<footnote confidence="0.985871">
1The prefix fb means the relations are defined in Freebase.
</footnote>
<page confidence="0.888095">
1912
</page>
<note confidence="0.9909585">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1912–1923,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.990917">
Figure 1: Two example sentences from which we
can harvest knowledge facts.
</figureCaption>
<bodyText confidence="0.999849272727273">
both of them. In KBs with well-defined schemas,
such as Freebase, type requirements can be col-
lected and utilized explicitly (Yao et al., 2010).
However, in other KBs with less reliable or even
no schemas, it is more appropriate to implicitly
capture the type expectations for a given relation
(Riedel et al., 2013).
Furthermore, previous RE approaches usually
process each triple individually, which ignores
whether those local predictions are compatible
with each other. For example, suppose the local
predictions of the two sentences above are &lt;Kobe
Bryant, fb:org.headquarters, Smithfield, Rhode Is-
land&gt; and &lt;Kobe Bryant, fb:pro athlete.teams,
Los Angeles Lakers&gt;, respectively, which, in fact,
disagree with each other with respect to the KB,
since, in most cases, these two relations cannot
share subjects. Now we can see that either the re-
lation predictions or the EL results for “Bryant”
are incorrect. Those disagreements provide us an
effective way to remove the possible incorrect pre-
dictions that cause the incompatibilities.
On the other hand, the automatically extracted
knowledge facts inevitably contain errors, espe-
cially for those triples collected from open do-
main. Extractions with confidence scores will be
more than useful for users to make proper deci-
sions according to their requirements, such as trad-
ing recall for precision, or supporting approximate
queries.
In this paper, we propose a joint framework to
populate an existing KB with new knowledge facts
extracted from reliable text resources. The joint
framework is designed to address the error propa-
gation issue in a pipeline system, where subtasks
are optimized in isolation and locally. We find an
optimal configuration from top k results of both
subtasks, which maximizes the scores of each step,
fulfills the argument type expectations of relations,
which can be captured explicitly or implicitly, in
the KB, and avoids globally incoherent predic-
tions. We formulate this optimization problem in
an Integer Linear Program (ILP) framework, and
further adopt a logistic regression model to mea-
sure the reliability of the whole process, and assign
confidences to all extracted triples to facilitate fur-
ther applications. The experiments on a real-world
case study show that our framework can elimi-
nate error propagations in the pipeline systems by
taking relations’ argument type expectations and
global compatibilities into account, thus outper-
forms the pipeline approaches based on state-of-
the-art relation extractors by a large margin. Fur-
thermore, we investigate both explicit and implicit
type clues for relations, and provide suggestions
about which to choose according to the character-
istics of existing KBs. Additionally, our proposed
confidence estimations can help to achieve a pre-
cision of over 85% for a considerable amount of
high quality extractions.
In the rest of the paper, we first review related
work and then define the knowledge base popula-
tion task that we will address in this paper. Next
we detail the proposed framework and present our
experiments and results. Finally, we conclude this
paper with future directions.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.981236380952381">
Knowledge base population (KBP), the task of ex-
tending existing KBs with entities and relations,
has been studied in the TAC-KBP evaluations (Ji et
al., 2011), containing three tasks. The entity link-
ing task links entity mentions to existing KB nodes
and creates new nodes for the entities absent in the
current KBs, which can be considered as a kind
of entity population (Dredze et al., 2010; Tamang
et al., 2012; Cassidy et al., 2011). The slot-filling
task populates new relations to the KB (Tamang
et al., 2012; Roth et al., 2012; Liu and Zhao,
2012), but the relations are limited to a predefined
sets of attributes according to the types of enti-
ties. In contrast, our RE models only require min-
imal supervision and do not need well-annotated
training data. Our framework is therefore easy to
adapt to new scenarios and suits real-world appli-
cations. The cold-start task aims at constructing a
KB from scratch in a slot-filling style (Sun et al.,
2012; Monahan and Carpenter, 2012).
Entity linking is a crucial part in many KB re-
</bodyText>
<figure confidence="0.97876675">
Sentence 2 : ... Shaq and [Bryant] led the [Lakers] to three consecutive championships ...
Sentence 1: ... [Bryant] is a private university located in [Smithfield]. ...
Bryant University
Bryant University
Bryant, Illinois
Kobe Bryant
Bryant, Illinois
Kobe Bryant
...
...
fb:business.board_member.leader_of
fb:people.person.place_of_birth
fb:sports.pro_athlete.teams
fb:org.org.headquarters
Smithfield, Rhode Island
Smithfield, Illinois
Los Angeles Lakers
Laguna Lakers
...
...
</figure>
<page confidence="0.976843">
1913
</page>
<bodyText confidence="0.999957513888889">
lated tasks. Many EL models explore local con-
texts of entity mentions to measure the similarity
between mentions and candidate entities (Han et
al., 2011; Han and Sun, 2011; Ratinov et al., 2011;
Cheng and Roth, 2013). Some methods further ex-
ploit global coherence among candidate entities in
the same document by assuming that these enti-
ties should be closely related (Han et al., 2011;
Ratinov et al., 2011; Sen, 2012; Cheng and Roth,
2013). There are also some approaches regarding
entity linking as a ranking task (Zhou et al., 2010;
Chen and Ji, 2011). Lin et al. (2012) propose an
approach to detect and type entities that are cur-
rently not in the KB.
Note that the EL task in KBP is different from
the name entity mention extraction task, mainly
in the ACE task style, which mainly identifies the
boundaries and types of entity mentions and does
not explicitly link entity mentions into a KB (ACE,
2004; Florian et al., 2006; Florian et al., 2010; Li
and Ji, 2014), thus are different from our work.
Meanwhile, relation extraction has also been
studied extensively in recent years, ranging from
supervised learning methods (ACE, 2004; Zhao
and Grishman, 2005; Li and Ji, 2014) to unsuper-
vised open extractions (Fader et al., 2011; Carl-
son et al., 2010). There are also models, with dis-
tant supervision (DS), utilizing reliable texts re-
sources and existing KBs to predict relations for a
large amount of texts (Mintz et al., 2009; Riedel et
al., 2010; Hoffmann et al., 2011; Surdeanu et al.,
2012). These distantly supervised models can ex-
tract relations from texts in open domain, and do
not need much human involvement. Hence, DS is
more suitable for our task compared to other tradi-
tional RE approaches.
Joint inference over multiple local models has
been applied to many NLP tasks. Our task is dif-
ferent from the traditional joint IE works based in
the ACE framework (Singh et al., 2013; Li and
Ji, 2014; Kate and Mooney, 2010), which jointly
extract and/or classify named entity mentions to
several predefined types in a sentence and iden-
tify in a sentence level which relation this specific
sentence describes (between a pair of entity men-
tions in this sentence). Li and Ji (2014) follow
the ACE task definitions and present a neat incre-
mental joint framework to simultaneously extract
entity mentions and relations by structure percep-
tron. In contrast, we link entity mentions from a
text corpus to their corresponding entities in an ex-
isting KB and identify the relations between pairs
of entities based on that text corpus. Choi et al.
(2006) jointly extracts the expressions and sources
of opinion as well as the linking relations (i.e., a
source entity expresses an opinion expression) be-
tween them, while we focus on jointly modeling
EL and RE in open domain, which is a different
and challenging task.
Since the automatically extracted knowledge
facts inevitably contain errors, many approaches
manage to assign confidences for those extracted
facts (Fader et al., 2011; Wick et al., 2013). Wick
et al. (2013) also point out that confidence estima-
tion should be a crucial part in the automated KB
constructions and will play a key role for the wide
applications of automatically built KBs. We thus
propose to model the reliability of the complete
extraction process and take the argument type ex-
pectations of the relation, coherence with other
predictions and the triples in the existing KB into
account for each populated triple.
</bodyText>
<sectionHeader confidence="0.987686" genericHeader="method">
3 Task definition
</sectionHeader>
<bodyText confidence="0.999950153846154">
We formalize our task as follows. Given a set
of entities sampled from an existing KB, E =
{e1, e2, ..., e|E|}, a set of canonicalized relations
from the same KB, R = {r1, r2, ..., r|R|}, a set
of sentences extracted from news corpus, SN =
{sn1, sn2, ..., sn|SN|}, each contains two men-
tions m1 and m2 whose candidate entities belong
to E, a set of text fragments T = {t1, t2, ..., t|T |},
where ti contains its corresponding target sentence
sni and acts as its context. Our task is to link those
mentions to entities in the given KB, identify the
relationship between entity pairs and populate new
knowledge facts into the KB.
</bodyText>
<sectionHeader confidence="0.996347" genericHeader="method">
4 The Framework
</sectionHeader>
<bodyText confidence="0.999922153846154">
We propose to perform joint inference over sub-
tasks involved. For each sentence with two entity
mentions, we first employ a preliminary EL model
and RE model to obtain entity candidates and pos-
sible relation candidates between the two men-
tions, respectively. Our joint inference framework
will then find an optimal assignment by taking the
preliminary prediction scores, the argument type
expectations of relations and the global compati-
bilities among the predictions into account. In the
task of KBP, an entity pair may appear in multiple
sentences as different relation instances, and the
crucial point is whether we can identify all the cor-
</bodyText>
<page confidence="0.983367">
1914
</page>
<figure confidence="0.917466111111111">
Sentence 1: ••- [Bryant] is a private university located in [Smithfield]. ••-
Smithfield, Rhode Island
Kobe Bryant
Disagreement!
Los Angeles Lakers
Bryant University
Bryant, Illinois
...
...
</figure>
<figureCaption confidence="0.9126485">
Sentence 2: ••- Shaq and [Bryant] led the [Lakers] to three consecutive
championships from 2000 to 2002. ••-
Figure 2: An example of our joint inference framework. The top and bottom are two example sentences
with entity mentions in the square brackets, candidate entities in the white boxes, candidate relations in
the grey boxes, and the solid lines with arrows between relations and entities represent their preference
scores, with thickness indicating the preferences’ value.
</figureCaption>
<figure confidence="0.999015727272727">
Bryant University
Bryant, Illinois
Kobe Bryant
...
fb:people.place_of_birth
fb:business.leader_of
fb:pro_athlete.teams
fb:org.headquarters
Smithfield, Illinois
Laguna Lakers
...
</figure>
<bodyText confidence="0.999289166666667">
rect relations for an entity pair. Thus, after finding
an optimal sentence-level assignment, we aggre-
gate those local predictions by ORing them into
the entity pair level. Finally, we employ a regres-
sion model to capture the reliability of the com-
plete extraction process.
</bodyText>
<subsectionHeader confidence="0.987162">
4.1 Preliminary Models
</subsectionHeader>
<bodyText confidence="0.99975435483871">
Entity Linking The preliminary EL model can
be any approach which outputs a score for each
entity candidate. Note that a recall-oriented model
will be more than welcome, since we expect to in-
troduce more potentially correct local predictions
into the inference step. In this paper, we adopt
an unsupervised approach in (Han et al., 2011)
to avoid preparing training data. Note the chal-
lenging NIL problem, i.e., identifying which en-
tity mentions do not have corresponding entities
in the KB (labeled as NIL) and clustering those
mentions, will be our future work. For each men-
tion we retain the entities with top p scores for the
succeeding inference step.
Relation Extraction The choice of RE model is
also broad. Any sentence level extractor whose
results are easy to be aggregated to entity pair
level can be utilized here (again, a recall-oriented
version will be welcome), such as Mintz++ men-
tioned in (Surdeanu et al., 2012), which we adapt
into a Maximum Entropy version. We also include
a special label, NA, to represent the case where
there is no predefined relationship between an en-
tity pair. For each sentence, we retain the relations
with top q scores for the inference step, and we
also call that this sentence supports those candi-
date relations. As for the features of RE models,
we use the same features (lexical features and syn-
tactic features) with the previous works (Chen et
al., 2014; Mintz et al., 2009; Riedel et al., 2010;
Hoffmann et al., 2011).
</bodyText>
<subsectionHeader confidence="0.961644">
4.2 Relations’ Expectations for Argument
Types
</subsectionHeader>
<bodyText confidence="0.9998315">
In most KBs’ schemas, canonicalized relations are
designed to expect specific types of entities to be
their arguments. For example, in Figure 2, it is
more likely that an entity Kobe Bryant takes the
subject position of a relation fb:pro athlete.teams,
but it is unlikely for this entity to take the subject
position of a relation fb:org.headquarters. Making
use of these type requirements can encourage the
framework to select relation and entity candidates
which are coherent with each other, and discard
incoherent choices.
In order to obtain the preference scores between
</bodyText>
<page confidence="0.965794">
1915
</page>
<bodyText confidence="0.9999662">
the entities in E and the relations in R, we gener-
ate two matrices with JEJ rows and JR1 columns,
whose elements spij indicates the preference score
of entity i and relation j. The matrix 5subj is for
relations and their subjects, and the matrix 5obj is
for relations and their objects. We initialize the
two matrices using the KB as follows: for entity i
and relation j, if relation j takes entity i as its sub-
ject/object in the KB, the element at the position
(i, j) of the corresponding matrix will be 1, oth-
erwise it will be 0. Note that in our experiments,
we do not count the triples that are evaluated in the
testing data, to build the matrices. Now the prob-
lem is how we can obtain the unknown elements
in the matrices.
Explicit Type Information Intuitively, we
should examine whether the explicit types of the
entities fulfill the expectations of relations in the
KB. For each unknown element 5subj(i, j), we
first obtain the type of entity i, which is collected
from the lowest level of the KB’s type hierarchy,
and examine whether there is another entity
with the same type taking the subject position
of relation j in the initial matrix. If such an
entity exists, 5subj(i, j) = 1, otherwise 0. For
example, for the subject Jay Fletcher Vincent and
the relation fb:pro athlete.teams, we first obtain
the subject’s type basketball player, and then we
go through the initial matrix and find another
entity Kobe Bryant with the same type taking
the subject position of fb:pro athlete.teams,
indicating that Jay Fletcher Vincent may take the
relation fb:pro athlete.teams. The matrix 5obj is
processed in the same way.
Implicit Type Expectations In practice, few
KBs have well-defined schemas. In order to make
our framework more flexible, we need to come up
with an approach to implicitly capture the rela-
tions’ type expectations, which will also be rep-
resented as preference scores.
Inspired by Riedel et al. (2013) who use a ma-
trix factorization approach to capture the associa-
tion between textual patterns, relations and entities
based on large text corpora, we adopt a collabora-
tive filtering (CF) method to compute the prefer-
ence scores between entities and relations based
on the statistics obtained from an existing KB.
In CF, the preferences between customers and
items are calculated via matrix factorization over
the initial customer-item matrix. In our frame-
work, we compute the preference scores between
entities and relations via the same approach over
the two initialized matrices 5subj and 5obj, re-
sulting in two entity-relation matrices with esti-
mated preference values. We use ALS-WR (Zhou
et al., 2008) to process the matrices and compute
the preference of a relation taking an entity as its
subject and object, respectively. We normalize the
preference scores of each entity using their means
µ and standard deviations Q.
</bodyText>
<subsectionHeader confidence="0.997164">
4.3 Compatibilities among Predicted Triples
</subsectionHeader>
<bodyText confidence="0.999969457142857">
The second aspect we investigate is whether the
extracted triples are compatible with respect to all
other knowledge facts. For example, according to
the KB, the two relations fb:org.headquarters and
fb:pro athlete.teams in Figure 2 cannot share the
same entity as their subjects. So if such sharing
happens, that will indicate either the predictions
of the relations or the entities are incorrect. The
clues can be roughly grouped into three categories,
namely whether two relations can share the same
subjects, whether two relations can share the same
objects, and whether one relation’s subject can be
the other relation’s object.
Global compatibilities among local predictions
have been investigated by several joint models (Li
et al., 2011; Li and Ji, 2014; Chen et al., 2014) to
eliminate the errors propagating in a pipeline sys-
tem. Specifically, Chen et al. (2014) utilized the
clues with respect to the compatibilities of rela-
tions in the task of relation extraction. Following
(Li et al., 2011; Chen et al., 2014), we extend the
idea of global compatibilities to the entity and re-
lation predictions during knowledge base popula-
tion. We examine the pointwise mutual informa-
tion (PMI) between the argument sets of two re-
lations to collect such clues. For example, if we
want to learn whether two relations can share the
same subject, we first collect the subject sets of
both relations from the KB, and then compute the
PMI value between them. If the value is lower
than a certain threshold (set to -3 in this paper), the
clue that the two relations cannot share the same
subject is added. These clues can be easily inte-
grated into an optimization framework in the form
of constraints.
</bodyText>
<subsectionHeader confidence="0.974965">
4.4 Integer Linear Program Formulation
</subsectionHeader>
<bodyText confidence="0.999735333333333">
Now we describe how we aggregate the above
components, and formulate the joint inference
problem into an ILP framework. For each candi-
</bodyText>
<page confidence="0.973466">
1916
</page>
<bodyText confidence="0.997510724137931">
date entity e of mention m in text fragment t, we
define a boolean decision variable dm,e
t , which de-
notes whether this entity is selected into the final
configuration or not. Similarly, for each candidate
relation r of fragment t, we define a boolean de-
cision variable drt . In order to introduce the pref-
erence scores into the model, we also need a deci-
sion variable dr,m,e
t , which denotes whether both
relation r and candidate entity e of mention m are
selected in t.
We use st,m,e
el to represent the score of mention
m in t disambiguated to entity e, which is output
by the EL model, st,r
re representing the score of re-
lation r assigned to t, which is output by the RE
model, sr,e
p the explicit/implicit preference score
between relation r and entity e.
Our goal is to find the best assignment to the
variables drt and dm,e
t , such that it maximizes the
overall scores of the two subtasks and the co-
herence among the preliminary predictions, while
satisfying the constraints between the predicted
triples as well. Our objective function can be writ-
ten as:
</bodyText>
<equation confidence="0.763402">
max el × confent + re × confrel + sp × cohe−r
(1)
</equation>
<bodyText confidence="0.987498142857143">
where el, re and sp are three weighting parameters
tuned on development set. confent is the overall
score of entity linking:
sem,edt ,e (2)
where M(t) is the set of mentions in t, Ce(m) is
the candidate entity set of the mention m. confrel
represents the overall score of relation extraction:
</bodyText>
<equation confidence="0.951823333333333">
st,r
re dr (3)
t
</equation>
<bodyText confidence="0.999843">
where Cr(t) is the set of candidate relations in t.
cohe−r is the coherence between the candidate re-
lations and entities in the framework:
</bodyText>
<equation confidence="0.9942315">
Xcohe−r =
t
</equation>
<bodyText confidence="0.999411">
Now we describe the constraints used in our ILP
problem. The first kind of constraints is intro-
duced to ensure that each mention should be dis-
ambiguated to only one entity:
</bodyText>
<equation confidence="0.974711333333333">
∀t, ∀m ∈ M(t), X dm,e
t ≤ 1 (5)
eECe(m)
</equation>
<bodyText confidence="0.994858666666667">
The second type of constraints ensure that each en-
tity mention pair in one sentence can only take one
relation label:
</bodyText>
<equation confidence="0.997788">
∀t, X dtr ≤ 1 (6)
rECr(t)
</equation>
<bodyText confidence="0.61591575">
The third is introduced to ensure the decision vari-
abledr,m,e
t equals 1 if and only if both the corre-
sponding variables drt and dm,e
</bodyText>
<equation confidence="0.9977944">
t equal 1.
∀t, ∀r ∈ Cr(t), ∀m ∈ M(t), ∀e ∈ Ce(m)
dr,m,e
t ≤ drt (7)
dr,m,e
t ≤ dm,e
t (8)
drt + dm,e
t ≤ dr,m,e
t + 1 (9)
</equation>
<bodyText confidence="0.999254888888889">
As for the compatibility constraints, we need to
introduce another type of boolean decision vari-
ables. If a mention m1 in t1 and another mention
m2 in t2 share an entity candidate e, we add a vari-
able y for this mention pair, which equals 1 if and
only if both dm1,e t1and dm2,e
t2 equal 1. So we add
the following constraints for each mention pair m1
and m2 satisfies the previous condition:
</bodyText>
<equation confidence="0.998944">
y ≤ dm1,e (10)
t1
y ≤ dm2,e (11)
t2
dm1,e t1+ dm2,e
t2 ≤ y + 1 (12)
</equation>
<bodyText confidence="0.998277333333333">
Then we further add the following constraints for
each mention pair to avoid incompatible predic-
tions:
</bodyText>
<equation confidence="0.999288846153846">
∀r1 ∈ Cr(t1), r2 ∈ Cr(t2)
If (r1, r2) ∈ Csr, p(m1) = subj, p(m2) = subj
dr1
t1 + dr2
t2 + y ≤ 2 (13)
If (r1, r2) ∈ Cro, p(m1) = obj, p(m2) = obj
dr1
t1 + dr2
t2 + y ≤ 2(14)
If (r1, r2) ∈ Csro, p(m1) = obj, p(m2) = subj
dr1
t1 + dr2
t2 + y ≤ 2(15)
</equation>
<bodyText confidence="0.997979333333333">
where p(m) returns the position of mention m, ei-
ther subj (subject) or obj (object). Csr is the pairs
of relations which cannot share the same subject,
Cro is the pairs of relations which cannot share the
same object, Csro is the pairs of relations in which
one relation’s subject cannot be the other one’s ob-
ject.
We use IBM ILOG Cplex2 to solve the above
ILP problem.
</bodyText>
<footnote confidence="0.835332">
2http://www.cplex.com
</footnote>
<equation confidence="0.999876833333333">
Xconfent = X X
t mEM(t) eECe(m)
Xconfrel = X
t rECr(t)
X X X sr,epdtr,m,e (4)
rECr(t) mEM(t) eECe(m)
</equation>
<page confidence="0.995933">
1917
</page>
<tableCaption confidence="0.977287">
Table 1: The features used to calculate the confi-
dence scores.
</tableCaption>
<figureCaption confidence="0.861974882352941">
Type Feature
Real The RE score of the relation.
Real The EL score of the subject.
Real The EL score of the object.
Real The preference score between the relation
and the subject.
Real The preference score between the relation
and the object.
Real The ratio of the highest and the second highest
relation score in this entity pair.
Real The ratio of the current relation score and the
maximum relation score in this entity pair.
Real The ratio of the number of sentences supporting
the current relation and the total number
of sentences in this entity pair.
Real Whether the extracted triple is coherent with the KB
according to the constraints in Section 4.3.
</figureCaption>
<subsectionHeader confidence="0.8812145">
4.5 Confidence Estimation for Extracted
Triples
</subsectionHeader>
<bodyText confidence="0.999982117647059">
The automatically extracted triples inevitably con-
tain errors and are often considered as with high
recall but low precision. Since our aim is to pop-
ulate the extracted triples into an existing KB,
which requires highly reliable knowledge facts,
we need a measure of confidence for those ex-
tracted triples, so that others can properly utilize
them.
Here, we use a logistic regression model to mea-
sure the reliability of the process, how the entities
are disambiguated, how the relationships are iden-
tified, and whether those predictions are compat-
ible. The features we used are listed in Table 1,
which are all efficiently computable and indepen-
dent from specific relations or entities. We manu-
ally annotate 1000 triples as correct or incorrect to
prepare the training data.
</bodyText>
<sectionHeader confidence="0.999646" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999622">
We evaluate the proposed framework in a real-
world scenario: given a set of news texts with en-
tity mentions and a KB, a model should find more
and accurate new knowledge facts between pairs
of those entities.
</bodyText>
<subsectionHeader confidence="0.889491">
5.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999995541666667">
We use New York Times dataset from 2005 to
2007 as the text corpus, and Freebase as the KB.
We divide the corpus into two equal parts, one for
creating training data for the RE models using the
distant supervision strategy (we do not need train-
ing data for EL), and the other as the testing data.
For the convenience of experimentation, we ran-
domly sample a subset of entities for testing. We
first collect all sentences containing two mentions
which may refer to the sampled entities, and prune
them according to: (1)there should be no more
than 10 words between the two mentions; (2)the
prior probability of the mention referring to the
target entity is higher than a threshold (set to 0.1
in this paper), which is set to filter the impossi-
ble mappings; (3)the mention pairs should not be-
long to different clauses. The resulting test set is
split into 10 parts and a development set, each with
3500 entity pairs roughly, which leads to averagely
200,000 variables and 900,000 constraints per split
and may take 1 hour for Cplex to solve. Note that
we do not count the triples that will be evaluated
in the testing data when we learn the preferences
and the clues from the KB.
</bodyText>
<subsectionHeader confidence="0.984552">
5.2 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.99998035483871">
We compare our framework with three baselines.
The first one, ME-pl, is the pipeline system con-
structed by the entity linker in (Han et al., 2011)
and the MaxEnt version of Mintz++ extractor
mentioned in (Surdeanu et al., 2012). The sec-
ond and third baselines are the pipeline systems
constructed by the same linker and two state-of-
the-art DS approaches, MultiR (Hoffmann et al.,
2011) and MIML-RE (Surdeanu et al., 2012), re-
spectively. They are referred to as MultiR-pl and
MIML-pl in the rest of this paper.
We also implement several variants of our
framework to investigate the following two com-
ponents in our framework: whether to use ex-
plicit (E) or implicit (I) argument type expecta-
tions, whether to take global (G) compatibilities
into account, resulting in four variants: ME-JE,
ME-JI, ME-JEG, ME-JIG.
We tune the parameters in the objective func-
tion on the development set to be re = 1, el = 4,
sp = 1. The numbers of preliminary results re-
tained to the inference step are set to p = 2, q = 3.
Three metrics used in our experiments include:
(1)the precision of extracted triples, which is the
ratio of the number of correct triples and the num-
ber of total extracted triples; (2)the number of cor-
rect triples (NoC); (3)the number of correct triples
in the results ranked in top n. The third metric
is crucial for KBP, since most users are only in-
terested in the knowledge facts with high confi-
dences. We compare the extracted triples against
</bodyText>
<page confidence="0.998373">
1918
</page>
<tableCaption confidence="0.77497">
Table 2: The results of our joint frameworks and
the three baselines.
</tableCaption>
<table confidence="0.99983975">
Approach Precision NoC Top 50 Top 100
ME-pl 28.7 ± 0.8 725 ± 12 38 ± 2 75 ± 4
MultiR-pl 31.0 ± 0.8 647 ± 15 39 ± 2 71 ± 3
MIML-pl 33.2 ± 0.6 608 ± 16 40 ± 3 74 ± 5
ME-JE 32.8 ± 0.7 768 ± 10 46 ± 2 90 ± 3
ME-JEG 34.2 ± 0.5 757 ± 8 46 ± 2 90 ± 3
ME-JI 34.5 ± 1.0 784 ± 9 43 ± 3 88 ± 3
ME-JIG 35.7 ± 1.0 772 ± 8 43 ± 3 88 ± 4
</table>
<bodyText confidence="0.999859">
Freebase to compute the precision, which may un-
derestimate the performance since Freebase is in-
complete. Since we do not have exact annotations
for the EL, it is difficult to calculate the exact re-
call. We therefore use NoC instead. We evalu-
ate our framework on the 10 subsets of the testing
dataset and compute their means and standard de-
viations.
</bodyText>
<subsectionHeader confidence="0.998352">
5.3 Overall Performance
</subsectionHeader>
<bodyText confidence="0.99977284375">
We are interested to find out: (a)whether the task
benefits from the joint inference i.e., can we col-
lect more and correct facts? Or with a higher pre-
cision? (b) whether the argument type expecta-
tions (explicit and implicit) and global compati-
bility do their jobs as we expected? And, how do
we choose from these components ? (c)whether
the framework can work with other RE models?
(d)whether we can find a suitable approach to
measure the confidence or uncertainty during the
extraction so that users or other applications can
better utilize the extracted KB facts?
Let us first look at the performance of the
baselines and our framework in Table 2 for an
overview. Comparing the three pipeline sys-
tems, we can discover that using the same en-
tity linker, MIML-pl performs the best in precision
with slightly fewer correct triples, while ME-pl
performs the worst. It is not surprising, ME-pl, as
a strong and high-recall baseline, outputs the most
correct triples. As for the results with high confi-
dences, MultiR-pl outputs more correct triples in
the top 50 results than ME-pl, and MIML-pl per-
forms better or comparable than ME-pl in top n
results.
After performing the joint inference, ME-JE
improves ME-pl with 4.1% in precision and 43
more correct triples averagely, and results in bet-
ter performance in top n results. By taking global
compatibilities into consideration, ME-JEG fur-
ther improve the precision to 34.2% in average
with slightly fewer correct triples, indicating that
</bodyText>
<figureCaption confidence="0.6259195">
Figure 3: The numbers of correct triples v.s. the
precisions for different approaches.
</figureCaption>
<bodyText confidence="0.999642342857143">
both argument type expectations and global com-
patibilities are useful in improving the perfor-
mance: argument type information can help to
select the correct and coherent predictions from
the candidates EL and RE outputs, while global
compatibilities can further prune incorrect triples
that cause disagreements, although a few correct
ones may be incorrectly eliminated. We can also
observe that ME-JIG performs even higher than
ME-JEG in overall precision, but ME-JEG col-
lects more correct triples than ME-JIG in the top
n predictions, showing that explicit type expec-
tations with more accurate type information may
perform better in high confidence results.
Furthermore, even though MultiR-pl and
MIML-pl are based on state-of-the-art RE ap-
proaches, our model (for example, ME-JIG) can
still outperform them in terms of all metrics, with
4.7% higher in precision than MultiR-pl, 2.5%
higher than MIML-pl. Our model can extract 125
more correct triples than MultiR-pl, 164 more
than MIML-pl, and perform better in top n results
as well.
In previous RE tasks, Precision-Recall curves
are mostly used to evaluate the systems’ perfor-
mances. In our task, since it is difficult to calculate
the recall exactly, we use the number of correct
triples instead, and plot curves of Precision-NoC
to show the performance of the competitors and
our approaches in more detail. For each value of
NoC, the precision is the average of the ten splits
of the testing dataset.
As shown in Figure 3, our approaches (ME-JEG
and ME-JIG) obtain higher precisions on each
NoC value, and the curves are much smoother than
</bodyText>
<page confidence="0.998986">
1919
</page>
<tableCaption confidence="0.998721">
Table 3: The results of our joint frameworks with
</tableCaption>
<table confidence="0.8994418">
MultiR sentence extractor.
Approach Precision NoC Top 50 Top 100
MultiR-pl 31.0 ± 0.8 647 ± 15 39 ± 2 71 ± 3
MultiR-JEG 36.9 ± 0.8 687 ± 15 46 ± 2 88 ± 3
MultiR-JIG 38.5 ± 0.9 700 ± 15 45 ± 2 88 ± 3
</table>
<bodyText confidence="0.99914625">
the pipeline systems, indicating that our frame-
work is more suitable for harvesting high quality
knowledge facts. Comparing the two kinds of type
clues, we can see that explicit ones perform better
when the confidence control is high and the num-
ber of correct triples is small, and then the two are
comparable. Since the precision of the triples with
high confidences is crucial for the task of KBP,
we still suggest choosing the explicit ones when
there is a well-defined schema available in the KB,
although implicit type expectations can result in
higher overall precision.
</bodyText>
<subsectionHeader confidence="0.9924725">
5.4 Adapting MultiR Sentence Extractor into
the Framework
</subsectionHeader>
<bodyText confidence="0.99960425">
The preliminary relation extractor of our frame-
work is not limited to the MaxEnt3 extractor. It
can be any sentence level recall-oriented relation
extractors. To further investigate the generaliza-
tion of our joint inference framework, we also
try to fit other sentence level relation extractors
into the framework. Considering that MIML-RE
does not output sentence-level results, we only
adapt MultiR, with both global compatibilities
and explicit/implicit type expectations, named as
MultiR-JEG and MultiR-JIG, respectively. Since
the scores output by the original MultiR are un-
normalized, which are difficult to directly apply to
our framework, we normalize their scores and re-
tune the framework’s parameters accordingly. The
parameters are set to re = 1, el = 32, sp = 16.
As seen in Table 3, MultiR-JEG helps MultiR
obtain about 40 more correct triples in average,
and achieves 5.9% higher in precision, as well
as significant improvements in top n correct pre-
dictions. As for MultiR-JIG, the improvements
are 7.5% in precision and 53 in number of cor-
rect triples. In terms of top n results, the explicit
and implicit type expectations perform compara-
ble. We also observe that our framework improves
MultiR as much as it does to MaxEnt, indicating
our joint framework can generalize well in differ-
ent RE models.
</bodyText>
<footnote confidence="0.9931795">
3http://homepages.inf.ed.ac.uk/
lzhang10/maxent_toolkit.html
</footnote>
<figureCaption confidence="0.9618655">
Figure 4: The numbers of correct triples v.s. the
precisions for approaches with MultiR extractor.
</figureCaption>
<figure confidence="0.885706">
Confidence Threshold
</figure>
<figureCaption confidence="0.966143">
Figure 5: The precisions of different models un-
</figureCaption>
<bodyText confidence="0.895349555555556">
der different confidence thresholds. The error bars
represents the standard deviations of the results.
We further plot Precision-NoC curves for
MultiR-JEG and MultiR-JIG in Figure 4, show-
ing that our framework can result in better perfor-
mance and smoother curves with MultiR extractor.
It is interesting to see that with MultiR extractor,
the two kinds of expectations perform comparably.
n
</bodyText>
<sectionHeader confidence="0.381856" genericHeader="evaluation">
5.5 Results with Confidence Estimations
</sectionHeader>
<subsectionHeader confidence="0.567566">
Peci
</subsectionHeader>
<bodyText confidence="0.999892833333333">
Now, we will investigate the results from another
perspective with the help of confidence estima-
tions. We calculate the precisions of the competi-
tors and our approaches on different confidence
thresholds from 0.5 to 1. The results are summa-
rized in Figure 5. Note that the results across dif-
ferent approaches are not directly comparable, we
put them in the same figure only to save space.
In Figure 5, intuitively, as the confidence thresh-
old goes up, the extraction precisions should
increase, indicating triples with higher confi-
dences are more likely to be correct. However,
</bodyText>
<figure confidence="0.9996054375">
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
M
M
M
M
MI
M
M
0.5 0.6 0.7 0.8
</figure>
<page confidence="0.939794">
1920
</page>
<bodyText confidence="0.999943411764706">
lower thresholds tend to result in estimations with
smaller standard derivations due to those preci-
sions are estimated over much more triples than
those with higher thresholds, which means the ran-
domness will be smaller.
On the other hand, our joint frameworks pro-
vide more evidences that can be used to well cap-
ture the reliability of an extraction. For example,
the precisions of Multir-JIG and ME-JIG both stay
around 85% when the confidence is higher than
0.85, with about 120 correct triples, indicating that
by setting a proper threshold, we can obtain con-
siderable amount of high quality knowledge facts
at an acceptable precision, which is crucial for
KBP. However, we cannot harvest such amount of
high quality knowledge facts from the other three
pipeline systems.
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999987714285714">
In this paper, we propose a joint framework for the
task of populating KBs with new knowledge facts,
which performs joint inference on two subtasks,
maximizes their preliminary scores, fulfills the
type expectations of relations and avoids global
incompatibilities with respect to all local predic-
tions to find an optimal assignment. Experimen-
tal results show that our framework can signifi-
cantly eliminate the error propagations in pipeline
systems and outperforms competitive pipeline sys-
tems with state-of-the-art RE models. Regard-
ing the explicit argument type expectations and
the implicit ones, the latter can result in a higher
overall precision, while the former performs bet-
ter in acquiring high quality knowledge facts with
higher confidence control, indicating that if the
KB has a well-defined schema we can use explicit
type requirements for the KBP task, and if not,
our model can still perform well by mining the
implicit ones. Our framework can also generalize
well with other preliminary RE models. Further-
more, we assign extraction confidences to all ex-
tracted facts to facilitate further applications. By
setting a suitable threshold, our framework can
populate high quality reliable knowledge facts to
existing KBs.
For future work, we will address the NIL is-
sue of EL where we currently assume all entities
should be linked to a KB. It would be also inter-
esting to jointly model the two subtasks through
structured learning, instead of joint inference only.
Currently we only use the coherence of extracted
triples and the KB to estimate confidences, which
would be nice to directly model the issue in a joint
model.
</bodyText>
<sectionHeader confidence="0.997713" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997898363636364">
We would like to thank Heng Ji, Kun Xu, Dong
Wang and Junyang Rao for their helpful discus-
sions and the anonymous reviewers for their in-
sightful comments that improved the work consid-
erably. This work was supported by the National
High Technology R&amp;D Program of China (Grant
No. 2012AA011101, 2014AA015102), National
Natural Science Foundation of China (Grant No.
61272344, 61202233, 61370055) and the joint
project with IBM Research. Any correspondence
please refer to Yansong Feng.
</bodyText>
<sectionHeader confidence="0.999213" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997673545454545">
ACE. 2004. The automatic content extraction projects.
http://projects.ldc.upenn.edu/ace.
Andrew Carlson, Justin Betteridge, Byran Kisiel, Burr
Settles, Estevam Hruschka Jr., and Tom Mitchell.
2010. Toward an architecture for never-ending lan-
guage learning. In Proceedings of the Conference
on Artificial Intelligence (AAAI), pages 1306–1313.
AAAI Press.
Taylor Cassidy, Zheng Chen, Javier Artiles, Heng Ji,
Hongbo Deng, Lev-Arie Ratinov, Jing Zheng, Jiawei
Han, and Dan Roth. 2011. Entity linking system
description. In TAC2011.
Zheng Chen and Heng Ji. 2011. Collaborative rank-
ing: A case study on entity linking. In Proceedings
of the Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP ’11, pages 771–
781, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Liwei Chen, Yansong Feng, Songfang Huang, Yong
Qin, and Dongyan Zhao. 2014. Encoding relation
requirements for relation extraction via joint infer-
ence. In Proceedings of the 52nd Annual Meeting
on Association for Computational Linguistics, ACL
2014, pages 818–827, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Xiao Cheng and Dan Roth. 2013. Relational inference
for wikification. In EMNLP.
Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint
extraction of entities and relations for opinion recog-
nition. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ’06, pages 431–439, Stroudsburg, PA,
USA. Association for Computational Linguistics.
</reference>
<page confidence="0.946171">
1921
</page>
<reference confidence="0.999731776785715">
Mark Dredze, Paul McNamee, Delip Rao, Adam Ger-
ber, and Tim Finin. 2010. Entity disambiguation for
knowledge base population. In Coling2010.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’11, pages 1535–1545, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Radu Florian, Hongyan Jing, Nanda Kambhatla, and
Imed Zitouni. 2006. Factorizing complex mod-
els: A case study in mention detection. In Proceed-
ings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting
of the Association for Computational Linguistics,
pages 473–480. Association for Computational Lin-
guistics.
Radu Florian, John F Pitrelli, Salim Roukos, and Imed
Zitouni. 2010. Improving mention detection robust-
ness to noisy input. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Language
Processing, pages 335–345. Association for Com-
putational Linguistics.
Xianpei Han and Le Sun. 2011. A generative entity-
mention model for linking entities with knowledge
base. In Proceedings of ACL, HLT ’11, pages 945–
954, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective
entity linking in web text: a graph-based method. In
SIGIR, SIGIR ’11, pages 765–774, New York, NY,
USA. ACM.
Raphael Hoffmann, Congle Zhang, Xiao Ling,
Luke Zettlemoyer, and Daniel S. Weld. 2011.
Knowledge-based weak supervision for information
extraction of overlapping relations. In Proceedings
of the 49th ACL-HLT - Volume 1, HLT ’11, pages
541–550, Stroudsburg, PA, USA. ACL.
Heng Ji, Ralph Grishman, and Hoa Dang. 2011.
Overview of the tac2011 knowledge base population
track. In Proceedings of TAC.
Rohit J. Kate and Raymond J. Mooney. 2010. Joint
entity and relation extraction using card-pyramid
parsing. In Proceedings of the Fourteenth Confer-
ence on Computational Natural Language Learning,
CoNLL ’10, pages 203–212, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Qi Li and Heng Ji. 2014. Incremental joint extrac-
tion of entity mentions and relations. In Proceed-
ings of the 52nd Annual Meeting on Association for
Computational Linguistics, ACL 2014, pages 402–
412, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Qi Li, Sam Anzaroot, Wen-Pin Lin, Xiang Li, and
Heng Ji. 2011. Joint inference for cross-document
information extraction. In Proceedings of the 20th
ACM International Conference on Information and
Knowledge Management, CIKM ’11, pages 2225–
2228, New York, NY, USA. ACM.
Thomas Lin, Mausam, and Oren Etzioni. 2012.
No noun phrase left behind: Detecting and typ-
ing unlinkable entities. In Proceedings of the 2012
EMNLP-CoNLL, EMNLP-CoNLL ’12, pages 893–
903, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Fang Liu and Jun Zhao. 2012. Sweat2012: Pattern
based english slot filling system for knowledge base
population at tac 2012. In TAC2012.
Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th IJCNLP of the AFNLP: Volume 2 -
Volume 2, ACL ’09, pages 1003–1011.
Sean Monahan and Dean Carpenter. 2012. Lorify: A
knowledge base from scratch. In TAC2012.
Lev Ratinov, Dan Roth, Doug Downey, and Mike An-
derson. 2011. Local and global algorithms for dis-
ambiguation to wikipedia. In ACL.
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Machine Learning and Knowl-
edge Discovery in Databases, volume 6323 of Lec-
ture Notes in Computer Science, pages 148–163.
Springer Berlin / Heidelberg.
Sebastian Riedel, Limin Yao, Benjamin M. Marlin, and
Andrew McCallum. 2013. Relation extraction with
matrix factorization and universal schemas. In Joint
Human Language Technology Conference/Annual
Meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics (HLT-NAACL
’13), June.
Benjamin Roth, Grzegorz Chrupala, Michael Wiegand,
Mittul Singh, and Dietrich Klakow. 2012. General-
izing from freebase and patterns using cluster-based
distant supervision for tac kbp slotfilling 2012. In
TAC2012.
Prithviraj Sen. 2012. Collective context-aware topic
models for entity disambiguation. In Proceedings
of the 21st International Conference on World Wide
Web, WWW ’12, pages 729–738, New York, NY,
USA. ACM.
Sameer Singh, Sebastian Riedel, Brian Martin, Jiap-
ing Zheng, and Andrew McCallum. 2013. Joint
inference of entities, relations, and coreference. In
Proceedings of the 2013 Workshop on Automated
Knowledge Base Construction, AKBC ’13, pages 1–
6, New York, NY, USA. ACM.
Ang Sun, Xin Wang, Sen Xu, Yigit Kiran, Shakthi
Poornima, Andrew Borthwick, , and Ralph Grish-
man. 2012. Intelius-nyu tac-kbp2012 cold start sys-
tem. In TAC2012.
</reference>
<page confidence="0.890222">
1922
</page>
<reference confidence="0.999615861111111">
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallap-
ati, and Christopher D. Manning. 2012. Multi-
instance multi-label learning for relation extraction.
In EMNLP-CoNLL, pages 455–465. ACL.
Suzanne Tamang, Zheng Chen, and Heng Ji. 2012. En-
tity linking system and slot filling validation system.
In TAC2012.
Michael Wick, Sameer Singh, Ari Kobren, and Andrew
McCallum. 2013. Assessing confidence of knowl-
edge base content with an experimental study in en-
tity resolution. In AKBC2013.
Limin Yao, Sebastian Riedel, and Andrew McCallum.
2010. Collective cross-document relation extraction
without labelled data. In Proceedings of EMNLP,
EMNLP ’10, pages 1013–1023, Stroudsburg, PA,
USA. ACL.
Shubin Zhao and Ralph Grishman. 2005. Extracting
relations with integrated information using kernel
methods. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
ACL ’05, pages 419–426, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Yunhong Zhou, Dennis Wilkinson, Robert Schreiber,
and Rong Pan. 2008. Large-scale parallel collabo-
rative filtering for the netflix prize. In Proceedings
of the 4th International Conference on Algorithmic
Aspects in Information and Management, AAIM
’08, pages 337–348, Berlin, Heidelberg. Springer-
Verlag.
Yiping Zhou, Lan Nie, Omid Rouhani-Kalleh, Fla-
vian Vasile, and Scott Gaffney. 2010. Resolving
surface forms to wikipedia topics. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics, COLING ’10, pages 1335–1343,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.96824">
1923
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.483239">
<title confidence="0.998697">Joint Inference for Knowledge Base Population</title>
<author confidence="0.996117">Yansong Feng Jinghui Songfang</author>
<affiliation confidence="0.999971">Peking University, Beijing,</affiliation>
<address confidence="0.493621">China Research Lab, Beijing,</address>
<email confidence="0.999734">huangsf@cn.ibm.com</email>
<abstract confidence="0.999388615384615">Populating Knowledge Base (KB) with new knowledge facts from reliable text resources usually consists of linking name mentions to KB entities and identifying relationship between entity pairs. However, the task often suffers from errors propagating from upstream entity linkers to downstream relation extractors. In this paper, we propose a novel joint inference framework to allow interactions between the two subtasks and find an optimal assignment by addressing the coherence among preliminary local predictions: whether the types of entities meet the expectations of relations explicitly or implicitly, and whether the local predictions are globally compatible. We further measure the confidence of the extracted triples by looking at the details of the complete extraction process. Experiments show that the proposed framework can significantly reduce the error propagations thus obtain more reliable facts, and outperforms competitive baselines with state-of-the-art relation extraction models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>ACE</author>
</authors>
<title>The automatic content extraction projects.</title>
<date>2004</date>
<note>http://projects.ldc.upenn.edu/ace.</note>
<contexts>
<context position="9816" citStr="ACE, 2004" startWordPosition="1538" endWordPosition="1539">e document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). Thes</context>
</contexts>
<marker>ACE, 2004</marker>
<rawString>ACE. 2004. The automatic content extraction projects. http://projects.ldc.upenn.edu/ace.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Byran Kisiel</author>
<author>Burr Settles</author>
<author>Estevam Hruschka Jr</author>
<author>Tom Mitchell</author>
</authors>
<title>Toward an architecture for never-ending language learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>1306--1313</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="10166" citStr="Carlson et al., 2010" startWordPosition="1593" endWordPosition="1597">ntly not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in </context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Byran Kisiel, Burr Settles, Estevam Hruschka Jr., and Tom Mitchell. 2010. Toward an architecture for never-ending language learning. In Proceedings of the Conference on Artificial Intelligence (AAAI), pages 1306–1313. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Cassidy</author>
<author>Zheng Chen</author>
<author>Javier Artiles</author>
<author>Heng Ji</author>
<author>Hongbo Deng</author>
<author>Lev-Arie Ratinov</author>
<author>Jing Zheng</author>
<author>Jiawei Han</author>
<author>Dan Roth</author>
</authors>
<title>Entity linking system description.</title>
<date>2011</date>
<booktitle>In TAC2011.</booktitle>
<contexts>
<context position="7827" citStr="Cassidy et al., 2011" startWordPosition="1216" endWordPosition="1219">hat we will address in this paper. Next we detail the proposed framework and present our experiments and results. Finally, we conclude this paper with future directions. 2 Related Work Knowledge base population (KBP), the task of extending existing KBs with entities and relations, has been studied in the TAC-KBP evaluations (Ji et al., 2011), containing three tasks. The entity linking task links entity mentions to existing KB nodes and creates new nodes for the entities absent in the current KBs, which can be considered as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012). Entity linking is a crucial part in many KB reSe</context>
</contexts>
<marker>Cassidy, Chen, Artiles, Ji, Deng, Ratinov, Zheng, Han, Roth, 2011</marker>
<rawString>Taylor Cassidy, Zheng Chen, Javier Artiles, Heng Ji, Hongbo Deng, Lev-Arie Ratinov, Jing Zheng, Jiawei Han, and Dan Roth. 2011. Entity linking system description. In TAC2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Collaborative ranking: A case study on entity linking.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>771--781</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9463" citStr="Chen and Ji, 2011" startWordPosition="1472" endWordPosition="1475">field, Illinois Los Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore local contexts of entity mentions to measure the similarity between mentions and candidate entities (Han et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Cheng and Roth, 2013). Some methods further exploit global coherence among candidate entities in the same document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grish</context>
</contexts>
<marker>Chen, Ji, 2011</marker>
<rawString>Zheng Chen and Heng Ji. 2011. Collaborative ranking: A case study on entity linking. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 771– 781, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liwei Chen</author>
<author>Yansong Feng</author>
<author>Songfang Huang</author>
<author>Yong Qin</author>
<author>Dongyan Zhao</author>
</authors>
<title>Encoding relation requirements for relation extraction via joint inference.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014,</booktitle>
<pages>818--827</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="16216" citStr="Chen et al., 2014" startWordPosition="2589" endWordPosition="2592">entity pair level can be utilized here (again, a recall-oriented version will be welcome), such as Mintz++ mentioned in (Surdeanu et al., 2012), which we adapt into a Maximum Entropy version. We also include a special label, NA, to represent the case where there is no predefined relationship between an entity pair. For each sentence, we retain the relations with top q scores for the inference step, and we also call that this sentence supports those candidate relations. As for the features of RE models, we use the same features (lexical features and syntactic features) with the previous works (Chen et al., 2014; Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011). 4.2 Relations’ Expectations for Argument Types In most KBs’ schemas, canonicalized relations are designed to expect specific types of entities to be their arguments. For example, in Figure 2, it is more likely that an entity Kobe Bryant takes the subject position of a relation fb:pro athlete.teams, but it is unlikely for this entity to take the subject position of a relation fb:org.headquarters. Making use of these type requirements can encourage the framework to select relation and entity candidates which are coherent with eac</context>
<context position="20585" citStr="Chen et al., 2014" startWordPosition="3308" endWordPosition="3311">wo relations fb:org.headquarters and fb:pro athlete.teams in Figure 2 cannot share the same entity as their subjects. So if such sharing happens, that will indicate either the predictions of the relations or the entities are incorrect. The clues can be roughly grouped into three categories, namely whether two relations can share the same subjects, whether two relations can share the same objects, and whether one relation’s subject can be the other relation’s object. Global compatibilities among local predictions have been investigated by several joint models (Li et al., 2011; Li and Ji, 2014; Chen et al., 2014) to eliminate the errors propagating in a pipeline system. Specifically, Chen et al. (2014) utilized the clues with respect to the compatibilities of relations in the task of relation extraction. Following (Li et al., 2011; Chen et al., 2014), we extend the idea of global compatibilities to the entity and relation predictions during knowledge base population. We examine the pointwise mutual information (PMI) between the argument sets of two relations to collect such clues. For example, if we want to learn whether two relations can share the same subject, we first collect the subject sets of bo</context>
</contexts>
<marker>Chen, Feng, Huang, Qin, Zhao, 2014</marker>
<rawString>Liwei Chen, Yansong Feng, Songfang Huang, Yong Qin, and Dongyan Zhao. 2014. Encoding relation requirements for relation extraction via joint inference. In Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014, pages 818–827, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Cheng</author>
<author>Dan Roth</author>
</authors>
<title>Relational inference for wikification.</title>
<date>2013</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="9124" citStr="Cheng and Roth, 2013" startWordPosition="1414" endWordPosition="1417">ionships ... Sentence 1: ... [Bryant] is a private university located in [Smithfield]. ... Bryant University Bryant University Bryant, Illinois Kobe Bryant Bryant, Illinois Kobe Bryant ... ... fb:business.board_member.leader_of fb:people.person.place_of_birth fb:sports.pro_athlete.teams fb:org.org.headquarters Smithfield, Rhode Island Smithfield, Illinois Los Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore local contexts of entity mentions to measure the similarity between mentions and candidate entities (Han et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Cheng and Roth, 2013). Some methods further exploit global coherence among candidate entities in the same document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries an</context>
</contexts>
<marker>Cheng, Roth, 2013</marker>
<rawString>Xiao Cheng and Dan Roth. 2013. Relational inference for wikification. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Eric Breck</author>
<author>Claire Cardie</author>
</authors>
<title>Joint extraction of entities and relations for opinion recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06,</booktitle>
<pages>431--439</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11464" citStr="Choi et al. (2006)" startWordPosition="1814" endWordPosition="1817">which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in a sentence level which relation this specific sentence describes (between a pair of entity mentions in this sentence). Li and Ji (2014) follow the ACE task definitions and present a neat incremental joint framework to simultaneously extract entity mentions and relations by structure perceptron. In contrast, we link entity mentions from a text corpus to their corresponding entities in an existing KB and identify the relations between pairs of entities based on that text corpus. Choi et al. (2006) jointly extracts the expressions and sources of opinion as well as the linking relations (i.e., a source entity expresses an opinion expression) between them, while we focus on jointly modeling EL and RE in open domain, which is a different and challenging task. Since the automatically extracted knowledge facts inevitably contain errors, many approaches manage to assign confidences for those extracted facts (Fader et al., 2011; Wick et al., 2013). Wick et al. (2013) also point out that confidence estimation should be a crucial part in the automated KB constructions and will play a key role fo</context>
</contexts>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint extraction of entities and relations for opinion recognition. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06, pages 431–439, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Paul McNamee</author>
<author>Delip Rao</author>
<author>Adam Gerber</author>
<author>Tim Finin</author>
</authors>
<title>Entity disambiguation for knowledge base population.</title>
<date>2010</date>
<booktitle>In Coling2010.</booktitle>
<contexts>
<context position="7783" citStr="Dredze et al., 2010" startWordPosition="1208" endWordPosition="1211">efine the knowledge base population task that we will address in this paper. Next we detail the proposed framework and present our experiments and results. Finally, we conclude this paper with future directions. 2 Related Work Knowledge base population (KBP), the task of extending existing KBs with entities and relations, has been studied in the TAC-KBP evaluations (Ji et al., 2011), containing three tasks. The entity linking task links entity mentions to existing KB nodes and creates new nodes for the entities absent in the current KBs, which can be considered as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012). Enti</context>
</contexts>
<marker>Dredze, McNamee, Rao, Gerber, Finin, 2010</marker>
<rawString>Mark Dredze, Paul McNamee, Delip Rao, Adam Gerber, and Tim Finin. 2010. Entity disambiguation for knowledge base population. In Coling2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1535--1545</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10143" citStr="Fader et al., 2011" startWordPosition="1589" endWordPosition="1592">ities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional j</context>
<context position="11895" citStr="Fader et al., 2011" startWordPosition="1881" endWordPosition="1884">ink entity mentions from a text corpus to their corresponding entities in an existing KB and identify the relations between pairs of entities based on that text corpus. Choi et al. (2006) jointly extracts the expressions and sources of opinion as well as the linking relations (i.e., a source entity expresses an opinion expression) between them, while we focus on jointly modeling EL and RE in open domain, which is a different and challenging task. Since the automatically extracted knowledge facts inevitably contain errors, many approaches manage to assign confidences for those extracted facts (Fader et al., 2011; Wick et al., 2013). Wick et al. (2013) also point out that confidence estimation should be a crucial part in the automated KB constructions and will play a key role for the wide applications of automatically built KBs. We thus propose to model the reliability of the complete extraction process and take the argument type expectations of the relation, coherence with other predictions and the triples in the existing KB into account for each populated triple. 3 Task definition We formalize our task as follows. Given a set of entities sampled from an existing KB, E = {e1, e2, ..., e|E|}, a set of</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1535–1545, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Imed Zitouni</author>
</authors>
<title>Factorizing complex models: A case study in mention detection.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>473--480</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9838" citStr="Florian et al., 2006" startWordPosition="1540" endWordPosition="1543">by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised</context>
</contexts>
<marker>Florian, Jing, Kambhatla, Zitouni, 2006</marker>
<rawString>Radu Florian, Hongyan Jing, Nanda Kambhatla, and Imed Zitouni. 2006. Factorizing complex models: A case study in mention detection. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 473–480. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>John F Pitrelli</author>
<author>Salim Roukos</author>
<author>Imed Zitouni</author>
</authors>
<title>Improving mention detection robustness to noisy input.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>335--345</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9860" citStr="Florian et al., 2010" startWordPosition="1544" endWordPosition="1547"> entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract re</context>
</contexts>
<marker>Florian, Pitrelli, Roukos, Zitouni, 2010</marker>
<rawString>Radu Florian, John F Pitrelli, Salim Roukos, and Imed Zitouni. 2010. Improving mention detection robustness to noisy input. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 335–345. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
</authors>
<title>A generative entitymention model for linking entities with knowledge base.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL, HLT ’11,</booktitle>
<pages>945--954</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Han, Le Sun, 2011</marker>
<rawString>Xianpei Han and Le Sun. 2011. A generative entitymention model for linking entities with knowledge base. In Proceedings of ACL, HLT ’11, pages 945– 954, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
<author>Jun Zhao</author>
</authors>
<title>Collective entity linking in web text: a graph-based method.</title>
<date>2011</date>
<booktitle>In SIGIR, SIGIR ’11,</booktitle>
<pages>765--774</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Han, Le Sun, Zhao, 2011</marker>
<rawString>Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective entity linking in web text: a graph-based method. In SIGIR, SIGIR ’11, pages 765–774, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledge-based weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th ACL-HLT - Volume 1, HLT ’11,</booktitle>
<pages>541--550</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10386" citStr="Hoffmann et al., 2011" startWordPosition="1632" endWordPosition="1635">xplicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010), which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in a sentence level which</context>
<context position="16281" citStr="Hoffmann et al., 2011" startWordPosition="2601" endWordPosition="2604">nted version will be welcome), such as Mintz++ mentioned in (Surdeanu et al., 2012), which we adapt into a Maximum Entropy version. We also include a special label, NA, to represent the case where there is no predefined relationship between an entity pair. For each sentence, we retain the relations with top q scores for the inference step, and we also call that this sentence supports those candidate relations. As for the features of RE models, we use the same features (lexical features and syntactic features) with the previous works (Chen et al., 2014; Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011). 4.2 Relations’ Expectations for Argument Types In most KBs’ schemas, canonicalized relations are designed to expect specific types of entities to be their arguments. For example, in Figure 2, it is more likely that an entity Kobe Bryant takes the subject position of a relation fb:pro athlete.teams, but it is unlikely for this entity to take the subject position of a relation fb:org.headquarters. Making use of these type requirements can encourage the framework to select relation and entity candidates which are coherent with each other, and discard incoherent choices. In order to obtain the p</context>
<context position="28542" citStr="Hoffmann et al., 2011" startWordPosition="4763" endWordPosition="4766">s and 900,000 constraints per split and may take 1 hour for Cplex to solve. Note that we do not count the triples that will be evaluated in the testing data when we learn the preferences and the clues from the KB. 5.2 Experimental Setup We compare our framework with three baselines. The first one, ME-pl, is the pipeline system constructed by the entity linker in (Han et al., 2011) and the MaxEnt version of Mintz++ extractor mentioned in (Surdeanu et al., 2012). The second and third baselines are the pipeline systems constructed by the same linker and two state-ofthe-art DS approaches, MultiR (Hoffmann et al., 2011) and MIML-RE (Surdeanu et al., 2012), respectively. They are referred to as MultiR-pl and MIML-pl in the rest of this paper. We also implement several variants of our framework to investigate the following two components in our framework: whether to use explicit (E) or implicit (I) argument type expectations, whether to take global (G) compatibilities into account, resulting in four variants: ME-JE, ME-JI, ME-JEG, ME-JIG. We tune the parameters in the objective function on the development set to be re = 1, el = 4, sp = 1. The numbers of preliminary results retained to the inference step are se</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of the 49th ACL-HLT - Volume 1, HLT ’11, pages 541–550, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Dang</author>
</authors>
<title>Overview of the tac2011 knowledge base population track.</title>
<date>2011</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="7549" citStr="Ji et al., 2011" startWordPosition="1167" endWordPosition="1170">of existing KBs. Additionally, our proposed confidence estimations can help to achieve a precision of over 85% for a considerable amount of high quality extractions. In the rest of the paper, we first review related work and then define the knowledge base population task that we will address in this paper. Next we detail the proposed framework and present our experiments and results. Finally, we conclude this paper with future directions. 2 Related Work Knowledge base population (KBP), the task of extending existing KBs with entities and relations, has been studied in the TAC-KBP evaluations (Ji et al., 2011), containing three tasks. The entity linking task links entity mentions to existing KB nodes and creates new nodes for the entities absent in the current KBs, which can be considered as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training d</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Dang. 2011. Overview of the tac2011 knowledge base population track. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
<author>Raymond J Mooney</author>
</authors>
<title>Joint entity and relation extraction using card-pyramid parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, CoNLL ’10,</booktitle>
<pages>203--212</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10844" citStr="Kate and Mooney, 2010" startWordPosition="1712" endWordPosition="1715">utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010), which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in a sentence level which relation this specific sentence describes (between a pair of entity mentions in this sentence). Li and Ji (2014) follow the ACE task definitions and present a neat incremental joint framework to simultaneously extract entity mentions and relations by structure perceptron. In contrast, we link entity mentions from a text corpus to their corresponding entities in an existing KB and identify the relations between pairs of entities based on that text corpus</context>
</contexts>
<marker>Kate, Mooney, 2010</marker>
<rawString>Rohit J. Kate and Raymond J. Mooney. 2010. Joint entity and relation extraction using card-pyramid parsing. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, CoNLL ’10, pages 203–212, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Heng Ji</author>
</authors>
<title>Incremental joint extraction of entity mentions and relations.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014,</booktitle>
<pages>402--412</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9878" citStr="Li and Ji, 2014" startWordPosition="1548" endWordPosition="1551">osely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts</context>
<context position="11099" citStr="Li and Ji (2014)" startWordPosition="1754" endWordPosition="1757">pen domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010), which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in a sentence level which relation this specific sentence describes (between a pair of entity mentions in this sentence). Li and Ji (2014) follow the ACE task definitions and present a neat incremental joint framework to simultaneously extract entity mentions and relations by structure perceptron. In contrast, we link entity mentions from a text corpus to their corresponding entities in an existing KB and identify the relations between pairs of entities based on that text corpus. Choi et al. (2006) jointly extracts the expressions and sources of opinion as well as the linking relations (i.e., a source entity expresses an opinion expression) between them, while we focus on jointly modeling EL and RE in open domain, which is a dif</context>
<context position="20565" citStr="Li and Ji, 2014" startWordPosition="3304" endWordPosition="3307"> to the KB, the two relations fb:org.headquarters and fb:pro athlete.teams in Figure 2 cannot share the same entity as their subjects. So if such sharing happens, that will indicate either the predictions of the relations or the entities are incorrect. The clues can be roughly grouped into three categories, namely whether two relations can share the same subjects, whether two relations can share the same objects, and whether one relation’s subject can be the other relation’s object. Global compatibilities among local predictions have been investigated by several joint models (Li et al., 2011; Li and Ji, 2014; Chen et al., 2014) to eliminate the errors propagating in a pipeline system. Specifically, Chen et al. (2014) utilized the clues with respect to the compatibilities of relations in the task of relation extraction. Following (Li et al., 2011; Chen et al., 2014), we extend the idea of global compatibilities to the entity and relation predictions during knowledge base population. We examine the pointwise mutual information (PMI) between the argument sets of two relations to collect such clues. For example, if we want to learn whether two relations can share the same subject, we first collect th</context>
</contexts>
<marker>Li, Ji, 2014</marker>
<rawString>Qi Li and Heng Ji. 2014. Incremental joint extraction of entity mentions and relations. In Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL 2014, pages 402– 412, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Sam Anzaroot</author>
<author>Wen-Pin Lin</author>
<author>Xiang Li</author>
<author>Heng Ji</author>
</authors>
<title>Joint inference for cross-document information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM ’11,</booktitle>
<pages>2225--2228</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="20548" citStr="Li et al., 2011" startWordPosition="3300" endWordPosition="3303">xample, according to the KB, the two relations fb:org.headquarters and fb:pro athlete.teams in Figure 2 cannot share the same entity as their subjects. So if such sharing happens, that will indicate either the predictions of the relations or the entities are incorrect. The clues can be roughly grouped into three categories, namely whether two relations can share the same subjects, whether two relations can share the same objects, and whether one relation’s subject can be the other relation’s object. Global compatibilities among local predictions have been investigated by several joint models (Li et al., 2011; Li and Ji, 2014; Chen et al., 2014) to eliminate the errors propagating in a pipeline system. Specifically, Chen et al. (2014) utilized the clues with respect to the compatibilities of relations in the task of relation extraction. Following (Li et al., 2011; Chen et al., 2014), we extend the idea of global compatibilities to the entity and relation predictions during knowledge base population. We examine the pointwise mutual information (PMI) between the argument sets of two relations to collect such clues. For example, if we want to learn whether two relations can share the same subject, we</context>
</contexts>
<marker>Li, Anzaroot, Lin, Li, Ji, 2011</marker>
<rawString>Qi Li, Sam Anzaroot, Wen-Pin Lin, Xiang Li, and Heng Ji. 2011. Joint inference for cross-document information extraction. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM ’11, pages 2225– 2228, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lin</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>No noun phrase left behind: Detecting and typing unlinkable entities.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 EMNLP-CoNLL, EMNLP-CoNLL ’12,</booktitle>
<pages>893--903</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9482" citStr="Lin et al. (2012)" startWordPosition="1476" endWordPosition="1479">Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore local contexts of entity mentions to measure the similarity between mentions and candidate entities (Han et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Cheng and Roth, 2013). Some methods further exploit global coherence among candidate entities in the same document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and J</context>
</contexts>
<marker>Lin, Mausam, Etzioni, 2012</marker>
<rawString>Thomas Lin, Mausam, and Oren Etzioni. 2012. No noun phrase left behind: Detecting and typing unlinkable entities. In Proceedings of the 2012 EMNLP-CoNLL, EMNLP-CoNLL ’12, pages 893– 903, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fang Liu</author>
<author>Jun Zhao</author>
</authors>
<title>Sweat2012: Pattern based english slot filling system for knowledge base population at tac 2012.</title>
<date>2012</date>
<booktitle>In TAC2012.</booktitle>
<contexts>
<context position="7945" citStr="Liu and Zhao, 2012" startWordPosition="1237" endWordPosition="1240">y, we conclude this paper with future directions. 2 Related Work Knowledge base population (KBP), the task of extending existing KBs with entities and relations, has been studied in the TAC-KBP evaluations (Ji et al., 2011), containing three tasks. The entity linking task links entity mentions to existing KB nodes and creates new nodes for the entities absent in the current KBs, which can be considered as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012). Entity linking is a crucial part in many KB reSentence 2 : ... Shaq and [Bryant] led the [Lakers] to three consecutive championships ... Sentence 1: ... [Bryant] is a</context>
</contexts>
<marker>Liu, Zhao, 2012</marker>
<rawString>Fang Liu and Jun Zhao. 2012. Sweat2012: Pattern based english slot filling system for knowledge base population at tac 2012. In TAC2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<contexts>
<context position="10342" citStr="Mintz et al., 2009" startWordPosition="1624" endWordPosition="1627">d types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010), which jointly extract and/or classify named entity mentions to several predefined types in a sen</context>
<context position="16236" citStr="Mintz et al., 2009" startWordPosition="2593" endWordPosition="2596">an be utilized here (again, a recall-oriented version will be welcome), such as Mintz++ mentioned in (Surdeanu et al., 2012), which we adapt into a Maximum Entropy version. We also include a special label, NA, to represent the case where there is no predefined relationship between an entity pair. For each sentence, we retain the relations with top q scores for the inference step, and we also call that this sentence supports those candidate relations. As for the features of RE models, we use the same features (lexical features and syntactic features) with the previous works (Chen et al., 2014; Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011). 4.2 Relations’ Expectations for Argument Types In most KBs’ schemas, canonicalized relations are designed to expect specific types of entities to be their arguments. For example, in Figure 2, it is more likely that an entity Kobe Bryant takes the subject position of a relation fb:pro athlete.teams, but it is unlikely for this entity to take the subject position of a relation fb:org.headquarters. Making use of these type requirements can encourage the framework to select relation and entity candidates which are coherent with each other, and discard</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP: Volume 2 -Volume 2, ACL ’09, pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Monahan</author>
<author>Dean Carpenter</author>
</authors>
<title>Lorify: A knowledge base from scratch.</title>
<date>2012</date>
<booktitle>In TAC2012.</booktitle>
<contexts>
<context position="8377" citStr="Monahan and Carpenter, 2012" startWordPosition="1309" endWordPosition="1312">ty population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012). Entity linking is a crucial part in many KB reSentence 2 : ... Shaq and [Bryant] led the [Lakers] to three consecutive championships ... Sentence 1: ... [Bryant] is a private university located in [Smithfield]. ... Bryant University Bryant University Bryant, Illinois Kobe Bryant Bryant, Illinois Kobe Bryant ... ... fb:business.board_member.leader_of fb:people.person.place_of_birth fb:sports.pro_athlete.teams fb:org.org.headquarters Smithfield, Rhode Island Smithfield, Illinois Los Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore local contexts of entity mentions </context>
</contexts>
<marker>Monahan, Carpenter, 2012</marker>
<rawString>Sean Monahan and Dean Carpenter. 2012. Lorify: A knowledge base from scratch. In TAC2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9101" citStr="Ratinov et al., 2011" startWordPosition="1410" endWordPosition="1413">hree consecutive championships ... Sentence 1: ... [Bryant] is a private university located in [Smithfield]. ... Bryant University Bryant University Bryant, Illinois Kobe Bryant Bryant, Illinois Kobe Bryant ... ... fb:business.board_member.leader_of fb:people.person.place_of_birth fb:sports.pro_athlete.teams fb:org.org.headquarters Smithfield, Rhode Island Smithfield, Illinois Los Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore local contexts of entity mentions to measure the similarity between mentions and candidate entities (Han et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Cheng and Roth, 2013). Some methods further exploit global coherence among candidate entities in the same document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly ident</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Machine Learning and Knowledge Discovery in Databases,</booktitle>
<volume>6323</volume>
<pages>148--163</pages>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="10363" citStr="Riedel et al., 2010" startWordPosition="1628" endWordPosition="1631">ntions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010), which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in</context>
<context position="16257" citStr="Riedel et al., 2010" startWordPosition="2597" endWordPosition="2600">(again, a recall-oriented version will be welcome), such as Mintz++ mentioned in (Surdeanu et al., 2012), which we adapt into a Maximum Entropy version. We also include a special label, NA, to represent the case where there is no predefined relationship between an entity pair. For each sentence, we retain the relations with top q scores for the inference step, and we also call that this sentence supports those candidate relations. As for the features of RE models, we use the same features (lexical features and syntactic features) with the previous works (Chen et al., 2014; Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011). 4.2 Relations’ Expectations for Argument Types In most KBs’ schemas, canonicalized relations are designed to expect specific types of entities to be their arguments. For example, in Figure 2, it is more likely that an entity Kobe Bryant takes the subject position of a relation fb:pro athlete.teams, but it is unlikely for this entity to take the subject position of a relation fb:org.headquarters. Making use of these type requirements can encourage the framework to select relation and entity candidates which are coherent with each other, and discard incoherent choices. </context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases, volume 6323 of Lecture Notes in Computer Science, pages 148–163. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Benjamin M Marlin</author>
<author>Andrew McCallum</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL ’13),</booktitle>
<contexts>
<context position="4568" citStr="Riedel et al., 2013" startWordPosition="707" endWordPosition="710">ons are defined in Freebase. 1912 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1912–1923, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: Two example sentences from which we can harvest knowledge facts. both of them. In KBs with well-defined schemas, such as Freebase, type requirements can be collected and utilized explicitly (Yao et al., 2010). However, in other KBs with less reliable or even no schemas, it is more appropriate to implicitly capture the type expectations for a given relation (Riedel et al., 2013). Furthermore, previous RE approaches usually process each triple individually, which ignores whether those local predictions are compatible with each other. For example, suppose the local predictions of the two sentences above are &lt;Kobe Bryant, fb:org.headquarters, Smithfield, Rhode Island&gt; and &lt;Kobe Bryant, fb:pro athlete.teams, Los Angeles Lakers&gt;, respectively, which, in fact, disagree with each other with respect to the KB, since, in most cases, these two relations cannot share subjects. Now we can see that either the relation predictions or the EL results for “Bryant” are incorrect. Thos</context>
<context position="18835" citStr="Riedel et al. (2013)" startWordPosition="3033" endWordPosition="3036">obtain the subject’s type basketball player, and then we go through the initial matrix and find another entity Kobe Bryant with the same type taking the subject position of fb:pro athlete.teams, indicating that Jay Fletcher Vincent may take the relation fb:pro athlete.teams. The matrix 5obj is processed in the same way. Implicit Type Expectations In practice, few KBs have well-defined schemas. In order to make our framework more flexible, we need to come up with an approach to implicitly capture the relations’ type expectations, which will also be represented as preference scores. Inspired by Riedel et al. (2013) who use a matrix factorization approach to capture the association between textual patterns, relations and entities based on large text corpora, we adopt a collaborative filtering (CF) method to compute the preference scores between entities and relations based on the statistics obtained from an existing KB. In CF, the preferences between customers and items are calculated via matrix factorization over the initial customer-item matrix. In our framework, we compute the preference scores between entities and relations via the same approach over the two initialized matrices 5subj and 5obj, resul</context>
</contexts>
<marker>Riedel, Yao, Marlin, McCallum, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Benjamin M. Marlin, and Andrew McCallum. 2013. Relation extraction with matrix factorization and universal schemas. In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL ’13), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Roth</author>
<author>Grzegorz Chrupala</author>
<author>Michael Wiegand</author>
<author>Mittul Singh</author>
<author>Dietrich Klakow</author>
</authors>
<title>Generalizing from freebase and patterns using cluster-based distant supervision for tac kbp slotfilling 2012.</title>
<date>2012</date>
<booktitle>In TAC2012.</booktitle>
<contexts>
<context position="7924" citStr="Roth et al., 2012" startWordPosition="1233" endWordPosition="1236">and results. Finally, we conclude this paper with future directions. 2 Related Work Knowledge base population (KBP), the task of extending existing KBs with entities and relations, has been studied in the TAC-KBP evaluations (Ji et al., 2011), containing three tasks. The entity linking task links entity mentions to existing KB nodes and creates new nodes for the entities absent in the current KBs, which can be considered as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012). Entity linking is a crucial part in many KB reSentence 2 : ... Shaq and [Bryant] led the [Lakers] to three consecutive championships ... Sentence</context>
</contexts>
<marker>Roth, Chrupala, Wiegand, Singh, Klakow, 2012</marker>
<rawString>Benjamin Roth, Grzegorz Chrupala, Michael Wiegand, Mittul Singh, and Dietrich Klakow. 2012. Generalizing from freebase and patterns using cluster-based distant supervision for tac kbp slotfilling 2012. In TAC2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prithviraj Sen</author>
</authors>
<title>Collective context-aware topic models for entity disambiguation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st International Conference on World Wide Web, WWW ’12,</booktitle>
<pages>729--738</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="9326" citStr="Sen, 2012" startWordPosition="1450" endWordPosition="1451">ber.leader_of fb:people.person.place_of_birth fb:sports.pro_athlete.teams fb:org.org.headquarters Smithfield, Rhode Island Smithfield, Illinois Los Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore local contexts of entity mentions to measure the similarity between mentions and candidate entities (Han et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Cheng and Roth, 2013). Some methods further exploit global coherence among candidate entities in the same document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, r</context>
</contexts>
<marker>Sen, 2012</marker>
<rawString>Prithviraj Sen. 2012. Collective context-aware topic models for entity disambiguation. In Proceedings of the 21st International Conference on World Wide Web, WWW ’12, pages 729–738, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Singh</author>
<author>Sebastian Riedel</author>
<author>Brian Martin</author>
<author>Jiaping Zheng</author>
<author>Andrew McCallum</author>
</authors>
<title>Joint inference of entities, relations, and coreference.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Workshop on Automated Knowledge Base Construction, AKBC ’13,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="10803" citStr="Singh et al., 2013" startWordPosition="1704" endWordPosition="1707">dels, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010), which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in a sentence level which relation this specific sentence describes (between a pair of entity mentions in this sentence). Li and Ji (2014) follow the ACE task definitions and present a neat incremental joint framework to simultaneously extract entity mentions and relations by structure perceptron. In contrast, we link entity mentions from a text corpus to their corresponding entities in an existing KB and identify the relations between pa</context>
</contexts>
<marker>Singh, Riedel, Martin, Zheng, McCallum, 2013</marker>
<rawString>Sameer Singh, Sebastian Riedel, Brian Martin, Jiaping Zheng, and Andrew McCallum. 2013. Joint inference of entities, relations, and coreference. In Proceedings of the 2013 Workshop on Automated Knowledge Base Construction, AKBC ’13, pages 1– 6, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ang Sun</author>
<author>Xin Wang</author>
<author>Sen Xu</author>
<author>Yigit Kiran</author>
<author>Shakthi Poornima</author>
<author>Andrew Borthwick</author>
</authors>
<title>Intelius-nyu tac-kbp2012 cold start system.</title>
<date>2012</date>
<booktitle>In TAC2012.</booktitle>
<contexts>
<context position="8347" citStr="Sun et al., 2012" startWordPosition="1305" endWordPosition="1308"> as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012). Entity linking is a crucial part in many KB reSentence 2 : ... Shaq and [Bryant] led the [Lakers] to three consecutive championships ... Sentence 1: ... [Bryant] is a private university located in [Smithfield]. ... Bryant University Bryant University Bryant, Illinois Kobe Bryant Bryant, Illinois Kobe Bryant ... ... fb:business.board_member.leader_of fb:people.person.place_of_birth fb:sports.pro_athlete.teams fb:org.org.headquarters Smithfield, Rhode Island Smithfield, Illinois Los Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore loca</context>
</contexts>
<marker>Sun, Wang, Xu, Kiran, Poornima, Borthwick, 2012</marker>
<rawString>Ang Sun, Xin Wang, Sen Xu, Yigit Kiran, Shakthi Poornima, Andrew Borthwick, , and Ralph Grishman. 2012. Intelius-nyu tac-kbp2012 cold start system. In TAC2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multiinstance multi-label learning for relation extraction.</title>
<date>2012</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>455--465</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="10410" citStr="Surdeanu et al., 2012" startWordPosition="1636" endWordPosition="1639">entions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been applied to many NLP tasks. Our task is different from the traditional joint IE works based in the ACE framework (Singh et al., 2013; Li and Ji, 2014; Kate and Mooney, 2010), which jointly extract and/or classify named entity mentions to several predefined types in a sentence and identify in a sentence level which relation this specific </context>
<context position="15742" citStr="Surdeanu et al., 2012" startWordPosition="2506" endWordPosition="2509">pproach in (Han et al., 2011) to avoid preparing training data. Note the challenging NIL problem, i.e., identifying which entity mentions do not have corresponding entities in the KB (labeled as NIL) and clustering those mentions, will be our future work. For each mention we retain the entities with top p scores for the succeeding inference step. Relation Extraction The choice of RE model is also broad. Any sentence level extractor whose results are easy to be aggregated to entity pair level can be utilized here (again, a recall-oriented version will be welcome), such as Mintz++ mentioned in (Surdeanu et al., 2012), which we adapt into a Maximum Entropy version. We also include a special label, NA, to represent the case where there is no predefined relationship between an entity pair. For each sentence, we retain the relations with top q scores for the inference step, and we also call that this sentence supports those candidate relations. As for the features of RE models, we use the same features (lexical features and syntactic features) with the previous works (Chen et al., 2014; Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011). 4.2 Relations’ Expectations for Argument Types In most KBs’</context>
<context position="28384" citStr="Surdeanu et al., 2012" startWordPosition="4737" endWordPosition="4740">t clauses. The resulting test set is split into 10 parts and a development set, each with 3500 entity pairs roughly, which leads to averagely 200,000 variables and 900,000 constraints per split and may take 1 hour for Cplex to solve. Note that we do not count the triples that will be evaluated in the testing data when we learn the preferences and the clues from the KB. 5.2 Experimental Setup We compare our framework with three baselines. The first one, ME-pl, is the pipeline system constructed by the entity linker in (Han et al., 2011) and the MaxEnt version of Mintz++ extractor mentioned in (Surdeanu et al., 2012). The second and third baselines are the pipeline systems constructed by the same linker and two state-ofthe-art DS approaches, MultiR (Hoffmann et al., 2011) and MIML-RE (Surdeanu et al., 2012), respectively. They are referred to as MultiR-pl and MIML-pl in the rest of this paper. We also implement several variants of our framework to investigate the following two components in our framework: whether to use explicit (E) or implicit (I) argument type expectations, whether to take global (G) compatibilities into account, resulting in four variants: ME-JE, ME-JI, ME-JEG, ME-JIG. We tune the para</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D. Manning. 2012. Multiinstance multi-label learning for relation extraction. In EMNLP-CoNLL, pages 455–465. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Tamang</author>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Entity linking system and slot filling validation system.</title>
<date>2012</date>
<booktitle>In TAC2012.</booktitle>
<contexts>
<context position="7804" citStr="Tamang et al., 2012" startWordPosition="1212" endWordPosition="1215">ase population task that we will address in this paper. Next we detail the proposed framework and present our experiments and results. Finally, we conclude this paper with future directions. 2 Related Work Knowledge base population (KBP), the task of extending existing KBs with entities and relations, has been studied in the TAC-KBP evaluations (Ji et al., 2011), containing three tasks. The entity linking task links entity mentions to existing KB nodes and creates new nodes for the entities absent in the current KBs, which can be considered as a kind of entity population (Dredze et al., 2010; Tamang et al., 2012; Cassidy et al., 2011). The slot-filling task populates new relations to the KB (Tamang et al., 2012; Roth et al., 2012; Liu and Zhao, 2012), but the relations are limited to a predefined sets of attributes according to the types of entities. In contrast, our RE models only require minimal supervision and do not need well-annotated training data. Our framework is therefore easy to adapt to new scenarios and suits real-world applications. The cold-start task aims at constructing a KB from scratch in a slot-filling style (Sun et al., 2012; Monahan and Carpenter, 2012). Entity linking is a cruci</context>
</contexts>
<marker>Tamang, Chen, Ji, 2012</marker>
<rawString>Suzanne Tamang, Zheng Chen, and Heng Ji. 2012. Entity linking system and slot filling validation system. In TAC2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wick</author>
<author>Sameer Singh</author>
<author>Ari Kobren</author>
<author>Andrew McCallum</author>
</authors>
<title>Assessing confidence of knowledge base content with an experimental study in entity resolution.</title>
<date>2013</date>
<booktitle>In AKBC2013.</booktitle>
<contexts>
<context position="11915" citStr="Wick et al., 2013" startWordPosition="1885" endWordPosition="1888">from a text corpus to their corresponding entities in an existing KB and identify the relations between pairs of entities based on that text corpus. Choi et al. (2006) jointly extracts the expressions and sources of opinion as well as the linking relations (i.e., a source entity expresses an opinion expression) between them, while we focus on jointly modeling EL and RE in open domain, which is a different and challenging task. Since the automatically extracted knowledge facts inevitably contain errors, many approaches manage to assign confidences for those extracted facts (Fader et al., 2011; Wick et al., 2013). Wick et al. (2013) also point out that confidence estimation should be a crucial part in the automated KB constructions and will play a key role for the wide applications of automatically built KBs. We thus propose to model the reliability of the complete extraction process and take the argument type expectations of the relation, coherence with other predictions and the triples in the existing KB into account for each populated triple. 3 Task definition We formalize our task as follows. Given a set of entities sampled from an existing KB, E = {e1, e2, ..., e|E|}, a set of canonicalized relat</context>
</contexts>
<marker>Wick, Singh, Kobren, McCallum, 2013</marker>
<rawString>Michael Wick, Sameer Singh, Ari Kobren, and Andrew McCallum. 2013. Assessing confidence of knowledge base content with an experimental study in entity resolution. In AKBC2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective cross-document relation extraction without labelled data.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP, EMNLP ’10,</booktitle>
<pages>1013--1023</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4396" citStr="Yao et al., 2010" startWordPosition="678" endWordPosition="681">t the argument type expectations of relations can encourage the two subtasks interact with each other and select coherent predictions for 1The prefix fb means the relations are defined in Freebase. 1912 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1912–1923, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: Two example sentences from which we can harvest knowledge facts. both of them. In KBs with well-defined schemas, such as Freebase, type requirements can be collected and utilized explicitly (Yao et al., 2010). However, in other KBs with less reliable or even no schemas, it is more appropriate to implicitly capture the type expectations for a given relation (Riedel et al., 2013). Furthermore, previous RE approaches usually process each triple individually, which ignores whether those local predictions are compatible with each other. For example, suppose the local predictions of the two sentences above are &lt;Kobe Bryant, fb:org.headquarters, Smithfield, Rhode Island&gt; and &lt;Kobe Bryant, fb:pro athlete.teams, Los Angeles Lakers&gt;, respectively, which, in fact, disagree with each other with respect to the</context>
</contexts>
<marker>Yao, Riedel, McCallum, 2010</marker>
<rawString>Limin Yao, Sebastian Riedel, and Andrew McCallum. 2010. Collective cross-document relation extraction without labelled data. In Proceedings of EMNLP, EMNLP ’10, pages 1013–1023, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shubin Zhao</author>
<author>Ralph Grishman</author>
</authors>
<title>Extracting relations with integrated information using kernel methods.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>419--426</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10072" citStr="Zhao and Grishman, 2005" startWordPosition="1576" endWordPosition="1579"> and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, 2004; Zhao and Grishman, 2005; Li and Ji, 2014) to unsupervised open extractions (Fader et al., 2011; Carlson et al., 2010). There are also models, with distant supervision (DS), utilizing reliable texts resources and existing KBs to predict relations for a large amount of texts (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). These distantly supervised models can extract relations from texts in open domain, and do not need much human involvement. Hence, DS is more suitable for our task compared to other traditional RE approaches. Joint inference over multiple local models has been </context>
</contexts>
<marker>Zhao, Grishman, 2005</marker>
<rawString>Shubin Zhao and Ralph Grishman. 2005. Extracting relations with integrated information using kernel methods. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05, pages 419–426, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunhong Zhou</author>
<author>Dennis Wilkinson</author>
<author>Robert Schreiber</author>
<author>Rong Pan</author>
</authors>
<title>Large-scale parallel collaborative filtering for the netflix prize.</title>
<date>2008</date>
<booktitle>In Proceedings of the 4th International Conference on Algorithmic Aspects in Information and Management, AAIM ’08,</booktitle>
<pages>337--348</pages>
<publisher>SpringerVerlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="19539" citStr="Zhou et al., 2008" startWordPosition="3144" endWordPosition="3147">tterns, relations and entities based on large text corpora, we adopt a collaborative filtering (CF) method to compute the preference scores between entities and relations based on the statistics obtained from an existing KB. In CF, the preferences between customers and items are calculated via matrix factorization over the initial customer-item matrix. In our framework, we compute the preference scores between entities and relations via the same approach over the two initialized matrices 5subj and 5obj, resulting in two entity-relation matrices with estimated preference values. We use ALS-WR (Zhou et al., 2008) to process the matrices and compute the preference of a relation taking an entity as its subject and object, respectively. We normalize the preference scores of each entity using their means µ and standard deviations Q. 4.3 Compatibilities among Predicted Triples The second aspect we investigate is whether the extracted triples are compatible with respect to all other knowledge facts. For example, according to the KB, the two relations fb:org.headquarters and fb:pro athlete.teams in Figure 2 cannot share the same entity as their subjects. So if such sharing happens, that will indicate either </context>
</contexts>
<marker>Zhou, Wilkinson, Schreiber, Pan, 2008</marker>
<rawString>Yunhong Zhou, Dennis Wilkinson, Robert Schreiber, and Rong Pan. 2008. Large-scale parallel collaborative filtering for the netflix prize. In Proceedings of the 4th International Conference on Algorithmic Aspects in Information and Management, AAIM ’08, pages 337–348, Berlin, Heidelberg. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiping Zhou</author>
<author>Lan Nie</author>
<author>Omid Rouhani-Kalleh</author>
<author>Flavian Vasile</author>
<author>Scott Gaffney</author>
</authors>
<title>Resolving surface forms to wikipedia topics.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>1335--1343</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9443" citStr="Zhou et al., 2010" startWordPosition="1468" endWordPosition="1471"> Rhode Island Smithfield, Illinois Los Angeles Lakers Laguna Lakers ... ... 1913 lated tasks. Many EL models explore local contexts of entity mentions to measure the similarity between mentions and candidate entities (Han et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Cheng and Roth, 2013). Some methods further exploit global coherence among candidate entities in the same document by assuming that these entities should be closely related (Han et al., 2011; Ratinov et al., 2011; Sen, 2012; Cheng and Roth, 2013). There are also some approaches regarding entity linking as a ranking task (Zhou et al., 2010; Chen and Ji, 2011). Lin et al. (2012) propose an approach to detect and type entities that are currently not in the KB. Note that the EL task in KBP is different from the name entity mention extraction task, mainly in the ACE task style, which mainly identifies the boundaries and types of entity mentions and does not explicitly link entity mentions into a KB (ACE, 2004; Florian et al., 2006; Florian et al., 2010; Li and Ji, 2014), thus are different from our work. Meanwhile, relation extraction has also been studied extensively in recent years, ranging from supervised learning methods (ACE, </context>
</contexts>
<marker>Zhou, Nie, Rouhani-Kalleh, Vasile, Gaffney, 2010</marker>
<rawString>Yiping Zhou, Lan Nie, Omid Rouhani-Kalleh, Flavian Vasile, and Scott Gaffney. 2010. Resolving surface forms to wikipedia topics. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 1335–1343, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>