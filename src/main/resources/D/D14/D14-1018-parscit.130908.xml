<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003852">
<title confidence="0.992627">
Asymmetric Features of Human Generated Translation
</title>
<author confidence="0.993659">
Sauleh Eetemadi Kristina Toutanova
</author>
<affiliation confidence="0.874738">
Michigan State University, East Lansing, MI Microsoft Research
Microsoft Research, Redmond, WA Redmond, WA
</affiliation>
<email confidence="0.992481">
saulehe@microsoft.com kristout@microsoft.com
</email>
<sectionHeader confidence="0.993736" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999959227272727">
Distinct properties of translated text have
been the subject of research in linguistics
for many year (Baker, 1993). In recent
years computational methods have been
developed to empirically verify the lin-
guistic theories about translated text (Ba-
roni and Bernardini, 2006). While many
characteristics of translated text are more
apparent in comparison to the original
text, most of the prior research has fo-
cused on monolingual features of trans-
lated and original text. The contribution
of this work is introducing bilingual fea-
tures that are capable of explaining dif-
ferences in translation direction using lo-
calized linguistic phenomena at the phrase
or sentence level, rather than using mono-
lingual statistics at the document level.
We show that these bilingual features out-
perform the monolingual features used in
prior work (Kurokawa et al., 2009) for the
task of classifying translation direction.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999084714285714">
It has been known for many years in linguis-
tics that translated text has distinct patterns com-
pared to original or authored text (Baker, 1993).
The term “Translationese” is often used to refer
to the characteristics of translated text. Patterns
of Translationese can be categorized as follows
(Volansky et al., 2013):
</bodyText>
<listItem confidence="0.957311375">
1. Simplification: The process of translation is
often coupled with a simplification process at
several levels. For example, there tends to be
less lexical variety in translated text and rare
words are often avoided.
2. Explicitation: Translators often have to be
more explicit in their translations due to lack
of the cultural context that speakers of the
</listItem>
<bodyText confidence="0.991886833333333">
source language have. Another manifesta-
tion of this pattern is making arguments more
explicit which can be observed in the heavy
use of cohesive markers like “therefore” and
“moreover” in translated text (Koppel and
Ordan, 2011).
</bodyText>
<listItem confidence="0.994144">
3. Normalization: Translated text often con-
tains more formal and repeating language.
4. Interference: A translator is likely to pro-
duce a translation that is structurally and
grammatically closer to the source text or
their native language.
</listItem>
<bodyText confidence="0.961752785714286">
In Figure 1 the size of a word in the “Translated”
section is proportional to the difference between
the frequency of the word in original and in the
translated text (Fellows, 2013). For example, it is
apparent that the word “the” is over-represented
in translated English as noted by other research
(Volansky et al., 2013). In addition, cohesive
markers are clearly more common in translated
text.
In the past few years there has been work on ma-
chine learning techniques for identifying Trans-
lationese. Standard machine learning algorithms
like SVMs (Baroni and Bernardini, 2006) and
Bayesian Logistic Regression (Koppel and Ordan,
2011) have been employed to train classifiers for
one of the following tasks:
i. Given a chunk of text in a specific language,
classify it as “Original” or “Translated”.
ii. Given a chunk of translated text, predict the
source language of the translation.
iii. Given a text chunk pair and their languages,
predict the direction of translation.
There are two stated motivations for the tasks
above: first, empirical validation of linguistic the-
ories about Translationese (Volansky et al., 2013),
and second, improving statistical machine trans-
lation by leveraging the knowledge of the trans-
lation direction in training and test data (Lember-
</bodyText>
<page confidence="0.967574">
159
</page>
<note confidence="0.6310995">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159–164,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.8765975">
Figure 1: EuroParl Word Cloud Data Visualiza-
tion (Translated vs Original) 1
sky et al., 2012a; Lembersky et al., 2013; Lember-
sky et al., 2012b). Few parallel corpora includ-
</figureCaption>
<bodyText confidence="0.957990454545455">
ing a customized version of EuroParl (Islam and
Mehler, 2012) and a processed version of Hansard
(Kurokawa et al., 2009) are labeled for translated
versus original text. Using these limited resources,
it has been shown that taking the translation direc-
tion into account when training a statistical ma-
chine translation system can improve translation
quality (Lembersky et al., 2013). However, im-
proving statistical machine translation using trans-
lation direction information has been limited by
several factors.
</bodyText>
<listItem confidence="0.973962647058823">
1. Limited Labeled Data: The amount of la-
beled data is limited by language and domain
and therefore by itself is not enough to make
a significant improvement in statistical ma-
chine translation.
2. Cross-Domain Scalability: Current meth-
ods of Translationese detection do not scale
across different corpora. For example, a
classifier trained on EuroParl corpus (Koehn,
2005) had in-domain accuracy of 92.7% but
out-of-domain accuracy of 64.8% (Koppel
and Ordan, 2011).
3. Text Chunk Size: The reported high accu-
racy of Translationese detection is based on
relatively large (approximately 1500 tokens)
text chunks (Koppel and Ordan, 2011). When
similar tasks are performed at the sentence
</listItem>
<bodyText confidence="0.938527307692308">
1This word cloud was created using the word-
cloud and tm R packages (Fellows, 2013) from
EuroParl parallel data annotated for translation di-
rection (Islam and Mehler, 2012) obtained from
http://www.hucompute.org/ressourcen/corpora/56.
level the accuracy drops by 15 percentage
points or more (Kurokawa et al., 2009). Fig-
ure 2 shows how detection accuracy drops
with the reduction of the input text chunk
size. Since parallel data are often available
at the sentence level or small chunks of text,
existing detection methods aren’t suitable for
this type of data.
</bodyText>
<figureCaption confidence="0.9233215">
Figure 2: Effects of Chunk Size on Translationese
Detection Accuracy2
</figureCaption>
<bodyText confidence="0.995486666666667">
Motivated by these limitations, in this work we
focus on improving sentence-level classification
accuracy by using non-domain-specific bilingual
features at the sentence level. In addition to im-
proving accuracy, these fine-grained features may
be better able to confirm existing theories or dis-
cover new linguistic phenomena that occur in the
translation process. We use a fast linear classi-
fier trained with online learning, Vowpal Wabbit
(Langford et al., 2007). The Hansard French-
English dataset (Kurokawa et al., 2009) is used for
training and test data in all experiments.
</bodyText>
<sectionHeader confidence="0.99923" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9625492">
While distinct patterns of Translationese have
been studied widely in the past, the work of Ba-
roni and Bernardini (2006) is the first to intro-
duce a computational method for detecting Trans-
lationese with high accuracy. Prior work has
shown in-domain accuracy can be very high at
the chunk-level if fully lexicalized features are
used (Volansky et al., 2013), but then the phenom-
ena learned are clearly not generalizable across
domains. For example, in Figure 1, it can be
observed that content words like “commission”,
“council” or “union” can be used effectively for
classification while they do not capture any gen-
eral linguistic phenomena and are unlikely to scale
2This is a reproduction of the results of Koppel and Or-
dan (2011) using function word frequencies as features for a
logistic regression classifier. Based on the description of how
text chunks were created, the results of the paper (92.7% ac-
curacy) are based on text chunk sizes of approximately 1500
tokens.
</bodyText>
<page confidence="0.993388">
160
</page>
<figureCaption confidence="0.999391">
Figure 3: POS Tagged Aligned Sentence Pairs
</figureCaption>
<bodyText confidence="0.999957545454545">
to other corpora. This is also confirmed by an
average human performance of 72.7% precision
with 82.1% recall on a similar task where the test
subjects were not familiar with the domain and
were not able to use domain-specific lexical fea-
tures (Baroni and Bernardini, 2006). A more gen-
eral feature set still with high in-domain accuracy
is POS tags with lexicalization of function words
(Baroni and Bernardini, 2006; Kurokawa et al.,
2009). We build on this feature set and explore
bilingual features.
The only work to consider features of the two
parallel chunks (one original, one translated) is the
work of Kurokawa et al. (2009). They simply used
the union of the n-gram mixed-POS3 features of
the two sides; these are monolingual features of
the original and translated text and do not look at
translation phenomena directly. Their work is also
the only work to look at sentence level detection
accuracy and report 15 percentage points drop in
accuracy when going from chunk level to sentence
level classification.
</bodyText>
<sectionHeader confidence="0.9833385" genericHeader="method">
3 Bilingual Features for Translation
Direction Classification
</sectionHeader>
<bodyText confidence="0.99994975">
We are interested in learning common localized
linguistic phenomena that occur during the trans-
lation process when translating in one direction
but not the other.
</bodyText>
<subsectionHeader confidence="0.993649">
3.1 POS Tag MTUs
</subsectionHeader>
<bodyText confidence="0.99806825">
Minimal translation units (MTUs) for a sentence
pair are defined as pairs of source and target word
sets that satisfy the following conditions (Quirk
and Menezes, 2006).
</bodyText>
<listItem confidence="0.972775666666667">
1. No alignment links between distinct MTUs.
2. MTUs are not decomposable into smaller
MTUs without violating the previous rule.
</listItem>
<bodyText confidence="0.964931722222222">
We use POS tags to capture linguistic struc-
tures and MTUs to map linguistic structures of
3Only replacing content words with their POS tags while
leaving function words as is.
the two languages. To obtain POS MTUs from
a parallel corpus, first, the parallel corpus is word
aligned. Next, the source and target side of the
corpus are tagged independently. Finally, words
are replaced with their corresponding POS tag
in word-aligned sentence pairs. MTUs were ex-
tracted from the POS tagged word-aligned sen-
tence pairs from left to right and listed in source
order. Unigram, bi-gram, and higher order n-
gram features were built over this sequence of
POS MTUs. For example, for the sentence pair
in Figure 3, the following POS MTUs will be ex-
tracted: VBZPD, PRPP(N,V), RBPADV,
JJPN, .PPUNC.
</bodyText>
<subsectionHeader confidence="0.99298">
3.2 Distortion
</subsectionHeader>
<bodyText confidence="0.999987941176471">
In addition to the mapping of linguistic structures,
another interesting phenomenon is the reordering
of linguistic structures during translation. One hy-
pothesis is that when translating from a fixed-order
to a free-order language, the order of the target will
be very influenced by the source (almost mono-
tone translation), but when translating into a fixed
order language, more re-ordering is required to
ensure grammaticality of the target. To capture
this pattern we add distortion to POS Tag MTU
features. We experiment with absolute distortion
(word position difference between source and tar-
get of a link) as well as HMM distortion (word
position difference between the target of a link and
the target of the previous link). We bin the distor-
tions into three bins: “= 0”, “&gt; 0” and “&lt; 0”, to
reduce sparsity.
</bodyText>
<sectionHeader confidence="0.999141" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.998423">
For the translation direction detection task ex-
plained in section 1, we use a fast linear classi-
fier trained with online learning, Vowpal Wabbit
(Langford et al., 2007). Training data and classi-
fication features are explained in section 4.1 and
4.2.
</bodyText>
<page confidence="0.997735">
161
</page>
<figureCaption confidence="0.9819665">
Figure 4: Sentence level translation direction detection precision using different features with n-gram
lengths of 1 through 5.
</figureCaption>
<subsectionHeader confidence="0.969956">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999938684210526">
For this task we require a parallel corpus with sen-
tence pairs available in both directions (sentences
authored in language A and then translated to lan-
guage B and vice versa). While the customized
version of EuroParl (Islam and Mehler, 2012) con-
tains sentence pairs for many language pairs, none
of the language pairs have sentence pairs available
in both directions (e.g., it does contain sentences
authored in English and translated into French but
not vice versa). The Canadian Hansard corpus
on the other hand fits the requirement as it has
742,408 sentence pairs translated from French to
English and 2,203,504 sentences pairs that were
translated from English to French (Kurokawa et
al., 2009). We use the Hansard data for training
classifiers. For training the HMM word alignment
model used to define features, we use a larger set
of ten billion words of parallel text from the WMT
English-French corpus.
</bodyText>
<subsectionHeader confidence="0.997746">
4.2 Preprocessing and Feature Extraction
</subsectionHeader>
<bodyText confidence="0.99991075">
We used a language filter4, deduplication filter5
and length ratio filter to clean the data. After fil-
tering we were left with 1,890,603 English-French
sentence pairs and 640,117 French-English sen-
tence pairs. The Stanford POS tagger (Toutanova
and Manning, 2000) was used to tag the English
and the French sides of the corpus. The HMM
alignment model (Vogel et al., 1996) trained on
</bodyText>
<footnote confidence="0.91461275">
4A character n-gram language model is used to detect the
language of source and target side text and filter them out if
they do not match their annotated language.
5Duplicate sentences pairs are filtered out.
</footnote>
<bodyText confidence="0.999575230769231">
WMT data was used to word-align the Hansard
corpus while replacing words with their corre-
sponding POS tags. Due to differences in word
breaking between the POS tagger tool and our
word alignment tool there were some mismatches.
For simplicity we dropped the entire sentence pair
whenever a token mismatch occurred. This left us
with 401,569 POS tag aligned sentence pairs in the
French to English direction and 1,184,702 pairs in
the other direction. We chose to create a balanced
dataset and reduced the number of English-French
sentences to 401,679 with 20,000 sentence pairs
held out for testing in each direction.
</bodyText>
<sectionHeader confidence="0.999836" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.9999625625">
The results of our experiments on the translation
direction detection task are listed in Table 4. We
would like to point out several results from the
table. First, when using only unigram features,
the highest accuracy is achieved by the “POS-
MTU + HMM Distortion” feature, which uses
POS minimal translation units together with dis-
tortion. The highest accuracy overall if obtained
by a “POS-MTU” trigram model, showing the ad-
vantage of bilingual features over prior work us-
ing only a union of monolingual features (repro-
duced by the “English-POS + French-POS” con-
figuration). While higher order features generally
show better in-domain accuracy, the advantage of
low-order bilingual features might be even higher
in cross-domain classification.
</bodyText>
<footnote confidence="0.8472155">
6For description of English POS tags see (Marcus et al.,
1993) and (Abeill´e et al., 2003) for French
</footnote>
<page confidence="0.984432">
162
</page>
<table confidence="0.999062428571428">
POS MTU (E⇒F) FE# EF# Example
1 NNPS⇒(N,C) 336 12 quebecers(NNPS) ⇒ qu´eb´ecoises(N) et(C) des qu´eb´ecois
2 TN⇒(CL,V) 69 1027 afew days ago(TN) ⇒ il y(CL) a(V) quelques
3 PRP⇒(N,V) 18 663 he(PRP) is ⇒ le d´eput´e(N) `a(V)
4 (NNP,POS)⇒A 155 28 quebec(NNP) ’s(POS) history ⇒ histoire qu´eb´ecoises(A)
5 (FW,FW)⇒ADV 7 195 pro(FW) bono(FW) work ⇒ b´en´evolement(ADV) travailler
6 (RB,MD)⇒V 2 112 money alone(RB) could(MD) solve ⇒ argent suffirait(V) a` r´esoudre
</table>
<tableCaption confidence="0.9926605">
Table 1: POS MTU features with highest weight. FE# indicates the number of times this feature ap-
peared when translating from French to English.6
</tableCaption>
<sectionHeader confidence="0.960156" genericHeader="method">
6 Analysis
</sectionHeader>
<bodyText confidence="0.999966181818182">
An interesting aspect of this work is that it is able
to extract features that can be linguistically inter-
preted. Although linguistic analysis of these fea-
tures is outside the scope of this work, we list
POS MTU features with highest positive or neg-
ative weights in Table 1. Although the top feature,
NNPS⇒(N,C)7, in this context is originating
from a common phrase used by French speaking
members of the Canadian Parliament, qu´eb´ecoises
et des qu´eb´ecois, it does highlight an underlying
linguistic phenomenon that is not specific to the
Canadian Parliament. When translating a plural
noun from English to French it is likely that only
the masculine form of the noun appears, while if
it was authored in French with both forms of the
nouns, a single plural noun would appear in En-
glish as English doesn’t have masculine and femi-
nine forms of the word. A more complete form of
this feature would have been NNPS⇒(N,C,N),
but since word alignment models, in general, dis-
courage one-to-many alignments, the extracted
MTU only covers the first noun and conjunction.
</bodyText>
<sectionHeader confidence="0.96186" genericHeader="evaluation">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999968857142857">
In this work we introduce new features for transla-
tion direction detection that leverage word align-
ment, source POS and target POS in the form
of POS MTUs. POS MTUs are a powerful tool
for capturing linguistic interactions between lan-
guages during the translation process. Since POS
MTUs are not lexical features they are more likely
to scale across corpora and domains compared to
lexicalized features. Although most of the high
weight POS MTU features used in classification
(Table 1) are not corpus specific, unfortunately,
due to lack of training data in multiple domains,
experiments were not run to validate this claim.
In future work, we intend to obtain training data
</bodyText>
<sectionHeader confidence="0.346735" genericHeader="conclusions">
7NNPS: Plural Noun, N: Noun, C:Conjunction
</sectionHeader>
<bodyText confidence="0.999903428571429">
from multiple domains that enables us to verify
cross-domain scalability of POS-MTUs. In addi-
tion, observing linguistic phenomena that occur in
one translation direction but not the other can be
very informative in improving statistical machine
translation quality. Another future direction for
this work is leveraging sentence level translation
direction detection to improve statistical machine
translation output quality. Finally, further investi-
gation of the linguistic interpretation of individual
feature that are most discriminating between op-
posite translation directions can lead to discovery
of new linguistic phenomena that occur during the
translation process.
</bodyText>
<sectionHeader confidence="0.959493" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999957333333333">
The authors would like to thank Lee Schwartz for
analyzing classification features and providing lin-
guistic insight for them. We would like to also ac-
knowledge the thoughtful comments and detailed
feedback of the reviewers which helped us im-
prove the paper.
</bodyText>
<sectionHeader confidence="0.996835" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.901092">
Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Tou-
ssenel. 2003. Building a treebank for french. In
Anne Abeill´e, editor, Treebanks, volume 20 of Text,
Speech and Language Technology, pages 165–187.
Springer Netherlands.
Mona Baker. 1993. Corpus linguistics and transla-
tion studies: Implications and applications. Text and
technology: in honour of John Sinclair, 233:250.
Marco Baroni and Silvia Bernardini. 2006. A new
approach to the study of translationese: Machine-
learning the difference between original and trans-
lated text. Literary and Linguistic Computing,
21(3):259–274.
Ian Fellows, 2013. wordcloud: Word Clouds. R pack-
age version 2.4.
</reference>
<page confidence="0.995628">
163
</page>
<reference confidence="0.999166169230769">
Zahurul Islam and Alexander Mehler. 2012. Cus-
tomization of the europarl corpus for translation
studies. In LREC, page 2505–2510.
Philipp Koehn. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. In Conference
Proceedings: the tenth Machine Translation Sum-
mit, pages 79–86, Phuket, Thailand. AAMT, AAMT.
Moshe Koppel and Noam Ordan. 2011. Translationese
and its dialects. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies-Volume
1, page 1318–1326. Association for Computational
Linguistics.
David Kurokawa, Cyril Goutte, and Pierre Isabelle.
2009. Automatic detection of translated text and
its impact on machine translation. Proceedings. MT
Summit XII, The twelfth Machine Translation Sum-
mit International Association for Machine Transla-
tion hosted by the Association for Machine Transla-
tion in the Americas.
J Langford, L Li, and A Strehl, 2007. Vowpal wabbit
online learning project.
Gennadi Lembersky, Noam Ordan, and Shuly Wint-
ner. 2012a. Adapting translation models to trans-
lationese improves SMT. In Proceedings of the 13th
Conference of the European Chapter of the Associ-
ation for Computational Linguistics, page 255–265.
Association for Computational Linguistics.
Gennadi Lembersky, Noam Ordan, and Shuly Wint-
ner. 2012b. Language models for machine trans-
lation: Original vs. translated texts. Computational
Linguistics, 38(4):799–825.
Gennadi Lembersky, Noam Ordan, and Shuly Wintner.
2013. Improving statistical machine translation by
adapting translation models to translationese.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: The penn treebank. Com-
put. Linguist., 19(2):313–330, June.
Chris Quirk and Arul Menezes. 2006. Do we need
phrases?: Challenging the conventional wisdom in
statistical machine translation. In Proceedings of
the Main Conference on Human Language Technol-
ogy Conference of the North American Chapter of
the Association of Computational Linguistics, HLT-
NAACL ’06, pages 9–16, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Kristina Toutanova and Christopher D. Manning.
2000. Enriching the knowledge sources used in a
maximum entropy part-of-speech tagger. In Pro-
ceedings of the 2000 Joint SIGDAT Conference on
Empirical Methods in Natural Language Process-
ing and Very Large Corpora: Held in Conjunction
with the 38th Annual Meeting of the Association
for Computational Linguistics - Volume 13, EMNLP
’00, pages 63–70, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. Hmm-based word alignment in statistical
translation. In Proceedings of the 16th conference
on Computational linguistics-Volume 2, pages 836–
841. Association for Computational Linguistics.
Vered Volansky, Noam Ordan, and Shuly Wintner.
2013. On the features of translationese. Literary
and Linguistic Computing, page fqt031.
</reference>
<page confidence="0.998519">
164
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.863965">
<title confidence="0.999781">Asymmetric Features of Human Generated Translation</title>
<author confidence="0.990418">Sauleh Eetemadi Kristina Toutanova</author>
<affiliation confidence="0.949909">Michigan State University, East Lansing, MI Microsoft Research Microsoft Research, Redmond, WA Redmond, WA</affiliation>
<email confidence="0.998623">saulehe@microsoft.comkristout@microsoft.com</email>
<abstract confidence="0.996952173913043">Distinct properties of translated text have been the subject of research in linguistics for many year (Baker, 1993). In recent years computational methods have been developed to empirically verify the linguistic theories about translated text (Baroni and Bernardini, 2006). While many characteristics of translated text are more apparent in comparison to the original text, most of the prior research has focused on monolingual features of translated and original text. The contribution of this work is introducing bilingual features that are capable of explaining differences in translation direction using localized linguistic phenomena at the phrase or sentence level, rather than using monolingual statistics at the document level. We show that these bilingual features outperform the monolingual features used in prior work (Kurokawa et al., 2009) for the task of classifying translation direction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Cl´ement</author>
<author>Franc¸ois Toussenel</author>
</authors>
<title>Building a treebank for french.</title>
<date>2003</date>
<booktitle>Text, Speech and Language Technology,</booktitle>
<volume>20</volume>
<pages>165--187</pages>
<editor>In Anne Abeill´e, editor, Treebanks,</editor>
<publisher>Springer Netherlands.</publisher>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel. 2003. Building a treebank for french. In Anne Abeill´e, editor, Treebanks, volume 20 of Text, Speech and Language Technology, pages 165–187. Springer Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Baker</author>
</authors>
<title>Corpus linguistics and translation studies: Implications and applications. Text and technology: in honour of John Sinclair,</title>
<date>1993</date>
<pages>233--250</pages>
<contexts>
<context position="1308" citStr="Baker, 1993" startWordPosition="192" endWordPosition="193">d and original text. The contribution of this work is introducing bilingual features that are capable of explaining differences in translation direction using localized linguistic phenomena at the phrase or sentence level, rather than using monolingual statistics at the document level. We show that these bilingual features outperform the monolingual features used in prior work (Kurokawa et al., 2009) for the task of classifying translation direction. 1 Introduction It has been known for many years in linguistics that translated text has distinct patterns compared to original or authored text (Baker, 1993). The term “Translationese” is often used to refer to the characteristics of translated text. Patterns of Translationese can be categorized as follows (Volansky et al., 2013): 1. Simplification: The process of translation is often coupled with a simplification process at several levels. For example, there tends to be less lexical variety in translated text and rare words are often avoided. 2. Explicitation: Translators often have to be more explicit in their translations due to lack of the cultural context that speakers of the source language have. Another manifestation of this pattern is maki</context>
</contexts>
<marker>Baker, 1993</marker>
<rawString>Mona Baker. 1993. Corpus linguistics and translation studies: Implications and applications. Text and technology: in honour of John Sinclair, 233:250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
</authors>
<title>A new approach to the study of translationese: Machinelearning the difference between original and translated text.</title>
<date>2006</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>21--3</pages>
<contexts>
<context position="2892" citStr="Baroni and Bernardini, 2006" startWordPosition="440" endWordPosition="443">er to the source text or their native language. In Figure 1 the size of a word in the “Translated” section is proportional to the difference between the frequency of the word in original and in the translated text (Fellows, 2013). For example, it is apparent that the word “the” is over-represented in translated English as noted by other research (Volansky et al., 2013). In addition, cohesive markers are clearly more common in translated text. In the past few years there has been work on machine learning techniques for identifying Translationese. Standard machine learning algorithms like SVMs (Baroni and Bernardini, 2006) and Bayesian Logistic Regression (Koppel and Ordan, 2011) have been employed to train classifiers for one of the following tasks: i. Given a chunk of text in a specific language, classify it as “Original” or “Translated”. ii. Given a chunk of translated text, predict the source language of the translation. iii. Given a text chunk pair and their languages, predict the direction of translation. There are two stated motivations for the tasks above: first, empirical validation of linguistic theories about Translationese (Volansky et al., 2013), and second, improving statistical machine translatio</context>
<context position="6496" citStr="Baroni and Bernardini (2006)" startWordPosition="992" endWordPosition="996">ssification accuracy by using non-domain-specific bilingual features at the sentence level. In addition to improving accuracy, these fine-grained features may be better able to confirm existing theories or discover new linguistic phenomena that occur in the translation process. We use a fast linear classifier trained with online learning, Vowpal Wabbit (Langford et al., 2007). The Hansard FrenchEnglish dataset (Kurokawa et al., 2009) is used for training and test data in all experiments. 2 Related Work While distinct patterns of Translationese have been studied widely in the past, the work of Baroni and Bernardini (2006) is the first to introduce a computational method for detecting Translationese with high accuracy. Prior work has shown in-domain accuracy can be very high at the chunk-level if fully lexicalized features are used (Volansky et al., 2013), but then the phenomena learned are clearly not generalizable across domains. For example, in Figure 1, it can be observed that content words like “commission”, “council” or “union” can be used effectively for classification while they do not capture any general linguistic phenomena and are unlikely to scale 2This is a reproduction of the results of Koppel and</context>
<context position="7815" citStr="Baroni and Bernardini, 2006" startWordPosition="1211" endWordPosition="1214">er. Based on the description of how text chunks were created, the results of the paper (92.7% accuracy) are based on text chunk sizes of approximately 1500 tokens. 160 Figure 3: POS Tagged Aligned Sentence Pairs to other corpora. This is also confirmed by an average human performance of 72.7% precision with 82.1% recall on a similar task where the test subjects were not familiar with the domain and were not able to use domain-specific lexical features (Baroni and Bernardini, 2006). A more general feature set still with high in-domain accuracy is POS tags with lexicalization of function words (Baroni and Bernardini, 2006; Kurokawa et al., 2009). We build on this feature set and explore bilingual features. The only work to consider features of the two parallel chunks (one original, one translated) is the work of Kurokawa et al. (2009). They simply used the union of the n-gram mixed-POS3 features of the two sides; these are monolingual features of the original and translated text and do not look at translation phenomena directly. Their work is also the only work to look at sentence level detection accuracy and report 15 percentage points drop in accuracy when going from chunk level to sentence level classificat</context>
</contexts>
<marker>Baroni, Bernardini, 2006</marker>
<rawString>Marco Baroni and Silvia Bernardini. 2006. A new approach to the study of translationese: Machinelearning the difference between original and translated text. Literary and Linguistic Computing, 21(3):259–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Fellows</author>
</authors>
<title>wordcloud: Word Clouds. R package version 2.4.</title>
<date>2013</date>
<contexts>
<context position="2493" citStr="Fellows, 2013" startWordPosition="380" endWordPosition="381">ation of this pattern is making arguments more explicit which can be observed in the heavy use of cohesive markers like “therefore” and “moreover” in translated text (Koppel and Ordan, 2011). 3. Normalization: Translated text often contains more formal and repeating language. 4. Interference: A translator is likely to produce a translation that is structurally and grammatically closer to the source text or their native language. In Figure 1 the size of a word in the “Translated” section is proportional to the difference between the frequency of the word in original and in the translated text (Fellows, 2013). For example, it is apparent that the word “the” is over-represented in translated English as noted by other research (Volansky et al., 2013). In addition, cohesive markers are clearly more common in translated text. In the past few years there has been work on machine learning techniques for identifying Translationese. Standard machine learning algorithms like SVMs (Baroni and Bernardini, 2006) and Bayesian Logistic Regression (Koppel and Ordan, 2011) have been employed to train classifiers for one of the following tasks: i. Given a chunk of text in a specific language, classify it as “Origi</context>
<context position="5233" citStr="Fellows, 2013" startWordPosition="802" endWordPosition="803">ent in statistical machine translation. 2. Cross-Domain Scalability: Current methods of Translationese detection do not scale across different corpora. For example, a classifier trained on EuroParl corpus (Koehn, 2005) had in-domain accuracy of 92.7% but out-of-domain accuracy of 64.8% (Koppel and Ordan, 2011). 3. Text Chunk Size: The reported high accuracy of Translationese detection is based on relatively large (approximately 1500 tokens) text chunks (Koppel and Ordan, 2011). When similar tasks are performed at the sentence 1This word cloud was created using the wordcloud and tm R packages (Fellows, 2013) from EuroParl parallel data annotated for translation direction (Islam and Mehler, 2012) obtained from http://www.hucompute.org/ressourcen/corpora/56. level the accuracy drops by 15 percentage points or more (Kurokawa et al., 2009). Figure 2 shows how detection accuracy drops with the reduction of the input text chunk size. Since parallel data are often available at the sentence level or small chunks of text, existing detection methods aren’t suitable for this type of data. Figure 2: Effects of Chunk Size on Translationese Detection Accuracy2 Motivated by these limitations, in this work we fo</context>
</contexts>
<marker>Fellows, 2013</marker>
<rawString>Ian Fellows, 2013. wordcloud: Word Clouds. R package version 2.4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zahurul Islam</author>
<author>Alexander Mehler</author>
</authors>
<title>Customization of the europarl corpus for translation studies.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<pages>2505--2510</pages>
<contexts>
<context position="4015" citStr="Islam and Mehler, 2012" startWordPosition="613" endWordPosition="616">s about Translationese (Volansky et al., 2013), and second, improving statistical machine translation by leveraging the knowledge of the translation direction in training and test data (Lember159 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159–164, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: EuroParl Word Cloud Data Visualization (Translated vs Original) 1 sky et al., 2012a; Lembersky et al., 2013; Lembersky et al., 2012b). Few parallel corpora including a customized version of EuroParl (Islam and Mehler, 2012) and a processed version of Hansard (Kurokawa et al., 2009) are labeled for translated versus original text. Using these limited resources, it has been shown that taking the translation direction into account when training a statistical machine translation system can improve translation quality (Lembersky et al., 2013). However, improving statistical machine translation using translation direction information has been limited by several factors. 1. Limited Labeled Data: The amount of labeled data is limited by language and domain and therefore by itself is not enough to make a significant impr</context>
<context position="5322" citStr="Islam and Mehler, 2012" startWordPosition="813" endWordPosition="816">hods of Translationese detection do not scale across different corpora. For example, a classifier trained on EuroParl corpus (Koehn, 2005) had in-domain accuracy of 92.7% but out-of-domain accuracy of 64.8% (Koppel and Ordan, 2011). 3. Text Chunk Size: The reported high accuracy of Translationese detection is based on relatively large (approximately 1500 tokens) text chunks (Koppel and Ordan, 2011). When similar tasks are performed at the sentence 1This word cloud was created using the wordcloud and tm R packages (Fellows, 2013) from EuroParl parallel data annotated for translation direction (Islam and Mehler, 2012) obtained from http://www.hucompute.org/ressourcen/corpora/56. level the accuracy drops by 15 percentage points or more (Kurokawa et al., 2009). Figure 2 shows how detection accuracy drops with the reduction of the input text chunk size. Since parallel data are often available at the sentence level or small chunks of text, existing detection methods aren’t suitable for this type of data. Figure 2: Effects of Chunk Size on Translationese Detection Accuracy2 Motivated by these limitations, in this work we focus on improving sentence-level classification accuracy by using non-domain-specific bili</context>
<context position="11232" citStr="Islam and Mehler, 2012" startWordPosition="1768" endWordPosition="1771">anslation direction detection task explained in section 1, we use a fast linear classifier trained with online learning, Vowpal Wabbit (Langford et al., 2007). Training data and classification features are explained in section 4.1 and 4.2. 161 Figure 4: Sentence level translation direction detection precision using different features with n-gram lengths of 1 through 5. 4.1 Data For this task we require a parallel corpus with sentence pairs available in both directions (sentences authored in language A and then translated to language B and vice versa). While the customized version of EuroParl (Islam and Mehler, 2012) contains sentence pairs for many language pairs, none of the language pairs have sentence pairs available in both directions (e.g., it does contain sentences authored in English and translated into French but not vice versa). The Canadian Hansard corpus on the other hand fits the requirement as it has 742,408 sentence pairs translated from French to English and 2,203,504 sentences pairs that were translated from English to French (Kurokawa et al., 2009). We use the Hansard data for training classifiers. For training the HMM word alignment model used to define features, we use a larger set of </context>
</contexts>
<marker>Islam, Mehler, 2012</marker>
<rawString>Zahurul Islam and Alexander Mehler. 2012. Customization of the europarl corpus for translation studies. In LREC, page 2505–2510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Conference Proceedings: the tenth Machine Translation Summit,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand. AAMT, AAMT.</location>
<contexts>
<context position="4837" citStr="Koehn, 2005" startWordPosition="739" endWordPosition="740">hen training a statistical machine translation system can improve translation quality (Lembersky et al., 2013). However, improving statistical machine translation using translation direction information has been limited by several factors. 1. Limited Labeled Data: The amount of labeled data is limited by language and domain and therefore by itself is not enough to make a significant improvement in statistical machine translation. 2. Cross-Domain Scalability: Current methods of Translationese detection do not scale across different corpora. For example, a classifier trained on EuroParl corpus (Koehn, 2005) had in-domain accuracy of 92.7% but out-of-domain accuracy of 64.8% (Koppel and Ordan, 2011). 3. Text Chunk Size: The reported high accuracy of Translationese detection is based on relatively large (approximately 1500 tokens) text chunks (Koppel and Ordan, 2011). When similar tasks are performed at the sentence 1This word cloud was created using the wordcloud and tm R packages (Fellows, 2013) from EuroParl parallel data annotated for translation direction (Islam and Mehler, 2012) obtained from http://www.hucompute.org/ressourcen/corpora/56. level the accuracy drops by 15 percentage points or </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Conference Proceedings: the tenth Machine Translation Summit, pages 79–86, Phuket, Thailand. AAMT, AAMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel</author>
<author>Noam Ordan</author>
</authors>
<title>Translationese and its dialects.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1318--1326</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2069" citStr="Koppel and Ordan, 2011" startWordPosition="309" endWordPosition="312">d as follows (Volansky et al., 2013): 1. Simplification: The process of translation is often coupled with a simplification process at several levels. For example, there tends to be less lexical variety in translated text and rare words are often avoided. 2. Explicitation: Translators often have to be more explicit in their translations due to lack of the cultural context that speakers of the source language have. Another manifestation of this pattern is making arguments more explicit which can be observed in the heavy use of cohesive markers like “therefore” and “moreover” in translated text (Koppel and Ordan, 2011). 3. Normalization: Translated text often contains more formal and repeating language. 4. Interference: A translator is likely to produce a translation that is structurally and grammatically closer to the source text or their native language. In Figure 1 the size of a word in the “Translated” section is proportional to the difference between the frequency of the word in original and in the translated text (Fellows, 2013). For example, it is apparent that the word “the” is over-represented in translated English as noted by other research (Volansky et al., 2013). In addition, cohesive markers ar</context>
<context position="4930" citStr="Koppel and Ordan, 2011" startWordPosition="751" endWordPosition="754">ity (Lembersky et al., 2013). However, improving statistical machine translation using translation direction information has been limited by several factors. 1. Limited Labeled Data: The amount of labeled data is limited by language and domain and therefore by itself is not enough to make a significant improvement in statistical machine translation. 2. Cross-Domain Scalability: Current methods of Translationese detection do not scale across different corpora. For example, a classifier trained on EuroParl corpus (Koehn, 2005) had in-domain accuracy of 92.7% but out-of-domain accuracy of 64.8% (Koppel and Ordan, 2011). 3. Text Chunk Size: The reported high accuracy of Translationese detection is based on relatively large (approximately 1500 tokens) text chunks (Koppel and Ordan, 2011). When similar tasks are performed at the sentence 1This word cloud was created using the wordcloud and tm R packages (Fellows, 2013) from EuroParl parallel data annotated for translation direction (Islam and Mehler, 2012) obtained from http://www.hucompute.org/ressourcen/corpora/56. level the accuracy drops by 15 percentage points or more (Kurokawa et al., 2009). Figure 2 shows how detection accuracy drops with the reduction </context>
<context position="7109" citStr="Koppel and Ordan (2011)" startWordPosition="1094" endWordPosition="1098">ini (2006) is the first to introduce a computational method for detecting Translationese with high accuracy. Prior work has shown in-domain accuracy can be very high at the chunk-level if fully lexicalized features are used (Volansky et al., 2013), but then the phenomena learned are clearly not generalizable across domains. For example, in Figure 1, it can be observed that content words like “commission”, “council” or “union” can be used effectively for classification while they do not capture any general linguistic phenomena and are unlikely to scale 2This is a reproduction of the results of Koppel and Ordan (2011) using function word frequencies as features for a logistic regression classifier. Based on the description of how text chunks were created, the results of the paper (92.7% accuracy) are based on text chunk sizes of approximately 1500 tokens. 160 Figure 3: POS Tagged Aligned Sentence Pairs to other corpora. This is also confirmed by an average human performance of 72.7% precision with 82.1% recall on a similar task where the test subjects were not familiar with the domain and were not able to use domain-specific lexical features (Baroni and Bernardini, 2006). A more general feature set still w</context>
</contexts>
<marker>Koppel, Ordan, 2011</marker>
<rawString>Moshe Koppel and Noam Ordan. 2011. Translationese and its dialects. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, page 1318–1326. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kurokawa</author>
<author>Cyril Goutte</author>
<author>Pierre Isabelle</author>
</authors>
<title>Automatic detection of translated text and its impact on machine translation.</title>
<date>2009</date>
<booktitle>Proceedings. MT Summit XII, The twelfth Machine Translation Summit International Association for Machine Translation</booktitle>
<contexts>
<context position="1099" citStr="Kurokawa et al., 2009" startWordPosition="156" endWordPosition="159">nslated text (Baroni and Bernardini, 2006). While many characteristics of translated text are more apparent in comparison to the original text, most of the prior research has focused on monolingual features of translated and original text. The contribution of this work is introducing bilingual features that are capable of explaining differences in translation direction using localized linguistic phenomena at the phrase or sentence level, rather than using monolingual statistics at the document level. We show that these bilingual features outperform the monolingual features used in prior work (Kurokawa et al., 2009) for the task of classifying translation direction. 1 Introduction It has been known for many years in linguistics that translated text has distinct patterns compared to original or authored text (Baker, 1993). The term “Translationese” is often used to refer to the characteristics of translated text. Patterns of Translationese can be categorized as follows (Volansky et al., 2013): 1. Simplification: The process of translation is often coupled with a simplification process at several levels. For example, there tends to be less lexical variety in translated text and rare words are often avoided</context>
<context position="4074" citStr="Kurokawa et al., 2009" startWordPosition="623" endWordPosition="626">improving statistical machine translation by leveraging the knowledge of the translation direction in training and test data (Lember159 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159–164, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: EuroParl Word Cloud Data Visualization (Translated vs Original) 1 sky et al., 2012a; Lembersky et al., 2013; Lembersky et al., 2012b). Few parallel corpora including a customized version of EuroParl (Islam and Mehler, 2012) and a processed version of Hansard (Kurokawa et al., 2009) are labeled for translated versus original text. Using these limited resources, it has been shown that taking the translation direction into account when training a statistical machine translation system can improve translation quality (Lembersky et al., 2013). However, improving statistical machine translation using translation direction information has been limited by several factors. 1. Limited Labeled Data: The amount of labeled data is limited by language and domain and therefore by itself is not enough to make a significant improvement in statistical machine translation. 2. Cross-Domain</context>
<context position="5465" citStr="Kurokawa et al., 2009" startWordPosition="830" endWordPosition="833">n-domain accuracy of 92.7% but out-of-domain accuracy of 64.8% (Koppel and Ordan, 2011). 3. Text Chunk Size: The reported high accuracy of Translationese detection is based on relatively large (approximately 1500 tokens) text chunks (Koppel and Ordan, 2011). When similar tasks are performed at the sentence 1This word cloud was created using the wordcloud and tm R packages (Fellows, 2013) from EuroParl parallel data annotated for translation direction (Islam and Mehler, 2012) obtained from http://www.hucompute.org/ressourcen/corpora/56. level the accuracy drops by 15 percentage points or more (Kurokawa et al., 2009). Figure 2 shows how detection accuracy drops with the reduction of the input text chunk size. Since parallel data are often available at the sentence level or small chunks of text, existing detection methods aren’t suitable for this type of data. Figure 2: Effects of Chunk Size on Translationese Detection Accuracy2 Motivated by these limitations, in this work we focus on improving sentence-level classification accuracy by using non-domain-specific bilingual features at the sentence level. In addition to improving accuracy, these fine-grained features may be better able to confirm existing the</context>
<context position="7839" citStr="Kurokawa et al., 2009" startWordPosition="1215" endWordPosition="1218">of how text chunks were created, the results of the paper (92.7% accuracy) are based on text chunk sizes of approximately 1500 tokens. 160 Figure 3: POS Tagged Aligned Sentence Pairs to other corpora. This is also confirmed by an average human performance of 72.7% precision with 82.1% recall on a similar task where the test subjects were not familiar with the domain and were not able to use domain-specific lexical features (Baroni and Bernardini, 2006). A more general feature set still with high in-domain accuracy is POS tags with lexicalization of function words (Baroni and Bernardini, 2006; Kurokawa et al., 2009). We build on this feature set and explore bilingual features. The only work to consider features of the two parallel chunks (one original, one translated) is the work of Kurokawa et al. (2009). They simply used the union of the n-gram mixed-POS3 features of the two sides; these are monolingual features of the original and translated text and do not look at translation phenomena directly. Their work is also the only work to look at sentence level detection accuracy and report 15 percentage points drop in accuracy when going from chunk level to sentence level classification. 3 Bilingual Feature</context>
<context position="11690" citStr="Kurokawa et al., 2009" startWordPosition="1841" endWordPosition="1844">th directions (sentences authored in language A and then translated to language B and vice versa). While the customized version of EuroParl (Islam and Mehler, 2012) contains sentence pairs for many language pairs, none of the language pairs have sentence pairs available in both directions (e.g., it does contain sentences authored in English and translated into French but not vice versa). The Canadian Hansard corpus on the other hand fits the requirement as it has 742,408 sentence pairs translated from French to English and 2,203,504 sentences pairs that were translated from English to French (Kurokawa et al., 2009). We use the Hansard data for training classifiers. For training the HMM word alignment model used to define features, we use a larger set of ten billion words of parallel text from the WMT English-French corpus. 4.2 Preprocessing and Feature Extraction We used a language filter4, deduplication filter5 and length ratio filter to clean the data. After filtering we were left with 1,890,603 English-French sentence pairs and 640,117 French-English sentence pairs. The Stanford POS tagger (Toutanova and Manning, 2000) was used to tag the English and the French sides of the corpus. The HMM alignment </context>
</contexts>
<marker>Kurokawa, Goutte, Isabelle, 2009</marker>
<rawString>David Kurokawa, Cyril Goutte, and Pierre Isabelle. 2009. Automatic detection of translated text and its impact on machine translation. Proceedings. MT Summit XII, The twelfth Machine Translation Summit International Association for Machine Translation hosted by the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Langford</author>
<author>L Li</author>
<author>A Strehl</author>
</authors>
<title>Vowpal wabbit online learning project.</title>
<date>2007</date>
<contexts>
<context position="6246" citStr="Langford et al., 2007" startWordPosition="951" endWordPosition="954"> small chunks of text, existing detection methods aren’t suitable for this type of data. Figure 2: Effects of Chunk Size on Translationese Detection Accuracy2 Motivated by these limitations, in this work we focus on improving sentence-level classification accuracy by using non-domain-specific bilingual features at the sentence level. In addition to improving accuracy, these fine-grained features may be better able to confirm existing theories or discover new linguistic phenomena that occur in the translation process. We use a fast linear classifier trained with online learning, Vowpal Wabbit (Langford et al., 2007). The Hansard FrenchEnglish dataset (Kurokawa et al., 2009) is used for training and test data in all experiments. 2 Related Work While distinct patterns of Translationese have been studied widely in the past, the work of Baroni and Bernardini (2006) is the first to introduce a computational method for detecting Translationese with high accuracy. Prior work has shown in-domain accuracy can be very high at the chunk-level if fully lexicalized features are used (Volansky et al., 2013), but then the phenomena learned are clearly not generalizable across domains. For example, in Figure 1, it can b</context>
<context position="10767" citStr="Langford et al., 2007" startWordPosition="1693" endWordPosition="1696">ordering is required to ensure grammaticality of the target. To capture this pattern we add distortion to POS Tag MTU features. We experiment with absolute distortion (word position difference between source and target of a link) as well as HMM distortion (word position difference between the target of a link and the target of the previous link). We bin the distortions into three bins: “= 0”, “&gt; 0” and “&lt; 0”, to reduce sparsity. 4 Experimental Setup For the translation direction detection task explained in section 1, we use a fast linear classifier trained with online learning, Vowpal Wabbit (Langford et al., 2007). Training data and classification features are explained in section 4.1 and 4.2. 161 Figure 4: Sentence level translation direction detection precision using different features with n-gram lengths of 1 through 5. 4.1 Data For this task we require a parallel corpus with sentence pairs available in both directions (sentences authored in language A and then translated to language B and vice versa). While the customized version of EuroParl (Islam and Mehler, 2012) contains sentence pairs for many language pairs, none of the language pairs have sentence pairs available in both directions (e.g., it</context>
</contexts>
<marker>Langford, Li, Strehl, 2007</marker>
<rawString>J Langford, L Li, and A Strehl, 2007. Vowpal wabbit online learning project.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gennadi Lembersky</author>
<author>Noam Ordan</author>
<author>Shuly Wintner</author>
</authors>
<title>Adapting translation models to translationese improves SMT.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>255--265</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="3923" citStr="Lembersky et al., 2012" startWordPosition="598" endWordPosition="602">o stated motivations for the tasks above: first, empirical validation of linguistic theories about Translationese (Volansky et al., 2013), and second, improving statistical machine translation by leveraging the knowledge of the translation direction in training and test data (Lember159 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159–164, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: EuroParl Word Cloud Data Visualization (Translated vs Original) 1 sky et al., 2012a; Lembersky et al., 2013; Lembersky et al., 2012b). Few parallel corpora including a customized version of EuroParl (Islam and Mehler, 2012) and a processed version of Hansard (Kurokawa et al., 2009) are labeled for translated versus original text. Using these limited resources, it has been shown that taking the translation direction into account when training a statistical machine translation system can improve translation quality (Lembersky et al., 2013). However, improving statistical machine translation using translation direction information has been limited by several factors. 1. Limited Labeled Data: The amount of labeled data is lim</context>
</contexts>
<marker>Lembersky, Ordan, Wintner, 2012</marker>
<rawString>Gennadi Lembersky, Noam Ordan, and Shuly Wintner. 2012a. Adapting translation models to translationese improves SMT. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, page 255–265. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gennadi Lembersky</author>
<author>Noam Ordan</author>
<author>Shuly Wintner</author>
</authors>
<title>Language models for machine translation: Original vs. translated texts.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>4</issue>
<contexts>
<context position="3923" citStr="Lembersky et al., 2012" startWordPosition="598" endWordPosition="602">o stated motivations for the tasks above: first, empirical validation of linguistic theories about Translationese (Volansky et al., 2013), and second, improving statistical machine translation by leveraging the knowledge of the translation direction in training and test data (Lember159 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159–164, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: EuroParl Word Cloud Data Visualization (Translated vs Original) 1 sky et al., 2012a; Lembersky et al., 2013; Lembersky et al., 2012b). Few parallel corpora including a customized version of EuroParl (Islam and Mehler, 2012) and a processed version of Hansard (Kurokawa et al., 2009) are labeled for translated versus original text. Using these limited resources, it has been shown that taking the translation direction into account when training a statistical machine translation system can improve translation quality (Lembersky et al., 2013). However, improving statistical machine translation using translation direction information has been limited by several factors. 1. Limited Labeled Data: The amount of labeled data is lim</context>
</contexts>
<marker>Lembersky, Ordan, Wintner, 2012</marker>
<rawString>Gennadi Lembersky, Noam Ordan, and Shuly Wintner. 2012b. Language models for machine translation: Original vs. translated texts. Computational Linguistics, 38(4):799–825.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gennadi Lembersky</author>
<author>Noam Ordan</author>
<author>Shuly Wintner</author>
</authors>
<title>Improving statistical machine translation by adapting translation models to translationese.</title>
<date>2013</date>
<contexts>
<context position="3899" citStr="Lembersky et al., 2013" startWordPosition="594" endWordPosition="597">ranslation. There are two stated motivations for the tasks above: first, empirical validation of linguistic theories about Translationese (Volansky et al., 2013), and second, improving statistical machine translation by leveraging the knowledge of the translation direction in training and test data (Lember159 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159–164, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: EuroParl Word Cloud Data Visualization (Translated vs Original) 1 sky et al., 2012a; Lembersky et al., 2013; Lembersky et al., 2012b). Few parallel corpora including a customized version of EuroParl (Islam and Mehler, 2012) and a processed version of Hansard (Kurokawa et al., 2009) are labeled for translated versus original text. Using these limited resources, it has been shown that taking the translation direction into account when training a statistical machine translation system can improve translation quality (Lembersky et al., 2013). However, improving statistical machine translation using translation direction information has been limited by several factors. 1. Limited Labeled Data: The amoun</context>
</contexts>
<marker>Lembersky, Ordan, Wintner, 2013</marker>
<rawString>Gennadi Lembersky, Noam Ordan, and Shuly Wintner. 2013. Improving statistical machine translation by adapting translation models to translationese.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="13972" citStr="Marcus et al., 1993" startWordPosition="2210" endWordPosition="2213"> features, the highest accuracy is achieved by the “POSMTU + HMM Distortion” feature, which uses POS minimal translation units together with distortion. The highest accuracy overall if obtained by a “POS-MTU” trigram model, showing the advantage of bilingual features over prior work using only a union of monolingual features (reproduced by the “English-POS + French-POS” configuration). While higher order features generally show better in-domain accuracy, the advantage of low-order bilingual features might be even higher in cross-domain classification. 6For description of English POS tags see (Marcus et al., 1993) and (Abeill´e et al., 2003) for French 162 POS MTU (E⇒F) FE# EF# Example 1 NNPS⇒(N,C) 336 12 quebecers(NNPS) ⇒ qu´eb´ecoises(N) et(C) des qu´eb´ecois 2 TN⇒(CL,V) 69 1027 afew days ago(TN) ⇒ il y(CL) a(V) quelques 3 PRP⇒(N,V) 18 663 he(PRP) is ⇒ le d´eput´e(N) `a(V) 4 (NNP,POS)⇒A 155 28 quebec(NNP) ’s(POS) history ⇒ histoire qu´eb´ecoises(A) 5 (FW,FW)⇒ADV 7 195 pro(FW) bono(FW) work ⇒ b´en´evolement(ADV) travailler 6 (RB,MD)⇒V 2 112 money alone(RB) could(MD) solve ⇒ argent suffirait(V) a` r´esoudre Table 1: POS MTU features with highest weight. FE# indicates the number of times this feature ap</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of english: The penn treebank. Comput. Linguist., 19(2):313–330, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
</authors>
<title>Do we need phrases?: Challenging the conventional wisdom in statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLTNAACL ’06,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8830" citStr="Quirk and Menezes, 2006" startWordPosition="1374" endWordPosition="1377">tion phenomena directly. Their work is also the only work to look at sentence level detection accuracy and report 15 percentage points drop in accuracy when going from chunk level to sentence level classification. 3 Bilingual Features for Translation Direction Classification We are interested in learning common localized linguistic phenomena that occur during the translation process when translating in one direction but not the other. 3.1 POS Tag MTUs Minimal translation units (MTUs) for a sentence pair are defined as pairs of source and target word sets that satisfy the following conditions (Quirk and Menezes, 2006). 1. No alignment links between distinct MTUs. 2. MTUs are not decomposable into smaller MTUs without violating the previous rule. We use POS tags to capture linguistic structures and MTUs to map linguistic structures of 3Only replacing content words with their POS tags while leaving function words as is. the two languages. To obtain POS MTUs from a parallel corpus, first, the parallel corpus is word aligned. Next, the source and target side of the corpus are tagged independently. Finally, words are replaced with their corresponding POS tag in word-aligned sentence pairs. MTUs were extracted f</context>
</contexts>
<marker>Quirk, Menezes, 2006</marker>
<rawString>Chris Quirk and Arul Menezes. 2006. Do we need phrases?: Challenging the conventional wisdom in statistical machine translation. In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLTNAACL ’06, pages 9–16, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
</authors>
<title>Enriching the knowledge sources used in a maximum entropy part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2000 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora: Held in Conjunction with the 38th Annual Meeting of the Association for Computational Linguistics - Volume 13, EMNLP ’00,</booktitle>
<pages>63--70</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12207" citStr="Toutanova and Manning, 2000" startWordPosition="1922" endWordPosition="1925">ch to English and 2,203,504 sentences pairs that were translated from English to French (Kurokawa et al., 2009). We use the Hansard data for training classifiers. For training the HMM word alignment model used to define features, we use a larger set of ten billion words of parallel text from the WMT English-French corpus. 4.2 Preprocessing and Feature Extraction We used a language filter4, deduplication filter5 and length ratio filter to clean the data. After filtering we were left with 1,890,603 English-French sentence pairs and 640,117 French-English sentence pairs. The Stanford POS tagger (Toutanova and Manning, 2000) was used to tag the English and the French sides of the corpus. The HMM alignment model (Vogel et al., 1996) trained on 4A character n-gram language model is used to detect the language of source and target side text and filter them out if they do not match their annotated language. 5Duplicate sentences pairs are filtered out. WMT data was used to word-align the Hansard corpus while replacing words with their corresponding POS tags. Due to differences in word breaking between the POS tagger tool and our word alignment tool there were some mismatches. For simplicity we dropped the entire sente</context>
</contexts>
<marker>Toutanova, Manning, 2000</marker>
<rawString>Kristina Toutanova and Christopher D. Manning. 2000. Enriching the knowledge sources used in a maximum entropy part-of-speech tagger. In Proceedings of the 2000 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora: Held in Conjunction with the 38th Annual Meeting of the Association for Computational Linguistics - Volume 13, EMNLP ’00, pages 63–70, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>Hmm-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th conference on Computational linguistics-Volume 2,</booktitle>
<pages>836--841</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12316" citStr="Vogel et al., 1996" startWordPosition="1943" endWordPosition="1946">e the Hansard data for training classifiers. For training the HMM word alignment model used to define features, we use a larger set of ten billion words of parallel text from the WMT English-French corpus. 4.2 Preprocessing and Feature Extraction We used a language filter4, deduplication filter5 and length ratio filter to clean the data. After filtering we were left with 1,890,603 English-French sentence pairs and 640,117 French-English sentence pairs. The Stanford POS tagger (Toutanova and Manning, 2000) was used to tag the English and the French sides of the corpus. The HMM alignment model (Vogel et al., 1996) trained on 4A character n-gram language model is used to detect the language of source and target side text and filter them out if they do not match their annotated language. 5Duplicate sentences pairs are filtered out. WMT data was used to word-align the Hansard corpus while replacing words with their corresponding POS tags. Due to differences in word breaking between the POS tagger tool and our word alignment tool there were some mismatches. For simplicity we dropped the entire sentence pair whenever a token mismatch occurred. This left us with 401,569 POS tag aligned sentence pairs in the </context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. Hmm-based word alignment in statistical translation. In Proceedings of the 16th conference on Computational linguistics-Volume 2, pages 836– 841. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vered Volansky</author>
<author>Noam Ordan</author>
<author>Shuly Wintner</author>
</authors>
<title>On the features of translationese.</title>
<date>2013</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>031</pages>
<contexts>
<context position="1482" citStr="Volansky et al., 2013" startWordPosition="216" endWordPosition="219">ized linguistic phenomena at the phrase or sentence level, rather than using monolingual statistics at the document level. We show that these bilingual features outperform the monolingual features used in prior work (Kurokawa et al., 2009) for the task of classifying translation direction. 1 Introduction It has been known for many years in linguistics that translated text has distinct patterns compared to original or authored text (Baker, 1993). The term “Translationese” is often used to refer to the characteristics of translated text. Patterns of Translationese can be categorized as follows (Volansky et al., 2013): 1. Simplification: The process of translation is often coupled with a simplification process at several levels. For example, there tends to be less lexical variety in translated text and rare words are often avoided. 2. Explicitation: Translators often have to be more explicit in their translations due to lack of the cultural context that speakers of the source language have. Another manifestation of this pattern is making arguments more explicit which can be observed in the heavy use of cohesive markers like “therefore” and “moreover” in translated text (Koppel and Ordan, 2011). 3. Normaliz</context>
<context position="3438" citStr="Volansky et al., 2013" startWordPosition="526" endWordPosition="529">Standard machine learning algorithms like SVMs (Baroni and Bernardini, 2006) and Bayesian Logistic Regression (Koppel and Ordan, 2011) have been employed to train classifiers for one of the following tasks: i. Given a chunk of text in a specific language, classify it as “Original” or “Translated”. ii. Given a chunk of translated text, predict the source language of the translation. iii. Given a text chunk pair and their languages, predict the direction of translation. There are two stated motivations for the tasks above: first, empirical validation of linguistic theories about Translationese (Volansky et al., 2013), and second, improving statistical machine translation by leveraging the knowledge of the translation direction in training and test data (Lember159 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 159–164, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Figure 1: EuroParl Word Cloud Data Visualization (Translated vs Original) 1 sky et al., 2012a; Lembersky et al., 2013; Lembersky et al., 2012b). Few parallel corpora including a customized version of EuroParl (Islam and Mehler, 2012) and a processed versio</context>
<context position="6733" citStr="Volansky et al., 2013" startWordPosition="1032" endWordPosition="1035">t occur in the translation process. We use a fast linear classifier trained with online learning, Vowpal Wabbit (Langford et al., 2007). The Hansard FrenchEnglish dataset (Kurokawa et al., 2009) is used for training and test data in all experiments. 2 Related Work While distinct patterns of Translationese have been studied widely in the past, the work of Baroni and Bernardini (2006) is the first to introduce a computational method for detecting Translationese with high accuracy. Prior work has shown in-domain accuracy can be very high at the chunk-level if fully lexicalized features are used (Volansky et al., 2013), but then the phenomena learned are clearly not generalizable across domains. For example, in Figure 1, it can be observed that content words like “commission”, “council” or “union” can be used effectively for classification while they do not capture any general linguistic phenomena and are unlikely to scale 2This is a reproduction of the results of Koppel and Ordan (2011) using function word frequencies as features for a logistic regression classifier. Based on the description of how text chunks were created, the results of the paper (92.7% accuracy) are based on text chunk sizes of approxim</context>
</contexts>
<marker>Volansky, Ordan, Wintner, 2013</marker>
<rawString>Vered Volansky, Noam Ordan, and Shuly Wintner. 2013. On the features of translationese. Literary and Linguistic Computing, page fqt031.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>