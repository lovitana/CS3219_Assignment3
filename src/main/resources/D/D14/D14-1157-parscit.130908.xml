<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000682">
<title confidence="0.998055">
Staying on Topic:
An Indicator of Power in Political Debates
</title>
<author confidence="0.995657">
Vinodkumar Prabhakaran
</author>
<affiliation confidence="0.9968535">
Dept. of Computer Science
Columbia University
</affiliation>
<address confidence="0.90176">
New York, NY, USA
</address>
<email confidence="0.996621">
vinod@cs.columbia.edu
</email>
<author confidence="0.978779">
Ashima Arora
</author>
<affiliation confidence="0.9966585">
Dept. of Computer Science
Columbia University
</affiliation>
<address confidence="0.897985">
New York, NY, USA
</address>
<email confidence="0.988793">
aa3470@columbia.edu
</email>
<author confidence="0.926858">
Owen Rambow
</author>
<affiliation confidence="0.930797">
CCLS
Columbia University
</affiliation>
<address confidence="0.892753">
New York, NY, USA
</address>
<email confidence="0.997176">
rambow@ccls.columbia.edu
</email>
<sectionHeader confidence="0.98485" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999880666666667">
We study the topic dynamics of interac-
tions in political debates using the 2012
Republican presidential primary debates
as data. We show that the tendency of
candidates to shift topics changes over the
course of the election campaign, and that it
is correlated with their relative power. We
also show that our topic shift features help
predict candidates’ relative rankings.
</bodyText>
<sectionHeader confidence="0.992495" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981047619048">
The field of computational social sciences has cre-
ated many interesting applications for natural lan-
guage processing in recent years. One of the areas
where NLP techniques have shown great promise
is in the analysis of political speech. For example,
researchers have applied NLP techniques to polit-
ical texts for a variety of tasks such as predicting
voting patterns (Thomas et al., 2006), identifying
markers of persuasion (Guerini et al., 2008), cap-
turing cues that signal charisma (Rosenberg and
Hirschberg, 2009), and detecting ideological po-
sitions (Sim et al., 2013). Our work also analyzes
political speech, more specifically, presidential de-
bates. The contribution of this paper is to show
that the topic shifting tendency of a presidential
candidate changes over the course of the election
campaign, and that it is correlated with his or her
relative power. We also show that this insight can
help computational systems that predict the candi-
dates’ relative rankings based on their interactions
in the debates.
</bodyText>
<sectionHeader confidence="0.981655" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.991317065934067">
The motivation for this paper stems from prior
work done by the first author in collaboration
with other researchers (Prabhakaran et al., 2013a;
Prabhakaran et al., 2013b). Prabhakaran et al.
(2013a) introduced the notion of power in the do-
main of presidential debates, and Prabhakaran et
al. (2013b) followed it up with an automatic power
ranker system based on interactions within the de-
bates. The power that a candidate had at a cer-
tain point in the election campaign was modeled
based on his or her recent poll standings: in elec-
tions, popularity is power. Those studies analyzed
the 2012 Republican presidential primary debates
and found that a candidate’s power at the time of
a debate correlates with the structure of interac-
tions within the debate (e.g., turn frequency and
interruption patterns). Another finding was that
the candidates’ power correlates with the distribu-
tion of topics they speak about in the debates: can-
didates with more power spoke significantly more
about certain topics (e.g., economy) and less about
certain other topics (e.g., energy). However, these
findings relate to the specific election cycle that
was analyzed and will not carry over to political
debates in general.
A further dimension with relevance beyond a
specific election campaign is how topics evolve
during the course of an interaction (e.g., who at-
tempts to shift topics). In (Prabhakaran et al.,
2014), we explored this dimension and found that
candidates with higher power introduce signifi-
cantly more topics in the debates, but attempt to
shift topics significantly less often while respond-
ing to a moderator. We used the basic LDA topic
modeling method (with a filter for substantivity of
turns) to assign topics to turns, which were then
used to detect shifts in topics. However, segment-
ing interactions into coherent topic segments is an
active area of research and a variety of topic mod-
eling approaches have been proposed for that pur-
pose. In this paper, we explore the utility of one
such topic modeling approach to tackle this prob-
lem.
While most of the early approaches for topic
segmenting in interactions have focused on the
1481
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1481–1486,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
content of the contribution, Nguyen et al. (2012)
introduced a system called Speaker Identity for
Topic Segmentation (SITS) which also takes into
account the topic shifting tendencies of the partic-
ipants of the conversation. In later work, Nguyen
et al. (2013) demonstrated the SITS system’s util-
ity in detecting influencers in Crossfire debates
and Wikipedia discussions. They also applied the
SITS system to the domain of political debates.
However they were able to perform only a qual-
itative analysis of its utility in the debates domain
since the debates data did not have influence an-
notations. In this paper, we use the SITS system
to assign topics to turns and perform a quantita-
tive analysis of how the topic shift features calcu-
lated using the SITS system relate to the notion of
power as captured by (Prabhakaran et al., 2013a).
The SITS system associates each debate partic-
ipant with a constant scalar value that captures his
or her tendency to shift topics. However, since
we want to investigate how each candidate’s topic
shifting tendency relates to his or her changing
power over the course of the campaign, we intro-
duce a variation of the SITS analysis in which we
represent a different “persona” for each candidate
in each debate. Once equipped with this notion
of “persona”, we find that the topic shifting ten-
dency of a candidate does indeed show a great deal
of fluctuation during the election campaign period.
We also find that this fluctuation in topic shifting
tendencies is significantly correlated with the can-
didates’ power.
As an additional contribution of this paper, we
demonstrate the utility of our topic shift features
extracted using both types of SITS-based anal-
yses in improving the performance of the auto-
matic power ranker system presented in (Prab-
hakaran et al., 2013b). We also investigated the
utility of topic shifting features described in (Prab-
hakaran et al., 2014) extracted using LDA based
topic modeling. However, they did not improve
the performance of the ranker, and hence we do
not discuss them in detail in this paper.
</bodyText>
<sectionHeader confidence="0.993413" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999993269230769">
We use the presidential debates corpus released by
Prabhakaran et al. (2013a), which contains manual
transcripts of 20 debates held between May 2011
and February 2012 as part of the 2012 Republican
presidential primaries. The corpus also captures
each candidate’s power at the time of each debate,
computed based on their relative standing in re-
cent public polls. The poll numbers capture how
successful candidates are in convincing the elec-
torate of their candidature, which in turn affects
their confidence within the debates. These debates
serve as a rich domain to explore manifestations
of power since they are a medium through which
candidates pursue and maintain power over other
candidates. Prabhakaran et al. (2013b) offers a de-
tailed description of how the relative standings in
national and state-level polls from various sources
are aggregated to obtain candidates’ power.
The transcripts are originally obtained from The
American Presidency Project, where each turn of
the conversation is manually demarcated and their
speakers identified. The turns in the corpus are
preprocessed using the Stanford CoreNLP pack-
age to perform basic NLP steps such as tokeniza-
tion, sentence segmentation, parts-of-speech tag-
ging and lemmatization.
</bodyText>
<sectionHeader confidence="0.821251" genericHeader="method">
4 Modeling Topic Shifts
</sectionHeader>
<bodyText confidence="0.999984461538462">
Topic segmentation, the task of segmenting inter-
actions into coherent topic segments, is an impor-
tant step in analyzing interactions. In addition
to its primary purpose, topic segmentation also
identifies the speaker turn where the conversation
changed from one topic to another, i.e., where the
topic shifted, which may shed light on the char-
acteristics of the speaker who changed the topic.
We use the SITS approach proposed by (Nguyen
et al., 2012) to detect topic shifts. We also propose
a different way of using SITS to obtain an analysis
of our corpus, which we call SITSvar. We discuss
both in turn, and then provide a discussion.
</bodyText>
<subsectionHeader confidence="0.999071">
4.1 Segmentation using SITS
</subsectionHeader>
<bodyText confidence="0.998869">
Most computational approaches towards auto-
matic topic segmentation have focused mainly on
the content of the contribution without taking into
account the social aspects or speaker character-
istics. Different discourse participants may have
different tendencies to introduce or shift topics in
interactions. In order to address this shortcom-
ing, Nguyen et al. (2012) proposed a new topic
segmentation model called Speaker Identity for
Topic Segmentation (SITS), in which they explic-
itly model the individual’s tendency to introduce
new topics.
Like traditional topic modeling approaches, the
SITS system also considers each turn to be a
</bodyText>
<figure confidence="0.98302604">
1482
0.6
0.5
0.4
0.3
Topic2
0.2
0.1
P(x_ I
0
)ODate
ofNDeb a t
)0
hi)�� Tend
ncy,
BACHMANN��
CAIN��
GINGRICH��
HUNTSMAN��
PAUL��
PERRY��
ROMNEY��
S
��
enc y value sacros sdebatesba gof wordsgenera tedf
</figure>
<bodyText confidence="0.989873515151515">
ANT OR UMrFi gure1:SIT Svar T opicshi ft tend
romamixtur eoft op-ics .T heset op ics them sel ves
aremu ltinom iald is-tri bution sov erterm s. In ord
ertoaccoun tfor thetopic s h iftsth athapp enduring
the c ourseo fan in-te racti on ,they int roducea bin
arylate ntvaria ble ld;tc al led th e topicshiftt
o in dica te wh etherth esp eakerchang ed thetop i
corno t inconve rsationda ttur nt.To captu rethein
dividu alspeake r’stop icshi fting tendency , the yi
ntroduc e d ano th erlat entvariabl eca lled topics
hi fttende n cy (πx)ofs p eaker x.Theπ
xvaluerepresentsthep ropensi
ofspeakerx toperforma topicshift. 4.2Segme
ty
ntationu si ng SITSvarWit hin t he SITSformul a tion
,thet opic sh iftingtendency ofan i nd ividual(πx
)is cons id eredacon -stant acro ss conve rsatio ns
.Whi le anind ivid ual si tytoshifttopicsor mayhavean inherentprop en
icshifting tendencyhe not, we argue that thetop
ybased onthesocial set- orshedisplays can var
tera ctsandhis orher tings in which heorshein
In otherwords, the status withinthosesettings.
ve differently samediscourseparticipantmaybeha in differen tsocials it uat ionsand
at dif ferentpo intsi nti me. This isespe cial l
yrelev an t i nthecon tex tof our da tas et,whe
re thed ebateshap pe nov er aperio d of10mon ths,
andthep oweran dsta tuso feachca
nd idatein t heelect io ncam paign varyg reat
lywit hint hat time p er iod.Wepr opos e avari
anto fS ITSw h ichtakest hisissuei nt oacc ount.We
co nsidereach candi -d atetoh ave a different “pe
rson a”ineachd e bat e.To accomp li shthis, we
c re ate newident itiesfo reach candid ate
</bodyText>
<table confidence="0.445878555555556">
s exp
thecan didat eROM NEYinthedeba te heldon 08-11-201
1. R unning the SITSsyste m usi ngthisfor mulation
,weobtain different πxdva luesf orcandidat ex f o
ba tes,
en cie sofx. capturingdifferent topic shifttend
rdifferentde
xfor e ach debated ,d eno tedbyxd.F orexam pl
e,‘ ROMNEY 08-1 1- 2011’ de-not esthepe rso naof
</table>
<subsectionHeader confidence="0.857479">
4.3 Execution
</subsectionHeader>
<bodyText confidence="0.901665464285714">
ITSandSITSvar analyses We performboth theS
rpus.Weusedthe non- on the 20debates inour co
rboth runs, sinceit parametric versionof SITSfo
the numberoftopicsin the systemicallyestimates
mumnumber of iterations data.Wesetthema xi at5000 ,s amplela ga t100
and in iti alnumbe ro ftopi csat25.Wer e
fer ther eader to(Ng uy enetal.,2 013 )for det
ailsonth eseparame te rs. Forea chcan didate,w
eca lc ul ate th eme anandsta ndard d evi ationof
th et opi c shifttenden cy( πx d)of hisorhe rpers
onasa cro ssalldeb atesheorshe par ticipa te din
.Weth enav er age t hes em eansand standard deviat
ions ,a nd obt ain a nav-e rage mea nof0. 14and anavera
gest an darddevia- tion of 0 .09. Thisshow sthatt
hetopi cshift te nden-c i esof c and id a tesva ryby
aconsid erable amountacr ossdebat
e s.Figure 1showstheπxd valuefluc
tuating acr oss dif fere ntd ebat es.5Anal ys i
-
sofTo pi cShif tFeature sN guyen etal. (2013)u
sedthe SI TSan alysis a sam eanstomo de linflue nce
inmultipa rtyco nver- sation s.The ypr oposetwo
featu resto d etect i n-fluen ce rs:Total Top icS
hifts( TTS)an dW eight edTopi cSh ifts(WTS). T
TS(x, d) capturesthee x- ifts he individual x pectednumber of topic sh
akes in conversation is d. cal- Thi
ectation
culated through the empirical average of samples
</bodyText>
<table confidence="0.87538625">
1483
Feature Set Feature Correlation
Total Topic Shifts (TTS) 0.12
TopSh
Weighted Topic Shifts (WTS) 0.16
Total Topic Shifts (TTSvar) 0.12
TopShvar Weighted Topic Shifts (WTSvar) 0.15
Topic Shift Tendency (PIvar) -0.27
</table>
<tableCaption confidence="0.988744">
Table 1: Pearson Correlations for Topical Features
boldface denotes statistical significance (p &lt; 0.05)
</tableCaption>
<bodyText confidence="0.999985333333333">
from the Gibbs sampler, after a burn-in period. We
refer the reader to (Nguyen et al., 2013) for more
details on how this value is computed. WTS(x, d)
is the value of TTS(x, d) weighted by 1 − 7rx. The
intuition here is that a topic shift by a speaker with
low topic shift tendency must be weighted higher
than that by a speaker with a high topic shift ten-
dency. We use these two features as well, and de-
note the set of these two features as TopSh.
We also extract the TTS and WTS features us-
ing our SITSvar variation of topic segmentation
analysis and denote them as TTSvar and WTSvar
respectively. In addition, we also use a feature
PIvar(x, d) which is the 7rx d value obtained by the
SITSvar for candidate x in debate d. It captures the
topic shifting tendency of candidate x in debate d.
(We do not include the SITS 7rx value in our corre-
lation analysis since it is constant across debates.)
We denote the set of these three features obtained
from the SITSvar run as TopShvar.
Table 1 shows the Pearson’s product correla-
tion between each topical feature and candidate’s
power. We obtain a highly significant (p = 0.002)
negative correlation between topic shift tendency
of a candidate (PI) and his/her power. In other
words, the variation in the topic shifting tenden-
cies is significantly correlated with the candidates’
recent poll standings. Candidates who are higher
up in the polls tend to stay on topic while the
candidates with less power attempt to shift top-
ics more often. This is in line with our previous
findings from (Prabhakaran et al., 2014) that can-
didates with higher power attempt to shift topics
less often than others when responding to moder-
ators. It is also in line with the findings by Prab-
hakaran et al. (2013a) that candidates with higher
power tend not to interrupt others. On the other
hand, we did not obtain any significant correlation
for the features proposed by Nguyen et al. (2013).
</bodyText>
<sectionHeader confidence="0.967641" genericHeader="method">
6 Topic Shift Features in Power Ranker
</sectionHeader>
<bodyText confidence="0.999356837837838">
In this section, we investigate the utility of the
SITS and SITSvar based topic shift features de-
scribed above in the problem of automatically
ranking the participants of debates based on their
power. Prabhakaran et al. (2013b) define the prob-
lem as follows: given a debate d with a set of par-
ticipants Cd = {x1, x2, ...xn} and corresponding
power indices P(xi) for 1 &lt; i &lt; n, find a ranking
function r : Cd —* 11...n} such that for all 1 &lt;
i, j &lt; n, r(xi) &gt; r(xj) P(xi) &gt; P(xj).
For our experiments, we use the SVMrank based
supervised learned power ranker presented in that
work to estimate this ranking function.
As we do in (Prabhakaran et al., 2013b), we
here report Kendall’s Tau and Normalized Dis-
counted Cumulative Gain values (NDCG and
NDCG@3) on 5-fold cross validation (at the de-
bate level). All three metrics are based on the
number of rank inversions between original and
predicted ranking. While Tau treats all rank in-
versions equal, NDCG and NDCG@3 penalize
the inversions happening in the top of the ranked
list more than those happening in the bottom.
NDCG@3 focuses only on the top 3 positions in
the ranked list.
We use the best performing feature set of (Prab-
hakaran et al., 2013b) as the baseline (BL), which
contains three features: Words Deviation (WD),
Question Deviation (QD) and Mention Percent-
age (MP). WD and QD capture the deviation of
percentage of words spoken by the candidate and
questions addressed to the candidate from the ex-
pected fair share of those measures in the particu-
lar debate. The fair share for debate d is 1/|Cd |—
the percentage each candidate would have gotten
for each feature if it was equally distributed. This
deviation measure is used instead of the raw per-
</bodyText>
<table confidence="0.96883025">
1484
Kendall’s Tau NDCG NDCG@3
BL 0.55 0.962 0.932
TopSh 0.36 0.907 0.830
TopShvar 0.39 0.919 0.847
BL + TopSh 0.59 0.967 0.929
BL + TopShvar 0.60 0.970 0.937
BL + TopSh + TopShvar 0.59 0.968 0.934
</table>
<tableCaption confidence="0.91118">
Table 2: Power Ranker results using topic shift features on 5-fold cross validation
</tableCaption>
<bodyText confidence="0.96995468">
BL: Baseline system (Prabhakaran et al., 2013b)
NDCG: Normalized Discounted Cumulative Gain
centage in order to handle the fact that the percent-
age values are dependent on the number of partic-
ipants in a debate, which varied from 9 to 4. MP
captures the percentage of mentions of the candi-
date within a debate.
Table 2 shows the results obtained using the
baseline features (BL) as well as combinations of
TopSh and TopShvar features. The baseline sys-
tem obtained a Kendall Tau of 0.55, NDCG of
0.962 and NDCG@3 of 0.932. The topic shift
features by themselves performed much worse,
with TopShvar posting marginally better results
than TopSh. Combining the topic shift and base-
line features increases performance considerably.
TopShvar obtained better performance than TopSh
across the board. BL + TopShvar posted the over-
all best system obtaining a Tau of 0.60, NDCG
of 0.970, and NDCG@3 of 0.937. These results
demonstrates the utility of topic shift features in
the power ranking problem, especially using the
SITSvar formulation. We also experimented with
all subsets of TopSh and TopShvar; the best results
were obtained using all features in each set.
</bodyText>
<sectionHeader confidence="0.99911" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999896526315789">
Studies in sociolinguistics (e.g., (Ng et al., 1993;
Ng et al., 1995; Reid and Ng, 2000)) have long
established that dialog structure in interactions re-
lates to power and influence. Researchers in the
NLP community have studied power and influence
in various genres of interactions, such as organiza-
tional email threads (Bramsen et al., 2011; Gilbert,
2012; Prabhakaran and Rambow, 2013; Prab-
hakaran and Rambow, 2014), online discussion fo-
rums (Danescu-Niculescu-Mizil et al., 2012; Bi-
ran et al., 2012) and online chat dialogs (Strza-
lkowski et al., 2012). The correlates analyzed in
these studies range from word and phrase patterns,
to derivatives of such patterns such as linguistic
coordination, to deeper dialogic features such as
argumentation and dialog acts. Our work differs
from these studies in that we study the correlates
of power in topic dynamics. Furthermore, we an-
alyze spoken interactions.
</bodyText>
<sectionHeader confidence="0.994646" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999950153846154">
In this paper, we studied how topic shift patterns
in the 2012 Republican presidential debates corre-
late with the power of candidates. We proposed an
alternate formulation of the SITS topic segmenta-
tion system that captures fluctuations in each can-
didate’s topic shifting tendencies, which we found
to be correlated with their power. We also showed
that features based on topic shift improve the pre-
diction of the relative rankings of candidates. In
future work, we will explore a model that cap-
tures individuals’ inherent topic shift propensities,
while also capturing their fluctuations due to so-
cial factors.
</bodyText>
<sectionHeader confidence="0.995466" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999918666666667">
This paper is based upon work supported by the
DARPA DEFT Program. The views expressed are
those of the authors and do not reflect the official
policy or position of the Department of Defense or
the U.S. Government. We also thank the anony-
mous reviewers for their constructive feedback.
</bodyText>
<page confidence="0.606719">
1485
</page>
<sectionHeader confidence="0.952961" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99863525">
Or Biran, Sara Rosenthal, Jacob Andreas, Kathleen
McKeown, and Owen Rambow. 2012. Detecting
influencers in written online conversations. In Pro-
ceedings of the Second Workshop on Language in
Social Media, pages 37–45, Montr´eal, Canada, June.
Association for Computational Linguistics.
Philip Bramsen, Martha Escobar-Molano, Ami Patel,
and Rafael Alonso. 2011. Extracting social power
relationships from natural language. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 773–782, Portland, Oregon, USA,
June. Association for Computational Linguistics.
Cristian Danescu-Niculescu-Mizil, Lillian Lee,
Bo Pang, and Jon Kleinberg. 2012. Echoes of
power: language effects and power differences in
social interaction. In Proceedings of the 21st in-
ternational conference on World Wide Web, WWW
’12, New York, NY, USA. ACM.
Eric Gilbert. 2012. Phrases that signal workplace hier-
archy. In Proceedings of the ACM 2012 conference
on Computer Supported Cooperative Work, CSCW
’12, pages 1037–1046, New York, NY, USA. ACM.
Marco Guerini, Carlo Strapparava, and Oliviero Stock.
2008. Corps: A corpus of tagged political speeches
for persuasive communication processing. Journal
of Information Technology &amp; Politics, 5(1):19–32.
Sik Hung Ng, Dean Bell, and Mark Brooke. 1993.
Gaining turns and achieving high in influence rank-
ing in small conversational groups. British Journal
of Social Psychology, pages 32, 265–275.
Sik Hung Ng, Mark Brooke, and Michael Dunne.
1995. Interruption and in influence in discussion
groups. Journal of Language and Social Psychol-
ogy, pages 14(4),369–381.
Viet-An Nguyen, Jordan Boyd-Graber, and Philip
Resnik. 2012. Sits: A hierarchical nonparametric
model using speaker identity for topic segmentation
in multiparty conversations. In Proceedings of the
50th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
pages 78–87, Jeju Island, Korea, July. Association
for Computational Linguistics.
Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik,
Deborah A. Cai, Jennifer E. Midberry, and Yuanxin
Wang. 2013. Modeling topic control to detect in-
fluence in conversations using nonparametric topic
models. Machine Learning, pages 1–41.
Vinodkumar Prabhakaran and Owen Rambow. 2013.
Written dialog and social power: Manifestations of
different types of power in dialog behavior. In Pro-
ceedings of the IJCNLP, pages 216–224, Nagoya,
Japan, October. Asian Federation of Natural Lan-
guage Processing.
Vinodkumar Prabhakaran and Owen Rambow. 2014.
Predicting power relations between participants in
written dialog from a single thread. In Proceed-
ings of the 52nd Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Pa-
pers), pages 339–344, Baltimore, Maryland, June.
Association for Computational Linguistics.
Vinodkumar Prabhakaran, Ajita John, and Dor´ee D.
Seligmann. 2013a. Power dynamics in spoken in-
teractions: a case study on 2012 republican primary
debates. In Proceedings of the 22nd international
conference on World Wide Web companion, pages
99–100. International World Wide Web Conferences
Steering Committee.
Vinodkumar Prabhakaran, Ajita John, and Dor´ee D.
Seligmann. 2013b. Who had the upper hand? rank-
ing participants of interactions based on their rela-
tive power. In Proceedings of the IJCNLP, pages
365–373, Nagoya, Japan, October. Asian Federation
of Natural Language Processing.
Vinodkumar Prabhakaran, Ashima Arora, and Owen
Rambow. 2014. Power of confidence: How poll
scores impact topic dynamics in political debates.
In Proceedings of the ACL 2014 Workshop on Lan-
guage Technologies and Computational Social Sci-
ence, page 49, Baltimore, MD, USA, June. Associa-
tion for Computational Linguistics.
Scott A. Reid and Sik Hung Ng. 2000. Conversation as
a resource for in influence: evidence for prototypical
arguments and social identification processes. Euro-
pean Journal of Social Psych., pages 30, 83–100.
Andrew Rosenberg and Julia Hirschberg. 2009.
Charisma perception from text and speech. Speech
Communication, 51(7):640–655.
Yanchuan Sim, Brice D. L. Acree, Justin H. Gross, and
Noah A. Smith. 2013. Measuring ideological pro-
portions in political speeches. In Proceedings of the
2013 Conference on EMNLP, pages 91–101, Seattle,
Washington, USA, October. Association for Compu-
tational Linguistics.
Tomek Strzalkowski, Samira Shaikh, Ting Liu,
George Aaron Broadwell, Jenny Stromer-Galley,
Sarah Taylor, Umit Boz, Veena Ravishankar, and
Xiaoai Ren. 2012. Modeling leadership and influ-
ence in multi-party online discourse. In Proceedings
of COLING, pages 2535–2552, Mumbai, India, De-
cember. The COLING 2012 Organizing Committee.
Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out
the vote: Determining support or opposition from
congressional floor-debate transcripts. In Proceed-
ings of the 2006 Conference on Empirical Methods
in Natural Language Processing, pages 327–335,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.779155">
1486
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.263140">
<title confidence="0.9998745">Staying on Topic: An Indicator of Power in Political Debates</title>
<author confidence="0.996025">Vinodkumar Prabhakaran</author>
<affiliation confidence="0.999897">Dept. of Computer Science Columbia University</affiliation>
<address confidence="0.999487">New York, NY, USA</address>
<email confidence="0.999221">vinod@cs.columbia.edu</email>
<author confidence="0.481291">Ashima</author>
<affiliation confidence="0.999455">Dept. of Computer</affiliation>
<address confidence="0.903288">Columbia New York, NY, USA</address>
<email confidence="0.998669">aa3470@columbia.edu</email>
<author confidence="0.822655">Owen</author>
<affiliation confidence="0.771173">Columbia</affiliation>
<address confidence="0.998355">New York, NY, USA</address>
<email confidence="0.999862">rambow@ccls.columbia.edu</email>
<abstract confidence="0.9985058">We study the topic dynamics of interactions in political debates using the 2012 Republican presidential primary debates as data. We show that the tendency of candidates to shift topics changes over the course of the election campaign, and that it is correlated with their relative power. We also show that our topic shift features help predict candidates’ relative rankings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Or Biran</author>
<author>Sara Rosenthal</author>
<author>Jacob Andreas</author>
<author>Kathleen McKeown</author>
<author>Owen Rambow</author>
</authors>
<title>Detecting influencers in written online conversations.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second Workshop on Language in Social Media,</booktitle>
<pages>37--45</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="18115" citStr="Biran et al., 2012" startWordPosition="2990" endWordPosition="2994">ith all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. 8 Conclusion In this paper, we studied how topic shift patterns in the 2012 Republican presidential debates correlate with the power of candidates. We proposed an alternate formulation of the SIT</context>
</contexts>
<marker>Biran, Rosenthal, Andreas, McKeown, Rambow, 2012</marker>
<rawString>Or Biran, Sara Rosenthal, Jacob Andreas, Kathleen McKeown, and Owen Rambow. 2012. Detecting influencers in written online conversations. In Proceedings of the Second Workshop on Language in Social Media, pages 37–45, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Bramsen</author>
<author>Martha Escobar-Molano</author>
<author>Ami Patel</author>
<author>Rafael Alonso</author>
</authors>
<title>Extracting social power relationships from natural language.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>773--782</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="17954" citStr="Bramsen et al., 2011" startWordPosition="2967" endWordPosition="2970">937. These results demonstrates the utility of topic shift features in the power ranking problem, especially using the SITSvar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. 8 Conclusion In this paper, we stu</context>
</contexts>
<marker>Bramsen, Escobar-Molano, Patel, Alonso, 2011</marker>
<rawString>Philip Bramsen, Martha Escobar-Molano, Ami Patel, and Rafael Alonso. 2011. Extracting social power relationships from natural language. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 773–782, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Lillian Lee</author>
<author>Bo Pang</author>
<author>Jon Kleinberg</author>
</authors>
<title>Echoes of power: language effects and power differences in social interaction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web, WWW ’12,</booktitle>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="18094" citStr="Danescu-Niculescu-Mizil et al., 2012" startWordPosition="2986" endWordPosition="2989">ar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. 8 Conclusion In this paper, we studied how topic shift patterns in the 2012 Republican presidential debates correlate with the power of candidates. We proposed an alternate f</context>
</contexts>
<marker>Danescu-Niculescu-Mizil, Lee, Pang, Kleinberg, 2012</marker>
<rawString>Cristian Danescu-Niculescu-Mizil, Lillian Lee, Bo Pang, and Jon Kleinberg. 2012. Echoes of power: language effects and power differences in social interaction. In Proceedings of the 21st international conference on World Wide Web, WWW ’12, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Gilbert</author>
</authors>
<title>Phrases that signal workplace hierarchy.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, CSCW ’12,</booktitle>
<pages>1037--1046</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="17969" citStr="Gilbert, 2012" startWordPosition="2971" endWordPosition="2972">onstrates the utility of topic shift features in the power ranking problem, especially using the SITSvar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. 8 Conclusion In this paper, we studied how topic </context>
</contexts>
<marker>Gilbert, 2012</marker>
<rawString>Eric Gilbert. 2012. Phrases that signal workplace hierarchy. In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, CSCW ’12, pages 1037–1046, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Guerini</author>
<author>Carlo Strapparava</author>
<author>Oliviero Stock</author>
</authors>
<title>Corps: A corpus of tagged political speeches for persuasive communication processing.</title>
<date>2008</date>
<journal>Journal of Information Technology &amp; Politics,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="1192" citStr="Guerini et al., 2008" startWordPosition="176" endWordPosition="179"> election campaign, and that it is correlated with their relative power. We also show that our topic shift features help predict candidates’ relative rankings. 1 Introduction The field of computational social sciences has created many interesting applications for natural language processing in recent years. One of the areas where NLP techniques have shown great promise is in the analysis of political speech. For example, researchers have applied NLP techniques to political texts for a variety of tasks such as predicting voting patterns (Thomas et al., 2006), identifying markers of persuasion (Guerini et al., 2008), capturing cues that signal charisma (Rosenberg and Hirschberg, 2009), and detecting ideological positions (Sim et al., 2013). Our work also analyzes political speech, more specifically, presidential debates. The contribution of this paper is to show that the topic shifting tendency of a presidential candidate changes over the course of the election campaign, and that it is correlated with his or her relative power. We also show that this insight can help computational systems that predict the candidates’ relative rankings based on their interactions in the debates. 2 Motivation The motivatio</context>
</contexts>
<marker>Guerini, Strapparava, Stock, 2008</marker>
<rawString>Marco Guerini, Carlo Strapparava, and Oliviero Stock. 2008. Corps: A corpus of tagged political speeches for persuasive communication processing. Journal of Information Technology &amp; Politics, 5(1):19–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sik Hung Ng</author>
<author>Dean Bell</author>
<author>Mark Brooke</author>
</authors>
<title>Gaining turns and achieving high in influence ranking in small conversational groups.</title>
<date>1993</date>
<journal>British Journal of Social Psychology,</journal>
<pages>32--265</pages>
<contexts>
<context position="17664" citStr="Ng et al., 1993" startWordPosition="2920" endWordPosition="2923">inally better results than TopSh. Combining the topic shift and baseline features increases performance considerably. TopShvar obtained better performance than TopSh across the board. BL + TopShvar posted the overall best system obtaining a Tau of 0.60, NDCG of 0.970, and NDCG@3 of 0.937. These results demonstrates the utility of topic shift features in the power ranking problem, especially using the SITSvar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of</context>
</contexts>
<marker>Ng, Bell, Brooke, 1993</marker>
<rawString>Sik Hung Ng, Dean Bell, and Mark Brooke. 1993. Gaining turns and achieving high in influence ranking in small conversational groups. British Journal of Social Psychology, pages 32, 265–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sik Hung Ng</author>
<author>Mark Brooke</author>
<author>Michael Dunne</author>
</authors>
<title>Interruption and in influence in discussion groups.</title>
<date>1995</date>
<journal>Journal of Language and Social Psychology,</journal>
<pages>14--4</pages>
<contexts>
<context position="17681" citStr="Ng et al., 1995" startWordPosition="2924" endWordPosition="2927">ults than TopSh. Combining the topic shift and baseline features increases performance considerably. TopShvar obtained better performance than TopSh across the board. BL + TopShvar posted the overall best system obtaining a Tau of 0.60, NDCG of 0.970, and NDCG@3 of 0.937. These results demonstrates the utility of topic shift features in the power ranking problem, especially using the SITSvar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns su</context>
</contexts>
<marker>Ng, Brooke, Dunne, 1995</marker>
<rawString>Sik Hung Ng, Mark Brooke, and Michael Dunne. 1995. Interruption and in influence in discussion groups. Journal of Language and Social Psychology, pages 14(4),369–381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-An Nguyen</author>
<author>Jordan Boyd-Graber</author>
<author>Philip Resnik</author>
</authors>
<title>Sits: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>78--87</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="4167" citStr="Nguyen et al. (2012)" startWordPosition="653" endWordPosition="656">topics. However, segmenting interactions into coherent topic segments is an active area of research and a variety of topic modeling approaches have been proposed for that purpose. In this paper, we explore the utility of one such topic modeling approach to tackle this problem. While most of the early approaches for topic segmenting in interactions have focused on the 1481 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1481–1486, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics content of the contribution, Nguyen et al. (2012) introduced a system called Speaker Identity for Topic Segmentation (SITS) which also takes into account the topic shifting tendencies of the participants of the conversation. In later work, Nguyen et al. (2013) demonstrated the SITS system’s utility in detecting influencers in Crossfire debates and Wikipedia discussions. They also applied the SITS system to the domain of political debates. However they were able to perform only a qualitative analysis of its utility in the debates domain since the debates data did not have influence annotations. In this paper, we use the SITS system to assign </context>
<context position="7915" citStr="Nguyen et al., 2012" startWordPosition="1258" endWordPosition="1261"> the Stanford CoreNLP package to perform basic NLP steps such as tokenization, sentence segmentation, parts-of-speech tagging and lemmatization. 4 Modeling Topic Shifts Topic segmentation, the task of segmenting interactions into coherent topic segments, is an important step in analyzing interactions. In addition to its primary purpose, topic segmentation also identifies the speaker turn where the conversation changed from one topic to another, i.e., where the topic shifted, which may shed light on the characteristics of the speaker who changed the topic. We use the SITS approach proposed by (Nguyen et al., 2012) to detect topic shifts. We also propose a different way of using SITS to obtain an analysis of our corpus, which we call SITSvar. We discuss both in turn, and then provide a discussion. 4.1 Segmentation using SITS Most computational approaches towards automatic topic segmentation have focused mainly on the content of the contribution without taking into account the social aspects or speaker characteristics. Different discourse participants may have different tendencies to introduce or shift topics in interactions. In order to address this shortcoming, Nguyen et al. (2012) proposed a new topic</context>
</contexts>
<marker>Nguyen, Boyd-Graber, Resnik, 2012</marker>
<rawString>Viet-An Nguyen, Jordan Boyd-Graber, and Philip Resnik. 2012. Sits: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 78–87, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-An Nguyen</author>
<author>Jordan Boyd-Graber</author>
<author>Philip Resnik</author>
<author>Deborah A Cai</author>
<author>Jennifer E Midberry</author>
<author>Yuanxin Wang</author>
</authors>
<title>Modeling topic control to detect influence in conversations using nonparametric topic models.</title>
<date>2013</date>
<booktitle>Machine Learning,</booktitle>
<pages>1--41</pages>
<contexts>
<context position="4378" citStr="Nguyen et al. (2013)" startWordPosition="686" endWordPosition="689">tility of one such topic modeling approach to tackle this problem. While most of the early approaches for topic segmenting in interactions have focused on the 1481 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1481–1486, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics content of the contribution, Nguyen et al. (2012) introduced a system called Speaker Identity for Topic Segmentation (SITS) which also takes into account the topic shifting tendencies of the participants of the conversation. In later work, Nguyen et al. (2013) demonstrated the SITS system’s utility in detecting influencers in Crossfire debates and Wikipedia discussions. They also applied the SITS system to the domain of political debates. However they were able to perform only a qualitative analysis of its utility in the debates domain since the debates data did not have influence annotations. In this paper, we use the SITS system to assign topics to turns and perform a quantitative analysis of how the topic shift features calculated using the SITS system relate to the notion of power as captured by (Prabhakaran et al., 2013a). The SITS system asso</context>
<context position="12579" citStr="Nguyen et al., 2013" startWordPosition="2033" endWordPosition="2036">TTS)an dW eight edTopi cSh ifts(WTS). T TS(x, d) capturesthee x- ifts he individual x pectednumber of topic sh akes in conversation is d. cal- Thi ectation culated through the empirical average of samples 1483 Feature Set Feature Correlation Total Topic Shifts (TTS) 0.12 TopSh Weighted Topic Shifts (WTS) 0.16 Total Topic Shifts (TTSvar) 0.12 TopShvar Weighted Topic Shifts (WTSvar) 0.15 Topic Shift Tendency (PIvar) -0.27 Table 1: Pearson Correlations for Topical Features boldface denotes statistical significance (p &lt; 0.05) from the Gibbs sampler, after a burn-in period. We refer the reader to (Nguyen et al., 2013) for more details on how this value is computed. WTS(x, d) is the value of TTS(x, d) weighted by 1 − 7rx. The intuition here is that a topic shift by a speaker with low topic shift tendency must be weighted higher than that by a speaker with a high topic shift tendency. We use these two features as well, and denote the set of these two features as TopSh. We also extract the TTS and WTS features using our SITSvar variation of topic segmentation analysis and denote them as TTSvar and WTSvar respectively. In addition, we also use a feature PIvar(x, d) which is the 7rx d value obtained by the SITS</context>
<context position="14405" citStr="Nguyen et al. (2013)" startWordPosition="2359" endWordPosition="2362">elated with the candidates’ recent poll standings. Candidates who are higher up in the polls tend to stay on topic while the candidates with less power attempt to shift topics more often. This is in line with our previous findings from (Prabhakaran et al., 2014) that candidates with higher power attempt to shift topics less often than others when responding to moderators. It is also in line with the findings by Prabhakaran et al. (2013a) that candidates with higher power tend not to interrupt others. On the other hand, we did not obtain any significant correlation for the features proposed by Nguyen et al. (2013). 6 Topic Shift Features in Power Ranker In this section, we investigate the utility of the SITS and SITSvar based topic shift features described above in the problem of automatically ranking the participants of debates based on their power. Prabhakaran et al. (2013b) define the problem as follows: given a debate d with a set of participants Cd = {x1, x2, ...xn} and corresponding power indices P(xi) for 1 &lt; i &lt; n, find a ranking function r : Cd —* 11...n} such that for all 1 &lt; i, j &lt; n, r(xi) &gt; r(xj) P(xi) &gt; P(xj). For our experiments, we use the SVMrank based supervised learned power ranker p</context>
</contexts>
<marker>Nguyen, Boyd-Graber, Resnik, Cai, Midberry, Wang, 2013</marker>
<rawString>Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik, Deborah A. Cai, Jennifer E. Midberry, and Yuanxin Wang. 2013. Modeling topic control to detect influence in conversations using nonparametric topic models. Machine Learning, pages 1–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Owen Rambow</author>
</authors>
<title>Written dialog and social power: Manifestations of different types of power in dialog behavior.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the IJCNLP,</booktitle>
<pages>216--224</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="17999" citStr="Prabhakaran and Rambow, 2013" startWordPosition="2973" endWordPosition="2976">tility of topic shift features in the power ranking problem, especially using the SITSvar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. 8 Conclusion In this paper, we studied how topic shift patterns in the 2012 Rep</context>
</contexts>
<marker>Prabhakaran, Rambow, 2013</marker>
<rawString>Vinodkumar Prabhakaran and Owen Rambow. 2013. Written dialog and social power: Manifestations of different types of power in dialog behavior. In Proceedings of the IJCNLP, pages 216–224, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Owen Rambow</author>
</authors>
<title>Predicting power relations between participants in written dialog from a single thread.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>339--344</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="18030" citStr="Prabhakaran and Rambow, 2014" startWordPosition="2977" endWordPosition="2981"> in the power ranking problem, especially using the SITSvar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. 8 Conclusion In this paper, we studied how topic shift patterns in the 2012 Republican presidential debates co</context>
</contexts>
<marker>Prabhakaran, Rambow, 2014</marker>
<rawString>Vinodkumar Prabhakaran and Owen Rambow. 2014. Predicting power relations between participants in written dialog from a single thread. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 339–344, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Ajita John</author>
<author>Dor´ee D Seligmann</author>
</authors>
<title>Power dynamics in spoken interactions: a case study on 2012 republican primary debates.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22nd international conference on World Wide Web companion,</booktitle>
<pages>99--100</pages>
<institution>International World Wide Web Conferences Steering Committee.</institution>
<contexts>
<context position="1921" citStr="Prabhakaran et al., 2013" startWordPosition="291" endWordPosition="294">ns (Sim et al., 2013). Our work also analyzes political speech, more specifically, presidential debates. The contribution of this paper is to show that the topic shifting tendency of a presidential candidate changes over the course of the election campaign, and that it is correlated with his or her relative power. We also show that this insight can help computational systems that predict the candidates’ relative rankings based on their interactions in the debates. 2 Motivation The motivation for this paper stems from prior work done by the first author in collaboration with other researchers (Prabhakaran et al., 2013a; Prabhakaran et al., 2013b). Prabhakaran et al. (2013a) introduced the notion of power in the domain of presidential debates, and Prabhakaran et al. (2013b) followed it up with an automatic power ranker system based on interactions within the debates. The power that a candidate had at a certain point in the election campaign was modeled based on his or her recent poll standings: in elections, popularity is power. Those studies analyzed the 2012 Republican presidential primary debates and found that a candidate’s power at the time of a debate correlates with the structure of interactions with</context>
<context position="4954" citStr="Prabhakaran et al., 2013" startWordPosition="785" endWordPosition="788">onversation. In later work, Nguyen et al. (2013) demonstrated the SITS system’s utility in detecting influencers in Crossfire debates and Wikipedia discussions. They also applied the SITS system to the domain of political debates. However they were able to perform only a qualitative analysis of its utility in the debates domain since the debates data did not have influence annotations. In this paper, we use the SITS system to assign topics to turns and perform a quantitative analysis of how the topic shift features calculated using the SITS system relate to the notion of power as captured by (Prabhakaran et al., 2013a). The SITS system associates each debate participant with a constant scalar value that captures his or her tendency to shift topics. However, since we want to investigate how each candidate’s topic shifting tendency relates to his or her changing power over the course of the campaign, we introduce a variation of the SITS analysis in which we represent a different “persona” for each candidate in each debate. Once equipped with this notion of “persona”, we find that the topic shifting tendency of a candidate does indeed show a great deal of fluctuation during the election campaign period. We a</context>
<context position="6271" citStr="Prabhakaran et al. (2013" startWordPosition="1003" endWordPosition="1006">the candidates’ power. As an additional contribution of this paper, we demonstrate the utility of our topic shift features extracted using both types of SITS-based analyses in improving the performance of the automatic power ranker system presented in (Prabhakaran et al., 2013b). We also investigated the utility of topic shifting features described in (Prabhakaran et al., 2014) extracted using LDA based topic modeling. However, they did not improve the performance of the ranker, and hence we do not discuss them in detail in this paper. 3 Data We use the presidential debates corpus released by Prabhakaran et al. (2013a), which contains manual transcripts of 20 debates held between May 2011 and February 2012 as part of the 2012 Republican presidential primaries. The corpus also captures each candidate’s power at the time of each debate, computed based on their relative standing in recent public polls. The poll numbers capture how successful candidates are in convincing the electorate of their candidature, which in turn affects their confidence within the debates. These debates serve as a rich domain to explore manifestations of power since they are a medium through which candidates pursue and maintain power</context>
<context position="14224" citStr="Prabhakaran et al. (2013" startWordPosition="2328" endWordPosition="2332">(p = 0.002) negative correlation between topic shift tendency of a candidate (PI) and his/her power. In other words, the variation in the topic shifting tendencies is significantly correlated with the candidates’ recent poll standings. Candidates who are higher up in the polls tend to stay on topic while the candidates with less power attempt to shift topics more often. This is in line with our previous findings from (Prabhakaran et al., 2014) that candidates with higher power attempt to shift topics less often than others when responding to moderators. It is also in line with the findings by Prabhakaran et al. (2013a) that candidates with higher power tend not to interrupt others. On the other hand, we did not obtain any significant correlation for the features proposed by Nguyen et al. (2013). 6 Topic Shift Features in Power Ranker In this section, we investigate the utility of the SITS and SITSvar based topic shift features described above in the problem of automatically ranking the participants of debates based on their power. Prabhakaran et al. (2013b) define the problem as follows: given a debate d with a set of participants Cd = {x1, x2, ...xn} and corresponding power indices P(xi) for 1 &lt; i &lt; n, f</context>
<context position="15645" citStr="Prabhakaran et al., 2013" startWordPosition="2582" endWordPosition="2586"> work to estimate this ranking function. As we do in (Prabhakaran et al., 2013b), we here report Kendall’s Tau and Normalized Discounted Cumulative Gain values (NDCG and NDCG@3) on 5-fold cross validation (at the debate level). All three metrics are based on the number of rank inversions between original and predicted ranking. While Tau treats all rank inversions equal, NDCG and NDCG@3 penalize the inversions happening in the top of the ranked list more than those happening in the bottom. NDCG@3 focuses only on the top 3 positions in the ranked list. We use the best performing feature set of (Prabhakaran et al., 2013b) as the baseline (BL), which contains three features: Words Deviation (WD), Question Deviation (QD) and Mention Percentage (MP). WD and QD capture the deviation of percentage of words spoken by the candidate and questions addressed to the candidate from the expected fair share of those measures in the particular debate. The fair share for debate d is 1/|Cd |— the percentage each candidate would have gotten for each feature if it was equally distributed. This deviation measure is used instead of the raw per1484 Kendall’s Tau NDCG NDCG@3 BL 0.55 0.962 0.932 TopSh 0.36 0.907 0.830 TopShvar 0.39</context>
</contexts>
<marker>Prabhakaran, John, Seligmann, 2013</marker>
<rawString>Vinodkumar Prabhakaran, Ajita John, and Dor´ee D. Seligmann. 2013a. Power dynamics in spoken interactions: a case study on 2012 republican primary debates. In Proceedings of the 22nd international conference on World Wide Web companion, pages 99–100. International World Wide Web Conferences Steering Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Ajita John</author>
<author>Dor´ee D Seligmann</author>
</authors>
<title>Who had the upper hand? ranking participants of interactions based on their relative power.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the IJCNLP,</booktitle>
<pages>365--373</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="1921" citStr="Prabhakaran et al., 2013" startWordPosition="291" endWordPosition="294">ns (Sim et al., 2013). Our work also analyzes political speech, more specifically, presidential debates. The contribution of this paper is to show that the topic shifting tendency of a presidential candidate changes over the course of the election campaign, and that it is correlated with his or her relative power. We also show that this insight can help computational systems that predict the candidates’ relative rankings based on their interactions in the debates. 2 Motivation The motivation for this paper stems from prior work done by the first author in collaboration with other researchers (Prabhakaran et al., 2013a; Prabhakaran et al., 2013b). Prabhakaran et al. (2013a) introduced the notion of power in the domain of presidential debates, and Prabhakaran et al. (2013b) followed it up with an automatic power ranker system based on interactions within the debates. The power that a candidate had at a certain point in the election campaign was modeled based on his or her recent poll standings: in elections, popularity is power. Those studies analyzed the 2012 Republican presidential primary debates and found that a candidate’s power at the time of a debate correlates with the structure of interactions with</context>
<context position="4954" citStr="Prabhakaran et al., 2013" startWordPosition="785" endWordPosition="788">onversation. In later work, Nguyen et al. (2013) demonstrated the SITS system’s utility in detecting influencers in Crossfire debates and Wikipedia discussions. They also applied the SITS system to the domain of political debates. However they were able to perform only a qualitative analysis of its utility in the debates domain since the debates data did not have influence annotations. In this paper, we use the SITS system to assign topics to turns and perform a quantitative analysis of how the topic shift features calculated using the SITS system relate to the notion of power as captured by (Prabhakaran et al., 2013a). The SITS system associates each debate participant with a constant scalar value that captures his or her tendency to shift topics. However, since we want to investigate how each candidate’s topic shifting tendency relates to his or her changing power over the course of the campaign, we introduce a variation of the SITS analysis in which we represent a different “persona” for each candidate in each debate. Once equipped with this notion of “persona”, we find that the topic shifting tendency of a candidate does indeed show a great deal of fluctuation during the election campaign period. We a</context>
<context position="6271" citStr="Prabhakaran et al. (2013" startWordPosition="1003" endWordPosition="1006">the candidates’ power. As an additional contribution of this paper, we demonstrate the utility of our topic shift features extracted using both types of SITS-based analyses in improving the performance of the automatic power ranker system presented in (Prabhakaran et al., 2013b). We also investigated the utility of topic shifting features described in (Prabhakaran et al., 2014) extracted using LDA based topic modeling. However, they did not improve the performance of the ranker, and hence we do not discuss them in detail in this paper. 3 Data We use the presidential debates corpus released by Prabhakaran et al. (2013a), which contains manual transcripts of 20 debates held between May 2011 and February 2012 as part of the 2012 Republican presidential primaries. The corpus also captures each candidate’s power at the time of each debate, computed based on their relative standing in recent public polls. The poll numbers capture how successful candidates are in convincing the electorate of their candidature, which in turn affects their confidence within the debates. These debates serve as a rich domain to explore manifestations of power since they are a medium through which candidates pursue and maintain power</context>
<context position="14224" citStr="Prabhakaran et al. (2013" startWordPosition="2328" endWordPosition="2332">(p = 0.002) negative correlation between topic shift tendency of a candidate (PI) and his/her power. In other words, the variation in the topic shifting tendencies is significantly correlated with the candidates’ recent poll standings. Candidates who are higher up in the polls tend to stay on topic while the candidates with less power attempt to shift topics more often. This is in line with our previous findings from (Prabhakaran et al., 2014) that candidates with higher power attempt to shift topics less often than others when responding to moderators. It is also in line with the findings by Prabhakaran et al. (2013a) that candidates with higher power tend not to interrupt others. On the other hand, we did not obtain any significant correlation for the features proposed by Nguyen et al. (2013). 6 Topic Shift Features in Power Ranker In this section, we investigate the utility of the SITS and SITSvar based topic shift features described above in the problem of automatically ranking the participants of debates based on their power. Prabhakaran et al. (2013b) define the problem as follows: given a debate d with a set of participants Cd = {x1, x2, ...xn} and corresponding power indices P(xi) for 1 &lt; i &lt; n, f</context>
<context position="15645" citStr="Prabhakaran et al., 2013" startWordPosition="2582" endWordPosition="2586"> work to estimate this ranking function. As we do in (Prabhakaran et al., 2013b), we here report Kendall’s Tau and Normalized Discounted Cumulative Gain values (NDCG and NDCG@3) on 5-fold cross validation (at the debate level). All three metrics are based on the number of rank inversions between original and predicted ranking. While Tau treats all rank inversions equal, NDCG and NDCG@3 penalize the inversions happening in the top of the ranked list more than those happening in the bottom. NDCG@3 focuses only on the top 3 positions in the ranked list. We use the best performing feature set of (Prabhakaran et al., 2013b) as the baseline (BL), which contains three features: Words Deviation (WD), Question Deviation (QD) and Mention Percentage (MP). WD and QD capture the deviation of percentage of words spoken by the candidate and questions addressed to the candidate from the expected fair share of those measures in the particular debate. The fair share for debate d is 1/|Cd |— the percentage each candidate would have gotten for each feature if it was equally distributed. This deviation measure is used instead of the raw per1484 Kendall’s Tau NDCG NDCG@3 BL 0.55 0.962 0.932 TopSh 0.36 0.907 0.830 TopShvar 0.39</context>
</contexts>
<marker>Prabhakaran, John, Seligmann, 2013</marker>
<rawString>Vinodkumar Prabhakaran, Ajita John, and Dor´ee D. Seligmann. 2013b. Who had the upper hand? ranking participants of interactions based on their relative power. In Proceedings of the IJCNLP, pages 365–373, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Ashima Arora</author>
<author>Owen Rambow</author>
</authors>
<title>Power of confidence: How poll scores impact topic dynamics in political debates.</title>
<date>2014</date>
<booktitle>In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, page 49,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, MD, USA,</location>
<contexts>
<context position="3181" citStr="Prabhakaran et al., 2014" startWordPosition="495" endWordPosition="498"> and interruption patterns). Another finding was that the candidates’ power correlates with the distribution of topics they speak about in the debates: candidates with more power spoke significantly more about certain topics (e.g., economy) and less about certain other topics (e.g., energy). However, these findings relate to the specific election cycle that was analyzed and will not carry over to political debates in general. A further dimension with relevance beyond a specific election campaign is how topics evolve during the course of an interaction (e.g., who attempts to shift topics). In (Prabhakaran et al., 2014), we explored this dimension and found that candidates with higher power introduce significantly more topics in the debates, but attempt to shift topics significantly less often while responding to a moderator. We used the basic LDA topic modeling method (with a filter for substantivity of turns) to assign topics to turns, which were then used to detect shifts in topics. However, segmenting interactions into coherent topic segments is an active area of research and a variety of topic modeling approaches have been proposed for that purpose. In this paper, we explore the utility of one such topi</context>
<context position="6027" citStr="Prabhakaran et al., 2014" startWordPosition="960" endWordPosition="964">persona”, we find that the topic shifting tendency of a candidate does indeed show a great deal of fluctuation during the election campaign period. We also find that this fluctuation in topic shifting tendencies is significantly correlated with the candidates’ power. As an additional contribution of this paper, we demonstrate the utility of our topic shift features extracted using both types of SITS-based analyses in improving the performance of the automatic power ranker system presented in (Prabhakaran et al., 2013b). We also investigated the utility of topic shifting features described in (Prabhakaran et al., 2014) extracted using LDA based topic modeling. However, they did not improve the performance of the ranker, and hence we do not discuss them in detail in this paper. 3 Data We use the presidential debates corpus released by Prabhakaran et al. (2013a), which contains manual transcripts of 20 debates held between May 2011 and February 2012 as part of the 2012 Republican presidential primaries. The corpus also captures each candidate’s power at the time of each debate, computed based on their relative standing in recent public polls. The poll numbers capture how successful candidates are in convincin</context>
<context position="14047" citStr="Prabhakaran et al., 2014" startWordPosition="2296" endWordPosition="2299">res obtained from the SITSvar run as TopShvar. Table 1 shows the Pearson’s product correlation between each topical feature and candidate’s power. We obtain a highly significant (p = 0.002) negative correlation between topic shift tendency of a candidate (PI) and his/her power. In other words, the variation in the topic shifting tendencies is significantly correlated with the candidates’ recent poll standings. Candidates who are higher up in the polls tend to stay on topic while the candidates with less power attempt to shift topics more often. This is in line with our previous findings from (Prabhakaran et al., 2014) that candidates with higher power attempt to shift topics less often than others when responding to moderators. It is also in line with the findings by Prabhakaran et al. (2013a) that candidates with higher power tend not to interrupt others. On the other hand, we did not obtain any significant correlation for the features proposed by Nguyen et al. (2013). 6 Topic Shift Features in Power Ranker In this section, we investigate the utility of the SITS and SITSvar based topic shift features described above in the problem of automatically ranking the participants of debates based on their power. </context>
</contexts>
<marker>Prabhakaran, Arora, Rambow, 2014</marker>
<rawString>Vinodkumar Prabhakaran, Ashima Arora, and Owen Rambow. 2014. Power of confidence: How poll scores impact topic dynamics in political debates. In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, page 49, Baltimore, MD, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott A Reid</author>
<author>Sik Hung Ng</author>
</authors>
<title>Conversation as a resource for in influence: evidence for prototypical arguments and social identification processes.</title>
<date>2000</date>
<journal>European Journal of Social Psych.,</journal>
<pages>30--83</pages>
<contexts>
<context position="17701" citStr="Reid and Ng, 2000" startWordPosition="2928" endWordPosition="2931">Combining the topic shift and baseline features increases performance considerably. TopShvar obtained better performance than TopSh across the board. BL + TopShvar posted the overall best system obtaining a Tau of 0.60, NDCG of 0.970, and NDCG@3 of 0.937. These results demonstrates the utility of topic shift features in the power ranking problem, especially using the SITSvar formulation. We also experimented with all subsets of TopSh and TopShvar; the best results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coo</context>
</contexts>
<marker>Reid, Ng, 2000</marker>
<rawString>Scott A. Reid and Sik Hung Ng. 2000. Conversation as a resource for in influence: evidence for prototypical arguments and social identification processes. European Journal of Social Psych., pages 30, 83–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Rosenberg</author>
<author>Julia Hirschberg</author>
</authors>
<title>Charisma perception from text and speech.</title>
<date>2009</date>
<journal>Speech Communication,</journal>
<volume>51</volume>
<issue>7</issue>
<contexts>
<context position="1262" citStr="Rosenberg and Hirschberg, 2009" startWordPosition="186" endWordPosition="189">ative power. We also show that our topic shift features help predict candidates’ relative rankings. 1 Introduction The field of computational social sciences has created many interesting applications for natural language processing in recent years. One of the areas where NLP techniques have shown great promise is in the analysis of political speech. For example, researchers have applied NLP techniques to political texts for a variety of tasks such as predicting voting patterns (Thomas et al., 2006), identifying markers of persuasion (Guerini et al., 2008), capturing cues that signal charisma (Rosenberg and Hirschberg, 2009), and detecting ideological positions (Sim et al., 2013). Our work also analyzes political speech, more specifically, presidential debates. The contribution of this paper is to show that the topic shifting tendency of a presidential candidate changes over the course of the election campaign, and that it is correlated with his or her relative power. We also show that this insight can help computational systems that predict the candidates’ relative rankings based on their interactions in the debates. 2 Motivation The motivation for this paper stems from prior work done by the first author in col</context>
</contexts>
<marker>Rosenberg, Hirschberg, 2009</marker>
<rawString>Andrew Rosenberg and Julia Hirschberg. 2009. Charisma perception from text and speech. Speech Communication, 51(7):640–655.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanchuan Sim</author>
<author>Brice D L Acree</author>
<author>Justin H Gross</author>
<author>Noah A Smith</author>
</authors>
<title>Measuring ideological proportions in political speeches.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on EMNLP,</booktitle>
<pages>91--101</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="1318" citStr="Sim et al., 2013" startWordPosition="195" endWordPosition="198">andidates’ relative rankings. 1 Introduction The field of computational social sciences has created many interesting applications for natural language processing in recent years. One of the areas where NLP techniques have shown great promise is in the analysis of political speech. For example, researchers have applied NLP techniques to political texts for a variety of tasks such as predicting voting patterns (Thomas et al., 2006), identifying markers of persuasion (Guerini et al., 2008), capturing cues that signal charisma (Rosenberg and Hirschberg, 2009), and detecting ideological positions (Sim et al., 2013). Our work also analyzes political speech, more specifically, presidential debates. The contribution of this paper is to show that the topic shifting tendency of a presidential candidate changes over the course of the election campaign, and that it is correlated with his or her relative power. We also show that this insight can help computational systems that predict the candidates’ relative rankings based on their interactions in the debates. 2 Motivation The motivation for this paper stems from prior work done by the first author in collaboration with other researchers (Prabhakaran et al., 2</context>
</contexts>
<marker>Sim, Acree, Gross, Smith, 2013</marker>
<rawString>Yanchuan Sim, Brice D. L. Acree, Justin H. Gross, and Noah A. Smith. 2013. Measuring ideological proportions in political speeches. In Proceedings of the 2013 Conference on EMNLP, pages 91–101, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>Samira Shaikh</author>
<author>Ting Liu</author>
<author>George Aaron Broadwell</author>
<author>Jenny Stromer-Galley</author>
<author>Sarah Taylor</author>
<author>Umit Boz</author>
<author>Veena Ravishankar</author>
<author>Xiaoai Ren</author>
</authors>
<title>Modeling leadership and influence in multi-party online discourse.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>2535--2552</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="18167" citStr="Strzalkowski et al., 2012" startWordPosition="2999" endWordPosition="3003">st results were obtained using all features in each set. 7 Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995; Reid and Ng, 2000)) have long established that dialog structure in interactions relates to power and influence. Researchers in the NLP community have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013; Prabhakaran and Rambow, 2014), online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012). The correlates analyzed in these studies range from word and phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. 8 Conclusion In this paper, we studied how topic shift patterns in the 2012 Republican presidential debates correlate with the power of candidates. We proposed an alternate formulation of the SITS topic segmentation system that captures fluctuatio</context>
</contexts>
<marker>Strzalkowski, Shaikh, Liu, Broadwell, Stromer-Galley, Taylor, Boz, Ravishankar, Ren, 2012</marker>
<rawString>Tomek Strzalkowski, Samira Shaikh, Ting Liu, George Aaron Broadwell, Jenny Stromer-Galley, Sarah Taylor, Umit Boz, Veena Ravishankar, and Xiaoai Ren. 2012. Modeling leadership and influence in multi-party online discourse. In Proceedings of COLING, pages 2535–2552, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Thomas</author>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Get out the vote: Determining support or opposition from congressional floor-debate transcripts.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>327--335</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="1134" citStr="Thomas et al., 2006" startWordPosition="168" endWordPosition="171">candidates to shift topics changes over the course of the election campaign, and that it is correlated with their relative power. We also show that our topic shift features help predict candidates’ relative rankings. 1 Introduction The field of computational social sciences has created many interesting applications for natural language processing in recent years. One of the areas where NLP techniques have shown great promise is in the analysis of political speech. For example, researchers have applied NLP techniques to political texts for a variety of tasks such as predicting voting patterns (Thomas et al., 2006), identifying markers of persuasion (Guerini et al., 2008), capturing cues that signal charisma (Rosenberg and Hirschberg, 2009), and detecting ideological positions (Sim et al., 2013). Our work also analyzes political speech, more specifically, presidential debates. The contribution of this paper is to show that the topic shifting tendency of a presidential candidate changes over the course of the election campaign, and that it is correlated with his or her relative power. We also show that this insight can help computational systems that predict the candidates’ relative rankings based on the</context>
</contexts>
<marker>Thomas, Pang, Lee, 2006</marker>
<rawString>Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out the vote: Determining support or opposition from congressional floor-debate transcripts. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 327–335, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>