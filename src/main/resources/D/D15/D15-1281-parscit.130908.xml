<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001522">
<title confidence="0.962768">
Verbal and Nonverbal Clues for Real-life Deception Detection
</title>
<author confidence="0.9814985">
Ver´onica P´erez-Rosas, Mohamed Abouelenien, Rada Mihalcea,
Yao Xiao, CJ Linton, Mihai Burzo
</author>
<affiliation confidence="0.998997">
University of Michigan
</affiliation>
<email confidence="0.996476">
(vrncapr,zmohamed,mihalcea,xyaoinum,cjlint,mburzo)@umich.edu
</email>
<sectionHeader confidence="0.993847" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999920636363636">
Deception detection has been receiving
an increasing amount of attention from
the computational linguistics, speech, and
multimodal processing communities. One
of the major challenges encountered in this
task is the availability of data, and most of
the research work to date has been con-
ducted on acted or artificially collected
data. The generated deception models
are thus lacking real-world evidence. In
this paper, we explore the use of multi-
modal real-life data for the task of decep-
tion detection. We develop a new decep-
tion dataset consisting of videos from real-
life scenarios, and build deception tools
relying on verbal and nonverbal features.
We achieve classification accuracies in the
range of 77-82% when using a model that
extracts and fuses features from the lin-
guistic and visual modalities. We show
that these results outperform the human
capability of identifying deceit.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999986078431373">
As deceptive behavior occurs on a daily basis in
different areas of life (Meyer, 2010; Smith et al.,
2014), the need arises for automated methodolo-
gies to detect deception in an efficient, yet reliable
manner. There are many applications that can ben-
efit from automatic deception identification, such
as airport security screening, crime investigation
and interrogation, interviews, advertisement, and
others. In many of these settings, the polygraph
test has been used as the main method to identify
deceptive behavior. However, this method requires
the use of skin-contact devices and human exper-
tise, making it infeasible for large-scale applica-
tions. Moreover, polygraph tests were shown to be
misleading in multiple cases (Vrij, 2001; Gannon
et al., 2009), as human judgment is often biased.
Given the difficulties associated with the use
of polygraph-like methods, learning-based ap-
proaches have been proposed to address the de-
ception detection task using a number of modali-
ties, including text (Feng et al., 2012) and speech
(Hirschberg et al., 2005; Newman et al., 2003).
Unlike the polygraph methods, learning-based
methods for deception detection rely mainly on
data collected from deceivers and truth-tellers.
The data is usually elicited from human contrib-
utors, in a lab setting or via crowdsourcing. An
important problem identified in this data-driven re-
search is the lack of real data. Because of the arti-
ficial setting, the subjects may not be emotionally
aroused, as they may not take the experiments seri-
ously given the lack of motivation and/or penalty.
In this paper, we describe what we believe is a
first attempt at building a multimodal system that
detects deception in real-life settings. We collect
a dataset consisting of 118 deceptive and truthful
video clips, from real trials and live street inter-
views aired in television shows. We use the tran-
scription of these videos to extract several linguis-
tic features, and we manually annotate the videos
for the presence of several gestures that are used to
extract nonverbal features. We then build a system
that jointly uses the verbal and nonverbal modali-
ties to automatically detect the presence of decep-
tion. Our experiments show that the multimodal
system can identify deception with an accuracy in
the range of 77-82%, significantly improving over
the baseline. In addition, we present a study on
the human ability to detect deception in single or
multimodal data streams, and show that our sys-
tem outperforms humans on this task.
</bodyText>
<sectionHeader confidence="0.997446" genericHeader="introduction">
2 Dataset
</sectionHeader>
<bodyText confidence="0.99934">
Our goal is to build a multimodal collection of oc-
currences of real deception, which will allow us
to analyze both verbal and nonverbal behaviors in
relation to deception.
</bodyText>
<page confidence="0.897166">
2336
</page>
<note confidence="0.99583">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2336–2346,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figureCaption confidence="0.9471864">
Figure 1: Sample screenshots showing facial displays and hand gestures from real-life deception and
truthful clips. Starting at the top left-hand corner: deceptive interview with up gaze (Up), deceptive
interview with side gaze (Side), deceptive trial with both hands (Both-H), truthful trial with forward
head (Forward), truthful interview with side turn (Side-Turn), and truthful interview with single hand
(Single-H).
</figureCaption>
<tableCaption confidence="0.664519">
Table 1: Sample transcripts for deceptive and truthful clips. The first row presents transcripts from the
Trials domain while the second shows transcripts corresponding to the Interviews domain.
</tableCaption>
<figure confidence="0.5110155">
Truthful
Deceptive
</figure>
<bodyText confidence="0.999501730769231">
I was sentenced to forty to sixty years in prison
for this crime that I didn’t commit. At the trial
the judge had exceeded the sentence guidelines
because he said I failed to show remorse. And I
told him, you know, I felt terrible for what happen
to this woman, shouldn’t happen to anyone, but I
can’t show remorse for something I didn’t do.
It’s difficult to pick just one but um I think Ten-
der Mercies uh is ... really captured my imagi-
nation um when I was in junior high. Had a lot
to do with Robert Duval’s performance certainly
and that got me excited about the possibility of
um .... pulling off an acting career for myself.
We had some drinks at the bar, maybe one ... two.
um I got onto the dance floor myself as I ex-
plained, um I have been a trained dancer for some
time, going to be able to dance freely is like a ...
release. I’m very much in my own space when I
do that and so I got up, and I was dancing alone
on the dance floor.
Yeah, yeah he was convincing as a wolf. Ahhh
actually you know ahhh this is like crazy I’m ter-
rified from wolves, it’s my worst fear even though
they don’t exist but thats my worst fear, sharks
and stuff like that. Yeah its my worst fear, I am
being honest with you.
</bodyText>
<subsectionHeader confidence="0.969399">
2.1 Data Collection
</subsectionHeader>
<bodyText confidence="0.9988574">
To collect real deception data, we start by identi-
fying online multimedia sources where deceptive
behavior can be observed and verified. We specif-
ically target videos of people, on which we en-
force some of the constraints imposed by current
data processing technologies: the person in the
video should be in front of the camera; her face
should be clearly visible; visual quality should
be clear enough to identify the facial expressions;
and finally, audio quality should be clear enough
to hear the voices and understand what the per-
son is saying. We collect video clips from pub-
lic real trials and interviews aired during television
shows, where the truth or falsehood of the partic-
ipant’s statements ends up being known. Video
clips from trials consist of statements from wit-
nesses and defendants in the same trial. In or-
der to have a clear distinction between deceptive
and truthful trial videos portraying defendants, the
process of labeling the trial relies on the verdict.
Thus, clips with a guilty verdict are considered
deceptive whereas clips with a non-guilty verdict
or exoneration are labeled as truthful. Clips con-
taining witness testimonies are labeled as truth-
ful if their statements are verified by police in-
vestigations. Examples of trials included in our
dataset are Jodi Arias, Andrea Sneiderman, and
Amanda Hayes. Exoneree’s statements were taken
from “The Innocence Project” (http://www.
innocenceproject.org).
</bodyText>
<page confidence="0.980405">
2337
</page>
<bodyText confidence="0.999941125">
Deceptive and truthful responses are also col-
lected from TV shows and interviews. Examples
of such shows are “Lie Witness,” “Golden Balls,”
and the “American Film Institute” and “RevYOU”
You-Tube channels. Deceptive videos portray sce-
narios where interviewees’ responses were known
to be a lie. For example, the interviewer asks a ran-
dom individual on his opinion on a non-existing
film where the interviewee fabricates a story. On
the other hand, truthful videos are collected from
individuals asked on their opinions on real movies.
Given our goals and constraints, data collec-
tion ended up being a lengthy and laborious pro-
cess consisting of several iterations of Web min-
ing, data processing and analysis, and content val-
idation.
The final dataset includes 118 videos, includ-
ing 59 that are labeled as deceptive and 59 la-
beled as truthful. Among them, 62 belong to the
TV street interviews and shows category (Inter-
views) with 28 deceptive and 34 truthful video
clips, and 56 belong to the trials category (Trials)
with 31 deceptive and 25 truthful clips. The aver-
age length of the videos in the dataset is 27.28 sec-
onds, with an average length of 33.02 seconds for
the truthful clips and 21.54 seconds for the decep-
tive clips. Collected trial samples cover famous
murder cases, while street interviews cover sev-
eral topics such as movies, music, politics, and re-
ligion. The dataset contains 23 unique female and
39 unique male speakers, with their ages ranging
approximately between 16 and 60 years.
</bodyText>
<subsectionHeader confidence="0.980565">
2.2 Transcriptions and Nonverbal Behavior
Annotations
</subsectionHeader>
<bodyText confidence="0.9998036">
Our goal is to analyze both verbal and nonverbal
behavior to understand their relation to deception.
First, all the video clips were manually tran-
scribed. The transcription was performed by two
transcribers using the Elan software (Wittenburg
et al., 2006). We asked transcribers to include
word repetitions and fillers such as um, ah, and
uh, as well as long pauses that were marked using
three consecutive dots. The final set of transcrip-
tions contain 7835 words, with an average of 66
words per transcript. Table 1 shows transcriptions
of sample deceptive and truthful statements from
both trials and reality shows.
Second, we annotate the gestures1 observed
during the interactions in the video clips. We
</bodyText>
<footnote confidence="0.762051333333333">
1As done in the Human-Computer Interaction commu-
nity, we use the term “gesture” to broadly refer to body move-
ments, including facial expressions and hand gestures.
</footnote>
<table confidence="0.999676363636364">
Gesture Category Agreement Kappa
Facial Expressions 72.88% 0.576
Eyebrows 80.51% 0.656
Eyes 68.64% 0.517
Gaze 61.40% 0.432
Mouth Openness 77.97% 0.361
Mouth Lips 82.20% 0.684
Head Movements 55.08% 0.420
Hand Movements 91.53% 0.858
Hand Trajectory 84.75% 0.753
Average 75.00% 0.584
</table>
<tableCaption confidence="0.998612">
Table 2: Gesture annotation agreement
</tableCaption>
<bodyText confidence="0.999828578947369">
specifically focus on the annotation of facial dis-
plays and hand movements, as they have been pre-
viously found to correlate with deceptive behav-
ior (Depaulo et al., 2003). The gesture annotation
is performed using the MUMIN coding scheme
(Allwood et al., 2007).
In the MUMIN scheme, facial displays consist
of several different facial expressions associated
with eyebrows, eyes, gaze, and mouth. Smile,
laughter, and scowl are also included, as well as
general head and hand movements.
The multimodal annotation was performed by
two annotators using the Elan software (Witten-
burg et al., 2006). We decided to perform the ges-
ture annotations at video level, rather than at utter-
ance level, because the overall judgment of truth-
fulness and deceitfulness is based on the whole
video content. During the annotation process, an-
notators were allowed to watch each video clip as
many times as they needed. They were asked to
identify the facial displays and hand gestures that
were most frequently observed or dominating dur-
ing the entire clip duration. For each video clip,
the annotators had to choose one label for each of
the nine gestures listed in Table 3.
Table 3 shows the frequency counts associated
with the nine gestures considered during the an-
notation. Note that the counts under each gesture
add up to 118, reflecting the fact that for every ges-
ture, the annotators had to choose one label for ev-
ery video clip. When none of the labels applied,
the “Other” category was selected. In the case
of gestures associated with hand movements, the
“Other” label also accounted for those cases where
the speaker’s hands were not moving or were not
visible.
After all the video clips were annotated for
gestures, the inter-annotator agreement was mea-
</bodyText>
<page confidence="0.983375">
2338
</page>
<table confidence="0.9997875">
Label Count Label Count Label Count
Eyebrows General Facial Expressions Hand Trajectory
Frown (Frowning) 17 Smile 41 Up (Upwards) 13
Raise (Raising) 71 Scowl 13 Down (Downwards) 5
Other 30 Laugh (Laughter) 1 Sideways 5
Eyes Other 63 Complex 33
X-open (Exaggerated opening) 17 Mouth Openness Other 62
Close-BE (Closing both) 7 Close-M (Closed mouth) 26 Head Movements
Closing-E (Closing one) 1 Open-M (Open mouth) 92 Down (Single nod) 3
Close-R (Closing repeated) 20 Mouth Lips Down-R (Repeated nods) 48
Other 73 Up-C (Corners up) 61 Forward (Move forward) 3
Gaze Down-C (Corners down) 51 Back (Move backward) 3
Interlocutor 69 Protruded 1 Side-tilt (Single tilt) 8
Up 7 Retracted 5 Side-Tilt-R (Repeated tilts) 9
Down 14 Hand Movements Side-Turn 9
Side 24 Both hands (Both-H) 31 Side-Turn-R (Shake repeated) 26
Other 4 Single hands (Single-H) 26 Waggle 3
Other 61 Other 6
</table>
<tableCaption confidence="0.9999">
Table 3: Frequency counts for nine facial displays and hand gestures
</tableCaption>
<bodyText confidence="0.999974466666667">
sured. Table 2 shows the observed annotation
agreement between the two annotators, along with
the Kappa statistic. The agreement measure rep-
resents the percentage of times the two annotators
agreed on the same label for each gesture category.
For instance, 72.88% of the time the annotators
agreed on the label assigned to the General Face
category. On average, the observed agreement was
measured at 75%, with a Kappa of 0.58 (macro-
averaged over the nine categories), which reflects
substantial agreement. Observed agreement for
Head Movements and Gaze is noticeably lower
than other categories, which can be attributed to
a higher number of available gesture choices, as
seen in Table 3.
</bodyText>
<sectionHeader confidence="0.938823" genericHeader="method">
3 Features of Verbal and Nonverbal
Behaviors
</sectionHeader>
<bodyText confidence="0.999955">
Given the multimodal nature of our dataset, we de-
cided to focus on the linguistic and gesture compo-
nents. In this section, we describe the sets of fea-
tures extracted for each modality, which will then
be used to build classifiers of deception.
</bodyText>
<subsectionHeader confidence="0.997979">
3.1 Verbal Features
</subsectionHeader>
<bodyText confidence="0.99994415">
We implement three types of features, consisting
of unigrams, psycholinguistic features, and syn-
tactic complexity features.
Unigrams. We extract unigrams derived from
the bag-of-words representation of the video
transcripts. The unigram features are en-
coded as word frequencies and include all the
words present in the transcripts.
Psycholinguistic Features. The Linguistic Word
Count (LIWC) is a psycholinguistics lexicon
that has been frequently used to incorporate
semantic and psychological information into
linguistic analysis (Pennebaker and Francis,
1999). It has been successfully used in pre-
vious work on deception detection (Newman
et al., 2003; Mihalcea and Strapparava, 2009;
Ott et al., 2011). We obtain features for each
of the 80 psycholinguistic classes present in
the lexicon by calculating the percentage of
words in the transcription belonging to each
class.
Syntactic Complexity. We also extract features
to measure the syntactic complexity of the
speech produced by the speakers in truth-
ful and deceptive clips. This set of features
is motivated by previous research that has
suggested that deceivers’ speech has lower
complexity (Depaulo et al., 2003). We use
the tool described in (Lu, 2010), which gen-
erates indexes of syntactic complexity, in-
cluding general complexity metrics, length of
production, and amount of coordination. The
set of features consists of fourteen indexes
including statistics related to T-units, which
are linguistic units that include a main clause
in addition to attached subordinate clauses.
T-unit analysis is extensively used to ana-
lyze syntactic complexity in speech and writ-
ten content. The set of features includes the
mean length of sentence, mean length of T-
</bodyText>
<page confidence="0.976408">
2339
</page>
<figure confidence="0.990680625">
Deceptive Truthful
1
0.8
0.6
0.4
0.2
0
Smile Close-R Side-Turn-R Raise Interlocutor Side Open-M Down-R Single-H
</figure>
<figureCaption confidence="0.999799">
Figure 2: Distribution of nonverbal features for deceptive and truthful groups
</figureCaption>
<bodyText confidence="0.999849875">
unit, mean length of clause, clauses per sen-
tence, verb phrases per T-unit, clauses per T-
unit, dependent clauses per clause, dependent
clauses per T-unit, T-units per sentence, com-
plex T-unit ratio, coordinate phrases per T-
unit, coordinate phrases per clause, complex
nominals per T-unit, and complex nominals
per clause.
</bodyText>
<subsectionHeader confidence="0.998707">
3.2 Nonverbal Features
</subsectionHeader>
<bodyText confidence="0.99942585">
The nonverbal features are derived from the an-
notations performed using the MUMIN coding
scheme as described in section 2.2. We create a
binary feature for each of the 40 available gesture
labels. Each feature indicates the presence of a
gesture only if it is observed during the majority
of the interaction duration. The generated features
represent nine different gesture categories cover-
ing facial displays and hand movements.
Facial Displays. These are facial expressions or
head movements displayed by the speaker
during the deceptive or truthful interaction.
They include all the behaviors listed in Table
3 under the General Facial Expressions, Eye-
brows, Eyes, Mouth Openness, Mouth Lips,
and Head Movements.
Hand Gestures. The second broad category cov-
ers gestures made with the hands, and it in-
cludes the Hand Movements and Hand Tra-
jectories listed in Table 3.
</bodyText>
<sectionHeader confidence="0.999509" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999214">
We start our experiments with an analysis of the
nonverbal behaviors occurring in deceptive and
truthful videos. We compare the percentage of
each behavior as observed in each class. For in-
stance, there is a total of 41 videos in the dataset
</bodyText>
<table confidence="0.9784446">
Feature Set SVM DT RF
Unigrams 69.49% 76.27% 67.79%
Psycholinguistic 53.38% 50.00% 66.10%
Syntactic Complexity 52.54% 62.71% 53.38%
Facial Displays 78.81% 74.57% 67.79%
Hand Gestures 59.32% 57.62% 57.62%
Unigr.+Facial Disp. 71.18% 70.33% 68.64%
All Verbal 65.25% 63.55 % 57.62 %
All Nonverbal 75.42% 68.64% 72.03%
All Features 77.11% 69.49% 73.72%
</table>
<tableCaption confidence="0.986604">
Table 4: Deception classifiers using individual and
combined sets of verbal and nonverbal features.
</tableCaption>
<bodyText confidence="0.999881958333333">
that include the Smile feature (as shown in Ta-
ble 3), out of which 12 are part of the deceptive
set of 59 videos, and 29 are part of the truthful
set (again, of 59 videos). Hence, the percentages
for this feature are 20.33% in the deceptive class,
and 49.13% in the truthful class. Figure 2 shows
the percentages of all the nonverbal features for
which we observe noticeable differences for the
deceptive and truthful groups. As the figure sug-
gests, facial displays seem to help differentiate be-
tween the deceptive and truthful conditions. For
instance, we can observe that truth-tellers smile
(Smile) and blink more (Close-R). Interestingly
deceivers seem to make more eye contact (Inter-
locutor gaze) and nod (Side-Turn-R) more fre-
quently than truth-tellers. This agrees with the
findings in (Depaulo et al., 2003) that liars who are
more motivated to get away with their lies (i.e., tri-
als) are likely to increase their eye-contact behav-
ior.
Motivated by these results, we proceed to con-
duct further experiments to evaluate the perfor-
mance of the extracted features using a machine
learning approach.
</bodyText>
<page confidence="0.873342">
2340
</page>
<table confidence="0.999943142857143">
Feature Set SVM
All 77.11%
– Hand gestures 74.57%
– Facial displays 64.40%
– Syntactic 76.27%
– Semantic 72.03%
– Unigrams 73.72%
</table>
<tableCaption confidence="0.996338">
Table 5: Feature ablation study.
</tableCaption>
<bodyText confidence="0.9999832">
We run our learning experiments on the real-
deception dataset introduced earlier. Given the
even distribution between deceptive and truthful
clips, the baseline on this dataset is 50%. For
each video clip, we create feature vectors formed
by combinations of the verbal and nonverbal fea-
tures described in the previous section. We build
deception classifiers using three classification al-
gorithms: Support Vector Machines (SVM), De-
cision Trees (DT), and Random Forest (RF).2 We
run several comparative experiments using leave-
one-out cross-validation. Table 4 shows the accu-
racy figures obtained by the three classifiers on the
major feature groups described in Section 3. As
shown in this table, the facial displays classifier
achieves the highest accuracy among the individ-
ual classifiers, followed by the unigrams classifier.
We also evaluate classifiers that rely on com-
bined sets of features. The nonverbal features
clearly outperform the verbal features, and the
classifier that includes all the features improves
over the classifiers that rely on all the verbal fea-
tures or all the nonverbal features. Importantly,
several of the classifiers improve significantly over
the baseline.
</bodyText>
<subsectionHeader confidence="0.999738">
4.1 Analysis of Feature Contribution
</subsectionHeader>
<bodyText confidence="0.999902538461538">
To better understand the contribution of the dif-
ferent feature sets to the overall classifier perfor-
mance, we conduct an ablation study where we re-
move one group of features at a time. Given that
SVM had the best performance in our initial set of
experiments, we run all our analysis experiments
only using this classifier. Table 5 shows the accu-
racies obtained when one feature group is removed
and the deception classifier is built using the re-
maining features. From this table, we can again
observe that Facial Displays contribute the most
to the classifier performance, while Syntactic Fea-
tures show the lowest contribution.
</bodyText>
<footnote confidence="0.825567">
2We use the implementation available in the Weka toolkit
with the default parameters.
</footnote>
<figureCaption confidence="0.999586">
Figure 3: Weights of top nonverbal features
</figureCaption>
<bodyText confidence="0.999961454545454">
For a closer look at the contribution of indi-
vidual features included in the group of Facial
Displays, we analyzed the absolute values of the
weights assigned by the learning algorithm to the
features in this group. Figure 3 shows the fea-
tures normalized with respect to the largest fea-
ture weight. The five most predictive features are
the presence of side turns, up gazes, blinking, and
smiling, which we previously identified as possi-
ble indicators of deception. This further confirms
our initial hypothesis that gestures associated with
human interaction are an important component of
human deception.
We also analyze the contribution of the lin-
guistic features. Using the linguistic ethnogra-
phy method (Mihalcea and Pulman, 2009), we ob-
tain the most dominant LIWC word classes asso-
ciated with deceptive and truthful transcripts ex-
tracted from trials and interviews clips. Results
are shown in Table 6. Interestingly, the most dom-
inant classes in truthful clips, regardless of being
from interviews or trials, correspond to words re-
lated to Family, Home, and Humans. This sug-
gests that truth-tellers show similar word usage
when interviewed on a real scenario. On the other
hand, dominant classes associated to deceivers are
less consistent as they discuss aspects related to
the topic being discussed. For instance, while be-
ing interviewed about a non-existing movie, de-
ceivers talk about their Past, Assent, and use Mo-
tion words in order to support their lies. In con-
trast, while being on trial stating their (false) inno-
cence, they use Anxiety, Anger, and negative emo-
</bodyText>
<figure confidence="0.966279583333333">
Feature Weights
0 0.2 0.4 0.6 0.8 1
Side turn
Up gaze
Blinking
Smile
Lips down
Open mouth
Single hand
Closing both eyes
Raising eyebrows
Side Tilt
</figure>
<page confidence="0.854511">
2341
</page>
<table confidence="0.990921666666667">
Truthful
Interviews Trials
Class Score Class Score
Metaphor 2.98 You 3.99
Money 2.74 Family 3.07
Inhibition 2.74 Home 2.45
Home 2.13 Humans 1.87
Humans 2.02 Posemo 1.81
Family 1.96 Insight 1.64
Deceptive
Interviews Trials
Class Score Class Score
Assent 4.81 Anger 2.61
Past 2.59 Anxiety 2.61
Sexual 2.00 Certain 2.28
Other 1.87 Death 1.96
Motion 1.68 Physical 1.77
Negemo 1.44 Negemo 1.52
</table>
<tableCaption confidence="0.9309125">
Table 6: LIWC word classes most strongly associ-
ated with deception and truth.
</tableCaption>
<bodyText confidence="0.999302166666667">
tion words (class Negemo). In line with earlier ob-
servations (Mihalcea and Strapparava, 2009), de-
ceptive texts include more words that reflect cer-
tainty (class Certain, with words such as com-
pletely, truly, always) and more references to oth-
ers (class Other, with words such as she, day, him).
</bodyText>
<subsectionHeader confidence="0.980459">
4.2 Domain Experiments
</subsectionHeader>
<bodyText confidence="0.9999125">
We perform three sets of experiments to determine
the role played by the domain. The first set of ex-
periments uses only the Interviews video clips (62
in total), and the results are shown in the left col-
umn of Table 7. The second set uses only the Tri-
als instances (56 in total), with results shown in the
right column of Table 7. Finally, we also perform
cross-domain experiments, with the training data
drawn from one domain and the test data from the
other. The results of these experiments are shown
in Table 8. Given the uneven distribution of the
truthful and deceptive video clips in two domains,
the baselines are 54.83% for the Interviews do-
main (34 truthful, 28 deceptive), and 55.35% for
the Trials domain (25 truthful, 31 deceptive).
What we learn from these experiments is that
the domain does matter. Despite the smaller
dataset, the experiments run on one domain at a
time lead to results that are higher than the ones
obtained with more data but with a mix of do-
mains. The cross-domain experiments also sup-
port this argument, as the performance drops sig-
</bodyText>
<table confidence="0.999901">
Feature Set Interviews Trials
Baseline 54.83% 55.35%
Unigrams 75.80 % 82.14%
Psycholinguistics 59.67% 50.00%
Syntactic Complexity 54.83% 60.71%
Facial Displays 70.96% 80.35%
Hand Gestures 56.45% 48.21%
Unigr.+Facial Disp. 70.96% 76.78%
All Verbal 70.96% 64.28%
All Nonverbal 67.14% 83.92%
All features 79.03% 82.14%
</table>
<tableCaption confidence="0.9857915">
Table 7: Deception classifiers for the Interviews
and Trials domains, using a SVM classifier trained
on individual and combined sets of verbal and
nonverbal features.
</tableCaption>
<table confidence="0.998935333333333">
Training Test SVM
Trials Interviews 58.06%
Interviews Trials 58.92%
</table>
<tableCaption confidence="0.9967005">
Table 8: Cross-domain classification results using
a SVM classifier trained on all the features
</tableCaption>
<bodyText confidence="0.9999483125">
nificantly when there is no overlap in domain be-
tween the training and the test instances. Over-
all, in all our machine learning experiments, the
combined classifier that makes use of all the verbal
and nonverbal features achieves the best trade-off
between performance and robustness, as it always
leads to the best or second best performance across
all the experiments using individual or combined
feature sets. While a classifier based on an individ-
ual feature set can sometime lead to a better per-
formance (e.g., the Facial Displays classifier has
better performance when all the video clips are
used), that same classifier may not perform well in
another setting (e.g., the Facial Displays classifier
is significantly below the All Features classifier in
the domain experiments).
</bodyText>
<sectionHeader confidence="0.971059" genericHeader="method">
5 Human Performance
</sectionHeader>
<bodyText confidence="0.999687272727273">
An important remaining question is concerned
with the human performance on the task of de-
ception detection. An answer to this question can
shed light on the difficulty of the task, and can also
place our results in perspective.
We conduct a study where we evaluate the hu-
man ability to identify deceit when exposed to four
different modalities: Text, consisting of the lan-
guage transcript; Audio, consisting of the audio
track of the clip; Silent video, consisting of only
the video with muted audio; and Full video, where
</bodyText>
<page confidence="0.977651">
2342
</page>
<table confidence="0.9996804">
Modality Agreement Kappa
Text 58.80% 0.047
Audio 66.70% 0.288
Silent video 52.00% 0.065
Full Video 61.60% 0.191
</table>
<tableCaption confidence="0.993204666666667">
Table 9: Agreement among three human annota-
tors on text, audio, silent video, and full video
modalities.
</tableCaption>
<table confidence="0.9996566">
Text Audio Silent video Full video
A1 54.24% 58.47% 50.85% 63.00%
A2 55.93% 67.80% 45.76% 68.00%
A3 65.25% 70.34% 55.93% 71.00%
Sys. 65.75% NA 75.42% 77.11%
</table>
<tableCaption confidence="0.923931">
Table 10: Performance of three annotators and
</tableCaption>
<bodyText confidence="0.986074676470588">
the developed automatic system (Sys) on the real-
deception dataset over four modalities.
audio and video are played simultaneously. We
create an annotation interface that shows an anno-
tator instances for each modality in random order,
and ask him or her to select a label of either “De-
ception” or “Truth” according to his or her percep-
tion of truthfulness or falsehood.
To avoid annotation bias, we show the modal-
ities in the following order: first we show either
Text or Silent video, then we show Audio, followed
by Full video. Note that apart from this constraint
which is enforced over the four modalities belong-
ing to each video clip, the order in which instances
are presented to an annotator is random. Further-
more, the annotators did not have access to any
information that would reveal the true label of an
instance. The only exception to this could have
been the annotators’ previous knowledge of some
of the public trials in our dataset. A discussion
with the annotators after the annotation took place
indicated however that this was not the case.
Three annotators labeled all the 118 video clips
in the dataset. Since four modalities were ex-
tracted from each video, each annotator annotated
a total of 412 instances. Annotators were not of-
fered a monetary reward and we considered their
judgments to be honest as they participated volun-
tarily in this experiment. Table 9 shows the ob-
served agreement and Kappa statistics among the
three annotators for each modality.3 The agree-
ment for most modalities is rather low and the
Kappa scores range between slight to fair agree-
ment. As noted before (Ott et al., 2011), this low
</bodyText>
<footnote confidence="0.60553">
3Inter-rater agreement with multiple raters and variables.
https://mlnl.net/jg/software/ira/
</footnote>
<bodyText confidence="0.999147736842105">
agreement can be interpreted as an indication that
people are poor judges of deception.
We also determine each annotator’s perfor-
mance for each modality. The results, shown in
Table 10, additionally support the argument that
human judges have difficulty performing the de-
ception detection task. An interesting, yet perhaps
unsurprising observation is that the human perfor-
mance increases with the availability of modali-
ties. The poorest accuracy is obtained in Silent
video, followed by Text, Audio, and Full Video
where the judges have the highest performance.
Overall, our study indicates that detecting de-
ception is indeed a difficult task for humans and
further verifies previous findings where human
ability to spot liars was found to be slightly better
than chance (Aamodt and Custer, 2006). More-
over, the performance of the human annotators ap-
pears to be significantly below that of our system.
</bodyText>
<sectionHeader confidence="0.999914" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.998962258064516">
Verbal Deception Detection. To date, several re-
search publications on verbal-based deception de-
tection have explored the identification of decep-
tive content in a variety of domains, including on-
line dating websites (Toma and Hancock, 2010;
Guadagno et al., 2012), forums (Warkentin et al.,
2010; Joinson and Dietz-Uhler, 2002), social net-
works (Ho and Hollister, 2013), and consumer re-
port websites (Ott et al., 2011; Li et al., 2014).
Research findings have shown the effectiveness
of features derived from text analysis, which fre-
quently includes basic linguistic representations
such as n-grams and sentence count statistics (Mi-
halcea and Strapparava, 2009), and also more
complex linguistic features derived from syntac-
tic CFG trees and part of speech tags (Feng et al.,
2012; Xu and Zhao, 2012). Research work has
also relied on the LIWC lexicon to build deception
models using machine learning approaches (Mi-
halcea and Strapparava, 2009; ´Angela Almela et
al., 2012) and showed that the use of psycholin-
guistic information is helpful for the automatic
identification of deceit. Following the hypothe-
sis that deceivers might create less complex sen-
tences in an effort to conceal the truth and being
able to recall their lies more easily, several re-
searchers have also studied the relation between
text syntactic complexity and deception (Yancheva
and Rudzicz, 2013).
Nonverbal Deception Detection. Earlier ap-
proaches to nonverbal deception detection relied
</bodyText>
<page confidence="0.942164">
2343
</page>
<bodyText confidence="0.999968254545455">
on polygraph tests to detect deceptive behavior.
These tests are mainly based on such physiolog-
ical features such as heart rate, respiration rate,
skin temperature. Several studies (Vrij, 2001;
Gannon et al., 2009; Derksen, 2012) indicated
that relying solely on physiological measurements
can be biased and misleading. Chittaranjan et
al. (Chittaranjan and Hung, 2010) created an au-
dio visual recording of the “Are you a Werewolf?”
game in order to detect deceptive behaviour us-
ing non-verbal audio cues and to predict the sub-
jects’ decisions in the game. For hand gestures,
blob analysis was used to detect deceit by track-
ing the hand movements of the subjects (Lu et al.,
2005; Tsechpenakis et al., 2005), or using geo-
metric features related to the hand and head mo-
tion (Meservy et al., 2005). Caso et al. (Caso
et al., 2006) identified particular hand gestures
that can be related to the act of deception using
data from simulated interviews. Cohen et al.
(2010) found that fewer iconic hand gestures were
a sign of a deceptive narration, and Hillman et al.
(2012) determined that increased speech prompt-
ing gestures were associated with deception while
increased rhythmic pulsing gestures were associ-
ated with truthful behavior. Also related is the
taxonomy of hand gestures developed by (Mar-
icchiolo et al., ) for deception and social behav-
ior. Facial expressions also played a critical role
in the identification of deception. (Ekman, 2001)
defined micro-expressions as relatively short in-
voluntary expressions, which can be indicative of
deceptive behavior. Moreover, these expressions
were analyzed using smoothness and asymmetry
measurements to further relate them to an act of
deceit (Ekman, 2003). Tian et al. (Tian et al.,
2005) considered features such as face orienta-
tion and facial expression intensity. Owayjan et
al. (Owayjan et al., 2012) extracted geometric-
based features from facial expressions, and Pfis-
ter and Pietikainen (Pfister and Pietik¨ainen, 2012)
developed a micro-expression dataset to identify
expressions that are clues for deception. Recently,
features from different modalities were integrated
in order to find a combination of multimodal fea-
tures with superior performance (Burgoon et al.,
2009; Jensen et al., 2010). A multimodal decep-
tion dataset consisting of linguistic, thermal, and
physiological features was introduced in (P´erez-
Rosas et al., 2014), which was then used to de-
velop a multimodal deception detection system
(Abouelenien et al., 2014). An extensive review
of approaches for evaluating human credibility us-
ing physiological, visual, acoustic, and linguistic
features is available in (Nunamaker et al., 2012).
</bodyText>
<sectionHeader confidence="0.992273" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.99966546875">
In this paper we presented a study of multimodal
deception detection using real-life occurrences of
deceit. We introduced a novel dataset covering
recordings from public real trials and street inter-
views, and used this dataset to perform both qual-
itative and quantitative experiments. Our analy-
sis of nonverbal behaviors occurring in deceptive
and truthful videos brought insight into the ges-
tures that play a role in deception. We also built
classifiers relying on individual or combined sets
of verbal and nonverbal features, and showed that
we can achieve accuracies in the range of 77-82%.
Additional analyses showed the role played by
the various feature sets used in the experiments,
and the importance of the domain. To place our re-
sults in perspective and better understand the dif-
ficulty of the task, we performed a study of hu-
man ability to detect deception, which revealed
high disagreement among the annotators. Our au-
tomatic system outperforms the human detection
of deceit by 6-15%.
To our knowledge this is the first work to auto-
matically detect instances of deceit using both ver-
bal and nonverbal features extracted from real de-
ception data. In order to develop a fully automated
deception deception system, our future work will
address the use of automatic gesture and facial ex-
pression identification and automated speech tran-
scription. Our goal is to move forward towards a
real-time deception detection system.
The dataset introduced in this paper is publicly
available from http://lit.eecs.umich.edu.
</bodyText>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997713727272727">
This material is based in part upon work sup-
ported by National Science Foundation awards
#1344257 and #1355633, by grant #48503 from
the John Templeton Foundation, and by DARPA-
BAA-12-47 DEFT grant #12475008. Any opin-
ions, findings, and conclusions or recommenda-
tions expressed in this material are those of the
authors and do not necessarily reflect the views of
the National Science Foundation, the John Tem-
pleton Foundation, or the Defense Advanced Re-
search Projects Agency.
</bodyText>
<page confidence="0.98122">
2344
</page>
<note confidence="0.4973244">
Paul Ekman. 2003. Darwin, deception, and facial ex-
pression. Annals of the New York Academy of Sci-
ences, 1000(EMOTIONS INSIDE OUT: 130 Years
after Darwin’s The Expression of the Emotions in
Man and Animals):205–221.
</note>
<sectionHeader confidence="0.621605" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.92782925">
Michael G. Aamodt and Heather Custer. 2006. Who
can best catch a liar? a meta-analysis of individual
differences in detecting deception. Forensic Exam-
iner, 15(1):6–11.
</bodyText>
<reference confidence="0.985251474226804">
Mohamed Abouelenien, Veronica P´erez-Rosas, Rada
Mihalcea, and Mihai Burzo. 2014. Deception de-
tection using a multimodal approach. In Proceed-
ings of the 16th International Conference on Mul-
timodal Interaction, pages 58–65, New York, NY,
USA. ACM.
Jens Allwood, Loredana Cerrato, Kristiina Jokinen,
Costanza Navarretta, and Patrizia Paggio. 2007.
The mumin coding scheme for the annotation of
feedback, turn management and sequencing phe-
nomena. Language Resources and Evaluation,
41(3-4):273–287.
´Angela Almela, Rafael Valencia-Garcia, and Pascual
Cantos. 2012. Seeing through deception: A com-
putational approach to deceit detection in written
communication. In Proceedings of the Workshop on
Computational Approaches to Deception Detection,
pages 15–22, Avignon, France, April.
Judee K. Burgoon, Douglas P. Twitchell, Matthew L.
Jensen, Thomas O. Meservy, Mark Adkins, John
Kruse, Amit V. Deokar, Gabriel Tsechpenakis, Shan
Lu, Dimitris N. Metaxas, et al. 2009. Detecting
concealment of intent in transportation screening: A
proof of concept. IEEE Transactions on Intelligent
Transportation Systems, 10(1):103–112, March.
Letizia Caso, Fridanna Maricchiolo, Marino Bonaiuto,
Aldert Vrij, and Samantha Mann. 2006. The impact
of deception and suspicion on different hand move-
ments. Journal of Nonverbal Behavior, 30(1):1–19.
Gokul Chittaranjan and Hayley Hung. 2010. Are you
awerewolf? detecting deceptive roles and outcomes
in a conversational role-playing game. In 2010
IEEE International Conference on Acoustics Speech
and Signal Processing (ICASSP), pages 5334–5337,
March.
Doron Cohen, Geoffrey Beattie, and Heather Shovel-
ton. 2010. Nonverbal indicators of deception: How
iconic gestures reveal thoughts that cannot be sup-
pressed. Semiotica, 2010(182):133–174.
Bella Depaulo, Brian Malone, James Lindsay, Laura
Muhlenbruck, Kelly Charlton, and Harris Cooper.
2003. Cues to deception. Psychological Bulletin,
pages 74–118.
Maarten Derksen. 2012. Control and resistance in
the psychology of lying. Theory and Psychology,
22(2):196–212.
Paul Ekman, 2001. Telling Lies: Clues to Deceit in the
Marketplace, Politics and Marriage. Norton, W.W.
and Company.
Song Feng, Ritwik Banerjee, and Yejin Choi. 2012.
Syntactic stylometry for deception detection. In
Proceedings of the 50th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 2:
Short Papers), pages 171–175, Jeju Island, Korea,
July. Association for Computational Linguistics.
Theresa Gannon, Anthony Beech, and Tony Ward,
2009. Risk Assessment and the Polygraph, pages
129–154. John Wiley and Sons Ltd.
Rosanna E. Guadagno, Bradley M. Okdie, and Sara A.
Kruse. 2012. Dating deception: Gender, online
dating, and exaggerated self-presentation. Comput.
Hum. Behav., 28(2):642–647, March.
Jackie Hillman, Aldert Vrij, and Samantha Mann.
2012. Um they were wearing : The effect of de-
ception on specific hand gestures. Legal and Crimi-
nological Psychology, 17(2):336–345.
Julia Hirschberg, Stefan Benus, Jason M. Brenier,
Frank Enos, Sarah Friedman, Sarah Gilman, Cynthia
Girand, Martin Graciarena, Andreas Kathol, Laura
Michaelis, et al. 2005. Distinguishing deceptive
from non-deceptive speech. In In Proceedings of In-
terspeech 2005 - Eurospeech, pages 1833–1836.
Shuyuan Mary Ho and Jonathan M Hollister. 2013.
Guess who? an empirical study of gender decep-
tion and detection in computer-mediated communi-
cation. Proceedings of the American Society for In-
formation Science and Technology, 50(1):1–4.
Matthew Jensen, Thomas Meservy, Judee Burgoon,
and Jay Nunamaker. 2010. Automatic, multimodal
evaluation of human interaction. Group Decision
and Negotiation, 19(4):367–389.
Adam N. Joinson and Beth Dietz-Uhler. 2002. Ex-
planations for the perpetration of and reactions to
deception in a virtual community. Social Science
Computer Review, 20(3):275–289.
Jiwei Li, Myle Ott, Claire Cardie, and Eduard Hovy.
2014. Towards a general rule for identifying decep-
tive opinion spam. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational
Linguistics, Baltimore, Maryland, June.
Shan Lu, Gabriel Tsechpenakis, Dimitris Metaxas,
Matthew Jensen, and John Kruse. 2005. Blob anal-
ysis of the head and hands: A method for decep-
tion detection. In Proceedings of the 38th Annual
Hawaii International Conference on System Sci-
ences (HICSS’05), HICSS ’05, pages 20–29, Wash-
ington, DC, USA.
</reference>
<page confidence="0.715888">
2345
</page>
<reference confidence="0.999923303571429">
Xiaofei Lu. 2010. Automatic analysis of syntac-
tic complexity in second language writing. Inter-
national Journal of Corpus Linguistics, 15(4):474–
496.
Fridanna Maricchiolo, Augusto Gnisci, and Marino
Bonaiuto. In Anna Esposito, AntoniettaM. Esposito,
Alessandro Vinciarelli, Rdiger Hoffmann, and Vin-
centC. Mller, editors, Cognitive Behavioural Sys-
tems, pages 405–416. Springer Berlin Heidelberg.
Thomas Meservy, Matthew Jensen, John Kruse, Dou-
glas Twitchell, Gabriel Tsechpenakis, Judee Bur-
goon, Dimitris Metaxas, and Jay Nunamaker. 2005.
Deception detection through automatic, unobtrusive
analysis of nonverbal behavior. IEEE Intelligent
Systems, 20(5):36–43, September.
Pamela Meyer. 2010. Liespotting: Proven Techniques
to Detect Deception. New York: St. Martin’s.
Rada Mihalcea and Stephen Pulman. 2009. Linguistic
ethnography: Identifying dominant word classes in
text. In Computational Linguistics and Intelligent
Text Processing, pages 594–602. Springer.
Rada Mihalcea and Carlo Strapparava. 2009. The lie
detector: Explorations in the automatic recognition
of deceptive language. In Proceedings of the Asso-
ciation for Computational Linguistics (ACL 2009),
Singapore. Association for Computational Linguis-
tics.
Matthew L. Newman, James W. Pennebaker, Diane S.
Berry, and Jane M. Richards. 2003. Lying words:
Predicting deception from linguistic styles. Person-
ality and Social Psychology Bulletin, 29.
Jay F. Nunamaker, Judee K. Burgoon, Nathan W.
Twyman, Jeffrey Gainer Proudfoot, Ryan M.
Schuetzler, and Justin Scott Giboney. 2012. Estab-
lishing a foundation for automated human credibility
screening. In 2012 IEEE International Conference
on Intelligence and Security Informatics (ISI), pages
202–211, June.
Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey Han-
cock. 2011. Finding deceptive opinion spam by
any stretch of the imagination. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies - Volume 1, HLT ’11, pages 309–319, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Michel Owayjan, Ahmad Kashour, Nancy Al Haddad,
Maurice Fadel, and Ghinwa Al Souki. 2012. The
design and development of a lie detection system
using facial micro-expressions. In 2012 2nd Inter-
national Conference on Advances in Computational
Tools for Engineering Applications (ACTEA), pages
33–38, Dec.
James W. Pennebaker and Martha E. Francis. 1999.
Linguistic inquiry and word count: LIWC. Erlbaum
Publishers.
Ver´onica P´erez-Rosas, Rada Mihalcea, Alexis Narvaez,
and Mihai Burzo. 2014. A multimodal dataset for
deception detection. In Proceedings of the Ninth In-
ternational Conference on Language Resources and
Evaluation (LREC-2014), Reykjavik, Iceland, May
26-31, 2014., pages 3118–3122.
Tomas Pfister and Matti Pietik¨ainen. 2012. Electronic
imaging &amp; signal processing automatic identifica-
tion of facial clues to lies. SPIE Newsroom, January.
Madeline Smith, Jeffrey Hancock, Lindsay Reynolds,
and Jeremy Birnholtz. 2014. Everyday deception
or a few prolific liars? the prevalence of lies in
text messaging. Computers in Human Behavior,
41(0):220–227.
Ying-Li Tian, Takeo Kanade, and Jeffrey F. Cohn.
2005. Facial expression analysis. In Handbook
of Face Recognition, pages 247–275. Springer New
York.
Catalina L. Toma and Jeffrey T. Hancock. 2010. Read-
ing between the lines: linguistic cues to deception in
online dating profiles. In Proceedings of the 2010
ACM conference on Computer supported coopera-
tive work, CSCW ’10, pages 5–8.
Gabriel Tsechpenakis, Dimitris Metaxas, Mark Ad-
kins, John Kruse, Judee K. Burgoon, Matthew L.
Jensen, Thomas Meservy, Douglas P. Twitchell,
Amit Deokar, and Jay F. Nunamaker. 2005. Hmm-
based deception recognition from visual cues. In
IEEE International Conference on Multimedia and
Expo, 2005. ICME 2005, pages 824–827, July.
Aldert Vrij. 2001. Detecting Lies and Deceit: The
Psychology of Lying and the Implications for Pro-
fessional Practice. Wiley series in the psychology
of crime, policing and law. Wiley.
Darcy Warkentin, Michael Woodworth, Jeffrey T Han-
cock, and Nicole Cormier. 2010. Warrants and
deception in computer mediated communication.
In Proceedings of the 2010 ACM conference on
Computer supported cooperative work, pages 9–12.
ACM.
Peter Wittenburg, Hennie Brugman, Albert Russel,
Alex Klassmann, and Han Sloetjes. 2006. Elan: a
professional framework for multimodality research.
In Language Resources and Evaluation, volume
2006.
Qiongkai Xu and Hai Zhao. 2012. Using deep lin-
guistic features for finding deceptive opinion spam.
In Proceedings of COLING 2012: Posters, Mumbai,
India, December.
Maria Yancheva and Frank Rudzicz. 2013. Automatic
detection of deception in child-produced speech us-
ing syntactic complexity features. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
pages 944–953, Sofia, Bulgaria, August. Associa-
tion for Computational Linguistics.
</reference>
<page confidence="0.989584">
2346
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.803776">
<title confidence="0.999753">Verbal and Nonverbal Clues for Real-life Deception Detection</title>
<author confidence="0.907064">Ver´onica P´erez-Rosas</author>
<author confidence="0.907064">Mohamed Abouelenien</author>
<author confidence="0.907064">Rada Yao Xiao</author>
<author confidence="0.907064">CJ Linton</author>
<author confidence="0.907064">Mihai</author>
<affiliation confidence="0.99946">University of</affiliation>
<email confidence="0.998415">(vrncapr,zmohamed,mihalcea,xyaoinum,cjlint,mburzo)@umich.edu</email>
<abstract confidence="0.999493347826087">Deception detection has been receiving an increasing amount of attention from the computational linguistics, speech, and multimodal processing communities. One of the major challenges encountered in this task is the availability of data, and most of the research work to date has been conducted on acted or artificially collected data. The generated deception models are thus lacking real-world evidence. In this paper, we explore the use of multimodal real-life data for the task of deception detection. We develop a new deception dataset consisting of videos from reallife scenarios, and build deception tools relying on verbal and nonverbal features. We achieve classification accuracies in the range of 77-82% when using a model that extracts and fuses features from the linguistic and visual modalities. We show that these results outperform the human capability of identifying deceit.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohamed Abouelenien</author>
<author>Veronica P´erez-Rosas</author>
<author>Rada Mihalcea</author>
<author>Mihai Burzo</author>
</authors>
<title>Deception detection using a multimodal approach.</title>
<date>2014</date>
<booktitle>In Proceedings of the 16th International Conference on Multimodal Interaction,</booktitle>
<pages>58--65</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Abouelenien, P´erez-Rosas, Mihalcea, Burzo, 2014</marker>
<rawString>Mohamed Abouelenien, Veronica P´erez-Rosas, Rada Mihalcea, and Mihai Burzo. 2014. Deception detection using a multimodal approach. In Proceedings of the 16th International Conference on Multimodal Interaction, pages 58–65, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Allwood</author>
<author>Loredana Cerrato</author>
<author>Kristiina Jokinen</author>
<author>Costanza Navarretta</author>
<author>Patrizia Paggio</author>
</authors>
<title>The mumin coding scheme for the annotation of feedback, turn management and sequencing phenomena. Language Resources and Evaluation,</title>
<date>2007</date>
<pages>41--3</pages>
<contexts>
<context position="10359" citStr="Allwood et al., 2007" startWordPosition="1666" endWordPosition="1669">ing facial expressions and hand gestures. Gesture Category Agreement Kappa Facial Expressions 72.88% 0.576 Eyebrows 80.51% 0.656 Eyes 68.64% 0.517 Gaze 61.40% 0.432 Mouth Openness 77.97% 0.361 Mouth Lips 82.20% 0.684 Head Movements 55.08% 0.420 Hand Movements 91.53% 0.858 Hand Trajectory 84.75% 0.753 Average 75.00% 0.584 Table 2: Gesture annotation agreement specifically focus on the annotation of facial displays and hand movements, as they have been previously found to correlate with deceptive behavior (Depaulo et al., 2003). The gesture annotation is performed using the MUMIN coding scheme (Allwood et al., 2007). In the MUMIN scheme, facial displays consist of several different facial expressions associated with eyebrows, eyes, gaze, and mouth. Smile, laughter, and scowl are also included, as well as general head and hand movements. The multimodal annotation was performed by two annotators using the Elan software (Wittenburg et al., 2006). We decided to perform the gesture annotations at video level, rather than at utterance level, because the overall judgment of truthfulness and deceitfulness is based on the whole video content. During the annotation process, annotators were allowed to watch each vi</context>
</contexts>
<marker>Allwood, Cerrato, Jokinen, Navarretta, Paggio, 2007</marker>
<rawString>Jens Allwood, Loredana Cerrato, Kristiina Jokinen, Costanza Navarretta, and Patrizia Paggio. 2007. The mumin coding scheme for the annotation of feedback, turn management and sequencing phenomena. Language Resources and Evaluation, 41(3-4):273–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>´Angela Almela</author>
<author>Rafael Valencia-Garcia</author>
<author>Pascual Cantos</author>
</authors>
<title>Seeing through deception: A computational approach to deceit detection in written communication.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Deception Detection,</booktitle>
<pages>15--22</pages>
<location>Avignon, France,</location>
<contexts>
<context position="30471" citStr="Almela et al., 2012" startWordPosition="4901" endWordPosition="4904">Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2012) and showed that the use of psycholinguistic information is helpful for the automatic identification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverbal Deception Detection. Earlier approaches to nonverbal deception detection relied 2343 on polygraph tests to detect deceptive behavior. These tests are mainly based on such physiological featu</context>
</contexts>
<marker>Almela, Valencia-Garcia, Cantos, 2012</marker>
<rawString>´Angela Almela, Rafael Valencia-Garcia, and Pascual Cantos. 2012. Seeing through deception: A computational approach to deceit detection in written communication. In Proceedings of the Workshop on Computational Approaches to Deception Detection, pages 15–22, Avignon, France, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judee K Burgoon</author>
<author>Douglas P Twitchell</author>
<author>Matthew L Jensen</author>
<author>Thomas O Meservy</author>
<author>Mark Adkins</author>
<author>John Kruse</author>
<author>Amit V Deokar</author>
<author>Gabriel Tsechpenakis</author>
<author>Shan Lu</author>
<author>Dimitris N Metaxas</author>
</authors>
<title>Detecting concealment of intent in transportation screening: A proof of concept.</title>
<date>2009</date>
<journal>IEEE Transactions on Intelligent Transportation Systems,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="33197" citStr="Burgoon et al., 2009" startWordPosition="5325" endWordPosition="5328">ng smoothness and asymmetry measurements to further relate them to an act of deceit (Ekman, 2003). Tian et al. (Tian et al., 2005) considered features such as face orientation and facial expression intensity. Owayjan et al. (Owayjan et al., 2012) extracted geometricbased features from facial expressions, and Pfister and Pietikainen (Pfister and Pietik¨ainen, 2012) developed a micro-expression dataset to identify expressions that are clues for deception. Recently, features from different modalities were integrated in order to find a combination of multimodal features with superior performance (Burgoon et al., 2009; Jensen et al., 2010). A multimodal deception dataset consisting of linguistic, thermal, and physiological features was introduced in (P´erezRosas et al., 2014), which was then used to develop a multimodal deception detection system (Abouelenien et al., 2014). An extensive review of approaches for evaluating human credibility using physiological, visual, acoustic, and linguistic features is available in (Nunamaker et al., 2012). 7 Conclusions In this paper we presented a study of multimodal deception detection using real-life occurrences of deceit. We introduced a novel dataset covering recor</context>
</contexts>
<marker>Burgoon, Twitchell, Jensen, Meservy, Adkins, Kruse, Deokar, Tsechpenakis, Lu, Metaxas, 2009</marker>
<rawString>Judee K. Burgoon, Douglas P. Twitchell, Matthew L. Jensen, Thomas O. Meservy, Mark Adkins, John Kruse, Amit V. Deokar, Gabriel Tsechpenakis, Shan Lu, Dimitris N. Metaxas, et al. 2009. Detecting concealment of intent in transportation screening: A proof of concept. IEEE Transactions on Intelligent Transportation Systems, 10(1):103–112, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Letizia Caso</author>
<author>Fridanna Maricchiolo</author>
<author>Marino Bonaiuto</author>
<author>Aldert Vrij</author>
<author>Samantha Mann</author>
</authors>
<title>The impact of deception and suspicion on different hand movements.</title>
<date>2006</date>
<journal>Journal of Nonverbal Behavior,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="31794" citStr="Caso et al., 2006" startWordPosition="5115" endWordPosition="5118">009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical role in the identification of decep</context>
</contexts>
<marker>Caso, Maricchiolo, Bonaiuto, Vrij, Mann, 2006</marker>
<rawString>Letizia Caso, Fridanna Maricchiolo, Marino Bonaiuto, Aldert Vrij, and Samantha Mann. 2006. The impact of deception and suspicion on different hand movements. Journal of Nonverbal Behavior, 30(1):1–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokul Chittaranjan</author>
<author>Hayley Hung</author>
</authors>
<title>Are you awerewolf? detecting deceptive roles and outcomes in a conversational role-playing game.</title>
<date>2010</date>
<booktitle>In 2010 IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP),</booktitle>
<pages>5334--5337</pages>
<contexts>
<context position="31335" citStr="Chittaranjan and Hung, 2010" startWordPosition="5030" endWordPosition="5033"> to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverbal Deception Detection. Earlier approaches to nonverbal deception detection relied 2343 on polygraph tests to detect deceptive behavior. These tests are mainly based on such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) fo</context>
</contexts>
<marker>Chittaranjan, Hung, 2010</marker>
<rawString>Gokul Chittaranjan and Hayley Hung. 2010. Are you awerewolf? detecting deceptive roles and outcomes in a conversational role-playing game. In 2010 IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), pages 5334–5337, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doron Cohen</author>
<author>Geoffrey Beattie</author>
<author>Heather Shovelton</author>
</authors>
<title>Nonverbal indicators of deception: How iconic gestures reveal thoughts that cannot be suppressed.</title>
<date>2010</date>
<journal>Semiotica,</journal>
<volume>2010</volume>
<issue>182</issue>
<contexts>
<context position="31932" citStr="Cohen et al. (2010)" startWordPosition="5137" endWordPosition="5140">ranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical role in the identification of deception. (Ekman, 2001) defined micro-expressions as relatively short involuntary expressions, which can be indicative of deceptive behavior. </context>
</contexts>
<marker>Cohen, Beattie, Shovelton, 2010</marker>
<rawString>Doron Cohen, Geoffrey Beattie, and Heather Shovelton. 2010. Nonverbal indicators of deception: How iconic gestures reveal thoughts that cannot be suppressed. Semiotica, 2010(182):133–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bella Depaulo</author>
<author>Brian Malone</author>
<author>James Lindsay</author>
<author>Laura Muhlenbruck</author>
<author>Kelly Charlton</author>
<author>Harris Cooper</author>
</authors>
<title>Cues to deception. Psychological Bulletin,</title>
<date>2003</date>
<pages>74--118</pages>
<contexts>
<context position="10269" citStr="Depaulo et al., 2003" startWordPosition="1652" endWordPosition="1655">nteraction community, we use the term “gesture” to broadly refer to body movements, including facial expressions and hand gestures. Gesture Category Agreement Kappa Facial Expressions 72.88% 0.576 Eyebrows 80.51% 0.656 Eyes 68.64% 0.517 Gaze 61.40% 0.432 Mouth Openness 77.97% 0.361 Mouth Lips 82.20% 0.684 Head Movements 55.08% 0.420 Hand Movements 91.53% 0.858 Hand Trajectory 84.75% 0.753 Average 75.00% 0.584 Table 2: Gesture annotation agreement specifically focus on the annotation of facial displays and hand movements, as they have been previously found to correlate with deceptive behavior (Depaulo et al., 2003). The gesture annotation is performed using the MUMIN coding scheme (Allwood et al., 2007). In the MUMIN scheme, facial displays consist of several different facial expressions associated with eyebrows, eyes, gaze, and mouth. Smile, laughter, and scowl are also included, as well as general head and hand movements. The multimodal annotation was performed by two annotators using the Elan software (Wittenburg et al., 2006). We decided to perform the gesture annotations at video level, rather than at utterance level, because the overall judgment of truthfulness and deceitfulness is based on the wh</context>
<context position="14964" citStr="Depaulo et al., 2003" startWordPosition="2405" endWordPosition="2408">cis, 1999). It has been successfully used in previous work on deception detection (Newman et al., 2003; Mihalcea and Strapparava, 2009; Ott et al., 2011). We obtain features for each of the 80 psycholinguistic classes present in the lexicon by calculating the percentage of words in the transcription belonging to each class. Syntactic Complexity. We also extract features to measure the syntactic complexity of the speech produced by the speakers in truthful and deceptive clips. This set of features is motivated by previous research that has suggested that deceivers’ speech has lower complexity (Depaulo et al., 2003). We use the tool described in (Lu, 2010), which generates indexes of syntactic complexity, including general complexity metrics, length of production, and amount of coordination. The set of features consists of fourteen indexes including statistics related to T-units, which are linguistic units that include a main clause in addition to attached subordinate clauses. T-unit analysis is extensively used to analyze syntactic complexity in speech and written content. The set of features includes the mean length of sentence, mean length of T2339 Deceptive Truthful 1 0.8 0.6 0.4 0.2 0 Smile Close-R </context>
<context position="18436" citStr="Depaulo et al., 2003" startWordPosition="2955" endWordPosition="2958">s for this feature are 20.33% in the deceptive class, and 49.13% in the truthful class. Figure 2 shows the percentages of all the nonverbal features for which we observe noticeable differences for the deceptive and truthful groups. As the figure suggests, facial displays seem to help differentiate between the deceptive and truthful conditions. For instance, we can observe that truth-tellers smile (Smile) and blink more (Close-R). Interestingly deceivers seem to make more eye contact (Interlocutor gaze) and nod (Side-Turn-R) more frequently than truth-tellers. This agrees with the findings in (Depaulo et al., 2003) that liars who are more motivated to get away with their lies (i.e., trials) are likely to increase their eye-contact behavior. Motivated by these results, we proceed to conduct further experiments to evaluate the performance of the extracted features using a machine learning approach. 2340 Feature Set SVM All 77.11% – Hand gestures 74.57% – Facial displays 64.40% – Syntactic 76.27% – Semantic 72.03% – Unigrams 73.72% Table 5: Feature ablation study. We run our learning experiments on the realdeception dataset introduced earlier. Given the even distribution between deceptive and truthful clip</context>
</contexts>
<marker>Depaulo, Malone, Lindsay, Muhlenbruck, Charlton, Cooper, 2003</marker>
<rawString>Bella Depaulo, Brian Malone, James Lindsay, Laura Muhlenbruck, Kelly Charlton, and Harris Cooper. 2003. Cues to deception. Psychological Bulletin, pages 74–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maarten Derksen</author>
</authors>
<title>Control and resistance in the psychology of lying.</title>
<date>2012</date>
<journal>Theory and Psychology,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="31195" citStr="Derksen, 2012" startWordPosition="5013" endWordPosition="5014">. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverbal Deception Detection. Earlier approaches to nonverbal deception detection relied 2343 on polygraph tests to detect deceptive behavior. These tests are mainly based on such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) </context>
</contexts>
<marker>Derksen, 2012</marker>
<rawString>Maarten Derksen. 2012. Control and resistance in the psychology of lying. Theory and Psychology, 22(2):196–212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>Telling Lies: Clues to Deceit in the Marketplace, Politics</title>
<date>2001</date>
<publisher>and Company.</publisher>
<contexts>
<context position="32413" citStr="Ekman, 2001" startWordPosition="5214" endWordPosition="5215">fied particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical role in the identification of deception. (Ekman, 2001) defined micro-expressions as relatively short involuntary expressions, which can be indicative of deceptive behavior. Moreover, these expressions were analyzed using smoothness and asymmetry measurements to further relate them to an act of deceit (Ekman, 2003). Tian et al. (Tian et al., 2005) considered features such as face orientation and facial expression intensity. Owayjan et al. (Owayjan et al., 2012) extracted geometricbased features from facial expressions, and Pfister and Pietikainen (Pfister and Pietik¨ainen, 2012) developed a micro-expression dataset to identify expressions that are</context>
</contexts>
<marker>Ekman, 2001</marker>
<rawString>Paul Ekman, 2001. Telling Lies: Clues to Deceit in the Marketplace, Politics and Marriage. Norton, W.W. and Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Ritwik Banerjee</author>
<author>Yejin Choi</author>
</authors>
<title>Syntactic stylometry for deception detection.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>171--175</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="2173" citStr="Feng et al., 2012" startWordPosition="320" endWordPosition="323">others. In many of these settings, the polygraph test has been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were shown to be misleading in multiple cases (Vrij, 2001; Gannon et al., 2009), as human judgment is often biased. Given the difficulties associated with the use of polygraph-like methods, learning-based approaches have been proposed to address the deception detection task using a number of modalities, including text (Feng et al., 2012) and speech (Hirschberg et al., 2005; Newman et al., 2003). Unlike the polygraph methods, learning-based methods for deception detection rely mainly on data collected from deceivers and truth-tellers. The data is usually elicited from human contributors, in a lab setting or via crowdsourcing. An important problem identified in this data-driven research is the lack of real data. Because of the artificial setting, the subjects may not be emotionally aroused, as they may not take the experiments seriously given the lack of motivation and/or penalty. In this paper, we describe what we believe is a</context>
<context position="30278" citStr="Feng et al., 2012" startWordPosition="4870" endWordPosition="4873">variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2012) and showed that the use of psycholinguistic information is helpful for the automatic identification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverb</context>
</contexts>
<marker>Feng, Banerjee, Choi, 2012</marker>
<rawString>Song Feng, Ritwik Banerjee, and Yejin Choi. 2012. Syntactic stylometry for deception detection. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 171–175, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Gannon</author>
<author>Anthony Beech</author>
<author>Tony Ward</author>
</authors>
<title>Risk Assessment and the Polygraph,</title>
<date>2009</date>
<pages>129--154</pages>
<publisher>John Wiley and Sons Ltd.</publisher>
<contexts>
<context position="1913" citStr="Gannon et al., 2009" startWordPosition="279" endWordPosition="282">thodologies to detect deception in an efficient, yet reliable manner. There are many applications that can benefit from automatic deception identification, such as airport security screening, crime investigation and interrogation, interviews, advertisement, and others. In many of these settings, the polygraph test has been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were shown to be misleading in multiple cases (Vrij, 2001; Gannon et al., 2009), as human judgment is often biased. Given the difficulties associated with the use of polygraph-like methods, learning-based approaches have been proposed to address the deception detection task using a number of modalities, including text (Feng et al., 2012) and speech (Hirschberg et al., 2005; Newman et al., 2003). Unlike the polygraph methods, learning-based methods for deception detection rely mainly on data collected from deceivers and truth-tellers. The data is usually elicited from human contributors, in a lab setting or via crowdsourcing. An important problem identified in this data-d</context>
<context position="31179" citStr="Gannon et al., 2009" startWordPosition="5009" endWordPosition="5012">ntification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverbal Deception Detection. Earlier approaches to nonverbal deception detection relied 2343 on polygraph tests to detect deceptive behavior. These tests are mainly based on such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Cas</context>
</contexts>
<marker>Gannon, Beech, Ward, 2009</marker>
<rawString>Theresa Gannon, Anthony Beech, and Tony Ward, 2009. Risk Assessment and the Polygraph, pages 129–154. John Wiley and Sons Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosanna E Guadagno</author>
<author>Bradley M Okdie</author>
<author>Sara A Kruse</author>
</authors>
<title>Dating deception: Gender, online dating, and exaggerated self-presentation.</title>
<date>2012</date>
<journal>Comput. Hum. Behav.,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="29761" citStr="Guadagno et al., 2012" startWordPosition="4789" endWordPosition="4792">nce. Overall, our study indicates that detecting deception is indeed a difficult task for humans and further verifies previous findings where human ability to spot liars was found to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system. 6 Related Work Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build de</context>
</contexts>
<marker>Guadagno, Okdie, Kruse, 2012</marker>
<rawString>Rosanna E. Guadagno, Bradley M. Okdie, and Sara A. Kruse. 2012. Dating deception: Gender, online dating, and exaggerated self-presentation. Comput. Hum. Behav., 28(2):642–647, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jackie Hillman</author>
<author>Aldert Vrij</author>
<author>Samantha Mann</author>
</authors>
<title>Um they were wearing : The effect of deception on specific hand gestures.</title>
<date>2012</date>
<journal>Legal and Criminological Psychology,</journal>
<volume>17</volume>
<issue>2</issue>
<contexts>
<context position="32034" citStr="Hillman et al. (2012)" startWordPosition="5155" endWordPosition="5158">to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical role in the identification of deception. (Ekman, 2001) defined micro-expressions as relatively short involuntary expressions, which can be indicative of deceptive behavior. Moreover, these expressions were analyzed using smoothness and asymmetry measurements to further relat</context>
</contexts>
<marker>Hillman, Vrij, Mann, 2012</marker>
<rawString>Jackie Hillman, Aldert Vrij, and Samantha Mann. 2012. Um they were wearing : The effect of deception on specific hand gestures. Legal and Criminological Psychology, 17(2):336–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hirschberg</author>
<author>Stefan Benus</author>
<author>Jason M Brenier</author>
<author>Frank Enos</author>
<author>Sarah Friedman</author>
<author>Sarah Gilman</author>
<author>Cynthia Girand</author>
<author>Martin Graciarena</author>
<author>Andreas Kathol</author>
<author>Laura Michaelis</author>
</authors>
<title>Distinguishing deceptive from non-deceptive speech. In</title>
<date>2005</date>
<booktitle>In Proceedings of Interspeech 2005 - Eurospeech,</booktitle>
<pages>1833--1836</pages>
<contexts>
<context position="2209" citStr="Hirschberg et al., 2005" startWordPosition="326" endWordPosition="329">gs, the polygraph test has been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were shown to be misleading in multiple cases (Vrij, 2001; Gannon et al., 2009), as human judgment is often biased. Given the difficulties associated with the use of polygraph-like methods, learning-based approaches have been proposed to address the deception detection task using a number of modalities, including text (Feng et al., 2012) and speech (Hirschberg et al., 2005; Newman et al., 2003). Unlike the polygraph methods, learning-based methods for deception detection rely mainly on data collected from deceivers and truth-tellers. The data is usually elicited from human contributors, in a lab setting or via crowdsourcing. An important problem identified in this data-driven research is the lack of real data. Because of the artificial setting, the subjects may not be emotionally aroused, as they may not take the experiments seriously given the lack of motivation and/or penalty. In this paper, we describe what we believe is a first attempt at building a multimo</context>
</contexts>
<marker>Hirschberg, Benus, Brenier, Enos, Friedman, Gilman, Girand, Graciarena, Kathol, Michaelis, 2005</marker>
<rawString>Julia Hirschberg, Stefan Benus, Jason M. Brenier, Frank Enos, Sarah Friedman, Sarah Gilman, Cynthia Girand, Martin Graciarena, Andreas Kathol, Laura Michaelis, et al. 2005. Distinguishing deceptive from non-deceptive speech. In In Proceedings of Interspeech 2005 - Eurospeech, pages 1833–1836.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuyuan Mary Ho</author>
<author>Jonathan M Hollister</author>
</authors>
<title>Guess who? an empirical study of gender deception and detection in computer-mediated communication.</title>
<date>2013</date>
<booktitle>Proceedings of the American Society for Information Science and Technology,</booktitle>
<pages>50--1</pages>
<contexts>
<context position="29867" citStr="Ho and Hollister, 2013" startWordPosition="4805" endWordPosition="4808">her verifies previous findings where human ability to spot liars was found to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system. 6 Related Work Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2</context>
</contexts>
<marker>Ho, Hollister, 2013</marker>
<rawString>Shuyuan Mary Ho and Jonathan M Hollister. 2013. Guess who? an empirical study of gender deception and detection in computer-mediated communication. Proceedings of the American Society for Information Science and Technology, 50(1):1–4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Jensen</author>
<author>Thomas Meservy</author>
<author>Judee Burgoon</author>
<author>Jay Nunamaker</author>
</authors>
<title>Automatic, multimodal evaluation of human interaction. Group Decision and Negotiation,</title>
<date>2010</date>
<contexts>
<context position="33219" citStr="Jensen et al., 2010" startWordPosition="5329" endWordPosition="5332">metry measurements to further relate them to an act of deceit (Ekman, 2003). Tian et al. (Tian et al., 2005) considered features such as face orientation and facial expression intensity. Owayjan et al. (Owayjan et al., 2012) extracted geometricbased features from facial expressions, and Pfister and Pietikainen (Pfister and Pietik¨ainen, 2012) developed a micro-expression dataset to identify expressions that are clues for deception. Recently, features from different modalities were integrated in order to find a combination of multimodal features with superior performance (Burgoon et al., 2009; Jensen et al., 2010). A multimodal deception dataset consisting of linguistic, thermal, and physiological features was introduced in (P´erezRosas et al., 2014), which was then used to develop a multimodal deception detection system (Abouelenien et al., 2014). An extensive review of approaches for evaluating human credibility using physiological, visual, acoustic, and linguistic features is available in (Nunamaker et al., 2012). 7 Conclusions In this paper we presented a study of multimodal deception detection using real-life occurrences of deceit. We introduced a novel dataset covering recordings from public real</context>
</contexts>
<marker>Jensen, Meservy, Burgoon, Nunamaker, 2010</marker>
<rawString>Matthew Jensen, Thomas Meservy, Judee Burgoon, and Jay Nunamaker. 2010. Automatic, multimodal evaluation of human interaction. Group Decision and Negotiation, 19(4):367–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam N Joinson</author>
<author>Beth Dietz-Uhler</author>
</authors>
<title>Explanations for the perpetration of and reactions to deception in a virtual community.</title>
<date>2002</date>
<journal>Social Science Computer Review,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="29825" citStr="Joinson and Dietz-Uhler, 2002" startWordPosition="4798" endWordPosition="4801">on is indeed a difficult task for humans and further verifies previous findings where human ability to spot liars was found to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system. 6 Related Work Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and S</context>
</contexts>
<marker>Joinson, Dietz-Uhler, 2002</marker>
<rawString>Adam N. Joinson and Beth Dietz-Uhler. 2002. Explanations for the perpetration of and reactions to deception in a virtual community. Social Science Computer Review, 20(3):275–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Eduard Hovy</author>
</authors>
<title>Towards a general rule for identifying deceptive opinion spam.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="29933" citStr="Li et al., 2014" startWordPosition="4818" endWordPosition="4821">d to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system. 6 Related Work Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2012) and showed that the use of psycholinguistic information is he</context>
</contexts>
<marker>Li, Ott, Cardie, Hovy, 2014</marker>
<rawString>Jiwei Li, Myle Ott, Claire Cardie, and Eduard Hovy. 2014. Towards a general rule for identifying deceptive opinion spam. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, Baltimore, Maryland, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shan Lu</author>
<author>Gabriel Tsechpenakis</author>
<author>Dimitris Metaxas</author>
<author>Matthew Jensen</author>
<author>John Kruse</author>
</authors>
<title>Blob analysis of the head and hands: A method for deception detection.</title>
<date>2005</date>
<booktitle>In Proceedings of the 38th Annual Hawaii International Conference on System Sciences (HICSS’05), HICSS ’05,</booktitle>
<pages>20--29</pages>
<location>Washington, DC, USA.</location>
<contexts>
<context position="31645" citStr="Lu et al., 2005" startWordPosition="5087" endWordPosition="5090"> mainly based on such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures</context>
</contexts>
<marker>Lu, Tsechpenakis, Metaxas, Jensen, Kruse, 2005</marker>
<rawString>Shan Lu, Gabriel Tsechpenakis, Dimitris Metaxas, Matthew Jensen, and John Kruse. 2005. Blob analysis of the head and hands: A method for deception detection. In Proceedings of the 38th Annual Hawaii International Conference on System Sciences (HICSS’05), HICSS ’05, pages 20–29, Washington, DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofei Lu</author>
</authors>
<title>Automatic analysis of syntactic complexity in second language writing.</title>
<date>2010</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>15</volume>
<issue>4</issue>
<pages>496</pages>
<contexts>
<context position="15005" citStr="Lu, 2010" startWordPosition="2415" endWordPosition="2416"> work on deception detection (Newman et al., 2003; Mihalcea and Strapparava, 2009; Ott et al., 2011). We obtain features for each of the 80 psycholinguistic classes present in the lexicon by calculating the percentage of words in the transcription belonging to each class. Syntactic Complexity. We also extract features to measure the syntactic complexity of the speech produced by the speakers in truthful and deceptive clips. This set of features is motivated by previous research that has suggested that deceivers’ speech has lower complexity (Depaulo et al., 2003). We use the tool described in (Lu, 2010), which generates indexes of syntactic complexity, including general complexity metrics, length of production, and amount of coordination. The set of features consists of fourteen indexes including statistics related to T-units, which are linguistic units that include a main clause in addition to attached subordinate clauses. T-unit analysis is extensively used to analyze syntactic complexity in speech and written content. The set of features includes the mean length of sentence, mean length of T2339 Deceptive Truthful 1 0.8 0.6 0.4 0.2 0 Smile Close-R Side-Turn-R Raise Interlocutor Side Open-</context>
</contexts>
<marker>Lu, 2010</marker>
<rawString>Xiaofei Lu. 2010. Automatic analysis of syntactic complexity in second language writing. International Journal of Corpus Linguistics, 15(4):474– 496.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fridanna Maricchiolo</author>
</authors>
<title>Augusto Gnisci, and Marino Bonaiuto. In</title>
<booktitle>Cognitive Behavioural Systems,</booktitle>
<pages>405--416</pages>
<editor>Anna Esposito, AntoniettaM. Esposito, Alessandro Vinciarelli, Rdiger Hoffmann, and VincentC. Mller, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Maricchiolo, </marker>
<rawString>Fridanna Maricchiolo, Augusto Gnisci, and Marino Bonaiuto. In Anna Esposito, AntoniettaM. Esposito, Alessandro Vinciarelli, Rdiger Hoffmann, and VincentC. Mller, editors, Cognitive Behavioural Systems, pages 405–416. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Meservy</author>
<author>Matthew Jensen</author>
<author>John Kruse</author>
<author>Douglas Twitchell</author>
<author>Gabriel Tsechpenakis</author>
<author>Judee Burgoon</author>
<author>Dimitris Metaxas</author>
<author>Jay Nunamaker</author>
</authors>
<title>Deception detection through automatic, unobtrusive analysis of nonverbal behavior.</title>
<date>2005</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="31761" citStr="Meservy et al., 2005" startWordPosition="5108" endWordPosition="5111">tudies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical ro</context>
</contexts>
<marker>Meservy, Jensen, Kruse, Twitchell, Tsechpenakis, Burgoon, Metaxas, Nunamaker, 2005</marker>
<rawString>Thomas Meservy, Matthew Jensen, John Kruse, Douglas Twitchell, Gabriel Tsechpenakis, Judee Burgoon, Dimitris Metaxas, and Jay Nunamaker. 2005. Deception detection through automatic, unobtrusive analysis of nonverbal behavior. IEEE Intelligent Systems, 20(5):36–43, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela Meyer</author>
</authors>
<title>Liespotting: Proven Techniques to Detect Deception.</title>
<date>2010</date>
<publisher>St. Martin’s.</publisher>
<location>New York:</location>
<contexts>
<context position="1238" citStr="Meyer, 2010" startWordPosition="180" endWordPosition="181">ing real-world evidence. In this paper, we explore the use of multimodal real-life data for the task of deception detection. We develop a new deception dataset consisting of videos from reallife scenarios, and build deception tools relying on verbal and nonverbal features. We achieve classification accuracies in the range of 77-82% when using a model that extracts and fuses features from the linguistic and visual modalities. We show that these results outperform the human capability of identifying deceit. 1 Introduction As deceptive behavior occurs on a daily basis in different areas of life (Meyer, 2010; Smith et al., 2014), the need arises for automated methodologies to detect deception in an efficient, yet reliable manner. There are many applications that can benefit from automatic deception identification, such as airport security screening, crime investigation and interrogation, interviews, advertisement, and others. In many of these settings, the polygraph test has been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were</context>
</contexts>
<marker>Meyer, 2010</marker>
<rawString>Pamela Meyer. 2010. Liespotting: Proven Techniques to Detect Deception. New York: St. Martin’s.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Stephen Pulman</author>
</authors>
<title>Linguistic ethnography: Identifying dominant word classes in text.</title>
<date>2009</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>594--602</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="21609" citStr="Mihalcea and Pulman, 2009" startWordPosition="3458" endWordPosition="3461">alyzed the absolute values of the weights assigned by the learning algorithm to the features in this group. Figure 3 shows the features normalized with respect to the largest feature weight. The five most predictive features are the presence of side turns, up gazes, blinking, and smiling, which we previously identified as possible indicators of deception. This further confirms our initial hypothesis that gestures associated with human interaction are an important component of human deception. We also analyze the contribution of the linguistic features. Using the linguistic ethnography method (Mihalcea and Pulman, 2009), we obtain the most dominant LIWC word classes associated with deceptive and truthful transcripts extracted from trials and interviews clips. Results are shown in Table 6. Interestingly, the most dominant classes in truthful clips, regardless of being from interviews or trials, correspond to words related to Family, Home, and Humans. This suggests that truth-tellers show similar word usage when interviewed on a real scenario. On the other hand, dominant classes associated to deceivers are less consistent as they discuss aspects related to the topic being discussed. For instance, while being i</context>
</contexts>
<marker>Mihalcea, Pulman, 2009</marker>
<rawString>Rada Mihalcea and Stephen Pulman. 2009. Linguistic ethnography: Identifying dominant word classes in text. In Computational Linguistics and Intelligent Text Processing, pages 594–602. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carlo Strapparava</author>
</authors>
<title>The lie detector: Explorations in the automatic recognition of deceptive language.</title>
<date>2009</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL 2009), Singapore. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="14477" citStr="Mihalcea and Strapparava, 2009" startWordPosition="2328" endWordPosition="2331">rams, psycholinguistic features, and syntactic complexity features. Unigrams. We extract unigrams derived from the bag-of-words representation of the video transcripts. The unigram features are encoded as word frequencies and include all the words present in the transcripts. Psycholinguistic Features. The Linguistic Word Count (LIWC) is a psycholinguistics lexicon that has been frequently used to incorporate semantic and psychological information into linguistic analysis (Pennebaker and Francis, 1999). It has been successfully used in previous work on deception detection (Newman et al., 2003; Mihalcea and Strapparava, 2009; Ott et al., 2011). We obtain features for each of the 80 psycholinguistic classes present in the lexicon by calculating the percentage of words in the transcription belonging to each class. Syntactic Complexity. We also extract features to measure the syntactic complexity of the speech produced by the speakers in truthful and deceptive clips. This set of features is motivated by previous research that has suggested that deceivers’ speech has lower complexity (Depaulo et al., 2003). We use the tool described in (Lu, 2010), which generates indexes of syntactic complexity, including general com</context>
<context position="23162" citStr="Mihalcea and Strapparava, 2009" startWordPosition="3714" endWordPosition="3717">en mouth Single hand Closing both eyes Raising eyebrows Side Tilt 2341 Truthful Interviews Trials Class Score Class Score Metaphor 2.98 You 3.99 Money 2.74 Family 3.07 Inhibition 2.74 Home 2.45 Home 2.13 Humans 1.87 Humans 2.02 Posemo 1.81 Family 1.96 Insight 1.64 Deceptive Interviews Trials Class Score Class Score Assent 4.81 Anger 2.61 Past 2.59 Anxiety 2.61 Sexual 2.00 Certain 2.28 Other 1.87 Death 1.96 Motion 1.68 Physical 1.77 Negemo 1.44 Negemo 1.52 Table 6: LIWC word classes most strongly associated with deception and truth. tion words (class Negemo). In line with earlier observations (Mihalcea and Strapparava, 2009), deceptive texts include more words that reflect certainty (class Certain, with words such as completely, truly, always) and more references to others (class Other, with words such as she, day, him). 4.2 Domain Experiments We perform three sets of experiments to determine the role played by the domain. The first set of experiments uses only the Interviews video clips (62 in total), and the results are shown in the left column of Table 7. The second set uses only the Trials instances (56 in total), with results shown in the right column of Table 7. Finally, we also perform cross-domain experim</context>
<context position="30159" citStr="Mihalcea and Strapparava, 2009" startWordPosition="4848" endWordPosition="4852">o date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2012) and showed that the use of psycholinguistic information is helpful for the automatic identification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researche</context>
</contexts>
<marker>Mihalcea, Strapparava, 2009</marker>
<rawString>Rada Mihalcea and Carlo Strapparava. 2009. The lie detector: Explorations in the automatic recognition of deceptive language. In Proceedings of the Association for Computational Linguistics (ACL 2009), Singapore. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew L Newman</author>
<author>James W Pennebaker</author>
<author>Diane S Berry</author>
<author>Jane M Richards</author>
</authors>
<title>Lying words: Predicting deception from linguistic styles.</title>
<date>2003</date>
<journal>Personality and Social Psychology Bulletin,</journal>
<volume>29</volume>
<contexts>
<context position="2231" citStr="Newman et al., 2003" startWordPosition="330" endWordPosition="333">s been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were shown to be misleading in multiple cases (Vrij, 2001; Gannon et al., 2009), as human judgment is often biased. Given the difficulties associated with the use of polygraph-like methods, learning-based approaches have been proposed to address the deception detection task using a number of modalities, including text (Feng et al., 2012) and speech (Hirschberg et al., 2005; Newman et al., 2003). Unlike the polygraph methods, learning-based methods for deception detection rely mainly on data collected from deceivers and truth-tellers. The data is usually elicited from human contributors, in a lab setting or via crowdsourcing. An important problem identified in this data-driven research is the lack of real data. Because of the artificial setting, the subjects may not be emotionally aroused, as they may not take the experiments seriously given the lack of motivation and/or penalty. In this paper, we describe what we believe is a first attempt at building a multimodal system that detect</context>
<context position="14445" citStr="Newman et al., 2003" startWordPosition="2324" endWordPosition="2327">s, consisting of unigrams, psycholinguistic features, and syntactic complexity features. Unigrams. We extract unigrams derived from the bag-of-words representation of the video transcripts. The unigram features are encoded as word frequencies and include all the words present in the transcripts. Psycholinguistic Features. The Linguistic Word Count (LIWC) is a psycholinguistics lexicon that has been frequently used to incorporate semantic and psychological information into linguistic analysis (Pennebaker and Francis, 1999). It has been successfully used in previous work on deception detection (Newman et al., 2003; Mihalcea and Strapparava, 2009; Ott et al., 2011). We obtain features for each of the 80 psycholinguistic classes present in the lexicon by calculating the percentage of words in the transcription belonging to each class. Syntactic Complexity. We also extract features to measure the syntactic complexity of the speech produced by the speakers in truthful and deceptive clips. This set of features is motivated by previous research that has suggested that deceivers’ speech has lower complexity (Depaulo et al., 2003). We use the tool described in (Lu, 2010), which generates indexes of syntactic c</context>
</contexts>
<marker>Newman, Pennebaker, Berry, Richards, 2003</marker>
<rawString>Matthew L. Newman, James W. Pennebaker, Diane S. Berry, and Jane M. Richards. 2003. Lying words: Predicting deception from linguistic styles. Personality and Social Psychology Bulletin, 29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay F Nunamaker</author>
<author>Judee K Burgoon</author>
<author>Nathan W Twyman</author>
<author>Jeffrey Gainer Proudfoot</author>
<author>Ryan M Schuetzler</author>
<author>Justin Scott Giboney</author>
</authors>
<title>Establishing a foundation for automated human credibility screening.</title>
<date>2012</date>
<booktitle>In 2012 IEEE International Conference on Intelligence and Security Informatics (ISI),</booktitle>
<pages>202--211</pages>
<contexts>
<context position="33629" citStr="Nunamaker et al., 2012" startWordPosition="5389" endWordPosition="5392">hat are clues for deception. Recently, features from different modalities were integrated in order to find a combination of multimodal features with superior performance (Burgoon et al., 2009; Jensen et al., 2010). A multimodal deception dataset consisting of linguistic, thermal, and physiological features was introduced in (P´erezRosas et al., 2014), which was then used to develop a multimodal deception detection system (Abouelenien et al., 2014). An extensive review of approaches for evaluating human credibility using physiological, visual, acoustic, and linguistic features is available in (Nunamaker et al., 2012). 7 Conclusions In this paper we presented a study of multimodal deception detection using real-life occurrences of deceit. We introduced a novel dataset covering recordings from public real trials and street interviews, and used this dataset to perform both qualitative and quantitative experiments. Our analysis of nonverbal behaviors occurring in deceptive and truthful videos brought insight into the gestures that play a role in deception. We also built classifiers relying on individual or combined sets of verbal and nonverbal features, and showed that we can achieve accuracies in the range o</context>
</contexts>
<marker>Nunamaker, Burgoon, Twyman, Proudfoot, Schuetzler, Giboney, 2012</marker>
<rawString>Jay F. Nunamaker, Judee K. Burgoon, Nathan W. Twyman, Jeffrey Gainer Proudfoot, Ryan M. Schuetzler, and Justin Scott Giboney. 2012. Establishing a foundation for automated human credibility screening. In 2012 IEEE International Conference on Intelligence and Security Informatics (ISI), pages 202–211, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myle Ott</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Jeffrey Hancock</author>
</authors>
<title>Finding deceptive opinion spam by any stretch of the imagination.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>309--319</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="14496" citStr="Ott et al., 2011" startWordPosition="2332" endWordPosition="2335"> and syntactic complexity features. Unigrams. We extract unigrams derived from the bag-of-words representation of the video transcripts. The unigram features are encoded as word frequencies and include all the words present in the transcripts. Psycholinguistic Features. The Linguistic Word Count (LIWC) is a psycholinguistics lexicon that has been frequently used to incorporate semantic and psychological information into linguistic analysis (Pennebaker and Francis, 1999). It has been successfully used in previous work on deception detection (Newman et al., 2003; Mihalcea and Strapparava, 2009; Ott et al., 2011). We obtain features for each of the 80 psycholinguistic classes present in the lexicon by calculating the percentage of words in the transcription belonging to each class. Syntactic Complexity. We also extract features to measure the syntactic complexity of the speech produced by the speakers in truthful and deceptive clips. This set of features is motivated by previous research that has suggested that deceivers’ speech has lower complexity (Depaulo et al., 2003). We use the tool described in (Lu, 2010), which generates indexes of syntactic complexity, including general complexity metrics, le</context>
<context position="28478" citStr="Ott et al., 2011" startWordPosition="4594" endWordPosition="4597"> place indicated however that this was not the case. Three annotators labeled all the 118 video clips in the dataset. Since four modalities were extracted from each video, each annotator annotated a total of 412 instances. Annotators were not offered a monetary reward and we considered their judgments to be honest as they participated voluntarily in this experiment. Table 9 shows the observed agreement and Kappa statistics among the three annotators for each modality.3 The agreement for most modalities is rather low and the Kappa scores range between slight to fair agreement. As noted before (Ott et al., 2011), this low 3Inter-rater agreement with multiple raters and variables. https://mlnl.net/jg/software/ira/ agreement can be interpreted as an indication that people are poor judges of deception. We also determine each annotator’s performance for each modality. The results, shown in Table 10, additionally support the argument that human judges have difficulty performing the deception detection task. An interesting, yet perhaps unsurprising observation is that the human performance increases with the availability of modalities. The poorest accuracy is obtained in Silent video, followed by Text, Aud</context>
<context position="29915" citStr="Ott et al., 2011" startWordPosition="4814" endWordPosition="4817">pot liars was found to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system. 6 Related Work Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2012) and showed that the use of psycholinguistic</context>
</contexts>
<marker>Ott, Choi, Cardie, Hancock, 2011</marker>
<rawString>Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey Hancock. 2011. Finding deceptive opinion spam by any stretch of the imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 309–319, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Owayjan</author>
<author>Ahmad Kashour</author>
<author>Nancy Al Haddad</author>
<author>Maurice Fadel</author>
<author>Ghinwa Al Souki</author>
</authors>
<title>The design and development of a lie detection system using facial micro-expressions.</title>
<date>2012</date>
<booktitle>In 2012 2nd International Conference on Advances in Computational Tools for Engineering Applications (ACTEA),</booktitle>
<pages>33--38</pages>
<contexts>
<context position="32823" citStr="Owayjan et al., 2012" startWordPosition="5273" endWordPosition="5276">so related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical role in the identification of deception. (Ekman, 2001) defined micro-expressions as relatively short involuntary expressions, which can be indicative of deceptive behavior. Moreover, these expressions were analyzed using smoothness and asymmetry measurements to further relate them to an act of deceit (Ekman, 2003). Tian et al. (Tian et al., 2005) considered features such as face orientation and facial expression intensity. Owayjan et al. (Owayjan et al., 2012) extracted geometricbased features from facial expressions, and Pfister and Pietikainen (Pfister and Pietik¨ainen, 2012) developed a micro-expression dataset to identify expressions that are clues for deception. Recently, features from different modalities were integrated in order to find a combination of multimodal features with superior performance (Burgoon et al., 2009; Jensen et al., 2010). A multimodal deception dataset consisting of linguistic, thermal, and physiological features was introduced in (P´erezRosas et al., 2014), which was then used to develop a multimodal deception detection</context>
</contexts>
<marker>Owayjan, Kashour, Haddad, Fadel, Souki, 2012</marker>
<rawString>Michel Owayjan, Ahmad Kashour, Nancy Al Haddad, Maurice Fadel, and Ghinwa Al Souki. 2012. The design and development of a lie detection system using facial micro-expressions. In 2012 2nd International Conference on Advances in Computational Tools for Engineering Applications (ACTEA), pages 33–38, Dec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Martha E Francis</author>
</authors>
<title>Linguistic inquiry and word count: LIWC.</title>
<date>1999</date>
<publisher>Erlbaum Publishers.</publisher>
<contexts>
<context position="14353" citStr="Pennebaker and Francis, 1999" startWordPosition="2308" endWordPosition="2311">hen be used to build classifiers of deception. 3.1 Verbal Features We implement three types of features, consisting of unigrams, psycholinguistic features, and syntactic complexity features. Unigrams. We extract unigrams derived from the bag-of-words representation of the video transcripts. The unigram features are encoded as word frequencies and include all the words present in the transcripts. Psycholinguistic Features. The Linguistic Word Count (LIWC) is a psycholinguistics lexicon that has been frequently used to incorporate semantic and psychological information into linguistic analysis (Pennebaker and Francis, 1999). It has been successfully used in previous work on deception detection (Newman et al., 2003; Mihalcea and Strapparava, 2009; Ott et al., 2011). We obtain features for each of the 80 psycholinguistic classes present in the lexicon by calculating the percentage of words in the transcription belonging to each class. Syntactic Complexity. We also extract features to measure the syntactic complexity of the speech produced by the speakers in truthful and deceptive clips. This set of features is motivated by previous research that has suggested that deceivers’ speech has lower complexity (Depaulo et</context>
</contexts>
<marker>Pennebaker, Francis, 1999</marker>
<rawString>James W. Pennebaker and Martha E. Francis. 1999. Linguistic inquiry and word count: LIWC. Erlbaum Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ver´onica P´erez-Rosas</author>
<author>Rada Mihalcea</author>
<author>Alexis Narvaez</author>
<author>Mihai Burzo</author>
</authors>
<title>A multimodal dataset for deception detection.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014),</booktitle>
<pages>3118--3122</pages>
<location>Reykjavik, Iceland,</location>
<marker>P´erez-Rosas, Mihalcea, Narvaez, Burzo, 2014</marker>
<rawString>Ver´onica P´erez-Rosas, Rada Mihalcea, Alexis Narvaez, and Mihai Burzo. 2014. A multimodal dataset for deception detection. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014), Reykjavik, Iceland, May 26-31, 2014., pages 3118–3122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Pfister</author>
<author>Matti Pietik¨ainen</author>
</authors>
<title>Electronic imaging &amp; signal processing automatic identification of facial clues to lies. SPIE Newsroom,</title>
<date>2012</date>
<marker>Pfister, Pietik¨ainen, 2012</marker>
<rawString>Tomas Pfister and Matti Pietik¨ainen. 2012. Electronic imaging &amp; signal processing automatic identification of facial clues to lies. SPIE Newsroom, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Madeline Smith</author>
<author>Jeffrey Hancock</author>
<author>Lindsay Reynolds</author>
<author>Jeremy Birnholtz</author>
</authors>
<title>Everyday deception or a few prolific liars? the prevalence of lies in text messaging.</title>
<date>2014</date>
<journal>Computers in Human Behavior,</journal>
<volume>41</volume>
<issue>0</issue>
<contexts>
<context position="1259" citStr="Smith et al., 2014" startWordPosition="182" endWordPosition="185">d evidence. In this paper, we explore the use of multimodal real-life data for the task of deception detection. We develop a new deception dataset consisting of videos from reallife scenarios, and build deception tools relying on verbal and nonverbal features. We achieve classification accuracies in the range of 77-82% when using a model that extracts and fuses features from the linguistic and visual modalities. We show that these results outperform the human capability of identifying deceit. 1 Introduction As deceptive behavior occurs on a daily basis in different areas of life (Meyer, 2010; Smith et al., 2014), the need arises for automated methodologies to detect deception in an efficient, yet reliable manner. There are many applications that can benefit from automatic deception identification, such as airport security screening, crime investigation and interrogation, interviews, advertisement, and others. In many of these settings, the polygraph test has been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were shown to be misleadi</context>
</contexts>
<marker>Smith, Hancock, Reynolds, Birnholtz, 2014</marker>
<rawString>Madeline Smith, Jeffrey Hancock, Lindsay Reynolds, and Jeremy Birnholtz. 2014. Everyday deception or a few prolific liars? the prevalence of lies in text messaging. Computers in Human Behavior, 41(0):220–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying-Li Tian</author>
<author>Takeo Kanade</author>
<author>Jeffrey F Cohn</author>
</authors>
<title>Facial expression analysis.</title>
<date>2005</date>
<booktitle>In Handbook of Face Recognition,</booktitle>
<pages>247--275</pages>
<publisher>Springer</publisher>
<location>New York.</location>
<contexts>
<context position="32707" citStr="Tian et al., 2005" startWordPosition="5255" endWordPosition="5258">re associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical role in the identification of deception. (Ekman, 2001) defined micro-expressions as relatively short involuntary expressions, which can be indicative of deceptive behavior. Moreover, these expressions were analyzed using smoothness and asymmetry measurements to further relate them to an act of deceit (Ekman, 2003). Tian et al. (Tian et al., 2005) considered features such as face orientation and facial expression intensity. Owayjan et al. (Owayjan et al., 2012) extracted geometricbased features from facial expressions, and Pfister and Pietikainen (Pfister and Pietik¨ainen, 2012) developed a micro-expression dataset to identify expressions that are clues for deception. Recently, features from different modalities were integrated in order to find a combination of multimodal features with superior performance (Burgoon et al., 2009; Jensen et al., 2010). A multimodal deception dataset consisting of linguistic, thermal, and physiological fe</context>
</contexts>
<marker>Tian, Kanade, Cohn, 2005</marker>
<rawString>Ying-Li Tian, Takeo Kanade, and Jeffrey F. Cohn. 2005. Facial expression analysis. In Handbook of Face Recognition, pages 247–275. Springer New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catalina L Toma</author>
<author>Jeffrey T Hancock</author>
</authors>
<title>Reading between the lines: linguistic cues to deception in online dating profiles.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 ACM conference on Computer supported cooperative work, CSCW ’10,</booktitle>
<pages>5--8</pages>
<contexts>
<context position="29737" citStr="Toma and Hancock, 2010" startWordPosition="4785" endWordPosition="4788">ave the highest performance. Overall, our study indicates that detecting deception is indeed a difficult task for humans and further verifies previous findings where human ability to spot liars was found to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system. 6 Related Work Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the </context>
</contexts>
<marker>Toma, Hancock, 2010</marker>
<rawString>Catalina L. Toma and Jeffrey T. Hancock. 2010. Reading between the lines: linguistic cues to deception in online dating profiles. In Proceedings of the 2010 ACM conference on Computer supported cooperative work, CSCW ’10, pages 5–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Tsechpenakis</author>
<author>Dimitris Metaxas</author>
<author>Mark Adkins</author>
<author>John Kruse</author>
<author>Judee K Burgoon</author>
<author>Matthew L Jensen</author>
<author>Thomas Meservy</author>
<author>Douglas P Twitchell</author>
<author>Amit Deokar</author>
<author>Jay F Nunamaker</author>
</authors>
<title>Hmmbased deception recognition from visual cues.</title>
<date>2005</date>
<booktitle>In IEEE International Conference on Multimedia and Expo,</booktitle>
<pages>824--827</pages>
<contexts>
<context position="31673" citStr="Tsechpenakis et al., 2005" startWordPosition="5091" endWordPosition="5094">such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo e</context>
</contexts>
<marker>Tsechpenakis, Metaxas, Adkins, Kruse, Burgoon, Jensen, Meservy, Twitchell, Deokar, Nunamaker, 2005</marker>
<rawString>Gabriel Tsechpenakis, Dimitris Metaxas, Mark Adkins, John Kruse, Judee K. Burgoon, Matthew L. Jensen, Thomas Meservy, Douglas P. Twitchell, Amit Deokar, and Jay F. Nunamaker. 2005. Hmmbased deception recognition from visual cues. In IEEE International Conference on Multimedia and Expo, 2005. ICME 2005, pages 824–827, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aldert Vrij</author>
</authors>
<title>Detecting Lies and Deceit: The Psychology of Lying and the Implications for Professional Practice. Wiley series in the psychology of crime, policing and law.</title>
<date>2001</date>
<publisher>Wiley.</publisher>
<contexts>
<context position="1891" citStr="Vrij, 2001" startWordPosition="277" endWordPosition="278">automated methodologies to detect deception in an efficient, yet reliable manner. There are many applications that can benefit from automatic deception identification, such as airport security screening, crime investigation and interrogation, interviews, advertisement, and others. In many of these settings, the polygraph test has been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were shown to be misleading in multiple cases (Vrij, 2001; Gannon et al., 2009), as human judgment is often biased. Given the difficulties associated with the use of polygraph-like methods, learning-based approaches have been proposed to address the deception detection task using a number of modalities, including text (Feng et al., 2012) and speech (Hirschberg et al., 2005; Newman et al., 2003). Unlike the polygraph methods, learning-based methods for deception detection rely mainly on data collected from deceivers and truth-tellers. The data is usually elicited from human contributors, in a lab setting or via crowdsourcing. An important problem ide</context>
<context position="31158" citStr="Vrij, 2001" startWordPosition="5007" endWordPosition="5008">utomatic identification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverbal Deception Detection. Earlier approaches to nonverbal deception detection relied 2343 on polygraph tests to detect deceptive behavior. These tests are mainly based on such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 20</context>
</contexts>
<marker>Vrij, 2001</marker>
<rawString>Aldert Vrij. 2001. Detecting Lies and Deceit: The Psychology of Lying and the Implications for Professional Practice. Wiley series in the psychology of crime, policing and law. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darcy Warkentin</author>
<author>Michael Woodworth</author>
<author>Jeffrey T Hancock</author>
<author>Nicole Cormier</author>
</authors>
<title>Warrants and deception in computer mediated communication.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 ACM conference on Computer supported cooperative work,</booktitle>
<pages>9--12</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="29793" citStr="Warkentin et al., 2010" startWordPosition="4794" endWordPosition="4797">s that detecting deception is indeed a difficult task for humans and further verifies previous findings where human ability to spot liars was found to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system. 6 Related Work Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine lea</context>
</contexts>
<marker>Warkentin, Woodworth, Hancock, Cormier, 2010</marker>
<rawString>Darcy Warkentin, Michael Woodworth, Jeffrey T Hancock, and Nicole Cormier. 2010. Warrants and deception in computer mediated communication. In Proceedings of the 2010 ACM conference on Computer supported cooperative work, pages 9–12. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Wittenburg</author>
<author>Hennie Brugman</author>
<author>Albert Russel</author>
<author>Alex Klassmann</author>
<author>Han Sloetjes</author>
</authors>
<title>Elan: a professional framework for multimodality research.</title>
<date>2006</date>
<booktitle>In Language Resources and Evaluation,</booktitle>
<volume>volume</volume>
<contexts>
<context position="9163" citStr="Wittenburg et al., 2006" startWordPosition="1478" endWordPosition="1481">d 21.54 seconds for the deceptive clips. Collected trial samples cover famous murder cases, while street interviews cover several topics such as movies, music, politics, and religion. The dataset contains 23 unique female and 39 unique male speakers, with their ages ranging approximately between 16 and 60 years. 2.2 Transcriptions and Nonverbal Behavior Annotations Our goal is to analyze both verbal and nonverbal behavior to understand their relation to deception. First, all the video clips were manually transcribed. The transcription was performed by two transcribers using the Elan software (Wittenburg et al., 2006). We asked transcribers to include word repetitions and fillers such as um, ah, and uh, as well as long pauses that were marked using three consecutive dots. The final set of transcriptions contain 7835 words, with an average of 66 words per transcript. Table 1 shows transcriptions of sample deceptive and truthful statements from both trials and reality shows. Second, we annotate the gestures1 observed during the interactions in the video clips. We 1As done in the Human-Computer Interaction community, we use the term “gesture” to broadly refer to body movements, including facial expressions an</context>
<context position="10692" citStr="Wittenburg et al., 2006" startWordPosition="1716" endWordPosition="1720">: Gesture annotation agreement specifically focus on the annotation of facial displays and hand movements, as they have been previously found to correlate with deceptive behavior (Depaulo et al., 2003). The gesture annotation is performed using the MUMIN coding scheme (Allwood et al., 2007). In the MUMIN scheme, facial displays consist of several different facial expressions associated with eyebrows, eyes, gaze, and mouth. Smile, laughter, and scowl are also included, as well as general head and hand movements. The multimodal annotation was performed by two annotators using the Elan software (Wittenburg et al., 2006). We decided to perform the gesture annotations at video level, rather than at utterance level, because the overall judgment of truthfulness and deceitfulness is based on the whole video content. During the annotation process, annotators were allowed to watch each video clip as many times as they needed. They were asked to identify the facial displays and hand gestures that were most frequently observed or dominating during the entire clip duration. For each video clip, the annotators had to choose one label for each of the nine gestures listed in Table 3. Table 3 shows the frequency counts as</context>
</contexts>
<marker>Wittenburg, Brugman, Russel, Klassmann, Sloetjes, 2006</marker>
<rawString>Peter Wittenburg, Hennie Brugman, Albert Russel, Alex Klassmann, and Han Sloetjes. 2006. Elan: a professional framework for multimodality research. In Language Resources and Evaluation, volume 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiongkai Xu</author>
<author>Hai Zhao</author>
</authors>
<title>Using deep linguistic features for finding deceptive opinion spam.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012: Posters,</booktitle>
<location>Mumbai, India,</location>
<contexts>
<context position="30298" citStr="Xu and Zhao, 2012" startWordPosition="4874" endWordPosition="4877"> including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2012) and showed that the use of psycholinguistic information is helpful for the automatic identification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverbal Deception Detecti</context>
</contexts>
<marker>Xu, Zhao, 2012</marker>
<rawString>Qiongkai Xu and Hai Zhao. 2012. Using deep linguistic features for finding deceptive opinion spam. In Proceedings of COLING 2012: Posters, Mumbai, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Yancheva</author>
<author>Frank Rudzicz</author>
</authors>
<title>Automatic detection of deception in child-produced speech using syntactic complexity features.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>944--953</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="30869" citStr="Yancheva and Rudzicz, 2013" startWordPosition="4964" endWordPosition="4967">rt of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; ´Angela Almela et al., 2012) and showed that the use of psycholinguistic information is helpful for the automatic identification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013). Nonverbal Deception Detection. Earlier approaches to nonverbal deception detection relied 2343 on polygraph tests to detect deceptive behavior. These tests are mainly based on such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cue</context>
</contexts>
<marker>Yancheva, Rudzicz, 2013</marker>
<rawString>Maria Yancheva and Frank Rudzicz. 2013. Automatic detection of deception in child-produced speech using syntactic complexity features. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 944–953, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>