<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.991601">
Do we need bigram alignment models? On the effect of alignment quality
on transduction accuracy in G2P
</title>
<author confidence="0.990131">
Steffen Eger
</author>
<affiliation confidence="0.973447">
Text Technology Lab
Goethe University Frankfurt am Main
</affiliation>
<email confidence="0.994662">
steeger@em.uni-frankfurt.de
</email>
<sectionHeader confidence="0.993789" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999912388888889">
We investigate the need for bigram align-
ment models and the benefit of super-
vised alignment techniques in grapheme-
to-phoneme (G2P) conversion. Moreover,
we quantitatively estimate the relation-
ship between alignment quality and over-
all G2P system performance. We find
that, in English, bigram alignment models
do perform better than unigram alignment
models on the G2P task. Moreover, we
find that supervised alignment techniques
may perform considerably better than their
unsupervised brethren and that few manu-
ally aligned training pairs suffice for them
to do so. Finally, we estimate a highly
significant impact of alignment quality on
overall G2P transcription performance and
that this relationship is linear in nature.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.984735272727273">
Grapheme-to-phoneme (G2P) conversion is the
problem of converting a string of letters into a
string of phonetic symbols. Closely related to
G2P are other string transduction problems in nat-
ural language processing (NLP) such as transliter-
ation (Sherif and Kondrak, 2007), lemmatization
(Dreyer et al., 2008), and spelling error correc-
tion (Brill and Moore, 2000). The classical learn-
ing paradigm in each of these settings is to train
a model on pairs of strings {(x, y)} and then to
evaluate model performance on test data. While
there are exceptions (e.g., (Rao et al., 2015)), most
state-of-the-art modelings (e.g., (Jiampojamarn et
al., 2007; Bisani and Ney, 2008; Jiampojamarn
et al., 2008; Jiampojamarn et al., 2010; Novak et
al., 2012)) view string transduction as a two-stage
process in which string pairs (x, y) in the train-
ing data are first aligned, and then a subsequent
(e.g., sequence labeling) module is learned on the
aligned data.
ph oe n i x
f i n I ks
</bodyText>
<tableCaption confidence="0.736664">
Table 1: Sample monotone many-to-many align-
ment between x = phoenix and y = finIks.
</tableCaption>
<bodyText confidence="0.97747948">
State-of-the-art alignments in G2P are charac-
terized by the following properties:
(i) Alignments are monotone in that the ordering
of characters in input and output sequences
is preserved by the alignments. Furthermore,
they are many-to-many in the sense that sev-
eral x sequence characters may be matched
up with several y sequence characters as il-
lustrated in Table 1.
(ii) The alignment is a latent variable and learnt
in an unsupervised manner from pairs of
strings in the training data.
(iii) The unsupervised alignment models are un-
igram alignment models insofar as the over-
all score that the alignment model assigns an
alignment is the same for all orderings of the
matched-up subsequences (context indepen-
dence).
To illustrate point (iii), consider, in the field of
lemmatization, the case of aligning an inflected
word form with the extended infinitive in German,
such as absagt (‘rejects’) with abzusagen (‘to re-
ject’). Critically, the insertion -zu- appears in in-
fixal position and a plausible alignment might be
as in Table 2. Then, correctly aligning certain
</bodyText>
<figure confidence="0.392161">
a b c s a g t
a b zu s a g en
</figure>
<tableCaption confidence="0.936258">
Table 2: Alignment between absagen and
abzusagen. Empty string denoted by c.
analogous forms such as zusagt (‘accepts’) with
</tableCaption>
<page confidence="0.934877">
1175
</page>
<note confidence="0.9850495">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1175–1185,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.997064">
their corresponding extended infinitive zuzusagen
(‘to accept’) is beyond the scope of a unigram
alignment model since this cannot distinguish the
linguistically correct alignment from the following
linguistically incorrect alignment
</bodyText>
<equation confidence="0.609776">
E z u s a g t
zu z u s a g en
</equation>
<bodyText confidence="0.991596434782609">
precisely because it has no notion of context.
In this work, we firstly address bigram align-
ment models in G2P. We investigate whether there
are phenomena in G2P that require bigram align-
ment models and, more generally, whether bigram
alignment models produce better alignments —
with respect to a human gold standard — than un-
igram alignment models within the G2P setting.
We do so, secondly, in a supervised setting where
the model learns from gold-standard alignments.
While this may seem an odd scenario at first sight,
modern alignment toolkits in the related field of
machine translation typically include the possibil-
ity to learn both in a supervised and unsupervised
manner (Liu et al., 2010; Liu and Sun, 2015).
The rationale behind supervised learning models
may be that they perform better than unsupervised
models, and if alignment quality has a large impact
upon subsequent string translation performance,
then a supervised model may be a suitable alterna-
tive. Thirdly, we investigate how alignment qual-
ity affects overall G2P performance. This allows
us to address whether it is worthwhile to work
on better alignment models, which bigram and
supervised alignment models promise to be. To
our knowledge, all three outlined aspects of align-
ments — bigram models, supervised learning, and
systematically estimating the relationship between
alignment quality and overall string transduction
performance — are novel in the G2P setting and
its related fields as outlined; however, see also the
related work section.
This work is structured as follows. Section 2
presents definitions and algorithms for uni- and bi-
gram alignment models. Section 3 surveys related
work. Section 4 presents our data and Section 5
our experiments. We conclude in Section 6.
2 Uni- and bigram alignment models
We first formally define the problem of aligning
two strings x and y over arbitrary alphabets in a
monotone and many-to-many manner. Let fx =
|x |and Ey = |y |denote the lengths of x and y,
respectively. Let N = {0, 1, 2, ...}, and let S ⊆
N2\{(0, 0)} be a set defining the valid match-up
operations between x characters and y characters.
In other words, when (s, t) ∈ S, then this means
we allow matches of subsequences of x of length
s and subsequences of y of length t.1
It is convenient to define a monotone many-to-
many alignment of x and y as a 2×k (for k ≥ 1 ar-
bitrary) nonnegative integer matrix Ax,y ∈ N2×k
satisfying Ax,y ✶k = (f1y) , i.e., the two rows
of Ax,y sum up to the lengths of the respective
strings,2 and where each column of Ax,y lies in
S. For any such alignment, we let (x1, ... , xk) be
the corresponding induced segmentation of x and
(y1, ... , yk) be the corresponding induced seg-
mentation of y.
Example. For any S ⊇ {(1, 1), (1, 2), (2, 1)},
the alignment of x = phoenix and y = finIks
shown in Table 1 may be represented by the ma-
trix Ax,y = (21 1 1 1 2) . The correspond-
ing induced segmentations are (ph,oe,n,i,x) and
(f,i,n,I,ks).
Let AS(x, y) denote the class of all alignments
of x and y. We call a function f : AS(x, y) → R
an alignment model. We call an alignment model
f a unigram alignment model if f takes the form,
for any Ax,y ∈ AS(x, y),
</bodyText>
<equation confidence="0.99539">
k
f(Ax,y) = sim1(xi,yi) (1)
i=1
</equation>
<bodyText confidence="0.99977975">
where sim1 is an arbitrary (real-valued) similar-
ity function measuring similarity of two subse-
quences. We call an alignment model f a bigram
alignment model if f takes the form
</bodyText>
<equation confidence="0.977115">
� �
sim2 (xi, yi), (xi−1, yi−1)
(2)
</equation>
<bodyText confidence="0.999555">
where sim2 is an arbitrary (real-valued) similarity
function measuring similarity of successive pairs
of subsequences.
Example. Let sim1(u, v) be equal to |u |· |v |and
let funi(Ax,y) be as in Eq. (1). Then, funi is a
unigram alignment model that assigns the score
</bodyText>
<footnote confidence="0.9299828">
1This is sometimes denoted in the manner M-N (e.g., 3-
2, 1-0), indicating that M characters of one string may be
matched up with N characters of the other string. Analo-
gously, we could write here s-t rather than (s, t).
2Here, ✶k denotes the unit vector of dimension k.
</footnote>
<equation confidence="0.69678775">
k
f(Ax,y) =
i=1
1176
1 + 1 + 0 + 1 + 1 + 1 + 2 = 7 to the alignment
given in Table 2.
Example. Let sim2 ((u, v), (u&apos;, v&apos;)) = (|u |·
|v|)|v&apos; |if |u |= |u&apos; |− 1 or u = v and −2 oth-
erwise. Let fbi(Ax,y) be as in Eq. (2). Then, fbi
is a bigram alignment model assigning the score
(1 · 1)0 + (1 · 1)1 + (0 · 2)1 + (1 · 1)2 + (1 · 1)1 +
(1 · 1)1 − 2 = 3 to the alignment in Table 2.
</equation>
<bodyText confidence="0.999869166666667">
In statistical alignment modeling, the task is to
find an optimal alignment (i.e., one with maxi-
mal score) given strings x and y and given the
alignment model f. When f is a unigram model,
this can be solved efficiently via dynamic pro-
gramming (DP). When f is a bigram alignment
model, then finding the optimal alignment can
still be solved via DP, by introducing a variable
Mijqw denoting the score of the best alignment
of x(1 : i) and y(1 : j) that ends in the match-
up of x(q : i) with y(w : j).3 The variable
Mijqw satisfies a recurrence leading to a DP al-
gorithm, shown in Algorithm 1. The actual align-
ment can be found by storing pointers to the maxi-
mizing steps taken. Running time of the algorithm
is O( x2 2y|S|). Note also that the sketched algo-
rithm is supervised insofar as it assumes that the
similarity values sim2(·, ·) are known. Typically,
such alignment algorithms can be converted into
unsupervised algorithms in which similarity mea-
sures sim are learnt iteratively, e.g., in an EM-like
fashion (cf., e.g., Eger (2012), Eger (2013)); how-
ever, in this paper, we only investigate the super-
vised base version as indicated.
</bodyText>
<sectionHeader confidence="0.999959" genericHeader="introduction">
3 Related work
</sectionHeader>
<bodyText confidence="0.985932888888889">
Monotone alignments have a long tradition in
NLP. The classical Needleman-Wunsch algo-
rithm (Needleman and Wunsch, 1970) computes
the optimal alignment between two sequences
when only single character matches, mismatches,
and skips are allowed. It is a special case
of the unigram model (1) for which S =
{(1, 0), (0, 1), (1, 1)} and sim1 takes on values
from {0, −1}, depending on whether compared
subsequences match or not. As is well-known, this
alignment specification is equivalent to the edit
distance problem (Levenshtein, 1966) in which
the minimal number of insertions, deletions and
substitutions is sought that transforms one string
3We denote by x(a : b) the substring xaxa+1 · · · xb of
the string x1x2 · · · xt.
into another. Substring-to-substring edit oper-
ations — or equivalently, (monotone) many-to-
many alignments — have appeared in the NLP
context, e.g., in Deligne et al. (1995), Brill and
Moore (2000), Jiampojamarn et al. (2007), Bisani
and Ney (2008), Jiampojamarn et al. (2010), or,
significantly earlier, in Ukkonen (1985), V´eronis
(1988). Learning edit distance/monotone align-
ments in an unsupervised manner has been the
topic of, e.g., Ristad and Yianilos (1998), Cot-
terell et al. (2014), besides the works already men-
tioned. All of these approaches are special cases of
our unigram model — i.e., they consider particular
S (most prominently, S = {(1, 0), (0, 1), (1, 1)})
and sim1.4 Eger (2015b), Yao and Kondrak
(2015), and Eger (2015a) generalize to alignments
of multiple strings, but likewise only consider un-
igram alignment models in their experiments.
Probably the most closely related work to ours
is Jiampojamarn and Kondrak (2010). There,
older and specialized alignment techniques such
as ALINE (Kondrak, 2000) (as well as partly
heuristic/semi-automatic alignment methods) are
compared with variants of the M2M alignment
algorithm, which we also survey. This work
does not consider supervised alignments or bigram
alignments, as we do. Moreover, Jiampojamarn
and Kondrak (2010) also evaluate the impact of
alignment quality on overall G2P system accuracy
by running a few experiments, finding that better
alignment quality does not always translate into
better G2P accuracy, but that there is a “strong
correlation” between the two. We more thorougly
investigate this question, using, arguably, more
heterogeneous aligners, and many more experi-
ments. We also quantitatively estimate how align-
ment quality influences G2P system accuracy on
two different languages via linear regression.
Goldwater et al. (2006) study the effect of
context in (unsupervised) word/sequence seg-
mentation, which may be considered the one-
dimensional specialization of sequence alignment,
using a Bayesian method. They find that bigram
models greatly outperform unigram models for
their task.
Of course, our study is also related to the field
of machine translation and its studies on the rela-
</bodyText>
<footnote confidence="0.8403828">
4In Cotterell et al. (2014), context influences alignments,
so that the approach goes beyond the unigram model sketched
in (1) (but does not allow for many-to-many match-ups). The
contextual dependencies in this model are set up differently
from the bigram dependencies in our paper.
</footnote>
<page confidence="0.986446">
1177
</page>
<construct confidence="0.401389">
Algorithm 1
</construct>
<listItem confidence="0.882242909090909">
1: procedure BIGRAM-ALIGN(x = x1 ... xn, y = y1 ... ym; 5, sime)
2: Mijqw −oc for all (i, j, q, w) E Z4
3: M0000 0
4: for i = 0 ... n do
5: for j = 0 ... m do
6: for q = 0 ... i + 1 do
7: for w = 0 ... j + 1 do
8: if (i, j, q, w) =� (0, 0, 0, 0) then
9: if (i − q + 1,j − w + 1) E 5 then
10: Mijqw= max Mq−1,w−1,q−a,w−b+5i11121 (x(q:i),y(w:j)),(x(q−a:q−1),y(w−b:w−1)))
(a,b)∈S
</listItem>
<bodyText confidence="0.991922">
tionship between alignment quality and translation
performance (Ganchev et al., 2008). In machine
translation, the monotonicity assumption of string
transduction does typically not hold, however, ren-
dering alignment and translation techniques differ-
ent and more heuristic in nature.
</bodyText>
<sectionHeader confidence="0.971668" genericHeader="method">
4 Data and systems
</sectionHeader>
<subsectionHeader confidence="0.970573">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.980983230769231">
For English, we conduct experiments on the Gen-
eral American (GA) variant of the Combilex data
set (Richmond et al., 2009). This contains about
128 000 grapheme-phoneme pairs as exemplified
in Table 3. Importantly, Combilex provides gold-
standard alignments, which we will make use of
for the supervised alignment models as well as for
measuring alignment quality. For German, we ran-
Grapheme string Phoneme string
g-e-n-e-r-a-l dZ-E-n-@-r-@-l
p-r-o-b-a-t-ion-a-r-y p-r-@U-b-eI-S-n=-E-r-i
w-oo-d-e-d w-U-d-@-d
M-u-r-m-a-n-s-k m-U@-r-m-A-n-s-k
Table 3: Sample grapheme-phoneme string pairs
in Combilex, using Combilex notation for the
phoneme strings. Gold-standard alignments indi-
cated in an intuitive manner.
domly extract 3 000 G2P string pairs from CELEX
(Baayen et al., 1995). We had a native speaker
manually align them so that gold standard align-
ments are available here, too. Both data sets con-
tain quite complex match-ups of character subse-
quences such as (2,3) as in English s-oi-r-ee-s/s-
wOA-r-P-z or (4,1) as in w-eigh-t/w-P-t but the
majority of match-ups are of type (1,1), (2,1), and,
to a lesser degree, (1,2) and (3,1).
</bodyText>
<subsectionHeader confidence="0.994955">
4.2 Alignment toolkits/models
</subsectionHeader>
<bodyText confidence="0.999995620689655">
The M2M aligner (Jiampojamarn et al., 2007),
which is based on EM maximum likelihood es-
timation of alignment parameters, is the classi-
cal unsupervised unigram many-to-many aligner
in G2P. As has been pointed out (Kubo et al.,
2011), M2M greatly overfits the data.5 This
means that when the M2M aligner is given the
freedom to align two sequences without restric-
tions, it matches them up as a whole. The rea-
son is that a (probabilistic) unigram alignment
model adds log-probabilities of matched-up sub-
sequences, which, if not appropriately corrected
for, makes alignments with few match-ups a pri-
ori more likely than alignments with many match-
ups, when probabilities of individual match-ups
are uniformly or randomly initialized (as is typi-
cally the case for EM maximum likelihood esti-
mation in unsupervised models). To address this,
M2M must artifically restrain, in our language, the
set 5 to be 1(1,1), (1, 2), (2, 1)}. In contrast, the
Mpaligner (Kubo et al., 2011) introduces a prior
(or penalty) in the alignment model which favors
‘short’ matches (s, t) over ‘long’ ones. Finally, the
Phonetisaurus aligner (Novak et al., 2012) mod-
ifies the M2M aligner by adding additional soft
constraints.
Our own alignment model is, as indicated, su-
pervised. We implement a unigram alignment
model where we specify sim1(u, v) as
</bodyText>
<equation confidence="0.783007">
α · logp((u, v)) + Q · logp((Iu�, �v�))
+ry · logp(u) + S · logp(v).
</equation>
<bodyText confidence="0.992346">
Here, logp(z) denotes the log-probability — esti-
mated from the training data — of observing the
</bodyText>
<footnote confidence="0.9973585">
5See also the discussion in (Goldwater et al., 2006) for the
related word segmentation problem.
</footnote>
<page confidence="0.993525">
1178
</page>
<bodyText confidence="0.972379777777778">
object z, and α, Q, ry and 6 are parameters. This
specification says that the subsequences u and v
are similar insofar as (i) u and v have been paired
frequently in the training data, (ii) the length of u
and the length of v have been paired frequently,
(iii)/(iv) u/v by itself is likely. We refer to this
unigram alignment model as uniα,β,γ,δ. We also
implement a bigram alignment model where we
specify sim2 ((u, v), (u0, v0)) as
</bodyText>
<equation confidence="0.998800666666667">
α · logp((u, v)  |(u0, v0))
+Q · logp((|u|, |v|) |(|u0|, |v0|))
+ry · logp(u|u0) + 6 · logp(v|v0).
</equation>
<bodyText confidence="0.99807575">
Here, logp(z  |z0) denotes the logarithm of the con-
ditional probability of observing the object z fol-
lowing the object z0. We refer to this bigram align-
ment model as biα,β,γ,δ.
</bodyText>
<subsectionHeader confidence="0.996059">
4.3 Transduction systems
</subsectionHeader>
<bodyText confidence="0.999874466666667">
We use two string transduction systems for our ex-
periments. The first one is DirecTL+ (Jiampo-
jamarn et al., 2010), a discriminative string-to-
string translation system incorporating joint n-
gram features. DirecTL+ is an extension of the
model presented in Jiampojamarn et al. (2008)
which treats string transduction as a source se-
quence segmentation and subsequent sequence la-
beling task. In addition, we use Phonetisaurus
(Novak et al., 2012), a weighted finite state-based
joint n-gram model employing recurrent neural
network language model N-best rescoring in de-
coding. Both systems take aligned pairs of strings
as input and from this construct a monotone trans-
lation model.6
</bodyText>
<subsectionHeader confidence="0.99803">
4.4 Measuring alignment quality
</subsectionHeader>
<bodyText confidence="0.999958083333333">
We employ two measures of alignment quality.
First, we use word accuracy, defined as the frac-
tion of correctly aligned sequence pairs in a test
sample. This is a very strict measure that penalizes
even tiny deviations from the gold standard. Addi-
tionally, we measure the edit distance between the
true alignment Ax,y and the predicted alignment
ˆAx,y. To implement this, we view the two induced
segmentations that constitute an alignment — e.g.,
(ph,oe,n,i,x) and (f,i,n,I,ks) — as strings includ-
ing splitting signs. Thus, we can compute the edit
distance between the gold-standard segmented x
</bodyText>
<footnote confidence="0.929853666666667">
6We run both systems with parameters determined by
some manual tuning, without trying to systematically opti-
mize their individual performances, however.
</footnote>
<bodyText confidence="0.9998825">
string and the predicted segmentation, and analo-
gously for the y sequence. Then, we define the
edit distance between Ax,y and ˆAx,y as the sum
of these two string edit distances. For a test sam-
ple, we indicate so-defined average edit distance,
averaged over all pairs in the sample.
</bodyText>
<sectionHeader confidence="0.999867" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999664">
5.1 Alignment quality
</subsectionHeader>
<bodyText confidence="0.977653380952381">
To measure alignment quality for the different sys-
tems, for English, we run experiments on sets of
size x+5 000, where x = 1000, 2 000, 5 000,
10 000, and 20 000. For the supervised models,
we consider x as the training data and the 5 000
additional string pairs as test data.7 To quantify
effects when training data is very little, we let x
also range over 100 and 500 string pairs for the
supervised models. For the unsupervised models,
we simply take all x+5 000 string pairs as data to
learn from (but evaluate performance only on the
5 000 string pairs, for comparability).
Results are shown in Tables 4, 5, and 6. We
first note (Table 4) that the unsupervised mod-
els perform decently, obtaining accuracy rates of
80% and beyond under appropriate parametriza-
tions. We also observe the M2M aligner’s de-
terioration in performance as we increase its de-
grees of freedom (allowing it to match subse-
quences of larger length), confirming our previous
remarks. The Mpaligner does not suffer from this
problem as it penalizes large matches. Phoneti-
saurus suffers from the same problems as M2M,
but to a lesser degree. Overall, we find that, under
optimal parametrizations, Phonetisaurus produces
best alignments, followed by Mpalign and M2M.
However, peak performances of all three unsu-
pervised aligners are close. Unsurprisingly, the
supervised alignment models perform better than
the unsupervised ones (Tables 5 and 6). Surpris-
ingly, however, they do so with very little train-
ing data; fewer than 100 aligned string pairs suf-
fice to outperform the unsupervised models under
good calibrations. When there is sufficient train-
ing data, the supervised models perform splen-
didly, with a peak accuracy of 99.43% for the bi-
gram alignment model that includes appropriate
features (scoring lengths of aligned subsequences,
7For all our below experiments involving the supervised
aligners, we set S to a (‘pessimistically’ large) value of
{(a, b) 11 &lt; a &lt; 6, 1 &lt; b &lt; 61. Also, for the bigram
models, we add special sequence boundary markers.
</bodyText>
<page confidence="0.986256">
1179
</page>
<bodyText confidence="0.995215636363636">
etc.). We also note that the bigram alignment
model is almost consistently better than the uni-
gram alignment model, with a surplus of about 1%
point, depending on specific parametrizations.
We performed an analogous analysis for the
German data. Results are quite similar except that
unigram and bigram alignment model have indis-
tinguishable performance on the German data, in-
dicating (the known fact) that G2P is a more com-
plex task in English, apparently not requiring bi-
gram alignment models.
</bodyText>
<table confidence="0.999821">
x uni0,0,1,1 uni1,0,0,0 uni1,1,1,1
100 70.34 58.13 87.22
500 81.94 84.64 95.60
1000 84.56 90.38 96.17
2000 85.41 93.47 97.13
5000 86.56 96.11 97.72
10000 86.13 97.07 98.14
20000 86.60 97.90 98.34
</table>
<tableCaption confidence="0.958932">
Table 5: Unigram model and its alignment accura-
</tableCaption>
<table confidence="0.963346666666667">
cies in % for various training sizes.
x bi0,0,1, 1 bi1,0,0,0 bi1,1,1,1
100 73.96 58.02 87.28
500 87.62 85.31 95.26
1000 91.87 90.73 97.32
2000 93.29 94.11 97.96
5000 95.58 97.01 99.03
10000 96.07 98.12 99.17
20000 97.21 98.73 99.43
</table>
<tableCaption confidence="0.772396">
Table 6: Bigram model and its alignment accura-
cies in % for various training sizes.
</tableCaption>
<bodyText confidence="0.962922027027027">
Error analysis Concerning errors that the uni-
gram model commits and the bigram model does
not, the majority of errors (roughly 80%) involve
match-ups of ed/d and d. For example, the uni-
gram model aligns as in
t w i n k le d
t w I N k @l d
while the gold-standard alignment is
t w i n k l ed
t w I N k @l d
While all match-ups in both alignments are plau-
sible, the bigram model assigns here higher proba-
bility to the correct ed/d match-up in terminal po-
sition (consistently favored in the data set), which
has a particular meaning there, namely, that of
a suffix marker for past tense.8,9 In the German
data, there is a single instance where the unigram
and bigram alignment model disagree, namely, in
the alignment of s-t-o-ff-f-l-a-sch-e/S-t-O-f-f-l-&amp;-
S-@, which the unigram model falsely aligns as
s-t-o-f-ff-l-a-sch-e/S-t-O-f-f-l-&amp;-S-@; note that in
the correct alignment f must follow ff, not vice
versa, which depends on context information, e.g.,
that o/O signifies a short vowel which is followed
by a double consonant, not a single consonant.
All remaining errors that the bigram align-
ment models commits are, for the best considered
parametrization and training set size, typically due
to match-up types not seen in the training data,
and thus mostly concern foreign names or writings
(e.g., Bh-u-tt-o/b-u-t-F, falsely aligned as B-hu-tt-
o/b-u-t-F). A few other errors might be corrected
when the feature coefficients α, Q, γ, δ were opti-
mized on a development set rather than set manu-
ally. We find no indication that our G2P data, ei-
ther for English or German, would further benefit
from n-gram alignment models of order n &gt; 2.
</bodyText>
<subsectionHeader confidence="0.8353865">
5.2 Alignment quality vs. overall G2P
performance
</subsectionHeader>
<bodyText confidence="0.9999805625">
Next, we estimate the relationship between align-
ment quality and overall G2P performance (tran-
scription accuracy). To this end, for the English
data, we use the 5 000 aligned string pairs from
the previous experiment on alignment quality and
feed them in — as training data — to either Di-
recTL+ or Phonetisaurus as outlined in Section 4.
We then evaluate G2P performance — in terms of
word accuracy (fraction of correctly transcribed
strings) — on a distinct test set of size 10000.
Figure 1 shows a plot of overall G2P accuracy
vs. training set size for the aligner (ranging over
the x values in the last section); and a second plot
that sketches G2P accuracy as a function of corre-
sponding alignment accuracy. We first note that,
as the supervised aligner receives more training
</bodyText>
<footnote confidence="0.779081833333333">
8Similar cases are, e.g., alignments of the type f-ee-d-b-
a-ck/f-i-d-b-a-k, which the unigram model falsely aligns as
f-e-ed-b-a-ck/f-i-d-b-a-k. Here, too, the unigram is unable to
account for the almost exclusive terminal position of the ed/d
match-up in the data.
9Other errors involve ‘unusual/foreign’
spelling/pronunciation pairs such as Ph-oe-n-i-c-ia/f-@-
n-i-S-@ (wrongly aligned as Ph-o-en-i-c-ia/f-@-n-i-S-@ by
the unigram model) or m-a-d-e-m-oi-s-e-ll-e-’s/m-a-d-@-m-
w@-z-E-l-0-z (m-a-d-e-m-o-i-s-e-ll-e-’s/m-a-d-@-m-w-@-
z-E-l-0-z), where the bigram alignment model has apparently
gathered the more appropriate statistics.
</footnote>
<page confidence="0.959422">
1180
</page>
<table confidence="0.999773833333333">
x Mpalign M2M2,2 M2M3,3 M2M6,6 Phon2,2 Phon3,3 Phon6,6
1000 76.48 77.87 34.59 18.96 78.27 78.15 11.70
2000 78.05 78.03 34.45 18.87 79.24 77.07 12.43
5000 76.68 77.93 35.09 19.72 79.77 80.47 17.63
10000 78.86 77.97 35.03 21.35 79.60 81.30 23.57
20000 79.87 78.60 37.09 22.90 80.09 83.37 34.61
</table>
<tableCaption confidence="0.833873">
Table 4: Unsupervised aligners and their alignment accuracies in % for various data sizes as described
in the text. Subscripts a, b denote restrictions on maximal lengths of subsequences allowed in match-ups
(a/b corresponds to x/y subsequences).
</tableCaption>
<figure confidence="0.997598045454545">
2K 10K 20K
Training size aligner
Phonetisaurus
DirecTL
0.58
Transduction Accuracy
0.54
0.50
0.46
0.42
0.38
0.60 0.70 0.80 0.90 1.00
Alignment quality (accuracy)
Phonetisaurus
DirecTL
0.58
Transduction Accuracy
0.54
0.50
0.46
0.42
0.38
</figure>
<figureCaption confidence="0.999288">
Figure 1: Left: Overall G2P accuracy as a function of training set size of supervised aligner uni1,0,0,0.
Right: G2P accuracy as a function of alignment quality (measured in accuracy).
</figureCaption>
<bodyText confidence="0.988299913043478">
data from which to align the 5 000 string pairs,
the overall G2P accuracy of both DirecTL+ and
Phonetisaurus increase substantially (and as a con-
vex function of training set size). Apparently, the
better alignments produced by more training data
for the particular supervised aligner considered di-
rectly translate into better overall G2P accuracy.
The other plot in the figure shows that, indeed,
there seems to be a linear trend coupling align-
ment quality with overall G2P performance. Table
7 pairs G2P accuracy with alignment accuracy of
selected systems, all run in the x = 20 000 set-
ting. While, in the table, better alignments do not
necessarily imply better overall G2P performance,
the two best alignments also lead to the two best
overall G2P performances (although, in this case,
the second best alignment is paired with the best
overall G2P performance); conversely, the worst
alignment quality is coupled with the worst over-
all G2P performance.
Overall, we ran 249 experiments (including the
German data) in which we trained DirecTL+ or
Phonetisaurus with alignments of specific quali-
</bodyText>
<table confidence="0.998683714285714">
Alignment acc. Phon. DirecTL+
Mpalign 79.87 55.48 57.54
M2M3,3 37.09 49.25 53.71
Phon3,3 83.37 54.05 56.11
uni0,0,1,1 86.60 53.19 55.49
uni1,1,1,1 98.34 55.72 57.78
bi1,1,1,1 99.43 55.71 57.71
</table>
<tableCaption confidence="0.993156">
Table 7: Systems, alignment accuracies of corre-
</tableCaption>
<bodyText confidence="0.996555846153846">
sponding produced alignments and transcription
accuracy of Phonetisaurus and DirecTL+ when
trained with the respective alignments.
ties obtained from particularly parametrized align-
ers. In each of these cases, we obtained an align-
ment quality score and a subsequent overall G2P
system performance. The English part of this
data is sketched in Figure 2. This figure seems
to corroborate the linear relationship (apparently
present in Figure 1) between alignment quality and
overall G2P system accuracy, particularly, when
alignment quality is measured in the more fine-
grained metric of edit distance. To formally test
</bodyText>
<page confidence="0.987381">
1181
</page>
<figure confidence="0.9995682">
0.55
Transduction Accuracy
0.45
0.35
0.25
0.15
0.55
Transduction Accuracy
0.45
0.35
0.25
0.15
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Alignment quality (accuracy)
0 1 2 3 4 5 6 7 8 9
Alignment quality (edit distance)
Phonetisaurus
DirecTL
Phonetisaurus
DirecTL
</figure>
<figureCaption confidence="0.9889275">
Figure 2: Overall G2P accuracy vs. alignment quality. Left: Alignment quality measured in accuracy.
Right: Alignment quality measured in edit distance. English data only.
</figureCaption>
<bodyText confidence="0.999875642857143">
this, we regress overall G2P system performance
(measured in word accuracy) on edit distance and
other variables.10 This yielded the coefficients as
given in Table 8; in each case, the goodness-of-
fit of the linear model was quite large, with R2
values above 90% for the English data and about
84% for the German data. Also, the coefficients
on alignment quality were highly significantly dif-
ferent from zero. The table shows that the co-
efficients are on the order of about −3.80% to
−4.70%, meaning that, all else being equal, in-
creasing alignment quality by 1 edit distance to the
gold-standard alignment increases overall G2P by
about 3.80 to 4.70%.
</bodyText>
<equation confidence="0.315077666666667">
DirecTL+ Phonetisaurus
English −3.80*** −4.14***
German - −4.68***
</equation>
<bodyText confidence="0.916955296296296">
Table 8: Coefficients on edit distance in the regres-
sion of G2P accuracy on edit distance and further
variables. For German, DirecTL+ is omitted due
to its long run times.
So far, we have estimated the effects of align-
ment quality on overall G2P system performance
for a fixed size of training data, namely, 5 000
aligned string pairs. To see whether this relation-
ship changes when we vary the amount of train-
ing data, we run several more experiments. In
these, we align training sets of sizes 100, 500,
10These include binary dummy variables for the specific
systems as well as alignment consistency and its square —
measured in conditional entropy H(YIX) (Pervouchine et
al., 2009) — in the regression.
1000, 2 000, 10 000, 20 000, 40 000 and 60 000
via our several alignment systems. Then we feed
the aligned data to the Phonetisaurus system (we
omit DirecTL+ here because of its long run times)
and compute overall G2P accuracy on a disjoint
test set of size 28 000 approximately. This time,
we only use the unsupervised aligners and the
gold-standard alignments directly, omitting results
for our various supervised aligners. Note, how-
ever, that these aligners could, in principle, imi-
tate the gold-standard alignments with a very high
degree of precision, as previously seen. Table 9
</bodyText>
<table confidence="0.979280666666667">
M2M3,3 Mpalign Phon3,3 Gold
100 5.38 6.43 0.19 9.60
500 16.80 22.43 5.08 23.93
1K 25.79 31.46 18.70 33.37
2K 35.31 42.01 37.74 43.64
10K 58.44 64.05 63.06 64.60
20K 67.70 71.70 71.51 72.21
40K 74.69 78.45 78.13 78.65
60K 78.00 81.07 80.92 81.17
</table>
<tableCaption confidence="0.9640255">
Table 9: Overall G2P accuracy in % as a function
training size of aligned data and alignment system.
</tableCaption>
<bodyText confidence="0.999752">
shows that training G2P systems from the human
gold standard alignments in each case yields bet-
ter overall G2P transcriptions than training them
from either of the three unsupervised alignments
considered here. However, we note that the sur-
plus over the unsupervised alignments decreases
as training set size increases. This may be due
to the fact that the unsupervised aligners them-
selves create better alignments once they are boot-
</bodyText>
<page confidence="0.985122">
1182
</page>
<bodyText confidence="0.999860333333333">
strapped from larger data sets (cf. Table 4). Ad-
ditionally, the effect of alignment quality on over-
all G2P system performance may simply vanish as
training set sizes become large enough because the
translation modules can better accomodate ‘noisy’
data as long as its size is sufficiently large. Figure
</bodyText>
<figure confidence="0.5865025">
0 10K 20K 40K 60K
Training set size
</figure>
<figureCaption confidence="0.946151">
Figure 3: Ratio of transcription accuracy when us-
</figureCaption>
<bodyText confidence="0.926933571428571">
ing gold standard alignments (GOLD) and when
using alignments generated by T = M2M3,3,
Mpalign, and Phon3,3, respectively, as a function
of size of aligned training set.
3 sketches the decreasing influence of alignment
system on overall G2P system performance as size
of the aligned data increases.
</bodyText>
<sectionHeader confidence="0.999349" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999987340909091">
We have investigated the need for bigram align-
ment models and the benefit of supervised align-
ment techniques in G2P. We have also quantita-
tively estimated the relationship between align-
ment quality and overall G2P system performance.
We have found that, in English, bigram alignment
models do perform better than unigram alignment
models on the G2P task (we find almost no dif-
ferences between unigram and bigram models for
the German sample of G2P data we considered).
Moreover, we have found that supervised align-
ment techniques may perform considerably better
than their unsupervised brethren and that few man-
ually aligned training pairs suffice for them to do
so. Finally, we have estimated a highly significant
impact of alignment quality on overall G2P tran-
scription performance and that this relationship is
linear in nature. At a particular training size, a
linear regression model has estimated that improv-
ing alignment quality by 1 edit distance toward the
gold standard alignments leads to an 3.80-4.70%
increase in G2P transcription accuracy. However,
we have also found that the importance of good
alignments on G2P accuracy appears to dimish as
data set size increases, possibly because the trans-
lation modules can accomodate more ‘noisy’ data
in this scenario.
As a ‘policy’ implication, we recommend the
use of supervised alignment techniques particu-
larly when the size of the G2P corpus is small or
when high quality alignments, as an end in them-
selves, are required. In this case, constructing a
few dozen or few hundred alignments in an unsu-
pervised manner and correcting them by hand (to
serve as an input for a supervised technique) may
be highly beneficial.
In future work, it may be worthwhile to study
the impact of alignment techniques on overall sys-
tem performance in other string transduction prob-
lems such as transliteration, lemmatization, and
spelling error correction.
Our supervised uni- and bigram aligners
are available via https://github.com/
SteffenEger/.
</bodyText>
<sectionHeader confidence="0.997492" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.98903">
I thank three anonymous reviewers and Tim vor
der Br¨uck for valuable suggestions.
</bodyText>
<sectionHeader confidence="0.998181" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9761511">
H. Baayen, R. Piepenbrock, and L. Gulikers. 1995.
The CELEX2 lexical database. ldc96l14.
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434–451.
Eric Brill and Robert C. Moore. 2000. An improved
error model for noisy channel spelling correction.
In Proceedings of the 38th Annual Meeting on As-
sociation for Computational Linguistics, ACL ’00,
pages 286–293, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Ryan Cotterell, Nanyun Peng, and Jason Eisner. 2014.
Stochastic contextual edit distance and probabilis-
tic FSTs. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 625–630, Baltimore, June.
Sabine Deligne, Franois Yvon, and Fr´ed´eric Bimbot.
1995. Variable-length sequence matching for pho-
netic transcription using joint multigrams. In EU-
ROSPEECH. ISCA.
</reference>
<figure confidence="0.9987556">
GOLD/T
1.10
1.08
1.06
1.04
1.02
1.00
M2M3,3
Mpalign
Phon3,3
</figure>
<page confidence="0.934785">
1183
</page>
<reference confidence="0.998644642857143">
Markus Dreyer, Jason Smith, and Jason Eisner. 2008.
Latent-variable modeling of string transductions
with finite-state methods. In EMNLP, pages 1080–
1089. ACL.
Steffen Eger. 2012. S-restricted monotone alignments:
Algorithm, search space, and applications. In COL-
ING’12, pages 781–798.
Steffen Eger. 2013. Sequence alignment with arbitrary
steps and further generalizations, with applications
to alignments in linguistics. Inf. Sci., 237:287–304.
Steffen Eger. 2015a. Improving g2p from wiktionary
and other (web) resources. In Proceedings of Inter-
speech. accepted.
Steffen Eger. 2015b. Multiple many-to-many se-
quence alignment for combining string-valued vari-
ables: A G2P experiment. In Proceedings of the
53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint
Conference on Natural Language Processing of the
Asian Federation of Natural Language Processing,
ACL 2015, July 26-31, 2015, Beijing, China, Volume
1: Long Papers, pages 909–919.
Kuzman Ganchev, Joo Graa, and Ben Taskar. 2008.
Better alignments = better translations? In Kath-
leen McKeown, Johanna D. Moore, Simone Teufel,
James Allan, and Sadaoki Furui, editors, ACL, pages
986–993. The Association for Computational Lin-
guistics.
Sharon Goldwater, Thomas L. Griffiths, and Mark
Johnson. 2006. Contextual dependencies in un-
supervised word segmentation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 673–680,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
Sittichai Jiampojamarn and Grzegorz Kondrak. 2010.
Letter-phoneme alignment: An exploration. In Jan
Hajic, Sandra Carberry, and Stephen Clark, editors,
ACL, pages 780–788. The Association for Compu-
tational Linguistics.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden markov models to letter-to-phoneme
conversion. In Human Language Technologies
2007: The Conference of the North American Chap-
ter of the Association for Computational Linguistics;
Proceedings of the Main Conference, pages 372–
379, Rochester, New York, April. Association for
Computational Linguistics.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Pro-
ceedings of ACL-08: HLT, pages 905–913, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2010. Integrating joint n-gram features
into a discriminative training framework. In HLT-
NAACL, pages 697–700. The Association for Com-
putational Linguistics.
Grzegorz Kondrak. 2000. A new algorithm for the
alignment of phonetic sequences. In Proceedings of
the 1st North American Chapter of the Association
for Computational Linguistics Conference, NAACL
2000, pages 288–295, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Keigo Kubo, Hiromichi Kawanami, Hiroshi
Saruwatari, and Kiyohiro Shikano. 2011. Un-
constrained many-to-many alignment for automatic
pronunciation annotation. In Proceedings of
Asia-Pacific Signal and Information Processing
Association Annual Summit and Conference 2011
(APSIPA2011), October.
VI Levenshtein. 1966. Binary Codes Capable of Cor-
recting Deletions, Insertions and Reversals. Soviet
Physics Doklady, 10:707.
Yang Liu and Maosong Sun. 2015. Contrastive unsu-
pervised word alignment with non-local features. In
Proceedings ofAAAI 2015.
Yang Liu, Qun Liu, and Shouxun Lin. 2010. Discrim-
inative word alignment by linear modeling. Compu-
tational Linguistics, pages 303–339.
Saul B. Needleman and Christian D. Wunsch. 1970.
A general method applicable to the search for sim-
ilarities in the amino acid sequence of two pro-
teins. Journal of Molecular Biology, 48(3):443–
453, March.
Josef R. Novak, Nobuaki Minematsu, and Keikichi Hi-
rose. 2012. WFST-based grapheme-to-phoneme
conversion: Open source tools for alignment,
model-building and decoding. In Proceedings of the
10th International Workshop on Finite State Meth-
ods and Natural Language Processing, pages 45–49,
Donostia–San Sebastin, July. Association for Com-
putational Linguistics.
Vladimir Pervouchine, Haizhou Li, and Bo Lin. 2009.
Transliteration alignment. In Proceedings of the
Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP:
Volume 1 - Volume 1, ACL ’09, pages 136–144,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Kanishka Rao, Fuchun Peng, Hasim Sak, and Franoise
Beaufays. 2015. Grapheme-to-phoneme conversion
using long short-term memory recurrent neural net-
works. In ICASSP 2015.
Korin Richmond, Robert A. J. Clark, and Susan Fitt.
2009. Robust LTS rules with the Combilex speech
technology lexicon. In INTERSPEECH, pages
1295–1298. ISCA.
</reference>
<page confidence="0.901743">
1184
</page>
<reference confidence="0.999674">
Eric Sven Ristad and Peter N. Yianilos. 1998. Learn-
ing string-edit distance. IEEE Trans. Pattern Anal.
Mach. Intell., 20(5):522–532.
Tarek Sherif and Grzegorz Kondrak. 2007. Substring-
based transliteration. In John A. Carroll, Antal
van den Bosch, and Annie Zaenen, editors, ACL.
The Association for Computational Linguistics.
Esko Ukkonen. 1985. Algorithms for approximate
string matching. Information and Control, 64:100–
118.
Jean V´eronis. 1988. Computerized correction of
phonographic errors. Computers and the Humani-
ties, 22(1):43–56.
Lei Yao and Grzegorz Kondrak. 2015. Joint generation
of transliterations from multiple representations. In
Proceedings of the 2015 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 943–952, Denver, Colorado, May–June. As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.994326">
1185
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.661323">
<title confidence="0.9889235">Do we need bigram alignment models? On the effect of alignment quality on transduction accuracy in G2P</title>
<author confidence="0.986354">Steffen</author>
<affiliation confidence="0.8626815">Text Technology Goethe University Frankfurt am</affiliation>
<email confidence="0.964119">steeger@em.uni-frankfurt.de</email>
<abstract confidence="0.998454684210527">investigate the need for alignmodels and the benefit of supertechniques in graphemeto-phoneme (G2P) conversion. Moreover, we quantitatively estimate the relationship between alignment quality and overall G2P system performance. We find that, in English, bigram alignment models do perform better than unigram alignment models on the G2P task. Moreover, we find that supervised alignment techniques may perform considerably better than their unsupervised brethren and that few manually aligned training pairs suffice for them to do so. Finally, we estimate a highly significant impact of alignment quality on overall G2P transcription performance and that this relationship is linear in nature.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Baayen</author>
<author>R Piepenbrock</author>
<author>L Gulikers</author>
</authors>
<date>1995</date>
<booktitle>The CELEX2 lexical database. ldc96l14.</booktitle>
<contexts>
<context position="13853" citStr="Baayen et al., 1995" startWordPosition="2348" endWordPosition="2351">eme-phoneme pairs as exemplified in Table 3. Importantly, Combilex provides goldstandard alignments, which we will make use of for the supervised alignment models as well as for measuring alignment quality. For German, we ranGrapheme string Phoneme string g-e-n-e-r-a-l dZ-E-n-@-r-@-l p-r-o-b-a-t-ion-a-r-y p-r-@U-b-eI-S-n=-E-r-i w-oo-d-e-d w-U-d-@-d M-u-r-m-a-n-s-k m-U@-r-m-A-n-s-k Table 3: Sample grapheme-phoneme string pairs in Combilex, using Combilex notation for the phoneme strings. Gold-standard alignments indicated in an intuitive manner. domly extract 3 000 G2P string pairs from CELEX (Baayen et al., 1995). We had a native speaker manually align them so that gold standard alignments are available here, too. Both data sets contain quite complex match-ups of character subsequences such as (2,3) as in English s-oi-r-ee-s/swOA-r-P-z or (4,1) as in w-eigh-t/w-P-t but the majority of match-ups are of type (1,1), (2,1), and, to a lesser degree, (1,2) and (3,1). 4.2 Alignment toolkits/models The M2M aligner (Jiampojamarn et al., 2007), which is based on EM maximum likelihood estimation of alignment parameters, is the classical unsupervised unigram many-to-many aligner in G2P. As has been pointed out (K</context>
</contexts>
<marker>Baayen, Piepenbrock, Gulikers, 1995</marker>
<rawString>H. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The CELEX2 lexical database. ldc96l14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<issue>5</issue>
<contexts>
<context position="1615" citStr="Bisani and Ney, 2008" startWordPosition="242" endWordPosition="245">oblem of converting a string of letters into a string of phonetic symbols. Closely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling) module is learned on the aligned data. ph oe n i x f i n I ks Table 1: Sample monotone many-to-many alignment between x = phoenix and y = finIks. State-of-the-art alignments in G2P are characterized by the following properties: (i) Alignments are monotone in that the ordering of characters in input and output sequences is preserved by the alignments. Furth</context>
<context position="10152" citStr="Bisani and Ney (2008)" startWordPosition="1758" endWordPosition="1761">es from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50(5):434–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert C Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, ACL ’00,</booktitle>
<pages>286--293</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1311" citStr="Brill and Moore, 2000" startWordPosition="191" endWordPosition="194">ised brethren and that few manually aligned training pairs suffice for them to do so. Finally, we estimate a highly significant impact of alignment quality on overall G2P transcription performance and that this relationship is linear in nature. 1 Introduction Grapheme-to-phoneme (G2P) conversion is the problem of converting a string of letters into a string of phonetic symbols. Closely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling) module is learned on the aligned data. ph oe n i x f i</context>
<context position="10101" citStr="Brill and Moore (2000)" startWordPosition="1750" endWordPosition="1753"> S = {(1, 0), (0, 1), (1, 1)} and sim1 takes on values from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likew</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Eric Brill and Robert C. Moore. 2000. An improved error model for noisy channel spelling correction. In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, ACL ’00, pages 286–293, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Cotterell</author>
<author>Nanyun Peng</author>
<author>Jason Eisner</author>
</authors>
<title>Stochastic contextual edit distance and probabilistic FSTs.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>625--630</pages>
<location>Baltimore,</location>
<contexts>
<context position="10394" citStr="Cotterell et al. (2014)" startWordPosition="1793" endWordPosition="1797"> substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojamarn and Kondrak (2010). There, older and specialized alignment techniques such as ALINE (Kondrak, 2000) (as well as partly heuristic/semi-automatic alignment methods) ar</context>
<context position="12115" citStr="Cotterell et al. (2014)" startWordPosition="2057" endWordPosition="2060">ion, using, arguably, more heterogeneous aligners, and many more experiments. We also quantitatively estimate how alignment quality influences G2P system accuracy on two different languages via linear regression. Goldwater et al. (2006) study the effect of context in (unsupervised) word/sequence segmentation, which may be considered the onedimensional specialization of sequence alignment, using a Bayesian method. They find that bigram models greatly outperform unigram models for their task. Of course, our study is also related to the field of machine translation and its studies on the rela4In Cotterell et al. (2014), context influences alignments, so that the approach goes beyond the unigram model sketched in (1) (but does not allow for many-to-many match-ups). The contextual dependencies in this model are set up differently from the bigram dependencies in our paper. 1177 Algorithm 1 1: procedure BIGRAM-ALIGN(x = x1 ... xn, y = y1 ... ym; 5, sime) 2: Mijqw −oc for all (i, j, q, w) E Z4 3: M0000 0 4: for i = 0 ... n do 5: for j = 0 ... m do 6: for q = 0 ... i + 1 do 7: for w = 0 ... j + 1 do 8: if (i, j, q, w) =� (0, 0, 0, 0) then 9: if (i − q + 1,j − w + 1) E 5 then 10: Mijqw= max Mq−1,w−1,q−a,w−b+5i1112</context>
</contexts>
<marker>Cotterell, Peng, Eisner, 2014</marker>
<rawString>Ryan Cotterell, Nanyun Peng, and Jason Eisner. 2014. Stochastic contextual edit distance and probabilistic FSTs. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 625–630, Baltimore, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Deligne</author>
<author>Franois Yvon</author>
<author>Fr´ed´eric Bimbot</author>
</authors>
<title>Variable-length sequence matching for phonetic transcription using joint multigrams.</title>
<date>1995</date>
<booktitle>In EUROSPEECH. ISCA.</booktitle>
<contexts>
<context position="10077" citStr="Deligne et al. (1995)" startWordPosition="1746" endWordPosition="1749">ram model (1) for which S = {(1, 0), (0, 1), (1, 1)} and sim1 takes on values from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of mul</context>
</contexts>
<marker>Deligne, Yvon, Bimbot, 1995</marker>
<rawString>Sabine Deligne, Franois Yvon, and Fr´ed´eric Bimbot. 1995. Variable-length sequence matching for phonetic transcription using joint multigrams. In EUROSPEECH. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dreyer</author>
<author>Jason Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Latent-variable modeling of string transductions with finite-state methods.</title>
<date>2008</date>
<booktitle>In EMNLP,</booktitle>
<pages>1080--1089</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1256" citStr="Dreyer et al., 2008" startWordPosition="182" endWordPosition="185">s may perform considerably better than their unsupervised brethren and that few manually aligned training pairs suffice for them to do so. Finally, we estimate a highly significant impact of alignment quality on overall G2P transcription performance and that this relationship is linear in nature. 1 Introduction Grapheme-to-phoneme (G2P) conversion is the problem of converting a string of letters into a string of phonetic symbols. Closely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling)</context>
</contexts>
<marker>Dreyer, Smith, Eisner, 2008</marker>
<rawString>Markus Dreyer, Jason Smith, and Jason Eisner. 2008. Latent-variable modeling of string transductions with finite-state methods. In EMNLP, pages 1080– 1089. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steffen Eger</author>
</authors>
<title>S-restricted monotone alignments: Algorithm, search space, and applications. In</title>
<date>2012</date>
<booktitle>COLING’12,</booktitle>
<pages>781--798</pages>
<contexts>
<context position="9063" citStr="Eger (2012)" startWordPosition="1580" endWordPosition="1581">(1 : i) and y(1 : j) that ends in the matchup of x(q : i) with y(w : j).3 The variable Mijqw satisfies a recurrence leading to a DP algorithm, shown in Algorithm 1. The actual alignment can be found by storing pointers to the maximizing steps taken. Running time of the algorithm is O( x2 2y|S|). Note also that the sketched algorithm is supervised insofar as it assumes that the similarity values sim2(·, ·) are known. Typically, such alignment algorithms can be converted into unsupervised algorithms in which similarity measures sim are learnt iteratively, e.g., in an EM-like fashion (cf., e.g., Eger (2012), Eger (2013)); however, in this paper, we only investigate the supervised base version as indicated. 3 Related work Monotone alignments have a long tradition in NLP. The classical Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) computes the optimal alignment between two sequences when only single character matches, mismatches, and skips are allowed. It is a special case of the unigram model (1) for which S = {(1, 0), (0, 1), (1, 1)} and sim1 takes on values from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivale</context>
</contexts>
<marker>Eger, 2012</marker>
<rawString>Steffen Eger. 2012. S-restricted monotone alignments: Algorithm, search space, and applications. In COLING’12, pages 781–798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steffen Eger</author>
</authors>
<title>Sequence alignment with arbitrary steps and further generalizations, with applications to alignments in linguistics.</title>
<date>2013</date>
<journal>Inf. Sci.,</journal>
<pages>237--287</pages>
<contexts>
<context position="9076" citStr="Eger (2013)" startWordPosition="1582" endWordPosition="1583">(1 : j) that ends in the matchup of x(q : i) with y(w : j).3 The variable Mijqw satisfies a recurrence leading to a DP algorithm, shown in Algorithm 1. The actual alignment can be found by storing pointers to the maximizing steps taken. Running time of the algorithm is O( x2 2y|S|). Note also that the sketched algorithm is supervised insofar as it assumes that the similarity values sim2(·, ·) are known. Typically, such alignment algorithms can be converted into unsupervised algorithms in which similarity measures sim are learnt iteratively, e.g., in an EM-like fashion (cf., e.g., Eger (2012), Eger (2013)); however, in this paper, we only investigate the supervised base version as indicated. 3 Related work Monotone alignments have a long tradition in NLP. The classical Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) computes the optimal alignment between two sequences when only single character matches, mismatches, and skips are allowed. It is a special case of the unigram model (1) for which S = {(1, 0), (0, 1), (1, 1)} and sim1 takes on values from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edi</context>
</contexts>
<marker>Eger, 2013</marker>
<rawString>Steffen Eger. 2013. Sequence alignment with arbitrary steps and further generalizations, with applications to alignments in linguistics. Inf. Sci., 237:287–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steffen Eger</author>
</authors>
<title>Improving g2p from wiktionary and other (web) resources.</title>
<date>2015</date>
<booktitle>In Proceedings of Interspeech. accepted.</booktitle>
<contexts>
<context position="10601" citStr="Eger (2015" startWordPosition="1833" endWordPosition="1834">y-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojamarn and Kondrak (2010). There, older and specialized alignment techniques such as ALINE (Kondrak, 2000) (as well as partly heuristic/semi-automatic alignment methods) are compared with variants of the M2M alignment algorithm, which we also survey. This work does not consider supervised alignments or bigram alignments, as we do. Moreover, Jiampojamarn and Kondrak (2010) also</context>
</contexts>
<marker>Eger, 2015</marker>
<rawString>Steffen Eger. 2015a. Improving g2p from wiktionary and other (web) resources. In Proceedings of Interspeech. accepted.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Steffen Eger</author>
</authors>
<title>Multiple many-to-many sequence alignment for combining string-valued variables: A G2P experiment.</title>
<date>2015</date>
<booktitle>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL</booktitle>
<pages>909--919</pages>
<location>Beijing, China, Volume</location>
<contexts>
<context position="10601" citStr="Eger (2015" startWordPosition="1833" endWordPosition="1834">y-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojamarn and Kondrak (2010). There, older and specialized alignment techniques such as ALINE (Kondrak, 2000) (as well as partly heuristic/semi-automatic alignment methods) are compared with variants of the M2M alignment algorithm, which we also survey. This work does not consider supervised alignments or bigram alignments, as we do. Moreover, Jiampojamarn and Kondrak (2010) also</context>
</contexts>
<marker>Eger, 2015</marker>
<rawString>Steffen Eger. 2015b. Multiple many-to-many sequence alignment for combining string-valued variables: A G2P experiment. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers, pages 909–919.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Joo Graa</author>
<author>Ben Taskar</author>
</authors>
<title>Better alignments = better translations?</title>
<date>2008</date>
<pages>986--993</pages>
<editor>In Kathleen McKeown, Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui, editors, ACL,</editor>
<publisher>The Association for Computational Linguistics.</publisher>
<contexts>
<context position="12851" citStr="Ganchev et al., 2008" startWordPosition="2206" endWordPosition="2209">llow for many-to-many match-ups). The contextual dependencies in this model are set up differently from the bigram dependencies in our paper. 1177 Algorithm 1 1: procedure BIGRAM-ALIGN(x = x1 ... xn, y = y1 ... ym; 5, sime) 2: Mijqw −oc for all (i, j, q, w) E Z4 3: M0000 0 4: for i = 0 ... n do 5: for j = 0 ... m do 6: for q = 0 ... i + 1 do 7: for w = 0 ... j + 1 do 8: if (i, j, q, w) =� (0, 0, 0, 0) then 9: if (i − q + 1,j − w + 1) E 5 then 10: Mijqw= max Mq−1,w−1,q−a,w−b+5i11121 (x(q:i),y(w:j)),(x(q−a:q−1),y(w−b:w−1))) (a,b)∈S tionship between alignment quality and translation performance (Ganchev et al., 2008). In machine translation, the monotonicity assumption of string transduction does typically not hold, however, rendering alignment and translation techniques different and more heuristic in nature. 4 Data and systems 4.1 Data For English, we conduct experiments on the General American (GA) variant of the Combilex data set (Richmond et al., 2009). This contains about 128 000 grapheme-phoneme pairs as exemplified in Table 3. Importantly, Combilex provides goldstandard alignments, which we will make use of for the supervised alignment models as well as for measuring alignment quality. For German,</context>
</contexts>
<marker>Ganchev, Graa, Taskar, 2008</marker>
<rawString>Kuzman Ganchev, Joo Graa, and Ben Taskar. 2008. Better alignments = better translations? In Kathleen McKeown, Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui, editors, ACL, pages 986–993. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Thomas L Griffiths</author>
<author>Mark Johnson</author>
</authors>
<title>Contextual dependencies in unsupervised word segmentation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>673--680</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="11728" citStr="Goldwater et al. (2006)" startWordPosition="1996" endWordPosition="1999">rvised alignments or bigram alignments, as we do. Moreover, Jiampojamarn and Kondrak (2010) also evaluate the impact of alignment quality on overall G2P system accuracy by running a few experiments, finding that better alignment quality does not always translate into better G2P accuracy, but that there is a “strong correlation” between the two. We more thorougly investigate this question, using, arguably, more heterogeneous aligners, and many more experiments. We also quantitatively estimate how alignment quality influences G2P system accuracy on two different languages via linear regression. Goldwater et al. (2006) study the effect of context in (unsupervised) word/sequence segmentation, which may be considered the onedimensional specialization of sequence alignment, using a Bayesian method. They find that bigram models greatly outperform unigram models for their task. Of course, our study is also related to the field of machine translation and its studies on the rela4In Cotterell et al. (2014), context influences alignments, so that the approach goes beyond the unigram model sketched in (1) (but does not allow for many-to-many match-ups). The contextual dependencies in this model are set up differently</context>
<context position="15778" citStr="Goldwater et al., 2006" startWordPosition="2669" endWordPosition="2672"> 1)}. In contrast, the Mpaligner (Kubo et al., 2011) introduces a prior (or penalty) in the alignment model which favors ‘short’ matches (s, t) over ‘long’ ones. Finally, the Phonetisaurus aligner (Novak et al., 2012) modifies the M2M aligner by adding additional soft constraints. Our own alignment model is, as indicated, supervised. We implement a unigram alignment model where we specify sim1(u, v) as α · logp((u, v)) + Q · logp((Iu�, �v�)) +ry · logp(u) + S · logp(v). Here, logp(z) denotes the log-probability — estimated from the training data — of observing the 5See also the discussion in (Goldwater et al., 2006) for the related word segmentation problem. 1178 object z, and α, Q, ry and 6 are parameters. This specification says that the subsequences u and v are similar insofar as (i) u and v have been paired frequently in the training data, (ii) the length of u and the length of v have been paired frequently, (iii)/(iv) u/v by itself is likely. We refer to this unigram alignment model as uniα,β,γ,δ. We also implement a bigram alignment model where we specify sim2 ((u, v), (u0, v0)) as α · logp((u, v) |(u0, v0)) +Q · logp((|u|, |v|) |(|u0|, |v0|)) +ry · logp(u|u0) + 6 · logp(v|v0). Here, logp(z |z0) de</context>
</contexts>
<marker>Goldwater, Griffiths, Johnson, 2006</marker>
<rawString>Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson. 2006. Contextual dependencies in unsupervised word segmentation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 673–680, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Letter-phoneme alignment: An exploration.</title>
<date>2010</date>
<pages>780--788</pages>
<editor>In Jan Hajic, Sandra Carberry, and Stephen Clark, editors, ACL,</editor>
<publisher>The Association for Computational Linguistics.</publisher>
<contexts>
<context position="10847" citStr="Jiampojamarn and Kondrak (2010)" startWordPosition="1868" endWordPosition="1871">nen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojamarn and Kondrak (2010). There, older and specialized alignment techniques such as ALINE (Kondrak, 2000) (as well as partly heuristic/semi-automatic alignment methods) are compared with variants of the M2M alignment algorithm, which we also survey. This work does not consider supervised alignments or bigram alignments, as we do. Moreover, Jiampojamarn and Kondrak (2010) also evaluate the impact of alignment quality on overall G2P system accuracy by running a few experiments, finding that better alignment quality does not always translate into better G2P accuracy, but that there is a “strong correlation” between the </context>
</contexts>
<marker>Jiampojamarn, Kondrak, 2010</marker>
<rawString>Sittichai Jiampojamarn and Grzegorz Kondrak. 2010. Letter-phoneme alignment: An exploration. In Jan Hajic, Sandra Carberry, and Stephen Clark, editors, ACL, pages 780–788. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>372--379</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York,</location>
<contexts>
<context position="1593" citStr="Jiampojamarn et al., 2007" startWordPosition="238" endWordPosition="241"> (G2P) conversion is the problem of converting a string of letters into a string of phonetic symbols. Closely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling) module is learned on the aligned data. ph oe n i x f i n I ks Table 1: Sample monotone many-to-many alignment between x = phoenix and y = finIks. State-of-the-art alignments in G2P are characterized by the following properties: (i) Alignments are monotone in that the ordering of characters in input and output sequences is preserved by</context>
<context position="10129" citStr="Jiampojamarn et al. (2007)" startWordPosition="1754" endWordPosition="1757">, 1)} and sim1 takes on values from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram al</context>
<context position="14282" citStr="Jiampojamarn et al., 2007" startWordPosition="2419" endWordPosition="2422"> pairs in Combilex, using Combilex notation for the phoneme strings. Gold-standard alignments indicated in an intuitive manner. domly extract 3 000 G2P string pairs from CELEX (Baayen et al., 1995). We had a native speaker manually align them so that gold standard alignments are available here, too. Both data sets contain quite complex match-ups of character subsequences such as (2,3) as in English s-oi-r-ee-s/swOA-r-P-z or (4,1) as in w-eigh-t/w-P-t but the majority of match-ups are of type (1,1), (2,1), and, to a lesser degree, (1,2) and (3,1). 4.2 Alignment toolkits/models The M2M aligner (Jiampojamarn et al., 2007), which is based on EM maximum likelihood estimation of alignment parameters, is the classical unsupervised unigram many-to-many aligner in G2P. As has been pointed out (Kubo et al., 2011), M2M greatly overfits the data.5 This means that when the M2M aligner is given the freedom to align two sequences without restrictions, it matches them up as a whole. The reason is that a (probabilistic) unigram alignment model adds log-probabilities of matched-up subsequences, which, if not appropriately corrected for, makes alignments with few match-ups a priori more likely than alignments with many matchu</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 372– 379, Rochester, New York, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Joint processing and discriminative training for letter-to-phoneme conversion.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>905--913</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="1642" citStr="Jiampojamarn et al., 2008" startWordPosition="246" endWordPosition="249">string of letters into a string of phonetic symbols. Closely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling) module is learned on the aligned data. ph oe n i x f i n I ks Table 1: Sample monotone many-to-many alignment between x = phoenix and y = finIks. State-of-the-art alignments in G2P are characterized by the following properties: (i) Alignments are monotone in that the ordering of characters in input and output sequences is preserved by the alignments. Furthermore, they are many-to-ma</context>
<context position="16839" citStr="Jiampojamarn et al. (2008)" startWordPosition="2853" endWordPosition="2856">el where we specify sim2 ((u, v), (u0, v0)) as α · logp((u, v) |(u0, v0)) +Q · logp((|u|, |v|) |(|u0|, |v0|)) +ry · logp(u|u0) + 6 · logp(v|v0). Here, logp(z |z0) denotes the logarithm of the conditional probability of observing the object z following the object z0. We refer to this bigram alignment model as biα,β,γ,δ. 4.3 Transduction systems We use two string transduction systems for our experiments. The first one is DirecTL+ (Jiampojamarn et al., 2010), a discriminative string-tostring translation system incorporating joint ngram features. DirecTL+ is an extension of the model presented in Jiampojamarn et al. (2008) which treats string transduction as a source sequence segmentation and subsequent sequence labeling task. In addition, we use Phonetisaurus (Novak et al., 2012), a weighted finite state-based joint n-gram model employing recurrent neural network language model N-best rescoring in decoding. Both systems take aligned pairs of strings as input and from this construct a monotone translation model.6 4.4 Measuring alignment quality We employ two measures of alignment quality. First, we use word accuracy, defined as the fraction of correctly aligned sequence pairs in a test sample. This is a very st</context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2008</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2008. Joint processing and discriminative training for letter-to-phoneme conversion. In Proceedings of ACL-08: HLT, pages 905–913, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Integrating joint n-gram features into a discriminative training framework.</title>
<date>2010</date>
<booktitle>In HLTNAACL,</booktitle>
<pages>697--700</pages>
<contexts>
<context position="1669" citStr="Jiampojamarn et al., 2010" startWordPosition="250" endWordPosition="253">ring of phonetic symbols. Closely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling) module is learned on the aligned data. ph oe n i x f i n I ks Table 1: Sample monotone many-to-many alignment between x = phoenix and y = finIks. State-of-the-art alignments in G2P are characterized by the following properties: (i) Alignments are monotone in that the ordering of characters in input and output sequences is preserved by the alignments. Furthermore, they are many-to-many in the sense that severa</context>
<context position="10180" citStr="Jiampojamarn et al. (2010)" startWordPosition="1762" endWordPosition="1765">ing on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the m</context>
<context position="16672" citStr="Jiampojamarn et al., 2010" startWordPosition="2828" endWordPosition="2832"> of v have been paired frequently, (iii)/(iv) u/v by itself is likely. We refer to this unigram alignment model as uniα,β,γ,δ. We also implement a bigram alignment model where we specify sim2 ((u, v), (u0, v0)) as α · logp((u, v) |(u0, v0)) +Q · logp((|u|, |v|) |(|u0|, |v0|)) +ry · logp(u|u0) + 6 · logp(v|v0). Here, logp(z |z0) denotes the logarithm of the conditional probability of observing the object z following the object z0. We refer to this bigram alignment model as biα,β,γ,δ. 4.3 Transduction systems We use two string transduction systems for our experiments. The first one is DirecTL+ (Jiampojamarn et al., 2010), a discriminative string-tostring translation system incorporating joint ngram features. DirecTL+ is an extension of the model presented in Jiampojamarn et al. (2008) which treats string transduction as a source sequence segmentation and subsequent sequence labeling task. In addition, we use Phonetisaurus (Novak et al., 2012), a weighted finite state-based joint n-gram model employing recurrent neural network language model N-best rescoring in decoding. Both systems take aligned pairs of strings as input and from this construct a monotone translation model.6 4.4 Measuring alignment quality We</context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2010</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2010. Integrating joint n-gram features into a discriminative training framework. In HLTNAACL, pages 697–700. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>A new algorithm for the alignment of phonetic sequences.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL</booktitle>
<pages>288--295</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10928" citStr="Kondrak, 2000" startWordPosition="1881" endWordPosition="1882">has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojamarn and Kondrak (2010). There, older and specialized alignment techniques such as ALINE (Kondrak, 2000) (as well as partly heuristic/semi-automatic alignment methods) are compared with variants of the M2M alignment algorithm, which we also survey. This work does not consider supervised alignments or bigram alignments, as we do. Moreover, Jiampojamarn and Kondrak (2010) also evaluate the impact of alignment quality on overall G2P system accuracy by running a few experiments, finding that better alignment quality does not always translate into better G2P accuracy, but that there is a “strong correlation” between the two. We more thorougly investigate this question, using, arguably, more heterogen</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Grzegorz Kondrak. 2000. A new algorithm for the alignment of phonetic sequences. In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL 2000, pages 288–295, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keigo Kubo</author>
<author>Hiromichi Kawanami</author>
<author>Hiroshi Saruwatari</author>
<author>Kiyohiro Shikano</author>
</authors>
<title>Unconstrained many-to-many alignment for automatic pronunciation annotation.</title>
<date>2011</date>
<booktitle>In Proceedings of Asia-Pacific Signal and Information Processing Association Annual Summit and Conference</booktitle>
<contexts>
<context position="14470" citStr="Kubo et al., 2011" startWordPosition="2450" endWordPosition="2453">). We had a native speaker manually align them so that gold standard alignments are available here, too. Both data sets contain quite complex match-ups of character subsequences such as (2,3) as in English s-oi-r-ee-s/swOA-r-P-z or (4,1) as in w-eigh-t/w-P-t but the majority of match-ups are of type (1,1), (2,1), and, to a lesser degree, (1,2) and (3,1). 4.2 Alignment toolkits/models The M2M aligner (Jiampojamarn et al., 2007), which is based on EM maximum likelihood estimation of alignment parameters, is the classical unsupervised unigram many-to-many aligner in G2P. As has been pointed out (Kubo et al., 2011), M2M greatly overfits the data.5 This means that when the M2M aligner is given the freedom to align two sequences without restrictions, it matches them up as a whole. The reason is that a (probabilistic) unigram alignment model adds log-probabilities of matched-up subsequences, which, if not appropriately corrected for, makes alignments with few match-ups a priori more likely than alignments with many matchups, when probabilities of individual match-ups are uniformly or randomly initialized (as is typically the case for EM maximum likelihood estimation in unsupervised models). To address this</context>
</contexts>
<marker>Kubo, Kawanami, Saruwatari, Shikano, 2011</marker>
<rawString>Keigo Kubo, Hiromichi Kawanami, Hiroshi Saruwatari, and Kiyohiro Shikano. 2011. Unconstrained many-to-many alignment for automatic pronunciation annotation. In Proceedings of Asia-Pacific Signal and Information Processing Association Annual Summit and Conference 2011 (APSIPA2011), October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Levenshtein</author>
</authors>
<title>Binary Codes Capable of Correcting Deletions, Insertions and Reversals. Soviet Physics Doklady,</title>
<date>1966</date>
<pages>10--707</pages>
<contexts>
<context position="9714" citStr="Levenshtein, 1966" startWordPosition="1685" endWordPosition="1686">paper, we only investigate the supervised base version as indicated. 3 Related work Monotone alignments have a long tradition in NLP. The classical Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) computes the optimal alignment between two sequences when only single character matches, mismatches, and skips are allowed. It is a special case of the unigram model (1) for which S = {(1, 0), (0, 1), (1, 1)} and sim1 takes on values from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner </context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>VI Levenshtein. 1966. Binary Codes Capable of Correcting Deletions, Insertions and Reversals. Soviet Physics Doklady, 10:707.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Maosong Sun</author>
</authors>
<title>Contrastive unsupervised word alignment with non-local features.</title>
<date>2015</date>
<booktitle>In Proceedings ofAAAI</booktitle>
<contexts>
<context position="4412" citStr="Liu and Sun, 2015" startWordPosition="707" endWordPosition="710">ls in G2P. We investigate whether there are phenomena in G2P that require bigram alignment models and, more generally, whether bigram alignment models produce better alignments — with respect to a human gold standard — than unigram alignment models within the G2P setting. We do so, secondly, in a supervised setting where the model learns from gold-standard alignments. While this may seem an odd scenario at first sight, modern alignment toolkits in the related field of machine translation typically include the possibility to learn both in a supervised and unsupervised manner (Liu et al., 2010; Liu and Sun, 2015). The rationale behind supervised learning models may be that they perform better than unsupervised models, and if alignment quality has a large impact upon subsequent string translation performance, then a supervised model may be a suitable alternative. Thirdly, we investigate how alignment quality affects overall G2P performance. This allows us to address whether it is worthwhile to work on better alignment models, which bigram and supervised alignment models promise to be. To our knowledge, all three outlined aspects of alignments — bigram models, supervised learning, and systematically est</context>
</contexts>
<marker>Liu, Sun, 2015</marker>
<rawString>Yang Liu and Maosong Sun. 2015. Contrastive unsupervised word alignment with non-local features. In Proceedings ofAAAI 2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Discriminative word alignment by linear modeling. Computational Linguistics,</title>
<date>2010</date>
<pages>303--339</pages>
<contexts>
<context position="4392" citStr="Liu et al., 2010" startWordPosition="703" endWordPosition="706">ram alignment models in G2P. We investigate whether there are phenomena in G2P that require bigram alignment models and, more generally, whether bigram alignment models produce better alignments — with respect to a human gold standard — than unigram alignment models within the G2P setting. We do so, secondly, in a supervised setting where the model learns from gold-standard alignments. While this may seem an odd scenario at first sight, modern alignment toolkits in the related field of machine translation typically include the possibility to learn both in a supervised and unsupervised manner (Liu et al., 2010; Liu and Sun, 2015). The rationale behind supervised learning models may be that they perform better than unsupervised models, and if alignment quality has a large impact upon subsequent string translation performance, then a supervised model may be a suitable alternative. Thirdly, we investigate how alignment quality affects overall G2P performance. This allows us to address whether it is worthwhile to work on better alignment models, which bigram and supervised alignment models promise to be. To our knowledge, all three outlined aspects of alignments — bigram models, supervised learning, an</context>
</contexts>
<marker>Liu, Liu, Lin, 2010</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2010. Discriminative word alignment by linear modeling. Computational Linguistics, pages 303–339.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saul B Needleman</author>
<author>Christian D Wunsch</author>
</authors>
<title>A general method applicable to the search for similarities in the amino acid sequence of two proteins.</title>
<date>1970</date>
<journal>Journal of Molecular Biology,</journal>
<volume>48</volume>
<issue>3</issue>
<pages>453</pages>
<contexts>
<context position="9299" citStr="Needleman and Wunsch, 1970" startWordPosition="1615" endWordPosition="1618">o the maximizing steps taken. Running time of the algorithm is O( x2 2y|S|). Note also that the sketched algorithm is supervised insofar as it assumes that the similarity values sim2(·, ·) are known. Typically, such alignment algorithms can be converted into unsupervised algorithms in which similarity measures sim are learnt iteratively, e.g., in an EM-like fashion (cf., e.g., Eger (2012), Eger (2013)); however, in this paper, we only investigate the supervised base version as indicated. 3 Related work Monotone alignments have a long tradition in NLP. The classical Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) computes the optimal alignment between two sequences when only single character matches, mismatches, and skips are allowed. It is a special case of the unigram model (1) for which S = {(1, 0), (0, 1), (1, 1)} and sim1 takes on values from {0, −1}, depending on whether compared subsequences match or not. As is well-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · </context>
</contexts>
<marker>Needleman, Wunsch, 1970</marker>
<rawString>Saul B. Needleman and Christian D. Wunsch. 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 48(3):443– 453, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef R Novak</author>
<author>Nobuaki Minematsu</author>
<author>Keikichi Hirose</author>
</authors>
<title>WFST-based grapheme-to-phoneme conversion: Open source tools for alignment, model-building and decoding.</title>
<date>2012</date>
<booktitle>In Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing,</booktitle>
<pages>45--49</pages>
<institution>Donostia–San Sebastin, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="1690" citStr="Novak et al., 2012" startWordPosition="254" endWordPosition="257">losely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a subsequent (e.g., sequence labeling) module is learned on the aligned data. ph oe n i x f i n I ks Table 1: Sample monotone many-to-many alignment between x = phoenix and y = finIks. State-of-the-art alignments in G2P are characterized by the following properties: (i) Alignments are monotone in that the ordering of characters in input and output sequences is preserved by the alignments. Furthermore, they are many-to-many in the sense that several x sequence characte</context>
<context position="15372" citStr="Novak et al., 2012" startWordPosition="2597" endWordPosition="2600">ch, if not appropriately corrected for, makes alignments with few match-ups a priori more likely than alignments with many matchups, when probabilities of individual match-ups are uniformly or randomly initialized (as is typically the case for EM maximum likelihood estimation in unsupervised models). To address this, M2M must artifically restrain, in our language, the set 5 to be 1(1,1), (1, 2), (2, 1)}. In contrast, the Mpaligner (Kubo et al., 2011) introduces a prior (or penalty) in the alignment model which favors ‘short’ matches (s, t) over ‘long’ ones. Finally, the Phonetisaurus aligner (Novak et al., 2012) modifies the M2M aligner by adding additional soft constraints. Our own alignment model is, as indicated, supervised. We implement a unigram alignment model where we specify sim1(u, v) as α · logp((u, v)) + Q · logp((Iu�, �v�)) +ry · logp(u) + S · logp(v). Here, logp(z) denotes the log-probability — estimated from the training data — of observing the 5See also the discussion in (Goldwater et al., 2006) for the related word segmentation problem. 1178 object z, and α, Q, ry and 6 are parameters. This specification says that the subsequences u and v are similar insofar as (i) u and v have been p</context>
<context position="17000" citStr="Novak et al., 2012" startWordPosition="2878" endWordPosition="2881">es the logarithm of the conditional probability of observing the object z following the object z0. We refer to this bigram alignment model as biα,β,γ,δ. 4.3 Transduction systems We use two string transduction systems for our experiments. The first one is DirecTL+ (Jiampojamarn et al., 2010), a discriminative string-tostring translation system incorporating joint ngram features. DirecTL+ is an extension of the model presented in Jiampojamarn et al. (2008) which treats string transduction as a source sequence segmentation and subsequent sequence labeling task. In addition, we use Phonetisaurus (Novak et al., 2012), a weighted finite state-based joint n-gram model employing recurrent neural network language model N-best rescoring in decoding. Both systems take aligned pairs of strings as input and from this construct a monotone translation model.6 4.4 Measuring alignment quality We employ two measures of alignment quality. First, we use word accuracy, defined as the fraction of correctly aligned sequence pairs in a test sample. This is a very strict measure that penalizes even tiny deviations from the gold standard. Additionally, we measure the edit distance between the true alignment Ax,y and the predi</context>
</contexts>
<marker>Novak, Minematsu, Hirose, 2012</marker>
<rawString>Josef R. Novak, Nobuaki Minematsu, and Keikichi Hirose. 2012. WFST-based grapheme-to-phoneme conversion: Open source tools for alignment, model-building and decoding. In Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 45–49, Donostia–San Sebastin, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Pervouchine</author>
<author>Haizhou Li</author>
<author>Bo Lin</author>
</authors>
<title>Transliteration alignment.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09,</booktitle>
<pages>136--144</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29283" citStr="Pervouchine et al., 2009" startWordPosition="4864" endWordPosition="4867">f G2P accuracy on edit distance and further variables. For German, DirecTL+ is omitted due to its long run times. So far, we have estimated the effects of alignment quality on overall G2P system performance for a fixed size of training data, namely, 5 000 aligned string pairs. To see whether this relationship changes when we vary the amount of training data, we run several more experiments. In these, we align training sets of sizes 100, 500, 10These include binary dummy variables for the specific systems as well as alignment consistency and its square — measured in conditional entropy H(YIX) (Pervouchine et al., 2009) — in the regression. 1000, 2 000, 10 000, 20 000, 40 000 and 60 000 via our several alignment systems. Then we feed the aligned data to the Phonetisaurus system (we omit DirecTL+ here because of its long run times) and compute overall G2P accuracy on a disjoint test set of size 28 000 approximately. This time, we only use the unsupervised aligners and the gold-standard alignments directly, omitting results for our various supervised aligners. Note, however, that these aligners could, in principle, imitate the gold-standard alignments with a very high degree of precision, as previously seen. T</context>
</contexts>
<marker>Pervouchine, Li, Lin, 2009</marker>
<rawString>Vladimir Pervouchine, Haizhou Li, and Bo Lin. 2009. Transliteration alignment. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09, pages 136–144, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kanishka Rao</author>
</authors>
<title>Fuchun Peng, Hasim Sak, and Franoise Beaufays.</title>
<date>2015</date>
<booktitle>In ICASSP</booktitle>
<marker>Rao, 2015</marker>
<rawString>Kanishka Rao, Fuchun Peng, Hasim Sak, and Franoise Beaufays. 2015. Grapheme-to-phoneme conversion using long short-term memory recurrent neural networks. In ICASSP 2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Korin Richmond</author>
<author>Robert A J Clark</author>
<author>Susan Fitt</author>
</authors>
<date>2009</date>
<booktitle>Robust LTS rules with the Combilex speech technology lexicon. In INTERSPEECH,</booktitle>
<pages>1295--1298</pages>
<publisher>ISCA.</publisher>
<contexts>
<context position="13198" citStr="Richmond et al., 2009" startWordPosition="2260" endWordPosition="2263"> for w = 0 ... j + 1 do 8: if (i, j, q, w) =� (0, 0, 0, 0) then 9: if (i − q + 1,j − w + 1) E 5 then 10: Mijqw= max Mq−1,w−1,q−a,w−b+5i11121 (x(q:i),y(w:j)),(x(q−a:q−1),y(w−b:w−1))) (a,b)∈S tionship between alignment quality and translation performance (Ganchev et al., 2008). In machine translation, the monotonicity assumption of string transduction does typically not hold, however, rendering alignment and translation techniques different and more heuristic in nature. 4 Data and systems 4.1 Data For English, we conduct experiments on the General American (GA) variant of the Combilex data set (Richmond et al., 2009). This contains about 128 000 grapheme-phoneme pairs as exemplified in Table 3. Importantly, Combilex provides goldstandard alignments, which we will make use of for the supervised alignment models as well as for measuring alignment quality. For German, we ranGrapheme string Phoneme string g-e-n-e-r-a-l dZ-E-n-@-r-@-l p-r-o-b-a-t-ion-a-r-y p-r-@U-b-eI-S-n=-E-r-i w-oo-d-e-d w-U-d-@-d M-u-r-m-a-n-s-k m-U@-r-m-A-n-s-k Table 3: Sample grapheme-phoneme string pairs in Combilex, using Combilex notation for the phoneme strings. Gold-standard alignments indicated in an intuitive manner. domly extract </context>
</contexts>
<marker>Richmond, Clark, Fitt, 2009</marker>
<rawString>Korin Richmond, Robert A. J. Clark, and Susan Fitt. 2009. Robust LTS rules with the Combilex speech technology lexicon. In INTERSPEECH, pages 1295–1298. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Sven Ristad</author>
<author>Peter N Yianilos</author>
</authors>
<title>Learning string-edit distance.</title>
<date>1998</date>
<journal>IEEE Trans. Pattern Anal. Mach. Intell.,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="10369" citStr="Ristad and Yianilos (1998)" startWordPosition="1789" endWordPosition="1792">of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojamarn and Kondrak (2010). There, older and specialized alignment techniques such as ALINE (Kondrak, 2000) (as well as partly heuristic/semi-automa</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>Eric Sven Ristad and Peter N. Yianilos. 1998. Learning string-edit distance. IEEE Trans. Pattern Anal. Mach. Intell., 20(5):522–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tarek Sherif</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Substringbased transliteration. In</title>
<date>2007</date>
<editor>John A. Carroll, Antal van den Bosch, and Annie Zaenen, editors, ACL.</editor>
<publisher>The Association for Computational Linguistics.</publisher>
<contexts>
<context position="1219" citStr="Sherif and Kondrak, 2007" startWordPosition="177" endWordPosition="180">e find that supervised alignment techniques may perform considerably better than their unsupervised brethren and that few manually aligned training pairs suffice for them to do so. Finally, we estimate a highly significant impact of alignment quality on overall G2P transcription performance and that this relationship is linear in nature. 1 Introduction Grapheme-to-phoneme (G2P) conversion is the problem of converting a string of letters into a string of phonetic symbols. Closely related to G2P are other string transduction problems in natural language processing (NLP) such as transliteration (Sherif and Kondrak, 2007), lemmatization (Dreyer et al., 2008), and spelling error correction (Brill and Moore, 2000). The classical learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. While there are exceptions (e.g., (Rao et al., 2015)), most state-of-the-art modelings (e.g., (Jiampojamarn et al., 2007; Bisani and Ney, 2008; Jiampojamarn et al., 2008; Jiampojamarn et al., 2010; Novak et al., 2012)) view string transduction as a two-stage process in which string pairs (x, y) in the training data are first aligned, and then a</context>
</contexts>
<marker>Sherif, Kondrak, 2007</marker>
<rawString>Tarek Sherif and Grzegorz Kondrak. 2007. Substringbased transliteration. In John A. Carroll, Antal van den Bosch, and Annie Zaenen, editors, ACL. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esko Ukkonen</author>
</authors>
<title>Algorithms for approximate string matching.</title>
<date>1985</date>
<journal>Information and Control,</journal>
<volume>64</volume>
<pages>118</pages>
<contexts>
<context position="10226" citStr="Ukkonen (1985)" startWordPosition="1770" endWordPosition="1771">ell-known, this alignment specification is equivalent to the edit distance problem (Levenshtein, 1966) in which the minimal number of insertions, deletions and substitutions is sought that transforms one string 3We denote by x(a : b) the substring xaxa+1 · · · xb of the string x1x2 · · · xt. into another. Substring-to-substring edit operations — or equivalently, (monotone) many-tomany alignments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojama</context>
</contexts>
<marker>Ukkonen, 1985</marker>
<rawString>Esko Ukkonen. 1985. Algorithms for approximate string matching. Information and Control, 64:100– 118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean V´eronis</author>
</authors>
<title>Computerized correction of phonographic errors.</title>
<date>1988</date>
<journal>Computers and the Humanities,</journal>
<volume>22</volume>
<issue>1</issue>
<marker>V´eronis, 1988</marker>
<rawString>Jean V´eronis. 1988. Computerized correction of phonographic errors. Computers and the Humanities, 22(1):43–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Yao</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Joint generation of transliterations from multiple representations.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>943--952</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Denver, Colorado, May–June.</location>
<contexts>
<context position="10627" citStr="Yao and Kondrak (2015)" startWordPosition="1835" endWordPosition="1838">ments — have appeared in the NLP context, e.g., in Deligne et al. (1995), Brill and Moore (2000), Jiampojamarn et al. (2007), Bisani and Ney (2008), Jiampojamarn et al. (2010), or, significantly earlier, in Ukkonen (1985), V´eronis (1988). Learning edit distance/monotone alignments in an unsupervised manner has been the topic of, e.g., Ristad and Yianilos (1998), Cotterell et al. (2014), besides the works already mentioned. All of these approaches are special cases of our unigram model — i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and sim1.4 Eger (2015b), Yao and Kondrak (2015), and Eger (2015a) generalize to alignments of multiple strings, but likewise only consider unigram alignment models in their experiments. Probably the most closely related work to ours is Jiampojamarn and Kondrak (2010). There, older and specialized alignment techniques such as ALINE (Kondrak, 2000) (as well as partly heuristic/semi-automatic alignment methods) are compared with variants of the M2M alignment algorithm, which we also survey. This work does not consider supervised alignments or bigram alignments, as we do. Moreover, Jiampojamarn and Kondrak (2010) also evaluate the impact of al</context>
</contexts>
<marker>Yao, Kondrak, 2015</marker>
<rawString>Lei Yao and Grzegorz Kondrak. 2015. Joint generation of transliterations from multiple representations. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 943–952, Denver, Colorado, May–June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>