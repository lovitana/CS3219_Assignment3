<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.643699">
Leave-one-out Word Alignment without Garbage Collector Effects
Xiaolin Wang Masao Utiyama Andrew Finch
</title>
<author confidence="0.948566">
Taro Watanabe∗ Eiichiro Sumita
</author>
<affiliation confidence="0.9511465">
Advanced Translation Research and Development Promotion Center
National Institute of Information and Communications Technology, Japan
</affiliation>
<email confidence="0.979888">
{xiaolin.wang,mutiyama,andrew.finch,eiichiro.sumita}@nict.go.jp
tarow@google.com
</email>
<sectionHeader confidence="0.994638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999135769230769">
Expectation-maximization algorithms,
such as those implemented in GIZA++
pervade the field of unsupervised word
alignment. However, these algorithms
have a problem of over-fitting, leading to
“garbage collector effects,” where rare
words tend to be erroneously aligned
to untranslated words. This paper
proposes a leave-one-out expectation-
maximization algorithm for unsupervised
word alignment to address this prob-
lem. The proposed method excludes
information derived from the alignment
of a sentence pair from the alignment
models used to align it. This prevents
erroneous alignments within a sentence
pair from supporting themselves. Ex-
perimental results on Chinese-English
and Japanese-English corpora show that
the F1, precision and recall of alignment
were consistently increased by 5.0% –
17.2%, and BLEU scores of end-to-end
translation were raised by 0.03 – 1.30.
The proposed method also outperformed
l0-normalized GIZA++ and Kneser-Ney
smoothed GIZA++.
</bodyText>
<sectionHeader confidence="0.998859" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9968258125">
Unsupervised word alignment (WA) on bilingual
sentence pairs serves as an essential foundation
for building most statistical machine translation
(SMT) systems. A lot of methods have been pro-
posed to raise the accuracy of WA in an effort to
improve end-to-end translation quality. This pa-
per contributes to this effort through refining the
widely used expectation-maximization (EM) algo-
rithm for WA (Dempster et al., 1977; Brown et al.,
1993b; Och and Ney, 2000).
∗ The author now is affiliated with Google, Japan.
The EM algorithm for WA has a great influ-
ence in SMT. Many well-known toolkits includ-
ing GIZA++ (Och and Ney, 2003), the Berkeley
Aligner (Liang et al., 2006; DeNero and Klein,
2007), Fast Align (Dyer et al., 2013) and SyM-
GIZA++ (Junczys-Dowmunt and Sza, 2012), all
employ this algorithm. GIZA++ in particular is
frequently used in systems participating in many
shared tasks (Goto et al., 2011; Cettolo et al.,
2013; Bojar et al., 2013).
However, the EM algorithm for WA is well-
known for introducing “garbage collector ef-
fects.” Rare words have a tendency to collect
garbage, that is they have a tendency to be erro-
neously aligned to untranslated words (Brown et
al., 1993a; Moore, 2004; Ganchev et al., 2008;
V Grac¸a et al., 2010). Figure 1(a) shows a real
sentence pair, denoted s, from the GALE Chinese-
English Word Alignment and Tagging Training
corpus (GALE WA corpus)1 with it’s human-
annotated word alignment. The Chinese word
“HE ZHANG,” denoted wr, which means river
custodian, only occurs once in the whole corpus.
We performed EM training using GIZA++ on this
corpus concatenated with 442,967 training sen-
tence pairs from the NIST Open Machine Trans-
lation (OpenMT) 2006 evaluation2. The resulting
alignment is shown in Figure 1(b). It can be seen
that wr is erroneously aligned to multiple English
words.
To find the cause of this, we checked the align-
ments in each iteration i of s, denoted as. We
found that in a��, wr together with the other
source-side words were aligned with uniform
probability to all the target-side words since the
alignment models provided no prior information.
However, in a$ , wr became erroneously aligned,
</bodyText>
<footnote confidence="0.9991634">
1Released by Linguistic Data Consortium, catalog
number LDC2012T16, LDC2012T20, LDC2012T24 and
LDC2013T05.
2http://www.itl.nist.gov/iad/mig/
tests/mt/2006/
</footnote>
<page confidence="0.872825">
1817
</page>
<note confidence="0.985617">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1817–1827,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999947416666667">
because the alignment distribution3 of wr was
only learned from a&apos;, thus consisted of non-zero
values only for generating the target-side words in
s. Therefore, the alignment probabilities from the
rare word wr to the unaligned words in s were ex-
traordinarily high, since almost all of the proba-
bility mass was distributed among them. In other
words, the story behind these garbage collector ef-
fects is that erroneous alignments are able to pro-
vide support for themselves; the probability distri-
bution learned only from s is re-applied to s. In
this way, these “garbage collector effects” are a
form of over-fitting.
Motivated by this observation, we propose a
leave-one-out EM algorithm for WA in this pa-
per. Recently this technique has been applied
to avoid over-fitting in kernel density estima-
tion (Roux and Bach, 2011); instead of performing
maximum likelihood estimation, maximum leave-
one-out likelihood estimation is performed. Fig-
ure 1(c) shows the effect of using our technique
on the example. The garbage collection has not
occurred, and the alignment of the word “HE
ZHANG” is identical to the human annotation.
</bodyText>
<sectionHeader confidence="0.999791" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999920363636363">
The most related work to this paper is train-
ing phrase translation models with leave-one-out
forced alignment (Wuebker et al., 2010; Wuebker
et al., 2012). The differences are that their work
operates at the phrase level, and their aim is to im-
prove translation models; while our work operates
at the word level, and our aim is to provide better
word alignment. As word alignment is a founda-
tion of most MT systems, our method have a wider
application.
Recently, better estimation methods during the
maximization step of EM have been proposed
to avoid the over-fitting in WA, such as using
Kneser-Ney Smoothing to back-off the expected
counts (Zhang and Chiang, 2014) or integrating
the smoothed l0 prior to the estimation of prob-
ability (Vaswani et al., 2012). Our work differs
from theirs by addressing the over-fitting directly
in the EM algorithm by adopting a leave-one-out
approach.
Bayesian methods (Gilks et al., 1996; Andrieu
et al., 2003; DeNero et al., 2008; Neubig et al.,
</bodyText>
<footnote confidence="0.99712125">
3The probability distribution of generating target lan-
guage words from w,.. The description here is only based on
IBM model1 for simplicity, and the other alignment models
are similar.
</footnote>
<bodyText confidence="0.361839">
he himself was then appointed river custodian of panlong river
</bodyText>
<figure confidence="0.82134125">
4ft *A Y1 q 39)2rc XK-
HE MANG
he himself was then appointed river custodian of panlong river
4ft *A Y1 q 39)2rc XK-
HE MANG
he himself was then appointed river custodian of panlong river
4ft *A Y1 q 39)2rc XK-
HE MANG
</figure>
<figureCaption confidence="0.875245666666667">
Figure 1: Examples of supervised word alignment.
(a) gold alignment; (b) standard EM (GIZA++);
(c) Leave-one-out alignment (proposed).
</figureCaption>
<bodyText confidence="0.77987025">
2011), also attempt to address the issue of over-
fitting, however EM algorithms related to the pro-
posed method have been shown to be more effi-
cient (Wang et al., 2014).
</bodyText>
<sectionHeader confidence="0.996896" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.9998066">
This section first formulates the standard EM for
WA, then presents the leave-one-out EM for WA,
and finally briefly discusses handling singletons
and effecient implementation. The main notation
used in this section is shown in Table 1.
</bodyText>
<subsectionHeader confidence="0.9983055">
3.1 Standard EM for IBM Models 1, 2 and
HMM Model
</subsectionHeader>
<bodyText confidence="0.9969076">
To perform WA through EM, the parallel corpus
is taken as observed data, the alignments are taken
as latent data. In order to maximize the likelihood
of the alignment model 0 given the data S, the fol-
lowing two steps are conducted iteratively (Brown
et al., 1993b; Och and Ney, 2000; Och and Ney,
2003),
Expectation Step (E step): calculating the con-
ditional probability of alignments for each sen-
tence pair,
</bodyText>
<equation confidence="0.999711">
P(a|s,e) = HJj=1 eali(aj|aj−1,I)0lex(fj|eaj),(1)
</equation>
<bodyText confidence="0.9852625">
where Bali(i|i′, I) is the alignment probability and
Olex(f|e) is the translation probability. Note that
</bodyText>
<page confidence="0.977001">
1818
</page>
<figure confidence="0.907594166666667">
a foreign sentence (f1, ... , fJ)
an English sentence (e1, ... , eI)
a sentence pair (f, e)
an alignment (a1, ... , aJ) where fj is
aligned to eaj
a list of the indexes of the foreign words
</figure>
<figureCaption confidence="0.303809">
which are aligned to ei
</figureCaption>
<bodyText confidence="0.73581525">
the index of the k-th foreign word
which is aligned to ei
is the average of all elements in Bi
the largest index of an English word
</bodyText>
<figure confidence="0.629909555555556">
s.t. ρi &lt; i and |Bρi |&gt; 0
the fertility of ei
the word class of ei
an probabilistic model
a leave-one-out probabilistic model for
s
the number of times that an event x
happens in (s, a)
the marginal number of times that an
</figure>
<tableCaption confidence="0.6677105">
event x happens in s
Table 1: Main Notation. Note that Nx(s) =
</tableCaption>
<equation confidence="0.665826">
P
a nx(s, a)P(a|s). In practical calculation, for
</equation>
<bodyText confidence="0.900297125">
IBM models 1, 2 and HMM model, this summa-
tion is performed by dynamic programming; for
IBM model 4, it is performed approximately us-
ing the best alignment and its neighbors.
(1) is a general form for IBM model 1, model 2
and the HMM model.
Maximization step (M step): re-estimating the
probability models,
</bodyText>
<equation confidence="0.99559425">
θali(i|i′, I) ← Ps Ni|i′,I (s) (2)
Ps Ni′,I(s)
θlex(f |e) ←Ps Nf |e (s) (3)
Ps ne(s)
</equation>
<bodyText confidence="0.999958428571429">
where Ni′,I(s) is the marginal number of times ei′
is aligned to some foreign word if the length of e is
I, or 0 otherwise; Ni|i′,I(s) is the marginal number
of times the next alignment position after i′ is i in
a if the length of e is I, or 0 otherwise; ne(s) is the
count of e in e; Nf|e(s, a) is the marginal number
of times e is aligned to f.
</bodyText>
<subsectionHeader confidence="0.960417">
3.2 Leave-one-out EM for IBM Models 1, 2
and HMM Model
</subsectionHeader>
<bodyText confidence="0.9992151">
Leave-one-out EM for WA differs from standard
EM in the way the alignment and translation prob-
abilities are calculated. Each sentence pair will
have its own alignment and translation probability
models calculated by excluding the sentence pair
itself. More formally, leave-one-out EM for WA
are formulated as follows,
Leave-one-out E step: employing leave-one-
out models for each s to calculate the conditional
probability of alignments
</bodyText>
<equation confidence="0.992449">
P(a|s,θ¯s) = QJ j=1 θ¯s ali(aj|aj−1,I)θ¯s lex(fj|eaj),(4)
</equation>
<bodyText confidence="0.961626833333333">
where θ¯sali(i|i′, I) and θlex
¯s(fj  |eaj) are the leave-
one-out alignment probability and translation
probability, respectively.
Leave-one-out M step: re-estimating leave-
one-out probability models,
</bodyText>
<equation confidence="0.988843">
P
s′6=s Ni|i′,I(s′)
θ¯s ali(i|i′, I) ← Ps′6=s Ni′,I(s′) (5)
P
s′6=s Nf|e(s′)
θ¯s lex(f|e) ← P (6)
s′6=s ne(s′) .
</equation>
<subsectionHeader confidence="0.981728">
3.3 Standard EM for IBM Model 4
</subsectionHeader>
<bodyText confidence="0.999871">
The framework of the standard EM for IBM
Model 4 is similar with the one for IBM Models 1,
2 and HMM Model, but the calculation of align-
ment probability is more complicated.
E step: calculating the conditional probabil-
ity through the reverted alignment (Och and Ney,
2003),
</bodyText>
<equation confidence="0.997372">
P(a|s, θ) = P(B0|B1,... , BI)·
θlex(fj|ei), (7)
</equation>
<bodyText confidence="0.999875857142857">
where B0 means the set of foreign words aligned
with the empty word; P(B0|B1, ... , BI) is as-
sumed to be a binomial distribution for the size
of B0 (Brown et al., 1993b) or an modified distri-
bution to relieve deficiency (Och and Ney, 2003).
The distribution P(Bi|Bi−1, ei) is decomposed
as
</bodyText>
<equation confidence="0.9961926">
P(Bi|Bi−1, ei) = θfer(φi|ei)·
φi
θhea(Bi,1 − Bρi|Eρi) · Y θoth(Bi,k − Bi,k−1),
k=2
(8)
</equation>
<bodyText confidence="0.9999785">
where θfer is a fertility model; θhea is a probabil-
ity model for the head (first) aligned foreign word;
θoth is a probability model for the other aligned
foreign words. θhea is assumed to be conditioned
</bodyText>
<figure confidence="0.959767230769231">
f
e
s
a
Bi
Bi,k
Bi
ρi
φi
Ei
θ·
θ s
·
</figure>
<equation confidence="0.7314185">
nx(s, a)
Nx(s)
YI P(Bi|Bi−1, ei) ·
i=1
YI
i=1
Y
j∈Bi
</equation>
<page confidence="0.955208">
1819
</page>
<bodyText confidence="0.8744015">
on the word class Eρi, following the paper of
(Och and Ney, 2003) and the implementation of
GIZA++ and CICADA.
M step: re-estimating the probability models,
</bodyText>
<equation confidence="0.9960995">
θfer(φ|e) Ps Nφ|e (s) ← (9)
Ps Pφ′ Nφ′ |e (s)
PsNhea
Δi|E(s)
θhea(Δi|E) ← P PΔi′ Nhea
Δi′|E(s) (10)
s
PsNoth
Δi (s)
θoth(Δi) ← P PΔi′ Noth
Δi′(s), (11)
s
</equation>
<bodyText confidence="0.950856">
where Δi is a difference of the indexes of two for-
eign words.
</bodyText>
<subsectionHeader confidence="0.905537">
3.4 Leave-one-out EM for IBM Model 4
</subsectionHeader>
<bodyText confidence="0.999511333333333">
The leave-one-out treatment were applied to the
three component probability models θfer, θhea and
θoth of IBM model 4.
Leave-one-out E step: calculating the condi-
tional probability through leave-one-out probabil-
ity models
</bodyText>
<equation confidence="0.781281">
P(a|s, θ s) = P(B0|B1, ... , BI)·
</equation>
<bodyText confidence="0.731886">
Leave-one-out M step: re-estimating the leave-
one-out probability models,
</bodyText>
<equation confidence="0.966034545454545">
P
s′6=s Nφ|e(s′)
θ¯s fer(φ|e) ← P Pφ′ Nφ′|e(s′) (14)
s′6=s P s′6=s
Nhea Δi|E(s′)
θ¯s hea(Δi|E) ← P PΔi′ Nhea
Δi′|E(s′) (15)
s′6=s P s′6=sNoth Δi (s′)
θ¯s oth(Δi) ← P PΔi′ Noth
Δi′(s′). (16)
s′6=s
</equation>
<subsectionHeader confidence="0.986597">
3.5 Handling Singletons
</subsectionHeader>
<bodyText confidence="0.999930642857143">
Singletons are the words that occur only once in
corpora. Singletons cause problems when apply-
ing leave-one-out to lexicalized models such as the
denominators become zero, thus the probabilities
are undefined.
For singletons, there is no prior information to
guide their alignment, so we back off to uniform
distributions. In that case, the alignments are pri-
marily determined by the rest of the sentence.
In addition, singletons can be in the target side
of the translation model θ¯slex. In that case, the prob-
abilities become zero. This is handled by setting a
minimum probability value of 1.0 × 10−12, which
was decided by pilot experiments.
</bodyText>
<subsectionHeader confidence="0.996326">
3.6 Implementation Details
</subsectionHeader>
<bodyText confidence="0.999638">
To alleviate memory requirements and increase
speed, our implementation did not build or store
the local alignment models explicitly for each sen-
tence pair. The following formula was used to effi-
ciently calculate (5), (6) and (14–16) to build tem-
porary probability models,
</bodyText>
<equation confidence="0.9962405">
X Nx(s′) = ( X Nx(s′)) − Nx(s), (17)
s′6=s s′
</equation>
<bodyText confidence="0.994238571428571">
where x is a alignment event. Our implemen-
tation maintained global counts of all alignment
events Ps′ Nx(s′), and (considerably smaller) lo-
cal counts Nx(s) from each sentence pair s.
Take the translation model θ¯slex for example. For
a sentence pair s = (f1 ... fJ, e1 ... eI), it is cau-
clulated as,
</bodyText>
<equation confidence="0.712263727272727">
θ¯slex(fj|ei) = (Ps′ N(fj|ei)(s′)) − N(fj|ei)(s).
(Ps′ nei (s′)) − nei (s)
(18)
P The global counts to be maintained are
are P
s′ N(fj|ei)(s′) and nei(s′), and the local counts
s N(fj|ei)(s) and nei(s). Therefore the
memory cost is,
X
|E |· (|F |+ 1) + Is(Js + 1), (19)
s
</equation>
<bodyText confidence="0.999561857142857">
where |E |is the size of English vocabulary, |F |is
the size of foreign language vocabulary, Is is the
length of the English sentence of s, and Js is the
length of the foreign sentence of s.
The calculation of the leave-one-out translation
model is performed for each English word and for-
eign word in s. Therefore, the time cost is,
</bodyText>
<equation confidence="0.897248611111111">
YI P s(Bi|Bi−1, ei) ·
i=1
θlex(fj|ei), (12)
s
P s(Bi|Bi−1, ei) = θfer(φi|ei)·
s
θhea(Bi,1 − Bρi|Eρi) ·
s
s
θoth(Bi,k − Bi k−1).
(13)
φi
Y
k=2
YI
i=1
Y
j∈Bi
</equation>
<table confidence="0.765252285714286">
translation model θlex and the fertility model θ
s
When calculating (6) and (14) for singletons, the
X Is(Js + 1). (20)
s
s
fer.
</table>
<page confidence="0.952236">
1820
</page>
<bodyText confidence="0.9999444">
In addition, because the local counts N(f,|ei)(s)
and nei(s) are read in order, storing them in a ex-
ternal memory such as a hard disk will not slow
down the running speed much. This will reduce
the memory cost to
</bodyText>
<equation confidence="0.916191">
|£ |· (|F |+ 1). (21)
</equation>
<bodyText confidence="0.997186111111111">
This cost is independent to the number of sentence
pairs4.
The speed of the proposed method can be
boosted through parallelism. These calculations
on each sentence pair can be performed indepen-
dently. We found empirically that when our im-
plementation of the proposed method is run on a
16-core computer, it finishes the task earlier than
GIZA++5.
</bodyText>
<sectionHeader confidence="0.999742" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999977875">
The proposed WA method was tested on two
language pairs: Chinese-English and Japanese-
English (Table 2). Performance was measured
both directly using the agreement with reference
to manual WA annotations, and indirectly using
the BLEU score in end-to-end machine translation
tasks. GIZA++ and our own implementation of
standard EM were used as baselines.
</bodyText>
<subsectionHeader confidence="0.977285">
4.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999802777777778">
The Chinese-English experimental data consisted
of the GALE WA corpus and the OpenMT cor-
pus. They are from the same domain, both con-
tain newswire texts and web blogs. The OpenMT
evaluation 2005 was used as a development set for
MERT tuning (Och, 2003), and the OpenMT eval-
uation 2006 was used as a test set. The Japanese-
English experimental data was the Kyoto Free
Translation Task (Neubig, 2011)6. The corpus
contains a set of 1,235 sentence pairs that are man-
ually word aligned.
The corpora were processed using a standard
procedure for machine translation. The English
texts were tokenized with the tokenization script
released with Europarl corpus (Koehn, 2005) and
converted to lowercase; the Chinese texts were
segmented into words using the Stanford Word
Segmenter (Xue et al., 2002)7; the Japanese texts
</bodyText>
<footnote confidence="0.9736776">
4We found the memory of our server is large enough, so
we did not implement it
5We plan to make our code public available.
6http://www.phontron.com/kftt/
7http://nlp.stanford.edu/software/
</footnote>
<page confidence="0.605643">
segmenter.shtml
</page>
<bodyText confidence="0.999506833333333">
were segmented into words using the Kyoto Text
Analysis Toolkit (KyTea8). Sentences longer than
100 words or those with foreign/English word
length ratios between larger than 9 were filtered
out.
GIZA++ was run with the default Moses set-
tings (Koehn et al., 2007). The IBM model 1,
HMM model, IBM model 3 and IBM model 4
were run with 5, 5, 3 and 3 iterations. We imple-
mented the proposed leave-one-out EM and stan-
dard EM in IBM model 1, HMM model and IBM
model 4. In the original work (Och and Ney, 2003)
this combination of models achieved comparable
performance to the default Moses settings. They
were run with 5, 5 and 6 iterations.
The standard EM was re-implemented as a
baseline to provide a solid basis for comparison,
because GIZA++ contains many undocumented
details. Our implementation is based on the toolkit
of CICADA (Watanabe and Sumita, 2011; Watan-
abe, 2012; Tamura et al., 2013)9. We named the
implemented aligner AGRIPPA, to support our in-
house decoders OCTAVIAN and AUGUSTUS.
In all experiments, WA was performed indepen-
dently in two directions: from foreign languages
to English, and from English to foreign languages.
Then the grow-diag-final-and heuristic was used to
combine the two alignments from both directions
to yield the final alignments for evaluation (Och
and Ney, 2000; Och and Ney, 2003).
</bodyText>
<subsectionHeader confidence="0.981414">
4.2 Word Alignment Accuracy
</subsectionHeader>
<bodyText confidence="0.999904117647059">
Word alignment accuracy of the baseline and the
proposed method is shown in Table 3 in terms of
precision, recall and F1 (Och and Ney, 2003). The
proposed method gave rise to higher quality align-
ments in all our experiments. The improvement
in F1, precision and recall based on IBM Model
4 is in the range 8.3% to 9.1% compared with the
GIZA++ baseline, and in the range 5.0% to 17.2%
compared with our own baseline.
The most meaningful result comes from the
comparison of the models trained using standard
EM log-likelihood training, and the proposed EM
leave-one-out log-likelihood training. These mod-
els are identical except for way in which the model
likelihood is calculated. In all our experiments the
proposed method gave rise to higher quality align-
ments. The standard EM implementation achieved
</bodyText>
<footnote confidence="0.999947">
8http://www.phontron.com/kytea/
9http://www2.nict.go.jp/univ-com/multi trans/cicada/
</footnote>
<page confidence="0.949991">
1821
</page>
<table confidence="0.999486363636364">
Corpus # Sent. pairs # Foreign Words # English Words
Chinese-English (GALE WA, OpenMT)
WA 18,057 392,447 518,137
Train 442,967 12,265,072 13,444,927
Eval. 05 1,082† 29,688 138,952
Eval. 06 1,664† 37,827 189,059
Japanese-English (Kyoto Free Translation)
WA 1,235 34,403 30,822
Train 329,882 6,085,131 5,911,486
Develop 1,166 26,856 24,309
Test 1,160 28,501 26,734
</table>
<tableCaption confidence="0.9865035">
Table 2: Experimental Data. † Each consists of one foreign sentence and four English reference sen-
tences.
</tableCaption>
<table confidence="0.9984478">
Models standard EM (GIZA++) standard EM (ours) Leave-one-out(prop.)
F1 P R F1 P R F1 P R
Chinese-English (GALE WA, OpenMT)
Model 1 0.498 0.656 0.401 0.518 0.670 0.423 0.553 0.689 0.461
HMM 0.584 0.720 0.491 0.593 0.722 0.503 0.665 0.774 0.583
Model 4 0.624 0.698 0.565 0.593 0.688 0.522 0.677 0.756 0.612
Japanese-English (Kyoto Free Translation)
Model 1 0.508 0.601 0.439 0.513 0.606 0.444 0.535 0.618 0.471
HMM 0.573 0.667 0.502 0.579 0.665 0.512 0.626 0.687 0.575
Model 4 0.577 0.594 0.561 0.570 0.617 0.530 0.628 0.648 0.609
</table>
<tableCaption confidence="0.99989">
Table 3: Word alignment accuracy measured by F1, precision and recall.
</tableCaption>
<bodyText confidence="0.995994666666667">
alignment performance approximately compara-
ble to GIZA++, whereas the proposed method ex-
ceeded the performance of both implementations.
</bodyText>
<subsectionHeader confidence="0.986808">
4.3 End-to-end Translation Quality
</subsectionHeader>
<bodyText confidence="0.999109875">
BLEU scores achieved by the phrase-based and
hierachical SMT systems10 which were trained
from different alignment results, are shown in
Table 4. Each experiment was conducted three
times to mitigate the variance in the results due to
MERT. The results show that the proposed align-
ment method achieved the highest BLEU score in
all experiments. The improvement over the base-
line is in range 0.03 to 1.03 for phrase-based sys-
tems, and ranged from 0.43 to 1.30 for hierarchical
systems.
Hierarchical systems benifit more from the pro-
posed method than phrase-based systems. We
think this is because that hierarchical systems are
more sensitive to word alignment quality than
phrase-based systems. Phrase-based systems only
</bodyText>
<footnote confidence="0.413038">
10from the Moses toolkit
Size of training corpora (Log)
</footnote>
<figureCaption confidence="0.9976225">
Figure 2: Curve of word alignment accuracy (F1)
under training corpora of different sizes.
</figureCaption>
<figure confidence="0.988128">
1k 4k 18k 64k 256k 461k
Word alignment F1
0.40 0.45 0.50 0.55 0.60 0.65 0.70
Norm. EM (Giza++)
Norm. EM (our)
Leave−one−out EM (prop.)
</figure>
<page confidence="0.971039">
1822
</page>
<table confidence="0.978639285714286">
SMT Systems standard EM (GIZA++) standard EM (ours) Leave-one-out (prop.)
Chinese-English (GALE WA, OpenMT)
Phrase-based 31.85 f 0.26 31.01 f 0.18 32.04 f 0.08
Hierarchical 32.27 f 0.23 31.40 f 0.26 32.70 f 0.14
Japanese-English (Kyoto Free Translation)
Phrase-based 18.35 f 0.27 18.20 f 0.20 18.38 f 0.11
Hierarchical 19.48 f 0.08 19.39 f 0.02 20.10 f 0.07
</table>
<tableCaption confidence="0.994652">
Table 4: End-to-end translation quality measured by BLEU
</tableCaption>
<table confidence="0.999129375">
Corpus size standard EM (GIZA++) standard EM (ours) Leave-one-out(prop.)
F1 P R F1 P R F1 P R
1K 0.429 0.466 0.397 0.419 0.463 0.382 0.470 0.568 0.402
4K 0.499 0.547 0.459 0.492 0.549 0.445 0.568 0.668 0.494
18K† 0.571 0.630 0.521 0.553 0.621 0.499 0.633 0.721 0.565
64K 0.588 0.659 0.531 0.555 0.638 0.492 0.645 0.712 0.590
256K 0.614 0.687 0.554 0.578 0.667 0.511 0.661 0.718 0.612
461K 0.624 0.698 0.565 0.593 0.688 0.522 0.677 0.756 0.612
</table>
<tableCaption confidence="0.99351">
Table 5: Effect of training corpus size on word alignment accuracy measured by F1, precision and recall
(Chinese-English). † the whole manually word aligned corpus
</tableCaption>
<table confidence="0.9999038">
Corpus size stan.(GIZA++) stan.(ours) LOO(prop.) Gold
Phrase-based
1k 7.86 7.66 9.38 10.01
4k 15.27 15.49 17.06 17.57
18K† 22.15 21.72 24.41 24.11
64K 28.10 27.91 29.23 NA
256K 31.05 30.82 31.51 NA
461K 31.85 31.01 32.04 NA
Hierarchical
1k 7.53 7.54 9.19 10.62
4k 14.89 15.51 17.91 18.31
18K† 22.85 22.56 24.66 24.52
64K 28.82 28.22 29.78 NA
256K 31.47 30.21 31.72 NA
461K 32.27 31.04 32.70 NA
</table>
<tableCaption confidence="0.977128">
Table 6: Effect of training corpus size on end-to-end translation quality measured by BLEU (Chinese-
</tableCaption>
<bodyText confidence="0.94938575">
English). † the whole manually word aligned corpus
take contiguous parallel phrase pairs as translation
rules, while hierarchical systems also use patterns
made by subtracting (inner) short parallel phrases
from (outer) longer parallel phrases. Both the
outer and inner phrases typically need to be noise-
free in order to produce high quality rules. This
puts a high demand on the alignment quality.
</bodyText>
<subsectionHeader confidence="0.999641">
4.4 Effect of Training Corpus Size
</subsectionHeader>
<bodyText confidence="0.99985575">
Training corpora of different sizes were employed
to perform unsupervised WA experiments and MT
experiments (see Tables 5 and 6).
The training corpora were randomly sampled
from the Chinese-English manual WA corpora and
the parallel training corpus. The manual WA cor-
pus has a priority for being sampled so that the
gold WA annotation is available for MT experi-
</bodyText>
<page confidence="0.95729">
1823
</page>
<figure confidence="0.995313444444444">
Size of training corpora (Log)
(a)
Size of training corpora (Log)
(b)
1k 4k 18k 64k 256k 461k
BLEU (phrase−based)
10 15 20 25 30
Standard EM (GIZA++)
Standard EM (ours)
Leave−one−out EM (prop.)
Gold
1k 4k 18k 64k 256k 461k
BLEU (Hierarchical)
10 15 20 25 30
Standard EM (GIZA++)
Standard EM (ours)
Leave−one−out EM (prop.)
Gold
</figure>
<figureCaption confidence="0.98601">
Figure 3: Curves of translation quality (BLEU) under training corpora of different sizes. (a) Phrase-based
MT; (b) Hierarchical MT.
</figureCaption>
<bodyText confidence="0.996074243243244">
ments.
The settings of the unsupervised WA experi-
ments and the MT experiments are the same with
the previous experiments. In the WA experiments,
GIZA++, our implemented standard EM and the
proposed leave-one-out EM are applied to training
corpora with the same parameter settings as the
previous. In the MT experiments, the WA results
of different methods and the gold WA (if available)
are employed to extract translation rules; the rest
settings including language models, development
and test corpus, and parameters are the same as the
previous.
On word alignment accuracy, the proposed
method achieved improvements of F1 from 0.041
to 0.090 under the different training corpora (Table
5. The maximum improvement compared with
GIZA++ is 0.069 when the training corpus has
4,000 sentence pairs. The maximum improvement
compared with our own implement is 0.090 when
the training corpus has 64,000 sentence pairs.
Figure 2 shows that the extent of improvements
slightly changes under different training corpora,
but they are all quite stable and obvious.
On translation quality, the proposed method
achieved improvements of BLEU under the dif-
ferent training corpora. The improvements ranged
from 0.19 to 1.72 for phrase-based MT and ranged
from 0.25 to 3.02 (see Table 5). The improve-
ments are larger under smaller training corpora
(see Figure 3).
In addition, the BLEUs achieved by the pro-
posed method is close to the ones achieved by gold
WA annotations. The proposed method slightly
outperforms the gold WA annotations when us-
ing the full manual WA corpus of 18,057 sentence
pairs.
</bodyText>
<subsectionHeader confidence="0.978727">
4.5 Comparison to l0-Iormalization and
Kneser-Iey Smoothing Methods
</subsectionHeader>
<bodyText confidence="0.999690421052632">
The proposed leave-one-word word align-
ment method was empirically compared to
l0-normalized GIZA++ (Vaswani et al., 2012)11
and Kneser-Ney smoothed GIZA++ (Zhang and
Chiang, 2014)12. l0-normalization and Kneser-
Ney smoothing methods are established methods
to overcome the sparse problem. This enables
the probability distributions on rare words to be
estimated more effectively. In this way, these
two GIZA++ variants are related to the proposed
method.
l0-normalized GIZA++ and Kneser-Ney
smoothed GIZA++ were run with the same
settings as GIZA++, which came from the
default settings of MOSES. For the settings of
l0-normalized GIZA++ that are not in common
with GIZA++ were the default settings. As for
Kneser-Ney smoothed GIZA++, the smooth
switches of IBM models 1 – 4 and HMM model
</bodyText>
<footnote confidence="0.998903333333333">
11http://www.isi.edu/˜avaswani/
giza-pp-l0.html
12https://github.com/hznlp/giza-kn
</footnote>
<page confidence="0.953779">
1824
</page>
<table confidence="0.999421363636364">
GIZA++ lo-Normalization Kneser-Ney Smooth. Leave-one-out(prop.)
Word Alignment Quality
Fl P R Fl P R Fl P R Fl P R
All Words 0.624 0.698 0.565 0.629 0.700 0.571 0.656 0.726 0.599 0.678 0.755 0.615
S.W.F=1 0.458 0.435 0.483 0.448 0.471 0.427 0.515 0.532 0.499 0.398 0.693 0.279
S.W.F≤2 0.466 0.451 0.481 0.461 0.485 0.440 0.522 0.545 0.501 0.450 0.707 0.330
S.W.F≤5 0.476 0.480 0.473 0.478 0.509 0.451 0.534 0.572 0.501 0.502 0.722 0.385
S.W.F≤10 0.485 0.505 0.466 0.491 0.531 0.456 0.541 0.593 0.498 0.529 0.733 0.414
Translation Quality (BLEU)
Phrase-based 31.85 ± 0.26 31.52 ± 0.06 31.94 ± 0.19 32.04 ± 0.08
Hierarchical 32.27 ± 0.23 32.20 ± 0.04 32.47 ± 0.33 32.70 ± 0.14
</table>
<tableCaption confidence="0.997451">
Table 7: Empirical Comparision with 10-Normalized and Kneser-Ney Smoothed GIZA++’s
</tableCaption>
<bodyText confidence="0.995642930232558">
were turned on.
The experimental results are presented in Ta-
ble 7. The experiments were run on the Chinese-
English language pair. The word alignment qual-
ity was evaluated separately for all words and for
various levels of rare words. The leave-one-out
method outperformed related methods in terms
of precision, recall and F1 when evaluated on all
words.
Rare words were categorized based on the num-
ber of occurences in the source-language text of
the training data. The evaluations were carried
out on the subset of alignment links that had a
rare word on the source side. Table 7 presents
the results for thresholds 1, 2, 5 and 10. The
proposed method achieved much higher preci-
sion on rare words than the other methods, but
performed poorly on recall. The Kneser-Ney
Smoothed GIZA++ had higher recall. The ex-
planation might be that the leave-one-out method
punishes rare words more than the Kneser-Ney
smoothing method, by totally removing the de-
rived expected counts of current sentence pair
from the alignment models. This leads to rare
words being passively aligned. In other words, the
leave-one-out method would align rare words un-
less the confidence is high. Therefore, we plan to
seek a method to integrate Kneser-Ney smoothing
into the proposed leave-one-out method in the fu-
ture work.
The BLEU scores achieved by phrase-based
SMT and hierarchical SMT for different align-
ment methods are presented in Table 7. The
proposed method outperforms the other methods.
The Kneser-Ney Smoothed GIZA++ performed
the second best. We tried to further analyze the
relation between word alignment and BLEU, but
found the analysis was obscured by the many
processing stages. These stages include paral-
lel phrase extraction (or translation rule extraction
from hierarchical SMT), log-linear model, MERT
tuning and practical decoding where a lot of prun-
ing happened.
</bodyText>
<sectionHeader confidence="0.999279" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999983777777778">
This paper proposes a leave-one-out EM algo-
rithm for WA to overcome the over-fitting prob-
lem that occurs when using standard EM for WA.
The experimental results on Chinese-English and
Japanese-English corpora show that both the WA
accuracy and the end-to-end translation are im-
proved.
In addition, we have a interesting finding about
the effect of manual WA annotations on train-
ing MT systems. In a Chinese-English parallel
training corpus of 18,057 sentence pairs, the man-
ual WA annotation outperformed the unsupervised
WA results produced by standard EM algorithms.
However, the unsupervised WA results produced
by proposed leave-one-out EM algorithm outper-
formed the manual WA annotation.
Our future work will focus on increasing the
gains in end-to-end translation quality through the
proposed leave-one-out aligner. It is a interest-
ing question why GIZA++ achieved competitive
BLEU scores though its alignment accuracy mea-
sured by F1 was substantially lower. The answer
to this question which may reveal essence of good
word alignment for MT and eventually help to im-
prove MT. In addition, we plan to improve the pro-
posed method by integrating Kneser-Ney smooth-
ing.
</bodyText>
<sectionHeader confidence="0.998026" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9991115">
We appreciated the valuable comments from the
reviewers.
</bodyText>
<page confidence="0.990326">
1825
</page>
<sectionHeader confidence="0.983276" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998738703703704">
Christophe Andrieu, Nando De Freitas, Arnaud
Doucet, and Michael I. Jordan. 2003. An intro-
duction to MCMC for machine learning. Machine
learning, 50(1-2):5–43.
Ondrej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut, and
Lucia Specia. 2013. Findings of the 2013 workshop
on statistical machine translation. In Proceedings of
the Eighth Workshop on Statistical Machine Trans-
lation, pages 1–44.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, Meredith J. Goldsmith, Jan Hajic,
Robert L. Mercer, and Surya Mohanty. 1993a. But
dictionaries are data too. In Proceedings of the
Workshop on Human Language Technology, HLT
’93, pages 202–205, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993b.
The mathematics of statistical machine translation:
parameter estimation. Computational linguistics,
19(2):263–311.
Mauro Cettolo, Jan Niehues, Sebastian St¨uker, Luisa
Bentivogli, and Marcello Federico. 2013. Report
on the 10th IWSLT evaluation campaign. In Pro-
ceedings of the International Workshop on Spoken
Language Translation, pages 29–38.
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete
data via the EM algorithm. Journal of the Royal
Statistical Society. Series B (Methodological), pages
1–38.
John DeNero and Dan Klein. 2007. Tailoring word
alignments to syntactic machine translation. In Pro-
ceedings of the 45th Annual Meeting on Association
for Computational Linguistics, pages 17–24.
John DeNero, Alexandre Bouchard-Cˆot´e, and Dan
Klein. 2008. Sampling alignment structure un-
der a bayesian translation model. In Proceedings
of the Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP ’08, pages 314–
323, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Chris Dyer, Victor Chahuneau, and Noah A Smith.
2013. A simple, fast, and effective reparameteriza-
tion of ibm model 2. In Proceedings of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 644–648.
Kuzman Ganchev, Joao V. Grac¸a, and Ben Taskar.
2008. Better alignments = better translations? Pro-
ceedings of the 46th Annual Meeting on Association
for Computational Linguistics, page 42.
Walter R. Gilks, Sylvia Richardson, and David J.
Spiegelhalter. 1996. Markov chain Monte Carlo in
practice, volume 2. CRC press.
Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, and
Benjamin K Tsou. 2011. Overview of the patent
machine translation task at the NTCIR-9 workshop.
In Proceedings ofNTCIR, volume 9, pages 559–578.
Marcin Junczys-Dowmunt and Arkadiusz Sza. 2012.
Symgiza++: Symmetrized word alignment mod-
els for machine translation. In Pascal Bouvry,
Mieczyslaw A. Klopotek, Franck Leprvost, Malgo-
rzata Marciniak, Agnieszka Mykowiecka, and Hen-
ryk Rybinski, editors, Security and Intelligent In-
formation Systems (SIIS), volume 7053 of Lecture
Notes in Computer Science, pages 379–390, War-
saw, Poland. Springer.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of the 45th Annual Meeting of the Associ-
ation for Computational Linguistics on Interactive
Poster and Demonstration Sessions, pages 177–180.
Association for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A parallel corpus
for statistical machine translation. In Proceedings
ofMT Summit, volume 5, pages 79–86.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the North
American Chapter of the Association of Computa-
tional Linguistics: Human Language Technologies,
pages 104–111. Association for Computational Lin-
guistics.
Robert C. Moore. 2004. Improving IBM word-
alignment model 1. In Proceedings of the 42nd An-
nual Meeting on Association for Computational Lin-
guistics, page 518. Association for Computational
Linguistics.
Graham Neubig, Taro Watanabe, Eiichiro Sumita,
Shinsuke Mori, and Tatsuya Kawahara. 2011. An
unsupervised model for joint phrase alignment and
extraction. In ACL, pages 632–641.
Graham Neubig. 2011. The Kyoto free translation
task. http://www.phontron.com/kftt.
Franz Josef Och and Hermann Ney. 2000. A com-
parison of alignment models for statistical machine
translation. In Proceedings of the 18th confer-
ence on Computational linguistics-Volume 2, pages
1086–1090. Association for Computational Linguis-
tics.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19–51.
</reference>
<page confidence="0.839397">
1826
</page>
<reference confidence="0.999907059701493">
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Compu-
tational Linguistics-Volume 1, pages 160–167. As-
sociation for Computational Linguistics.
Nicolas Le Roux and Francis Bach. 2011. Local com-
ponent analysis. Technical report.
Akihiro Tamura, Taro Watanabe, Eiichiro Sumita, Hi-
roya Takamura, and Manabu Okumura. 2013. Part-
of-speech induction in dependency trees for statisti-
cal machine translation. In Proceedings of the 51th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 841–851.
Jo˜ao V Grac¸a, Kuzman Ganchev, and Ben Taskar.
2010. Learning tractable word alignment models
with complex constraints. Computational Linguis-
tics, 36(3):481–504.
Ashish Vaswani, Liang Huang, and David Chiang.
2012. Smaller alignment models for better trans-
lations: unsupervised word alignment with the lo-
norm. In Proceedings of the 50th Annual Meeting
of the Association for Computational Linguistics:
Long Papers-Volume 1, pages 311–319. Association
for Computational Linguistics.
Xiaolin Wang, Masao Utiyama, Andrew Finch, and Ei-
ichiro Sumita. 2014. Empirical study of unsuper-
vised chinese word segmentation methods for smt
on large-scale corpora. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 2: Short Papers), pages
752–758, Baltimore, Maryland, June. Association
for Computational Linguistics.
Taro Watanabe and Eiichiro Sumita. 2011. Machine
translation system combination by confusion forest.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies, pages 1249–1257. Associ-
ation for Computational Linguistics.
Taro Watanabe. 2012. Optimized online rank learning
for machine translation. In Proceedings of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 253–262. Association for Computational Lin-
guistics.
Joern Wuebker, Arne Mauser, and Hermann Ney.
2010. Training phrase translation models with
leaving-one-out. In Proceedings of the 48th Annual
Meeting of the Association for Computational Lin-
guistics, pages 475–484. Association for Computa-
tional Linguistics.
Joern Wuebker, Mei-Yuh Hwang, and Chris Quirk.
2012. Leave-one-out phrase model training for
large-scale deployment. In Proceedings of the Sev-
enth Workshop on Statistical Machine Translation,
pages 460–467. Association for Computational Lin-
guistics.
Nianwen Xue, Fu-Dong Chiou, and Martha Palmer.
2002. Building a large-scale annotated chinese cor-
pus. In Proceedings of the 19th International Con-
ference on Computational Linguistics, pages 1–8.
Association for Computational Linguistics.
Hui Zhang and David Chiang. 2014. Kneser-ney
smoothing on expected counts. In Proceedings of
the 52nd Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Pa-
pers), pages 765–774, Baltimore, Maryland, June.
Association for Computational Linguistics.
</reference>
<page confidence="0.994256">
1827
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.323834">
<title confidence="0.999773">Leave-one-out Word Alignment without Garbage Collector Effects</title>
<author confidence="0.950944">Xiaolin Wang Masao Utiyama Andrew Finch</author>
<affiliation confidence="0.767394333333333">Eiichiro Advanced Translation Research and Development Promotion National Institute of Information and Communications Technology,</affiliation>
<email confidence="0.999209">tarow@google.com</email>
<abstract confidence="0.98997137037037">Expectation-maximization algorithms, such as those implemented in GIZA++ pervade the field of unsupervised word alignment. However, these algorithms have a problem of over-fitting, leading to “garbage collector effects,” where rare words tend to be erroneously aligned to untranslated words. This proposes a leave-one-out expectationmaximization algorithm for unsupervised word alignment to address this problem. The proposed method excludes information derived from the alignment of a sentence pair from the alignment models used to align it. This prevents erroneous alignments within a sentence pair from supporting themselves. Experimental results on Chinese-English and Japanese-English corpora show that precision and recall of alignment were consistently increased by 5.0% – 17.2%, and BLEU scores of end-to-end translation were raised by 0.03 – 1.30. The proposed method also outperformed GIZA++ and Kneser-Ney smoothed GIZA++.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christophe Andrieu</author>
<author>Nando De Freitas</author>
<author>Arnaud Doucet</author>
<author>Michael I Jordan</author>
</authors>
<title>An introduction to MCMC for machine learning.</title>
<date>2003</date>
<booktitle>Machine learning,</booktitle>
<pages>50--1</pages>
<marker>Andrieu, De Freitas, Doucet, Jordan, 2003</marker>
<rawString>Christophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I. Jordan. 2003. An introduction to MCMC for machine learning. Machine learning, 50(1-2):5–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ondrej Bojar</author>
<author>Christian Buck</author>
<author>Chris Callison-Burch</author>
<author>Christian Federmann</author>
<author>Barry Haddow</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Matt Post</author>
<author>Radu Soricut</author>
<author>Lucia Specia</author>
</authors>
<title>workshop on statistical machine translation.</title>
<date>2013</date>
<journal>Findings of the</journal>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<pages>1--44</pages>
<contexts>
<context position="2286" citStr="Bojar et al., 2013" startWordPosition="325" endWordPosition="328">ing the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Grac¸a et al., 2010). Figure 1(a) shows a real sentence pair, denoted s, from the GALE ChineseEnglish Word Alignment and Tagging Training corpus (GALE WA corpus)1 with it’s humanannotated word alignment. The Chinese word “HE ZHANG,” denoted wr, which means river custodian, only occurs once in the whole corpus. We performed</context>
</contexts>
<marker>Bojar, Buck, Callison-Burch, Federmann, Haddow, Koehn, Monz, Post, Soricut, Specia, 2013</marker>
<rawString>Ondrej Bojar, Christian Buck, Chris Callison-Burch, Christian Federmann, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2013. Findings of the 2013 workshop on statistical machine translation. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 1–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Meredith J Goldsmith</author>
<author>Jan Hajic</author>
<author>Robert L Mercer</author>
<author>Surya Mohanty</author>
</authors>
<title>But dictionaries are data too.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology, HLT ’93,</booktitle>
<pages>202--205</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1776" citStr="Brown et al., 1993" startWordPosition="237" endWordPosition="240">, and BLEU scores of end-to-end translation were raised by 0.03 – 1.30. The proposed method also outperformed l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++. 1 Introduction Unsupervised word alignment (WA) on bilingual sentence pairs serves as an essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects</context>
<context position="7302" citStr="Brown et al., 1993" startWordPosition="1145" endWordPosition="1148">e been shown to be more efficient (Wang et al., 2014). 3 Methodology This section first formulates the standard EM for WA, then presents the leave-one-out EM for WA, and finally briefly discusses handling singletons and effecient implementation. The main notation used in this section is shown in Table 1. 3.1 Standard EM for IBM Models 1, 2 and HMM Model To perform WA through EM, the parallel corpus is taken as observed data, the alignments are taken as latent data. In order to maximize the likelihood of the alignment model 0 given the data S, the following two steps are conducted iteratively (Brown et al., 1993b; Och and Ney, 2000; Och and Ney, 2003), Expectation Step (E step): calculating the conditional probability of alignments for each sentence pair, P(a|s,e) = HJj=1 eali(aj|aj−1,I)0lex(fj|eaj),(1) where Bali(i|i′, I) is the alignment probability and Olex(f|e) is the translation probability. Note that 1818 a foreign sentence (f1, ... , fJ) an English sentence (e1, ... , eI) a sentence pair (f, e) an alignment (a1, ... , aJ) where fj is aligned to eaj a list of the indexes of the foreign words which are aligned to ei the index of the k-th foreign word which is aligned to ei is the average of all </context>
<context position="10409" citStr="Brown et al., 1993" startWordPosition="1698" endWordPosition="1701">s′) θ¯s ali(i|i′, I) ← Ps′6=s Ni′,I(s′) (5) P s′6=s Nf|e(s′) θ¯s lex(f|e) ← P (6) s′6=s ne(s′) . 3.3 Standard EM for IBM Model 4 The framework of the standard EM for IBM Model 4 is similar with the one for IBM Models 1, 2 and HMM Model, but the calculation of alignment probability is more complicated. E step: calculating the conditional probability through the reverted alignment (Och and Ney, 2003), P(a|s, θ) = P(B0|B1,... , BI)· θlex(fj|ei), (7) where B0 means the set of foreign words aligned with the empty word; P(B0|B1, ... , BI) is assumed to be a binomial distribution for the size of B0 (Brown et al., 1993b) or an modified distribution to relieve deficiency (Och and Ney, 2003). The distribution P(Bi|Bi−1, ei) is decomposed as P(Bi|Bi−1, ei) = θfer(φi|ei)· φi θhea(Bi,1 − Bρi|Eρi) · Y θoth(Bi,k − Bi,k−1), k=2 (8) where θfer is a fertility model; θhea is a probability model for the head (first) aligned foreign word; θoth is a probability model for the other aligned foreign words. θhea is assumed to be conditioned f e s a Bi Bi,k Bi ρi φi Ei θ· θ s · nx(s, a) Nx(s) YI P(Bi|Bi−1, ei) · i=1 YI i=1 Y j∈Bi 1819 on the word class Eρi, following the paper of (Och and Ney, 2003) and the implementation of </context>
</contexts>
<marker>Brown, Pietra, Pietra, Goldsmith, Hajic, Mercer, Mohanty, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, Meredith J. Goldsmith, Jan Hajic, Robert L. Mercer, and Surya Mohanty. 1993a. But dictionaries are data too. In Proceedings of the Workshop on Human Language Technology, HLT ’93, pages 202–205, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1776" citStr="Brown et al., 1993" startWordPosition="237" endWordPosition="240">, and BLEU scores of end-to-end translation were raised by 0.03 – 1.30. The proposed method also outperformed l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++. 1 Introduction Unsupervised word alignment (WA) on bilingual sentence pairs serves as an essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects</context>
<context position="7302" citStr="Brown et al., 1993" startWordPosition="1145" endWordPosition="1148">e been shown to be more efficient (Wang et al., 2014). 3 Methodology This section first formulates the standard EM for WA, then presents the leave-one-out EM for WA, and finally briefly discusses handling singletons and effecient implementation. The main notation used in this section is shown in Table 1. 3.1 Standard EM for IBM Models 1, 2 and HMM Model To perform WA through EM, the parallel corpus is taken as observed data, the alignments are taken as latent data. In order to maximize the likelihood of the alignment model 0 given the data S, the following two steps are conducted iteratively (Brown et al., 1993b; Och and Ney, 2000; Och and Ney, 2003), Expectation Step (E step): calculating the conditional probability of alignments for each sentence pair, P(a|s,e) = HJj=1 eali(aj|aj−1,I)0lex(fj|eaj),(1) where Bali(i|i′, I) is the alignment probability and Olex(f|e) is the translation probability. Note that 1818 a foreign sentence (f1, ... , fJ) an English sentence (e1, ... , eI) a sentence pair (f, e) an alignment (a1, ... , aJ) where fj is aligned to eaj a list of the indexes of the foreign words which are aligned to ei the index of the k-th foreign word which is aligned to ei is the average of all </context>
<context position="10409" citStr="Brown et al., 1993" startWordPosition="1698" endWordPosition="1701">s′) θ¯s ali(i|i′, I) ← Ps′6=s Ni′,I(s′) (5) P s′6=s Nf|e(s′) θ¯s lex(f|e) ← P (6) s′6=s ne(s′) . 3.3 Standard EM for IBM Model 4 The framework of the standard EM for IBM Model 4 is similar with the one for IBM Models 1, 2 and HMM Model, but the calculation of alignment probability is more complicated. E step: calculating the conditional probability through the reverted alignment (Och and Ney, 2003), P(a|s, θ) = P(B0|B1,... , BI)· θlex(fj|ei), (7) where B0 means the set of foreign words aligned with the empty word; P(B0|B1, ... , BI) is assumed to be a binomial distribution for the size of B0 (Brown et al., 1993b) or an modified distribution to relieve deficiency (Och and Ney, 2003). The distribution P(Bi|Bi−1, ei) is decomposed as P(Bi|Bi−1, ei) = θfer(φi|ei)· φi θhea(Bi,1 − Bρi|Eρi) · Y θoth(Bi,k − Bi,k−1), k=2 (8) where θfer is a fertility model; θhea is a probability model for the head (first) aligned foreign word; θoth is a probability model for the other aligned foreign words. θhea is assumed to be conditioned f e s a Bi Bi,k Bi ρi φi Ei θ· θ s · nx(s, a) Nx(s) YI P(Bi|Bi−1, ei) · i=1 YI i=1 Y j∈Bi 1819 on the word class Eρi, following the paper of (Och and Ney, 2003) and the implementation of </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993b. The mathematics of statistical machine translation: parameter estimation. Computational linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Jan Niehues</author>
<author>Sebastian St¨uker</author>
<author>Luisa Bentivogli</author>
<author>Marcello Federico</author>
</authors>
<title>Report on the 10th IWSLT evaluation campaign.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>29--38</pages>
<marker>Cettolo, Niehues, St¨uker, Bentivogli, Federico, 2013</marker>
<rawString>Mauro Cettolo, Jan Niehues, Sebastian St¨uker, Luisa Bentivogli, and Marcello Federico. 2013. Report on the 10th IWSLT evaluation campaign. In Proceedings of the International Workshop on Spoken Language Translation, pages 29–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>Nan M Laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society. Series B (Methodological),</journal>
<pages>1--38</pages>
<contexts>
<context position="1756" citStr="Dempster et al., 1977" startWordPosition="233" endWordPosition="236">creased by 5.0% – 17.2%, and BLEU scores of end-to-end translation were raised by 0.03 – 1.30. The proposed method also outperformed l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++. 1 Introduction Unsupervised word alignment (WA) on bilingual sentence pairs serves as an essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garba</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society. Series B (Methodological), pages 1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailoring word alignments to syntactic machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="2032" citStr="DeNero and Klein, 2007" startWordPosition="283" endWordPosition="286"> essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Grac¸a et al., 2010). Figure 1(a) shows a real sentence pair, denoted </context>
</contexts>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. 2007. Tailoring word alignments to syntactic machine translation. In Proceedings of the 45th Annual Meeting on Association for Computational Linguistics, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>Dan Klein</author>
</authors>
<title>Sampling alignment structure under a bayesian translation model.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>314--323</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>DeNero, Bouchard-Cˆot´e, Klein, 2008</marker>
<rawString>John DeNero, Alexandre Bouchard-Cˆot´e, and Dan Klein. 2008. Sampling alignment structure under a bayesian translation model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 314– 323, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Victor Chahuneau</author>
<author>Noah A Smith</author>
</authors>
<title>A simple, fast, and effective reparameterization of ibm model 2.</title>
<date>2013</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>644--648</pages>
<contexts>
<context position="2064" citStr="Dyer et al., 2013" startWordPosition="289" endWordPosition="292">st statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Grac¸a et al., 2010). Figure 1(a) shows a real sentence pair, denoted s, from the GALE ChineseEnglish </context>
</contexts>
<marker>Dyer, Chahuneau, Smith, 2013</marker>
<rawString>Chris Dyer, Victor Chahuneau, and Noah A Smith. 2013. A simple, fast, and effective reparameterization of ibm model 2. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 644–648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Joao V Grac¸a</author>
<author>Ben Taskar</author>
</authors>
<title>Better alignments = better translations?</title>
<date>2008</date>
<booktitle>Proceedings of the 46th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>42</pages>
<marker>Ganchev, Grac¸a, Taskar, 2008</marker>
<rawString>Kuzman Ganchev, Joao V. Grac¸a, and Ben Taskar. 2008. Better alignments = better translations? Proceedings of the 46th Annual Meeting on Association for Computational Linguistics, page 42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter R Gilks</author>
<author>Sylvia Richardson</author>
<author>David J Spiegelhalter</author>
</authors>
<title>Markov chain Monte Carlo in practice, volume 2.</title>
<date>1996</date>
<publisher>CRC press.</publisher>
<contexts>
<context position="5915" citStr="Gilks et al., 1996" startWordPosition="905" endWordPosition="908">evel, and our aim is to provide better word alignment. As word alignment is a foundation of most MT systems, our method have a wider application. Recently, better estimation methods during the maximization step of EM have been proposed to avoid the over-fitting in WA, such as using Kneser-Ney Smoothing to back-off the expected counts (Zhang and Chiang, 2014) or integrating the smoothed l0 prior to the estimation of probability (Vaswani et al., 2012). Our work differs from theirs by addressing the over-fitting directly in the EM algorithm by adopting a leave-one-out approach. Bayesian methods (Gilks et al., 1996; Andrieu et al., 2003; DeNero et al., 2008; Neubig et al., 3The probability distribution of generating target language words from w,.. The description here is only based on IBM model1 for simplicity, and the other alignment models are similar. he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG Figure 1: Examples of supervised word alignment. (a) gold alignment; (b) standa</context>
</contexts>
<marker>Gilks, Richardson, Spiegelhalter, 1996</marker>
<rawString>Walter R. Gilks, Sylvia Richardson, and David J. Spiegelhalter. 1996. Markov chain Monte Carlo in practice, volume 2. CRC press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isao Goto</author>
<author>Bin Lu</author>
<author>Ka Po Chow</author>
<author>Eiichiro Sumita</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Overview of the patent machine translation task at the NTCIR-9 workshop.</title>
<date>2011</date>
<booktitle>In Proceedings ofNTCIR,</booktitle>
<volume>9</volume>
<pages>559--578</pages>
<contexts>
<context position="2243" citStr="Goto et al., 2011" startWordPosition="317" endWordPosition="320"> contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Grac¸a et al., 2010). Figure 1(a) shows a real sentence pair, denoted s, from the GALE ChineseEnglish Word Alignment and Tagging Training corpus (GALE WA corpus)1 with it’s humanannotated word alignment. The Chinese word “HE ZHANG,” denoted wr, which means river custodian, only oc</context>
</contexts>
<marker>Goto, Lu, Chow, Sumita, Tsou, 2011</marker>
<rawString>Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, and Benjamin K Tsou. 2011. Overview of the patent machine translation task at the NTCIR-9 workshop. In Proceedings ofNTCIR, volume 9, pages 559–578.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcin Junczys-Dowmunt</author>
<author>Arkadiusz Sza</author>
</authors>
<title>Symgiza++: Symmetrized word alignment models for machine translation.</title>
<date>2012</date>
<booktitle>Security and Intelligent Information Systems (SIIS),</booktitle>
<volume>7053</volume>
<pages>379--390</pages>
<editor>In Pascal Bouvry, Mieczyslaw A. Klopotek, Franck Leprvost, Malgorzata Marciniak, Agnieszka Mykowiecka, and Henryk Rybinski, editors,</editor>
<publisher>Springer.</publisher>
<location>Warsaw, Poland.</location>
<contexts>
<context position="2110" citStr="Junczys-Dowmunt and Sza, 2012" startWordPosition="296" endWordPosition="299"> (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Grac¸a et al., 2010). Figure 1(a) shows a real sentence pair, denoted s, from the GALE ChineseEnglish Word Alignment and Tagging Training corpus (GA</context>
</contexts>
<marker>Junczys-Dowmunt, Sza, 2012</marker>
<rawString>Marcin Junczys-Dowmunt and Arkadiusz Sza. 2012. Symgiza++: Symmetrized word alignment models for machine translation. In Pascal Bouvry, Mieczyslaw A. Klopotek, Franck Leprvost, Malgorzata Marciniak, Agnieszka Mykowiecka, and Henryk Rybinski, editors, Security and Intelligent Information Systems (SIIS), volume 7053 of Lecture Notes in Computer Science, pages 379–390, Warsaw, Poland. Springer.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="16318" citStr="Koehn et al., 2007" startWordPosition="2714" endWordPosition="2717">005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002)7; the Japanese texts 4We found the memory of our server is large enough, so we did not implement it 5We plan to make our code public available. 6http://www.phontron.com/kftt/ 7http://nlp.stanford.edu/software/ segmenter.shtml were segmented into words using the Kyoto Text Analysis Toolkit (KyTea8). Sentences longer than 100 words or those with foreign/English word length ratios between larger than 9 were filtered out. GIZA++ was run with the default Moses settings (Koehn et al., 2007). The IBM model 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations. We implemented the proposed leave-one-out EM and standard EM in IBM model 1, HMM model and IBM model 4. In the original work (Och and Ney, 2003) this combination of models achieved comparable performance to the default Moses settings. They were run with 5, 5 and 6 iterations. The standard EM was re-implemented as a baseline to provide a solid basis for comparison, because GIZA++ contains many undocumented details. Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Wat</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, et al. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions, pages 177–180. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings ofMT Summit,</booktitle>
<volume>5</volume>
<pages>79--86</pages>
<contexts>
<context position="15703" citStr="Koehn, 2005" startWordPosition="2623" endWordPosition="2624">e GALE WA corpus and the OpenMT corpus. They are from the same domain, both contain newswire texts and web blogs. The OpenMT evaluation 2005 was used as a development set for MERT tuning (Och, 2003), and the OpenMT evaluation 2006 was used as a test set. The JapaneseEnglish experimental data was the Kyoto Free Translation Task (Neubig, 2011)6. The corpus contains a set of 1,235 sentence pairs that are manually word aligned. The corpora were processed using a standard procedure for machine translation. The English texts were tokenized with the tokenization script released with Europarl corpus (Koehn, 2005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002)7; the Japanese texts 4We found the memory of our server is large enough, so we did not implement it 5We plan to make our code public available. 6http://www.phontron.com/kftt/ 7http://nlp.stanford.edu/software/ segmenter.shtml were segmented into words using the Kyoto Text Analysis Toolkit (KyTea8). Sentences longer than 100 words or those with foreign/English word length ratios between larger than 9 were filtered out. GIZA++ was run with the default Moses settings (Koeh</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings ofMT Summit, volume 5, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of the North American Chapter of the Association of Computational Linguistics: Human Language Technologies,</booktitle>
<pages>104--111</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2007" citStr="Liang et al., 2006" startWordPosition="279" endWordPosition="282">e pairs serves as an essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Grac¸a et al., 2010). Figure 1(a) shows a rea</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proceedings of the North American Chapter of the Association of Computational Linguistics: Human Language Technologies, pages 104–111. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Improving IBM wordalignment model 1.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>518</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2536" citStr="Moore, 2004" startWordPosition="370" endWordPosition="371">its including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Grac¸a et al., 2010). Figure 1(a) shows a real sentence pair, denoted s, from the GALE ChineseEnglish Word Alignment and Tagging Training corpus (GALE WA corpus)1 with it’s humanannotated word alignment. The Chinese word “HE ZHANG,” denoted wr, which means river custodian, only occurs once in the whole corpus. We performed EM training using GIZA++ on this corpus concatenated with 442,967 training sentence pairs from the NIST Open Machine Translation (OpenMT) 2006 evaluation2. The resulting alignment is shown in Figure 1(b). It can be seen that wr is erroneously aligne</context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Robert C. Moore. 2004. Improving IBM wordalignment model 1. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 518. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Taro Watanabe</author>
<author>Eiichiro Sumita</author>
<author>Shinsuke Mori</author>
<author>Tatsuya Kawahara</author>
</authors>
<title>An unsupervised model for joint phrase alignment and extraction.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>632--641</pages>
<marker>Neubig, Watanabe, Sumita, Mori, Kawahara, 2011</marker>
<rawString>Graham Neubig, Taro Watanabe, Eiichiro Sumita, Shinsuke Mori, and Tatsuya Kawahara. 2011. An unsupervised model for joint phrase alignment and extraction. In ACL, pages 632–641.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
</authors>
<title>The Kyoto free translation task.</title>
<date>2011</date>
<note>http://www.phontron.com/kftt.</note>
<contexts>
<context position="15434" citStr="Neubig, 2011" startWordPosition="2582" endWordPosition="2583">with reference to manual WA annotations, and indirectly using the BLEU score in end-to-end machine translation tasks. GIZA++ and our own implementation of standard EM were used as baselines. 4.1 Experimental Settings The Chinese-English experimental data consisted of the GALE WA corpus and the OpenMT corpus. They are from the same domain, both contain newswire texts and web blogs. The OpenMT evaluation 2005 was used as a development set for MERT tuning (Och, 2003), and the OpenMT evaluation 2006 was used as a test set. The JapaneseEnglish experimental data was the Kyoto Free Translation Task (Neubig, 2011)6. The corpus contains a set of 1,235 sentence pairs that are manually word aligned. The corpora were processed using a standard procedure for machine translation. The English texts were tokenized with the tokenization script released with Europarl corpus (Koehn, 2005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002)7; the Japanese texts 4We found the memory of our server is large enough, so we did not implement it 5We plan to make our code public available. 6http://www.phontron.com/kftt/ 7http://nlp.stanford.edu/softw</context>
</contexts>
<marker>Neubig, 2011</marker>
<rawString>Graham Neubig. 2011. The Kyoto free translation task. http://www.phontron.com/kftt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A comparison of alignment models for statistical machine translation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th conference on Computational linguistics-Volume 2,</booktitle>
<pages>1086--1090</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1797" citStr="Och and Ney, 2000" startWordPosition="241" endWordPosition="244">end-to-end translation were raised by 0.03 – 1.30. The proposed method also outperformed l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++. 1 Introduction Unsupervised word alignment (WA) on bilingual sentence pairs serves as an essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a </context>
<context position="7322" citStr="Och and Ney, 2000" startWordPosition="1149" endWordPosition="1152">re efficient (Wang et al., 2014). 3 Methodology This section first formulates the standard EM for WA, then presents the leave-one-out EM for WA, and finally briefly discusses handling singletons and effecient implementation. The main notation used in this section is shown in Table 1. 3.1 Standard EM for IBM Models 1, 2 and HMM Model To perform WA through EM, the parallel corpus is taken as observed data, the alignments are taken as latent data. In order to maximize the likelihood of the alignment model 0 given the data S, the following two steps are conducted iteratively (Brown et al., 1993b; Och and Ney, 2000; Och and Ney, 2003), Expectation Step (E step): calculating the conditional probability of alignments for each sentence pair, P(a|s,e) = HJj=1 eali(aj|aj−1,I)0lex(fj|eaj),(1) where Bali(i|i′, I) is the alignment probability and Olex(f|e) is the translation probability. Note that 1818 a foreign sentence (f1, ... , fJ) an English sentence (e1, ... , eI) a sentence pair (f, e) an alignment (a1, ... , aJ) where fj is aligned to eaj a list of the indexes of the foreign words which are aligned to ei the index of the k-th foreign word which is aligned to ei is the average of all elements in Bi the l</context>
<context position="17357" citStr="Och and Ney, 2000" startWordPosition="2889" endWordPosition="2892">e to provide a solid basis for comparison, because GIZA++ contains many undocumented details. Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Watanabe, 2012; Tamura et al., 2013)9. We named the implemented aligner AGRIPPA, to support our inhouse decoders OCTAVIAN and AUGUSTUS. In all experiments, WA was performed independently in two directions: from foreign languages to English, and from English to foreign languages. Then the grow-diag-final-and heuristic was used to combine the two alignments from both directions to yield the final alignments for evaluation (Och and Ney, 2000; Och and Ney, 2003). 4.2 Word Alignment Accuracy Word alignment accuracy of the baseline and the proposed method is shown in Table 3 in terms of precision, recall and F1 (Och and Ney, 2003). The proposed method gave rise to higher quality alignments in all our experiments. The improvement in F1, precision and recall based on IBM Model 4 is in the range 8.3% to 9.1% compared with the GIZA++ baseline, and in the range 5.0% to 17.2% compared with our own baseline. The most meaningful result comes from the comparison of the models trained using standard EM log-likelihood training, and the propose</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. A comparison of alignment models for statistical machine translation. In Proceedings of the 18th conference on Computational linguistics-Volume 2, pages 1086–1090. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="1965" citStr="Och and Ney, 2003" startWordPosition="272" endWordPosition="275">d word alignment (WA) on bilingual sentence pairs serves as an essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000). ∗ The author now is affiliated with Google, Japan. The EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013). However, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Gra</context>
<context position="7342" citStr="Och and Ney, 2003" startWordPosition="1153" endWordPosition="1156">et al., 2014). 3 Methodology This section first formulates the standard EM for WA, then presents the leave-one-out EM for WA, and finally briefly discusses handling singletons and effecient implementation. The main notation used in this section is shown in Table 1. 3.1 Standard EM for IBM Models 1, 2 and HMM Model To perform WA through EM, the parallel corpus is taken as observed data, the alignments are taken as latent data. In order to maximize the likelihood of the alignment model 0 given the data S, the following two steps are conducted iteratively (Brown et al., 1993b; Och and Ney, 2000; Och and Ney, 2003), Expectation Step (E step): calculating the conditional probability of alignments for each sentence pair, P(a|s,e) = HJj=1 eali(aj|aj−1,I)0lex(fj|eaj),(1) where Bali(i|i′, I) is the alignment probability and Olex(f|e) is the translation probability. Note that 1818 a foreign sentence (f1, ... , fJ) an English sentence (e1, ... , eI) a sentence pair (f, e) an alignment (a1, ... , aJ) where fj is aligned to eaj a list of the indexes of the foreign words which are aligned to ei the index of the k-th foreign word which is aligned to ei is the average of all elements in Bi the largest index of an E</context>
<context position="10192" citStr="Och and Ney, 2003" startWordPosition="1656" endWordPosition="1659">4) where θ¯sali(i|i′, I) and θlex ¯s(fj |eaj) are the leaveone-out alignment probability and translation probability, respectively. Leave-one-out M step: re-estimating leaveone-out probability models, P s′6=s Ni|i′,I(s′) θ¯s ali(i|i′, I) ← Ps′6=s Ni′,I(s′) (5) P s′6=s Nf|e(s′) θ¯s lex(f|e) ← P (6) s′6=s ne(s′) . 3.3 Standard EM for IBM Model 4 The framework of the standard EM for IBM Model 4 is similar with the one for IBM Models 1, 2 and HMM Model, but the calculation of alignment probability is more complicated. E step: calculating the conditional probability through the reverted alignment (Och and Ney, 2003), P(a|s, θ) = P(B0|B1,... , BI)· θlex(fj|ei), (7) where B0 means the set of foreign words aligned with the empty word; P(B0|B1, ... , BI) is assumed to be a binomial distribution for the size of B0 (Brown et al., 1993b) or an modified distribution to relieve deficiency (Och and Ney, 2003). The distribution P(Bi|Bi−1, ei) is decomposed as P(Bi|Bi−1, ei) = θfer(φi|ei)· φi θhea(Bi,1 − Bρi|Eρi) · Y θoth(Bi,k − Bi,k−1), k=2 (8) where θfer is a fertility model; θhea is a probability model for the head (first) aligned foreign word; θoth is a probability model for the other aligned foreign words. θhea</context>
<context position="16560" citStr="Och and Ney, 2003" startWordPosition="2765" endWordPosition="2768">ake our code public available. 6http://www.phontron.com/kftt/ 7http://nlp.stanford.edu/software/ segmenter.shtml were segmented into words using the Kyoto Text Analysis Toolkit (KyTea8). Sentences longer than 100 words or those with foreign/English word length ratios between larger than 9 were filtered out. GIZA++ was run with the default Moses settings (Koehn et al., 2007). The IBM model 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations. We implemented the proposed leave-one-out EM and standard EM in IBM model 1, HMM model and IBM model 4. In the original work (Och and Ney, 2003) this combination of models achieved comparable performance to the default Moses settings. They were run with 5, 5 and 6 iterations. The standard EM was re-implemented as a baseline to provide a solid basis for comparison, because GIZA++ contains many undocumented details. Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Watanabe, 2012; Tamura et al., 2013)9. We named the implemented aligner AGRIPPA, to support our inhouse decoders OCTAVIAN and AUGUSTUS. In all experiments, WA was performed independently in two directions: from foreign languages to English, and </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1,</booktitle>
<pages>160--167</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15289" citStr="Och, 2003" startWordPosition="2557" endWordPosition="2558">d was tested on two language pairs: Chinese-English and JapaneseEnglish (Table 2). Performance was measured both directly using the agreement with reference to manual WA annotations, and indirectly using the BLEU score in end-to-end machine translation tasks. GIZA++ and our own implementation of standard EM were used as baselines. 4.1 Experimental Settings The Chinese-English experimental data consisted of the GALE WA corpus and the OpenMT corpus. They are from the same domain, both contain newswire texts and web blogs. The OpenMT evaluation 2005 was used as a development set for MERT tuning (Och, 2003), and the OpenMT evaluation 2006 was used as a test set. The JapaneseEnglish experimental data was the Kyoto Free Translation Task (Neubig, 2011)6. The corpus contains a set of 1,235 sentence pairs that are manually word aligned. The corpora were processed using a standard procedure for machine translation. The English texts were tokenized with the tokenization script released with Europarl corpus (Koehn, 2005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002)7; the Japanese texts 4We found the memory of our server is l</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 160–167. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Le Roux</author>
<author>Francis Bach</author>
</authors>
<title>Local component analysis.</title>
<date>2011</date>
<tech>Technical report.</tech>
<marker>Le Roux, Bach, 2011</marker>
<rawString>Nicolas Le Roux and Francis Bach. 2011. Local component analysis. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akihiro Tamura</author>
<author>Taro Watanabe</author>
<author>Eiichiro Sumita</author>
<author>Hiroya Takamura</author>
<author>Manabu Okumura</author>
</authors>
<title>Partof-speech induction in dependency trees for statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>841--851</pages>
<contexts>
<context position="16951" citStr="Tamura et al., 2013" startWordPosition="2827" endWordPosition="2830">el 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations. We implemented the proposed leave-one-out EM and standard EM in IBM model 1, HMM model and IBM model 4. In the original work (Och and Ney, 2003) this combination of models achieved comparable performance to the default Moses settings. They were run with 5, 5 and 6 iterations. The standard EM was re-implemented as a baseline to provide a solid basis for comparison, because GIZA++ contains many undocumented details. Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Watanabe, 2012; Tamura et al., 2013)9. We named the implemented aligner AGRIPPA, to support our inhouse decoders OCTAVIAN and AUGUSTUS. In all experiments, WA was performed independently in two directions: from foreign languages to English, and from English to foreign languages. Then the grow-diag-final-and heuristic was used to combine the two alignments from both directions to yield the final alignments for evaluation (Och and Ney, 2000; Och and Ney, 2003). 4.2 Word Alignment Accuracy Word alignment accuracy of the baseline and the proposed method is shown in Table 3 in terms of precision, recall and F1 (Och and Ney, 2003). Th</context>
</contexts>
<marker>Tamura, Watanabe, Sumita, Takamura, Okumura, 2013</marker>
<rawString>Akihiro Tamura, Taro Watanabe, Eiichiro Sumita, Hiroya Takamura, and Manabu Okumura. 2013. Partof-speech induction in dependency trees for statistical machine translation. In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics, pages 841–851.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao V Grac¸a</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Learning tractable word alignment models with complex constraints.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<marker>Grac¸a, Ganchev, Taskar, 2010</marker>
<rawString>Jo˜ao V Grac¸a, Kuzman Ganchev, and Ben Taskar. 2010. Learning tractable word alignment models with complex constraints. Computational Linguistics, 36(3):481–504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Vaswani</author>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Smaller alignment models for better translations: unsupervised word alignment with the lonorm.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>311--319</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5750" citStr="Vaswani et al., 2012" startWordPosition="880" endWordPosition="883">r et al., 2012). The differences are that their work operates at the phrase level, and their aim is to improve translation models; while our work operates at the word level, and our aim is to provide better word alignment. As word alignment is a foundation of most MT systems, our method have a wider application. Recently, better estimation methods during the maximization step of EM have been proposed to avoid the over-fitting in WA, such as using Kneser-Ney Smoothing to back-off the expected counts (Zhang and Chiang, 2014) or integrating the smoothed l0 prior to the estimation of probability (Vaswani et al., 2012). Our work differs from theirs by addressing the over-fitting directly in the EM algorithm by adopting a leave-one-out approach. Bayesian methods (Gilks et al., 1996; Andrieu et al., 2003; DeNero et al., 2008; Neubig et al., 3The probability distribution of generating target language words from w,.. The description here is only based on IBM model1 for simplicity, and the other alignment models are similar. he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG he him</context>
<context position="25097" citStr="Vaswani et al., 2012" startWordPosition="4123" endWordPosition="4126">ning corpora. The improvements ranged from 0.19 to 1.72 for phrase-based MT and ranged from 0.25 to 3.02 (see Table 5). The improvements are larger under smaller training corpora (see Figure 3). In addition, the BLEUs achieved by the proposed method is close to the ones achieved by gold WA annotations. The proposed method slightly outperforms the gold WA annotations when using the full manual WA corpus of 18,057 sentence pairs. 4.5 Comparison to l0-Iormalization and Kneser-Iey Smoothing Methods The proposed leave-one-word word alignment method was empirically compared to l0-normalized GIZA++ (Vaswani et al., 2012)11 and Kneser-Ney smoothed GIZA++ (Zhang and Chiang, 2014)12. l0-normalization and KneserNey smoothing methods are established methods to overcome the sparse problem. This enables the probability distributions on rare words to be estimated more effectively. In this way, these two GIZA++ variants are related to the proposed method. l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++ were run with the same settings as GIZA++, which came from the default settings of MOSES. For the settings of l0-normalized GIZA++ that are not in common with GIZA++ were the default settings. As for Kneser-Ney smoo</context>
</contexts>
<marker>Vaswani, Huang, Chiang, 2012</marker>
<rawString>Ashish Vaswani, Liang Huang, and David Chiang. 2012. Smaller alignment models for better translations: unsupervised word alignment with the lonorm. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 311–319. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaolin Wang</author>
<author>Masao Utiyama</author>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Empirical study of unsupervised chinese word segmentation methods for smt on large-scale corpora.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>752--758</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="6737" citStr="Wang et al., 2014" startWordPosition="1048" endWordPosition="1051"> the other alignment models are similar. he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG Figure 1: Examples of supervised word alignment. (a) gold alignment; (b) standard EM (GIZA++); (c) Leave-one-out alignment (proposed). 2011), also attempt to address the issue of overfitting, however EM algorithms related to the proposed method have been shown to be more efficient (Wang et al., 2014). 3 Methodology This section first formulates the standard EM for WA, then presents the leave-one-out EM for WA, and finally briefly discusses handling singletons and effecient implementation. The main notation used in this section is shown in Table 1. 3.1 Standard EM for IBM Models 1, 2 and HMM Model To perform WA through EM, the parallel corpus is taken as observed data, the alignments are taken as latent data. In order to maximize the likelihood of the alignment model 0 given the data S, the following two steps are conducted iteratively (Brown et al., 1993b; Och and Ney, 2000; Och and Ney, </context>
</contexts>
<marker>Wang, Utiyama, Finch, Sumita, 2014</marker>
<rawString>Xiaolin Wang, Masao Utiyama, Andrew Finch, and Eiichiro Sumita. 2014. Empirical study of unsupervised chinese word segmentation methods for smt on large-scale corpora. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 752–758, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Machine translation system combination by confusion forest.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1249--1257</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="16913" citStr="Watanabe and Sumita, 2011" startWordPosition="2820" endWordPosition="2823"> settings (Koehn et al., 2007). The IBM model 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations. We implemented the proposed leave-one-out EM and standard EM in IBM model 1, HMM model and IBM model 4. In the original work (Och and Ney, 2003) this combination of models achieved comparable performance to the default Moses settings. They were run with 5, 5 and 6 iterations. The standard EM was re-implemented as a baseline to provide a solid basis for comparison, because GIZA++ contains many undocumented details. Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Watanabe, 2012; Tamura et al., 2013)9. We named the implemented aligner AGRIPPA, to support our inhouse decoders OCTAVIAN and AUGUSTUS. In all experiments, WA was performed independently in two directions: from foreign languages to English, and from English to foreign languages. Then the grow-diag-final-and heuristic was used to combine the two alignments from both directions to yield the final alignments for evaluation (Och and Ney, 2000; Och and Ney, 2003). 4.2 Word Alignment Accuracy Word alignment accuracy of the baseline and the proposed method is shown in Table 3 in terms of precision,</context>
</contexts>
<marker>Watanabe, Sumita, 2011</marker>
<rawString>Taro Watanabe and Eiichiro Sumita. 2011. Machine translation system combination by confusion forest. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1249–1257. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
</authors>
<title>Optimized online rank learning for machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>253--262</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="16929" citStr="Watanabe, 2012" startWordPosition="2824" endWordPosition="2826">07). The IBM model 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations. We implemented the proposed leave-one-out EM and standard EM in IBM model 1, HMM model and IBM model 4. In the original work (Och and Ney, 2003) this combination of models achieved comparable performance to the default Moses settings. They were run with 5, 5 and 6 iterations. The standard EM was re-implemented as a baseline to provide a solid basis for comparison, because GIZA++ contains many undocumented details. Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Watanabe, 2012; Tamura et al., 2013)9. We named the implemented aligner AGRIPPA, to support our inhouse decoders OCTAVIAN and AUGUSTUS. In all experiments, WA was performed independently in two directions: from foreign languages to English, and from English to foreign languages. Then the grow-diag-final-and heuristic was used to combine the two alignments from both directions to yield the final alignments for evaluation (Och and Ney, 2000; Och and Ney, 2003). 4.2 Word Alignment Accuracy Word alignment accuracy of the baseline and the proposed method is shown in Table 3 in terms of precision, recall and F1 (</context>
</contexts>
<marker>Watanabe, 2012</marker>
<rawString>Taro Watanabe. 2012. Optimized online rank learning for machine translation. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 253–262. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joern Wuebker</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Training phrase translation models with leaving-one-out.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>475--484</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5121" citStr="Wuebker et al., 2010" startWordPosition="773" endWordPosition="776">e propose a leave-one-out EM algorithm for WA in this paper. Recently this technique has been applied to avoid over-fitting in kernel density estimation (Roux and Bach, 2011); instead of performing maximum likelihood estimation, maximum leaveone-out likelihood estimation is performed. Figure 1(c) shows the effect of using our technique on the example. The garbage collection has not occurred, and the alignment of the word “HE ZHANG” is identical to the human annotation. 2 Related Work The most related work to this paper is training phrase translation models with leave-one-out forced alignment (Wuebker et al., 2010; Wuebker et al., 2012). The differences are that their work operates at the phrase level, and their aim is to improve translation models; while our work operates at the word level, and our aim is to provide better word alignment. As word alignment is a foundation of most MT systems, our method have a wider application. Recently, better estimation methods during the maximization step of EM have been proposed to avoid the over-fitting in WA, such as using Kneser-Ney Smoothing to back-off the expected counts (Zhang and Chiang, 2014) or integrating the smoothed l0 prior to the estimation of proba</context>
</contexts>
<marker>Wuebker, Mauser, Ney, 2010</marker>
<rawString>Joern Wuebker, Arne Mauser, and Hermann Ney. 2010. Training phrase translation models with leaving-one-out. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 475–484. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joern Wuebker</author>
<author>Mei-Yuh Hwang</author>
<author>Chris Quirk</author>
</authors>
<title>Leave-one-out phrase model training for large-scale deployment.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>460--467</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5144" citStr="Wuebker et al., 2012" startWordPosition="777" endWordPosition="780">out EM algorithm for WA in this paper. Recently this technique has been applied to avoid over-fitting in kernel density estimation (Roux and Bach, 2011); instead of performing maximum likelihood estimation, maximum leaveone-out likelihood estimation is performed. Figure 1(c) shows the effect of using our technique on the example. The garbage collection has not occurred, and the alignment of the word “HE ZHANG” is identical to the human annotation. 2 Related Work The most related work to this paper is training phrase translation models with leave-one-out forced alignment (Wuebker et al., 2010; Wuebker et al., 2012). The differences are that their work operates at the phrase level, and their aim is to improve translation models; while our work operates at the word level, and our aim is to provide better word alignment. As word alignment is a foundation of most MT systems, our method have a wider application. Recently, better estimation methods during the maximization step of EM have been proposed to avoid the over-fitting in WA, such as using Kneser-Ney Smoothing to back-off the expected counts (Zhang and Chiang, 2014) or integrating the smoothed l0 prior to the estimation of probability (Vaswani et al.,</context>
</contexts>
<marker>Wuebker, Hwang, Quirk, 2012</marker>
<rawString>Joern Wuebker, Mei-Yuh Hwang, and Chris Quirk. 2012. Leave-one-out phrase model training for large-scale deployment. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 460–467. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>Building a large-scale annotated chinese corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15828" citStr="Xue et al., 2002" startWordPosition="2641" endWordPosition="2644">enMT evaluation 2005 was used as a development set for MERT tuning (Och, 2003), and the OpenMT evaluation 2006 was used as a test set. The JapaneseEnglish experimental data was the Kyoto Free Translation Task (Neubig, 2011)6. The corpus contains a set of 1,235 sentence pairs that are manually word aligned. The corpora were processed using a standard procedure for machine translation. The English texts were tokenized with the tokenization script released with Europarl corpus (Koehn, 2005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002)7; the Japanese texts 4We found the memory of our server is large enough, so we did not implement it 5We plan to make our code public available. 6http://www.phontron.com/kftt/ 7http://nlp.stanford.edu/software/ segmenter.shtml were segmented into words using the Kyoto Text Analysis Toolkit (KyTea8). Sentences longer than 100 words or those with foreign/English word length ratios between larger than 9 were filtered out. GIZA++ was run with the default Moses settings (Koehn et al., 2007). The IBM model 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations. We implement</context>
</contexts>
<marker>Xue, Chiou, Palmer, 2002</marker>
<rawString>Nianwen Xue, Fu-Dong Chiou, and Martha Palmer. 2002. Building a large-scale annotated chinese corpus. In Proceedings of the 19th International Conference on Computational Linguistics, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zhang</author>
<author>David Chiang</author>
</authors>
<title>Kneser-ney smoothing on expected counts.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>765--774</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="5657" citStr="Zhang and Chiang, 2014" startWordPosition="864" endWordPosition="867">ing phrase translation models with leave-one-out forced alignment (Wuebker et al., 2010; Wuebker et al., 2012). The differences are that their work operates at the phrase level, and their aim is to improve translation models; while our work operates at the word level, and our aim is to provide better word alignment. As word alignment is a foundation of most MT systems, our method have a wider application. Recently, better estimation methods during the maximization step of EM have been proposed to avoid the over-fitting in WA, such as using Kneser-Ney Smoothing to back-off the expected counts (Zhang and Chiang, 2014) or integrating the smoothed l0 prior to the estimation of probability (Vaswani et al., 2012). Our work differs from theirs by addressing the over-fitting directly in the EM algorithm by adopting a leave-one-out approach. Bayesian methods (Gilks et al., 1996; Andrieu et al., 2003; DeNero et al., 2008; Neubig et al., 3The probability distribution of generating target language words from w,.. The description here is only based on IBM model1 for simplicity, and the other alignment models are similar. he himself was then appointed river custodian of panlong river 4ft *A Y1 q 39)2rc XKHE MANG he hi</context>
<context position="25155" citStr="Zhang and Chiang, 2014" startWordPosition="4131" endWordPosition="4134">for phrase-based MT and ranged from 0.25 to 3.02 (see Table 5). The improvements are larger under smaller training corpora (see Figure 3). In addition, the BLEUs achieved by the proposed method is close to the ones achieved by gold WA annotations. The proposed method slightly outperforms the gold WA annotations when using the full manual WA corpus of 18,057 sentence pairs. 4.5 Comparison to l0-Iormalization and Kneser-Iey Smoothing Methods The proposed leave-one-word word alignment method was empirically compared to l0-normalized GIZA++ (Vaswani et al., 2012)11 and Kneser-Ney smoothed GIZA++ (Zhang and Chiang, 2014)12. l0-normalization and KneserNey smoothing methods are established methods to overcome the sparse problem. This enables the probability distributions on rare words to be estimated more effectively. In this way, these two GIZA++ variants are related to the proposed method. l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++ were run with the same settings as GIZA++, which came from the default settings of MOSES. For the settings of l0-normalized GIZA++ that are not in common with GIZA++ were the default settings. As for Kneser-Ney smoothed GIZA++, the smooth switches of IBM models 1 – 4 and H</context>
</contexts>
<marker>Zhang, Chiang, 2014</marker>
<rawString>Hui Zhang and David Chiang. 2014. Kneser-ney smoothing on expected counts. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 765–774, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>