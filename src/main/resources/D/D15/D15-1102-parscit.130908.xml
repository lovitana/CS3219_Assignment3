<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000417">
<title confidence="0.960858">
Joint Mention Extraction and Classification with Mention Hypergraphs
</title>
<author confidence="0.999395">
Wei Lu Dan Roth
</author>
<affiliation confidence="0.9491365">
Singapore University University of Illinois
of Technology and Design at Urbana-Champaign
</affiliation>
<email confidence="0.993213">
luwei@sutd.edu.sg danr@illinois.edu
</email>
<sectionHeader confidence="0.993709" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999236">
We present a novel model for the task
of joint mention extraction and classifi-
cation. Unlike existing approaches, our
model is able to effectively capture over-
lapping mentions with unbounded lengths.
The model is highly scalable, with a time
complexity that is linear in the number of
words in the input sentence and linear in
the number of possible mention classes.
Our model can be extended to additionally
capture mention heads explicitly in a joint
manner under the same time complexity.
We demonstrate the effectiveness of our
model through extensive experiments on
standard datasets.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999784967741936">
One of the essential goals in natural language pro-
cessing (NLP) is the development of effective sys-
tems that can capture the underlying semantics
conveyed by human languages. An important step
towards such a goal is the development of practi-
cal systems that can efficiently extract useful shal-
low semantic information such as entities and at
the same time identify their semantic classes (e.g.,
person, organization, etc).
Such a task is often known as named entity
recognition and classification (NERC), one of
the standard tasks in information extraction (IE).
While such a task focuses on the extraction and
classification of entities in the texts which are
named, recently researchers also showed inter-
est in a closely related task – mention extraction
and classification/typing. Unlike a named entity,
a mention is typically defined as a reference to
an entity in natural language text that can be ei-
ther named, nominal or pronominal (Florian et al.,
2004). The task of mention detection and track-
ing has received substantial attention, largely due
to its important role in conducting several down-
stream tasks, such as relation extraction (Mintz et
al., 2009), entity linking (Guo et al., 2013), and
coreference resolution (Chang et al., 2013).
While most existing work on named entity
recognition and mention extraction and classifi-
cation have been effective, there remain several
key limitations associated with existing models. In
fact, one can view these problems as instances of
the more general problem of semantic tagging –
the task of assigning appropriate semantic tags to
certain text spans for a given input sentence. Un-
like part-of-speech (POS) tagging, which has been
extensively studied in the past few decades by the
community, such a semantic tagging task presents
several additional new challenges. First, a men-
tion can consist of multiple words, so its length
can be arbitrarily long. Second, the mentions can
overlap with one another. Popular models used for
POS tagging, such as linear-chain conditional ran-
dom fields (Lafferty et al., 2001) or semi-Markov
conditional random fields (Sarawagi and Cohen,
2004) have difficulties coping with these issues.
While approaches on addressing these issues ex-
ist, current algorithms typically suffer from high
time complexity (Finkel and Manning, 2009) and
are therefore difficult to scale to large datasets.
On the other hand, the problem of designing ef-
ficient and scalable models for mention extraction
and classification from natural language texts be-
comes increasingly important in this era where a
large volume of textual data is becoming available
on the Web every day – users need systems which
are able to scale to extremely large datasets to sup-
port efficient semantic analysis for timely decison-
making.
In this paper, we tackle the above-mentioned is-
sue by introducing a novel model for joint mention
extraction and classification. We make the follow-
ing major contributions in this work:
</bodyText>
<listItem confidence="0.948241">
• We propose a model that is able to effectively
</listItem>
<page confidence="0.970568">
857
</page>
<note confidence="0.9843895">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 857–867,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.796275">
handle overlapping mentions with unbounded
lengths.
</bodyText>
<listItem confidence="0.923594777777778">
• The learning and inference algorithms of our
proposed model have a time complexity that is
linear in the number of words in the input sen-
tence and also linear in the number of possi-
ble semantic classes/types, making our model
scalable to extremely large datasets.
• Our model can additionally capture mentions’
head information in a joint manner under the
same time complexity.
</listItem>
<bodyText confidence="0.9562">
Our system and code are available for download
from http://statnlp.org/research/ie/.
</bodyText>
<sectionHeader confidence="0.999791" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999957396226415">
Existing work has been largely focused on the
task of named entity recognition and classifica-
tion (NERC). The survey of (Nadeau and Sekine,
2007) is a comprehensive study of this topic.
Most prior work took a supervised learning ap-
proach. Zhou and Su (2002) presented a system
for recognizing named entities using an HMM-
based approach. Florian et al. (2003) presented a
system for named entity recognition by combining
different classifiers. McDonald and Pereira (2005)
used conditional random fields for extracting gene
and protein mentions from biomedical texts. Rati-
nov and Roth (2009) presented a systematic anal-
ysis over several issues related to the design of a
named entity recognition and classification system
where issues such as chunk representations and
the choice of inference algorithms were discussed.
Researchers also looked into semi-supervised and
unsupervised approaches for such a task (Cuc-
chiarelli and Velardi, 2001; Etzioni et al., 2005).
Additional efforts on addressing the NERC prob-
lem under a multilingual or cross lingual setting
also exist (Florian et al., 2004; Che et al., 2013;
Wang et al., 2013).
As pointed out by Finkel and Manning (2009),
named entities are often nested. This fact was of-
ten ignored by the community largely due to tech-
nical reasons. They therefore proposed to use a
constituency parser with a O(n3) time complexity
(n is the number of words in the input sentence)
to handle nested entities, and showed its effective-
ness across several datasets. Alex et al. (2007) also
presented several approaches by building models
on top of linear-chain conditional random fields
for recognizing nested entities in biomedical texts.
Hoffmann et al. (2011) looked into a separate
issue, which is to identify overlapping relations
amongst entities.
Named entity recognition and classification still
remains a popular topic in the field of statistical
natural language processing. Ritter et al. (2011)
looked into recognizing entities from social me-
dia data that involves informal and potentially
noisy texts. Pasupat and Liang (2014) looked
into the issue of zero-shot entity extraction from
Web pages with natural language queries where
minimal supervision was used. Neelakantan and
Collins (2014) looked into the problem of auto-
matically constructing dictionaries with minimal
supervision for improved named entity extraction.
Li and Ji (2014) presented an approach to perform
the task of extraction of mentions and their rela-
tions in a joint and incremental manner.
</bodyText>
<sectionHeader confidence="0.999574" genericHeader="method">
3 Approach
</sectionHeader>
<subsectionHeader confidence="0.999816">
3.1 Mentions and Their Combinations
</subsectionHeader>
<bodyText confidence="0.999339148148148">
Typically, a mention that appears in a natural lan-
guage sentence consists of a contiguous sequence
of natural language words. Consider a sentence
that consists of n words where each word is in-
dexed with its position in the sentence. A men-
tion m can be uniquely represented with a tuple
(bm, em, 7), where bm and em are the indices of
the first and last word of the mention, respectively,
and 7 is its semantic class (type).
We can see that for a given sentence consisting
of n words, there are altogether tn(n + 1)/2 pos-
sible different mention candidates, where t is the
total number of possible mention types. Now, for
each such candidate in the given sentence, it can
be either a mention, or not a mention. This leads
to a total number of 2tn(n+1)/2 possible mention
combinations. This number is prohibitively large
even for small values of n and t, which prevents us
from exhaustively enumerating all of them during
learning and inference.
One approach to performing inference over
such a large space is to introduce compact rep-
resentations that are able to encode exponentially
many mentions that would enable tractable infer-
ence algorithms to be employed. We discuss in the
next section our novel mention hypergraph repre-
sentation proposed for such a purpose.
</bodyText>
<subsectionHeader confidence="0.999618">
3.2 Mention Hypergraphs
</subsectionHeader>
<bodyText confidence="0.998185">
Central to our approach is the introduction of
the novel mention hypergraphs that allow us to
</bodyText>
<page confidence="0.998121">
858
</page>
<figureCaption confidence="0.873962">
Figure 1: The (partial) hypergraph for representing all possi-
ble combinations of mention occurrences. Links that belong
to the same hyperedge are highlighted with the same color,
and different hyperedges are highlighted with different col-
ors, e.g., the green link that connects two I nodes forms a
single hyperedge, while the two brown links that connect two
I nodes and one X node form a separate single hyperedge.
</figureCaption>
<bodyText confidence="0.99869795">
compactly represent exponentially many possible
combinations of potentially overlapping, length-
unbounded mentions of different types.
A hypergraph is a generalization of a conven-
tional graph, whose edges (a.k.a. hyperedges) can
connect two or more nodes. In this work, we con-
sider a special class of hypergraphs, where each
hyperedge consists of a designated parent node
and an ordered list of child nodes. Hypergraphs
have also been used in other fields, such as syntac-
tic parsing (Klein and Manning, 2001), semantic
parsing (Lu, 2015) and machine translation (Cme-
jrek et al., 2013).
Our mention hypergraphs consist of five types
of nodes which are used to compactly represent
many mentions of different semantic types and
boundaries, namely, A nodes, E nodes, T nodes, I
nodes, and X nodes. A partial mention hypergraph
is depicted in Figure 1. We describe the definition
of each type of nodes next.
</bodyText>
<listItem confidence="0.992810818181818">
• A nodes. These nodes are used to sequentially
arrange mentions with different left bound-
aries. Specifically, each A node at position
k (the k-th word), or Ak, is used to com-
pactly represent all such mentions in the sen-
tence whose left boundaries are exactly at or
strictly after k.
• E nodes. The node Ek is used to compactly
represent all possible mentions (possibly of
length zero) whose left boundaries are exactly
at the current position k.
• T nodes. The node Tkj is used to compactly
represent all mentions (possibly of length
zero) whose left boundaries are exactly at po-
sition k, and have the mention type j.
• I nodes. The node Ikj is used to compactly
represent all incomplete mentions which con-
tain the current word at position k as part of
the mention, and have the mention type j.
• X nodes. These are the “terminal” nodes indi-
cating the completion of a path. No additional
node will be attached to such nodes as a child.
</listItem>
<bodyText confidence="0.978123725">
There are also various hyperedges that con-
nect different nodes in the mention hypergraph.
We use (α ← β1, ... , βn) to denote a hyperedge
which connects a parent node α and child nodes
β1, . . . , βn.Each hyperedge essentially provides
one possible way of re-expressing the semantics
conveyed by the parent node using the child nodes.
For example, as shown in Figure 1, the hyperedge
connecting the parent node Ak and the child nodes
Ek, Ak+1 explains the fact that any mention cov-
ered by Ak either has a left boundary that is “ex-
actly at k” (Ek), or “exactly at or strictly after
k + 1” (Ak+1).
Similarly, for each I node, there exist 3 hyper-
edges that connect it to other child nodes. The top
hyperedge (in green) encodes the fact that the cur-
rent word appears in the middle of a mention; the
bottom hyperedge (in yellow) encodes the fact that
the current word appears in a mention as the last
word; the middle hyperedge (in brown) encodes
the fact that both cases can occur at the same time
(i.e., the current word belongs to multiple over-
lapping mentions of the same type). We have the
following theorem:
Theorem 3.1 Any combination of mentions in a
sentence can be represented with exactly one sub-
hypergraph of the complete mention hypergraph.
Proof For each mention, there exists a unique
path in the mention hypergraph to represent it. For
any combination of mentions, there exist unique
paths in the mention hypergraph to represent such
a combination. These paths altogether form a
unique sub-hypergraph of the original hypergraph.
For example, consider the following sentence:
“he also talked with the egyptian president .” This
sentence contains three mentions. The first is “he”
with type PER, the second is “the egyptian pres-
ident’’ with type PER, and the third mention is
“egyptian” with type GPE. Figure 2 gives the sub-
hypergraph structure showing how these mentions
</bodyText>
<figure confidence="0.972945523809524">
k k + 1
...
...
X
A A
E E
Ti
Ti
...
...
Tj
X Tj X
...
...
Tm
Tm
...
...
Ij Ij
859
He also talked with the Egyptian president .
</figure>
<figureCaption confidence="0.998639666666667">
Figure 2: An example sub-hypergraph structure for jointly representing all the three mentions that appear in the sentence “He
also talked with the Egyptian president .” For simplicity and the ease of illustration, we assume there are only two possible
mention types: PER and GPE.
</figureCaption>
<figure confidence="0.790437">
T1 X T1 X T1 X T1 X T1 X T1 T1 X T1 X
T2 T2 X T2 X T2 X T2 T2 X T2 X T2 X
I2 I2 I2 I2
[PER]
A A A A A A A A
X [ PER ] X
E E E E E E E E
I1
X
[GPE]
</figure>
<bodyText confidence="0.990710571428571">
are jointly represented. The mention hypergraph
defined over the input sentence contains exponen-
tially many such sub-hypergraph structures.
We note that the converse of Theorem 3.1 is not
true. In certain cases, it is possible for two differ-
ent overlapping mention combinations to share the
same mention hypergraph.
</bodyText>
<figureCaption confidence="0.953415">
Figure 3: An example illustrating the converse of Theorem
3.1 is not true.
</figureCaption>
<bodyText confidence="0.999964863636364">
For example, consider a toy example sentence A
B C D shown in Figure 3, both B C and A B C D are
mentions of the same type PER (i.e. one is strictly
contained by the other. We call such combinations
type-I combinations). The above sub-hypergraph
shows how to encode such a combination. How-
ever, if both A B C and B C D are mentions of the
same type PER (i.e., two mentions overlap but no
one is contained by the other. We call such com-
binations type-II combinations), such a combina-
tion shares the same representation as the above
sub-hypergraph. Note that such an ambiguity hap-
pens only when two overlapping mentions have
the same type, and one mention is strictly con-
tained by the other and their boundaries are all dif-
ferent. In practice, however, we found that in the
two datasets that we used for evaluations, if two
mentions overlap with one another, they almost al-
ways form a type-I combination, and type-II com-
binations are very rare. Empirically, as we will see
later in our experiments, our model is effective in
handling overlapping mentions.
</bodyText>
<subsectionHeader confidence="0.98908">
3.3 Log-Linear Modeling
</subsectionHeader>
<bodyText confidence="0.999889714285714">
Following the conditional random fields (Lafferty
et al., 2001), we adopted a log-linear approach for
such a joint mention extraction and typing task.
Specifically, for a given input sentence x, the prob-
ability of predicting a possible output y (a mention
sub-hypergraph that represents a particular combi-
nation of mentions) is given as follows:
</bodyText>
<equation confidence="0.979655666666667">
exp(wTf(x,y))
p(y|x) = (1)
Ey/ exp(wTf(x, y&apos;))
</equation>
<bodyText confidence="0.9998782">
where f(x, y) is the feature vector defined over the
input-output pair (x, y), and the weight vector w
gives the parameters of the model.
Our objective is to minimize the regularized
negative joint log-likelihood of the dataset:
</bodyText>
<equation confidence="0.985518857142857">
exp(wTf(xi, y&apos;))
y/
:− wT f(xi, yi) + AwTw (2)
i
A B C D
[ PER ]
[ PER ]
T1 X T1 X T1 T1 X
T2 T2 T2 X T2 X
I2 I2 I2 I2
A A A A
E E E E
I1
X
X X
[GPE]
:
L(w) =
i
:
log
</equation>
<page confidence="0.94376">
860
</page>
<bodyText confidence="0.9999915">
where (xi, yi) refers to the i-th training instance,
and the last term is a L2 regularization term with A
being a positive scalar (fixed to 0.01 in this work).
The gradient of the above objective function is:
</bodyText>
<equation confidence="0.978832666666667">
Ep(y&apos;|xi)[fk(xi, yI)l
�− fk(xi, yi) + 2Awk (3)
Z
</equation>
<bodyText confidence="0.999775">
where wk is the weight of the k-th feature fk.
We note that unlike many recent latent-variable
approaches to structured prediction (Petrov and
Klein, 2007; Blunsom et al., 2008), we are able to
represent each of our outputs y with a single fully-
observed structure. Thus, our objective function
essentially defines a standard regularized softmax
regression model, and is therefore convex (Boyd
and Vandenberghe, 2004), where a global opti-
mum can be found.
The objective function defined in Equation 2
can be optimized with standard gradient-based
methods. We used L-BFGS (Liu and Nocedal,
1989) as our optimization method.
</bodyText>
<subsectionHeader confidence="0.904005">
3.4 Algorithms
</subsectionHeader>
<bodyText confidence="0.999979772727273">
In order to solve the optimization problem de-
scribed above, one needs to compute the values
of the gradient scores in Equation 3. Computa-
tion of the second and third terms in this equa-
tion is straightforward. The first term in Equa-
tion 3 involves the computation of an expecta-
tion of feature values over all possible mention
combinations for a given input sentence. Follow-
ing classic dynamic programming algorithms used
in graphical models, we develop analogous effi-
cient dynamic programming algorithms that work
on hypergraphs and generalize the conventional
forward-backward/inside-outside algorithm to ef-
ficiently compute such values.
Time Complexity At each time step k, we need
to compute scores for m I nodes, m T nodes, 1 E
node, and 1 A node. Hence, the overall time com-
plexity for our algorithm is in O(mn) (assuming
computation of the feature scores at each node in-
volves a constant time), where m is the total num-
ber of possible mention types, and n is the total
number of words in the given sentence. 1
</bodyText>
<footnote confidence="0.698682">
1Note that the time complexity for the linear chain CRF is
in O(m2n) due to their first-order assumption.
</footnote>
<sectionHeader confidence="0.69981" genericHeader="method">
3.5 Features
</sectionHeader>
<bodyText confidence="0.998235666666667">
The features that we use are inspired by the work
of (Carreras et al., 2002). Specifically, we consider
the following features defined over the inputs:
</bodyText>
<listItem confidence="0.989859888888889">
• Words (and POS tags, if available) that appear
around the current word (with position infor-
mation), with a window of size 3.
• Word n-grams (and POS n-grams, if available)
that contain the current word (with position in-
formation), for n = 2, 3, 4.
• Bag of words around the current word, with a
window of size 5.
• Word pattern features 2.
</listItem>
<bodyText confidence="0.9988124">
Note that these are the indicator functions de-
fined over the inputs. The final set of features are
defined over (x, y) tuples, which is obtained as a
cross-product between the above indicator func-
tions and the following indicator function:
</bodyText>
<listItem confidence="0.55217">
• The type of the node (such as T or I).
</listItem>
<bodyText confidence="0.998942">
In addition, we also introduce the following fea-
ture defined over the output structure only:
</bodyText>
<listItem confidence="0.826869">
• The number of such hyperedges that exactly
connect one T node and one I node.
</listItem>
<bodyText confidence="0.998735">
We call this feature mention penalty. This fea-
ture learns a global preference of the number of
mentions that should appear in any input sentence.
</bodyText>
<subsectionHeader confidence="0.981122">
3.6 Joint Modeling of Mention Heads
</subsectionHeader>
<bodyText confidence="0.999972473684211">
One additional assumption for the mention extrac-
tion and typing task is that each mention comes
with a head. A head is strictly a substring of the
mention and provides important information about
the mention. It is possible to extend our model
to support joint modeling of mention heads, while
still maintaining the same time complexity.
Due to space limitations, we could only give
a relatively brief description of this extension in
this section. The idea is to replace the I nodes
with three different types of nodes, namely Ij–B
nodes (used to represent words that appear within
a mention of type j and before its head), Ij–W
nodes (used to represent words that appear within
the head of a mention of type j), and Ij–A nodes
(used to represent words that appear within a men-
tion of type j and after its head). The hyperedges
also need to be established accordingly in order
to properly model all possible mention and head
</bodyText>
<construct confidence="0.816031666666667">
2all-caps, all-digits, all-alphanumeric, contains-digits,
contains-dots, contains-hyphen, initial-caps, lonely-initial,
punctuaion-mark, roman-number, single-character, URL.
</construct>
<figure confidence="0.668945">
aL(w)
awk
�=
Z
</figure>
<page confidence="0.968218">
861
</page>
<table confidence="0.9997745">
TRAIN ACE2004 TEST TRAIN ACE2005 TEST
DEV DEV
Documents 356 41 46 370 43 51
Sentences 6,799 829 879 7,336 958 1,047
with o.l. mentions 2,683 (39%) 293 (35%) 373 (42%) 2,683 (37%) 340 (35%) 330 (32%)
Mentions 22,207 2,511 3,031 24,687 3,217 3,027
length &gt; 6 1,439 (6%) 179 (7%) 199 (7%) 1,343 (5%) 148 (5%) 160 (6%)
max length 57 35 43 49 30 27
</table>
<tableCaption confidence="0.994651">
Table 1: Corpora statistics for the ACE2004 and ACE2005 datasets.
</tableCaption>
<table confidence="0.999962888888889">
P DEV ACE2004 P TEST F P DEV ACE2005 P TEST F
R F R R F R
CRF (BIO) 69.6 42.8 53.0 70.0 40.3 51.2 69.8 45.3 55.0 67.6 43.7 53.1
CRF (BILOU) 70.7 42.6 53.1 71.8 40.8 52.1 71.1 45.5 55.5 69.5 44.5 54.2
CRF (CC) 77.9 49.1 60.2 78.4 46.4 58.3 76.8 52.0 62.0 74.8 49.1 59.3
Semi-CRF (c=6) 75.4 44.1 55.6 76.1 41.4 53.6 75.3 48.5 59.0 72.8 45.0 55.6
Semi-CRF (c=∞) 66.8 44.8 53.7 66.7 42.0 51.5 69.7 48.9 57.5 67.5 46.1 54.8
MH 79.6 50.0 61.4 79.2 46.8 58.9 79.3 50.6 61.8 76.9 47.7 58.9
MH (F) 70.0 59.2 63.8 70.0 56.9 62.8 67.5 61.8 64.5 66.3 59.2 62.5
</table>
<tableCaption confidence="0.999843">
Table 2: Results on ACE2004 and ACE2005. The last two rows give the results of this work.
</tableCaption>
<bodyText confidence="0.9990234">
combinations. Since in such a new hypergraph, at
each time step, only a constant number (2) of addi-
tional nodes are involved, the time complexity for
learning and inference with such a model remains
the same, which is in O(mn).
</bodyText>
<subsectionHeader confidence="0.997278">
3.7 Optimization of F measure
</subsectionHeader>
<bodyText confidence="0.999990054054054">
One standard evaluation metric for named entity
recognition is the F (Fl) measure. In our task,
the F measure is defined as the harmonic mean
of the precision (P) and recall (R) scores, where
precision is the ratio between the number of cor-
rectly predicted mentions and the total number of
predicted mentions, and recall is the ratio between
the number of correctly predicted mentions and
the total number of gold mentions. We will also
adopt these metrics in our evaluations later. Un-
fortunately, the model only optimizes its objec-
tive function defined in Equation 2, which is the
negative (regularized) joint log-likelihood. Previ-
ous work showed it was possible to optimize the
F measure in a log-linear model (Suzuki et al.,
2006). Culotta and McCallum (2004) also pro-
posed a method for optimizing information extrac-
tion performance based on confidence estimation.
Their work is based on linear-chain CRF and es-
timate the confidence of extracted fields based on
marginal probabilities. The technique is not di-
rectly applicable to our task where a hypergraph
representation is used to encode overlapping men-
tions. In this work, we used a very simple and
intuitive technique for optimizing the F measure.
The idea is to further tune the weight of a single
parameter – mention penalty based on the devel-
opment set, after the training process completes.
This is based on the observation that by increas-
ing the value of the mention penalty, we are essen-
tially forcing our model to predict more mentions.
Therefore the recall is a monotonic function with
respect to the mention penalty. Based on this fact,
we use a simple search algorithm with a fixed step
size (we set it to 0.01) to determine the optimal
value of the modified mention penalty so that the
F measure of the development set is optimized.
</bodyText>
<sectionHeader confidence="0.999585" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999255">
In this section, we present empirical evaluations.
Our main experiments were conducted on the stan-
dard ACE2004 and ACE2005 datasets which
contain overlapping mentions. Two additional ex-
periments on the GENIA and CONLL2003 dataset
were also conducted.
</bodyText>
<subsectionHeader confidence="0.942337">
4.1 Results on ACE
</subsectionHeader>
<bodyText confidence="0.999988818181818">
Our primary experiments were conducted based
on the English portion of the ACE2004 dataset3
and the ACE2005 dataset4. Following previous
work, for ACE2004, we considered all documents
from arabic treebank, bnews, chinese treebank,
and nwire, and for ACE2005, we considered all
documents from bc, bn, nw, and wl . We randomly
split the documents for each dataset into three por-
tions: 80% for training, 10% for development, and
the remaining 10% for evaluations. The statistics
of the datasets are summarized in Table 15. We
</bodyText>
<footnote confidence="0.99930125">
3https://catalog.ldc.upenn.edu/LDC2005T09
4https://catalog.ldc.upenn.edu/LDC2006T06
5Exact train/dev/test splits information can be found on
http://statnlp.org/research/ie/.
</footnote>
<page confidence="0.997132">
862
</page>
<bodyText confidence="0.999923520833334">
can observe that overlapping mentions are com-
mon – over 30% of the sentences contain overlap-
ping mentions (see row 3 of the table). Mentions
can also be very long – over 5% of the mentions
consist of more than 6 words, and the longest men-
tion consists of 57 words.
We compared our system’s performance with
those of several baseline approaches. We first
built two simple baseline approaches based on se-
quence labelling models using the conditional ran-
dom fields (CRFs). Such approaches can not han-
dle overlapping mentions. To train such mod-
els, whenever two mentions overlap with one an-
other in the training set, we remove the mention
that is shorter in length. Following (Ratinov and
Roth, 2009), we considered the BIO (Begin, In-
side, Outside) approach and the BILOU (Begin,
Inside, Last, Outside, Unit) approach for design-
ing the output labels. Results show the BILOU ap-
proach yields better results. Similar observations
were reported in Ratinov and Roth (2009).
In the work of (Alex et al., 2007), the authors
proposed several approaches for building mod-
els to handle nested named entities in biomedi-
cal texts. Their best results were obtained from a
cascaded approach where they built one model for
each named entity class. Outputs from one model
can then served as the inputs to the next model
for predicting the named entity class of a differ-
ent type. One fundamental limitation of such an
approach is that it being unable to handle overlap-
ping mentions of the same type. Nevertheless, this
approach worked very well on both datasets. The
results are shown in the row of “CRF (CC)”.6
Another class of models that is often used in in-
formation extraction are the semi-Markov condi-
tional random fields (semi-CRFs) (Sarawagi and
Cohen, 2004). Semi-CRF models are able to cap-
ture the non-Markovian properties of mentions.
However, they are unable to handle nested or over-
lapping mentions. We thus used the same method
as discussed above to exclude certain mentions
for training. Such semi-CRF models typically as-
sume there is a length restriction for the mentions
– each mention can consist of up to c words – in
order to scale linearly. When such a restriction
is lifted, the time complexity of such models be-
comes quadratic in the number of words in the in-
</bodyText>
<footnote confidence="0.9970036">
6For all such linear chain CRF-related experiments, we
used the CRF++ toolkit (https://code.google.com/p/crfpp/)
with L-BFGS, which gives us the most competitive re-
sults over several different CRF implementations (see:
http://www.chokkan.org/software/crfsuite/benchmark.html).
</footnote>
<table confidence="0.98663775">
7 TYPES 14 TYPES 28 TYPES
#f w/s #f w/s #f w/s
CRF 3.6M 1219 13.6M 305 51.9M 76
MH 4.2M 1532 8.4M 733 16.9M 430
</table>
<tableCaption confidence="0.999392">
Table 3: The decoding time and the number of features
</tableCaption>
<bodyText confidence="0.98612552173913">
change as we increase the number of possible types. (#f:
number of features created (in millions). w/s: number of
words processed per second.) Experiments are conducted on
the ACE 2004 dataset.
put sentence. We train two models: one with a
length restriction, where c = 6, and the other with-
out a length restriction (c = ∞). For features de-
fined over the inputs, besides the Markovian fea-
tures described in Sec 3.5, we also used the sur-
face forms of complete mention spans as features.
The results of these two models are reported in the
fourth and fifth row of Table 2, respectively. Inter-
estingly, imposing the length restriction appears to
be helpful for precision, and as a result it makes a
positive contribution towards the final F measure.
Our basic model (MH: mention hypergraph)
that optimizes the negative joint log likelihood is
able to obtain the best precision across these two
datasets. When the model is further augmented
with the F measure optimization step described in
Sec 3.7 (MH (F)) it consistently yields the best
results in terms of both recall score and F measure
across these two datasets.
</bodyText>
<subsectionHeader confidence="0.975774">
4.1.1 Running Time
</subsectionHeader>
<bodyText confidence="0.999973347826087">
We also conducted controlled experiments to re-
port the actual execution time of our model and
make a comparison with the linear-chain CRF
model (BILOU approach). The experiments are
all conducted on the ACE2004 dataset on the same
machine. To make a proper comparison here,
we implemented the linear-chain CRF model us-
ing Java (the same language is used when imple-
menting our model), and employed the same data
structures for creating features as well as the same
learning and inference routines used by our men-
tion hypergraph model.
To understand how the features and speed
change as we increase the number of mention
types (i.e., semantic types), we also conducted ex-
periments where we increase the number of possi-
ble mention types. Specifically, we created sub-
types from each original type annotated in the
dataset. For example, we randomly replaced the
type “GPE” by sub-types “GPE1” or “GPE2” in
the dataset. This gave us 14 different mention
types. Similarly, we could randomly replace the
type “GPE” by sub-types “GPE1” – “GPE4”, re-
</bodyText>
<page confidence="0.998001">
863
</page>
<table confidence="0.999728222222222">
P DEV ACE2004 P TEST F P DEV ACE2005 P TEST F
R F R R F R
CRF (CC-S) 57.0 35.9 44.1 52.7 31.2 39.2 56.5 38.3 45.6 54.2 35.5 42.9
CRF (CC-F) 51.5 32.5 39.9 47.4 28.0 35.2 53.3 36.1 43.1 51.3 33.6 40.6
CRF (CC-L) 64.4 40.6 49.9 61.6 36.4 45.8 66.6 45.1 53.8 65.3 42.8 51.7
CRF (CC-CC) 63.6 40.5 49.5 60.8 36.1 45.3 65.9 44.8 53.3 64.2 42.0 50.7
MH (L) 66.7 41.9 51.5 64.7 38.2 48.1 70.5 45.0 55.0 69.2 43.0 53.0
MH (Joint) 78.6 47.4 59.1 79.0 44.1 56.6 79.2 48.7 60.3 70.1 45.1 54.8
MH (Joint F) 73.9 52.4 61.3 74.4 50.0 59.8 70.2 57.4 63.2 63.4 53.8 58.3
</table>
<tableCaption confidence="0.999933">
Table 4: Results on joint mention boundary, type, and head prediction on ACE2004 and ACE2005.
</tableCaption>
<bodyText confidence="0.999948956521739">
sulting in 28 different mention types in total. Our
purpose of doing so is to understand how the mod-
els behave when the number of possible mention
types becomes large. We found that training on the
entire training set of ACE2004 using the linear-
chain CRF model with a large number of men-
tion types was very expensive due to the extremely
large number of features involved. We instead
trained the models on the development set and pre-
sented decoding time on the test set.
Table 3 shows the results. We empirically cap-
tured the relationship between the speed of each
system (average number of words processed per
second) and the number of mention types. Specif-
ically, we found that as we linearly increased the
number of mention types, for the linear-chain CRF
model, the number of features grew quadratically
and the speed dropped quadratically, whereas for
our model, the number of features grew linearly
and the speed dropped linearly. This indicates
that our model is more scalable to large, practical
datasets with a large number of fine-grained men-
tion types.
</bodyText>
<subsectionHeader confidence="0.669593">
4.1.2 Joint Modeling of Heads
</subsectionHeader>
<bodyText confidence="0.999984">
We also conducted experiments on these two
datasets for the task of joint modeling of mention
boundaries, types and heads. We used the same
training and tuning methodology for optimizing
the F measure. In such experiments, we adopted
a very strict evaluation criterion: a predicted men-
tion is regarded as correct iff and only if its bound-
aries, type and head all exactly match those of the
gold standard.
We compared our system’s results with those of
several baseline approaches based on CRF where
the cascaded BILOU approach described above
was always used. Specifically, we considered ap-
proaches that always regarded the complete span
(CC-S), the first word (CC-F), and the last word
(CC-L) as the predicted mention’s head, respec-
tively. We also considered a cascaded approach
(CC-CC) where we first predicted mentions, and
then predicted their heads by following a simi-
lar approach used for predicting overlapping men-
tions discussed above. The first four rows of Ta-
ble 4 give the results of these baseline approaches.
We can observe that always predicting the last
word as the head gives the best performance. In-
spired by this, we performed a simple approach
by training a model presented in the previous sec-
tion without considering head information. When
making predictions, we always regarded the last
word of each predicted mention as its head. The
results for such an approach are given in the fifth
row of Table 4. The sixth row shows the results ob-
tained by optimizing our model’s objective func-
tion. The last row gives the results obtained by
tuning the mention penalty based on the develop-
ment set. As seen, our joint models significantly
outperformed all those baseline approaches. We
are not aware of any prior work in the literature
that performs joint modeling of mention bound-
aries, types, and heads.
</bodyText>
<subsectionHeader confidence="0.997927">
4.2 Additional Experiments
</subsectionHeader>
<bodyText confidence="0.999916625">
We also additionally evaluated on the GENIA
dataset (v3.02) whose focus was on biomedical
related named entity recognition and classifica-
tion, where the entities may overlap with one an-
other. Furthermore, to see how our model works
on datasets where mentions do not overlap with
one another, we also conducted evaluations on the
standard CONLL2003 NER dataset.
</bodyText>
<sectionHeader confidence="0.498981" genericHeader="evaluation">
4.2.1 Results on GENIA
</sectionHeader>
<bodyText confidence="0.9999153">
We followed the description of Finkel and Man-
ning (2009) to set up our experiments on the GE-
NIA dataset. Specifically, we used the first 90% of
the sentences as the training data and the remain-
ing 10% as the evaluation data. We also adhered
to the paper’s prescription of collapsing all DNA
subtypes into DNA; RNA subtypes into RNA; and
all protein subtypes into protein. We kept cell line
and cell type, and removed all other entities.
To optimize the F measure, we further split the
</bodyText>
<page confidence="0.994502">
864
</page>
<table confidence="0.999889">
P R F
Semi-CRF 76.2 61.7 68.2
F &amp; M (2009) 75.4 65.9 70.3
MH (F) 72.5 65.2 68.7
</table>
<tableCaption confidence="0.99983">
Table 5: Results on the GENIA dataset
</tableCaption>
<bodyText confidence="0.999980217391304">
training set into two portions. We trained a model
using the first 90% of the training data, and used
the remaining 10% for development. For features,
no POS and no bag-of-words features are used.
We compared our model’s performance with
that of a model based on a constituency parser pro-
posed by (Finkel and Manning, 2009), as well as
the semi-CRF model reported there. The results
are shown in Table 5. Our model yields a better
F measure than the semi-CRF model, but gives a
lower performance than the model of (Finkel and
Manning, 2009). We note that, however, these
results are not directly comparable. Specifically,
both of these two previous models relied on an ad-
ditional 200 million words from PubMed abstracts
to learn word clusters as additional features, which
we do not have access to.
One distinctive advantage of our model is the
efficiency and scalability. The model of (Finkel
and Manning, 2009) had a time complexity that is
cubic in the number of words in the input sentence.
In contrast, our model scales linearly as the length
of the input sentence increases. 7
</bodyText>
<subsubsectionHeader confidence="0.727875">
4.2.2 Results on CONLL2003
</subsubsectionHeader>
<bodyText confidence="0.878029086956522">
To understand how well our model works on
datasets where mentions or entities do not overlap
with one another, we conducted additional experi-
ments on the standard dataset used in the CONLL
2003 shared task (Tjong Kim Sang and De Meul-
der, 2003), where the named entities strictly do
not overlap with one another. We compared our
system’s performance against that of a baseline
version of the state-of-the-art Illinois NER sys-
tem (Ratinov and Roth, 2009). Their system per-
formed sequential prediction over the input words
and adopted the BILOU approach. Their full
model also incorporates external knowledge re-
sources (e.g., gazetteers and word class).
In order to make a proper comparison with the
baseline version of their model, besides the gen-
eral features we mentioned earlier, we also fol-
7In our experiments, for this dataset our model tagged
over 5,000 words/second. In (Finkel and Manning, 2009),
the authors mentioned that their model tagged about 38
words/second, and the semi-CRF model tagged about 45
words/second. However, we note these numbers are not di-
rectly comparable due to the advancement of CPU speed.
</bodyText>
<table confidence="0.9992944">
P DEV F P TEST F
R R
Illinois (b) - - 89.3 - - 83.7
MH 94.7 83.0 88.5 91.4 76.5 83.3
MH (F) 91.4 86.7 89.2 87.3 80.7 83.8
</table>
<tableCaption confidence="0.979458">
Table 6: Results on the CONLL2003. Illinois (b): baseline
version of (Ratinov and Roth, 2009).
</tableCaption>
<bodyText confidence="0.999664076923077">
lowed (Ratinov and Roth, 2009) in incorporat-
ing word’s prefixes and suffixes (of length up to
5) as features, and normalized words referring to
months, dates and numbers. Table 6 shows that
our system gives an F measure that is compara-
ble to that of the baseline version of their system,
where no external resources are used.
This additional experiment showed that while
our model is designed for handling more real-
istic scenarios where mentions can overlap, it
yields a performance competitive to a state-of-the-
art system which only handles datasets with non-
overlapping mentions.
</bodyText>
<sectionHeader confidence="0.999718" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999837">
In this work, we have introduced a novel model
for the task of joint modeling of mention bound-
aries, types, as well as their heads. Unlike many
previous research efforts for mention extraction
and classification, our novel mention hypergraph
representations for compactly representing expo-
nentially many possible mentions enables a men-
tion’s boundaries, type and head information to be
jointly learned in a single framework. The model
scales linearly with respect to the number of words
in the input sentence, and performs exact learning
where a unique global optimum can be found. Em-
pirically, we have demonstrated the effectiveness
of such a model across several standard datasets.
Future work include explorations of efficient al-
gorithms for other information extraction tasks,
such as joint mention and relation extraction (Li
and Ji, 2014) and event extraction (Li et al., 2013).
Our system and code can be downloaded from
http://statnlp.org/research/ie/.
</bodyText>
<sectionHeader confidence="0.996514" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999765">
We would like to thank Kian Ming A. Chai, Hai
Leong Chieu and the three anonymous reviewers
for their comments on this work. This work is sup-
ported by Temasek Lab of Singapore University
of Technology and Design project IGDSS1403011
and IGDST1403013, and is partly supported by
DARPA (under agreement number FA8750-13-2-
0008).
</bodyText>
<page confidence="0.997889">
865
</page>
<sectionHeader confidence="0.989994" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999865529411765">
Beatrice Alex, Barry Haddow, and Claire Grover.
2007. Recognising nested named entities in biomed-
ical text. In BioNLP, pages 65–72. Association for
Computational Linguistics.
Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
A Discriminative Latent Variable Model for Statisti-
cal Machine Translation. In ACL, pages 200–208.
Stephen Boyd and Lieven Vandenberghe. 2004. Con-
vex optimization. Cambridge university press.
Xavier Carreras, Lluis Marquez, and Llu´ıs Padr´o.
2002. Named entity extraction using adaboost.
CONLL, pages 167–170.
Kai-Wei Chang, Rajhans Samdani, and Dan Roth.
2013. A Constrained Latent Variable Model for
Coreference Resolution. In EMNLP, pages 601–
612.
Wanxiang Che, Mengqiu Wang, Christopher D Man-
ning, and Ting Liu. 2013. Named Entity Recog-
nition with Bilingual Constraints. In NAACL-HLT,
pages 52–62.
Martin Cmejrek, Haitao Mi, and Bowen Zhou. 2013.
Flexible and efficient hypergraph interactions for
joint hierarchical and forest-to-string decoding. In
EMNLP, pages 545–555.
Alessandro Cucchiarelli and Paola Velardi. 2001. Un-
supervised named entity recognition using syntactic
and semantic contextual evidence. Computational
Linguistics, 27(1):123–131.
Aron Culotta and Andrew McCallum. 2004. Con-
fidence estimation for information extraction. In
HLT-NAACL, pages 109–112.
Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel S Weld, and Alexander Yates. 2005. Un-
supervised named-entity extraction from the web:
An experimental study. Artificial Intelligence,
165(1):91–134.
Jenny Rose Finkel and Christopher D Manning. 2009.
Nested named entity recognition. In EMNLP, pages
141–150. Association for Computational Linguis-
tics.
Radu Florian, Abe Ittycheriah, Hongyan Jing, and
Tong Zhang. 2003. Named entity recognition
through classifier combination. In CONLL, pages
168–171. Association for Computational Linguis-
tics.
Radu Florian, Hany Hassan, Abraham Ittycheriah,
Hongyan Jing, Nanda Kambhatla, Xiaoqiang Luo,
H Nicolov, and Salim Roukos. 2004. A statistical
model for multilingual entity detection and tracking.
In HLT-NAACL, pages 1–8. DTIC Document.
Stephen Guo, Ming-Wei Chang, and Emre Kiciman.
2013. To Link or Not to Link? A Study on End-to-
End Tweet Entity Linking. In NAACL-HLT, pages
1020–1030.
Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction
of overlapping relations. In ACL, pages 541–550.
Association for Computational Linguistics.
Dan Klein and Christopher D. Manning. 2001. Parsing
and hypergraphs. In IWPT, pages 123–134.
John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In ICML.
Qi Li and Heng Ji. 2014. Incremental Joint Extraction
of Entity Mentions and Relations. In ACL, pages
402–412.
Qi Li, Heng Ji, and Liang Huang. 2013. Joint Event
Extraction via Structured Prediction with Global
Features. In ACL, pages 73–82.
Dong C Liu and Jorge Nocedal. 1989. On the limited
memory BFGS method for large scale optimization.
Mathematical programming, 45(1-3):503–528.
Wei Lu. 2015. Constrained semantic forests for im-
proved discriminative semantic parsing. In ACL.
Ryan McDonald and Fernando Pereira. 2005. Identi-
fying gene and protein mentions in text using condi-
tional random fields. BMC bioinformatics, 6(S6).
Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. In ACL-IJCNLP, pages
1003–1011. Association for Computational Linguis-
tics.
David Nadeau and Satoshi Sekine. 2007. A sur-
vey of named entity recognition and classification.
Lingvisticae Investigationes, 30(1):3–26.
Arvind Neelakantan and Michael Collins. 2014.
Learning Dictionaries for Named Entity Recogni-
tion using Minimal Supervision. In EACL, pages
452–461.
Panupong Pasupat and Percy Liang. 2014. Zero-shot
Entity Extraction from Web Pages. In ACL, pages
391–401.
Slav Petrov and Dan Klein. 2007. Discriminative
log-linear grammars with latent variables. In NIPS,
pages 1153–1160.
Lev Ratinov and Dan Roth. 2009. Design challenges
and misconceptions in named entity recognition. In
CONLL, pages 147–155. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.986851">
866
</page>
<reference confidence="0.999374043478261">
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.
2011. Named entity recognition in tweets: an exper-
imental study. In EMNLP, pages 1524–1534. Asso-
ciation for Computational Linguistics.
Sunita Sarawagi and William W Cohen. 2004. Semi-
markov conditional random fields for information
extraction. In NIPS, pages 1185–1192.
Jun Suzuki, Erik McDermott, and Hideki Isozaki.
2006. Training conditional random fields with
multivariate evaluation measures. In COLING/AC,
pages 217–224.
Erik F Tjong Kim Sang and Fien De Meulder.
2003. Introduction to the CoNLL-2003 shared task:
Language-independent named entity recognition. In
CONLL, pages 142–147. Association for Computa-
tional Linguistics.
Mengqiu Wang, Wanxiang Che, and Christopher D
Manning. 2013. Joint Word Alignment and Bilin-
gual Named Entity Recognition Using Dual Decom-
position. In ACL, pages 1073–1082.
GuoDong Zhou and Jian Su. 2002. Named entity
recognition using an hmm-based chunk tagger. In
ACL, pages 473–480.
</reference>
<page confidence="0.997927">
867
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.873966">
<title confidence="0.997201">Joint Mention Extraction and Classification with Mention Hypergraphs</title>
<author confidence="0.999922">Wei Lu Dan Roth</author>
<affiliation confidence="0.947478">Singapore University University of Illinois of Technology and Design at Urbana-Champaign</affiliation>
<email confidence="0.989316">luwei@sutd.edu.sgdanr@illinois.edu</email>
<abstract confidence="0.998949375">We present a novel model for the task of joint mention extraction and classification. Unlike existing approaches, our model is able to effectively capture overlapping mentions with unbounded lengths. The model is highly scalable, with a time complexity that is linear in the number of words in the input sentence and linear in the number of possible mention classes. Our model can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity. We demonstrate the effectiveness of our model through extensive experiments on standard datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Beatrice Alex</author>
<author>Barry Haddow</author>
<author>Claire Grover</author>
</authors>
<title>Recognising nested named entities in biomedical text.</title>
<date>2007</date>
<booktitle>In BioNLP,</booktitle>
<pages>65--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6084" citStr="Alex et al. (2007)" startWordPosition="950" endWordPosition="953">a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate issue, which is to identify overlapping relations amongst entities. Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing. Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts. Pasupat and Liang (2014) looked into the issue of zero-shot entity ext</context>
<context position="24831" citStr="Alex et al., 2007" startWordPosition="4196" endWordPosition="4199">pproaches based on sequence labelling models using the conditional random fields (CRFs). Such approaches can not handle overlapping mentions. To train such models, whenever two mentions overlap with one another in the training set, we remove the mention that is shorter in length. Following (Ratinov and Roth, 2009), we considered the BIO (Begin, Inside, Outside) approach and the BILOU (Begin, Inside, Last, Outside, Unit) approach for designing the output labels. Results show the BILOU approach yields better results. Similar observations were reported in Ratinov and Roth (2009). In the work of (Alex et al., 2007), the authors proposed several approaches for building models to handle nested named entities in biomedical texts. Their best results were obtained from a cascaded approach where they built one model for each named entity class. Outputs from one model can then served as the inputs to the next model for predicting the named entity class of a different type. One fundamental limitation of such an approach is that it being unable to handle overlapping mentions of the same type. Nevertheless, this approach worked very well on both datasets. The results are shown in the row of “CRF (CC)”.6 Another c</context>
</contexts>
<marker>Alex, Haddow, Grover, 2007</marker>
<rawString>Beatrice Alex, Barry Haddow, and Claire Grover. 2007. Recognising nested named entities in biomedical text. In BioNLP, pages 65–72. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
<author>Miles Osborne</author>
</authors>
<title>A Discriminative Latent Variable Model for Statistical Machine Translation. In</title>
<date>2008</date>
<booktitle>ACL,</booktitle>
<pages>200--208</pages>
<contexts>
<context position="15895" citStr="Blunsom et al., 2008" startWordPosition="2680" endWordPosition="2683">f the dataset: exp(wTf(xi, y&apos;)) y/ :− wT f(xi, yi) + AwTw (2) i A B C D [ PER ] [ PER ] T1 X T1 X T1 T1 X T2 T2 T2 X T2 X I2 I2 I2 I2 A A A A E E E E I1 X X X [GPE] : L(w) = i : log 860 where (xi, yi) refers to the i-th training instance, and the last term is a L2 regularization term with A being a positive scalar (fixed to 0.01 in this work). The gradient of the above objective function is: Ep(y&apos;|xi)[fk(xi, yI)l �− fk(xi, yi) + 2Awk (3) Z where wk is the weight of the k-th feature fk. We note that unlike many recent latent-variable approaches to structured prediction (Petrov and Klein, 2007; Blunsom et al., 2008), we are able to represent each of our outputs y with a single fullyobserved structure. Thus, our objective function essentially defines a standard regularized softmax regression model, and is therefore convex (Boyd and Vandenberghe, 2004), where a global optimum can be found. The objective function defined in Equation 2 can be optimized with standard gradient-based methods. We used L-BFGS (Liu and Nocedal, 1989) as our optimization method. 3.4 Algorithms In order to solve the optimization problem described above, one needs to compute the values of the gradient scores in Equation 3. Computatio</context>
</contexts>
<marker>Blunsom, Cohn, Osborne, 2008</marker>
<rawString>Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008. A Discriminative Latent Variable Model for Statistical Machine Translation. In ACL, pages 200–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Boyd</author>
<author>Lieven Vandenberghe</author>
</authors>
<title>Convex optimization. Cambridge university press.</title>
<date>2004</date>
<contexts>
<context position="16134" citStr="Boyd and Vandenberghe, 2004" startWordPosition="2716" endWordPosition="2719">tance, and the last term is a L2 regularization term with A being a positive scalar (fixed to 0.01 in this work). The gradient of the above objective function is: Ep(y&apos;|xi)[fk(xi, yI)l �− fk(xi, yi) + 2Awk (3) Z where wk is the weight of the k-th feature fk. We note that unlike many recent latent-variable approaches to structured prediction (Petrov and Klein, 2007; Blunsom et al., 2008), we are able to represent each of our outputs y with a single fullyobserved structure. Thus, our objective function essentially defines a standard regularized softmax regression model, and is therefore convex (Boyd and Vandenberghe, 2004), where a global optimum can be found. The objective function defined in Equation 2 can be optimized with standard gradient-based methods. We used L-BFGS (Liu and Nocedal, 1989) as our optimization method. 3.4 Algorithms In order to solve the optimization problem described above, one needs to compute the values of the gradient scores in Equation 3. Computation of the second and third terms in this equation is straightforward. The first term in Equation 3 involves the computation of an expectation of feature values over all possible mention combinations for a given input sentence. Following cla</context>
</contexts>
<marker>Boyd, Vandenberghe, 2004</marker>
<rawString>Stephen Boyd and Lieven Vandenberghe. 2004. Convex optimization. Cambridge university press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis Marquez</author>
<author>Llu´ıs Padr´o</author>
</authors>
<title>Named entity extraction using adaboost. CONLL,</title>
<date>2002</date>
<pages>167--170</pages>
<marker>Carreras, Marquez, Padr´o, 2002</marker>
<rawString>Xavier Carreras, Lluis Marquez, and Llu´ıs Padr´o. 2002. Named entity extraction using adaboost. CONLL, pages 167–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai-Wei Chang</author>
<author>Rajhans Samdani</author>
<author>Dan Roth</author>
</authors>
<title>A Constrained Latent Variable Model for Coreference Resolution. In</title>
<date>2013</date>
<booktitle>EMNLP,</booktitle>
<pages>601--612</pages>
<contexts>
<context position="2072" citStr="Chang et al., 2013" startWordPosition="318" endWordPosition="321">entities in the texts which are named, recently researchers also showed interest in a closely related task – mention extraction and classification/typing. Unlike a named entity, a mention is typically defined as a reference to an entity in natural language text that can be either named, nominal or pronominal (Florian et al., 2004). The task of mention detection and tracking has received substantial attention, largely due to its important role in conducting several downstream tasks, such as relation extraction (Mintz et al., 2009), entity linking (Guo et al., 2013), and coreference resolution (Chang et al., 2013). While most existing work on named entity recognition and mention extraction and classification have been effective, there remain several key limitations associated with existing models. In fact, one can view these problems as instances of the more general problem of semantic tagging – the task of assigning appropriate semantic tags to certain text spans for a given input sentence. Unlike part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic tagging task presents several additional new challenges. First, a mention can consis</context>
</contexts>
<marker>Chang, Samdani, Roth, 2013</marker>
<rawString>Kai-Wei Chang, Rajhans Samdani, and Dan Roth. 2013. A Constrained Latent Variable Model for Coreference Resolution. In EMNLP, pages 601– 612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Mengqiu Wang</author>
<author>Christopher D Manning</author>
<author>Ting Liu</author>
</authors>
<title>Named Entity Recognition with Bilingual Constraints. In</title>
<date>2013</date>
<booktitle>NAACL-HLT,</booktitle>
<pages>52--62</pages>
<contexts>
<context position="5675" citStr="Che et al., 2013" startWordPosition="879" endWordPosition="882">m fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into </context>
</contexts>
<marker>Che, Wang, Manning, Liu, 2013</marker>
<rawString>Wanxiang Che, Mengqiu Wang, Christopher D Manning, and Ting Liu. 2013. Named Entity Recognition with Bilingual Constraints. In NAACL-HLT, pages 52–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Cmejrek</author>
<author>Haitao Mi</author>
<author>Bowen Zhou</author>
</authors>
<title>Flexible and efficient hypergraph interactions for joint hierarchical and forest-to-string decoding.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>545--555</pages>
<contexts>
<context position="9507" citStr="Cmejrek et al., 2013" startWordPosition="1499" endWordPosition="1503">ode form a separate single hyperedge. compactly represent exponentially many possible combinations of potentially overlapping, lengthunbounded mentions of different types. A hypergraph is a generalization of a conventional graph, whose edges (a.k.a. hyperedges) can connect two or more nodes. In this work, we consider a special class of hypergraphs, where each hyperedge consists of a designated parent node and an ordered list of child nodes. Hypergraphs have also been used in other fields, such as syntactic parsing (Klein and Manning, 2001), semantic parsing (Lu, 2015) and machine translation (Cmejrek et al., 2013). Our mention hypergraphs consist of five types of nodes which are used to compactly represent many mentions of different semantic types and boundaries, namely, A nodes, E nodes, T nodes, I nodes, and X nodes. A partial mention hypergraph is depicted in Figure 1. We describe the definition of each type of nodes next. • A nodes. These nodes are used to sequentially arrange mentions with different left boundaries. Specifically, each A node at position k (the k-th word), or Ak, is used to compactly represent all such mentions in the sentence whose left boundaries are exactly at or strictly after </context>
</contexts>
<marker>Cmejrek, Mi, Zhou, 2013</marker>
<rawString>Martin Cmejrek, Haitao Mi, and Bowen Zhou. 2013. Flexible and efficient hypergraph interactions for joint hierarchical and forest-to-string decoding. In EMNLP, pages 545–555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Cucchiarelli</author>
<author>Paola Velardi</author>
</authors>
<title>Unsupervised named entity recognition using syntactic and semantic contextual evidence.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>1</issue>
<contexts>
<context position="5504" citStr="Cucchiarelli and Velardi, 2001" startWordPosition="849" endWordPosition="853"> using an HMMbased approach. Florian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented seve</context>
</contexts>
<marker>Cucchiarelli, Velardi, 2001</marker>
<rawString>Alessandro Cucchiarelli and Paola Velardi. 2001. Unsupervised named entity recognition using syntactic and semantic contextual evidence. Computational Linguistics, 27(1):123–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
</authors>
<title>Confidence estimation for information extraction.</title>
<date>2004</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>109--112</pages>
<contexts>
<context position="21807" citStr="Culotta and McCallum (2004)" startWordPosition="3708" endWordPosition="3711">c mean of the precision (P) and recall (R) scores, where precision is the ratio between the number of correctly predicted mentions and the total number of predicted mentions, and recall is the ratio between the number of correctly predicted mentions and the total number of gold mentions. We will also adopt these metrics in our evaluations later. Unfortunately, the model only optimizes its objective function defined in Equation 2, which is the negative (regularized) joint log-likelihood. Previous work showed it was possible to optimize the F measure in a log-linear model (Suzuki et al., 2006). Culotta and McCallum (2004) also proposed a method for optimizing information extraction performance based on confidence estimation. Their work is based on linear-chain CRF and estimate the confidence of extracted fields based on marginal probabilities. The technique is not directly applicable to our task where a hypergraph representation is used to encode overlapping mentions. In this work, we used a very simple and intuitive technique for optimizing the F measure. The idea is to further tune the weight of a single parameter – mention penalty based on the development set, after the training process completes. This is b</context>
</contexts>
<marker>Culotta, McCallum, 2004</marker>
<rawString>Aron Culotta and Andrew McCallum. 2004. Confidence estimation for information extraction. In HLT-NAACL, pages 109–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>AnaMaria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: An experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="5527" citStr="Etzioni et al., 2005" startWordPosition="854" endWordPosition="857">rian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by build</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, AnaMaria Popescu, Tal Shaked, Stephen Soderland, Daniel S Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web: An experimental study. Artificial Intelligence, 165(1):91–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Nested named entity recognition.</title>
<date>2009</date>
<booktitle>In EMNLP,</booktitle>
<pages>141--150</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3142" citStr="Finkel and Manning, 2009" startWordPosition="482" endWordPosition="485">vely studied in the past few decades by the community, such a semantic tagging task presents several additional new challenges. First, a mention can consist of multiple words, so its length can be arbitrarily long. Second, the mentions can overlap with one another. Popular models used for POS tagging, such as linear-chain conditional random fields (Lafferty et al., 2001) or semi-Markov conditional random fields (Sarawagi and Cohen, 2004) have difficulties coping with these issues. While approaches on addressing these issues exist, current algorithms typically suffer from high time complexity (Finkel and Manning, 2009) and are therefore difficult to scale to large datasets. On the other hand, the problem of designing efficient and scalable models for mention extraction and classification from natural language texts becomes increasingly important in this era where a large volume of textual data is becoming available on the Web every day – users need systems which are able to scale to extremely large datasets to support efficient semantic analysis for timely decisonmaking. In this paper, we tackle the above-mentioned issue by introducing a novel model for joint mention extraction and classification. We make t</context>
<context position="5740" citStr="Finkel and Manning (2009)" startWordPosition="891" endWordPosition="894">iomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate issue, which is to identify overlapping relations amon</context>
<context position="32738" citStr="Finkel and Manning (2009)" startWordPosition="5541" endWordPosition="5545">med all those baseline approaches. We are not aware of any prior work in the literature that performs joint modeling of mention boundaries, types, and heads. 4.2 Additional Experiments We also additionally evaluated on the GENIA dataset (v3.02) whose focus was on biomedical related named entity recognition and classification, where the entities may overlap with one another. Furthermore, to see how our model works on datasets where mentions do not overlap with one another, we also conducted evaluations on the standard CONLL2003 NER dataset. 4.2.1 Results on GENIA We followed the description of Finkel and Manning (2009) to set up our experiments on the GENIA dataset. Specifically, we used the first 90% of the sentences as the training data and the remaining 10% as the evaluation data. We also adhered to the paper’s prescription of collapsing all DNA subtypes into DNA; RNA subtypes into RNA; and all protein subtypes into protein. We kept cell line and cell type, and removed all other entities. To optimize the F measure, we further split the 864 P R F Semi-CRF 76.2 61.7 68.2 F &amp; M (2009) 75.4 65.9 70.3 MH (F) 72.5 65.2 68.7 Table 5: Results on the GENIA dataset training set into two portions. We trained a mode</context>
<context position="34201" citStr="Finkel and Manning, 2009" startWordPosition="5801" endWordPosition="5804">oposed by (Finkel and Manning, 2009), as well as the semi-CRF model reported there. The results are shown in Table 5. Our model yields a better F measure than the semi-CRF model, but gives a lower performance than the model of (Finkel and Manning, 2009). We note that, however, these results are not directly comparable. Specifically, both of these two previous models relied on an additional 200 million words from PubMed abstracts to learn word clusters as additional features, which we do not have access to. One distinctive advantage of our model is the efficiency and scalability. The model of (Finkel and Manning, 2009) had a time complexity that is cubic in the number of words in the input sentence. In contrast, our model scales linearly as the length of the input sentence increases. 7 4.2.2 Results on CONLL2003 To understand how well our model works on datasets where mentions or entities do not overlap with one another, we conducted additional experiments on the standard dataset used in the CONLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003), where the named entities strictly do not overlap with one another. We compared our system’s performance against that of a baseline version of the state-of-th</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D Manning. 2009. Nested named entity recognition. In EMNLP, pages 141–150. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Abe Ittycheriah</author>
<author>Hongyan Jing</author>
<author>Tong Zhang</author>
</authors>
<title>Named entity recognition through classifier combination.</title>
<date>2003</date>
<booktitle>In CONLL,</booktitle>
<pages>168--171</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4924" citStr="Florian et al. (2003)" startWordPosition="766" endWordPosition="769">g our model scalable to extremely large datasets. • Our model can additionally capture mentions’ head information in a joint manner under the same time complexity. Our system and code are available for download from http://statnlp.org/research/ie/. 2 Related Work Existing work has been largely focused on the task of named entity recognition and classification (NERC). The survey of (Nadeau and Sekine, 2007) is a comprehensive study of this topic. Most prior work took a supervised learning approach. Zhou and Su (2002) presented a system for recognizing named entities using an HMMbased approach. Florian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 20</context>
</contexts>
<marker>Florian, Ittycheriah, Jing, Zhang, 2003</marker>
<rawString>Radu Florian, Abe Ittycheriah, Hongyan Jing, and Tong Zhang. 2003. Named entity recognition through classifier combination. In CONLL, pages 168–171. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Hany Hassan</author>
<author>Abraham Ittycheriah</author>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Xiaoqiang Luo</author>
<author>H Nicolov</author>
<author>Salim Roukos</author>
</authors>
<title>A statistical model for multilingual entity detection and tracking.</title>
<date>2004</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>1--8</pages>
<publisher>DTIC Document.</publisher>
<contexts>
<context position="1785" citStr="Florian et al., 2004" startWordPosition="273" endWordPosition="276">t the same time identify their semantic classes (e.g., person, organization, etc). Such a task is often known as named entity recognition and classification (NERC), one of the standard tasks in information extraction (IE). While such a task focuses on the extraction and classification of entities in the texts which are named, recently researchers also showed interest in a closely related task – mention extraction and classification/typing. Unlike a named entity, a mention is typically defined as a reference to an entity in natural language text that can be either named, nominal or pronominal (Florian et al., 2004). The task of mention detection and tracking has received substantial attention, largely due to its important role in conducting several downstream tasks, such as relation extraction (Mintz et al., 2009), entity linking (Guo et al., 2013), and coreference resolution (Chang et al., 2013). While most existing work on named entity recognition and mention extraction and classification have been effective, there remain several key limitations associated with existing models. In fact, one can view these problems as instances of the more general problem of semantic tagging – the task of assigning app</context>
<context position="5657" citStr="Florian et al., 2004" startWordPosition="875" endWordPosition="878">used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (</context>
</contexts>
<marker>Florian, Hassan, Ittycheriah, Jing, Kambhatla, Luo, Nicolov, Roukos, 2004</marker>
<rawString>Radu Florian, Hany Hassan, Abraham Ittycheriah, Hongyan Jing, Nanda Kambhatla, Xiaoqiang Luo, H Nicolov, and Salim Roukos. 2004. A statistical model for multilingual entity detection and tracking. In HLT-NAACL, pages 1–8. DTIC Document.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Guo</author>
<author>Ming-Wei Chang</author>
<author>Emre Kiciman</author>
</authors>
<title>To Link or Not to Link? A Study on End-toEnd Tweet Entity Linking. In</title>
<date>2013</date>
<booktitle>NAACL-HLT,</booktitle>
<pages>1020--1030</pages>
<contexts>
<context position="2023" citStr="Guo et al., 2013" startWordPosition="311" endWordPosition="314">ocuses on the extraction and classification of entities in the texts which are named, recently researchers also showed interest in a closely related task – mention extraction and classification/typing. Unlike a named entity, a mention is typically defined as a reference to an entity in natural language text that can be either named, nominal or pronominal (Florian et al., 2004). The task of mention detection and tracking has received substantial attention, largely due to its important role in conducting several downstream tasks, such as relation extraction (Mintz et al., 2009), entity linking (Guo et al., 2013), and coreference resolution (Chang et al., 2013). While most existing work on named entity recognition and mention extraction and classification have been effective, there remain several key limitations associated with existing models. In fact, one can view these problems as instances of the more general problem of semantic tagging – the task of assigning appropriate semantic tags to certain text spans for a given input sentence. Unlike part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic tagging task presents several addit</context>
</contexts>
<marker>Guo, Chang, Kiciman, 2013</marker>
<rawString>Stephen Guo, Ming-Wei Chang, and Emre Kiciman. 2013. To Link or Not to Link? A Study on End-toEnd Tweet Entity Linking. In NAACL-HLT, pages 1020–1030.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledgebased weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>541--550</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6262" citStr="Hoffmann et al. (2011)" startWordPosition="975" endWordPosition="978">rian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate issue, which is to identify overlapping relations amongst entities. Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing. Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts. Pasupat and Liang (2014) looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used. Neelakantan and Collins (2014) looked into the problem of automatically constructing dict</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In ACL, pages 541–550. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing and hypergraphs.</title>
<date>2001</date>
<booktitle>In IWPT,</booktitle>
<pages>123--134</pages>
<contexts>
<context position="9431" citStr="Klein and Manning, 2001" startWordPosition="1488" endWordPosition="1491">ingle hyperedge, while the two brown links that connect two I nodes and one X node form a separate single hyperedge. compactly represent exponentially many possible combinations of potentially overlapping, lengthunbounded mentions of different types. A hypergraph is a generalization of a conventional graph, whose edges (a.k.a. hyperedges) can connect two or more nodes. In this work, we consider a special class of hypergraphs, where each hyperedge consists of a designated parent node and an ordered list of child nodes. Hypergraphs have also been used in other fields, such as syntactic parsing (Klein and Manning, 2001), semantic parsing (Lu, 2015) and machine translation (Cmejrek et al., 2013). Our mention hypergraphs consist of five types of nodes which are used to compactly represent many mentions of different semantic types and boundaries, namely, A nodes, E nodes, T nodes, I nodes, and X nodes. A partial mention hypergraph is depicted in Figure 1. We describe the definition of each type of nodes next. • A nodes. These nodes are used to sequentially arrange mentions with different left boundaries. Specifically, each A node at position k (the k-th word), or Ak, is used to compactly represent all such ment</context>
</contexts>
<marker>Klein, Manning, 2001</marker>
<rawString>Dan Klein and Christopher D. Manning. 2001. Parsing and hypergraphs. In IWPT, pages 123–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando CN Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="2890" citStr="Lafferty et al., 2001" startWordPosition="447" endWordPosition="450"> one can view these problems as instances of the more general problem of semantic tagging – the task of assigning appropriate semantic tags to certain text spans for a given input sentence. Unlike part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic tagging task presents several additional new challenges. First, a mention can consist of multiple words, so its length can be arbitrarily long. Second, the mentions can overlap with one another. Popular models used for POS tagging, such as linear-chain conditional random fields (Lafferty et al., 2001) or semi-Markov conditional random fields (Sarawagi and Cohen, 2004) have difficulties coping with these issues. While approaches on addressing these issues exist, current algorithms typically suffer from high time complexity (Finkel and Manning, 2009) and are therefore difficult to scale to large datasets. On the other hand, the problem of designing efficient and scalable models for mention extraction and classification from natural language texts becomes increasingly important in this era where a large volume of textual data is becoming available on the Web every day – users need systems whi</context>
<context position="14730" citStr="Lafferty et al., 2001" startWordPosition="2456" endWordPosition="2459">s the above sub-hypergraph. Note that such an ambiguity happens only when two overlapping mentions have the same type, and one mention is strictly contained by the other and their boundaries are all different. In practice, however, we found that in the two datasets that we used for evaluations, if two mentions overlap with one another, they almost always form a type-I combination, and type-II combinations are very rare. Empirically, as we will see later in our experiments, our model is effective in handling overlapping mentions. 3.3 Log-Linear Modeling Following the conditional random fields (Lafferty et al., 2001), we adopted a log-linear approach for such a joint mention extraction and typing task. Specifically, for a given input sentence x, the probability of predicting a possible output y (a mention sub-hypergraph that represents a particular combination of mentions) is given as follows: exp(wTf(x,y)) p(y|x) = (1) Ey/ exp(wTf(x, y&apos;)) where f(x, y) is the feature vector defined over the input-output pair (x, y), and the weight vector w gives the parameters of the model. Our objective is to minimize the regularized negative joint log-likelihood of the dataset: exp(wTf(xi, y&apos;)) y/ :− wT f(xi, yi) + AwT</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Heng Ji</author>
</authors>
<title>Incremental Joint Extraction of Entity Mentions and Relations.</title>
<date>2014</date>
<booktitle>In ACL,</booktitle>
<pages>402--412</pages>
<contexts>
<context position="6950" citStr="Li and Ji (2014)" startWordPosition="1075" endWordPosition="1078">s amongst entities. Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing. Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts. Pasupat and Liang (2014) looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used. Neelakantan and Collins (2014) looked into the problem of automatically constructing dictionaries with minimal supervision for improved named entity extraction. Li and Ji (2014) presented an approach to perform the task of extraction of mentions and their relations in a joint and incremental manner. 3 Approach 3.1 Mentions and Their Combinations Typically, a mention that appears in a natural language sentence consists of a contiguous sequence of natural language words. Consider a sentence that consists of n words where each word is indexed with its position in the sentence. A mention m can be uniquely represented with a tuple (bm, em, 7), where bm and em are the indices of the first and last word of the mention, respectively, and 7 is its semantic class (type). We ca</context>
</contexts>
<marker>Li, Ji, 2014</marker>
<rawString>Qi Li and Heng Ji. 2014. Incremental Joint Extraction of Entity Mentions and Relations. In ACL, pages 402–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Heng Ji</author>
<author>Liang Huang</author>
</authors>
<title>Joint Event Extraction via Structured Prediction with Global Features. In</title>
<date>2013</date>
<booktitle>ACL,</booktitle>
<pages>73--82</pages>
<marker>Li, Ji, Huang, 2013</marker>
<rawString>Qi Li, Heng Ji, and Liang Huang. 2013. Joint Event Extraction via Structured Prediction with Global Features. In ACL, pages 73–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory BFGS method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical programming,</booktitle>
<pages>45--1</pages>
<contexts>
<context position="16311" citStr="Liu and Nocedal, 1989" startWordPosition="2745" endWordPosition="2748">l �− fk(xi, yi) + 2Awk (3) Z where wk is the weight of the k-th feature fk. We note that unlike many recent latent-variable approaches to structured prediction (Petrov and Klein, 2007; Blunsom et al., 2008), we are able to represent each of our outputs y with a single fullyobserved structure. Thus, our objective function essentially defines a standard regularized softmax regression model, and is therefore convex (Boyd and Vandenberghe, 2004), where a global optimum can be found. The objective function defined in Equation 2 can be optimized with standard gradient-based methods. We used L-BFGS (Liu and Nocedal, 1989) as our optimization method. 3.4 Algorithms In order to solve the optimization problem described above, one needs to compute the values of the gradient scores in Equation 3. Computation of the second and third terms in this equation is straightforward. The first term in Equation 3 involves the computation of an expectation of feature values over all possible mention combinations for a given input sentence. Following classic dynamic programming algorithms used in graphical models, we develop analogous efficient dynamic programming algorithms that work on hypergraphs and generalize the conventio</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C Liu and Jorge Nocedal. 1989. On the limited memory BFGS method for large scale optimization. Mathematical programming, 45(1-3):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
</authors>
<title>Constrained semantic forests for improved discriminative semantic parsing.</title>
<date>2015</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9460" citStr="Lu, 2015" startWordPosition="1494" endWordPosition="1495">hat connect two I nodes and one X node form a separate single hyperedge. compactly represent exponentially many possible combinations of potentially overlapping, lengthunbounded mentions of different types. A hypergraph is a generalization of a conventional graph, whose edges (a.k.a. hyperedges) can connect two or more nodes. In this work, we consider a special class of hypergraphs, where each hyperedge consists of a designated parent node and an ordered list of child nodes. Hypergraphs have also been used in other fields, such as syntactic parsing (Klein and Manning, 2001), semantic parsing (Lu, 2015) and machine translation (Cmejrek et al., 2013). Our mention hypergraphs consist of five types of nodes which are used to compactly represent many mentions of different semantic types and boundaries, namely, A nodes, E nodes, T nodes, I nodes, and X nodes. A partial mention hypergraph is depicted in Figure 1. We describe the definition of each type of nodes next. • A nodes. These nodes are used to sequentially arrange mentions with different left boundaries. Specifically, each A node at position k (the k-th word), or Ak, is used to compactly represent all such mentions in the sentence whose le</context>
</contexts>
<marker>Lu, 2015</marker>
<rawString>Wei Lu. 2015. Constrained semantic forests for improved discriminative semantic parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Identifying gene and protein mentions in text using conditional random fields.</title>
<date>2005</date>
<journal>BMC bioinformatics,</journal>
<pages>6--6</pages>
<contexts>
<context position="5036" citStr="McDonald and Pereira (2005)" startWordPosition="781" endWordPosition="784">rmation in a joint manner under the same time complexity. Our system and code are available for download from http://statnlp.org/research/ie/. 2 Related Work Existing work has been largely focused on the task of named entity recognition and classification (NERC). The survey of (Nadeau and Sekine, 2007) is a comprehensive study of this topic. Most prior work took a supervised learning approach. Zhou and Su (2002) presented a system for recognizing named entities using an HMMbased approach. Florian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist </context>
</contexts>
<marker>McDonald, Pereira, 2005</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2005. Identifying gene and protein mentions in text using conditional random fields. BMC bioinformatics, 6(S6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data. In</title>
<date>2009</date>
<booktitle>ACL-IJCNLP,</booktitle>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1988" citStr="Mintz et al., 2009" startWordPosition="305" endWordPosition="308"> extraction (IE). While such a task focuses on the extraction and classification of entities in the texts which are named, recently researchers also showed interest in a closely related task – mention extraction and classification/typing. Unlike a named entity, a mention is typically defined as a reference to an entity in natural language text that can be either named, nominal or pronominal (Florian et al., 2004). The task of mention detection and tracking has received substantial attention, largely due to its important role in conducting several downstream tasks, such as relation extraction (Mintz et al., 2009), entity linking (Guo et al., 2013), and coreference resolution (Chang et al., 2013). While most existing work on named entity recognition and mention extraction and classification have been effective, there remain several key limitations associated with existing models. In fact, one can view these problems as instances of the more general problem of semantic tagging – the task of assigning appropriate semantic tags to certain text spans for a given input sentence. Unlike part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic </context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In ACL-IJCNLP, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Satoshi Sekine</author>
</authors>
<title>A survey of named entity recognition and classification.</title>
<date>2007</date>
<journal>Lingvisticae Investigationes,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="4712" citStr="Nadeau and Sekine, 2007" startWordPosition="730" endWordPosition="733"> The learning and inference algorithms of our proposed model have a time complexity that is linear in the number of words in the input sentence and also linear in the number of possible semantic classes/types, making our model scalable to extremely large datasets. • Our model can additionally capture mentions’ head information in a joint manner under the same time complexity. Our system and code are available for download from http://statnlp.org/research/ie/. 2 Related Work Existing work has been largely focused on the task of named entity recognition and classification (NERC). The survey of (Nadeau and Sekine, 2007) is a comprehensive study of this topic. Most prior work took a supervised learning approach. Zhou and Su (2002) presented a system for recognizing named entities using an HMMbased approach. Florian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk</context>
</contexts>
<marker>Nadeau, Sekine, 2007</marker>
<rawString>David Nadeau and Satoshi Sekine. 2007. A survey of named entity recognition and classification. Lingvisticae Investigationes, 30(1):3–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arvind Neelakantan</author>
<author>Michael Collins</author>
</authors>
<title>Learning Dictionaries for Named Entity Recognition using Minimal Supervision. In</title>
<date>2014</date>
<booktitle>EACL,</booktitle>
<pages>452--461</pages>
<contexts>
<context position="6803" citStr="Neelakantan and Collins (2014)" startWordPosition="1054" endWordPosition="1057">random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate issue, which is to identify overlapping relations amongst entities. Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing. Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts. Pasupat and Liang (2014) looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used. Neelakantan and Collins (2014) looked into the problem of automatically constructing dictionaries with minimal supervision for improved named entity extraction. Li and Ji (2014) presented an approach to perform the task of extraction of mentions and their relations in a joint and incremental manner. 3 Approach 3.1 Mentions and Their Combinations Typically, a mention that appears in a natural language sentence consists of a contiguous sequence of natural language words. Consider a sentence that consists of n words where each word is indexed with its position in the sentence. A mention m can be uniquely represented with a tu</context>
</contexts>
<marker>Neelakantan, Collins, 2014</marker>
<rawString>Arvind Neelakantan and Michael Collins. 2014. Learning Dictionaries for Named Entity Recognition using Minimal Supervision. In EACL, pages 452–461.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Panupong Pasupat</author>
<author>Percy Liang</author>
</authors>
<title>Zero-shot Entity Extraction from Web Pages. In</title>
<date>2014</date>
<booktitle>ACL,</booktitle>
<pages>391--401</pages>
<contexts>
<context position="6638" citStr="Pasupat and Liang (2014)" startWordPosition="1030" endWordPosition="1033">d showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate issue, which is to identify overlapping relations amongst entities. Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing. Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts. Pasupat and Liang (2014) looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used. Neelakantan and Collins (2014) looked into the problem of automatically constructing dictionaries with minimal supervision for improved named entity extraction. Li and Ji (2014) presented an approach to perform the task of extraction of mentions and their relations in a joint and incremental manner. 3 Approach 3.1 Mentions and Their Combinations Typically, a mention that appears in a natural language sentence consists of a contiguous sequence of natural languag</context>
</contexts>
<marker>Pasupat, Liang, 2014</marker>
<rawString>Panupong Pasupat and Percy Liang. 2014. Zero-shot Entity Extraction from Web Pages. In ACL, pages 391–401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Discriminative log-linear grammars with latent variables.</title>
<date>2007</date>
<booktitle>In NIPS,</booktitle>
<pages>1153--1160</pages>
<contexts>
<context position="15872" citStr="Petrov and Klein, 2007" startWordPosition="2676" endWordPosition="2679">e joint log-likelihood of the dataset: exp(wTf(xi, y&apos;)) y/ :− wT f(xi, yi) + AwTw (2) i A B C D [ PER ] [ PER ] T1 X T1 X T1 T1 X T2 T2 T2 X T2 X I2 I2 I2 I2 A A A A E E E E I1 X X X [GPE] : L(w) = i : log 860 where (xi, yi) refers to the i-th training instance, and the last term is a L2 regularization term with A being a positive scalar (fixed to 0.01 in this work). The gradient of the above objective function is: Ep(y&apos;|xi)[fk(xi, yI)l �− fk(xi, yi) + 2Awk (3) Z where wk is the weight of the k-th feature fk. We note that unlike many recent latent-variable approaches to structured prediction (Petrov and Klein, 2007; Blunsom et al., 2008), we are able to represent each of our outputs y with a single fullyobserved structure. Thus, our objective function essentially defines a standard regularized softmax regression model, and is therefore convex (Boyd and Vandenberghe, 2004), where a global optimum can be found. The objective function defined in Equation 2 can be optimized with standard gradient-based methods. We used L-BFGS (Liu and Nocedal, 1989) as our optimization method. 3.4 Algorithms In order to solve the optimization problem described above, one needs to compute the values of the gradient scores in</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Discriminative log-linear grammars with latent variables. In NIPS, pages 1153–1160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Design challenges and misconceptions in named entity recognition.</title>
<date>2009</date>
<booktitle>In CONLL,</booktitle>
<pages>147--155</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5155" citStr="Ratinov and Roth (2009)" startWordPosition="798" endWordPosition="802">p.org/research/ie/. 2 Related Work Existing work has been largely focused on the task of named entity recognition and classification (NERC). The survey of (Nadeau and Sekine, 2007) is a comprehensive study of this topic. Most prior work took a supervised learning approach. Zhou and Su (2002) presented a system for recognizing named entities using an HMMbased approach. Florian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entitie</context>
<context position="24528" citStr="Ratinov and Roth, 2009" startWordPosition="4146" endWordPosition="4149">ces contain overlapping mentions (see row 3 of the table). Mentions can also be very long – over 5% of the mentions consist of more than 6 words, and the longest mention consists of 57 words. We compared our system’s performance with those of several baseline approaches. We first built two simple baseline approaches based on sequence labelling models using the conditional random fields (CRFs). Such approaches can not handle overlapping mentions. To train such models, whenever two mentions overlap with one another in the training set, we remove the mention that is shorter in length. Following (Ratinov and Roth, 2009), we considered the BIO (Begin, Inside, Outside) approach and the BILOU (Begin, Inside, Last, Outside, Unit) approach for designing the output labels. Results show the BILOU approach yields better results. Similar observations were reported in Ratinov and Roth (2009). In the work of (Alex et al., 2007), the authors proposed several approaches for building models to handle nested named entities in biomedical texts. Their best results were obtained from a cascaded approach where they built one model for each named entity class. Outputs from one model can then served as the inputs to the next mod</context>
<context position="34851" citStr="Ratinov and Roth, 2009" startWordPosition="5912" endWordPosition="5915"> is cubic in the number of words in the input sentence. In contrast, our model scales linearly as the length of the input sentence increases. 7 4.2.2 Results on CONLL2003 To understand how well our model works on datasets where mentions or entities do not overlap with one another, we conducted additional experiments on the standard dataset used in the CONLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003), where the named entities strictly do not overlap with one another. We compared our system’s performance against that of a baseline version of the state-of-the-art Illinois NER system (Ratinov and Roth, 2009). Their system performed sequential prediction over the input words and adopted the BILOU approach. Their full model also incorporates external knowledge resources (e.g., gazetteers and word class). In order to make a proper comparison with the baseline version of their model, besides the general features we mentioned earlier, we also fol7In our experiments, for this dataset our model tagged over 5,000 words/second. In (Finkel and Manning, 2009), the authors mentioned that their model tagged about 38 words/second, and the semi-CRF model tagged about 45 words/second. However, we note these numb</context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>Lev Ratinov and Dan Roth. 2009. Design challenges and misconceptions in named entity recognition. In CONLL, pages 147–155. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: an experimental study.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<pages>1524--1534</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6505" citStr="Ritter et al. (2011)" startWordPosition="1010" endWordPosition="1013">a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate issue, which is to identify overlapping relations amongst entities. Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing. Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts. Pasupat and Liang (2014) looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used. Neelakantan and Collins (2014) looked into the problem of automatically constructing dictionaries with minimal supervision for improved named entity extraction. Li and Ji (2014) presented an approach to perform the task of extraction of mentions and their relations in a joint and incremental manner. 3 Approach 3.1 Mentions and The</context>
</contexts>
<marker>Ritter, Clark, Mausam, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named entity recognition in tweets: an experimental study. In EMNLP, pages 1524–1534. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>Semimarkov conditional random fields for information extraction.</title>
<date>2004</date>
<booktitle>In NIPS,</booktitle>
<pages>1185--1192</pages>
<contexts>
<context position="2958" citStr="Sarawagi and Cohen, 2004" startWordPosition="456" endWordPosition="459">blem of semantic tagging – the task of assigning appropriate semantic tags to certain text spans for a given input sentence. Unlike part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic tagging task presents several additional new challenges. First, a mention can consist of multiple words, so its length can be arbitrarily long. Second, the mentions can overlap with one another. Popular models used for POS tagging, such as linear-chain conditional random fields (Lafferty et al., 2001) or semi-Markov conditional random fields (Sarawagi and Cohen, 2004) have difficulties coping with these issues. While approaches on addressing these issues exist, current algorithms typically suffer from high time complexity (Finkel and Manning, 2009) and are therefore difficult to scale to large datasets. On the other hand, the problem of designing efficient and scalable models for mention extraction and classification from natural language texts becomes increasingly important in this era where a large volume of textual data is becoming available on the Web every day – users need systems which are able to scale to extremely large datasets to support efficien</context>
<context position="25575" citStr="Sarawagi and Cohen, 2004" startWordPosition="4322" endWordPosition="4325">r best results were obtained from a cascaded approach where they built one model for each named entity class. Outputs from one model can then served as the inputs to the next model for predicting the named entity class of a different type. One fundamental limitation of such an approach is that it being unable to handle overlapping mentions of the same type. Nevertheless, this approach worked very well on both datasets. The results are shown in the row of “CRF (CC)”.6 Another class of models that is often used in information extraction are the semi-Markov conditional random fields (semi-CRFs) (Sarawagi and Cohen, 2004). Semi-CRF models are able to capture the non-Markovian properties of mentions. However, they are unable to handle nested or overlapping mentions. We thus used the same method as discussed above to exclude certain mentions for training. Such semi-CRF models typically assume there is a length restriction for the mentions – each mention can consist of up to c words – in order to scale linearly. When such a restriction is lifted, the time complexity of such models becomes quadratic in the number of words in the in6For all such linear chain CRF-related experiments, we used the CRF++ toolkit (https</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi and William W Cohen. 2004. Semimarkov conditional random fields for information extraction. In NIPS, pages 1185–1192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Erik McDermott</author>
<author>Hideki Isozaki</author>
</authors>
<title>Training conditional random fields with multivariate evaluation measures.</title>
<date>2006</date>
<booktitle>In COLING/AC,</booktitle>
<pages>217--224</pages>
<contexts>
<context position="21778" citStr="Suzuki et al., 2006" startWordPosition="3704" endWordPosition="3707">defined as the harmonic mean of the precision (P) and recall (R) scores, where precision is the ratio between the number of correctly predicted mentions and the total number of predicted mentions, and recall is the ratio between the number of correctly predicted mentions and the total number of gold mentions. We will also adopt these metrics in our evaluations later. Unfortunately, the model only optimizes its objective function defined in Equation 2, which is the negative (regularized) joint log-likelihood. Previous work showed it was possible to optimize the F measure in a log-linear model (Suzuki et al., 2006). Culotta and McCallum (2004) also proposed a method for optimizing information extraction performance based on confidence estimation. Their work is based on linear-chain CRF and estimate the confidence of extracted fields based on marginal probabilities. The technique is not directly applicable to our task where a hypergraph representation is used to encode overlapping mentions. In this work, we used a very simple and intuitive technique for optimizing the F measure. The idea is to further tune the weight of a single parameter – mention penalty based on the development set, after the training</context>
</contexts>
<marker>Suzuki, McDermott, Isozaki, 2006</marker>
<rawString>Jun Suzuki, Erik McDermott, and Hideki Isozaki. 2006. Training conditional random fields with multivariate evaluation measures. In COLING/AC, pages 217–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Fien De Meulder</author>
</authors>
<title>Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition.</title>
<date>2003</date>
<booktitle>In CONLL,</booktitle>
<pages>142--147</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Sang, De Meulder, 2003</marker>
<rawString>Erik F Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. In CONLL, pages 142–147. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Wanxiang Che</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition. In</title>
<date>2013</date>
<booktitle>ACL,</booktitle>
<pages>1073--1082</pages>
<contexts>
<context position="5695" citStr="Wang et al., 2013" startWordPosition="883" endWordPosition="886">cting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013). As pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate issue, wh</context>
</contexts>
<marker>Wang, Che, Manning, 2013</marker>
<rawString>Mengqiu Wang, Wanxiang Che, and Christopher D Manning. 2013. Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition. In ACL, pages 1073–1082.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Jian Su</author>
</authors>
<title>Named entity recognition using an hmm-based chunk tagger.</title>
<date>2002</date>
<booktitle>In ACL,</booktitle>
<pages>473--480</pages>
<contexts>
<context position="4824" citStr="Zhou and Su (2002)" startWordPosition="750" endWordPosition="753">rds in the input sentence and also linear in the number of possible semantic classes/types, making our model scalable to extremely large datasets. • Our model can additionally capture mentions’ head information in a joint manner under the same time complexity. Our system and code are available for download from http://statnlp.org/research/ie/. 2 Related Work Existing work has been largely focused on the task of named entity recognition and classification (NERC). The survey of (Nadeau and Sekine, 2007) is a comprehensive study of this topic. Most prior work took a supervised learning approach. Zhou and Su (2002) presented a system for recognizing named entities using an HMMbased approach. Florian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-superv</context>
</contexts>
<marker>Zhou, Su, 2002</marker>
<rawString>GuoDong Zhou and Jian Su. 2002. Named entity recognition using an hmm-based chunk tagger. In ACL, pages 473–480.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>