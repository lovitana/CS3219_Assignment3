<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001542">
<title confidence="0.9538455">
Scientific Article Summarization Using Citation-Context
and Article’s Discourse Structure
</title>
<author confidence="0.978063">
Arman Cohan
</author>
<affiliation confidence="0.982793">
Information Retrieval Lab
Computer Science Department
Georgetown University
</affiliation>
<email confidence="0.997473">
arman@ir.cs.georgetown.edu
</email>
<author confidence="0.919979">
Nazli Goharian
</author>
<affiliation confidence="0.967538">
Information Retrieval Lab
Computer Science Department
Georgetown University
</affiliation>
<email confidence="0.998391">
nazli@ir.cs.georgetown.edu
</email>
<sectionHeader confidence="0.994789" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994908">
We propose a summarization approach for
scientific articles which takes advantage
of citation-context and the document
discourse model. While citations have
been previously used in generating
scientific summaries, they lack the related
context from the referenced article and
therefore do not accurately reflect the
article’s content. Our method overcomes
the problem of inconsistency between
the citation summary and the article’s
content by providing context for each
citation. We also leverage the inherent
scientific article’s discourse for producing
better summaries. We show that our
proposed method effectively improves
over existing summarization approaches
(greater than 30% improvement over the
best performing baseline) in terms of
ROUGE scores on TAC2014 scientific
summarization dataset. While the dataset
we use for evaluation is in the biomedical
domain, most of our approaches are
general and therefore adaptable to other
domains.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999726764705882">
Due to the expanding rate at which articles
are being published in each scientific field, it
has become difficult for researchers to keep up
with the developments in their respective fields.
Scientific summarization aims to facilitate this
problem by providing readers with concise and
informative representation of contributions or
findings of an article. Scientific summarization
is different than general summarization in three
main aspects (Teufel and Moens, 2002). First, the
length of scientific papers are usually much longer
than general articles (e.g newswire). Second,
in scientific summarization, the goal is typically
to provide a technical summary of the paper
which includes important findings, contributions
or impacts of a paper to the community. Finally,
scientific papers follow a natural discourse. A
common organization for scientific paper is the
one in which the problem is first introduced and
is followed by the description of hypotheses,
methods, experiments, findings and finally results
and implications. Scientific summarization
was recently further motivated by TAC2014
biomedical summarization track1 in which they
planned to investigate this problem in the domain
of biomedical science.
There are currently two types of approaches
towards scientific summarization. First is the
articles’ abstracts. While abstracts provide a
general overview of the paper, they cannot be
considered as an accurate scientific summary by
themselves. That is due to the fact that not all
the contributions and impacts of the paper are
included in the abstract (Elkiss et al., 2008). In
addition, the stated contributions are those that the
authors deem important while they might be less
important to the scientific community. Moreover,
contributions are stated in a general and less
focused fashion. These problems motivated the
other form of scientific summaries, i.e., citation
based summaries. Citation based summary is a
summary which is formed by utilizing a set of
citations to a referenced article (Qazvinian and
Radev, 2008; Qazvinian et al., 2013). This
set of citations has been previously indicated as
a good representation of important findings and
contributions of the article. Contributions stated
in the citations are usually more focused than the
abstract and contain additional information that is
not in the abstract (Elkiss et al., 2008).
However, citations may not accurately represent
</bodyText>
<footnote confidence="0.976315">
1Text Analysis Conference - http://www.nist.gov/tac/
</footnote>
<page confidence="0.7527085">
2014
390
</page>
<note confidence="0.985195">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 390–400,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999825971428571">
the content of the referenced article as they are
biased towards the viewpoint of the citing authors.
Moreover, citations may address a contribution or
a finding regarding the referenced article without
referring to the assumptions and data under which
it was obtained.
The problem of inconsistency between the
degree of certainty of expressing findings between
the citing article and referenced article has
been also reported (De Waard and Maat, 2012).
Therefore, citations by themselves lack the related
“context” from the original article. We call the
textual spans in the reference articles that reflect
the citation, the citation-context. Figure 1 shows
an example of the citation-context in the reference
article (green color) for a citation in the citing
article (blue color).
We propose an approach to overcome the
aforementioned shortcomings of existing
scientific summaries. Specifically, we extract
citation-context in the reference article for each
citation. Then, by using the discourse facets of
the citations as well as community structure of the
citation-contexts, we extract candidate sentences
for the summary. The final summary is formed by
maximizing both novelty and informativeness of
the sentences in the summary. We evaluate and
compare our methods against several well-known
summarization methods. Evaluation results on the
TAC2014 dataset show that our proposed methods
can effectively improve over the well-known
existing summarization approaches. That is, we
obtained greater than 30% improvement over the
highest performing baseline in terms of mean
ROUGE scores.
</bodyText>
<sectionHeader confidence="0.999714" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.994726642857143">
Document summarization is a relatively well
studied area and various types of approaches for
document summarization have been proposed in
the past twenty years.
Latent Semantic Analysis (LSA) has been
used in text summarization first by (Gong
and Liu, 2001). Other variations of LSA
based summarization approaches have later
been introduced (Steinberger and Jezek, 2004;
Steinberger et al., 2005; Lee et al., 2009; Ozsoy
et al., 2010). Summarization approaches based
on topic modeling and Bayesian models have
also been explored (Vanderwende et al., 2007;
Haghighi and Vanderwende, 2009; Celikyilmaz
</bodyText>
<subsectionHeader confidence="0.740707">
Citing article:
</subsectionHeader>
<bodyText confidence="0.9439486875">
... The general impression that has emerged is that transformation
of human cells by Ras requires the inactivation of both the pRb and p53
pathways, typically achieved by introducing DNA tumor virus oncoproteins
such as SV40 large tumor antigen (T-Ag) or human papillomavirus E6 and
E7 proteins ( Serrano et al., 1997 ).
To address this question, we have been investigating the ...
Reference article (Serrano et al., 1997):
... continued to incorporate BrdU and proliferate following introduction
of H-ras V12. In agreement with previous reports ( 66 and 60), both
p53/ and p16/ MEFs expressing H-ras V12 displayed features of oncogenic
transformation (e.g., refractile morphology, loss of contact inhibition), which
were apparent almost immediately after H-ras V12 was transduced (data not
shown). These results indicate that p53 and p16 are essential for ras-induced
arrest in MEFs, and that inactivation of either p53 or p16 alone is sufficient
to circumvent arrest. In REF52 and IMR90 fibroblasts, a different approach
was ...
</bodyText>
<figureCaption confidence="0.988672166666667">
Figure 1: The blue highlighted span in the citing article
(top) shows the citation text, followed by the citation marker
(pink span). For this citation, the citation-context is the
green highlighted span in the reference article (bottom). The
text spans outside the scope of the citation text and citation-
context are not highlighted.
</figureCaption>
<bodyText confidence="0.999630705882353">
and Hakkani-Tur, 2010; Ritter et al., 2010;
Celikyilmaz and Hakkani-T¨ur, 2011; Ma and
Nakagawa, 2013; Li and Li, 2014). In these
approaches, the content/topic distribution in the
final summary is estimated using a graphical
probabilistic model. Some approaches have
viewed summarization as an optimization task
solved by linear programming (Clarke and
Lapata, 2008; Berg-Kirkpatrick et al., 2011;
Woodsend and Lapata, 2012). Many works
have viewed the summarization problem as a
supervised classification problem in which several
features are used to predict the inclusion of
document sentences in the summary. Variations
of supervised models have been utilized for
summary generation, such as: maximum entropy
(Osborne, 2002), HMM (Conroy et al., 2011),
CRF (Galley, 2006; Shen et al., 2007; Chali and
Hasan, 2012), SVM (Xie and Liu, 2010), logistic
regression (Louis et al., 2010) and reinforcement
learning (Rioux et al., 2014). Problems with
supervised models in context of summarization
include the need for large amount of annotated
data and domain dependency.
Graph based models have shown promising
results for text summarization. In these
approaches, the goal is to find the most central
sentences in the document by constructing a
graph in which nodes are sentences and edges
are similarity between these sentences. Examples
of these techniques include LexRank (Erkan
and Radev, 2004), TextRank (Mihalcea and
Tarau, 2004), and the work by (Paul et al.,
2010). Maximizing the novelty and preventing
</bodyText>
<page confidence="0.997692">
391
</page>
<bodyText confidence="0.999914181818182">
the redundancy in a summary is addressed
by greedy selection of content summarization
(Carbonell and Goldstein, 1998; Guo and Sanner,
2010; Lin et al., 2010). Rhetorical structure
of the documents have also been investigated
for automatic summarization. In this line of
work, dependency and discourse parsing based
on Rhetorical Structure Theory (RST) (Mann
and Thompson, 1988) is used for analyzing the
structure of the documents (Hirao et al., 2013;
Kikuchi et al., 2014; Yoshida et al., 2014).
Summarization based on rhetorical structure is
better suited for shorter documents and is highly
dependent on the quality of the discourse parser
that is used. Training the discourse parser
requires large amount of training data in the RST
framework.
Scientific article summarization was first
studied by (Teufel and Moens, 2002) in which
they trained a supervised Naive Bayes classifier
to select informative content for the summary.
Later (Elkiss et al., 2008) argue the benefits of
citations to scientific work analysis. (Cohan et
al., 2015) use a search oriented approach for
finding relevant parts of the reference paper to
citations. (Qazvinian and Radev, 2008; Qazvinian
et al., 2013) use citations to an article to construct
its summary. More specifically, they perform
hierarchical agglomerative clustering on citations
to maximize purity and select most central
sentences from each cluster for the final summary.
Our work is closest to (Qazvinian and Radev,
2008) with the difference that they only make
use of citations. While citations are useful for
summarization, relying solely on them might
not accurately capture the original context of
the referenced paper. That is, the generated
summary lacks the appropriate evidence to
reflect the content of the original paper, such as
circumstances, data and assumptions under which
certain findings were obtained. We address this
shortcoming by leveraging the citation-context
and the inherent discourse model in the scientific
articles.
</bodyText>
<sectionHeader confidence="0.970858" genericHeader="method">
3 The summarization approach
</sectionHeader>
<bodyText confidence="0.966771">
Our scientific summary generation algorithm is
composed of four steps: (1) Extracting the
citation-context, (2) Grouping citation-contexts,
</bodyText>
<listItem confidence="0.9997465">
(3) Ranking the sentences within each group and
(4) Selecting the sentences for final summary. We
</listItem>
<bodyText confidence="0.9994595">
assume that the citation text (the text span in
the citing article that references another article)
in each citing article is already known. We
describe each step in the following sub-sections.
Our proposed method generates a summary of
an article with the premise that the article has
a number of citations to it. We call the article
that is being referenced the “reference article”.
We shall note that we tokenized the articles’ text
to sentences by using the punkt unsupervised
sentence boundary detection algorithm (Kiss and
Strunk, 2006). We modified the original sentence
boundary detection algorithm to also account for
biomedical abbreviations. For the rest of the
paper, “sentence” refers to units that are output
of the sentence boundary detection algorithm,
whereas “text span” or in short “span” can consist
of multiple sentences.
</bodyText>
<subsectionHeader confidence="0.999927">
3.1 Extracting the citation-context
</subsectionHeader>
<bodyText confidence="0.9997565">
As described in section 2, one problem with
existing citation based summarization approaches
is that they lack the context of the referenced
paper. Therefore, our goal is to leverage citation-
context in the reference article to correctly reflect
the reference paper. To find citation-contexts, we
consider each citation as an n-gram vector and use
vector space model for locating the relevant text
spans in the reference article. More specifically,
given a citation c, we return the ranked list of
text spans r1, r2, ..., rn which have the highest
similarity to c. We call the retrieved text spans
reference spans. These reference spans are
essentially forming the context for each citation.
The similarity function is the cosine similarity
between the pivoted normalized vectors. We
evaluated four different approaches for forming
the citation vector.
</bodyText>
<listItem confidence="0.999378">
1. All terms in citation except for stopwords,
numeric values and citation markers i.e., name
of authors or numbered citations. In figure 1 an
example of citation marker is shown.
2. Terms with high inverted document frequency
(idf). Idf values of terms have shown to be a good
estimate of term informativeness.
3. Concepts that are represented through noun
phrases in the citation, for example in the
following: “ ... typically achieved by introducing
DNA tumor virus oncoproteins such a ... ” which
is part of a citation, the phrase “DNA tumor virus
oncoproteins” is a noun phrase.
</listItem>
<page confidence="0.963741">
392
</page>
<bodyText confidence="0.979022153846154">
4. Biomedical concepts and noun phrases
expanded by related biomedical concepts: This
formation is specific to the biomedical domain.
It selects biomedical concepts and noun phrases
in the citation and uses related biomedical
terminology to expand the citation vector.
We used Metamap1 for extracting biomedical
concepts from the citation text (which is a tool
for mapping free form text to UMLS2 concepts).
For expanding the citation vector using the related
biomedical terminology, we used SNOMED CT3
ontology by which we added synonyms of the
concepts in the citation text to the citation vector.
</bodyText>
<subsectionHeader confidence="0.999973">
3.2 Grouping the citation-contexts
</subsectionHeader>
<bodyText confidence="0.974643066666667">
After identifying the context for each citation, we
use them to form the summary. To capture various
important aspects of the reference article, we form
groups of citation-contexts that are about the same
topic. We use the following two approaches for
forming these groups:
Community detection - We want to find diverse
key aspects of the reference article. We form
the graph of extracted reference spans in which
nodes are sentences and edges are similarity
between sentences. As for the similarity function,
we use cosine similarity between tf-idf vectors
of the sentences. Similar to (Qazvinian and
Radev, 2008), we want to find subgraphs or
communities whose intra-connectivity is high but
inter-connectivity is low. Such quality is captured
by the modularity measure of the graph (Newman,
2006; Newman, 2012). Graph modularity
quantifies the denseness of the subgraphs in
comparison with denseness of the graph of
randomly distributed edges and is defined as
follows:
[Avw − kv ×kw Jδ(cv, cw)
2m
Where Avw is the weigh of the edge (v, w); kv is
the degree of the vertex v; cv is the community of
vertex v; δ is the Kronecker’s delta function and
m = Evw Avw is the normalization factor.
While the general problem of precise partitioning
of the graph into highly dense communities
</bodyText>
<footnote confidence="0.9946195">
1http://metamap.nlm.nih.gov/
2Unified Medical Language System - a compendium of
controlled vocabularies in the biomedical sciences, http://
www.nlm.nih.gov/research/umls
3http://www.nlm.nih.gov/research/umls/Snomed/
snomed main.html
</footnote>
<bodyText confidence="0.999977764705883">
that optimizes the modularity is computationally
prohibitive (Brandes et al., 2008), many heuristic
algorithms have been proposed with reasonable
results. To extract communities from the graph
of reference spans, we use the algorithm proposed
by (Blondel et al., 2008) which is a simple
yet accurate and efficient community detection
algorithm. Specifically, communities are built in
a hierarchical fashion. At first, each node belongs
to a separate community. Then nodes are assigned
to new communities if there is a positive gain
in modularity. This process is applied iteratively
until no further improvement in modularity is
possible.
Discourse model - A natural discourse model is
followed in each scientific article. In this method,
instead of finding communities to capture different
important aspects of the paper, we try to select
reference spans based on the discourse model of
the paper. The discourse model is according
to the following facets: “hypothesis”, “method”,
“results”, “implication”, “discussion” and “data-
set-used”. The goal is to ideally include reference
spans from each of these discourse facets of the
article in the summary to correctly capture all
aspects of the article. We use a one-vs-rest SVM
supervised model with linear kernel to classify
the reference spans to their respective discourse
facets. Training was done on both the citation
and reference spans since empirical evaluation
showed marginal improvements upon including
the reference spans in addition to the citation
itself. We use unigram and verb features with tf-
idf weighting to train the classifier.
</bodyText>
<subsectionHeader confidence="0.99852">
3.3 Ranking model
</subsectionHeader>
<bodyText confidence="0.999928384615385">
To identify the most representative sentences of
each group, we require a measure of importance
of sentences. We consider the sentences in a
group as a graph and rank nodes based on their
importance. An important node is a node that
has many connections with other nodes. There
are various ways of measuring centrality of nodes
such as nodes degree, betweenness, closeness and
eigenvectors. Here, we opt for eigenvectors and
we find the most central sentences in each group
by using the “power method” (Erkan and Radev,
2004) which iteratively updates the eigenvector
until convergence.
</bodyText>
<equation confidence="0.9617135">
1 � Q = 2m
vw
</equation>
<page confidence="0.992204">
393
</page>
<subsectionHeader confidence="0.995933">
3.4 Selecting the sentences for final summary
</subsectionHeader>
<bodyText confidence="0.9998246">
After scoring and ranking the sentences in each
group which were identified either by discourse
model or by community detection algorithm, we
employ two strategies for generating the summary
within the summary length threshold.
</bodyText>
<listItem confidence="0.992577571428572">
• Iterative: We select top sentences iteratively from
each group until we reach the summary length
threshold. That is, we first pick the top sentence
from all groups and if the threshold is not met,
we select the second sentence and so forth. In the
discourse based method, the following ordering
for selecting sentences from groups is used:
“hypothesis”, “method”,“results”, “implication”
and “discussion”. In the community detection
method, no pre-determined order is specified.
• Novelty: We employ a greedy strategy similar to
MMR (Carbonell and Goldstein, 1998) in which
sentences from each group are selected based on
the following scoring formula:
</listItem>
<equation confidence="0.9943395">
score(S) def=λSim1(S, D)
− (1 − λ)Sim2(S,Summary)
</equation>
<bodyText confidence="0.99994875">
Where, for each sentence S, the score is a
linear interpolation of similarity of sentence with
all other sentences (Sim1) and the similarity
of sentence with the sentences already in the
summary (Sim2) and λ is a constant. We
empirically set λ = 0.7 and also selected
top 3 central sentences from each group as the
candidates for the final summary.
</bodyText>
<sectionHeader confidence="0.997944" genericHeader="method">
4 Experimental setup
</sectionHeader>
<subsectionHeader confidence="0.931575">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.9998424">
We used the TAC2014 biomedical summarization
dataset for evaluation of our proposed method.
The TAC2014 benchmark contains 20 topics
each of which consists of one reference article
and several articles that have citations to each
reference article (the statistics of the dataset is
shown in Table 1). All articles are biomedical
papers published by Elsevier. For each topic,
4 experts in biomedical domain have written a
scientific summary of length not exceeding 250
words for the reference article. The data also
contains annotated citation texts as well as the
discourse facets. The latter were used to build the
supervised discourse model. The distribution of
discourse facets is shown in Table 2.
</bodyText>
<tableCaption confidence="0.995367">
Table 1: Dataset statistics
</tableCaption>
<table confidence="0.999105875">
mean std
# of topics (reference articles) 20 0
# of Gold summaries for each topic 4 0
# of citing articles in each topic 15.65 2.70
# of citations to the reference article in 1.57 1.17
each citing article
Length of summaries (words) 235.64 31.24
Length of articles (words) 9759.86 2199.48
</table>
<tableCaption confidence="0.822952">
Table 2: Distribution of annotated discourse facets
</tableCaption>
<table confidence="0.974868">
Discourse facet count
Hypothesis 21
Method 155
Results 490
Implication 140
Discussion 446
</table>
<subsectionHeader confidence="0.938285">
4.2 Baselines
</subsectionHeader>
<bodyText confidence="0.999668">
We compared existing well-known and widely-
used approaches discussed in section 2 with
our approach and evaluated their effectiveness
for scientific summarization. The first three
approaches use the scientific article’s text and the
last approach uses the citations to the article for
generating the summary.
</bodyText>
<listItem confidence="0.647830857142857">
• LSA (Steinberger and Jezek, 2004) - The LSA
summarization method is based on singular value
decomposition. In this method, a term document
index A is created in which the values correspond
to the tf-idf values of terms in the document.
Then, Singular Value Decomposition, a dimension
reduction approach, is applied to A. This will
yield a singular value matrix E and a singular
vector matrix VT. The top singular vectors are
selected from VT iteratively until length of the
summary reaches a predefined threshold.
• LexRank (Erkan and Radev, 2004) - LexRank
uses a measure called centrality to find the most
representative sentences in given sets of sentences.
</listItem>
<bodyText confidence="0.691261875">
It finds the most central sentences by updating the
score of each sentence using an algorithm based
on PageRank random walk ranking model (Page et
al., 1999). More specifically, the centrality score
of each sentence is represented by a centrality
matrix p which is updated iteratively through the
following equation using a method called “power
method”:
</bodyText>
<figure confidence="0.854591">
p = ATp
Where matrix A is based on the similarity matrix
B of the sentences:
A = [dU + (1 − d)B]
</figure>
<page confidence="0.992406">
394
</page>
<bodyText confidence="0.999909333333333">
In which U is a square matrix with values 1/N and
d is a parameter called the damping factor. We set
d to 0.1 which is the default suggested value.
</bodyText>
<listItem confidence="0.964954">
• MMR (Carbonell and Goldstein, 1998) - In
Maximal Marginal Relevance (MMR), sentences
are greedily ranked according to a score based on
their relevance to the document and the amount
of redundant information they carry. It scores
sentences based on the maximization of the linear
interpolation of the relevance to the document and
diversity:
</listItem>
<equation confidence="0.9816795">
MMR(S,D) def =ASim1(S, D)
− (1 − A)Sim2(S,Summary)
</equation>
<bodyText confidence="0.99115425">
Where S is the sentence being evaluated, D is
the document being summarized, Sim1 and Sim2
are similarity function, Summary is the summary
formed by the previously selected sentences and
A is a parameter. We used cosine similarity as
similarity functions and we set A to 0.3, 0.5 and
0.7 for observing the effect of informativeness vs.
novelty.
</bodyText>
<listItem confidence="0.926497">
• Citation summary (Qazvinian and Radev, 2008)-
</listItem>
<bodyText confidence="0.993931076923077">
In this approach, a network of citations is built
and citations are clustered to maximum purity
(Zhao and Karypis, 2001) and mutual information.
These clusters are then used to generate the final
summary by selecting the top central sentences
from each cluster in a round-robin fashion. Our
approach is similar to this work in that they also
use centrality scores on citation network clusters.
Since they only focus on citations, comparison of
our approach with this work gives a better insight
into how beneficial our use of citation-context
and article’s discourse model can be in generating
scientific summaries.
</bodyText>
<sectionHeader confidence="0.999318" genericHeader="evaluation">
5 Results and discussions
</sectionHeader>
<subsectionHeader confidence="0.972054">
5.1 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.9657309">
We use the ROUGE evaluation metrics which
has shown consistent correlation with manually
evaluated summarization scores (Lin, 2004). More
specifically, we use ROUGE-L, ROUGE-1 and
ROUGE-2 to evaluate and compare the quality of
the summaries generated by our system. While
ROUGE-N focuses on n-gram overlaps, ROUGE-L
uses the longest common subsequence to measure
the quality of the summary. ROUGE-N where N
is the n-gram order, is defined as follows:
</bodyText>
<equation confidence="0.99371075">
P P fmatch(W )
ROUGE-N = SE{Gold summaries} WES
P P
SE{Gold summaries} WES
</equation>
<bodyText confidence="0.992168833333333">
Where W is the n-gram, f(.) is the count function,
fmatch(.) is the maximum number of n-grams co-
occurring in the generated summary and in a set of
gold summaries. For a candidate summary C with
n words and a gold summary S with u sentences,
ROUGE-L is defined as follows:
</bodyText>
<equation confidence="0.997187">
LCS∪(ri, C)
Pui=1 |ri|
i=1
Pu LCS∪(ri, C)
n
</equation>
<bodyText confidence="0.9950708">
Where LCS∪(., .) is the Longest common
subsequence (LCS) score of the union of LCS
between gold sentence ri and the candidate
summary C. ROUGE-L f score is the harmonic
mean between precision and recall.
</bodyText>
<subsectionHeader confidence="0.999718">
5.2 Comparison between summarizers
</subsectionHeader>
<bodyText confidence="0.999847458333333">
We generated two sets of summaries using the
methods and baselines described in previous
sections. We consider short summaries of
length 100 words and longer summaries of
length 250 words (which corresponds to the
length threshold in gold summaries). We also
considered the oracle’s performance by averaging
over the ROUGE scores of all human summaries
calculated by considering one human summary
against others in each topic. As far as 100
words summaries, since we did not have gold
summaries of that length, we considered the first
100 words from each gold summary. Figure 2
shows the box-and-whisker plots with ROUGE
scores. For each metric, the scores of each
summarizer in comparison with the baselines for
100 word summaries and 250 words summaries
are shown. The citation-context for all the
methods were identified by the citation text vector
method which uses the citation text except for
numeric values, stop words and citation markers
(first method in section 3.1). In section 5.3,
we analyze the effect of various citation-context
extraction methods that we discussed in section 3
</bodyText>
<equation confidence="0.9930766">
f(W)
ROUGE-Lrec =
ROUGE-Lprec =
Pu
i=1
</equation>
<page confidence="0.998134">
395
</page>
<figureCaption confidence="0.969523714285714">
Figure 2: ROUGE-1, ROUGE-2 and ROUGE-L scores for different summarization approaches. Chartreuse (yellowish
green) box shows the oracle, green boxes show the proposed summarizers and blue boxes show the baselines; From left,
Oracle; Citation-Context-Comm-It: Community detection on citation-context followed by iterative selection; Citation-Context-
Community-Div: Community detection on citation-context followed by relevance and diversification in sentence selection;
Citation-Context-Discourse-Div: Discourse model on citation-context followed by relevance and diversification; Citation-
Context-Discourse-It: Discourse model on citation-context followed by iterative selection; Citation Summ.: Citation summary;
MMR 0.3: Maximal marginal relevance with λ = 0.3.
</figureCaption>
<page confidence="0.997433">
396
</page>
<bodyText confidence="0.999940705882353">
on the final summary. The name of each
of our methods is shortened by the following
convention: [Summarization approach] [Sentence
selection strategy]. Summarization approach is
based on either community detection (Citation-
Context-Comm) or discourse model of the article
(Citation-Context-Disc) and sentence selection
strategy can be iterative (It) or by relevance and
diversification (Div).
We can clearly observe that our proposed
methods achieve encouraging results in
comparison with existing baselines. Specifically,
for 100 words short summaries, the discourse
based method (with 34.6% mean ROUGE-L
improvement over the best baseline) and for 250
word summaries, the community based method
(with 3.5% mean ROUGE-L improvement over the
best baseline) are the best performing methods.
We observe relative consistency between different
rouge scores for each summarization approach.
Grouping citation-context based on both the
discourse structure and the communities show
comparable results. The community detection
approach is thus effectively able to identify
diverse aspects of the article. The discourse
model of the scientific article is also able to
diversify selection of citation contexts for the final
summary. These results confirm our hypotheses
that using the citation context along with the
discourse model of the scientific articles can help
producing better summaries.
Comparison of performance of methods on
individual topics showed that the citation-context
methods consistently over perform all other
methods in most of the topics (65% of all topics).
While the discourse approach shows
encouraging results, we attribute its limitation
in achieving higher ROUGE scores to the
classification errors that we observed in intrinsic
classification evaluation. In evaluating the
performance of several classifiers, linear SVM
achieved the highest performance with accuracy
of 0.788 in comparison with human annotation
performance. Many of the citations cannot exactly
belong to only one of the discourse facets of
the paper and thus some errors in classification
are inevitable. This is also observable in
disagreements between the annotators in labeling
as reported by (Cohan et al., 2014). This fact
influences the diversification and finally the
summarization quality.
Among baseline summarization approaches,
LexRank performs relatively well. Its
performance is the best for short summaries
among other baselines. This is expected since
LexRank tries to find the most central sentences.
When the length of the summary is short, the
main idea in the summary is usually captured by
finding the most representative sentence which
LexRank can effectively achieve. However, the
sentences that it chooses are usually about the
same topic. Hence, the diversity in the gold
summaries is not considered. This becomes more
visible when we observe 250 word summaries.
Our discourse based method can overcome this
problem by including important contents for
diverse discourse facets (34.6% mean ROUGE-L
improvement for 100 words summaries and
13.9% improvement for 250 word summaries).
The community based approach achieves the
same diversification effect in an unsupervised
fashion by forming citation-context communities
(27.16% mean ROUGE-L improvement for 100
words summaries and 14.9% improvement for
250 word summaries).
The citation based summarization baseline
has somewhat average performance among the
baseline methods. This confirms that relying only
on the citations can not be optimal for scientific
summarization. While LSA approach performs
relatively well, we observe lower scores for all
variations of MMR approaches. We attribute
the low performance of MMR to its sub optimal
greedy selection of sentences from relatively long
scientific articles.
By comparing the two sentence selection
approaches (i.e., iterative and diversification-
relevance), we observe that while for shorter
length summaries the method based on
diversification performs better, for the longer
summaries results for the two methods are
comparable. This is because when the length
threshold is smaller, iterative approach may fail
to select best representative sentences from all
the groups. It essentially selects one sentence
from each group until the length threshold is met,
and consequently misses some aspects. Whereas,
the diversification method selects sentences that
maximize the gain in informativeness and at
the same time contributes to the novelty of the
summary. In longer summaries, due to larger
threshold, iterative approach seems to be able
</bodyText>
<page confidence="0.996406">
397
</page>
<figureCaption confidence="0.999713">
Figure 3: Comparison of the effect of different citation-context extraction methods on the quality of the final summary.
</figureCaption>
<bodyText confidence="0.999957636363636">
to select the top sentences from each group,
enabling it to reflect different aspect of the
paper. Therefore, the iterative approach performs
comparably well to the diversification approach.
This outcome is expected because the number of
groups are small. For discourse method, there are
5 different discourse facets and for community
method, on average 5.2 communities are detected.
Hence, iterative selection can select sentences
from most of these groups within 250 words limit
summaries.
</bodyText>
<subsectionHeader confidence="0.9876835">
5.3 Analysis of strategies for citation-context
extraction
</subsectionHeader>
<bodyText confidence="0.998316032258065">
Figure 3 shows ROUGE-L results for 250 words
summaries based on using different citation-
context extraction approaches, described in
section 3.1. Relatively comparable performance
for all the approaches is achieved. Using
the citation text for extracting the context is
almost as effective as other methods. Keywords
approach which uses the terms with high idf
values for locating the context achieves slightly
higher Rouge-L precision while it has the lowest
recall. This is expected since keywords approach
chooses only informative terms for extracting
citation-contexts. This results in missing terms
that may not be keywords by themselves but
help providing meaning. Noun phrases has
the highest mean F-score and thus suggests the
fact that noun phrases are good indicators of
important concepts in scientific text. We attribute
the high recall of noun phrases to the fact that
most important concepts are captured by only
selecting noun phrases. Interestingly, introducing
biomedical concepts and expanding the citation
vector by related concepts does not improve
the performance. This approach achieves a
relatively higher recall but a lower mean precision.
While capturing domain concepts along with noun
phrases helps improving the performance, adding
related concepts to the citation vector causes
drift from the original context as expressed in
the reference article. Therefore some decline in
performance is incurred.
</bodyText>
<sectionHeader confidence="0.999015" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999965411764706">
We proposed a pipeline approach for
summarization of scientific articles which
takes advantage of the article’s inherent discourse
model and citation-contexts extracted from the
reference article1. Our approach focuses on the
problem of lack of context in existing citation
based summarization approaches. We effectively
achieved improvement over several well known
summarization approaches on the TAC2014
biomedical summarization dataset. That is, in all
cases we improved over the baselines; in some
cases we obtained greater than 30% improvement
for mean ROUGE scores over the best performing
baseline. While the dataset we use for evaluation
of scientific articles is in biomedical domain,
most of our approaches are general and therefore
adaptable to other scientific domains.
</bodyText>
<sectionHeader confidence="0.998028" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9992718">
The authors would like to thank the three
anonymous reviewers for their valuable feedback
and comments. This research was partially
supported by National Science Foundation (NSF)
under grant CNS-1204347.
</bodyText>
<footnote confidence="0.9685005">
1Code can be found at: https://github.com/acohan/
scientific-summ
</footnote>
<page confidence="0.996314">
398
</page>
<sectionHeader confidence="0.982716" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999035425925926">
Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein.
2011. Jointly learning to extract and compress.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies-Volume 1, pages 481–490.
Association for Computational Linguistics.
Vincent D Blondel, Jean-Loup Guillaume, Renaud
Lambiotte, and Etienne Lefebvre. 2008. Fast
unfolding of communities in large networks.
Journal of Statistical Mechanics: Theory and
Experiment, 2008(10):P10008.
Ulrik Brandes, Daniel Delling, Marco Gaertler,
Robert Gorke, Martin Hoefer, Zoran Nikoloski,
and Dorothea Wagner. 2008. On modularity
clustering. Knowledge and Data Engineering, IEEE
Transactions on, 20(2):172–188.
Jaime Carbonell and Jade Goldstein. 1998. The use
of mmr, diversity-based reranking for reordering
documents and producing summaries. In SIGIR,
pages 335–336. ACM.
Asli Celikyilmaz and Dilek Hakkani-Tur. 2010. A
hybrid hierarchical model for multi-document
summarization. In ACL, pages 815–824.
Association for Computational Linguistics.
Asli Celikyilmaz and Dilek Hakkani-T¨ur. 2011.
Discovery of topically coherent sentences for
extractive summarization. In ACL: HLT-Volume
1, pages 491–499. Association for Computational
Linguistics.
Yllias Chali and Sadid a. Hasan. 2012. Query-focused
multi-document summarization: Automatic data
annotations and supervised learning approaches.
Nat. Lang. Eng., 18(1):109–145, January.
James Clarke and Mirella Lapata. 2008. Global
inference for sentence compression an integer
linear programming approach. J. Artif. Int. Res.,
31(1):399–429, March.
Arman Cohan, Luca Soldaini, and Nazli Goharian.
2014. Towards citation-based summarization of
biomedical literature. Proceedings of the Text
Analysis Conference (TAC ’14).
Arman Cohan, Luca Soldaini, and Nazli Goharian.
2015. Matching citation text and cited spans
in biomedical literature: a search-oriented
approach. In Proceedings of the 2015 NAACL-HLT,
pages 1042–1048. Association for Computational
Linguistics.
John M Conroy, Judith D Schlesinger, Jeff Kubina,
Peter A Rankel, and Dianne P OLeary. 2011. Classy
2011 at tac: Guided and multi-lingual summaries
and evaluation metrics. In Proceedings of the Text
Analysis Conference.
Anita De Waard and Henk Pander Maat. 2012.
Epistemic modality and knowledge attribution
in scientific discourse: A taxonomy of types
and overview of features. In Proceedings
of the Workshop on Detecting Structure in
Scholarly Discourse, pages 47–55. Association
for Computational Linguistics.
Aaron Elkiss, Siwei Shen, Anthony Fader, G¨unes¸
Erkan, David States, and Dragomir Radev. 2008.
Blind men and elephants: What do citation
summaries tell us about a research article? Journal
of the American Society for Information Science and
Technology, 59(1):51–62.
G¨unes Erkan and Dragomir R Radev. 2004.
Lexrank: Graph-based lexical centrality as salience
in text summarization. J. Artif. Intell. Res.(JAIR),
22(1):457–479.
Michel Galley. 2006. A skip-chain conditional
random field for ranking meeting utterances
by importance. In EMNLP, pages 364–372.
Association for Computational Linguistics.
Yihong Gong and Xin Liu. 2001. Generic text
summarization using relevance measure and latent
semantic analysis. In Proceedings of the 24th
annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 19–25. ACM.
Shengbo Guo and Scott Sanner. 2010. Probabilistic
latent maximal marginal relevance. In SIGIR, pages
833–834. ACM.
Aria Haghighi and Lucy Vanderwende. 2009.
Exploring content models for multi-document
summarization. In NAACL-HLT, pages 362–370.
Association for Computational Linguistics.
Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,
Norihito Yasuda, and Masaaki Nagata. 2013.
Single-document summarization as a tree knapsack
problem. In EMNLP, pages 1515–1520.
Yuta Kikuchi, Tsutomu Hirao, Hiroya Takamura,
Manabu Okumura, and Masaaki Nagata. 2014.
Single document summarization based on nested
tree structure. In Proceedings of the 52nd Annual
Meeting of the Association for Computational
Linguistics, volume 2, pages 315–320.
Tibor Kiss and Jan Strunk. 2006. Unsupervised
multilingual sentence boundary detection.
Computational Linguistics, 32(4):485–525.
Ju-Hong Lee, Sun Park, Chan-Min Ahn, and Daeho
Kim. 2009. Automatic generic document
summarization based on non-negative matrix
factorization. Information Processing &amp;
Management, 45(1):20 – 34.
Jiwei Li and Sujian Li. 2014. A novel feature-based
bayesian model for query focused multi-document
summarization. Transactions of the Association for
Computational Linguistics, 1:89–98.
</reference>
<page confidence="0.988461">
399
</page>
<reference confidence="0.999899450450451">
Jimmy Lin, Nitin Madnani, and Bonnie J Dorr.
2010. Putting the user in the loop: interactive
maximal marginal relevance for query-focused
summarization. In NAACL-HLT, pages 305–308.
Association for Computational Linguistics.
Chin-Yew Lin. 2004. Rouge: A package for
automatic evaluation of summaries. In Text
Summarization Branches Out: Proceedings of the
ACL-04 Workshop, pages 74–81.
Annie Louis, Aravind Joshi, and Ani Nenkova.
2010. Discourse indicators for content selection in
summarization. In Proceedings of the 11th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue, pages 147–156. Association for
Computational Linguistics.
Tengfei Ma and Hiroshi Nakagawa. 2013.
Automatically determining a proper length for
multi-document summarization: A bayesian
nonparametric approach. In EMNLP, pages 736–
746. Association for Computational Linguistics.
William C Mann and Sandra A Thompson. 1988.
Rhetorical structure theory: Toward a functional
theory of text organization. Text, 8(3):243–281.
Rada Mihalcea and Paul Tarau. 2004. Textrank:
Bringing order into texts. Association for
Computational Linguistics.
Mark EJ Newman. 2006. Modularity and community
structure in networks. Proceedings of the National
Academy of Sciences, 103(23):8577–8582.
MEJ Newman. 2012. Communities, modules and
large-scale structure in networks. Nature Physics,
8(1):25–31.
Miles Osborne. 2002. Using maximum entropy
for sentence extraction. In Proceedings of the
ACL-02 Workshop on Automatic Summarization-
Volume 4, pages 1–8. Association for Computational
Linguistics.
Makbule Gulcin Ozsoy, Ilyas Cicekli, and Ferda Nur
Alpaslan. 2010. Text summarization of turkish
texts using latent semantic analysis. In COLING,
pages 869–876. Association for Computational
Linguistics.
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation
ranking: Bringing order to the web.
Michael Paul, ChengXiang Zhai, and Roxana Girju.
2010. Summarizing contrastive viewpoints in
opinionated text. In EMNLP, pages 66–76.
Association for Computational Linguistics.
Vahed Qazvinian and Dragomir R Radev. 2008.
Scientific paper summarization using citation
summary networks. In Proceedings of the 22nd
International Conference on Computational
Linguistics-Volume 1, pages 689–696. Association
for Computational Linguistics.
Vahed Qazvinian, Dragomir R Radev, Saif
Mohammad, Bonnie J Dorr, David M Zajic,
Michael Whidby, and Taesun Moon. 2013.
Generating extractive summaries of scientific
paradigms. J. Artif. Intell. Res.(JAIR), 46:165–201.
Cody Rioux, A. Sadid Hasan, and Yllias Chali.
2014. Fear the reaper: A system for automatic
multi-document summarization with reinforcement
learning. In EMNLP, pages 681–690. Association
for Computational Linguistics.
Alan Ritter, Colin Cherry, and Bill Dolan.
2010. Unsupervised modeling of twitter
conversations. In NAACL-HLT, HLT ’10, pages
172–180, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, and
Zheng Chen. 2007. Document summarization using
conditional random fields. In IJCAI, volume 7,
pages 2862–2867.
Josef Steinberger and Karel Jezek. 2004. Using
latent semantic analysis in text summarization and
summary evaluation. In Proc. ISIM04, pages 93–
100.
Josef Steinberger, Mijail A Kabadjov, Massimo
Poesio, and Olivia Sanchez-Graillet. 2005.
Improving lsa-based summarization with anaphora
resolution. In EMNLP-HLT, pages 1–8. Association
for Computational Linguistics.
Simone Teufel and Marc Moens. 2002. Summarizing
scientific articles: Experiments with relevance and
rhetorical status. Comput. Linguist., 28(4):409–445,
December.
Lucy Vanderwende, Hisami Suzuki, Chris Brockett,
and Ani Nenkova. 2007. Beyond sumbasic: Task-
focused summarization with sentence simplification
and lexical expansion. Information Processing &amp;
Management, 43(6):1606–1618.
Kristian Woodsend and Mirella Lapata. 2012.
Multiple aspect summarization using integer linear
programming. In EMNLP, pages 233–243.
Association for Computational Linguistics.
Shasha Xie and Yang Liu. 2010. Improving supervised
learning for meeting summarization using sampling
and regression. Computer Speech &amp; Language,
24(3):495 – 514. Emergent Artificial Intelligence
Approaches for Pattern Recognition in Speech and
Language Processing.
Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao,
and Masaaki Nagata. 2014. Dependency-
based discourse parser for single-document
summarization. In EMNLP, pages 1834–
1839, Doha, Qatar, October. Association for
Computational Linguistics.
Ying Zhao and George Karypis. 2001. Criterion
functions for document clustering: Experiments and
analysis. Technical report, Citeseer.
</reference>
<page confidence="0.997281">
400
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.385435">
<title confidence="0.9956675">Scientific Article Summarization Using and Article’s Discourse Structure</title>
<author confidence="0.99324">Arman</author>
<affiliation confidence="0.930625">Information Retrieval Computer Science Georgetown</affiliation>
<email confidence="0.999294">arman@ir.cs.georgetown.edu</email>
<author confidence="0.626439">Nazli</author>
<affiliation confidence="0.924901">Information Retrieval Computer Science Georgetown</affiliation>
<email confidence="0.999666">nazli@ir.cs.georgetown.edu</email>
<abstract confidence="0.9978965">We propose a summarization approach for scientific articles which takes advantage of citation-context and the document discourse model. While citations have been previously used in generating scientific summaries, they lack the related context from the referenced article and therefore do not accurately reflect the article’s content. Our method overcomes the problem of inconsistency between the citation summary and the article’s content by providing context for each citation. We also leverage the inherent scientific article’s discourse for producing better summaries. We show that our proposed method effectively improves over existing summarization approaches (greater than 30% improvement over the best performing baseline) in terms of on TAC2014 scientific summarization dataset. While the dataset we use for evaluation is in the biomedical domain, most of our approaches are general and therefore adaptable to other domains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Gillick</author>
<author>Dan Klein</author>
</authors>
<title>Jointly learning to extract and compress.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>481--490</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7952" citStr="Berg-Kirkpatrick et al., 2011" startWordPosition="1156" endWordPosition="1159">the citation marker (pink span). For this citation, the citation-context is the green highlighted span in the reference article (bottom). The text spans outside the scope of the citation text and citationcontext are not highlighted. and Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-T¨ur, 2011; Ma and Nakagawa, 2013; Li and Li, 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization inc</context>
</contexts>
<marker>Berg-Kirkpatrick, Gillick, Klein, 2011</marker>
<rawString>Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein. 2011. Jointly learning to extract and compress. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 481–490. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent D Blondel</author>
<author>Jean-Loup Guillaume</author>
<author>Renaud Lambiotte</author>
<author>Etienne Lefebvre</author>
</authors>
<title>Fast unfolding of communities in large networks.</title>
<date>2008</date>
<journal>Journal of Statistical Mechanics: Theory and Experiment,</journal>
<volume>2008</volume>
<issue>10</issue>
<contexts>
<context position="16069" citStr="Blondel et al., 2008" startWordPosition="2406" endWordPosition="2409"> the normalization factor. While the general problem of precise partitioning of the graph into highly dense communities 1http://metamap.nlm.nih.gov/ 2Unified Medical Language System - a compendium of controlled vocabularies in the biomedical sciences, http:// www.nlm.nih.gov/research/umls 3http://www.nlm.nih.gov/research/umls/Snomed/ snomed main.html that optimizes the modularity is computationally prohibitive (Brandes et al., 2008), many heuristic algorithms have been proposed with reasonable results. To extract communities from the graph of reference spans, we use the algorithm proposed by (Blondel et al., 2008) which is a simple yet accurate and efficient community detection algorithm. Specifically, communities are built in a hierarchical fashion. At first, each node belongs to a separate community. Then nodes are assigned to new communities if there is a positive gain in modularity. This process is applied iteratively until no further improvement in modularity is possible. Discourse model - A natural discourse model is followed in each scientific article. In this method, instead of finding communities to capture different important aspects of the paper, we try to select reference spans based on the</context>
</contexts>
<marker>Blondel, Guillaume, Lambiotte, Lefebvre, 2008</marker>
<rawString>Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrik Brandes</author>
<author>Daniel Delling</author>
<author>Marco Gaertler</author>
<author>Robert Gorke</author>
<author>Martin Hoefer</author>
<author>Zoran Nikoloski</author>
<author>Dorothea Wagner</author>
</authors>
<title>On modularity clustering. Knowledge and Data Engineering,</title>
<date>2008</date>
<journal>IEEE Transactions on,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="15884" citStr="Brandes et al., 2008" startWordPosition="2378" endWordPosition="2381">kv ×kw Jδ(cv, cw) 2m Where Avw is the weigh of the edge (v, w); kv is the degree of the vertex v; cv is the community of vertex v; δ is the Kronecker’s delta function and m = Evw Avw is the normalization factor. While the general problem of precise partitioning of the graph into highly dense communities 1http://metamap.nlm.nih.gov/ 2Unified Medical Language System - a compendium of controlled vocabularies in the biomedical sciences, http:// www.nlm.nih.gov/research/umls 3http://www.nlm.nih.gov/research/umls/Snomed/ snomed main.html that optimizes the modularity is computationally prohibitive (Brandes et al., 2008), many heuristic algorithms have been proposed with reasonable results. To extract communities from the graph of reference spans, we use the algorithm proposed by (Blondel et al., 2008) which is a simple yet accurate and efficient community detection algorithm. Specifically, communities are built in a hierarchical fashion. At first, each node belongs to a separate community. Then nodes are assigned to new communities if there is a positive gain in modularity. This process is applied iteratively until no further improvement in modularity is possible. Discourse model - A natural discourse model </context>
</contexts>
<marker>Brandes, Delling, Gaertler, Gorke, Hoefer, Nikoloski, Wagner, 2008</marker>
<rawString>Ulrik Brandes, Daniel Delling, Marco Gaertler, Robert Gorke, Martin Hoefer, Zoran Nikoloski, and Dorothea Wagner. 2008. On modularity clustering. Knowledge and Data Engineering, IEEE Transactions on, 20(2):172–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of mmr, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In SIGIR,</booktitle>
<pages>335--336</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9185" citStr="Carbonell and Goldstein, 1998" startWordPosition="1345" endWordPosition="1348"> the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of trai</context>
<context position="18862" citStr="Carbonell and Goldstein, 1998" startWordPosition="2843" endWordPosition="2846">for generating the summary within the summary length threshold. • Iterative: We select top sentences iteratively from each group until we reach the summary length threshold. That is, we first pick the top sentence from all groups and if the threshold is not met, we select the second sentence and so forth. In the discourse based method, the following ordering for selecting sentences from groups is used: “hypothesis”, “method”,“results”, “implication” and “discussion”. In the community detection method, no pre-determined order is specified. • Novelty: We employ a greedy strategy similar to MMR (Carbonell and Goldstein, 1998) in which sentences from each group are selected based on the following scoring formula: score(S) def=λSim1(S, D) − (1 − λ)Sim2(S,Summary) Where, for each sentence S, the score is a linear interpolation of similarity of sentence with all other sentences (Sim1) and the similarity of sentence with the sentences already in the summary (Sim2) and λ is a constant. We empirically set λ = 0.7 and also selected top 3 central sentences from each group as the candidates for the final summary. 4 Experimental setup 4.1 Data We used the TAC2014 biomedical summarization dataset for evaluation of our propose</context>
<context position="22166" citStr="Carbonell and Goldstein, 1998" startWordPosition="3389" endWordPosition="3392">he most central sentences by updating the score of each sentence using an algorithm based on PageRank random walk ranking model (Page et al., 1999). More specifically, the centrality score of each sentence is represented by a centrality matrix p which is updated iteratively through the following equation using a method called “power method”: p = ATp Where matrix A is based on the similarity matrix B of the sentences: A = [dU + (1 − d)B] 394 In which U is a square matrix with values 1/N and d is a parameter called the damping factor. We set d to 0.1 which is the default suggested value. • MMR (Carbonell and Goldstein, 1998) - In Maximal Marginal Relevance (MMR), sentences are greedily ranked according to a score based on their relevance to the document and the amount of redundant information they carry. It scores sentences based on the maximization of the linear interpolation of the relevance to the document and diversity: MMR(S,D) def =ASim1(S, D) − (1 − A)Sim2(S,Summary) Where S is the sentence being evaluated, D is the document being summarized, Sim1 and Sim2 are similarity function, Summary is the summary formed by the previously selected sentences and A is a parameter. We used cosine similarity as similarit</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In SIGIR, pages 335–336. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-Tur</author>
</authors>
<title>A hybrid hierarchical model for multi-document summarization. In</title>
<date>2010</date>
<booktitle>ACL,</booktitle>
<pages>815--824</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Celikyilmaz, Hakkani-Tur, 2010</marker>
<rawString>Asli Celikyilmaz and Dilek Hakkani-Tur. 2010. A hybrid hierarchical model for multi-document summarization. In ACL, pages 815–824. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-T¨ur</author>
</authors>
<title>Discovery of topically coherent sentences for extractive summarization.</title>
<date>2011</date>
<booktitle>In ACL: HLT-Volume 1,</booktitle>
<pages>491--499</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Celikyilmaz, Hakkani-T¨ur, 2011</marker>
<rawString>Asli Celikyilmaz and Dilek Hakkani-T¨ur. 2011. Discovery of topically coherent sentences for extractive summarization. In ACL: HLT-Volume 1, pages 491–499. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yllias Chali</author>
<author>Sadid a Hasan</author>
</authors>
<title>Query-focused multi-document summarization: Automatic data annotations and supervised learning approaches.</title>
<date>2012</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="8372" citStr="Chali and Hasan, 2012" startWordPosition="1220" endWordPosition="1223">is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea </context>
</contexts>
<marker>Chali, Hasan, 2012</marker>
<rawString>Yllias Chali and Sadid a. Hasan. 2012. Query-focused multi-document summarization: Automatic data annotations and supervised learning approaches. Nat. Lang. Eng., 18(1):109–145, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression an integer linear programming approach.</title>
<date>2008</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="7921" citStr="Clarke and Lapata, 2008" startWordPosition="1152" endWordPosition="1155">tation text, followed by the citation marker (pink span). For this citation, the citation-context is the green highlighted span in the reference article (bottom). The text spans outside the scope of the citation text and citationcontext are not highlighted. and Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-T¨ur, 2011; Ma and Nakagawa, 2013; Li and Li, 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models </context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>James Clarke and Mirella Lapata. 2008. Global inference for sentence compression an integer linear programming approach. J. Artif. Int. Res., 31(1):399–429, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arman Cohan</author>
<author>Luca Soldaini</author>
<author>Nazli Goharian</author>
</authors>
<title>Towards citation-based summarization of biomedical literature.</title>
<date>2014</date>
<booktitle>Proceedings of the Text Analysis Conference (TAC ’14).</booktitle>
<contexts>
<context position="28769" citStr="Cohan et al., 2014" startWordPosition="4387" endWordPosition="4390">course approach shows encouraging results, we attribute its limitation in achieving higher ROUGE scores to the classification errors that we observed in intrinsic classification evaluation. In evaluating the performance of several classifiers, linear SVM achieved the highest performance with accuracy of 0.788 in comparison with human annotation performance. Many of the citations cannot exactly belong to only one of the discourse facets of the paper and thus some errors in classification are inevitable. This is also observable in disagreements between the annotators in labeling as reported by (Cohan et al., 2014). This fact influences the diversification and finally the summarization quality. Among baseline summarization approaches, LexRank performs relatively well. Its performance is the best for short summaries among other baselines. This is expected since LexRank tries to find the most central sentences. When the length of the summary is short, the main idea in the summary is usually captured by finding the most representative sentence which LexRank can effectively achieve. However, the sentences that it chooses are usually about the same topic. Hence, the diversity in the gold summaries is not con</context>
</contexts>
<marker>Cohan, Soldaini, Goharian, 2014</marker>
<rawString>Arman Cohan, Luca Soldaini, and Nazli Goharian. 2014. Towards citation-based summarization of biomedical literature. Proceedings of the Text Analysis Conference (TAC ’14).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arman Cohan</author>
<author>Luca Soldaini</author>
<author>Nazli Goharian</author>
</authors>
<title>Matching citation text and cited spans in biomedical literature: a search-oriented approach.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 NAACL-HLT,</booktitle>
<pages>1042--1048</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10110" citStr="Cohan et al., 2015" startWordPosition="1489" endWordPosition="1492">ocuments (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis. (Cohan et al., 2015) use a search oriented approach for finding relevant parts of the reference paper to citations. (Qazvinian and Radev, 2008; Qazvinian et al., 2013) use citations to an article to construct its summary. More specifically, they perform hierarchical agglomerative clustering on citations to maximize purity and select most central sentences from each cluster for the final summary. Our work is closest to (Qazvinian and Radev, 2008) with the difference that they only make use of citations. While citations are useful for summarization, relying solely on them might not accurately capture the original c</context>
</contexts>
<marker>Cohan, Soldaini, Goharian, 2015</marker>
<rawString>Arman Cohan, Luca Soldaini, and Nazli Goharian. 2015. Matching citation text and cited spans in biomedical literature: a search-oriented approach. In Proceedings of the 2015 NAACL-HLT, pages 1042–1048. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Conroy</author>
<author>Judith D Schlesinger</author>
<author>Jeff Kubina</author>
<author>Peter A Rankel</author>
<author>Dianne P OLeary</author>
</authors>
<title>Classy</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference.</booktitle>
<contexts>
<context position="8310" citStr="Conroy et al., 2011" startWordPosition="1209" endWordPosition="1212">oaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these technique</context>
</contexts>
<marker>Conroy, Schlesinger, Kubina, Rankel, OLeary, 2011</marker>
<rawString>John M Conroy, Judith D Schlesinger, Jeff Kubina, Peter A Rankel, and Dianne P OLeary. 2011. Classy 2011 at tac: Guided and multi-lingual summaries and evaluation metrics. In Proceedings of the Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anita De Waard</author>
<author>Henk Pander Maat</author>
</authors>
<title>Epistemic modality and knowledge attribution in scientific discourse: A taxonomy of types and overview of features.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Detecting Structure in Scholarly Discourse,</booktitle>
<pages>47--55</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>De Waard, Maat, 2012</marker>
<rawString>Anita De Waard and Henk Pander Maat. 2012. Epistemic modality and knowledge attribution in scientific discourse: A taxonomy of types and overview of features. In Proceedings of the Workshop on Detecting Structure in Scholarly Discourse, pages 47–55. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron Elkiss</author>
<author>Siwei Shen</author>
<author>Anthony Fader</author>
<author>G¨unes¸ Erkan</author>
<author>David States</author>
<author>Dragomir Radev</author>
</authors>
<title>Blind men and elephants: What do citation summaries tell us about a research article?</title>
<date>2008</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>59</volume>
<issue>1</issue>
<contexts>
<context position="2886" citStr="Elkiss et al., 2008" startWordPosition="400" endWordPosition="403">experiments, findings and finally results and implications. Scientific summarization was recently further motivated by TAC2014 biomedical summarization track1 in which they planned to investigate this problem in the domain of biomedical science. There are currently two types of approaches towards scientific summarization. First is the articles’ abstracts. While abstracts provide a general overview of the paper, they cannot be considered as an accurate scientific summary by themselves. That is due to the fact that not all the contributions and impacts of the paper are included in the abstract (Elkiss et al., 2008). In addition, the stated contributions are those that the authors deem important while they might be less important to the scientific community. Moreover, contributions are stated in a general and less focused fashion. These problems motivated the other form of scientific summaries, i.e., citation based summaries. Citation based summary is a summary which is formed by utilizing a set of citations to a referenced article (Qazvinian and Radev, 2008; Qazvinian et al., 2013). This set of citations has been previously indicated as a good representation of important findings and contributions of th</context>
<context position="10028" citStr="Elkiss et al., 2008" startWordPosition="1476" endWordPosition="1479">Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis. (Cohan et al., 2015) use a search oriented approach for finding relevant parts of the reference paper to citations. (Qazvinian and Radev, 2008; Qazvinian et al., 2013) use citations to an article to construct its summary. More specifically, they perform hierarchical agglomerative clustering on citations to maximize purity and select most central sentences from each cluster for the final summary. Our work is closest to (Qazvinian and Radev, 2008) with the difference that they only make use of citations. While citations are useful for</context>
</contexts>
<marker>Elkiss, Shen, Fader, Erkan, States, Radev, 2008</marker>
<rawString>Aaron Elkiss, Siwei Shen, Anthony Fader, G¨unes¸ Erkan, David States, and Dragomir Radev. 2008. Blind men and elephants: What do citation summaries tell us about a research article? Journal of the American Society for Information Science and Technology, 59(1):51–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>Lexrank: Graph-based lexical centrality as salience in text summarization.</title>
<date>2004</date>
<journal>J. Artif. Intell. Res.(JAIR),</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="8951" citStr="Erkan and Radev, 2004" startWordPosition="1309" endWordPosition="1312">; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida </context>
<context position="17942" citStr="Erkan and Radev, 2004" startWordPosition="2701" endWordPosition="2704">We use unigram and verb features with tfidf weighting to train the classifier. 3.3 Ranking model To identify the most representative sentences of each group, we require a measure of importance of sentences. We consider the sentences in a group as a graph and rank nodes based on their importance. An important node is a node that has many connections with other nodes. There are various ways of measuring centrality of nodes such as nodes degree, betweenness, closeness and eigenvectors. Here, we opt for eigenvectors and we find the most central sentences in each group by using the “power method” (Erkan and Radev, 2004) which iteratively updates the eigenvector until convergence. 1 � Q = 2m vw 393 3.4 Selecting the sentences for final summary After scoring and ranking the sentences in each group which were identified either by discourse model or by community detection algorithm, we employ two strategies for generating the summary within the summary length threshold. • Iterative: We select top sentences iteratively from each group until we reach the summary length threshold. That is, we first pick the top sentence from all groups and if the threshold is not met, we select the second sentence and so forth. In </context>
<context position="21412" citStr="Erkan and Radev, 2004" startWordPosition="3255" endWordPosition="3258">t approach uses the citations to the article for generating the summary. • LSA (Steinberger and Jezek, 2004) - The LSA summarization method is based on singular value decomposition. In this method, a term document index A is created in which the values correspond to the tf-idf values of terms in the document. Then, Singular Value Decomposition, a dimension reduction approach, is applied to A. This will yield a singular value matrix E and a singular vector matrix VT. The top singular vectors are selected from VT iteratively until length of the summary reaches a predefined threshold. • LexRank (Erkan and Radev, 2004) - LexRank uses a measure called centrality to find the most representative sentences in given sets of sentences. It finds the most central sentences by updating the score of each sentence using an algorithm based on PageRank random walk ranking model (Page et al., 1999). More specifically, the centrality score of each sentence is represented by a centrality matrix p which is updated iteratively through the following equation using a method called “power method”: p = ATp Where matrix A is based on the similarity matrix B of the sentences: A = [dU + (1 − d)B] 394 In which U is a square matrix w</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes Erkan and Dragomir R Radev. 2004. Lexrank: Graph-based lexical centrality as salience in text summarization. J. Artif. Intell. Res.(JAIR), 22(1):457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
</authors>
<title>A skip-chain conditional random field for ranking meeting utterances by importance.</title>
<date>2006</date>
<booktitle>In EMNLP,</booktitle>
<pages>364--372</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8329" citStr="Galley, 2006" startWordPosition="1214" endWordPosition="1215">istribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (</context>
</contexts>
<marker>Galley, 2006</marker>
<rawString>Michel Galley. 2006. A skip-chain conditional random field for ranking meeting utterances by importance. In EMNLP, pages 364–372. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yihong Gong</author>
<author>Xin Liu</author>
</authors>
<title>Generic text summarization using relevance measure and latent semantic analysis.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>pages</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5832" citStr="Gong and Liu, 2001" startWordPosition="834" endWordPosition="837">te and compare our methods against several well-known summarization methods. Evaluation results on the TAC2014 dataset show that our proposed methods can effectively improve over the well-known existing summarization approaches. That is, we obtained greater than 30% improvement over the highest performing baseline in terms of mean ROUGE scores. 2 Related work Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years. Latent Semantic Analysis (LSA) has been used in text summarization first by (Gong and Liu, 2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010). Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz Citing article: ... The general impression that has emerged is that transformation of human cells by Ras requires the inactivation of both the pRb and p53 pathways, typically achieved by introducing DNA tumor virus oncoproteins such as SV40 large tumor anti</context>
</contexts>
<marker>Gong, Liu, 2001</marker>
<rawString>Yihong Gong and Xin Liu. 2001. Generic text summarization using relevance measure and latent semantic analysis. In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 19–25. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shengbo Guo</author>
<author>Scott Sanner</author>
</authors>
<title>Probabilistic latent maximal marginal relevance.</title>
<date>2010</date>
<booktitle>In SIGIR,</booktitle>
<pages>833--834</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9207" citStr="Guo and Sanner, 2010" startWordPosition="1349" endWordPosition="1352">nnotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST f</context>
</contexts>
<marker>Guo, Sanner, 2010</marker>
<rawString>Shengbo Guo and Scott Sanner. 2010. Probabilistic latent maximal marginal relevance. In SIGIR, pages 833–834. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Exploring content models for multi-document summarization.</title>
<date>2009</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>362--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6161" citStr="Haghighi and Vanderwende, 2009" startWordPosition="882" endWordPosition="885"> terms of mean ROUGE scores. 2 Related work Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years. Latent Semantic Analysis (LSA) has been used in text summarization first by (Gong and Liu, 2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010). Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz Citing article: ... The general impression that has emerged is that transformation of human cells by Ras requires the inactivation of both the pRb and p53 pathways, typically achieved by introducing DNA tumor virus oncoproteins such as SV40 large tumor antigen (T-Ag) or human papillomavirus E6 and E7 proteins ( Serrano et al., 1997 ). To address this question, we have been investigating the ... Reference article (Serrano et al., 1997): ... continued to incorporate BrdU and proliferate following introduction of H-ras V12. In agreement with previous reports ( 66 and 60), both p53/ </context>
</contexts>
<marker>Haghighi, Vanderwende, 2009</marker>
<rawString>Aria Haghighi and Lucy Vanderwende. 2009. Exploring content models for multi-document summarization. In NAACL-HLT, pages 362–370. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsutomu Hirao</author>
<author>Yasuhisa Yoshida</author>
<author>Masaaki Nishino</author>
<author>Norihito Yasuda</author>
<author>Masaaki Nagata</author>
</authors>
<title>Single-document summarization as a tree knapsack problem.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>1515--1520</pages>
<contexts>
<context position="9519" citStr="Hirao et al., 2013" startWordPosition="1397" endWordPosition="1400">techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis. (Cohan et al., 2015) use a se</context>
</contexts>
<marker>Hirao, Yoshida, Nishino, Yasuda, Nagata, 2013</marker>
<rawString>Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino, Norihito Yasuda, and Masaaki Nagata. 2013. Single-document summarization as a tree knapsack problem. In EMNLP, pages 1515–1520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuta Kikuchi</author>
<author>Tsutomu Hirao</author>
<author>Hiroya Takamura</author>
<author>Manabu Okumura</author>
<author>Masaaki Nagata</author>
</authors>
<title>Single document summarization based on nested tree structure.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>315--320</pages>
<contexts>
<context position="9541" citStr="Kikuchi et al., 2014" startWordPosition="1401" endWordPosition="1404">exRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis. (Cohan et al., 2015) use a search oriented approach</context>
</contexts>
<marker>Kikuchi, Hirao, Takamura, Okumura, Nagata, 2014</marker>
<rawString>Yuta Kikuchi, Tsutomu Hirao, Hiroya Takamura, Manabu Okumura, and Masaaki Nagata. 2014. Single document summarization based on nested tree structure. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, volume 2, pages 315–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tibor Kiss</author>
<author>Jan Strunk</author>
</authors>
<title>Unsupervised multilingual sentence boundary detection.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>4</issue>
<contexts>
<context position="11871" citStr="Kiss and Strunk, 2006" startWordPosition="1756" endWordPosition="1759">ntences within each group and (4) Selecting the sentences for final summary. We assume that the citation text (the text span in the citing article that references another article) in each citing article is already known. We describe each step in the following sub-sections. Our proposed method generates a summary of an article with the premise that the article has a number of citations to it. We call the article that is being referenced the “reference article”. We shall note that we tokenized the articles’ text to sentences by using the punkt unsupervised sentence boundary detection algorithm (Kiss and Strunk, 2006). We modified the original sentence boundary detection algorithm to also account for biomedical abbreviations. For the rest of the paper, “sentence” refers to units that are output of the sentence boundary detection algorithm, whereas “text span” or in short “span” can consist of multiple sentences. 3.1 Extracting the citation-context As described in section 2, one problem with existing citation based summarization approaches is that they lack the context of the referenced paper. Therefore, our goal is to leverage citationcontext in the reference article to correctly reflect the reference pape</context>
</contexts>
<marker>Kiss, Strunk, 2006</marker>
<rawString>Tibor Kiss and Jan Strunk. 2006. Unsupervised multilingual sentence boundary detection. Computational Linguistics, 32(4):485–525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ju-Hong Lee</author>
<author>Sun Park</author>
<author>Chan-Min Ahn</author>
<author>Daeho Kim</author>
</authors>
<title>Automatic generic document summarization based on non-negative matrix factorization.</title>
<date>2009</date>
<journal>Information Processing &amp; Management,</journal>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="5988" citStr="Lee et al., 2009" startWordPosition="857" endWordPosition="860">tively improve over the well-known existing summarization approaches. That is, we obtained greater than 30% improvement over the highest performing baseline in terms of mean ROUGE scores. 2 Related work Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years. Latent Semantic Analysis (LSA) has been used in text summarization first by (Gong and Liu, 2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010). Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz Citing article: ... The general impression that has emerged is that transformation of human cells by Ras requires the inactivation of both the pRb and p53 pathways, typically achieved by introducing DNA tumor virus oncoproteins such as SV40 large tumor antigen (T-Ag) or human papillomavirus E6 and E7 proteins ( Serrano et al., 1997 ). To address this question, we have been investigating the ... Reference artic</context>
</contexts>
<marker>Lee, Park, Ahn, Kim, 2009</marker>
<rawString>Ju-Hong Lee, Sun Park, Chan-Min Ahn, and Daeho Kim. 2009. Automatic generic document summarization based on non-negative matrix factorization. Information Processing &amp; Management, 45(1):20 – 34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Sujian Li</author>
</authors>
<title>A novel feature-based bayesian model for query focused multi-document summarization.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--89</pages>
<contexts>
<context position="7675" citStr="Li and Li, 2014" startWordPosition="1118" endWordPosition="1121"> arrest in MEFs, and that inactivation of either p53 or p16 alone is sufficient to circumvent arrest. In REF52 and IMR90 fibroblasts, a different approach was ... Figure 1: The blue highlighted span in the citing article (top) shows the citation text, followed by the citation marker (pink span). For this citation, the citation-context is the green highlighted span in the reference article (bottom). The text spans outside the scope of the citation text and citationcontext are not highlighted. and Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-T¨ur, 2011; Ma and Nakagawa, 2013; Li and Li, 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborn</context>
</contexts>
<marker>Li, Li, 2014</marker>
<rawString>Jiwei Li and Sujian Li. 2014. A novel feature-based bayesian model for query focused multi-document summarization. Transactions of the Association for Computational Linguistics, 1:89–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jimmy Lin</author>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Putting the user in the loop: interactive maximal marginal relevance for query-focused summarization. In</title>
<date>2010</date>
<booktitle>NAACL-HLT,</booktitle>
<pages>305--308</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9226" citStr="Lin et al., 2010" startWordPosition="1353" endWordPosition="1356">in dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientifi</context>
</contexts>
<marker>Lin, Madnani, Dorr, 2010</marker>
<rawString>Jimmy Lin, Nitin Madnani, and Bonnie J Dorr. 2010. Putting the user in the loop: interactive maximal marginal relevance for query-focused summarization. In NAACL-HLT, pages 305–308. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>Rouge: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop,</booktitle>
<pages>74--81</pages>
<contexts>
<context position="23712" citStr="Lin, 2004" startWordPosition="3635" endWordPosition="3636">the final summary by selecting the top central sentences from each cluster in a round-robin fashion. Our approach is similar to this work in that they also use centrality scores on citation network clusters. Since they only focus on citations, comparison of our approach with this work gives a better insight into how beneficial our use of citation-context and article’s discourse model can be in generating scientific summaries. 5 Results and discussions 5.1 Evaluation metrics We use the ROUGE evaluation metrics which has shown consistent correlation with manually evaluated summarization scores (Lin, 2004). More specifically, we use ROUGE-L, ROUGE-1 and ROUGE-2 to evaluate and compare the quality of the summaries generated by our system. While ROUGE-N focuses on n-gram overlaps, ROUGE-L uses the longest common subsequence to measure the quality of the summary. ROUGE-N where N is the n-gram order, is defined as follows: P P fmatch(W ) ROUGE-N = SE{Gold summaries} WES P P SE{Gold summaries} WES Where W is the n-gram, f(.) is the count function, fmatch(.) is the maximum number of n-grams cooccurring in the generated summary and in a set of gold summaries. For a candidate summary C with n words and</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pages 74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Aravind Joshi</author>
<author>Ani Nenkova</author>
</authors>
<title>Discourse indicators for content selection in summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>147--156</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8439" citStr="Louis et al., 2010" startWordPosition="1231" endWordPosition="1234">ve viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing t</context>
</contexts>
<marker>Louis, Joshi, Nenkova, 2010</marker>
<rawString>Annie Louis, Aravind Joshi, and Ani Nenkova. 2010. Discourse indicators for content selection in summarization. In Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 147–156. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tengfei Ma</author>
<author>Hiroshi Nakagawa</author>
</authors>
<title>Automatically determining a proper length for multi-document summarization: A bayesian nonparametric approach.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>736--746</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7657" citStr="Ma and Nakagawa, 2013" startWordPosition="1114" endWordPosition="1117">sential for ras-induced arrest in MEFs, and that inactivation of either p53 or p16 alone is sufficient to circumvent arrest. In REF52 and IMR90 fibroblasts, a different approach was ... Figure 1: The blue highlighted span in the citing article (top) shows the citation text, followed by the citation marker (pink span). For this citation, the citation-context is the green highlighted span in the reference article (bottom). The text spans outside the scope of the citation text and citationcontext are not highlighted. and Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-T¨ur, 2011; Ma and Nakagawa, 2013; Li and Li, 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maxim</context>
</contexts>
<marker>Ma, Nakagawa, 2013</marker>
<rawString>Tengfei Ma and Hiroshi Nakagawa. 2013. Automatically determining a proper length for multi-document summarization: A bayesian nonparametric approach. In EMNLP, pages 736– 746. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="9446" citStr="Mann and Thompson, 1988" startWordPosition="1384" endWordPosition="1387"> sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefit</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C Mann and Sandra A Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>Textrank: Bringing order into texts. Association for Computational Linguistics.</title>
<date>2004</date>
<contexts>
<context position="8988" citStr="Mihalcea and Tarau, 2004" startWordPosition="1314" endWordPosition="1317">an, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. Textrank: Bringing order into texts. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark EJ Newman</author>
</authors>
<title>Modularity and community structure in networks.</title>
<date>2006</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<pages>103--23</pages>
<contexts>
<context position="15081" citStr="Newman, 2006" startWordPosition="2262" endWordPosition="2263">are about the same topic. We use the following two approaches for forming these groups: Community detection - We want to find diverse key aspects of the reference article. We form the graph of extracted reference spans in which nodes are sentences and edges are similarity between sentences. As for the similarity function, we use cosine similarity between tf-idf vectors of the sentences. Similar to (Qazvinian and Radev, 2008), we want to find subgraphs or communities whose intra-connectivity is high but inter-connectivity is low. Such quality is captured by the modularity measure of the graph (Newman, 2006; Newman, 2012). Graph modularity quantifies the denseness of the subgraphs in comparison with denseness of the graph of randomly distributed edges and is defined as follows: [Avw − kv ×kw Jδ(cv, cw) 2m Where Avw is the weigh of the edge (v, w); kv is the degree of the vertex v; cv is the community of vertex v; δ is the Kronecker’s delta function and m = Evw Avw is the normalization factor. While the general problem of precise partitioning of the graph into highly dense communities 1http://metamap.nlm.nih.gov/ 2Unified Medical Language System - a compendium of controlled vocabularies in the bi</context>
</contexts>
<marker>Newman, 2006</marker>
<rawString>Mark EJ Newman. 2006. Modularity and community structure in networks. Proceedings of the National Academy of Sciences, 103(23):8577–8582.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MEJ Newman</author>
</authors>
<title>Communities, modules and large-scale structure in networks.</title>
<date>2012</date>
<journal>Nature Physics,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="15096" citStr="Newman, 2012" startWordPosition="2264" endWordPosition="2265">same topic. We use the following two approaches for forming these groups: Community detection - We want to find diverse key aspects of the reference article. We form the graph of extracted reference spans in which nodes are sentences and edges are similarity between sentences. As for the similarity function, we use cosine similarity between tf-idf vectors of the sentences. Similar to (Qazvinian and Radev, 2008), we want to find subgraphs or communities whose intra-connectivity is high but inter-connectivity is low. Such quality is captured by the modularity measure of the graph (Newman, 2006; Newman, 2012). Graph modularity quantifies the denseness of the subgraphs in comparison with denseness of the graph of randomly distributed edges and is defined as follows: [Avw − kv ×kw Jδ(cv, cw) 2m Where Avw is the weigh of the edge (v, w); kv is the degree of the vertex v; cv is the community of vertex v; δ is the Kronecker’s delta function and m = Evw Avw is the normalization factor. While the general problem of precise partitioning of the graph into highly dense communities 1http://metamap.nlm.nih.gov/ 2Unified Medical Language System - a compendium of controlled vocabularies in the biomedical scienc</context>
</contexts>
<marker>Newman, 2012</marker>
<rawString>MEJ Newman. 2012. Communities, modules and large-scale structure in networks. Nature Physics, 8(1):25–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miles Osborne</author>
</authors>
<title>Using maximum entropy for sentence extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Automatic SummarizationVolume 4,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8283" citStr="Osborne, 2002" startWordPosition="1206" endWordPosition="1207"> 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. </context>
</contexts>
<marker>Osborne, 2002</marker>
<rawString>Miles Osborne. 2002. Using maximum entropy for sentence extraction. In Proceedings of the ACL-02 Workshop on Automatic SummarizationVolume 4, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makbule Gulcin Ozsoy</author>
</authors>
<title>Ilyas Cicekli, and Ferda Nur Alpaslan.</title>
<date>2010</date>
<booktitle>In COLING,</booktitle>
<pages>869--876</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Ozsoy, 2010</marker>
<rawString>Makbule Gulcin Ozsoy, Ilyas Cicekli, and Ferda Nur Alpaslan. 2010. Text summarization of turkish texts using latent semantic analysis. In COLING, pages 869–876. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<contexts>
<context position="21683" citStr="Page et al., 1999" startWordPosition="3300" endWordPosition="3303">df values of terms in the document. Then, Singular Value Decomposition, a dimension reduction approach, is applied to A. This will yield a singular value matrix E and a singular vector matrix VT. The top singular vectors are selected from VT iteratively until length of the summary reaches a predefined threshold. • LexRank (Erkan and Radev, 2004) - LexRank uses a measure called centrality to find the most representative sentences in given sets of sentences. It finds the most central sentences by updating the score of each sentence using an algorithm based on PageRank random walk ranking model (Page et al., 1999). More specifically, the centrality score of each sentence is represented by a centrality matrix p which is updated iteratively through the following equation using a method called “power method”: p = ATp Where matrix A is based on the similarity matrix B of the sentences: A = [dU + (1 − d)B] 394 In which U is a square matrix with values 1/N and d is a parameter called the damping factor. We set d to 0.1 which is the default suggested value. • MMR (Carbonell and Goldstein, 1998) - In Maximal Marginal Relevance (MMR), sentences are greedily ranked according to a score based on their relevance t</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Paul</author>
<author>ChengXiang Zhai</author>
<author>Roxana Girju</author>
</authors>
<title>Summarizing contrastive viewpoints in opinionated text.</title>
<date>2010</date>
<booktitle>In EMNLP,</booktitle>
<pages>66--76</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9025" citStr="Paul et al., 2010" startWordPosition="1322" endWordPosition="1325"> regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suite</context>
</contexts>
<marker>Paul, Zhai, Girju, 2010</marker>
<rawString>Michael Paul, ChengXiang Zhai, and Roxana Girju. 2010. Summarizing contrastive viewpoints in opinionated text. In EMNLP, pages 66–76. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vahed Qazvinian</author>
<author>Dragomir R Radev</author>
</authors>
<title>Scientific paper summarization using citation summary networks.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1,</booktitle>
<pages>689--696</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3337" citStr="Qazvinian and Radev, 2008" startWordPosition="469" endWordPosition="472"> accurate scientific summary by themselves. That is due to the fact that not all the contributions and impacts of the paper are included in the abstract (Elkiss et al., 2008). In addition, the stated contributions are those that the authors deem important while they might be less important to the scientific community. Moreover, contributions are stated in a general and less focused fashion. These problems motivated the other form of scientific summaries, i.e., citation based summaries. Citation based summary is a summary which is formed by utilizing a set of citations to a referenced article (Qazvinian and Radev, 2008; Qazvinian et al., 2013). This set of citations has been previously indicated as a good representation of important findings and contributions of the article. Contributions stated in the citations are usually more focused than the abstract and contain additional information that is not in the abstract (Elkiss et al., 2008). However, citations may not accurately represent 1Text Analysis Conference - http://www.nist.gov/tac/ 2014 390 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 390–400, Lisbon, Portugal, 17-21 September 2015. c�2015 Association f</context>
<context position="10232" citStr="Qazvinian and Radev, 2008" startWordPosition="1508" endWordPosition="1511">re is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis. (Cohan et al., 2015) use a search oriented approach for finding relevant parts of the reference paper to citations. (Qazvinian and Radev, 2008; Qazvinian et al., 2013) use citations to an article to construct its summary. More specifically, they perform hierarchical agglomerative clustering on citations to maximize purity and select most central sentences from each cluster for the final summary. Our work is closest to (Qazvinian and Radev, 2008) with the difference that they only make use of citations. While citations are useful for summarization, relying solely on them might not accurately capture the original context of the referenced paper. That is, the generated summary lacks the appropriate evidence to reflect the content of th</context>
<context position="14897" citStr="Qazvinian and Radev, 2008" startWordPosition="2232" endWordPosition="2235">on-contexts After identifying the context for each citation, we use them to form the summary. To capture various important aspects of the reference article, we form groups of citation-contexts that are about the same topic. We use the following two approaches for forming these groups: Community detection - We want to find diverse key aspects of the reference article. We form the graph of extracted reference spans in which nodes are sentences and edges are similarity between sentences. As for the similarity function, we use cosine similarity between tf-idf vectors of the sentences. Similar to (Qazvinian and Radev, 2008), we want to find subgraphs or communities whose intra-connectivity is high but inter-connectivity is low. Such quality is captured by the modularity measure of the graph (Newman, 2006; Newman, 2012). Graph modularity quantifies the denseness of the subgraphs in comparison with denseness of the graph of randomly distributed edges and is defined as follows: [Avw − kv ×kw Jδ(cv, cw) 2m Where Avw is the weigh of the edge (v, w); kv is the degree of the vertex v; cv is the community of vertex v; δ is the Kronecker’s delta function and m = Evw Avw is the normalization factor. While the general prob</context>
<context position="22914" citStr="Qazvinian and Radev, 2008" startWordPosition="3510" endWordPosition="3513"> document and the amount of redundant information they carry. It scores sentences based on the maximization of the linear interpolation of the relevance to the document and diversity: MMR(S,D) def =ASim1(S, D) − (1 − A)Sim2(S,Summary) Where S is the sentence being evaluated, D is the document being summarized, Sim1 and Sim2 are similarity function, Summary is the summary formed by the previously selected sentences and A is a parameter. We used cosine similarity as similarity functions and we set A to 0.3, 0.5 and 0.7 for observing the effect of informativeness vs. novelty. • Citation summary (Qazvinian and Radev, 2008)- In this approach, a network of citations is built and citations are clustered to maximum purity (Zhao and Karypis, 2001) and mutual information. These clusters are then used to generate the final summary by selecting the top central sentences from each cluster in a round-robin fashion. Our approach is similar to this work in that they also use centrality scores on citation network clusters. Since they only focus on citations, comparison of our approach with this work gives a better insight into how beneficial our use of citation-context and article’s discourse model can be in generating scie</context>
</contexts>
<marker>Qazvinian, Radev, 2008</marker>
<rawString>Vahed Qazvinian and Dragomir R Radev. 2008. Scientific paper summarization using citation summary networks. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pages 689–696. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Vahed Qazvinian</author>
<author>Dragomir R Radev</author>
<author>Saif Mohammad</author>
<author>Bonnie J Dorr</author>
<author>David M Zajic</author>
</authors>
<marker>Qazvinian, Radev, Mohammad, Dorr, Zajic, </marker>
<rawString>Vahed Qazvinian, Dragomir R Radev, Saif Mohammad, Bonnie J Dorr, David M Zajic,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Whidby</author>
<author>Taesun Moon</author>
</authors>
<title>Generating extractive summaries of scientific paradigms.</title>
<date>2013</date>
<journal>J. Artif. Intell. Res.(JAIR),</journal>
<pages>46--165</pages>
<marker>Whidby, Moon, 2013</marker>
<rawString>Michael Whidby, and Taesun Moon. 2013. Generating extractive summaries of scientific paradigms. J. Artif. Intell. Res.(JAIR), 46:165–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cody Rioux</author>
<author>A Sadid Hasan</author>
<author>Yllias Chali</author>
</authors>
<title>Fear the reaper: A system for automatic multi-document summarization with reinforcement learning.</title>
<date>2014</date>
<booktitle>In EMNLP,</booktitle>
<pages>681--690</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8487" citStr="Rioux et al., 2014" startWordPosition="1238" endWordPosition="1241">solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in </context>
</contexts>
<marker>Rioux, Hasan, Chali, 2014</marker>
<rawString>Cody Rioux, A. Sadid Hasan, and Yllias Chali. 2014. Fear the reaper: A system for automatic multi-document summarization with reinforcement learning. In EMNLP, pages 681–690. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Colin Cherry</author>
<author>Bill Dolan</author>
</authors>
<title>Unsupervised modeling of twitter conversations.</title>
<date>2010</date>
<booktitle>In NAACL-HLT, HLT ’10,</booktitle>
<pages>172--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7598" citStr="Ritter et al., 2010" startWordPosition="1106" endWordPosition="1109">ot shown). These results indicate that p53 and p16 are essential for ras-induced arrest in MEFs, and that inactivation of either p53 or p16 alone is sufficient to circumvent arrest. In REF52 and IMR90 fibroblasts, a different approach was ... Figure 1: The blue highlighted span in the citing article (top) shows the citation text, followed by the citation marker (pink span). For this citation, the citation-context is the green highlighted span in the reference article (bottom). The text spans outside the scope of the citation text and citationcontext are not highlighted. and Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-T¨ur, 2011; Ma and Nakagawa, 2013; Li and Li, 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised model</context>
</contexts>
<marker>Ritter, Cherry, Dolan, 2010</marker>
<rawString>Alan Ritter, Colin Cherry, and Bill Dolan. 2010. Unsupervised modeling of twitter conversations. In NAACL-HLT, HLT ’10, pages 172–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dou Shen</author>
<author>Jian-Tao Sun</author>
<author>Hua Li</author>
<author>Qiang Yang</author>
<author>Zheng Chen</author>
</authors>
<title>Document summarization using conditional random fields.</title>
<date>2007</date>
<booktitle>In IJCAI,</booktitle>
<volume>7</volume>
<pages>2862--2867</pages>
<contexts>
<context position="8348" citStr="Shen et al., 2007" startWordPosition="1216" endWordPosition="1219"> the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 20</context>
</contexts>
<marker>Shen, Sun, Li, Yang, Chen, 2007</marker>
<rawString>Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, and Zheng Chen. 2007. Document summarization using conditional random fields. In IJCAI, volume 7, pages 2862–2867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Steinberger</author>
<author>Karel Jezek</author>
</authors>
<title>Using latent semantic analysis in text summarization and summary evaluation.</title>
<date>2004</date>
<booktitle>In Proc. ISIM04,</booktitle>
<pages>93--100</pages>
<contexts>
<context position="5944" citStr="Steinberger and Jezek, 2004" startWordPosition="849" endWordPosition="852">AC2014 dataset show that our proposed methods can effectively improve over the well-known existing summarization approaches. That is, we obtained greater than 30% improvement over the highest performing baseline in terms of mean ROUGE scores. 2 Related work Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years. Latent Semantic Analysis (LSA) has been used in text summarization first by (Gong and Liu, 2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010). Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz Citing article: ... The general impression that has emerged is that transformation of human cells by Ras requires the inactivation of both the pRb and p53 pathways, typically achieved by introducing DNA tumor virus oncoproteins such as SV40 large tumor antigen (T-Ag) or human papillomavirus E6 and E7 proteins ( Serrano et al., 1997 ). To address this question, we hav</context>
<context position="20898" citStr="Steinberger and Jezek, 2004" startWordPosition="3170" endWordPosition="3173">nce article in 1.57 1.17 each citing article Length of summaries (words) 235.64 31.24 Length of articles (words) 9759.86 2199.48 Table 2: Distribution of annotated discourse facets Discourse facet count Hypothesis 21 Method 155 Results 490 Implication 140 Discussion 446 4.2 Baselines We compared existing well-known and widelyused approaches discussed in section 2 with our approach and evaluated their effectiveness for scientific summarization. The first three approaches use the scientific article’s text and the last approach uses the citations to the article for generating the summary. • LSA (Steinberger and Jezek, 2004) - The LSA summarization method is based on singular value decomposition. In this method, a term document index A is created in which the values correspond to the tf-idf values of terms in the document. Then, Singular Value Decomposition, a dimension reduction approach, is applied to A. This will yield a singular value matrix E and a singular vector matrix VT. The top singular vectors are selected from VT iteratively until length of the summary reaches a predefined threshold. • LexRank (Erkan and Radev, 2004) - LexRank uses a measure called centrality to find the most representative sentences </context>
</contexts>
<marker>Steinberger, Jezek, 2004</marker>
<rawString>Josef Steinberger and Karel Jezek. 2004. Using latent semantic analysis in text summarization and summary evaluation. In Proc. ISIM04, pages 93– 100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Steinberger</author>
<author>Mijail A Kabadjov</author>
<author>Massimo Poesio</author>
<author>Olivia Sanchez-Graillet</author>
</authors>
<title>Improving lsa-based summarization with anaphora resolution.</title>
<date>2005</date>
<booktitle>In EMNLP-HLT,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5970" citStr="Steinberger et al., 2005" startWordPosition="853" endWordPosition="856">proposed methods can effectively improve over the well-known existing summarization approaches. That is, we obtained greater than 30% improvement over the highest performing baseline in terms of mean ROUGE scores. 2 Related work Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years. Latent Semantic Analysis (LSA) has been used in text summarization first by (Gong and Liu, 2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010). Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz Citing article: ... The general impression that has emerged is that transformation of human cells by Ras requires the inactivation of both the pRb and p53 pathways, typically achieved by introducing DNA tumor virus oncoproteins such as SV40 large tumor antigen (T-Ag) or human papillomavirus E6 and E7 proteins ( Serrano et al., 1997 ). To address this question, we have been investigating the .</context>
</contexts>
<marker>Steinberger, Kabadjov, Poesio, Sanchez-Graillet, 2005</marker>
<rawString>Josef Steinberger, Mijail A Kabadjov, Massimo Poesio, and Olivia Sanchez-Graillet. 2005. Improving lsa-based summarization with anaphora resolution. In EMNLP-HLT, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Teufel</author>
<author>Marc Moens</author>
</authors>
<title>Summarizing scientific articles: Experiments with relevance and rhetorical status.</title>
<date>2002</date>
<journal>Comput. Linguist.,</journal>
<volume>28</volume>
<issue>4</issue>
<contexts>
<context position="1762" citStr="Teufel and Moens, 2002" startWordPosition="232" endWordPosition="235">the dataset we use for evaluation is in the biomedical domain, most of our approaches are general and therefore adaptable to other domains. 1 Introduction Due to the expanding rate at which articles are being published in each scientific field, it has become difficult for researchers to keep up with the developments in their respective fields. Scientific summarization aims to facilitate this problem by providing readers with concise and informative representation of contributions or findings of an article. Scientific summarization is different than general summarization in three main aspects (Teufel and Moens, 2002). First, the length of scientific papers are usually much longer than general articles (e.g newswire). Second, in scientific summarization, the goal is typically to provide a technical summary of the paper which includes important findings, contributions or impacts of a paper to the community. Finally, scientific papers follow a natural discourse. A common organization for scientific paper is the one in which the problem is first introduced and is followed by the description of hypotheses, methods, experiments, findings and finally results and implications. Scientific summarization was recentl</context>
<context position="9895" citStr="Teufel and Moens, 2002" startWordPosition="1455" endWordPosition="1458">lso been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis. (Cohan et al., 2015) use a search oriented approach for finding relevant parts of the reference paper to citations. (Qazvinian and Radev, 2008; Qazvinian et al., 2013) use citations to an article to construct its summary. More specifically, they perform hierarchical agglomerative clustering on citations to maximize purity and select most central sentences from each cluster for the final summary. Our wo</context>
</contexts>
<marker>Teufel, Moens, 2002</marker>
<rawString>Simone Teufel and Marc Moens. 2002. Summarizing scientific articles: Experiments with relevance and rhetorical status. Comput. Linguist., 28(4):409–445, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucy Vanderwende</author>
<author>Hisami Suzuki</author>
<author>Chris Brockett</author>
<author>Ani Nenkova</author>
</authors>
<title>Beyond sumbasic: Taskfocused summarization with sentence simplification and lexical expansion.</title>
<date>2007</date>
<journal>Information Processing &amp; Management,</journal>
<volume>43</volume>
<issue>6</issue>
<contexts>
<context position="6129" citStr="Vanderwende et al., 2007" startWordPosition="878" endWordPosition="881">est performing baseline in terms of mean ROUGE scores. 2 Related work Document summarization is a relatively well studied area and various types of approaches for document summarization have been proposed in the past twenty years. Latent Semantic Analysis (LSA) has been used in text summarization first by (Gong and Liu, 2001). Other variations of LSA based summarization approaches have later been introduced (Steinberger and Jezek, 2004; Steinberger et al., 2005; Lee et al., 2009; Ozsoy et al., 2010). Summarization approaches based on topic modeling and Bayesian models have also been explored (Vanderwende et al., 2007; Haghighi and Vanderwende, 2009; Celikyilmaz Citing article: ... The general impression that has emerged is that transformation of human cells by Ras requires the inactivation of both the pRb and p53 pathways, typically achieved by introducing DNA tumor virus oncoproteins such as SV40 large tumor antigen (T-Ag) or human papillomavirus E6 and E7 proteins ( Serrano et al., 1997 ). To address this question, we have been investigating the ... Reference article (Serrano et al., 1997): ... continued to incorporate BrdU and proliferate following introduction of H-ras V12. In agreement with previous </context>
</contexts>
<marker>Vanderwende, Suzuki, Brockett, Nenkova, 2007</marker>
<rawString>Lucy Vanderwende, Hisami Suzuki, Chris Brockett, and Ani Nenkova. 2007. Beyond sumbasic: Taskfocused summarization with sentence simplification and lexical expansion. Information Processing &amp; Management, 43(6):1606–1618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristian Woodsend</author>
<author>Mirella Lapata</author>
</authors>
<title>Multiple aspect summarization using integer linear programming.</title>
<date>2012</date>
<booktitle>In EMNLP,</booktitle>
<pages>233--243</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7980" citStr="Woodsend and Lapata, 2012" startWordPosition="1160" endWordPosition="1163">. For this citation, the citation-context is the green highlighted span in the reference article (bottom). The text spans outside the scope of the citation text and citationcontext are not highlighted. and Hakkani-Tur, 2010; Ritter et al., 2010; Celikyilmaz and Hakkani-T¨ur, 2011; Ma and Nakagawa, 2013; Li and Li, 2014). In these approaches, the content/topic distribution in the final summary is estimated using a graphical probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amou</context>
</contexts>
<marker>Woodsend, Lapata, 2012</marker>
<rawString>Kristian Woodsend and Mirella Lapata. 2012. Multiple aspect summarization using integer linear programming. In EMNLP, pages 233–243. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shasha Xie</author>
<author>Yang Liu</author>
</authors>
<title>Improving supervised learning for meeting summarization using sampling and regression.</title>
<date>2010</date>
<journal>Computer Speech &amp; Language,</journal>
<booktitle>514. Emergent Artificial Intelligence Approaches for Pattern Recognition in Speech and Language Processing.</booktitle>
<volume>24</volume>
<issue>3</issue>
<contexts>
<context position="8397" citStr="Xie and Liu, 2010" startWordPosition="1225" endWordPosition="1228">l probabilistic model. Some approaches have viewed summarization as an optimization task solved by linear programming (Clarke and Lapata, 2008; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012). Many works have viewed the summarization problem as a supervised classification problem in which several features are used to predict the inclusion of document sentences in the summary. Variations of supervised models have been utilized for summary generation, such as: maximum entropy (Osborne, 2002), HMM (Conroy et al., 2011), CRF (Galley, 2006; Shen et al., 2007; Chali and Hasan, 2012), SVM (Xie and Liu, 2010), logistic regression (Louis et al., 2010) and reinforcement learning (Rioux et al., 2014). Problems with supervised models in context of summarization include the need for large amount of annotated data and domain dependency. Graph based models have shown promising results for text summarization. In these approaches, the goal is to find the most central sentences in the document by constructing a graph in which nodes are sentences and edges are similarity between these sentences. Examples of these techniques include LexRank (Erkan and Radev, 2004), TextRank (Mihalcea and Tarau, 2004), and the</context>
</contexts>
<marker>Xie, Liu, 2010</marker>
<rawString>Shasha Xie and Yang Liu. 2010. Improving supervised learning for meeting summarization using sampling and regression. Computer Speech &amp; Language, 24(3):495 – 514. Emergent Artificial Intelligence Approaches for Pattern Recognition in Speech and Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhisa Yoshida</author>
<author>Jun Suzuki</author>
<author>Tsutomu Hirao</author>
<author>Masaaki Nagata</author>
</authors>
<title>Dependencybased discourse parser for single-document summarization.</title>
<date>2014</date>
<booktitle>In EMNLP,</booktitle>
<pages>1834--1839</pages>
<location>Doha, Qatar,</location>
<contexts>
<context position="9564" citStr="Yoshida et al., 2014" startWordPosition="1405" endWordPosition="1408">v, 2004), TextRank (Mihalcea and Tarau, 2004), and the work by (Paul et al., 2010). Maximizing the novelty and preventing 391 the redundancy in a summary is addressed by greedy selection of content summarization (Carbonell and Goldstein, 1998; Guo and Sanner, 2010; Lin et al., 2010). Rhetorical structure of the documents have also been investigated for automatic summarization. In this line of work, dependency and discourse parsing based on Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is used for analyzing the structure of the documents (Hirao et al., 2013; Kikuchi et al., 2014; Yoshida et al., 2014). Summarization based on rhetorical structure is better suited for shorter documents and is highly dependent on the quality of the discourse parser that is used. Training the discourse parser requires large amount of training data in the RST framework. Scientific article summarization was first studied by (Teufel and Moens, 2002) in which they trained a supervised Naive Bayes classifier to select informative content for the summary. Later (Elkiss et al., 2008) argue the benefits of citations to scientific work analysis. (Cohan et al., 2015) use a search oriented approach for finding relevant p</context>
</contexts>
<marker>Yoshida, Suzuki, Hirao, Nagata, 2014</marker>
<rawString>Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and Masaaki Nagata. 2014. Dependencybased discourse parser for single-document summarization. In EMNLP, pages 1834– 1839, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhao</author>
<author>George Karypis</author>
</authors>
<title>Criterion functions for document clustering: Experiments and analysis.</title>
<date>2001</date>
<tech>Technical report, Citeseer.</tech>
<contexts>
<context position="23036" citStr="Zhao and Karypis, 2001" startWordPosition="3530" endWordPosition="3533">erpolation of the relevance to the document and diversity: MMR(S,D) def =ASim1(S, D) − (1 − A)Sim2(S,Summary) Where S is the sentence being evaluated, D is the document being summarized, Sim1 and Sim2 are similarity function, Summary is the summary formed by the previously selected sentences and A is a parameter. We used cosine similarity as similarity functions and we set A to 0.3, 0.5 and 0.7 for observing the effect of informativeness vs. novelty. • Citation summary (Qazvinian and Radev, 2008)- In this approach, a network of citations is built and citations are clustered to maximum purity (Zhao and Karypis, 2001) and mutual information. These clusters are then used to generate the final summary by selecting the top central sentences from each cluster in a round-robin fashion. Our approach is similar to this work in that they also use centrality scores on citation network clusters. Since they only focus on citations, comparison of our approach with this work gives a better insight into how beneficial our use of citation-context and article’s discourse model can be in generating scientific summaries. 5 Results and discussions 5.1 Evaluation metrics We use the ROUGE evaluation metrics which has shown con</context>
</contexts>
<marker>Zhao, Karypis, 2001</marker>
<rawString>Ying Zhao and George Karypis. 2001. Criterion functions for document clustering: Experiments and analysis. Technical report, Citeseer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>