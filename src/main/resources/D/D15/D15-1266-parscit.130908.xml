<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000494">
<title confidence="0.995527">
Shallow Convolutional Neural Network
for Implicit Discourse Relation Recognition
</title>
<author confidence="0.987914">
Biao Zhang&apos;, Jinsong Su&apos;∗, Deyi Xiong2, Yaojie Lu&apos;, Hong Duan&apos; and Junfeng Yao&apos;
</author>
<affiliation confidence="0.943015">
Xiamen University, Xiamen, China 361005&apos;
</affiliation>
<address confidence="0.874291">
Soochow University, Suzhou, China 2150062
</address>
<email confidence="0.8417035">
{zb, lyj}@stu.xmu.edu.cn, {jssu, hduan, yao0010}@xmu.edu.cn
dyxiong@suda.edu.cn
</email>
<sectionHeader confidence="0.993771" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999849411764706">
Implicit discourse relation recognition re-
mains a serious challenge due to the ab-
sence of discourse connectives. In this pa-
per, we propose a Shallow Convolutional
Neural Network (SCNN) for implicit dis-
course relation recognition, which con-
tains only one hidden layer but is effec-
tive in relation recognition. The shallow
structure alleviates the overfitting prob-
lem, while the convolution and nonlinear
operations help preserve the recognition
and generalization ability of our model.
Experiments on the benchmark data set
show that our model achieves comparable
and even better performance when com-
paring against current state-of-the-art sys-
tems.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991389440677966">
As a crucial task for discourse analysis, discourse
relation recognition (DRR) aims to automatically
identify the internal structure and logical relation-
ship of coherent text (e.g., TEMPORAL, CONTIN-
GENCY, EXPANSION, etc). It provides important
information to many other natural language pro-
cessing systems, such as question answering (Ver-
berne et al., 2007), information extraction (Cimi-
ano et al., 2005), machine translation (Guzm´an et
al., 2014) and so on. Despite great progress in ex-
plicit DRR where the discourse connectives (e.g.,
“because”, “but” et al.) explicitly exist in the text
(Miltsakaki et al., 2005; Pitler et al., 2008), im-
plicit DRR remains a serious challenge because of
the absence of discourse connectives (Prasad et al.,
2008).
Conventional methods for implicit DRR di-
rectly rely on feature engineering, wherein re-
searchers generally exploit various hand-crafted
features, such as words, part-of-speech tags and
∗Corresponding author
production rules (Pitler et al., 2009; Lin et al.,
2009; Louis et al., 2010; Wang et al., 2012; Park
and Cardie, 2012; McKeown and Biran, 2013;
Lan et al., 2013; Versley, 2013; Braud and De-
nis, 2014; Rutherford and Xue, 2014). Although
these methods have proven successful, these man-
ual features are labor-intensive and weak to cap-
ture intentional, semantic and syntactic aspects
that govern discourse coherence (Li et al., 2014),
thus limiting the effectiveness of these methods.
Recently, deep learning models have achieved
remarkable results in natural language processing
(Bengio et al., 2003; Bengio et al., 2006; Socher
et al., 2011b; Socher et al., 2011a; Socher et al.,
2013; Li et al., 2013; Kim, 2014). However, to the
best of our knowledge, there is little deep learning
work specifically for implicit DRR. The neglect of
this important domain may be due to the follow-
ing two reasons: (1) discourse relation distribution
is rather unbalanced, where the generalization of
deep models is relatively insufficient despite their
powerful studying ability; (2) training dataset in
implicit DRR is relatively small, where overfitting
problems become more prominent.
In this paper, we propose a Shallow Convolu-
tional Neural Network (SCNN) for implicit DRR,
with only one simple convolution layer on the
top of word vectors. On one hand, the network
structure is simple, thereby overfitting issue can
be alleviated; on the other hand, the convolution
operation and nonlinear transformation help pre-
serve the recognition ability of SCNN. This makes
our model able to generalize better on the test
dataset. We performed evaluation for English im-
plicit DRR on the PDTB-style corpus. Experi-
mental results show that the proposed method can
obtain comparable even better performance when
compares against several baselines.
</bodyText>
<sectionHeader confidence="0.985932" genericHeader="introduction">
2 Model
</sectionHeader>
<bodyText confidence="0.623137">
In Penn Discourse Treebank (PDTB) (Prasad et
al., 2008), implicit discourse relations are anno-
</bodyText>
<page confidence="0.894655">
2230
</page>
<note confidence="0.696065333333333">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2230–2235,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
Arg1: our competitors say we overbid them Arg2: who cares
</note>
<figureCaption confidence="0.99831">
Figure 1: SCNN model architecture visualized with an instance.
</figureCaption>
<figure confidence="0.809537333333333">
SoftMax Layer
Concatenate,Tanh,Norm
average max min average max min
</figure>
<bodyText confidence="0.927715714285715">
tated with connective expressions that best convey
implicit relations between two neighboring argu-
ments, e.g.
Arg1: (But) our competitions say we overbid
them
Arg2: who cares
the connective “But”, which is annotated manu-
ally, is used to express the inferred COMPARISON
relation.
We learn a classifier for implicit DRR based on
convonlutional neural network. The overall model
architecture is illustrated in Figure 1.1 In our
model, each word in vocabulary V corresponds to
a d-dimensional dense, real-valued vector, and all
words are stacked into a word embedding matrix
L E Rd×|V |, where |V  |is the vocabulary size.
Given an ordered list of n words in an argument,
we retrieve the i-th word representation xvi E Rd
from L with its corresponding vocabulary index
vi. All word vectors in the argument produce the
following output matrix:
</bodyText>
<equation confidence="0.99933">
X = (xv1, xv2, ... , xvn) (1)
</equation>
<bodyText confidence="0.9989368">
Following previous work (Collobert et al., 2011;
Socher et al., 2011a), for each row r in X, we
explore three convolutional operations to obtain
three convolution features average, min and max
as follows:
</bodyText>
<equation confidence="0.98051">
Xr,i (2)
min
cr =min (Xr,1, Xr,2, ... , Xr,n) (3)
</equation>
<footnote confidence="0.8909865">
1For better illustration, we assume that the dimension of
word vectors is 4 throughout this paper.
</footnote>
<equation confidence="0.9758565">
max
cr = max (Xr,1, Xr,2, ... ,Xr,n) (4)
</equation>
<bodyText confidence="0.99978375">
In this way, SCNN is able to capture almost all im-
portant information inside X (one with the highest,
lowest and average values). Besides, each convo-
lution operation naturally deals with variable argu-
ment lengths (Note that c E Rd). Back to Figure
1, we present cavg, cmin and cmax with red, purple
and green color respectively.
After obtaining the features of both arguments,
we concatenate all of them into one vector, and
then apply tanh transformation and length nor-
malization successively to generate the hidden lay-
ers:
</bodyText>
<equation confidence="0.9971485">
r avg min max avg min max 1
a = cArg1; cArg1; cArg1; cArg2; cArg2; cArg2 J
(5)
tanh (a)
h = (6)
�tanh (a)�
</equation>
<bodyText confidence="0.999949285714286">
where h E R6d is the hidden layer representa-
tion. The normalization operation scales the com-
ponents of a feature vector to unit length. This, to
some extent, eliminates the manifold differences
among different features.
Upon the hidden layer, we stack a Softmax layer
for relation recognition,
</bodyText>
<equation confidence="0.980748">
y = f(Wh + b) (7)
</equation>
<bodyText confidence="0.9999926">
where f is the softmax function, W E Rl×6d is the
parameter matrix, b E Rl is the bias term, and l is
the relation number.
To assess how well the predicted relation y rep-
resents the real relation, we supervise it with the
</bodyText>
<equation confidence="0.901249">
cavg = 1
r n
n
i
</equation>
<page confidence="0.887739">
2231
</page>
<bodyText confidence="0.997412">
gold relation g in the annotated training corpus us-
ing the traditional cross-entropy error,
</bodyText>
<equation confidence="0.973543">
l
E(y, g) = − gj x log (yj) (8)
j
</equation>
<bodyText confidence="0.9692465">
Combined with the regularization error, the joint
training objective function is
</bodyText>
<equation confidence="0.8888805">
A
E(yt,gt) + 2 110112 (9)
</equation>
<bodyText confidence="0.999951777777778">
where m is the number of training instances, yt is
the t-th predicted distribution, A is the regulariza-
tion coefficient and 0 is parameters, including L,
W and b.2
To train SCNN, we first employ the toolkit
Word2Uec3 (Mikolov et al., 2013) to initialize the
word embedding matrix L using a large-scale un-
labeled data. Then, L-BFGS algorithm is applied
to fine-tune the parameters 0.
</bodyText>
<sectionHeader confidence="0.99957" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999974">
We conducted a series of experiments on English
implicit DRR task. After a brief description of
the experimental setup and the baseline systems,
we further investigated the effectiveness of our
method with deep analysis.
</bodyText>
<subsectionHeader confidence="0.998031">
3.1 Setup
</subsectionHeader>
<bodyText confidence="0.999875631578947">
For comparison with other systems, we formu-
lated the task as four separate one-against-all bi-
nary classification problems: one for each top
level sense of implicit discourse relations (Pitler
et al., 2009).
We used the PDTB 2.0 corpus4 (Prasad et al.,
2008) for evaluation. The PDTB corpus contains
discourse annotations over 2,312 Wall Street Jour-
nal articles, and is organized in different sections.
Following Pitler et al. (2009), we used sections 2-
20 as training set, sections 21-22 as test set, and
sections 0-1 as development set for parameter op-
timization. For each relation, we randomly ex-
tracted the same number of positive and negative
instances as training data, while all instances in
sections 21 and 22 are used as our test set. The
statistics of various data sets is listed in Table 1.
We tokenized PDTB corpus using Stanford NLP
Tool5. For all experiments, we empirically set
</bodyText>
<footnote confidence="0.9995804">
2The bias terms b is not regularized. We preserve it in the
equation just for clarity.
3https://code.google.com/p/word2vec/
4http://www.seas.upenn.edu/ pdtb/
5http://nlp.stanford.edu/software/corenlp.shtml
</footnote>
<table confidence="0.999912666666667">
Relation Positive/Negative Sentences
Train Dev Test
COMP. 1942/1942 197/986 152/894
CONT. 3342/3342 295/888 279/767
EXP. 7004/7004 671/512 574/472
TEMP. 760/760 64/1119 85/96l
</table>
<tableCaption confidence="0.978521">
Table 1: Statistics of positive and negative in-
stances in training (Train), development (Dev)
</tableCaption>
<bodyText confidence="0.6221225">
and test (Test) sets. COMP.=COMPARISON,
CONT.=CONTINGENCY, EXP.=EXPANSION and
TEMP.=TEMPORAL
d=128 and A=1e−4. Besides, the unlabeled data
for word embedding initialization contains 1.02M
sentences with 33.5M words.
</bodyText>
<subsectionHeader confidence="0.996962">
3.2 Baselines
</subsectionHeader>
<bodyText confidence="0.9927275">
We compared our model against the following
baseline methods:
</bodyText>
<listItem confidence="0.977593416666667">
• SVM: This method learns a support vector
machine (SVM) classifier with the labeled
data.
• TSVM: This method learns a transductive
SVM (TSVM) classifiers given the labeled
data and unlabeled data. We extracted unla-
beled data from above-mentioned 1.02M sen-
tences. After filtering the noise ones, we
finally obtained 0.11M unlabeled instances,
each of which contains only two clauses.
• RAE: This method learns a recursive autoen-
coder (RAE) classifier with the labeled data.
</listItem>
<bodyText confidence="0.968081466666667">
We first utilized standard RAEs to represent
arguments, and then stacked a Softmax layer
upon them. The hyperparameters were set as
follows: word dimension 64, balance factor
for reconstruction error 0.10282 and regular-
ization factor 1e−5. Word embeddings are
initialized via Word2Vec.
Rutherford and Xue (2014) show that Brown
cluster pair feature is very impactful in implicit
DRR (Rutherford and Xue, 2014). This feature
is superior to one-hot representation for the in-
teractions between two arguments, such as cross-
argument word pair features in our baseline meth-
ods. We therefore conducted two additional exper-
iments for comparison:
</bodyText>
<listItem confidence="0.9830876">
• Add-Bro: This method learns an SVM clas-
sifier using baseline system features along
with the Brown cluster pair feature.
• No-Cro: This method learns an SVM clas-
sifier on Add-Bro’s features without cross-
</listItem>
<equation confidence="0.92293775">
J(0) = m
m
L
t=1
</equation>
<page confidence="0.899721">
2232
</page>
<table confidence="0.999969827586207">
Relation Model Precision Recall Accuracy MacroF1
COMP. vs Other SVM 22.22 60.53 63.48 32.51
TSVM 20.53 66.45 57.74 31.37
Add-Bro 22.79 64.47 63.10 33.68
No-Cro 22.89 67.76 62.14 34.22
RAE 18.38 62.50 54.21 28.40
SCNN-No-Norm 21.07 54.61 63.67 30.40
SCNN 22.00 67.76 60.42 33.22
CONT. vs Other SVM 39.70 67.03 64.05 49.87
TSVM 38.72 67.03 62.91 49.08
Add-Bro 39.14 72.40 62.62 50.82
No-Cro 39.50 74.19 62.81 51.56
RAE 37.55 68.10 61.28 48.41
SCNN-No-Norm 39.02 71.33 62.62 50.44
SCNN 39.80 75.29 63.00 52.04
EXP. vs Other SVM 66.35 60.10 61.38 63.07
TSVM 66.48 61.15 61.76 63.70
Add-Bro 65.89 58.89 60.71 62.19
No-Cro 66.73 61.15 61.95 63.82
RAE 58.24 70.29 56.02 63.67
SCNN-No-Norm 59.39 74.39 58.03 66.05
SCNN 56.29 91.11 56.30 69.59
TEMP. vs Other SVM 15.76 68.24 67.78 25.61
TSVM 16.26 77.65 65.68 26.88
Add-Bro 15.10 68.24 66.25 24.73
No-Cro 13.89 64.71 64.53 22.87
RAE 10.02 60.00 52.96 17.17
SCNN-No-Norm 18.26 67.06 72.94 28.71
SCNN 20.22 62.35 76.95 30.54
</table>
<tableCaption confidence="0.999214">
Table 2: Performance comparison of different systems on the test set.
</tableCaption>
<bodyText confidence="0.98885436">
argument word pair features.
In addition, to further verify the effectiveness of
normalization, we also compared against SCNN
model without normalization (SCNN-No-Norm).
Throughout our experiments, we used the
toolkit SVM-light6 (Joachims, 1999) in all the
SVM-related experiments. Following previous
work (Pitler et al., 2009; Lin et al., 2009), we
adopted the following features for baseline meth-
ods:
Bag of Words: Three binary features that check
whether a word occurs in Arg1, Arg2 and both ar-
guments.
Cross-Argument Word Pairs: We group all
words from Arg1 and Arg2 into two sets W1,W2
respectively, then extract any possible word pair
(wi, wj)(wi ∈ W1, wj ∈ W2) as features.
Polarity: The count of positive, negated positive,
negative and neutral words in Arg1 and Arg2 ac-
cording to the MPQA corpus (English). Their
cross products are used as features.
First-Last, First3: The first and last words of
each argument, the pair of the first words in two
arguments, the pair of the last words in two argu-
ments, and the first three words of each argument
</bodyText>
<footnote confidence="0.834013">
6http://svmlight.joachims.org/
</footnote>
<bodyText confidence="0.995578466666667">
are used as features.
Production Rules: We extract all production
rules from syntactic trees of arguments. We de-
fined three binary features for each rule to check
whether this rule appear in Arg1, Arg2 and both
arguments.
Dependency Rules: We also extracted all de-
pendency rules from dependency trees of argu-
ments. Similarly, we defined three binary features
for each rule to check whether this rule appear in
Arg1, Arg2 and both arguments.
In order to collect bag of words, production
rules, dependency rules, and cross-argument word
pairs, we used a frequency cutoff of 5 to remove
rare features, following Lin et al. (2009).
</bodyText>
<subsectionHeader confidence="0.988886">
3.3 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.9999465">
All models are evaluated by assessing the accuracy
and F1 scores on account of the imbalance in test
set. Besides, for better analysis, we also provided
the precision and recall results.
Table 2 summarizes the performance of dif-
ferent models. On the whole, the F1 scores
for implicit DRR are relatively low on average:
COMP., CONT., EXP. and TEMP. about 32%,
50%, 65% and 28% respectively. This illustrates
the difficulty in implicit DRR. Although we ex-
</bodyText>
<page confidence="0.952814">
2233
</page>
<bodyText confidence="0.99998345">
pected unlabeled data could obtain improvement,
we observed negative results appeared in TSVM:
COMP. and CONT. dropped 1.14% and 0.79% re-
spectively7. The F1 scores of TEMP. and EXP. are
improved (1.27% and 0.63% respectively). The
main reason may be that our unlabeled data is not
strictly from the discourse corpus.
Incorporating Brown cluster pair features en-
hances the recognition of COMP. and CONT.. Par-
ticllarly, No-Cro achieves the best result in COMP.
34.22%. But we found no consistent improve-
ment in EXP. and TEMP.: No-Cro loses 2.74% in
TEMP.; Add-Bro loses 0.88% and 2.12% in EXP.
and TEMP. respectively. This result is inconsistent
with the finding of Rutherford and Xue (2014).
The reason may lie in the training strategy, where
we used sampling to solve the problem of unbal-
anced dataset while they reweighted training sam-
ples.
Compared with SVM-based models, RAE per-
forms poorly in three relations, except EXP. which
has the largest training dataset. Maybe RAE
needs more labeled training data for better re-
sults. However, SCNN models perform remark-
ably well, producing comparable and even bet-
ter results. Without normalization, SCNN-No-
Norm gains 0.57%, 2.98% and 3.1% F1 scores for
CONT., EXP. and TEMP. respectively, but loses
2.11% for COMP.. We obtain further improvement
using SCNN with normalization: 0.71%, 2.17%,
6.52% and 4.93% for COMP., CONT., EXP. and
TEMP. respectively. This suggests that normaliza-
tion is useful for generalization of shallow models.
From Table 2, we found that our models do not
achieve consistent improvements in precision, but
benefit greatly from the gains of recall. Besides,
our model works quite well for small dataset (Both
accuracy and F1 score are improved in TEMP.).
All of these demonstrate that our model is suitable
for implicit DRR.
</bodyText>
<sectionHeader confidence="0.984627" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.994379857142857">
In this paper, we have presented a convolutional
neural network based approach to learn better
DRR classifiers. The method is simple but effec-
tive for relation recognition. Experiment results
show that our approach achieves satisfactory per-
formance against the baseline models.
In the future, we will verify our model on other
</bodyText>
<footnote confidence="0.8790575">
7Without special illustration, all improvements and de-
clines are against SVM.
</footnote>
<bodyText confidence="0.9999468">
languages, for example, Chinese and Arabic. Be-
sides, since our model is general to classification
problems, we would like to investigate its effec-
tiveness on other similar tasks, such as sentiment
classification and movie review classification, etc.
</bodyText>
<sectionHeader confidence="0.979348" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.915403571428572">
The authors were supported by National Nat-
ural Science Foundation of China (Grant Nos
61303082 and 61403269), Natural Science
Foundation of Jiangsu Province (Grant No.
BK20140355), Natural Science Foundation of Fu-
jian Province of China (Grant No. 2013J01250),
the Special and Major Subject Project of the
Industrial Science and Technology in Fujian
Province 2013 (Grant No. 2013HZ0004-1),
and 2014 Key Project of Anhui Science and
Technology Bureau (Grant No. 1301021018). We
thank the anonymous reviewers for their insightful
comments. We are also grateful to Kaixu Zhang
for his valuable suggestions.
</bodyText>
<sectionHeader confidence="0.998117" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999530827586207">
Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and
Christian Janvin. 2003. A neural probabilistic lan-
guage model. JMLR, 3:1137–1155.
Yoshua Bengio, Holger Schwenk, Jean-S´ebastien
Sen´ecal, Fr´ederic Morin, and Jean-Luc Gauvain.
2006. Neural probabilistic language models. In
Innovations in Machine Learning, pages 137–186.
Springer Berlin Heidelberg.
Chlo´e Braud and Pascal Denis. 2014. Combining nat-
ural and artificial examples to improve implicit dis-
course relation identification. In Proc. of COLING,
pages 1694–1705.
Philipp Cimiano, Uwe Reyle, and Jasmin ˇSari´c. 2005.
Ontology-driven discourse analysis for information
extraction. Data &amp; Knowledge Engineering, pages
59–83.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. JMLR, pages 2493–2537.
Francisco Guzm´an, Shafiq Joty, Llu´ıs M`arquez, and
Preslav Nakov. 2014. Using discourse structure
improves machine translation evaluation. In Proc.
of ACL, pages 687–698. Association for Computa-
tional Linguistics.
T. Joachims. 1999. Making large-scale SVM learning
practical. In Advances in Kernel Methods - Support
Vector Learning, chapter 11, pages 169–184. MIT
Press, Cambridge, MA.
</reference>
<page confidence="0.925808">
2234
</page>
<reference confidence="0.999459325842696">
Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proc. of EMNLP, pages
1746–1751. Association for Computational Linguis-
tics.
Man Lan, Yu Xu, and Zhengyu Niu. 2013. Leverag-
ing synthetic discourse data via multi-task learning
for implicit discourse relation recognition. In Proc.
of ACL, pages 476–485. Association for Computa-
tional Linguistics.
Peng Li, Yang Liu, and Maosong Sun. 2013. Re-
cursive autoencoders for ITG-based translation. In
Proc. of EMNLP, pages 567–577. Association for
Computational Linguistics.
Jiwei Li, Rumeng Li, and Eduard Hovy. 2014. Recur-
sive deep models for discourse parsing. In Proc. of
EMNLP, pages 2061–2069. Association for Compu-
tational Linguistics.
Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009.
Recognizing implicit discourse relations in the Penn
Discourse Treebank. In Proc. of EMNLP, pages
343–351. Association for Computational Linguis-
tics.
Annie Louis, Aravind Joshi, Rashmi Prasad, and Ani
Nenkova. 2010. Using entity features to classify
implicit discourse relations. In Proc. of SIGDIAL,
pages 59–62. Association for Computational Lin-
guistics.
Kathleen McKeown and Or Biran. 2013. Aggregated
word pair features for implicit discourse relation dis-
ambiguation. In Proc. of ACL, pages 69–73. The
Association for Computational Linguistics.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. CoRR, abs/1310.4546.
Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Ar-
avind Joshi, and Bonnie Webber. 2005. Experi-
ments on sense annotations and sense disambigua-
tion of discourse connectives. In Proc. of TLT2005.
Joonsuk Park and Claire Cardie. 2012. Improving Im-
plicit Discourse Relation Recognition Through Fea-
ture Set Optimization. In Proc. of SIGDIAL, pages
108–112. Association for Computational Linguis-
tics.
Emily Pitler, Mridhula Raghupathy, Hena Mehta, Ani
Nenkova, Alan Lee, and Aravind K Joshi. 2008.
Easily identifiable discourse relations. Technical
Reports (CIS).
Emily Pitler, Annie Louis, and Ani Nenkova. 2009.
Automatic sense prediction for implicit discourse re-
lations in text. In Proc. of ACL-AFNLP, pages 683–
691. Association for Computational Linguistics.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind K Joshi, and Bon-
nie L Webber. 2008. The penn discourse treebank
2.0. In Proc. of LREC. Citeseer.
Attapol Rutherford and Nianwen Xue. 2014. Dis-
covering implicit discourse relations through brown
cluster pair representation and coreference patterns.
In Proc. of EACL, pages 645–654. Association for
Computational Linguistics.
Richard Socher, Eric H. Huang, Jeffrey Pennin,
Christopher D Manning, and Andrew Y. Ng. 2011a.
Dynamic pooling and unfolding recursive autoen-
coders for paraphrase detection. In Proc. of NIPS,
pages 801–809. Curran Associates, Inc.
Richard Socher, Cliff Chiung-Yu Lin, Andrew Y. Ng,
and Christopher D. Manning. 2011b. Parsing natu-
ral scenes and natural language with recursive neural
networks. In Proc. of ICML, pages 129–136. Omni-
press.
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In Proc. of EMNLP, pages 1631–1642. Asso-
ciation for Computational Linguistics.
Suzan Verberne, Lou Boves, Nelleke Oostdijk, and
Peter-Arno Coppen. 2007. Evaluating discourse-
based answer extraction for why-question answer-
ing. In Proc. of SIGIR, pages 735–736. ACM.
Yannick Versley. 2013. Subgraph-based classification
of explicit and implicit discourse relations. In Proc.
of IWCS, pages 264–275. Association for Computa-
tional Linguistics.
Xun Wang, Sujian Li, Jiwei Li, and Wenjie Li. 2012.
Implicit discourse relation recognition by selecting
typical training examples. In Proc. of COLING,
pages 2757–2772.
</reference>
<page confidence="0.991232">
2235
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.365476">
<title confidence="0.9980575">Shallow Convolutional Neural for Implicit Discourse Relation Recognition</title>
<author confidence="0.924122">Jinsong Deyi Yaojie Hong</author>
<address confidence="0.7603505">University, Xiamen, China University, Suzhou, China</address>
<email confidence="0.938007">hduan,dyxiong@suda.edu.cn</email>
<abstract confidence="0.991829388888889">Implicit discourse relation recognition remains a serious challenge due to the absence of discourse connectives. In this paper, we propose a Shallow Convolutional Neural Network (SCNN) for implicit discourse relation recognition, which contains only one hidden layer but is effective in relation recognition. The shallow structure alleviates the overfitting problem, while the convolution and nonlinear operations help preserve the recognition and generalization ability of our model. Experiments on the benchmark data set show that our model achieves comparable and even better performance when comparing against current state-of-the-art systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>R´ejean Ducharme</author>
<author>Pascal Vincent</author>
<author>Christian Janvin</author>
</authors>
<title>A neural probabilistic language model.</title>
<date>2003</date>
<journal>JMLR,</journal>
<pages>3--1137</pages>
<contexts>
<context position="2550" citStr="Bengio et al., 2003" startWordPosition="370" endWordPosition="373"> ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neglect of this important domain may be due to the following two reasons: (1) discourse relation distribution is rather unbalanced, where the generalization of deep models is relatively insufficient despite their powerful studying ability; (2) training dataset in implicit DRR is relatively small, where overfitting problems become more prominent. In this paper, we propose </context>
</contexts>
<marker>Bengio, Ducharme, Vincent, Janvin, 2003</marker>
<rawString>Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and Christian Janvin. 2003. A neural probabilistic language model. JMLR, 3:1137–1155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>Holger Schwenk</author>
<author>Jean-S´ebastien Sen´ecal</author>
<author>Fr´ederic Morin</author>
<author>Jean-Luc Gauvain</author>
</authors>
<title>Neural probabilistic language models.</title>
<date>2006</date>
<booktitle>In Innovations in Machine Learning,</booktitle>
<pages>137--186</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Bengio, Schwenk, Sen´ecal, Morin, Gauvain, 2006</marker>
<rawString>Yoshua Bengio, Holger Schwenk, Jean-S´ebastien Sen´ecal, Fr´ederic Morin, and Jean-Luc Gauvain. 2006. Neural probabilistic language models. In Innovations in Machine Learning, pages 137–186. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chlo´e Braud</author>
<author>Pascal Denis</author>
</authors>
<title>Combining natural and artificial examples to improve implicit discourse relation identification.</title>
<date>2014</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>1694--1705</pages>
<contexts>
<context position="2152" citStr="Braud and Denis, 2014" startWordPosition="312" endWordPosition="316">., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specificall</context>
</contexts>
<marker>Braud, Denis, 2014</marker>
<rawString>Chlo´e Braud and Pascal Denis. 2014. Combining natural and artificial examples to improve implicit discourse relation identification. In Proc. of COLING, pages 1694–1705.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Cimiano</author>
<author>Uwe Reyle</author>
<author>Jasmin ˇSari´c</author>
</authors>
<title>Ontology-driven discourse analysis for information extraction.</title>
<date>2005</date>
<journal>Data &amp; Knowledge Engineering,</journal>
<pages>59--83</pages>
<marker>Cimiano, Reyle, ˇSari´c, 2005</marker>
<rawString>Philipp Cimiano, Uwe Reyle, and Jasmin ˇSari´c. 2005. Ontology-driven discourse analysis for information extraction. Data &amp; Knowledge Engineering, pages 59–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<pages>2493--2537</pages>
<publisher>JMLR,</publisher>
<contexts>
<context position="5180" citStr="Collobert et al., 2011" startWordPosition="782" endWordPosition="785">ssifier for implicit DRR based on convonlutional neural network. The overall model architecture is illustrated in Figure 1.1 In our model, each word in vocabulary V corresponds to a d-dimensional dense, real-valued vector, and all words are stacked into a word embedding matrix L E Rd×|V |, where |V |is the vocabulary size. Given an ordered list of n words in an argument, we retrieve the i-th word representation xvi E Rd from L with its corresponding vocabulary index vi. All word vectors in the argument produce the following output matrix: X = (xv1, xv2, ... , xvn) (1) Following previous work (Collobert et al., 2011; Socher et al., 2011a), for each row r in X, we explore three convolutional operations to obtain three convolution features average, min and max as follows: Xr,i (2) min cr =min (Xr,1, Xr,2, ... , Xr,n) (3) 1For better illustration, we assume that the dimension of word vectors is 4 throughout this paper. max cr = max (Xr,1, Xr,2, ... ,Xr,n) (4) In this way, SCNN is able to capture almost all important information inside X (one with the highest, lowest and average values). Besides, each convolution operation naturally deals with variable argument lengths (Note that c E Rd). Back to Figure 1, w</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. JMLR, pages 2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Guzm´an</author>
<author>Shafiq Joty</author>
<author>Llu´ıs M`arquez</author>
<author>Preslav Nakov</author>
</authors>
<title>Using discourse structure improves machine translation evaluation.</title>
<date>2014</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>687--698</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Guzm´an, Joty, M`arquez, Nakov, 2014</marker>
<rawString>Francisco Guzm´an, Shafiq Joty, Llu´ıs M`arquez, and Preslav Nakov. 2014. Using discourse structure improves machine translation evaluation. In Proc. of ACL, pages 687–698. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>In Advances in Kernel Methods - Support Vector Learning, chapter 11,</booktitle>
<pages>169--184</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="11856" citStr="Joachims, 1999" startWordPosition="1864" endWordPosition="1865">3.67 SCNN-No-Norm 59.39 74.39 58.03 66.05 SCNN 56.29 91.11 56.30 69.59 TEMP. vs Other SVM 15.76 68.24 67.78 25.61 TSVM 16.26 77.65 65.68 26.88 Add-Bro 15.10 68.24 66.25 24.73 No-Cro 13.89 64.71 64.53 22.87 RAE 10.02 60.00 52.96 17.17 SCNN-No-Norm 18.26 67.06 72.94 28.71 SCNN 20.22 62.35 76.95 30.54 Table 2: Performance comparison of different systems on the test set. argument word pair features. In addition, to further verify the effectiveness of normalization, we also compared against SCNN model without normalization (SCNN-No-Norm). Throughout our experiments, we used the toolkit SVM-light6 (Joachims, 1999) in all the SVM-related experiments. Following previous work (Pitler et al., 2009; Lin et al., 2009), we adopted the following features for baseline methods: Bag of Words: Three binary features that check whether a word occurs in Arg1, Arg2 and both arguments. Cross-Argument Word Pairs: We group all words from Arg1 and Arg2 into two sets W1,W2 respectively, then extract any possible word pair (wi, wj)(wi ∈ W1, wj ∈ W2) as features. Polarity: The count of positive, negated positive, negative and neutral words in Arg1 and Arg2 according to the MPQA corpus (English). Their cross products are used</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Making large-scale SVM learning practical. In Advances in Kernel Methods - Support Vector Learning, chapter 11, pages 169–184. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Convolutional neural networks for sentence classification.</title>
<date>2014</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>1746--1751</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2665" citStr="Kim, 2014" startWordPosition="394" endWordPosition="395">and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neglect of this important domain may be due to the following two reasons: (1) discourse relation distribution is rather unbalanced, where the generalization of deep models is relatively insufficient despite their powerful studying ability; (2) training dataset in implicit DRR is relatively small, where overfitting problems become more prominent. In this paper, we propose a Shallow Convolutional Neural Network (SCNN) for implicit DRR, with only one simple convolution layer on the top o</context>
</contexts>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim. 2014. Convolutional neural networks for sentence classification. In Proc. of EMNLP, pages 1746–1751. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Man Lan</author>
<author>Yu Xu</author>
<author>Zhengyu Niu</author>
</authors>
<title>Leveraging synthetic discourse data via multi-task learning for implicit discourse relation recognition.</title>
<date>2013</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>476--485</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2114" citStr="Lan et al., 2013" startWordPosition="306" endWordPosition="309">re the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is</context>
</contexts>
<marker>Lan, Xu, Niu, 2013</marker>
<rawString>Man Lan, Yu Xu, and Zhengyu Niu. 2013. Leveraging synthetic discourse data via multi-task learning for implicit discourse relation recognition. In Proc. of ACL, pages 476–485. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Li</author>
<author>Yang Liu</author>
<author>Maosong Sun</author>
</authors>
<title>Recursive autoencoders for ITG-based translation.</title>
<date>2013</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>567--577</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2653" citStr="Li et al., 2013" startWordPosition="390" endWordPosition="393"> al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neglect of this important domain may be due to the following two reasons: (1) discourse relation distribution is rather unbalanced, where the generalization of deep models is relatively insufficient despite their powerful studying ability; (2) training dataset in implicit DRR is relatively small, where overfitting problems become more prominent. In this paper, we propose a Shallow Convolutional Neural Network (SCNN) for implicit DRR, with only one simple convolution layer </context>
</contexts>
<marker>Li, Liu, Sun, 2013</marker>
<rawString>Peng Li, Yang Liu, and Maosong Sun. 2013. Recursive autoencoders for ITG-based translation. In Proc. of EMNLP, pages 567–577. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Rumeng Li</author>
<author>Eduard Hovy</author>
</authors>
<title>Recursive deep models for discourse parsing.</title>
<date>2014</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>2061--2069</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2383" citStr="Li et al., 2014" startWordPosition="347" endWordPosition="350">s for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neglect of this important domain may be due to the following two reasons: (1) discourse relation distribution is rather unbalanced, where the generalization of deep models is relatively insufficient despite </context>
</contexts>
<marker>Li, Li, Hovy, 2014</marker>
<rawString>Jiwei Li, Rumeng Li, and Eduard Hovy. 2014. Recursive deep models for discourse parsing. In Proc. of EMNLP, pages 2061–2069. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ziheng Lin</author>
<author>Min-Yen Kan</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Recognizing implicit discourse relations in the Penn Discourse Treebank.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>343--351</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2009" citStr="Lin et al., 2009" startWordPosition="286" endWordPosition="289">, 2005), machine translation (Guzm´an et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al.,</context>
<context position="11956" citStr="Lin et al., 2009" startWordPosition="1878" endWordPosition="1881">.24 67.78 25.61 TSVM 16.26 77.65 65.68 26.88 Add-Bro 15.10 68.24 66.25 24.73 No-Cro 13.89 64.71 64.53 22.87 RAE 10.02 60.00 52.96 17.17 SCNN-No-Norm 18.26 67.06 72.94 28.71 SCNN 20.22 62.35 76.95 30.54 Table 2: Performance comparison of different systems on the test set. argument word pair features. In addition, to further verify the effectiveness of normalization, we also compared against SCNN model without normalization (SCNN-No-Norm). Throughout our experiments, we used the toolkit SVM-light6 (Joachims, 1999) in all the SVM-related experiments. Following previous work (Pitler et al., 2009; Lin et al., 2009), we adopted the following features for baseline methods: Bag of Words: Three binary features that check whether a word occurs in Arg1, Arg2 and both arguments. Cross-Argument Word Pairs: We group all words from Arg1 and Arg2 into two sets W1,W2 respectively, then extract any possible word pair (wi, wj)(wi ∈ W1, wj ∈ W2) as features. Polarity: The count of positive, negated positive, negative and neutral words in Arg1 and Arg2 according to the MPQA corpus (English). Their cross products are used as features. First-Last, First3: The first and last words of each argument, the pair of the first w</context>
<context position="13324" citStr="Lin et al. (2009)" startWordPosition="2108" endWordPosition="2111">as features. Production Rules: We extract all production rules from syntactic trees of arguments. We defined three binary features for each rule to check whether this rule appear in Arg1, Arg2 and both arguments. Dependency Rules: We also extracted all dependency rules from dependency trees of arguments. Similarly, we defined three binary features for each rule to check whether this rule appear in Arg1, Arg2 and both arguments. In order to collect bag of words, production rules, dependency rules, and cross-argument word pairs, we used a frequency cutoff of 5 to remove rare features, following Lin et al. (2009). 3.3 Results and Analysis All models are evaluated by assessing the accuracy and F1 scores on account of the imbalance in test set. Besides, for better analysis, we also provided the precision and recall results. Table 2 summarizes the performance of different models. On the whole, the F1 scores for implicit DRR are relatively low on average: COMP., CONT., EXP. and TEMP. about 32%, 50%, 65% and 28% respectively. This illustrates the difficulty in implicit DRR. Although we ex2233 pected unlabeled data could obtain improvement, we observed negative results appeared in TSVM: COMP. and CONT. drop</context>
</contexts>
<marker>Lin, Kan, Ng, 2009</marker>
<rawString>Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proc. of EMNLP, pages 343–351. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Aravind Joshi</author>
<author>Rashmi Prasad</author>
<author>Ani Nenkova</author>
</authors>
<title>Using entity features to classify implicit discourse relations.</title>
<date>2010</date>
<booktitle>In Proc. of SIGDIAL,</booktitle>
<pages>59--62</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2029" citStr="Louis et al., 2010" startWordPosition="290" endWordPosition="293">ranslation (Guzm´an et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al</context>
</contexts>
<marker>Louis, Joshi, Prasad, Nenkova, 2010</marker>
<rawString>Annie Louis, Aravind Joshi, Rashmi Prasad, and Ani Nenkova. 2010. Using entity features to classify implicit discourse relations. In Proc. of SIGDIAL, pages 59–62. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
<author>Or Biran</author>
</authors>
<title>Aggregated word pair features for implicit discourse relation disambiguation.</title>
<date>2013</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>69--73</pages>
<contexts>
<context position="2096" citStr="McKeown and Biran, 2013" startWordPosition="302" endWordPosition="305">gress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our k</context>
</contexts>
<marker>McKeown, Biran, 2013</marker>
<rawString>Kathleen McKeown and Or Biran. 2013. Aggregated word pair features for implicit discourse relation disambiguation. In Proc. of ACL, pages 69–73. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<location>CoRR, abs/1310.4546.</location>
<contexts>
<context position="7188" citStr="Mikolov et al., 2013" startWordPosition="1146" endWordPosition="1149">d l is the relation number. To assess how well the predicted relation y represents the real relation, we supervise it with the cavg = 1 r n n i 2231 gold relation g in the annotated training corpus using the traditional cross-entropy error, l E(y, g) = − gj x log (yj) (8) j Combined with the regularization error, the joint training objective function is A E(yt,gt) + 2 110112 (9) where m is the number of training instances, yt is the t-th predicted distribution, A is the regularization coefficient and 0 is parameters, including L, W and b.2 To train SCNN, we first employ the toolkit Word2Uec3 (Mikolov et al., 2013) to initialize the word embedding matrix L using a large-scale unlabeled data. Then, L-BFGS algorithm is applied to fine-tune the parameters 0. 3 Experiments We conducted a series of experiments on English implicit DRR task. After a brief description of the experimental setup and the baseline systems, we further investigated the effectiveness of our method with deep analysis. 3.1 Setup For comparison with other systems, we formulated the task as four separate one-against-all binary classification problems: one for each top level sense of implicit discourse relations (Pitler et al., 2009). We u</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed representations of words and phrases and their compositionality. CoRR, abs/1310.4546.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Nikhil Dinesh</author>
<author>Rashmi Prasad</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>Experiments on sense annotations and sense disambiguation of discourse connectives.</title>
<date>2005</date>
<booktitle>In Proc. of TLT2005.</booktitle>
<contexts>
<context position="1612" citStr="Miltsakaki et al., 2005" startWordPosition="227" endWordPosition="230">uction As a crucial task for discourse analysis, discourse relation recognition (DRR) aims to automatically identify the internal structure and logical relationship of coherent text (e.g., TEMPORAL, CONTINGENCY, EXPANSION, etc). It provides important information to many other natural language processing systems, such as question answering (Verberne et al., 2007), information extraction (Cimiano et al., 2005), machine translation (Guzm´an et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have pro</context>
</contexts>
<marker>Miltsakaki, Dinesh, Prasad, Joshi, Webber, 2005</marker>
<rawString>Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Aravind Joshi, and Bonnie Webber. 2005. Experiments on sense annotations and sense disambiguation of discourse connectives. In Proc. of TLT2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joonsuk Park</author>
<author>Claire Cardie</author>
</authors>
<title>Improving Implicit Discourse Relation Recognition Through Feature Set Optimization.</title>
<date>2012</date>
<booktitle>In Proc. of SIGDIAL,</booktitle>
<pages>108--112</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2071" citStr="Park and Cardie, 2012" startWordPosition="298" endWordPosition="301">o on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). Howe</context>
</contexts>
<marker>Park, Cardie, 2012</marker>
<rawString>Joonsuk Park and Claire Cardie. 2012. Improving Implicit Discourse Relation Recognition Through Feature Set Optimization. In Proc. of SIGDIAL, pages 108–112. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Mridhula Raghupathy</author>
<author>Hena Mehta</author>
<author>Ani Nenkova</author>
<author>Alan Lee</author>
<author>Aravind K Joshi</author>
</authors>
<title>Easily identifiable discourse relations.</title>
<date>2008</date>
<tech>Technical Reports (CIS).</tech>
<contexts>
<context position="1634" citStr="Pitler et al., 2008" startWordPosition="231" endWordPosition="234">for discourse analysis, discourse relation recognition (DRR) aims to automatically identify the internal structure and logical relationship of coherent text (e.g., TEMPORAL, CONTINGENCY, EXPANSION, etc). It provides important information to many other natural language processing systems, such as question answering (Verberne et al., 2007), information extraction (Cimiano et al., 2005), machine translation (Guzm´an et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these </context>
</contexts>
<marker>Pitler, Raghupathy, Mehta, Nenkova, Lee, Joshi, 2008</marker>
<rawString>Emily Pitler, Mridhula Raghupathy, Hena Mehta, Ani Nenkova, Alan Lee, and Aravind K Joshi. 2008. Easily identifiable discourse relations. Technical Reports (CIS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>Automatic sense prediction for implicit discourse relations in text.</title>
<date>2009</date>
<booktitle>In Proc. of ACL-AFNLP,</booktitle>
<pages>683--691</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1991" citStr="Pitler et al., 2009" startWordPosition="282" endWordPosition="285">ction (Cimiano et al., 2005), machine translation (Guzm´an et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 201</context>
<context position="7782" citStr="Pitler et al., 2009" startWordPosition="1239" endWordPosition="1242">ec3 (Mikolov et al., 2013) to initialize the word embedding matrix L using a large-scale unlabeled data. Then, L-BFGS algorithm is applied to fine-tune the parameters 0. 3 Experiments We conducted a series of experiments on English implicit DRR task. After a brief description of the experimental setup and the baseline systems, we further investigated the effectiveness of our method with deep analysis. 3.1 Setup For comparison with other systems, we formulated the task as four separate one-against-all binary classification problems: one for each top level sense of implicit discourse relations (Pitler et al., 2009). We used the PDTB 2.0 corpus4 (Prasad et al., 2008) for evaluation. The PDTB corpus contains discourse annotations over 2,312 Wall Street Journal articles, and is organized in different sections. Following Pitler et al. (2009), we used sections 2- 20 as training set, sections 21-22 as test set, and sections 0-1 as development set for parameter optimization. For each relation, we randomly extracted the same number of positive and negative instances as training data, while all instances in sections 21 and 22 are used as our test set. The statistics of various data sets is listed in Table 1. We </context>
<context position="11937" citStr="Pitler et al., 2009" startWordPosition="1874" endWordPosition="1877">vs Other SVM 15.76 68.24 67.78 25.61 TSVM 16.26 77.65 65.68 26.88 Add-Bro 15.10 68.24 66.25 24.73 No-Cro 13.89 64.71 64.53 22.87 RAE 10.02 60.00 52.96 17.17 SCNN-No-Norm 18.26 67.06 72.94 28.71 SCNN 20.22 62.35 76.95 30.54 Table 2: Performance comparison of different systems on the test set. argument word pair features. In addition, to further verify the effectiveness of normalization, we also compared against SCNN model without normalization (SCNN-No-Norm). Throughout our experiments, we used the toolkit SVM-light6 (Joachims, 1999) in all the SVM-related experiments. Following previous work (Pitler et al., 2009; Lin et al., 2009), we adopted the following features for baseline methods: Bag of Words: Three binary features that check whether a word occurs in Arg1, Arg2 and both arguments. Cross-Argument Word Pairs: We group all words from Arg1 and Arg2 into two sets W1,W2 respectively, then extract any possible word pair (wi, wj)(wi ∈ W1, wj ∈ W2) as features. Polarity: The count of positive, negated positive, negative and neutral words in Arg1 and Arg2 according to the MPQA corpus (English). Their cross products are used as features. First-Last, First3: The first and last words of each argument, the </context>
</contexts>
<marker>Pitler, Louis, Nenkova, 2009</marker>
<rawString>Emily Pitler, Annie Louis, and Ani Nenkova. 2009. Automatic sense prediction for implicit discourse relations in text. In Proc. of ACL-AFNLP, pages 683– 691. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind K Joshi</author>
<author>Bonnie L Webber</author>
</authors>
<title>The penn discourse treebank 2.0. In</title>
<date>2008</date>
<booktitle>Proc. of LREC.</booktitle>
<publisher>Citeseer.</publisher>
<contexts>
<context position="1746" citStr="Prasad et al., 2008" startWordPosition="249" endWordPosition="252">re and logical relationship of coherent text (e.g., TEMPORAL, CONTINGENCY, EXPANSION, etc). It provides important information to many other natural language processing systems, such as question answering (Verberne et al., 2007), information extraction (Cimiano et al., 2005), machine translation (Guzm´an et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern </context>
<context position="3837" citStr="Prasad et al., 2008" startWordPosition="573" endWordPosition="576">h only one simple convolution layer on the top of word vectors. On one hand, the network structure is simple, thereby overfitting issue can be alleviated; on the other hand, the convolution operation and nonlinear transformation help preserve the recognition ability of SCNN. This makes our model able to generalize better on the test dataset. We performed evaluation for English implicit DRR on the PDTB-style corpus. Experimental results show that the proposed method can obtain comparable even better performance when compares against several baselines. 2 Model In Penn Discourse Treebank (PDTB) (Prasad et al., 2008), implicit discourse relations are anno2230 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2230–2235, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Arg1: our competitors say we overbid them Arg2: who cares Figure 1: SCNN model architecture visualized with an instance. SoftMax Layer Concatenate,Tanh,Norm average max min average max min tated with connective expressions that best convey implicit relations between two neighboring arguments, e.g. Arg1: (But) our competitions say we overbid them Arg2: who car</context>
<context position="7834" citStr="Prasad et al., 2008" startWordPosition="1249" endWordPosition="1252">bedding matrix L using a large-scale unlabeled data. Then, L-BFGS algorithm is applied to fine-tune the parameters 0. 3 Experiments We conducted a series of experiments on English implicit DRR task. After a brief description of the experimental setup and the baseline systems, we further investigated the effectiveness of our method with deep analysis. 3.1 Setup For comparison with other systems, we formulated the task as four separate one-against-all binary classification problems: one for each top level sense of implicit discourse relations (Pitler et al., 2009). We used the PDTB 2.0 corpus4 (Prasad et al., 2008) for evaluation. The PDTB corpus contains discourse annotations over 2,312 Wall Street Journal articles, and is organized in different sections. Following Pitler et al. (2009), we used sections 2- 20 as training set, sections 21-22 as test set, and sections 0-1 as development set for parameter optimization. For each relation, we randomly extracted the same number of positive and negative instances as training data, while all instances in sections 21 and 22 are used as our test set. The statistics of various data sets is listed in Table 1. We tokenized PDTB corpus using Stanford NLP Tool5. For </context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind K Joshi, and Bonnie L Webber. 2008. The penn discourse treebank 2.0. In Proc. of LREC. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Attapol Rutherford</author>
<author>Nianwen Xue</author>
</authors>
<title>Discovering implicit discourse relations through brown cluster pair representation and coreference patterns.</title>
<date>2014</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>645--654</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2179" citStr="Rutherford and Xue, 2014" startWordPosition="317" endWordPosition="320">al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neg</context>
<context position="10024" citStr="Rutherford and Xue (2014)" startWordPosition="1569" endWordPosition="1572"> the labeled data and unlabeled data. We extracted unlabeled data from above-mentioned 1.02M sentences. After filtering the noise ones, we finally obtained 0.11M unlabeled instances, each of which contains only two clauses. • RAE: This method learns a recursive autoencoder (RAE) classifier with the labeled data. We first utilized standard RAEs to represent arguments, and then stacked a Softmax layer upon them. The hyperparameters were set as follows: word dimension 64, balance factor for reconstruction error 0.10282 and regularization factor 1e−5. Word embeddings are initialized via Word2Vec. Rutherford and Xue (2014) show that Brown cluster pair feature is very impactful in implicit DRR (Rutherford and Xue, 2014). This feature is superior to one-hot representation for the interactions between two arguments, such as crossargument word pair features in our baseline methods. We therefore conducted two additional experiments for comparison: • Add-Bro: This method learns an SVM classifier using baseline system features along with the Brown cluster pair feature. • No-Cro: This method learns an SVM classifier on Add-Bro’s features without crossJ(0) = m m L t=1 2232 Relation Model Precision Recall Accuracy MacroF</context>
<context position="14498" citStr="Rutherford and Xue (2014)" startWordPosition="2301" endWordPosition="2304">tive results appeared in TSVM: COMP. and CONT. dropped 1.14% and 0.79% respectively7. The F1 scores of TEMP. and EXP. are improved (1.27% and 0.63% respectively). The main reason may be that our unlabeled data is not strictly from the discourse corpus. Incorporating Brown cluster pair features enhances the recognition of COMP. and CONT.. Particllarly, No-Cro achieves the best result in COMP. 34.22%. But we found no consistent improvement in EXP. and TEMP.: No-Cro loses 2.74% in TEMP.; Add-Bro loses 0.88% and 2.12% in EXP. and TEMP. respectively. This result is inconsistent with the finding of Rutherford and Xue (2014). The reason may lie in the training strategy, where we used sampling to solve the problem of unbalanced dataset while they reweighted training samples. Compared with SVM-based models, RAE performs poorly in three relations, except EXP. which has the largest training dataset. Maybe RAE needs more labeled training data for better results. However, SCNN models perform remarkably well, producing comparable and even better results. Without normalization, SCNN-NoNorm gains 0.57%, 2.98% and 3.1% F1 scores for CONT., EXP. and TEMP. respectively, but loses 2.11% for COMP.. We obtain further improvemen</context>
</contexts>
<marker>Rutherford, Xue, 2014</marker>
<rawString>Attapol Rutherford and Nianwen Xue. 2014. Discovering implicit discourse relations through brown cluster pair representation and coreference patterns. In Proc. of EACL, pages 645–654. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Eric H Huang</author>
<author>Jeffrey Pennin</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Dynamic pooling and unfolding recursive autoencoders for paraphrase detection.</title>
<date>2011</date>
<booktitle>In Proc. of NIPS,</booktitle>
<pages>801--809</pages>
<publisher>Curran Associates, Inc.</publisher>
<contexts>
<context position="2592" citStr="Socher et al., 2011" startWordPosition="378" endWordPosition="381">itler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neglect of this important domain may be due to the following two reasons: (1) discourse relation distribution is rather unbalanced, where the generalization of deep models is relatively insufficient despite their powerful studying ability; (2) training dataset in implicit DRR is relatively small, where overfitting problems become more prominent. In this paper, we propose a Shallow Convolutional Neural Network (SC</context>
<context position="5201" citStr="Socher et al., 2011" startWordPosition="786" endWordPosition="789"> based on convonlutional neural network. The overall model architecture is illustrated in Figure 1.1 In our model, each word in vocabulary V corresponds to a d-dimensional dense, real-valued vector, and all words are stacked into a word embedding matrix L E Rd×|V |, where |V |is the vocabulary size. Given an ordered list of n words in an argument, we retrieve the i-th word representation xvi E Rd from L with its corresponding vocabulary index vi. All word vectors in the argument produce the following output matrix: X = (xv1, xv2, ... , xvn) (1) Following previous work (Collobert et al., 2011; Socher et al., 2011a), for each row r in X, we explore three convolutional operations to obtain three convolution features average, min and max as follows: Xr,i (2) min cr =min (Xr,1, Xr,2, ... , Xr,n) (3) 1For better illustration, we assume that the dimension of word vectors is 4 throughout this paper. max cr = max (Xr,1, Xr,2, ... ,Xr,n) (4) In this way, SCNN is able to capture almost all important information inside X (one with the highest, lowest and average values). Besides, each convolution operation naturally deals with variable argument lengths (Note that c E Rd). Back to Figure 1, we present cavg, cmin </context>
</contexts>
<marker>Socher, Huang, Pennin, Manning, Ng, 2011</marker>
<rawString>Richard Socher, Eric H. Huang, Jeffrey Pennin, Christopher D Manning, and Andrew Y. Ng. 2011a. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Proc. of NIPS, pages 801–809. Curran Associates, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Cliff Chiung-Yu Lin</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing natural scenes and natural language with recursive neural networks.</title>
<date>2011</date>
<booktitle>In Proc. of ICML,</booktitle>
<pages>129--136</pages>
<publisher>Omnipress.</publisher>
<contexts>
<context position="2592" citStr="Socher et al., 2011" startWordPosition="378" endWordPosition="381">itler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neglect of this important domain may be due to the following two reasons: (1) discourse relation distribution is rather unbalanced, where the generalization of deep models is relatively insufficient despite their powerful studying ability; (2) training dataset in implicit DRR is relatively small, where overfitting problems become more prominent. In this paper, we propose a Shallow Convolutional Neural Network (SC</context>
<context position="5201" citStr="Socher et al., 2011" startWordPosition="786" endWordPosition="789"> based on convonlutional neural network. The overall model architecture is illustrated in Figure 1.1 In our model, each word in vocabulary V corresponds to a d-dimensional dense, real-valued vector, and all words are stacked into a word embedding matrix L E Rd×|V |, where |V |is the vocabulary size. Given an ordered list of n words in an argument, we retrieve the i-th word representation xvi E Rd from L with its corresponding vocabulary index vi. All word vectors in the argument produce the following output matrix: X = (xv1, xv2, ... , xvn) (1) Following previous work (Collobert et al., 2011; Socher et al., 2011a), for each row r in X, we explore three convolutional operations to obtain three convolution features average, min and max as follows: Xr,i (2) min cr =min (Xr,1, Xr,2, ... , Xr,n) (3) 1For better illustration, we assume that the dimension of word vectors is 4 throughout this paper. max cr = max (Xr,1, Xr,2, ... ,Xr,n) (4) In this way, SCNN is able to capture almost all important information inside X (one with the highest, lowest and average values). Besides, each convolution operation naturally deals with variable argument lengths (Note that c E Rd). Back to Figure 1, we present cavg, cmin </context>
</contexts>
<marker>Socher, Lin, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Cliff Chiung-Yu Lin, Andrew Y. Ng, and Christopher D. Manning. 2011b. Parsing natural scenes and natural language with recursive neural networks. In Proc. of ICML, pages 129–136. Omnipress.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>1631--1642</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2636" citStr="Socher et al., 2013" startWordPosition="386" endWordPosition="389">et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep learning work specifically for implicit DRR. The neglect of this important domain may be due to the following two reasons: (1) discourse relation distribution is rather unbalanced, where the generalization of deep models is relatively insufficient despite their powerful studying ability; (2) training dataset in implicit DRR is relatively small, where overfitting problems become more prominent. In this paper, we propose a Shallow Convolutional Neural Network (SCNN) for implicit DRR, with only one simple c</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proc. of EMNLP, pages 1631–1642. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzan Verberne</author>
<author>Lou Boves</author>
<author>Nelleke Oostdijk</author>
<author>Peter-Arno Coppen</author>
</authors>
<title>Evaluating discoursebased answer extraction for why-question answering.</title>
<date>2007</date>
<booktitle>In Proc. of SIGIR,</booktitle>
<pages>735--736</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1353" citStr="Verberne et al., 2007" startWordPosition="185" endWordPosition="189">near operations help preserve the recognition and generalization ability of our model. Experiments on the benchmark data set show that our model achieves comparable and even better performance when comparing against current state-of-the-art systems. 1 Introduction As a crucial task for discourse analysis, discourse relation recognition (DRR) aims to automatically identify the internal structure and logical relationship of coherent text (e.g., TEMPORAL, CONTINGENCY, EXPANSION, etc). It provides important information to many other natural language processing systems, such as question answering (Verberne et al., 2007), information extraction (Cimiano et al., 2005), machine translation (Guzm´an et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author</context>
</contexts>
<marker>Verberne, Boves, Oostdijk, Coppen, 2007</marker>
<rawString>Suzan Verberne, Lou Boves, Nelleke Oostdijk, and Peter-Arno Coppen. 2007. Evaluating discoursebased answer extraction for why-question answering. In Proc. of SIGIR, pages 735–736. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
</authors>
<title>Subgraph-based classification of explicit and implicit discourse relations.</title>
<date>2013</date>
<booktitle>In Proc. of IWCS,</booktitle>
<pages>264--275</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2129" citStr="Versley, 2013" startWordPosition="310" endWordPosition="311">onnectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al., 2013; Kim, 2014). However, to the best of our knowledge, there is little deep le</context>
</contexts>
<marker>Versley, 2013</marker>
<rawString>Yannick Versley. 2013. Subgraph-based classification of explicit and implicit discourse relations. In Proc. of IWCS, pages 264–275. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xun Wang</author>
<author>Sujian Li</author>
<author>Jiwei Li</author>
<author>Wenjie Li</author>
</authors>
<title>Implicit discourse relation recognition by selecting typical training examples.</title>
<date>2012</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>2757--2772</pages>
<contexts>
<context position="2048" citStr="Wang et al., 2012" startWordPosition="294" endWordPosition="297">et al., 2014) and so on. Despite great progress in explicit DRR where the discourse connectives (e.g., “because”, “but” et al.) explicitly exist in the text (Miltsakaki et al., 2005; Pitler et al., 2008), implicit DRR remains a serious challenge because of the absence of discourse connectives (Prasad et al., 2008). Conventional methods for implicit DRR directly rely on feature engineering, wherein researchers generally exploit various hand-crafted features, such as words, part-of-speech tags and ∗Corresponding author production rules (Pitler et al., 2009; Lin et al., 2009; Louis et al., 2010; Wang et al., 2012; Park and Cardie, 2012; McKeown and Biran, 2013; Lan et al., 2013; Versley, 2013; Braud and Denis, 2014; Rutherford and Xue, 2014). Although these methods have proven successful, these manual features are labor-intensive and weak to capture intentional, semantic and syntactic aspects that govern discourse coherence (Li et al., 2014), thus limiting the effectiveness of these methods. Recently, deep learning models have achieved remarkable results in natural language processing (Bengio et al., 2003; Bengio et al., 2006; Socher et al., 2011b; Socher et al., 2011a; Socher et al., 2013; Li et al.,</context>
</contexts>
<marker>Wang, Li, Li, Li, 2012</marker>
<rawString>Xun Wang, Sujian Li, Jiwei Li, and Wenjie Li. 2012. Implicit discourse relation recognition by selecting typical training examples. In Proc. of COLING, pages 2757–2772.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>