<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.988">
Improving Semantic Parsing with Enriched Synchronous Context-Free
Grammar
</title>
<author confidence="0.981458">
Junhui Li&apos; Muhua Zhu2 Wei Lu3 Guodong Zhou&apos;
</author>
<affiliation confidence="0.902279">
&apos;Natural Language Processing Lab, Soochow University, China
</affiliation>
<email confidence="0.678602">
{lijunhui, gdzhou}@suda.edu.cn
</email>
<affiliation confidence="0.982259">
2 Alibaba Inc., Hangzhou, China
muhua.zmh@alibaba-inc.com
3 Information Systems Technology and Design,
Singapore University of Technology and Design
</affiliation>
<email confidence="0.994942">
luwei@sutd.edu.sg
</email>
<sectionHeader confidence="0.993828" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99980925">
Semantic parsing maps a sentence in natu-
ral language into a structured meaning rep-
resentation. Previous studies show that se-
mantic parsing with synchronous context-
free grammars (SCFGs) achieves favor-
able performance over most other alter-
natives. Motivated by the observation
that the performance of semantic pars-
ing with SCFGs is closely tied to the
translation rules, this paper explores ex-
tending translation rules with high qual-
ity and increased coverage in three ways.
First, we introduce structure informed
non-terminals, better guiding the parsing
in favor of well formed structure, instead
of using a uninformed non-terminal in
SCFGs. Second, we examine the differ-
ence between word alignments for seman-
tic parsing and statistical machine transla-
tion (SMT) to better adapt word alignment
in SMT to semantic parsing. Finally, we
address the unknown word translation is-
sue via synthetic translation rules. Eval-
uation on the standard GeoQuery bench-
mark dataset shows that our approach
achieves the state-of-the-art across various
languages, including English, German and
Greek.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998310285714286">
Semantic parsing, the task of mapping natural
language (NL) sentences into a formal meaning
representation language (MRL), has recently re-
ceived a significant amount of attention with vari-
ous models proposed over the past few years. Con-
sider the NL sentence paired with its correspond-
ing MRL in Figure 1(a). Semantic parsing can be
</bodyText>
<figure confidence="0.8901455">
NL: What is the area of Seattle
MRL: answer(area_1(cityid(‘seattle’, _)))
(a) before pre-processing
NL’: what be the area of seattle
MRL’: answer@1 area_1@1 cityid@2 seattle@s _@0
(b) after pre-processing
</figure>
<figureCaption confidence="0.999995">
Figure 1: Example of a sentence pair in NL and MRL.
</figureCaption>
<bodyText confidence="0.999969428571429">
naturally viewed as a statistical machine transla-
tion (SMT) task, which translates a sentence in NL
(i.e., the source language in SMT) into its mean-
ing representation in MRL (i.e., the target lan-
guage in SMT). Indeed, many attempts have been
made to directly apply statistical machine transla-
tion (SMT) systems (or methodologies) to seman-
tic parsing (Papineni et al., 1997; Macherey et al.,
2001; Wong and Mooney, 2006; Andreas et al.,
2013). However, although recent studies (Wong
and Mooney, 2006; Andreas et al., 2013) show that
semantic parsing with SCFGs, which form the ba-
sis of most existing statistical syntax-based trans-
lation models (Yamada and Knight, 2001; Chiang,
2007), achieves favorable results, this approach is
still behind the most recent state-of-the-art. For
details, please see performance comparison in An-
dreas et al. (2013) and Lu (2014).
The key issues behind the limited success of ap-
plying SMT systems directly to semantic parsing
lie in the difference between semantic parsing and
SMT: MRL is not a real natural language with
different properties from natural language. First,
MRL is machine-interpretable and thus strictly
structured with the meaning representation in a
nested structure of functions and arguments. Sec-
ond, the two languages are intrinsically asymmet-
ric since each token in MRL carries specific mean-
</bodyText>
<page confidence="0.923703">
1455
</page>
<note confidence="0.9847305">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1455–1465,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999409771428571">
ing1 while this does not hold in NL since auxil-
iary words and some function words usually have
no counterparts in MRL. Third and finally, the ex-
pressions in NL are more flexible with respect to
lexicon selection and token ordering. For exam-
ple, since sentences in NL ‘could you tell me the
states that utah borders’, ‘what states does utah
border’, and ‘utah borders what states’ convey the
same meaning, they should have the same expres-
sion in MRL.
Motivated by the above observations, we be-
lieve that semantic parsing with standard SMT
components is not an ideal approach. Alterna-
tively, this paper proposes an effective, yet simple
way to enrich SCFG in hierarchical phrase-based
SMT for better semantic parsing. Specifically,
since the translation rules play a critical role in
SMT, we explore to improve translation rule qual-
ity and increase its coverage in three ways. First,
we enrich non-terminal symbols as to capture con-
textual and structured information. The enrich-
ment of non-terminal symbols not only guides the
translation in favor of well formed structures, but
also is beneficial to translation. Second, we ex-
amine the difference between word alignments for
semantic parsing and SMT to better adapt word
alignment in SMT to semantic parsing. Third,
unlike most existing SMT systems that keep un-
known words untranslated and intact in transla-
tion, we exploit the translation of unknown words
via synthetic translation rules. Evaluation on Geo-
Query benchmark dataset shows that our approach
obtains consistent improvement and achieves the
state-of-the-art across various languages, includ-
ing English, German and Greek.
</bodyText>
<sectionHeader confidence="0.9507475" genericHeader="method">
2 Background: Semantic Parsing as
Statistical Machine Translation
</sectionHeader>
<bodyText confidence="0.9997537">
In this section, we present the framework of
semantic parsing as SMT, which was proposed
in Andreas et al. (2013).
Pre-Processing Various semantic formalisms
have been considered for semantic parsing. Ex-
amples include the variable-free semantic repre-
sentations (that is, the meaning representation for
each utterance is tree-shaped), the lambda calculus
expressions, and dependency-based compositional
semantic representations. In this work, we specifi-
</bodyText>
<footnote confidence="0.738726333333333">
1As seen in Section 2, delimiters, including parentheses
and commas which do not carry any meaning will be removed
in pre-processing and be recovered in post-processing
</footnote>
<bodyText confidence="0.999712153846154">
cally focus on the variable-free semantic represen-
tations, as shown in Figure 1. On the target side,
we convert these meaning representations to series
of strings similar to NL. To do so, we simply take a
preorder traversal of every functional form, and la-
bel every function with the number of arguments
it takes. Figure 1(b) shows an example of con-
verted meaning representation, where each token
is in the format of A@B where A is the symbol
while B is either s indicating that the symbol is
a string or a number indicating the symbol’s arity
(constants, including strings, are treated as zero-
argument functions).
On the source side, we perform stemming (for
English and German) and lowercasing to over-
come data sparseness.
Hereafter, we refer to the pre-processed NL and
MRL as NL&apos; and MRL&apos; respectively.
Translation Given a corpus of NL&apos; sentences
paired with MRL&apos;, we learn a semantic parser
by adopting a string-to-string translation system.
Typical components in such a translation system
include word alignments between the source and
the target languages, translation rule extraction,
language model learning, parameter tuning and
decoding. For more details about each component,
please refer to (Chiang, 2007). In the rest of this
paper, we refer to the source language (side) as
NL&apos;, and the target language (side) as MRL&apos;.
Post-Processing We convert MRL&apos; back into
MRL by recovering parentheses and commas to
reconstruct the corresponding tree structure in
MRL. This can be easily done by examining each
symbol’s arity. It eliminates any possible ambi-
guity from the tree reconstruction: given any se-
quence of tokens in MRL&apos;, we can always recon-
struct the tree structure (if one exists). For those
translations that can not be successfully converted,
we call them illformed translations.
</bodyText>
<sectionHeader confidence="0.974222" genericHeader="method">
3 Semantic Parsing with Enriched SCFG
</sectionHeader>
<bodyText confidence="0.9601505">
In this section, we present the details of our en-
riched SCFG for semantic parsing.
</bodyText>
<subsectionHeader confidence="0.995588">
3.1 Enriched SCFG
</subsectionHeader>
<bodyText confidence="0.999927">
In hierarchical phrase-based (HPB) translation
models, synchronous rules take the form X →
(-y, α, —), where X is the non-terminal sym-
bol, -y and α are strings of lexical items and
non-terminals in the source and target side re-
spectively, and — indicates the one-to-one cor-
</bodyText>
<page confidence="0.987326">
1456
</page>
<bodyText confidence="0.998439042553191">
respondence between non-terminals in γ and α.
From an aligned phrase pair &lt;state that border,
state@1 next to 2@1&gt; in Figure 2(a), for ex-
ample, we can get a synchronous rule X —*
state X1 , state@1 X1 ), where we use boxed in-
dices to indicate which nonterminal occurrences
are linked by —. The fact that SCFGs in HPB mod-
els contain only one type of non-terminal symbol2
is responsible for ill-formed translation (e.g., an-
swer@1 state@1). To this end, we enrich the non-
terminals to capture the tree structure information,
guiding the translation in favor of well-formed
translations. The enrichment of non-terminals is
two-fold: first, it can handle MRL with a nested
structure to guarantee the well-formed transla-
tions; second, related studies in SMT have shown
that introducing multiple non-terminal symbols in
SCFGs benefits translation (Zollmann and Venu-
gopal, 2006; Li et al., 2012).
Given a word sequence eij from position i to
position j in MRL&apos;, we enrich the non-terminal
symbol X to reflect the internal structure of the
word sequence of eij . A correct translation rule
selection therefore not only maps source termi-
nals into target terminals, but is both constrained
and guided by structure information in the non-
terminals. As mentioned earlier, we regard the
nested structure in MRL&apos; as function-argument
structure, where each function takes one or more
arguments as input while its return serves as an ar-
gument to the outside function. As in Figure 1,
function cityid holds two arguments and returns as
an argument to function area 1. For a word se-
quence eij, we examine its completeness, which is
defined as:
Definition 1. For word sequence eij, it is regarded
as complete if it satisfies 1) every function (if ex-
ists) meets its argument requirement; and 2) it can
serve as one argument to another function.
We use symbol C to label word sequences
which are complete. For an incomplete word se-
quence, we examine 1) the number of arguments
it requires on the right to be complete; and 2)
the arity of a function it requires on the left to
be complete. Then the sequence is labeled as
(C\Fm)/An, indicating it requires n arguments on
the right and a function with m arities on the left. 3
</bodyText>
<footnote confidence="0.992054">
2In practice, non-terminal symbol S is used in glue rules.
However, this is not relevant in the present discussion.
3This is similar to the naming convention in combinatory
categorial grammar (CCG) (Steedman, 2000)
</footnote>
<equation confidence="0.7177695">
texas, stateid@1 texas@s
C--+ (texas, stateid@1 texas@s)
seattle, seattle@s @0
C\F2--+ (seattle, seattle@s @0)
that border, next to 2@1
C/A1--+ (that border, next to 2@1)
</equation>
<bodyText confidence="0.233859">
state that border, state@1 next to 2@1
</bodyText>
<figure confidence="0.790523">
D E
C/A1--+ state C/A1 1 , state@1 C/A1 1
(a) Examples of phrase pairs in enriched SCFG.
state that✿✿✿✿✿✿ ✿✿border , state @ 1 next to 2 @ 1
C/A1--+ DC/A1 1 C/A1 2 , C/A1 1 C/A1 2 E
state that border ✿✿✿✿
texas ✿✿✿✿
have ✿✿
the✿✿✿✿✿✿ highest✿✿✿✿✿✿✿✿population,
L. one@1 p.. 1@1 state@1 n..@1 s..@1 t..@s
D E
C--+ C1 C/A1 2 , C/A1 2 C 1
(b) Examples of glue rules in enriched SCFG.
</figure>
<tableCaption confidence="0.957125">
Table 1: Example of translation rules in enriched SCFG,
</tableCaption>
<bodyText confidence="0.984709303030303">
where underline and ✿✿✿✿✿✿✿✿
underwave indicate the first and the sec-
ond phrases respectively.
Specifically, we omit \Fm and /An if m = 0 and
n = 0 respectively.4
Table 1(a) demonstrates examples of phrase
pairs in our enriched SCFG. For instance, word
sequence stateid@1 texas@s is complete, and thus
labeled as C. Similarly, to be complete, word se-
quence next to 2@1 requires one argument on the
right side, labeled as C/A1 accordingly.
When extracting translation rules from aligned
datasets, we follow Chiang (2007) except that
we use enriched non-terminal symbols rather than
X. Each translation rule is associated with a
set of translation model features fφil, including
phrase translation probability p (α  |γ) and its in-
verse p (γ  |α), the lexical translation probability
plex (α  |γ) and its inverse plex (γ  |α), and a rule
penalty that learns the preference for longer or
shorter derivations.
Inverted Glue Rules In SMT decoding (Chiang,
2007), if no rule (e.g., a rule whose left-hand side
is X) can be applied or the length of the poten-
tial source span is larger than a pre-defined length
(e.g., 10 as in Chiang (2007)), a glue rule (either
S —* �X1 , X1) or S —* �S1 X2 , S1 X2)) will
be used to simply stitch two consequent translated
phrases together in a monotone way. Although
this will reduce computational and modeling chal-
lenges, it obviously prevents some reasonable
translation derivations because in certain cases,
the order of phrases may be inverted on the target
</bodyText>
<footnote confidence="0.725222">
4If m = 0, it indicates that no function is needed.
</footnote>
<page confidence="0.972377">
1457
</page>
<bodyText confidence="0.999906818181818">
side. In this work, we additionally use an inverted
glue rule which combines two non-terminals in
a swapped way. Each glue rule, either straight
or inverted, contains only two non-terminal sym-
bols and is associated with two features, includ-
ing phrase translation probability p (α  |γ), and a
glue rule penalty. Table 1(b) shows examples of
a straight and an inverted glue rules. Moreover,
these glue rules can be applied to any two neigh-
boring translation nodes if the non-terminal sym-
bols are matched.
</bodyText>
<subsectionHeader confidence="0.999602">
3.2 Word Alignment for Semantic Parsing
</subsectionHeader>
<bodyText confidence="0.960894383720931">
Word alignment is an essential step for rule ex-
traction in SMT, where recognizing that wo shi in
Chinese is a good translation for I am in English
requires establishing a correspondence between
wo and I, and between shi and am. In the SMT
community, researchers have developed standard,
proven alignment tools such as GIZA++ (Och and
Ney, 2003), which can be used to train IBM Mod-
els 1-5. However, there is one fundamental prob-
lem with the IBM models (Brown et al., 1993):
each word on one side can be traced back to ex-
actly one particular on the other word (or the null
token which indicates the word aligns to no word
on the other side). Figure 2(a) shows an example
of GIZA++ alignment output from source side to
target side, from which we can see that each source
word aligns to exactly one target word. While
alignment of multiple target words to one source
word is common in SMT, a trick is then to run
IBM model training in both directions. Then two
resulting word alignments can be symmetrized, for
instance, taking the intersection or the union of
alignment points of each alignment. For example,
Figure 2(b) shows GIZA++ alignment output from
target side to source side while Figure 2(c) shows
the symmetrization result with widely used grow-
diag-final-and strategy.
Although symmetrization of word alignments
works for SMT, can it be applied to semantic pars-
ing? There are reasons to be doubtful. Word align-
ment for semantic parsing differs from alignment
for SMT in several important aspects, at least in-
cluding:
1. It is intrinsically asymmetric: within the se-
mantic formalism used in this paper, NL&apos; is
often longer than MRL&apos;, and commonly con-
tains words which have no counterpart in
MRL&apos;.
2. Little training data is available. SMT align-
ment models are typically trained in unsu-
pervised fashion, inducing lexical correspon-
dences from massive quantities of sentence-
aligned bitexts.
Consequently, the symmetrization of word align-
ments may not work perfectly for semantic pars-
ing. According to word alignment in Figure 2(c),
a phrase extractor will generate a phrase pair
(have the highest, largest one@1), which is non-
intuitive. By contrast, a more useful and general
phrase pair (highest, largest one@1) is typically
excluded because largest one@1 aligns to all of
have, the, and highest. Similarly, another useful
phrase pair (texas, texas@s) is prohibited since
texas aligns to both stateid@1 and texas@s.
Ideally a new semantic parsing aligner should
be able to capture the semantic equivalence. Un-
fortunately we are not aware of any research on
alignment for semantic parsing, possibly due to
lack of a paucity of high quality, publicly avail-
able data from which to learn. Instead of de-
veloping new alignment algorithm for semantic
parsing, we make use of all the alignments as
shown in Figure 2. That is to say, we triple
the training data with each sentence pair having
three alignments, i.e., two alignments in both di-
rections, and the symmetrization alignment.5 The
advantages include: first, considering more pos-
sible alignments would increase the phrase cov-
erage, especially when the training data is little;
second, including the alignment from both direc-
tions would alleviate the error propagation caused
by mis-aligned stop words (e.g., be, the in NL&apos; and
stateid@1 in MRL&apos;). As a result, the phrase ex-
tractor will include phrase pairs of both (highest,
largest one@1) and (texas, texas@s). Our exper-
iment shows that using the combination of all the
three alignments achieve better performance than
using any one, or any combination of two. More-
over, we found that we could achieve comparable
performance even with manual alignment.
5Combining multiple alignments from different alignment
models usually improves translation performance in SMT (Tu
et al., 2012). However, our preliminary experiments showed
that this did not yield higher improvement in semantic pars-
ing, which in turn also demonstrates the difference in align-
ments for semantic parsing and SMT.
</bodyText>
<page confidence="0.965858">
1458
</page>
<figure confidence="0.959341666666667">
(a) word alignment from source to target direction
(b) word alignment from target to source direction
(c) symmetrization of word alignment using grow-diag-final-and strategy
</figure>
<figureCaption confidence="0.999153">
Figure 2: Example of a sentence pair with different alignments.
</figureCaption>
<table confidence="0.94077052631579">
what state that border
texas
have the highest
population
answer@1 largest_one@1
population_1@1 state@1 next_to_2@1 stateid@1 texas@s
what state that border
texas
have the
highest
population
answer@1 largest_one@1
population_1@1 state@1 next_to_2@1 stateid@1 texas@s
what state that border
have the highest
population
texas
answer@1 largest_one@1
population_1@1 state@1 next_to_2@1 stateid@1 texas@s
</table>
<subsectionHeader confidence="0.898966">
3.3 Synthetic Translation Rules for Unknown
Word Translation
</subsectionHeader>
<bodyText confidence="0.965549482758621">
Most NLP tasks face the problem of unknown
words, especially if only little training data is
available. For example, it is estimated that 5.7%
sentences in the (English) test data in our exper-
iments have unknown words. Unknown words
usually remain intact in the translation in most
machine translation systems (Koehn et al., 2007;
Dyer et al., 2010), resulting in the fact that cer-
tain translations can not be converted back to tree
structures. This indicates that in semantic pars-
ing the translation of a word can be from two cat-
egories: 1) a token in MRL; or 2) null (i.e., not
translated at all), we generate synthetic translation
rules for unknown word translation.
As a baseline, we simply skip unknown words
as Kwiatkowski et al. (2010) by adding translation
rules that translate them to null in MRL&apos;. Each
such rule is accompanied with one feature indicat-
ing that it is a translation rule for unknown word.
Alternatively, taking advantage of publicly
available resources, we generate synthetic trans-
lation rules for unknown words pivoted by their
semantically close words. Algorithm 1 illustrates
the process to generate synthetic translation rules
for unknown word translation. Given an unknown
word wu, it generates its synthetic rules in two
steps: 1) finding top n (e.g., 5 as in our experi-
ments) close words via Word2Vec;6 and 2) gener-
ating synthetic translation rules based on the close
</bodyText>
<footnote confidence="0.9897392">
6It is available at http://code.google.com/p/word2vec/.
We use Word2Vec rather than other linguistic resources like
WordNet because the approach can be easily adopted to other
languages only if there exists large monolingual data to train
Word2Vec models.
</footnote>
<table confidence="0.668200428571429">
Algorithm 1: Generating synthetic translation
rules for unknown words
Input: Unknown word wu in the source language
Source side training data vocabulary: W
Lexical translation tables T1 and T2 (two
directions)
Output: Synthetic translation rule set R for wu
</table>
<listItem confidence="0.963604666666667">
1. foreach word wi in W
2. si = sim(wu, wi)
3. get the top n words WB = {wb1...wbn}
with the highest {si}
4. R = φ
5. foreach wbi in WB
6. foreach tj such (wbi, tj) in T1 and T2
7. R U = generate rule(wu, wbi, tj, T1, T2)
8. return R
</listItem>
<bodyText confidence="0.915659727272727">
sim: returns the similarity between wu and wi.
generate rule: returns rule (wu, tj) with a feature
indicating the similarity between wu and wbi, and
two features indicating the lexical translation prob-
abilities from wbi to tj and the way around.
words. Note that it may generate a synthetic rule
with null at the target side since the lexical transla-
tion table derived from aligned training data con-
tains translation to null. Each synthetic translation
rule for unknown words is associated with three
features returned from function generate rule.
</bodyText>
<sectionHeader confidence="0.999182" genericHeader="method">
4 Experimentation
</sectionHeader>
<bodyText confidence="0.9993285">
In this section, we test our approach on the Geo-
Query dataset, which is publicly available.
</bodyText>
<subsectionHeader confidence="0.969698">
4.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.9713506">
Data GeoQuery dataset consists of 880 questions
paired with their corresponding tree structured se-
mantic representations. Following the experimen-
tal setup in Jones et al. (2012), we use the 600
question pairs to train and tune our SMT de-
</bodyText>
<page confidence="0.981927">
1459
</page>
<bodyText confidence="0.971959254901961">
coder, and evaluated on the remaining 280. Note
that there is another version of GeoQuery dataset
where the semantic representation is annotated
with lambda calculus expressions and which is ex-
tensively studied (Zettlemoyer and Collins, 2005;
Wong and Mooney, 2007; Liang et al., 2011;
Kwiatkowski et al., 2013). Performance on the
version of lambda calculus is higher than that on
the tree structured version, however, the results ob-
tained over the two versions are not directly com-
parable.
SMT Setting We use cdec (Dyer et al., 2010) as
our HPB decoder. As mentioned above, 600 in-
stances are used to train and tune our decoder. To
get fair results, we split the 600 instances into 10
folds, each having 60 instances. Then for each
fold, we use it as the tuning data while the other
540 instances and the NP list are used as train-
ing data.7 We use IRSTLM toolkit (Federico et
al., 2008) to train a 5-gram LM on the MRL&apos; side
of the training data, using modified Kneser-Ney
smoothing. We use Mira (Chiang et al., 2008)
to tune the parameters of the system to maximize
BLEU (Papineni et al., 2002). When extracting
translation rules from aligned training data, we in-
clude both tight and untight phrases.
Evaluation We use the standard evaluation crite-
ria for evaluation by executing both the predicted
MRL and the gold standard against the database
and obtaining their respective answer. Specifi-
cally, we convert a translation from MRL&apos; into
MRL (if exists). The translation then is consid-
ered correct if and only if its MRL retrieves the
same answers as the gold standard MRL (Jones et
al., 2012), allowing for a fair comparison between
our systems and previous works. As in Jones et
al. (2012), we report accuracy, i.e. the percent-
age of translations with correct answers, and F1,
i.e. the harmonic mean of precision (the propor-
tion of correct answers out of translations with an
answer) and recall (the proportion of correct an-
swers out of all translations). In this section, we
report our performance scores and analysis num-
bers averaged on our 10 SMT models.
7The NP list is from GeoQUery dataset in Jones et al.
(2012), which contains MRs for every noun phrase that ap-
pears in the NL utterances of each language. As in Andreas
et al. (2013), the NP list is included by appending all entries
as extra training sentences with 50 times the weight of regular
training examples, to ensure that they are learned as transla-
tion rules.
</bodyText>
<table confidence="0.999655117647059">
SCFG alignment Acc. F1
src2tgt 75.0 82.5
tgt2src 78.5 82.5
non-enriched gdfa 77.5 83.5
src2tgt + tgt2src 81.4 85.0
src2tgt + gdfa 77.1 83.1
tgt2src + gdfa 80.6 83.9
all 81.5 85.2
gold 82.4 86.2
src2tgt 76.3 82.9
tgt2src 82.0 85.2
enriched gdfa 78.9 83.9
src2tgt + tgt2src 82.6 85.9
src2tgt + gdfa 78.8 83.7
tgt2src + gdfa 83.1 86.1
all 82.9 86.1
gold 84.1 87.1
</table>
<tableCaption confidence="0.953644">
Table 2: Performance of our (non-) enriched
SCFG systems with different alignment settings.
</tableCaption>
<subsectionHeader confidence="0.961314">
4.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.99948996875">
Table 2 shows the results of (non-) enriched SCFG
systems over different alignment settings. In Ta-
ble 2, src2tgt and tgt2src indicate alignment of
source to target direction and alignment of tar-
get to source direction, respectively; gdfa indi-
cates symmetrization of alignment with grow-
diag-final-and strategy; src2tgt+tgt2src indicates
doubling the training data with each sentence pair
having both src2tgt and tgt2src alignments, sim-
ilar for src2tgt+gdfa and tgt2src+gdfa; all indi-
cates tripling the training data with each sentence
pair having three alignments. Finally, gold indi-
cates using gold alignment. 8
Effect of Enriched SCFG From Table 2, we
observe that enriched SCFG systems outperform
non-enriched SCFG systems over all alignment
settings, indicating the effect of enriching non-
terminals. In particular for tgt2src alignment, it
obtains improvements of 3.5% in accuracy and
2.7% in F1.
As mentioned earlier, the non-enriched SCFG
system may result in ill-formed translations,
which can not be converted back to tree struc-
ture. One natural way to overcome this issue,
as in Andreas et al. (2013), would be to simply
filter n-best translation till a well-formed one is
found. However, we see very limited performance
changes in accuracy and F1, suggesting that the ef-
fect of using n-best translation is very limited. For
example, after using n-best translation, the non-
enriched SCFG system with all alignment obtains
82.0 in accuracy (increased from 81.5) and 84.5 in
</bodyText>
<footnote confidence="0.990292">
8We manually aligned sentence pairs in NL&apos; and MRL&apos;.
</footnote>
<page confidence="0.977692">
1460
</page>
<figure confidence="0.925899695652174">
wrong
correct
6
53
correct
wrong
211
10
non-enriched + gdfa
alignment Rec. Pre. F1
src2tgt 96.3 68.8 80.3
tgt2src 90.0 77.0 83.0
gdfa 95.1 62.7 75.6
Table 3: Alignment performance.
enriched + gdfa
correct
wrong
215
6
enriched + all
17
42
F1 (reduced from 85.2).
</figure>
<bodyText confidence="0.913950333333333">
Effect of Word Alignment With respect to the
performance over different alignment settings, we
have the following observations from Table 2:
</bodyText>
<listItem confidence="0.932713625">
• Semantic parsing is substantially sensitive
to alignment. Surprisingly, gdfa alignment,
which is widely adopted in SMT, is inferior
to tgt2src alignment. As expected, src2tgt
alignment achieves the worst performance.
• Thanks to the increased coverage, dou-
bling the training data (e.g., rows
of src2tgt+tgt2src, src2tgt+gdfa, and
tgt2src+gdfa) usually outperforms its cor-
responding single alignment. Moreover,
tripling the training data (e.g., rows of all)
achieves slightly better performance than
any way of doubling the training data. This
is expected since the gdfa alignment actually
comes from the alignments of src2tgt and
tgt2src, thus doubling the training with
src2tgt and tgt2src have already included
most aligns in gdfa alignment.
• Our approach of tripling the training data
achieves comparable performance to the one
with gold alignment, suggesting that instead
of developing a brand new algorithm for se-
mantic parsing alignment, we can simply
make use of GIZA++ alignment output.
</listItem>
<bodyText confidence="0.999882866666667">
In terms of the src2tgt, tgt2src and gdfa align-
ments, the trend of the results is consistent over
both non-enriched and enriched SCFG systems:
the systems with tgt2src alignment work best
while the systems with src2tgt alignment work
worst. Next we look at the non-enriched SCFG
systems to explore the behavior differences among
the three alignments.
We examine the alignment accuracy against the
gold alignment on training data (except the NP list
part). As shown in Table 3, src2tgt has the high-
est recall while tgt2src has the highest precision.
This is partly due to: 1) In src2tgt alignment, each
source word aligns to exactly one particular tar-
get word (or the null token), resulting in frequent
</bodyText>
<tableCaption confidence="0.6328">
Table 4: Confusion matrices of three SMT systems
on English test sentences.
</tableCaption>
<bodyText confidence="0.993473375">
alignment errors for source side words that have
no counterpart in target side. For example, both
words of the and be on source side, which play
functional roles in NL, rather than semantic roles,
align to 15 different target words. 2) Except for
a few words on target side, including stateid@1,
all@0 which have strong occurrence patterns (e.g.,
stateid@1 is always followed by a state name),
each word has counterpart on source side.
As to have a clearer understanding on the
individual contribution of using enriched non-
terminals and multiple word alignments, Table 4
presents two confusion matrices which show num-
bers of sentences that are correctly/wrongly parsed
by three SMT systems on English test sentences.
It shows that, for example, 211 sentences are cor-
rectly parsed by both non-enriched and enriched
SCFG systems with gdfa alignment. Moving
from performance of the non-enriched SMT sys-
tem with gdfa alignment to that of the enriched
SMT system with all alignment, we observe that
on average more than half of the improvement
comes from using multiple word alignments, the
rest from using enriched non-terminals.
</bodyText>
<subsectionHeader confidence="0.656573">
Effect of Unknown Word Translation Since
</subsectionHeader>
<bodyText confidence="0.999950888888889">
each of our SMT model is actually trained on 540
instances (plus the NP list), the rate of unknown
words in the test data tends to be higher than that
in a system trained with the whole 600 instances.
Based on the system of enriched SCFG with all
alignment, Table 5 shows the results of applying
unknown word translation. It shows that translat-
ing all unknown words into null obtains 2.4 points
in accuracy over the system without it (e.g., 85.3
vs. 82.9). However, the slight improvement in F1
(e.g., 86.3 vs. 86.1) suggests that there are many
scenarios that translating unknown words into null
is incorrect. Fortunately, our semantic approach is
partially able to generate correct translation rules
for those unknown words which have translation
in MRL&apos;. Actually, the effect of our approach is
highly dependent on the quality of the close words
found via Word2Vec. With a manual examination
</bodyText>
<page confidence="0.964339">
1461
</page>
<table confidence="0.999558">
System Acc. F1
No unknown word translation 82.9 86.1
null: baseline 85.3 86.3
semantic: ours 86.3 87.1
</table>
<tableCaption confidence="0.999938">
Table 5: Performance with unknown word translation.
</tableCaption>
<bodyText confidence="0.999396302325581">
on the test data, we found that 11 out of all 17
unknown words should be translated into a corre-
sponding token in MRL. For 8 of them, the syn-
thetic translation rule set returned by Algorithm 1
contains correct translation rules.
Effect across Different Languages We have also
tested our approach on the same dataset with other
three languages. Specifically, while we are not
aware of public resources to looking for seman-
tically close words in German, Greek and Thai,
we translate unknown words into null for the three
languages. Table 6 shows the performance over
four different languages. It shows that our ap-
proach, including enriched SCFG, tripling train-
ing data with three alignments, and unknown word
translation, obtains consistent improvement over
the four languages.
Decoding Time Analysis We analyze the effect
on the decoding time of our approach, which is
closely related to the size of phrase tables. Firstly,
splitting non-terminal X into enriched ones in-
creases the size of phrase tables. 9 This is not
surprising since a phrase with non-terminal X
(e.g., the X on the source side) may be further
specified as multiple phrases with various non-
terminals (e.g., the C, the C/A1, etc.). As a re-
sult, the average number of phrases per sentence
(in English test data, hereafter) increases from 453
to 893 while the decoding time of the SMT de-
coder increases from 0.11 seconds to 0.19 seconds
per sentence on average. Secondly, using multiple
alignments also leads to larger phrase tables. This
is illustrated by the increase of average number of
phrases per sentence from 893 to 2055 while the
decoding time moves from 0.19 seconds to 0.38
seconds per sentence on average. Finally, finding
similar words via Word2Vec, however, is quite fast
since this is bounded by the vocabulary size of our
training set. Thanks to the small size of unknown
words, adding unknown word translation rules has
a very limited impact on the size of phrase ta-
ble, consequently negligible changes on decoding
time.
</bodyText>
<footnote confidence="0.800907">
9In cdec, we generate a phrase table for each sentence.
</footnote>
<sectionHeader confidence="0.997771" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99471876">
While there has been substantial work on seman-
tic parsing, we focus our discussions on several
approaches (e.g., SCFG approach, hybrid tree ap-
proach, and others approaches) that focus on the
variable-free semantic representations.
WASP (Wong and Mooney, 2006) was strongly
influenced by SMT techniques. Although WASP
was also using multiple non-terminal symbols in
SCFG to guarantee well-formed translations, our
work differs from theirs in at least three ways.
First, we use a different inventory of non-terminal
symbols from theirs which was derived from MRL
parses in the GeoQuery dataset. Second, to avoid
the issues caused by word alignment between NL
and MRL, we triple training data with each sen-
tence pair having multiple alignments. However,
WASP used a sequence of productions to repre-
sent MRL before running GIZA++. Third, we use
typical features in HPB SMT (e.g., phrase transla-
tion probabilities, lexical translation probabilities,
language model feature, etc.) while WASP used
rule identity features. SMT-SemParse (Andreas et
al., 2013) adapted standard SMT components for
semantic parsing. The present work is based on
theirs with all the extensions detailed in Section 3.
HYBRIDTREE+ (Lu et al., 2008) learned a
synchronous generative model which simultane-
ously generated a NL sentence and an MRL tree.
tsVB (Jones et al., 2012) used tree transducers,
which were similar to the hybrid tree structures, to
learn a generative process under a Bayesian frame-
work. RHT (Lu, 2014) defined distributions over
relaxed hybrid tree structures that jointly repre-
sented both sentences and semantics. Most re-
cently, f-RHT (Lu, 2015) introduced constrained
semantic forests to improve RHT model.
SCISSOR (Ge and Mooney, 2005) augmented
syntactic parse tree with semantic information and
then performed integrated semantic and syntac-
tic parsing to NL sentences. KRISP (Mooney,
2006) used string classifiers to label substrings of
an NL with entities from the meaning representa-
tion. UBL (Kwiatkowski et al., 2010) performed
semantic parsing with an automatically-induced
CCG lexicon.
Table 7 shows the evaluation results of our sys-
tem as well as those of several other compara-
ble related works which share the same experi-
ment setup as ours. We can observe from Table 7
that semantic parsing with SMT components gives
</bodyText>
<page confidence="0.970778">
1462
</page>
<table confidence="0.969941666666667">
System English German Greek Thai
Acc. F1 Acc. F1 Acc. F1 Acc. F1
non-enriched + gdfa 77.5 83.5 66.0 74.9 65.6 74.1 65.4 72.4
non-enriched + all 81.5 85.2 72.1 76.8 75.2 80.5 72.7 76.4
enriched + gdfa 78.9 83.9 66.7 74.6 67.8 76.1 68.5 74.1
enriched + all 82.9 86.1 75.4 79.5 76.5 81.2 75.2 77.9
enriched + all + unknown word translation 86.3 87.1 79.1 80.3 80.5 81.6 76.3 77.9
Table 6: Performance for the multilingual GeoQuery test set.
System English German Greek Thai
Acc. F1 Acc. F1 Acc. F1 Acc. F1
WASP 71.1 77.7 65.7 74.9 70.7 78.6 71.4 75.0
SMT-SemParse 80.5 81.8 68.9 71.8 69.1 72.3 70.4 70.7
HYBRIDTREE+ 76.8 81.0 62.1 68.5 69.3 74.6 73.6 76.7
tsVB 79.3 79.3 74.6 74.6 75.4 75.4 78.2 78.2
RHT 83.6 83.6 74.3 74.3 78.2 78.2 79.3 79.3
f-RHT 86.8 86.8 75.7 75.7 79.3 79.3 80.7 80.7
UBL 82.1 82.1 73.6 73.7 75.0 75.0 66.4 66.4
this work 86.3 87.1 79.1 80.3 80.5 81.6 76.3 77.9
</table>
<tableCaption confidence="0.8114885">
Table 7: Performance comparison for the multilingual GeoQuery test set. The performance of WASP,
HYBRIDTREE+, tsVB and UBL is taken from Jones et al. (2012).
</tableCaption>
<bodyText confidence="0.997177636363637">
competitive performance when all the extensions
(described in Section 3) are used. Specifically, it
significantly outperforms the semantic parser with
standard SMT components (Andreas et al., 2013).
Our approach reports the best accuracy and F1
scores on English, German, and Greek. While
we are able to obtain improvement on Thai, the
performance is still lower than those of RHT and
TREETRANS. This is probably because of the
low quality of word alignment output between this
Asian language and MRL.
</bodyText>
<sectionHeader confidence="0.996435" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999952">
In this paper, we have presented an enriched SCFG
approach for semantic parsing which realizes the
potential of the SMT approach. The performance
improvement is contributed from the extension of
translation rules with informative symbols and in-
creased coverage. Such an extension share a sim-
ilar spirit as generalization of a CCG lexicon for
CCG-based semantic parser (Kwiatkowski et al.,
2011; Wang et al., 2014). Experiments on bench-
mark data have shown that our model is competi-
tive to previous work and achieves state-of-the-art
performance across a few different languages.
Recently the research of semantic parsing in
open domain with weakly (or un-) supervised se-
tups, under different settings where the goal was to
optimize the performance of certain downstream
NLP tasks such as answering questions, has re-
ceived a significant amount of attention (Poon and
Domingos, 2009; Clarke et al., 2010; Berant et
al., 2013; Berant and Liang, 2014). One direc-
tion of our future work is to extend the current
framework to support the generation of synthetic
translation rules from weaker signals (e.g., from
question-answer pairs), rather than from aligned
parallel data.
We also noticed recent advance in tree-based
SMT. Applying such string-to-tree or tree-to-tree
translation models (Yamada and Knight, 2001;
Shen et al., 2008) to semantic parsing will nat-
urally resolve the inconsistent semantic structure
issue, though they require additional information
to generate tree labels on the target side. However,
due to the constraint that each target phrase needs
to map to a syntactic constituent, phrase tables in
tree-based translation models usually suffer from
the low coverage issue, especially if the training
data size is small. Therefore, another direction of
our future work is to explore specific problems that
will emerge when employing tree-based SMT sys-
tems to semantic parsing, and provide solutions to
them.
</bodyText>
<sectionHeader confidence="0.997486" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.995951">
The authors would like to thank Zhaopeng
Tu, S. Matthew English and three anony-
mous reviewers for providing helpful sugges-
tions, and also acknowledge Jacob Andreas for
help in running SMT-SemParse. Junhui Li
and Guodong Zhou were supported partially
by NSFC grants, No.61273320, No.61331011,
No.61305088, No.61401295. Wei Lu was sup-
ported by SUTD grant SRG ISTD 2013 064.
</bodyText>
<page confidence="0.964613">
1463
</page>
<sectionHeader confidence="0.989743" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998779480769231">
Jacob Andreas, Andreas Vlachos, and Stephen Clark.
2013. Semantic parsing as machine translation. In
Proceedings ofACL 2013, pages 47–52.
Jonathan Berant and Percy Liang. 2014. Semantic
parsing via paraphrasing. In Proceedings of ACL
2014, pages 1415–1425.
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy
Liang. 2013. Semantic parsing on freebase from
question-answer pairs. In Proceedings of EMNLP
2013, pages 1533–1544.
Peter E. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics,
19(2):263–313.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of EMNLP
2008, pages 224–233.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201–228.
James Clarke, Dan Goldwasser, Ming-Wei Chang, and
Dan Roth. 2010. Driving semantic parsing from the
worlds response. In Proceedings of CoNLL 2010,
pages 18–27.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Seti-
awan, Vladimir Eidelman, and Philip Resnik. 2010.
cdec: A decoder, alignment, and learning framework
for finite-state and context-free translation models.
In Proceedings of ACL 2010 System Demonstra-
tions, pages 7–12.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: an open source toolkit for
handling large scale language models. In Proceed-
ings of Interspeech 2008, pages 1618–1621.
Ruifang Ge and Raymond Mooney. 2005. A statistical
semantic parser that integrates syntax and semantics.
In Proceedings of CoNLL 2006, pages 9–16.
Bevan Jones, Mark Johnson, and Sharon Goldwater.
2012. Semantic parsing with bayesian tree transduc-
ers. In Proceedings ofACL 2012, pages 488–496.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of ACL 2010 System Demonstrations,
pages 177–180.
Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing probabilis-
tic CCG grammars from logical form with higher-
order unification. In Proceedings of EMNLP 2010,
pages 1223–1233.
Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2011. Lexical generaliza-
tion in ccg grammar induction for semantic parsing.
In Proceedings of EMNLP 2011, pages 1512–1523.
Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke
Zettlemoyer. 2013. Scaling semantic parsers with
on-the-fly ontology matching. In Proceedings of
EMNLP 2013, pages 1545–1556.
Junhui Li, Zhaopeng Tu, Guodong Zhou, and Josef van
Genabith. 2012. Using syntactic head information
in hierarchical phrase-based translation. In Proceed-
ings of WMT 2012, pages 232–242.
Percy Liang, Michael I. Jordan, and Dan Klein. 2011.
Learning dependency-based compositional seman-
tics. In Proceedings ofACL 2011, pages 590–599.
Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S.
Zettlemoyer. 2008. A generative model for pars-
ing natural language to meaning representations. In
Proceedings of EMNLP 2008, pages 783–792.
Wei Lu. 2014. Semantic parsing with relaxed hybrid
trees. In Proceedings of EMNLP 2014, pages 1308–
1318.
Wei Lu. 2015. Constrained semantic forests for im-
proved discriminative semantic parsing. In Proceed-
ings of ACL-IJCNLP 2015, pages 737–742.
Klaus Macherey, Franz Josef Och, and Hermann Ney.
2001. Natural language understanding using sta-
tistical machine translation. In Proceedings of Eu-
roSpeech 2001, pages 2205–2208.
Rohit J. Kate; Raymond J. Mooney. 2006. Using
string-kernels for learning semantic parsers. In Pro-
ceedings ofACL-COLING 2006, pages 913–920.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Kishore A. Papineni, Salim Roukos, and Todd Ward.
1997. Feature-based language understanding. In
Proceedings of EuroSpeech 1997, pages 1435–1438.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evaluation of machine translation. In Proceedings
ofACL 2002, pages 311–318.
Hoifung Poon and Pedro Domingos. 2009. Unsuper-
vised semantic parsing. In Proceedings of EMNLP
2009, pages 1–10.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proceedings ofACL 2008, pages 577–585.
</reference>
<page confidence="0.889415">
1464
</page>
<reference confidence="0.999280566666666">
Mark Steedman. 2000. The syntactic process. The
MIT Press.
Zhaopeng Tu, Yang Liu, Yifan He, Josef van Gen-
abith, Qun Liu, and Shouxun Lin. 2012. Combin-
ing multiple alignments to improve machine trans-
lation. In Proceedings of COLING 2012: Posters,
pages 1249–1260.
Adrienne Wang, Tom Kwiatkowski, and Luke Zettle-
moyer. 2014. Morpho-syntactic lexical generaliza-
tion for ccg semantic parsing. In Proceedings of
EMNLP 2014, pages 1284–1295.
Yuk Wah Wong and Raymond Mooney. 2006. Learn-
ing for semantic parsing with statistical machine
translation. In Proceedings of HLT-NAACL 2006,
pages 439–446.
Yuk Wah Wong and Raymond Mooney. 2007. Learn-
ing synchronous grammars for semantic parsing
with lambda calculus. In Proceedings of ACL 2007,
pages 960–967.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings
of ACL 2001, pages 523–530.
Luke S. Zettlemoyer and Michael Collins. 2005.
Learning to map sentences to logical form: Struc-
tured classification with probabilistic categorial
grammars. In Proceedings of UAI 2005, pages 658–
666.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax augmented machine translation via chart parsing.
In Proceedings of WMT 2006, pages 138–141.
</reference>
<page confidence="0.992982">
1465
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.320594">
<title confidence="0.9135195">Improving Semantic Parsing with Enriched Synchronous Context-Free Grammar</title>
<author confidence="0.99662">Wei Guodong</author>
<affiliation confidence="0.930299">Language Processing Lab, Soochow University, 2Alibaba Inc., Hangzhou, 3Information Systems Technology and Singapore University of Technology and</affiliation>
<email confidence="0.887395">luwei@sutd.edu.sg</email>
<abstract confidence="0.983842379310345">Semantic parsing maps a sentence in natural language into a structured meaning representation. Previous studies show that semantic parsing with synchronous contextfree grammars (SCFGs) achieves favorable performance over most other alternatives. Motivated by the observation that the performance of semantic parsing with SCFGs is closely tied to the translation rules, this paper explores extending translation rules with high quality and increased coverage in three ways. First, we introduce structure informed non-terminals, better guiding the parsing in favor of well formed structure, instead of using a uninformed non-terminal in SCFGs. Second, we examine the difference between word alignments for semantic parsing and statistical machine translation (SMT) to better adapt word alignment in SMT to semantic parsing. Finally, we address the unknown word translation issue via synthetic translation rules. Evaluation on the standard GeoQuery benchmark dataset shows that our approach achieves the state-of-the-art across various languages, including English, German and Greek.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jacob Andreas</author>
<author>Andreas Vlachos</author>
<author>Stephen Clark</author>
</authors>
<title>Semantic parsing as machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings ofACL 2013,</booktitle>
<pages>47--52</pages>
<contexts>
<context position="2511" citStr="Andreas et al., 2013" startWordPosition="374" endWordPosition="377"> before pre-processing NL’: what be the area of seattle MRL’: answer@1 area_1@1 cityid@2 seattle@s _@0 (b) after pre-processing Figure 1: Example of a sentence pair in NL and MRL. naturally viewed as a statistical machine translation (SMT) task, which translates a sentence in NL (i.e., the source language in SMT) into its meaning representation in MRL (i.e., the target language in SMT). Indeed, many attempts have been made to directly apply statistical machine translation (SMT) systems (or methodologies) to semantic parsing (Papineni et al., 1997; Macherey et al., 2001; Wong and Mooney, 2006; Andreas et al., 2013). However, although recent studies (Wong and Mooney, 2006; Andreas et al., 2013) show that semantic parsing with SCFGs, which form the basis of most existing statistical syntax-based translation models (Yamada and Knight, 2001; Chiang, 2007), achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in Andreas et al. (2013) and Lu (2014). The key issues behind the limited success of applying SMT systems directly to semantic parsing lie in the difference between semantic parsing and SMT: MRL is not a real natural l</context>
<context position="5426" citStr="Andreas et al. (2013)" startWordPosition="827" endWordPosition="830"> and SMT to better adapt word alignment in SMT to semantic parsing. Third, unlike most existing SMT systems that keep unknown words untranslated and intact in translation, we exploit the translation of unknown words via synthetic translation rules. Evaluation on GeoQuery benchmark dataset shows that our approach obtains consistent improvement and achieves the state-of-the-art across various languages, including English, German and Greek. 2 Background: Semantic Parsing as Statistical Machine Translation In this section, we present the framework of semantic parsing as SMT, which was proposed in Andreas et al. (2013). Pre-Processing Various semantic formalisms have been considered for semantic parsing. Examples include the variable-free semantic representations (that is, the meaning representation for each utterance is tree-shaped), the lambda calculus expressions, and dependency-based compositional semantic representations. In this work, we specifi1As seen in Section 2, delimiters, including parentheses and commas which do not carry any meaning will be removed in pre-processing and be recovered in post-processing cally focus on the variable-free semantic representations, as shown in Figure 1. On the targ</context>
<context position="23307" citStr="Andreas et al. (2013)" startWordPosition="3793" endWordPosition="3796">ison between our systems and previous works. As in Jones et al. (2012), we report accuracy, i.e. the percentage of translations with correct answers, and F1, i.e. the harmonic mean of precision (the proportion of correct answers out of translations with an answer) and recall (the proportion of correct answers out of all translations). In this section, we report our performance scores and analysis numbers averaged on our 10 SMT models. 7The NP list is from GeoQUery dataset in Jones et al. (2012), which contains MRs for every noun phrase that appears in the NL utterances of each language. As in Andreas et al. (2013), the NP list is included by appending all entries as extra training sentences with 50 times the weight of regular training examples, to ensure that they are learned as translation rules. SCFG alignment Acc. F1 src2tgt 75.0 82.5 tgt2src 78.5 82.5 non-enriched gdfa 77.5 83.5 src2tgt + tgt2src 81.4 85.0 src2tgt + gdfa 77.1 83.1 tgt2src + gdfa 80.6 83.9 all 81.5 85.2 gold 82.4 86.2 src2tgt 76.3 82.9 tgt2src 82.0 85.2 enriched gdfa 78.9 83.9 src2tgt + tgt2src 82.6 85.9 src2tgt + gdfa 78.8 83.7 tgt2src + gdfa 83.1 86.1 all 82.9 86.1 gold 84.1 87.1 Table 2: Performance of our (non-) enriched SCFG sy</context>
<context position="25081" citStr="Andreas et al. (2013)" startWordPosition="4077" endWordPosition="4080"> tripling the training data with each sentence pair having three alignments. Finally, gold indicates using gold alignment. 8 Effect of Enriched SCFG From Table 2, we observe that enriched SCFG systems outperform non-enriched SCFG systems over all alignment settings, indicating the effect of enriching nonterminals. In particular for tgt2src alignment, it obtains improvements of 3.5% in accuracy and 2.7% in F1. As mentioned earlier, the non-enriched SCFG system may result in ill-formed translations, which can not be converted back to tree structure. One natural way to overcome this issue, as in Andreas et al. (2013), would be to simply filter n-best translation till a well-formed one is found. However, we see very limited performance changes in accuracy and F1, suggesting that the effect of using n-best translation is very limited. For example, after using n-best translation, the nonenriched SCFG system with all alignment obtains 82.0 in accuracy (increased from 81.5) and 84.5 in 8We manually aligned sentence pairs in NL&apos; and MRL&apos;. 1460 wrong correct 6 53 correct wrong 211 10 non-enriched + gdfa alignment Rec. Pre. F1 src2tgt 96.3 68.8 80.3 tgt2src 90.0 77.0 83.0 gdfa 95.1 62.7 75.6 Table 3: Alignment pe</context>
<context position="33036" citStr="Andreas et al., 2013" startWordPosition="5365" endWordPosition="5368">m theirs in at least three ways. First, we use a different inventory of non-terminal symbols from theirs which was derived from MRL parses in the GeoQuery dataset. Second, to avoid the issues caused by word alignment between NL and MRL, we triple training data with each sentence pair having multiple alignments. However, WASP used a sequence of productions to represent MRL before running GIZA++. Third, we use typical features in HPB SMT (e.g., phrase translation probabilities, lexical translation probabilities, language model feature, etc.) while WASP used rule identity features. SMT-SemParse (Andreas et al., 2013) adapted standard SMT components for semantic parsing. The present work is based on theirs with all the extensions detailed in Section 3. HYBRIDTREE+ (Lu et al., 2008) learned a synchronous generative model which simultaneously generated a NL sentence and an MRL tree. tsVB (Jones et al., 2012) used tree transducers, which were similar to the hybrid tree structures, to learn a generative process under a Bayesian framework. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly represented both sentences and semantics. Most recently, f-RHT (Lu, 2015) introduced con</context>
<context position="35546" citStr="Andreas et al., 2013" startWordPosition="5785" endWordPosition="5788">8 81.0 62.1 68.5 69.3 74.6 73.6 76.7 tsVB 79.3 79.3 74.6 74.6 75.4 75.4 78.2 78.2 RHT 83.6 83.6 74.3 74.3 78.2 78.2 79.3 79.3 f-RHT 86.8 86.8 75.7 75.7 79.3 79.3 80.7 80.7 UBL 82.1 82.1 73.6 73.7 75.0 75.0 66.4 66.4 this work 86.3 87.1 79.1 80.3 80.5 81.6 76.3 77.9 Table 7: Performance comparison for the multilingual GeoQuery test set. The performance of WASP, HYBRIDTREE+, tsVB and UBL is taken from Jones et al. (2012). competitive performance when all the extensions (described in Section 3) are used. Specifically, it significantly outperforms the semantic parser with standard SMT components (Andreas et al., 2013). Our approach reports the best accuracy and F1 scores on English, German, and Greek. While we are able to obtain improvement on Thai, the performance is still lower than those of RHT and TREETRANS. This is probably because of the low quality of word alignment output between this Asian language and MRL. 6 Conclusion and Future Work In this paper, we have presented an enriched SCFG approach for semantic parsing which realizes the potential of the SMT approach. The performance improvement is contributed from the extension of translation rules with informative symbols and increased coverage. Such</context>
</contexts>
<marker>Andreas, Vlachos, Clark, 2013</marker>
<rawString>Jacob Andreas, Andreas Vlachos, and Stephen Clark. 2013. Semantic parsing as machine translation. In Proceedings ofACL 2013, pages 47–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Percy Liang</author>
</authors>
<title>Semantic parsing via paraphrasing.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL 2014,</booktitle>
<pages>1415--1425</pages>
<contexts>
<context position="36827" citStr="Berant and Liang, 2014" startWordPosition="5992" endWordPosition="5995">a CCG lexicon for CCG-based semantic parser (Kwiatkowski et al., 2011; Wang et al., 2014). Experiments on benchmark data have shown that our model is competitive to previous work and achieves state-of-the-art performance across a few different languages. Recently the research of semantic parsing in open domain with weakly (or un-) supervised setups, under different settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to extend the current framework to support the generation of synthetic translation rules from weaker signals (e.g., from question-answer pairs), rather than from aligned parallel data. We also noticed recent advance in tree-based SMT. Applying such string-to-tree or tree-to-tree translation models (Yamada and Knight, 2001; Shen et al., 2008) to semantic parsing will naturally resolve the inconsistent semantic structure issue, though they require additional information to generate tree labels on the target side. However, due to the constraint that each targ</context>
</contexts>
<marker>Berant, Liang, 2014</marker>
<rawString>Jonathan Berant and Percy Liang. 2014. Semantic parsing via paraphrasing. In Proceedings of ACL 2014, pages 1415–1425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Andrew Chou</author>
<author>Roy Frostig</author>
<author>Percy Liang</author>
</authors>
<title>Semantic parsing on freebase from question-answer pairs.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP 2013,</booktitle>
<pages>1533--1544</pages>
<contexts>
<context position="36802" citStr="Berant et al., 2013" startWordPosition="5988" endWordPosition="5991">as generalization of a CCG lexicon for CCG-based semantic parser (Kwiatkowski et al., 2011; Wang et al., 2014). Experiments on benchmark data have shown that our model is competitive to previous work and achieves state-of-the-art performance across a few different languages. Recently the research of semantic parsing in open domain with weakly (or un-) supervised setups, under different settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to extend the current framework to support the generation of synthetic translation rules from weaker signals (e.g., from question-answer pairs), rather than from aligned parallel data. We also noticed recent advance in tree-based SMT. Applying such string-to-tree or tree-to-tree translation models (Yamada and Knight, 2001; Shen et al., 2008) to semantic parsing will naturally resolve the inconsistent semantic structure issue, though they require additional information to generate tree labels on the target side. However, due to the </context>
</contexts>
<marker>Berant, Chou, Frostig, Liang, 2013</marker>
<rawString>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Proceedings of EMNLP 2013, pages 1533–1544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter E Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="13769" citStr="Brown et al., 1993" startWordPosition="2229" endWordPosition="2232">glue rules can be applied to any two neighboring translation nodes if the non-terminal symbols are matched. 3.2 Word Alignment for Semantic Parsing Word alignment is an essential step for rule extraction in SMT, where recognizing that wo shi in Chinese is a good translation for I am in English requires establishing a correspondence between wo and I, and between shi and am. In the SMT community, researchers have developed standard, proven alignment tools such as GIZA++ (Och and Ney, 2003), which can be used to train IBM Models 1-5. However, there is one fundamental problem with the IBM models (Brown et al., 1993): each word on one side can be traced back to exactly one particular on the other word (or the null token which indicates the word aligns to no word on the other side). Figure 2(a) shows an example of GIZA++ alignment output from source side to target side, from which we can see that each source word aligns to exactly one target word. While alignment of multiple target words to one source word is common in SMT, a trick is then to run IBM model training in both directions. Then two resulting word alignments can be symmetrized, for instance, taking the intersection or the union of alignment poin</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter E. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>224--233</pages>
<contexts>
<context position="22080" citStr="Chiang et al., 2008" startWordPosition="3583" endWordPosition="3586">red version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7 We use IRSTLM toolkit (Federico et al., 2008) to train a 5-gram LM on the MRL&apos; side of the training data, using modified Kneser-Ney smoothing. We use Mira (Chiang et al., 2008) to tune the parameters of the system to maximize BLEU (Papineni et al., 2002). When extracting translation rules from aligned training data, we include both tight and untight phrases. Evaluation We use the standard evaluation criteria for evaluation by executing both the predicted MRL and the gold standard against the database and obtaining their respective answer. Specifically, we convert a translation from MRL&apos; into MRL (if exists). The translation then is considered correct if and only if its MRL retrieves the same answers as the gold standard MRL (Jones et al., 2012), allowing for a fair </context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of EMNLP 2008, pages 224–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="2752" citStr="Chiang, 2007" startWordPosition="413" endWordPosition="414">ch translates a sentence in NL (i.e., the source language in SMT) into its meaning representation in MRL (i.e., the target language in SMT). Indeed, many attempts have been made to directly apply statistical machine translation (SMT) systems (or methodologies) to semantic parsing (Papineni et al., 1997; Macherey et al., 2001; Wong and Mooney, 2006; Andreas et al., 2013). However, although recent studies (Wong and Mooney, 2006; Andreas et al., 2013) show that semantic parsing with SCFGs, which form the basis of most existing statistical syntax-based translation models (Yamada and Knight, 2001; Chiang, 2007), achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in Andreas et al. (2013) and Lu (2014). The key issues behind the limited success of applying SMT systems directly to semantic parsing lie in the difference between semantic parsing and SMT: MRL is not a real natural language with different properties from natural language. First, MRL is machine-interpretable and thus strictly structured with the meaning representation in a nested structure of functions and arguments. Second, the two languages are intrins</context>
<context position="7152" citStr="Chiang, 2007" startWordPosition="1094" endWordPosition="1095">nctions). On the source side, we perform stemming (for English and German) and lowercasing to overcome data sparseness. Hereafter, we refer to the pre-processed NL and MRL as NL&apos; and MRL&apos; respectively. Translation Given a corpus of NL&apos; sentences paired with MRL&apos;, we learn a semantic parser by adopting a string-to-string translation system. Typical components in such a translation system include word alignments between the source and the target languages, translation rule extraction, language model learning, parameter tuning and decoding. For more details about each component, please refer to (Chiang, 2007). In the rest of this paper, we refer to the source language (side) as NL&apos;, and the target language (side) as MRL&apos;. Post-Processing We convert MRL&apos; back into MRL by recovering parentheses and commas to reconstruct the corresponding tree structure in MRL. This can be easily done by examining each symbol’s arity. It eliminates any possible ambiguity from the tree reconstruction: given any sequence of tokens in MRL&apos;, we can always reconstruct the tree structure (if one exists). For those translations that can not be successfully converted, we call them illformed translations. 3 Semantic Parsing w</context>
<context position="11731" citStr="Chiang (2007)" startWordPosition="1877" endWordPosition="1878">mples of glue rules in enriched SCFG. Table 1: Example of translation rules in enriched SCFG, where underline and ✿✿✿✿✿✿✿✿ underwave indicate the first and the second phrases respectively. Specifically, we omit \Fm and /An if m = 0 and n = 0 respectively.4 Table 1(a) demonstrates examples of phrase pairs in our enriched SCFG. For instance, word sequence stateid@1 texas@s is complete, and thus labeled as C. Similarly, to be complete, word sequence next to 2@1 requires one argument on the right side, labeled as C/A1 accordingly. When extracting translation rules from aligned datasets, we follow Chiang (2007) except that we use enriched non-terminal symbols rather than X. Each translation rule is associated with a set of translation model features fφil, including phrase translation probability p (α |γ) and its inverse p (γ |α), the lexical translation probability plex (α |γ) and its inverse plex (γ |α), and a rule penalty that learns the preference for longer or shorter derivations. Inverted Glue Rules In SMT decoding (Chiang, 2007), if no rule (e.g., a rule whose left-hand side is X) can be applied or the length of the potential source span is larger than a pre-defined length (e.g., 10 as in Chia</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Dan Goldwasser</author>
<author>Ming-Wei Chang</author>
<author>Dan Roth</author>
</authors>
<title>Driving semantic parsing from the worlds response.</title>
<date>2010</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<pages>18--27</pages>
<contexts>
<context position="36781" citStr="Clarke et al., 2010" startWordPosition="5984" endWordPosition="5987">are a similar spirit as generalization of a CCG lexicon for CCG-based semantic parser (Kwiatkowski et al., 2011; Wang et al., 2014). Experiments on benchmark data have shown that our model is competitive to previous work and achieves state-of-the-art performance across a few different languages. Recently the research of semantic parsing in open domain with weakly (or un-) supervised setups, under different settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to extend the current framework to support the generation of synthetic translation rules from weaker signals (e.g., from question-answer pairs), rather than from aligned parallel data. We also noticed recent advance in tree-based SMT. Applying such string-to-tree or tree-to-tree translation models (Yamada and Knight, 2001; Shen et al., 2008) to semantic parsing will naturally resolve the inconsistent semantic structure issue, though they require additional information to generate tree labels on the target side.</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>James Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the worlds response. In Proceedings of CoNLL 2010, pages 18–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Adam Lopez</author>
<author>Juri Ganitkevitch</author>
<author>Jonathan Weese</author>
<author>Ferhan Ture</author>
<author>Phil Blunsom</author>
<author>Hendra Setiawan</author>
<author>Vladimir Eidelman</author>
<author>Philip Resnik</author>
</authors>
<title>cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL 2010 System Demonstrations,</booktitle>
<pages>7--12</pages>
<contexts>
<context position="18337" citStr="Dyer et al., 2010" startWordPosition="2949" endWordPosition="2952">nswer@1 largest_one@1 population_1@1 state@1 next_to_2@1 stateid@1 texas@s what state that border have the highest population texas answer@1 largest_one@1 population_1@1 state@1 next_to_2@1 stateid@1 texas@s 3.3 Synthetic Translation Rules for Unknown Word Translation Most NLP tasks face the problem of unknown words, especially if only little training data is available. For example, it is estimated that 5.7% sentences in the (English) test data in our experiments have unknown words. Unknown words usually remain intact in the translation in most machine translation systems (Koehn et al., 2007; Dyer et al., 2010), resulting in the fact that certain translations can not be converted back to tree structures. This indicates that in semantic parsing the translation of a word can be from two categories: 1) a token in MRL; or 2) null (i.e., not translated at all), we generate synthetic translation rules for unknown word translation. As a baseline, we simply skip unknown words as Kwiatkowski et al. (2010) by adding translation rules that translate them to null in MRL&apos;. Each such rule is accompanied with one feature indicating that it is a translation rule for unknown word. Alternatively, taking advantage of </context>
<context position="21597" citStr="Dyer et al., 2010" startWordPosition="3491" endWordPosition="3494">ones et al. (2012), we use the 600 question pairs to train and tune our SMT de1459 coder, and evaluated on the remaining 280. Note that there is another version of GeoQuery dataset where the semantic representation is annotated with lambda calculus expressions and which is extensively studied (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Liang et al., 2011; Kwiatkowski et al., 2013). Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7 We use IRSTLM toolkit (Federico et al., 2008) to train a 5-gram LM on the MRL&apos; side of the training data, using modified Kneser-Ney smoothing. We use Mira (Chiang et al., 2008) to tune the parameters of the system to maximize BLEU (Papineni et al., 2002). When extracting translation rules fro</context>
</contexts>
<marker>Dyer, Lopez, Ganitkevitch, Weese, Ture, Blunsom, Setiawan, Eidelman, Resnik, 2010</marker>
<rawString>Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of ACL 2010 System Demonstrations, pages 7–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
</authors>
<title>IRSTLM: an open source toolkit for handling large scale language models.</title>
<date>2008</date>
<booktitle>In Proceedings of Interspeech</booktitle>
<pages>1618--1621</pages>
<contexts>
<context position="21949" citStr="Federico et al., 2008" startWordPosition="3559" endWordPosition="3562"> Liang et al., 2011; Kwiatkowski et al., 2013). Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7 We use IRSTLM toolkit (Federico et al., 2008) to train a 5-gram LM on the MRL&apos; side of the training data, using modified Kneser-Ney smoothing. We use Mira (Chiang et al., 2008) to tune the parameters of the system to maximize BLEU (Papineni et al., 2002). When extracting translation rules from aligned training data, we include both tight and untight phrases. Evaluation We use the standard evaluation criteria for evaluation by executing both the predicted MRL and the gold standard against the database and obtaining their respective answer. Specifically, we convert a translation from MRL&apos; into MRL (if exists). The translation then is consi</context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In Proceedings of Interspeech 2008, pages 1618–1621.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifang Ge</author>
<author>Raymond Mooney</author>
</authors>
<title>A statistical semantic parser that integrates syntax and semantics.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<pages>9--16</pages>
<contexts>
<context position="33713" citStr="Ge and Mooney, 2005" startWordPosition="5471" endWordPosition="5474">e present work is based on theirs with all the extensions detailed in Section 3. HYBRIDTREE+ (Lu et al., 2008) learned a synchronous generative model which simultaneously generated a NL sentence and an MRL tree. tsVB (Jones et al., 2012) used tree transducers, which were similar to the hybrid tree structures, to learn a generative process under a Bayesian framework. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly represented both sentences and semantics. Most recently, f-RHT (Lu, 2015) introduced constrained semantic forests to improve RHT model. SCISSOR (Ge and Mooney, 2005) augmented syntactic parse tree with semantic information and then performed integrated semantic and syntactic parsing to NL sentences. KRISP (Mooney, 2006) used string classifiers to label substrings of an NL with entities from the meaning representation. UBL (Kwiatkowski et al., 2010) performed semantic parsing with an automatically-induced CCG lexicon. Table 7 shows the evaluation results of our system as well as those of several other comparable related works which share the same experiment setup as ours. We can observe from Table 7 that semantic parsing with SMT components gives 1462 Syst</context>
</contexts>
<marker>Ge, Mooney, 2005</marker>
<rawString>Ruifang Ge and Raymond Mooney. 2005. A statistical semantic parser that integrates syntax and semantics. In Proceedings of CoNLL 2006, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bevan Jones</author>
<author>Mark Johnson</author>
<author>Sharon Goldwater</author>
</authors>
<title>Semantic parsing with bayesian tree transducers.</title>
<date>2012</date>
<booktitle>In Proceedings ofACL 2012,</booktitle>
<pages>488--496</pages>
<contexts>
<context position="20997" citStr="Jones et al. (2012)" startWordPosition="3390" endWordPosition="3393">nd. words. Note that it may generate a synthetic rule with null at the target side since the lexical translation table derived from aligned training data contains translation to null. Each synthetic translation rule for unknown words is associated with three features returned from function generate rule. 4 Experimentation In this section, we test our approach on the GeoQuery dataset, which is publicly available. 4.1 Experimental Settings Data GeoQuery dataset consists of 880 questions paired with their corresponding tree structured semantic representations. Following the experimental setup in Jones et al. (2012), we use the 600 question pairs to train and tune our SMT de1459 coder, and evaluated on the remaining 280. Note that there is another version of GeoQuery dataset where the semantic representation is annotated with lambda calculus expressions and which is extensively studied (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Liang et al., 2011; Kwiatkowski et al., 2013). Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010)</context>
<context position="22658" citStr="Jones et al., 2012" startWordPosition="3679" endWordPosition="3682">othing. We use Mira (Chiang et al., 2008) to tune the parameters of the system to maximize BLEU (Papineni et al., 2002). When extracting translation rules from aligned training data, we include both tight and untight phrases. Evaluation We use the standard evaluation criteria for evaluation by executing both the predicted MRL and the gold standard against the database and obtaining their respective answer. Specifically, we convert a translation from MRL&apos; into MRL (if exists). The translation then is considered correct if and only if its MRL retrieves the same answers as the gold standard MRL (Jones et al., 2012), allowing for a fair comparison between our systems and previous works. As in Jones et al. (2012), we report accuracy, i.e. the percentage of translations with correct answers, and F1, i.e. the harmonic mean of precision (the proportion of correct answers out of translations with an answer) and recall (the proportion of correct answers out of all translations). In this section, we report our performance scores and analysis numbers averaged on our 10 SMT models. 7The NP list is from GeoQUery dataset in Jones et al. (2012), which contains MRs for every noun phrase that appears in the NL utteran</context>
<context position="33330" citStr="Jones et al., 2012" startWordPosition="5413" endWordPosition="5416">iple alignments. However, WASP used a sequence of productions to represent MRL before running GIZA++. Third, we use typical features in HPB SMT (e.g., phrase translation probabilities, lexical translation probabilities, language model feature, etc.) while WASP used rule identity features. SMT-SemParse (Andreas et al., 2013) adapted standard SMT components for semantic parsing. The present work is based on theirs with all the extensions detailed in Section 3. HYBRIDTREE+ (Lu et al., 2008) learned a synchronous generative model which simultaneously generated a NL sentence and an MRL tree. tsVB (Jones et al., 2012) used tree transducers, which were similar to the hybrid tree structures, to learn a generative process under a Bayesian framework. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly represented both sentences and semantics. Most recently, f-RHT (Lu, 2015) introduced constrained semantic forests to improve RHT model. SCISSOR (Ge and Mooney, 2005) augmented syntactic parse tree with semantic information and then performed integrated semantic and syntactic parsing to NL sentences. KRISP (Mooney, 2006) used string classifiers to label substrings of an NL with en</context>
<context position="35347" citStr="Jones et al. (2012)" startWordPosition="5758" endWordPosition="5761">GeoQuery test set. System English German Greek Thai Acc. F1 Acc. F1 Acc. F1 Acc. F1 WASP 71.1 77.7 65.7 74.9 70.7 78.6 71.4 75.0 SMT-SemParse 80.5 81.8 68.9 71.8 69.1 72.3 70.4 70.7 HYBRIDTREE+ 76.8 81.0 62.1 68.5 69.3 74.6 73.6 76.7 tsVB 79.3 79.3 74.6 74.6 75.4 75.4 78.2 78.2 RHT 83.6 83.6 74.3 74.3 78.2 78.2 79.3 79.3 f-RHT 86.8 86.8 75.7 75.7 79.3 79.3 80.7 80.7 UBL 82.1 82.1 73.6 73.7 75.0 75.0 66.4 66.4 this work 86.3 87.1 79.1 80.3 80.5 81.6 76.3 77.9 Table 7: Performance comparison for the multilingual GeoQuery test set. The performance of WASP, HYBRIDTREE+, tsVB and UBL is taken from Jones et al. (2012). competitive performance when all the extensions (described in Section 3) are used. Specifically, it significantly outperforms the semantic parser with standard SMT components (Andreas et al., 2013). Our approach reports the best accuracy and F1 scores on English, German, and Greek. While we are able to obtain improvement on Thai, the performance is still lower than those of RHT and TREETRANS. This is probably because of the low quality of word alignment output between this Asian language and MRL. 6 Conclusion and Future Work In this paper, we have presented an enriched SCFG approach for sema</context>
</contexts>
<marker>Jones, Johnson, Goldwater, 2012</marker>
<rawString>Bevan Jones, Mark Johnson, and Sharon Goldwater. 2012. Semantic parsing with bayesian tree transducers. In Proceedings ofACL 2012, pages 488–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL 2010 System Demonstrations,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="18317" citStr="Koehn et al., 2007" startWordPosition="2945" endWordPosition="2948">highest population answer@1 largest_one@1 population_1@1 state@1 next_to_2@1 stateid@1 texas@s what state that border have the highest population texas answer@1 largest_one@1 population_1@1 state@1 next_to_2@1 stateid@1 texas@s 3.3 Synthetic Translation Rules for Unknown Word Translation Most NLP tasks face the problem of unknown words, especially if only little training data is available. For example, it is estimated that 5.7% sentences in the (English) test data in our experiments have unknown words. Unknown words usually remain intact in the translation in most machine translation systems (Koehn et al., 2007; Dyer et al., 2010), resulting in the fact that certain translations can not be converted back to tree structures. This indicates that in semantic parsing the translation of a word can be from two categories: 1) a token in MRL; or 2) null (i.e., not translated at all), we generate synthetic translation rules for unknown word translation. As a baseline, we simply skip unknown words as Kwiatkowski et al. (2010) by adding translation rules that translate them to null in MRL&apos;. Each such rule is accompanied with one feature indicating that it is a translation rule for unknown word. Alternatively, </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of ACL 2010 System Demonstrations, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Inducing probabilistic CCG grammars from logical form with higherorder unification.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>1223--1233</pages>
<contexts>
<context position="18730" citStr="Kwiatkowski et al. (2010)" startWordPosition="3018" endWordPosition="3021">it is estimated that 5.7% sentences in the (English) test data in our experiments have unknown words. Unknown words usually remain intact in the translation in most machine translation systems (Koehn et al., 2007; Dyer et al., 2010), resulting in the fact that certain translations can not be converted back to tree structures. This indicates that in semantic parsing the translation of a word can be from two categories: 1) a token in MRL; or 2) null (i.e., not translated at all), we generate synthetic translation rules for unknown word translation. As a baseline, we simply skip unknown words as Kwiatkowski et al. (2010) by adding translation rules that translate them to null in MRL&apos;. Each such rule is accompanied with one feature indicating that it is a translation rule for unknown word. Alternatively, taking advantage of publicly available resources, we generate synthetic translation rules for unknown words pivoted by their semantically close words. Algorithm 1 illustrates the process to generate synthetic translation rules for unknown word translation. Given an unknown word wu, it generates its synthetic rules in two steps: 1) finding top n (e.g., 5 as in our experiments) close words via Word2Vec;6 and 2) </context>
<context position="34000" citStr="Kwiatkowski et al., 2010" startWordPosition="5514" endWordPosition="5517"> the hybrid tree structures, to learn a generative process under a Bayesian framework. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly represented both sentences and semantics. Most recently, f-RHT (Lu, 2015) introduced constrained semantic forests to improve RHT model. SCISSOR (Ge and Mooney, 2005) augmented syntactic parse tree with semantic information and then performed integrated semantic and syntactic parsing to NL sentences. KRISP (Mooney, 2006) used string classifiers to label substrings of an NL with entities from the meaning representation. UBL (Kwiatkowski et al., 2010) performed semantic parsing with an automatically-induced CCG lexicon. Table 7 shows the evaluation results of our system as well as those of several other comparable related works which share the same experiment setup as ours. We can observe from Table 7 that semantic parsing with SMT components gives 1462 System English German Greek Thai Acc. F1 Acc. F1 Acc. F1 Acc. F1 non-enriched + gdfa 77.5 83.5 66.0 74.9 65.6 74.1 65.4 72.4 non-enriched + all 81.5 85.2 72.1 76.8 75.2 80.5 72.7 76.4 enriched + gdfa 78.9 83.9 66.7 74.6 67.8 76.1 68.5 74.1 enriched + all 82.9 86.1 75.4 79.5 76.5 81.2 75.2 7</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing probabilistic CCG grammars from logical form with higherorder unification. In Proceedings of EMNLP 2010, pages 1223–1233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Lexical generalization in ccg grammar induction for semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP 2011,</booktitle>
<pages>1512--1523</pages>
<contexts>
<context position="36273" citStr="Kwiatkowski et al., 2011" startWordPosition="5903" endWordPosition="5906"> to obtain improvement on Thai, the performance is still lower than those of RHT and TREETRANS. This is probably because of the low quality of word alignment output between this Asian language and MRL. 6 Conclusion and Future Work In this paper, we have presented an enriched SCFG approach for semantic parsing which realizes the potential of the SMT approach. The performance improvement is contributed from the extension of translation rules with informative symbols and increased coverage. Such an extension share a similar spirit as generalization of a CCG lexicon for CCG-based semantic parser (Kwiatkowski et al., 2011; Wang et al., 2014). Experiments on benchmark data have shown that our model is competitive to previous work and achieves state-of-the-art performance across a few different languages. Recently the research of semantic parsing in open domain with weakly (or un-) supervised setups, under different settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to exten</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2011</marker>
<rawString>Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2011. Lexical generalization in ccg grammar induction for semantic parsing. In Proceedings of EMNLP 2011, pages 1512–1523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Eunsol Choi</author>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Scaling semantic parsers with on-the-fly ontology matching.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP 2013,</booktitle>
<pages>1545--1556</pages>
<contexts>
<context position="21373" citStr="Kwiatkowski et al., 2013" startWordPosition="3452" endWordPosition="3455">eoQuery dataset, which is publicly available. 4.1 Experimental Settings Data GeoQuery dataset consists of 880 questions paired with their corresponding tree structured semantic representations. Following the experimental setup in Jones et al. (2012), we use the 600 question pairs to train and tune our SMT de1459 coder, and evaluated on the remaining 280. Note that there is another version of GeoQuery dataset where the semantic representation is annotated with lambda calculus expressions and which is extensively studied (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Liang et al., 2011; Kwiatkowski et al., 2013). Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7 We use IRSTLM toolkit (Federico et al., 2008) to train a 5-gram LM on</context>
</contexts>
<marker>Kwiatkowski, Choi, Artzi, Zettlemoyer, 2013</marker>
<rawString>Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer. 2013. Scaling semantic parsers with on-the-fly ontology matching. In Proceedings of EMNLP 2013, pages 1545–1556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhui Li</author>
<author>Zhaopeng Tu</author>
<author>Guodong Zhou</author>
<author>Josef van Genabith</author>
</authors>
<title>Using syntactic head information in hierarchical phrase-based translation.</title>
<date>2012</date>
<booktitle>In Proceedings of WMT 2012,</booktitle>
<pages>232--242</pages>
<marker>Li, Tu, Zhou, van Genabith, 2012</marker>
<rawString>Junhui Li, Zhaopeng Tu, Guodong Zhou, and Josef van Genabith. 2012. Using syntactic head information in hierarchical phrase-based translation. In Proceedings of WMT 2012, pages 232–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning dependency-based compositional semantics.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL 2011,</booktitle>
<pages>590--599</pages>
<contexts>
<context position="21346" citStr="Liang et al., 2011" startWordPosition="3448" endWordPosition="3451">ur approach on the GeoQuery dataset, which is publicly available. 4.1 Experimental Settings Data GeoQuery dataset consists of 880 questions paired with their corresponding tree structured semantic representations. Following the experimental setup in Jones et al. (2012), we use the 600 question pairs to train and tune our SMT de1459 coder, and evaluated on the remaining 280. Note that there is another version of GeoQuery dataset where the semantic representation is annotated with lambda calculus expressions and which is extensively studied (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Liang et al., 2011; Kwiatkowski et al., 2013). Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7 We use IRSTLM toolkit (Federico et al., 20</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2011. Learning dependency-based compositional semantics. In Proceedings ofACL 2011, pages 590–599.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
<author>Hwee Tou Ng</author>
<author>Wee Sun Lee</author>
<author>Luke S Zettlemoyer</author>
</authors>
<title>A generative model for parsing natural language to meaning representations.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>783--792</pages>
<contexts>
<context position="33203" citStr="Lu et al., 2008" startWordPosition="5392" endWordPosition="5395">to avoid the issues caused by word alignment between NL and MRL, we triple training data with each sentence pair having multiple alignments. However, WASP used a sequence of productions to represent MRL before running GIZA++. Third, we use typical features in HPB SMT (e.g., phrase translation probabilities, lexical translation probabilities, language model feature, etc.) while WASP used rule identity features. SMT-SemParse (Andreas et al., 2013) adapted standard SMT components for semantic parsing. The present work is based on theirs with all the extensions detailed in Section 3. HYBRIDTREE+ (Lu et al., 2008) learned a synchronous generative model which simultaneously generated a NL sentence and an MRL tree. tsVB (Jones et al., 2012) used tree transducers, which were similar to the hybrid tree structures, to learn a generative process under a Bayesian framework. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly represented both sentences and semantics. Most recently, f-RHT (Lu, 2015) introduced constrained semantic forests to improve RHT model. SCISSOR (Ge and Mooney, 2005) augmented syntactic parse tree with semantic information and then performed integrated se</context>
</contexts>
<marker>Lu, Ng, Lee, Zettlemoyer, 2008</marker>
<rawString>Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettlemoyer. 2008. A generative model for parsing natural language to meaning representations. In Proceedings of EMNLP 2008, pages 783–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
</authors>
<title>Semantic parsing with relaxed hybrid trees.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP 2014,</booktitle>
<pages>1308--1318</pages>
<contexts>
<context position="2931" citStr="Lu (2014)" startWordPosition="440" endWordPosition="441">rectly apply statistical machine translation (SMT) systems (or methodologies) to semantic parsing (Papineni et al., 1997; Macherey et al., 2001; Wong and Mooney, 2006; Andreas et al., 2013). However, although recent studies (Wong and Mooney, 2006; Andreas et al., 2013) show that semantic parsing with SCFGs, which form the basis of most existing statistical syntax-based translation models (Yamada and Knight, 2001; Chiang, 2007), achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in Andreas et al. (2013) and Lu (2014). The key issues behind the limited success of applying SMT systems directly to semantic parsing lie in the difference between semantic parsing and SMT: MRL is not a real natural language with different properties from natural language. First, MRL is machine-interpretable and thus strictly structured with the meaning representation in a nested structure of functions and arguments. Second, the two languages are intrinsically asymmetric since each token in MRL carries specific mean1455 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1455–1465, Lisbon</context>
<context position="33476" citStr="Lu, 2014" startWordPosition="5439" endWordPosition="5440">e translation probabilities, lexical translation probabilities, language model feature, etc.) while WASP used rule identity features. SMT-SemParse (Andreas et al., 2013) adapted standard SMT components for semantic parsing. The present work is based on theirs with all the extensions detailed in Section 3. HYBRIDTREE+ (Lu et al., 2008) learned a synchronous generative model which simultaneously generated a NL sentence and an MRL tree. tsVB (Jones et al., 2012) used tree transducers, which were similar to the hybrid tree structures, to learn a generative process under a Bayesian framework. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly represented both sentences and semantics. Most recently, f-RHT (Lu, 2015) introduced constrained semantic forests to improve RHT model. SCISSOR (Ge and Mooney, 2005) augmented syntactic parse tree with semantic information and then performed integrated semantic and syntactic parsing to NL sentences. KRISP (Mooney, 2006) used string classifiers to label substrings of an NL with entities from the meaning representation. UBL (Kwiatkowski et al., 2010) performed semantic parsing with an automatically-induced CCG lexicon. Table</context>
</contexts>
<marker>Lu, 2014</marker>
<rawString>Wei Lu. 2014. Semantic parsing with relaxed hybrid trees. In Proceedings of EMNLP 2014, pages 1308– 1318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
</authors>
<title>Constrained semantic forests for improved discriminative semantic parsing.</title>
<date>2015</date>
<booktitle>In Proceedings of ACL-IJCNLP</booktitle>
<pages>737--742</pages>
<contexts>
<context position="33621" citStr="Lu, 2015" startWordPosition="5460" endWordPosition="5461">e (Andreas et al., 2013) adapted standard SMT components for semantic parsing. The present work is based on theirs with all the extensions detailed in Section 3. HYBRIDTREE+ (Lu et al., 2008) learned a synchronous generative model which simultaneously generated a NL sentence and an MRL tree. tsVB (Jones et al., 2012) used tree transducers, which were similar to the hybrid tree structures, to learn a generative process under a Bayesian framework. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly represented both sentences and semantics. Most recently, f-RHT (Lu, 2015) introduced constrained semantic forests to improve RHT model. SCISSOR (Ge and Mooney, 2005) augmented syntactic parse tree with semantic information and then performed integrated semantic and syntactic parsing to NL sentences. KRISP (Mooney, 2006) used string classifiers to label substrings of an NL with entities from the meaning representation. UBL (Kwiatkowski et al., 2010) performed semantic parsing with an automatically-induced CCG lexicon. Table 7 shows the evaluation results of our system as well as those of several other comparable related works which share the same experiment setup as</context>
</contexts>
<marker>Lu, 2015</marker>
<rawString>Wei Lu. 2015. Constrained semantic forests for improved discriminative semantic parsing. In Proceedings of ACL-IJCNLP 2015, pages 737–742.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Macherey</author>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Natural language understanding using statistical machine translation.</title>
<date>2001</date>
<booktitle>In Proceedings of EuroSpeech</booktitle>
<pages>2205--2208</pages>
<contexts>
<context position="2465" citStr="Macherey et al., 2001" startWordPosition="366" endWordPosition="369"> MRL: answer(area_1(cityid(‘seattle’, _))) (a) before pre-processing NL’: what be the area of seattle MRL’: answer@1 area_1@1 cityid@2 seattle@s _@0 (b) after pre-processing Figure 1: Example of a sentence pair in NL and MRL. naturally viewed as a statistical machine translation (SMT) task, which translates a sentence in NL (i.e., the source language in SMT) into its meaning representation in MRL (i.e., the target language in SMT). Indeed, many attempts have been made to directly apply statistical machine translation (SMT) systems (or methodologies) to semantic parsing (Papineni et al., 1997; Macherey et al., 2001; Wong and Mooney, 2006; Andreas et al., 2013). However, although recent studies (Wong and Mooney, 2006; Andreas et al., 2013) show that semantic parsing with SCFGs, which form the basis of most existing statistical syntax-based translation models (Yamada and Knight, 2001; Chiang, 2007), achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in Andreas et al. (2013) and Lu (2014). The key issues behind the limited success of applying SMT systems directly to semantic parsing lie in the difference between semanti</context>
</contexts>
<marker>Macherey, Och, Ney, 2001</marker>
<rawString>Klaus Macherey, Franz Josef Och, and Hermann Ney. 2001. Natural language understanding using statistical machine translation. In Proceedings of EuroSpeech 2001, pages 2205–2208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
<author>Raymond J Mooney</author>
</authors>
<title>Using string-kernels for learning semantic parsers.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL-COLING</booktitle>
<pages>913--920</pages>
<marker>Kate, Mooney, 2006</marker>
<rawString>Rohit J. Kate; Raymond J. Mooney. 2006. Using string-kernels for learning semantic parsers. In Proceedings ofACL-COLING 2006, pages 913–920.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="13642" citStr="Och and Ney, 2003" startWordPosition="2204" endWordPosition="2207">bility p (α |γ), and a glue rule penalty. Table 1(b) shows examples of a straight and an inverted glue rules. Moreover, these glue rules can be applied to any two neighboring translation nodes if the non-terminal symbols are matched. 3.2 Word Alignment for Semantic Parsing Word alignment is an essential step for rule extraction in SMT, where recognizing that wo shi in Chinese is a good translation for I am in English requires establishing a correspondence between wo and I, and between shi and am. In the SMT community, researchers have developed standard, proven alignment tools such as GIZA++ (Och and Ney, 2003), which can be used to train IBM Models 1-5. However, there is one fundamental problem with the IBM models (Brown et al., 1993): each word on one side can be traced back to exactly one particular on the other word (or the null token which indicates the word aligns to no word on the other side). Figure 2(a) shows an example of GIZA++ alignment output from source side to target side, from which we can see that each source word aligns to exactly one target word. While alignment of multiple target words to one source word is common in SMT, a trick is then to run IBM model training in both directio</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore A Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
</authors>
<title>Feature-based language understanding.</title>
<date>1997</date>
<booktitle>In Proceedings of EuroSpeech</booktitle>
<pages>1435--1438</pages>
<contexts>
<context position="2442" citStr="Papineni et al., 1997" startWordPosition="362" endWordPosition="365"> is the area of Seattle MRL: answer(area_1(cityid(‘seattle’, _))) (a) before pre-processing NL’: what be the area of seattle MRL’: answer@1 area_1@1 cityid@2 seattle@s _@0 (b) after pre-processing Figure 1: Example of a sentence pair in NL and MRL. naturally viewed as a statistical machine translation (SMT) task, which translates a sentence in NL (i.e., the source language in SMT) into its meaning representation in MRL (i.e., the target language in SMT). Indeed, many attempts have been made to directly apply statistical machine translation (SMT) systems (or methodologies) to semantic parsing (Papineni et al., 1997; Macherey et al., 2001; Wong and Mooney, 2006; Andreas et al., 2013). However, although recent studies (Wong and Mooney, 2006; Andreas et al., 2013) show that semantic parsing with SCFGs, which form the basis of most existing statistical syntax-based translation models (Yamada and Knight, 2001; Chiang, 2007), achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in Andreas et al. (2013) and Lu (2014). The key issues behind the limited success of applying SMT systems directly to semantic parsing lie in the dif</context>
</contexts>
<marker>Papineni, Roukos, Ward, 1997</marker>
<rawString>Kishore A. Papineni, Salim Roukos, and Todd Ward. 1997. Feature-based language understanding. In Proceedings of EuroSpeech 1997, pages 1435–1438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL 2002,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="22158" citStr="Papineni et al., 2002" startWordPosition="3597" endWordPosition="3600">ectly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7 We use IRSTLM toolkit (Federico et al., 2008) to train a 5-gram LM on the MRL&apos; side of the training data, using modified Kneser-Ney smoothing. We use Mira (Chiang et al., 2008) to tune the parameters of the system to maximize BLEU (Papineni et al., 2002). When extracting translation rules from aligned training data, we include both tight and untight phrases. Evaluation We use the standard evaluation criteria for evaluation by executing both the predicted MRL and the gold standard against the database and obtaining their respective answer. Specifically, we convert a translation from MRL&apos; into MRL (if exists). The translation then is considered correct if and only if its MRL retrieves the same answers as the gold standard MRL (Jones et al., 2012), allowing for a fair comparison between our systems and previous works. As in Jones et al. (2012), </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings ofACL 2002, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>1--10</pages>
<contexts>
<context position="36760" citStr="Poon and Domingos, 2009" startWordPosition="5980" endWordPosition="5983">age. Such an extension share a similar spirit as generalization of a CCG lexicon for CCG-based semantic parser (Kwiatkowski et al., 2011; Wang et al., 2014). Experiments on benchmark data have shown that our model is competitive to previous work and achieves state-of-the-art performance across a few different languages. Recently the research of semantic parsing in open domain with weakly (or un-) supervised setups, under different settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to extend the current framework to support the generation of synthetic translation rules from weaker signals (e.g., from question-answer pairs), rather than from aligned parallel data. We also noticed recent advance in tree-based SMT. Applying such string-to-tree or tree-to-tree translation models (Yamada and Knight, 2001; Shen et al., 2008) to semantic parsing will naturally resolve the inconsistent semantic structure issue, though they require additional information to generate tree label</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2009. Unsupervised semantic parsing. In Proceedings of EMNLP 2009, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL</booktitle>
<pages>577--585</pages>
<contexts>
<context position="37208" citStr="Shen et al., 2008" startWordPosition="6049" endWordPosition="6052"> goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to extend the current framework to support the generation of synthetic translation rules from weaker signals (e.g., from question-answer pairs), rather than from aligned parallel data. We also noticed recent advance in tree-based SMT. Applying such string-to-tree or tree-to-tree translation models (Yamada and Knight, 2001; Shen et al., 2008) to semantic parsing will naturally resolve the inconsistent semantic structure issue, though they require additional information to generate tree labels on the target side. However, due to the constraint that each target phrase needs to map to a syntactic constituent, phrase tables in tree-based translation models usually suffer from the low coverage issue, especially if the training data size is small. Therefore, another direction of our future work is to explore specific problems that will emerge when employing tree-based SMT systems to semantic parsing, and provide solutions to them. Ackno</context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A new string-to-dependency machine translation algorithm with a target dependency language model. In Proceedings ofACL 2008, pages 577–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The syntactic process.</title>
<date>2000</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="10564" citStr="Steedman, 2000" startWordPosition="1673" endWordPosition="1674"> to another function. We use symbol C to label word sequences which are complete. For an incomplete word sequence, we examine 1) the number of arguments it requires on the right to be complete; and 2) the arity of a function it requires on the left to be complete. Then the sequence is labeled as (C\Fm)/An, indicating it requires n arguments on the right and a function with m arities on the left. 3 2In practice, non-terminal symbol S is used in glue rules. However, this is not relevant in the present discussion. 3This is similar to the naming convention in combinatory categorial grammar (CCG) (Steedman, 2000) texas, stateid@1 texas@s C--+ (texas, stateid@1 texas@s) seattle, seattle@s @0 C\F2--+ (seattle, seattle@s @0) that border, next to 2@1 C/A1--+ (that border, next to 2@1) state that border, state@1 next to 2@1 D E C/A1--+ state C/A1 1 , state@1 C/A1 1 (a) Examples of phrase pairs in enriched SCFG. state that✿✿✿✿✿✿ ✿✿border , state @ 1 next to 2 @ 1 C/A1--+ DC/A1 1 C/A1 2 , C/A1 1 C/A1 2 E state that border ✿✿✿✿ texas ✿✿✿✿ have ✿✿ the✿✿✿✿✿✿ highest✿✿✿✿✿✿✿✿population, L. one@1 p.. 1@1 state@1 n..@1 s..@1 t..@s D E C--+ C1 C/A1 2 , C/A1 2 C 1 (b) Examples of glue rules in enriched SCFG. Table 1:</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The syntactic process. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhaopeng Tu</author>
<author>Yang Liu</author>
<author>Yifan He</author>
<author>Josef van Genabith</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Combining multiple alignments to improve machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012: Posters,</booktitle>
<pages>1249--1260</pages>
<marker>Tu, Liu, He, van Genabith, Liu, Lin, 2012</marker>
<rawString>Zhaopeng Tu, Yang Liu, Yifan He, Josef van Genabith, Qun Liu, and Shouxun Lin. 2012. Combining multiple alignments to improve machine translation. In Proceedings of COLING 2012: Posters, pages 1249–1260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrienne Wang</author>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Morpho-syntactic lexical generalization for ccg semantic parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP 2014,</booktitle>
<pages>1284--1295</pages>
<contexts>
<context position="36293" citStr="Wang et al., 2014" startWordPosition="5907" endWordPosition="5910">Thai, the performance is still lower than those of RHT and TREETRANS. This is probably because of the low quality of word alignment output between this Asian language and MRL. 6 Conclusion and Future Work In this paper, we have presented an enriched SCFG approach for semantic parsing which realizes the potential of the SMT approach. The performance improvement is contributed from the extension of translation rules with informative symbols and increased coverage. Such an extension share a similar spirit as generalization of a CCG lexicon for CCG-based semantic parser (Kwiatkowski et al., 2011; Wang et al., 2014). Experiments on benchmark data have shown that our model is competitive to previous work and achieves state-of-the-art performance across a few different languages. Recently the research of semantic parsing in open domain with weakly (or un-) supervised setups, under different settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to extend the current framew</context>
</contexts>
<marker>Wang, Kwiatkowski, Zettlemoyer, 2014</marker>
<rawString>Adrienne Wang, Tom Kwiatkowski, and Luke Zettlemoyer. 2014. Morpho-syntactic lexical generalization for ccg semantic parsing. In Proceedings of EMNLP 2014, pages 1284–1295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond Mooney</author>
</authors>
<title>Learning for semantic parsing with statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<pages>439--446</pages>
<contexts>
<context position="2488" citStr="Wong and Mooney, 2006" startWordPosition="370" endWordPosition="373">yid(‘seattle’, _))) (a) before pre-processing NL’: what be the area of seattle MRL’: answer@1 area_1@1 cityid@2 seattle@s _@0 (b) after pre-processing Figure 1: Example of a sentence pair in NL and MRL. naturally viewed as a statistical machine translation (SMT) task, which translates a sentence in NL (i.e., the source language in SMT) into its meaning representation in MRL (i.e., the target language in SMT). Indeed, many attempts have been made to directly apply statistical machine translation (SMT) systems (or methodologies) to semantic parsing (Papineni et al., 1997; Macherey et al., 2001; Wong and Mooney, 2006; Andreas et al., 2013). However, although recent studies (Wong and Mooney, 2006; Andreas et al., 2013) show that semantic parsing with SCFGs, which form the basis of most existing statistical syntax-based translation models (Yamada and Knight, 2001; Chiang, 2007), achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in Andreas et al. (2013) and Lu (2014). The key issues behind the limited success of applying SMT systems directly to semantic parsing lie in the difference between semantic parsing and SMT: MRL </context>
<context position="32245" citStr="Wong and Mooney, 2006" startWordPosition="5244" endWordPosition="5247">ds via Word2Vec, however, is quite fast since this is bounded by the vocabulary size of our training set. Thanks to the small size of unknown words, adding unknown word translation rules has a very limited impact on the size of phrase table, consequently negligible changes on decoding time. 9In cdec, we generate a phrase table for each sentence. 5 Related Work While there has been substantial work on semantic parsing, we focus our discussions on several approaches (e.g., SCFG approach, hybrid tree approach, and others approaches) that focus on the variable-free semantic representations. WASP (Wong and Mooney, 2006) was strongly influenced by SMT techniques. Although WASP was also using multiple non-terminal symbols in SCFG to guarantee well-formed translations, our work differs from theirs in at least three ways. First, we use a different inventory of non-terminal symbols from theirs which was derived from MRL parses in the GeoQuery dataset. Second, to avoid the issues caused by word alignment between NL and MRL, we triple training data with each sentence pair having multiple alignments. However, WASP used a sequence of productions to represent MRL before running GIZA++. Third, we use typical features i</context>
</contexts>
<marker>Wong, Mooney, 2006</marker>
<rawString>Yuk Wah Wong and Raymond Mooney. 2006. Learning for semantic parsing with statistical machine translation. In Proceedings of HLT-NAACL 2006, pages 439–446.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>960--967</pages>
<contexts>
<context position="21326" citStr="Wong and Mooney, 2007" startWordPosition="3444" endWordPosition="3447">this section, we test our approach on the GeoQuery dataset, which is publicly available. 4.1 Experimental Settings Data GeoQuery dataset consists of 880 questions paired with their corresponding tree structured semantic representations. Following the experimental setup in Jones et al. (2012), we use the 600 question pairs to train and tune our SMT de1459 coder, and evaluated on the remaining 280. Note that there is another version of GeoQuery dataset where the semantic representation is annotated with lambda calculus expressions and which is extensively studied (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Liang et al., 2011; Kwiatkowski et al., 2013). Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7 We use IRSTLM toolkit </context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Yuk Wah Wong and Raymond Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In Proceedings of ACL 2007, pages 960–967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntaxbased statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>523--530</pages>
<contexts>
<context position="2737" citStr="Yamada and Knight, 2001" startWordPosition="409" endWordPosition="412">anslation (SMT) task, which translates a sentence in NL (i.e., the source language in SMT) into its meaning representation in MRL (i.e., the target language in SMT). Indeed, many attempts have been made to directly apply statistical machine translation (SMT) systems (or methodologies) to semantic parsing (Papineni et al., 1997; Macherey et al., 2001; Wong and Mooney, 2006; Andreas et al., 2013). However, although recent studies (Wong and Mooney, 2006; Andreas et al., 2013) show that semantic parsing with SCFGs, which form the basis of most existing statistical syntax-based translation models (Yamada and Knight, 2001; Chiang, 2007), achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in Andreas et al. (2013) and Lu (2014). The key issues behind the limited success of applying SMT systems directly to semantic parsing lie in the difference between semantic parsing and SMT: MRL is not a real natural language with different properties from natural language. First, MRL is machine-interpretable and thus strictly structured with the meaning representation in a nested structure of functions and arguments. Second, the two langua</context>
<context position="37188" citStr="Yamada and Knight, 2001" startWordPosition="6045" endWordPosition="6048">ferent settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has received a significant amount of attention (Poon and Domingos, 2009; Clarke et al., 2010; Berant et al., 2013; Berant and Liang, 2014). One direction of our future work is to extend the current framework to support the generation of synthetic translation rules from weaker signals (e.g., from question-answer pairs), rather than from aligned parallel data. We also noticed recent advance in tree-based SMT. Applying such string-to-tree or tree-to-tree translation models (Yamada and Knight, 2001; Shen et al., 2008) to semantic parsing will naturally resolve the inconsistent semantic structure issue, though they require additional information to generate tree labels on the target side. However, due to the constraint that each target phrase needs to map to a syntactic constituent, phrase tables in tree-based translation models usually suffer from the low coverage issue, especially if the training data size is small. Therefore, another direction of our future work is to explore specific problems that will emerge when employing tree-based SMT systems to semantic parsing, and provide solu</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntaxbased statistical translation model. In Proceedings of ACL 2001, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of UAI</booktitle>
<pages>658--666</pages>
<contexts>
<context position="21303" citStr="Zettlemoyer and Collins, 2005" startWordPosition="3440" endWordPosition="3443">ate rule. 4 Experimentation In this section, we test our approach on the GeoQuery dataset, which is publicly available. 4.1 Experimental Settings Data GeoQuery dataset consists of 880 questions paired with their corresponding tree structured semantic representations. Following the experimental setup in Jones et al. (2012), we use the 600 question pairs to train and tune our SMT de1459 coder, and evaluated on the remaining 280. Note that there is another version of GeoQuery dataset where the semantic representation is annotated with lambda calculus expressions and which is extensively studied (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Liang et al., 2011; Kwiatkowski et al., 2013). Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results obtained over the two versions are not directly comparable. SMT Setting We use cdec (Dyer et al., 2010) as our HPB decoder. As mentioned above, 600 instances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as training data.7</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>Luke S. Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of UAI 2005, pages 658– 666.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollmann</author>
<author>Ashish Venugopal</author>
</authors>
<title>Syntax augmented machine translation via chart parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of WMT</booktitle>
<pages>138--141</pages>
<contexts>
<context position="9017" citStr="Zollmann and Venugopal, 2006" startWordPosition="1400" endWordPosition="1404">te which nonterminal occurrences are linked by —. The fact that SCFGs in HPB models contain only one type of non-terminal symbol2 is responsible for ill-formed translation (e.g., answer@1 state@1). To this end, we enrich the nonterminals to capture the tree structure information, guiding the translation in favor of well-formed translations. The enrichment of non-terminals is two-fold: first, it can handle MRL with a nested structure to guarantee the well-formed translations; second, related studies in SMT have shown that introducing multiple non-terminal symbols in SCFGs benefits translation (Zollmann and Venugopal, 2006; Li et al., 2012). Given a word sequence eij from position i to position j in MRL&apos;, we enrich the non-terminal symbol X to reflect the internal structure of the word sequence of eij . A correct translation rule selection therefore not only maps source terminals into target terminals, but is both constrained and guided by structure information in the nonterminals. As mentioned earlier, we regard the nested structure in MRL&apos; as function-argument structure, where each function takes one or more arguments as input while its return serves as an argument to the outside function. As in Figure 1, fun</context>
</contexts>
<marker>Zollmann, Venugopal, 2006</marker>
<rawString>Andreas Zollmann and Ashish Venugopal. 2006. Syntax augmented machine translation via chart parsing. In Proceedings of WMT 2006, pages 138–141.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>