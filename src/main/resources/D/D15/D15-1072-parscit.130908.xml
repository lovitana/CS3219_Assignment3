<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.96335">
Sentiment Flow – A General Model of Web Review Argumentation
</title>
<author confidence="0.995469">
Henning Wachsmuth and Johannes Kiesel and Benno Stein
</author>
<affiliation confidence="0.99167">
Faculty of Media, Bauhaus-Universität Weimar, Germany
</affiliation>
<email confidence="0.498277">
{henning.wachsmuth,johannes.kiesel,benno.stein}@uni-weimar.de
</email>
<sectionHeader confidence="0.978789" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999971818181818">
Web reviews have been intensively studied
in argumentation-related tasks such as sen-
timent analysis. However, due to their fo-
cus on content-based features, many sen-
timent analysis approaches are effective
only for reviews from those domains they
have been specifically modeled for. This
paper puts its focus on domain indepen-
dence and asks whether a general model
can be found for how people argue in web
reviews. Our hypothesis is that people ex-
press their global sentiment on a topic with
similar sequences of local sentiment inde-
pendent of the domain. We model such
sentiment flow robustly under uncertainty
through abstraction. To test our hypoth-
esis, we predict global sentiment based on
sentiment flow. In systematic experiments,
we improve over the domain independence
of strong baselines. Our findings suggest
that sentiment flow qualifies as a general
model of web review argumentation.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956122807018">
The web is full of user-generated reviews on prod-
ucts, services, and works of art, like those from
Amazon, TripAdvisor, and Rotten Tomatoes. Such
web reviews provide facts, positive opinions, and
negative opinions on different aspects. By that, the
reviews express, implicitly or explicitly, an overall
opinion on the topic in question. From an abstract
viewpoint, the argumentation of a web review can
thus be seen as a composition of local sentiments
used to justify some global sentiment.
Both local and global sentiment of reviews are
in the focus of numerous sentiment analysis ap-
proaches (cf. Section 2 for details). Many of these
approaches model reviews primarily with content-
based features, derived from the words in the re-
views. The use of words, however, varies strongly
across domains, as illustrated in Figure 1 for a
product, a hotel, and a movie review. As a con-
sequence, sentiment analysis suffers from domain
dependence (Wu et al., 2010), i.e., high effective-
ness is often achieved only in the domain an ap-
proach has been specifically modeled for. To adapt
to other domains, prior knowledge about these
domains or about domain-independent features is
needed (Prettenhofer and Stein, 2010).
This paper considers the question as to whether
the overall argumentation of web reviews can be
modeled in a general way in order to increase do-
main independence in sentiment analysis. We ob-
serve that people structure web reviews largely
sequentially—in contrast to the complex struc-
tures of many other argumentative texts. While the
reviewed aspects differ between domains, our as-
sumption is that the overall argumentation of a
web review is generally represented by a sequence
of local sentiments, called the review’s sentiment
flow (Mao and Lebanon, 2007). In particular, we
hypothesize that, under an adequate model, similar
sentiment flows express similar global sentiments,
also across domains. All reviews in Figure 1, for
instance, express neutral global sentiment starting
with positive, continuing with negative, and end-
ing with positive local sentiment.
Unlike in our previous approach (Wachsmuth et
al., 2014a), we analyze the major abstraction steps
when modeling sentiment flow to represent global
sentiment. A general model should abstract from
both content and other domain differences, such as
a review’s length or the density of local sentiment
in it. Based on web review corpora with known
sentiment flows, we empirically analyze several
model variants across three domains. Our results
offer clear evidence for the truth of our hypothe-
sis, indicating the generality of sentiment flow as
a model of web review argumentation.
The abstract nature of sentiment flow, however,
does not directly achieve domain independence, as
</bodyText>
<page confidence="0.977255">
601
</page>
<note confidence="0.852950555555556">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 601–611,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
Product review from Amazon Hotel review from TripAdvisor Movie review from Rotten Tomatoes
Bought this based on previous reviews and is
generally a good player. Setting it up seemed
relatively straight forward and I&apos;ve managed to
record several times onto the hard drive
without any problems. The picture quality is
also very good and the main reason I bought it
</note>
<bodyText confidence="0.975277785714286">
was the upscaling to match my TV - very
impressive. Downsides are that if you have
built-in freeview on your TV, it does get
confused sometimes and will refuse to allow
you to watch it through either TV or HDD
player - I had to mess around with the settings
several times to make it stop doing this. (Why
did I buy it if I had freeview already? It was
cheaper than to get one without) It is also very
noisy and performs random updates in the
night, which can be annoying. But in terms of
function and ease of use it&apos;s very good.
We stayed overnight at the Castle Inn in San
Francisco in November. It was a fairly
</bodyText>
<note confidence="0.78736">
convenient to Alcatraz Island and California
Academy of Science in Golden Gate Park. We
were looking for a reasonably priced
convenient location in SF that we did not have
to pay for parking. Very basic motel with
continental breakfast. It was within walking
distance to quite a few restaurants (Miller&apos;s
</note>
<figure confidence="0.483510857142857">
East Coast Deli-yummy!)
I did find that the clerk at the desk was rather
unfriendly, though helpful. The free parking
spaces were extremely tight for our mini van.
The noise was not too bad, being only 1 block
from Van Ness Ave.
If you are looking for a no frills, comfortable
</figure>
<bodyText confidence="0.961818">
place to stay, Castle Inn was a good choice.
comfortable beds, mini refrig and basic
something when it brought unnecessary action
into play, such as a child kidnapping and the
problem of drugs being sold in school. There
problems to Heather&apos;s story [...].
was no place to go in developing Heather&apos;s
character by adding these major societal
Solondz knows his subject well, [...] and the
result is an unusual movie that focuses in on a
[...] The film was intense and pulsating when it
zoomed in on Heather&apos;s travails, but lost
subject very few filmmakers have chosen to do.
It was unfortunate that Heather never evolved,
so the cruelty we observed in the beginning of
the film was also the way she was observed
when the film ended; nevertheless, an honest
effort was put forth by the filmmaker to see
how school age children cope with their unique
problems they have.
Global sentiment: neutral (3 out of 5) Global sentiment: neutral (3 out of 5) Global sentiment: neutral (2 out of 3)
</bodyText>
<figureCaption confidence="0.998723">
Figure 1. Example web reviews with neutral global sentiment from three domains, taken from the corpora described in Sec-
tion 5. Corpus annotations of positive and negative local sentiment are marked in light green and medium red, respectively.
</figureCaption>
<bodyText confidence="0.995373083333333">
the recognition of local sentiment in unknown re-
views may still be domain-dependent. We there-
fore also present a novel edit distance approach to
robustly compare flows, when local sentiment is
obtained using state-of-the-art techniques (Socher
et al., 2013). In systematic cross-domain exper-
iments with the given corpora, we classify global
sentiment based on sentiment flow without any do-
main adaptation. While not being perfectly effec-
tive, our approach improves over the domain ro-
bustness of strong baselines.
Altogether, the paper’s main contributions are:
</bodyText>
<listItem confidence="0.99427">
1. Evidence that sentiment flow qualifies as a
general model of the overall argumentation of
web reviews across domains.
2. A domain-robust approach for the classifica-
tion of the global sentiment of web reviews.
</listItem>
<sectionHeader confidence="0.999069" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999948433962264">
As surveyed by Pang and Lee (2008) and by Liu
(2012), numerous sentiment analysis approaches
have been proposed for different text types, lev-
els of granularity, sentiment scales, and domains.
We target at global text-level sentiment of web
reviews. While we distinguish three sentiment
classes here, our approach can be adapted to other
scales. Our goal is not to optimize sentiment anal-
ysis in a specific domain, but to find a model that
supports sentiment analysis across domains.
As common in text classification (Manning et
al., 2008), sentiment analysis often relies on words
and other content features, which tends to be prone
to domain dependence (Wu et al., 2010). Existing
domain adaptation techniques for sentiment analy-
sis require a few training texts from each target do-
main or a few domain-independent pivot features
to align domain-specific features (Prettenhofer and
Stein, 2010). Our model complements these tech-
niques and could be leveraged for pivot features.
In tasks like authorship attribution and argumenta-
tive zoning, non-topical words benefit domain in-
dependence (Menon and Choi, 2011; Ó Séaghdha
and Teufel, 2014). Instead, we focus on the local
sentiment on different aspects in a review here.
Aspect-based sentiment analysis extracts fine-
grained opinions from a review (Popescu and Et-
zioni, 2005). These aspects in turn impact the re-
view’s global sentiment (Wang et al., 2010). How-
ever, relevant aspects naturally tend to be domain-
specific, like the picture quality of HDD players
or the beds of hotels (cf. Figure 1). While weakly-
supervised approaches to extract aspects and local
sentiment exist (Brody and Elhadad, 2010; Lazari-
dou et al., 2013), it is not clear how to align aspects
from different domains. We ignore aspects here,
only preserving the local sentiment itself.
State-of-the-art approaches for classifying local
sentiment within a domain model the composition
of words, e.g., relying on deep learning (Socher
et al., 2013). We do not compete with such an
approach, but we use it to then predict global sen-
timent. Täckström and McDonald (2011) observe
that local and global sentiment correlate, aiming
for the opposite direction, though. In (Wachsmuth
et al., 2014b), we already compute frequent flows
of local sentiment, but we neither analyze their
generality, nor do we use them for prediction.
The idea of modeling sentiment flow was intro-
duced by Mao and Lebanon (2007) who classify
local sentiment based on neighboring local sen-
timent in a review. When inferring global senti-
ment from a flow, however, the authors model only
</bodyText>
<page confidence="0.997769">
602
</page>
<bodyText confidence="0.999778304347826">
single flow positions, not their ordering. In con-
trast, we capture the overall structure of reviews in
(Wachsmuth et al., 2014a) by measuring the simi-
larity of a given flow to known sentiment flow pat-
terns. We point out the domain robustness of sen-
timent flow there, but we still use domain-specific
local sentiment classifiers and we do not handle
some major domain differences of web reviews.
Both limitations are addressed in this paper, where
we align flows similar to how Persing et al. (2010)
align essay organizations.
We claim that sentiment flow models a review’s
argumentation, such that local sentiments ressem-
ble rhetorical moves. Comparable simplifications
are common for scientific argumentation (Teufel,
2014). Usually, argumentative texts are studied
more deeply, considering different types of argu-
ment components and their relations (Mochales
and Moens, 2011). Mining such structure is get-
ting increasing attention recently (Habernal et al.,
2014), also in the analysis of reviews (Villalba and
Saint-Dizier, 2012). To express global sentiment,
however, web reviews argue in simpler ways.
</bodyText>
<sectionHeader confidence="0.931962" genericHeader="method">
3 Web Review Argumentation
</sectionHeader>
<bodyText confidence="0.999780793103448">
Argumentation refers to the exchange of opinions,
to defending positions, and to convincing others
of certain stances (van Eemeren et al., 2014). A
review is a written form of monological argumen-
tation, where an author structures a selection of ar-
guments in order to justify his or her conclusion on
a topic of discussion (Besnard and Hunter, 2008).
Reviews, in particular, discuss products, services,
works of art, or similar. The arguments in a review
correspond to objective facts, positive and nega-
tive opinions, and mixtures of these on the topic
as a whole or on specific aspects of the topic.
In this paper, we are interested in the overall
argumentation of reviews. Our assumption is that
the conclusion of a review’s overall argumentation
consists in its global sentiment. Global sentiment
is often explicitly reflected by an assigned overall
rating, at least for web reviews.
Many web reviews are written by people in an
ad-hoc fashion to quickly share opinions. As a re-
sult, unlike other argumentative texts, web reviews
often remain with a sequential structure (Villalba
and Saint-Dizier, 2012) and miss explicit relations
between the shared opinions. E.g., while the prod-
uct review and the hotel review in Figure 1 cover
opinions on several aspects, no deliberate structure
is found in their argumentation. However, the ex-
cerpt of the more professional movie review shows
that this is not always the case.
</bodyText>
<subsectionHeader confidence="0.998203">
3.1 Domain Differences
</subsectionHeader>
<bodyText confidence="0.999987052631579">
In Figure 1, we categorize domains by source and
topical theme (e.g., Amazon products). Other gra-
nularities would be possible (e.g., consumer elec-
tronics) or other categorization schemes (e.g., user
vs. pro reviews). That being said, we speak of do-
mains only to roughly distinguish web reviews that
vary in how they argue for a conclusion.1 We ob-
serve major differences in three broad respects:
Content Especially topical web review domains
differ widely regarding the terms and phrases that
play a role in their argumentation. This includes
the aspects being discussed (e.g., “beds” of ho-
tels vs. the “subject” of movies) as well as the
words used to express sentiment and their explic-
itness (e.g., “yummy” vs. “an unusual movie”).
Form As sketched above, further differences refer
to the structure and style of web reviews. Some
are rather subtle, like a careful use of paragraph
breaks, whereas others are obvious, like a review’s
length. The movie review in Figure 1, for instance,
is actually over twice as long as the shown excerpt,
starting with an objective synopsis of the plot and
including “sub-reviews” of different aspects.2
Subjectivity Finally, the use of subjectivity varies
across web review domains: First, the density of
sentiment tends to be high in some cases, like ho-
tel reviews (cf. Figure 1), but low in others, like
movie reviews, where objective plot descriptions
and subjective opinions often alternate (the short-
ened excerpt in Figure 1 hides this to some extent).
Second, sentiment is sometimes very intense (as in
the product review in Figure 1), sometimes subtle.
And third, in some domains even single sentences
often contain mixed sentiment, whereas in others
opinions tend to be laid out across sentences.
We will empirically underpin most observations
in Section 5, where we analyze the domain inde-
pendence of the model described next.
</bodyText>
<sectionHeader confidence="0.869059" genericHeader="method">
4 Sentiment Flow as a General Model
</sectionHeader>
<bodyText confidence="0.999564333333333">
In the following, we introduce our model of web
review argumentation. We discuss how to abstract
for generality and how to deal with uncertainty.
</bodyText>
<footnote confidence="0.9851846">
1In the end, this paper seeks for findings that generalize
from domains, making an exact distinction unnecessary.
2Also, many web reviews have explicit structure elements
like a title. To obtain a common ground, however, we con-
sider only the plain text of a web review’s body in this paper.
</footnote>
<page confidence="0.997342">
603
</page>
<figure confidence="0.980201">
Web review Local sentiment Sentiment flow
comprises represents
represents
Overall argumentation Global sentiment
</figure>
<figureCaption confidence="0.737700333333333">
Figure 2. Modeling the overall argumentation of a web re-
view as a flow of positive (light green), neutral (dark gray),
and negative (medium red) local sentiments.
</figureCaption>
<subsectionHeader confidence="0.999797">
4.1 Modeling a Review by its Sentiment Flow
</subsectionHeader>
<bodyText confidence="0.999943285714286">
We propose a fairly simple argumentation model
based on the observation that many web reviews
are organized sequentially (cf. Section 3). As we
assume that the overall argumentation of a web re-
view represents global sentiment in the first place,
we fully abstract from the content of the facts and
opinions that serve as arguments. In particular, we
model the argumentation of a web review solely by
its sentiment flow, i.e., the sequence of local sen-
timents comprised in the review’s text. We do not
presume the granularity of local sentiment, but we
propose to distinguish positive, neutral, and nega-
tive local sentiment, which is the common ground
of related works (cf. Section 2).
Figure 2 illustrates how we model web review
argumentation. Our hypothesis is that similar sen-
timent flows are used across domains of web re-
views to express the same global sentiment. How-
ever, because of the domain differences described
in Section 3, we do not expect that the original
sentiment flows of web reviews generalize well.
</bodyText>
<subsectionHeader confidence="0.99909">
4.2 Abstracting Flows for Generality
</subsectionHeader>
<bodyText confidence="0.999829625">
By concept, sentiment flow avoids to capture con-
tent and some facets of form like paragraph usage.
To abstract from the length of reviews, Mao and
Lebanon (2007) and our approach in (Wachsmuth
et al., 2014a) length-normalize sentiment flow via
interpolation. While this may preserve all infor-
mation, it does not account for sub-reviews and the
density of subjectivity. Here, we investigate more
informed ways of abstracting flows. In particular,
we consider three transformations of flows:
Change Deletion of repeating local sentiments.
The rationale is to reduce subjectivity differences
by focusing on changes of local sentiment.
NoLoops Deletion of repeating sequences of two
or more local sentiments. The rationale is to reduce
length differences by merging similar sub-reviews.
</bodyText>
<figureCaption confidence="0.959778">
Figure 3. The original sentiment flow from Figure 2 and the
resulting flow for each of the three proposed transformations.
</figureCaption>
<bodyText confidence="0.9704114">
2Class Deletion of neutral local sentiments. The
rationale is to reduce length and subjectivity dif-
ferences emanating from objective descriptions.
Figure 3 exemplifies the three transformations.
They are not commutative, as can partly be seen
for the example. In Section 5, we test what combi-
nations of transformations lead to an adequate sen-
timent flow model. While more transformations
will benefit generality, the lost specificity may de-
crease the correlation with global sentiment.
</bodyText>
<subsectionHeader confidence="0.999895">
4.3 Analyzing Flows under Uncertainty
</subsectionHeader>
<bodyText confidence="0.999838633333333">
Given an adequate sentiment flow model, we seek
to find out to what extent it enables domain-robust
sentiment analysis. This brings up two challenges
related to uncertainty: (1) The classification of lo-
cal sentiment in unknown reviews will not be free
of errors, and, (2) reviews may comprise flows for
which the global sentiment is unknown.
Classification errors are naturally problematic
for modeling sentiment flow. At least, some errors
are bypassed by the three transformations. E.g., if
one negative local sentiment in the original flow in
Figure 3 is misclassified as positive, the Change
transformation fixes this. If it is classified as neu-
tral, Change and 2Class together eliminate the ef-
fect. Moreover, errors can be countered by limit-
ing the impact of single positions in a flow.
In (Wachsmuth et al., 2014a), we learn to infer
global sentiment from the Manhattan distances be-
tween a sentiment flow and a set of common flows,
thereby analyzing the flow as a whole. The com-
mon flows are found in a preceding clustering step.
While we adopt the learning approach here, the
Manhattan distances imply that flows are similar
only if their changes are at similar positions.
Instead, we compare sentiment flows (modified
with zero to three transformations) based on their
normalized minimum edit distance (Cormen et al.,
2009). Analog to Persing et al. (2010), we incre-
mentally compute the edit distance using sequence
alignment. To this end, we specify costs for pos-
</bodyText>
<figure confidence="0.932879375">
Original
sentiment flow
After Change
transformation
After NoLoops
transformation
After 2Class
transformation
</figure>
<bodyText confidence="0.998343888888889">
We stayed overnight at the Castle Inn in San
Francisco in November. It was a fairly
convenient to Alcatraz Island and California
Academy of Science in Golden Gate Park. We
were looking for a reasonably priced
convenient location in SF that we did not have
to pay for parking. Very basic motel with
comfortable beds, mini refrig and basic
continental breakfast. It was within walking
distance to quite a few restaurants (Miller&apos;s
East Coast Deli-yummy!)
I did find that the clerk at the desk was rather
unfriendly, though helpful. The free parking
spaces were extremely tight for our mini van.
The noise was not too bad, being only 1 block
from Van Ness Ave.
If you are looking for a no frills, comfortable
place to stay, Castle Inn was a good choice.
</bodyText>
<page confidence="0.989777">
604
</page>
<figure confidence="0.562878">
Sentiment flow 1 (length 4)
</figure>
<figureCaption confidence="0.9882845">
Figure 4. Computation of the normalized edit distance of two
sentiment flows, resulting in (2 · 0 + 3 · 1/3) / 4 = 1/4.
</figureCaption>
<bodyText confidence="0.9996272">
sible edit operations, i.e., substitutions, insertions,
and deletions of single local sentiments. We map
positive local sentiment to the value 1.0, neutral to
0.5, and negative to 0.0. The cost is then provided
by a function d for any two values s and s&apos;:
</bodyText>
<equation confidence="0.774577">
If s&apos; substitutes s.
+ (1−α) · |s−s&apos; |If s&apos; is inserted
or deleted after s.
</equation>
<bodyText confidence="0.9998818">
Here, α ∈ [0, 1] specifies some fixed cost (we set
α to 1/3 in Section 6). The intuition behind d is to
have a higher cost the more s and s&apos; differ. Still, in-
sertions and deletions are never free, as they affect
differences that remain after applying transforma-
tions to abstract from irrelevant differences.
Figure 4 illustrates the alignment of two flows
as a shortest-path search. We normalize the flows’
minimum edit distance by their maximum length.
Before we evaluate if the edit distance captures
flow similarity more robustly than the Manhattan
distance, we analyze what representation of senti-
ment flows proves most general. This will also re-
veal that the proposed abstractions reduce the need
to perform clustering for finding common flows.
</bodyText>
<sectionHeader confidence="0.429622" genericHeader="method">
5 Analysis of the Generality of the Model
</sectionHeader>
<bodyText confidence="0.99995975">
We now report on experiments on corpora from
three domains that empirically analyze to what ex-
tent different sentiment flow variants qualify as
general models of web review argumentation.3
</bodyText>
<subsectionHeader confidence="0.972267">
5.1 Ground-Truth Data with Sentiment Flow
</subsectionHeader>
<bodyText confidence="0.999433857142857">
We process three existing corpora with local senti-
ment annotations of complete texts. While the first
two are available online, we obtained the last from
the authors. Each corpus comprises English web
reviews from one broad topical domain. Table 1
lists some statistics of the three corpora, which in-
dicate clear domain differences.
</bodyText>
<footnote confidence="0.8681024">
Product Domain The Finegrained Sentiment
Data Set, Release 1 (Täckström and McDonald,
2011) contains 294 Amazon reviews, nearly bal-
3The source code that can be used to reproduce the exper-
iments is provided at http://www.arguana.com/software.
</footnote>
<table confidence="0.999332166666667">
Corpus Sentences Tokens Local sentiment
domain per text per sent.
positive neutral negative
Product 14.0 22.7 24.1% 41.5% 34.4%
Hotel 11.5 18.3 38.0% 20.3% 41.7%
Movie 28.8 30.3 17.6% 61.2% 21.2%
</table>
<tableCaption confidence="0.931498">
Table 1. Sentences, tokens, and annotated local sentiments
for the domains represented by the given web review corpora.
</tableCaption>
<bodyText confidence="0.999960194444445">
anced among five categories: books (59 reviews),
DVD (59), electronics (57), music (59), and video-
games (60). We use the first three for training and
the others for testing. Under the authors’ mapping
from Amazon star ratings to global sentiment, all
categories subsume 19 to 20 positive, neutral, and
negative reviews each. In each review, every sen-
tence is classified as positive, negative, neutral,
mixed, or irrelevant. To match the other corpora,
we merge the three latter into one neutral class.
Hotel Domain Our ArguAna TripAdvisor cor-
pus (Wachsmuth et al., 2014b) consists of 2100
TripAdvisor reviews, 300 for seven hotel locations
each. Three locations belong to a predefined train-
ing set and two to a validation and a test set each.
For all locations, the reviews are evenly distributed
over the five TripAdvisor overall scores. In accor-
dance with the product corpus, we see score 4–5 as
positive global sentiment, 3 as neutral, and 1–2 as
negative. In each review, all main clauses together
with their subordinate clauses have been classified
as being positive, negative, or neutral.
Movie Domain Finally, the third corpus (Mao and
Lebanon, 2007) compiles 450 Rotten Tomatoes re-
views from the Cornell Movie Review Data scale
dataset v1.0 (Pang and Lee, 2005) that refer to two
authors. We use the 201 reviews of Scott Renshaw
for training and the 249 of Dennis Schwartz for
testing. The reviews lack punctuation, capitaliza-
tion, and their overall ratings. We recovered the
overall ratings from the original dataset based on
the rating scale 0–2, resulting in 178 positive, 139
neutral, and 133 negative reviews. In each review,
Mao and Lebanon (2007) classified all sentences
to be very positive, positive, neutral, negative, or
very negative, which we reduce to three classes.
</bodyText>
<subsectionHeader confidence="0.954473">
5.2 Experimental Set-up
</subsectionHeader>
<bodyText confidence="0.999954285714286">
To find the most general model of web review ar-
gumentation across domains, we compare 16 sen-
timent flow variants using three measures:
Model Variants The original sentiment flow of all
corpus reviews can be directly derived from the
ground-truth data. In each model variant, the flow
is modified by a combination of zero to three of the
</bodyText>
<figure confidence="0.999206763157895">
Sentiment flow 2
(length 3)
1
1
1
1/3
1 1 1 1
1
1
0
1
0
1
1/3 1/3 1/3 1
1/3 1/3
1/3
1
1
1
1
0
1
1 1
1/3 1/3
1
1
0 1
1
1/3
1/3
1
0
0
1
1/3
d(s, s&apos;) =
�|s − s&apos;|
α
</figure>
<page confidence="0.993397">
605
</page>
<table confidence="0.999952156862745">
Training Model variant # Flows Aggregate recall Weighted precision W’d Hellinger distance
domain of sentiment flows
all 1% Product Hotel Movie Product Hotel Movie Product Hotel Movie
Product 2class-change-noloops 7 7 100.0 100.0 100.0 75.6 69.9 62.4 0.17 0.21 0.23
175 reviews 2class-noloops-change 11 7 90.8 96.0 98.0 74.1 71.0 64.6 0.17 0.26 0.28
change-noloops-2class 22 14 89.9 81.5 80.7 74.8 74.6 68.3 0.19 0.26 0.26
noloops-2class-change 11 8 89.9 86.1 86.9 73.8 72.3 66.2 0.16 0.24 0.27
2class-change 12 8 89.9 85.6 87.1 74.8 73.2 66.3 0.17 0.25 0.27
change-2class-noloops 37 20 85.7 85.8 76.9 78.4 74.1 72.5 0.19 0.26 0.33
noloops-change-2class 35 19 81.5 72.8 62.2 76.3 76.3 73.6 0.17 0.26 0.28
2class-noloops 49 24 77.3 62.9 60.0 81.5 80.8 76.7 0.27 0.27 0.31
change-2class 47 22 77.3 61.6 49.6 79.3 79.5 71.7 0.20 0.24 0.28
change-noloops 55 29 70.6 64.6 59.1 84.5 77.2 72.2 0.25 0.30 0.32
noloops-2class 67 24 62.2 48.2 36.7 85.1 82.7 78.8 0.18 0.25 0.22
noloops-change 78 29 55.5 52.0 30.9 89.4 79.7 77.0 0.16 0.28 0.23
change 93 30 49.6 43.5 27.3 89.8 82.6 75.6 0.18 0.25 0.22
2class 91 27 45.4 36.8 28.7 83.3 85.1 79.8 0.21 0.22 0.22
noloops 153 17 12.6 14.0 6.0 100.0 91.5 85.2 0.07 0.11 0.04
original 173 2 0.8 3.6 0.0 100.0 94.7 0.0 0.02 0.05 0.00
Hotel 2class-change-noloops 7 7 100.0 100.0 100.0 71.1 68.5 62.4 0.19 0.06 0.13
900 reviews 2class-noloops-change 20 14 99.7 98.8 99.8 72.0 69.3 64.8 0.25 0.08 0.17
change-noloops-2class 85 21 99.0 91.2 91.3 74.6 72.0 67.9 0.26 0.14 0.19
noloops-2class-change 27 15 100.0 98.3 99.6 72.4 69.8 65.2 0.26 0.10 0.17
2class-change 31 17 99.7 98.2 98.9 72.7 70.6 65.6 0.26 0.11 0.19
change-2class-noloops 91 22 92.9 91.7 85.3 75.5 72.5 72.7 0.23 0.14 0.26
noloops-change-2class 145 21 90.5 85.3 76.7 74.4 74.6 73.0 0.28 0.15 0.29
2class-noloops 246 19 85.0 77.2 75.6 78.0 81.0 75.6 0.27 0.20 0.27
change-2class 231 19 88.1 74.0 56.2 75.7 76.4 73.5 0.26 0.17 0.28
change-noloops 212 24 69.7 77.7 66.7 80.0 75.5 73.7 0.20 0.18 0.24
noloops-2class 398 14 64.6 55.3 44.0 81.6 82.5 77.8 0.19 0.15 0.26
noloops-change 343 17 48.0 64.0 38.0 81.6 77.9 77.8 0.19 0.15 0.21
change 426 14 36.1 52.3 24.7 83.0 77.7 77.5 0.18 0.14 0.16
2class 549 17 54.4 32.5 29.8 83.1 86.2 77.6 0.14 0.08 0.17
noloops 626 9 9.2 27.7 1.8 92.6 83.7 100.0 0.04 0.08 0.01
original 743 4 1.4 16.5 0.0 75.0 78.8 0.0 0.01 0.04 0.00
Movie 2class-change-noloops 6 6 97.3 94.5 99.6 71.7 70.3 58.9 0.26 0.10 0.19
201 reviews 2class-noloops-change 14 10 96.9 93.7 99.2 72.6 70.7 59.9 0.32 0.15 0.24
change-noloops-2class 44 17 96.6 85.4 91.6 75.4 73.9 62.7 0.34 0.22 0.32
noloops-2class-change 16 14 96.9 92.2 98.0 73.0 71.0 59.8 0.33 0.16 0.26
2class-change 19 15 96.9 90.8 98.0 73.3 72.1 61.1 0.33 0.18 0.28
change-2class-noloops 57 19 85.7 73.0 81.1 76.2 73.4 68.8 0.36 0.25 0.30
noloops-change-2class 84 19 82.0 63.0 72.7 77.6 72.3 71.8 0.34 0.25 0.27
2class-noloops 103 20 78.2 58.0 62.7 78.7 85.1 72.4 0.34 0.24 0.27
change-2class 107 20 57.5 34.4 40.6 72.8 76.2 72.3 0.33 0.22 0.22
change-noloops 94 17 66.7 41.6 66.7 81.6 81.0 70.5 0.35 0.21 0.33
noloops-2class 154 8 38.8 22.1 28.5 86.8 89.7 85.9 0.19 0.14 0.14
noloops-change 146 9 30.6 19.7 30.5 87.8 83.3 77.6 0.16 0.14 0.18
change 161 8 16.0 9.9 13.7 85.1 87.5 82.4 0.15 0.10 0.12
2class 182 5 21.8 11.1 8.0 90.6 96.6 95.0 0.08 0.06 0.03
noloops 200 5 0.3 0.6 0.4 100.0 91.7 100.0 0.01 0.01 0.00
original 200 0 0.0 0.0 0.0 0.0 0.0 0.0 0.00 0.00 0.00
</table>
<tableCaption confidence="0.991231666666667">
Table 2. Results on the generality of sentiment flow for all evaluated model variants on ground-truth data for each combination
of training and test domain. The most general variants in terms of both aggregated recall and weighted precision are marked in
bold. For illustration, # Flows lists the numbers of all flows in the training reviews and of those with a recall of at least 1%.
</tableCaption>
<bodyText confidence="0.999069384615385">
transformations from Section 4. All variants are
named according to the applied transformations.
Measures In (Wachsmuth et al., 2014b), we pro-
pose specific notions of the recall and precision of
a sentiment flow f in a given collection of reviews:
The recall Rf denotes the relative frequency of re-
views with flow f, while the precision Pf(s) with
respect to some global sentiment s denotes the rel-
ative co-occurrence of f with s. Here, we extend
these measures for complete models as follows.
We define the aggregate recall of a model on a
collection of reviews as the sum of the recall of the
set F of all its known sentiment flows:
</bodyText>
<equation confidence="0.950494">
Aggregate Recall(F) = � Rf
f∈F
</equation>
<bodyText confidence="0.965825666666667">
With weighted precision, we denote the sum of
the maximum precision of each such flow in F,
weighted with the recall of the flow:
</bodyText>
<equation confidence="0.905618666666667">
�
Weighted Precision(F) =
f∈F
</equation>
<bodyText confidence="0.9996252">
In addition, we assess how much two domains dif-
fer under a given model variant. To this end, we
measure the Hellinger distance Hf (in the range
[0, 1]) between the global sentiment distributions
of each flow f known for both domains:
</bodyText>
<figure confidence="0.964588">
{Pf(s)} · Rf
max
S
</figure>
<page confidence="0.994168">
606
</page>
<table confidence="0.99981864">
Model variant Domain Most common flow Rank Recall Positive Neutral Negative
change-2class-noloops Product (negative, negative) 1. 13.6 0.0% 25.0% 75.0%
Hotel 9. 4.2 0.0% 8.9% 91.1%
Movie 4. 6.7 0.0% 0.0% 100.0%
Product (positive, negative, positive) 8. 3.4 34.1% 65.9% 0.0%
Hotel 1. 10.5 45.1% 49.6% 5.3%
Movie 14. 2.3 0.0% 73.3% 26.7%
Product (negative, negative, positive, negative) 10. 3.4 0.0% 33.3% 66.7%
Hotel 15. 2.2 0.0% 16.7% 83.3%
Movie 1. 8.6 0.0% 57.9% 42.1%
2class-noloops Product (negative, negative) 1. 15.3 7.6% 29.6% 62.8%
Hotel 5. 4.4 0.0% 8.5% 91.5%
Movie 1. 6.7 0.0% 0.0% 100.0%
Product (positive, positive) 12.8 86.8% 8.8% 4.4%
Hotel 1. 7.6 87.8% 12.2% 0.0%
Movie 10. 2.1 61.1% 38.9% 0.0%
change-noloops Product (positive, neutral, positive) 1. 10.5 94.6% 0.0% 5.4%
Hotel 6. 3.3 88.9% 11.1 % 0.0%
Movie 23. 1.3 100.0% 0.0% 0.0%
Product (positive) 22. 1.1 50.9% 49.1% 0.0%
Hotel 6.6 83.1% 14.1% 2.8%
Movie – – – – –
Product (neutral, negative) 9.1 6.5% 24.9% 68.6%
Hotel 5. 3.5 0.0% 10.5% 89.5%
Movie 1. 7.6 8.6% 0.0% 91.4%
</table>
<tableCaption confidence="0.971044">
Table 3. The most common flow in the training set of each evaluated domain for three of the 16 evaluated model variants. For
each flow, the recall rank, the recall, and the distribution over the three global sentiments within each domain are given.
</tableCaption>
<equation confidence="0.980017">
Hf (p1, p2) = 1· j:(y p1(s) − y p2(s))2
S
</equation>
<bodyText confidence="0.999960916666667">
Here, p1 and p2 denote the global sentiment dis-
tributions of f. For weighted Hellinger distances,
we multiply the distance of each flow in F with
the sum of its recall in both domains.4
Experiments Given all 16 possible model variants
for all reviews, we analyze the generality of each
variant for every combination of domains. I.e., we
first determine the known sentiment flows on the
training set of one domain. Then, we compute the
aggregate recall, weighted precision, and weighted
Hellinger distance once for the in-domain test set
and once for both full out-of-domain corpora.5
</bodyText>
<subsectionHeader confidence="0.95496">
5.3 Results on the Generality across Domains
</subsectionHeader>
<bodyText confidence="0.998118571428571">
Table 2 contains the number of known flows and
the experiment results for each domain combina-
tion. Model variants whose benefit seems limited
are not marked in bold: The bottom six have a low
aggregate recall in all domains, suggesting that
they do not generalize well. Most significantly, the
original flows from the movie training set are not
4We chose the Hellinger distance, as it applies to distribu-
tions with zero-probabilities (unlike alternatives like the KL-
divergence). Also, it is a true metric (Lebret and Collobert,
2014), allowing for relative comparisons. On the flipside, the
meaning of concrete distances is not clear by itself.
5Here, we use all occurring sentiment flows to evaluate a
model variant in its overall manifestation. In Section 6, we
consider only frequent flows in order to refrain from outliers.
found in any test domain. The top five achieve al-
most total recall, but much less precision than the
others, indicating that they abstract too much.
Among the five robust model variants (marked
in bold), change-2class-noloops has the highest
aggregate recall throughout, ranging from 73.0 to
92.9. Consistently, global sentiment is represented
best by change-noloops in the product domain and
by 2class-noloops in the other domains (with up to
85.1 weighted precision). Also, 2class-noloops is
third-best in terms of recall. While no clear “win-
ner” exists, this variant seems most promising for
modeling web review argumentation.
The weighted Hellinger distances show that the
domain differences of many variants are small. On
average, change-2class has the most stable global
sentiment distribution. Most distances are only
slightly higher out-of-domain than in-domain or
even lower. Hence, sentiment flows hardly vary
stronger across domains than within a domain.
</bodyText>
<subsectionHeader confidence="0.987041">
5.4 The Most Common Sentiment Flows
</subsectionHeader>
<bodyText confidence="0.999946">
To investigate what sentiment flows actually occur
in web reviews, we determined the flow with high-
est recall for the training set of each corpus. For
comparability, we balanced the flows in the train-
ing set before by weighting their occurrences ac-
cording to the distribution of global sentiment.6
</bodyText>
<footnote confidence="0.687971">
6E.g., if 40% of all reviews are positive, 30% neutral, and
30% negative, then the occurrences of flows with positive
global sentiment are weighted by 0.75 and the others by 1.0.
</footnote>
<page confidence="0.996081">
607
</page>
<bodyText confidence="0.991814333333333">
Table 3 shows the recall and the sentiment dis-
tribution of each such flow in all evaluated do-
mains exemplarily for three of the model variants
discussed above. While high-recall flows naturally
tend to be simple, we also observe more complex
flows, such as (negative, negative, positive, neg-
ative) in case of change-2class-noloops. Except
for the change-noloops flow (positive), which does
not occur at all in the movie training set, all shown
flows are common across domains, achieving a re-
call of over 2% in most cases. For 2class-noloops,
only two flows are listed, because (negative, nega-
tive) is the most common flow in both the product
and the movie domain. Regarding the distribution
of global sentiments, nearly all flows behave sim-
ilar across domains. The only exception is (posi-
tive, negative, positive) in change-2class-noloops,
which never turns out negative in product reviews
but never positive in movie reviews.
Altogether, we conclude that sentiment flow is
not a fully precise model of web review argumen-
tation, but it proves general with respect to global
sentiment. What remains to be checked is the ben-
efit of modeling sentiment flow under uncertainty.
6 Analysis of the Robustness of the Model
Finally, we evaluate how effectively and domain-
robustly sentiment flow predicts global sentiment,
when local sentiment is not given but classified. To
analyze the domain independence of our model,
no knowledge about target domains is used.
</bodyText>
<subsectionHeader confidence="0.999896">
6.1 Sentiment Analysis Approaches
</subsectionHeader>
<bodyText confidence="0.999749538461539">
To classify sentiment flows, we build on the edit
distance approach presented in Section 4:
Model Variants As in Section 5, we look at all 16
possible variants of the proposed model. For each
variant, we determine all sentiment flows that rep-
resent at least 1% of all reviews in a given training
set. We learn a mapping from the edit distance be-
tween a review’s sentiment flow and each of these
flows to global sentiment. For robustness, we also
combine different model variants.
We compare the accuracy of the model variants
to previous approaches evaluated on the given cor-
pora. In addition, we analyze domain robustness
based on three baselines, which relate to the three
abstraction levels in Figure 2 (cf. Section 4):
Bag-of-Words (b1) The frequencies of all tokens
that occur in at least 5% of all training reviews.
Local Sentiment (b2) The frequencies of positive,
neutral, and negative local sentiment in a review as
well as the first and last local sentiment (analog to
Section 4, local sentiment is mapped to [0,1]).
Sentiment Flow Patterns (b3) The Manhattan
distances to those sentiment flows obtained by our
clustering approach (Wachsmuth et al., 2014a).
All approaches are used as feature types in ma-
chine learning (with values normalized to [0,1]).
</bodyText>
<subsectionHeader confidence="0.996497">
6.2 Experimental Set-up
</subsectionHeader>
<bodyText confidence="0.999954580645161">
We tackle three-class sentiment analysis, which is
supposed to be particularly hard due to the fuzzy
nature of neutral sentiment (Täckström and Mc-
Donald, 2011). Given the three review corpora
described in Section 5, we proceed as follows:7
Local Sentiment For feature computations, we
split all reviews into tokens and sentences. Then,
we classify local sentiment with the algorithm of
Socher et al. (2013) from Stanford CoreNLP.8 The
algorithm was trained on subjective movie review
sentences. We found that its accuracy is limited to
around 50% on the given corpora, partly as it tends
to misclassify objective sentences. Still, we use it
to avoid any adaptation to the domains at hand.
Global Sentiment To determine global sentiment,
we perform supervised learning based on the fea-
ture types outlined above. In particular, we use the
default configuration of the random forest classi-
fier from Weka (Breiman, 2001; Hall et al., 2009)
without any parameter optimization.
Experiments Having classified local sentiment in
all reviews, we learn a random forest classifier on
each feature type and different feature sets for all
combinations of training and test domain. To pre-
vent class bias, the training sets are balanced with
duplicate oversampling. Since the size of the cor-
pora is limited, we evaluate in-domain accuracy on
the whole corpora using 10-fold cross-validation,
averaged over five runs. Afterwards, we test the
out-of-domain accuracy by applying the learned
classifier to the other complete corpora.
</bodyText>
<subsectionHeader confidence="0.988186">
6.3 Results on the Domain Robustness
</subsectionHeader>
<bodyText confidence="0.995607285714286">
Table 4 lists accuracy results for all domain combi-
nations. In the movie domain, we obtain an over-
all accuracy of 71.8. On average, we thus succeed
over Pang and Lee (2005) who report about 75 on
the reviews of Scott Renshaw and 63 on those of
Dennis Schwartz. Similarly, we beat all our three-
class sentiment analysis results from (Wachsmuth,
</bodyText>
<footnote confidence="0.999954">
7Again, see http://www.arguana.com/software for code.
8Stanford CoreNLP, http://nlp.stanford.edu/software
</footnote>
<page confidence="0.986707">
608
</page>
<figure confidence="0.824782575">
Training Feature types Product Hotel Movie
Product b1 Bag-of-words
b2 Local sentiment
b3 Sentiment flow patterns
All baseline features b1-3
v1 change-2class
v2 change-2class-noloops
v3 noloops-2class
v4 2class
v5 2class-noloops
All model variants v1-5
All flows (v1-5+b3)
All sentiment (v1-5+b2-3)
All features (v1-5+b1-3)
Hotel b1 Bag-of-words
b2 Local sentiment
b3 Sentiment flow patterns
All baseline features b1-3
v1 change-2class
v2 change-2class-noloops
v3 noloops-2class
v4 2class
v5 2class-noloops
All model variants v1-5
All flows (v1-5+b3)
All sentiment (v1-5+b2-3)
All features (v1-5+b1-3)
Movie b1 Bag-of-words
b2 Local sentiment
b3 Sentiment flow patterns
All baseline features b1-3
v1 change-2class
v2 change-2class-noloops
v3 noloops-2class
v4 2class
v5 2class-noloops
All model variants v1-5
All flows (v1-5+b3)
All sentiment (v1-5+b2-3)
All features (v1-5+b1-3)
</figure>
<tableCaption confidence="0.751704">
Table 4. Accuracy of predicting 3-class global sentiment for
each combination of training and test domain using the base-
lines and/or a selection of the 16 evaluated model variants.
</tableCaption>
<bodyText confidence="0.999949272727273">
2015) in the hotel domain. In the product domain,
our approach fails to compete with Täckström and
McDonald (2011) who classify the global senti-
ment of 66.6% of all reviews correctly after train-
ing on large-scale product corpora. The small size
of the given corpus explains the limited in-domain
accuracy in Table 4; even some out-of-domain
classifiers perform better on the product reviews.
Still, the value 54.2 significantly improves over all
baselines under a paired t-test (p &lt; 5%).
As expected, bag-of-words (b1) proves strong
in some in-domain tasks—achieving even the best
overall accuracy in the hotel domain (79.6)—but
it consistently fails out-of-domain. Although less
clear, similar observations can be made for b2.
This shows that a restriction to the distribution of
local sentiment is insufficient to tackle domain de-
pendence. The sentiment flow patterns are compa-
rably effective out-of-domain, but still suffer from
the domain change on the evaluated corpora.
For space reasons, we compare the baselines b1
to b3 only to a selection of five of the most effec-
tive model variants, v1 to v5. Alone, these variants
only occasionally do better than the sentiment flow
patterns (b3). However, their combination (v1–5)
clearly outperforms b3 in 4 out of 6 out-of-domain
experiments. A strong variant is 2class-noloops,
which already proved general in the results from
Section 5. In contrast, 2class (v4) appears contro-
versial. While it turns out being both effective and
domain-robust when training in the product and
hotel domain, no 2class sentiment flow represents
at least 1% of the movie corpus, emphasizing that
more abstraction is required for robustness.
Altogether, the bottom lines of each domain in
Table 4 provide clear evidence that our approach
improves domain robustness in sentiment analy-
sis: In all cases, the out-of-domain accuracy is best
when using our sentiment flow features v1–5. At
the same time, our results suggest that very high
effectiveness might require more adaptation to the
target domain. In this regard, modeling sentiment
flow serves as a promising basis to align more ef-
fective but domain-dependent features.
</bodyText>
<sectionHeader confidence="0.998377" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999991115384615">
This paper puts the goal of domain independence
in the sentiment analysis of web reviews into the
focus. In particular, we hypothesize that an ab-
stract model of the local sentiment flow in a review
generally captures the review’s overall argumenta-
tion regarding global sentiment. In ground-truth
data from three domains, we have found clear ev-
idence for our hypothesis, indicating that people
write reviews in similar ways across domains.
On this basis, we have presented a novel learn-
ing approach, which predicts the global sentiment
of a review from the edit distance between the re-
view’s sentiment flow and a set of common flows.
While we determined common flows with cluster-
ing in previous work (Wachsmuth et al., 2014a),
instead here we rely on different flow abstractions
at the same time. Systematic experiments empha-
size that, in this manner, our approach achieves
domain robustness without any domain adaptation
even when the accuracy of the local sentiment in
the flows is limited.
However, our experiments also show that sen-
timent flow alone does not always suffice to pre-
dict global sentiment. In future sentiment analysis
approaches, sentiment flows may therefore rather
serve as pivot features for domain adaptation.
</bodyText>
<table confidence="0.998571487179487">
49.0 45.9 32.4
51.7 50.4 39.3
46.8 57.5 47.8
51.9 58.8 49.8
46.0 46.6 41.3
48.7 46.9 38.4
48.7 50.1 43.6
52.0 53.8 44.9
48.0 50.4 42.4
50.5 51.3 42.4
50.9 58.2 51.1
50.8 59.7 50.2
54.2 60.0 48.7
37.8 79.6 39.8
51.4 64.2 51.1
50.7 74.2 51.1
54.8 78.9 48.7
43.2 54.3 43.3
46.6 49.4 45.3
49.3 57.4 46.7
52.4 58.6 51.6
46.9 54.0 48.2
53.4 69.0 54.7
53.8 75.5 53.6
57.1 75.6 51.8
56.4 79.0 53.3
35.0 41.2 64.8
43.2 44.2 59.0
42.2 39.5 67.2
48.0 50.4 70.5
42.9 44.0 44.8
40.8 48.1 44.2
44.9 46.5 50.7
– – –
44.2 44.7 55.9
44.6 49.7 60.9
47.6 51.9 65.2
49.7 54.1 65.9
48.0 52.3 71.8
</table>
<page confidence="0.985773">
609
</page>
<sectionHeader confidence="0.605981" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991581320754717">
Philippe Besnard and Anthony Hunter. 2008. Ele-
ments of Argumentation. The MIT Press.
Raquel Mochales and Marie-Francine Moens. 2011.
Argumentation Mining. Artificial Intelligence and
Law, 19(1):1–22.
Leo Breiman. 2001. Random Forests. Machine Learn-
ing, 45(1):5–32.
Samuel Brody and Noemie Elhadad. 2010. An Un-
supervised Aspect-Sentiment Model for Online Re-
views. In Human Language Technologies: The 2010
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 804–812.
Thomas H. Cormen, Charles E. Leiserson, Ronald L.
Rivest, and Clifford Stein. 2009. Introduction to
Algorithms. MIT Press, third edition.
Ivan Habernal, Judith Eckle-Kohler, and Iryna
Gurevych. 2014. Argumentation Mining on the
Web from Information Seeking Perspective. In Pro-
ceedings of the Workshop on Frontiers and Connec-
tions between Argumentation Theory and Natural
Language Processing, pages 26–39.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA Data Mining Software: An Up-
date. SIGKDD Explorations, 11(1):10–18.
Minqing Hu and Bing Liu. 2004. Mining and Sum-
marizing Customer Reviews. In Proceedings of the
Tenth ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pages 168–
177.
Angeliki Lazaridou, Ivan Titov, and Caroline
Sporleder. 2013. A Bayesian Model for Joint
Unsupervised Induction of Sentiment, Aspect and
Discourse Representations. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1630–1639.
Rémi Lebret and Ronan Collobert. 2014. Word Em-
beddings through Hellinger PCA. In Proceedings
of the 14th Conference of the European Chapter
of the Association for Computational Linguistics,
pages 482–490.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan &amp; Claypool.
Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Schütze. 2008. Introduction to Information
Retrieval. Cambridge University Press.
Yi Mao and Guy Lebanon. 2007. Isotonic Conditional
Random Fields and Local Sentiment Flow. Ad-
vances in Neural Information Processing Systems,
19:961–968.
Rohith Menon and Yejin Choi. 2011. Domain In-
dependent Authorship Attribution without Domain
Adaptation. In Proceedings of the International
Conference on Recent Advances in Natural Lan-
guage Processing 2011, pages 309–315.
Diarmuid Ó Séaghdha and Simone Teufel. 2014. Un-
supervised Learning of Rhetorical Structure with
Un-topic Models. In Proceedings of he 25th Inter-
national Conference on Computational Linguistics:
Technical Papers, pages 2–13.
Bo Pang and Lillian Lee. 2005. Seeing Stars: Ex-
ploiting Class Relationships for Sentiment Catego-
rization with Respect to Rating Scales. In Proceed-
ings of the 43rd Annual Meeting on Association for
Computational Linguistics, pages 115–124.
Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis. Foundations and Trends in In-
formal Retrieval, 2(1–2):1–135.
Isaac Persing, Alan Davis, and Vincent Ng. 2010.
Modeling Essay Organization in Student Essays. In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages
229–239.
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing Product Features and Opinions from Reviews.
In Proceedings of the Conference on Human Lan-
guage Technology and Empirical Methods in Natu-
ral Language Processing, pages 339–346.
Peter Prettenhofer and Benno Stein. 2010. Cross-
Language Text Classification using Structural Cor-
respondence Learning. In Proceedings of the 48th
Annual Meeting of the Association of Computational
Linguistics, pages 1118–1127.
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Y. Ng,
and Christopher Potts. 2013. Recursive Deep Mod-
els for Semantic Compositionality Over a Sentiment
Treebank. In Proceedings of the 2013 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1631–1642.
Oscar Täckström and Ryan McDonald. 2011. Discov-
ering Fine-grained Sentiment with Latent Variable
Structured Prediction Models. In Proceedings of the
33rd European Conference on Advances in Informa-
tion Retrieval, pages 368–374.
Simone Teufel. 2014. Scientific Argumentation Detec-
tion as Limited-Domain Intention Recognition. In
Proceedings of the Workshop on Frontiers and Con-
nections between Argumentation Theory and Natu-
ral Language Processing, pages 101–109.
Frans H. van Eemeren, Bart Garssen, Erik C. W.
Krabbe, A. Francisca Snoeck Henkemans, Bart Ver-
heij, and Jean H. M. Wagemans. 2014. Handbook
ofArgumentation Theory. Springer.
</reference>
<page confidence="0.967691">
610
</page>
<reference confidence="0.999860515151515">
Maria Paz Garcia Villalba and Patrick Saint-Dizier.
2012. Some Facets of Argument Mining for Opin-
ion Analysis. In Proceedings of the 2012 Confer-
ence on Computational Models of Argument, pages
23–34.
Henning Wachsmuth, Martin Trenkmann, Benno Stein,
and Gregor Engels. 2014a. Modeling Review Argu-
mentation for Robust Sentiment Analysis. In Pro-
ceedings of the 25th International Conference on
Computational Linguistics: Technical Papers, pages
553–564.
Henning Wachsmuth, Martin Trenkmann, Benno Stein,
Gregor Engels, and Tsvetomira Palakarska. 2014b.
A Review Corpus for Argumentation Analysis. In
Proceedings of the 15th International Conference on
Intelligent Text Processing and Computational Lin-
guistics, pages 115–127.
Henning Wachsmuth. 2015. Pipelines for Ad-hoc
Large-Scale Text Mining. To appear in Lecture
Notes in Computer Science. Springer, available at
http://is.upb.de/?id=wachsmuth.
Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010.
Latent Aspect Rating Analysis on Review Text Data:
A Rating Regression Approach. In Proceedings of
the 16th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pages 783–
792.
Qiong Wu, Songbo Tan, Miyi Duan, and Xueqi Cheng.
2010. A Two-Stage Algorithm for Domain Adap-
tation with Application to Sentiment Transfer Prob-
lems. In Information Retrieval Technology, volume
6458 of Lecture Notes in Computer Science, pages
443–453. Springer.
</reference>
<page confidence="0.997988">
611
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.976415">
<title confidence="0.999545">Sentiment Flow – A General Model of Web Review Argumentation</title>
<author confidence="0.987803">Wachsmuth Kiesel</author>
<affiliation confidence="0.991654">Faculty of Media, Bauhaus-Universität Weimar,</affiliation>
<abstract confidence="0.999771130434783">Web reviews have been intensively studied in argumentation-related tasks such as sentiment analysis. However, due to their focus on content-based features, many sentiment analysis approaches are effective only for reviews from those domains they have been specifically modeled for. This paper puts its focus on domain independence and asks whether a general model can be found for how people argue in web reviews. Our hypothesis is that people express their global sentiment on a topic with similar sequences of local sentiment independent of the domain. We model such flow under uncertainty through abstraction. To test our hypothesis, we predict global sentiment based on sentiment flow. In systematic experiments, we improve over the domain independence of strong baselines. Our findings suggest that sentiment flow qualifies as a general model of web review argumentation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Philippe Besnard</author>
<author>Anthony Hunter</author>
</authors>
<title>Elements of Argumentation.</title>
<date>2008</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="11728" citStr="Besnard and Hunter, 2008" startWordPosition="1877" endWordPosition="1880">les and Moens, 2011). Mining such structure is getting increasing attention recently (Habernal et al., 2014), also in the analysis of reviews (Villalba and Saint-Dizier, 2012). To express global sentiment, however, web reviews argue in simpler ways. 3 Web Review Argumentation Argumentation refers to the exchange of opinions, to defending positions, and to convincing others of certain stances (van Eemeren et al., 2014). A review is a written form of monological argumentation, where an author structures a selection of arguments in order to justify his or her conclusion on a topic of discussion (Besnard and Hunter, 2008). Reviews, in particular, discuss products, services, works of art, or similar. The arguments in a review correspond to objective facts, positive and negative opinions, and mixtures of these on the topic as a whole or on specific aspects of the topic. In this paper, we are interested in the overall argumentation of reviews. Our assumption is that the conclusion of a review’s overall argumentation consists in its global sentiment. Global sentiment is often explicitly reflected by an assigned overall rating, at least for web reviews. Many web reviews are written by people in an ad-hoc fashion to</context>
</contexts>
<marker>Besnard, Hunter, 2008</marker>
<rawString>Philippe Besnard and Anthony Hunter. 2008. Elements of Argumentation. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raquel Mochales</author>
<author>Marie-Francine Moens</author>
</authors>
<date>2011</date>
<journal>Argumentation Mining. Artificial Intelligence and Law,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="11123" citStr="Mochales and Moens, 2011" startWordPosition="1781" endWordPosition="1784">nt flow there, but we still use domain-specific local sentiment classifiers and we do not handle some major domain differences of web reviews. Both limitations are addressed in this paper, where we align flows similar to how Persing et al. (2010) align essay organizations. We claim that sentiment flow models a review’s argumentation, such that local sentiments ressemble rhetorical moves. Comparable simplifications are common for scientific argumentation (Teufel, 2014). Usually, argumentative texts are studied more deeply, considering different types of argument components and their relations (Mochales and Moens, 2011). Mining such structure is getting increasing attention recently (Habernal et al., 2014), also in the analysis of reviews (Villalba and Saint-Dizier, 2012). To express global sentiment, however, web reviews argue in simpler ways. 3 Web Review Argumentation Argumentation refers to the exchange of opinions, to defending positions, and to convincing others of certain stances (van Eemeren et al., 2014). A review is a written form of monological argumentation, where an author structures a selection of arguments in order to justify his or her conclusion on a topic of discussion (Besnard and Hunter, </context>
</contexts>
<marker>Mochales, Moens, 2011</marker>
<rawString>Raquel Mochales and Marie-Francine Moens. 2011. Argumentation Mining. Artificial Intelligence and Law, 19(1):1–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Random Forests.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="37889" citStr="Breiman, 2001" startWordPosition="6236" endWordPosition="6237"> into tokens and sentences. Then, we classify local sentiment with the algorithm of Socher et al. (2013) from Stanford CoreNLP.8 The algorithm was trained on subjective movie review sentences. We found that its accuracy is limited to around 50% on the given corpora, partly as it tends to misclassify objective sentences. Still, we use it to avoid any adaptation to the domains at hand. Global Sentiment To determine global sentiment, we perform supervised learning based on the feature types outlined above. In particular, we use the default configuration of the random forest classifier from Weka (Breiman, 2001; Hall et al., 2009) without any parameter optimization. Experiments Having classified local sentiment in all reviews, we learn a random forest classifier on each feature type and different feature sets for all combinations of training and test domain. To prevent class bias, the training sets are balanced with duplicate oversampling. Since the size of the corpora is limited, we evaluate in-domain accuracy on the whole corpora using 10-fold cross-validation, averaged over five runs. Afterwards, we test the out-of-domain accuracy by applying the learned classifier to the other complete corpora. </context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Leo Breiman. 2001. Random Forests. Machine Learning, 45(1):5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Noemie Elhadad</author>
</authors>
<title>An Unsupervised Aspect-Sentiment Model for Online Reviews. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>804--812</pages>
<contexts>
<context position="9318" citStr="Brody and Elhadad, 2010" startWordPosition="1495" endWordPosition="1498">tative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an approach, but we use it to then predict global sentiment. Täckström and McDonald (2011) observe that local and global sentiment correlate, aiming for the opposite direction, though. In (Wachsmuth et al., 2014b), we already compute frequent flows of lo</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Samuel Brody and Noemie Elhadad. 2010. An Unsupervised Aspect-Sentiment Model for Online Reviews. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 804–812.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Cormen</author>
<author>Charles E Leiserson</author>
<author>Ronald L Rivest</author>
<author>Clifford Stein</author>
</authors>
<title>Introduction to Algorithms.</title>
<date>2009</date>
<publisher>MIT Press,</publisher>
<note>third edition.</note>
<contexts>
<context position="19307" citStr="Cormen et al., 2009" startWordPosition="3094" endWordPosition="3097">r, errors can be countered by limiting the impact of single positions in a flow. In (Wachsmuth et al., 2014a), we learn to infer global sentiment from the Manhattan distances between a sentiment flow and a set of common flows, thereby analyzing the flow as a whole. The common flows are found in a preceding clustering step. While we adopt the learning approach here, the Manhattan distances imply that flows are similar only if their changes are at similar positions. Instead, we compare sentiment flows (modified with zero to three transformations) based on their normalized minimum edit distance (Cormen et al., 2009). Analog to Persing et al. (2010), we incrementally compute the edit distance using sequence alignment. To this end, we specify costs for posOriginal sentiment flow After Change transformation After NoLoops transformation After 2Class transformation We stayed overnight at the Castle Inn in San Francisco in November. It was a fairly convenient to Alcatraz Island and California Academy of Science in Golden Gate Park. We were looking for a reasonably priced convenient location in SF that we did not have to pay for parking. Very basic motel with comfortable beds, mini refrig and basic continental </context>
</contexts>
<marker>Cormen, Leiserson, Rivest, Stein, 2009</marker>
<rawString>Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2009. Introduction to Algorithms. MIT Press, third edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Habernal</author>
<author>Judith Eckle-Kohler</author>
<author>Iryna Gurevych</author>
</authors>
<title>Argumentation Mining on the Web from Information Seeking Perspective.</title>
<date>2014</date>
<booktitle>In Proceedings of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing,</booktitle>
<pages>26--39</pages>
<contexts>
<context position="11211" citStr="Habernal et al., 2014" startWordPosition="1794" endWordPosition="1797">andle some major domain differences of web reviews. Both limitations are addressed in this paper, where we align flows similar to how Persing et al. (2010) align essay organizations. We claim that sentiment flow models a review’s argumentation, such that local sentiments ressemble rhetorical moves. Comparable simplifications are common for scientific argumentation (Teufel, 2014). Usually, argumentative texts are studied more deeply, considering different types of argument components and their relations (Mochales and Moens, 2011). Mining such structure is getting increasing attention recently (Habernal et al., 2014), also in the analysis of reviews (Villalba and Saint-Dizier, 2012). To express global sentiment, however, web reviews argue in simpler ways. 3 Web Review Argumentation Argumentation refers to the exchange of opinions, to defending positions, and to convincing others of certain stances (van Eemeren et al., 2014). A review is a written form of monological argumentation, where an author structures a selection of arguments in order to justify his or her conclusion on a topic of discussion (Besnard and Hunter, 2008). Reviews, in particular, discuss products, services, works of art, or similar. The</context>
</contexts>
<marker>Habernal, Eckle-Kohler, Gurevych, 2014</marker>
<rawString>Ivan Habernal, Judith Eckle-Kohler, and Iryna Gurevych. 2014. Argumentation Mining on the Web from Information Seeking Perspective. In Proceedings of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing, pages 26–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA Data Mining Software: An Update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="37909" citStr="Hall et al., 2009" startWordPosition="6238" endWordPosition="6241">d sentences. Then, we classify local sentiment with the algorithm of Socher et al. (2013) from Stanford CoreNLP.8 The algorithm was trained on subjective movie review sentences. We found that its accuracy is limited to around 50% on the given corpora, partly as it tends to misclassify objective sentences. Still, we use it to avoid any adaptation to the domains at hand. Global Sentiment To determine global sentiment, we perform supervised learning based on the feature types outlined above. In particular, we use the default configuration of the random forest classifier from Weka (Breiman, 2001; Hall et al., 2009) without any parameter optimization. Experiments Having classified local sentiment in all reviews, we learn a random forest classifier on each feature type and different feature sets for all combinations of training and test domain. To prevent class bias, the training sets are balanced with duplicate oversampling. Since the size of the corpora is limited, we evaluate in-domain accuracy on the whole corpora using 10-fold cross-validation, averaged over five runs. Afterwards, we test the out-of-domain accuracy by applying the learned classifier to the other complete corpora. 6.3 Results on the D</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA Data Mining Software: An Update. SIGKDD Explorations, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and Summarizing Customer Reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 168– 177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Lazaridou</author>
<author>Ivan Titov</author>
<author>Caroline Sporleder</author>
</authors>
<title>A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1630--1639</pages>
<contexts>
<context position="9343" citStr="Lazaridou et al., 2013" startWordPosition="1499" endWordPosition="1503">l words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an approach, but we use it to then predict global sentiment. Täckström and McDonald (2011) observe that local and global sentiment correlate, aiming for the opposite direction, though. In (Wachsmuth et al., 2014b), we already compute frequent flows of local sentiment, but we nei</context>
</contexts>
<marker>Lazaridou, Titov, Sporleder, 2013</marker>
<rawString>Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder. 2013. A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1630–1639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rémi Lebret</author>
<author>Ronan Collobert</author>
</authors>
<title>Word Embeddings through Hellinger PCA.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>482--490</pages>
<contexts>
<context position="32419" citStr="Lebret and Collobert, 2014" startWordPosition="5358" endWordPosition="5361">t and once for both full out-of-domain corpora.5 5.3 Results on the Generality across Domains Table 2 contains the number of known flows and the experiment results for each domain combination. Model variants whose benefit seems limited are not marked in bold: The bottom six have a low aggregate recall in all domains, suggesting that they do not generalize well. Most significantly, the original flows from the movie training set are not 4We chose the Hellinger distance, as it applies to distributions with zero-probabilities (unlike alternatives like the KLdivergence). Also, it is a true metric (Lebret and Collobert, 2014), allowing for relative comparisons. On the flipside, the meaning of concrete distances is not clear by itself. 5Here, we use all occurring sentiment flows to evaluate a model variant in its overall manifestation. In Section 6, we consider only frequent flows in order to refrain from outliers. found in any test domain. The top five achieve almost total recall, but much less precision than the others, indicating that they abstract too much. Among the five robust model variants (marked in bold), change-2class-noloops has the highest aggregate recall throughout, ranging from 73.0 to 92.9. Consist</context>
</contexts>
<marker>Lebret, Collobert, 2014</marker>
<rawString>Rémi Lebret and Ronan Collobert. 2014. Word Embeddings through Hellinger PCA. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 482–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool.</publisher>
<contexts>
<context position="7721" citStr="Liu (2012)" startWordPosition="1247" endWordPosition="1248">iques (Socher et al., 2013). In systematic cross-domain experiments with the given corpora, we classify global sentiment based on sentiment flow without any domain adaptation. While not being perfectly effective, our approach improves over the domain robustness of strong baselines. Altogether, the paper’s main contributions are: 1. Evidence that sentiment flow qualifies as a general model of the overall argumentation of web reviews across domains. 2. A domain-robust approach for the classification of the global sentiment of web reviews. 2 Related Work As surveyed by Pang and Lee (2008) and by Liu (2012), numerous sentiment analysis approaches have been proposed for different text types, levels of granularity, sentiment scales, and domains. We target at global text-level sentiment of web reviews. While we distinguish three sentiment classes here, our approach can be adapted to other scales. Our goal is not to optimize sentiment analysis in a specific domain, but to find a model that supports sentiment analysis across domains. As common in text classification (Manning et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone to domain dependenc</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Schütze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="8207" citStr="Manning et al., 2008" startWordPosition="1321" endWordPosition="1324">oach for the classification of the global sentiment of web reviews. 2 Related Work As surveyed by Pang and Lee (2008) and by Liu (2012), numerous sentiment analysis approaches have been proposed for different text types, levels of granularity, sentiment scales, and domains. We target at global text-level sentiment of web reviews. While we distinguish three sentiment classes here, our approach can be adapted to other scales. Our goal is not to optimize sentiment analysis in a specific domain, but to find a model that supports sentiment analysis across domains. As common in text classification (Manning et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone to domain dependence (Wu et al., 2010). Existing domain adaptation techniques for sentiment analysis require a few training texts from each target domain or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014)</context>
</contexts>
<marker>Manning, Raghavan, Schütze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze. 2008. Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Mao</author>
<author>Guy Lebanon</author>
</authors>
<title>Isotonic Conditional Random Fields and Local Sentiment Flow.</title>
<date>2007</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<pages>19--961</pages>
<contexts>
<context position="2916" citStr="Mao and Lebanon, 2007" startWordPosition="449" endWordPosition="452">-independent features is needed (Prettenhofer and Stein, 2010). This paper considers the question as to whether the overall argumentation of web reviews can be modeled in a general way in order to increase domain independence in sentiment analysis. We observe that people structure web reviews largely sequentially—in contrast to the complex structures of many other argumentative texts. While the reviewed aspects differ between domains, our assumption is that the overall argumentation of a web review is generally represented by a sequence of local sentiments, called the review’s sentiment flow (Mao and Lebanon, 2007). In particular, we hypothesize that, under an adequate model, similar sentiment flows express similar global sentiments, also across domains. All reviews in Figure 1, for instance, express neutral global sentiment starting with positive, continuing with negative, and ending with positive local sentiment. Unlike in our previous approach (Wachsmuth et al., 2014a), we analyze the major abstraction steps when modeling sentiment flow to represent global sentiment. A general model should abstract from both content and other domain differences, such as a review’s length or the density of local senti</context>
<context position="10085" citStr="Mao and Lebanon (2007)" startWordPosition="1619" endWordPosition="1622">nt itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an approach, but we use it to then predict global sentiment. Täckström and McDonald (2011) observe that local and global sentiment correlate, aiming for the opposite direction, though. In (Wachsmuth et al., 2014b), we already compute frequent flows of local sentiment, but we neither analyze their generality, nor do we use them for prediction. The idea of modeling sentiment flow was introduced by Mao and Lebanon (2007) who classify local sentiment based on neighboring local sentiment in a review. When inferring global sentiment from a flow, however, the authors model only 602 single flow positions, not their ordering. In contrast, we capture the overall structure of reviews in (Wachsmuth et al., 2014a) by measuring the similarity of a given flow to known sentiment flow patterns. We point out the domain robustness of sentiment flow there, but we still use domain-specific local sentiment classifiers and we do not handle some major domain differences of web reviews. Both limitations are addressed in this paper</context>
<context position="16707" citStr="Mao and Lebanon (2007)" startWordPosition="2689" endWordPosition="2692">nd negative local sentiment, which is the common ground of related works (cf. Section 2). Figure 2 illustrates how we model web review argumentation. Our hypothesis is that similar sentiment flows are used across domains of web reviews to express the same global sentiment. However, because of the domain differences described in Section 3, we do not expect that the original sentiment flows of web reviews generalize well. 4.2 Abstracting Flows for Generality By concept, sentiment flow avoids to capture content and some facets of form like paragraph usage. To abstract from the length of reviews, Mao and Lebanon (2007) and our approach in (Wachsmuth et al., 2014a) length-normalize sentiment flow via interpolation. While this may preserve all information, it does not account for sub-reviews and the density of subjectivity. Here, we investigate more informed ways of abstracting flows. In particular, we consider three transformations of flows: Change Deletion of repeating local sentiments. The rationale is to reduce subjectivity differences by focusing on changes of local sentiment. NoLoops Deletion of repeating sequences of two or more local sentiments. The rationale is to reduce length differences by merging</context>
<context position="23863" citStr="Mao and Lebanon, 2007" startWordPosition="3846" endWordPosition="3849">sor corpus (Wachsmuth et al., 2014b) consists of 2100 TripAdvisor reviews, 300 for seven hotel locations each. Three locations belong to a predefined training set and two to a validation and a test set each. For all locations, the reviews are evenly distributed over the five TripAdvisor overall scores. In accordance with the product corpus, we see score 4–5 as positive global sentiment, 3 as neutral, and 1–2 as negative. In each review, all main clauses together with their subordinate clauses have been classified as being positive, negative, or neutral. Movie Domain Finally, the third corpus (Mao and Lebanon, 2007) compiles 450 Rotten Tomatoes reviews from the Cornell Movie Review Data scale dataset v1.0 (Pang and Lee, 2005) that refer to two authors. We use the 201 reviews of Scott Renshaw for training and the 249 of Dennis Schwartz for testing. The reviews lack punctuation, capitalization, and their overall ratings. We recovered the overall ratings from the original dataset based on the rating scale 0–2, resulting in 178 positive, 139 neutral, and 133 negative reviews. In each review, Mao and Lebanon (2007) classified all sentences to be very positive, positive, neutral, negative, or very negative, wh</context>
</contexts>
<marker>Mao, Lebanon, 2007</marker>
<rawString>Yi Mao and Guy Lebanon. 2007. Isotonic Conditional Random Fields and Local Sentiment Flow. Advances in Neural Information Processing Systems, 19:961–968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohith Menon</author>
<author>Yejin Choi</author>
</authors>
<title>Domain Independent Authorship Attribution without Domain Adaptation.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Recent Advances in Natural Language Processing</booktitle>
<pages>309--315</pages>
<contexts>
<context position="8777" citStr="Menon and Choi, 2011" startWordPosition="1407" endWordPosition="1410">mmon in text classification (Manning et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone to domain dependence (Wu et al., 2010). Existing domain adaptation techniques for sentiment analysis require a few training texts from each target domain or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align asp</context>
</contexts>
<marker>Menon, Choi, 2011</marker>
<rawString>Rohith Menon and Yejin Choi. 2011. Domain Independent Authorship Attribution without Domain Adaptation. In Proceedings of the International Conference on Recent Advances in Natural Language Processing 2011, pages 309–315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid Ó Séaghdha</author>
<author>Simone Teufel</author>
</authors>
<title>Unsupervised Learning of Rhetorical Structure with Un-topic Models.</title>
<date>2014</date>
<booktitle>In Proceedings of he 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>2--13</pages>
<contexts>
<context position="8807" citStr="Séaghdha and Teufel, 2014" startWordPosition="1412" endWordPosition="1415">ion (Manning et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone to domain dependence (Wu et al., 2010). Existing domain adaptation techniques for sentiment analysis require a few training texts from each target domain or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. W</context>
</contexts>
<marker>Séaghdha, Teufel, 2014</marker>
<rawString>Diarmuid Ó Séaghdha and Simone Teufel. 2014. Unsupervised Learning of Rhetorical Structure with Un-topic Models. In Proceedings of he 25th International Conference on Computational Linguistics: Technical Papers, pages 2–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="23975" citStr="Pang and Lee, 2005" startWordPosition="3865" endWordPosition="3868">e locations belong to a predefined training set and two to a validation and a test set each. For all locations, the reviews are evenly distributed over the five TripAdvisor overall scores. In accordance with the product corpus, we see score 4–5 as positive global sentiment, 3 as neutral, and 1–2 as negative. In each review, all main clauses together with their subordinate clauses have been classified as being positive, negative, or neutral. Movie Domain Finally, the third corpus (Mao and Lebanon, 2007) compiles 450 Rotten Tomatoes reviews from the Cornell Movie Review Data scale dataset v1.0 (Pang and Lee, 2005) that refer to two authors. We use the 201 reviews of Scott Renshaw for training and the 249 of Dennis Schwartz for testing. The reviews lack punctuation, capitalization, and their overall ratings. We recovered the overall ratings from the original dataset based on the rating scale 0–2, resulting in 178 positive, 139 neutral, and 133 negative reviews. In each review, Mao and Lebanon (2007) classified all sentences to be very positive, positive, neutral, negative, or very negative, which we reduce to three classes. 5.2 Experimental Set-up To find the most general model of web review argumentati</context>
<context position="38698" citStr="Pang and Lee (2005)" startWordPosition="6363" endWordPosition="6366">feature sets for all combinations of training and test domain. To prevent class bias, the training sets are balanced with duplicate oversampling. Since the size of the corpora is limited, we evaluate in-domain accuracy on the whole corpora using 10-fold cross-validation, averaged over five runs. Afterwards, we test the out-of-domain accuracy by applying the learned classifier to the other complete corpora. 6.3 Results on the Domain Robustness Table 4 lists accuracy results for all domain combinations. In the movie domain, we obtain an overall accuracy of 71.8. On average, we thus succeed over Pang and Lee (2005) who report about 75 on the reviews of Scott Renshaw and 63 on those of Dennis Schwartz. Similarly, we beat all our threeclass sentiment analysis results from (Wachsmuth, 7Again, see http://www.arguana.com/software for code. 8Stanford CoreNLP, http://nlp.stanford.edu/software 608 Training Feature types Product Hotel Movie Product b1 Bag-of-words b2 Local sentiment b3 Sentiment flow patterns All baseline features b1-3 v1 change-2class v2 change-2class-noloops v3 noloops-2class v4 2class v5 2class-noloops All model variants v1-5 All flows (v1-5+b3) All sentiment (v1-5+b2-3) All features (v1-5+b1</context>
</contexts>
<marker>Pang, Lee, 2005</marker>
<rawString>Bo Pang and Lillian Lee. 2005. Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis. Foundations and Trends in Informal Retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="7703" citStr="Pang and Lee (2008)" startWordPosition="1241" endWordPosition="1244">sing state-of-the-art techniques (Socher et al., 2013). In systematic cross-domain experiments with the given corpora, we classify global sentiment based on sentiment flow without any domain adaptation. While not being perfectly effective, our approach improves over the domain robustness of strong baselines. Altogether, the paper’s main contributions are: 1. Evidence that sentiment flow qualifies as a general model of the overall argumentation of web reviews across domains. 2. A domain-robust approach for the classification of the global sentiment of web reviews. 2 Related Work As surveyed by Pang and Lee (2008) and by Liu (2012), numerous sentiment analysis approaches have been proposed for different text types, levels of granularity, sentiment scales, and domains. We target at global text-level sentiment of web reviews. While we distinguish three sentiment classes here, our approach can be adapted to other scales. Our goal is not to optimize sentiment analysis in a specific domain, but to find a model that supports sentiment analysis across domains. As common in text classification (Manning et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone t</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion Mining and Sentiment Analysis. Foundations and Trends in Informal Retrieval, 2(1–2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isaac Persing</author>
<author>Alan Davis</author>
<author>Vincent Ng</author>
</authors>
<title>Modeling Essay Organization in Student Essays.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>229--239</pages>
<contexts>
<context position="10744" citStr="Persing et al. (2010)" startWordPosition="1731" endWordPosition="1734"> neighboring local sentiment in a review. When inferring global sentiment from a flow, however, the authors model only 602 single flow positions, not their ordering. In contrast, we capture the overall structure of reviews in (Wachsmuth et al., 2014a) by measuring the similarity of a given flow to known sentiment flow patterns. We point out the domain robustness of sentiment flow there, but we still use domain-specific local sentiment classifiers and we do not handle some major domain differences of web reviews. Both limitations are addressed in this paper, where we align flows similar to how Persing et al. (2010) align essay organizations. We claim that sentiment flow models a review’s argumentation, such that local sentiments ressemble rhetorical moves. Comparable simplifications are common for scientific argumentation (Teufel, 2014). Usually, argumentative texts are studied more deeply, considering different types of argument components and their relations (Mochales and Moens, 2011). Mining such structure is getting increasing attention recently (Habernal et al., 2014), also in the analysis of reviews (Villalba and Saint-Dizier, 2012). To express global sentiment, however, web reviews argue in simpl</context>
<context position="19340" citStr="Persing et al. (2010)" startWordPosition="3100" endWordPosition="3103">miting the impact of single positions in a flow. In (Wachsmuth et al., 2014a), we learn to infer global sentiment from the Manhattan distances between a sentiment flow and a set of common flows, thereby analyzing the flow as a whole. The common flows are found in a preceding clustering step. While we adopt the learning approach here, the Manhattan distances imply that flows are similar only if their changes are at similar positions. Instead, we compare sentiment flows (modified with zero to three transformations) based on their normalized minimum edit distance (Cormen et al., 2009). Analog to Persing et al. (2010), we incrementally compute the edit distance using sequence alignment. To this end, we specify costs for posOriginal sentiment flow After Change transformation After NoLoops transformation After 2Class transformation We stayed overnight at the Castle Inn in San Francisco in November. It was a fairly convenient to Alcatraz Island and California Academy of Science in Golden Gate Park. We were looking for a reasonably priced convenient location in SF that we did not have to pay for parking. Very basic motel with comfortable beds, mini refrig and basic continental breakfast. It was within walking </context>
</contexts>
<marker>Persing, Davis, Ng, 2010</marker>
<rawString>Isaac Persing, Alan Davis, and Vincent Ng. 2010. Modeling Essay Organization in Student Essays. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 229–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting Product Features and Opinions from Reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>339--346</pages>
<contexts>
<context position="8992" citStr="Popescu and Etzioni, 2005" startWordPosition="1440" endWordPosition="1444">on techniques for sentiment analysis require a few training texts from each target domain or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., rely</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting Product Features and Opinions from Reviews. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 339–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Prettenhofer</author>
<author>Benno Stein</author>
</authors>
<title>CrossLanguage Text Classification using Structural Correspondence Learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>1118--1127</pages>
<contexts>
<context position="2356" citStr="Prettenhofer and Stein, 2010" startWordPosition="360" endWordPosition="363">alysis approaches (cf. Section 2 for details). Many of these approaches model reviews primarily with contentbased features, derived from the words in the reviews. The use of words, however, varies strongly across domains, as illustrated in Figure 1 for a product, a hotel, and a movie review. As a consequence, sentiment analysis suffers from domain dependence (Wu et al., 2010), i.e., high effectiveness is often achieved only in the domain an approach has been specifically modeled for. To adapt to other domains, prior knowledge about these domains or about domain-independent features is needed (Prettenhofer and Stein, 2010). This paper considers the question as to whether the overall argumentation of web reviews can be modeled in a general way in order to increase domain independence in sentiment analysis. We observe that people structure web reviews largely sequentially—in contrast to the complex structures of many other argumentative texts. While the reviewed aspects differ between domains, our assumption is that the overall argumentation of a web review is generally represented by a sequence of local sentiments, called the review’s sentiment flow (Mao and Lebanon, 2007). In particular, we hypothesize that, un</context>
<context position="8563" citStr="Prettenhofer and Stein, 2010" startWordPosition="1375" endWordPosition="1378">uish three sentiment classes here, our approach can be adapted to other scales. Our goal is not to optimize sentiment analysis in a specific domain, but to find a model that supports sentiment analysis across domains. As common in text classification (Manning et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone to domain dependence (Wu et al., 2010). Existing domain adaptation techniques for sentiment analysis require a few training texts from each target domain or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality o</context>
</contexts>
<marker>Prettenhofer, Stein, 2010</marker>
<rawString>Peter Prettenhofer and Benno Stein. 2010. CrossLanguage Text Classification using Structural Correspondence Learning. In Proceedings of the 48th Annual Meeting of the Association of Computational Linguistics, pages 1118–1127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1631--1642</pages>
<contexts>
<context position="7138" citStr="Socher et al., 2013" startWordPosition="1152" endWordPosition="1155">e. Global sentiment: neutral (3 out of 5) Global sentiment: neutral (3 out of 5) Global sentiment: neutral (2 out of 3) Figure 1. Example web reviews with neutral global sentiment from three domains, taken from the corpora described in Section 5. Corpus annotations of positive and negative local sentiment are marked in light green and medium red, respectively. the recognition of local sentiment in unknown reviews may still be domain-dependent. We therefore also present a novel edit distance approach to robustly compare flows, when local sentiment is obtained using state-of-the-art techniques (Socher et al., 2013). In systematic cross-domain experiments with the given corpora, we classify global sentiment based on sentiment flow without any domain adaptation. While not being perfectly effective, our approach improves over the domain robustness of strong baselines. Altogether, the paper’s main contributions are: 1. Evidence that sentiment flow qualifies as a general model of the overall argumentation of web reviews across domains. 2. A domain-robust approach for the classification of the global sentiment of web reviews. 2 Related Work As surveyed by Pang and Lee (2008) and by Liu (2012), numerous sentim</context>
<context position="9634" citStr="Socher et al., 2013" startWordPosition="1544" endWordPosition="1547">n impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an approach, but we use it to then predict global sentiment. Täckström and McDonald (2011) observe that local and global sentiment correlate, aiming for the opposite direction, though. In (Wachsmuth et al., 2014b), we already compute frequent flows of local sentiment, but we neither analyze their generality, nor do we use them for prediction. The idea of modeling sentiment flow was introduced by Mao and Lebanon (2007) who classify local sentiment based on neighboring local sentiment in a review. When inferring global sentiment from a flow, however, the authors mod</context>
<context position="37380" citStr="Socher et al. (2013)" startWordPosition="6152" endWordPosition="6155">ances to those sentiment flows obtained by our clustering approach (Wachsmuth et al., 2014a). All approaches are used as feature types in machine learning (with values normalized to [0,1]). 6.2 Experimental Set-up We tackle three-class sentiment analysis, which is supposed to be particularly hard due to the fuzzy nature of neutral sentiment (Täckström and McDonald, 2011). Given the three review corpora described in Section 5, we proceed as follows:7 Local Sentiment For feature computations, we split all reviews into tokens and sentences. Then, we classify local sentiment with the algorithm of Socher et al. (2013) from Stanford CoreNLP.8 The algorithm was trained on subjective movie review sentences. We found that its accuracy is limited to around 50% on the given corpora, partly as it tends to misclassify objective sentences. Still, we use it to avoid any adaptation to the domains at hand. Global Sentiment To determine global sentiment, we perform supervised learning based on the feature types outlined above. In particular, we use the default configuration of the random forest classifier from Weka (Breiman, 2001; Hall et al., 2009) without any parameter optimization. Experiments Having classified loca</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013. Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631–1642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Täckström</author>
<author>Ryan McDonald</author>
</authors>
<title>Discovering Fine-grained Sentiment with Latent Variable Structured Prediction Models.</title>
<date>2011</date>
<booktitle>In Proceedings of the 33rd European Conference on Advances in Information Retrieval,</booktitle>
<pages>368--374</pages>
<contexts>
<context position="9754" citStr="Täckström and McDonald (2011)" startWordPosition="1566" endWordPosition="1569">inspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an approach, but we use it to then predict global sentiment. Täckström and McDonald (2011) observe that local and global sentiment correlate, aiming for the opposite direction, though. In (Wachsmuth et al., 2014b), we already compute frequent flows of local sentiment, but we neither analyze their generality, nor do we use them for prediction. The idea of modeling sentiment flow was introduced by Mao and Lebanon (2007) who classify local sentiment based on neighboring local sentiment in a review. When inferring global sentiment from a flow, however, the authors model only 602 single flow positions, not their ordering. In contrast, we capture the overall structure of reviews in (Wach</context>
<context position="22239" citStr="Täckström and McDonald, 2011" startWordPosition="3587" endWordPosition="3590">ts on corpora from three domains that empirically analyze to what extent different sentiment flow variants qualify as general models of web review argumentation.3 5.1 Ground-Truth Data with Sentiment Flow We process three existing corpora with local sentiment annotations of complete texts. While the first two are available online, we obtained the last from the authors. Each corpus comprises English web reviews from one broad topical domain. Table 1 lists some statistics of the three corpora, which indicate clear domain differences. Product Domain The Finegrained Sentiment Data Set, Release 1 (Täckström and McDonald, 2011) contains 294 Amazon reviews, nearly bal3The source code that can be used to reproduce the experiments is provided at http://www.arguana.com/software. Corpus Sentences Tokens Local sentiment domain per text per sent. positive neutral negative Product 14.0 22.7 24.1% 41.5% 34.4% Hotel 11.5 18.3 38.0% 20.3% 41.7% Movie 28.8 30.3 17.6% 61.2% 21.2% Table 1. Sentences, tokens, and annotated local sentiments for the domains represented by the given web review corpora. anced among five categories: books (59 reviews), DVD (59), electronics (57), music (59), and videogames (60). We use the first three </context>
<context position="37133" citStr="Täckström and McDonald, 2011" startWordPosition="6112" endWordPosition="6116">ws. Local Sentiment (b2) The frequencies of positive, neutral, and negative local sentiment in a review as well as the first and last local sentiment (analog to Section 4, local sentiment is mapped to [0,1]). Sentiment Flow Patterns (b3) The Manhattan distances to those sentiment flows obtained by our clustering approach (Wachsmuth et al., 2014a). All approaches are used as feature types in machine learning (with values normalized to [0,1]). 6.2 Experimental Set-up We tackle three-class sentiment analysis, which is supposed to be particularly hard due to the fuzzy nature of neutral sentiment (Täckström and McDonald, 2011). Given the three review corpora described in Section 5, we proceed as follows:7 Local Sentiment For feature computations, we split all reviews into tokens and sentences. Then, we classify local sentiment with the algorithm of Socher et al. (2013) from Stanford CoreNLP.8 The algorithm was trained on subjective movie review sentences. We found that its accuracy is limited to around 50% on the given corpora, partly as it tends to misclassify objective sentences. Still, we use it to avoid any adaptation to the domains at hand. Global Sentiment To determine global sentiment, we perform supervised </context>
<context position="40153" citStr="Täckström and McDonald (2011)" startWordPosition="6566" endWordPosition="6569">+b3) All sentiment (v1-5+b2-3) All features (v1-5+b1-3) Movie b1 Bag-of-words b2 Local sentiment b3 Sentiment flow patterns All baseline features b1-3 v1 change-2class v2 change-2class-noloops v3 noloops-2class v4 2class v5 2class-noloops All model variants v1-5 All flows (v1-5+b3) All sentiment (v1-5+b2-3) All features (v1-5+b1-3) Table 4. Accuracy of predicting 3-class global sentiment for each combination of training and test domain using the baselines and/or a selection of the 16 evaluated model variants. 2015) in the hotel domain. In the product domain, our approach fails to compete with Täckström and McDonald (2011) who classify the global sentiment of 66.6% of all reviews correctly after training on large-scale product corpora. The small size of the given corpus explains the limited in-domain accuracy in Table 4; even some out-of-domain classifiers perform better on the product reviews. Still, the value 54.2 significantly improves over all baselines under a paired t-test (p &lt; 5%). As expected, bag-of-words (b1) proves strong in some in-domain tasks—achieving even the best overall accuracy in the hotel domain (79.6)—but it consistently fails out-of-domain. Although less clear, similar observations can be</context>
</contexts>
<marker>Täckström, McDonald, 2011</marker>
<rawString>Oscar Täckström and Ryan McDonald. 2011. Discovering Fine-grained Sentiment with Latent Variable Structured Prediction Models. In Proceedings of the 33rd European Conference on Advances in Information Retrieval, pages 368–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Teufel</author>
</authors>
<title>Scientific Argumentation Detection as Limited-Domain Intention Recognition.</title>
<date>2014</date>
<booktitle>In Proceedings of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing,</booktitle>
<pages>101--109</pages>
<contexts>
<context position="8807" citStr="Teufel, 2014" startWordPosition="1414" endWordPosition="1415">et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone to domain dependence (Wu et al., 2010). Existing domain adaptation techniques for sentiment analysis require a few training texts from each target domain or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. W</context>
<context position="10970" citStr="Teufel, 2014" startWordPosition="1762" endWordPosition="1763">th et al., 2014a) by measuring the similarity of a given flow to known sentiment flow patterns. We point out the domain robustness of sentiment flow there, but we still use domain-specific local sentiment classifiers and we do not handle some major domain differences of web reviews. Both limitations are addressed in this paper, where we align flows similar to how Persing et al. (2010) align essay organizations. We claim that sentiment flow models a review’s argumentation, such that local sentiments ressemble rhetorical moves. Comparable simplifications are common for scientific argumentation (Teufel, 2014). Usually, argumentative texts are studied more deeply, considering different types of argument components and their relations (Mochales and Moens, 2011). Mining such structure is getting increasing attention recently (Habernal et al., 2014), also in the analysis of reviews (Villalba and Saint-Dizier, 2012). To express global sentiment, however, web reviews argue in simpler ways. 3 Web Review Argumentation Argumentation refers to the exchange of opinions, to defending positions, and to convincing others of certain stances (van Eemeren et al., 2014). A review is a written form of monological ar</context>
</contexts>
<marker>Teufel, 2014</marker>
<rawString>Simone Teufel. 2014. Scientific Argumentation Detection as Limited-Domain Intention Recognition. In Proceedings of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing, pages 101–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frans H van Eemeren</author>
<author>Bart Garssen</author>
<author>Erik C W Krabbe</author>
<author>A Francisca Snoeck Henkemans</author>
<author>Bart Verheij</author>
<author>Jean H M Wagemans</author>
</authors>
<title>Handbook ofArgumentation Theory.</title>
<date>2014</date>
<publisher>Springer.</publisher>
<marker>van Eemeren, Garssen, Krabbe, Henkemans, Verheij, Wagemans, 2014</marker>
<rawString>Frans H. van Eemeren, Bart Garssen, Erik C. W. Krabbe, A. Francisca Snoeck Henkemans, Bart Verheij, and Jean H. M. Wagemans. 2014. Handbook ofArgumentation Theory. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Paz Garcia Villalba</author>
<author>Patrick Saint-Dizier</author>
</authors>
<title>Some Facets of Argument Mining for Opinion Analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference on Computational Models of Argument,</booktitle>
<pages>23--34</pages>
<contexts>
<context position="11278" citStr="Villalba and Saint-Dizier, 2012" startWordPosition="1804" endWordPosition="1807">limitations are addressed in this paper, where we align flows similar to how Persing et al. (2010) align essay organizations. We claim that sentiment flow models a review’s argumentation, such that local sentiments ressemble rhetorical moves. Comparable simplifications are common for scientific argumentation (Teufel, 2014). Usually, argumentative texts are studied more deeply, considering different types of argument components and their relations (Mochales and Moens, 2011). Mining such structure is getting increasing attention recently (Habernal et al., 2014), also in the analysis of reviews (Villalba and Saint-Dizier, 2012). To express global sentiment, however, web reviews argue in simpler ways. 3 Web Review Argumentation Argumentation refers to the exchange of opinions, to defending positions, and to convincing others of certain stances (van Eemeren et al., 2014). A review is a written form of monological argumentation, where an author structures a selection of arguments in order to justify his or her conclusion on a topic of discussion (Besnard and Hunter, 2008). Reviews, in particular, discuss products, services, works of art, or similar. The arguments in a review correspond to objective facts, positive and </context>
</contexts>
<marker>Villalba, Saint-Dizier, 2012</marker>
<rawString>Maria Paz Garcia Villalba and Patrick Saint-Dizier. 2012. Some Facets of Argument Mining for Opinion Analysis. In Proceedings of the 2012 Conference on Computational Models of Argument, pages 23–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henning Wachsmuth</author>
<author>Martin Trenkmann</author>
<author>Benno Stein</author>
<author>Gregor Engels</author>
</authors>
<title>Modeling Review Argumentation for Robust Sentiment Analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>553--564</pages>
<contexts>
<context position="3278" citStr="Wachsmuth et al., 2014" startWordPosition="501" endWordPosition="504">ther argumentative texts. While the reviewed aspects differ between domains, our assumption is that the overall argumentation of a web review is generally represented by a sequence of local sentiments, called the review’s sentiment flow (Mao and Lebanon, 2007). In particular, we hypothesize that, under an adequate model, similar sentiment flows express similar global sentiments, also across domains. All reviews in Figure 1, for instance, express neutral global sentiment starting with positive, continuing with negative, and ending with positive local sentiment. Unlike in our previous approach (Wachsmuth et al., 2014a), we analyze the major abstraction steps when modeling sentiment flow to represent global sentiment. A general model should abstract from both content and other domain differences, such as a review’s length or the density of local sentiment in it. Based on web review corpora with known sentiment flows, we empirically analyze several model variants across three domains. Our results offer clear evidence for the truth of our hypothesis, indicating the generality of sentiment flow as a model of web review argumentation. The abstract nature of sentiment flow, however, does not directly achieve do</context>
<context position="9875" citStr="Wachsmuth et al., 2014" startWordPosition="1584" endWordPosition="1587">xtract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an approach, but we use it to then predict global sentiment. Täckström and McDonald (2011) observe that local and global sentiment correlate, aiming for the opposite direction, though. In (Wachsmuth et al., 2014b), we already compute frequent flows of local sentiment, but we neither analyze their generality, nor do we use them for prediction. The idea of modeling sentiment flow was introduced by Mao and Lebanon (2007) who classify local sentiment based on neighboring local sentiment in a review. When inferring global sentiment from a flow, however, the authors model only 602 single flow positions, not their ordering. In contrast, we capture the overall structure of reviews in (Wachsmuth et al., 2014a) by measuring the similarity of a given flow to known sentiment flow patterns. We point out the domai</context>
<context position="16751" citStr="Wachsmuth et al., 2014" startWordPosition="2697" endWordPosition="2700">mmon ground of related works (cf. Section 2). Figure 2 illustrates how we model web review argumentation. Our hypothesis is that similar sentiment flows are used across domains of web reviews to express the same global sentiment. However, because of the domain differences described in Section 3, we do not expect that the original sentiment flows of web reviews generalize well. 4.2 Abstracting Flows for Generality By concept, sentiment flow avoids to capture content and some facets of form like paragraph usage. To abstract from the length of reviews, Mao and Lebanon (2007) and our approach in (Wachsmuth et al., 2014a) length-normalize sentiment flow via interpolation. While this may preserve all information, it does not account for sub-reviews and the density of subjectivity. Here, we investigate more informed ways of abstracting flows. In particular, we consider three transformations of flows: Change Deletion of repeating local sentiments. The rationale is to reduce subjectivity differences by focusing on changes of local sentiment. NoLoops Deletion of repeating sequences of two or more local sentiments. The rationale is to reduce length differences by merging similar sub-reviews. Figure 3. The original</context>
<context position="18794" citStr="Wachsmuth et al., 2014" startWordPosition="3010" endWordPosition="3013"> of local sentiment in unknown reviews will not be free of errors, and, (2) reviews may comprise flows for which the global sentiment is unknown. Classification errors are naturally problematic for modeling sentiment flow. At least, some errors are bypassed by the three transformations. E.g., if one negative local sentiment in the original flow in Figure 3 is misclassified as positive, the Change transformation fixes this. If it is classified as neutral, Change and 2Class together eliminate the effect. Moreover, errors can be countered by limiting the impact of single positions in a flow. In (Wachsmuth et al., 2014a), we learn to infer global sentiment from the Manhattan distances between a sentiment flow and a set of common flows, thereby analyzing the flow as a whole. The common flows are found in a preceding clustering step. While we adopt the learning approach here, the Manhattan distances imply that flows are similar only if their changes are at similar positions. Instead, we compare sentiment flows (modified with zero to three transformations) based on their normalized minimum edit distance (Cormen et al., 2009). Analog to Persing et al. (2010), we incrementally compute the edit distance using seq</context>
<context position="23275" citStr="Wachsmuth et al., 2014" startWordPosition="3750" endWordPosition="3753">domains represented by the given web review corpora. anced among five categories: books (59 reviews), DVD (59), electronics (57), music (59), and videogames (60). We use the first three for training and the others for testing. Under the authors’ mapping from Amazon star ratings to global sentiment, all categories subsume 19 to 20 positive, neutral, and negative reviews each. In each review, every sentence is classified as positive, negative, neutral, mixed, or irrelevant. To match the other corpora, we merge the three latter into one neutral class. Hotel Domain Our ArguAna TripAdvisor corpus (Wachsmuth et al., 2014b) consists of 2100 TripAdvisor reviews, 300 for seven hotel locations each. Three locations belong to a predefined training set and two to a validation and a test set each. For all locations, the reviews are evenly distributed over the five TripAdvisor overall scores. In accordance with the product corpus, we see score 4–5 as positive global sentiment, 3 as neutral, and 1–2 as negative. In each review, all main clauses together with their subordinate clauses have been classified as being positive, negative, or neutral. Movie Domain Finally, the third corpus (Mao and Lebanon, 2007) compiles 45</context>
<context position="28971" citStr="Wachsmuth et al., 2014" startWordPosition="4763" endWordPosition="4766"> 200 5 0.3 0.6 0.4 100.0 91.7 100.0 0.01 0.01 0.00 original 200 0 0.0 0.0 0.0 0.0 0.0 0.0 0.00 0.00 0.00 Table 2. Results on the generality of sentiment flow for all evaluated model variants on ground-truth data for each combination of training and test domain. The most general variants in terms of both aggregated recall and weighted precision are marked in bold. For illustration, # Flows lists the numbers of all flows in the training reviews and of those with a recall of at least 1%. transformations from Section 4. All variants are named according to the applied transformations. Measures In (Wachsmuth et al., 2014b), we propose specific notions of the recall and precision of a sentiment flow f in a given collection of reviews: The recall Rf denotes the relative frequency of reviews with flow f, while the precision Pf(s) with respect to some global sentiment s denotes the relative co-occurrence of f with s. Here, we extend these measures for complete models as follows. We define the aggregate recall of a model on a collection of reviews as the sum of the recall of the set F of all its known sentiment flows: Aggregate Recall(F) = � Rf f∈F With weighted precision, we denote the sum of the maximum precisio</context>
<context position="36850" citStr="Wachsmuth et al., 2014" startWordPosition="6069" endWordPosition="6072">oaches evaluated on the given corpora. In addition, we analyze domain robustness based on three baselines, which relate to the three abstraction levels in Figure 2 (cf. Section 4): Bag-of-Words (b1) The frequencies of all tokens that occur in at least 5% of all training reviews. Local Sentiment (b2) The frequencies of positive, neutral, and negative local sentiment in a review as well as the first and last local sentiment (analog to Section 4, local sentiment is mapped to [0,1]). Sentiment Flow Patterns (b3) The Manhattan distances to those sentiment flows obtained by our clustering approach (Wachsmuth et al., 2014a). All approaches are used as feature types in machine learning (with values normalized to [0,1]). 6.2 Experimental Set-up We tackle three-class sentiment analysis, which is supposed to be particularly hard due to the fuzzy nature of neutral sentiment (Täckström and McDonald, 2011). Given the three review corpora described in Section 5, we proceed as follows:7 Local Sentiment For feature computations, we split all reviews into tokens and sentences. Then, we classify local sentiment with the algorithm of Socher et al. (2013) from Stanford CoreNLP.8 The algorithm was trained on subjective movie</context>
<context position="42928" citStr="Wachsmuth et al., 2014" startWordPosition="7008" endWordPosition="7011">cus. In particular, we hypothesize that an abstract model of the local sentiment flow in a review generally captures the review’s overall argumentation regarding global sentiment. In ground-truth data from three domains, we have found clear evidence for our hypothesis, indicating that people write reviews in similar ways across domains. On this basis, we have presented a novel learning approach, which predicts the global sentiment of a review from the edit distance between the review’s sentiment flow and a set of common flows. While we determined common flows with clustering in previous work (Wachsmuth et al., 2014a), instead here we rely on different flow abstractions at the same time. Systematic experiments emphasize that, in this manner, our approach achieves domain robustness without any domain adaptation even when the accuracy of the local sentiment in the flows is limited. However, our experiments also show that sentiment flow alone does not always suffice to predict global sentiment. In future sentiment analysis approaches, sentiment flows may therefore rather serve as pivot features for domain adaptation. 49.0 45.9 32.4 51.7 50.4 39.3 46.8 57.5 47.8 51.9 58.8 49.8 46.0 46.6 41.3 48.7 46.9 38.4 4</context>
</contexts>
<marker>Wachsmuth, Trenkmann, Stein, Engels, 2014</marker>
<rawString>Henning Wachsmuth, Martin Trenkmann, Benno Stein, and Gregor Engels. 2014a. Modeling Review Argumentation for Robust Sentiment Analysis. In Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers, pages 553–564.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henning Wachsmuth</author>
<author>Martin Trenkmann</author>
<author>Benno Stein</author>
<author>Gregor Engels</author>
<author>Tsvetomira Palakarska</author>
</authors>
<title>A Review Corpus for Argumentation Analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the 15th International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>115--127</pages>
<contexts>
<context position="3278" citStr="Wachsmuth et al., 2014" startWordPosition="501" endWordPosition="504">ther argumentative texts. While the reviewed aspects differ between domains, our assumption is that the overall argumentation of a web review is generally represented by a sequence of local sentiments, called the review’s sentiment flow (Mao and Lebanon, 2007). In particular, we hypothesize that, under an adequate model, similar sentiment flows express similar global sentiments, also across domains. All reviews in Figure 1, for instance, express neutral global sentiment starting with positive, continuing with negative, and ending with positive local sentiment. Unlike in our previous approach (Wachsmuth et al., 2014a), we analyze the major abstraction steps when modeling sentiment flow to represent global sentiment. A general model should abstract from both content and other domain differences, such as a review’s length or the density of local sentiment in it. Based on web review corpora with known sentiment flows, we empirically analyze several model variants across three domains. Our results offer clear evidence for the truth of our hypothesis, indicating the generality of sentiment flow as a model of web review argumentation. The abstract nature of sentiment flow, however, does not directly achieve do</context>
<context position="9875" citStr="Wachsmuth et al., 2014" startWordPosition="1584" endWordPosition="1587">xtract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an approach, but we use it to then predict global sentiment. Täckström and McDonald (2011) observe that local and global sentiment correlate, aiming for the opposite direction, though. In (Wachsmuth et al., 2014b), we already compute frequent flows of local sentiment, but we neither analyze their generality, nor do we use them for prediction. The idea of modeling sentiment flow was introduced by Mao and Lebanon (2007) who classify local sentiment based on neighboring local sentiment in a review. When inferring global sentiment from a flow, however, the authors model only 602 single flow positions, not their ordering. In contrast, we capture the overall structure of reviews in (Wachsmuth et al., 2014a) by measuring the similarity of a given flow to known sentiment flow patterns. We point out the domai</context>
<context position="16751" citStr="Wachsmuth et al., 2014" startWordPosition="2697" endWordPosition="2700">mmon ground of related works (cf. Section 2). Figure 2 illustrates how we model web review argumentation. Our hypothesis is that similar sentiment flows are used across domains of web reviews to express the same global sentiment. However, because of the domain differences described in Section 3, we do not expect that the original sentiment flows of web reviews generalize well. 4.2 Abstracting Flows for Generality By concept, sentiment flow avoids to capture content and some facets of form like paragraph usage. To abstract from the length of reviews, Mao and Lebanon (2007) and our approach in (Wachsmuth et al., 2014a) length-normalize sentiment flow via interpolation. While this may preserve all information, it does not account for sub-reviews and the density of subjectivity. Here, we investigate more informed ways of abstracting flows. In particular, we consider three transformations of flows: Change Deletion of repeating local sentiments. The rationale is to reduce subjectivity differences by focusing on changes of local sentiment. NoLoops Deletion of repeating sequences of two or more local sentiments. The rationale is to reduce length differences by merging similar sub-reviews. Figure 3. The original</context>
<context position="18794" citStr="Wachsmuth et al., 2014" startWordPosition="3010" endWordPosition="3013"> of local sentiment in unknown reviews will not be free of errors, and, (2) reviews may comprise flows for which the global sentiment is unknown. Classification errors are naturally problematic for modeling sentiment flow. At least, some errors are bypassed by the three transformations. E.g., if one negative local sentiment in the original flow in Figure 3 is misclassified as positive, the Change transformation fixes this. If it is classified as neutral, Change and 2Class together eliminate the effect. Moreover, errors can be countered by limiting the impact of single positions in a flow. In (Wachsmuth et al., 2014a), we learn to infer global sentiment from the Manhattan distances between a sentiment flow and a set of common flows, thereby analyzing the flow as a whole. The common flows are found in a preceding clustering step. While we adopt the learning approach here, the Manhattan distances imply that flows are similar only if their changes are at similar positions. Instead, we compare sentiment flows (modified with zero to three transformations) based on their normalized minimum edit distance (Cormen et al., 2009). Analog to Persing et al. (2010), we incrementally compute the edit distance using seq</context>
<context position="23275" citStr="Wachsmuth et al., 2014" startWordPosition="3750" endWordPosition="3753">domains represented by the given web review corpora. anced among five categories: books (59 reviews), DVD (59), electronics (57), music (59), and videogames (60). We use the first three for training and the others for testing. Under the authors’ mapping from Amazon star ratings to global sentiment, all categories subsume 19 to 20 positive, neutral, and negative reviews each. In each review, every sentence is classified as positive, negative, neutral, mixed, or irrelevant. To match the other corpora, we merge the three latter into one neutral class. Hotel Domain Our ArguAna TripAdvisor corpus (Wachsmuth et al., 2014b) consists of 2100 TripAdvisor reviews, 300 for seven hotel locations each. Three locations belong to a predefined training set and two to a validation and a test set each. For all locations, the reviews are evenly distributed over the five TripAdvisor overall scores. In accordance with the product corpus, we see score 4–5 as positive global sentiment, 3 as neutral, and 1–2 as negative. In each review, all main clauses together with their subordinate clauses have been classified as being positive, negative, or neutral. Movie Domain Finally, the third corpus (Mao and Lebanon, 2007) compiles 45</context>
<context position="28971" citStr="Wachsmuth et al., 2014" startWordPosition="4763" endWordPosition="4766"> 200 5 0.3 0.6 0.4 100.0 91.7 100.0 0.01 0.01 0.00 original 200 0 0.0 0.0 0.0 0.0 0.0 0.0 0.00 0.00 0.00 Table 2. Results on the generality of sentiment flow for all evaluated model variants on ground-truth data for each combination of training and test domain. The most general variants in terms of both aggregated recall and weighted precision are marked in bold. For illustration, # Flows lists the numbers of all flows in the training reviews and of those with a recall of at least 1%. transformations from Section 4. All variants are named according to the applied transformations. Measures In (Wachsmuth et al., 2014b), we propose specific notions of the recall and precision of a sentiment flow f in a given collection of reviews: The recall Rf denotes the relative frequency of reviews with flow f, while the precision Pf(s) with respect to some global sentiment s denotes the relative co-occurrence of f with s. Here, we extend these measures for complete models as follows. We define the aggregate recall of a model on a collection of reviews as the sum of the recall of the set F of all its known sentiment flows: Aggregate Recall(F) = � Rf f∈F With weighted precision, we denote the sum of the maximum precisio</context>
<context position="36850" citStr="Wachsmuth et al., 2014" startWordPosition="6069" endWordPosition="6072">oaches evaluated on the given corpora. In addition, we analyze domain robustness based on three baselines, which relate to the three abstraction levels in Figure 2 (cf. Section 4): Bag-of-Words (b1) The frequencies of all tokens that occur in at least 5% of all training reviews. Local Sentiment (b2) The frequencies of positive, neutral, and negative local sentiment in a review as well as the first and last local sentiment (analog to Section 4, local sentiment is mapped to [0,1]). Sentiment Flow Patterns (b3) The Manhattan distances to those sentiment flows obtained by our clustering approach (Wachsmuth et al., 2014a). All approaches are used as feature types in machine learning (with values normalized to [0,1]). 6.2 Experimental Set-up We tackle three-class sentiment analysis, which is supposed to be particularly hard due to the fuzzy nature of neutral sentiment (Täckström and McDonald, 2011). Given the three review corpora described in Section 5, we proceed as follows:7 Local Sentiment For feature computations, we split all reviews into tokens and sentences. Then, we classify local sentiment with the algorithm of Socher et al. (2013) from Stanford CoreNLP.8 The algorithm was trained on subjective movie</context>
<context position="42928" citStr="Wachsmuth et al., 2014" startWordPosition="7008" endWordPosition="7011">cus. In particular, we hypothesize that an abstract model of the local sentiment flow in a review generally captures the review’s overall argumentation regarding global sentiment. In ground-truth data from three domains, we have found clear evidence for our hypothesis, indicating that people write reviews in similar ways across domains. On this basis, we have presented a novel learning approach, which predicts the global sentiment of a review from the edit distance between the review’s sentiment flow and a set of common flows. While we determined common flows with clustering in previous work (Wachsmuth et al., 2014a), instead here we rely on different flow abstractions at the same time. Systematic experiments emphasize that, in this manner, our approach achieves domain robustness without any domain adaptation even when the accuracy of the local sentiment in the flows is limited. However, our experiments also show that sentiment flow alone does not always suffice to predict global sentiment. In future sentiment analysis approaches, sentiment flows may therefore rather serve as pivot features for domain adaptation. 49.0 45.9 32.4 51.7 50.4 39.3 46.8 57.5 47.8 51.9 58.8 49.8 46.0 46.6 41.3 48.7 46.9 38.4 4</context>
</contexts>
<marker>Wachsmuth, Trenkmann, Stein, Engels, Palakarska, 2014</marker>
<rawString>Henning Wachsmuth, Martin Trenkmann, Benno Stein, Gregor Engels, and Tsvetomira Palakarska. 2014b. A Review Corpus for Argumentation Analysis. In Proceedings of the 15th International Conference on Intelligent Text Processing and Computational Linguistics, pages 115–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henning Wachsmuth</author>
</authors>
<title>Pipelines for Ad-hoc Large-Scale Text Mining. To appear</title>
<date>2015</date>
<booktitle>in Lecture Notes in Computer Science.</booktitle>
<publisher>Springer,</publisher>
<note>available at http://is.upb.de/?id=wachsmuth.</note>
<marker>Wachsmuth, 2015</marker>
<rawString>Henning Wachsmuth. 2015. Pipelines for Ad-hoc Large-Scale Text Mining. To appear in Lecture Notes in Computer Science. Springer, available at http://is.upb.de/?id=wachsmuth.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach.</title>
<date>2010</date>
<booktitle>In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>783--792</pages>
<contexts>
<context position="9072" citStr="Wang et al., 2010" startWordPosition="1455" endWordPosition="1458">n or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegrained opinions from a review (Popescu and Etzioni, 2005). These aspects in turn impact the review’s global sentiment (Wang et al., 2010). However, relevant aspects naturally tend to be domainspecific, like the picture quality of HDD players or the beds of hotels (cf. Figure 1). While weaklysupervised approaches to extract aspects and local sentiment exist (Brody and Elhadad, 2010; Lazaridou et al., 2013), it is not clear how to align aspects from different domains. We ignore aspects here, only preserving the local sentiment itself. State-of-the-art approaches for classifying local sentiment within a domain model the composition of words, e.g., relying on deep learning (Socher et al., 2013). We do not compete with such an appro</context>
</contexts>
<marker>Wang, Lu, Zhai, 2010</marker>
<rawString>Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010. Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 783– 792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiong Wu</author>
<author>Songbo Tan</author>
<author>Miyi Duan</author>
<author>Xueqi Cheng</author>
</authors>
<title>A Two-Stage Algorithm for Domain Adaptation with Application to Sentiment Transfer Problems.</title>
<date>2010</date>
<booktitle>In Information Retrieval Technology,</booktitle>
<volume>6458</volume>
<pages>443--453</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2105" citStr="Wu et al., 2010" startWordPosition="321" endWordPosition="324">rom an abstract viewpoint, the argumentation of a web review can thus be seen as a composition of local sentiments used to justify some global sentiment. Both local and global sentiment of reviews are in the focus of numerous sentiment analysis approaches (cf. Section 2 for details). Many of these approaches model reviews primarily with contentbased features, derived from the words in the reviews. The use of words, however, varies strongly across domains, as illustrated in Figure 1 for a product, a hotel, and a movie review. As a consequence, sentiment analysis suffers from domain dependence (Wu et al., 2010), i.e., high effectiveness is often achieved only in the domain an approach has been specifically modeled for. To adapt to other domains, prior knowledge about these domains or about domain-independent features is needed (Prettenhofer and Stein, 2010). This paper considers the question as to whether the overall argumentation of web reviews can be modeled in a general way in order to increase domain independence in sentiment analysis. We observe that people structure web reviews largely sequentially—in contrast to the complex structures of many other argumentative texts. While the reviewed aspe</context>
<context position="8340" citStr="Wu et al., 2010" startWordPosition="1343" endWordPosition="1346">umerous sentiment analysis approaches have been proposed for different text types, levels of granularity, sentiment scales, and domains. We target at global text-level sentiment of web reviews. While we distinguish three sentiment classes here, our approach can be adapted to other scales. Our goal is not to optimize sentiment analysis in a specific domain, but to find a model that supports sentiment analysis across domains. As common in text classification (Manning et al., 2008), sentiment analysis often relies on words and other content features, which tends to be prone to domain dependence (Wu et al., 2010). Existing domain adaptation techniques for sentiment analysis require a few training texts from each target domain or a few domain-independent pivot features to align domain-specific features (Prettenhofer and Stein, 2010). Our model complements these techniques and could be leveraged for pivot features. In tasks like authorship attribution and argumentative zoning, non-topical words benefit domain independence (Menon and Choi, 2011; Ó Séaghdha and Teufel, 2014). Instead, we focus on the local sentiment on different aspects in a review here. Aspect-based sentiment analysis extracts finegraine</context>
</contexts>
<marker>Wu, Tan, Duan, Cheng, 2010</marker>
<rawString>Qiong Wu, Songbo Tan, Miyi Duan, and Xueqi Cheng. 2010. A Two-Stage Algorithm for Domain Adaptation with Application to Sentiment Transfer Problems. In Information Retrieval Technology, volume 6458 of Lecture Notes in Computer Science, pages 443–453. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>