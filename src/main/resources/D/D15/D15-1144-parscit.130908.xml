<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.903782">
Consistency-Aware Search for Word Alignment
</title>
<author confidence="0.976462">
Shiqi Shen†, Yang Liu†$, Huanbo Luan† and Maosong Sun†$
</author>
<affiliation confidence="0.99391025">
†State Key Laboratory of Intelligent Technology and Systems
Tsinghua National Laboratory for Information Science and Technology
Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China
$Jiangsu Collaborative Innovation Center for Language Competence, Jiangsu, China
</affiliation>
<email confidence="0.995277">
{vicapple22,liuyang.china,luanhuanbo}@gmail.com, sms@tsinghua.edu.cn
</email>
<sectionHeader confidence="0.994746" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999901">
As conventional word alignment search
algorithms usually ignore the consistency
constraint in translation rule extraction,
improving alignment accuracy does not
necessarily increase translation quality.
We propose to use coverage, which
reflects how well extracted phrases can
recover the training data, to enable word
alignment to model consistency and corre-
late better with machine translation. This
can be done by introducing an objective
that maximizes both alignment model
score and coverage. We introduce an
efficient algorithm to calculate coverage
on the fly during search. Experiments
show that our consistency-aware search
algorithm significantly outperforms both
generative and discriminative alignment
approaches across various languages and
translation models.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999520466666667">
Word alignment, which aims to identify the
correspondence between words in two languages,
plays an important role in statistical machine
translation (Brown et al., 1993). Word alignment
and translation rule extraction often constitute two
consecutive steps in the training pipeline. Word-
aligned bilingual corpora serve as a fundamental
resource for translation rule extraction, not only
for phrase-based models (Koehn et al., 2003; Och
and Ney, 2004), but also for syntax-based models
(Chiang, 2005; Galley et al., 2006). Dividing
alignment and extraction into two separate steps
significantly improves the efficiency and scala-
bility of parameter estimation as compared with
directly learning translation models from bilingual
</bodyText>
<note confidence="0.749813">
∗Corresponding author: Yang Liu.
</note>
<bodyText confidence="0.989225585365854">
corpora (Marcu and Wong, 2002; DeNero and
Klein, 2008; Cohn and Blunsom, 2009).
However, separating word alignment from
translation rule extraction suffers from a major
problem: maximizing the accuracy of word align-
ment does not necessarily lead to the improvement
of translation quality. A number of studies
show that alignment error rate (AER) only has
a loose correlation with BLEU (Callison-Burch
et al., 2004; Goutte et al., 2004; Ittycheriah
and Roukos, 2005). Ayan and Dorr (2006)
find that precision-oriented alignments result in
better translation performance than recall-oriented
alignments. Fraser and Marcu (2007) show that
using AER and balanced F-measure can only
partially explain the effect of alignment quality on
BLEU for several language pairs.
We believe that the correlation problem arises
from the discrepancy between word alignment
and translation rule extraction. On one hand,
aligners seek to find the alignment with the
highest alignment model score, without regard
to structural constraints. Consequently, sensible
translation rules may not be extracted because
they violate consistency constraints required by
translation rule extraction (Och and Ney, 2004).
Wang et al. (2010) find that the standard alignment
tools are not optimal for training syntax-based
models. As a result, they have to resort to re-
aligning. On the other hand, the consistency
constraint used in most translation rule extraction
algorithms tolerate wrong links within consistent
phrase pairs. Chiang (2007) uses the union
of two unidirectional alignments, which usually
has a low precision, for extracting hierarchical
phrases. Therefore, it is important to include
both alignment model score and the consistency
constraint in the optimization objective of word
alignment.
In this work, we propose to use coverage,
which measures how well extracted phrases can
</bodyText>
<page confidence="0.933298">
1228
</page>
<note confidence="0.9958275">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1228–1237,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figureCaption confidence="0.995178">
Figure 1: (a) An alignment resulting in a set of bilingual phrases (highlighted by shading) that can recover
</figureCaption>
<bodyText confidence="0.8710624">
the training example, and (b) an alignment resulting in a set of bilingual phrases that fails to fully recover
the training example. We assume the maximum phrase length w = 3. Our approach aims to avoid adding
links that both have low posterior probabilities and hurt the recovery (e.g., the link between “huiwu” and
“hold”).
recover the training data, to bridge word alignment
and (hierarchical) phrase-based translation. We
introduce a new alignment search algorithm with
an objective that maximizes both alignment model
score and coverage while keeping the training
algorithm unchanged. The coverage of an align-
ment is calculated on the fly during search using
a local phrase extraction algorithm. Experiments
show that our approach achieves significant im-
provements over state-of-the-art baselines across
various languages and translation models.
</bodyText>
<sectionHeader confidence="0.987576" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.972027666666667">
We begin by introducing the preliminaries of word
alignment and phrase-based translation.
Definition 1 Given a source-language sentence
f = fJ1 = f1 ... fJ and atarget-language sentence
e = eI1 = e1 ... eI, an alignment a is a subset
of the Cartesian product of the word positions of
two sentences: a C_ {(j, i) : j = 1, ... , J; i =
1,...,II.
Figure 1(a) shows an alignment for a Chinese
sentence “oumeng he eluosi shounao huiwu zai
mosike juxing” and an English sentence “EU and
Russia hold summit in Moscow”. We use black
circles to denote links. The link (1, 1) indicates
that the first Chinese word “oumeng” and the first
English word “EU” are translations of each other.
Definition 2 Given a training example (f, e, a), a
bilingual phrase B is a pair of source and target
phrases: B=(fj2
</bodyText>
<equation confidence="0.9948065">
j1 , ei2
i1) such that 1 &lt; j1 &lt; &lt;
j2
J ∧ 1 &lt; i1 &lt; i2 &lt; I.
</equation>
<bodyText confidence="0.941647285714286">
For example, (“zai mosike”, “in Moscow”) in
Figure 1 can be denoted as a bilingual phrase
B = (f67, e76). For convenience, We use B.j1 and
B.j2 to denote the beginning and ending positions
of the source phrase in B, respectively. B.i1 and
B.i2 are defined likewise for the target side.
Definition 3 A bilingual phrase B = (fj2
</bodyText>
<equation confidence="0.86049">
j1 , ei2
i1) is
</equation>
<bodyText confidence="0.9492357">
said to be tight if and only if all boundary words
(i.e., fj1, fj2, ei1, and ei2) are aligned. Otherwise,
it is a loose bilingual phrase.
For example, in Figure 1, while (f31 , e31) is a
tight bilingual phrase, (f41 , e41) is a loose bilingual
phrase.
Definition 4 (Och and Ney, 2004) Given a train-
ing example (f, e, a), a bilingual phrase B =
(fj2
j1 , ei2
</bodyText>
<listItem confidence="0.97044225">
i1) is said to be consistent with the word
alignment a if and only if:
1. No words in the source phrase are aligned
with words outside the target phrase and vice
versa: b(j,i) E a : j1 &lt; j &lt; j2 H i1 &lt; i &lt;
i2,
2. At least one word in the source phrase is
aligned with at least one word in the target
</listItem>
<page confidence="0.989168">
1229
</page>
<bodyText confidence="0.98008195">
phrase: ](j, i) E a : j1 G j G j2 n i1 G i G
i2.
Alignment consistency forms the basis of trans-
lation rule extraction in modern SMT systems
(Koehn and Hoang, 2007; Chiang, 2007; Galley
et al., 2006; Liu et al., 2006). In Figure 1,
(fi , e31) is consistent with the alignment because
all words in “oumeng he eluosi” are aligned with
all words in “EU and Russia”. In contrast, in
Figure 1(b), “huiwu shounao” and “hold summit”
are not consistent with the alignment because
“hold” is also aligned to a word “juxing” outside.
However, alignment consistency only defines a
loose relationship between alignment and trans-
lation. A phrase pair consistent with alignment
tolerates wrong inside links. For example, even
if “oumeng” is aligned with “Russia”, (fi , ei) is
still consistent. This is one possible reason that
maximizing alignment accuracy does not neces-
sarily lead to improved translation performance.
</bodyText>
<sectionHeader confidence="0.6478545" genericHeader="method">
3 Modeling Consistency in Word
Alignment
</sectionHeader>
<bodyText confidence="0.998270789473685">
Our intuition is that including the consistency
constraint in word alignment can hopefully reduce
the discrepancy between alignment and transla-
tion. While this idea has been suggested by a
number of authors (e.g., (Deng and Zhou, 2009;
DeNero and Klein, 2010)), our goal is to optimize
arbitrary alignment models with respect to end-to-
end translation in the search phase without labeled
data (see Related Work for detailed comparison).
A natural way is to include consistency in
the optimization objective as a regularization
term. However, as consistency is only defined
at the phrase level (see Definition 4), we need
a sentence-level measure to reflect how well an
alignment conforms to the consistency constraint.
A straightforward measure is the number of bilin-
gual phrases consistent with the alignment (phrase
count for short), which is easy and efficient to
calculate during search (Deng and Zhou, 2009).
Unfortunately, optimizing with respect to phrase
count is prone to yield alignments with very few
links in a biased way, which result in a large
number of bilingual phrases extracted from a small
fraction of the training data. Another alternative is
reachability (Liang et al., 2006a; Yu et al., 2013)
that indicates whether there exists a full derivation
to recover the training data. However, calculating
reachability faces a major problem: a large portion
of training data cannot be fully recovered due to
noisy alignments and the distortion limit (Yu et al.,
2013).
In this work, we propose coverage, which
reflects how well extracted phrases can recover
the training data, to measure the sentence-level
consistency. In the following, we will introduce
a number of definitions to facilitate the exposition.
Definition 5 A source word fj is said to be
covered by a bilingual phrase B = (fj2
</bodyText>
<equation confidence="0.934604">
j1 , ei2
i1) if
</equation>
<bodyText confidence="0.998015454545455">
and only if j1 G j G j2 : cov(fj, B) = Jj1 G j G
j2K. Similarly, a target word ei is covered by B if
and only if i1 G i G i2.
The indicator function JexprK returns 1 if the
boolean expression expr is true and returns 0
otherwise. For example, in Figure 1(a), “oumeng”
and “EU” are covered by the bilingual phrase B =
(f31 , ei).
Definition 6 Given a set of bilingual phrases B =
{B(k)}Kk=1, a source word fj is said to be covered
by the bilingual phrase set B if and only if it is
covered by at least one phrase in B : cov(fj, B) =
JEKk=1 cov(fj,B(k)) &gt; 0K. The definition for a
target word is similar.
For example, in Figure 1(a), all source and
target words are covered by the bilingual phrase
set. In Figure 1(b), the source words “shounao”,
“huiwu”, “juxing” and the target words “hold” and
“summit” are not covered.
Definition 7 Given a sentence pair (f, e) and a
phrase length limit w 1, the hard coverage of an
alignment a is defined as a boolean value:
</bodyText>
<equation confidence="0.9918184">
t
J
Ch(f, e, a, w) = δ( E cov(fj, B), J) n
j=1
)|cov(ei, B), I (1)
</equation>
<bodyText confidence="0.868843909090909">
where B = EXTRACT(f, e, a,1, J,1,I, w) is
the set of consistent bilingual phrases extracted
from the sentence pair using a standard phrase
extraction algorithm (Och and Ney, 2004). The
function δ returns true if the two parameters are
same and returns false otherwise.
1The phrase length limit w is essential in defining
coverage, restricting that the sentence pair must be covered
by bilingual phrases no longer than w words. Otherwise, a
very long bilingual phrase (e.g., the entire sentence pair) can
achieve full coverage in a biased way.
</bodyText>
<equation confidence="0.9201915">
(
δ
I
i=1
</equation>
<page confidence="0.88503">
1230
</page>
<construct confidence="0.646635">
Algorithm 1 A consistency-aware search
algorithm for word alignment.
</construct>
<listItem confidence="0.981437777777778">
1: procedure ALIGN(f, e, 6, w, β, b, n)
2: open 0
3: N 0
4: (a, B) (0, 0)
5: ADD(open, (a, B), β, b)
6: while open =� 0 do
7: closed 0
8: for all (a, B) E open do
9: for all l E J x I − a do
</listItem>
<figure confidence="0.797080545454546">
10: a0 a U {l}
11: B0 UPDATE(f, e, a, l, B, w)
12: if GAIN(f, e, a, a0, w, 6) &gt; 0 then
13: ADD(closed, (a0, B0), β, b)
14: end if
15: ADD(N, (a0, B0), β, n)
16: end for
17: end for
18: open closed
19: end while
20: return N
</figure>
<subsectionHeader confidence="0.548652">
21: end procedure
</subsectionHeader>
<bodyText confidence="0.9993128">
Depending on the tightness of extracted phrases
(see Definition 3), we further distinguish between
Ch+t(f, e, a, w) and Ch+l(f, e, a, w), which
denote hard coverage calculated with tight and
loose phrases, respectively.
Hard coverage denotes whether extracted
phrases can fully recover the training data. For
example, the values of hard coverage for Figures
1(a) and 1(b) are 1 and 0, respectively. As most
training examples can hardly be fully recovered,
we introduce soft coverage to better account for
partially recoverable training data.
Definition 8 Given a sentence pair (f, e) and a
phrase length limit w, the soft coverage of an
alignment a is defined as
</bodyText>
<equation confidence="0.984785666666667">
Cs(f,e,a,w)
(2)
J + I
</equation>
<bodyText confidence="0.998897444444445">
Similarly, we also distinguish between Cs+t and
Cs+l depending on the tightness of extracted
phrases.
Definition 9 Given a word-aligned bilingual cor-
pus D = {(f(s), e(s), a(s))}Ss=1 and a phrase
length limit w, the corpus-level soft coverage is
defined as
Algorithm 2 Updating the set of extracted
bilingual phrases after adding a link.
</bodyText>
<listItem confidence="0.700594571428571">
1: procedure UPDATE(f, e, a, l, B, w)
2: B0 B
3: for all B E B0 do
4: if B.j1 &lt; l.j &lt; B.j2 V B.i1 &lt; l.i &lt; B.i2 then
5: B0 B0 − {B}
6: end if
7: end for
</listItem>
<figure confidence="0.899797888888889">
8: j1 l.j − w + 1
9: j2 l.j + w − 1
10: i1 l.i − w + 1
11: i2 l.i + w − 1
12: a0 a U {l}
13: B00 EXTRACT(f, e, a0, j1, j2, i1, i2, w)
14: B0 B0 U B00
15: return B0
16: end procedure
</figure>
<bodyText confidence="0.8866015">
The corpus-level hard coverage is defined like-
wise.
</bodyText>
<sectionHeader confidence="0.997582" genericHeader="method">
4 Consistency-Aware Search
</sectionHeader>
<bodyText confidence="0.929670428571429">
While Deng and Zhou (2009) focus on intro-
ducing an effectiveness function such as phrase
count into alignment symmetrization, we are inter-
ested in guiding the search algorithms of arbitrary
alignment models using coverage. Therefore, the
objective of our search algorithm is defined as
score(f, e, a, w, 9)
= M(f, e, a, 9) + AC(f, e, a, w) (4)
where M(f, e, a, 9) is alignment model score,
9 is a set of model parameters, C(f, e, a, w) is
coverage (either hard or soft), and A is a hyper-
parameter that controls the preference between
alignment model score and coverage. 2
Therefore, the decision rule is given by
</bodyText>
<equation confidence="0.9975275">
aˆ = argmax{ score(f, e, a, w, 9)) (5)
aEA(f,e) l
</equation>
<bodyText confidence="0.999976555555556">
where A(f, e) is a set of all possible alignments
for the sentence pair.
Algorithm 1 shows the consistency-aware
search algorithm for word alignment. The input
of the algorithm includes a source sentence f, a
target sentence e, a set of model parameters 9,
phrase length limit w, pruning parameters Q and
b, and the number of most likely alignments to be
retaind n (line 1). Inspired by Liu et al. (2010),
</bodyText>
<footnote confidence="0.77034975">
2Note that training algorithms are unchanged. We
only introduce a new search algorithm that takes coverage
into consideration. We leave consistency-aware training
algorithms for arbitrary alignment models for future work.
</footnote>
<equation confidence="0.961165181818182">
PJ j=1 cov(fj, B) + PIi=1 cov(ei, B)
P|f(s)|
j=1 cov(f(s)
j , B(s))
Cs(D, w) = +
PsS=1 |f (s) |+ |e(s)
P|e(s)|
i=1 cov(e(s)
i ,B(s))
3
Ps 1 |f(s) |+ |e(s)|
</equation>
<page confidence="0.899866">
1231
</page>
<bodyText confidence="0.990985760869565">
the algorithm starts with an empty alignment a
together with an empty phrase set B. We use
open to store active alignments during search and
N to store top-n alignments after search (lines
2-4). The procedure ADD(open, (a, B), Q, b)
adds (a, B) to open and discards any alignment
that has a score worse than Q multiplied by the
best score in the list or the score of the b-th best
alignment (line 5). For each iteration (line 6), we
use a list closed to store promising alignments
that have higher scores than the current alignment
(line 8). For every possible link l (line 9), the
algorithm produces a new alignment a&apos; and
updates the phrase set by calling a procedure
UPDATE(f, e, a,l, B, w) (lines 10-11). Then, the
algorithm calls a procedure GAIN(f, e, a, a&apos;, w, 0)
to calculate the difference of model score after
adding the link l:
score(f, e, a&apos;, w, 0) − score(f, e, a, w, 0)
If a&apos; has a higher score, it is added to closed
(line 13). We also update N to retain the top
n alignment explored during the search (line 15).
This process iterates until the model score does not
increase.
Algorithm 2 describes how to update the set
of extracted bilingual phrases after adding a link.
Our idea is to only update the phrases near the
added link l and keep other phrases unchanged.
This strategy improves the efficiency by avoiding
extracting phrases from the entire sentence pair.
The algorithm first removes bilingual phrases that
are either in the same row or in the same column
with l (lines 2-7). For example, in Figure 1,
the following bilingual phrases are removed after
adding the link between “huiwu” and “hold”
because the link breaks the consistency:
(“shounao huiwu”, “summit”)
(“juxing”, “hold”)
Other phrases out of the reach of the added link
remain unchanged.
Then, the algorithm extracts bilingual phrases
near l by calling the procedure EXTRACT. Note
that the phrase extraction is restricted to a local
region (j1, j2, i1, i2) by the phrase length limit w.
We use l.i and l.j to denote the source and target
positions of the link, respectively.
</bodyText>
<table confidence="0.9961988">
coverage BLEU
Ch+l 24.89
Ch+t 23.16
Cs+l 24.69
Cs+t 25.41
</table>
<tableCaption confidence="0.999515">
Table 1: Comparison of different settings of
</tableCaption>
<bodyText confidence="0.993463857142857">
coverage on the Chinese-English dataset using
Moses. “h” denotes “hard”, “s” denotes “soft”,
“l” denotes “loose”, and “t” denotes “tight”. The
BLEU scores were calculated on the development
set. For quick validation, we used a small fraction
of the training data to train the phrase-based
model.
</bodyText>
<sectionHeader confidence="0.999831" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.985142">
5.1 Setup
</subsectionHeader>
<subsubsectionHeader confidence="0.826143">
5.1.1 Languages and Datasets
</subsubsectionHeader>
<bodyText confidence="0.999819774193548">
We evaluated our approach in terms of alignment
and translation quality on five language pairs:
Chinese-English (ZH-EN), Czech-English (CS-
EN), German-English (DE-EN), Spanish-English
(ES-EN), and French-English (FR-EN). The eval-
uation metrics for alignment and translation are
alignment error rate (AER) (Och and Ney, 2003)
and case-insensitive BLEU (Papineni et al., 2002),
respectively.
For Chinese-English, the training data consists
of 1.2M pairs of sentences with 30.9M Chinese
words and 35.5M English words. We used
the SRILM toolkit (Stolcke, 2002) to train a 4-
gram language model on the Xinhua portion of
the English GIGAWORD corpus, which contains
398.6M words. For alignment evaluation, we used
the Tsinghua Chinese-English word alignment
evaluation data set (Liu and Sun, 2015). 3 For
translation evaluation, we used the NIST 2006
dataset as the development set and the NIST 2002,
2003, 2004, 2005 and 2008 datasets as the test
sets.
For other languages, the training data is Euro-
parl v7. The English language model trained
on the Xinhua portion of the English GIGA-
WORD corpus was also used for translation from
European languages to English. For translation
evaluation, we used the “news-test2012” dataset
that contains 3,003 sentences as the development
set and the “news-test2013” dataset that contains
3,000 sentences as the test set.
</bodyText>
<footnote confidence="0.9505585">
3http://nlp.csai.tsinghua.edu.cn/˜ly/systems/TsinghuaAlig
ner/TsinghuaAligner.html
</footnote>
<page confidence="0.954105">
1232
</page>
<table confidence="0.997401">
method # bp # sp # tp # sw # tw Cs+t Cs+l AER BLEU
C → E 49.8M 33.0M 14.1M 80.4K 89.5K 73.76 82.82 29.21 30.49
E → C 66.0M 14.9M 43.1M 80.0K 82.2K 74.58 86.49 33.04 29.76
Intersection 465.6M 64.3M 72.5M 133.1K 165.0K 72.46 98.52 28.01 29.90
Union 11.8M 7.4M 7.8M 51.3K 50.5K 53.17 54.34 32.80 30.24
GDF 15.9M 9.6M 10.0M 64.7K 62.2K 63.12 64.45 30.56 30.40
phrase count 388.7M 58.5M 63.7M 133.4K 164.5K 78.42 99.52 25.70 30.16
this work 46.0M 20.6M 21.7M 130.8K 159.6K 91.25 98.34 25.77 31.33
</table>
<tableCaption confidence="0.938487333333333">
Table 2: Comparison of different alignment methods on the Chinese-English dataset. “GDF” denotes the
grow-diag-final heuristic. “phrase count” denotes optimizing with respect to maximizing the number of
extracted tight phrases. We used Moses to extract loose phrases from word-aligned training data for all
methods. “# bp” denotes the number of extracted bilingual phrases, “# sp” denotes the number of source
phrases, “# tp” denotes the number of target phrases, “# sw” denotes the source vocabulary size, “# tw”
denotes the target vocabulary size. We report BLEU scores on the NIST 2005 test set.
</tableCaption>
<table confidence="0.9956342">
alignment NIST06 NIST02 NIST03 NIST04 NIST05 NIST08
generative 29.60 31.84 31.68 31.80 30.40 24.53
+coverage 30.63** 32.89** 32.77** 32.96** 31.33** 25.25**
discriminative 28.98 32.31 31.69 31.89 30.65 23.20
+coverage 29.98** 32.93** 32.45** 32.45** 31.10** 24.67**
</table>
<tableCaption confidence="0.994636">
Table 3: Translation evaluation on different alignment models. We apply our approach to both generative
</tableCaption>
<bodyText confidence="0.984468">
and discriminative alignment models. “generative” denotes applying the grow-diag-final heuristic to
the alignments produced by IBM Model 4 in two directions. “discriminative” denotes the log-linear
alignment model (Liu et al., 2010). Adding coverage leads to significant improvements. We use “**” to
denote that the difference is statistically significant at p &lt; 0.01 level.
</bodyText>
<subsubsectionHeader confidence="0.80361">
5.1.2 Alignment Models
</subsubsectionHeader>
<bodyText confidence="0.999986416666667">
We apply our approach to both generative and
discriminative alignment models. For generative
models, we used GIZA++ (Och and Ney, 2003) to
train IBM Model 4 in two directions. To calculate
a model score for symmetrized alignments, we fol-
low Liang et al. (2006b) to leverage link posterior
marginal probabilities. For discriminative models,
we used the open-source toolkit TsinghuaAligner
(Liu and Sun, 2015) that implements the log-linear
alignment model as described in (Liu et al., 2010).
The model score for the log-linear model is also
defined using link posteriors.
</bodyText>
<subsubsectionHeader confidence="0.926746">
5.1.3 Translation Models
</subsubsectionHeader>
<bodyText confidence="0.9988593">
Two kinds of translation models, phrase-based
(Koehn et al., 2003) and hierarchical phrase-based
(Chiang, 2007), are used to evaluate whether
our approach improves the correlation between
alignment and translation. For the phrase-based
model, we used the open-source toolkit Moses
(Koehn and Hoang, 2007). For the hierarchical
phrase-based model, we used an in-house re-
implementation on par with state-of-the-art open-
source decoders.
</bodyText>
<subsectionHeader confidence="0.999768">
5.2 Comparison of Different Settings
</subsectionHeader>
<bodyText confidence="0.999945380952381">
We first investigate the optimal setting for
coverage (hard vs. soft, tight vs. loose) on the
Chinese-English dataset. For quick validation,
we used a subset of the training data to train the
phrase-based model using Moses. We used the
development set to optimize the scaling factor A
(see Eq. (4)) and set it to 0.3 in our experiments.
Table 1 compares Ch+l, Ch+t, Cs+l, and Cs+t.
We find that the “soft + tight” combination (i.e.,
Cs+t) yields the highest BLEU score on the
development set. One possible reason is that
tight phrases are usually of high quality and
soft coverage allows for taking full advantage of
the training data. On the contrary, Ch+t yields
the lowest BLEU score because hard coverage
fails to distinguish between partially recoverable
training examples as it assigns zero to all partially
recoverable data.
Then, we investigate the effect of the phrase
length limit w in Algorithm 1 on translation
quality. We find w = 7 achieves the best result,
</bodyText>
<page confidence="0.966323">
1233
</page>
<bodyText confidence="0.999924333333333">
which is consistent with the default setting in
Moses. As a result, we used Cs+t and set w = 7
in the following experiments.
</bodyText>
<subsectionHeader confidence="0.8142465">
5.3 Comparison of Different Alignment
Methods
</subsectionHeader>
<bodyText confidence="0.999983870967742">
We compare our approach with a number of
alignment methods in terms of AER and BLEU,
including IBM Model 4 in two directions (C →
E and E → C), symmetrization heuristics (Inter-
section, Union, grow-diag-final), and consistency-
aware models (tight phrase count and coverage).
We used Moses to extract loose bilingual phrases
from word-aligned bilingual corpora from all
methods. Note that our approach uses Cs+t for
finding alignments, from which Moses extracts
loose phrases.
Table 2 lists the numbers of extracted bilingual
phrases (“# bp”), source phrases (“# sp”), target
phrases (“# tp”), source vocabulary size (“# sw”),
and target vocabulary size (“# tw”). We find
that a very large number of loose phrases can be
extracted from the Intersection alignments, which
also have the highest vocabulary sizes. However, a
large portion of words in these phrases are actually
unaligned, resulting in low translation quality.
We observe that adding consistency, either in
terms of phrase count or coverage, significantly
improves alignment accuracy by a large margin,
suggesting that imposing structural constraint
helps to reduce alignment errors. Our approach
outperforms all methods in terms of BLEU
significantly. Note that the coverage itself does
not correlate well with BLEU. It is important
to achieve a balance between model score and
coverage. As mentioned in Section 5.2, we set
A = 0.3 in our experiments.
</bodyText>
<subsectionHeader confidence="0.9990065">
5.4 Translation Evaluation on Different
Alignment Models
</subsectionHeader>
<bodyText confidence="0.999937875">
We apply our approach to both generative (Brown
et al., 1993) and discriminative (Liu et al., 2010)
alignment models. As shown in Table 3, we find
that adding coverage to the optimization objective
significantly improves the BLEU scores. All
differences are statistically significant at p &lt; 0.01
level. This finding suggests that our approach
generalizes well to various alignment models.
</bodyText>
<subsectionHeader confidence="0.9903665">
5.5 Translation Evaluation on Different
Translation Models
</subsectionHeader>
<bodyText confidence="0.999907090909091">
We also evaluated our approach on both phrase-
based and hierarchical phrase-based models. As
shown in Table 4, adding coverage to generative
models leads to significant improvements for
both models. All the differences are statistically
significant at p &lt; 0.01 level.
Although coverage is designed for extracting
phrases, using coverage is still beneficial to hier-
archical phrase-based models because hierarchical
phrases are derived from phrases consistent with
word alignment. 4
</bodyText>
<subsectionHeader confidence="0.9946015">
5.6 Translation Evaluation on Different
Language Pairs
</subsectionHeader>
<bodyText confidence="0.999872916666667">
Finally, we report BLEU scores across five
language pairs in Table 5: Chinese-English (ZH-
EN), Czech-English (CS-EN), German-English
(DE-EN), Spanish-English (ES-EN), and French-
English (FR-EN). ZH-EN uses four references and
other language pairs only use single references.
We find that our approach outperforms the
baseline statistically significantly at p &lt; 0.01 for
four language pairs and p &lt; 0.05 for one language
pair. Therefore, using coverage to bridge word
alignment and machine translation can hopefully
benefit more languages.
</bodyText>
<sectionHeader confidence="0.999853" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.992185">
Our work is inspired by three lines of research:
(1) reachability in discriminative training of
translation models, (2) structural constraints for
alignment, and (3) learning with constraints.
</bodyText>
<subsectionHeader confidence="0.9970915">
6.1 Reachability in Discriminative Training
of Translation Models
</subsectionHeader>
<bodyText confidence="0.999933142857143">
Discriminative training algorithms for statistical
machine translation often need reachable training
examples to find full derivations for updating
model parameters (Liang et al., 2006a; Yu et
al., 2013). Yu et al. (2013) report that only
32.1% sentences in the Chinese-English training
data that contain 12.7% words are fully reachable
</bodyText>
<footnote confidence="0.656710375">
4We also tested our approach on syntax-based models
(Galley et al., 2006; Liu et al., 2006) but failed to achieve
significant improvements. The reason is that extracting
syntactic translation rules often imposes an additional con-
straint: a phrase must be a constituent that is subsumed by
a subtree. We believe that appending such constraint to the
optimization objective will hopefully benefit syntax-based
translation models. We leave this for future work.
</footnote>
<page confidence="0.903695">
1234
</page>
<table confidence="0.9998274">
translation alignment NIST06 NIST02 NIST03 NIST04 NIST05 NIST08
phrase generative 29.60 31.84 31.68 31.80 30.40 24.53
+coverage 30.63** 32.89 ** 32.77** 32.96** 31.33 ** 25.25 **
hierarchical generative 30.43 33.36 32.58 32.72 31.57 24.21
+coverage 31.60** 34.67 ** 34.14** 34.24** 32.73 ** 24.89 **
</table>
<tableCaption confidence="0.986767">
Table 4: Translation evaluation on different translation models. For translation, We used both phrase-
</tableCaption>
<bodyText confidence="0.9469865">
based and hierarchical phrase-based models. For alignment, we used the generative model. “generative”
denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two
directions. Adding coverage leads to significant improvements. We use “**” to denote that the difference
is statistically significant at p &lt; 0.01 level.
</bodyText>
<table confidence="0.877476">
alignment ZH-EN CS-EN DE-EN ES-EN FR-EN
generative 30.40 19.89 21.13 26.39 26.22
+coverage 31.33** 20.04* 21.63** 26.79** 26.76**
</table>
<tableCaption confidence="0.887343">
Table 5: Translation evaluation on five language pairs. “generative” denotes applying the grow-diag-final
</tableCaption>
<bodyText confidence="0.995895894736842">
heuristic to the alignments produced by IBM Model 4 in two directions. We use “*” and“**” to denote
that the difference is statistically significant at p &lt; 0.05 and p &lt; 0.01, respectively. Note that ZH-EN
uses four references and other language pairs only use single references.
due to noisy alignments and distortion limit. They
find that most reachable sentences are short and
generally literal.
We borrow the idea of measuring the degree
of recovering training data from reachability but
ignore the dependency between bilingual phrases
for efficiency. To calculate reachability, one
needs to figure out a full derivation, in which the
bilingual phrases cover the training data and do not
intersect with each other. Yu et al. (2013) indicate
that using forced decoding to select reachable
sentences with an unlimited distortion limit runs
in O(2nn3) time. In contrast, calculating coverage
is much easier and more efficient by ignoring the
dependency between phrases but still retains the
spirit of measuring recovery.
</bodyText>
<subsectionHeader confidence="0.997878">
6.2 Structural Constraints for Alignment
</subsectionHeader>
<bodyText confidence="0.999975666666666">
Modeling structural constraints in alignment has
received intensive attention in the community,
either directly modeling phrase-to-phrase align-
ment (Marcu and Wong, 2002; DeNero and
Klein, 2008; Cohn and Blunsom, 2009) or inter-
secting synchronous grammars with alignment
(Wu, 1997; Zhang and Gildea, 2005; Haghighi et
al., 2009).
Our work is in spirit most close to (Deng and
Zhou, 2009) and (DeNero and Klein, 2010). Deng
and Bowen (2009) cast combining IBM Model 4
alignments in two directions as an optimization
problem driven by an effectiveness function. They
evaluate the impact of adding or removing a
link with respect to phrase extraction using the
effectiveness function of phrase count. The major
difference is that we generalize their idea to
arbitrary alignment models in the search phase
rather than bidirectional alignment combination in
the post-processing phase. In addition, we find
that using coverage instead of phrase count results
in better translation performance (see Table 2).
DeNero and Klein (2010) develop a discrimi-
native model of extraction sets and optimize an
extraction-based loss function with respect to
translation. Their model is capable of predicting
the extracted phrase set. While their approach
relies on annotated data for training the discrimi-
native model, our method only needs to tune
the scaling factor A on the development set. In
addition, our approach is very general and can
easily apply to arbitrary alignment models by
appending a term to the optimization objective.
</bodyText>
<subsectionHeader confidence="0.999823">
6.3 Learning with Constraints
</subsectionHeader>
<bodyText confidence="0.999945222222222">
Our work is also related to learning with con-
straints such as constraint-driven learning (Chang
et al., 2007) and posterior regularization (Ganchev
et al., 2010). The basic idea is to inject
prior knowledge to the model as a regularization
term. The major difference is that our coverage
regularizer is independent of model parameters.
As a result, alignment models can still be trained
independently.
</bodyText>
<page confidence="0.987835">
1235
</page>
<sectionHeader confidence="0.997637" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999971941176471">
In this work, we have presented a general frame-
work for optimizing word alignment with respect
to machine translation. We introduce coverage
to measure how well extracted bilingual phrases
can recover the training data. We develop a
consistency-aware search algorithm that calculates
coverage on the fly during search efficiently.
Experiments show the our approach is effective
in both alignment and translation tasks across
various alignment models, translation models, and
language pairs.
In the future, we plan to apply our approach to
syntax-based models (Galley et al., 2006; Liu et
al., 2006; Shen et al., 2008) and include the con-
stituency constraint in the optimization objective.
It is also interesting to develop consistency-aware
training algorithms for word alignment.
</bodyText>
<sectionHeader confidence="0.996949" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999681076923077">
Yang Liu and Maosong Sun are supported by
the 863 Program (2015AA011808) and the Na-
tional Natural Science Foundation of China (No.
61331013 and No. 61432013). Huanbo Luan
is supported by the National Natural Science
Foundation of China (No. 61303075). This
research is also supported by the Singapore Na-
tional Research Foundation under its International
Research Centre@Singapore Funding Initiative
and administered by the IDM Programme. Many
thanks go to Chunyang Liu and Meng Zhang for
their discussions. We also thank the anonymous
reviewers for their valuable feedback.
</bodyText>
<sectionHeader confidence="0.992781" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988426447761194">
Necip Fazil Ayan and Bonnie J. Dorr. 2006. Going be-
yond aer: An extensive analysis of word alignments
and their impact on mt. In Proceedings of COLING-
ACL 2006, pages 9–16, Sydney, Australia, July.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: Pa-
rameter estimation. Computational Linguistics,
19(2):263–311.
Chris Callison-Burch, David Talbot, and Miles Os-
borne. 2004. Statistical machine translation with
word- and sentence aligned parallel corpora. In
Proceedings of ACL 2004.
Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007.
Guiding semi-supervision with constraint-driven
learning. In Proceedings ofACL 2007.
David Chiang. 2005. A hierarchical phrase-
based model for statistical machine translation. In
Proceedings of ACL 2005, pages 263–270, Ann
Arbor, Michigan, June.
David Chiang. 2007. Hierarchical phrase-based
translation. Computational Linguistics, 33(2):201–
228.
Trevor Cohn and Phil Blunsom. 2009. A bayesian
model of syntax-directed tree to string grammar
induction. In Proceedings of EMNLP 2009.
John DeNero and Dan Klein. 2008. The complexity of
phrase alignment problems. In Proceedings of ACL
2008.
John DeNero and Klein Klein. 2010. Discriminative
modeling of extraction sets for machine translation.
In Proceedings ofACL 2010.
Yonggang Deng and Bowen Zhou. 2009. Optimizing
word alignment combination for phrase table train-
ing. In Proceedings of ACL 2009.
Alexander Fraser and Daniel Marcu. 2007. Measur-
ing word alignment quality for statistical machine
translation. Computational Linguistics, Squibs and
Discussions, 33(3):293–303.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training
of context-rich syntactic translation models. In
Proceedings of COLING-ACL 2006, pages 961–968,
Sydney, Australia, July.
Kuzmann Ganchev, Jo˜ao Grac¸a, Jennifer Gillenwater,
and Ben Taskar. 2010. Posterior regularization
for structured latent variable models. Journal of
Machine Learning Research.
Cyril Goutte, Kenji Yamada, and Eric Gaussier. 2004.
Aligning words using matrix factorisation. In
Proceedings ofACL 2004.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with
supervised itg models. In Proceedings ofACL 2009.
Abraham Ittycheriah and Salim Roukos. 2005. A
maximum entropy word aligner for arabic-english
machine translation. In Proceedings of EMNLP
2005.
Philipp Koehn and Hieu Hoang. 2007. Factored
translation models. In Proceedings of EMNLP-
CoNLL 2007, pages 868–876, Prague, Czech Re-
public, June.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of HLT-NAACL 2003, pages 127–133, Edmonton,
Canada, May.
</reference>
<page confidence="0.790196">
1236
</page>
<reference confidence="0.99982536">
Percy Liang, Alexandre Bouchard-Cote, Dan Klein,
and Ben Taskar. 2006a. An end-to-end dis-
criminative approach to machine translation. In
Proceedings of ACL 2006.
Percy Liang, Ben Taskar, and Dan Klein. 2006b.
Alignment by agreement. In Proceedings of HLT-
NAACL 2006, pages 104–111, New York City, USA,
June.
Yang Liu and Maosong Sun. 2015. Contrastive unsu-
pervised word alignment with non-local features. In
Proceedings of AAAI 2015.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of COLING/ACL 2006.
Yang Liu, Qun Liu, and Shouxun Lin. 2010.
Discriminaitve word alignment by linear modeling.
Computational Linguistics, 36(3):303–339.
Daniel Marcu and William Wong. 2002. A phrase-
based, joint probability model for statistical machine
translation. In Proceedings of EMNLP 2002.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19–51.
Franz J. Och and Hermann Ney. 2004. The alignment
template approach to statistical machine translation.
Computational Linguistics, 30(4):417–449.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a methof for automatic
evaluation of machine translation. In Proceedings
of ACL 2002.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008.
A new string-to-dependency machine translation
algorithm with a target dependency language model.
In Proceedings of ACL 2008.
Andreas Stolcke. 2002. Srilm - an extensible language
modeling toolkit. In Proceedings of ICSLP 2002.
Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, re-labeling, and
re-aligning for syntax-based machine translation.
Computational Linguistics.
Dekai Wu. 1997. Stochastic inversion transaction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23:377–404.
Heng Yu, Liang Huang, Haitao Mi, and Kai Zhao.
2013. Max-violation perceptron and forced decod-
ing for scalable mt training. In Proceedings of
EMNLP 2013.
Hao Zhang and Danieal Gildea. 2005. Stochastic
lexicalized inversion transduction grammars for
alignment. In Proceedings ofACL 2005.
</reference>
<page confidence="0.992316">
1237
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.609407">
<title confidence="0.997672">Consistency-Aware Search for Word Alignment</title>
<author confidence="0.763668">Yang</author>
<affiliation confidence="0.867537666666667">Key Laboratory of Intelligent Technology and Tsinghua National Laboratory for Information Science and Department of Computer Science and Technology, Tsinghua University, Beijing 100084,</affiliation>
<address confidence="0.890637">Collaborative Innovation Center for Language Competence, Jiangsu, China</address>
<email confidence="0.987896">sms@tsinghua.edu.cn</email>
<abstract confidence="0.999341095238095">As conventional word alignment search algorithms usually ignore the consistency constraint in translation rule extraction, improving alignment accuracy does not necessarily increase translation quality. propose to use which reflects how well extracted phrases can recover the training data, to enable word alignment to model consistency and correlate better with machine translation. This can be done by introducing an objective that maximizes both alignment model score and coverage. We introduce an efficient algorithm to calculate coverage on the fly during search. Experiments show that our consistency-aware search algorithm significantly outperforms both generative and discriminative alignment approaches across various languages and translation models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Going beyond aer: An extensive analysis of word alignments and their impact on mt.</title>
<date>2006</date>
<booktitle>In Proceedings of COLINGACL</booktitle>
<pages>9--16</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="2513" citStr="Ayan and Dorr (2006)" startWordPosition="339" endWordPosition="342">bility of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs. We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may not be extracted becaus</context>
</contexts>
<marker>Ayan, Dorr, 2006</marker>
<rawString>Necip Fazil Ayan and Bonnie J. Dorr. 2006. Going beyond aer: An extensive analysis of word alignments and their impact on mt. In Proceedings of COLINGACL 2006, pages 9–16, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1435" citStr="Brown et al., 1993" startWordPosition="180" endWordPosition="183">onsistency and correlate better with machine translation. This can be done by introducing an objective that maximizes both alignment model score and coverage. We introduce an efficient algorithm to calculate coverage on the fly during search. Experiments show that our consistency-aware search algorithm significantly outperforms both generative and discriminative alignment approaches across various languages and translation models. 1 Introduction Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation (Brown et al., 1993). Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (</context>
<context position="24222" citStr="Brown et al., 1993" startWordPosition="4021" endWordPosition="4024">quality. We observe that adding consistency, either in terms of phrase count or coverage, significantly improves alignment accuracy by a large margin, suggesting that imposing structural constraint helps to reduce alignment errors. Our approach outperforms all methods in terms of BLEU significantly. Note that the coverage itself does not correlate well with BLEU. It is important to achieve a balance between model score and coverage. As mentioned in Section 5.2, we set A = 0.3 in our experiments. 5.4 Translation Evaluation on Different Alignment Models We apply our approach to both generative (Brown et al., 1993) and discriminative (Liu et al., 2010) alignment models. As shown in Table 3, we find that adding coverage to the optimization objective significantly improves the BLEU scores. All differences are statistically significant at p &lt; 0.01 level. This finding suggests that our approach generalizes well to various alignment models. 5.5 Translation Evaluation on Different Translation Models We also evaluated our approach on both phrasebased and hierarchical phrase-based models. As shown in Table 4, adding coverage to generative models leads to significant improvements for both models. All the differe</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Statistical machine translation with word- and sentence aligned parallel corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="2439" citStr="Callison-Burch et al., 2004" startWordPosition="327" endWordPosition="330">xtraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs. We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constra</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>Chris Callison-Burch, David Talbot, and Miles Osborne. 2004. Statistical machine translation with word- and sentence aligned parallel corpora. In Proceedings of ACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Guiding semi-supervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="30464" citStr="Chang et al., 2007" startWordPosition="4953" endWordPosition="4956">criminative model of extraction sets and optimize an extraction-based loss function with respect to translation. Their model is capable of predicting the extracted phrase set. While their approach relies on annotated data for training the discriminative model, our method only needs to tune the scaling factor A on the development set. In addition, our approach is very general and can easily apply to arbitrary alignment models by appending a term to the optimization objective. 6.3 Learning with Constraints Our work is also related to learning with constraints such as constraint-driven learning (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). The basic idea is to inject prior knowledge to the model as a regularization term. The major difference is that our coverage regularizer is independent of model parameters. As a result, alignment models can still be trained independently. 1235 7 Conclusion In this work, we have presented a general framework for optimizing word alignment with respect to machine translation. We introduce coverage to measure how well extracted bilingual phrases can recover the training data. We develop a consistency-aware search algorithm that calculates cover</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraint-driven learning. In Proceedings ofACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrasebased model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>263--270</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="1764" citStr="Chiang, 2005" startWordPosition="230" endWordPosition="231">enerative and discriminative alignment approaches across various languages and translation models. 1 Introduction Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation (Brown et al., 1993). Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rat</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrasebased model for statistical machine translation. In Proceedings of ACL 2005, pages 263–270, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<pages>228</pages>
<contexts>
<context position="3533" citStr="Chiang (2007)" startWordPosition="488" endWordPosition="489"> hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may not be extracted because they violate consistency constraints required by translation rule extraction (Och and Ney, 2004). Wang et al. (2010) find that the standard alignment tools are not optimal for training syntax-based models. As a result, they have to resort to realigning. On the other hand, the consistency constraint used in most translation rule extraction algorithms tolerate wrong links within consistent phrase pairs. Chiang (2007) uses the union of two unidirectional alignments, which usually has a low precision, for extracting hierarchical phrases. Therefore, it is important to include both alignment model score and the consistency constraint in the optimization objective of word alignment. In this work, we propose to use coverage, which measures how well extracted phrases can 1228 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1228–1237, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Figure 1: (a) An alignment resulting in a set</context>
<context position="7094" citStr="Chiang, 2007" startWordPosition="1120" endWordPosition="1121">a loose bilingual phrase. Definition 4 (Och and Ney, 2004) Given a training example (f, e, a), a bilingual phrase B = (fj2 j1 , ei2 i1) is said to be consistent with the word alignment a if and only if: 1. No words in the source phrase are aligned with words outside the target phrase and vice versa: b(j,i) E a : j1 &lt; j &lt; j2 H i1 &lt; i &lt; i2, 2. At least one word in the source phrase is aligned with at least one word in the target 1229 phrase: ](j, i) E a : j1 G j G j2 n i1 G i G i2. Alignment consistency forms the basis of translation rule extraction in modern SMT systems (Koehn and Hoang, 2007; Chiang, 2007; Galley et al., 2006; Liu et al., 2006). In Figure 1, (fi , e31) is consistent with the alignment because all words in “oumeng he eluosi” are aligned with all words in “EU and Russia”. In contrast, in Figure 1(b), “huiwu shounao” and “hold summit” are not consistent with the alignment because “hold” is also aligned to a word “juxing” outside. However, alignment consistency only defines a loose relationship between alignment and translation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if “oumeng” is aligned with “Russia”, (fi , ei) is still consisten</context>
<context position="21183" citStr="Chiang, 2007" startWordPosition="3536" endWordPosition="3537">odels, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we follow Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-source toolkit Moses (Koehn and Hoang, 2007). For the hierarchical phrase-based model, we used an in-house reimplementation on par with state-of-the-art opensource decoders. 5.2 Comparison of Different Settings We first investigate the optimal setting for coverage (hard vs. soft, tight vs. loose) on the Chinese-English dataset. For quick validation, we used a subset of the training data to train the phrase-based model using Moses. We used the deve</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201– 228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Phil Blunsom</author>
</authors>
<title>A bayesian model of syntax-directed tree to string grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="2104" citStr="Cohn and Blunsom, 2009" startWordPosition="276" endWordPosition="279">on often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only </context>
<context position="29024" citStr="Cohn and Blunsom, 2009" startWordPosition="4726" endWordPosition="4729">over the training data and do not intersect with each other. Yu et al. (2013) indicate that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidi</context>
</contexts>
<marker>Cohn, Blunsom, 2009</marker>
<rawString>Trevor Cohn and Phil Blunsom. 2009. A bayesian model of syntax-directed tree to string grammar induction. In Proceedings of EMNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>The complexity of phrase alignment problems.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="2079" citStr="DeNero and Klein, 2008" startWordPosition="272" endWordPosition="275">ranslation rule extraction often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and bal</context>
<context position="28999" citStr="DeNero and Klein, 2008" startWordPosition="4722" endWordPosition="4725"> the bilingual phrases cover the training data and do not intersect with each other. Yu et al. (2013) indicate that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the sear</context>
</contexts>
<marker>DeNero, Klein, 2008</marker>
<rawString>John DeNero and Dan Klein. 2008. The complexity of phrase alignment problems. In Proceedings of ACL 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Klein Klein</author>
</authors>
<title>Discriminative modeling of extraction sets for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="8123" citStr="DeNero and Klein, 2010" startWordPosition="1282" endWordPosition="1285">ship between alignment and translation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if “oumeng” is aligned with “Russia”, (fi , ei) is still consistent. This is one possible reason that maximizing alignment accuracy does not necessarily lead to improved translation performance. 3 Modeling Consistency in Word Alignment Our intuition is that including the consistency constraint in word alignment can hopefully reduce the discrepancy between alignment and translation. While this idea has been suggested by a number of authors (e.g., (Deng and Zhou, 2009; DeNero and Klein, 2010)), our goal is to optimize arbitrary alignment models with respect to end-toend translation in the search phase without labeled data (see Related Work for detailed comparison). A natural way is to include consistency in the optimization objective as a regularization term. However, as consistency is only defined at the phrase level (see Definition 4), we need a sentence-level measure to reflect how well an alignment conforms to the consistency constraint. A straightforward measure is the number of bilingual phrases consistent with the alignment (phrase count for short), which is easy and effici</context>
<context position="29222" citStr="DeNero and Klein, 2010" startWordPosition="4760" endWordPosition="4763">e. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidirectional alignment combination in the post-processing phase. In addition, we find that using coverage instead of phrase count results in better translation performance (see Table 2). DeNero and Kle</context>
</contexts>
<marker>DeNero, Klein, 2010</marker>
<rawString>John DeNero and Klein Klein. 2010. Discriminative modeling of extraction sets for machine translation. In Proceedings ofACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yonggang Deng</author>
<author>Bowen Zhou</author>
</authors>
<title>Optimizing word alignment combination for phrase table training.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="8098" citStr="Deng and Zhou, 2009" startWordPosition="1278" endWordPosition="1281">ines a loose relationship between alignment and translation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if “oumeng” is aligned with “Russia”, (fi , ei) is still consistent. This is one possible reason that maximizing alignment accuracy does not necessarily lead to improved translation performance. 3 Modeling Consistency in Word Alignment Our intuition is that including the consistency constraint in word alignment can hopefully reduce the discrepancy between alignment and translation. While this idea has been suggested by a number of authors (e.g., (Deng and Zhou, 2009; DeNero and Klein, 2010)), our goal is to optimize arbitrary alignment models with respect to end-toend translation in the search phase without labeled data (see Related Work for detailed comparison). A natural way is to include consistency in the optimization objective as a regularization term. However, as consistency is only defined at the phrase level (see Definition 4), we need a sentence-level measure to reflect how well an alignment conforms to the consistency constraint. A straightforward measure is the number of bilingual phrases consistent with the alignment (phrase count for short),</context>
<context position="13236" citStr="Deng and Zhou (2009)" startWordPosition="2239" endWordPosition="2242"> {(f(s), e(s), a(s))}Ss=1 and a phrase length limit w, the corpus-level soft coverage is defined as Algorithm 2 Updating the set of extracted bilingual phrases after adding a link. 1: procedure UPDATE(f, e, a, l, B, w) 2: B0 B 3: for all B E B0 do 4: if B.j1 &lt; l.j &lt; B.j2 V B.i1 &lt; l.i &lt; B.i2 then 5: B0 B0 − {B} 6: end if 7: end for 8: j1 l.j − w + 1 9: j2 l.j + w − 1 10: i1 l.i − w + 1 11: i2 l.i + w − 1 12: a0 a U {l} 13: B00 EXTRACT(f, e, a0, j1, j2, i1, i2, w) 14: B0 B0 U B00 15: return B0 16: end procedure The corpus-level hard coverage is defined likewise. 4 Consistency-Aware Search While Deng and Zhou (2009) focus on introducing an effectiveness function such as phrase count into alignment symmetrization, we are interested in guiding the search algorithms of arbitrary alignment models using coverage. Therefore, the objective of our search algorithm is defined as score(f, e, a, w, 9) = M(f, e, a, 9) + AC(f, e, a, w) (4) where M(f, e, a, 9) is alignment model score, 9 is a set of model parameters, C(f, e, a, w) is coverage (either hard or soft), and A is a hyperparameter that controls the preference between alignment model score and coverage. 2 Therefore, the decision rule is given by aˆ = argmax{ </context>
<context position="29193" citStr="Deng and Zhou, 2009" startWordPosition="4755" endWordPosition="4758"> limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidirectional alignment combination in the post-processing phase. In addition, we find that using coverage instead of phrase count results in better translation performance </context>
</contexts>
<marker>Deng, Zhou, 2009</marker>
<rawString>Yonggang Deng and Bowen Zhou. 2009. Optimizing word alignment combination for phrase table training. In Proceedings of ACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<booktitle>Computational Linguistics, Squibs and Discussions,</booktitle>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="2651" citStr="Fraser and Marcu (2007)" startWordPosition="355" endWordPosition="358">rpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs. We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may not be extracted because they violate consistency constraints required by translation rule extraction (Och and Ney, 2004). Wang et al. (2010) find that the stand</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring word alignment quality for statistical machine translation. Computational Linguistics, Squibs and Discussions, 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<pages>961--968</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="1786" citStr="Galley et al., 2006" startWordPosition="232" endWordPosition="235">discriminative alignment approaches across various languages and translation models. 1 Introduction Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation (Brown et al., 1993). Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loo</context>
<context position="7115" citStr="Galley et al., 2006" startWordPosition="1122" endWordPosition="1125">ual phrase. Definition 4 (Och and Ney, 2004) Given a training example (f, e, a), a bilingual phrase B = (fj2 j1 , ei2 i1) is said to be consistent with the word alignment a if and only if: 1. No words in the source phrase are aligned with words outside the target phrase and vice versa: b(j,i) E a : j1 &lt; j &lt; j2 H i1 &lt; i &lt; i2, 2. At least one word in the source phrase is aligned with at least one word in the target 1229 phrase: ](j, i) E a : j1 G j G j2 n i1 G i G i2. Alignment consistency forms the basis of translation rule extraction in modern SMT systems (Koehn and Hoang, 2007; Chiang, 2007; Galley et al., 2006; Liu et al., 2006). In Figure 1, (fi , e31) is consistent with the alignment because all words in “oumeng he eluosi” are aligned with all words in “EU and Russia”. In contrast, in Figure 1(b), “huiwu shounao” and “hold summit” are not consistent with the alignment because “hold” is also aligned to a word “juxing” outside. However, alignment consistency only defines a loose relationship between alignment and translation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if “oumeng” is aligned with “Russia”, (fi , ei) is still consistent. This is one possib</context>
<context position="26364" citStr="Galley et al., 2006" startWordPosition="4331" endWordPosition="4334">(1) reachability in discriminative training of translation models, (2) structural constraints for alignment, and (3) learning with constraints. 6.1 Reachability in Discriminative Training of Translation Models Discriminative training algorithms for statistical machine translation often need reachable training examples to find full derivations for updating model parameters (Liang et al., 2006a; Yu et al., 2013). Yu et al. (2013) report that only 32.1% sentences in the Chinese-English training data that contain 12.7% words are fully reachable 4We also tested our approach on syntax-based models (Galley et al., 2006; Liu et al., 2006) but failed to achieve significant improvements. The reason is that extracting syntactic translation rules often imposes an additional constraint: a phrase must be a constituent that is subsumed by a subtree. We believe that appending such constraint to the optimization objective will hopefully benefit syntax-based translation models. We leave this for future work. 1234 translation alignment NIST06 NIST02 NIST03 NIST04 NIST05 NIST08 phrase generative 29.60 31.84 31.68 31.80 30.40 24.53 +coverage 30.63** 32.89 ** 32.77** 32.96** 31.33 ** 25.25 ** hierarchical generative 30.43</context>
<context position="31354" citStr="Galley et al., 2006" startWordPosition="5088" endWordPosition="5091">rained independently. 1235 7 Conclusion In this work, we have presented a general framework for optimizing word alignment with respect to machine translation. We introduce coverage to measure how well extracted bilingual phrases can recover the training data. We develop a consistency-aware search algorithm that calculates coverage on the fly during search efficiently. Experiments show the our approach is effective in both alignment and translation tasks across various alignment models, translation models, and language pairs. In the future, we plan to apply our approach to syntax-based models (Galley et al., 2006; Liu et al., 2006; Shen et al., 2008) and include the constituency constraint in the optimization objective. It is also interesting to develop consistency-aware training algorithms for word alignment. Acknowledgements Yang Liu and Maosong Sun are supported by the 863 Program (2015AA011808) and the National Natural Science Foundation of China (No. 61331013 and No. 61432013). Huanbo Luan is supported by the National Natural Science Foundation of China (No. 61303075). This research is also supported by the Singapore National Research Foundation under its International Research Centre@Singapore F</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proceedings of COLING-ACL 2006, pages 961–968, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzmann Ganchev</author>
<author>Jo˜ao Grac¸a</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research.</journal>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzmann Ganchev, Jo˜ao Grac¸a, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cyril Goutte</author>
<author>Kenji Yamada</author>
<author>Eric Gaussier</author>
</authors>
<title>Aligning words using matrix factorisation.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="2460" citStr="Goutte et al., 2004" startWordPosition="331" endWordPosition="334">teps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs. We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, s</context>
</contexts>
<marker>Goutte, Yamada, Gaussier, 2004</marker>
<rawString>Cyril Goutte, Kenji Yamada, and Eric Gaussier. 2004. Aligning words using matrix factorisation. In Proceedings ofACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>John Blitzer</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Better word alignments with supervised itg models.</title>
<date>2009</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="29134" citStr="Haghighi et al., 2009" startWordPosition="4743" endWordPosition="4746">ng to select reachable sentences with an unlimited distortion limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidirectional alignment combination in the post-processing phase. In addition, we find that using coverage instead</context>
</contexts>
<marker>Haghighi, Blitzer, DeNero, Klein, 2009</marker>
<rawString>Aria Haghighi, John Blitzer, John DeNero, and Dan Klein. 2009. Better word alignments with supervised itg models. In Proceedings ofACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Ittycheriah</author>
<author>Salim Roukos</author>
</authors>
<title>A maximum entropy word aligner for arabic-english machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="2491" citStr="Ittycheriah and Roukos, 2005" startWordPosition="335" endWordPosition="338">proves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs. We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may n</context>
</contexts>
<marker>Ittycheriah, Roukos, 2005</marker>
<rawString>Abraham Ittycheriah and Salim Roukos. 2005. A maximum entropy word aligner for arabic-english machine translation. In Proceedings of EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLPCoNLL 2007,</booktitle>
<pages>868--876</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="7080" citStr="Koehn and Hoang, 2007" startWordPosition="1116" endWordPosition="1119">phrase, (f41 , e41) is a loose bilingual phrase. Definition 4 (Och and Ney, 2004) Given a training example (f, e, a), a bilingual phrase B = (fj2 j1 , ei2 i1) is said to be consistent with the word alignment a if and only if: 1. No words in the source phrase are aligned with words outside the target phrase and vice versa: b(j,i) E a : j1 &lt; j &lt; j2 H i1 &lt; i &lt; i2, 2. At least one word in the source phrase is aligned with at least one word in the target 1229 phrase: ](j, i) E a : j1 G j G j2 n i1 G i G i2. Alignment consistency forms the basis of translation rule extraction in modern SMT systems (Koehn and Hoang, 2007; Chiang, 2007; Galley et al., 2006; Liu et al., 2006). In Figure 1, (fi , e31) is consistent with the alignment because all words in “oumeng he eluosi” are aligned with all words in “EU and Russia”. In contrast, in Figure 1(b), “huiwu shounao” and “hold summit” are not consistent with the alignment because “hold” is also aligned to a word “juxing” outside. However, alignment consistency only defines a loose relationship between alignment and translation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if “oumeng” is aligned with “Russia”, (fi , ei) is s</context>
<context position="21376" citStr="Koehn and Hoang, 2007" startWordPosition="3562" endWordPosition="3565"> posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-source toolkit Moses (Koehn and Hoang, 2007). For the hierarchical phrase-based model, we used an in-house reimplementation on par with state-of-the-art opensource decoders. 5.2 Comparison of Different Settings We first investigate the optimal setting for coverage (hard vs. soft, tight vs. loose) on the Chinese-English dataset. For quick validation, we used a subset of the training data to train the phrase-based model using Moses. We used the development set to optimize the scaling factor A (see Eq. (4)) and set it to 0.3 in our experiments. Table 1 compares Ch+l, Ch+t, Cs+l, and Cs+t. We find that the “soft + tight” combination (i.e., </context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In Proceedings of EMNLPCoNLL 2007, pages 868–876, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL 2003,</booktitle>
<pages>127--133</pages>
<location>Edmonton, Canada,</location>
<contexts>
<context position="1696" citStr="Koehn et al., 2003" startWordPosition="217" endWordPosition="220">at our consistency-aware search algorithm significantly outperforms both generative and discriminative alignment approaches across various languages and translation models. 1 Introduction Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation (Brown et al., 1993). Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of tr</context>
<context position="21138" citStr="Koehn et al., 2003" startWordPosition="3529" endWordPosition="3532">d discriminative alignment models. For generative models, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we follow Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-source toolkit Moses (Koehn and Hoang, 2007). For the hierarchical phrase-based model, we used an in-house reimplementation on par with state-of-the-art opensource decoders. 5.2 Comparison of Different Settings We first investigate the optimal setting for coverage (hard vs. soft, tight vs. loose) on the Chinese-English dataset. For quick validation, we used a subset of the training data to train the phr</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL 2003, pages 127–133, Edmonton, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Bouchard-Cote</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="9059" citStr="Liang et al., 2006" startWordPosition="1430" endWordPosition="1433">e phrase level (see Definition 4), we need a sentence-level measure to reflect how well an alignment conforms to the consistency constraint. A straightforward measure is the number of bilingual phrases consistent with the alignment (phrase count for short), which is easy and efficient to calculate during search (Deng and Zhou, 2009). Unfortunately, optimizing with respect to phrase count is prone to yield alignments with very few links in a biased way, which result in a large number of bilingual phrases extracted from a small fraction of the training data. Another alternative is reachability (Liang et al., 2006a; Yu et al., 2013) that indicates whether there exists a full derivation to recover the training data. However, calculating reachability faces a major problem: a large portion of training data cannot be fully recovered due to noisy alignments and the distortion limit (Yu et al., 2013). In this work, we propose coverage, which reflects how well extracted phrases can recover the training data, to measure the sentence-level consistency. In the following, we will introduce a number of definitions to facilitate the exposition. Definition 5 A source word fj is said to be covered by a bilingual phra</context>
<context position="20735" citStr="Liang et al. (2006" startWordPosition="3471" endWordPosition="3474">enerative” denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions. “discriminative” denotes the log-linear alignment model (Liu et al., 2010). Adding coverage leads to significant improvements. We use “**” to denote that the difference is statistically significant at p &lt; 0.01 level. 5.1.2 Alignment Models We apply our approach to both generative and discriminative alignment models. For generative models, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we follow Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-sou</context>
<context position="26139" citStr="Liang et al., 2006" startWordPosition="4294" endWordPosition="4297">uage pairs and p &lt; 0.05 for one language pair. Therefore, using coverage to bridge word alignment and machine translation can hopefully benefit more languages. 6 Related Work Our work is inspired by three lines of research: (1) reachability in discriminative training of translation models, (2) structural constraints for alignment, and (3) learning with constraints. 6.1 Reachability in Discriminative Training of Translation Models Discriminative training algorithms for statistical machine translation often need reachable training examples to find full derivations for updating model parameters (Liang et al., 2006a; Yu et al., 2013). Yu et al. (2013) report that only 32.1% sentences in the Chinese-English training data that contain 12.7% words are fully reachable 4We also tested our approach on syntax-based models (Galley et al., 2006; Liu et al., 2006) but failed to achieve significant improvements. The reason is that extracting syntactic translation rules often imposes an additional constraint: a phrase must be a constituent that is subsumed by a subtree. We believe that appending such constraint to the optimization objective will hopefully benefit syntax-based translation models. We leave this for f</context>
</contexts>
<marker>Liang, Bouchard-Cote, Klein, Taskar, 2006</marker>
<rawString>Percy Liang, Alexandre Bouchard-Cote, Dan Klein, and Ben Taskar. 2006a. An end-to-end discriminative approach to machine translation. In Proceedings of ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of HLTNAACL</booktitle>
<pages>104--111</pages>
<location>New York City, USA,</location>
<contexts>
<context position="9059" citStr="Liang et al., 2006" startWordPosition="1430" endWordPosition="1433">e phrase level (see Definition 4), we need a sentence-level measure to reflect how well an alignment conforms to the consistency constraint. A straightforward measure is the number of bilingual phrases consistent with the alignment (phrase count for short), which is easy and efficient to calculate during search (Deng and Zhou, 2009). Unfortunately, optimizing with respect to phrase count is prone to yield alignments with very few links in a biased way, which result in a large number of bilingual phrases extracted from a small fraction of the training data. Another alternative is reachability (Liang et al., 2006a; Yu et al., 2013) that indicates whether there exists a full derivation to recover the training data. However, calculating reachability faces a major problem: a large portion of training data cannot be fully recovered due to noisy alignments and the distortion limit (Yu et al., 2013). In this work, we propose coverage, which reflects how well extracted phrases can recover the training data, to measure the sentence-level consistency. In the following, we will introduce a number of definitions to facilitate the exposition. Definition 5 A source word fj is said to be covered by a bilingual phra</context>
<context position="20735" citStr="Liang et al. (2006" startWordPosition="3471" endWordPosition="3474">enerative” denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions. “discriminative” denotes the log-linear alignment model (Liu et al., 2010). Adding coverage leads to significant improvements. We use “**” to denote that the difference is statistically significant at p &lt; 0.01 level. 5.1.2 Alignment Models We apply our approach to both generative and discriminative alignment models. For generative models, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we follow Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-sou</context>
<context position="26139" citStr="Liang et al., 2006" startWordPosition="4294" endWordPosition="4297">uage pairs and p &lt; 0.05 for one language pair. Therefore, using coverage to bridge word alignment and machine translation can hopefully benefit more languages. 6 Related Work Our work is inspired by three lines of research: (1) reachability in discriminative training of translation models, (2) structural constraints for alignment, and (3) learning with constraints. 6.1 Reachability in Discriminative Training of Translation Models Discriminative training algorithms for statistical machine translation often need reachable training examples to find full derivations for updating model parameters (Liang et al., 2006a; Yu et al., 2013). Yu et al. (2013) report that only 32.1% sentences in the Chinese-English training data that contain 12.7% words are fully reachable 4We also tested our approach on syntax-based models (Galley et al., 2006; Liu et al., 2006) but failed to achieve significant improvements. The reason is that extracting syntactic translation rules often imposes an additional constraint: a phrase must be a constituent that is subsumed by a subtree. We believe that appending such constraint to the optimization objective will hopefully benefit syntax-based translation models. We leave this for f</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006b. Alignment by agreement. In Proceedings of HLTNAACL 2006, pages 104–111, New York City, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Maosong Sun</author>
</authors>
<title>Contrastive unsupervised word alignment with non-local features.</title>
<date>2015</date>
<booktitle>In Proceedings of AAAI</booktitle>
<contexts>
<context position="17967" citStr="Liu and Sun, 2015" startWordPosition="3043" endWordPosition="3046">sh-English (ES-EN), and French-English (FR-EN). The evaluation metrics for alignment and translation are alignment error rate (AER) (Och and Ney, 2003) and case-insensitive BLEU (Papineni et al., 2002), respectively. For Chinese-English, the training data consists of 1.2M pairs of sentences with 30.9M Chinese words and 35.5M English words. We used the SRILM toolkit (Stolcke, 2002) to train a 4- gram language model on the Xinhua portion of the English GIGAWORD corpus, which contains 398.6M words. For alignment evaluation, we used the Tsinghua Chinese-English word alignment evaluation data set (Liu and Sun, 2015). 3 For translation evaluation, we used the NIST 2006 dataset as the development set and the NIST 2002, 2003, 2004, 2005 and 2008 datasets as the test sets. For other languages, the training data is Europarl v7. The English language model trained on the Xinhua portion of the English GIGAWORD corpus was also used for translation from European languages to English. For translation evaluation, we used the “news-test2012” dataset that contains 3,003 sentences as the development set and the “news-test2013” dataset that contains 3,000 sentences as the test set. 3http://nlp.csai.tsinghua.edu.cn/˜ly/s</context>
<context position="20883" citStr="Liu and Sun, 2015" startWordPosition="3490" endWordPosition="3493">log-linear alignment model (Liu et al., 2010). Adding coverage leads to significant improvements. We use “**” to denote that the difference is statistically significant at p &lt; 0.01 level. 5.1.2 Alignment Models We apply our approach to both generative and discriminative alignment models. For generative models, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we follow Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate whether our approach improves the correlation between alignment and translation. For the phrase-based model, we used the open-source toolkit Moses (Koehn and Hoang, 2007). For the hierarchical phrase-based model, we used an in-house reimplementation on par with state-of-the-ar</context>
</contexts>
<marker>Liu, Sun, 2015</marker>
<rawString>Yang Liu and Maosong Sun. 2015. Contrastive unsupervised word alignment with non-local features. In Proceedings of AAAI 2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Treeto-string alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL</booktitle>
<contexts>
<context position="7134" citStr="Liu et al., 2006" startWordPosition="1126" endWordPosition="1129">n 4 (Och and Ney, 2004) Given a training example (f, e, a), a bilingual phrase B = (fj2 j1 , ei2 i1) is said to be consistent with the word alignment a if and only if: 1. No words in the source phrase are aligned with words outside the target phrase and vice versa: b(j,i) E a : j1 &lt; j &lt; j2 H i1 &lt; i &lt; i2, 2. At least one word in the source phrase is aligned with at least one word in the target 1229 phrase: ](j, i) E a : j1 G j G j2 n i1 G i G i2. Alignment consistency forms the basis of translation rule extraction in modern SMT systems (Koehn and Hoang, 2007; Chiang, 2007; Galley et al., 2006; Liu et al., 2006). In Figure 1, (fi , e31) is consistent with the alignment because all words in “oumeng he eluosi” are aligned with all words in “EU and Russia”. In contrast, in Figure 1(b), “huiwu shounao” and “hold summit” are not consistent with the alignment because “hold” is also aligned to a word “juxing” outside. However, alignment consistency only defines a loose relationship between alignment and translation. A phrase pair consistent with alignment tolerates wrong inside links. For example, even if “oumeng” is aligned with “Russia”, (fi , ei) is still consistent. This is one possible reason that maxi</context>
<context position="26383" citStr="Liu et al., 2006" startWordPosition="4335" endWordPosition="4338">iscriminative training of translation models, (2) structural constraints for alignment, and (3) learning with constraints. 6.1 Reachability in Discriminative Training of Translation Models Discriminative training algorithms for statistical machine translation often need reachable training examples to find full derivations for updating model parameters (Liang et al., 2006a; Yu et al., 2013). Yu et al. (2013) report that only 32.1% sentences in the Chinese-English training data that contain 12.7% words are fully reachable 4We also tested our approach on syntax-based models (Galley et al., 2006; Liu et al., 2006) but failed to achieve significant improvements. The reason is that extracting syntactic translation rules often imposes an additional constraint: a phrase must be a constituent that is subsumed by a subtree. We believe that appending such constraint to the optimization objective will hopefully benefit syntax-based translation models. We leave this for future work. 1234 translation alignment NIST06 NIST02 NIST03 NIST04 NIST05 NIST08 phrase generative 29.60 31.84 31.68 31.80 30.40 24.53 +coverage 30.63** 32.89 ** 32.77** 32.96** 31.33 ** 25.25 ** hierarchical generative 30.43 33.36 32.58 32.72 </context>
<context position="31372" citStr="Liu et al., 2006" startWordPosition="5092" endWordPosition="5095"> 1235 7 Conclusion In this work, we have presented a general framework for optimizing word alignment with respect to machine translation. We introduce coverage to measure how well extracted bilingual phrases can recover the training data. We develop a consistency-aware search algorithm that calculates coverage on the fly during search efficiently. Experiments show the our approach is effective in both alignment and translation tasks across various alignment models, translation models, and language pairs. In the future, we plan to apply our approach to syntax-based models (Galley et al., 2006; Liu et al., 2006; Shen et al., 2008) and include the constituency constraint in the optimization objective. It is also interesting to develop consistency-aware training algorithms for word alignment. Acknowledgements Yang Liu and Maosong Sun are supported by the 863 Program (2015AA011808) and the National Natural Science Foundation of China (No. 61331013 and No. 61432013). Huanbo Luan is supported by the National Natural Science Foundation of China (No. 61303075). This research is also supported by the Singapore National Research Foundation under its International Research Centre@Singapore Funding Initiative </context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2006. Treeto-string alignment template for statistical machine translation. In Proceedings of COLING/ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Discriminaitve word alignment by linear modeling.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<contexts>
<context position="14277" citStr="Liu et al. (2010)" startWordPosition="2427" endWordPosition="2430">ither hard or soft), and A is a hyperparameter that controls the preference between alignment model score and coverage. 2 Therefore, the decision rule is given by aˆ = argmax{ score(f, e, a, w, 9)) (5) aEA(f,e) l where A(f, e) is a set of all possible alignments for the sentence pair. Algorithm 1 shows the consistency-aware search algorithm for word alignment. The input of the algorithm includes a source sentence f, a target sentence e, a set of model parameters 9, phrase length limit w, pruning parameters Q and b, and the number of most likely alignments to be retaind n (line 1). Inspired by Liu et al. (2010), 2Note that training algorithms are unchanged. We only introduce a new search algorithm that takes coverage into consideration. We leave consistency-aware training algorithms for arbitrary alignment models for future work. PJ j=1 cov(fj, B) + PIi=1 cov(ei, B) P|f(s)| j=1 cov(f(s) j , B(s)) Cs(D, w) = + PsS=1 |f (s) |+ |e(s) P|e(s)| i=1 cov(e(s) i ,B(s)) 3 Ps 1 |f(s) |+ |e(s)| 1231 the algorithm starts with an empty alignment a together with an empty phrase set B. We use open to store active alignments during search and N to store top-n alignments after search (lines 2-4). The procedure ADD(op</context>
<context position="20310" citStr="Liu et al., 2010" startWordPosition="3402" endWordPosition="3405">2005 test set. alignment NIST06 NIST02 NIST03 NIST04 NIST05 NIST08 generative 29.60 31.84 31.68 31.80 30.40 24.53 +coverage 30.63** 32.89** 32.77** 32.96** 31.33** 25.25** discriminative 28.98 32.31 31.69 31.89 30.65 23.20 +coverage 29.98** 32.93** 32.45** 32.45** 31.10** 24.67** Table 3: Translation evaluation on different alignment models. We apply our approach to both generative and discriminative alignment models. “generative” denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions. “discriminative” denotes the log-linear alignment model (Liu et al., 2010). Adding coverage leads to significant improvements. We use “**” to denote that the difference is statistically significant at p &lt; 0.01 level. 5.1.2 Alignment Models We apply our approach to both generative and discriminative alignment models. For generative models, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we follow Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-li</context>
<context position="24260" citStr="Liu et al., 2010" startWordPosition="4027" endWordPosition="4030">ncy, either in terms of phrase count or coverage, significantly improves alignment accuracy by a large margin, suggesting that imposing structural constraint helps to reduce alignment errors. Our approach outperforms all methods in terms of BLEU significantly. Note that the coverage itself does not correlate well with BLEU. It is important to achieve a balance between model score and coverage. As mentioned in Section 5.2, we set A = 0.3 in our experiments. 5.4 Translation Evaluation on Different Alignment Models We apply our approach to both generative (Brown et al., 1993) and discriminative (Liu et al., 2010) alignment models. As shown in Table 3, we find that adding coverage to the optimization objective significantly improves the BLEU scores. All differences are statistically significant at p &lt; 0.01 level. This finding suggests that our approach generalizes well to various alignment models. 5.5 Translation Evaluation on Different Translation Models We also evaluated our approach on both phrasebased and hierarchical phrase-based models. As shown in Table 4, adding coverage to generative models leads to significant improvements for both models. All the differences are statistically significant at </context>
</contexts>
<marker>Liu, Liu, Lin, 2010</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2010. Discriminaitve word alignment by linear modeling. Computational Linguistics, 36(3):303–339.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>William Wong</author>
</authors>
<title>A phrasebased, joint probability model for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="2055" citStr="Marcu and Wong, 2002" startWordPosition="268" endWordPosition="271">. Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU (Callison-Burch et al., 2004; Goutte et al., 2004; Ittycheriah and Roukos, 2005). Ayan and Dorr (2006) find that precision-oriented alignments result in better translation performance than recall-oriented alignments. Fraser and Marcu (2007) sho</context>
<context position="28975" citStr="Marcu and Wong, 2002" startWordPosition="4718" endWordPosition="4721">l derivation, in which the bilingual phrases cover the training data and do not intersect with each other. Yu et al. (2013) indicate that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alig</context>
</contexts>
<marker>Marcu, Wong, 2002</marker>
<rawString>Daniel Marcu and William Wong. 2002. A phrasebased, joint probability model for statistical machine translation. In Proceedings of EMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="17500" citStr="Och and Ney, 2003" startWordPosition="2972" endWordPosition="2975">h” denotes “hard”, “s” denotes “soft”, “l” denotes “loose”, and “t” denotes “tight”. The BLEU scores were calculated on the development set. For quick validation, we used a small fraction of the training data to train the phrase-based model. 5 Experiments 5.1 Setup 5.1.1 Languages and Datasets We evaluated our approach in terms of alignment and translation quality on five language pairs: Chinese-English (ZH-EN), Czech-English (CSEN), German-English (DE-EN), Spanish-English (ES-EN), and French-English (FR-EN). The evaluation metrics for alignment and translation are alignment error rate (AER) (Och and Ney, 2003) and case-insensitive BLEU (Papineni et al., 2002), respectively. For Chinese-English, the training data consists of 1.2M pairs of sentences with 30.9M Chinese words and 35.5M English words. We used the SRILM toolkit (Stolcke, 2002) to train a 4- gram language model on the Xinhua portion of the English GIGAWORD corpus, which contains 398.6M words. For alignment evaluation, we used the Tsinghua Chinese-English word alignment evaluation data set (Liu and Sun, 2015). 3 For translation evaluation, we used the NIST 2006 dataset as the development set and the NIST 2002, 2003, 2004, 2005 and 2008 dat</context>
<context position="20611" citStr="Och and Ney, 2003" startWordPosition="3448" endWordPosition="3451">n evaluation on different alignment models. We apply our approach to both generative and discriminative alignment models. “generative” denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions. “discriminative” denotes the log-linear alignment model (Liu et al., 2010). Adding coverage leads to significant improvements. We use “**” to denote that the difference is statistically significant at p &lt; 0.01 level. 5.1.2 Alignment Models We apply our approach to both generative and discriminative alignment models. For generative models, we used GIZA++ (Och and Ney, 2003) to train IBM Model 4 in two directions. To calculate a model score for symmetrized alignments, we follow Liang et al. (2006b) to leverage link posterior marginal probabilities. For discriminative models, we used the open-source toolkit TsinghuaAligner (Liu and Sun, 2015) that implements the log-linear alignment model as described in (Liu et al., 2010). The model score for the log-linear model is also defined using link posteriors. 5.1.3 Translation Models Two kinds of translation models, phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007), are used to evaluate wheth</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="1716" citStr="Och and Ney, 2004" startWordPosition="221" endWordPosition="224">ware search algorithm significantly outperforms both generative and discriminative alignment approaches across various languages and translation models. 1 Introduction Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation (Brown et al., 1993). Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline. Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (Koehn et al., 2003; Och and Ney, 2004), but also for syntax-based models (Chiang, 2005; Galley et al., 2006). Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual ∗Corresponding author: Yang Liu. corpora (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009). However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality. A</context>
<context position="3211" citStr="Och and Ney, 2004" startWordPosition="436" endWordPosition="439">e than recall-oriented alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs. We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may not be extracted because they violate consistency constraints required by translation rule extraction (Och and Ney, 2004). Wang et al. (2010) find that the standard alignment tools are not optimal for training syntax-based models. As a result, they have to resort to realigning. On the other hand, the consistency constraint used in most translation rule extraction algorithms tolerate wrong links within consistent phrase pairs. Chiang (2007) uses the union of two unidirectional alignments, which usually has a low precision, for extracting hierarchical phrases. Therefore, it is important to include both alignment model score and the consistency constraint in the optimization objective of word alignment. In this wor</context>
<context position="6540" citStr="Och and Ney, 2004" startWordPosition="996" endWordPosition="999">le, (“zai mosike”, “in Moscow”) in Figure 1 can be denoted as a bilingual phrase B = (f67, e76). For convenience, We use B.j1 and B.j2 to denote the beginning and ending positions of the source phrase in B, respectively. B.i1 and B.i2 are defined likewise for the target side. Definition 3 A bilingual phrase B = (fj2 j1 , ei2 i1) is said to be tight if and only if all boundary words (i.e., fj1, fj2, ei1, and ei2) are aligned. Otherwise, it is a loose bilingual phrase. For example, in Figure 1, while (f31 , e31) is a tight bilingual phrase, (f41 , e41) is a loose bilingual phrase. Definition 4 (Och and Ney, 2004) Given a training example (f, e, a), a bilingual phrase B = (fj2 j1 , ei2 i1) is said to be consistent with the word alignment a if and only if: 1. No words in the source phrase are aligned with words outside the target phrase and vice versa: b(j,i) E a : j1 &lt; j &lt; j2 H i1 &lt; i &lt; i2, 2. At least one word in the source phrase is aligned with at least one word in the target 1229 phrase: ](j, i) E a : j1 G j G j2 n i1 G i G i2. Alignment consistency forms the basis of translation rule extraction in modern SMT systems (Koehn and Hoang, 2007; Chiang, 2007; Galley et al., 2006; Liu et al., 2006). In F</context>
<context position="10894" citStr="Och and Ney, 2004" startWordPosition="1774" endWordPosition="1777">d is similar. For example, in Figure 1(a), all source and target words are covered by the bilingual phrase set. In Figure 1(b), the source words “shounao”, “huiwu”, “juxing” and the target words “hold” and “summit” are not covered. Definition 7 Given a sentence pair (f, e) and a phrase length limit w 1, the hard coverage of an alignment a is defined as a boolean value: t J Ch(f, e, a, w) = δ( E cov(fj, B), J) n j=1 )|cov(ei, B), I (1) where B = EXTRACT(f, e, a,1, J,1,I, w) is the set of consistent bilingual phrases extracted from the sentence pair using a standard phrase extraction algorithm (Och and Ney, 2004). The function δ returns true if the two parameters are same and returns false otherwise. 1The phrase length limit w is essential in defining coverage, restricting that the sentence pair must be covered by bilingual phrases no longer than w words. Otherwise, a very long bilingual phrase (e.g., the entire sentence pair) can achieve full coverage in a biased way. ( δ I i=1 1230 Algorithm 1 A consistency-aware search algorithm for word alignment. 1: procedure ALIGN(f, e, 6, w, β, b, n) 2: open 0 3: N 0 4: (a, B) (0, 0) 5: ADD(open, (a, B), β, b) 6: while open =� 0 do 7: closed 0 8: for all (a, B)</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz J. Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4):417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a methof for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="17550" citStr="Papineni et al., 2002" startWordPosition="2979" endWordPosition="2982">otes “loose”, and “t” denotes “tight”. The BLEU scores were calculated on the development set. For quick validation, we used a small fraction of the training data to train the phrase-based model. 5 Experiments 5.1 Setup 5.1.1 Languages and Datasets We evaluated our approach in terms of alignment and translation quality on five language pairs: Chinese-English (ZH-EN), Czech-English (CSEN), German-English (DE-EN), Spanish-English (ES-EN), and French-English (FR-EN). The evaluation metrics for alignment and translation are alignment error rate (AER) (Och and Ney, 2003) and case-insensitive BLEU (Papineni et al., 2002), respectively. For Chinese-English, the training data consists of 1.2M pairs of sentences with 30.9M Chinese words and 35.5M English words. We used the SRILM toolkit (Stolcke, 2002) to train a 4- gram language model on the Xinhua portion of the English GIGAWORD corpus, which contains 398.6M words. For alignment evaluation, we used the Tsinghua Chinese-English word alignment evaluation data set (Liu and Sun, 2015). 3 For translation evaluation, we used the NIST 2006 dataset as the development set and the NIST 2002, 2003, 2004, 2005 and 2008 datasets as the test sets. For other languages, the t</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a methof for automatic evaluation of machine translation. In Proceedings of ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="31392" citStr="Shen et al., 2008" startWordPosition="5096" endWordPosition="5099"> In this work, we have presented a general framework for optimizing word alignment with respect to machine translation. We introduce coverage to measure how well extracted bilingual phrases can recover the training data. We develop a consistency-aware search algorithm that calculates coverage on the fly during search efficiently. Experiments show the our approach is effective in both alignment and translation tasks across various alignment models, translation models, and language pairs. In the future, we plan to apply our approach to syntax-based models (Galley et al., 2006; Liu et al., 2006; Shen et al., 2008) and include the constituency constraint in the optimization objective. It is also interesting to develop consistency-aware training algorithms for word alignment. Acknowledgements Yang Liu and Maosong Sun are supported by the 863 Program (2015AA011808) and the National Natural Science Foundation of China (No. 61331013 and No. 61432013). Huanbo Luan is supported by the National Natural Science Foundation of China (No. 61303075). This research is also supported by the Singapore National Research Foundation under its International Research Centre@Singapore Funding Initiative and administered by </context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A new string-to-dependency machine translation algorithm with a target dependency language model. In Proceedings of ACL 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP</booktitle>
<contexts>
<context position="17732" citStr="Stolcke, 2002" startWordPosition="3008" endWordPosition="3009">odel. 5 Experiments 5.1 Setup 5.1.1 Languages and Datasets We evaluated our approach in terms of alignment and translation quality on five language pairs: Chinese-English (ZH-EN), Czech-English (CSEN), German-English (DE-EN), Spanish-English (ES-EN), and French-English (FR-EN). The evaluation metrics for alignment and translation are alignment error rate (AER) (Och and Ney, 2003) and case-insensitive BLEU (Papineni et al., 2002), respectively. For Chinese-English, the training data consists of 1.2M pairs of sentences with 30.9M Chinese words and 35.5M English words. We used the SRILM toolkit (Stolcke, 2002) to train a 4- gram language model on the Xinhua portion of the English GIGAWORD corpus, which contains 398.6M words. For alignment evaluation, we used the Tsinghua Chinese-English word alignment evaluation data set (Liu and Sun, 2015). 3 For translation evaluation, we used the NIST 2006 dataset as the development set and the NIST 2002, 2003, 2004, 2005 and 2008 datasets as the test sets. For other languages, the training data is Europarl v7. The English language model trained on the Xinhua portion of the English GIGAWORD corpus was also used for translation from European languages to English.</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm - an extensible language modeling toolkit. In Proceedings of ICSLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
<author>Jonathan May</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Re-structuring, re-labeling, and re-aligning for syntax-based machine translation. Computational Linguistics.</title>
<date>2010</date>
<contexts>
<context position="3231" citStr="Wang et al. (2010)" startWordPosition="440" endWordPosition="443">ed alignments. Fraser and Marcu (2007) show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs. We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction. On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints. Consequently, sensible translation rules may not be extracted because they violate consistency constraints required by translation rule extraction (Och and Ney, 2004). Wang et al. (2010) find that the standard alignment tools are not optimal for training syntax-based models. As a result, they have to resort to realigning. On the other hand, the consistency constraint used in most translation rule extraction algorithms tolerate wrong links within consistent phrase pairs. Chiang (2007) uses the union of two unidirectional alignments, which usually has a low precision, for extracting hierarchical phrases. Therefore, it is important to include both alignment model score and the consistency constraint in the optimization objective of word alignment. In this work, we propose to use</context>
</contexts>
<marker>Wang, May, Knight, Marcu, 2010</marker>
<rawString>Wei Wang, Jonathan May, Kevin Knight, and Daniel Marcu. 2010. Re-structuring, re-labeling, and re-aligning for syntax-based machine translation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transaction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--377</pages>
<contexts>
<context position="29086" citStr="Wu, 1997" startWordPosition="4737" endWordPosition="4738"> indicate that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidirectional alignment combination in the post-processing phase. </context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transaction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23:377–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Yu</author>
<author>Liang Huang</author>
<author>Haitao Mi</author>
<author>Kai Zhao</author>
</authors>
<title>Max-violation perceptron and forced decoding for scalable mt training.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="9078" citStr="Yu et al., 2013" startWordPosition="1434" endWordPosition="1437">efinition 4), we need a sentence-level measure to reflect how well an alignment conforms to the consistency constraint. A straightforward measure is the number of bilingual phrases consistent with the alignment (phrase count for short), which is easy and efficient to calculate during search (Deng and Zhou, 2009). Unfortunately, optimizing with respect to phrase count is prone to yield alignments with very few links in a biased way, which result in a large number of bilingual phrases extracted from a small fraction of the training data. Another alternative is reachability (Liang et al., 2006a; Yu et al., 2013) that indicates whether there exists a full derivation to recover the training data. However, calculating reachability faces a major problem: a large portion of training data cannot be fully recovered due to noisy alignments and the distortion limit (Yu et al., 2013). In this work, we propose coverage, which reflects how well extracted phrases can recover the training data, to measure the sentence-level consistency. In the following, we will introduce a number of definitions to facilitate the exposition. Definition 5 A source word fj is said to be covered by a bilingual phrase B = (fj2 j1 , ei</context>
<context position="26158" citStr="Yu et al., 2013" startWordPosition="4298" endWordPosition="4301">05 for one language pair. Therefore, using coverage to bridge word alignment and machine translation can hopefully benefit more languages. 6 Related Work Our work is inspired by three lines of research: (1) reachability in discriminative training of translation models, (2) structural constraints for alignment, and (3) learning with constraints. 6.1 Reachability in Discriminative Training of Translation Models Discriminative training algorithms for statistical machine translation often need reachable training examples to find full derivations for updating model parameters (Liang et al., 2006a; Yu et al., 2013). Yu et al. (2013) report that only 32.1% sentences in the Chinese-English training data that contain 12.7% words are fully reachable 4We also tested our approach on syntax-based models (Galley et al., 2006; Liu et al., 2006) but failed to achieve significant improvements. The reason is that extracting syntactic translation rules often imposes an additional constraint: a phrase must be a constituent that is subsumed by a subtree. We believe that appending such constraint to the optimization objective will hopefully benefit syntax-based translation models. We leave this for future work. 1234 tr</context>
<context position="28478" citStr="Yu et al. (2013)" startWordPosition="4649" endWordPosition="4652">e is statistically significant at p &lt; 0.05 and p &lt; 0.01, respectively. Note that ZH-EN uses four references and other language pairs only use single references. due to noisy alignments and distortion limit. They find that most reachable sentences are short and generally literal. We borrow the idea of measuring the degree of recovering training data from reachability but ignore the dependency between bilingual phrases for efficiency. To calculate reachability, one needs to figure out a full derivation, in which the bilingual phrases cover the training data and do not intersect with each other. Yu et al. (2013) indicate that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (</context>
</contexts>
<marker>Yu, Huang, Mi, Zhao, 2013</marker>
<rawString>Heng Yu, Liang Huang, Haitao Mi, and Kai Zhao. 2013. Max-violation perceptron and forced decoding for scalable mt training. In Proceedings of EMNLP 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Danieal Gildea</author>
</authors>
<title>Stochastic lexicalized inversion transduction grammars for alignment.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="29110" citStr="Zhang and Gildea, 2005" startWordPosition="4739" endWordPosition="4742">that using forced decoding to select reachable sentences with an unlimited distortion limit runs in O(2nn3) time. In contrast, calculating coverage is much easier and more efficient by ignoring the dependency between phrases but still retains the spirit of measuring recovery. 6.2 Structural Constraints for Alignment Modeling structural constraints in alignment has received intensive attention in the community, either directly modeling phrase-to-phrase alignment (Marcu and Wong, 2002; DeNero and Klein, 2008; Cohn and Blunsom, 2009) or intersecting synchronous grammars with alignment (Wu, 1997; Zhang and Gildea, 2005; Haghighi et al., 2009). Our work is in spirit most close to (Deng and Zhou, 2009) and (DeNero and Klein, 2010). Deng and Bowen (2009) cast combining IBM Model 4 alignments in two directions as an optimization problem driven by an effectiveness function. They evaluate the impact of adding or removing a link with respect to phrase extraction using the effectiveness function of phrase count. The major difference is that we generalize their idea to arbitrary alignment models in the search phase rather than bidirectional alignment combination in the post-processing phase. In addition, we find tha</context>
</contexts>
<marker>Zhang, Gildea, 2005</marker>
<rawString>Hao Zhang and Danieal Gildea. 2005. Stochastic lexicalized inversion transduction grammars for alignment. In Proceedings ofACL 2005.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>