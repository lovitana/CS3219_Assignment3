<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009920">
<title confidence="0.9992915">
A quantitative analysis of gender differences in movies using
psycholinguistic normatives
</title>
<author confidence="0.999278">
Anil Ramakrishna1, Nikolaos Malandrakis1, Elizabeth Staruk1, Shrikanth Narayanan1, 2
</author>
<affiliation confidence="0.999449">
1Department of Computer Science,
2Department of Electrical Engineering,
University of Southern California, Los Angeles, USA
</affiliation>
<email confidence="0.99875">
{akramakr,malandra,staruk}@usc.edu, shri@sipi.usc.edu
</email>
<sectionHeader confidence="0.994114" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99685325">
Direct content analysis reveals important
details about movies including those of
gender representations and potential bi-
ases. We investigate the differences be-
tween male and female character depic-
tions in movies, based on patterns of lan-
guage used. Specifically, we use an au-
tomatically generated lexicon of linguis-
tic norms characterizing gender ladenness.
We use multivariate analysis to investigate
gender depictions and correlate them with
elements of movie production. The pro-
posed metric differentiates between male
and female utterances and exhibits some
interesting interactions with movie genres
and the screenplay writer gender.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999940983870968">
Gender has been an important research topic in the
social sciences, with studies conducted on the ef-
fect of gender on various aspects of human percep-
tion and expression (Benshoff and Griffin, 2011)
as well as investigations of the societal (Behm-
Morawitz and Mastro, 2008) and career implica-
tions of gender and possible underlying biases.
Previous studies report significant implications of
gender on career progress in medicine (Sidhu et
al., 2009), information technology (Cohoon and
Aspray, 2006), politics (Niven, 2006) and show-
business (Smith, 2010).
In this paper we investigate the depictions of
the genders in feature films, through the analysis
of their respective dialogues. The differences in
depiction are a contentious subject, since aspects
of these can be viewed as the result of stereotyp-
ing or gender bias, with the relative presence of
women being a well investigated subject (Bielby
and Bielby, 1996; Lincoln and Allen, 2004). We
are interested in the existing gender depictions, re-
gardless of relative frequencies, as well as any fac-
tors that may affect them. While popular tools
such as the Bechdel test provide a test for detecting
female presence in the movies, we hope to iden-
tify more subtle forms of gender differences across
character gender from the dialogues. Our aim is
to devise a non-binary metric that can be used to
compare or rank movies, characters and perhaps
individual utterances.
To analyze the dialogues we propose using
a metric of language gender ladenness, a num-
ber representing a normative rating of the “per-
ceived feminine or masculine association” (Paivio
et al., 1968) of language. The metric, as origi-
nally defined, is meant to provide an indication
of gender-specificity of individual words, with ex-
treme values assigned to highly stereotypical con-
cepts. Generating this rating for male and fe-
male character dialogues and comparing the char-
acter gender with this rating of “language gender”
should allow us to observe stereotypical behavior.
Word based ratings such as the gender laden-
ness are referred to as linguistic norms (or psy-
cholinguistic norms when corresponding to psy-
chological constructs) and are popular in cognitive
psychology (Clark and Paivio, 2004) and some
computational disciplines, such as sentiment anal-
ysis (Nielsen, 2011) and opinion mining. To uti-
lize gender ladenness, we follow an approach sim-
ilar to simple sentiment analysis, with word-level
norms automatically generated based on a small
starting set of manually annotated norms and sen-
tence (and higher) level norms estimated through
word-level norm statistics. The resulting algo-
rithm allows us to estimate gender ladenness at
any arbitrary granularity.
We use these ratings of dialogue language to
quantify the depictions of male and female char-
acters and attempt to relate the observed gender
ladenness with objective factors.
In section 2 and 3 we describe the data corpus
</bodyText>
<page confidence="0.934974">
1996
</page>
<note confidence="0.8607295">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1996–2001,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<table confidence="0.999645666666667">
Word Norm
Infantry -0.97
Truck -0.73
Dictator -0.56
Strider -0.36
United -0.18
Volunteerism 0.04
Hygiene 0.22
Candle 0.45
Radiant 0.66
Bride 0.84
Gorgeous 0.96
</table>
<tableCaption confidence="0.9202655">
Table 1: Sample word norms(E [−1,1]); −1:
Most masculine and +1: Most feminine.
</tableCaption>
<bodyText confidence="0.99661775">
and the feature extraction process respectively. We
detail the experimental procedure in section 4 and
analysis in section 5 and conclude with future ex-
tensions in section 6.
</bodyText>
<sectionHeader confidence="0.711429" genericHeader="method">
2 Estimating Gender Ladenness
</sectionHeader>
<bodyText confidence="0.999904">
Gender Ladenness, as defined in (Clark and
Paivio, 2004) represents the degree of perceived
“feminine or masculine association” on a numeri-
cal scale ranging from very masculine to very fem-
inine. It is important to note that there was no re-
striction to what “association” may mean: while
it is reasonable to assume that associations of the
form “A is B” or “A has B” would dominate an-
notator perception, that does not preclude other
forms of association. Because of that, referring to
the norms as indicators of how masculine or femi-
nine the words are is not entirely accurate, though
it is a reasonable approximation. The original rat-
ings were re-scaled to [−1, 1] for our purposes,
with lower values indicating a masculine associ-
ation and high values indicating a feminine asso-
ciation. Some sample words, utterances and their
corresponding ratings are presented in Table 1 and
Table 3. Figure 1 shows the average gender laden-
ness across all utterances for the major characters
of a few movies. The annotations as a whole are
reflective of stereotypical views of gender roles,
e.g., words related to war and violence have a
strong masculine association, whereas words re-
lated to family or positive emotions carry strong
feminine associations.
The manual annotations from (Clark and Paivio,
2004) contain ratings for only 925 words, which
are not enough to provide sufficient coverage.
</bodyText>
<figure confidence="0.516641">
g Gede adeess o Majo Caats
</figure>
<figureCaption confidence="0.824168166666667">
Figure 1: Average Gender Ladenness for a few
sample movies, marker size proportional to num-
ber of utterances. Filled markers: Female charac-
ters, Hollow markers: Male characters; PF: Pulp
Fiction, KB: Kill Bill, BC: Breakfast Club, AH:
Annie Hall.
</figureCaption>
<bodyText confidence="0.9999766">
Therefore we use a lexicon expansion method, in-
spired by the work of (Malandrakis et al., 2013)
to estimate the gender ladenness ˆg(wi) of word wi
using the semantic similarities s() between wi and
reference words or concepts cj, as
</bodyText>
<equation confidence="0.990294">
N
ˆg(wi) = θ0 + θjs(wi,cj), (1)
j=1
</equation>
<bodyText confidence="0.999982545454545">
where the terms θi are trained model parameters.
Given a manually annotated lexicon and a set of
reference words, this equation can be used to cre-
ate a linear system. Solving the system via Least
Squares Estimation (LSE) gives us the parameters
θ and an equation that can be used to generate gen-
der ladenness for any new set of words.
Gender ladenness for larger lexical units is gen-
erated via simple statistics, as the average of word
gender ladenness over all content words (adjec-
tives, nouns, verbs and adverbs).
</bodyText>
<sectionHeader confidence="0.997306" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.99964825">
Our primary data source is the Movie DiC corpus
(Banchs, 2012) which includes 619 movie scripts
parsed from The Internet Movie Script Database
(IMSDb, 2015). The xml formatted scripts con-
tain transcripts with speaker information as well as
some structural information. Additional metadata
for each movie were collected from the Internet
Movie Database (IMDb, 2015).
</bodyText>
<figure confidence="0.998503166666667">
-0.05 -0.04 -0.03 -0.02 -0.01 0.0 0.01 002
Gender Ladenness
PF
KB
BC
AH
Jules Vinent Buth
Andrew Brian
Bride Bill
Alvy Annie
Bender
Claire
</figure>
<page confidence="0.965706">
1997
</page>
<bodyText confidence="0.999837666666667">
Since our goal was to analyze gender depic-
tions, we had to annotate each script utterance with
a gender label. The process was complicated by
inconsistencies between the information contained
in the IMDb and Movie DiC corpora, like mis-
matched names, particularly for minor characters.
Initially the script character names were cleaned
using simple heuristics, such as the removal of
all instances of the possessive “’s”. The IMDb
api (IMDbPY, 2015) was used to recover candi-
date movies matching the script movie name and,
in the case of multiple candidates, the best candi-
date was selected based on the number of character
names matching the script. Character names were
compared using the Jaro-Winkler distance (Win-
kler, 1990). Having achieved a one to one map-
ping between IMDb and Movie DiC, we assigned
a gender label to each matched character, using
the gender predictor (NamSor Applied Onomas-
tics, 2015). To make these predictions, we first
use the name of the corresponding actor portraying
that role; if there was no character match, we use
the name of the character. Finally, we calculate a
confidence score of our gender assignment per ut-
terance for each movie, equal to the percentage of
utterances with perfectly matched character name
and a high confidence by the gender predictor. For
the movies for which the confidence scores are not
satisfactory, we manually match the script charac-
ters with IMDb’s characters and annotate genders.
In our experiments, we did this manual annotation
with roughly 75 movies.
Having a mapping of scripts to IMDb en-
tries, we collected more information about the
movie such as the list of genres it belongs to and
the members of the production team (producers,
scriptwriters, directors), and followed a similar
process as described above to assign genders to all
persons. While movies may be created by multi-
ple scriptwriters and directors, we retain only the
first name, the primary credit, in each category.
We removed infrequent genres and movies which
belonged only to the removed genres. We also fil-
tered out utterances with missing or incorrect char-
acter information and the utterances correspond-
ing to characters for which the gender predictor
fails to make confident predictions.
Movies with missing fields were also removed,
leaving us with a total of 568 movies after the
aforementioned pre-processing steps. Table 2 lists
some descriptive statistics of the processed movie
</bodyText>
<table confidence="0.999876571428571">
Property Name Female Male Total
Movie Utterances 107372 256274 363646
Producers 746 2974 3720
Directors 33 572 605
Assistant Directors 846 2739 3585
Screenplay Writers 130 1217 1347
Casting Directors 548 195 743
</table>
<tableCaption confidence="0.834716">
Table 2: Movie Dataset statistics
</tableCaption>
<table confidence="0.9946965">
Utterance Avg. GL
Flowers for the Diva. 0.77
Yeah, what a woman. 0.47
Got the house to yourselves? -0.01
What about the crew? -0.51
Yeah? You and what army? -0.85
</table>
<tableCaption confidence="0.97414">
Table 3: Average gender ladenness for sample ut-
terances from the dataset
</tableCaption>
<bodyText confidence="0.989990866666667">
corpus. At least in terms of raw frequencies, the
gender ratio is clearly skewed towards male, par-
ticularly in the case of directors and with the ex-
ception of casting directors.
The norm generating equation (1) requires a se-
mantic similarity estimate s(), which for the pur-
poses of this paper is the cosine of context vectors
generated over a large corpus of raw web text. The
corpus was created by posing a query to the Ya-
hoo! search engine for every word in the English
version of the aspell spell-checker and collecting
the top 500 result previews. Each preview is com-
posed of a title and a sample of the content, each
being a single sentence. Overall the collected cor-
pus contains approximately 117 million sentences.
</bodyText>
<sectionHeader confidence="0.999273" genericHeader="method">
4 Experimental Procedure
</sectionHeader>
<bodyText confidence="0.999564142857143">
The descriptive feature in this method is gender
ladenness, so we extracted an estimate for each
utterance of every movie. Initially, all utterances
were part-of-speech tagged and non-content words
were removed. Then, word-level gender landen-
ness norms were generated for every remaining
word.
To generate word-level norms, we used equa-
tion (1) with the intermediate seed words wz be-
ing the top 10000 most frequent words in our cor-
pus of web text with length longer that 3 char-
acters. For each word in our corpus, we gener-
ated a binary weighted context vector (of window
size 1) of size ∼ 125000. Then, for each word
</bodyText>
<page confidence="0.988989">
1998
</page>
<bodyText confidence="0.999957210526316">
of interest we calculated a 10000 place similar-
ity vector, containing the cosine similarity scores
between the context vector of said word and the
context vectors of the 10000 intermediate seeds.
Using the training set we generated a K × 10000
matrix of similarities to the seed words and ap-
plied dimensionality reduction via Principal Com-
ponent Analysis (PCA), keeping the first N = 300
components. These transformed similarities be-
came the similarity terms s() of equation (1) and
were used to train the model. For any word in
the scripts, a 10000 place similarity vector is gen-
erated and transformed using the pre-calculated
PCA matrix, then equation (1) is used to create
the gender ladenness estimate.
Ratings were generated at the utterance level,
and collective ratings (per character, gender or
movie) were calculated as utterance rating aver-
ages.
</bodyText>
<sectionHeader confidence="0.999973" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999946633333333">
To evaluate the word norm generation algorithm,
we performed a 10-fold cross-validation experi-
ment on the 925 manually annotated norms in
(Paivio et al., 1968). The generated norms were
evaluated against the ground truth and the method
achieved a 0.801 Pearson correlation to the ground
truth. While there is no comparable result in lit-
erature, the resulting performance appears suffi-
ciently high.
We first investigated the overall gender laden-
ness of movies, represented as the average of all
utterance level scores, with respect to the genre(s)
the movie belongs to. The independent variables
for this analysis were nine binary indicator vari-
ables, one for each of the most frequent genre la-
bels in our movie corpus, with values of zero if
the movie does not belong to the specific genre
and one if it does. The particular representa-
tion of genres as separate variables was chosen
because each movie can belong to multiple gen-
res. Interaction terms were included. Running n-
way ANOVA with the aggregate gender ladenness
across both character genders as the dependent
variable revealed significant differences between
genres, with Action movies leaning towards the
masculine (p = 0.013) compared to Non-Action
movies, a not surprising result.
A few significant interactions between genres
are shown in figure 2. Fig. 2a indicates that among
non-drama movies, romantic movies tend to in-
</bodyText>
<figure confidence="0.549963">
(c) Action v/s Drama (d) Adventure v/s Mystery
</figure>
<figureCaption confidence="0.992539">
Figure 2: Interactions between genres
</figureCaption>
<bodyText confidence="0.99909375">
clude more feminine language compared to non-
romantic movies. However, if a movie belongs
to the genre drama, its mean gender ladenness
scores remain fairly constant, irrespective of its
other genres. Similar interpretations can be drawn
from the other plots in figure 2.
To analyze the effect of character gender on
the gender ladenness scores, we next ran ANOVA
with the character gender and the movie writer’s
gender as additional independent variables. The
dependent variable in this case was the aggregate
gender ladenness score across all utterances for
male and female characters, so two scores per
movie. The interaction of character gender and
movie genre is shown in figure 3. The scores of
male and female characters are correlated, which
can be attributed to the underlying concepts in
the utterances from these movies. The differ-
ence between genders is significant (p = 0.034),
with male characters consistently using signifi-
cantly more masculine language than their female
counterparts, a finding that lends some credence
to the metric used. Looking at the binary genre
variables revealed that
Action movies contained significantly more
masculine language than Non-Action movies (p
&lt; 10−5) and the same holds for Crime movies (p
&lt; 10−5). Conversely, Romantic movies leaned
towards the more feminine language than non-
Romantic movies (p &lt; 10−5) and similarly for
Comedy movies compared to non-Comedy movies
(p = 0.02). The male - female character gender
</bodyText>
<figure confidence="0.969227833333333">
−0.008
−0.01
−0.012
−0.014
−0.016
−0.018
0.01
0
−0.01
−0.02
(a) Drama v/s Romance (b) Crime v/s Thriller
Dra
Oth
Action Others
Mys
Oth
Adventure Others
Drama Others Crime Others
−2
−4
−6
−8
Thr
Oth
−10
−12
−0.008
−0.01
−0.012
−0.014
x 10−3
Rom
Oth
1999
Mean feature value across character gender
Feature mean
</figure>
<figureCaption confidence="0.9215635">
Figure 3: Interaction of movie genre with charac-
ter gender
</figureCaption>
<figure confidence="0.8221025">
Mean feature value across writer gender
Feature mean
</figure>
<figureCaption confidence="0.967514">
Figure 4: Interaction of screenplay writer’s gender
with genre
</figureCaption>
<figure confidence="0.99438432">
Adventure
Female
Male
Sci−Fi
Drama
Crime
Comedy
Romance
Mystery
−0.05 −0.04 −0.03 −0.02 −0.01 0
Genre
Action
Thriller
Adventure
Mystery
Drama
Genre
Comedy
Romance
Thriller
Crime
Female
Male
Action
−0.04 −0.02 0 0.02
</figure>
<bodyText confidence="0.998352526315789">
ladenness distance however is not affected in any
significant way by the genre.
We include only the screenplay writer’s gen-
der in our analysis, though both the directors and
screenplay writers influence the dialog lines (utter-
ances), since the writers are more likely to directly
influence the actual language used. In addition, the
very small number of female directors in the data,
as seen in table 2, leads to a violation of ANOVA’s
homoscedasticity assumption. Though the writer
gender itself was not a significant factor, the inter-
action of writer’s gender with the Action genre was
significant (p = 0.005). The plot illustrating this
interaction is shown in figure 4. It appears that
female script writers write more masculine utter-
ances compared to their male colleagues, at least
for Action movies. We also investigated interac-
tions between the writer and character gender, but
none proved significant.
</bodyText>
<sectionHeader confidence="0.998619" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999966266666667">
We used regression to extrapolate manually an-
notated psycholinguistic normatives to movie ut-
terances and investigated the use of these met-
rics to describe gender depictions. The metric
proved successful, showing significant differences
between the genders and predictable patterns with
respect to movie genres.
Future work will include the use of further met-
rics, with those describing emotions being the first
candidates. We also intend to collect more movie
and character level metadata to be used in anal-
ysis. Finally, it is worth remembering that lan-
guage provides only a partial description of de-
picted characters, so we should aim to augment
with aural/visual information.
</bodyText>
<sectionHeader confidence="0.999082" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999307">
The authors gratefully acknowledge support from
NSF, Geena Davis Institute on Gender in Media
and Google.org.
</bodyText>
<sectionHeader confidence="0.999094" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998752">
Rafael E Banchs. 2012. Movie-Dic: a movie dia-
logue corpus for research and development. In Pro-
ceedings of the 50th Annual Meeting of the Associ-
ation for Computational Linguistics: Short Papers-
Volume 2, pages 203–207. Association for Compu-
tational Linguistics.
Elizabeth Behm-Morawitz and Dana E Mastro. 2008.
Mean girls? the influence of gender portrayals in
teen movies on emerging adults’ gender-based atti-
tudes and beliefs. Journalism &amp; Mass Communica-
tion Quarterly, 85(1):131–146.
Harry M Benshoff and Sean Griffin. 2011. America on
film: Representing race, class, gender, and sexuality
at the movies. John Wiley &amp; Sons.
Denise D Bielby and William T Bielby. 1996. Women
and men in film gender inequality among writers in a
culture industry. Gender &amp; Society, 10(3):248–270.
James M Clark and Allan Paivio. 2004. Extensions of
the Paivio, Yuille, and Madigan (1968) norms. Be-
havior Research Methods, Instruments, &amp; Comput-
ers, 36(3):371–383.
J McGrath Cohoon and William Aspray. 2006. Women
and information technology: Research on underrep-
resentation, volume 1. The MIT Press.
</reference>
<page confidence="0.697775">
2000
</page>
<reference confidence="0.99914695">
IMDb. 2015. Internet movie database. [Online; ac-
cessed 10-June-2015].
IMDbPY. 2015. [Online; accessed 10-June-2015].
IMSDb. 2015. Internet movie script database. [On-
line; accessed 10-June-2015].
Anne E Lincoln and Michael Patrick Allen. 2004.
Double jeopardy in hollywood: Age and gender in
the careers of film actors, 1926–1999. Sociological
Forum, 19(4):611–631.
Nikolaos Malandrakis, Alexandros Potamianos, Elias
Iosif, and Shrikanth Narayanan. 2013. Distri-
butional semantic models for affective text analy-
sis. Audio, Speech, and Language Processing, IEEE
Transactions on, 21(11):2379–2392, Nov.
NamSor Applied Onomastics. 2015. NamSor gender
API. [Online; accessed 10-June-2015].
Finn ˚Arup Nielsen. 2011. Anew ANEW: Evaluation
of a word list for sentiment analysis in microblogs.
arXiv preprint arXiv:1103.2903.
David Niven. 2006. Throwing your hat out of the
ring: Negative recruitment and the gender imbalance
in state legislative candidacy. Politics &amp; Gender,
2(04):473–489.
Allan Paivio, John C Yuille, and Stephen A Madigan.
1968. Concreteness, imagery, and meaningfulness
values for 925 nouns. Journal of experimental psy-
chology, 76(1p2):1.
Reena Sidhu, Praveen Rajashekhar, Victoria L Lavin,
Joanne Parry, James Attwood, Anita Holdcroft, and
David S Sanders. 2009. The gender imbalance in
academic medicine: a study of female authorship in
the united kingdom. Journal of the Royal Society of
Medicine, 102(8):337–342.
Stacy L Smith. 2010. Gender oppression in cinematic
content? a look at females on-screen &amp; behind-
the-camera in top-grossing 2007 films. Retrieved
September, 2:2010.
William E Winkler. 1990. String comparator met-
rics and enhanced decision rules in the fellegi-sunter
model of record linkage.
</reference>
<page confidence="0.991496">
2001
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974605">
<title confidence="0.996565">A quantitative analysis of gender differences in movies psycholinguistic normatives</title>
<author confidence="0.999699">Nikolaos Elizabeth Shrikanth</author>
<affiliation confidence="0.994711666666667">of Computer of Electrical University of Southern California, Los Angeles,</affiliation>
<email confidence="0.999899">shri@sipi.usc.edu</email>
<abstract confidence="0.99967">Direct content analysis reveals important details about movies including those of gender representations and potential biases. We investigate the differences between male and female character depictions in movies, based on patterns of language used. Specifically, we use an automatically generated lexicon of linguistic norms characterizing gender ladenness. We use multivariate analysis to investigate gender depictions and correlate them with elements of movie production. The proposed metric differentiates between male and female utterances and exhibits some interesting interactions with movie genres and the screenplay writer gender.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rafael E Banchs</author>
</authors>
<title>Movie-Dic: a movie dialogue corpus for research and development.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short PapersVolume 2,</booktitle>
<pages>203--207</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7081" citStr="Banchs, 2012" startWordPosition="1110" endWordPosition="1111"> = θ0 + θjs(wi,cj), (1) j=1 where the terms θi are trained model parameters. Given a manually annotated lexicon and a set of reference words, this equation can be used to create a linear system. Solving the system via Least Squares Estimation (LSE) gives us the parameters θ and an equation that can be used to generate gender ladenness for any new set of words. Gender ladenness for larger lexical units is generated via simple statistics, as the average of word gender ladenness over all content words (adjectives, nouns, verbs and adverbs). 3 Data Our primary data source is the Movie DiC corpus (Banchs, 2012) which includes 619 movie scripts parsed from The Internet Movie Script Database (IMSDb, 2015). The xml formatted scripts contain transcripts with speaker information as well as some structural information. Additional metadata for each movie were collected from the Internet Movie Database (IMDb, 2015). -0.05 -0.04 -0.03 -0.02 -0.01 0.0 0.01 002 Gender Ladenness PF KB BC AH Jules Vinent Buth Andrew Brian Bride Bill Alvy Annie Bender Claire 1997 Since our goal was to analyze gender depictions, we had to annotate each script utterance with a gender label. The process was complicated by inconsiste</context>
</contexts>
<marker>Banchs, 2012</marker>
<rawString>Rafael E Banchs. 2012. Movie-Dic: a movie dialogue corpus for research and development. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short PapersVolume 2, pages 203–207. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth Behm-Morawitz</author>
<author>Dana E Mastro</author>
</authors>
<title>Mean girls? the influence of gender portrayals in teen movies on emerging adults’ gender-based attitudes and beliefs.</title>
<date>2008</date>
<journal>Journalism &amp; Mass Communication Quarterly,</journal>
<volume>85</volume>
<issue>1</issue>
<marker>Behm-Morawitz, Mastro, 2008</marker>
<rawString>Elizabeth Behm-Morawitz and Dana E Mastro. 2008. Mean girls? the influence of gender portrayals in teen movies on emerging adults’ gender-based attitudes and beliefs. Journalism &amp; Mass Communication Quarterly, 85(1):131–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry M Benshoff</author>
<author>Sean Griffin</author>
</authors>
<title>America on film: Representing race, class, gender, and sexuality at the movies.</title>
<date>2011</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="1214" citStr="Benshoff and Griffin, 2011" startWordPosition="161" endWordPosition="164">tterns of language used. Specifically, we use an automatically generated lexicon of linguistic norms characterizing gender ladenness. We use multivariate analysis to investigate gender depictions and correlate them with elements of movie production. The proposed metric differentiates between male and female utterances and exhibits some interesting interactions with movie genres and the screenplay writer gender. 1 Introduction Gender has been an important research topic in the social sciences, with studies conducted on the effect of gender on various aspects of human perception and expression (Benshoff and Griffin, 2011) as well as investigations of the societal (BehmMorawitz and Mastro, 2008) and career implications of gender and possible underlying biases. Previous studies report significant implications of gender on career progress in medicine (Sidhu et al., 2009), information technology (Cohoon and Aspray, 2006), politics (Niven, 2006) and showbusiness (Smith, 2010). In this paper we investigate the depictions of the genders in feature films, through the analysis of their respective dialogues. The differences in depiction are a contentious subject, since aspects of these can be viewed as the result of ste</context>
</contexts>
<marker>Benshoff, Griffin, 2011</marker>
<rawString>Harry M Benshoff and Sean Griffin. 2011. America on film: Representing race, class, gender, and sexuality at the movies. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Denise D Bielby</author>
<author>William T Bielby</author>
</authors>
<title>Women and men in film gender inequality among writers in a culture industry.</title>
<date>1996</date>
<journal>Gender &amp; Society,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="1934" citStr="Bielby and Bielby, 1996" startWordPosition="272" endWordPosition="275">s of gender and possible underlying biases. Previous studies report significant implications of gender on career progress in medicine (Sidhu et al., 2009), information technology (Cohoon and Aspray, 2006), politics (Niven, 2006) and showbusiness (Smith, 2010). In this paper we investigate the depictions of the genders in feature films, through the analysis of their respective dialogues. The differences in depiction are a contentious subject, since aspects of these can be viewed as the result of stereotyping or gender bias, with the relative presence of women being a well investigated subject (Bielby and Bielby, 1996; Lincoln and Allen, 2004). We are interested in the existing gender depictions, regardless of relative frequencies, as well as any factors that may affect them. While popular tools such as the Bechdel test provide a test for detecting female presence in the movies, we hope to identify more subtle forms of gender differences across character gender from the dialogues. Our aim is to devise a non-binary metric that can be used to compare or rank movies, characters and perhaps individual utterances. To analyze the dialogues we propose using a metric of language gender ladenness, a number represen</context>
</contexts>
<marker>Bielby, Bielby, 1996</marker>
<rawString>Denise D Bielby and William T Bielby. 1996. Women and men in film gender inequality among writers in a culture industry. Gender &amp; Society, 10(3):248–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James M Clark</author>
<author>Allan Paivio</author>
</authors>
<title>norms.</title>
<date>2004</date>
<journal>Extensions of the Paivio, Yuille, and Madigan</journal>
<volume>36</volume>
<issue>3</issue>
<contexts>
<context position="3231" citStr="Clark and Paivio, 2004" startWordPosition="481" endWordPosition="484">n” (Paivio et al., 1968) of language. The metric, as originally defined, is meant to provide an indication of gender-specificity of individual words, with extreme values assigned to highly stereotypical concepts. Generating this rating for male and female character dialogues and comparing the character gender with this rating of “language gender” should allow us to observe stereotypical behavior. Word based ratings such as the gender ladenness are referred to as linguistic norms (or psycholinguistic norms when corresponding to psychological constructs) and are popular in cognitive psychology (Clark and Paivio, 2004) and some computational disciplines, such as sentiment analysis (Nielsen, 2011) and opinion mining. To utilize gender ladenness, we follow an approach similar to simple sentiment analysis, with word-level norms automatically generated based on a small starting set of manually annotated norms and sentence (and higher) level norms estimated through word-level norm statistics. The resulting algorithm allows us to estimate gender ladenness at any arbitrary granularity. We use these ratings of dialogue language to quantify the depictions of male and female characters and attempt to relate the obser</context>
<context position="4624" citStr="Clark and Paivio, 2004" startWordPosition="692" endWordPosition="695">ge Processing, pages 1996–2001, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Word Norm Infantry -0.97 Truck -0.73 Dictator -0.56 Strider -0.36 United -0.18 Volunteerism 0.04 Hygiene 0.22 Candle 0.45 Radiant 0.66 Bride 0.84 Gorgeous 0.96 Table 1: Sample word norms(E [−1,1]); −1: Most masculine and +1: Most feminine. and the feature extraction process respectively. We detail the experimental procedure in section 4 and analysis in section 5 and conclude with future extensions in section 6. 2 Estimating Gender Ladenness Gender Ladenness, as defined in (Clark and Paivio, 2004) represents the degree of perceived “feminine or masculine association” on a numerical scale ranging from very masculine to very feminine. It is important to note that there was no restriction to what “association” may mean: while it is reasonable to assume that associations of the form “A is B” or “A has B” would dominate annotator perception, that does not preclude other forms of association. Because of that, referring to the norms as indicators of how masculine or feminine the words are is not entirely accurate, though it is a reasonable approximation. The original ratings were re-scaled to</context>
<context position="5863" citStr="Clark and Paivio, 2004" startWordPosition="898" endWordPosition="901"> purposes, with lower values indicating a masculine association and high values indicating a feminine association. Some sample words, utterances and their corresponding ratings are presented in Table 1 and Table 3. Figure 1 shows the average gender ladenness across all utterances for the major characters of a few movies. The annotations as a whole are reflective of stereotypical views of gender roles, e.g., words related to war and violence have a strong masculine association, whereas words related to family or positive emotions carry strong feminine associations. The manual annotations from (Clark and Paivio, 2004) contain ratings for only 925 words, which are not enough to provide sufficient coverage. g Gede adeess o Majo Caats Figure 1: Average Gender Ladenness for a few sample movies, marker size proportional to number of utterances. Filled markers: Female characters, Hollow markers: Male characters; PF: Pulp Fiction, KB: Kill Bill, BC: Breakfast Club, AH: Annie Hall. Therefore we use a lexicon expansion method, inspired by the work of (Malandrakis et al., 2013) to estimate the gender ladenness ˆg(wi) of word wi using the semantic similarities s() between wi and reference words or concepts cj, as N ˆ</context>
</contexts>
<marker>Clark, Paivio, 2004</marker>
<rawString>James M Clark and Allan Paivio. 2004. Extensions of the Paivio, Yuille, and Madigan (1968) norms. Behavior Research Methods, Instruments, &amp; Computers, 36(3):371–383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McGrath Cohoon</author>
<author>William Aspray</author>
</authors>
<title>Women and information technology:</title>
<date>2006</date>
<journal>Research on underrepresentation,</journal>
<volume>1</volume>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="1515" citStr="Cohoon and Aspray, 2006" startWordPosition="205" endWordPosition="208">male utterances and exhibits some interesting interactions with movie genres and the screenplay writer gender. 1 Introduction Gender has been an important research topic in the social sciences, with studies conducted on the effect of gender on various aspects of human perception and expression (Benshoff and Griffin, 2011) as well as investigations of the societal (BehmMorawitz and Mastro, 2008) and career implications of gender and possible underlying biases. Previous studies report significant implications of gender on career progress in medicine (Sidhu et al., 2009), information technology (Cohoon and Aspray, 2006), politics (Niven, 2006) and showbusiness (Smith, 2010). In this paper we investigate the depictions of the genders in feature films, through the analysis of their respective dialogues. The differences in depiction are a contentious subject, since aspects of these can be viewed as the result of stereotyping or gender bias, with the relative presence of women being a well investigated subject (Bielby and Bielby, 1996; Lincoln and Allen, 2004). We are interested in the existing gender depictions, regardless of relative frequencies, as well as any factors that may affect them. While popular tools</context>
</contexts>
<marker>Cohoon, Aspray, 2006</marker>
<rawString>J McGrath Cohoon and William Aspray. 2006. Women and information technology: Research on underrepresentation, volume 1. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IMDb</author>
</authors>
<title>Internet movie database. [Online; accessed 10-June-2015]. IMDbPY.</title>
<date>2015</date>
<note>[Online; accessed 10-June-2015].</note>
<contexts>
<context position="7383" citStr="IMDb, 2015" startWordPosition="1154" endWordPosition="1155">sed to generate gender ladenness for any new set of words. Gender ladenness for larger lexical units is generated via simple statistics, as the average of word gender ladenness over all content words (adjectives, nouns, verbs and adverbs). 3 Data Our primary data source is the Movie DiC corpus (Banchs, 2012) which includes 619 movie scripts parsed from The Internet Movie Script Database (IMSDb, 2015). The xml formatted scripts contain transcripts with speaker information as well as some structural information. Additional metadata for each movie were collected from the Internet Movie Database (IMDb, 2015). -0.05 -0.04 -0.03 -0.02 -0.01 0.0 0.01 002 Gender Ladenness PF KB BC AH Jules Vinent Buth Andrew Brian Bride Bill Alvy Annie Bender Claire 1997 Since our goal was to analyze gender depictions, we had to annotate each script utterance with a gender label. The process was complicated by inconsistencies between the information contained in the IMDb and Movie DiC corpora, like mismatched names, particularly for minor characters. Initially the script character names were cleaned using simple heuristics, such as the removal of all instances of the possessive “’s”. The IMDb api (IMDbPY, 2015) was u</context>
</contexts>
<marker>IMDb, 2015</marker>
<rawString>IMDb. 2015. Internet movie database. [Online; accessed 10-June-2015]. IMDbPY. 2015. [Online; accessed 10-June-2015].</rawString>
</citation>
<citation valid="true">
<authors>
<author>IMSDb</author>
</authors>
<title>Internet movie script database.</title>
<date>2015</date>
<note>[Online; accessed 10-June-2015].</note>
<contexts>
<context position="7175" citStr="IMSDb, 2015" startWordPosition="1124" endWordPosition="1125">nnotated lexicon and a set of reference words, this equation can be used to create a linear system. Solving the system via Least Squares Estimation (LSE) gives us the parameters θ and an equation that can be used to generate gender ladenness for any new set of words. Gender ladenness for larger lexical units is generated via simple statistics, as the average of word gender ladenness over all content words (adjectives, nouns, verbs and adverbs). 3 Data Our primary data source is the Movie DiC corpus (Banchs, 2012) which includes 619 movie scripts parsed from The Internet Movie Script Database (IMSDb, 2015). The xml formatted scripts contain transcripts with speaker information as well as some structural information. Additional metadata for each movie were collected from the Internet Movie Database (IMDb, 2015). -0.05 -0.04 -0.03 -0.02 -0.01 0.0 0.01 002 Gender Ladenness PF KB BC AH Jules Vinent Buth Andrew Brian Bride Bill Alvy Annie Bender Claire 1997 Since our goal was to analyze gender depictions, we had to annotate each script utterance with a gender label. The process was complicated by inconsistencies between the information contained in the IMDb and Movie DiC corpora, like mismatched nam</context>
</contexts>
<marker>IMSDb, 2015</marker>
<rawString>IMSDb. 2015. Internet movie script database. [Online; accessed 10-June-2015].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne E Lincoln</author>
<author>Michael Patrick Allen</author>
</authors>
<title>Double jeopardy in hollywood: Age and gender in the careers of film actors, 1926–1999. Sociological Forum,</title>
<date>2004</date>
<contexts>
<context position="1960" citStr="Lincoln and Allen, 2004" startWordPosition="276" endWordPosition="279">underlying biases. Previous studies report significant implications of gender on career progress in medicine (Sidhu et al., 2009), information technology (Cohoon and Aspray, 2006), politics (Niven, 2006) and showbusiness (Smith, 2010). In this paper we investigate the depictions of the genders in feature films, through the analysis of their respective dialogues. The differences in depiction are a contentious subject, since aspects of these can be viewed as the result of stereotyping or gender bias, with the relative presence of women being a well investigated subject (Bielby and Bielby, 1996; Lincoln and Allen, 2004). We are interested in the existing gender depictions, regardless of relative frequencies, as well as any factors that may affect them. While popular tools such as the Bechdel test provide a test for detecting female presence in the movies, we hope to identify more subtle forms of gender differences across character gender from the dialogues. Our aim is to devise a non-binary metric that can be used to compare or rank movies, characters and perhaps individual utterances. To analyze the dialogues we propose using a metric of language gender ladenness, a number representing a normative rating of</context>
</contexts>
<marker>Lincoln, Allen, 2004</marker>
<rawString>Anne E Lincoln and Michael Patrick Allen. 2004. Double jeopardy in hollywood: Age and gender in the careers of film actors, 1926–1999. Sociological Forum, 19(4):611–631.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikolaos Malandrakis</author>
<author>Alexandros Potamianos</author>
<author>Elias Iosif</author>
<author>Shrikanth Narayanan</author>
</authors>
<title>Distributional semantic models for affective text analysis. Audio, Speech, and Language Processing,</title>
<date>2013</date>
<journal>IEEE Transactions on,</journal>
<volume>21</volume>
<issue>11</issue>
<contexts>
<context position="6322" citStr="Malandrakis et al., 2013" startWordPosition="974" endWordPosition="977">g masculine association, whereas words related to family or positive emotions carry strong feminine associations. The manual annotations from (Clark and Paivio, 2004) contain ratings for only 925 words, which are not enough to provide sufficient coverage. g Gede adeess o Majo Caats Figure 1: Average Gender Ladenness for a few sample movies, marker size proportional to number of utterances. Filled markers: Female characters, Hollow markers: Male characters; PF: Pulp Fiction, KB: Kill Bill, BC: Breakfast Club, AH: Annie Hall. Therefore we use a lexicon expansion method, inspired by the work of (Malandrakis et al., 2013) to estimate the gender ladenness ˆg(wi) of word wi using the semantic similarities s() between wi and reference words or concepts cj, as N ˆg(wi) = θ0 + θjs(wi,cj), (1) j=1 where the terms θi are trained model parameters. Given a manually annotated lexicon and a set of reference words, this equation can be used to create a linear system. Solving the system via Least Squares Estimation (LSE) gives us the parameters θ and an equation that can be used to generate gender ladenness for any new set of words. Gender ladenness for larger lexical units is generated via simple statistics, as the averag</context>
</contexts>
<marker>Malandrakis, Potamianos, Iosif, Narayanan, 2013</marker>
<rawString>Nikolaos Malandrakis, Alexandros Potamianos, Elias Iosif, and Shrikanth Narayanan. 2013. Distributional semantic models for affective text analysis. Audio, Speech, and Language Processing, IEEE Transactions on, 21(11):2379–2392, Nov.</rawString>
</citation>
<citation valid="true">
<title>NamSor Applied Onomastics.</title>
<date>2015</date>
<note>NamSor gender API. [Online; accessed 10-June-2015].</note>
<marker>2015</marker>
<rawString>NamSor Applied Onomastics. 2015. NamSor gender API. [Online; accessed 10-June-2015].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Finn ˚Arup Nielsen</author>
</authors>
<title>Anew ANEW: Evaluation of a word list for sentiment analysis in microblogs. arXiv preprint arXiv:1103.2903.</title>
<date>2011</date>
<contexts>
<context position="3310" citStr="Nielsen, 2011" startWordPosition="494" endWordPosition="495">vide an indication of gender-specificity of individual words, with extreme values assigned to highly stereotypical concepts. Generating this rating for male and female character dialogues and comparing the character gender with this rating of “language gender” should allow us to observe stereotypical behavior. Word based ratings such as the gender ladenness are referred to as linguistic norms (or psycholinguistic norms when corresponding to psychological constructs) and are popular in cognitive psychology (Clark and Paivio, 2004) and some computational disciplines, such as sentiment analysis (Nielsen, 2011) and opinion mining. To utilize gender ladenness, we follow an approach similar to simple sentiment analysis, with word-level norms automatically generated based on a small starting set of manually annotated norms and sentence (and higher) level norms estimated through word-level norm statistics. The resulting algorithm allows us to estimate gender ladenness at any arbitrary granularity. We use these ratings of dialogue language to quantify the depictions of male and female characters and attempt to relate the observed gender ladenness with objective factors. In section 2 and 3 we describe the</context>
</contexts>
<marker>Nielsen, 2011</marker>
<rawString>Finn ˚Arup Nielsen. 2011. Anew ANEW: Evaluation of a word list for sentiment analysis in microblogs. arXiv preprint arXiv:1103.2903.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Niven</author>
</authors>
<title>Throwing your hat out of the ring: Negative recruitment and the gender imbalance in state legislative candidacy.</title>
<date>2006</date>
<journal>Politics &amp; Gender,</journal>
<volume>2</volume>
<issue>04</issue>
<contexts>
<context position="1539" citStr="Niven, 2006" startWordPosition="210" endWordPosition="211">teresting interactions with movie genres and the screenplay writer gender. 1 Introduction Gender has been an important research topic in the social sciences, with studies conducted on the effect of gender on various aspects of human perception and expression (Benshoff and Griffin, 2011) as well as investigations of the societal (BehmMorawitz and Mastro, 2008) and career implications of gender and possible underlying biases. Previous studies report significant implications of gender on career progress in medicine (Sidhu et al., 2009), information technology (Cohoon and Aspray, 2006), politics (Niven, 2006) and showbusiness (Smith, 2010). In this paper we investigate the depictions of the genders in feature films, through the analysis of their respective dialogues. The differences in depiction are a contentious subject, since aspects of these can be viewed as the result of stereotyping or gender bias, with the relative presence of women being a well investigated subject (Bielby and Bielby, 1996; Lincoln and Allen, 2004). We are interested in the existing gender depictions, regardless of relative frequencies, as well as any factors that may affect them. While popular tools such as the Bechdel tes</context>
</contexts>
<marker>Niven, 2006</marker>
<rawString>David Niven. 2006. Throwing your hat out of the ring: Negative recruitment and the gender imbalance in state legislative candidacy. Politics &amp; Gender, 2(04):473–489.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allan Paivio</author>
<author>John C Yuille</author>
<author>Stephen A Madigan</author>
</authors>
<title>Concreteness, imagery, and meaningfulness values for 925 nouns.</title>
<date>1968</date>
<journal>Journal of experimental psychology,</journal>
<pages>76--1</pages>
<contexts>
<context position="2632" citStr="Paivio et al., 1968" startWordPosition="388" endWordPosition="391">s, regardless of relative frequencies, as well as any factors that may affect them. While popular tools such as the Bechdel test provide a test for detecting female presence in the movies, we hope to identify more subtle forms of gender differences across character gender from the dialogues. Our aim is to devise a non-binary metric that can be used to compare or rank movies, characters and perhaps individual utterances. To analyze the dialogues we propose using a metric of language gender ladenness, a number representing a normative rating of the “perceived feminine or masculine association” (Paivio et al., 1968) of language. The metric, as originally defined, is meant to provide an indication of gender-specificity of individual words, with extreme values assigned to highly stereotypical concepts. Generating this rating for male and female character dialogues and comparing the character gender with this rating of “language gender” should allow us to observe stereotypical behavior. Word based ratings such as the gender ladenness are referred to as linguistic norms (or psycholinguistic norms when corresponding to psychological constructs) and are popular in cognitive psychology (Clark and Paivio, 2004) </context>
<context position="12833" citStr="Paivio et al., 1968" startWordPosition="2054" endWordPosition="2057"> transformed similarities became the similarity terms s() of equation (1) and were used to train the model. For any word in the scripts, a 10000 place similarity vector is generated and transformed using the pre-calculated PCA matrix, then equation (1) is used to create the gender ladenness estimate. Ratings were generated at the utterance level, and collective ratings (per character, gender or movie) were calculated as utterance rating averages. 5 Results To evaluate the word norm generation algorithm, we performed a 10-fold cross-validation experiment on the 925 manually annotated norms in (Paivio et al., 1968). The generated norms were evaluated against the ground truth and the method achieved a 0.801 Pearson correlation to the ground truth. While there is no comparable result in literature, the resulting performance appears sufficiently high. We first investigated the overall gender ladenness of movies, represented as the average of all utterance level scores, with respect to the genre(s) the movie belongs to. The independent variables for this analysis were nine binary indicator variables, one for each of the most frequent genre labels in our movie corpus, with values of zero if the movie does no</context>
</contexts>
<marker>Paivio, Yuille, Madigan, 1968</marker>
<rawString>Allan Paivio, John C Yuille, and Stephen A Madigan. 1968. Concreteness, imagery, and meaningfulness values for 925 nouns. Journal of experimental psychology, 76(1p2):1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reena Sidhu</author>
<author>Praveen Rajashekhar</author>
<author>Victoria L Lavin</author>
<author>Joanne Parry</author>
<author>James Attwood</author>
<author>Anita Holdcroft</author>
<author>David S Sanders</author>
</authors>
<title>The gender imbalance in academic medicine: a study of female authorship in the united kingdom.</title>
<date>2009</date>
<journal>Journal of the Royal Society of Medicine,</journal>
<volume>102</volume>
<issue>8</issue>
<contexts>
<context position="1465" citStr="Sidhu et al., 2009" startWordPosition="199" endWordPosition="202">sed metric differentiates between male and female utterances and exhibits some interesting interactions with movie genres and the screenplay writer gender. 1 Introduction Gender has been an important research topic in the social sciences, with studies conducted on the effect of gender on various aspects of human perception and expression (Benshoff and Griffin, 2011) as well as investigations of the societal (BehmMorawitz and Mastro, 2008) and career implications of gender and possible underlying biases. Previous studies report significant implications of gender on career progress in medicine (Sidhu et al., 2009), information technology (Cohoon and Aspray, 2006), politics (Niven, 2006) and showbusiness (Smith, 2010). In this paper we investigate the depictions of the genders in feature films, through the analysis of their respective dialogues. The differences in depiction are a contentious subject, since aspects of these can be viewed as the result of stereotyping or gender bias, with the relative presence of women being a well investigated subject (Bielby and Bielby, 1996; Lincoln and Allen, 2004). We are interested in the existing gender depictions, regardless of relative frequencies, as well as any</context>
</contexts>
<marker>Sidhu, Rajashekhar, Lavin, Parry, Attwood, Holdcroft, Sanders, 2009</marker>
<rawString>Reena Sidhu, Praveen Rajashekhar, Victoria L Lavin, Joanne Parry, James Attwood, Anita Holdcroft, and David S Sanders. 2009. The gender imbalance in academic medicine: a study of female authorship in the united kingdom. Journal of the Royal Society of Medicine, 102(8):337–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stacy L Smith</author>
</authors>
<title>Gender oppression in cinematic content? a look at females on-screen &amp; behindthe-camera in top-grossing</title>
<date>2010</date>
<contexts>
<context position="1570" citStr="Smith, 2010" startWordPosition="215" endWordPosition="216">ie genres and the screenplay writer gender. 1 Introduction Gender has been an important research topic in the social sciences, with studies conducted on the effect of gender on various aspects of human perception and expression (Benshoff and Griffin, 2011) as well as investigations of the societal (BehmMorawitz and Mastro, 2008) and career implications of gender and possible underlying biases. Previous studies report significant implications of gender on career progress in medicine (Sidhu et al., 2009), information technology (Cohoon and Aspray, 2006), politics (Niven, 2006) and showbusiness (Smith, 2010). In this paper we investigate the depictions of the genders in feature films, through the analysis of their respective dialogues. The differences in depiction are a contentious subject, since aspects of these can be viewed as the result of stereotyping or gender bias, with the relative presence of women being a well investigated subject (Bielby and Bielby, 1996; Lincoln and Allen, 2004). We are interested in the existing gender depictions, regardless of relative frequencies, as well as any factors that may affect them. While popular tools such as the Bechdel test provide a test for detecting </context>
</contexts>
<marker>Smith, 2010</marker>
<rawString>Stacy L Smith. 2010. Gender oppression in cinematic content? a look at females on-screen &amp; behindthe-camera in top-grossing 2007 films. Retrieved September, 2:2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William E Winkler</author>
</authors>
<title>String comparator metrics and enhanced decision rules in the fellegi-sunter model of record linkage.</title>
<date>1990</date>
<contexts>
<context position="8256" citStr="Winkler, 1990" startWordPosition="1296" endWordPosition="1298">e process was complicated by inconsistencies between the information contained in the IMDb and Movie DiC corpora, like mismatched names, particularly for minor characters. Initially the script character names were cleaned using simple heuristics, such as the removal of all instances of the possessive “’s”. The IMDb api (IMDbPY, 2015) was used to recover candidate movies matching the script movie name and, in the case of multiple candidates, the best candidate was selected based on the number of character names matching the script. Character names were compared using the Jaro-Winkler distance (Winkler, 1990). Having achieved a one to one mapping between IMDb and Movie DiC, we assigned a gender label to each matched character, using the gender predictor (NamSor Applied Onomastics, 2015). To make these predictions, we first use the name of the corresponding actor portraying that role; if there was no character match, we use the name of the character. Finally, we calculate a confidence score of our gender assignment per utterance for each movie, equal to the percentage of utterances with perfectly matched character name and a high confidence by the gender predictor. For the movies for which the conf</context>
</contexts>
<marker>Winkler, 1990</marker>
<rawString>William E Winkler. 1990. String comparator metrics and enhanced decision rules in the fellegi-sunter model of record linkage.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>