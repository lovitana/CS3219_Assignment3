<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.96962">
Confounds and Consequences in Geotagged Twitter Data
</title>
<author confidence="0.995332">
Umashanthi Pavalanathan and Jacob Eisenstein
</author>
<affiliation confidence="0.9986465">
School of Interactive Computing
Georgia Institute of Technology
</affiliation>
<address confidence="0.983881">
Atlanta, GA 30308
</address>
<email confidence="0.998021">
{umashanthi + jacobe}@gatech.edu
</email>
<sectionHeader confidence="0.993817" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998347826087">
Twitter is often used in quantitative stud-
ies that identify geographically-preferred
topics, writing styles, and entities. These
studies rely on either GPS coordinates at-
tached to individual messages, or on the
user-supplied location field in each profile.
In this paper, we compare these data ac-
quisition techniques and quantify the bi-
ases that they introduce; we also measure
their effects on linguistic analysis and text-
based geolocation. GPS-tagging and self-
reported locations yield measurably dif-
ferent corpora, and these linguistic differ-
ences are partially attributable to differ-
ences in dataset composition by age and
gender. Using a latent variable model
to induce age and gender, we show how
these demographic variables interact with
geography to affect language use. We
also show that the accuracy of text-based
geolocation varies with population demo-
graphics, giving the best results for men
above the age of 40.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998025441860465">
Social media data such as Twitter is frequently
used to identify the unique characteristics of
geographical regions, including topics of inter-
est (Hong et al., 2012), linguistic styles and di-
alects (Eisenstein et al., 2010; Gonc¸alves and
S´anchez, 2014), political opinions (Caldarelli et
al., 2014), and public health (Broniatowski et al.,
2013). Social media permits the aggregation of
datasets that are orders of magnitude larger than
could be assembled via traditional survey tech-
niques, enabling analysis that is simultaneously
fine-grained and global in scale. Yet social media
is not a representative sample of any “real world”
population, aside from social media itself. Using
social media as a sample therefore risks introduc-
ing both geographic and demographic biases (Mis-
love et al., 2011; Hecht and Stephens, 2014; Lon-
gley et al., 2015; Malik et al., 2015).
This paper examines the effects of these bi-
ases on the geo-linguistic inferences that can be
drawn from Twitter. We focus on the ten largest
metropolitan areas in the United States, and con-
sider three sampling techniques: drawing an equal
number of GPS-tagged tweets from each area;
drawing a county-balanced sample of GPS-tagged
messages to correct Twitter’s urban skew (Hecht
and Stephens, 2014); and drawing a sample of
location-annotated messages, using the location
field in the user profile. Leveraging self-reported
first names and census statistics, we show that the
age and gender composition of these datasets dif-
fer significantly.
Next, we apply standard methods from the lit-
erature to identify geo-linguistic differences, and
test how the outcomes of these methods depend
on the sampling technique and on the underlying
demographics. We also test the accuracy of text-
based geolocation (Cheng et al., 2010; Eisenstein
et al., 2010) in each dataset, to determine whether
the accuracies reported in recent work will gener-
alize to more balanced samples.
The paper reports several new findings about
geotagged Twitter data:
</bodyText>
<listItem confidence="0.888323272727273">
• In comparison with tweets with self-reported
locations, GPS-tagged tweets are written
more often by young people and by women.
• There are corresponding linguistic dif-
ferences between these datasets, with
GPS-tagged tweets including more
geographically-specific non-standard words.
• Young people use significantly more
geographically-specific non-standard words.
Men tend to mention more geographically-
specific entities than women, but these
</listItem>
<page confidence="0.952513">
2138
</page>
<note confidence="0.9909985">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2138–2148,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.528442">
differences are significant only for individu-
als at the age of 30 or older.
• Users who GPS-tag their tweets tend to write
more, making them easier to geolocate. Eval-
uating text-based geolocation on GPS-tagged
tweets probably overestimates its accuracy.
</bodyText>
<listItem confidence="0.9705415">
• Text-based geolocation is significantly more
accurate for men and for older people.
</listItem>
<bodyText confidence="0.999851916666667">
These findings should inform future attempts to
generalize from geotagged Twitter data, and may
suggest investigations into the demographic prop-
erties of other social media sites.
We first describe the basic data collection prin-
ciples that hold throughout the paper (§ 2). The
following three sections tackle demographic bi-
ases (§ 3), their linguistic consequences (§ 4), and
the impact on text-based geolocation (§ 5); each
of these sections begins with a discussion of meth-
ods, and then presents results. We then summarize
related work and conclude.
</bodyText>
<sectionHeader confidence="0.995659" genericHeader="introduction">
2 Dataset
</sectionHeader>
<bodyText confidence="0.997793942857143">
This study is performed on a dataset of tweets
gathered from Twitter’s streaming API from
February 2014 to January 2015. During an ini-
tial filtering step we removed retweets, repetitions
of previously posted messages which contain the
“retweeted status” metadata or “RT” token which
is widely used among Twitter users to indicate a
retweet. To eliminate spam and automated ac-
counts (Yardi et al., 2009), we removed tweets
containing URLs, user accounts with more than
1000 followers or followees, accounts which have
tweeted more than 5000 messages at the time of
data collection, and the top 10% of accounts based
on number of messages in our dataset. We also re-
moved users who have written more than 10% of
their tweets in any language other than English,
using Twitter’s lang metadata field. Exploration
of code-switching (Solorio and Liu, 2008) and the
role of second-language English speakers (Eleta
and Golbeck, 2014) is left for future work.
We consider the ten largest Metropolitan Sta-
tistical Areas (MSAs) in the United States, listed
in Table 1. MSAs are defined by the U.S. Cen-
sus Bureau as geographical regions of high popu-
lation with density organized around a single ur-
ban core; they are not legal administrative divi-
sions. MSAs include outlying areas that may be
substantially less urban than the core itself. For
example, the Atlanta MSA is centered on Fulton
County (1750 people per square mile), but extends
to Haralson County (100 people per square mile),
on the border of Alabama. A per-county analysis
of this data therefore enables us to assess the de-
gree to which Twitter’s skew towards urban areas
biases geo-linguistic analysis.
</bodyText>
<sectionHeader confidence="0.612874" genericHeader="method">
3 Representativeness of geotagged
</sectionHeader>
<subsectionHeader confidence="0.86923">
Twitter data
</subsectionHeader>
<bodyText confidence="0.999903142857143">
We first assess potential biases in sampling tech-
niques for obtaining geotagged Twitter data. In
particular, we compare two possible techniques
for obtaining data: the location field in the user
profile (Poblete et al., 2011; Dredze et al., 2013),
and the GPS coordinates attached to each mes-
sage (Cheng et al., 2010; Eisenstein et al., 2010).
</bodyText>
<subsectionHeader confidence="0.992667">
3.1 Methods
</subsectionHeader>
<bodyText confidence="0.999935724137931">
To build a dataset of GPS-tagged messages, we
extracted the GPS latitude and longitude coordi-
nates reported in the tweet, and used GIS-TOOLS1
reverse geocoding to identify the corresponding
counties. This set of geotagged messages will be
denoted DG. Only 1.24% of messages contain
geo-coordinates, and it is possible that the individ-
uals willing to share their GPS comprise a skewed
population. We therefore also considered the user-
reported location field in the Twitter profile, focus-
ing on the two most widely-used patterns: (1) city
name, (2) city name and two letter state name (e.g.
Chicago and Chicago, IL). Messages that matched
any of the ten largest MSAs were grouped into a
second set, DL.
While the inconsistencies of writing style in
the Twitter location field are well-known (Hecht
et al., 2011), analysis of the intersection between
DG and DL found that the two data sources agreed
the overwhelming majority of the time, suggest-
ing that most self-provided locations are accurate.
Of course, there may be many false negatives —
profiles that we fail to geolocate due to the use of
non-standard toponyms like Pixburgh and ATL. If
so, this would introduce a bias in the population
sample in DL. Such a bias might have linguistic
consequences, with datasets based on the location
field containing less non-standard language over-
all.
</bodyText>
<footnote confidence="0.999293666666667">
1https://github.com/DrSkippy/
Data-Science-45min-Intros/blob/master/
gis-tools-101/gis_tools.ipynb
</footnote>
<page confidence="0.998084">
2139
</page>
<figure confidence="0.999918549019608">
Population
Tweets
Users
Population
Tweets
Users
% of MSA 0.25
0.20
0.15
0.10
0.05
0.00
% of MSA 0.25
0.20
0.15
0.10
0.05
0.00
Fulton
Gwinnett
Other
Cobb
DeKalb
Clayton
Cherokee
Henry
Forsyth
Paulding
Douglas
Coweta
Carroll
Kings
Queens
New York
Suffolk
Bronx
Nassau
Westchester
Bergen
Middlesex
Essex
Hudson
Monmouth
Ocean
Union
Passaic
Morris
Richmond
Other
Somerset
Rockland
</figure>
<figureCaption confidence="0.998116">
Figure 1: Proportion of census population, Twitter messages, and Twitter user accounts, by county. New
York is shown on the left, Atlanta on the right.
</figureCaption>
<subsectionHeader confidence="0.947154">
3.1.1 Subsampling
</subsectionHeader>
<bodyText confidence="0.992039">
The initial samples DG and DL were then resam-
pled to create the following balanced datasets:
GPS-MSA-BALANCED From DG, we randomly
sampled 25,000 tweets per MSA as the
message-balanced sample, and all the tweets
from 2,500 users per MSA as the user-
balanced sample. Balancing across MSAs
ensures that the largest MSAs do not domi-
nate the linguistic analysis.
</bodyText>
<sectionHeader confidence="0.454752" genericHeader="method">
GPS-COUNTY-BALANCED We resampled
</sectionHeader>
<bodyText confidence="0.984875692307692">
DG based on county-level population (ob-
tained from the U.S. Census Bureau), and
again obtained message-balanced and user-
balanced samples. These samples are more
geographically representative of the overall
population distribution across each MSA.
LOC-MSA-BALANCED From DL, we randomly
sampled 25,000 tweets per MSA as the
message-balanced sample, and all the tweets
from 2,500 users per MSA as the user-
balanced sample. It is not possible to obtain
county-level geolocations in DL, as exact ge-
ographical coordinates are unavailable.
</bodyText>
<subsectionHeader confidence="0.966529">
3.1.2 Age and gender identification
</subsectionHeader>
<bodyText confidence="0.99988652">
To estimate the distribution of ages and genders
in each sample, we queried statistics from the So-
cial Security Administration, which records the
number of individuals born each year with each
given name. Using this information, we obtained
the probability distribution of age values for each
given name. We then matched the names against
the first token in the name field of each user’s
profile, enabling us to induce approximate distri-
butions over ages and genders. Unlike Facebook
and Google+, Twitter does not have a “real name”
policy, so users are free to give names that are
fake, humorous, etc. We eliminate user accounts
whose names are not sufficiently common in the
social security database (i.e. first names which
are at least 100 times more frequent in Twitter
than in the social security database), thereby omit-
ting 33% of user accounts, and 34% of tweets.
While some individuals will choose names not
typically associated with their gender, we assume
that this will happen with roughly equal probabil-
ity in both directions. So, with these caveats in
mind, we induce the age distribution for the GPS-
MSA-BALANCED sample and the LOC-MSA-
BALANCED sample as,
</bodyText>
<equation confidence="0.99016875">
= count(name = n, age = a) (1)
p(a  |name = n) Lia, count(name = n, age = a&apos;)
�pD(a) ∝ p(a  |name = ni). (2)
iED
</equation>
<bodyText confidence="0.999991416666667">
We induce distributions over author gender in
much the same way (Mislove et al., 2011). This
method does not incorporate prior information
about the ages of Twitter users, and thus assigns
too much probability to the extremely young and
old, who are unlikely to use the service. While it
would be easy to design such a prior — for exam-
ple, assigning zero prior probability to users under
the age of five or above the age of 95 — we see
no principled basis for determining these cutoffs.
We therefore focus on the differences between the
estimated pD(a) for each sample D.
</bodyText>
<page confidence="0.966204">
2140
</page>
<table confidence="0.999893923076923">
MSA Num. L1 Dist. L1 Dist.
Counties Population Population
vs. Users vs. Tweets
New York 23 0.2891 0.2825
Los Angeles 2 0.0203 0.0223
Chicago 14 0.0482 0.0535
Dallas 12 0.1437 0.1176
Houston 10 0.0394 0.0472
Philadelphia 11 0.1426 0.1202
Washington DC 22 0.2089 0.2750
Miami 3 0.0428 0.0362
Atlanta 28 0.1448 0.1730
Boston 7 0.1878 0.2303
</table>
<tableCaption confidence="0.9848105">
Table 1: L1 distance between county-level popu-
lation and Twitter users and messages
</tableCaption>
<subsectionHeader confidence="0.852644">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999746388888889">
Geographical biases in the GPS Sample We
first assess the differences between the true pop-
ulation distributions over counties, and the per-
tweet and per-user distributions. Because coun-
ties vary widely in their degree of urbanization
and other demographic characteristics, this mea-
sure is a proxy for the representativeness of GPS-
based Twitter samples (county information is not
available for the LOC-MSA-BALANCED sample).
Population distributions for New York and Atlanta
are shown in Figure 1. In Atlanta, Fulton County
is the most populous and most urban, and is over-
represented in both geotagged tweets and user ac-
counts; most of the remaining counties are corre-
spondingly underrepresented. This coheres with
the urban bias noted earlier by Hecht and Stephens
(2014). In New York, Kings County (Brooklyn)
is the most populous, but is underrepresented in
both the number of geotagged tweets and user ac-
counts, at the expense of New York County (Man-
hattan). Manhattan is the commercial and enter-
tainment center of the New York MSA, so resi-
dents of outlying counties may be tweeting from
their jobs or social activities.
To quantify the representativeness of each sam-
ple, we use the L1 distance ||x − y||1 = &amp; |p, −
t,|, where p, is the proportion of the MSA pop-
ulation residing in county c and t, is the propor-
tion of tweets (Table 1). County boundaries are
determined by states, and their density varies: for
example, the Los Angeles MSA covers only two
counties, while the smaller Atlanta MSA is spread
over 28 counties. The table shows that while New
York is the most extreme example, most MSAs
feature an asymmetry between county population
and Twitter adoption.
</bodyText>
<figureCaption confidence="0.5405715">
Figure 2: User counts by number of Twitter mes-
sages
</figureCaption>
<bodyText confidence="0.999947405405405">
Usage Next, we turn to differences between the
GPS-based and profile-based techniques for ob-
taining ground truth data. As shown in Fig-
ure 2, the LOC-MSA-BALANCED sample con-
tains more low-volume users than either the GPS-
MSA-BALANCED or GPS-COUNTY-BALANCED
samples. We can therefore conclude that the
county-level geographical bias in the GPS-based
data does not impact usage rate, but that the differ-
ence between GPS-based and profile-based sam-
pling does; the linguistic consequences of this dif-
ference will be explored in the following sections.
Demographics Table 2 shows the expected age
and gender for each dataset, with bootstrap con-
fidence intervals. Users in the LOC-MSA-
BALANCED dataset are on average two years older
than in the GPS-MSA-BALANCED and GPS-
COUNTY-BALANCED datasets, which are statis-
tically indistinguishable. Focusing on the differ-
ence between GPS-MSA-BALANCED and LOC-
MSA-BALANCED, we plot the difference in age
probabilities in Figure 3, showing that GPS-
MSA-BALANCED includes many more teens and
people in their early twenties, while LOC-MSA-
BALANCED includes more people at middle age
and older. Young people are especially likely to
use social media on cellphones (Lenhart, 2015),
where location tagging would be more relevant
than when Twitter is accessed via a personal com-
puter. Social media users in the age brackets 18-
29 and 30-49 are also more likely to tag their lo-
cations in social media posts than social media
users in the age brackets 50-64 and 65+ (Zickuhr,
2013), with women and men tagging at roughly
equal rates. Table 2 shows that the GPS-MSA-
BALANCED and GPS-COUNTY-BALANCED sam-
ples contain significantly more women than LOC-
</bodyText>
<figure confidence="0.9947817">
1e4 Number of users in each category
0-2 2-5 5-10 10-15 &gt;15
Number of messages by a user
Number of users 1.5
1.0
0.5
0.0
GPS-MSA-Balanced
GPS-County-Balanced
LOC-MSA-Balanced
</figure>
<page confidence="0.879769">
2141
</page>
<table confidence="0.8712265">
Sample Expected Age 95% CI % Female 95% CI
GPS-MSA-BALANCED 36.17 [36.07 – 36.27] 51.5 [51.3 – 51.8]
GPS-COUNTY-BALANCED 36.25 [36.16 – 36.30] 51.3 [51.1 – 51.6]
LOC-MSA-BALANCED 38.35 [38.25 – 38.44] 49.3 [49.1 – 49.6]
</table>
<tableCaption confidence="0.890504">
Table 2: Demographic statistics for each dataset
</tableCaption>
<figure confidence="0.993597">
−0.5
−1.0
</figure>
<figureCaption confidence="0.964873">
Figure 3: Difference in age probability distribu-
tions between GPS-MSA-BALANCED and LOC-
MSA-BALANCED.
</figureCaption>
<bodyText confidence="0.798933">
MSA-BALANCED, though all three samples are
close to 50%.
</bodyText>
<sectionHeader confidence="0.973549" genericHeader="method">
4 Impact on linguistic generalizations
</sectionHeader>
<bodyText confidence="0.999858933333333">
Many papers use Twitter data to draw conclusions
about the relationship between language and ge-
ography. What role do the demographic differ-
ences identified in the previous section have on
the linguistic conclusions that emerge? We mea-
sure the differences between the linguistic corpora
obtained by each data acquisition approach. Since
the GPS-MSA-BALANCED and GPS-COUNTY-
BALANCED methods have nearly identical pat-
terns of usage and demographics, we focus on the
difference between GPS-MSA-BALANCED and
LOC-MSA-BALANCED. These datasets differ in
age and gender, so we also directly measure the
impact of these demographic factors on the use of
geographically-specific linguistic variables.
</bodyText>
<subsectionHeader confidence="0.927187">
4.1 Methods
</subsectionHeader>
<bodyText confidence="0.985261444444445">
Discovering geographical linguistic variables
We focus on lexical variation, which is relatively
easy to identify in text corpora. Monroe et al.
(2008) survey a range of alternative statistics for
finding lexical variables, demonstrating that a reg-
ularized log-odds ratio strikes a good balance be-
tween distinctiveness and robustness. A similar
approach is implemented in SAGE (Eisenstein et
al., 2011a)2, which we use here. For each sam-
</bodyText>
<footnote confidence="0.509138">
2https://github.com/jacobeisenstein/jos-gender-2014
</footnote>
<bodyText confidence="0.992582564102564">
ple — GPS-MSA-BALANCED and LOC-MSA-
BALANCED — we apply SAGE to identify the
twenty-five most salient lexical items for each
metropolitan area.
Keyword annotation Previous research has
identified two main types of geographical lexi-
cal variables. The first are non-standard words
and spellings, such as hella and yinz, which have
been found to be very frequent in social me-
dia (Eisenstein, 2015). Other researchers have fo-
cused on the “long tail” of entity names (Roller
et al., 2012). A key question is the relative im-
portance of these two variable types, since this
would decide whether geo-linguistic differences
are primarily topic-based or stylistic. It is there-
fore important to know whether the frequency
of these two variable types depends on proper-
ties of the sample. To test this, we take the
lexical items identified by SAGE (25 per MSA,
for both the GPS-MSA-BALANCED and LOC-
MSA-BALANCED samples), and annotate them
as NONSTANDARD-WORD, ENTITY-NAME, or
OTHER. Annotation for ambiguous cases is based
on the majority sense in randomly-selected exam-
ples. Overall, we identify 24 NONSTANDARD-
WORDs and 185 ENTITY-NAMEs.
Inferring author demographics As described
in § 3.1.2, we can obtain an approximate distri-
bution over author age and gender by linking self-
reported first names with aggregate statistics from
the United States Census. To sharpen these esti-
mates, we now consider the text as well, build-
ing a simple latent variable model in which both
the name and the word counts are drawn from dis-
tributions associated with the latent age and gen-
der (Chang et al., 2010). The model is shown in
Figure 4, and involves the following generative
process:
For each user i E {1...N},
</bodyText>
<figure confidence="0.845982588235294">
(a) draw the age, ai — Categorical(π)
(b) draw the gender, gi — Categorical(0.5)
2.51e−3
2.0
1.5
1.0
0.5
0.0
1.50 20 40 60 80 100
Age
2142
7r
ai 9i
wi ni
N
e 0
2B
</figure>
<table confidence="0.9638322">
ai Age (bin) for author i
gi Gender of author i
wi Word counts for author i
ni First name of author i
it Prior distribution over
age bins
θa,g Word distribution for
age a and gender g
φa,g First name distribution
for age a and gender g
</table>
<figureCaption confidence="0.977603">
Figure 4: Plate diagram for latent variable model
of age and gender
</figureCaption>
<listItem confidence="0.83690075">
(c) draw the author’s given name, ni -
Categorical(φai,gi)
(d) draw the word counts, wi -
Multinomial(Bai,gi),
</listItem>
<bodyText confidence="0.999968214285714">
where we elide the second parameter of the multi-
nomial distribution, the total word count. We use
expectation-maximization to perform inference in
this model, binning the latent age variable into
four groups: 0-17, 18-29, 30-39, above 40.3 Be-
cause the distribution of names given demograph-
ics is available from the Social Security data, we
clamp the value of φ throughout the EM proce-
dure. Other work in the domain of demographic
prediction often involves more complex meth-
ods (Nguyen et al., 2014; Volkova and Durme,
2015), but since it is not the focus of our research,
we take a relatively simple approach here, assum-
ing no labeled data for demographic attributes.
</bodyText>
<sectionHeader confidence="0.778984" genericHeader="method">
4.2 Results
</sectionHeader>
<bodyText confidence="0.9799934">
Linguistic differences by dataset We first con-
sider the impact of the data acquisition tech-
nique on the lexical features associated with each
city. The keywords identified in GPS-MSA-
BALANCED dataset feature more geographically-
specific non-standard words, which occur at a rate
of 3.9 x 10−4 in GPS-MSA-BALANCED, versus
2.6 x 10−4 in LOC-MSA-BALANCED; this differ-
ence is statistically significant (p &lt; .05, t = 3.2).4
3Binning is often employed in work on text-based age pre-
diction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosen-
thal and McKeown, 2011); it enables word and name counts
to be shared over multiple ages, and avoids the complexity
inherent in regressing a high-dimensional textual predictors
against a numerical variable.
4We employ a paired t-test, comparing the difference in
frequency for each word across the two datasets. Since we
cannot test the complete set of entity names or non-standard
words, this quantifies whether the observed difference is ro-
bust across the subset of the vocabulary that we have selected.
</bodyText>
<figure confidence="0.9995455">
(a) non-standard words
(b) entity names
</figure>
<figureCaption confidence="0.94182825">
Figure 5: Aggregate statistics for geographically-
specific non-standard words and entity names
across imputed demographic groups, from the
GPS-MSA-BALANCED sample.
</figureCaption>
<bodyText confidence="0.999427607142857">
For entity names, the difference between datasets
was not significant, with a rate of 4.0 x 10−3 for
GPS-MSA-BALANCED, and 3.7x10−3 for LOC-
MSA-BALANCED. Note that these rates include
only the non-standard words and entity names de-
tected by SAGE as among the top 25 most distinc-
tive for one of the ten largest cities in the US; of
course there are many other relevant terms that are
below this threshold.
In a pilot study of the GPS-COUNTY-
BALANCED data, we found few linguistic differ-
ences from GPS-MSA-BALANCED, in either the
aggregate word-group frequencies or the SAGE
word lists — despite the geographical imbalances
shown in Table 1 and Figure 1. Informal ex-
amination of specific counties shows some ex-
pected differences: for example, Clayton County,
which hosts Atlanta’s Hartsfield-Jackson airport,
includes terms related to air travel, and other coun-
ties include mentions of local cities and business
districts. But the aggregate statistics for under-
represented counties are not substantially different
from those of overrepresented counties, and are
largely unaffected by county-based resampling.
Demographics Aggregate linguistic statistics
for demographic groups are shown in Fig-
ure 5. Men use significantly more geographically-
specific entity names than women (p « .01, t =
</bodyText>
<figure confidence="0.923655754716981">
1e 4
Male
Female
0.00009
0.00004
0.00002 0.000010.00002
0-17 18-29 30-39 40+
Age group
0.00015
0.00005
0.00002
1.6
Per-word frequency
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0
1e 3
Male
Female
0.00075
0.00050
0.00034
0.00021
0-17 18-29 30-39 40+
Age group
0.00027
0.00037
0.00038
0.00117
Per-word frequency
1.2
1.0
0.8
0.6
0.4
0.2
0.0
2143
Age Sex New York Dallas
0-17 F niall, ilysm, hemmings, stalk, ily fanuary, idol, lmbo, lowkey, jonas
M ight, technique, kisses, lesbian, dicks homies, daniels, oomf, teenager, brah
18-29 F roses, castle, hmmmm, chem, sinking socially, coma, hubby, bra, swimming
M drunken, manhattan, spoiler, guardians, gonna harden, watt, astros, rockets, mavs
30-39 F suite, nyc, colleagues, york, portugal astros, sophia, recommendations, houston, prepping
M mets, effectively, cruz, founder, knicks texans, rockets, embarrassment, tcu, mississippi
F cultural, affected, encouraged, proverb, un- determine, islam, rejoice, psalm, responsibility
40+ happy
M reuters, investors, shares, lawsuit, theaters mph, wazers, houston, tx, harris
</figure>
<tableCaption confidence="0.897661">
Table 3: Most characteristic words for demographic subsets of each city, as compared with the overall
average word distribution
</tableCaption>
<bodyText confidence="0.98839225">
8.0), but gender differences for geographically-
specific non-standard words are not significant
(p ≈ .2).5 Younger people use significantly
more geographically-specific non-standard words
than older people (ages 0–29 versus 30+, p �
.01, t = 7.8), and older people mention signifi-
cantly more geographically-specific entity names
(p « .01, t = 5.1). Of particular interest
is the intersection of age and gender: the use
of geographically-specific non-standard words de-
creases with age much more profoundly for men
than for women; conversely, the frequency of
mentioning geographically-specific entity names
increases dramatically with age for men, but to a
much lesser extent for women. The observation
that high-level patterns of geographically-oriented
language are more age-dependent for men than
for women suggests an intriguing site for future
research on the intersectional construction of lin-
guistic identity.
For a more detailed view, we apply SAGE to
identify the most salient lexical items for each
MSA, subgrouped by age and gender. Table 3
shows word lists for New York (the largest MSA)
and Dallas (the 5th-largest MSA), using the GPS-
MSA-BALANCED sample. Non-standard words
tend to be used by the youngest authors: ilysm (’I
love you so much’), ight (’alright’), oomf (’one of
my followers’). Older authors write more about
local entities (manhattan, nyc, houston), with
men focusing on sports-related entities (harden,
watt, astros, mets, texans), and women above the
age of 40 emphasizing religiously-oriented terms
(proverb, islam, rejoice, psalm).
5But see Bamman et al. (2014) for a much more detailed
discussion of gender and standardness.
</bodyText>
<sectionHeader confidence="0.96726" genericHeader="method">
5 Impact on text-based geolocation
</sectionHeader>
<bodyText confidence="0.999946269230769">
A major application of geotagged social media
is to predict the geolocation of individuals based
on their text (Eisenstein et al., 2010; Cheng et
al., 2010; Wing and Baldridge, 2011; Hong et
al., 2012; Han et al., 2014). Text-based geolo-
cation has obvious commercial implications for
location-based marketing and opinion analysis; it
is also potentially useful for researchers who want
to measure geographical phenomena in social me-
dia, and wish to access a larger set of individuals
than those who provide their locations explicitly.
Previous research has obtained impressive ac-
curacies for text-based geolocation: for exam-
ple, Hong et al. (2012) report a median error of
120 km, which is roughly the distance from Los
Angeles to San Diego, in a prediction space over
the entire continental United States. These accura-
cies are computed on test sets that were acquired
through the same procedures as the training data,
so if the acquisition procedures have geographic
and demographic biases, then the resulting accu-
racy estimates will be biased too. Consequently,
they may be overly optimistic (or pessimistic!) for
some types of authors. In this section, we explore
where these text-based geolocation methods are
most and least accurate.
</bodyText>
<subsectionHeader confidence="0.984748">
5.1 Methods
</subsectionHeader>
<bodyText confidence="0.9992975">
Our data is drawn from the ten largest metropoli-
tan areas in the United States, and we formulate
text-based geolocation as a ten-way classification
problem, similar to Han et al. (2014).6 Using our
</bodyText>
<footnote confidence="0.981354666666667">
6Many previous papers have attempted to identify the pre-
cise latitude and longitude coordinates of individual authors,
but obtaining high accuracy on this task involves much more
complex methods, such as latent variable models (Eisenstein
et al., 2010; Hong et al., 2012), or multilevel grid struc-
tures (Cheng et al., 2010; Roller et al., 2012). Tuning such
</footnote>
<page confidence="0.996711">
2144
</page>
<bodyText confidence="0.99946375">
user-balanced samples, we apply ten-fold cross
validation, and tune the regularization parameter
on a development fold, using the vocabulary of the
sample as features.
</bodyText>
<subsectionHeader confidence="0.927543">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999803146341464">
Many author-attribute prediction tasks become
substantially easier as more data is avail-
able (Burger et al., 2011), and text-based ge-
olocation is no exception. Since GPS-MSA-
BALANCED and LOC-MSA-BALANCED have
very different usage rates (Figure 2), perceived dif-
ferences in accuracy may be purely attributable to
the amount of data available per user, rather than
to users in one group being inherently harder to
classify than another. For this reason, we bin users
by the number of messages in our sample of their
timeline, and report results separately for each bin.
All errorbars represent 95% confidence intervals.
GPS versus location As seen in Figure 6a, there
is little difference in accuracy across sampling
techniques: the location-based sample is slightly
easier to geolocate at each usage bin, but the dif-
ference is not statistically significant. However,
due to the higher average usage rate in GPS-
MSA-BALANCED(see Figure 2), the overall accu-
racy for a sample of users will appear to be higher
on this data.
Demographics Next, we measure classification
accuracy by gender and age, using the posterior
distribution from the expectation-maximization al-
gorithm to predict the gender of each user (broadly
similar results are obtained by using the prior dis-
tribution). For this experiment, we focus on the
GPS-MSA-BALANCED sample. As shown in
Figure 6b, text-based geolocation is consistently
more accurate for male authors, across almost the
entire spectrum of usage rates. As shown in Fig-
ure 6c, older users also tend to be easier to ge-
olocate: at each usage level, the highest accuracy
goes to one of the two older groups, and the dif-
ference is significant in almost every case. As dis-
cussed in § 4, older male users tend to mention
many entities, particularly sports-related terms;
these terms are apparently more predictive than
the non-standard spellings and slang favored by
younger authors.
</bodyText>
<footnote confidence="0.48661775">
models can be challenging, and the resulting accuracies might
be affected by initial conditions or hyperparameters. We
therefore focus on classification, employing the familiar and
well-understood method of logistic regression.
</footnote>
<sectionHeader confidence="0.998242" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9999662">
Several researchers have studied how adoption of
Internet technology varies with factors such as so-
cioeconomic status, age, gender, and living condi-
tions (Zillien and Hargittai, 2009). Hargittai and
Litt (2011) use a longitudinal survey methodology
to compare the effects of gender, race, and topics
of interest on Twitter usage among young adults.
Geographic variation in Twitter adoption has been
considered both internationally (Kulshrestha et al.,
2012) and within the United States, using both
the Twitter location field (Mislove et al., 2011)
and per-message GPS coordinates (Hecht and
Stephens, 2014). Aggregate demographic statis-
tics of Twitter users’ geographic census blocks
were computed by O’Connor et al. (2010) and
Eisenstein et al. (2011b); Malik et al. (2015) use
census demographics in spatial error model. These
papers draw similar conclusions, showing that the
the distribution of geotagged tweets over the US
population is not random, and that higher usage
is correlated with urban areas, high income, more
ethnic minorities, and more young people. How-
ever, this prior work did not consider the biases
introduced by relying on geotagged messages, nor
the consequences for geo-linguistic analysis.
Twitter has often been used to study the ge-
ographical distribution of linguistic information,
and of particular relevance are Twitter-based stud-
ies of regional dialect differences (Eisenstein et
al., 2010; Doyle, 2014; Gonc¸alves and S´anchez,
2014; Eisenstein, 2015) and text-based geoloca-
tion (Cheng et al., 2010; Hong et al., 2012; Han et
al., 2014). This prior work rarely considers the im-
pact of the demographic confounds, or of the geo-
graphical biases mentioned in § 3. Recent research
shows that accuracies of core language technol-
ogy tasks such as part-of-speech tagging are cor-
related with author demographics such as author
age (Hovy and Søgaard, 2015); our results on lo-
cation prediction are in accord with these findings.
Hovy (2015) show that including author demo-
graphics can improve text classification, a similar
approach might improve text-based geolocation as
well.
We address the question about the impact of
geographical biases and demographic confounds
by measuring differences between three sampling
techniques, in both language use and in the ac-
curacy of text-based geolocation. Recent unpub-
lished work proposes reweighting Twitter data to
</bodyText>
<page confidence="0.989587">
2145
</page>
<figure confidence="0.998838">
0-2 3-5 6-10 11-15 &gt;15
Number of messages by a user
0-2 3-5 6-10 11-15 &gt;15
Number of messages by a user
0.28
0.26
Accuracy
0.24
0.22
0.20
0.18
0.16
0.14
0.24
0.22
Accuracy
0.20
0.18
0.16
0.14
0.24
0.22
Accuracy
0.20
0.18
0.16
30-39
18-29
0-2 3-5 6-10 11-15 &gt;15
Number of messages by a user
0-17
40+
0.14
0.12
LOC-MSA-Balanced
GPS-MSA-Balanced
Male
Female
(a) Classification accuracy by sampling (b) Classification accuracy by user gen- (c) Classification accuracy by imputed
technique der age
</figure>
<figureCaption confidence="0.999987">
Figure 6: Classification accuracies
</figureCaption>
<bodyText confidence="0.999220625">
correct biases in political analysis (Choy et al.,
2012) and public health (Culotta, 2014). Our
results suggest that the linguistic differences be-
tween user-supplied profile locations and per-
message geotags are more significant, and that ac-
counting for the geographical biases among geo-
tagged messages is not sufficient to offer a repre-
sentative sample of Twitter users.
</bodyText>
<sectionHeader confidence="0.999687" genericHeader="conclusions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999949342857143">
Geotagged Twitter data offers an invaluable re-
source for studying the interaction of language and
geography, and is helping to usher in a new gener-
ation of location-aware language technology. This
makes critical investigation of the nature of this
data source particularly important. This paper un-
covers demographic confounds in the linguistic
analysis of geo-located Twitter data, but is lim-
ited to demographics that can be readily induced
from given names. A key task for future work is to
quantify the representativeness of geotagged Twit-
ter data with respect to factors such as race and so-
cioeconomic status, while holding geography con-
stant. However, these features may be more diffi-
cult to impute from names alone. Another cru-
cial task is to expand this investigation beyond the
United States, as the varying patterns of use for so-
cial media across countries (Pew Research Center,
2012) implies that the findings here cannot be ex-
pected to generalize to every international context.
Acknowledgments Thanks to the anonymous
reviewers for their useful and constructive feed-
back on our submission. The following mem-
bers of the Georgia Tech Computational Linguis-
tics Laboratory offered feedback throughout the
research process: Naman Goyal, Yangfeng Ji, Vin-
odh Krishan, Ana Smith, Yijie Wang, and Yi Yang.
This research was supported by the National Sci-
ence Foundation under awards IIS-1111142 and
RI-1452443, by the National Institutes of Health
under award number R01GM112697-01, and by
the Air Force Office of Scientific Research. The
content is solely the responsibility of the authors
and does not necessarily represent the official
views of these sponsors.
</bodyText>
<sectionHeader confidence="0.998913" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99843371875">
David Bamman, Jacob Eisenstein, and Tyler Schnoe-
belen. 2014. Gender identity and lexical varia-
tion in social media. Journal of Sociolinguistics,
18(2):135–160.
David A Broniatowski, Michael J Paul, and Mark
Dredze. 2013. National and local influenza surveil-
lance through twitter: An analysis of the 2012-2013
influenza epidemic. PloS one, 8(12):e83672.
John D. Burger, John Henderson, George Kim, and
Guido Zarrella. 2011. Discriminating gender on
twitter. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing.
Guido Caldarelli, Alessandro Chessa, Fabio Pammolli,
Gabriele Pompa, Michelangelo Puliga, Massimo
Riccaboni, and Gianni Riotta. 2014. A multi-level
geographical study of Italian political elections from
Twitter Data. PloS one, 9(5):e95809.
Jonathan Chang, Itamar Rosenn, Lars Backstrom, and
Cameron Marlow. 2010. ePluribus: Ethnicity on
social networks. In Proceedings of the International
Conference on Web and Social Media (ICWSM),
pages 18–25, Menlo Park, California. AAAI Pub-
lications.
Zhiyuan Cheng, James Caverlee, and Kyumin Lee.
2010. You are where you tweet: a content-based ap-
proach to geo-locating twitter users. In Proceedings
of the International Conference on Information and
Knowledge Management (CIKM), pages 759–768.
Murphy Choy, Michelle Cheong, Ma Nang Laik, and
Koo Ping Shung. 2012. Us presidential elec-
tion 2012 prediction using census corrected twitter
model. arXiv preprint arXiv:1211.0938.
</reference>
<page confidence="0.922812">
2146
</page>
<reference confidence="0.999734038095238">
Aron Culotta. 2014. Reducing sampling bias in so-
cial media data for county health inference. In Joint
Statistical Meetings Proceedings.
Gabriel Doyle. 2014. Mapping dialectal variation
by querying social media. In Proceedings of the
European Chapter of the Association for Computa-
tional Linguistics (EACL), pages 98–106, Strouds-
burg, Pennsylvania. Association for Computational
Linguistics.
Mark Dredze, Michael J Paul, Shane Bergsma, and
Hieu Tran. 2013. Carmen: A Twitter geolocation
system with applications to public health. In AAAI
Workshop on Expanding the Boundaries of Health
Informatics Using Artificial Intelligence, pages 20–
24.
Jacob Eisenstein, Brendan O’Connor, Noah A. Smith,
and Eric P. Xing. 2010. A latent variable model for
geographic lexical variation. In Proceedings of Em-
pirical Methods for Natural Language Processing
(EMNLP), pages 1277–1287, Stroudsburg, Pennsyl-
vania. Association for Computational Linguistics.
Jacob Eisenstein, Amr Ahmed, and Eric P. Xing.
2011a. Sparse additive generative models of text. In
Proceedings of the International Conference on Ma-
chine Learning (ICML), pages 1041–1048, Seattle,
WA.
Jacob Eisenstein, Noah A. Smith, and Eric P. Xing.
2011b. Discovering sociolinguistic associations
with structured sparsity. In Proceedings of the Asso-
ciation for Computational Linguistics (ACL), pages
1365–1374, Portland, OR.
Jacob Eisenstein. 2015. Written dialect variation in
online social media. In Charles Boberg, John Ner-
bonne, and Dom Watt, editors, Handbook of Dialec-
tology. Wiley.
Irene Eleta and Jennifer Golbeck. 2014. Multilingual
use of twitter: Social networks at the language fron-
tier. Computers in Human Behavior, 41:424–432.
Nikesh Garera and David Yarowsky. 2009. Modeling
latent biographic attributes in conversational genres.
In Proceedings of the Association for Computational
Linguistics (ACL), pages 710–718.
Bruno Gonc¸alves and David S´anchez. 2014. Crowd-
sourcing dialect characterization through twitter.
PloS one, 9(11):e112074.
Bo Han, Paul Cook, and Timothy Baldwin. 2014.
Text-based twitter user geolocation prediction.
Journal of Artificial Intelligence Research (JAIR),
49:451–500.
Eszter Hargittai and Eden Litt. 2011. The tweet smell
of celebrity success: Explaining variation in twit-
ter adoption among a diverse group of young adults.
New Media &amp; Society, 13(5):824–842.
Brent Hecht and Monica Stephens. 2014. A tale of
cities: Urban biases in volunteered geographic in-
formation. In Proceedings of the International Con-
ference on Web and Social Media (ICWSM), pages
197–205, Menlo Park, California. AAAI Publica-
tions.
Brent Hecht, Lichan Hong, Bongwon Suh, and Ed H
Chi. 2011. Tweets from Justin Bieber’s heart: the
dynamics of the location field in user profiles. In
Proceedings of Human Factors in Computing Sys-
tems (CHI), pages 237–246.
Liangjie Hong, Amr Ahmed, Siva Gurumurthy,
Alexander J. Smola, and Kostas Tsioutsiouliklis.
2012. Discovering geographical topics in the twitter
stream. In Proceedings of the Conference on World-
Wide Web (WWW), pages 769–778, Lyon, France.
Dirk Hovy and Anders Søgaard. 2015. Tagging per-
formance correlates with author age. In Proceed-
ings of the Association for Computational Linguis-
tics (ACL), pages 483–488, Beijing, China.
Dirk Hovy. 2015. Demographic factors improve clas-
sification performance. In Proceedings of the Asso-
ciation for Computational Linguistics (ACL), pages
752–762, Beijing, China.
Juhi Kulshrestha, Farshad Kooti, Ashkan Nikravesh,
and Krishna P. Gummadi. 2012. Geographic Dis-
section of the Twitter Network. In Proceedings of
the International Conference on Web and Social Me-
dia (ICWSM), Menlo Park, California. AAAI Publi-
cations.
Amanda Lenhart. 2015. Mobile access shifts social
media use and other online activities. Technical re-
port, Pew Research Center, April.
P. A. Longley, M. Adnan, and G. Lansley. 2015. The
geotemporal demographics of twitter usage. Envi-
ronment and Planning A, 47(2):465–484.
Momin Malik, Hemank Lamba, Constantine Nakos,
and J¨urgen Pfeffer. 2015. Population bias in geo-
tagged tweets. In Papers from the 2015 ICWSM
Workshop on Standards and Practices in Large-
Scale Social Media Research, pages 18–27. The
AAAI Press.
Alan Mislove, Sune Lehmann, Yong-Yeol Ahn, Jukka-
Pekka Onnela, and J. Niels Rosenquist. 2011. Un-
derstanding the demographics of twitter users. In
Proceedings of the International Conference on Web
and Social Media (ICWSM), pages 554–557, Menlo
Park, California. AAAI Publications.
Burt L Monroe, Michael P Colaresi, and Kevin M
Quinn. 2008. Fightin’words: Lexical feature se-
lection and evaluation for identifying the content of
political conflict. Political Analysis, 16(4):372–403.
</reference>
<page confidence="0.834455">
2147
</page>
<reference confidence="0.99965386440678">
Dong Nguyen, Dolf Trieschnigg, A Seza Dogru¨oz, Ri-
lana Gravel, Mari¨et Theune, Theo Meder, and Fran-
ciska de Jong. 2014. Why gender and age predic-
tion from tweets is hard: Lessons from a crowd-
sourcing experiment. In Proceedings of the Inter-
national Conference on Computational Linguistics
(COLING), pages 1950–1961.
Brendan O’Connor, Jacob Eisenstein, Eric P. Xing, and
Noah A. Smith. 2010. A mixture model of demo-
graphic lexical variation. In Proceedings of NIPS
Workshop on Machine Learning for Social Comput-
ing, Vancouver.
Pew Research Center. 2012. Social networking popu-
lar across globe. Technical report, December.
Barbara Poblete, Ruth Garcia, Marcelo Mendoza, and
Alejandro Jaimes. 2011. Do all birds tweet the
same? characterizing Twitter around the world.
In Proceedings of the International Conference on
Information and Knowledge Management (CIKM),
pages 1025–1030. ACM.
Delip Rao, David Yarowsky, Abhishek Shreevats, and
Manaswi Gupta. 2010. Classifying latent user at-
tributes in twitter. In Proceedings of Workshop on
Search and mining user-generated contents.
Stephen Roller, Michael Speriosu, Sarat Rallapalli,
Benjamin Wing, and Jason Baldridge. 2012. Super-
vised text-based geolocation using language mod-
els on an adaptive grid. In Proceedings of Em-
pirical Methods for Natural Language Processing
(EMNLP), pages 1500–1510.
Sara Rosenthal and Kathleen McKeown. 2011. Age
prediction in blogs: A study of style, content, and
online behavior in pre- and Post-Social media gen-
erations. In Proceedings of the Association for Com-
putational Linguistics (ACL), pages 763–772, Port-
land, OR.
Thamar Solorio and Yang Liu. 2008. Learning to pre-
dict code-switching points. In Proceedings of Em-
pirical Methods for Natural Language Processing
(EMNLP), pages 973–981, Honolulu, HI, October.
Association for Computational Linguistics.
Svitlana Volkova and Benjamin Van Durme. 2015.
Online bayesian models for personal analytics in so-
cial media. In Proceedings of the National Confer-
ence on Artificial Intelligence (AAAI), pages 2325–
2331.
Benjamin Wing and Jason Baldridge. 2011. Sim-
ple supervised document geolocation with geodesic
grids. In Proceedings of the Association for Com-
putational Linguistics (ACL), pages 955–964, Port-
land, OR.
Sarita Yardi, Daniel Romero, Grant Schoenebeck, et al.
2009. Detecting spam in a twitter network. First
Monday, 15(1).
Kathryn Zickuhr. 2013. Location-based services.
Technical report, Pew Research Center, Septmeber.
Nicole Zillien and Eszter Hargittai. 2009. Digital
distinction: Status-specific types of internet usage*.
Social Science Quarterly, 90(2):274–291.
</reference>
<page confidence="0.994337">
2148
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.670792">
<title confidence="0.999289">Confounds and Consequences in Geotagged Twitter Data</title>
<author confidence="0.905081">Pavalanathan</author>
<affiliation confidence="0.998881">School of Interactive Georgia Institute of</affiliation>
<address confidence="0.973958">Atlanta, GA</address>
<email confidence="0.787161">+</email>
<abstract confidence="0.997961875">Twitter is often used in quantitative studies that identify geographically-preferred topics, writing styles, and entities. These studies rely on either GPS coordinates attached to individual messages, or on the user-supplied location field in each profile. In this paper, we compare these data acquisition techniques and quantify the biases that they introduce; we also measure their effects on linguistic analysis and textbased geolocation. GPS-tagging and selfreported locations yield measurably different corpora, and these linguistic differences are partially attributable to differences in dataset composition by age and gender. Using a latent variable model to induce age and gender, we show how these demographic variables interact with geography to affect language use. We also show that the accuracy of text-based geolocation varies with population demographics, giving the best results for men above the age of 40.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Bamman</author>
<author>Jacob Eisenstein</author>
<author>Tyler Schnoebelen</author>
</authors>
<title>Gender identity and lexical variation in social media.</title>
<date>2014</date>
<journal>Journal of Sociolinguistics,</journal>
<volume>18</volume>
<issue>2</issue>
<contexts>
<context position="25481" citStr="Bamman et al. (2014)" startWordPosition="4024" endWordPosition="4027">ost salient lexical items for each MSA, subgrouped by age and gender. Table 3 shows word lists for New York (the largest MSA) and Dallas (the 5th-largest MSA), using the GPSMSA-BALANCED sample. Non-standard words tend to be used by the youngest authors: ilysm (’I love you so much’), ight (’alright’), oomf (’one of my followers’). Older authors write more about local entities (manhattan, nyc, houston), with men focusing on sports-related entities (harden, watt, astros, mets, texans), and women above the age of 40 emphasizing religiously-oriented terms (proverb, islam, rejoice, psalm). 5But see Bamman et al. (2014) for a much more detailed discussion of gender and standardness. 5 Impact on text-based geolocation A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014). Text-based geolocation has obvious commercial implications for location-based marketing and opinion analysis; it is also potentially useful for researchers who want to measure geographical phenomena in social media, and wish to access a larger set of individuals than those who p</context>
</contexts>
<marker>Bamman, Eisenstein, Schnoebelen, 2014</marker>
<rawString>David Bamman, Jacob Eisenstein, and Tyler Schnoebelen. 2014. Gender identity and lexical variation in social media. Journal of Sociolinguistics, 18(2):135–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Broniatowski</author>
<author>Michael J Paul</author>
<author>Mark Dredze</author>
</authors>
<title>National and local influenza surveillance through twitter: An analysis of the 2012-2013 influenza epidemic.</title>
<date>2013</date>
<tech>PloS one, 8(12):e83672.</tech>
<contexts>
<context position="1509" citStr="Broniatowski et al., 2013" startWordPosition="220" endWordPosition="223">el to induce age and gender, we show how these demographic variables interact with geography to affect language use. We also show that the accuracy of text-based geolocation varies with population demographics, giving the best results for men above the age of 40. 1 Introduction Social media data such as Twitter is frequently used to identify the unique characteristics of geographical regions, including topics of interest (Hong et al., 2012), linguistic styles and dialects (Eisenstein et al., 2010; Gonc¸alves and S´anchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any “real world” population, aside from social media itself. Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015). This paper examines the effects of these biases on the geo-linguistic inferen</context>
</contexts>
<marker>Broniatowski, Paul, Dredze, 2013</marker>
<rawString>David A Broniatowski, Michael J Paul, and Mark Dredze. 2013. National and local influenza surveillance through twitter: An analysis of the 2012-2013 influenza epidemic. PloS one, 8(12):e83672.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Burger</author>
<author>John Henderson</author>
<author>George Kim</author>
<author>Guido Zarrella</author>
</authors>
<title>Discriminating gender on twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="27687" citStr="Burger et al., 2011" startWordPosition="4371" endWordPosition="4374">to identify the precise latitude and longitude coordinates of individual authors, but obtaining high accuracy on this task involves much more complex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012). Tuning such 2144 user-balanced samples, we apply ten-fold cross validation, and tune the regularization parameter on a development fold, using the vocabulary of the sample as features. 5.2 Results Many author-attribute prediction tasks become substantially easier as more data is available (Burger et al., 2011), and text-based geolocation is no exception. Since GPS-MSABALANCED and LOC-MSA-BALANCED have very different usage rates (Figure 2), perceived differences in accuracy may be purely attributable to the amount of data available per user, rather than to users in one group being inherently harder to classify than another. For this reason, we bin users by the number of messages in our sample of their timeline, and report results separately for each bin. All errorbars represent 95% confidence intervals. GPS versus location As seen in Figure 6a, there is little difference in accuracy across sampling </context>
</contexts>
<marker>Burger, Henderson, Kim, Zarrella, 2011</marker>
<rawString>John D. Burger, John Henderson, George Kim, and Guido Zarrella. 2011. Discriminating gender on twitter. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Caldarelli</author>
<author>Alessandro Chessa</author>
<author>Fabio Pammolli</author>
<author>Gabriele Pompa</author>
<author>Michelangelo Puliga</author>
<author>Massimo Riccaboni</author>
<author>Gianni Riotta</author>
</authors>
<title>A multi-level geographical study of Italian political elections from Twitter Data. PloS one,</title>
<date>2014</date>
<pages>9--5</pages>
<contexts>
<context position="1462" citStr="Caldarelli et al., 2014" startWordPosition="213" endWordPosition="216">y age and gender. Using a latent variable model to induce age and gender, we show how these demographic variables interact with geography to affect language use. We also show that the accuracy of text-based geolocation varies with population demographics, giving the best results for men above the age of 40. 1 Introduction Social media data such as Twitter is frequently used to identify the unique characteristics of geographical regions, including topics of interest (Hong et al., 2012), linguistic styles and dialects (Eisenstein et al., 2010; Gonc¸alves and S´anchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any “real world” population, aside from social media itself. Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015). This paper examines the effect</context>
</contexts>
<marker>Caldarelli, Chessa, Pammolli, Pompa, Puliga, Riccaboni, Riotta, 2014</marker>
<rawString>Guido Caldarelli, Alessandro Chessa, Fabio Pammolli, Gabriele Pompa, Michelangelo Puliga, Massimo Riccaboni, and Gianni Riotta. 2014. A multi-level geographical study of Italian political elections from Twitter Data. PloS one, 9(5):e95809.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Itamar Rosenn</author>
<author>Lars Backstrom</author>
<author>Cameron Marlow</author>
</authors>
<title>ePluribus: Ethnicity on social networks.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Web and Social Media (ICWSM),</booktitle>
<pages>18--25</pages>
<publisher>AAAI Publications.</publisher>
<location>Menlo Park, California.</location>
<contexts>
<context position="18817" citStr="Chang et al., 2010" startWordPosition="2971" endWordPosition="2974">or OTHER. Annotation for ambiguous cases is based on the majority sense in randomly-selected examples. Overall, we identify 24 NONSTANDARDWORDs and 185 ENTITY-NAMEs. Inferring author demographics As described in § 3.1.2, we can obtain an approximate distribution over author age and gender by linking selfreported first names with aggregate statistics from the United States Census. To sharpen these estimates, we now consider the text as well, building a simple latent variable model in which both the name and the word counts are drawn from distributions associated with the latent age and gender (Chang et al., 2010). The model is shown in Figure 4, and involves the following generative process: For each user i E {1...N}, (a) draw the age, ai — Categorical(π) (b) draw the gender, gi — Categorical(0.5) 2.51e−3 2.0 1.5 1.0 0.5 0.0 1.50 20 40 60 80 100 Age 2142 7r ai 9i wi ni N e 0 2B ai Age (bin) for author i gi Gender of author i wi Word counts for author i ni First name of author i it Prior distribution over age bins θa,g Word distribution for age a and gender g φa,g First name distribution for age a and gender g Figure 4: Plate diagram for latent variable model of age and gender (c) draw the author’s giv</context>
</contexts>
<marker>Chang, Rosenn, Backstrom, Marlow, 2010</marker>
<rawString>Jonathan Chang, Itamar Rosenn, Lars Backstrom, and Cameron Marlow. 2010. ePluribus: Ethnicity on social networks. In Proceedings of the International Conference on Web and Social Media (ICWSM), pages 18–25, Menlo Park, California. AAAI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Cheng</author>
<author>James Caverlee</author>
<author>Kyumin Lee</author>
</authors>
<title>You are where you tweet: a content-based approach to geo-locating twitter users.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>759--768</pages>
<contexts>
<context position="2948" citStr="Cheng et al., 2010" startWordPosition="446" endWordPosition="449">y-balanced sample of GPS-tagged messages to correct Twitter’s urban skew (Hecht and Stephens, 2014); and drawing a sample of location-annotated messages, using the location field in the user profile. Leveraging self-reported first names and census statistics, we show that the age and gender composition of these datasets differ significantly. Next, we apply standard methods from the literature to identify geo-linguistic differences, and test how the outcomes of these methods depend on the sampling technique and on the underlying demographics. We also test the accuracy of textbased geolocation (Cheng et al., 2010; Eisenstein et al., 2010) in each dataset, to determine whether the accuracies reported in recent work will generalize to more balanced samples. The paper reports several new findings about geotagged Twitter data: • In comparison with tweets with self-reported locations, GPS-tagged tweets are written more often by young people and by women. • There are corresponding linguistic differences between these datasets, with GPS-tagged tweets including more geographically-specific non-standard words. • Young people use significantly more geographically-specific non-standard words. Men tend to mention</context>
<context position="6727" citStr="Cheng et al., 2010" startWordPosition="1036" endWordPosition="1039"> square mile), but extends to Haralson County (100 people per square mile), on the border of Alabama. A per-county analysis of this data therefore enables us to assess the degree to which Twitter’s skew towards urban areas biases geo-linguistic analysis. 3 Representativeness of geotagged Twitter data We first assess potential biases in sampling techniques for obtaining geotagged Twitter data. In particular, we compare two possible techniques for obtaining data: the location field in the user profile (Poblete et al., 2011; Dredze et al., 2013), and the GPS coordinates attached to each message (Cheng et al., 2010; Eisenstein et al., 2010). 3.1 Methods To build a dataset of GPS-tagged messages, we extracted the GPS latitude and longitude coordinates reported in the tweet, and used GIS-TOOLS1 reverse geocoding to identify the corresponding counties. This set of geotagged messages will be denoted DG. Only 1.24% of messages contain geo-coordinates, and it is possible that the individuals willing to share their GPS comprise a skewed population. We therefore also considered the userreported location field in the Twitter profile, focusing on the two most widely-used patterns: (1) city name, (2) city name and</context>
<context position="25736" citStr="Cheng et al., 2010" startWordPosition="4065" endWordPosition="4068">sm (’I love you so much’), ight (’alright’), oomf (’one of my followers’). Older authors write more about local entities (manhattan, nyc, houston), with men focusing on sports-related entities (harden, watt, astros, mets, texans), and women above the age of 40 emphasizing religiously-oriented terms (proverb, islam, rejoice, psalm). 5But see Bamman et al. (2014) for a much more detailed discussion of gender and standardness. 5 Impact on text-based geolocation A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014). Text-based geolocation has obvious commercial implications for location-based marketing and opinion analysis; it is also potentially useful for researchers who want to measure geographical phenomena in social media, and wish to access a larger set of individuals than those who provide their locations explicitly. Previous research has obtained impressive accuracies for text-based geolocation: for example, Hong et al. (2012) report a median error of 120 km, which is roughly the distance from Los Angeles to San Diego, in a predicti</context>
<context position="27352" citStr="Cheng et al., 2010" startWordPosition="4321" endWordPosition="4324">n, we explore where these text-based geolocation methods are most and least accurate. 5.1 Methods Our data is drawn from the ten largest metropolitan areas in the United States, and we formulate text-based geolocation as a ten-way classification problem, similar to Han et al. (2014).6 Using our 6Many previous papers have attempted to identify the precise latitude and longitude coordinates of individual authors, but obtaining high accuracy on this task involves much more complex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012). Tuning such 2144 user-balanced samples, we apply ten-fold cross validation, and tune the regularization parameter on a development fold, using the vocabulary of the sample as features. 5.2 Results Many author-attribute prediction tasks become substantially easier as more data is available (Burger et al., 2011), and text-based geolocation is no exception. Since GPS-MSABALANCED and LOC-MSA-BALANCED have very different usage rates (Figure 2), perceived differences in accuracy may be purely attributable to the amount of data available per user, rather than to users in one g</context>
<context position="31252" citStr="Cheng et al., 2010" startWordPosition="4922" endWordPosition="4925">ets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc¸alves and S´anchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in § 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and Søgaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geolocation as well. We address the question about </context>
</contexts>
<marker>Cheng, Caverlee, Lee, 2010</marker>
<rawString>Zhiyuan Cheng, James Caverlee, and Kyumin Lee. 2010. You are where you tweet: a content-based approach to geo-locating twitter users. In Proceedings of the International Conference on Information and Knowledge Management (CIKM), pages 759–768.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Murphy Choy</author>
<author>Michelle Cheong</author>
<author>Ma Nang Laik</author>
<author>Koo Ping Shung</author>
</authors>
<title>Us presidential election 2012 prediction using census corrected twitter model. arXiv preprint arXiv:1211.0938.</title>
<date>2012</date>
<contexts>
<context position="32691" citStr="Choy et al., 2012" startWordPosition="5153" endWordPosition="5156">reweighting Twitter data to 2145 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0.28 0.26 Accuracy 0.24 0.22 0.20 0.18 0.16 0.14 0.24 0.22 Accuracy 0.20 0.18 0.16 0.14 0.24 0.22 Accuracy 0.20 0.18 0.16 30-39 18-29 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0-17 40+ 0.14 0.12 LOC-MSA-Balanced GPS-MSA-Balanced Male Female (a) Classification accuracy by sampling (b) Classification accuracy by user gen- (c) Classification accuracy by imputed technique der age Figure 6: Classification accuracies correct biases in political analysis (Choy et al., 2012) and public health (Culotta, 2014). Our results suggest that the linguistic differences between user-supplied profile locations and permessage geotags are more significant, and that accounting for the geographical biases among geotagged messages is not sufficient to offer a representative sample of Twitter users. 7 Discussion Geotagged Twitter data offers an invaluable resource for studying the interaction of language and geography, and is helping to usher in a new generation of location-aware language technology. This makes critical investigation of the nature of this data source particularly</context>
</contexts>
<marker>Choy, Cheong, Laik, Shung, 2012</marker>
<rawString>Murphy Choy, Michelle Cheong, Ma Nang Laik, and Koo Ping Shung. 2012. Us presidential election 2012 prediction using census corrected twitter model. arXiv preprint arXiv:1211.0938.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
</authors>
<title>Reducing sampling bias in social media data for county health inference.</title>
<date>2014</date>
<booktitle>In Joint Statistical Meetings Proceedings.</booktitle>
<contexts>
<context position="32725" citStr="Culotta, 2014" startWordPosition="5160" endWordPosition="5161">-5 6-10 11-15 &gt;15 Number of messages by a user 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0.28 0.26 Accuracy 0.24 0.22 0.20 0.18 0.16 0.14 0.24 0.22 Accuracy 0.20 0.18 0.16 0.14 0.24 0.22 Accuracy 0.20 0.18 0.16 30-39 18-29 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0-17 40+ 0.14 0.12 LOC-MSA-Balanced GPS-MSA-Balanced Male Female (a) Classification accuracy by sampling (b) Classification accuracy by user gen- (c) Classification accuracy by imputed technique der age Figure 6: Classification accuracies correct biases in political analysis (Choy et al., 2012) and public health (Culotta, 2014). Our results suggest that the linguistic differences between user-supplied profile locations and permessage geotags are more significant, and that accounting for the geographical biases among geotagged messages is not sufficient to offer a representative sample of Twitter users. 7 Discussion Geotagged Twitter data offers an invaluable resource for studying the interaction of language and geography, and is helping to usher in a new generation of location-aware language technology. This makes critical investigation of the nature of this data source particularly important. This paper uncovers de</context>
</contexts>
<marker>Culotta, 2014</marker>
<rawString>Aron Culotta. 2014. Reducing sampling bias in social media data for county health inference. In Joint Statistical Meetings Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Doyle</author>
</authors>
<title>Mapping dialectal variation by querying social media.</title>
<date>2014</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>98--106</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, Pennsylvania.</location>
<contexts>
<context position="31155" citStr="Doyle, 2014" startWordPosition="4910" endWordPosition="4911"> These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc¸alves and S´anchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in § 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and Søgaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification</context>
</contexts>
<marker>Doyle, 2014</marker>
<rawString>Gabriel Doyle. 2014. Mapping dialectal variation by querying social media. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL), pages 98–106, Stroudsburg, Pennsylvania. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Michael J Paul</author>
<author>Shane Bergsma</author>
<author>Hieu Tran</author>
</authors>
<title>Carmen: A Twitter geolocation system with applications to public health.</title>
<date>2013</date>
<booktitle>In AAAI Workshop on Expanding the Boundaries of Health Informatics Using Artificial Intelligence,</booktitle>
<pages>20--24</pages>
<contexts>
<context position="6657" citStr="Dredze et al., 2013" startWordPosition="1023" endWordPosition="1026">r example, the Atlanta MSA is centered on Fulton County (1750 people per square mile), but extends to Haralson County (100 people per square mile), on the border of Alabama. A per-county analysis of this data therefore enables us to assess the degree to which Twitter’s skew towards urban areas biases geo-linguistic analysis. 3 Representativeness of geotagged Twitter data We first assess potential biases in sampling techniques for obtaining geotagged Twitter data. In particular, we compare two possible techniques for obtaining data: the location field in the user profile (Poblete et al., 2011; Dredze et al., 2013), and the GPS coordinates attached to each message (Cheng et al., 2010; Eisenstein et al., 2010). 3.1 Methods To build a dataset of GPS-tagged messages, we extracted the GPS latitude and longitude coordinates reported in the tweet, and used GIS-TOOLS1 reverse geocoding to identify the corresponding counties. This set of geotagged messages will be denoted DG. Only 1.24% of messages contain geo-coordinates, and it is possible that the individuals willing to share their GPS comprise a skewed population. We therefore also considered the userreported location field in the Twitter profile, focusing </context>
</contexts>
<marker>Dredze, Paul, Bergsma, Tran, 2013</marker>
<rawString>Mark Dredze, Michael J Paul, Shane Bergsma, and Hieu Tran. 2013. Carmen: A Twitter geolocation system with applications to public health. In AAAI Workshop on Expanding the Boundaries of Health Informatics Using Artificial Intelligence, pages 20– 24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>A latent variable model for geographic lexical variation.</title>
<date>2010</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>1277--1287</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, Pennsylvania.</location>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Jacob Eisenstein, Brendan O’Connor, Noah A. Smith, and Eric P. Xing. 2010. A latent variable model for geographic lexical variation. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 1277–1287, Stroudsburg, Pennsylvania. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Amr Ahmed</author>
<author>Eric P Xing</author>
</authors>
<title>Sparse additive generative models of text.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML),</booktitle>
<pages>1041--1048</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="17152" citStr="Eisenstein et al., 2011" startWordPosition="2706" endWordPosition="2709">n GPS-MSA-BALANCED and LOC-MSA-BALANCED. These datasets differ in age and gender, so we also directly measure the impact of these demographic factors on the use of geographically-specific linguistic variables. 4.1 Methods Discovering geographical linguistic variables We focus on lexical variation, which is relatively easy to identify in text corpora. Monroe et al. (2008) survey a range of alternative statistics for finding lexical variables, demonstrating that a regularized log-odds ratio strikes a good balance between distinctiveness and robustness. A similar approach is implemented in SAGE (Eisenstein et al., 2011a)2, which we use here. For each sam2https://github.com/jacobeisenstein/jos-gender-2014 ple — GPS-MSA-BALANCED and LOC-MSABALANCED — we apply SAGE to identify the twenty-five most salient lexical items for each metropolitan area. Keyword annotation Previous research has identified two main types of geographical lexical variables. The first are non-standard words and spellings, such as hella and yinz, which have been found to be very frequent in social media (Eisenstein, 2015). Other researchers have focused on the “long tail” of entity names (Roller et al., 2012). A key question is the relativ</context>
<context position="30473" citStr="Eisenstein et al. (2011" startWordPosition="4805" endWordPosition="4808">r, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model. These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-b</context>
</contexts>
<marker>Eisenstein, Ahmed, Xing, 2011</marker>
<rawString>Jacob Eisenstein, Amr Ahmed, and Eric P. Xing. 2011a. Sparse additive generative models of text. In Proceedings of the International Conference on Machine Learning (ICML), pages 1041–1048, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Discovering sociolinguistic associations with structured sparsity.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1365--1374</pages>
<location>Portland, OR.</location>
<contexts>
<context position="17152" citStr="Eisenstein et al., 2011" startWordPosition="2706" endWordPosition="2709">n GPS-MSA-BALANCED and LOC-MSA-BALANCED. These datasets differ in age and gender, so we also directly measure the impact of these demographic factors on the use of geographically-specific linguistic variables. 4.1 Methods Discovering geographical linguistic variables We focus on lexical variation, which is relatively easy to identify in text corpora. Monroe et al. (2008) survey a range of alternative statistics for finding lexical variables, demonstrating that a regularized log-odds ratio strikes a good balance between distinctiveness and robustness. A similar approach is implemented in SAGE (Eisenstein et al., 2011a)2, which we use here. For each sam2https://github.com/jacobeisenstein/jos-gender-2014 ple — GPS-MSA-BALANCED and LOC-MSABALANCED — we apply SAGE to identify the twenty-five most salient lexical items for each metropolitan area. Keyword annotation Previous research has identified two main types of geographical lexical variables. The first are non-standard words and spellings, such as hella and yinz, which have been found to be very frequent in social media (Eisenstein, 2015). Other researchers have focused on the “long tail” of entity names (Roller et al., 2012). A key question is the relativ</context>
<context position="30473" citStr="Eisenstein et al. (2011" startWordPosition="4805" endWordPosition="4808">r, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model. These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-b</context>
</contexts>
<marker>Eisenstein, Smith, Xing, 2011</marker>
<rawString>Jacob Eisenstein, Noah A. Smith, and Eric P. Xing. 2011b. Discovering sociolinguistic associations with structured sparsity. In Proceedings of the Association for Computational Linguistics (ACL), pages 1365–1374, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
</authors>
<title>Written dialect variation in online social media.</title>
<date>2015</date>
<booktitle>Handbook of Dialectology.</booktitle>
<editor>In Charles Boberg, John Nerbonne, and Dom Watt, editors,</editor>
<publisher>Wiley.</publisher>
<contexts>
<context position="17632" citStr="Eisenstein, 2015" startWordPosition="2778" endWordPosition="2779">s ratio strikes a good balance between distinctiveness and robustness. A similar approach is implemented in SAGE (Eisenstein et al., 2011a)2, which we use here. For each sam2https://github.com/jacobeisenstein/jos-gender-2014 ple — GPS-MSA-BALANCED and LOC-MSABALANCED — we apply SAGE to identify the twenty-five most salient lexical items for each metropolitan area. Keyword annotation Previous research has identified two main types of geographical lexical variables. The first are non-standard words and spellings, such as hella and yinz, which have been found to be very frequent in social media (Eisenstein, 2015). Other researchers have focused on the “long tail” of entity names (Roller et al., 2012). A key question is the relative importance of these two variable types, since this would decide whether geo-linguistic differences are primarily topic-based or stylistic. It is therefore important to know whether the frequency of these two variable types depends on properties of the sample. To test this, we take the lexical items identified by SAGE (25 per MSA, for both the GPS-MSA-BALANCED and LOCMSA-BALANCED samples), and annotate them as NONSTANDARD-WORD, ENTITY-NAME, or OTHER. Annotation for ambiguous</context>
<context position="31205" citStr="Eisenstein, 2015" startWordPosition="4916" endWordPosition="4917">ing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc¸alves and S´anchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in § 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and Søgaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geol</context>
</contexts>
<marker>Eisenstein, 2015</marker>
<rawString>Jacob Eisenstein. 2015. Written dialect variation in online social media. In Charles Boberg, John Nerbonne, and Dom Watt, editors, Handbook of Dialectology. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Eleta</author>
<author>Jennifer Golbeck</author>
</authors>
<title>Multilingual use of twitter: Social networks at the language frontier.</title>
<date>2014</date>
<booktitle>Computers in Human Behavior,</booktitle>
<pages>41--424</pages>
<contexts>
<context position="5633" citStr="Eleta and Golbeck, 2014" startWordPosition="855" endWordPosition="858">mong Twitter users to indicate a retweet. To eliminate spam and automated accounts (Yardi et al., 2009), we removed tweets containing URLs, user accounts with more than 1000 followers or followees, accounts which have tweeted more than 5000 messages at the time of data collection, and the top 10% of accounts based on number of messages in our dataset. We also removed users who have written more than 10% of their tweets in any language other than English, using Twitter’s lang metadata field. Exploration of code-switching (Solorio and Liu, 2008) and the role of second-language English speakers (Eleta and Golbeck, 2014) is left for future work. We consider the ten largest Metropolitan Statistical Areas (MSAs) in the United States, listed in Table 1. MSAs are defined by the U.S. Census Bureau as geographical regions of high population with density organized around a single urban core; they are not legal administrative divisions. MSAs include outlying areas that may be substantially less urban than the core itself. For example, the Atlanta MSA is centered on Fulton County (1750 people per square mile), but extends to Haralson County (100 people per square mile), on the border of Alabama. A per-county analysis </context>
</contexts>
<marker>Eleta, Golbeck, 2014</marker>
<rawString>Irene Eleta and Jennifer Golbeck. 2014. Multilingual use of twitter: Social networks at the language frontier. Computers in Human Behavior, 41:424–432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikesh Garera</author>
<author>David Yarowsky</author>
</authors>
<title>Modeling latent biographic attributes in conversational genres.</title>
<date>2009</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>710--718</pages>
<contexts>
<context position="20690" citStr="Garera and Yarowsky, 2009" startWordPosition="3298" endWordPosition="3301">research, we take a relatively simple approach here, assuming no labeled data for demographic attributes. 4.2 Results Linguistic differences by dataset We first consider the impact of the data acquisition technique on the lexical features associated with each city. The keywords identified in GPS-MSABALANCED dataset feature more geographicallyspecific non-standard words, which occur at a rate of 3.9 x 10−4 in GPS-MSA-BALANCED, versus 2.6 x 10−4 in LOC-MSA-BALANCED; this difference is statistically significant (p &lt; .05, t = 3.2).4 3Binning is often employed in work on text-based age prediction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosenthal and McKeown, 2011); it enables word and name counts to be shared over multiple ages, and avoids the complexity inherent in regressing a high-dimensional textual predictors against a numerical variable. 4We employ a paired t-test, comparing the difference in frequency for each word across the two datasets. Since we cannot test the complete set of entity names or non-standard words, this quantifies whether the observed difference is robust across the subset of the vocabulary that we have selected. (a) non-standard words (b) entity names Figure 5: Aggregate statistic</context>
</contexts>
<marker>Garera, Yarowsky, 2009</marker>
<rawString>Nikesh Garera and David Yarowsky. 2009. Modeling latent biographic attributes in conversational genres. In Proceedings of the Association for Computational Linguistics (ACL), pages 710–718.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Gonc¸alves</author>
<author>David S´anchez</author>
</authors>
<title>Crowdsourcing dialect characterization through twitter.</title>
<date>2014</date>
<tech>PloS one, 9(11):e112074.</tech>
<marker>Gonc¸alves, S´anchez, 2014</marker>
<rawString>Bruno Gonc¸alves and David S´anchez. 2014. Crowdsourcing dialect characterization through twitter. PloS one, 9(11):e112074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>Text-based twitter user geolocation prediction.</title>
<date>2014</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<pages>49--451</pages>
<contexts>
<context position="25800" citStr="Han et al., 2014" startWordPosition="4077" endWordPosition="4080">lowers’). Older authors write more about local entities (manhattan, nyc, houston), with men focusing on sports-related entities (harden, watt, astros, mets, texans), and women above the age of 40 emphasizing religiously-oriented terms (proverb, islam, rejoice, psalm). 5But see Bamman et al. (2014) for a much more detailed discussion of gender and standardness. 5 Impact on text-based geolocation A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014). Text-based geolocation has obvious commercial implications for location-based marketing and opinion analysis; it is also potentially useful for researchers who want to measure geographical phenomena in social media, and wish to access a larger set of individuals than those who provide their locations explicitly. Previous research has obtained impressive accuracies for text-based geolocation: for example, Hong et al. (2012) report a median error of 120 km, which is roughly the distance from Los Angeles to San Diego, in a prediction space over the entire continental United States. These accura</context>
<context position="27017" citStr="Han et al. (2014)" startWordPosition="4268" endWordPosition="4271">cies are computed on test sets that were acquired through the same procedures as the training data, so if the acquisition procedures have geographic and demographic biases, then the resulting accuracy estimates will be biased too. Consequently, they may be overly optimistic (or pessimistic!) for some types of authors. In this section, we explore where these text-based geolocation methods are most and least accurate. 5.1 Methods Our data is drawn from the ten largest metropolitan areas in the United States, and we formulate text-based geolocation as a ten-way classification problem, similar to Han et al. (2014).6 Using our 6Many previous papers have attempted to identify the precise latitude and longitude coordinates of individual authors, but obtaining high accuracy on this task involves much more complex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012). Tuning such 2144 user-balanced samples, we apply ten-fold cross validation, and tune the regularization parameter on a development fold, using the vocabulary of the sample as features. 5.2 Results Many author-attribute prediction tasks becom</context>
<context position="31290" citStr="Han et al., 2014" startWordPosition="4930" endWordPosition="4933">m, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc¸alves and S´anchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in § 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and Søgaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geolocation as well. We address the question about the impact of geographical biases and </context>
</contexts>
<marker>Han, Cook, Baldwin, 2014</marker>
<rawString>Bo Han, Paul Cook, and Timothy Baldwin. 2014. Text-based twitter user geolocation prediction. Journal of Artificial Intelligence Research (JAIR), 49:451–500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eszter Hargittai</author>
<author>Eden Litt</author>
</authors>
<title>The tweet smell of celebrity success: Explaining variation in twitter adoption among a diverse group of young adults.</title>
<date>2011</date>
<pages>13--5</pages>
<publisher>Society,</publisher>
<location>New Media</location>
<contexts>
<context position="29931" citStr="Hargittai and Litt (2011)" startWordPosition="4724" endWordPosition="4727"> mention many entities, particularly sports-related terms; these terms are apparently more predictive than the non-standard spellings and slang favored by younger authors. models can be challenging, and the resulting accuracies might be affected by initial conditions or hyperparameters. We therefore focus on classification, employing the familiar and well-understood method of logistic regression. 6 Related Work Several researchers have studied how adoption of Internet technology varies with factors such as socioeconomic status, age, gender, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial</context>
</contexts>
<marker>Hargittai, Litt, 2011</marker>
<rawString>Eszter Hargittai and Eden Litt. 2011. The tweet smell of celebrity success: Explaining variation in twitter adoption among a diverse group of young adults. New Media &amp; Society, 13(5):824–842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brent Hecht</author>
<author>Monica Stephens</author>
</authors>
<title>A tale of cities: Urban biases in volunteered geographic information.</title>
<date>2014</date>
<booktitle>In Proceedings of the International Conference on Web and Social Media (ICWSM),</booktitle>
<pages>197--205</pages>
<publisher>AAAI Publications.</publisher>
<location>Menlo Park, California.</location>
<contexts>
<context position="1987" citStr="Hecht and Stephens, 2014" startWordPosition="294" endWordPosition="297">senstein et al., 2010; Gonc¸alves and S´anchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any “real world” population, aside from social media itself. Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015). This paper examines the effects of these biases on the geo-linguistic inferences that can be drawn from Twitter. We focus on the ten largest metropolitan areas in the United States, and consider three sampling techniques: drawing an equal number of GPS-tagged tweets from each area; drawing a county-balanced sample of GPS-tagged messages to correct Twitter’s urban skew (Hecht and Stephens, 2014); and drawing a sample of location-annotated messages, using the location field in the user profile. Leveraging self-reported first names and census statistic</context>
<context position="12780" citStr="Hecht and Stephens (2014)" startWordPosition="2011" endWordPosition="2014">and per-user distributions. Because counties vary widely in their degree of urbanization and other demographic characteristics, this measure is a proxy for the representativeness of GPSbased Twitter samples (county information is not available for the LOC-MSA-BALANCED sample). Population distributions for New York and Atlanta are shown in Figure 1. In Atlanta, Fulton County is the most populous and most urban, and is overrepresented in both geotagged tweets and user accounts; most of the remaining counties are correspondingly underrepresented. This coheres with the urban bias noted earlier by Hecht and Stephens (2014). In New York, Kings County (Brooklyn) is the most populous, but is underrepresented in both the number of geotagged tweets and user accounts, at the expense of New York County (Manhattan). Manhattan is the commercial and entertainment center of the New York MSA, so residents of outlying counties may be tweeting from their jobs or social activities. To quantify the representativeness of each sample, we use the L1 distance ||x − y||1 = &amp; |p, − t,|, where p, is the proportion of the MSA population residing in county c and t, is the proportion of tweets (Table 1). County boundaries are determined</context>
<context position="30328" citStr="Hecht and Stephens, 2014" startWordPosition="4783" endWordPosition="4786">n. 6 Related Work Several researchers have studied how adoption of Internet technology varies with factors such as socioeconomic status, age, gender, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model. These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic </context>
</contexts>
<marker>Hecht, Stephens, 2014</marker>
<rawString>Brent Hecht and Monica Stephens. 2014. A tale of cities: Urban biases in volunteered geographic information. In Proceedings of the International Conference on Web and Social Media (ICWSM), pages 197–205, Menlo Park, California. AAAI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brent Hecht</author>
<author>Lichan Hong</author>
<author>Bongwon Suh</author>
<author>Ed H Chi</author>
</authors>
<title>Tweets from Justin Bieber’s heart: the dynamics of the location field in user profiles.</title>
<date>2011</date>
<booktitle>In Proceedings of Human Factors in Computing Systems (CHI),</booktitle>
<pages>237--246</pages>
<contexts>
<context position="7576" citStr="Hecht et al., 2011" startWordPosition="1174" endWordPosition="1177">counties. This set of geotagged messages will be denoted DG. Only 1.24% of messages contain geo-coordinates, and it is possible that the individuals willing to share their GPS comprise a skewed population. We therefore also considered the userreported location field in the Twitter profile, focusing on the two most widely-used patterns: (1) city name, (2) city name and two letter state name (e.g. Chicago and Chicago, IL). Messages that matched any of the ten largest MSAs were grouped into a second set, DL. While the inconsistencies of writing style in the Twitter location field are well-known (Hecht et al., 2011), analysis of the intersection between DG and DL found that the two data sources agreed the overwhelming majority of the time, suggesting that most self-provided locations are accurate. Of course, there may be many false negatives — profiles that we fail to geolocate due to the use of non-standard toponyms like Pixburgh and ATL. If so, this would introduce a bias in the population sample in DL. Such a bias might have linguistic consequences, with datasets based on the location field containing less non-standard language overall. 1https://github.com/DrSkippy/ Data-Science-45min-Intros/blob/mast</context>
</contexts>
<marker>Hecht, Hong, Suh, Chi, 2011</marker>
<rawString>Brent Hecht, Lichan Hong, Bongwon Suh, and Ed H Chi. 2011. Tweets from Justin Bieber’s heart: the dynamics of the location field in user profiles. In Proceedings of Human Factors in Computing Systems (CHI), pages 237–246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liangjie Hong</author>
<author>Amr Ahmed</author>
<author>Siva Gurumurthy</author>
<author>Alexander J Smola</author>
<author>Kostas Tsioutsiouliklis</author>
</authors>
<title>Discovering geographical topics in the twitter stream.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on WorldWide Web (WWW),</booktitle>
<pages>769--778</pages>
<location>Lyon, France.</location>
<contexts>
<context position="1327" citStr="Hong et al., 2012" startWordPosition="194" endWordPosition="197">measurably different corpora, and these linguistic differences are partially attributable to differences in dataset composition by age and gender. Using a latent variable model to induce age and gender, we show how these demographic variables interact with geography to affect language use. We also show that the accuracy of text-based geolocation varies with population demographics, giving the best results for men above the age of 40. 1 Introduction Social media data such as Twitter is frequently used to identify the unique characteristics of geographical regions, including topics of interest (Hong et al., 2012), linguistic styles and dialects (Eisenstein et al., 2010; Gonc¸alves and S´anchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any “real world” population, aside from social media itself. Using social media as a sample therefore risks introducing both geographic and demogr</context>
<context position="25781" citStr="Hong et al., 2012" startWordPosition="4073" endWordPosition="4076">omf (’one of my followers’). Older authors write more about local entities (manhattan, nyc, houston), with men focusing on sports-related entities (harden, watt, astros, mets, texans), and women above the age of 40 emphasizing religiously-oriented terms (proverb, islam, rejoice, psalm). 5But see Bamman et al. (2014) for a much more detailed discussion of gender and standardness. 5 Impact on text-based geolocation A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014). Text-based geolocation has obvious commercial implications for location-based marketing and opinion analysis; it is also potentially useful for researchers who want to measure geographical phenomena in social media, and wish to access a larger set of individuals than those who provide their locations explicitly. Previous research has obtained impressive accuracies for text-based geolocation: for example, Hong et al. (2012) report a median error of 120 km, which is roughly the distance from Los Angeles to San Diego, in a prediction space over the entire continental United S</context>
<context position="27301" citStr="Hong et al., 2012" startWordPosition="4312" endWordPosition="4315">imistic!) for some types of authors. In this section, we explore where these text-based geolocation methods are most and least accurate. 5.1 Methods Our data is drawn from the ten largest metropolitan areas in the United States, and we formulate text-based geolocation as a ten-way classification problem, similar to Han et al. (2014).6 Using our 6Many previous papers have attempted to identify the precise latitude and longitude coordinates of individual authors, but obtaining high accuracy on this task involves much more complex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012). Tuning such 2144 user-balanced samples, we apply ten-fold cross validation, and tune the regularization parameter on a development fold, using the vocabulary of the sample as features. 5.2 Results Many author-attribute prediction tasks become substantially easier as more data is available (Burger et al., 2011), and text-based geolocation is no exception. Since GPS-MSABALANCED and LOC-MSA-BALANCED have very different usage rates (Figure 2), perceived differences in accuracy may be purely attributable to the amount of dat</context>
<context position="31271" citStr="Hong et al., 2012" startWordPosition="4926" endWordPosition="4929">lation is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc¸alves and S´anchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in § 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and Søgaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geolocation as well. We address the question about the impact of geogr</context>
</contexts>
<marker>Hong, Ahmed, Gurumurthy, Smola, Tsioutsiouliklis, 2012</marker>
<rawString>Liangjie Hong, Amr Ahmed, Siva Gurumurthy, Alexander J. Smola, and Kostas Tsioutsiouliklis. 2012. Discovering geographical topics in the twitter stream. In Proceedings of the Conference on WorldWide Web (WWW), pages 769–778, Lyon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Hovy</author>
<author>Anders Søgaard</author>
</authors>
<title>Tagging performance correlates with author age.</title>
<date>2015</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>483--488</pages>
<location>Beijing, China.</location>
<contexts>
<context position="31600" citStr="Hovy and Søgaard, 2015" startWordPosition="4981" endWordPosition="4984">e geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc¸alves and S´anchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in § 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and Søgaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geolocation as well. We address the question about the impact of geographical biases and demographic confounds by measuring differences between three sampling techniques, in both language use and in the accuracy of text-based geolocation. Recent unpublished work proposes reweighting Twitter data to 2145 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0-2 3-5 6-10 11-15 &gt;15 Number of messages </context>
</contexts>
<marker>Hovy, Søgaard, 2015</marker>
<rawString>Dirk Hovy and Anders Søgaard. 2015. Tagging performance correlates with author age. In Proceedings of the Association for Computational Linguistics (ACL), pages 483–488, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Hovy</author>
</authors>
<title>Demographic factors improve classification performance.</title>
<date>2015</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>752--762</pages>
<location>Beijing, China.</location>
<contexts>
<context position="31683" citStr="Hovy (2015)" startWordPosition="4997" endWordPosition="4998">based studies of regional dialect differences (Eisenstein et al., 2010; Doyle, 2014; Gonc¸alves and S´anchez, 2014; Eisenstein, 2015) and text-based geolocation (Cheng et al., 2010; Hong et al., 2012; Han et al., 2014). This prior work rarely considers the impact of the demographic confounds, or of the geographical biases mentioned in § 3. Recent research shows that accuracies of core language technology tasks such as part-of-speech tagging are correlated with author demographics such as author age (Hovy and Søgaard, 2015); our results on location prediction are in accord with these findings. Hovy (2015) show that including author demographics can improve text classification, a similar approach might improve text-based geolocation as well. We address the question about the impact of geographical biases and demographic confounds by measuring differences between three sampling techniques, in both language use and in the accuracy of text-based geolocation. Recent unpublished work proposes reweighting Twitter data to 2145 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0-2 3-5 6-10 11-15 &gt;15 Number of messages by a user 0.28 0.26 Accuracy 0.24 0.22 0.20 0.18 0.16 0.14 0.24 0.22 Accuracy 0.20 </context>
</contexts>
<marker>Hovy, 2015</marker>
<rawString>Dirk Hovy. 2015. Demographic factors improve classification performance. In Proceedings of the Association for Computational Linguistics (ACL), pages 752–762, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juhi Kulshrestha</author>
<author>Farshad Kooti</author>
<author>Ashkan Nikravesh</author>
<author>Krishna P Gummadi</author>
</authors>
<title>Geographic Dissection of the Twitter Network.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Web and Social Media (ICWSM), Menlo Park,</booktitle>
<publisher>AAAI Publications.</publisher>
<location>California.</location>
<contexts>
<context position="30178" citStr="Kulshrestha et al., 2012" startWordPosition="4760" endWordPosition="4763">y initial conditions or hyperparameters. We therefore focus on classification, employing the familiar and well-understood method of logistic regression. 6 Related Work Several researchers have studied how adoption of Internet technology varies with factors such as socioeconomic status, age, gender, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model. These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more yo</context>
</contexts>
<marker>Kulshrestha, Kooti, Nikravesh, Gummadi, 2012</marker>
<rawString>Juhi Kulshrestha, Farshad Kooti, Ashkan Nikravesh, and Krishna P. Gummadi. 2012. Geographic Dissection of the Twitter Network. In Proceedings of the International Conference on Web and Social Media (ICWSM), Menlo Park, California. AAAI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amanda Lenhart</author>
</authors>
<title>Mobile access shifts social media use and other online activities.</title>
<date>2015</date>
<tech>Technical report,</tech>
<institution>Pew Research Center,</institution>
<contexts>
<context position="14932" citStr="Lenhart, 2015" startWordPosition="2366" endWordPosition="2367">ge and gender for each dataset, with bootstrap confidence intervals. Users in the LOC-MSABALANCED dataset are on average two years older than in the GPS-MSA-BALANCED and GPSCOUNTY-BALANCED datasets, which are statistically indistinguishable. Focusing on the difference between GPS-MSA-BALANCED and LOCMSA-BALANCED, we plot the difference in age probabilities in Figure 3, showing that GPSMSA-BALANCED includes many more teens and people in their early twenties, while LOC-MSABALANCED includes more people at middle age and older. Young people are especially likely to use social media on cellphones (Lenhart, 2015), where location tagging would be more relevant than when Twitter is accessed via a personal computer. Social media users in the age brackets 18- 29 and 30-49 are also more likely to tag their locations in social media posts than social media users in the age brackets 50-64 and 65+ (Zickuhr, 2013), with women and men tagging at roughly equal rates. Table 2 shows that the GPS-MSABALANCED and GPS-COUNTY-BALANCED samples contain significantly more women than LOC1e4 Number of users in each category 0-2 2-5 5-10 10-15 &gt;15 Number of messages by a user Number of users 1.5 1.0 0.5 0.0 GPS-MSA-Balanced</context>
</contexts>
<marker>Lenhart, 2015</marker>
<rawString>Amanda Lenhart. 2015. Mobile access shifts social media use and other online activities. Technical report, Pew Research Center, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Longley</author>
<author>M Adnan</author>
<author>G Lansley</author>
</authors>
<title>The geotemporal demographics of twitter usage.</title>
<date>2015</date>
<journal>Environment and Planning A,</journal>
<volume>47</volume>
<issue>2</issue>
<contexts>
<context position="2009" citStr="Longley et al., 2015" startWordPosition="298" endWordPosition="302">c¸alves and S´anchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any “real world” population, aside from social media itself. Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015). This paper examines the effects of these biases on the geo-linguistic inferences that can be drawn from Twitter. We focus on the ten largest metropolitan areas in the United States, and consider three sampling techniques: drawing an equal number of GPS-tagged tweets from each area; drawing a county-balanced sample of GPS-tagged messages to correct Twitter’s urban skew (Hecht and Stephens, 2014); and drawing a sample of location-annotated messages, using the location field in the user profile. Leveraging self-reported first names and census statistics, we show that the ag</context>
</contexts>
<marker>Longley, Adnan, Lansley, 2015</marker>
<rawString>P. A. Longley, M. Adnan, and G. Lansley. 2015. The geotemporal demographics of twitter usage. Environment and Planning A, 47(2):465–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Momin Malik</author>
<author>Hemank Lamba</author>
<author>Constantine Nakos</author>
<author>J¨urgen Pfeffer</author>
</authors>
<title>Population bias in geotagged tweets.</title>
<date>2015</date>
<booktitle>In Papers from the 2015 ICWSM Workshop on Standards and Practices in LargeScale Social Media Research,</booktitle>
<pages>18--27</pages>
<publisher>The AAAI Press.</publisher>
<contexts>
<context position="2030" citStr="Malik et al., 2015" startWordPosition="303" endWordPosition="306">2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any “real world” population, aside from social media itself. Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015). This paper examines the effects of these biases on the geo-linguistic inferences that can be drawn from Twitter. We focus on the ten largest metropolitan areas in the United States, and consider three sampling techniques: drawing an equal number of GPS-tagged tweets from each area; drawing a county-balanced sample of GPS-tagged messages to correct Twitter’s urban skew (Hecht and Stephens, 2014); and drawing a sample of location-annotated messages, using the location field in the user profile. Leveraging self-reported first names and census statistics, we show that the age and gender composit</context>
<context position="30496" citStr="Malik et al. (2015)" startWordPosition="4809" endWordPosition="4812">illien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model. These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on geotagged messages, nor the consequences for geo-linguistic analysis. Twitter has often been used to study the geographical distribution of linguistic information, and of particular relevance are Twitter-based studies of regiona</context>
</contexts>
<marker>Malik, Lamba, Nakos, Pfeffer, 2015</marker>
<rawString>Momin Malik, Hemank Lamba, Constantine Nakos, and J¨urgen Pfeffer. 2015. Population bias in geotagged tweets. In Papers from the 2015 ICWSM Workshop on Standards and Practices in LargeScale Social Media Research, pages 18–27. The AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Mislove</author>
<author>Sune Lehmann</author>
<author>Yong-Yeol Ahn</author>
<author>JukkaPekka Onnela</author>
<author>J Niels Rosenquist</author>
</authors>
<title>Understanding the demographics of twitter users.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Web and Social Media (ICWSM),</booktitle>
<pages>554--557</pages>
<publisher>AAAI Publications.</publisher>
<location>Menlo Park, California.</location>
<contexts>
<context position="1961" citStr="Mislove et al., 2011" startWordPosition="289" endWordPosition="293">tyles and dialects (Eisenstein et al., 2010; Gonc¸alves and S´anchez, 2014), political opinions (Caldarelli et al., 2014), and public health (Broniatowski et al., 2013). Social media permits the aggregation of datasets that are orders of magnitude larger than could be assembled via traditional survey techniques, enabling analysis that is simultaneously fine-grained and global in scale. Yet social media is not a representative sample of any “real world” population, aside from social media itself. Using social media as a sample therefore risks introducing both geographic and demographic biases (Mislove et al., 2011; Hecht and Stephens, 2014; Longley et al., 2015; Malik et al., 2015). This paper examines the effects of these biases on the geo-linguistic inferences that can be drawn from Twitter. We focus on the ten largest metropolitan areas in the United States, and consider three sampling techniques: drawing an equal number of GPS-tagged tweets from each area; drawing a county-balanced sample of GPS-tagged messages to correct Twitter’s urban skew (Hecht and Stephens, 2014); and drawing a sample of location-annotated messages, using the location field in the user profile. Leveraging self-reported first </context>
<context position="11086" citStr="Mislove et al., 2011" startWordPosition="1732" endWordPosition="1735">imes more frequent in Twitter than in the social security database), thereby omitting 33% of user accounts, and 34% of tweets. While some individuals will choose names not typically associated with their gender, we assume that this will happen with roughly equal probability in both directions. So, with these caveats in mind, we induce the age distribution for the GPSMSA-BALANCED sample and the LOC-MSABALANCED sample as, = count(name = n, age = a) (1) p(a |name = n) Lia, count(name = n, age = a&apos;) �pD(a) ∝ p(a |name = ni). (2) iED We induce distributions over author gender in much the same way (Mislove et al., 2011). This method does not incorporate prior information about the ages of Twitter users, and thus assigns too much probability to the extremely young and old, who are unlikely to use the service. While it would be easy to design such a prior — for example, assigning zero prior probability to users under the age of five or above the age of 95 — we see no principled basis for determining these cutoffs. We therefore focus on the differences between the estimated pD(a) for each sample D. 2140 MSA Num. L1 Dist. L1 Dist. Counties Population Population vs. Users vs. Tweets New York 23 0.2891 0.2825 Los </context>
<context position="30269" citStr="Mislove et al., 2011" startWordPosition="4775" endWordPosition="4778">miliar and well-understood method of logistic regression. 6 Related Work Several researchers have studied how adoption of Internet technology varies with factors such as socioeconomic status, age, gender, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use census demographics in spatial error model. These papers draw similar conclusions, showing that the the distribution of geotagged tweets over the US population is not random, and that higher usage is correlated with urban areas, high income, more ethnic minorities, and more young people. However, this prior work did not consider the biases introduced by relying on g</context>
</contexts>
<marker>Mislove, Lehmann, Ahn, Onnela, Rosenquist, 2011</marker>
<rawString>Alan Mislove, Sune Lehmann, Yong-Yeol Ahn, JukkaPekka Onnela, and J. Niels Rosenquist. 2011. Understanding the demographics of twitter users. In Proceedings of the International Conference on Web and Social Media (ICWSM), pages 554–557, Menlo Park, California. AAAI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burt L Monroe</author>
<author>Michael P Colaresi</author>
<author>Kevin M Quinn</author>
</authors>
<title>Fightin’words: Lexical feature selection and evaluation for identifying the content of political conflict.</title>
<date>2008</date>
<journal>Political Analysis,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="16902" citStr="Monroe et al. (2008)" startWordPosition="2669" endWordPosition="2672">easure the differences between the linguistic corpora obtained by each data acquisition approach. Since the GPS-MSA-BALANCED and GPS-COUNTYBALANCED methods have nearly identical patterns of usage and demographics, we focus on the difference between GPS-MSA-BALANCED and LOC-MSA-BALANCED. These datasets differ in age and gender, so we also directly measure the impact of these demographic factors on the use of geographically-specific linguistic variables. 4.1 Methods Discovering geographical linguistic variables We focus on lexical variation, which is relatively easy to identify in text corpora. Monroe et al. (2008) survey a range of alternative statistics for finding lexical variables, demonstrating that a regularized log-odds ratio strikes a good balance between distinctiveness and robustness. A similar approach is implemented in SAGE (Eisenstein et al., 2011a)2, which we use here. For each sam2https://github.com/jacobeisenstein/jos-gender-2014 ple — GPS-MSA-BALANCED and LOC-MSABALANCED — we apply SAGE to identify the twenty-five most salient lexical items for each metropolitan area. Keyword annotation Previous research has identified two main types of geographical lexical variables. The first are non-</context>
</contexts>
<marker>Monroe, Colaresi, Quinn, 2008</marker>
<rawString>Burt L Monroe, Michael P Colaresi, and Kevin M Quinn. 2008. Fightin’words: Lexical feature selection and evaluation for identifying the content of political conflict. Political Analysis, 16(4):372–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong Nguyen</author>
<author>Dolf Trieschnigg</author>
<author>A Seza Dogru¨oz</author>
<author>Rilana Gravel</author>
<author>Mari¨et Theune</author>
<author>Theo Meder</author>
<author>Franciska de Jong</author>
</authors>
<title>Why gender and age prediction from tweets is hard: Lessons from a crowdsourcing experiment.</title>
<date>2014</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1950--1961</pages>
<marker>Nguyen, Trieschnigg, Dogru¨oz, Gravel, Theune, Meder, de Jong, 2014</marker>
<rawString>Dong Nguyen, Dolf Trieschnigg, A Seza Dogru¨oz, Rilana Gravel, Mari¨et Theune, Theo Meder, and Franciska de Jong. 2014. Why gender and age prediction from tweets is hard: Lessons from a crowdsourcing experiment. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 1950–1961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Jacob Eisenstein</author>
<author>Eric P Xing</author>
<author>Noah A Smith</author>
</authors>
<title>A mixture model of demographic lexical variation.</title>
<date>2010</date>
<booktitle>In Proceedings of NIPS Workshop on Machine Learning for Social Computing,</booktitle>
<location>Vancouver.</location>
<marker>O’Connor, Eisenstein, Xing, Smith, 2010</marker>
<rawString>Brendan O’Connor, Jacob Eisenstein, Eric P. Xing, and Noah A. Smith. 2010. A mixture model of demographic lexical variation. In Proceedings of NIPS Workshop on Machine Learning for Social Computing, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pew Research Center</author>
</authors>
<title>Social networking popular across globe.</title>
<date>2012</date>
<tech>Technical report,</tech>
<contexts>
<context position="33911" citStr="Center, 2012" startWordPosition="5350" endWordPosition="5351">ant. This paper uncovers demographic confounds in the linguistic analysis of geo-located Twitter data, but is limited to demographics that can be readily induced from given names. A key task for future work is to quantify the representativeness of geotagged Twitter data with respect to factors such as race and socioeconomic status, while holding geography constant. However, these features may be more difficult to impute from names alone. Another crucial task is to expand this investigation beyond the United States, as the varying patterns of use for social media across countries (Pew Research Center, 2012) implies that the findings here cannot be expected to generalize to every international context. Acknowledgments Thanks to the anonymous reviewers for their useful and constructive feedback on our submission. The following members of the Georgia Tech Computational Linguistics Laboratory offered feedback throughout the research process: Naman Goyal, Yangfeng Ji, Vinodh Krishan, Ana Smith, Yijie Wang, and Yi Yang. This research was supported by the National Science Foundation under awards IIS-1111142 and RI-1452443, by the National Institutes of Health under award number R01GM112697-01, and by t</context>
</contexts>
<marker>Center, 2012</marker>
<rawString>Pew Research Center. 2012. Social networking popular across globe. Technical report, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Poblete</author>
<author>Ruth Garcia</author>
<author>Marcelo Mendoza</author>
<author>Alejandro Jaimes</author>
</authors>
<title>Do all birds tweet the same? characterizing Twitter around the world.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>1025--1030</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="6635" citStr="Poblete et al., 2011" startWordPosition="1019" endWordPosition="1022">an the core itself. For example, the Atlanta MSA is centered on Fulton County (1750 people per square mile), but extends to Haralson County (100 people per square mile), on the border of Alabama. A per-county analysis of this data therefore enables us to assess the degree to which Twitter’s skew towards urban areas biases geo-linguistic analysis. 3 Representativeness of geotagged Twitter data We first assess potential biases in sampling techniques for obtaining geotagged Twitter data. In particular, we compare two possible techniques for obtaining data: the location field in the user profile (Poblete et al., 2011; Dredze et al., 2013), and the GPS coordinates attached to each message (Cheng et al., 2010; Eisenstein et al., 2010). 3.1 Methods To build a dataset of GPS-tagged messages, we extracted the GPS latitude and longitude coordinates reported in the tweet, and used GIS-TOOLS1 reverse geocoding to identify the corresponding counties. This set of geotagged messages will be denoted DG. Only 1.24% of messages contain geo-coordinates, and it is possible that the individuals willing to share their GPS comprise a skewed population. We therefore also considered the userreported location field in the Twit</context>
</contexts>
<marker>Poblete, Garcia, Mendoza, Jaimes, 2011</marker>
<rawString>Barbara Poblete, Ruth Garcia, Marcelo Mendoza, and Alejandro Jaimes. 2011. Do all birds tweet the same? characterizing Twitter around the world. In Proceedings of the International Conference on Information and Knowledge Management (CIKM), pages 1025–1030. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>David Yarowsky</author>
<author>Abhishek Shreevats</author>
<author>Manaswi Gupta</author>
</authors>
<title>Classifying latent user attributes in twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of Workshop on Search and mining user-generated contents.</booktitle>
<contexts>
<context position="20708" citStr="Rao et al., 2010" startWordPosition="3302" endWordPosition="3305">ely simple approach here, assuming no labeled data for demographic attributes. 4.2 Results Linguistic differences by dataset We first consider the impact of the data acquisition technique on the lexical features associated with each city. The keywords identified in GPS-MSABALANCED dataset feature more geographicallyspecific non-standard words, which occur at a rate of 3.9 x 10−4 in GPS-MSA-BALANCED, versus 2.6 x 10−4 in LOC-MSA-BALANCED; this difference is statistically significant (p &lt; .05, t = 3.2).4 3Binning is often employed in work on text-based age prediction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosenthal and McKeown, 2011); it enables word and name counts to be shared over multiple ages, and avoids the complexity inherent in regressing a high-dimensional textual predictors against a numerical variable. 4We employ a paired t-test, comparing the difference in frequency for each word across the two datasets. Since we cannot test the complete set of entity names or non-standard words, this quantifies whether the observed difference is robust across the subset of the vocabulary that we have selected. (a) non-standard words (b) entity names Figure 5: Aggregate statistics for geographical</context>
</contexts>
<marker>Rao, Yarowsky, Shreevats, Gupta, 2010</marker>
<rawString>Delip Rao, David Yarowsky, Abhishek Shreevats, and Manaswi Gupta. 2010. Classifying latent user attributes in twitter. In Proceedings of Workshop on Search and mining user-generated contents.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Roller</author>
<author>Michael Speriosu</author>
<author>Sarat Rallapalli</author>
<author>Benjamin Wing</author>
<author>Jason Baldridge</author>
</authors>
<title>Supervised text-based geolocation using language models on an adaptive grid.</title>
<date>2012</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>1500--1510</pages>
<contexts>
<context position="17721" citStr="Roller et al., 2012" startWordPosition="2792" endWordPosition="2795">ach is implemented in SAGE (Eisenstein et al., 2011a)2, which we use here. For each sam2https://github.com/jacobeisenstein/jos-gender-2014 ple — GPS-MSA-BALANCED and LOC-MSABALANCED — we apply SAGE to identify the twenty-five most salient lexical items for each metropolitan area. Keyword annotation Previous research has identified two main types of geographical lexical variables. The first are non-standard words and spellings, such as hella and yinz, which have been found to be very frequent in social media (Eisenstein, 2015). Other researchers have focused on the “long tail” of entity names (Roller et al., 2012). A key question is the relative importance of these two variable types, since this would decide whether geo-linguistic differences are primarily topic-based or stylistic. It is therefore important to know whether the frequency of these two variable types depends on properties of the sample. To test this, we take the lexical items identified by SAGE (25 per MSA, for both the GPS-MSA-BALANCED and LOCMSA-BALANCED samples), and annotate them as NONSTANDARD-WORD, ENTITY-NAME, or OTHER. Annotation for ambiguous cases is based on the majority sense in randomly-selected examples. Overall, we identify</context>
<context position="27374" citStr="Roller et al., 2012" startWordPosition="4325" endWordPosition="4328">these text-based geolocation methods are most and least accurate. 5.1 Methods Our data is drawn from the ten largest metropolitan areas in the United States, and we formulate text-based geolocation as a ten-way classification problem, similar to Han et al. (2014).6 Using our 6Many previous papers have attempted to identify the precise latitude and longitude coordinates of individual authors, but obtaining high accuracy on this task involves much more complex methods, such as latent variable models (Eisenstein et al., 2010; Hong et al., 2012), or multilevel grid structures (Cheng et al., 2010; Roller et al., 2012). Tuning such 2144 user-balanced samples, we apply ten-fold cross validation, and tune the regularization parameter on a development fold, using the vocabulary of the sample as features. 5.2 Results Many author-attribute prediction tasks become substantially easier as more data is available (Burger et al., 2011), and text-based geolocation is no exception. Since GPS-MSABALANCED and LOC-MSA-BALANCED have very different usage rates (Figure 2), perceived differences in accuracy may be purely attributable to the amount of data available per user, rather than to users in one group being inherently </context>
</contexts>
<marker>Roller, Speriosu, Rallapalli, Wing, Baldridge, 2012</marker>
<rawString>Stephen Roller, Michael Speriosu, Sarat Rallapalli, Benjamin Wing, and Jason Baldridge. 2012. Supervised text-based geolocation using language models on an adaptive grid. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 1500–1510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Kathleen McKeown</author>
</authors>
<title>Age prediction in blogs: A study of style, content, and online behavior in pre- and Post-Social media generations.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>763--772</pages>
<location>Portland, OR.</location>
<contexts>
<context position="20738" citStr="Rosenthal and McKeown, 2011" startWordPosition="3306" endWordPosition="3310">h here, assuming no labeled data for demographic attributes. 4.2 Results Linguistic differences by dataset We first consider the impact of the data acquisition technique on the lexical features associated with each city. The keywords identified in GPS-MSABALANCED dataset feature more geographicallyspecific non-standard words, which occur at a rate of 3.9 x 10−4 in GPS-MSA-BALANCED, versus 2.6 x 10−4 in LOC-MSA-BALANCED; this difference is statistically significant (p &lt; .05, t = 3.2).4 3Binning is often employed in work on text-based age prediction (Garera and Yarowsky, 2009; Rao et al., 2010; Rosenthal and McKeown, 2011); it enables word and name counts to be shared over multiple ages, and avoids the complexity inherent in regressing a high-dimensional textual predictors against a numerical variable. 4We employ a paired t-test, comparing the difference in frequency for each word across the two datasets. Since we cannot test the complete set of entity names or non-standard words, this quantifies whether the observed difference is robust across the subset of the vocabulary that we have selected. (a) non-standard words (b) entity names Figure 5: Aggregate statistics for geographicallyspecific non-standard words </context>
</contexts>
<marker>Rosenthal, McKeown, 2011</marker>
<rawString>Sara Rosenthal and Kathleen McKeown. 2011. Age prediction in blogs: A study of style, content, and online behavior in pre- and Post-Social media generations. In Proceedings of the Association for Computational Linguistics (ACL), pages 763–772, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thamar Solorio</author>
<author>Yang Liu</author>
</authors>
<title>Learning to predict code-switching points.</title>
<date>2008</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>973--981</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, HI,</location>
<contexts>
<context position="5558" citStr="Solorio and Liu, 2008" startWordPosition="844" endWordPosition="847">tain the “retweeted status” metadata or “RT” token which is widely used among Twitter users to indicate a retweet. To eliminate spam and automated accounts (Yardi et al., 2009), we removed tweets containing URLs, user accounts with more than 1000 followers or followees, accounts which have tweeted more than 5000 messages at the time of data collection, and the top 10% of accounts based on number of messages in our dataset. We also removed users who have written more than 10% of their tweets in any language other than English, using Twitter’s lang metadata field. Exploration of code-switching (Solorio and Liu, 2008) and the role of second-language English speakers (Eleta and Golbeck, 2014) is left for future work. We consider the ten largest Metropolitan Statistical Areas (MSAs) in the United States, listed in Table 1. MSAs are defined by the U.S. Census Bureau as geographical regions of high population with density organized around a single urban core; they are not legal administrative divisions. MSAs include outlying areas that may be substantially less urban than the core itself. For example, the Atlanta MSA is centered on Fulton County (1750 people per square mile), but extends to Haralson County (10</context>
</contexts>
<marker>Solorio, Liu, 2008</marker>
<rawString>Thamar Solorio and Yang Liu. 2008. Learning to predict code-switching points. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 973–981, Honolulu, HI, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svitlana Volkova</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Online bayesian models for personal analytics in social media.</title>
<date>2015</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>2325--2331</pages>
<marker>Volkova, Van Durme, 2015</marker>
<rawString>Svitlana Volkova and Benjamin Van Durme. 2015. Online bayesian models for personal analytics in social media. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 2325– 2331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Wing</author>
<author>Jason Baldridge</author>
</authors>
<title>Simple supervised document geolocation with geodesic grids.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>955--964</pages>
<location>Portland, OR.</location>
<contexts>
<context position="25762" citStr="Wing and Baldridge, 2011" startWordPosition="4069" endWordPosition="4072">uch’), ight (’alright’), oomf (’one of my followers’). Older authors write more about local entities (manhattan, nyc, houston), with men focusing on sports-related entities (harden, watt, astros, mets, texans), and women above the age of 40 emphasizing religiously-oriented terms (proverb, islam, rejoice, psalm). 5But see Bamman et al. (2014) for a much more detailed discussion of gender and standardness. 5 Impact on text-based geolocation A major application of geotagged social media is to predict the geolocation of individuals based on their text (Eisenstein et al., 2010; Cheng et al., 2010; Wing and Baldridge, 2011; Hong et al., 2012; Han et al., 2014). Text-based geolocation has obvious commercial implications for location-based marketing and opinion analysis; it is also potentially useful for researchers who want to measure geographical phenomena in social media, and wish to access a larger set of individuals than those who provide their locations explicitly. Previous research has obtained impressive accuracies for text-based geolocation: for example, Hong et al. (2012) report a median error of 120 km, which is roughly the distance from Los Angeles to San Diego, in a prediction space over the entire c</context>
</contexts>
<marker>Wing, Baldridge, 2011</marker>
<rawString>Benjamin Wing and Jason Baldridge. 2011. Simple supervised document geolocation with geodesic grids. In Proceedings of the Association for Computational Linguistics (ACL), pages 955–964, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarita Yardi</author>
<author>Daniel Romero</author>
<author>Grant Schoenebeck</author>
</authors>
<title>Detecting spam in a twitter network.</title>
<date>2009</date>
<journal>First Monday,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="5112" citStr="Yardi et al., 2009" startWordPosition="770" endWordPosition="773">uistic consequences (§ 4), and the impact on text-based geolocation (§ 5); each of these sections begins with a discussion of methods, and then presents results. We then summarize related work and conclude. 2 Dataset This study is performed on a dataset of tweets gathered from Twitter’s streaming API from February 2014 to January 2015. During an initial filtering step we removed retweets, repetitions of previously posted messages which contain the “retweeted status” metadata or “RT” token which is widely used among Twitter users to indicate a retweet. To eliminate spam and automated accounts (Yardi et al., 2009), we removed tweets containing URLs, user accounts with more than 1000 followers or followees, accounts which have tweeted more than 5000 messages at the time of data collection, and the top 10% of accounts based on number of messages in our dataset. We also removed users who have written more than 10% of their tweets in any language other than English, using Twitter’s lang metadata field. Exploration of code-switching (Solorio and Liu, 2008) and the role of second-language English speakers (Eleta and Golbeck, 2014) is left for future work. We consider the ten largest Metropolitan Statistical </context>
</contexts>
<marker>Yardi, Romero, Schoenebeck, 2009</marker>
<rawString>Sarita Yardi, Daniel Romero, Grant Schoenebeck, et al. 2009. Detecting spam in a twitter network. First Monday, 15(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathryn Zickuhr</author>
</authors>
<title>Location-based services.</title>
<date>2013</date>
<tech>Technical report,</tech>
<institution>Pew Research Center, Septmeber.</institution>
<contexts>
<context position="15230" citStr="Zickuhr, 2013" startWordPosition="2420" endWordPosition="2421">LOCMSA-BALANCED, we plot the difference in age probabilities in Figure 3, showing that GPSMSA-BALANCED includes many more teens and people in their early twenties, while LOC-MSABALANCED includes more people at middle age and older. Young people are especially likely to use social media on cellphones (Lenhart, 2015), where location tagging would be more relevant than when Twitter is accessed via a personal computer. Social media users in the age brackets 18- 29 and 30-49 are also more likely to tag their locations in social media posts than social media users in the age brackets 50-64 and 65+ (Zickuhr, 2013), with women and men tagging at roughly equal rates. Table 2 shows that the GPS-MSABALANCED and GPS-COUNTY-BALANCED samples contain significantly more women than LOC1e4 Number of users in each category 0-2 2-5 5-10 10-15 &gt;15 Number of messages by a user Number of users 1.5 1.0 0.5 0.0 GPS-MSA-Balanced GPS-County-Balanced LOC-MSA-Balanced 2141 Sample Expected Age 95% CI % Female 95% CI GPS-MSA-BALANCED 36.17 [36.07 – 36.27] 51.5 [51.3 – 51.8] GPS-COUNTY-BALANCED 36.25 [36.16 – 36.30] 51.3 [51.1 – 51.6] LOC-MSA-BALANCED 38.35 [38.25 – 38.44] 49.3 [49.1 – 49.6] Table 2: Demographic statistics for</context>
</contexts>
<marker>Zickuhr, 2013</marker>
<rawString>Kathryn Zickuhr. 2013. Location-based services. Technical report, Pew Research Center, Septmeber.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Zillien</author>
<author>Eszter Hargittai</author>
</authors>
<title>Digital distinction: Status-specific types of internet usage*.</title>
<date>2009</date>
<journal>Social Science Quarterly,</journal>
<volume>90</volume>
<issue>2</issue>
<contexts>
<context position="29904" citStr="Zillien and Hargittai, 2009" startWordPosition="4720" endWordPosition="4723"> § 4, older male users tend to mention many entities, particularly sports-related terms; these terms are apparently more predictive than the non-standard spellings and slang favored by younger authors. models can be challenging, and the resulting accuracies might be affected by initial conditions or hyperparameters. We therefore focus on classification, employing the familiar and well-understood method of logistic regression. 6 Related Work Several researchers have studied how adoption of Internet technology varies with factors such as socioeconomic status, age, gender, and living conditions (Zillien and Hargittai, 2009). Hargittai and Litt (2011) use a longitudinal survey methodology to compare the effects of gender, race, and topics of interest on Twitter usage among young adults. Geographic variation in Twitter adoption has been considered both internationally (Kulshrestha et al., 2012) and within the United States, using both the Twitter location field (Mislove et al., 2011) and per-message GPS coordinates (Hecht and Stephens, 2014). Aggregate demographic statistics of Twitter users’ geographic census blocks were computed by O’Connor et al. (2010) and Eisenstein et al. (2011b); Malik et al. (2015) use cen</context>
</contexts>
<marker>Zillien, Hargittai, 2009</marker>
<rawString>Nicole Zillien and Eszter Hargittai. 2009. Digital distinction: Status-specific types of internet usage*. Social Science Quarterly, 90(2):274–291.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>