<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011770">
<title confidence="0.883649">
Sieve-Based Spatial Relation Extraction with Expanding Parse Trees
</title>
<author confidence="0.963117">
Jennifer D’Souza and Vincent Ng
</author>
<affiliation confidence="0.983457">
Human Language Technology Research Institute
University of Texas at Dallas
</affiliation>
<address confidence="0.900607">
Richardson, TX 75083-0688
</address>
<email confidence="0.998627">
fjld082000,vincel@hlt.utdallas.edu
</email>
<sectionHeader confidence="0.99738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999871666666667">
A key challenge introduced by the re-
cent SpaceEval shared task on spatial re-
lation extraction is the identification of
MOVELINKs, a type of spatial relation in
which up to eight spatial elements can
participate. To handle the complexity of
extracting MOVELINKs, we combine two
ideas that have been successfully applied
to information extraction tasks, namely
tree kernels and multi-pass sieves, propos-
ing the use of an expanding parse tree
as a novel structured feature for train-
ing MOVELINK classifiers. Our approach
yields state-of-the-art results on two key
tasks in SpaceEval.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971826086957">
Spatial relation extraction is the task of determin-
ing the relation among a set of spatial elements.
Although it has thus far received much less atten-
tion than temporal relation extraction, there has
been a surge of interest in it in recent years, as
evidenced by the organization of the three shared
tasks on spatial relation extraction, namely the
spatial role labeling tasks in 2012 (Kordjamshidi
et al., 2012) and 2013 (Kolomiyets et al., 2013),
as well as this year’s SpaceEval task (Pustejovsky
et al., 2015). The task has also evolved over the
years, with new types of spatial elements and/or
spatial relations being defined in each shared task.
For instance, while the first two shared tasks have
focused on extracting spatial relations between
stationary objects, SpaceEval examines for the
first time spatial relations on objects in motion.
Extracting spatial relations on objects in mo-
tion, or MOVELINKs, is very challenging. The
challenge stems in part from the fact that a
MOVELINK involves two mandatory participants
(with roles mover and trigger) and up to six op-
tional participants (with other semantic roles). As
</bodyText>
<figureCaption confidence="0.999533">
Figure 1: A MOVELINK example.
</figureCaption>
<bodyText confidence="0.999946638888889">
an example, consider the MOVELINK that can be
extracted from the sentence “John walked from
Boston to Cambridge”. As shown in Figure 1, this
MOVELINK involves six spatial elements: “John”
as the mover, “walked” as the trigger, “Boston”
as the source, “Cambridge” as the goal, and
“from” and “to” as the motion signals.
Given the complexity of MOVELINKs, any ap-
proach that attempts to jointly identify all the spa-
tial elements involved in a MOVELINK and their
roles is computationally infeasible. On the other
extreme, one can tackle the task by identifying
each element involved in a MOVELINK indepen-
dently of the other elements. In fact, this is roughly
the approach adopted by our participating sys-
tem in SpaceEval (D’Souza and Ng, 2015), which
achieved the best results in one of the SpaceE-
val tasks involving MOVELINK extraction. Specif-
ically, this system trains one classifier for each
optional role r to identify the filler for r in a
MOVELINK independently of the other optional
roles. Although this approach has achieved state-
of-the-art performance, it is arguably not ideal: in-
tuitively, dependencies exist among elements of
different roles, and not capturing them may harm
system performance.
Our goal in this paper is to advance the state
of the art in spatial relation extraction, focusing
on the extraction of MOVELINKs by addressing
the aforementioned weakness. The key question
is: how can we capture the dependencies among
the spatial elements involved without sacrificing
computational tractability? To address this ques-
tion, we combine two ideas that have been suc-
cessfully applied to a variety of information ex-
traction tasks, namely multi-pass sieves (Raghu-
</bodyText>
<page confidence="0.961374">
758
</page>
<note confidence="0.98702">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 758–768,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.995056288888889">
nathan et al., 2010; Lee et al., 2013) and tree
kernels (Moschitti, 2004; Moschitti, 2006). Re-
call that a sieve-based approach is composed of a
pipeline of sieves ordered by precision, where the
decisions made by earlier sieves can be exploited
by later sieves in order to incrementally construct
a complex structure. When applied to MOVELINK
identification, we can create a sieve for identifying
each role, so that (1) spatial elements correspond-
ing to different roles are incrementally added to a
MOVELINK, and (2) earlier attachment decisions
can be exploited as additional contextual informa-
tion by later sieves. Hence, compared to a joint
approach, a sieve-based approach achieves com-
putational tractability by modeling partial, rather
thanfull dependencies among the spatial elements.
While a sieve-based approach allows us to ex-
ploit additional contextual information provided
by earlier sieves, we still have to specify how we
encode such contextual information. Motivated by
the successful application of tree kernels to rela-
tion extraction (e.g., Zelenko et al. (2003), Cu-
lotta and Sorensen (2004), Bunescu and Mooney
(2005), Zhou et al. (2007)), we propose to (1)
encode the syntactic context in which the spa-
tial elements extracted by the sieves appear us-
ing a syntactic parse tree, and then (2) employ the
tree as an (additional) structured feature for train-
ing the classifier associated with each sieve. This
novel combination of sieves and tree-based struc-
tured features results in what we call an expand-
ing parse tree. Specifically, as a spatial element
for a MOVELINK is extracted by a (role-specific)
sieve, it will be added to the structured feature for
the classifier associated with the following sieve.
In other words, the parse tree corresponding to
the structured feature will keep expanding as we
move along the sieves in the pipeline. This con-
trasts with previous applications of tree kernels,
where a structured feature is created from a static
parse subtree for extracting exactly two arguments
involved in a relation. To our knowledge, this is
the first attempt to combine sieves and parse trees
to create expanding trees to extract complex rela-
tions involving multiple arguments.
</bodyText>
<sectionHeader confidence="0.939333" genericHeader="introduction">
2 Corpus and Task Definition
</sectionHeader>
<bodyText confidence="0.9998695">
In this section, we introduce our corpus and the
spatial relation extraction task. Owing to space
limitations, we will only discuss those aspects that
are relevant to the SpaceEval tasks we focus on.
</bodyText>
<subsectionHeader confidence="0.997889">
2.1 The SpaceEval Corpus
</subsectionHeader>
<bodyText confidence="0.999924235294118">
We use as our corpus the SpaceEval training cor-
pus, which is a subset of ISO-SpaceBank (Puste-
jovsky and Yocum, 2013). The corpus consists
of 59 travel narratives annotated with seven types
of spatial elements (Table 1) and three types of
spatial relations (Table 2), following the ISO-
Space (2012) annotation specifications. Different
types of spatial elements have different attributes.
The only attribute that is relevant to our work is
semantic type, which is one of the attributes of a
spatial entity. Semantic type expresses the type of
the relation it triggers and can take one of three
values: topological, directional, or both.
What is missing in Table 2 about spatial rela-
tions is that each element participating in a re-
lation has a role. Each QSLINK/OLINK involves
exactly three elements participating as trajector
(the object of interest), landmark (the ground-
ing location), and trigger (the relation indicator).
On the other hand, a MOVELINK has two fixed
participants and up to six optional participants.
The two mandatory MOVELINK participants are
mover (object in motion) and trigger (verb de-
noting motion). Five of the optional participants
express different aspects of the mover in space,
namely, source (the spatial element at the begin-
ning of the motion path), midpoint (the spatial
elements along the motion path), goal (the spatial
element at the end of the motion path), path (the
spatial element that reflects the path of motion),
and landmark (the grounding location). The
sixth optional participant, motion signal, con-
nects the spatial aspect to the mover. Note that
all spatial relations are intra-sentential.
</bodyText>
<subsectionHeader confidence="0.99977">
2.2 The Spatial Relation Extraction Task
</subsectionHeader>
<bodyText confidence="0.999920714285714">
Given a set of n spatial elements, the spatial rela-
tion extraction task aims to (1) determine whether
the elements form a spatial relation of a par-
ticular type, and if so, (2) classify the roles of
each participating element. For example, from
the sentence “The cup is on the table”, two re-
lations can be extracted: QSLINK(cuptrajector,
tablelandmark, ontrigger) and OLINK(cuptrajector,
tablelandmark, ontrigger). As another exam-
ple, from the sentence “John walked from
Boston to Cambridge”, a MOVELINK with partici-
pants Johnmover, walkedtrigger, frommotion signal,
Bostonsource, tomotion signal, and Cambridgegoal
can be extracted.
</bodyText>
<page confidence="0.998085">
759
</page>
<table confidence="0.99932525">
Type Description
place A geographic entity or region (e.g., lakes, mountains) or an administrative entity (e.g., towns, countries)
path A location where the focus is on the potential for traversal (e.g., road)
spatial entity A spatially relevant entity that is neither a place nor a path (e.g., car)
non-motion event An event that does not involve movement but is directly related to another spatial element
motion event A species of event that involves movement (e.g., arrived)
motion signal A particle, preposition, verb, or adverb that encodes path or manner information about a motion event
spatial signal A preposition/prepositional phrase that reveals the relationship between two locations (e.g., north of)
</table>
<tableCaption confidence="0.992727">
Table 1: Seven types of spatial elements in SpaceEval.
</tableCaption>
<table confidence="0.999099">
Relation Description
QSLINK Exists between stationary spatial elements with a regional connection. E.g., in “The cup is on the table”, the
regions of “cup” and “table” are externally connected and hence they are involved in a QSLINK.
OLINK Exists between stationary spatial elements expressing their relative or absolute orientations. E.g., in the above
sentence, “cup” and “table” are involved in an OLINK, which conveys that “cup” is oriented above “table”.
MOVELINK Exists between spatial elements in motion. E.g., in “John walked from Boston to Cambridge”, there is a
MOVELINK involving mover “John”, motion verb “walked”, source “Boston”, and goal “Cambridge”.
</table>
<tableCaption confidence="0.997849">
Table 2: Three types of spatial relations in SpaceEval.
</tableCaption>
<sectionHeader confidence="0.999922" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999277689655172">
Broadly speaking, existing spatial relation extrac-
tion systems have adopted either a pipeline ap-
proach or a joint approach to these subtasks. Given
a set of spatial elements, a pipeline spatial relation
extraction system (1) extracts the triggers, (2) de-
termines whether a spatial relation exists between
each extracted trigger and each of the remaining
spatial elements, and (3) classifies the role of each
non-trigger in each pair of spatially-related ele-
ments (Kordjamshidi et al., 2011; Bastianelli et al.,
2013; Kordjamshidi and Moens, 2015).
The major weakness of pipeline approaches is
that errors in trigger identification can propagate
to the relation classification component, whose
errors can in turn propagate to the role labeling
component. To address this weakness, Roberts
et al. (2012; 2013) investigated joint approaches.
Given a set of spatial elements with an assign-
ment of roles to each element, a joint spatial re-
lation extraction system uses a binary classifier
to determine whether these elements form a spa-
tial relation with the roles correctly assigned to all
participating elements. In other words, the clas-
sifier will output a 1 if and only if (1) the ele-
ments in the set form a relation and (2) their roles
in the relation are correct. The systems participat-
ing in SpaceEval all seem to be in favor of joint
approaches (D’Souza and Ng, 2015; Nichols and
Botros, 2015; Salaberri et al., 2015).
</bodyText>
<sectionHeader confidence="0.990154" genericHeader="method">
4 Baseline System
</sectionHeader>
<bodyText confidence="0.995493764705882">
To ensure that we have a state-of-the-art baseline
system for spatial relation extraction, we employ
our SpaceEval participating system (D’Souza and
Ng, 2015), which achieved the best results on task
3a in the official SpaceEval evaluation.1
This Baseline system performs joint role la-
beling and relation classification using an ensem-
ble of classifiers. Specifically, it trains one clas-
sifier for extracting QSLINKs and OLINKs, and
seven classifiers for extracting MOVELINKs. Cre-
ating these eight classifiers permits (1) separating
the treatment of MOVELINKs from QSLINKs and
OLINKs (because the former involves objects in
motion while the latter involve stationary objects);
and (2) simplifying the extraction of MOVELINKs
(because its optional participants are extracted in-
dependently of each other by these classifiers).
</bodyText>
<subsectionHeader confidence="0.998923">
4.1 Training the Baseline Classifiers
</subsectionHeader>
<bodyText confidence="0.999802">
In this subsection, we describe how we train
the Baseline classifiers, which include one clas-
sifier for identifying QSLINKs and OLINKs (Sec-
tion 4.1.1) and seven classifiers for identifying
MOVELINKs (Section 4.1.2).
</bodyText>
<subsectionHeader confidence="0.553801">
4.1.1 The LINK Classifier
</subsectionHeader>
<bodyText confidence="0.994196384615385">
We collapse QSLINKs and OLINKs to a single re-
lation type, LINK, identifying these two types of
links using the LINK classifier. To understand why
we can do this, recall from Section 2.1 that in QS-
LINKs and OLINKs, the trigger has to be a spatial
signal element having a semantic type attribute. If
its semantic type is topological, it triggers a QS-
LINK; if it is directional, it triggers an OLINK; and
1Since the official annotated test data is not available to
us, we cannot compare our results with the shared task sys-
tems’ official results, but comparing against a state-of-the-art
baseline will enable us to determine whether our approach is
better than the best existing spatial relation extraction system.
</bodyText>
<page confidence="0.963711">
760
</page>
<bodyText confidence="0.951458814814815">
if it is both, it triggers both relation types. Hence,
if a LINK is identified by our classifier, we can sim-
ply use the semantic type of the relation’s trigger
to determine whether the relation is a QSLINK, an
OLINK, or both.
We create training instances for training a LINK
classifier as follows. Following the joint ap-
proach described above, we create one training
instance for each possible role labeling of each
triplet of distinct spatial elements in each sen-
tence in a training document. The role labels
assigned to the spatial elements in each triplet
are subject to the following constraints: (1) each
triplet contains a trajector, a landmark, and
a trigger; (2) neither the trajector nor the
landmark are of type spatial signal or motion
signal; and (3) the trigger is a spatial signal.
These role constraints are derived from the data
annotation scheme. Note that a LINK may have
at most one implicit participant. For instance, the
relation LINK(balloontrajector, uptrigger) extracted
from the sentence “The balloon went up” has an
implicit landmark. To allow for implicit partic-
ipants, from each training instance we have cre-
ated thus far, we create three additional training
instances, where exactly one of the three partici-
pants has the value IMPLICIT.
A training instance is labeled as positive if and
only if the elements in the triplet form a rela-
tion and their roles are correct. As an example,
for the QSLINK and OLINK sentence in Table 2,
exactly one positive instance, LINK(cuptrajector,
tablelandmark, ontrigger), will be created.
Each instance is represented using the 31 fea-
tures, which can be broadly divided into seven
types: lexical, grammatical, semantic, positional,
distance, entity attributes, and entity roles.2 We
train the LINK classifier using the SVM learning
algorithm as implemented in the SVMlight soft-
ware package (Joachims, 1999). To optimize clas-
sifier performance, we tune two parameters, the
regularization parameter C and the cost-factor pa-
rameter J, to maximize F-score on the develop-
ment data.3 Since joint tuning of these parameters
is computationally expensive, we employ a hill-
climbing algorithm to find a local maximum, al-
2Space limitations preclude a description of these fea-
tures. See D’Souza and Ng (2015) for details.
3C is chosen from the set {0.01, 0.05, 0.1, 0.5, 1.0, 10.0,
50.0, 100.01, and J is chosen from the set {0.01, 0.05, 0.1,
0.5, 1.0, 2.0, 4.0, 6.01. All other learning parameters are set
to their default values. In particular, a linear kernel is used.
tering one parameter at a time to optimize F-score
by holding the other parameter fixed.
</bodyText>
<subsubsectionHeader confidence="0.757408">
4.1.2 The Seven MOVELINK Classifiers
</subsubsectionHeader>
<bodyText confidence="0.999986791666667">
If we adopted the aforementioned joint method
as is for extracting MOVELINKs, each instance
would correspond to an octuple of the form
(triggeri, moverj, sourcek, midpointm, goaln,
landmarko, pathp, motion signalr), where
each participant in the octuple is either a dis-
tinct spatial element with a role or the NULL el-
ement (if it is not present in the relation). How-
ever, generating role permutations for octuples
from all spatial elements in a sentence is com-
putationally infeasible. For this reason, we sim-
plify MOVELINK extraction as follows. First,
we decompose the MOVELINK octuple into seven
smaller tuples including one pair and six triplets.
These seven tuples are: [1] (triggeri, moverj);
[2] (triggeri, moverj, sourcek); [3] (triggeri,
moverj, midpointm); [4] (triggeri, moverj,
goaln); [5] (triggeri, moverj, landmarko); [6]
(triggeri, moverj, pathp); and [7] (triggeri,
moverj, motion signalr). Then, we create seven
separate classifiers for identifying these seven
MOVELINK tuples, respectively.
Using this decomposition for MOVELINK in-
stances, we can generate instances for each clas-
sifier using the aforementioned joint approach as
is. For instance, to train classifier [1], we gener-
ate pairs of the form (triggeri, moverj), where
triggeri and moverj are spatial elements pro-
posed as a candidate trigger and a candidate
mover, respectively. Positive training instances
are those (triggeri, moverj) pairs annotated as
being part of a MOVELINK in the training data,
while the rest of the candidate pairs are negative
training instances. The instances for training the
remaining six classifiers are generated similarly.
As in the LINK classifier, we enforce global role
constraints when creating training instances for
the MOVELINK classifiers. Specifically, the roles
assigned to the spatial elements in each training
instance of each MOVELINK classifier are subject
to six constraints: (1) the trigger has type motion
event; (2) the mover has type place, path, spa-
tial entity, or non-motion event; (3) the source, the
goal, and the landmark can be NULL or have type
place, path, spatial entity, or non-motion event;
(4) the midpoint can be NULL or have type place,
path, or spatial entity; (5) the path can be NULL
or have type path; and (6) the motion signal can
</bodyText>
<page confidence="0.986621">
761
</page>
<bodyText confidence="0.999376826086957">
be NULL or have type motion signal.
Our method for decomposing the octuple by
role can be justified as follows. Since trigger and
mover are mandatory MOVELINK participants, we
have a classifier for classifying this core aspect
of a MOVELINK. The next six classifiers, [2]
to [7], aim to improve the core MOVELINK ex-
traction by exploiting the contextual dependencies
with each of its unique spatial aspects, namely
source, midpoint, goal, landmark, path, and
motion signal.
As an example, for the MOVELINK sentence
in Table 2, we will create three positive in-
stances: (Johnmover, walkedtrigger) for classi-
fier [1], (Johnmover, walkedtrigger, Bostonsource)
for classifier [2], and (Johnmover, walkedtrigger,
Cambridgegoal) for classifier [4].
We represent each training instance using the 31
features that were used to train the LINK classi-
fier. We train each of the MOVELINK classifiers
using SVMlight. We tune the C and J parameters
to maximize F-score on the development data us-
ing the hill-climbing algorithm described earlier.4
</bodyText>
<subsectionHeader confidence="0.998055">
4.2 Applying the Baseline Classifiers
</subsectionHeader>
<bodyText confidence="0.999672916666667">
After training, we apply the resulting classifiers to
classify the test instances, which are created in the
same way as the training instances. As noted be-
fore, each LINK extracted from a test document
by the LINK classifier is further qualified as QS-
LINK, OLINK, or both based on the semantic type
of its trigger. The MOVELINKs are extracted from
a test document by combining the outputs from the
seven MOVELINK classifiers.
There is a caveat, however: different
MOVELINK classifiers can make conflicting
decisions. For instance, classifier [1] might mis-
classify (Johnmover, walkedtrigger) as negative,
whereas classifier [2] might correctly classify
(Johnmover, walkedtrigger, Bostonsource) as pos-
itive. To resolve these conflicting decisions, we
give preference to positive decisions, meaning that
in this case we will posit “John” and “walked”
as having the roles of mover and trigger
respectively. There are two more sources of
conflicts. First, a spatial element may be assigned
different roles for a given MOVELINK by different
classifiers. Second, the global constraint that each
MOVELINK can have at most one source, at most
</bodyText>
<footnote confidence="0.961527">
4See Footnote 3 for the set of values of C and J used for
parameter tuning.
</footnote>
<bodyText confidence="0.999843">
one goal, and at most one landmark can be
violated. To resolve these conflicts, we select for
each spatial element the role that was predicted
with highest confidence by the SVM classifiers
subject to the global constraint.5
</bodyText>
<sectionHeader confidence="0.994967" genericHeader="method">
5 Our Multi-Pass Sieve Approach
</sectionHeader>
<bodyText confidence="0.9995335">
In this section, we describe two methods for em-
ploying sieves for extracting spatial relations.
</bodyText>
<subsectionHeader confidence="0.997407">
5.1 Using Sieves without Trees
</subsectionHeader>
<bodyText confidence="0.999983842105263">
To motivate our first method, recall that the Base-
line resolves conflicting decisions in a heuristic
manner. For instance, it prefers positive to nega-
tive decisions, effectively favoring recall over pre-
cision for spatial relation extraction. It is not
clear whether this ad-hoc decision is good or
not. As another example, when more than one
role is assigned to the same spatial element in a
MOVELINK, it favors the role associated with the
highest SVM confidence. This, however, is also
an ad-hoc decision: recall that each classifier’s pa-
rameters are tuned independently of the others, so
different confidence values assigned by different
classifiers are not directly comparable.
Employing sieves for spatial relation extrac-
tion obviates the need for such ad-hoc decisions.
In our implementation, we have eight sieves,
each of which corresponds to exactly one of the
eight classifiers employed by the Baseline. Re-
call from the introduction that these sieves are
ordered as a pipeline. So, whenever a con-
flict arises, earlier sieves’ decisions have prece-
dence over later sieves’ decisions. Returning
to the conflicting decisions mentioned before, if
sieve 1 misclassifies (Johnmover, walkedtrigger)
as negative, whereas sieve 2 correctly classifies
(Johnmover, walkedtrigger, Bostonsource) as posi-
tive, then we will posit that no MOVELINK exists
between “John” and “walked” because we have
more confidence in sieve 1’s decision than sieve
2’s decision. As another example, if two classi-
fiers assign different roles to the same spatial ele-
ment, then we will choose the role assigned by the
classifier associated with the earlier sieve.
Given the above discussion, it should be clear
that the ordering of the sieves is important. Typ-
ically, sieves are ordered by precision, with the
hope of reducing the number of erroneous deci-
</bodyText>
<footnote confidence="0.942921">
5We use the distance from the hyperplane as a measure of
an SVM classifier’s confidence.
</footnote>
<page confidence="0.988516">
762
</page>
<bodyText confidence="0.999933">
sions passed from the earlier sieves to the later
sieves (e.g., Raghunathan et al. (2010), Lee et al.
(2013), Chambers et al. (2014)). Motivated by this
observation, we order the sieves as follows. We
set sieve 0 to be the LINK classifier and sieve 1 to
be the (trigger, mover) classifier, and then order
the remaining sieves by precision. Specifically, we
compute the precision of each sieve on the devel-
opment data, then add sieves into the pipeline in
decreasing order of precision.
</bodyText>
<subsectionHeader confidence="0.999235">
5.2 Using Sieves with Trees
</subsectionHeader>
<bodyText confidence="0.999976794871795">
Next, we describe our second method for applying
sieves to spatial relation extraction. To motivate
this method, recall that one important property of
a sieve-based approach is that later sieves can ex-
ploit earlier sieves’ decisions when making their
own decisions. However, our first method of using
sieves makes limited use of the decisions made by
earlier sieves. In particular, while each sieve ex-
ploits the knowledge of whether a spatial element
has been assigned a role by an earlier sieve, it does
not exploit the knowledge of what the role is.
Our second method exploits the role decisions
made by earlier sieves, but another question arises:
how can we encode these role decisions so that
they can be best exploited by later sieves? One
possibility is to employ them as additional fea-
tures for training the classifiers associated with
later sieves. Motivated by previous work on tree
kernels for relation extraction, we employ parse
trees as a structured feature to encode the syntac-
tic relationships among the roles extracted so far
for a given MOVELINK.
We create the structured feature as follows. To
strike a better balance between having a rich repre-
sentation of the context surrounding a spatial rela-
tion and improving the learner’s ability to general-
ize, we extract a subtree from a parse tree and use
it as the value of the structured feature. Specif-
ically, given relation candidate triplet (e1,e2,e3),
where spatial elements e1, e2, and e3 are posited
in roles r1, r2, and r3, respectively, and the asso-
ciated syntactic parse tree T, we extract our parse
subtree from T as follows. First, we identify the
smallest subtree that covers all three spatial ele-
ments and call its root r. Second, for each path
from each spatial element to r, we include in the
parse subtree all the nodes that lie on the path
and their immediate children. Third, we simplify
the subtree by removing the POS nodes above
</bodyText>
<figure confidence="0.992144">
(a) (b)
</figure>
<figureCaption confidence="0.997874">
Figure 2: Syntactic parse trees for two example
sentences containing MOVELINKs.
</figureCaption>
<bodyText confidence="0.998081097560975">
each spatial element, effectively attaching it to its
grandparent. Finally, for better generalization, we
replace each spatial element with its role.
Since this subtree centers on a spatial relation,
we call it a spatial relation centered tree (SRCT).
As mentioned before, we will use SRCTs in com-
bination with our sieve-based approach. This re-
sults in a novel application of structured features:
to our knowledge, all trees that were previously
used as structured features were static. By con-
trast, SRCTs expand as we move along the sieve
pipeline. We will discuss examples of how to cre-
ate SRCTs below.
Creating training instances with structured fea-
tures is straightforward. Recall that a structured
feature is used as an additional feature when train-
ing each classifier. In other words, it will be
used in combination with the original 31 features.
The training instance creation method used by the
Baseline remains unchanged. All we need to do
is to add a SRCT as a structured feature to each
training instance.
Consider the sentence “John walked from
Boston to Cambridge”, whose parse tree is shown
in Figure 2(a). Since only one MOVELINK can
be extracted from it, only one positive training
instance will be created for each classifier. As-
sume that sieve 1 contains the (trigger, mover)
classifier; sieve 2 contains the (trigger, mover,
motion signal) classifier; and sieve 3 contains
the (trigger, mover, goal) classifier. Figure 3(a)
shows the SRCTs used in the corresponding posi-
tive instances, while Figure 3(b) shows the SRCTs
associated with randomly chosen negative in-
stances used to train the classifiers in these sieves.
To train a classifier on instances containing
the original 31 features and SRCTs, we employ
SVMlight−Tx (Moschitti, 2004; Moschitti, 2006),
which (1) trains an SVM classifier using the 31
features with a linear kernel; (2) trains an SVM
classifier using only the SRCTs with a convolution
</bodyText>
<page confidence="0.995">
763
</page>
<figure confidence="0.986630666666667">
(a) SRCTs associated with positive training instances in sieves
1, 2, and 3.
(a) SRCTs associated with correctly classified test instances in
sieves 1, 2, and 3.
(b) SRCTs associated with randomly chosen negative training
instances in sieves 1, 2, and 3.
</figure>
<figureCaption confidence="0.9747495">
Figure 3: SRCTs associated with training in-
stances created for the sentence in Figure 2a.
</figureCaption>
<bodyText confidence="0.977086">
kernel; and (3) combines these two kernels using a
composite kernel. Specifically, we define compos-
ite kernel K, for combining linear kernel Kl and
convolution kernel Kt as follows:
</bodyText>
<equation confidence="0.998664">
K,(F1,F2) = Kl(F1,F2) + T · Kt(T1,T2),
</equation>
<bodyText confidence="0.96648765625">
where F1 and F2 are the set of 31 features from
two training instances, T1 and T2 are their SRCTs,
and T is the combination parameter. We em-
ploy the hill-climbing algorithm described before
to tune the C, J and T parameters to maximize
F-score on the development data.6
The test instances with structured features are
created in the same way as the training instances,
with one notable difference. Note that roles are
used to create structured features. While they are
available in training, they are not available in the
test documents. Hence, to create SRCTs for a test
instance, we have to employ the roles predicted by
preceding sieves. This is precisely how we exploit
the role decisions made by earlier sieves in later
sieves. This also explains why the SRCTs expand:
more and more roles will be attached to a SRCT
as it passes through the sieve pipeline.
As an example, consider the test sentence “He
biked to Maine from Cambridge”, whose parse
tree is shown in Figure 2(b). Figure 4(a) shows
the SRCTs generated when each sieve makes the
correct decisions. Specifically, sieve 1 correctly
identifies “He” as the mover and “biked” as the
trigger. The roles (correctly) extracted by sieve 1
(shown in boxes) are incorporated into the SRCT
created in sieve 2. Similarly, the motion signals
6To tune T, we attempted values between 0 and 2 in in-
crements of 0.2. To tune C and J, we attempted the values
specified in Footnote 3.
(b) SRCTs associated with incorrectly classified test instances
in sieves 1, 2, and 3.
</bodyText>
<figureCaption confidence="0.959325">
Figure 4: SRCTs associated with test instances for
the sentence in Figure 2b.
</figureCaption>
<bodyText confidence="0.999982727272727">
(correctly) extracted by sieve 2 are incorporated
into the SRCT created in sieve 3. Figure 4(b)
shows the SRCTs generated for misclassified in-
stances. Assume that sieve 1 misclassifies the test
instance underlying the SRCT (as positive). As we
can see, this mistake is propagated to the SRCTs
generated in later sieves.
Note that the precision of a sieve may change
with the addition of SRCTs. For this reason, the
sieves need to be reordered using the algorithm de-
scribed in the previous subsection.
</bodyText>
<sectionHeader confidence="0.999503" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999685">
6.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.84415547826087">
SpaceEval tasks. We evaluate our approach in
tasks 1d and 3a of SpaceEval. These two tasks
evaluate a system’s ability to extract (trajector,
landmark, trigger) triplets in QSLINKs and
OLINKs as well as (trigger, mover) pairs in
MOVELINKs using gold spatial elements (1d) and
automatically extracted spatial elements (3a). To
extract the spatial elements needed for task 3a, we
follow Bastianelli et al.’s (2013) sequence labeling
approach, except that we train the sequence labeler
using a CRF rather than an HMM.7
Dataset. Since the annotated test set used in
SpaceEval’s official evaluation is not available
7We train two CRF models using CRF++ (https://
taku910.github.io/crfpp/), one to extract motion
signals and the other to extract the remaining six types of
spatial elements (see Table 1). The reason is that motion sig-
nal is the only type of spatial element that can overlap with
other types. When predicting spatial signals, we also pre-
dict their semantic types, since the LINK classifier needs this
attribute to distinguish between QSLINKs and OLINKs (see
Section 4.1.1). To increase recall, we use the 10-best outputs
returned by the CRFs as candidate spatial elements.
</bodyText>
<page confidence="0.990592">
764
</page>
<table confidence="0.994912">
QSLINK OLINK MOVELINK OVERALL
False True False True False True
R P F R P F R P F R P F R P F R P F R P F
Baseline 99.5 99.4 99.5 46.9 48.9 47.9 100 99.4 99.7 50.3 100 66.9 91.3 99.8 95.3 84.8 61.5 71.3 78.8 84.8 81.7
Sieve 99.5 99.4 99.5 46.9 48.9 47.9 100 99.4 99.7 50.3 100 66.9 94.7 99.8 97.2 79.4 72.1 75.5 78.5 86.6 82.3
+SRCTs 99.8 99.4 99.6 43.1 66.4 52.3 100 99.4 99.7 43.7 100 60.8 97.1 99.8 98.4 77.3 82.3 79.7 76.8 91.2 83.4
(a) Results obtained using gold spatial elements.
QSLINK OLINK MOVELINK OVERALL
False True False True False True
R P F R P F R P F R P F R P F R P F R P F
Baseline 99.8 99.9 99.9 28.5 11.5 16.4 100 99.9 100 31.2 100 47.5 92.3 50.0 64.9 54.0 17.1 26.0 67.6 63.1 65.3
Sieve 99.8 99.9 99.9 28.5 11.5 16.4 100 99.9 100 31.2 100 47.5 96.1 50.0 65.8 42.5 25.3 31.7 66.4 64.4 65.4
+ SRCTs 99.8 99.9 99.9 28.3 12.9 17.8 100 99.9 100 31.2 100 47.5 94.7 50.0 65.5 56.2 24.5 34.2 68.4 64.6 66.4
(b) Results obtained using extracted spatial elements.
</table>
<tableCaption confidence="0.999197">
Table 3: Results for extracting spatial relations.
</tableCaption>
<bodyText confidence="0.999905210526316">
to us at the time of writing, we conduct our
evaluation on the SpaceEval training corpus,
which contains 1890 spatial relations (886 QS-
LINKs, 225 OLINKs, and 779 MOVELINKs) and
1139 MOVELINK optional roles (95 sources, 65
midpoints, 310 goals, 77 landmarks, 100 paths,
and 492 motion signals). We partition the 59
narratives in the corpus into five folds and report
five-fold cross-validation results. In each fold ex-
periment, we employ three folds for training, one
fold for development, and one fold for testing.
Evaluation metrics. To evaluate the results for
the two SpaceEval tasks, we employ the official
SpaceEval scoring program, which reports results
in terms of recall, precision, and F-score on the
three types of spatial relations in isolation and in
combination. To evaluate the results for extracting
MOVELINK optional roles, we compute the recall,
precision, and F-score for each role.
</bodyText>
<subsectionHeader confidence="0.991684">
6.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999969411764706">
Tables 3a and 3b show the spatial relation ex-
traction results for three systems — the Base-
line (row 1), our Sieve approach without SRCTs
(row 2), and our Sieve approach with SRCTs
(row 3) — obtained using gold and extracted spa-
tial elements, respectively.
The official scoring program reports spatial re-
lation extraction results in terms of recall (R),
precision (P), and F-score (F). For QSLINKs
and OLINKs, it reports results on (1) extracting
spatially-related (trajector, landmark, trigger)
triplets (see the “True” columns) and (2) identify-
ing that no spatial relation exists among a (can-
didate trajector, candidate landmark, candidate
trigger) triplet (see the “False” columns). For
MOVELINKs, it reports results on (1) extracting
spatially-related (trigger, mover) pairs (see the
“True” columns) and (2) identifying that no spa-
tial relation exists between a (candidate trigger,
candidate mover) pair (see the “False” columns).
Since the pairs/triplets without links considerably
outnumber those with links, the OVERALL scores
are dominated by the performances on “False”,
which, as expected, are high.
Of particular interest are the MOVELINK scores
under the “True” columns. When gold spatial el-
ements are used, Sieve significantly outperforms
Baseline (p &lt; 0.001) owing to substantial gains
in precision with smaller losses in recall.8 Adding
SRCTs to Sieve further boosts performance signif-
icantly (p &lt; 0.005). As we can see, Sieve+SRCTs
outperforms Baseline by 8.4% absolute F-score on
extracting (trigger, mover) pairs. With respect
to the OVERALL score, which also takes into ac-
count QSLINKs and OLINKs, Sieve+SRCTs out-
performs Baseline significantly by 1.7% absolute
F-score. Similar trends can be observed for the
results obtained using extracted spatial elements.
Note that Baseline and Sieve have the same QS-
LINK and OLINK results because the LINK classi-
fier is associated with the first sieve.
Tables 4a and 4b show the results on extract-
ing MOVELINK optional roles using gold and
extracted spatial elements, respectively. When
gold elements are used, Sieve insignificantly out-
performs Baseline on source, midpoint, and
motion signal. When used with SRCTs, Sieve
insignificantly outperforms Baseline on source,
midpoint, path, and motion signal. Overall,
Sieve+SRCTs insignificantly outperforms Base-
line by 3.0% absolute F-score.9 While the results
</bodyText>
<footnote confidence="0.9976346">
8All statistical significance tests are paired t-tests, with p
set to 0.05 unless otherwise stated.
9A closer examination of the results reveals why the im-
provement is insignificant: since many roles occur infre-
quently in the corpus, the parameters learned from the devel-
</footnote>
<page confidence="0.984839">
765
</page>
<table confidence="0.993998833333333">
source midpoint goal landmark path motion-signal OVERALL
R P F R P F R P F R P F R P F R P F R P F
Baseline 34.7 37.1 35.9 43.1 26.9 33.1 46.1 73.7 56.8 19.5 31.9 24.2 44.0 62.0 51.5 72.6 67.4 69.9 54.4 59.9 57.0
Sieve 29.5 62.2 40.0 30.8 39.2 34.5 43.6 79.4 56.3 13.0 37.0 19.2 36.0 69.2 47.4 67.5 74.8 71.0 49.3 71.1 58.2
+SRCTs 23.2 100 37.6 30.8 71.4 43.0 41.3 85.3 55.7 5.2 66.7 9.6 40.0 85.1 54.4 64.0 84.5 72.8 46.5 84.5 60.0
(a) Results obtained using gold spatial elements.
source midpoint goal landmark path motion signal OVERALL
R P F R P F R P F R P F R P F R P F R P F
Baseline 25.3 12.0 16.3 35.4 8.9 14.3 38.7 15.2 21.8 18.2 2.5 4.4 14.0 12.9 13.4 27.7 24.0 25.7 29.1 13.3 18.2
Sieve 10.5 23.3 14.5 20.0 20.2 20.2 30.3 24.1 26.9 5.2 3.3 4.1 10.0 20.0 13.3 27.4 25.3 26.3 23.4 22.1 22.7
+ SRCTs 15.8 51.7 24.2 16.9 34.4 22.7 32.3 25.4 28.4 5.2 8.3 6.4 12.0 18.5 14.6 28.1 22.9 25.2 24.6 23.9 24.3
(b) Results obtained using extracted spatial elements.
</table>
<tableCaption confidence="0.998629">
Table 4: Results for extracting MOVELINK optional roles.
</tableCaption>
<bodyText confidence="0.997410769230769">
obtained using extracted elements exhibit different
trends, Sieve+SRCTs’s OVERALL improvement
of 6.1% absolute F-score over Baseline is signifi-
cant (p &lt; 0.001).
Table 5 shows the results of these systems on
extracting entire MOVELINKs, where a MOVELINK
is considered correctly extracted if all of its partic-
ipating elements and their roles are correct. Note
that none of the SpaceEval tasks employ this strin-
gent but informative evaluation measure. As we
can see, Sieve+SRCTs insignificantly outperforms
Baseline by 2.3–3.0% absolute F-score, regardless
of whether gold or extracted elements are used.
</bodyText>
<subsectionHeader confidence="0.947031">
6.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.97443692">
In this subsection, we analyze the errors made by
the best-performing system, Sieve+SRCTs, with
respect to the extraction of MOVELINKs given our
focus on this type of spatial relation.
Extracting (mover, trigger) pairs. The major
source of recall error stems from the system’s in-
ability to extract movers that are unseen in the
training data. This error could be addressed using
a named entity recognizer and WordNet categories
related to people, places, animals, etc. The major
source of precision error arises from missing gold
annotations. Consider the sentence “I found my-
self biking...” Our system correctly extracted “bik-
ing” as the trigger and “I” as the mover, but was
considered wrong because “myself”, not “I”, was
annotated as the mover in the gold standard.
Extracting optional roles. A major source of
recall/precision error stems from the system’s in-
ability to exploit contextual cues that are reli-
able indicators of a particular role. For instance,
a statistical analysis of the training data reveals
that sources are commonly preceded by prepo-
sitions such as “from” and “or”, whereas goals
opment data are not necessarily the same as those that yield
the best results on the test data.
</bodyText>
<table confidence="0.9989818">
Gold Extracted
R P F R P F
Baseline 40.6 50.4 45.0 21.7 15.3 18.0
Sieve 40.7 50.4 45.0 20.9 14.9 17.4
+ SRCTs 40.5 59.0 48.0 23.3 18.0 20.3
</table>
<tableCaption confidence="0.9396165">
Table 5: Results for extracting entire MOVELINKs
using gold and extracted elements.
</tableCaption>
<bodyText confidence="0.999768066666667">
are commonly associated with verbs such as “re-
turn”, “visit”, “arrive”, and “reach”. This prob-
lem could be addressed by encoding these cues
explicitly as additional features for training the
role-specific classifiers. Another source of recall
error can be attributed to the lack of background
knowledge. Consider the sentence “We had only
70 more km to Cluj taking this way, but if get-
ting back to Ciucea and on to Cluj the normal way
would have been 25 km longer”. Despite correctly
extracting “Cluj” as the goal, the system failed
to extract “Ciucea” as the midpoint. This prob-
lem could be alleviated by exploiting geographi-
cal knowledge concerning these cities in external
knowledge sources such as Wikipedia.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999996777777778">
We have examined the under-studied task of spa-
tial relation extraction, focusing on spatial rela-
tions of objects in motion. Our approach exploited
expanding parse trees, which resulted from a novel
combination of multi-pass sieves and tree ker-
nels, achieving state-of-the-art results on two key
SpaceEval tasks. To facilitate comparison with fu-
ture work on this task, we released the source code
of our spatial relation extraction system.10
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997827333333333">
We thank the three anonymous reviewers for their
comments. This work was supported in part by
NSF Grants IIS-1147644 and IIS-1219142.
</bodyText>
<footnote confidence="0.979789">
10See our website at http://www.hlt.utdallas.
edu/˜jld082000/spatial-relations/ for details.
</footnote>
<page confidence="0.997215">
766
</page>
<sectionHeader confidence="0.998326" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999865009433962">
Emanuele Bastianelli, Danilo Croce, Daniele Nardi,
and Roberto Basili. 2013. Unitor-HMM-TK: Struc-
tured kernel-based learning for spatial role labeling.
In Proceedings of the 7th International Workshop on
Semantic Evaluation, pages 573–579.
Razvan Bunescu and Raymond Mooney. 2005. A
shortest path dependency kernel for relation extrac-
tion. In Proceedings of Human Language Technol-
ogy Conference and Conference on Empirical Meth-
ods in Natural Language Processing, pages 724–
731.
Nathanael Chambers, Taylor Cassidy, Bill McDowell,
and Steven Bethard. 2014. Dense event ordering
with a multi-pass architecture. Transactions of the
Association for Computational Linguistics, 2:273–
284.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings
of the 42nd Meeting of the Association for Compu-
tational Linguistics, Main Volume, pages 423–429.
Jennifer D’Souza and Vincent Ng. 2015. UTD:
Ensemble-based spatial relation extraction. In Pro-
ceedings of the 9th International Workshop on Se-
mantic Evaluation, pages 862–869.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In Bernhard Scholkopf and
Alexander Smola, editors, Advances in Kernel Meth-
ods - Support Vector Learning, pages 44–56. MIT
Press.
Oleksandr Kolomiyets, Parisa Kordjamshidi, Steven
Bethard, and Marie-Francine Moens. 2013.
SemEval-2013 Task 3: Spatial role labeling. In Pro-
ceedings of the 7th International Workshop on Se-
mantic Evaluation, pages 255–266.
Parisa Kordjamshidi and Marie-Francine Moens.
2015. Global machine learning for spatial ontology
population. Web Semantics: Science, Services and
Agents on the World Wide Web, 30(C):3–21.
Parisa Kordjamshidi, Martijn Van Otterlo, and Marie-
Francine Moens. 2011. Spatial role labeling: To-
wards extraction of spatial relations from natural
language. ACM Transactions on Speech and Lan-
guage Processing, 8(3):4.
Parisa Kordjamshidi, Steven Bethard, and Marie-
Francine Moens. 2012. SemEval-2012 Task 3: Spa-
tial role labeling. In Proceedings of the 6th Inter-
national Workshop on Semantic Evaluation, pages
365–373.
Heeyoung Lee, Angel Chang, Yves Peirsman,
Nathanael Chambers, Mihai Surdeanu, and Dan Ju-
rafsky. 2013. Deterministic coreference resolu-
tion based on entity-centric, precision-ranked rules.
Computational Linguistics, 39(4):885–916.
Alessandro Moschitti. 2004. A study on convolution
kernels for shallow statistic parsing. In Proceedings
of the 42nd Meeting of the Association for Compu-
tational Linguistics, Main Volume, pages 335–342.
Alessandro Moschitti. 2006. Making tree kernels prac-
tical for natural language processing. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 113–120.
Eric Nichols and Fadi Botros. 2015. SpRL-
CWW: Spatial relation classification with indepen-
dent multi-class models. In Proceedings of the
9th International Workshop on Semantic Evaluation,
pages 895–901.
James Pustejovsky and Zachary Yocum. 2013. Cap-
turing motion in ISO-SpaceBank. Proceedings of
the 9th Joint ISO - ACL SIGSEM Workshop on In-
teroperable Semantic Annotation, pages 25–34.
James Pustejovsky, Jessica Moszkowicz, and Marc
Verhagen. 2012. A linguistically grounded an-
notation language for spatial information. TAL,
53(2):87–113.
James Pustejovsky, Parisa Kordjamshidi, Marie-
Francine Moens, Aaron Levine, Seth Dworman, and
Zachary Yocum. 2015. SemEval-2015 Task 8:
SpaceEval. In Proceedings of the 9th International
Workshop on Semantic Evaluation, pages 884–894.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nate Chambers, Mihai Surdeanu, Dan Ju-
rafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In Proceed-
ings of the 2010 Conference on Empirical Methods
in Natural Language Processing, pages 492–501.
Kirk Roberts and Sanda M. Harabagiu. 2012. UTD-
SpRL: A joint approach to spatial role labeling. In
Proceedings of the 6th International Workshop on
Semantic Evaluation, pages 419–424.
Kirk Roberts, Michael A. Skinner, and Sanda M.
Harabagiu. 2013. Recognizing spatial containment
relations between event mentions. In Proceedings of
the 10th International Conference on Computational
Semantics – Long Papers, pages 216–227.
Haritz Salaberri, Olatz Arregi, and Be˜nat Zapirain.
2015. IXAGroupEHUSpaceEval: (X-Space) A
WordNet-based approach towards the automatic
recognition of spatial information following the
ISO-Space annotation scheme. In Proceedings of
the 9th International Workshop on Semantic Eval-
uation, pages 856–861.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. Journal of Machine Learning Research,
3:1083–1106.
</reference>
<page confidence="0.963427">
767
</page>
<reference confidence="0.996718571428571">
GuoDong Zhou, Min Zhang, DongHong Ji, and
QiaoMing Zhu. 2007. Tree kernel-based relation
extraction with context-sensitive structured parse
tree information. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 728–736.
</reference>
<page confidence="0.996299">
768
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.462213">
<title confidence="0.996947">Sieve-Based Spatial Relation Extraction with Expanding Parse Trees</title>
<author confidence="0.889182">D’Souza</author>
<affiliation confidence="0.988731">Human Language Technology Research University of Texas at</affiliation>
<address confidence="0.548865">Richardson, TX</address>
<abstract confidence="0.997391625">A key challenge introduced by the recent SpaceEval shared task on spatial relation extraction is the identification of a type of spatial relation in which up to eight spatial elements can participate. To handle the complexity of we combine two ideas that have been successfully applied to information extraction tasks, namely kernels proposing the use of an expanding parse tree as a novel structured feature for train- Our approach yields state-of-the-art results on two key tasks in SpaceEval.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Emanuele Bastianelli</author>
<author>Danilo Croce</author>
<author>Daniele Nardi</author>
<author>Roberto Basili</author>
</authors>
<title>Unitor-HMM-TK: Structured kernel-based learning for spatial role labeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation,</booktitle>
<pages>573--579</pages>
<contexts>
<context position="10672" citStr="Bastianelli et al., 2013" startWordPosition="1664" endWordPosition="1667">ource “Boston”, and goal “Cambridge”. Table 2: Three types of spatial relations in SpaceEval. 3 Related Work Broadly speaking, existing spatial relation extraction systems have adopted either a pipeline approach or a joint approach to these subtasks. Given a set of spatial elements, a pipeline spatial relation extraction system (1) extracts the triggers, (2) determines whether a spatial relation exists between each extracted trigger and each of the remaining spatial elements, and (3) classifies the role of each non-trigger in each pair of spatially-related elements (Kordjamshidi et al., 2011; Bastianelli et al., 2013; Kordjamshidi and Moens, 2015). The major weakness of pipeline approaches is that errors in trigger identification can propagate to the relation classification component, whose errors can in turn propagate to the role labeling component. To address this weakness, Roberts et al. (2012; 2013) investigated joint approaches. Given a set of spatial elements with an assignment of roles to each element, a joint spatial relation extraction system uses a binary classifier to determine whether these elements form a spatial relation with the roles correctly assigned to all participating elements. In oth</context>
</contexts>
<marker>Bastianelli, Croce, Nardi, Basili, 2013</marker>
<rawString>Emanuele Bastianelli, Danilo Croce, Daniele Nardi, and Roberto Basili. 2013. Unitor-HMM-TK: Structured kernel-based learning for spatial role labeling. In Proceedings of the 7th International Workshop on Semantic Evaluation, pages 573–579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>724--731</pages>
<contexts>
<context position="5008" citStr="Bunescu and Mooney (2005)" startWordPosition="773" endWordPosition="776">and (2) earlier attachment decisions can be exploited as additional contextual information by later sieves. Hence, compared to a joint approach, a sieve-based approach achieves computational tractability by modeling partial, rather thanfull dependencies among the spatial elements. While a sieve-based approach allows us to exploit additional contextual information provided by earlier sieves, we still have to specify how we encode such contextual information. Motivated by the successful application of tree kernels to relation extraction (e.g., Zelenko et al. (2003), Culotta and Sorensen (2004), Bunescu and Mooney (2005), Zhou et al. (2007)), we propose to (1) encode the syntactic context in which the spatial elements extracted by the sieves appear using a syntactic parse tree, and then (2) employ the tree as an (additional) structured feature for training the classifier associated with each sieve. This novel combination of sieves and tree-based structured features results in what we call an expanding parse tree. Specifically, as a spatial element for a MOVELINK is extracted by a (role-specific) sieve, it will be added to the structured feature for the classifier associated with the following sieve. In other </context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan Bunescu and Raymond Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 724– 731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Taylor Cassidy</author>
<author>Bill McDowell</author>
<author>Steven Bethard</author>
</authors>
<title>Dense event ordering with a multi-pass architecture.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>2</volume>
<pages>284</pages>
<contexts>
<context position="23061" citStr="Chambers et al. (2014)" startWordPosition="3636" endWordPosition="3639">han sieve 2’s decision. As another example, if two classifiers assign different roles to the same spatial element, then we will choose the role assigned by the classifier associated with the earlier sieve. Given the above discussion, it should be clear that the ordering of the sieves is important. Typically, sieves are ordered by precision, with the hope of reducing the number of erroneous deci5We use the distance from the hyperplane as a measure of an SVM classifier’s confidence. 762 sions passed from the earlier sieves to the later sieves (e.g., Raghunathan et al. (2010), Lee et al. (2013), Chambers et al. (2014)). Motivated by this observation, we order the sieves as follows. We set sieve 0 to be the LINK classifier and sieve 1 to be the (trigger, mover) classifier, and then order the remaining sieves by precision. Specifically, we compute the precision of each sieve on the development data, then add sieves into the pipeline in decreasing order of precision. 5.2 Using Sieves with Trees Next, we describe our second method for applying sieves to spatial relation extraction. To motivate this method, recall that one important property of a sieve-based approach is that later sieves can exploit earlier sie</context>
</contexts>
<marker>Chambers, Cassidy, McDowell, Bethard, 2014</marker>
<rawString>Nathanael Chambers, Taylor Cassidy, Bill McDowell, and Steven Bethard. 2014. Dense event ordering with a multi-pass architecture. Transactions of the Association for Computational Linguistics, 2:273– 284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Main Volume,</booktitle>
<pages>423--429</pages>
<contexts>
<context position="4981" citStr="Culotta and Sorensen (2004)" startWordPosition="768" endWordPosition="772">entally added to a MOVELINK, and (2) earlier attachment decisions can be exploited as additional contextual information by later sieves. Hence, compared to a joint approach, a sieve-based approach achieves computational tractability by modeling partial, rather thanfull dependencies among the spatial elements. While a sieve-based approach allows us to exploit additional contextual information provided by earlier sieves, we still have to specify how we encode such contextual information. Motivated by the successful application of tree kernels to relation extraction (e.g., Zelenko et al. (2003), Culotta and Sorensen (2004), Bunescu and Mooney (2005), Zhou et al. (2007)), we propose to (1) encode the syntactic context in which the spatial elements extracted by the sieves appear using a syntactic parse tree, and then (2) employ the tree as an (additional) structured feature for training the classifier associated with each sieve. This novel combination of sieves and tree-based structured features results in what we call an expanding parse tree. Specifically, as a spatial element for a MOVELINK is extracted by a (role-specific) sieve, it will be added to the structured feature for the classifier associated with the</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Main Volume, pages 423–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer D’Souza</author>
<author>Vincent Ng</author>
</authors>
<title>UTD: Ensemble-based spatial relation extraction.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation,</booktitle>
<pages>862--869</pages>
<marker>D’Souza, Ng, 2015</marker>
<rawString>Jennifer D’Souza and Vincent Ng. 2015. UTD: Ensemble-based spatial relation extraction. In Proceedings of the 9th International Workshop on Semantic Evaluation, pages 862–869.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>In Bernhard Scholkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning,</booktitle>
<pages>44--56</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="15285" citStr="Joachims, 1999" startWordPosition="2406" endWordPosition="2407">e IMPLICIT. A training instance is labeled as positive if and only if the elements in the triplet form a relation and their roles are correct. As an example, for the QSLINK and OLINK sentence in Table 2, exactly one positive instance, LINK(cuptrajector, tablelandmark, ontrigger), will be created. Each instance is represented using the 31 features, which can be broadly divided into seven types: lexical, grammatical, semantic, positional, distance, entity attributes, and entity roles.2 We train the LINK classifier using the SVM learning algorithm as implemented in the SVMlight software package (Joachims, 1999). To optimize classifier performance, we tune two parameters, the regularization parameter C and the cost-factor parameter J, to maximize F-score on the development data.3 Since joint tuning of these parameters is computationally expensive, we employ a hillclimbing algorithm to find a local maximum, al2Space limitations preclude a description of these features. See D’Souza and Ng (2015) for details. 3C is chosen from the set {0.01, 0.05, 0.1, 0.5, 1.0, 10.0, 50.0, 100.01, and J is chosen from the set {0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 4.0, 6.01. All other learning parameters are set to their def</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale SVM learning practical. In Bernhard Scholkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning, pages 44–56. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oleksandr Kolomiyets</author>
<author>Parisa Kordjamshidi</author>
<author>Steven Bethard</author>
<author>Marie-Francine Moens</author>
</authors>
<title>SemEval-2013 Task 3: Spatial role labeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation,</booktitle>
<pages>255--266</pages>
<contexts>
<context position="1288" citStr="Kolomiyets et al., 2013" startWordPosition="192" endWordPosition="195">xpanding parse tree as a novel structured feature for training MOVELINK classifiers. Our approach yields state-of-the-art results on two key tasks in SpaceEval. 1 Introduction Spatial relation extraction is the task of determining the relation among a set of spatial elements. Although it has thus far received much less attention than temporal relation extraction, there has been a surge of interest in it in recent years, as evidenced by the organization of the three shared tasks on spatial relation extraction, namely the spatial role labeling tasks in 2012 (Kordjamshidi et al., 2012) and 2013 (Kolomiyets et al., 2013), as well as this year’s SpaceEval task (Pustejovsky et al., 2015). The task has also evolved over the years, with new types of spatial elements and/or spatial relations being defined in each shared task. For instance, while the first two shared tasks have focused on extracting spatial relations between stationary objects, SpaceEval examines for the first time spatial relations on objects in motion. Extracting spatial relations on objects in motion, or MOVELINKs, is very challenging. The challenge stems in part from the fact that a MOVELINK involves two mandatory participants (with roles mover</context>
</contexts>
<marker>Kolomiyets, Kordjamshidi, Bethard, Moens, 2013</marker>
<rawString>Oleksandr Kolomiyets, Parisa Kordjamshidi, Steven Bethard, and Marie-Francine Moens. 2013. SemEval-2013 Task 3: Spatial role labeling. In Proceedings of the 7th International Workshop on Semantic Evaluation, pages 255–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Parisa Kordjamshidi</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Global machine learning for spatial ontology population. Web Semantics: Science, Services and Agents on the World Wide Web,</title>
<date>2015</date>
<contexts>
<context position="10703" citStr="Kordjamshidi and Moens, 2015" startWordPosition="1668" endWordPosition="1671">Cambridge”. Table 2: Three types of spatial relations in SpaceEval. 3 Related Work Broadly speaking, existing spatial relation extraction systems have adopted either a pipeline approach or a joint approach to these subtasks. Given a set of spatial elements, a pipeline spatial relation extraction system (1) extracts the triggers, (2) determines whether a spatial relation exists between each extracted trigger and each of the remaining spatial elements, and (3) classifies the role of each non-trigger in each pair of spatially-related elements (Kordjamshidi et al., 2011; Bastianelli et al., 2013; Kordjamshidi and Moens, 2015). The major weakness of pipeline approaches is that errors in trigger identification can propagate to the relation classification component, whose errors can in turn propagate to the role labeling component. To address this weakness, Roberts et al. (2012; 2013) investigated joint approaches. Given a set of spatial elements with an assignment of roles to each element, a joint spatial relation extraction system uses a binary classifier to determine whether these elements form a spatial relation with the roles correctly assigned to all participating elements. In other words, the classifier will o</context>
</contexts>
<marker>Kordjamshidi, Moens, 2015</marker>
<rawString>Parisa Kordjamshidi and Marie-Francine Moens. 2015. Global machine learning for spatial ontology population. Web Semantics: Science, Services and Agents on the World Wide Web, 30(C):3–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Parisa Kordjamshidi</author>
<author>Martijn Van Otterlo</author>
<author>MarieFrancine Moens</author>
</authors>
<title>Spatial role labeling: Towards extraction of spatial relations from natural language.</title>
<date>2011</date>
<journal>ACM Transactions on Speech and Language Processing,</journal>
<volume>8</volume>
<issue>3</issue>
<marker>Kordjamshidi, Van Otterlo, Moens, 2011</marker>
<rawString>Parisa Kordjamshidi, Martijn Van Otterlo, and MarieFrancine Moens. 2011. Spatial role labeling: Towards extraction of spatial relations from natural language. ACM Transactions on Speech and Language Processing, 8(3):4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Parisa Kordjamshidi</author>
<author>Steven Bethard</author>
<author>MarieFrancine Moens</author>
</authors>
<title>SemEval-2012 Task 3: Spatial role labeling.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation,</booktitle>
<pages>365--373</pages>
<contexts>
<context position="1253" citStr="Kordjamshidi et al., 2012" startWordPosition="186" endWordPosition="189">ass sieves, proposing the use of an expanding parse tree as a novel structured feature for training MOVELINK classifiers. Our approach yields state-of-the-art results on two key tasks in SpaceEval. 1 Introduction Spatial relation extraction is the task of determining the relation among a set of spatial elements. Although it has thus far received much less attention than temporal relation extraction, there has been a surge of interest in it in recent years, as evidenced by the organization of the three shared tasks on spatial relation extraction, namely the spatial role labeling tasks in 2012 (Kordjamshidi et al., 2012) and 2013 (Kolomiyets et al., 2013), as well as this year’s SpaceEval task (Pustejovsky et al., 2015). The task has also evolved over the years, with new types of spatial elements and/or spatial relations being defined in each shared task. For instance, while the first two shared tasks have focused on extracting spatial relations between stationary objects, SpaceEval examines for the first time spatial relations on objects in motion. Extracting spatial relations on objects in motion, or MOVELINKs, is very challenging. The challenge stems in part from the fact that a MOVELINK involves two manda</context>
</contexts>
<marker>Kordjamshidi, Bethard, Moens, 2012</marker>
<rawString>Parisa Kordjamshidi, Steven Bethard, and MarieFrancine Moens. 2012. SemEval-2012 Task 3: Spatial role labeling. In Proceedings of the 6th International Workshop on Semantic Evaluation, pages 365–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Angel Chang</author>
<author>Yves Peirsman</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Deterministic coreference resolution based on entity-centric, precision-ranked rules.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>4</issue>
<contexts>
<context position="3912" citStr="Lee et al., 2013" startWordPosition="607" endWordPosition="610">cusing on the extraction of MOVELINKs by addressing the aforementioned weakness. The key question is: how can we capture the dependencies among the spatial elements involved without sacrificing computational tractability? To address this question, we combine two ideas that have been successfully applied to a variety of information extraction tasks, namely multi-pass sieves (Raghu758 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 758–768, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. nathan et al., 2010; Lee et al., 2013) and tree kernels (Moschitti, 2004; Moschitti, 2006). Recall that a sieve-based approach is composed of a pipeline of sieves ordered by precision, where the decisions made by earlier sieves can be exploited by later sieves in order to incrementally construct a complex structure. When applied to MOVELINK identification, we can create a sieve for identifying each role, so that (1) spatial elements corresponding to different roles are incrementally added to a MOVELINK, and (2) earlier attachment decisions can be exploited as additional contextual information by later sieves. Hence, compared to a </context>
<context position="23037" citStr="Lee et al. (2013)" startWordPosition="3632" endWordPosition="3635">ieve 1’s decision than sieve 2’s decision. As another example, if two classifiers assign different roles to the same spatial element, then we will choose the role assigned by the classifier associated with the earlier sieve. Given the above discussion, it should be clear that the ordering of the sieves is important. Typically, sieves are ordered by precision, with the hope of reducing the number of erroneous deci5We use the distance from the hyperplane as a measure of an SVM classifier’s confidence. 762 sions passed from the earlier sieves to the later sieves (e.g., Raghunathan et al. (2010), Lee et al. (2013), Chambers et al. (2014)). Motivated by this observation, we order the sieves as follows. We set sieve 0 to be the LINK classifier and sieve 1 to be the (trigger, mover) classifier, and then order the remaining sieves by precision. Specifically, we compute the precision of each sieve on the development data, then add sieves into the pipeline in decreasing order of precision. 5.2 Using Sieves with Trees Next, we describe our second method for applying sieves to spatial relation extraction. To motivate this method, recall that one important property of a sieve-based approach is that later sieves</context>
</contexts>
<marker>Lee, Chang, Peirsman, Chambers, Surdeanu, Jurafsky, 2013</marker>
<rawString>Heeyoung Lee, Angel Chang, Yves Peirsman, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2013. Deterministic coreference resolution based on entity-centric, precision-ranked rules. Computational Linguistics, 39(4):885–916.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>A study on convolution kernels for shallow statistic parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Main Volume,</booktitle>
<pages>335--342</pages>
<contexts>
<context position="3946" citStr="Moschitti, 2004" startWordPosition="614" endWordPosition="615">s by addressing the aforementioned weakness. The key question is: how can we capture the dependencies among the spatial elements involved without sacrificing computational tractability? To address this question, we combine two ideas that have been successfully applied to a variety of information extraction tasks, namely multi-pass sieves (Raghu758 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 758–768, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. nathan et al., 2010; Lee et al., 2013) and tree kernels (Moschitti, 2004; Moschitti, 2006). Recall that a sieve-based approach is composed of a pipeline of sieves ordered by precision, where the decisions made by earlier sieves can be exploited by later sieves in order to incrementally construct a complex structure. When applied to MOVELINK identification, we can create a sieve for identifying each role, so that (1) spatial elements corresponding to different roles are incrementally added to a MOVELINK, and (2) earlier attachment decisions can be exploited as additional contextual information by later sieves. Hence, compared to a joint approach, a sieve-based appr</context>
<context position="27202" citStr="Moschitti, 2004" startWordPosition="4324" endWordPosition="4325">NK can be extracted from it, only one positive training instance will be created for each classifier. Assume that sieve 1 contains the (trigger, mover) classifier; sieve 2 contains the (trigger, mover, motion signal) classifier; and sieve 3 contains the (trigger, mover, goal) classifier. Figure 3(a) shows the SRCTs used in the corresponding positive instances, while Figure 3(b) shows the SRCTs associated with randomly chosen negative instances used to train the classifiers in these sieves. To train a classifier on instances containing the original 31 features and SRCTs, we employ SVMlight−Tx (Moschitti, 2004; Moschitti, 2006), which (1) trains an SVM classifier using the 31 features with a linear kernel; (2) trains an SVM classifier using only the SRCTs with a convolution 763 (a) SRCTs associated with positive training instances in sieves 1, 2, and 3. (a) SRCTs associated with correctly classified test instances in sieves 1, 2, and 3. (b) SRCTs associated with randomly chosen negative training instances in sieves 1, 2, and 3. Figure 3: SRCTs associated with training instances created for the sentence in Figure 2a. kernel; and (3) combines these two kernels using a composite kernel. Specifically, </context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>Alessandro Moschitti. 2004. A study on convolution kernels for shallow statistic parsing. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Main Volume, pages 335–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language processing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="3964" citStr="Moschitti, 2006" startWordPosition="616" endWordPosition="617">he aforementioned weakness. The key question is: how can we capture the dependencies among the spatial elements involved without sacrificing computational tractability? To address this question, we combine two ideas that have been successfully applied to a variety of information extraction tasks, namely multi-pass sieves (Raghu758 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 758–768, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. nathan et al., 2010; Lee et al., 2013) and tree kernels (Moschitti, 2004; Moschitti, 2006). Recall that a sieve-based approach is composed of a pipeline of sieves ordered by precision, where the decisions made by earlier sieves can be exploited by later sieves in order to incrementally construct a complex structure. When applied to MOVELINK identification, we can create a sieve for identifying each role, so that (1) spatial elements corresponding to different roles are incrementally added to a MOVELINK, and (2) earlier attachment decisions can be exploited as additional contextual information by later sieves. Hence, compared to a joint approach, a sieve-based approach achieves comp</context>
<context position="27220" citStr="Moschitti, 2006" startWordPosition="4326" endWordPosition="4327">ed from it, only one positive training instance will be created for each classifier. Assume that sieve 1 contains the (trigger, mover) classifier; sieve 2 contains the (trigger, mover, motion signal) classifier; and sieve 3 contains the (trigger, mover, goal) classifier. Figure 3(a) shows the SRCTs used in the corresponding positive instances, while Figure 3(b) shows the SRCTs associated with randomly chosen negative instances used to train the classifiers in these sieves. To train a classifier on instances containing the original 31 features and SRCTs, we employ SVMlight−Tx (Moschitti, 2004; Moschitti, 2006), which (1) trains an SVM classifier using the 31 features with a linear kernel; (2) trains an SVM classifier using only the SRCTs with a convolution 763 (a) SRCTs associated with positive training instances in sieves 1, 2, and 3. (a) SRCTs associated with correctly classified test instances in sieves 1, 2, and 3. (b) SRCTs associated with randomly chosen negative training instances in sieves 1, 2, and 3. Figure 3: SRCTs associated with training instances created for the sentence in Figure 2a. kernel; and (3) combines these two kernels using a composite kernel. Specifically, we define composit</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Making tree kernels practical for natural language processing. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Nichols</author>
<author>Fadi Botros</author>
</authors>
<title>SpRLCWW: Spatial relation classification with independent multi-class models.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation,</booktitle>
<pages>895--901</pages>
<contexts>
<context position="11551" citStr="Nichols and Botros, 2015" startWordPosition="1811" endWordPosition="1814">weakness, Roberts et al. (2012; 2013) investigated joint approaches. Given a set of spatial elements with an assignment of roles to each element, a joint spatial relation extraction system uses a binary classifier to determine whether these elements form a spatial relation with the roles correctly assigned to all participating elements. In other words, the classifier will output a 1 if and only if (1) the elements in the set form a relation and (2) their roles in the relation are correct. The systems participating in SpaceEval all seem to be in favor of joint approaches (D’Souza and Ng, 2015; Nichols and Botros, 2015; Salaberri et al., 2015). 4 Baseline System To ensure that we have a state-of-the-art baseline system for spatial relation extraction, we employ our SpaceEval participating system (D’Souza and Ng, 2015), which achieved the best results on task 3a in the official SpaceEval evaluation.1 This Baseline system performs joint role labeling and relation classification using an ensemble of classifiers. Specifically, it trains one classifier for extracting QSLINKs and OLINKs, and seven classifiers for extracting MOVELINKs. Creating these eight classifiers permits (1) separating the treatment of MOVELI</context>
</contexts>
<marker>Nichols, Botros, 2015</marker>
<rawString>Eric Nichols and Fadi Botros. 2015. SpRLCWW: Spatial relation classification with independent multi-class models. In Proceedings of the 9th International Workshop on Semantic Evaluation, pages 895–901.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Zachary Yocum</author>
</authors>
<title>Capturing motion in ISO-SpaceBank.</title>
<date>2013</date>
<booktitle>Proceedings of the 9th Joint ISO - ACL SIGSEM Workshop on Interoperable Semantic Annotation,</booktitle>
<pages>25--34</pages>
<contexts>
<context position="6454" citStr="Pustejovsky and Yocum, 2013" startWordPosition="1012" endWordPosition="1016">eated from a static parse subtree for extracting exactly two arguments involved in a relation. To our knowledge, this is the first attempt to combine sieves and parse trees to create expanding trees to extract complex relations involving multiple arguments. 2 Corpus and Task Definition In this section, we introduce our corpus and the spatial relation extraction task. Owing to space limitations, we will only discuss those aspects that are relevant to the SpaceEval tasks we focus on. 2.1 The SpaceEval Corpus We use as our corpus the SpaceEval training corpus, which is a subset of ISO-SpaceBank (Pustejovsky and Yocum, 2013). The corpus consists of 59 travel narratives annotated with seven types of spatial elements (Table 1) and three types of spatial relations (Table 2), following the ISOSpace (2012) annotation specifications. Different types of spatial elements have different attributes. The only attribute that is relevant to our work is semantic type, which is one of the attributes of a spatial entity. Semantic type expresses the type of the relation it triggers and can take one of three values: topological, directional, or both. What is missing in Table 2 about spatial relations is that each element participa</context>
</contexts>
<marker>Pustejovsky, Yocum, 2013</marker>
<rawString>James Pustejovsky and Zachary Yocum. 2013. Capturing motion in ISO-SpaceBank. Proceedings of the 9th Joint ISO - ACL SIGSEM Workshop on Interoperable Semantic Annotation, pages 25–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jessica Moszkowicz</author>
<author>Marc Verhagen</author>
</authors>
<title>A linguistically grounded annotation language for spatial information.</title>
<date>2012</date>
<journal>TAL,</journal>
<volume>53</volume>
<issue>2</issue>
<marker>Pustejovsky, Moszkowicz, Verhagen, 2012</marker>
<rawString>James Pustejovsky, Jessica Moszkowicz, and Marc Verhagen. 2012. A linguistically grounded annotation language for spatial information. TAL, 53(2):87–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Parisa Kordjamshidi</author>
<author>MarieFrancine Moens</author>
<author>Aaron Levine</author>
<author>Seth Dworman</author>
<author>Zachary Yocum</author>
</authors>
<date>2015</date>
<booktitle>SemEval-2015 Task 8: SpaceEval. In Proceedings of the 9th International Workshop on Semantic Evaluation,</booktitle>
<pages>884--894</pages>
<contexts>
<context position="1354" citStr="Pustejovsky et al., 2015" startWordPosition="203" endWordPosition="206">VELINK classifiers. Our approach yields state-of-the-art results on two key tasks in SpaceEval. 1 Introduction Spatial relation extraction is the task of determining the relation among a set of spatial elements. Although it has thus far received much less attention than temporal relation extraction, there has been a surge of interest in it in recent years, as evidenced by the organization of the three shared tasks on spatial relation extraction, namely the spatial role labeling tasks in 2012 (Kordjamshidi et al., 2012) and 2013 (Kolomiyets et al., 2013), as well as this year’s SpaceEval task (Pustejovsky et al., 2015). The task has also evolved over the years, with new types of spatial elements and/or spatial relations being defined in each shared task. For instance, while the first two shared tasks have focused on extracting spatial relations between stationary objects, SpaceEval examines for the first time spatial relations on objects in motion. Extracting spatial relations on objects in motion, or MOVELINKs, is very challenging. The challenge stems in part from the fact that a MOVELINK involves two mandatory participants (with roles mover and trigger) and up to six optional participants (with other sema</context>
</contexts>
<marker>Pustejovsky, Kordjamshidi, Moens, Levine, Dworman, Yocum, 2015</marker>
<rawString>James Pustejovsky, Parisa Kordjamshidi, MarieFrancine Moens, Aaron Levine, Seth Dworman, and Zachary Yocum. 2015. SemEval-2015 Task 8: SpaceEval. In Proceedings of the 9th International Workshop on Semantic Evaluation, pages 884–894.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karthik Raghunathan</author>
<author>Heeyoung Lee</author>
<author>Sudarshan Rangarajan</author>
<author>Nate Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A multipass sieve for coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>492--501</pages>
<contexts>
<context position="23018" citStr="Raghunathan et al. (2010)" startWordPosition="3628" endWordPosition="3631">e have more confidence in sieve 1’s decision than sieve 2’s decision. As another example, if two classifiers assign different roles to the same spatial element, then we will choose the role assigned by the classifier associated with the earlier sieve. Given the above discussion, it should be clear that the ordering of the sieves is important. Typically, sieves are ordered by precision, with the hope of reducing the number of erroneous deci5We use the distance from the hyperplane as a measure of an SVM classifier’s confidence. 762 sions passed from the earlier sieves to the later sieves (e.g., Raghunathan et al. (2010), Lee et al. (2013), Chambers et al. (2014)). Motivated by this observation, we order the sieves as follows. We set sieve 0 to be the LINK classifier and sieve 1 to be the (trigger, mover) classifier, and then order the remaining sieves by precision. Specifically, we compute the precision of each sieve on the development data, then add sieves into the pipeline in decreasing order of precision. 5.2 Using Sieves with Trees Next, we describe our second method for applying sieves to spatial relation extraction. To motivate this method, recall that one important property of a sieve-based approach i</context>
</contexts>
<marker>Raghunathan, Lee, Rangarajan, Chambers, Surdeanu, Jurafsky, Manning, 2010</marker>
<rawString>Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nate Chambers, Mihai Surdeanu, Dan Jurafsky, and Christopher Manning. 2010. A multipass sieve for coreference resolution. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 492–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kirk Roberts</author>
<author>Sanda M Harabagiu</author>
</authors>
<title>UTDSpRL: A joint approach to spatial role labeling.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation,</booktitle>
<pages>419--424</pages>
<marker>Roberts, Harabagiu, 2012</marker>
<rawString>Kirk Roberts and Sanda M. Harabagiu. 2012. UTDSpRL: A joint approach to spatial role labeling. In Proceedings of the 6th International Workshop on Semantic Evaluation, pages 419–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kirk Roberts</author>
<author>Michael A Skinner</author>
<author>Sanda M Harabagiu</author>
</authors>
<title>Recognizing spatial containment relations between event mentions.</title>
<date>2013</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Semantics – Long Papers,</booktitle>
<pages>216--227</pages>
<marker>Roberts, Skinner, Harabagiu, 2013</marker>
<rawString>Kirk Roberts, Michael A. Skinner, and Sanda M. Harabagiu. 2013. Recognizing spatial containment relations between event mentions. In Proceedings of the 10th International Conference on Computational Semantics – Long Papers, pages 216–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haritz Salaberri</author>
<author>Olatz Arregi</author>
<author>Be˜nat Zapirain</author>
</authors>
<title>IXAGroupEHUSpaceEval: (X-Space) A WordNet-based approach towards the automatic recognition of spatial information following the ISO-Space annotation scheme.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation,</booktitle>
<pages>856--861</pages>
<contexts>
<context position="11576" citStr="Salaberri et al., 2015" startWordPosition="1815" endWordPosition="1818">2012; 2013) investigated joint approaches. Given a set of spatial elements with an assignment of roles to each element, a joint spatial relation extraction system uses a binary classifier to determine whether these elements form a spatial relation with the roles correctly assigned to all participating elements. In other words, the classifier will output a 1 if and only if (1) the elements in the set form a relation and (2) their roles in the relation are correct. The systems participating in SpaceEval all seem to be in favor of joint approaches (D’Souza and Ng, 2015; Nichols and Botros, 2015; Salaberri et al., 2015). 4 Baseline System To ensure that we have a state-of-the-art baseline system for spatial relation extraction, we employ our SpaceEval participating system (D’Souza and Ng, 2015), which achieved the best results on task 3a in the official SpaceEval evaluation.1 This Baseline system performs joint role labeling and relation classification using an ensemble of classifiers. Specifically, it trains one classifier for extracting QSLINKs and OLINKs, and seven classifiers for extracting MOVELINKs. Creating these eight classifiers permits (1) separating the treatment of MOVELINKs from QSLINKs and OLIN</context>
</contexts>
<marker>Salaberri, Arregi, Zapirain, 2015</marker>
<rawString>Haritz Salaberri, Olatz Arregi, and Be˜nat Zapirain. 2015. IXAGroupEHUSpaceEval: (X-Space) A WordNet-based approach towards the automatic recognition of spatial information following the ISO-Space annotation scheme. In Proceedings of the 9th International Workshop on Semantic Evaluation, pages 856–861.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
<author>Anthony Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1083</pages>
<contexts>
<context position="4952" citStr="Zelenko et al. (2003)" startWordPosition="764" endWordPosition="767">ferent roles are incrementally added to a MOVELINK, and (2) earlier attachment decisions can be exploited as additional contextual information by later sieves. Hence, compared to a joint approach, a sieve-based approach achieves computational tractability by modeling partial, rather thanfull dependencies among the spatial elements. While a sieve-based approach allows us to exploit additional contextual information provided by earlier sieves, we still have to specify how we encode such contextual information. Motivated by the successful application of tree kernels to relation extraction (e.g., Zelenko et al. (2003), Culotta and Sorensen (2004), Bunescu and Mooney (2005), Zhou et al. (2007)), we propose to (1) encode the syntactic context in which the spatial elements extracted by the sieves appear using a syntactic parse tree, and then (2) employ the tree as an (additional) structured feature for training the classifier associated with each sieve. This novel combination of sieves and tree-based structured features results in what we call an expanding parse tree. Specifically, as a spatial element for a MOVELINK is extracted by a (role-specific) sieve, it will be added to the structured feature for the c</context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2003</marker>
<rawString>Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella. 2003. Kernel methods for relation extraction. Journal of Machine Learning Research, 3:1083–1106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Min Zhang</author>
<author>DongHong Ji</author>
<author>QiaoMing Zhu</author>
</authors>
<title>Tree kernel-based relation extraction with context-sensitive structured parse tree information.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>728--736</pages>
<contexts>
<context position="5028" citStr="Zhou et al. (2007)" startWordPosition="777" endWordPosition="780">decisions can be exploited as additional contextual information by later sieves. Hence, compared to a joint approach, a sieve-based approach achieves computational tractability by modeling partial, rather thanfull dependencies among the spatial elements. While a sieve-based approach allows us to exploit additional contextual information provided by earlier sieves, we still have to specify how we encode such contextual information. Motivated by the successful application of tree kernels to relation extraction (e.g., Zelenko et al. (2003), Culotta and Sorensen (2004), Bunescu and Mooney (2005), Zhou et al. (2007)), we propose to (1) encode the syntactic context in which the spatial elements extracted by the sieves appear using a syntactic parse tree, and then (2) employ the tree as an (additional) structured feature for training the classifier associated with each sieve. This novel combination of sieves and tree-based structured features results in what we call an expanding parse tree. Specifically, as a spatial element for a MOVELINK is extracted by a (role-specific) sieve, it will be added to the structured feature for the classifier associated with the following sieve. In other words, the parse tre</context>
</contexts>
<marker>Zhou, Zhang, Ji, Zhu, 2007</marker>
<rawString>GuoDong Zhou, Min Zhang, DongHong Ji, and QiaoMing Zhu. 2007. Tree kernel-based relation extraction with context-sensitive structured parse tree information. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 728–736.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>