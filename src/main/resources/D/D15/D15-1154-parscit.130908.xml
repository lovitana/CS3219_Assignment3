<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000166">
<title confidence="0.9986905">
Efficient Inner-to-outer Greedy Algorithm
for Higher-order Labeled Dependency Parsing
</title>
<author confidence="0.97819">
Xuezhe Ma and Eduard Hovy
</author>
<affiliation confidence="0.885314333333333">
Language Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998575">
xuezhem@cs.cmu.edu, ehovy@andrew.cmu.edu
</email>
<sectionHeader confidence="0.997389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9978341875">
Many NLP systems use dependency
parsers as critical components. Jonit learn-
ing parsers usually achieve better parsing
accuracies than two-stage methods. How-
ever, classical joint parsing algorithms
significantly increase computational com-
plexity, which makes joint learning im-
practical. In this paper, we proposed an ef-
ficient dependency parsing algorithm that
is capable of capturing multiple edge-label
features, while maintaining low computa-
tional complexity. We evaluate our parser
on 14 different languages. Our parser
consistently obtains more accurate results
than three baseline systems and three pop-
ular, off-the-shelf parsers.
</bodyText>
<sectionHeader confidence="0.999521" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999741531914894">
Natural language processing (NLP) systems, like
machine translation (Xie et al., 2011), resource-
low languages processing (McDonald et al., 2013;
Ma and Xia, 2014), word sense disambigua-
tion (Fauceglia et al., 2015) , and entity corefer-
ence resolution (Durrett and Klein, 2013), are be-
coming more sophisticated, in part because of uti-
lizing syntacitc knowledges such as dependency
parsing trees.
Dependency parsers predict dependency struc-
tures and dependency type labels on each edge.
However, most graph-based dependency parsing
algorithms only produce unlabeled dependency
trees, particularly when higher-order factoriza-
tions are used (Koo and Collins, 2010; Ma and
Zhao, 2012b; Martins et al., 2013; Ma and Zhao,
2012a). A two-stage method (McDonald, 2006) is
often used because the complexity of some joint
learning models is unacceptably high. On the
other hand, joint learning models can benefit from
edge-label information that has proven to be im-
portant to provide more accurate tree structures
and labels (Nivre and Scholz, 2004).
Previous studies explored the trade-off between
computational costs and parsing performance.
Some work (McDonald, 2006; Carreras, 2007)
simplified labeled information to only single la-
bel features. Other work (Johansson and Nugues,
2008; Bohnet, 2010) used richer label features
but increased systems’ complexities significantly,
while achieving better parsing accuracy. Yet, there
are no previous work addressing the problem of
good balance between parsing accuracy and com-
putational costs for joint parsing models.
In this paper, we propose a new dependency
parsing algorithm that can utilize edge-label infor-
mation of more than one edge, while simultane-
ously maintaining low computational complexity.
The component needed to solve this dilemma is an
inner-to-outer greedy approximation to avoid an
exhaustive search. The contributions of this work
are (i) showing the effectiveness of edge-label in-
formation on both UAS and LAS. (ii) proposing a
joint learning parsing model which achieves both
effectiveness and efficience. (iii) giving empiri-
cal evaluations of this parser on different treebanks
over 14 languages.
</bodyText>
<sectionHeader confidence="0.965646" genericHeader="method">
2 Joint Parsing Algorithm
</sectionHeader>
<subsectionHeader confidence="0.969778">
2.1 Basic Notations
</subsectionHeader>
<bodyText confidence="0.9998194">
In the following, x represents a generic input sen-
tence, and y represents a generic dependency tree.
Formally, for a sentence x, dependency parsing is
the task of finding the dependency tree y with the
highest-score for x:
</bodyText>
<equation confidence="0.997306">
y∗(x) = argmax Score(x,y). (1)
y∈Y(x)
</equation>
<bodyText confidence="0.998511">
Here y(x) denotes the set of possible dependency
trees for sentence x.
In this paper, we adopt the second-order sib-
ling factorization (Eisner, 1996; McDonald and
</bodyText>
<page confidence="0.935602">
1322
</page>
<note confidence="0.6610955">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1322–1328,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.973663">
Pereira, 2006), in which each sibling part consists
of a tuple of indices (h, m, c) where (h, m) and
(h, c) are a pair of adjacent edges to the same side
of the head h. By adding labele information to this
factorization, Score(x, y) can be rewritten as:
</bodyText>
<equation confidence="0.82595825">
Score(x, y) = P Ssib(h, m, c, l1, l2)
(h,m,c,l1,l2)Ey λT f(h, m, c, l1, l2) (2)
= P
(h,m,c,l1,l2)Ey
</equation>
<figureCaption confidence="0.735175666666667">
Figure 1: The dynamic-programming structures
and derivation of four parsing algorithms. I(s,t,l)
and I(s,t) are depicted as trapezoids with solid and
dashed lines, respectively. C(s,t) are depicted as
triangles and S(s,t) are depicted as boxes. Sym-
metric right-headed versions are elided for brevity.
</figureCaption>
<bodyText confidence="0.9995435">
number in the treebank of CoNLL-2008 shared
task is 70. So it is impractical to perform an ex-
haustive search for parsing, and more efficient ap-
proximating algorithms are needed.
</bodyText>
<subsectionHeader confidence="0.998643">
2.3 Two Intermediate Models
</subsectionHeader>
<bodyText confidence="0.9999715">
In this section, we describe two intuitive simpli-
fications of the labeled parsing model presented
above. For the two simplified parsing models, ef-
ficient algorithms are available.
</bodyText>
<subsectionHeader confidence="0.980665">
2.3.1 Model 0: Single-edge Label
</subsectionHeader>
<bodyText confidence="0.9816136">
In this parsing model, labeled features are re-
stricted to a single edge. Specifically,
Ssib(h, m, c, l1, l2) = Ssib(h, c, l2).
Then the dynamic-programming derivation for
each incomplete span becomes
</bodyText>
<equation confidence="0.91048">
I(s,t) = ma&lt;_t nI(s,r) + S(r,t) + max Ssib(s, t, l)s&lt;ro
lEL
n o
= max I(s,r) + S(r,t) + Ssib(s, t, l(s, t))
s&lt;r5t
where l(s, t) = argmax Sgib(s, t, l).
l∈L
</equation>
<bodyText confidence="0.9974233">
In this case, therefore, we do not have to ex-
tend incomplete spans. The computational cost to
calculate l(s,t) is O(|L|n2) time, so the compu-
tational complexity of this algorithm is O(n3 +
|L|n2) time and O(n2) space.
where Sgib(h, m, c, l1, l2) is the score function for
the sibling part (h, m, c) with l1 and l2 being the
labels of edge (h, m) and (h, c), respectively. f
are feature functions and A is the parameters of
parsing model.
</bodyText>
<subsectionHeader confidence="0.970568">
2.2 Exact Search Parsing
</subsectionHeader>
<bodyText confidence="0.999320842105263">
The unlabeled sibling parser introduces three
types of dynamic-programming structures: com-
plete spans C(s,t), which consist of the headword
s and its descendents on one side with the endpoint
t, incomplete spans I(s,t), which consist of the de-
pendency (s, t) and the region between the head s
and the modifier t, and sibling spans S(s,t), which
represent the region between successive modifiers
s and t of some head. To capture label infor-
mation, we have to extend each incomplete span
Is,t to Is,t,l to store the label of dependency edge
from s to t. The reason is that there is an edge
shared by two adjacent sibling parts (e.g. (h, m, c)
and (h, c, c&apos;) share the edge (h, c)). So the in-
complete span I(s,t) does not only depend on the
label of dependency (s, t), but also the label of
the dependency (s, r) for each split point r. The
dynamic-programming procedure for new incom-
plete spans1 are
</bodyText>
<equation confidence="0.994783375">
I(s,t,l) = s&lt;r5t E L
l,
S(r,t) +max I(s,r,l,)+Ssib(s, r, t, l&apos;, l) (3)
where L is set of all edge labels. Then we have,
I(s,t) = max I(s,t,l) (4)
lEL
l�s,t) = argmax I(s,t,l) (5)
lEL
</equation>
<bodyText confidence="0.995901428571429">
The graphical specification of the this parsing al-
gorithm is provided in Figure 1 (a). The compu-
tational complexity of the exactly searching algo-
rithm is O(|L|2n3) time and O(|L|n2) space. In
practice, |L |is probably large. For English, the
number of edge labels in Stanford Basic Depen-
dencies (De Marneffe et al., 2006) is 45, and the
</bodyText>
<figure confidence="0.918308714285714">
1Symmetric right-headed versions are elided for brevity
t s r r
t s r r t
(a) Exact search
(b) Model 0: single-edge label
(c) Model 1: sibling with single label
(d) Inner-to-outer greedy search
</figure>
<equation confidence="0.985410515625">
l l’
t
+
r
l
r t
t s r
l(s, t)
+
r t
t s t
l*(s, t)
=
l
=
l*(s, t)
=
l*(s, r)
+
=
l*(s, r)
+
l(s, r, t, l*(s, r))
l(s, r, t)
=
s r
+
r
+
rt
l*(s, t)
l
*(s,
t)
=
l*(s, r)
t
t
r
=
l*(s, r)
+
=
l*(s, r)
+
=
=
+
r r+1
t
t
+
r r+1 t
+
r r+1 t
=
t
=
t s r r t
r r
+
r r+1
t
t
</equation>
<page confidence="0.866856">
1323
</page>
<subsectionHeader confidence="0.605714">
2.3.2 Model 1: Sibling with Single Label
</subsectionHeader>
<bodyText confidence="0.999498333333333">
As remarked in McDonald (2006), Model 0 can
be slightly enriched to include single label features
associated with a sibling part. Formally,
</bodyText>
<equation confidence="0.8958654">
Ssib(h, m, c, l1, l2) = Ssib(h, m, c, l2).
Now, the dynamic-programming derivation is
I(s,t) = maw {I(s,r) + S(r,t) + Ssib(s, r, t, l(s, r, t))}
where l(s, r, t) = argmax Ssib(s, r, t, l).
lEL
</equation>
<bodyText confidence="0.9998965">
The additional algorithm to calculate the best
edge label l(s, r, t) takes O( LIn3) time. There-
fore, this algorithm requires O( L n3) time and
O(n2) space2. Figure 1 (b) and Figure 1 (c) pro-
vide the graphical specifications for Model 0 and
Model 1, respectively.
</bodyText>
<subsectionHeader confidence="0.991778">
2.4 Inner-to-outer Greedy Search
</subsectionHeader>
<bodyText confidence="0.99999815">
Though the two intermediate parsing models,
model 0 and model 1, encode edge-label infor-
mation and have efficient parsing algorithms, the
labeled features they are able to capture are rela-
tively limited due to restricting their labeled fea-
ture functions to a single label. Our experimental
results show that utilizing these edge-label infor-
mation yields a slight improvement of parsing ac-
curacy (see Section 3 for details). In this section,
we describe our new labeled parsing model that
can exploit labeled features involving two edge-
labels in a sibling part. To achieve efficient search,
we adopt an method characterized by inferring la-
bels of outer parts from the labels of inner ones.
Formally, consider the maximization problem
in Eq 3. It can be treated as a two-layer maxi-
mization: first fixes a split point r and maximizes
over all edge-label l, then maximizes over all pos-
sible split points. Our approach approximates the
maximization in the first layer:
</bodyText>
<equation confidence="0.988297">
≈
(6)
I(s,r) + Ssib(s, r, t, l∗(s,r), l)
</equation>
<bodyText confidence="0.9213035">
Then the dynamic-programming derivation for
each incomplete span is
</bodyText>
<equation confidence="0.9743315">
I(s,t) = max
s&lt;r≤t I(s,r)+S(r,t)+max Ssib(s, r, t, l∗(s,r), l) (7)
l∈ L
To compute I(3,t), we need to calculate
l(s, r, t, l∗(s,r)) = argmax Ssib(s, r, t, l∗(s,r), l), (8)
l∈L
</equation>
<footnote confidence="0.8498695">
2We do not have to store l(s, r, t), as each l(s, r, t) will
be calculated exactly once.
</footnote>
<bodyText confidence="0.998599416666667">
which is similar to the calculation of l(s, r, t) in
Model 1. The only difference between them is
l*(3,r) that can be calculated in previous derivations.
Thus, their computation costs are almost the same.
The procedure of our algorithm to derivate in-
complete spans can be regarded as two steps. At
the first step, the algorithm goes through all pos-
sible split points (Eq 7). Then at the second
step, at each split point r, it calculate the label
l(s, r, t, l* (3,r)) (Eq 8) based on the sibling part
(s, r, t) and the label l* (3,r) which is the “best” la-
bel for dependency edge (s, r) based on incom-
plete span I(3,r). The key insight of this algorithm
is the inner-to-outer dynamic-programming struc-
ture: inner modifiers (r) of a head (s) and their
“best” labels (l*(3,r)) are generated before outer
ones (t). Thus, using already computed “best” la-
bels of inner dependency edges makes us get rid
of maximizing over two labels, l&apos; and l. Moreover,
we do not have to extend each incomplete span by
the augmentation with a “label” index. This makes
the space complexity remains O(n2), which is im-
portant in practice. The graphical specification is
provided in Figure 1 (d).
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99357">
3.1 Setup
</subsectionHeader>
<bodyText confidence="0.999803266666667">
We conduct our experiments on 14 languages, in-
cluding the English treebank from CoNLL-2008
shared task (Surdeanu et al., 2008) and all 13 tree-
banks from CoNLL-2006 shared task (Buchholz
and Marsi, 2006). We train our parser using The k-
best version of the Margin Infused Relaxed Algo-
rithm (MIRA) (Crammer and Singer, 2003; Cram-
mer et al., 2006; McDonald, 2006). In our experi-
ments, we set k = 1 and fix the number of iteration
to 10, instead of tuning these parameters on devel-
opment sets. Following previous work, all exper-
iments are evaluated on the metrics of unlabeled
attachment score (UAS) and Labeled attachment
score (LAS), using the official scorer3 of CoNLL-
2006 shared task.
</bodyText>
<subsectionHeader confidence="0.990542">
3.2 Non-Projective Parsing
</subsectionHeader>
<bodyText confidence="0.9998222">
The parsing algorithms described in the paper fall
into the category of projective dependency parsers,
which exclude crossing dependency edges. Since
the treebanks from CoNLL shared tasks con-
tain non-projective edges, we use the “mountain-
</bodyText>
<equation confidence="0.85388175">
3http://ilk.uvt.nl/conll/software.html
I(s,r,l�) + Ssib(s, r, t, l0, l)
max
l�∈L
</equation>
<page confidence="0.973095">
1324
</page>
<table confidence="0.999873294117647">
Two-stage Model 0 Model 1 Our Model Best in CoNLL
UAS LAS UAS LAS UAS LAS UAS LAS UAS LAS System
ar 78.52 64.69 79.38 66.91 78.72 66.67 79.60 67.09 79.34 66.91 MD06
bg 91.98 86.75 92.34 87.47 92.12 87.41 92.68 87.79 92.04 87.57 MD06
zh 91.25 86.50 91.81 87.53 92.27 88.23 92.58 88.51 93.18 89.96 RD06
cs 87.32 76.56 87.36 78.42 87.72 78.90 88.01 79.31 87.30 80.18 MD06
da 90.96 84.63 91.24 85.47 91.50 85.79 91.44 85.55 90.58 84.79 MD06
nl 83.79 78.81 84.25 80.49 84.27 80.41 84.45 80.31 83.57 79.19 MD06
en 91.92 88.09 92.10 88.96 92.19 89.18 92.45 89.43 92.38 90.13 JN08
de 90.52 87.46 90.52 87.12 90.40 87.30 90.79 87.74 90.38 87.34 MD06
ja 93.14 90.95 93.32 91.29 93.52 91.80 93.54 91.80 93.10 91.65 NV06
pt 91.60 86.05 91.04 86.46 91.02 87.30 91.54 87.68 91.22 87.60 NV06
sl 83.03 70.80 83.23 72.88 83.93 73.38 84.39 73.74 83.17 73.44 MD06
es 85.61 80.95 86.05 82.83 86.42 83.59 86.44 83.29 86.05 82.25 MD06
sv 89.07 81.88 89.74 82.77 89.82 83.13 89.94 83.09 89.50 84.58 NV06
tr 75.02 57.78 75.40 60.25 74.75 59.73 75.32 60.39 75.82 65.68 NV06
av 87.41 80.14 87.70 81.35 87.76 81.63 88.08 81.84 87.69 82.23 – –
</table>
<tableCaption confidence="0.692678333333333">
Table 1: UAS and LAS of non-projective versions of our parsing algorithms on 14 treebanks from
CoNLL shared tasks, together with three baseline systems and the best systems for each language re-
ported in CoNLL shared tasks. MD06 is McDonald et al. (2006), RD06 is Riedel et al. (2006), JN08
</tableCaption>
<bodyText confidence="0.9901982">
is Johansson and Nugues (2008), and NV06 is Nivre et al. (2006) Bold indicates the best result for a
language. Red values represent statistically significant improvements over two-stage baseline system
on the corresponding metrics with p &lt; 0.01, using McNemar’s test. Blue values indicate statistically
significant improvements with p &lt; 0.05.
climbing” non-projective parsing algorithm pro-
posed in McDonald and Pereira (2006). This ap-
proximating algorithm first searches the highest
scoring projective parse tree and then it rearranges
edges in the tree until the rearrangements do not
increase the score for the tree anymore 4.
</bodyText>
<subsectionHeader confidence="0.866771">
3.3 Results and Comparison
</subsectionHeader>
<bodyText confidence="0.999963473684211">
Table 1 illustrates the parsing results our parser
with non-projective parsing algorithm, together
with three baseline systems—the two-stage sys-
tem (McDonald, 2006) and the two intermediate
models, Model 0 and Model 1—and the best sys-
tems reported in CoNLL shared tasks for each lan-
guage. Our parser achieves better parsing perfor-
mance on both UAS and LAS than all the three
baseline systems for 12 languages. The two ex-
ceptions are Portuguese and Turkish, on which our
parser achieves better LAS and comparable UAS.
Comparing with the best systems from CoNLL,
our parser achieves better performance on both
UAS and LAS for 9 languages. Moreover, the av-
erage UAS of our parser over the 14 languages is
better than that of the best systems in CoNLL. It
should be noted that the best results for 14 lan-
guages in CoNLL are not from one single system,
but different systems that achieved best results for
</bodyText>
<footnote confidence="0.878307666666667">
4Additional care is required in the non-projective approx-
imation since a change of one edge could result in a label
change for multiple edges
</footnote>
<table confidence="0.999481">
System UAS LAS
MaltParser 89.3 86.9
MSTParser 90.7 87.6
DNNParser 91.8 89.6
This Paper 92.4 89.9
</table>
<tableCaption confidence="0.997995">
Table 2: Parsing performance on PTB. The re-
</tableCaption>
<bodyText confidence="0.946078909090909">
sults for MaltParser, MSTParser and DNNParser
are from table 5 of Chen and Manning (2014).
different languages. The system of McDonald et
al. (2006) achieved the best average parsing per-
formance over 13 languages (excluding English)
in CoNLL-2006 shared tasks. Its average UAS and
LAS are 87.03% and 80.83%, respectively, while
our average UAS and LAS excluding English are
87.79% and 81.29%. So our parser shows signif-
icant improvement over the single best system re-
ported in CoNLL-2006 shared task.
</bodyText>
<subsectionHeader confidence="0.988364">
3.4 Experiments on PTB
</subsectionHeader>
<bodyText confidence="0.999932">
To make a thorough empirical comparison with
previous studies, we also evaluate our system on
the English Penn Treebanks (Marcus et al., 1993)
with Stanford Basic Dependencies (De Marn-
effe et al., 2006). We compare our parser with
three off-the-shelf parsers: MaltParser (Nivre and
Scholz, 2004; Zhang and Clark, 2008; Zhang
and Nivre, 2011), MSTParser (McDonald et al.,
2005), and the parser using Neural Networks
</bodyText>
<page confidence="0.968044">
1325
</page>
<table confidence="0.999868090909091">
Label Description F1 (UAS) diff F1 (LAS) diff
TST Ours TST Ours
MNR Adverbial of manner 54.01 66.10 12.10 52.23 62.15 9.92
OPRD Predicative complement of raising/control verb 86.61 96.92 10.31 86.61 89.89 3.28
APPO Apposition 77.40 82.62 5.22 72.74 77.03 4.29
ADV General adverbial 73.33 77.65 4.32 69.86 73.14 3.28
AMOD Modifier of adjective or adverbial 75.49 79.58 4.09 72.60 76.91 4.30
TMP Temporal adverbial or nominal modifier 73.47 76.76 3.29 64.50 68.59 4.09
DIR Adverbial of direction 62.42 65.02 2.60 62.42 64.61 2.19
LOC Locative adverbial or nominal modifier 75.78 78.35 2.57 63.11 65.83 2.72
OBJ Object 91.69 94.08 2.39 90.62 93.23 2.61
</table>
<tableCaption confidence="0.996235">
Table 3: Top 10 dependency labels on which our algorithm achieves most improvements on the F1 score
</tableCaption>
<bodyText confidence="0.959355166666667">
of UAS, together with the corresponding improvements of LAS. “TST” indicates the two-stage system.
The first column is the label name in the treebank. The second column is the label’s description from
Surdeanu et al. (2008).
(DNNParser) (Chen and Manning, 2014). The re-
sults are listed in Table 2. Clearly, our parser is
superior in terms of both UAS and LAS.
</bodyText>
<subsectionHeader confidence="0.971402">
3.5 Analysis
</subsectionHeader>
<bodyText confidence="0.999974473684211">
To better understand the performance of our
parser, we analyze the distribution of our parser’s
UAS and LAS over different dependency labels
on the English CoNLL treebank, compared with
the ones of the two-stage model. Table 3 lists the
top 10 dependency labels on which our algorithm
achieves most improvements on the F1 score of
UAS, together with the corresponding improve-
ments of LAS.
From Table 3 we can see among the 10 labels,
there are 5 labels — “MNR”, “ADV”, “TMP”,
“DIR”, “LOC” — which are a specific kind of ad-
verbials. This illustrates that our parser performs
well on the recognition of different kinds of ad-
verbials. Moreover, the label “OPRD” and “OBJ”
indicate dependency relations between verbs and
their modifiers, too. In addition, our parser also
significantly improves the accuracy of apposi-
tional relations (“APPO”).
</bodyText>
<sectionHeader confidence="0.996454" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999978095238095">
We proposed a new dependency parsing algo-
rithm which can jointly learn dependency struc-
tures and edge labels. Our parser is able to use
multiple edge-label features, while maintaining
low computational complexity. Experimental re-
sults on 14 languages show that our parser sig-
nificantly improves the accuracy of both depen-
dency structures (UAS) and edge labels (LAS),
over three baseline systems and three off-the-shelf
parsers. This demonstrates that jointly learning
dependency structures and edge labels can bene-
fit both performance of tree structures and label-
ing accuracy. Moreover, our parser outperforms
the best systems of different languages reported in
CoNLL shared task for 9 languages.
In future, we are interested in extending our
parser to higher-order factorization by increas-
ing horizontal context (e.g., from siblings to “tri-
siblings”) and vertical context (e.g., from siblings
to “grand-siblings”) and validating its effective-
ness via a wide range of NLP applications.
</bodyText>
<sectionHeader confidence="0.996924" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997045">
This research was supported in part by DARPA
grant FA8750-12-2-0342 funded under the DEFT
program. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of DARPA.
</bodyText>
<sectionHeader confidence="0.998851" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.970635875">
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of Coling-2010, pages 89–97, Beijing, China,
August.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceeding of CoNLL-2006, pages 149–164, New
York, NY.
Xavier Carreras. 2007. Experiments with a higher-
order projective dependency parser. In Proceed-
ings of the CoNLL Shared Task Session of EMNLP-
CONLL, pages 957–961.
Danqi Chen and Christopher Manning. 2014. A fast
and accurate dependency parser using neural net-
works. In Proceedings of EMNLP-2014, pages 740–
750, Doha, Qatar, October.
</reference>
<page confidence="0.942852">
1326
</page>
<reference confidence="0.994808163636363">
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
Journal of Machine Learining Research, 3:951–991.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. Jornal of Machine
Learning Research, 7:551–585.
Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In Proceedings of LREC-2006, pages 449–
454.
Greg Durrett and Dan Klein. 2013. Easy victories
and uphill battles in coreference resolution. In Pro-
ceedings of EMNLP-2013, pages 1971–1982, Seat-
tle, Washington, USA, October.
Jason Eisner. 1996. Three new probabilistic models
for dependency parsing: An exploration. In Pro-
ceedings of COLING-1996, pages 340–345.
Nicolas R Fauceglia, Yiu-Chang Lin, Xuezhe Ma, and
Eduard Hovy. 2015. Word sense disambiguation
via propstore and ontonotes for event mention de-
tection. In Proceedings of the The 3rd Workshop on
EVENTS: Definition, Detection, Coreference, and
Representation, pages 11–15, Denver, Colorado,
June.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based syntactic-semantic analysis with
propbank and nombank. In Proceedings of the
CoNLL-2008, pages 183–187.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of ACL-
2010, pages 1–11, Uppsala, Sweden, July.
Xuezhe Ma and Fei Xia. 2014. Unsupervised de-
pendency parsing with transferring distribution via
parallel guidance and entropy regularization. In
Proceedings of ACL-2014, pages 1337–1348, Bal-
timore, Maryland, June.
Xuezhe Ma and Hai Zhao. 2012a. Fourth-order depen-
dency parsing. In Proceedings of COLING 2012:
Posters, pages 785–796, Mumbai, India, December.
Xuezhe Ma and Hai Zhao. 2012b. Probabilistic mod-
els for high-order projective dependency parsing.
Technical Report, arXiv:1502.04174.
Mitchell Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: the Penn Treebank. Computa-
tional Linguistics, 19(2):313–330.
Andre Martins, Miguel Almeida, and Noah A. Smith.
2013. Turning on the turbo: Fast third-order non-
projective turbo parsers. In Proceedings of ACL-
2013 (Volume 2: Short Papers), pages 617–622,
Sofia, Bulgaria, August.
Ryan McDonald and Fernando Pereira. 2006. Online
learning of approximate dependency parsing algo-
rithms. In Proceedings of EACL-2006, pages 81–88,
Trento, Italy, April.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of HLT/EMNLP-2005, pages 523–530, Vancouver,
Canada, October.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a two-
stage discriminative parser. In Proceedings of the
Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X), pages 216–220, New
York City, June.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria
Bertomeu Castell´o, and Jungmee Lee. 2013. Uni-
versal dependency annotation for multilingual pars-
ing. In Proceedings of ACL-2013, pages 92–97,
Sofia, Bulgaria, August.
Ryan McDonald. 2006. Discriminative learning span-
ning tree algorithm for dependency parsing. Ph.D.
thesis, University of Pennsylvania.
Joakim Nivre and Mario Scholz. 2004. Deterministic
dependency parsing of English text. In Proceedings
of COLING-2004, pages 64–70, Geneva, Switzer-
land, August 23-27.
Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en
Eryiˇgit, and Svetoslav Marinov. 2006. Labeled
pseudo-projective dependency parsing with support
vector machines. In Proceedings of the Tenth Con-
ference on Computational Natural Language Learn-
ing (CoNLL-X), pages 221–225, New York City,
June.
Sebastian Riedel, Ruket C¸akıcı, and Ivan Meza-Ruiz.
2006. Multi-lingual dependency parsing with incre-
mental integer linear programming. In Proceedings
of the Tenth Conference on Computational Natu-
ral Language Learning (CoNLL-X), pages 226–230,
New York City, June.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu´ıs M`arquez, and Joakim Nivre. 2008. The conll-
2008 shared task on joint parsing of syntactic and
semantic dependencies. In Proceedings of CoNLL-
2008, pages 159–177.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel
dependency-to-string model for statistical machine
translation. In Proceedings of EMNLP-2011, pages
216–226, Edinburgh, Scotland, UK., July.
Yue Zhang and Stephen Clark. 2008. A tale of
two parsers: investigating and combining graph-
based and transition-based dependency parsing us-
ing beam search. In Proceedings of EMNLP, pages
562–571.
</reference>
<page confidence="0.840198">
1327
</page>
<reference confidence="0.98165425">
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceeding of ACL 2011, pages 188–193, Portland,
Oregon, June.
</reference>
<page confidence="0.993809">
1328
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.538518">
<title confidence="0.99893">Efficient Inner-to-outer Greedy for Higher-order Labeled Dependency Parsing</title>
<author confidence="0.637254">Ma</author>
<affiliation confidence="0.7890145">Language Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.993588">Pittsburgh, PA 15213,</address>
<email confidence="0.999649">xuezhem@cs.cmu.edu,ehovy@andrew.cmu.edu</email>
<abstract confidence="0.99625">Many NLP systems use dependency parsers as critical components. Jonit learning parsers usually achieve better parsing accuracies than two-stage methods. However, classical joint parsing algorithms significantly increase computational complexity, which makes joint learning impractical. In this paper, we proposed an efficient dependency parsing algorithm that is capable of capturing multiple edge-label features, while maintaining low computational complexity. We evaluate our parser on 14 different languages. Our parser consistently obtains more accurate results than three baseline systems and three popular, off-the-shelf parsers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Very high accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling-2010,</booktitle>
<pages>89--97</pages>
<location>Beijing, China,</location>
<contexts>
<context position="2198" citStr="Bohnet, 2010" startWordPosition="307" endWordPosition="308">b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; Bohnet, 2010) used richer label features but increased systems’ complexities significantly, while achieving better parsing accuracy. Yet, there are no previous work addressing the problem of good balance between parsing accuracy and computational costs for joint parsing models. In this paper, we propose a new dependency parsing algorithm that can utilize edge-label information of more than one edge, while simultaneously maintaining low computational complexity. The component needed to solve this dilemma is an inner-to-outer greedy approximation to avoid an exhaustive search. The contributions of this work </context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Very high accuracy and fast dependency parsing is not a contradiction. In Proceedings of Coling-2010, pages 89–97, Beijing, China, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceeding of CoNLL-2006,</booktitle>
<pages>149--164</pages>
<location>New York, NY.</location>
<contexts>
<context position="10922" citStr="Buchholz and Marsi, 2006" startWordPosition="1849" endWordPosition="1852"> are generated before outer ones (t). Thus, using already computed “best” labels of inner dependency edges makes us get rid of maximizing over two labels, l&apos; and l. Moreover, we do not have to extend each incomplete span by the augmentation with a “label” index. This makes the space complexity remains O(n2), which is important in practice. The graphical specification is provided in Figure 1 (d). 3 Experiments 3.1 Setup We conduct our experiments on 14 languages, including the English treebank from CoNLL-2008 shared task (Surdeanu et al., 2008) and all 13 treebanks from CoNLL-2006 shared task (Buchholz and Marsi, 2006). We train our parser using The kbest version of the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; Crammer et al., 2006; McDonald, 2006). In our experiments, we set k = 1 and fix the number of iteration to 10, instead of tuning these parameters on development sets. Following previous work, all experiments are evaluated on the metrics of unlabeled attachment score (UAS) and Labeled attachment score (LAS), using the official scorer3 of CoNLL2006 shared task. 3.2 Non-Projective Parsing The parsing algorithms described in the paper fall into the category of projective dependen</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceeding of CoNLL-2006, pages 149–164, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
</authors>
<title>Experiments with a higherorder projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLPCONLL,</booktitle>
<pages>957--961</pages>
<contexts>
<context position="2082" citStr="Carreras, 2007" startWordPosition="290" endWordPosition="291">led dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; Bohnet, 2010) used richer label features but increased systems’ complexities significantly, while achieving better parsing accuracy. Yet, there are no previous work addressing the problem of good balance between parsing accuracy and computational costs for joint parsing models. In this paper, we propose a new dependency parsing algorithm that can utilize edge-label information of more than one edge, while simultaneously maintaining low computational complexity. The component needed to solve t</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>Xavier Carreras. 2007. Experiments with a higherorder projective dependency parser. In Proceedings of the CoNLL Shared Task Session of EMNLPCONLL, pages 957–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danqi Chen</author>
<author>Christopher Manning</author>
</authors>
<title>A fast and accurate dependency parser using neural networks.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP-2014,</booktitle>
<pages>740--750</pages>
<location>Doha, Qatar,</location>
<contexts>
<context position="15089" citStr="Chen and Manning (2014)" startWordPosition="2550" endWordPosition="2553">e average UAS of our parser over the 14 languages is better than that of the best systems in CoNLL. It should be noted that the best results for 14 languages in CoNLL are not from one single system, but different systems that achieved best results for 4Additional care is required in the non-projective approximation since a change of one edge could result in a label change for multiple edges System UAS LAS MaltParser 89.3 86.9 MSTParser 90.7 87.6 DNNParser 91.8 89.6 This Paper 92.4 89.9 Table 2: Parsing performance on PTB. The results for MaltParser, MSTParser and DNNParser are from table 5 of Chen and Manning (2014). different languages. The system of McDonald et al. (2006) achieved the best average parsing performance over 13 languages (excluding English) in CoNLL-2006 shared tasks. Its average UAS and LAS are 87.03% and 80.83%, respectively, while our average UAS and LAS excluding English are 87.79% and 81.29%. So our parser shows significant improvement over the single best system reported in CoNLL-2006 shared task. 3.4 Experiments on PTB To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks (Marcus et al., 1993) with Stanford Basic De</context>
<context position="16955" citStr="Chen and Manning, 2014" startWordPosition="2848" endWordPosition="2851">0 TMP Temporal adverbial or nominal modifier 73.47 76.76 3.29 64.50 68.59 4.09 DIR Adverbial of direction 62.42 65.02 2.60 62.42 64.61 2.19 LOC Locative adverbial or nominal modifier 75.78 78.35 2.57 63.11 65.83 2.72 OBJ Object 91.69 94.08 2.39 90.62 93.23 2.61 Table 3: Top 10 dependency labels on which our algorithm achieves most improvements on the F1 score of UAS, together with the corresponding improvements of LAS. “TST” indicates the two-stage system. The first column is the label name in the treebank. The second column is the label’s description from Surdeanu et al. (2008). (DNNParser) (Chen and Manning, 2014). The results are listed in Table 2. Clearly, our parser is superior in terms of both UAS and LAS. 3.5 Analysis To better understand the performance of our parser, we analyze the distribution of our parser’s UAS and LAS over different dependency labels on the English CoNLL treebank, compared with the ones of the two-stage model. Table 3 lists the top 10 dependency labels on which our algorithm achieves most improvements on the F1 score of UAS, together with the corresponding improvements of LAS. From Table 3 we can see among the 10 labels, there are 5 labels — “MNR”, “ADV”, “TMP”, “DIR”, “LOC”</context>
</contexts>
<marker>Chen, Manning, 2014</marker>
<rawString>Danqi Chen and Christopher Manning. 2014. A fast and accurate dependency parser using neural networks. In Proceedings of EMNLP-2014, pages 740– 750, Doha, Qatar, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal of Machine Learining Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="11040" citStr="Crammer and Singer, 2003" startWordPosition="1870" endWordPosition="1873"> rid of maximizing over two labels, l&apos; and l. Moreover, we do not have to extend each incomplete span by the augmentation with a “label” index. This makes the space complexity remains O(n2), which is important in practice. The graphical specification is provided in Figure 1 (d). 3 Experiments 3.1 Setup We conduct our experiments on 14 languages, including the English treebank from CoNLL-2008 shared task (Surdeanu et al., 2008) and all 13 treebanks from CoNLL-2006 shared task (Buchholz and Marsi, 2006). We train our parser using The kbest version of the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; Crammer et al., 2006; McDonald, 2006). In our experiments, we set k = 1 and fix the number of iteration to 10, instead of tuning these parameters on development sets. Following previous work, all experiments are evaluated on the metrics of unlabeled attachment score (UAS) and Labeled attachment score (LAS), using the official scorer3 of CoNLL2006 shared task. 3.2 Non-Projective Parsing The parsing algorithms described in the paper fall into the category of projective dependency parsers, which exclude crossing dependency edges. Since the treebanks from CoNLL shared tasks contain non-projectiv</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal of Machine Learining Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>Jornal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="11062" citStr="Crammer et al., 2006" startWordPosition="1874" endWordPosition="1878">o labels, l&apos; and l. Moreover, we do not have to extend each incomplete span by the augmentation with a “label” index. This makes the space complexity remains O(n2), which is important in practice. The graphical specification is provided in Figure 1 (d). 3 Experiments 3.1 Setup We conduct our experiments on 14 languages, including the English treebank from CoNLL-2008 shared task (Surdeanu et al., 2008) and all 13 treebanks from CoNLL-2006 shared task (Buchholz and Marsi, 2006). We train our parser using The kbest version of the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; Crammer et al., 2006; McDonald, 2006). In our experiments, we set k = 1 and fix the number of iteration to 10, instead of tuning these parameters on development sets. Following previous work, all experiments are evaluated on the metrics of unlabeled attachment score (UAS) and Labeled attachment score (LAS), using the official scorer3 of CoNLL2006 shared task. 3.2 Non-Projective Parsing The parsing algorithms described in the paper fall into the category of projective dependency parsers, which exclude crossing dependency edges. Since the treebanks from CoNLL shared tasks contain non-projective edges, we use the “m</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. Jornal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC-2006,</booktitle>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC-2006, pages 449– 454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>Easy victories and uphill battles in coreference resolution.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP-2013,</booktitle>
<pages>1971--1982</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="1183" citStr="Durrett and Klein, 2013" startWordPosition="156" endWordPosition="159"> proposed an efficient dependency parsing algorithm that is capable of capturing multiple edge-label features, while maintaining low computational complexity. We evaluate our parser on 14 different languages. Our parser consistently obtains more accurate results than three baseline systems and three popular, off-the-shelf parsers. 1 Introduction Natural language processing (NLP) systems, like machine translation (Xie et al., 2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint le</context>
</contexts>
<marker>Durrett, Klein, 2013</marker>
<rawString>Greg Durrett and Dan Klein. 2013. Easy victories and uphill battles in coreference resolution. In Proceedings of EMNLP-2013, pages 1971–1982, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING-1996,</booktitle>
<pages>340--345</pages>
<contexts>
<context position="3521" citStr="Eisner, 1996" startWordPosition="510" endWordPosition="511">g parsing model which achieves both effectiveness and efficience. (iii) giving empirical evaluations of this parser on different treebanks over 14 languages. 2 Joint Parsing Algorithm 2.1 Basic Notations In the following, x represents a generic input sentence, and y represents a generic dependency tree. Formally, for a sentence x, dependency parsing is the task of finding the dependency tree y with the highest-score for x: y∗(x) = argmax Score(x,y). (1) y∈Y(x) Here y(x) denotes the set of possible dependency trees for sentence x. In this paper, we adopt the second-order sibling factorization (Eisner, 1996; McDonald and 1322 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1322–1328, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Pereira, 2006), in which each sibling part consists of a tuple of indices (h, m, c) where (h, m) and (h, c) are a pair of adjacent edges to the same side of the head h. By adding labele information to this factorization, Score(x, y) can be rewritten as: Score(x, y) = P Ssib(h, m, c, l1, l2) (h,m,c,l1,l2)Ey λT f(h, m, c, l1, l2) (2) = P (h,m,c,l1,l2)Ey Figure 1: The dynamic-programmi</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proceedings of COLING-1996, pages 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas R Fauceglia</author>
<author>Yiu-Chang Lin</author>
<author>Xuezhe Ma</author>
<author>Eduard Hovy</author>
</authors>
<title>Word sense disambiguation via propstore and ontonotes for event mention detection.</title>
<date>2015</date>
<booktitle>In Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation,</booktitle>
<pages>11--15</pages>
<location>Denver, Colorado,</location>
<contexts>
<context position="1121" citStr="Fauceglia et al., 2015" startWordPosition="146" endWordPosition="149">ty, which makes joint learning impractical. In this paper, we proposed an efficient dependency parsing algorithm that is capable of capturing multiple edge-label features, while maintaining low computational complexity. We evaluate our parser on 14 different languages. Our parser consistently obtains more accurate results than three baseline systems and three popular, off-the-shelf parsers. 1 Introduction Natural language processing (NLP) systems, like machine translation (Xie et al., 2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint lea</context>
</contexts>
<marker>Fauceglia, Lin, Ma, Hovy, 2015</marker>
<rawString>Nicolas R Fauceglia, Yiu-Chang Lin, Xuezhe Ma, and Eduard Hovy. 2015. Word sense disambiguation via propstore and ontonotes for event mention detection. In Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 11–15, Denver, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based syntactic-semantic analysis with propbank and nombank.</title>
<date>2008</date>
<booktitle>In Proceedings of the CoNLL-2008,</booktitle>
<pages>183--187</pages>
<contexts>
<context position="2183" citStr="Johansson and Nugues, 2008" startWordPosition="303" endWordPosition="306">ins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; Bohnet, 2010) used richer label features but increased systems’ complexities significantly, while achieving better parsing accuracy. Yet, there are no previous work addressing the problem of good balance between parsing accuracy and computational costs for joint parsing models. In this paper, we propose a new dependency parsing algorithm that can utilize edge-label information of more than one edge, while simultaneously maintaining low computational complexity. The component needed to solve this dilemma is an inner-to-outer greedy approximation to avoid an exhaustive search. The contribution</context>
<context position="13191" citStr="Johansson and Nugues (2008)" startWordPosition="2239" endWordPosition="2242"> 73.38 84.39 73.74 83.17 73.44 MD06 es 85.61 80.95 86.05 82.83 86.42 83.59 86.44 83.29 86.05 82.25 MD06 sv 89.07 81.88 89.74 82.77 89.82 83.13 89.94 83.09 89.50 84.58 NV06 tr 75.02 57.78 75.40 60.25 74.75 59.73 75.32 60.39 75.82 65.68 NV06 av 87.41 80.14 87.70 81.35 87.76 81.63 88.08 81.84 87.69 82.23 – – Table 1: UAS and LAS of non-projective versions of our parsing algorithms on 14 treebanks from CoNLL shared tasks, together with three baseline systems and the best systems for each language reported in CoNLL shared tasks. MD06 is McDonald et al. (2006), RD06 is Riedel et al. (2006), JN08 is Johansson and Nugues (2008), and NV06 is Nivre et al. (2006) Bold indicates the best result for a language. Red values represent statistically significant improvements over two-stage baseline system on the corresponding metrics with p &lt; 0.01, using McNemar’s test. Blue values indicate statistically significant improvements with p &lt; 0.05. climbing” non-projective parsing algorithm proposed in McDonald and Pereira (2006). This approximating algorithm first searches the highest scoring projective parse tree and then it rearranges edges in the tree until the rearrangements do not increase the score for the tree anymore 4. 3</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008. Dependency-based syntactic-semantic analysis with propbank and nombank. In Proceedings of the CoNLL-2008, pages 183–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient thirdorder dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL2010,</booktitle>
<pages>1--11</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="1566" citStr="Koo and Collins, 2010" startWordPosition="209" endWordPosition="212">ems, like machine translation (Xie et al., 2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of ACL2010, pages 1–11, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuezhe Ma</author>
<author>Fei Xia</author>
</authors>
<title>Unsupervised dependency parsing with transferring distribution via parallel guidance and entropy regularization.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL-2014,</booktitle>
<pages>1337--1348</pages>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="1069" citStr="Ma and Xia, 2014" startWordPosition="138" endWordPosition="141"> significantly increase computational complexity, which makes joint learning impractical. In this paper, we proposed an efficient dependency parsing algorithm that is capable of capturing multiple edge-label features, while maintaining low computational complexity. We evaluate our parser on 14 different languages. Our parser consistently obtains more accurate results than three baseline systems and three popular, off-the-shelf parsers. 1 Introduction Natural language processing (NLP) systems, like machine translation (Xie et al., 2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is</context>
</contexts>
<marker>Ma, Xia, 2014</marker>
<rawString>Xuezhe Ma and Fei Xia. 2014. Unsupervised dependency parsing with transferring distribution via parallel guidance and entropy regularization. In Proceedings of ACL-2014, pages 1337–1348, Baltimore, Maryland, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuezhe Ma</author>
<author>Hai Zhao</author>
</authors>
<title>Fourth-order dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012: Posters,</booktitle>
<pages>785--796</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="1585" citStr="Ma and Zhao, 2012" startWordPosition="213" endWordPosition="216">lation (Xie et al., 2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; </context>
</contexts>
<marker>Ma, Zhao, 2012</marker>
<rawString>Xuezhe Ma and Hai Zhao. 2012a. Fourth-order dependency parsing. In Proceedings of COLING 2012: Posters, pages 785–796, Mumbai, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuezhe Ma</author>
<author>Hai Zhao</author>
</authors>
<title>Probabilistic models for high-order projective dependency parsing.</title>
<date>2012</date>
<tech>Technical Report, arXiv:1502.04174.</tech>
<contexts>
<context position="1585" citStr="Ma and Zhao, 2012" startWordPosition="213" endWordPosition="216">lation (Xie et al., 2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; </context>
</contexts>
<marker>Ma, Zhao, 2012</marker>
<rawString>Xuezhe Ma and Hai Zhao. 2012b. Probabilistic models for high-order projective dependency parsing. Technical Report, arXiv:1502.04174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="15666" citStr="Marcus et al., 1993" startWordPosition="2642" endWordPosition="2645">are from table 5 of Chen and Manning (2014). different languages. The system of McDonald et al. (2006) achieved the best average parsing performance over 13 languages (excluding English) in CoNLL-2006 shared tasks. Its average UAS and LAS are 87.03% and 80.83%, respectively, while our average UAS and LAS excluding English are 87.79% and 81.29%. So our parser shows significant improvement over the single best system reported in CoNLL-2006 shared task. 3.4 Experiments on PTB To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks (Marcus et al., 1993) with Stanford Basic Dependencies (De Marneffe et al., 2006). We compare our parser with three off-the-shelf parsers: MaltParser (Nivre and Scholz, 2004; Zhang and Clark, 2008; Zhang and Nivre, 2011), MSTParser (McDonald et al., 2005), and the parser using Neural Networks 1325 Label Description F1 (UAS) diff F1 (LAS) diff TST Ours TST Ours MNR Adverbial of manner 54.01 66.10 12.10 52.23 62.15 9.92 OPRD Predicative complement of raising/control verb 86.61 96.92 10.31 86.61 89.89 3.28 APPO Apposition 77.40 82.62 5.22 72.74 77.03 4.29 ADV General adverbial 73.33 77.65 4.32 69.86 73.14 3.28 AMOD M</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Miguel Almeida</author>
<author>Noah A Smith</author>
</authors>
<title>Turning on the turbo: Fast third-order nonprojective turbo parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL2013 (Volume 2: Short Papers),</booktitle>
<pages>617--622</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="1608" citStr="Martins et al., 2013" startWordPosition="217" endWordPosition="220">2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; Bohnet, 2010) used rich</context>
</contexts>
<marker>Martins, Almeida, Smith, 2013</marker>
<rawString>Andre Martins, Miguel Almeida, and Noah A. Smith. 2013. Turning on the turbo: Fast third-order nonprojective turbo parsers. In Proceedings of ACL2013 (Volume 2: Short Papers), pages 617–622, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL-2006,</booktitle>
<pages>81--88</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="13586" citStr="McDonald and Pereira (2006)" startWordPosition="2296" endWordPosition="2299">s from CoNLL shared tasks, together with three baseline systems and the best systems for each language reported in CoNLL shared tasks. MD06 is McDonald et al. (2006), RD06 is Riedel et al. (2006), JN08 is Johansson and Nugues (2008), and NV06 is Nivre et al. (2006) Bold indicates the best result for a language. Red values represent statistically significant improvements over two-stage baseline system on the corresponding metrics with p &lt; 0.01, using McNemar’s test. Blue values indicate statistically significant improvements with p &lt; 0.05. climbing” non-projective parsing algorithm proposed in McDonald and Pereira (2006). This approximating algorithm first searches the highest scoring projective parse tree and then it rearranges edges in the tree until the rearrangements do not increase the score for the tree anymore 4. 3.3 Results and Comparison Table 1 illustrates the parsing results our parser with non-projective parsing algorithm, together with three baseline systems—the two-stage system (McDonald, 2006) and the two intermediate models, Model 0 and Model 1—and the best systems reported in CoNLL shared tasks for each language. Our parser achieves better parsing performance on both UAS and LAS than all the </context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL-2006, pages 81–88, Trento, Italy, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP-2005,</booktitle>
<pages>523--530</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="15900" citStr="McDonald et al., 2005" startWordPosition="2678" endWordPosition="2681">nd LAS are 87.03% and 80.83%, respectively, while our average UAS and LAS excluding English are 87.79% and 81.29%. So our parser shows significant improvement over the single best system reported in CoNLL-2006 shared task. 3.4 Experiments on PTB To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks (Marcus et al., 1993) with Stanford Basic Dependencies (De Marneffe et al., 2006). We compare our parser with three off-the-shelf parsers: MaltParser (Nivre and Scholz, 2004; Zhang and Clark, 2008; Zhang and Nivre, 2011), MSTParser (McDonald et al., 2005), and the parser using Neural Networks 1325 Label Description F1 (UAS) diff F1 (LAS) diff TST Ours TST Ours MNR Adverbial of manner 54.01 66.10 12.10 52.23 62.15 9.92 OPRD Predicative complement of raising/control verb 86.61 96.92 10.31 86.61 89.89 3.28 APPO Apposition 77.40 82.62 5.22 72.74 77.03 4.29 ADV General adverbial 73.33 77.65 4.32 69.86 73.14 3.28 AMOD Modifier of adjective or adverbial 75.49 79.58 4.09 72.60 76.91 4.30 TMP Temporal adverbial or nominal modifier 73.47 76.76 3.29 64.50 68.59 4.09 DIR Adverbial of direction 62.42 65.02 2.60 62.42 64.61 2.19 LOC Locative adverbial or no</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of HLT/EMNLP-2005, pages 523–530, Vancouver, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual dependency analysis with a twostage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>216--220</pages>
<location>New York City,</location>
<contexts>
<context position="13124" citStr="McDonald et al. (2006)" startWordPosition="2227" endWordPosition="2230"> 91.54 87.68 91.22 87.60 NV06 sl 83.03 70.80 83.23 72.88 83.93 73.38 84.39 73.74 83.17 73.44 MD06 es 85.61 80.95 86.05 82.83 86.42 83.59 86.44 83.29 86.05 82.25 MD06 sv 89.07 81.88 89.74 82.77 89.82 83.13 89.94 83.09 89.50 84.58 NV06 tr 75.02 57.78 75.40 60.25 74.75 59.73 75.32 60.39 75.82 65.68 NV06 av 87.41 80.14 87.70 81.35 87.76 81.63 88.08 81.84 87.69 82.23 – – Table 1: UAS and LAS of non-projective versions of our parsing algorithms on 14 treebanks from CoNLL shared tasks, together with three baseline systems and the best systems for each language reported in CoNLL shared tasks. MD06 is McDonald et al. (2006), RD06 is Riedel et al. (2006), JN08 is Johansson and Nugues (2008), and NV06 is Nivre et al. (2006) Bold indicates the best result for a language. Red values represent statistically significant improvements over two-stage baseline system on the corresponding metrics with p &lt; 0.01, using McNemar’s test. Blue values indicate statistically significant improvements with p &lt; 0.05. climbing” non-projective parsing algorithm proposed in McDonald and Pereira (2006). This approximating algorithm first searches the highest scoring projective parse tree and then it rearranges edges in the tree until the</context>
<context position="15148" citStr="McDonald et al. (2006)" startWordPosition="2559" endWordPosition="2562">than that of the best systems in CoNLL. It should be noted that the best results for 14 languages in CoNLL are not from one single system, but different systems that achieved best results for 4Additional care is required in the non-projective approximation since a change of one edge could result in a label change for multiple edges System UAS LAS MaltParser 89.3 86.9 MSTParser 90.7 87.6 DNNParser 91.8 89.6 This Paper 92.4 89.9 Table 2: Parsing performance on PTB. The results for MaltParser, MSTParser and DNNParser are from table 5 of Chen and Manning (2014). different languages. The system of McDonald et al. (2006) achieved the best average parsing performance over 13 languages (excluding English) in CoNLL-2006 shared tasks. Its average UAS and LAS are 87.03% and 80.83%, respectively, while our average UAS and LAS excluding English are 87.79% and 81.29%. So our parser shows significant improvement over the single best system reported in CoNLL-2006 shared task. 3.4 Experiments on PTB To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks (Marcus et al., 1993) with Stanford Basic Dependencies (De Marneffe et al., 2006). We compare our parse</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual dependency analysis with a twostage discriminative parser. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 216–220, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini,</title>
<date>2013</date>
<journal>N´uria Bertomeu Castell´o, and Jungmee</journal>
<booktitle>In Proceedings of ACL-2013,</booktitle>
<pages>92--97</pages>
<location>Sofia, Bulgaria,</location>
<marker>McDonald, Nivre, 2013</marker>
<rawString>Ryan McDonald, Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu Castell´o, and Jungmee Lee. 2013. Universal dependency annotation for multilingual parsing. In Proceedings of ACL-2013, pages 92–97, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative learning spanning tree algorithm for dependency parsing.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1666" citStr="McDonald, 2006" startWordPosition="228" endWordPosition="229"> Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; Bohnet, 2010) used richer label features but increased systems’ complexities sign</context>
<context position="7587" citStr="McDonald (2006)" startWordPosition="1270" endWordPosition="1271">s in Stanford Basic Dependencies (De Marneffe et al., 2006) is 45, and the 1Symmetric right-headed versions are elided for brevity t s r r t s r r t (a) Exact search (b) Model 0: single-edge label (c) Model 1: sibling with single label (d) Inner-to-outer greedy search l l’ t + r l r t t s r l(s, t) + r t t s t l*(s, t) = l = l*(s, t) = l*(s, r) + = l*(s, r) + l(s, r, t, l*(s, r)) l(s, r, t) = s r + r + rt l*(s, t) l *(s, t) = l*(s, r) t t r = l*(s, r) + = l*(s, r) + = = + r r+1 t t + r r+1 t + r r+1 t = t = t s r r t r r + r r+1 t t 1323 2.3.2 Model 1: Sibling with Single Label As remarked in McDonald (2006), Model 0 can be slightly enriched to include single label features associated with a sibling part. Formally, Ssib(h, m, c, l1, l2) = Ssib(h, m, c, l2). Now, the dynamic-programming derivation is I(s,t) = maw {I(s,r) + S(r,t) + Ssib(s, r, t, l(s, r, t))} where l(s, r, t) = argmax Ssib(s, r, t, l). lEL The additional algorithm to calculate the best edge label l(s, r, t) takes O( LIn3) time. Therefore, this algorithm requires O( L n3) time and O(n2) space2. Figure 1 (b) and Figure 1 (c) provide the graphical specifications for Model 0 and Model 1, respectively. 2.4 Inner-to-outer Greedy Search T</context>
<context position="11079" citStr="McDonald, 2006" startWordPosition="1879" endWordPosition="1880">reover, we do not have to extend each incomplete span by the augmentation with a “label” index. This makes the space complexity remains O(n2), which is important in practice. The graphical specification is provided in Figure 1 (d). 3 Experiments 3.1 Setup We conduct our experiments on 14 languages, including the English treebank from CoNLL-2008 shared task (Surdeanu et al., 2008) and all 13 treebanks from CoNLL-2006 shared task (Buchholz and Marsi, 2006). We train our parser using The kbest version of the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; Crammer et al., 2006; McDonald, 2006). In our experiments, we set k = 1 and fix the number of iteration to 10, instead of tuning these parameters on development sets. Following previous work, all experiments are evaluated on the metrics of unlabeled attachment score (UAS) and Labeled attachment score (LAS), using the official scorer3 of CoNLL2006 shared task. 3.2 Non-Projective Parsing The parsing algorithms described in the paper fall into the category of projective dependency parsers, which exclude crossing dependency edges. Since the treebanks from CoNLL shared tasks contain non-projective edges, we use the “mountain3http://il</context>
<context position="13981" citStr="McDonald, 2006" startWordPosition="2357" endWordPosition="2358">the corresponding metrics with p &lt; 0.01, using McNemar’s test. Blue values indicate statistically significant improvements with p &lt; 0.05. climbing” non-projective parsing algorithm proposed in McDonald and Pereira (2006). This approximating algorithm first searches the highest scoring projective parse tree and then it rearranges edges in the tree until the rearrangements do not increase the score for the tree anymore 4. 3.3 Results and Comparison Table 1 illustrates the parsing results our parser with non-projective parsing algorithm, together with three baseline systems—the two-stage system (McDonald, 2006) and the two intermediate models, Model 0 and Model 1—and the best systems reported in CoNLL shared tasks for each language. Our parser achieves better parsing performance on both UAS and LAS than all the three baseline systems for 12 languages. The two exceptions are Portuguese and Turkish, on which our parser achieves better LAS and comparable UAS. Comparing with the best systems from CoNLL, our parser achieves better performance on both UAS and LAS for 9 languages. Moreover, the average UAS of our parser over the 14 languages is better than that of the best systems in CoNLL. It should be no</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan McDonald. 2006. Discriminative learning spanning tree algorithm for dependency parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Mario Scholz</author>
</authors>
<title>Deterministic dependency parsing of English text.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING-2004,</booktitle>
<pages>64--70</pages>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="1945" citStr="Nivre and Scholz, 2004" startWordPosition="271" endWordPosition="274">redict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Martins et al., 2013; Ma and Zhao, 2012a). A two-stage method (McDonald, 2006) is often used because the complexity of some joint learning models is unacceptably high. On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels (Nivre and Scholz, 2004). Previous studies explored the trade-off between computational costs and parsing performance. Some work (McDonald, 2006; Carreras, 2007) simplified labeled information to only single label features. Other work (Johansson and Nugues, 2008; Bohnet, 2010) used richer label features but increased systems’ complexities significantly, while achieving better parsing accuracy. Yet, there are no previous work addressing the problem of good balance between parsing accuracy and computational costs for joint parsing models. In this paper, we propose a new dependency parsing algorithm that can utilize edg</context>
<context position="15818" citStr="Nivre and Scholz, 2004" startWordPosition="2665" endWordPosition="2668">ver 13 languages (excluding English) in CoNLL-2006 shared tasks. Its average UAS and LAS are 87.03% and 80.83%, respectively, while our average UAS and LAS excluding English are 87.79% and 81.29%. So our parser shows significant improvement over the single best system reported in CoNLL-2006 shared task. 3.4 Experiments on PTB To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks (Marcus et al., 1993) with Stanford Basic Dependencies (De Marneffe et al., 2006). We compare our parser with three off-the-shelf parsers: MaltParser (Nivre and Scholz, 2004; Zhang and Clark, 2008; Zhang and Nivre, 2011), MSTParser (McDonald et al., 2005), and the parser using Neural Networks 1325 Label Description F1 (UAS) diff F1 (LAS) diff TST Ours TST Ours MNR Adverbial of manner 54.01 66.10 12.10 52.23 62.15 9.92 OPRD Predicative complement of raising/control verb 86.61 96.92 10.31 86.61 89.89 3.28 APPO Apposition 77.40 82.62 5.22 72.74 77.03 4.29 ADV General adverbial 73.33 77.65 4.32 69.86 73.14 3.28 AMOD Modifier of adjective or adverbial 75.49 79.58 4.09 72.60 76.91 4.30 TMP Temporal adverbial or nominal modifier 73.47 76.76 3.29 64.50 68.59 4.09 DIR Adv</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>Joakim Nivre and Mario Scholz. 2004. Deterministic dependency parsing of English text. In Proceedings of COLING-2004, pages 64–70, Geneva, Switzerland, August 23-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>G¨uls¸en Eryiˇgit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudo-projective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>221--225</pages>
<location>New York City,</location>
<marker>Nivre, Hall, Nilsson, Eryiˇgit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryiˇgit, and Svetoslav Marinov. 2006. Labeled pseudo-projective dependency parsing with support vector machines. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 221–225, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Ruket C¸akıcı</author>
<author>Ivan Meza-Ruiz</author>
</authors>
<title>Multi-lingual dependency parsing with incremental integer linear programming.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>226--230</pages>
<location>New York City,</location>
<marker>Riedel, C¸akıcı, Meza-Ruiz, 2006</marker>
<rawString>Sebastian Riedel, Ruket C¸akıcı, and Ivan Meza-Ruiz. 2006. Multi-lingual dependency parsing with incremental integer linear programming. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 226–230, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llu´ıs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The conll2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL2008,</booktitle>
<pages>159--177</pages>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llu´ıs M`arquez, and Joakim Nivre. 2008. The conll2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of CoNLL2008, pages 159–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Xie</author>
<author>Haitao Mi</author>
<author>Qun Liu</author>
</authors>
<title>A novel dependency-to-string model for statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP-2011,</booktitle>
<pages>216--226</pages>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="993" citStr="Xie et al., 2011" startWordPosition="126" endWordPosition="129">curacies than two-stage methods. However, classical joint parsing algorithms significantly increase computational complexity, which makes joint learning impractical. In this paper, we proposed an efficient dependency parsing algorithm that is capable of capturing multiple edge-label features, while maintaining low computational complexity. We evaluate our parser on 14 different languages. Our parser consistently obtains more accurate results than three baseline systems and three popular, off-the-shelf parsers. 1 Introduction Natural language processing (NLP) systems, like machine translation (Xie et al., 2011), resourcelow languages processing (McDonald et al., 2013; Ma and Xia, 2014), word sense disambiguation (Fauceglia et al., 2015) , and entity coreference resolution (Durrett and Klein, 2013), are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees. Dependency parsers predict dependency structures and dependency type labels on each edge. However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (Koo and Collins, 2010; Ma and Zhao, 2012b; Marti</context>
</contexts>
<marker>Xie, Mi, Liu, 2011</marker>
<rawString>Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel dependency-to-string model for statistical machine translation. In Proceedings of EMNLP-2011, pages 216–226, Edinburgh, Scotland, UK., July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: investigating and combining graphbased and transition-based dependency parsing using beam search.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>562--571</pages>
<contexts>
<context position="15841" citStr="Zhang and Clark, 2008" startWordPosition="2669" endWordPosition="2672">ing English) in CoNLL-2006 shared tasks. Its average UAS and LAS are 87.03% and 80.83%, respectively, while our average UAS and LAS excluding English are 87.79% and 81.29%. So our parser shows significant improvement over the single best system reported in CoNLL-2006 shared task. 3.4 Experiments on PTB To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks (Marcus et al., 1993) with Stanford Basic Dependencies (De Marneffe et al., 2006). We compare our parser with three off-the-shelf parsers: MaltParser (Nivre and Scholz, 2004; Zhang and Clark, 2008; Zhang and Nivre, 2011), MSTParser (McDonald et al., 2005), and the parser using Neural Networks 1325 Label Description F1 (UAS) diff F1 (LAS) diff TST Ours TST Ours MNR Adverbial of manner 54.01 66.10 12.10 52.23 62.15 9.92 OPRD Predicative complement of raising/control verb 86.61 96.92 10.31 86.61 89.89 3.28 APPO Apposition 77.40 82.62 5.22 72.74 77.03 4.29 ADV General adverbial 73.33 77.65 4.32 69.86 73.14 3.28 AMOD Modifier of adjective or adverbial 75.49 79.58 4.09 72.60 76.91 4.30 TMP Temporal adverbial or nominal modifier 73.47 76.76 3.29 64.50 68.59 4.09 DIR Adverbial of direction 62.</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: investigating and combining graphbased and transition-based dependency parsing using beam search. In Proceedings of EMNLP, pages 562–571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceeding of ACL 2011,</booktitle>
<pages>188--193</pages>
<location>Portland, Oregon,</location>
<contexts>
<context position="15865" citStr="Zhang and Nivre, 2011" startWordPosition="2673" endWordPosition="2676">006 shared tasks. Its average UAS and LAS are 87.03% and 80.83%, respectively, while our average UAS and LAS excluding English are 87.79% and 81.29%. So our parser shows significant improvement over the single best system reported in CoNLL-2006 shared task. 3.4 Experiments on PTB To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks (Marcus et al., 1993) with Stanford Basic Dependencies (De Marneffe et al., 2006). We compare our parser with three off-the-shelf parsers: MaltParser (Nivre and Scholz, 2004; Zhang and Clark, 2008; Zhang and Nivre, 2011), MSTParser (McDonald et al., 2005), and the parser using Neural Networks 1325 Label Description F1 (UAS) diff F1 (LAS) diff TST Ours TST Ours MNR Adverbial of manner 54.01 66.10 12.10 52.23 62.15 9.92 OPRD Predicative complement of raising/control verb 86.61 96.92 10.31 86.61 89.89 3.28 APPO Apposition 77.40 82.62 5.22 72.74 77.03 4.29 ADV General adverbial 73.33 77.65 4.32 69.86 73.14 3.28 AMOD Modifier of adjective or adverbial 75.49 79.58 4.09 72.60 76.91 4.30 TMP Temporal adverbial or nominal modifier 73.47 76.76 3.29 64.50 68.59 4.09 DIR Adverbial of direction 62.42 65.02 2.60 62.42 64.6</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceeding of ACL 2011, pages 188–193, Portland, Oregon, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>