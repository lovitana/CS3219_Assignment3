<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.992704">
Representing Text for Joint Embedding of Text and Knowledge Bases
</title>
<author confidence="0.994184">
Kristina Toutanova Danqi Chen∗ Patrick Pantel
</author>
<affiliation confidence="0.995827">
Microsoft Research Computer Science Department Microsoft Research
</affiliation>
<address confidence="0.728466">
Redmond, WA, USA Stanford University Redmond, WA, USA
</address>
<author confidence="0.670737">
Hoifung Poon
</author>
<affiliation confidence="0.666214">
Microsoft Research
</affiliation>
<address confidence="0.689916285714286">
Redmond, WA, USA
Pallavi Choudhury
Microsoft Research
Redmond, WA, USA
Michael Gamon
Microsoft Research
Redmond, WA, USA
</address>
<sectionHeader confidence="0.942942" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999907142857143">
Models that learn to represent textual and
knowledge base relations in the same con-
tinuous latent space are able to perform
joint inferences among the two kinds of re-
lations and obtain high accuracy on knowl-
edge base completion (Riedel et al., 2013).
In this paper we propose a model that cap-
tures the compositional structure of tex-
tual relations, and jointly optimizes entity,
knowledge base, and textual relation rep-
resentations. The proposed model signifi-
cantly improves performance over a model
that does not share parameters among tex-
tual relations with common sub-structure.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999107">
Representing information about real-world enti-
ties and their relations in structured knowledge
base (KB) form enables numerous applications.
Large, collaboratively created knowledge bases
have recently become available e.g., Freebase
(Bollacker et al., 2008), YAGO (Suchanek et al.,
2007), and DBPedia (Auer et al., 2007), but even
though they are impressively large, their coverage
is far from complete. This has motivated research
in automatically deriving new facts to extend a
manually built knowledge base, by using infor-
mation from the existing knowledge base, textual
mentions of entities, and semi-structured data such
as tables and web forms (Nickel et al., 2015).
In this paper we build upon the work of Riedel
et al. (2013), which jointly learns continuous rep-
resentations for knowledge base and textual rela-
tions. This common representation in the same
vector space can serve as a kind of “universal
schema” which admits joint inferences among
</bodyText>
<footnote confidence="0.7021305">
∗This research was conducted during the author’s intern-
ship at Microsoft Research.
</footnote>
<subsectionHeader confidence="0.923941">
Knowledge Base
</subsectionHeader>
<bodyText confidence="0.829472">
nationality
</bodyText>
<subsectionHeader confidence="0.967274">
Textual Mentions
</subsectionHeader>
<bodyText confidence="0.8905402">
Barack Obama is the 44th and current
President of United States.
Obama was born in the United States
just as he has always said.
...
</bodyText>
<figureCaption confidence="0.9973535">
Figure 1: A knowledge base fragment coupled with textual
mentions of pairs of entities.
</figureCaption>
<bodyText confidence="0.999973038461539">
KBs and text. The textual relations represent the
relationships between entities expressed in indi-
vidual sentences (see Figure 1 for an example).
Riedel et al. (2013) represented each textual men-
tion of an entity pair by the lexicalized depen-
dency path between the two entities (see Figure 2).
Each such path is treated as a separate relation in
a combined knowledge graph including both KB
and textual relations. Following prior work in la-
tent feature models for knowledge base comple-
tion, every textual relation receives its own contin-
uous representation, learned from the pattern of its
co-occurrences in the knowledge graph.
However, largely synonymous textual relations
often share common sub-structure, and are com-
posed of similar words and dependency arcs.
For example, Table 1 shows a collection of
dependency paths co-occurring with the per-
son/organizations founded relation.
In this paper we model this sub-structure
and share parameters among related dependency
paths, using a unified loss function learning entity
and relation representations to maximize perfor-
mance on the knowledge base link prediction task.
We evaluate our approach on the FB15k-237
dataset, a knowledge base derived from the Free-
</bodyText>
<figure confidence="0.996390125">
United
States
Barack
Obama
Honolulu
place-of-birth
city-of
ClueWeb
</figure>
<page confidence="0.979657">
1499
</page>
<note confidence="0.985021">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999880272727273">
base subset FB15k (Bordes et al., 2013) and
filtered to remove highly redundant relations
(Toutanova and Chen, 2015). The knowledge base
is paired with textual mentions for all entity pairs
derived from ClueWeb121 with Freebase entity
mention annotations (Gabrilovich et al., 2013).
We show that using a convolutional neural net-
work to derive continuous representations for tex-
tual relations boosts the overall performance on
link prediction, with larger improvement on entity
pairs that have textual mentions.
</bodyText>
<sectionHeader confidence="0.999815" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999556">
There has been a growing body of work on learn-
ing to predict relations between entities without re-
quiring sentence-level annotations of textual men-
tions at training time. We group such related work
into three groups based on whether KB, text, or
both sources of information are used. Addition-
ally, we discuss related work in the area of super-
vised relation extraction using continuous repre-
sentations of text, even though we do not use su-
pervision at the level of textual mentions.
</bodyText>
<subsectionHeader confidence="0.489373">
Knowledge base completion
</subsectionHeader>
<bodyText confidence="0.999878090909091">
Nickel et al. (2015) provide a broad overview of
machine learning models for knowledge graphs,
including models based on observed graph fea-
tures such as the path ranking algorithm (Lao et
al., 2011), models based on continuous represen-
tations (latent features), and model combinations
(Dong et al., 2014). These models predict new
facts in a given knowledge base, based on infor-
mation from existing entities and relations. From
this line of work, most relevant to our study is
prior work evaluating continuous representation
models on the FB15k dataset. Yang et al. (2015)
showed that a simple variant of a bilinear model
DISTMULT outperformed TRANSE (Bordes et al.,
2013) and more richly parameterized models on
this dataset. We therefore build upon the best per-
forming prior model DISTMULT from this line of
work, as well as additional models E and F devel-
oped in the context of text-augmented knowledge
graphs (Riedel et al., 2013), and extend them to in-
corporate compositional representations of textual
relations.
</bodyText>
<footnote confidence="0.997249">
1http://lemurproject.org/clueweb12/
FACC1/
</footnote>
<subsectionHeader confidence="0.717484">
Relation extraction using distant supervision
</subsectionHeader>
<bodyText confidence="0.998833632653062">
A number of works have focused on extracting
new instances of relations using information from
textual mentions, without sophisticated model-
ing of prior knowledge from the knowledge base.
Mintz et al. (2009) demonstrated that both surface
context and dependency path context were help-
ful for the task, but did not model the composi-
tional sub-structure of this context. Other work
proposed more sophisticated models that reason
about sentence-level hidden variables (Riedel et
al., 2010; Hoffmann et al., 2011; Surdeanu et al.,
2012) or model the noise arising from the incom-
pleteness of knowledge bases and text collections
(Ritter et al., 2013), inter alia. Our work focuses
on representing the compositional structure of sen-
tential context for learning joint continuous repre-
sentations of text and knowledge bases.
Combining knowledge base and text
information
A combination of knowledge base and textual in-
formation was first shown to outperform either
source alone in the framework of path-ranking al-
gorithms in a combined knowledge base and text
graph (Lao et al., 2012). To alleviate the spar-
sity of textual relations arising in such a com-
bined graph, (Gardner et al., 2013; Gardner et al.,
2014) showed how to incorporate clusters or con-
tinuous representations of textual relations. Note
that these vector representations are based on the
co-occurrence patterns for the textual relations
and not on their compositional structure. Co-
occurrence based textual relation representations
were also learned in (Neelakantan et al., 2015).
Wang et al. (2014a) combined knowledge base and
text information by embedding knowledge base
entities and the words in their names in the same
vector space, but did not model the textual co-
occurrences of entity pairs and the expressed tex-
tual relations. Weston et al. (2013) combined con-
tinuous representations from a knowledge base
and textual mentions for prediction of new rela-
tions. The two representations were trained inde-
pendently of each other and using different loss
functions, and were only combined at inference
time. Additionally, the employed representations
of text were non-compositional.
In this work we train continuous representations
of knowledge base and textual relations jointly,
which allows for deeper interactions between the
</bodyText>
<page confidence="0.971638">
1500
</page>
<bodyText confidence="0.9998068">
sources of information. We directly build on the
universal schema approach of Riedel et al. (2013)
as well as the universal schema extension of the
DISTMULT model mentioned previously, to im-
prove the representations of textual relations by
capturing their compositional structure. Addition-
ally, we evaluate the approach on a dataset that
contains rich prior information from the training
knowledge base, as well as a wealth of textual in-
formation from a large document collection.
</bodyText>
<sectionHeader confidence="0.5417105" genericHeader="method">
Continuous representations for supervised
relation extraction
</sectionHeader>
<bodyText confidence="0.999718625">
In contrast to the work reviewed so far, work on
sentence-level relation extraction using direct su-
pervision has focused heavily on representing sen-
tence context. Models using hand-crafted fea-
tures have evolved for more than a decade, and
recently, models using continuous representations
have been found to achieve new state-of-the-art
performance (Zeng et al., 2014; Gormley et al.,
2015). Compared to work on representation learn-
ing for sentence-level context, such as this recent
work using LSTM models on constituency or de-
pendency trees (Tai et al., 2015), our approach us-
ing a one-hidden-layer convolutional neural net-
work is relatively simple. However, even such a
simple approach has been shown to be very com-
petitive (Kim, 2014).
</bodyText>
<sectionHeader confidence="0.995851" genericHeader="method">
3 Models for knowledge base completion
</sectionHeader>
<bodyText confidence="0.99904745">
We begin by introducing notation to define the
task, largely following the terminology in Nickel
et al. (2015). We assume knowledge bases are rep-
resented using RDF triples, in the form (subject,
predicate, object), where the subject and object are
entities and the predicate is the type of relation.
For example, the KB fragment shown in Figure 1
is shown as a knowledge graph, where the enti-
ties are the nodes, and the relations are shown as
directed labeled edges: we see three entities par-
ticipating in three relation instances indicated by
the edges. For brevity, we will denote triples by
(es, r, eo), where es and eo denote the subject and
object entities, respectively.
The task is, given a training KB consisting of
entities with some relations between them, to pre-
dict new relations (links) that do not appear in the
training KB. More specifically, we will build mod-
els that rank candidate entities for given queries
(es, r, ?) or (?, r, eo), which ask about the object
</bodyText>
<equation confidence="0.632755333333333">
Barack Obama is the 44th and currrent President of United States .
nsubj prep obj
SUBJECT &lt; president ——+ of —+ OBJECT
</equation>
<figureCaption confidence="0.9622265">
Figure 2: Textual relation extracted from an entity
pair mention.
</figureCaption>
<bodyText confidence="0.996807863636364">
or subject of a given relation.
This task setting has been used in models for
KB completion previously, e.g. (Dong et al., 2014;
Gardner et al., 2014), even though it has not been
standard in evaluations of distant supervision for
relation extraction (Mintz et al., 2009; Riedel et
al., 2013). The advantage of this evaluation set-
ting is that it enables automatic evaluation without
requiring humans to label candidate extractions,
while making only a local closed world assump-
tion for the completeness of the knowledge base
— i.e., if one object eo for a certain subject / rela-
tion pair (es, r) is present in the knowledge base,
it is assumed likely that all other objects (es, r, eo)
will be present. Such an assumption is particularly
justified for nearly functional relations.
To incorporate textual information, we follow
prior work (Lao et al., 2012; Riedel et al., 2013)
and represent both textual and knowledge base re-
lations in a single graph of “universal” relations.
The textual relations are represented as full lexi-
calized dependency paths, as illustrated in Figure
</bodyText>
<listItem confidence="0.7102">
2. An instance of the textual relation SUBJECT( n
</listItem>
<bodyText confidence="0.940672409090909">
subj
prep obj
president ��) of �)OBJECT connecting the entities
BARACK OBAMA and UNITED STATES, is added to the
knowledge graph based on this sentential occur-
rence.
To present the models for knowledge base
completion based on such combined knowledge
graphs, we first introduce some notation. Let £
denote the set of entities in the knowledge graph
and let R denote the set of relation types. We de-
note each possible triple as T = (es, r, eo) where
es, eo E £, r E R, and model its presence with
a binary random variable yT E 10, 11 which in-
dicates whether the triple exists. The models we
build score possible triples (es, r, eo) using contin-
uous representations (latent features) of the three
elements of the triple. The models use scoring
function f(es, r, eo) to represent the model’s con-
fidence in the existence of the triple. We present
the models and then the loss function used to train
nsubj prep pobj
</bodyText>
<page confidence="0.573505">
1501
</page>
<figure confidence="0.9206265">
r (es, eo)
F:
E:
DISTMULT:
</figure>
<figureCaption confidence="0.9975335">
Figure 3: The continuous representations for
model F, E and DISTMULT.
</figureCaption>
<bodyText confidence="0.774141">
their parameters.
</bodyText>
<subsectionHeader confidence="0.998289">
3.1 Basic Models
</subsectionHeader>
<bodyText confidence="0.999974722222222">
We begin with presenting the three models from
prior work that this research builds upon. They
all learn latent continuous representations of rela-
tions and entities or entity pairs, and score possible
triples based on the learned continuous represen-
tations. Each of the models can be defined on a
knowledge graph containing entities and KB rela-
tions only, or on a knowledge graph additionally
containing textual relations. We use models F and
E from (Riedel et al., 2013) where they were used
for a combined KB+text graph, and model DIST-
MULT from (Yang et al., 2015), which was origi-
nally used for a knowledge graph containing only
KB relations.
As shown in Figure 3, model F learns a K-
dimensional latent feature vector for each can-
didate entity pair (es, eo), as well as a same-
dimensional vector for each relation r, and the
</bodyText>
<sectionHeader confidence="0.397259" genericHeader="method">
1
</sectionHeader>
<bodyText confidence="0.999663034482759">
scoring function is simply defined as their inner
product: f(es, r, eo) = v(r)Tv(es, eo). Therefore,
different pairs sharing the same entity would not
share parameters in this model.
Model E does not have parameters for entity
pairs, and instead has parameters for individual
entities. It aims to capture the compatibility be-
tween entities and the subject and object posi-
tions of relations. For each relation type r, the
model learns two latent feature vectors v(rs) and
v(ro) of dimension K. For each entity (node) ei,
the model also learns a latent feature vector of
the same dimensionality. The score of a candi-
date triple (es, r, eo) is defined as f(es, r, eo) =
v(rs)Tv(es) + v(ro)Tv(eo). It can be seen that
when a subject entity is fixed in a query (es, r, ?),
the ranking of candidate object entity fillers ac-
cording to f does not depend on the subject entity
but only on the relation type r.
The third model DISTMULT, is a special form
of a bilinear model like RESCAL (Nickel et al.,
2011), where the non-diagonal entries in the rela-
tion matrices are assumed to be zero. This model
was proposed in Yang et al. (2015) and was shown
to outperform prior work on the FB15k dataset.
In this model, each entity ei and each relation r
is assigned a latent feature vector of dimension K.
The score of a candidate triple (es, r, eo) is defined
as f(es, r, eo) = v(r)T (v(es) o v(eo)), where o
denotes the element-wise vector product. In this
model, entity pairs which share an entity also share
parameters, and the ranking of candidate objects
for queries (es, r, ?) depends on the subject entity.
Denote Ne = |£|, Nr = |R|, and K = di-
mension of latent feature vectors, then model E
has KNe + 2KNr parameters and model DIST-
MULT has KNe + KNr parameters. Model F
has KN2e + KNr parameters, although most en-
tity pairs will not co-occur in the knowledge base
or text.
In the basic models, knowledge base and textual
relations are treated uniformly, and each textual re-
lation receives its own latent representation of di-
mensionality K. When textual relations are added
to the training knowledge graph, the total number
of relations |R |grows substantially (it increases
from 237 to more than 2.7 million for the dataset
in this study), resulting in a substantial increase in
the total number of independent parameters.
Note that in all of these models queries
about the arguments of knowledge base relations
(es, r, ?) are answered by scoring functions look-
ing only at the entity and KB relation represen-
tations, without using representations of textual
mentions. The textual mention information and
representations are only used at training time to
improve the learned representations of KB rela-
tions and entities.
</bodyText>
<table confidence="0.9785875">
rs es ro eo
+
r es eo
( )
</table>
<page confidence="0.906061">
1502
</page>
<subsectionHeader confidence="0.9646035">
3.2 CONV: Compositional Representations of
Textual Relations
</subsectionHeader>
<bodyText confidence="0.999950581395349">
In the standard latent feature models discussed
above, each textual relation is treated as an atomic
unit receiving its own set of latent features. How-
ever, many textual relations differ only slightly
in the words or dependency arcs used to express
the relation. For example, Table 1 shows sev-
eral textual patterns that co-occurr with the re-
lation person/organizations founded in the train-
ing KB. While some dependency paths occur fre-
quently, many very closely related ones have been
observed only once. The statistical strength of the
model could be improved if similar dependency
paths have a shared parameterization. We build on
work using similar intuitions for other tasks and
learn compositional representations of textual re-
lations based on their internal structure, so that the
derived representations are accurate for the task of
predicting knowledge base relations.
We use a convolutional neural network applied
to the lexicalized dependency paths treated as a se-
quence of words and dependency arcs with direc-
tion. Figure 4 depicts the neural network archi-
tecture. In the first layer, each word or directed la-
beled arc is mapped to a continuous representation
using an embedding matrix V. In the hidden layer,
every window of three elements is mapped to a
hidden vector using position-specific maps W, a
bias vector b, and a tanh activation function. A
max-pooling operation over the sequence is ap-
plied to derive the final continuous representation
for the dependency path.
The CONV representation of textual relations
can be used to augment any of the three basic mod-
els. The difference between a basic model and its
CONV-augmented variant is in the parameteriza-
tion of textual mentions. The basic models learn
distinct latent feature vectors of dimensionality K
for all textual relation types, whereas the CONV
models derive the K-dimensional latent feature
vectors for textual relation types as the activation
at the top layer of the convolutional network in
Figure 4, given the corresponding lexicalized de-
pendency path as input.
</bodyText>
<subsectionHeader confidence="0.996698">
3.3 Training loss function
</subsectionHeader>
<bodyText confidence="0.999846888888889">
All basic and CONV-augmented models use the
same training loss function. Our loss function
is motivated by the link prediction task and the
performance measures used. As previously men-
tioned, the task is to predict the subject or ob-
ject entity for given held-out triples (es, r, eo),
i.e., to rank all entities with respect to their like-
lihood of filling the respective position in the
triple2. We would thus like the model to score cor-
rect triples (es, r, eo) higher than incorrect triples
(e&apos;, r, eo) and (es, r, e&apos;) which differ from the cor-
rect triple by one entity. Several approaches
(Nickel et al., 2015) use a margin-based loss func-
tion. We use an approximation to the negative log-
likelihood of the correct entity filler instead3. We
define the conditional probabilities p(eo|es, r) and
p(es|r, eo) for object and subject entities given the
relation and the other argument as follows:
</bodyText>
<equation confidence="0.99961">
p(eo|es, r; O) = f (es,r,e&apos;;Θ)
Ee&apos;ENeg(es,r,?) e
</equation>
<bodyText confidence="0.985730529411765">
Conditional probabilities for subject entities
p(es|eo, r; O) are defined analogously. Here O de-
notes all the parameters of latent features. The
denominator is defined using a set of entities
that do not fill the object position in any relation
triple (es, r, ?) in the training knowledge graph.
Since the number of such entities is impractically
large, we sample negative triples from the full
set. We also limit the candidate entities to ones
that have types consistent with the position in the
relation triple (Chang et al., 2014; Yang et al.,
2015), where the types are approximated follow-
ing Toutanova and Chen (2015). Additionally,
since the task of predicting textual relations is aux-
iliary to the main task, we use a weighting factor T
for the loss on predicting the arguments of textual
relations (Toutanova and Chen, 2015).
</bodyText>
<equation confidence="0.986857">
Denote T as a set of triples, we define the loss
L(T ; O) as:
L(T ; O) = − � log p(eo|es, r; O)
(es,r,eo)ET
�− log p(es|eo, r; O)
(es,r,eo)ET
</equation>
<bodyText confidence="0.999878">
Let TKB and Ttext represent the set of knowl-
edge base triples and textual relation triples re-
spectively. The final training loss function is de-
</bodyText>
<footnote confidence="0.977548142857143">
2Our experimental comparison focuses on predicting ob-
ject entities only, but we consider both argument types in the
training loss function.
3Note that both margin-based and likelihood-based loss
functions are susceptible to noise from potential selection of
false negative examples. An empirical comparison of training
loss functions would be interesting.
</footnote>
<table confidence="0.995429894736842">
ef(es,r,eo;Θ)
1503
Textual Pattern Count
appos −−→of pobj 12
SUBJECT −−−→founder prep −−→OBJECT 3
nsubj dobj 3
SUBJECT ←−−−co-founded→OBJECT 3
appos −−→of pobj 2
SUBJECT −−−→co-founder prep −−→OBJECT 2
conj −−→of pobj 2
SUBJECT −−→co-founder prep −−→OBJECT 2
pobj ←−−co-founded dobj 2
SUBJECT ←−−with prep −−→OBJECT 2
nsubjxcomp dobj 2
SUBJECT ←−−−signed−−−→establishingOBJECT 1
pobj −−→of pobj 1
SUBJECT ←−−with prep 1
←−−founders prep −−→OBJECT 1
appos −−→of pobj 1
SUBJECT −−−→founders prep −−→OBJECT
nsubj prep pobj prep pobj
SUBJECT ←−−−one−−→of→founders→of→OBJECT
nsubj dobjconj
SUBJECT ←−−−founded→production→OBJECT
appos pobj −−→production conj
SUBJECT ←−−−partner ←−−with prep
←−−founded dobj −−→OBJECT
pobj ←−−co-founded rcmod
SUBJECT ←−−by prep ←−−−OBJECT
−−→of pobj
SUBJECTnn ←−co-founder prep
−−→OBJECT
dep −−→of pobj
SUBJECT −−→co-founder prep −−→OBJECT
nsubjxcomp dobj
SUBJECT ←−−−helped−−−→establishOBJECT
nsubjxcomp dobj
SUBJECT ←−−−signed−−−→creatingOBJECT
</table>
<tableCaption confidence="0.977272333333333">
Table 1: Textual patterns occurring with entity pairs in a person/organizations founded relationship. The
count indicates the number of training set instances that have this KB relation, which co-occur with each
textual pattern.
</tableCaption>
<figureCaption confidence="0.998951">
Figure 4: The convolutional neural network architecture for representing textual relations.
</figureCaption>
<equation confidence="0.96186375">
r = max{h }
h = tanh(W—1v _1 + W0v + W1v +1 + b)
v = V e
SUBJECT appos
���! co-founder prep pobj
��! of ��! OBJECT
fined as:
L(TKB; o) + TL(Ttext; o) + Akok2,
</equation>
<bodyText confidence="0.999983625">
where A is the regularization parameter, and T is
the weighing factor of the textual relations.
The parameters of all models are trained using a
batch training algorithm. The gradients of the ba-
sic models are straightforward to compute, and the
gradients of the convolutional network parameters
for the CONV-augmented models are also not hard
to derive using back-propagation.
</bodyText>
<sectionHeader confidence="0.999867" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.946319">
Dataset and Evaluation Protocol
</subsectionHeader>
<bodyText confidence="0.994472625">
We use the FB15k-237 4 dataset, which is a sub-
set of FB15k (Bordes et al., 2013) that excludes
redundant relations and direct training links for
held-out triples, with the goal of making the task
more realistic (Toutanova and Chen, 2015). The
FB15k dataset has been used in multiple stud-
ies on knowledge base completion (Wang et al.,
2014b; Yang et al., 2015). Textual relations for
</bodyText>
<footnote confidence="0.95727">
4Check the first author’s website for a release of the
dataset.
</footnote>
<page confidence="0.997446">
1504
</page>
<bodyText confidence="0.999868130434782">
FB15k-237 are extracted from 200 million sen-
tences in the ClueWeb12 corpus coupled with
Freebase mention annotations (Gabrilovich et al.,
2013), and include textual links of all co-occurring
entities from the KB set. After pruning5, there are
2.7 million unique textual relations that are added
to the knowledge graph. The set of textual rela-
tions is larger than the set used in Toutanova and
Chen (2015) (25,000 versus 2.7 million), leading
to improved performance.
The number of relations and triples in the train-
ing, validation and test portions of the data are
given in Table 2. The two rows list statistics for
the KB and text portions of the data separately.
The 2.7 million textual relations occur in 3.9 mil-
lion text triples. Almost all entities occur in tex-
tual relations (13,937 out of 14,541). The num-
bers of triples for textual relations are shown as
zero for the validation and test sets because we
don’t evaluate on prediction of textual relations
(all text triples are used in training). The per-
centage of KB triples that have textual relations
for their pair of entities is 40.5% for the training,
26.6% for the validation, and 28.1% for the test
set. While 26.6% of the validation set triples have
textual mentions, the percentage with textual re-
lations that have been seen in the training set is
18.4%. Having a mention increases the chance
that a random entity pair has a relation from 0.1%
to 5.0% — a fifty-fold increase.
Given a set of triples in a set disjoint from a
training knowledge graph, we test models on pre-
dicting the object of each triple, given the subject
and relation type. We rank all entities in the train-
ing knowledge base in order of their likelihood of
filling the argument position. We report the mean
reciprocal rank (MRR) of the correct entity, as
well as HITS@10 — the percentage of test triples
for which the correct entity is ranked in the top
10. We use filtered measures following the pro-
tocol proposed in Bordes et al. (2013) — that is,
when we rank entities for a given position, we re-
move all other entities that are known to be part of
an existing triple in the training, validation, or test
set. This avoids penalizing the model for ranking
other correct fillers higher than the tested entity.
</bodyText>
<footnote confidence="0.61456975">
5The full set of 37 million textual patterns connecting the
entity pairs of interest was pruned based on the count of pat-
terns and their tri-grams, and their precision in indicating that
entity pairs have KB relations.
</footnote>
<subsectionHeader confidence="0.575189">
Implementation details
</subsectionHeader>
<bodyText confidence="0.998864361111111">
We used a value of A = 1 for the weight of the
L2 penalty for the main results in Table 3, and
present some results on the impact of A at the end
of this section. We used batch optimization af-
ter initial experiments with AdaGrad showed in-
ferior performance. L-BFGS (Liu and Nocedal,
1989) and RProp (Riedmiller and Braun, 1993)
were found to converge to similar function values,
with RProp converging significantly faster. We
thus used RProp for optimization. We initialized
the KB+text models from the KB-only models and
also from random initial values (sampled from a
Gaussian distribution), and stopped optimization
when the overall MRR on the validation set de-
creased. For each model type, we chose the better
of random and KB-only initialization. The word
embeddings in the CONV models were initialized
using the 50-dimensional vectors from Turian et
al. (2010) in the main experiments, with a slight
positive impact. The effect of initialization is dis-
cussed at the end of the section.
The number of negative examples for each triple
was set to 200. Performance improved substan-
tially when the number of negative examples was
increased and reached a plateau around 200. We
chose the optimal number of latent feature dimen-
sions via a grid search to optimize MRR on the
validation set, testing the values 5, 10, 15, 35, 50,
100, 200 and 500. We also performed a grid search
over the values of the parameter T, testing values
in the set 10.01, 0.1, 0.25, 0.5, 11. The best dimen-
sion for latent feature vectors was 10 for most KB-
only models (not including model F), and 5 for the
two model configurations including F. We used
K = 10 for all KB+text models, as higher dimen-
sion was also not helpful for them.
</bodyText>
<subsectionHeader confidence="0.878992">
Experimental results
</subsectionHeader>
<bodyText confidence="0.999943333333333">
In Table 3 we show the performance of differ-
ent models and their combinations6, both when
using textual mentions (KB+text), and when us-
ing only knowledge base relations (KB only). In
the KB+text setting, we evaluate the contribution
of the CONV representations of the textual rela-
tions. The upper portion of the Table shows the
performance of models that have been trained us-
ing knowledge graphs including only knowledge
</bodyText>
<footnote confidence="0.791896666666667">
6Different models are combined by simply defining a
combined scoring function which adds the scores from in-
dividual models. Combined models are trained jointly.
</footnote>
<page confidence="0.89635">
1505
</page>
<table confidence="0.999677333333333">
# Relations # Entities # Triples in Train / Validation / Test
KB 237 14,541 272,115 / 17,535 / 20, 466
Text 2,740k 13,937 3,978k / 0 / 0
</table>
<tableCaption confidence="0.993534">
Table 2: The statistics of dataset FB15k-237.
</tableCaption>
<table confidence="0.999946411764706">
Model Overall With mentions Without mentions
MRR HITS@10 MRR HITS@10 MRR HITS@10
KB only
F 16.9 24.5 26.4 49.1 13.3 15.5
E 33.2 47.6 25.5 37.8 36.0 51.2
DISTMULT 35.7 52.3 26.0 39.0 39.3 57.2
E+DISTMULT 37.3 55.2 28.6 42.9 40.5 59.8
F+E+DISTMULT 33.8 50.1 15.0 26.1 40.7 59.0
KB and text
F (τ = 1) 19.4 27.9 35.4 61.6 13.4 15.5
CONV-F (τ = 1) 19.2 28.4 34.9 63.7 13.3 15.4
E (τ = 0) 33.2 47.6 25.5 37.8 36.0 51.2
CONV-E (τ = 0) 33.2 47.6 25.5 37.8 36.0 51.2
DISTMULT (τ = 0.01) 36.1 52.7 26.5 39.5 39.6 57.5
CONV-DISTMULT (τ = 0.25) 36.6 53.5 28.3 43.4 39.7 57.2
E + DISTMULT (τ = 0.01) 37.7 55.7 28.9 43.4 40.9 60.2
CONV-E + CONV-DISTMULT (τ = 0.25) 40.1 58.1 33.9 49.9 42.4 61.1
</table>
<tableCaption confidence="0.999401">
Table 3: Results on FB15k-237 for KB only and KB+text inference, with basic models versus the pro-
</tableCaption>
<bodyText confidence="0.982974769230769">
posed CONV-augmented models. The values of the hyper-parameter τ (as shown in the Table) were
chosen to maximize MRR on the validation set. The reported numbers were obtained for the test set.
base relations, and are not using any information
from textual mentions. The lower portion of the
Table shows the performance when textual rela-
tions are added to the training knowledge graph
and the corresponding training loss function. Note
that all models predict based on the learned knowl-
edge base relation and entity representations, and
the textual relations are only used at training time
when they can impact these representations.
The performance of all models is shown as an
overall MRR (scaled by 100) and HITS@10, as
well as performance on the subset of triples that
have textual mentions (column With mentions),
and ones that do not (column Without mentions).
Around 28% of the test triples have mentions and
contribute toward the measures in the With men-
tions column, and the other 72% of the test triples
contribute to the Without mentions column.
For the KB-only models, we see the perfor-
mance of each individual model F, E, and DIST-
MULT. Model F was the best performing single
model from (Riedel et al., 2013), but it does not
perform well when textual mentions are not used.
In our implementation of model F, we created en-
tity pair parameters only for entity pairs that co-
occur in the text data (Riedel et al. (2013) also
trained pairwise vectors for co-occuring entities
only, but all of the training and test tuples in their
study were co-occurring)7. Without textual in-
formation, model F is performing essentially ran-
domly, because entity pairs in the test sets do not
occur in training set relations (by construction of
the dataset). Model E is able to do surprisingly
well, given that it is making predictions for each
object position of a relation without considering
the given subject of the relation. DISTMULT is
the best performing single model. Unlike model
F, it is able to share parameters among entity pairs
with common subject or object entities, and, un-
like model E, it captures some dependencies be-
tween the subject and object entities of a relation.
The combination of models E+DISTMULT im-
proves performance, but combining model F with
the other two is not helpful.
The lower portion of Table 3 shows results when
textual relations are added to the training knowl-
edge graph. The basic models treat the textual re-
lations as atomic and learn a separate latent feature
vector for each textual relation. The CONV- mod-
els use the compositional representations of tex-
</bodyText>
<footnote confidence="0.9983556">
7Learning entity pair parameters for all entity pairs would
result in 2.2 billion parameters for vectors with dimensional-
ity 10 for our dataset. This was infeasible and was also not
found useful based on experiments with vectors of lower di-
mensionality.
</footnote>
<page confidence="0.992691">
1506
</page>
<bodyText confidence="0.999980976190477">
tual relations learned using the convolutional neu-
ral network architecture shown in Figure 4. We
show the performance of each individual model
and its corresponding variant with a CONV pa-
rameterization. For each model, we also show the
optimal value of T, the weight of the textual re-
lations loss. Model F is able to benefit from tex-
tual relations and its performance increases by 2.5
points in MRR, with the gain in performance be-
ing particularly large on test triples with textual
mentions. Model F is essentially limiting its space
of considered argument fillers to ones that have co-
occurred with the given subject entity. This gives it
an advantage on test triples with textual mentions,
but model F still does relatively very poorly over-
all when taking into account the much more nu-
merous test triples without textual mentions. The
CONV parameterization performs slightly worse
in MRR, but slightly better in HITS@10, com-
pared to the atomic parameterization. For model
E and its CONV variant, we see that text does not
help as its performance using text is the same as
that when not using text and the optimal weight
of the text is zero. Model DISTMULT benefits
from text, and its convolutional text variant CONV-
DISTMULT outperforms the basic model, with the
gain being larger on test triples with mentions.
The best model overall, as in the KB-only
case, is E+DISTMULT. The basic model bene-
fits from text slightly and the model with compo-
sitional representations of textual patterns CONV-
E+CONV-DISTMULT, improves the performance
further, by 2.4 MRR overall, and by 5 MRR on
triples with textual mentions. It is interesting
that the text and the compositional representations
helped most for this combined model. One hy-
pothesis is that model E, which provides a prior
over relation arguments, is needed in combination
with DISTMULT to prevent the prediction of un-
likely arguments based on noisy inference from
textual patterns and their individual words and de-
pendency links.
</bodyText>
<subsectionHeader confidence="0.891697">
Hyperparameter Sensitivity
</subsectionHeader>
<bodyText confidence="0.99998703125">
To gain insight into the sensitivity of the model to
hyper-parameters and initialization, we report on
experiments starting with the best model CONV-
E + CONV-DISTMULT from Table 3 and varying
one parameter at a time. This model has weight
of the textual relations loss T = 0.25, weight of
the L2 penalty A = 1, convolution window size of
three, and is initialized randomly for the entity and
KB relation vectors, and from pre-trained embed-
dings for word vectors (Turian et al., 2010). The
overall MRR of the model is 40.4 on the validation
set (test results are shown in the Table).
When the weight of T is changed to 1 (i.e., equal
contribution of textual and KB relations), the over-
all MRR goes down to 39.6 from 40.4, indicat-
ing the usefulness of weighting the two kinds of
relations non-uniformly. When A is reduced to
0.04, MRR is 40.0 and when A is increased to
25, MRR goes down to 38.9. This indicates the
L2 penalty hyper-parameter has a large impact on
performance. When we initialize the word embed-
dings randomly instead of using pre-trained word
vectors, performance drops only slightly to 40.3.
If we initialize from a model trained using KB-
only information, performance goes down sub-
stantially to 38.7. This indicates that initialization
is important and there is a small gain from using
pre-trained word embeddings. There was a drop
in performance to MRR 40.2 when using a win-
dow size of one for the convolutional architecture
in Figure 4, and an increase to 40.6 when using a
window size of five.
</bodyText>
<sectionHeader confidence="0.992794" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999878">
Here we explored an alternative representation
of textual relations for latent feature models that
learn to represent knowledge base and textual re-
lations in the same vector space. We showed that
given the large degree of sharing of sub-structure
in the textual relations, it was beneficial to com-
pose their continuous representations out of the
representations of their component words and de-
pendency arc links. We applied a convolutional
neural network model and trained it jointly with a
model mapping entities and knowledge base rela-
tions to the same vector space, obtaining substan-
tial improvements over an approach that treats the
textual relations as atomic units having indepen-
dent parameterization.
</bodyText>
<sectionHeader confidence="0.996177" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998043">
We would like to thank the anonymous review-
ers for their suggestions, and Jianfeng Gao, Scott
Wen-tau Yih, and Wei Xu for useful discussions.
</bodyText>
<page confidence="0.992761">
1507
</page>
<sectionHeader confidence="0.982154" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999756961904762">
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives.
2007. Dbpedia: A nucleus for a web of open data.
Springer.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring
human knowledge. In Proceedings of the 2008 ACM
SIGMOD international conference on Management
of data, pages 1247–1250. ACM.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Advances in Neural Information
Processing Systems (NIPS).
Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and
Christopher Meek. 2014. Typed tensor decompo-
sition of knowledge bases for relation extraction. In
Empirical Methods in Natural Language Processing
(EMNLP).
Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowledge
vault: A web-scale approach to probabilistic knowl-
edge fusion. In International Conference on Knowl-
edge Discovery and Data Mining (KDD).
Evgeniy Gabrilovich, Michael Ringgaard, and Amar-
nag Subramanya. 2013. FACC1: Freebase anno-
tation of ClueWeb corpora, Version 1 (release date
2013-06-26, format version 1, correction level 0).
Matt Gardner, Partha Pratim Talukdar, Bryan Kisiel,
and Tom Mitchell. 2013. Improving learning and
inference in a large knowledge-base using latent
syntactic cues. In Empirical Methods in Natural
Language Processing (EMNLP).
Matt Gardner, Partha Talukdar, Jayant Krishnamurthy,
and Tom Mitchell. 2014. Incorporating vector space
similarity in random walk inference over knowledge
bases. In Empirical Methods in Natural Language
Processing (EMNLP).
Matthew R Gormley, Mo Yu, and Mark Dredze.
2015. Improved relation extraction with feature-rich
compositional embedding models. arXiv preprint
arXiv:1505.02419.
Raphael Hoffmann, Congle Zhang, Xiao Ling,
Luke Zettlemoyer, and Daniel S. Weld. 2011.
Knowledge-based weak supervision for information
extraction of overlapping relations. In Association
for Computational Linguistics (ACL).
Yoon Kim. 2014. Convolutional neural net-
works for sentence classification. arXiv preprint
arXiv:1408.5882.
Ni Lao, Tom Mitchell, and William W Cohen. 2011.
Random walk inference and learning in a large scale
knowledge base. In Empirical Methods in Natural
Language Processing (EMNLP).
Ni Lao, Amarnag Subramanya, Fernando Pereira, and
William W Cohen. 2012. Reading the web
with learned syntactic-semantic inference rules. In
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP/CoNLL).
Dong C Liu and Jorge Nocedal. 1989. On the limited
memory bfgs method for large scale optimization.
Mathematical programming, 45(1-3):503–528.
Mike Mintz, Steven Bills, Rion Snow, and Daniel Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Association for
Computational Linguistics and International Joint
Conference on Natural Language Processing (ACL-
IJCNLP).
Arvind Neelakantan, Benjamin Roth, and Andrew Mc-
Callum. 2015. Compositional vector space models
for knowledge base completion. In ACL.
Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In Proceedings of
the 28th international conference on machine learn-
ing (ICML-11), pages 809–816.
Maximilian Nickel, Kevin Murphy, Volker Tresp, and
Evgeniy Gabrilovich. 2015. A review of re-
lational machine learning for knowledge graphs:
From multi-relational link prediction to automated
knowledge graph construction. arXiv preprint
arXiv:1503.00759.
Sebastian Riedel, Limin Yao, and Andrew McCal-
lum. 2010. Modeling relations and their men-
tions without labeled text. In Machine Learning and
Knowledge Discovery in Databases, pages 148–163.
Springer.
Sebastian Riedel, Limin Yao, Benjamin M. Marlin,
and Andrew McCallum. 2013. Relation extraction
with matrix factorization and universal schemas.
In North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies (NAACL-HLT).
Martin Riedmiller and Heinrich Braun. 1993. A direct
adaptive method for faster backpropagation learn-
ing: The rprop algorithm. In Neural Networks,
1993., IEEE International Conference on, pages
586–591. IEEE.
Alan Ritter, Luke Zettlemoyer, Oren Etzioni, et al.
2013. Modeling missing data in distant supervision
for information extraction. Transactions of the As-
sociation for Computational Linguistics, 1:367–378.
</reference>
<page confidence="0.818961">
1508
</page>
<reference confidence="0.999871568627451">
Fabian M Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge. In Proceedings of the 16th international con-
ference on World Wide Web, pages 697–706. ACM.
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallap-
ati, and Christopher D. Manning. 2012. Multi-
instance multi-label learning for relation extraction.
In Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP/CoNLL).
Kai Sheng Tai, Richard Socher, and Christopher D
Manning. 2015. Improved semantic representa-
tions from tree-structured long short-term memory
networks. arXiv preprint arXiv:1503.00075.
Kristina Toutanova and Danqi Chen. 2015. Observed
versus latent features for knowledge base and text
inference. In Proceedings of the 3rd Workshop on
Continuous Vector Space Models and their Compo-
sitionality, pages 57–66. Association for Computa-
tional Linguistics.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th annual meeting of the association for compu-
tational linguistics, pages 384–394. Association for
Computational Linguistics.
Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014a. Knowledge graph and text jointly em-
bedding. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP). Association for Computational Linguis-
tics, pages 1591–1601.
Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014b. Knowledge graph embedding by
translating on hyperplanes. In Proceedings of the
Twenty-Eighth AAAI Conference on Artificial Intel-
ligence, pages 1112–1119.
Jason Weston, Antoine Bordes, Oksana Yakhnenko,
and Nicolas Usunier. 2013. Connecting language
and knowledge bases with embedding models for re-
lation extraction. In Empirical Methods in Natural
Language Processing (EMNLP).
Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng
Gao, and Li Deng. 2015. Embedding entities and
relations for learning and inference in knowledge
bases. In International Conference on Learning
Representations (ICLR).
Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,
and Jun Zhao. 2014. Relation classification via con-
volutional deep neural network. In Proceedings of
COLING, pages 2335–2344.
</reference>
<page confidence="0.996123">
1509
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.313637">
<title confidence="0.999901">Representing Text for Joint Embedding of Text and Knowledge Bases</title>
<author confidence="0.990044">Toutanova Danqi Pantel</author>
<affiliation confidence="0.999489">Microsoft Research Computer Science Department Microsoft Research</affiliation>
<address confidence="0.998938">Redmond, WA, USA Stanford University Redmond, WA, USA</address>
<email confidence="0.724511">Hoifung</email>
<affiliation confidence="0.896051">Microsoft</affiliation>
<address confidence="0.99848">Redmond, WA, USA</address>
<email confidence="0.620911">Pallavi</email>
<affiliation confidence="0.928285">Microsoft</affiliation>
<address confidence="0.9952">Redmond, WA, USA</address>
<author confidence="0.882396">Michael</author>
<affiliation confidence="0.971208">Microsoft</affiliation>
<address confidence="0.999009">Redmond, WA, USA</address>
<abstract confidence="0.998963733333333">Models that learn to represent textual and knowledge base relations in the same continuous latent space are able to perform joint inferences among the two kinds of relations and obtain high accuracy on knowledge base completion (Riedel et al., 2013). In this paper we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations. The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: A nucleus for a web of open data.</title>
<date>2007</date>
<publisher>Springer.</publisher>
<contexts>
<context position="1311" citStr="Auer et al., 2007" startWordPosition="188" endWordPosition="191">he compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations. The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure. 1 Introduction Representing information about real-world entities and their relations in structured knowledge base (KB) form enables numerous applications. Large, collaboratively created knowledge bases have recently become available e.g., Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), and DBPedia (Auer et al., 2007), but even though they are impressively large, their coverage is far from complete. This has motivated research in automatically deriving new facts to extend a manually built knowledge base, by using information from the existing knowledge base, textual mentions of entities, and semi-structured data such as tables and web forms (Nickel et al., 2015). In this paper we build upon the work of Riedel et al. (2013), which jointly learns continuous representations for knowledge base and textual relations. This common representation in the same vector space can serve as a kind of “universal schema” w</context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: a collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM SIGMOD international conference on Management of data,</booktitle>
<pages>1247--1250</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1248" citStr="Bollacker et al., 2008" startWordPosition="177" endWordPosition="180">edel et al., 2013). In this paper we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations. The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure. 1 Introduction Representing information about real-world entities and their relations in structured knowledge base (KB) form enables numerous applications. Large, collaboratively created knowledge bases have recently become available e.g., Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), and DBPedia (Auer et al., 2007), but even though they are impressively large, their coverage is far from complete. This has motivated research in automatically deriving new facts to extend a manually built knowledge base, by using information from the existing knowledge base, textual mentions of entities, and semi-structured data such as tables and web forms (Nickel et al., 2015). In this paper we build upon the work of Riedel et al. (2013), which jointly learns continuous representations for knowledge base and textual relations. This common representation in th</context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 1247–1250. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
<author>Alberto GarciaDuran</author>
<author>Jason Weston</author>
<author>Oksana Yakhnenko</author>
</authors>
<title>Translating embeddings for modeling multirelational data.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="3812" citStr="Bordes et al., 2013" startWordPosition="573" endWordPosition="576"> we model this sub-structure and share parameters among related dependency paths, using a unified loss function learning entity and relation representations to maximize performance on the knowledge base link prediction task. We evaluate our approach on the FB15k-237 dataset, a knowledge base derived from the FreeUnited States Barack Obama Honolulu place-of-birth city-of ClueWeb 1499 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. base subset FB15k (Bordes et al., 2013) and filtered to remove highly redundant relations (Toutanova and Chen, 2015). The knowledge base is paired with textual mentions for all entity pairs derived from ClueWeb121 with Freebase entity mention annotations (Gabrilovich et al., 2013). We show that using a convolutional neural network to derive continuous representations for textual relations boosts the overall performance on link prediction, with larger improvement on entity pairs that have textual mentions. 2 Related Work There has been a growing body of work on learning to predict relations between entities without requiring sentenc</context>
<context position="5479" citStr="Bordes et al., 2013" startWordPosition="838" endWordPosition="841">hine learning models for knowledge graphs, including models based on observed graph features such as the path ranking algorithm (Lao et al., 2011), models based on continuous representations (latent features), and model combinations (Dong et al., 2014). These models predict new facts in a given knowledge base, based on information from existing entities and relations. From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset. Yang et al. (2015) showed that a simple variant of a bilinear model DISTMULT outperformed TRANSE (Bordes et al., 2013) and more richly parameterized models on this dataset. We therefore build upon the best performing prior model DISTMULT from this line of work, as well as additional models E and F developed in the context of text-augmented knowledge graphs (Riedel et al., 2013), and extend them to incorporate compositional representations of textual relations. 1http://lemurproject.org/clueweb12/ FACC1/ Relation extraction using distant supervision A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge f</context>
<context position="22951" citStr="Bordes et al., 2013" startWordPosition="3698" endWordPosition="3701">1 + b) v = V e SUBJECT appos ���! co-founder prep pobj ��! of ��! OBJECT fined as: L(TKB; o) + TL(Ttext; o) + Akok2, where A is the regularization parameter, and T is the weighing factor of the textual relations. The parameters of all models are trained using a batch training algorithm. The gradients of the basic models are straightforward to compute, and the gradients of the convolutional network parameters for the CONV-augmented models are also not hard to derive using back-propagation. 4 Experiments Dataset and Evaluation Protocol We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015). The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015). Textual relations for 4Check the first author’s website for a release of the dataset. 1504 FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set. After pruni</context>
<context position="25298" citStr="Bordes et al. (2013)" startWordPosition="4103" endWordPosition="4106">nce that a random entity pair has a relation from 0.1% to 5.0% — a fifty-fold increase. Given a set of triples in a set disjoint from a training knowledge graph, we test models on predicting the object of each triple, given the subject and relation type. We rank all entities in the training knowledge base in order of their likelihood of filling the argument position. We report the mean reciprocal rank (MRR) of the correct entity, as well as HITS@10 — the percentage of test triples for which the correct entity is ranked in the top 10. We use filtered measures following the protocol proposed in Bordes et al. (2013) — that is, when we rank entities for a given position, we remove all other entities that are known to be part of an existing triple in the training, validation, or test set. This avoids penalizing the model for ranking other correct fillers higher than the tested entity. 5The full set of 37 million textual patterns connecting the entity pairs of interest was pruned based on the count of patterns and their tri-grams, and their precision in indicating that entity pairs have KB relations. Implementation details We used a value of A = 1 for the weight of the L2 penalty for the main results in Tab</context>
</contexts>
<marker>Bordes, Usunier, GarciaDuran, Weston, Yakhnenko, 2013</marker>
<rawString>Antoine Bordes, Nicolas Usunier, Alberto GarciaDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Advances in Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai-Wei Chang</author>
<author>Wen-tau Yih</author>
<author>Bishan Yang</author>
<author>Christopher Meek</author>
</authors>
<title>Typed tensor decomposition of knowledge bases for relation extraction.</title>
<date>2014</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="20050" citStr="Chang et al., 2014" startWordPosition="3254" endWordPosition="3257">n and the other argument as follows: p(eo|es, r; O) = f (es,r,e&apos;;Θ) Ee&apos;ENeg(es,r,?) e Conditional probabilities for subject entities p(es|eo, r; O) are defined analogously. Here O denotes all the parameters of latent features. The denominator is defined using a set of entities that do not fill the object position in any relation triple (es, r, ?) in the training knowledge graph. Since the number of such entities is impractically large, we sample negative triples from the full set. We also limit the candidate entities to ones that have types consistent with the position in the relation triple (Chang et al., 2014; Yang et al., 2015), where the types are approximated following Toutanova and Chen (2015). Additionally, since the task of predicting textual relations is auxiliary to the main task, we use a weighting factor T for the loss on predicting the arguments of textual relations (Toutanova and Chen, 2015). Denote T as a set of triples, we define the loss L(T ; O) as: L(T ; O) = − � log p(eo|es, r; O) (es,r,eo)ET �− log p(es|eo, r; O) (es,r,eo)ET Let TKB and Ttext represent the set of knowledge base triples and textual relation triples respectively. The final training loss function is de2Our experime</context>
</contexts>
<marker>Chang, Yih, Yang, Meek, 2014</marker>
<rawString>Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and Christopher Meek. 2014. Typed tensor decomposition of knowledge bases for relation extraction. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Dong</author>
<author>Evgeniy Gabrilovich</author>
<author>Geremy Heitz</author>
<author>Wilko Horn</author>
<author>Ni Lao</author>
<author>Kevin Murphy</author>
<author>Thomas Strohmann</author>
<author>Shaohua Sun</author>
<author>Wei Zhang</author>
</authors>
<title>Knowledge vault: A web-scale approach to probabilistic knowledge fusion.</title>
<date>2014</date>
<booktitle>In International Conference on Knowledge Discovery and Data Mining (KDD).</booktitle>
<contexts>
<context position="5111" citStr="Dong et al., 2014" startWordPosition="778" endWordPosition="781">ork into three groups based on whether KB, text, or both sources of information are used. Additionally, we discuss related work in the area of supervised relation extraction using continuous representations of text, even though we do not use supervision at the level of textual mentions. Knowledge base completion Nickel et al. (2015) provide a broad overview of machine learning models for knowledge graphs, including models based on observed graph features such as the path ranking algorithm (Lao et al., 2011), models based on continuous representations (latent features), and model combinations (Dong et al., 2014). These models predict new facts in a given knowledge base, based on information from existing entities and relations. From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset. Yang et al. (2015) showed that a simple variant of a bilinear model DISTMULT outperformed TRANSE (Bordes et al., 2013) and more richly parameterized models on this dataset. We therefore build upon the best performing prior model DISTMULT from this line of work, as well as additional models E and F developed in the context of text-augmented knowledg</context>
<context position="10823" citStr="Dong et al., 2014" startWordPosition="1683" endWordPosition="1686">y. The task is, given a training KB consisting of entities with some relations between them, to predict new relations (links) that do not appear in the training KB. More specifically, we will build models that rank candidate entities for given queries (es, r, ?) or (?, r, eo), which ask about the object Barack Obama is the 44th and currrent President of United States . nsubj prep obj SUBJECT &lt; president ——+ of —+ OBJECT Figure 2: Textual relation extracted from an entity pair mention. or subject of a given relation. This task setting has been used in models for KB completion previously, e.g. (Dong et al., 2014; Gardner et al., 2014), even though it has not been standard in evaluations of distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2013). The advantage of this evaluation setting is that it enables automatic evaluation without requiring humans to label candidate extractions, while making only a local closed world assumption for the completeness of the knowledge base — i.e., if one object eo for a certain subject / relation pair (es, r) is present in the knowledge base, it is assumed likely that all other objects (es, r, eo) will be present. Such an assumption is pa</context>
</contexts>
<marker>Dong, Gabrilovich, Heitz, Horn, Lao, Murphy, Strohmann, Sun, Zhang, 2014</marker>
<rawString>Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In International Conference on Knowledge Discovery and Data Mining (KDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Michael Ringgaard</author>
<author>Amarnag Subramanya</author>
</authors>
<title>FACC1: Freebase annotation of ClueWeb corpora,</title>
<date>2013</date>
<journal>Version</journal>
<volume>1</volume>
<contexts>
<context position="4054" citStr="Gabrilovich et al., 2013" startWordPosition="608" endWordPosition="611">our approach on the FB15k-237 dataset, a knowledge base derived from the FreeUnited States Barack Obama Honolulu place-of-birth city-of ClueWeb 1499 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. base subset FB15k (Bordes et al., 2013) and filtered to remove highly redundant relations (Toutanova and Chen, 2015). The knowledge base is paired with textual mentions for all entity pairs derived from ClueWeb121 with Freebase entity mention annotations (Gabrilovich et al., 2013). We show that using a convolutional neural network to derive continuous representations for textual relations boosts the overall performance on link prediction, with larger improvement on entity pairs that have textual mentions. 2 Related Work There has been a growing body of work on learning to predict relations between entities without requiring sentence-level annotations of textual mentions at training time. We group such related work into three groups based on whether KB, text, or both sources of information are used. Additionally, we discuss related work in the area of supervised relatio</context>
<context position="23466" citStr="Gabrilovich et al., 2013" startWordPosition="3780" endWordPosition="3783">taset and Evaluation Protocol We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015). The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015). Textual relations for 4Check the first author’s website for a release of the dataset. 1504 FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set. After pruning5, there are 2.7 million unique textual relations that are added to the knowledge graph. The set of textual relations is larger than the set used in Toutanova and Chen (2015) (25,000 versus 2.7 million), leading to improved performance. The number of relations and triples in the training, validation and test portions of the data are given in Table 2. The two rows list statistics for the KB and text portions of the data separately. The 2.7 million textual relations occur in 3.9 million text triples. Almost al</context>
</contexts>
<marker>Gabrilovich, Ringgaard, Subramanya, 2013</marker>
<rawString>Evgeniy Gabrilovich, Michael Ringgaard, and Amarnag Subramanya. 2013. FACC1: Freebase annotation of ClueWeb corpora, Version 1 (release date 2013-06-26, format version 1, correction level 0).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gardner</author>
<author>Partha Pratim Talukdar</author>
<author>Bryan Kisiel</author>
<author>Tom Mitchell</author>
</authors>
<title>Improving learning and inference in a large knowledge-base using latent syntactic cues.</title>
<date>2013</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7094" citStr="Gardner et al., 2013" startWordPosition="1088" endWordPosition="1091"> from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases. Combining knowledge base and text information A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations. Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure. Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015). Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textua</context>
</contexts>
<marker>Gardner, Talukdar, Kisiel, Mitchell, 2013</marker>
<rawString>Matt Gardner, Partha Pratim Talukdar, Bryan Kisiel, and Tom Mitchell. 2013. Improving learning and inference in a large knowledge-base using latent syntactic cues. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gardner</author>
<author>Partha Talukdar</author>
<author>Jayant Krishnamurthy</author>
<author>Tom Mitchell</author>
</authors>
<title>Incorporating vector space similarity in random walk inference over knowledge bases.</title>
<date>2014</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7117" citStr="Gardner et al., 2014" startWordPosition="1092" endWordPosition="1095">ss of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases. Combining knowledge base and text information A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations. Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure. Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015). Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textual relations. Weston et </context>
<context position="10846" citStr="Gardner et al., 2014" startWordPosition="1687" endWordPosition="1690">en a training KB consisting of entities with some relations between them, to predict new relations (links) that do not appear in the training KB. More specifically, we will build models that rank candidate entities for given queries (es, r, ?) or (?, r, eo), which ask about the object Barack Obama is the 44th and currrent President of United States . nsubj prep obj SUBJECT &lt; president ——+ of —+ OBJECT Figure 2: Textual relation extracted from an entity pair mention. or subject of a given relation. This task setting has been used in models for KB completion previously, e.g. (Dong et al., 2014; Gardner et al., 2014), even though it has not been standard in evaluations of distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2013). The advantage of this evaluation setting is that it enables automatic evaluation without requiring humans to label candidate extractions, while making only a local closed world assumption for the completeness of the knowledge base — i.e., if one object eo for a certain subject / relation pair (es, r) is present in the knowledge base, it is assumed likely that all other objects (es, r, eo) will be present. Such an assumption is particularly justified fo</context>
</contexts>
<marker>Gardner, Talukdar, Krishnamurthy, Mitchell, 2014</marker>
<rawString>Matt Gardner, Partha Talukdar, Jayant Krishnamurthy, and Tom Mitchell. 2014. Incorporating vector space similarity in random walk inference over knowledge bases. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew R Gormley</author>
<author>Mo Yu</author>
<author>Mark Dredze</author>
</authors>
<title>Improved relation extraction with feature-rich compositional embedding models. arXiv preprint arXiv:1505.02419.</title>
<date>2015</date>
<contexts>
<context position="9143" citStr="Gormley et al., 2015" startWordPosition="1395" endWordPosition="1398">pproach on a dataset that contains rich prior information from the training knowledge base, as well as a wealth of textual information from a large document collection. Continuous representations for supervised relation extraction In contrast to the work reviewed so far, work on sentence-level relation extraction using direct supervision has focused heavily on representing sentence context. Models using hand-crafted features have evolved for more than a decade, and recently, models using continuous representations have been found to achieve new state-of-the-art performance (Zeng et al., 2014; Gormley et al., 2015). Compared to work on representation learning for sentence-level context, such as this recent work using LSTM models on constituency or dependency trees (Tai et al., 2015), our approach using a one-hidden-layer convolutional neural network is relatively simple. However, even such a simple approach has been shown to be very competitive (Kim, 2014). 3 Models for knowledge base completion We begin by introducing notation to define the task, largely following the terminology in Nickel et al. (2015). We assume knowledge bases are represented using RDF triples, in the form (subject, predicate, objec</context>
</contexts>
<marker>Gormley, Yu, Dredze, 2015</marker>
<rawString>Matthew R Gormley, Mo Yu, and Mark Dredze. 2015. Improved relation extraction with feature-rich compositional embedding models. arXiv preprint arXiv:1505.02419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledge-based weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="6423" citStr="Hoffmann et al., 2011" startWordPosition="979" endWordPosition="982">s of textual relations. 1http://lemurproject.org/clueweb12/ FACC1/ Relation extraction using distant supervision A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base. Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context. Other work proposed more sophisticated models that reason about sentence-level hidden variables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases. Combining knowledge base and text information A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of te</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882.</title>
<date>2014</date>
<contexts>
<context position="9491" citStr="Kim, 2014" startWordPosition="1454" endWordPosition="1455"> on representing sentence context. Models using hand-crafted features have evolved for more than a decade, and recently, models using continuous representations have been found to achieve new state-of-the-art performance (Zeng et al., 2014; Gormley et al., 2015). Compared to work on representation learning for sentence-level context, such as this recent work using LSTM models on constituency or dependency trees (Tai et al., 2015), our approach using a one-hidden-layer convolutional neural network is relatively simple. However, even such a simple approach has been shown to be very competitive (Kim, 2014). 3 Models for knowledge base completion We begin by introducing notation to define the task, largely following the terminology in Nickel et al. (2015). We assume knowledge bases are represented using RDF triples, in the form (subject, predicate, object), where the subject and object are entities and the predicate is the type of relation. For example, the KB fragment shown in Figure 1 is shown as a knowledge graph, where the entities are the nodes, and the relations are shown as directed labeled edges: we see three entities participating in three relation instances indicated by the edges. For </context>
</contexts>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim. 2014. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
<author>Tom Mitchell</author>
<author>William W Cohen</author>
</authors>
<title>Random walk inference and learning in a large scale knowledge base.</title>
<date>2011</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="5005" citStr="Lao et al., 2011" startWordPosition="763" endWordPosition="766">ithout requiring sentence-level annotations of textual mentions at training time. We group such related work into three groups based on whether KB, text, or both sources of information are used. Additionally, we discuss related work in the area of supervised relation extraction using continuous representations of text, even though we do not use supervision at the level of textual mentions. Knowledge base completion Nickel et al. (2015) provide a broad overview of machine learning models for knowledge graphs, including models based on observed graph features such as the path ranking algorithm (Lao et al., 2011), models based on continuous representations (latent features), and model combinations (Dong et al., 2014). These models predict new facts in a given knowledge base, based on information from existing entities and relations. From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset. Yang et al. (2015) showed that a simple variant of a bilinear model DISTMULT outperformed TRANSE (Bordes et al., 2013) and more richly parameterized models on this dataset. We therefore build upon the best performing prior model DISTMULT from t</context>
</contexts>
<marker>Lao, Mitchell, Cohen, 2011</marker>
<rawString>Ni Lao, Tom Mitchell, and William W Cohen. 2011. Random walk inference and learning in a large scale knowledge base. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
<author>Amarnag Subramanya</author>
<author>Fernando Pereira</author>
<author>William W Cohen</author>
</authors>
<title>Reading the web with learned syntactic-semantic inference rules.</title>
<date>2012</date>
<booktitle>In Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</booktitle>
<contexts>
<context position="6990" citStr="Lao et al., 2012" startWordPosition="1069" endWordPosition="1072">iables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases. Combining knowledge base and text information A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations. Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure. Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015). Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the</context>
<context position="11551" citStr="Lao et al., 2012" startWordPosition="1804" endWordPosition="1807"> extraction (Mintz et al., 2009; Riedel et al., 2013). The advantage of this evaluation setting is that it enables automatic evaluation without requiring humans to label candidate extractions, while making only a local closed world assumption for the completeness of the knowledge base — i.e., if one object eo for a certain subject / relation pair (es, r) is present in the knowledge base, it is assumed likely that all other objects (es, r, eo) will be present. Such an assumption is particularly justified for nearly functional relations. To incorporate textual information, we follow prior work (Lao et al., 2012; Riedel et al., 2013) and represent both textual and knowledge base relations in a single graph of “universal” relations. The textual relations are represented as full lexicalized dependency paths, as illustrated in Figure 2. An instance of the textual relation SUBJECT( n subj prep obj president ��) of �)OBJECT connecting the entities BARACK OBAMA and UNITED STATES, is added to the knowledge graph based on this sentential occurrence. To present the models for knowledge base completion based on such combined knowledge graphs, we first introduce some notation. Let £ denote the set of entities i</context>
</contexts>
<marker>Lao, Subramanya, Pereira, Cohen, 2012</marker>
<rawString>Ni Lao, Amarnag Subramanya, Fernando Pereira, and William W Cohen. 2012. Reading the web with learned syntactic-semantic inference rules. In Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory bfgs method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical programming,</booktitle>
<pages>45--1</pages>
<contexts>
<context position="26101" citStr="Liu and Nocedal, 1989" startWordPosition="4247" endWordPosition="4250">voids penalizing the model for ranking other correct fillers higher than the tested entity. 5The full set of 37 million textual patterns connecting the entity pairs of interest was pruned based on the count of patterns and their tri-grams, and their precision in indicating that entity pairs have KB relations. Implementation details We used a value of A = 1 for the weight of the L2 penalty for the main results in Table 3, and present some results on the impact of A at the end of this section. We used batch optimization after initial experiments with AdaGrad showed inferior performance. L-BFGS (Liu and Nocedal, 1989) and RProp (Riedmiller and Braun, 1993) were found to converge to similar function values, with RProp converging significantly faster. We thus used RProp for optimization. We initialized the KB+text models from the KB-only models and also from random initial values (sampled from a Gaussian distribution), and stopped optimization when the overall MRR on the validation set decreased. For each model type, we chose the better of random and KB-only initialization. The word embeddings in the CONV models were initialized using the 50-dimensional vectors from Turian et al. (2010) in the main experimen</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C Liu and Jorge Nocedal. 1989. On the limited memory bfgs method for large scale optimization. Mathematical programming, 45(1-3):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACLIJCNLP).</booktitle>
<contexts>
<context position="6122" citStr="Mintz et al. (2009)" startWordPosition="933" endWordPosition="936">erized models on this dataset. We therefore build upon the best performing prior model DISTMULT from this line of work, as well as additional models E and F developed in the context of text-augmented knowledge graphs (Riedel et al., 2013), and extend them to incorporate compositional representations of textual relations. 1http://lemurproject.org/clueweb12/ FACC1/ Relation extraction using distant supervision A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base. Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context. Other work proposed more sophisticated models that reason about sentence-level hidden variables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowled</context>
<context position="10966" citStr="Mintz et al., 2009" startWordPosition="1706" endWordPosition="1709">ar in the training KB. More specifically, we will build models that rank candidate entities for given queries (es, r, ?) or (?, r, eo), which ask about the object Barack Obama is the 44th and currrent President of United States . nsubj prep obj SUBJECT &lt; president ——+ of —+ OBJECT Figure 2: Textual relation extracted from an entity pair mention. or subject of a given relation. This task setting has been used in models for KB completion previously, e.g. (Dong et al., 2014; Gardner et al., 2014), even though it has not been standard in evaluations of distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2013). The advantage of this evaluation setting is that it enables automatic evaluation without requiring humans to label candidate extractions, while making only a local closed world assumption for the completeness of the knowledge base — i.e., if one object eo for a certain subject / relation pair (es, r) is present in the knowledge base, it is assumed likely that all other objects (es, r, eo) will be present. Such an assumption is particularly justified for nearly functional relations. To incorporate textual information, we follow prior work (Lao et al., 2012; Riedel et al.</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACLIJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arvind Neelakantan</author>
<author>Benjamin Roth</author>
<author>Andrew McCallum</author>
</authors>
<title>Compositional vector space models for knowledge base completion.</title>
<date>2015</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7451" citStr="Neelakantan et al., 2015" startWordPosition="1139" endWordPosition="1142">rmation was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations. Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure. Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015). Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textual relations. Weston et al. (2013) combined continuous representations from a knowledge base and textual mentions for prediction of new relations. The two representations were trained independently of each other and using different loss functions, and were only combined at inference time. Additionally, the employed representations of text were non-composit</context>
</contexts>
<marker>Neelakantan, Roth, McCallum, 2015</marker>
<rawString>Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. 2015. Compositional vector space models for knowledge base completion. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Nickel</author>
<author>Volker Tresp</author>
<author>Hans-Peter Kriegel</author>
</authors>
<title>A three-way model for collective learning on multi-relational data.</title>
<date>2011</date>
<booktitle>In Proceedings of the 28th international conference on machine learning (ICML-11),</booktitle>
<pages>809--816</pages>
<contexts>
<context position="14698" citStr="Nickel et al., 2011" startWordPosition="2358" endWordPosition="2361">f relations. For each relation type r, the model learns two latent feature vectors v(rs) and v(ro) of dimension K. For each entity (node) ei, the model also learns a latent feature vector of the same dimensionality. The score of a candidate triple (es, r, eo) is defined as f(es, r, eo) = v(rs)Tv(es) + v(ro)Tv(eo). It can be seen that when a subject entity is fixed in a query (es, r, ?), the ranking of candidate object entity fillers according to f does not depend on the subject entity but only on the relation type r. The third model DISTMULT, is a special form of a bilinear model like RESCAL (Nickel et al., 2011), where the non-diagonal entries in the relation matrices are assumed to be zero. This model was proposed in Yang et al. (2015) and was shown to outperform prior work on the FB15k dataset. In this model, each entity ei and each relation r is assigned a latent feature vector of dimension K. The score of a candidate triple (es, r, eo) is defined as f(es, r, eo) = v(r)T (v(es) o v(eo)), where o denotes the element-wise vector product. In this model, entity pairs which share an entity also share parameters, and the ranking of candidate objects for queries (es, r, ?) depends on the subject entity. </context>
</contexts>
<marker>Nickel, Tresp, Kriegel, 2011</marker>
<rawString>Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th international conference on machine learning (ICML-11), pages 809–816.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Nickel</author>
<author>Kevin Murphy</author>
<author>Volker Tresp</author>
<author>Evgeniy Gabrilovich</author>
</authors>
<title>A review of relational machine learning for knowledge graphs: From multi-relational link prediction to automated knowledge graph construction. arXiv preprint arXiv:1503.00759.</title>
<date>2015</date>
<contexts>
<context position="1662" citStr="Nickel et al., 2015" startWordPosition="243" endWordPosition="246">nd their relations in structured knowledge base (KB) form enables numerous applications. Large, collaboratively created knowledge bases have recently become available e.g., Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), and DBPedia (Auer et al., 2007), but even though they are impressively large, their coverage is far from complete. This has motivated research in automatically deriving new facts to extend a manually built knowledge base, by using information from the existing knowledge base, textual mentions of entities, and semi-structured data such as tables and web forms (Nickel et al., 2015). In this paper we build upon the work of Riedel et al. (2013), which jointly learns continuous representations for knowledge base and textual relations. This common representation in the same vector space can serve as a kind of “universal schema” which admits joint inferences among ∗This research was conducted during the author’s internship at Microsoft Research. Knowledge Base nationality Textual Mentions Barack Obama is the 44th and current President of United States. Obama was born in the United States just as he has always said. ... Figure 1: A knowledge base fragment coupled with textual</context>
<context position="4827" citStr="Nickel et al. (2015)" startWordPosition="734" endWordPosition="737">diction, with larger improvement on entity pairs that have textual mentions. 2 Related Work There has been a growing body of work on learning to predict relations between entities without requiring sentence-level annotations of textual mentions at training time. We group such related work into three groups based on whether KB, text, or both sources of information are used. Additionally, we discuss related work in the area of supervised relation extraction using continuous representations of text, even though we do not use supervision at the level of textual mentions. Knowledge base completion Nickel et al. (2015) provide a broad overview of machine learning models for knowledge graphs, including models based on observed graph features such as the path ranking algorithm (Lao et al., 2011), models based on continuous representations (latent features), and model combinations (Dong et al., 2014). These models predict new facts in a given knowledge base, based on information from existing entities and relations. From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset. Yang et al. (2015) showed that a simple variant of a bilinear mode</context>
<context position="9642" citStr="Nickel et al. (2015)" startWordPosition="1476" endWordPosition="1479">ous representations have been found to achieve new state-of-the-art performance (Zeng et al., 2014; Gormley et al., 2015). Compared to work on representation learning for sentence-level context, such as this recent work using LSTM models on constituency or dependency trees (Tai et al., 2015), our approach using a one-hidden-layer convolutional neural network is relatively simple. However, even such a simple approach has been shown to be very competitive (Kim, 2014). 3 Models for knowledge base completion We begin by introducing notation to define the task, largely following the terminology in Nickel et al. (2015). We assume knowledge bases are represented using RDF triples, in the form (subject, predicate, object), where the subject and object are entities and the predicate is the type of relation. For example, the KB fragment shown in Figure 1 is shown as a knowledge graph, where the entities are the nodes, and the relations are shown as directed labeled edges: we see three entities participating in three relation instances indicated by the edges. For brevity, we will denote triples by (es, r, eo), where es and eo denote the subject and object entities, respectively. The task is, given a training KB </context>
<context position="19187" citStr="Nickel et al., 2015" startWordPosition="3112" endWordPosition="3115">function All basic and CONV-augmented models use the same training loss function. Our loss function is motivated by the link prediction task and the performance measures used. As previously mentioned, the task is to predict the subject or object entity for given held-out triples (es, r, eo), i.e., to rank all entities with respect to their likelihood of filling the respective position in the triple2. We would thus like the model to score correct triples (es, r, eo) higher than incorrect triples (e&apos;, r, eo) and (es, r, e&apos;) which differ from the correct triple by one entity. Several approaches (Nickel et al., 2015) use a margin-based loss function. We use an approximation to the negative loglikelihood of the correct entity filler instead3. We define the conditional probabilities p(eo|es, r) and p(es|r, eo) for object and subject entities given the relation and the other argument as follows: p(eo|es, r; O) = f (es,r,e&apos;;Θ) Ee&apos;ENeg(es,r,?) e Conditional probabilities for subject entities p(es|eo, r; O) are defined analogously. Here O denotes all the parameters of latent features. The denominator is defined using a set of entities that do not fill the object position in any relation triple (es, r, ?) in the</context>
</contexts>
<marker>Nickel, Murphy, Tresp, Gabrilovich, 2015</marker>
<rawString>Maximilian Nickel, Kevin Murphy, Volker Tresp, and Evgeniy Gabrilovich. 2015. A review of relational machine learning for knowledge graphs: From multi-relational link prediction to automated knowledge graph construction. arXiv preprint arXiv:1503.00759.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Machine Learning and Knowledge Discovery in Databases,</booktitle>
<pages>148--163</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6400" citStr="Riedel et al., 2010" startWordPosition="975" endWordPosition="978">tional representations of textual relations. 1http://lemurproject.org/clueweb12/ FACC1/ Relation extraction using distant supervision A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base. Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context. Other work proposed more sophisticated models that reason about sentence-level hidden variables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases. Combining knowledge base and text information A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To allev</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases, pages 148–163. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Benjamin M Marlin</author>
<author>Andrew McCallum</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).</booktitle>
<contexts>
<context position="643" citStr="Riedel et al., 2013" startWordPosition="92" endWordPosition="95">oint Embedding of Text and Knowledge Bases Kristina Toutanova Danqi Chen∗ Patrick Pantel Microsoft Research Computer Science Department Microsoft Research Redmond, WA, USA Stanford University Redmond, WA, USA Hoifung Poon Microsoft Research Redmond, WA, USA Pallavi Choudhury Microsoft Research Redmond, WA, USA Michael Gamon Microsoft Research Redmond, WA, USA Abstract Models that learn to represent textual and knowledge base relations in the same continuous latent space are able to perform joint inferences among the two kinds of relations and obtain high accuracy on knowledge base completion (Riedel et al., 2013). In this paper we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations. The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure. 1 Introduction Representing information about real-world entities and their relations in structured knowledge base (KB) form enables numerous applications. Large, collaboratively created knowledge bases have recently become available e.g., Freebase (Bollacker et al., </context>
<context position="2460" citStr="Riedel et al. (2013)" startWordPosition="372" endWordPosition="375">on in the same vector space can serve as a kind of “universal schema” which admits joint inferences among ∗This research was conducted during the author’s internship at Microsoft Research. Knowledge Base nationality Textual Mentions Barack Obama is the 44th and current President of United States. Obama was born in the United States just as he has always said. ... Figure 1: A knowledge base fragment coupled with textual mentions of pairs of entities. KBs and text. The textual relations represent the relationships between entities expressed in individual sentences (see Figure 1 for an example). Riedel et al. (2013) represented each textual mention of an entity pair by the lexicalized dependency path between the two entities (see Figure 2). Each such path is treated as a separate relation in a combined knowledge graph including both KB and textual relations. Following prior work in latent feature models for knowledge base completion, every textual relation receives its own continuous representation, learned from the pattern of its co-occurrences in the knowledge graph. However, largely synonymous textual relations often share common sub-structure, and are composed of similar words and dependency arcs. Fo</context>
<context position="5741" citStr="Riedel et al., 2013" startWordPosition="883" endWordPosition="886">dels predict new facts in a given knowledge base, based on information from existing entities and relations. From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset. Yang et al. (2015) showed that a simple variant of a bilinear model DISTMULT outperformed TRANSE (Bordes et al., 2013) and more richly parameterized models on this dataset. We therefore build upon the best performing prior model DISTMULT from this line of work, as well as additional models E and F developed in the context of text-augmented knowledge graphs (Riedel et al., 2013), and extend them to incorporate compositional representations of textual relations. 1http://lemurproject.org/clueweb12/ FACC1/ Relation extraction using distant supervision A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base. Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context. Other work proposed more sophisticated models that reason</context>
<context position="8308" citStr="Riedel et al. (2013)" startWordPosition="1271" endWordPosition="1274">textual relations. Weston et al. (2013) combined continuous representations from a knowledge base and textual mentions for prediction of new relations. The two representations were trained independently of each other and using different loss functions, and were only combined at inference time. Additionally, the employed representations of text were non-compositional. In this work we train continuous representations of knowledge base and textual relations jointly, which allows for deeper interactions between the 1500 sources of information. We directly build on the universal schema approach of Riedel et al. (2013) as well as the universal schema extension of the DISTMULT model mentioned previously, to improve the representations of textual relations by capturing their compositional structure. Additionally, we evaluate the approach on a dataset that contains rich prior information from the training knowledge base, as well as a wealth of textual information from a large document collection. Continuous representations for supervised relation extraction In contrast to the work reviewed so far, work on sentence-level relation extraction using direct supervision has focused heavily on representing sentence c</context>
<context position="10988" citStr="Riedel et al., 2013" startWordPosition="1710" endWordPosition="1713">B. More specifically, we will build models that rank candidate entities for given queries (es, r, ?) or (?, r, eo), which ask about the object Barack Obama is the 44th and currrent President of United States . nsubj prep obj SUBJECT &lt; president ——+ of —+ OBJECT Figure 2: Textual relation extracted from an entity pair mention. or subject of a given relation. This task setting has been used in models for KB completion previously, e.g. (Dong et al., 2014; Gardner et al., 2014), even though it has not been standard in evaluations of distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2013). The advantage of this evaluation setting is that it enables automatic evaluation without requiring humans to label candidate extractions, while making only a local closed world assumption for the completeness of the knowledge base — i.e., if one object eo for a certain subject / relation pair (es, r) is present in the knowledge base, it is assumed likely that all other objects (es, r, eo) will be present. Such an assumption is particularly justified for nearly functional relations. To incorporate textual information, we follow prior work (Lao et al., 2012; Riedel et al., 2013) and represent </context>
<context position="13343" citStr="Riedel et al., 2013" startWordPosition="2113" endWordPosition="2116">j prep pobj 1501 r (es, eo) F: E: DISTMULT: Figure 3: The continuous representations for model F, E and DISTMULT. their parameters. 3.1 Basic Models We begin with presenting the three models from prior work that this research builds upon. They all learn latent continuous representations of relations and entities or entity pairs, and score possible triples based on the learned continuous representations. Each of the models can be defined on a knowledge graph containing entities and KB relations only, or on a knowledge graph additionally containing textual relations. We use models F and E from (Riedel et al., 2013) where they were used for a combined KB+text graph, and model DISTMULT from (Yang et al., 2015), which was originally used for a knowledge graph containing only KB relations. As shown in Figure 3, model F learns a Kdimensional latent feature vector for each candidate entity pair (es, eo), as well as a samedimensional vector for each relation r, and the 1 scoring function is simply defined as their inner product: f(es, r, eo) = v(r)Tv(es, eo). Therefore, different pairs sharing the same entity would not share parameters in this model. Model E does not have parameters for entity pairs, and inste</context>
<context position="30311" citStr="Riedel et al., 2013" startWordPosition="4981" endWordPosition="4984">can impact these representations. The performance of all models is shown as an overall MRR (scaled by 100) and HITS@10, as well as performance on the subset of triples that have textual mentions (column With mentions), and ones that do not (column Without mentions). Around 28% of the test triples have mentions and contribute toward the measures in the With mentions column, and the other 72% of the test triples contribute to the Without mentions column. For the KB-only models, we see the performance of each individual model F, E, and DISTMULT. Model F was the best performing single model from (Riedel et al., 2013), but it does not perform well when textual mentions are not used. In our implementation of model F, we created entity pair parameters only for entity pairs that cooccur in the text data (Riedel et al. (2013) also trained pairwise vectors for co-occuring entities only, but all of the training and test tuples in their study were co-occurring)7. Without textual information, model F is performing essentially randomly, because entity pairs in the test sets do not occur in training set relations (by construction of the dataset). Model E is able to do surprisingly well, given that it is making predi</context>
</contexts>
<marker>Riedel, Yao, Marlin, McCallum, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Benjamin M. Marlin, and Andrew McCallum. 2013. Relation extraction with matrix factorization and universal schemas. In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Riedmiller</author>
<author>Heinrich Braun</author>
</authors>
<title>A direct adaptive method for faster backpropagation learning: The rprop algorithm.</title>
<date>1993</date>
<booktitle>In Neural Networks, 1993., IEEE International Conference on,</booktitle>
<pages>586--591</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="26140" citStr="Riedmiller and Braun, 1993" startWordPosition="4253" endWordPosition="4256">king other correct fillers higher than the tested entity. 5The full set of 37 million textual patterns connecting the entity pairs of interest was pruned based on the count of patterns and their tri-grams, and their precision in indicating that entity pairs have KB relations. Implementation details We used a value of A = 1 for the weight of the L2 penalty for the main results in Table 3, and present some results on the impact of A at the end of this section. We used batch optimization after initial experiments with AdaGrad showed inferior performance. L-BFGS (Liu and Nocedal, 1989) and RProp (Riedmiller and Braun, 1993) were found to converge to similar function values, with RProp converging significantly faster. We thus used RProp for optimization. We initialized the KB+text models from the KB-only models and also from random initial values (sampled from a Gaussian distribution), and stopped optimization when the overall MRR on the validation set decreased. For each model type, we chose the better of random and KB-only initialization. The word embeddings in the CONV models were initialized using the 50-dimensional vectors from Turian et al. (2010) in the main experiments, with a slight positive impact. The </context>
</contexts>
<marker>Riedmiller, Braun, 1993</marker>
<rawString>Martin Riedmiller and Heinrich Braun. 1993. A direct adaptive method for faster backpropagation learning: The rprop algorithm. In Neural Networks, 1993., IEEE International Conference on, pages 586–591. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Luke Zettlemoyer</author>
<author>Oren Etzioni</author>
</authors>
<title>Modeling missing data in distant supervision for information extraction.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--367</pages>
<contexts>
<context position="6560" citStr="Ritter et al., 2013" startWordPosition="1002" endWordPosition="1005">cused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base. Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context. Other work proposed more sophisticated models that reason about sentence-level hidden variables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases. Combining knowledge base and text information A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or cont</context>
</contexts>
<marker>Ritter, Zettlemoyer, Etzioni, 2013</marker>
<rawString>Alan Ritter, Luke Zettlemoyer, Oren Etzioni, et al. 2013. Modeling missing data in distant supervision for information extraction. Transactions of the Association for Computational Linguistics, 1:367–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1278" citStr="Suchanek et al., 2007" startWordPosition="182" endWordPosition="185">er we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations. The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure. 1 Introduction Representing information about real-world entities and their relations in structured knowledge base (KB) form enables numerous applications. Large, collaboratively created knowledge bases have recently become available e.g., Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), and DBPedia (Auer et al., 2007), but even though they are impressively large, their coverage is far from complete. This has motivated research in automatically deriving new facts to extend a manually built knowledge base, by using information from the existing knowledge base, textual mentions of entities, and semi-structured data such as tables and web forms (Nickel et al., 2015). In this paper we build upon the work of Riedel et al. (2013), which jointly learns continuous representations for knowledge base and textual relations. This common representation in the same vector space can serve </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of the 16th international conference on World Wide Web, pages 697–706. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multiinstance multi-label learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</booktitle>
<contexts>
<context position="6447" citStr="Surdeanu et al., 2012" startWordPosition="983" endWordPosition="986"> 1http://lemurproject.org/clueweb12/ FACC1/ Relation extraction using distant supervision A number of works have focused on extracting new instances of relations using information from textual mentions, without sophisticated modeling of prior knowledge from the knowledge base. Mintz et al. (2009) demonstrated that both surface context and dependency path context were helpful for the task, but did not model the compositional sub-structure of this context. Other work proposed more sophisticated models that reason about sentence-level hidden variables (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) or model the noise arising from the incompleteness of knowledge bases and text collections (Ritter et al., 2013), inter alia. Our work focuses on representing the compositional structure of sentential context for learning joint continuous representations of text and knowledge bases. Combining knowledge base and text information A combination of knowledge base and textual information was first shown to outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising </context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D. Manning. 2012. Multiinstance multi-label learning for relation extraction. In Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Sheng Tai</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Improved semantic representations from tree-structured long short-term memory networks. arXiv preprint arXiv:1503.00075.</title>
<date>2015</date>
<contexts>
<context position="9314" citStr="Tai et al., 2015" startWordPosition="1423" endWordPosition="1426">uous representations for supervised relation extraction In contrast to the work reviewed so far, work on sentence-level relation extraction using direct supervision has focused heavily on representing sentence context. Models using hand-crafted features have evolved for more than a decade, and recently, models using continuous representations have been found to achieve new state-of-the-art performance (Zeng et al., 2014; Gormley et al., 2015). Compared to work on representation learning for sentence-level context, such as this recent work using LSTM models on constituency or dependency trees (Tai et al., 2015), our approach using a one-hidden-layer convolutional neural network is relatively simple. However, even such a simple approach has been shown to be very competitive (Kim, 2014). 3 Models for knowledge base completion We begin by introducing notation to define the task, largely following the terminology in Nickel et al. (2015). We assume knowledge bases are represented using RDF triples, in the form (subject, predicate, object), where the subject and object are entities and the predicate is the type of relation. For example, the KB fragment shown in Figure 1 is shown as a knowledge graph, wher</context>
</contexts>
<marker>Tai, Socher, Manning, 2015</marker>
<rawString>Kai Sheng Tai, Richard Socher, and Christopher D Manning. 2015. Improved semantic representations from tree-structured long short-term memory networks. arXiv preprint arXiv:1503.00075.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Danqi Chen</author>
</authors>
<title>Observed versus latent features for knowledge base and text inference.</title>
<date>2015</date>
<booktitle>In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality,</booktitle>
<pages>57--66</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3889" citStr="Toutanova and Chen, 2015" startWordPosition="584" endWordPosition="587">cy paths, using a unified loss function learning entity and relation representations to maximize performance on the knowledge base link prediction task. We evaluate our approach on the FB15k-237 dataset, a knowledge base derived from the FreeUnited States Barack Obama Honolulu place-of-birth city-of ClueWeb 1499 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. base subset FB15k (Bordes et al., 2013) and filtered to remove highly redundant relations (Toutanova and Chen, 2015). The knowledge base is paired with textual mentions for all entity pairs derived from ClueWeb121 with Freebase entity mention annotations (Gabrilovich et al., 2013). We show that using a convolutional neural network to derive continuous representations for textual relations boosts the overall performance on link prediction, with larger improvement on entity pairs that have textual mentions. 2 Related Work There has been a growing body of work on learning to predict relations between entities without requiring sentence-level annotations of textual mentions at training time. We group such relat</context>
<context position="20140" citStr="Toutanova and Chen (2015)" startWordPosition="3269" endWordPosition="3272"> e Conditional probabilities for subject entities p(es|eo, r; O) are defined analogously. Here O denotes all the parameters of latent features. The denominator is defined using a set of entities that do not fill the object position in any relation triple (es, r, ?) in the training knowledge graph. Since the number of such entities is impractically large, we sample negative triples from the full set. We also limit the candidate entities to ones that have types consistent with the position in the relation triple (Chang et al., 2014; Yang et al., 2015), where the types are approximated following Toutanova and Chen (2015). Additionally, since the task of predicting textual relations is auxiliary to the main task, we use a weighting factor T for the loss on predicting the arguments of textual relations (Toutanova and Chen, 2015). Denote T as a set of triples, we define the loss L(T ; O) as: L(T ; O) = − � log p(eo|es, r; O) (es,r,eo)ET �− log p(es|eo, r; O) (es,r,eo)ET Let TKB and Ttext represent the set of knowledge base triples and textual relation triples respectively. The final training loss function is de2Our experimental comparison focuses on predicting object entities only, but we consider both argument </context>
<context position="23108" citStr="Toutanova and Chen, 2015" startWordPosition="3722" endWordPosition="3725">eter, and T is the weighing factor of the textual relations. The parameters of all models are trained using a batch training algorithm. The gradients of the basic models are straightforward to compute, and the gradients of the convolutional network parameters for the CONV-augmented models are also not hard to derive using back-propagation. 4 Experiments Dataset and Evaluation Protocol We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015). The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015). Textual relations for 4Check the first author’s website for a release of the dataset. 1504 FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set. After pruning5, there are 2.7 million unique textual relations that are added to the knowledge graph. The set of textual relations is larger than the set used in Toutan</context>
</contexts>
<marker>Toutanova, Chen, 2015</marker>
<rawString>Kristina Toutanova and Danqi Chen. 2015. Observed versus latent features for knowledge base and text inference. In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality, pages 57–66. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th annual meeting of the association for computational linguistics,</booktitle>
<pages>384--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="26679" citStr="Turian et al. (2010)" startWordPosition="4336" endWordPosition="4339">erformance. L-BFGS (Liu and Nocedal, 1989) and RProp (Riedmiller and Braun, 1993) were found to converge to similar function values, with RProp converging significantly faster. We thus used RProp for optimization. We initialized the KB+text models from the KB-only models and also from random initial values (sampled from a Gaussian distribution), and stopped optimization when the overall MRR on the validation set decreased. For each model type, we chose the better of random and KB-only initialization. The word embeddings in the CONV models were initialized using the 50-dimensional vectors from Turian et al. (2010) in the main experiments, with a slight positive impact. The effect of initialization is discussed at the end of the section. The number of negative examples for each triple was set to 200. Performance improved substantially when the number of negative examples was increased and reached a plateau around 200. We chose the optimal number of latent feature dimensions via a grid search to optimize MRR on the validation set, testing the values 5, 10, 15, 35, 50, 100, 200 and 500. We also performed a grid search over the values of the parameter T, testing values in the set 10.01, 0.1, 0.25, 0.5, 11.</context>
<context position="34430" citStr="Turian et al., 2010" startWordPosition="5671" endWordPosition="5674">kely arguments based on noisy inference from textual patterns and their individual words and dependency links. Hyperparameter Sensitivity To gain insight into the sensitivity of the model to hyper-parameters and initialization, we report on experiments starting with the best model CONVE + CONV-DISTMULT from Table 3 and varying one parameter at a time. This model has weight of the textual relations loss T = 0.25, weight of the L2 penalty A = 1, convolution window size of three, and is initialized randomly for the entity and KB relation vectors, and from pre-trained embeddings for word vectors (Turian et al., 2010). The overall MRR of the model is 40.4 on the validation set (test results are shown in the Table). When the weight of T is changed to 1 (i.e., equal contribution of textual and KB relations), the overall MRR goes down to 39.6 from 40.4, indicating the usefulness of weighting the two kinds of relations non-uniformly. When A is reduced to 0.04, MRR is 40.0 and when A is increased to 25, MRR goes down to 38.9. This indicates the L2 penalty hyper-parameter has a large impact on performance. When we initialize the word embeddings randomly instead of using pre-trained word vectors, performance drop</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384–394. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhen Wang</author>
<author>Jianwen Zhang</author>
<author>Jianlin Feng</author>
<author>Zheng Chen</author>
</authors>
<title>Knowledge graph and text jointly embedding.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics,</booktitle>
<pages>1591--1601</pages>
<contexts>
<context position="7470" citStr="Wang et al. (2014" startWordPosition="1143" endWordPosition="1146">outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations. Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure. Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015). Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textual relations. Weston et al. (2013) combined continuous representations from a knowledge base and textual mentions for prediction of new relations. The two representations were trained independently of each other and using different loss functions, and were only combined at inference time. Additionally, the employed representations of text were non-compositional. In this work</context>
<context position="23209" citStr="Wang et al., 2014" startWordPosition="3740" endWordPosition="3743"> batch training algorithm. The gradients of the basic models are straightforward to compute, and the gradients of the convolutional network parameters for the CONV-augmented models are also not hard to derive using back-propagation. 4 Experiments Dataset and Evaluation Protocol We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015). The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015). Textual relations for 4Check the first author’s website for a release of the dataset. 1504 FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set. After pruning5, there are 2.7 million unique textual relations that are added to the knowledge graph. The set of textual relations is larger than the set used in Toutanova and Chen (2015) (25,000 versus 2.7 million), leading to improved performance. The number of relat</context>
</contexts>
<marker>Wang, Zhang, Feng, Chen, 2014</marker>
<rawString>Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014a. Knowledge graph and text jointly embedding. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, pages 1591–1601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhen Wang</author>
<author>Jianwen Zhang</author>
<author>Jianlin Feng</author>
<author>Zheng Chen</author>
</authors>
<title>Knowledge graph embedding by translating on hyperplanes.</title>
<date>2014</date>
<booktitle>In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence,</booktitle>
<pages>1112--1119</pages>
<contexts>
<context position="7470" citStr="Wang et al. (2014" startWordPosition="1143" endWordPosition="1146">outperform either source alone in the framework of path-ranking algorithms in a combined knowledge base and text graph (Lao et al., 2012). To alleviate the sparsity of textual relations arising in such a combined graph, (Gardner et al., 2013; Gardner et al., 2014) showed how to incorporate clusters or continuous representations of textual relations. Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure. Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015). Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textual relations. Weston et al. (2013) combined continuous representations from a knowledge base and textual mentions for prediction of new relations. The two representations were trained independently of each other and using different loss functions, and were only combined at inference time. Additionally, the employed representations of text were non-compositional. In this work</context>
<context position="23209" citStr="Wang et al., 2014" startWordPosition="3740" endWordPosition="3743"> batch training algorithm. The gradients of the basic models are straightforward to compute, and the gradients of the convolutional network parameters for the CONV-augmented models are also not hard to derive using back-propagation. 4 Experiments Dataset and Evaluation Protocol We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015). The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015). Textual relations for 4Check the first author’s website for a release of the dataset. 1504 FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set. After pruning5, there are 2.7 million unique textual relations that are added to the knowledge graph. The set of textual relations is larger than the set used in Toutanova and Chen (2015) (25,000 versus 2.7 million), leading to improved performance. The number of relat</context>
</contexts>
<marker>Wang, Zhang, Feng, Chen, 2014</marker>
<rawString>Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014b. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, pages 1112–1119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
<author>Antoine Bordes</author>
<author>Oksana Yakhnenko</author>
<author>Nicolas Usunier</author>
</authors>
<title>Connecting language and knowledge bases with embedding models for relation extraction.</title>
<date>2013</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7727" citStr="Weston et al. (2013)" startWordPosition="1186" endWordPosition="1189">al., 2014) showed how to incorporate clusters or continuous representations of textual relations. Note that these vector representations are based on the co-occurrence patterns for the textual relations and not on their compositional structure. Cooccurrence based textual relation representations were also learned in (Neelakantan et al., 2015). Wang et al. (2014a) combined knowledge base and text information by embedding knowledge base entities and the words in their names in the same vector space, but did not model the textual cooccurrences of entity pairs and the expressed textual relations. Weston et al. (2013) combined continuous representations from a knowledge base and textual mentions for prediction of new relations. The two representations were trained independently of each other and using different loss functions, and were only combined at inference time. Additionally, the employed representations of text were non-compositional. In this work we train continuous representations of knowledge base and textual relations jointly, which allows for deeper interactions between the 1500 sources of information. We directly build on the universal schema approach of Riedel et al. (2013) as well as the uni</context>
</contexts>
<marker>Weston, Bordes, Yakhnenko, Usunier, 2013</marker>
<rawString>Jason Weston, Antoine Bordes, Oksana Yakhnenko, and Nicolas Usunier. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bishan Yang</author>
<author>Wen-tau Yih</author>
<author>Xiaodong He</author>
<author>Jianfeng Gao</author>
<author>Li Deng</author>
</authors>
<title>Embedding entities and relations for learning and inference in knowledge bases.</title>
<date>2015</date>
<booktitle>In International Conference on Learning Representations (ICLR).</booktitle>
<contexts>
<context position="5379" citStr="Yang et al. (2015)" startWordPosition="822" endWordPosition="825">f textual mentions. Knowledge base completion Nickel et al. (2015) provide a broad overview of machine learning models for knowledge graphs, including models based on observed graph features such as the path ranking algorithm (Lao et al., 2011), models based on continuous representations (latent features), and model combinations (Dong et al., 2014). These models predict new facts in a given knowledge base, based on information from existing entities and relations. From this line of work, most relevant to our study is prior work evaluating continuous representation models on the FB15k dataset. Yang et al. (2015) showed that a simple variant of a bilinear model DISTMULT outperformed TRANSE (Bordes et al., 2013) and more richly parameterized models on this dataset. We therefore build upon the best performing prior model DISTMULT from this line of work, as well as additional models E and F developed in the context of text-augmented knowledge graphs (Riedel et al., 2013), and extend them to incorporate compositional representations of textual relations. 1http://lemurproject.org/clueweb12/ FACC1/ Relation extraction using distant supervision A number of works have focused on extracting new instances of re</context>
<context position="13438" citStr="Yang et al., 2015" startWordPosition="2131" endWordPosition="2134"> E and DISTMULT. their parameters. 3.1 Basic Models We begin with presenting the three models from prior work that this research builds upon. They all learn latent continuous representations of relations and entities or entity pairs, and score possible triples based on the learned continuous representations. Each of the models can be defined on a knowledge graph containing entities and KB relations only, or on a knowledge graph additionally containing textual relations. We use models F and E from (Riedel et al., 2013) where they were used for a combined KB+text graph, and model DISTMULT from (Yang et al., 2015), which was originally used for a knowledge graph containing only KB relations. As shown in Figure 3, model F learns a Kdimensional latent feature vector for each candidate entity pair (es, eo), as well as a samedimensional vector for each relation r, and the 1 scoring function is simply defined as their inner product: f(es, r, eo) = v(r)Tv(es, eo). Therefore, different pairs sharing the same entity would not share parameters in this model. Model E does not have parameters for entity pairs, and instead has parameters for individual entities. It aims to capture the compatibility between entitie</context>
<context position="14825" citStr="Yang et al. (2015)" startWordPosition="2381" endWordPosition="2384">y (node) ei, the model also learns a latent feature vector of the same dimensionality. The score of a candidate triple (es, r, eo) is defined as f(es, r, eo) = v(rs)Tv(es) + v(ro)Tv(eo). It can be seen that when a subject entity is fixed in a query (es, r, ?), the ranking of candidate object entity fillers according to f does not depend on the subject entity but only on the relation type r. The third model DISTMULT, is a special form of a bilinear model like RESCAL (Nickel et al., 2011), where the non-diagonal entries in the relation matrices are assumed to be zero. This model was proposed in Yang et al. (2015) and was shown to outperform prior work on the FB15k dataset. In this model, each entity ei and each relation r is assigned a latent feature vector of dimension K. The score of a candidate triple (es, r, eo) is defined as f(es, r, eo) = v(r)T (v(es) o v(eo)), where o denotes the element-wise vector product. In this model, entity pairs which share an entity also share parameters, and the ranking of candidate objects for queries (es, r, ?) depends on the subject entity. Denote Ne = |£|, Nr = |R|, and K = dimension of latent feature vectors, then model E has KNe + 2KNr parameters and model DISTMU</context>
<context position="20070" citStr="Yang et al., 2015" startWordPosition="3258" endWordPosition="3261">ment as follows: p(eo|es, r; O) = f (es,r,e&apos;;Θ) Ee&apos;ENeg(es,r,?) e Conditional probabilities for subject entities p(es|eo, r; O) are defined analogously. Here O denotes all the parameters of latent features. The denominator is defined using a set of entities that do not fill the object position in any relation triple (es, r, ?) in the training knowledge graph. Since the number of such entities is impractically large, we sample negative triples from the full set. We also limit the candidate entities to ones that have types consistent with the position in the relation triple (Chang et al., 2014; Yang et al., 2015), where the types are approximated following Toutanova and Chen (2015). Additionally, since the task of predicting textual relations is auxiliary to the main task, we use a weighting factor T for the loss on predicting the arguments of textual relations (Toutanova and Chen, 2015). Denote T as a set of triples, we define the loss L(T ; O) as: L(T ; O) = − � log p(eo|es, r; O) (es,r,eo)ET �− log p(es|eo, r; O) (es,r,eo)ET Let TKB and Ttext represent the set of knowledge base triples and textual relation triples respectively. The final training loss function is de2Our experimental comparison focu</context>
<context position="23230" citStr="Yang et al., 2015" startWordPosition="3744" endWordPosition="3747">rithm. The gradients of the basic models are straightforward to compute, and the gradients of the convolutional network parameters for the CONV-augmented models are also not hard to derive using back-propagation. 4 Experiments Dataset and Evaluation Protocol We use the FB15k-237 4 dataset, which is a subset of FB15k (Bordes et al., 2013) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic (Toutanova and Chen, 2015). The FB15k dataset has been used in multiple studies on knowledge base completion (Wang et al., 2014b; Yang et al., 2015). Textual relations for 4Check the first author’s website for a release of the dataset. 1504 FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (Gabrilovich et al., 2013), and include textual links of all co-occurring entities from the KB set. After pruning5, there are 2.7 million unique textual relations that are added to the knowledge graph. The set of textual relations is larger than the set used in Toutanova and Chen (2015) (25,000 versus 2.7 million), leading to improved performance. The number of relations and triples in t</context>
</contexts>
<marker>Yang, Yih, He, Gao, Deng, 2015</marker>
<rawString>Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2015. Embedding entities and relations for learning and inference in knowledge bases. In International Conference on Learning Representations (ICLR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daojian Zeng</author>
<author>Kang Liu</author>
<author>Siwei Lai</author>
<author>Guangyou Zhou</author>
<author>Jun Zhao</author>
</authors>
<title>Relation classification via convolutional deep neural network.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>2335--2344</pages>
<contexts>
<context position="9120" citStr="Zeng et al., 2014" startWordPosition="1391" endWordPosition="1394">, we evaluate the approach on a dataset that contains rich prior information from the training knowledge base, as well as a wealth of textual information from a large document collection. Continuous representations for supervised relation extraction In contrast to the work reviewed so far, work on sentence-level relation extraction using direct supervision has focused heavily on representing sentence context. Models using hand-crafted features have evolved for more than a decade, and recently, models using continuous representations have been found to achieve new state-of-the-art performance (Zeng et al., 2014; Gormley et al., 2015). Compared to work on representation learning for sentence-level context, such as this recent work using LSTM models on constituency or dependency trees (Tai et al., 2015), our approach using a one-hidden-layer convolutional neural network is relatively simple. However, even such a simple approach has been shown to be very competitive (Kim, 2014). 3 Models for knowledge base completion We begin by introducing notation to define the task, largely following the terminology in Nickel et al. (2015). We assume knowledge bases are represented using RDF triples, in the form (su</context>
</contexts>
<marker>Zeng, Liu, Lai, Zhou, Zhao, 2014</marker>
<rawString>Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via convolutional deep neural network. In Proceedings of COLING, pages 2335–2344.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>