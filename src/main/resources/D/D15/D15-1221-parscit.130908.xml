<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014212">
<title confidence="0.982667">
GhostWriter: Using an LSTM for Automatic Rap Lyric Generation
</title>
<author confidence="0.999265">
Peter Potash, Alexey Romanov, Anna Rumshisky
</author>
<affiliation confidence="0.9988075">
Dept. of Computer Science
University of Massachusetts Lowell
</affiliation>
<address confidence="0.8449">
Lowell, MA 01854
</address>
<email confidence="0.999656">
{ppotash,aromanov,arum}@cs.uml.edu
</email>
<sectionHeader confidence="0.9974" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999956333333333">
This paper demonstrates the effectiveness
of a Long Short-Term Memory language
model in our initial efforts to generate un-
constrained rap lyrics. The goal of this
model is to generate lyrics that are simi-
lar in style to that of a given rapper, but
not identical to existing lyrics: this is
the task of ghostwriting. Unlike previ-
ous work, which defines explicit templates
for lyric generation, our model defines its
own rhyme scheme, line length, and verse
length. Our experiments show that a Long
Short-Term Memory language model pro-
duces better “ghostwritten” lyrics than a
baseline model.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999925631578947">
Ghostwriting defines a distinction between the
performer/presenter of text, lyrics, etc, and the cre-
ator of text/lyrics. The goal is to present some-
thing in a style that is believable enough to be
credited to the performer. In the domain of rap
specifically, rappers sometimes function as ghost-
writers early on before embarking on their own
public careers, and there are even businesses that
provide written lyrics as a service 1. The goal
of GhostWriter is to produce a system that can
take a given artist’s lyrics and generate similar yet
unique lyrics. To accomplish this, we must cre-
ate a language model to produce text, while also
understanding what ’style’ means in a quantitative
sense.
The contribution of this paper is three-fold: (1)
we present the ghostwriting problem of producing
similar yet different lyrics; (2) we present compu-
tational, quantitative evaluation methods for these
</bodyText>
<footnote confidence="0.966503">
1http://www.rap-rebirth.com/,
http://www.precisionwrittens.com/
rap-ghostwriters-for-hire/
</footnote>
<bodyText confidence="0.983826666666667">
two aspects; (3) we evaluate the performance of
a Long Short-Term Memory (LSTM) vs n-gram
model for this problem.
</bodyText>
<sectionHeader confidence="0.999941" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999956194444445">
Recent work (Sutskever et al., 2011; Graves,
2013) has shown the effectiveness of Recurrent
Neural Networks (RNNs) for text generation. In
their works, the authors use an RNN to create a
language model at the character level. The results
are inspiring, as the models learn various gram-
matical and punctuation rules, such as opening
and closing parentheses, plus learning a large vo-
cabulary of English words at the character level.
Graves (2013) uses a variation of an RNN called
LSTM architecture which creates a better lan-
guage model than a regular RNN.
Text generation for artistic purposes, such as po-
etry and lyrics, has also been explored, often using
templates and constraints (Oliveira et al., 2014;
Barbieri et al., 2012). In regards to rap lyrics, Wu
et al. (2013) present a system for rap lyric gener-
ation that produces a single line of lyrics that are
meant to be a response to a single line of input.
However, the work that is most similar to ours is
that of Malmi et al. (2015). The authors create
fixed 16-line verses, generating the verse line-by-
line using full lines from existing rap songs. The
system predicts the best next line based on the pre-
vious lines, using a system that records an 81.9%
accuracy predicting next lines in already existing
verses. The feature that provides the greatest accu-
racy gain is a neural embedding of the lines, cre-
ated from the character level.
Hir ee and Brown (2010b) have developed a
rhyme detection tool based on a probabilistic
model (Hir ee and Brown, 2010a) that analyzes
phoneme patterns in words. The model is trained
on a set of lyrics that were manually annotated for
rhyming words. The statistics generated by the
rhyme detection tool will be an important part of
</bodyText>
<page confidence="0.968965">
1919
</page>
<note confidence="0.7751275">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1919–1924,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.555215">
our evaluation (see Section 5).
</bodyText>
<sectionHeader confidence="0.983758" genericHeader="method">
3 Generating Lyrics
</sectionHeader>
<bodyText confidence="0.999965454545455">
In a departure from previous work on poetry/lyric
generation, our goal is to build a model that
does not require templates/constraints to generate
lyrics, while also being able to produce full verses,
as opposed to single lines. The system must be
able to model general human language in order to
produce fluent lyrics, but it must also be able to
model the style of a target artist, by understanding
the artist’s vocabulary and rhythmic style, in order
to fully execute the ghostwriting task of producing
similar yet new lyrics.
</bodyText>
<subsectionHeader confidence="0.971265">
3.1 LSTM
</subsectionHeader>
<bodyText confidence="0.996691454545455">
Here we will give a very brief overview of RNNs
and LSTMs. For a more detailed explanation
please refer to (Graves, 2013). The foundation
of an RNN (of which an LSTM is specific ar-
chitecture) is a word embedding E that provides
a vector representation for each of the words in
our corpus. Given a history of words wk, ..., w0
we want to determine P(wk+1|wk, ..., w0; E, Φ),
where Φ is a set of parameters used by our
model. In the context of an RNN we define this
probability by:
</bodyText>
<equation confidence="0.974752">
P(wk+1|wk,..., w0; E, Φ) = f(x, s) (1)
</equation>
<bodyText confidence="0.983333785714286">
At each time-step the RNN computes f given an
observation x and a previous state s. The input
goes through a transformation where it passes
through one or several hidden layers.
The LSTM model uses a specific architecture
for the hidden transformation, defined by the
LSTM memory cell. The key feature to the LSTM
memory cell is the presence of an input gate, out-
put gate, forget gate, and cell/cell memory, which
manifest themselves in the model as activation
vectors. Each of these gates/cells has its own
bias vector, and the hidden layer at each time-step
is now a complex nonlinear combination of gate,
cell, and hidden vectors.
</bodyText>
<subsectionHeader confidence="0.999908">
3.2 Using LSTM for Lyrics Generation
</subsectionHeader>
<bodyText confidence="0.999978066666667">
Since previous work has shown the power of
RNNs to model language, we hope that it can cap-
ture the rhythmic style of an artist by learning
rhyme and meter patterns. As noted in Section 2,
LSTMs have performed well at sequence forecast-
ing, for example at learning punctuation, such as
opening and closing parentheses. We see the task
of rhyme detection as something similar in na-
ture. Kaparthy et al. (2015) have also shown that
LSTMs could successfully learn where to place
the brackets and indentation in C++ code. In their
model, certain LSTM cells activated specifically
when encountering end of the line. We believe
learning rhymes at the end of the line is concep-
tually similar to such tasks.
</bodyText>
<subsectionHeader confidence="0.999962">
3.3 Verse Structure and Rhyme Inference
</subsectionHeader>
<bodyText confidence="0.9996383">
The goal of our model is to not just generate
lyrics, but generate the structure for the lyrics as
well. To do this, we have added “&lt;endLine&gt;”
and “&lt;endVerse&gt;” tokens to the lyrics. From this,
the system will generate its own line breaks, while
also defining when a generated verse ends. This
allows us to analyze non-rhyming features from
(Hirjee and Brown, 2010a), such as number of
syllables per line and number of lines per verse.
We also desire that, by using the “&lt;endLine&gt;”
token, the system has a better chance of un-
derstanding rhyme schemes used by an artist.
For example, the LSTM can capture the pat-
tern of “came &lt;endLine&gt;” followed shortly by
“name &lt;endLine&gt;” to understand that “came”
and “name” are a rhyming pair. To do this effec-
tively, the system would need sufficient training
data where rhyming pairs occur frequently enough
to actually dictate a pattern, similar to (Reddy and
Knight, 2011; Addanki and Wu, 2013).
</bodyText>
<sectionHeader confidence="0.997983" genericHeader="method">
4 Experimental Design
</sectionHeader>
<subsectionHeader confidence="0.950046">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999846166666667">
We collected songs from 14 artists from the site
The Original Hip-Hop (Rap) Lyrics Archive -
OHHLA.com - Hip-Hop Since 19922. In the
present lyrics generation experiments, we used the
lyrics from the rapper Fabolous. For training, we
used 219 verses with at least 175 words in each
verse. We selected Fabolous because his lyrics
produced the highest accuracy in the artist recog-
nition experiments in (Hirjee and Brown, 2010a).
We conjecture that because of this, he had the most
consistent style, making him a good choice for ini-
tial experiments.
</bodyText>
<footnote confidence="0.966616">
2http://www.ohhla.com/
</footnote>
<page confidence="0.983857">
1920
</page>
<subsectionHeader confidence="0.8954">
4.2 Baseline
</subsectionHeader>
<bodyText confidence="0.979590388888889">
To compare with the results of the LSTM model,
we followed the work of (Barbieri et al., 2012)
and created a Markov model for lyric generation.
Since the goal of our work is to make an unsu-
pervised system, we do not use any constraints
or templates to produce the lyrics. Thus, our
baseline simplifies to a basic n-gram model.
Given a history of wk+n−1,...,wk, the system
generates a new token t as follows:
|wk,...,wk+n−1,•|
where |wk...wk+n−1t |is the amount of times
the the context wk+n−1,...,w1 is followed by t
in the training data, and |wk...wk+n−1 •  |is the
amount of times the context appears followed by
any token. There is the possibility that the context
has never been encountered in the training data.
When this occurs, we back off to a smaller n-gram
model:
</bodyText>
<equation confidence="0.950513">
(3)
|wk,...,wk+n−2,•,•|
</equation>
<bodyText confidence="0.9999696">
The model may have to back-off multiple
times before it encounters context it has seen
in the training data. Once we back-off to the
point where we compute P(wn+k = t|wk), we
are guaranteed to have at least one non-zero
probability, because wk must have appeared in
the vocabulary for it to have been generated
previously.
Note that rather than backing off to a lower-
order n-gram model, we use a skip-gram model
which drops the words immediately preceding the
predicted word. The main motivation for this is
that it allows us to capture long-range dependen-
cies, which makes it into a better baseline compar-
ison for an LSTM.
</bodyText>
<subsectionHeader confidence="0.996976">
4.3 Model Initialization
</subsectionHeader>
<bodyText confidence="0.999783428571429">
When producing lyrics with either the LSTM
or baseline model, we initialize with the
“&lt;startVerse&gt;” token. Once the model produces
a token, it becomes part of the context for the next
step of token generation. Our models are closed in
the sense that they only produce tokens that appear
in the training vocabulary.
</bodyText>
<subsectionHeader confidence="0.956684">
4.4 LSTM Implementation
</subsectionHeader>
<bodyText confidence="0.9999652">
We used a Python implementation of an LSTM
from Jonathan Raiman3. The LSTM is built on
top of Theano (Bastien et al., 2012; Bergstra et
al., 2010). Following (Graves, 2013), we set the
amount of LSTM inputs/outputs to be equal to the
vocabulary size. Also, to avoid the vanishing gra-
dient problem when training RNNs, we clip the
gradients in the range [-1,1]. We train our LSTM
model using a Tesla K40 GPU on a single work-
station.
</bodyText>
<sectionHeader confidence="0.999912" genericHeader="method">
5 Evaluation Methods
</sectionHeader>
<bodyText confidence="0.99998455">
In this section, we present automated methods for
evaluating the quality of generated lyrics. Ide-
ally, judging system output in terms of, e.g. flu-
ency, should be conducted using manual evalua-
tion. However, conducting formal human evalua-
tion is somewhat problematic. For a full qualita-
tive evaluation of a given artist that would assess
both similarity of style and novelty, the evaluator
would need to know that particular artist’s body
of work very well. Even finding annotators who
are well-versed in the general art of rap lyrics can
be challenging (Addanki and Wu, 2014). While
this may be possible for the present experiments
that focus on a single artist, it is hardly feasible for
larger-scale studies that will use our full data set
that contains the lyrics of 14 different artists. We
therefore propose an automated evaluation method
which we believe is able to capture two critical as-
pects of ghostwriting, which are in fact quite tricky
to capture together: being similar, yet different.
</bodyText>
<subsectionHeader confidence="0.992696">
5.1 Similarity to existing lyrics
</subsectionHeader>
<bodyText confidence="0.999960090909091">
In order to evaluate the novelty of generated
lyrics, we compare the similarity of the generated
lyrics to the lyrics in our training set. We used an
algorithm proposed by (Mahedero et al., 2005)
for calculating the similarity between produced
lyrics and all verses from the same artist. This
algorithm is based on the well-known Inverse
Document Frequency, using cosine on document
vectors to calculate distance. First, we build the
Term-Document Matrix with weights for each
term in each song:
</bodyText>
<equation confidence="0.988188857142857">
wij = fijlog(njN ) (4)
3https://github.com/JonathanRaiman/
theano_lstm
P(wk+n = t|wk+n−1, ..., wk) =
|wk,...,wk+n−1,t |(2)
P(wk+n = t|wk+n−2, ..., wk) =
|wk,...,wk+n−2,•,t|
</equation>
<page confidence="0.944259">
1921
</page>
<bodyText confidence="0.9999856">
where N is the total number of documents
(verses, in our case), nj is the number of verses
that contains term j and fij is the frequency of
term j in the ith verse. Using this matrix, we can
calculate the cosine distance between verses and
use it as a measure of similarity. When discussing
similarity, we refer to the max similarity: of all
verses it is most similar to, exactly how similar is
it? The lower the max similarity score, the more
novel the lyrics.
</bodyText>
<subsectionHeader confidence="0.996945">
5.2 Numerical features of the lyrics
</subsectionHeader>
<bodyText confidence="0.999997454545455">
We also produced the features from (Hirjee and
Brown, 2010a) for our generated verses. The
statistics of these features are meant to represent
how effective we are in modeling an artist’s style.
The point of the system is not to produce arbitrary
rhymes; it is to produce rhyme types and rhyme
frequency that are similar to the target artist. Fol-
lowing (Malmi et al., 2015), the rhyme feature we
examine in this work is rhyme density. Rhyme
density is defined as the total number of rhymed
syllables divided by the total number of syllables.
</bodyText>
<sectionHeader confidence="0.999956" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999872">
For the lyrics generation experiments reported
here, we used the rapper Fabolous as the artist
whose style we tried to emulate.
</bodyText>
<subsectionHeader confidence="0.997809">
6.1 Example of Generated Lyrics (Warning:
Explicit Content)
</subsectionHeader>
<bodyText confidence="0.95871436">
Below is a sample of lyrics generated by the
LSTM model:
Line 1: i m old enough to know better young
enough to not give a fuck
Line 2: rather hold my head high and die then
live and duck
Line 3: i got ta fuck be up and little niggaz go
in
Line 4: when i m in the feds and scoped by
uncle sam
Line 5: dope and hunn ed grams rope and
hunn ed grams
Line 6: at the same time she jerking and wig-
gling
Line 7: smirking and giggling
While the pairs of rhyming end-lines in the gen-
erated lyrics are taken from the training data (the
max similarity is 0.41), no more than two lines
appear from a single verse. Though the gener-
ated lyrics aren’t novel in a strict sense, the LSTM
model is more effective than the n-gram model
at using lines from multiple verses (see next Sec-
tion 6.3). The rhyme density of this verse is 0.35,
which is almost equal to Fabolous’s average rhyme
density (0.34).
</bodyText>
<subsectionHeader confidence="0.999889">
6.2 Quantitative Analysis
</subsectionHeader>
<bodyText confidence="0.999719653846154">
As previously mentioned, the key to effective
ghostwriting is to mirror an artist’s style, but
also providing original content. While vocabu-
lary and lyrical content are key components for an
artist’s style, this is inherently satisfied by using
words only from the training data. Thus, rhyme
style – specifically rhyme density – will be the
key performance indicator for imitating an artist’s
style. In terms of rap lyrics in general, a higher
rhyme density is often better. Therefore for our
system we would like a high rhyme density, but
with a low max similarity score (a higher nov-
elty). Figures 2 and 1 show the graph for rhyme
density and max similarity for the LSTM and n-
grams models, respectively. For the LSTM model
the values are graphed compared to training iter-
ation number – as the model becomes more fit to
the data. For the n-gram model they are graphed
dependent on n-gram value. For each n-gram
value, we generate 10 verses and compute the av-
erage value of the two metrics. One expects that
a perfectly fit LSTM model without regularization
would exactly reproduce lyrics from the training
data, and a high n-gram value would would also
produce duplicate lyrics. This is evident in the
graphs.
</bodyText>
<figureCaption confidence="0.976906">
Figure 1: Values of rhyme density and max simi-
larity versus n-gram value for the n-gram model.
</figureCaption>
<page confidence="0.977982">
1922
</page>
<figureCaption confidence="0.996414">
Figure 2: Values of rhyme density and max sim-
ilarity versus iteration number when training the
LSTM model.
</figureCaption>
<subsectionHeader confidence="0.9935325">
6.3 Correlation of Rhyme Density and Max
Similarity
</subsectionHeader>
<bodyText confidence="0.999986681818182">
Since exact replication would assuredly give a
higher rhyme density than randomly produced
lyrics, we desire a low correlation between rhyme
density and max similarity. The correlation be-
tween rhyme density and max similarity for the
LSTM model is 0.32, and for the n-gram model it
is 0.47. When examining Figures 1 and 2 one may
notice the anomalous points of high rhyme density
(at n = 6 on the n-gram graph and 3,000 iterations
for the LSTM model). After further inspection of
the lyrics at these points, we see the lyrics con-
tain repetitions of the exact same phrase. Since
words are repeated frequently, the rhyme density
of the lyrics is high (repeated words create rhymed
phonemes, according to the rhyme detection tool).
These points cause the similarity-density correla-
tions to be artificially lower. After removing these
data points, the LSTM model still has a lower
correlation than the n-gram model, but the gap is
much smaller: 0.71 compared to 0.75. Ultimately
however, this shows that the LSTM model is better
at generating original, rhyming lyrics.
</bodyText>
<subsectionHeader confidence="0.995547">
6.4 Style Matching
</subsectionHeader>
<bodyText confidence="0.999984666666667">
Unfortunately, the correlation numbers do not dic-
tate specifically the effectiveness of the LSTM
model in the ghostwriting task. Instead, we can
look at that max similarity values of both systems
when they generate lyrics that produce a rhyme
density similar to the average rhyme density of
the target rapper. Looking at 100 randomly se-
lected verses, Fabolous has an average rhyme den-
sity of 0.34. To do our analysis, first we create
four regression lines, one for each metric (max
similarity and rhyme density) in each model (we
do not include the points of high rhyme density).
Next we use the two rhyme density lines to deter-
mine at which iteration/n value the systems gen-
erate a rhyme density of 0.34. After that we plug
these numbers into the two similarity lines to de-
termine what similarity is needed to achieve the
target rhyme density. The n-gram model line has
a similarity of 1.28 at this point (above the max
value of 1 for the metric), while the LSTM model
has a value of 0.59. Based on these numbers,
the LSTM model clearly outperforms the n-gram
model when it comes to making original lyrics that
are similar in style to our target rapper.
</bodyText>
<sectionHeader confidence="0.999466" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999972304347826">
In this work, we have shown the effectiveness of
an LSTM model for generating novel lyrics that
are similar in style to a target artist. We com-
pare the performance of the LSTM model to a
much simpler system: an n-gram model. The re-
sults of our experiments show that, as an unsu-
pervised, non-template model, the LSTM model
is better able to produce novel lyrics that also re-
flect the rhyming style of the target artist. In fu-
ture work, we plan to use more data to train our
model, making it easier for our system to actually
identify rhyming pairs and use them in new con-
texts. We also plan to encode phoneme features of
words to improve rhyme discovery. Furthermore,
we plan to generate lyrics from artists with a vary-
ing vocabulary size to see if it is easier to generate
lyrics for an artist with a smaller vocabulary. In
terms of evaluation, we hope to incorporate some
method to evaluate the fluency of generated lyrics
(Addanki and Wu, 2014). Lastly, to further avoid
over-fitting to the training data and reproducing
lyrics with a high similarity, we plan to use weight
noise (Jim et al., 1996) to regularize our model.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999883">
We would like to thank the anonymous reviewers
for their feedback.
</bodyText>
<sectionHeader confidence="0.986441" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.514662666666667">
Karteek Addanki and Dekai Wu. 2013. Unsupervised
rhyme scheme identification in hip hop lyrics using
hidden markov models. In Statistical Language and
Speech Processing, pages 39–50. Springer.
Karteek Addanki and Dekai Wu. 2014. Evaluating
improvised hip hop lyrics–challenges and observa-
</bodyText>
<page confidence="0.92437">
1923
</page>
<reference confidence="0.999485805970149">
tions. In Proceedings of The Ninth International
Conference on Language Resources and Evaluation
(LREC).
Gabriele Barbieri, Franc¸ois Pachet, Pierre Roy, and
Mirko Degli Esposti. 2012. Markov constraints for
generating lyrics with style. In ECAI, pages 115–
120.
Fr´ed´eric Bastien, Pascal Lamblin, Razvan Pascanu,
James Bergstra, Ian Goodfellow, Arnaud Bergeron,
Nicolas Bouchard, David Warde-Farley, and Yoshua
Bengio. 2012. Theano: new features and speed im-
provements. arXiv preprint arXiv:1211.5590.
James Bergstra, Olivier Breuleux, Fr´ed´eric Bastien,
Pascal Lamblin, Razvan Pascanu, Guillaume Des-
jardins, Joseph Turian, David Warde-Farley, and
Yoshua Bengio. 2010. Theano: a cpu and gpu
math expression compiler. In Proceedings of the
Python for scientific computing conference (SciPy),
volume 4, page 3. Austin, TX.
Alex Graves. 2013. Generating sequences
with recurrent neural networks. arXiv preprint
arXiv:1308.0850.
Hussein Hirjee and Daniel Brown. 2010a. Using auto-
mated rhyme detection to characterize rhyming style
in rap music.
Hussein Hirjee and Daniel G Brown. 2010b. Rhyme
analyzer: An analysis tool for rap lyrics. In Pro-
ceedings of the 11th International Society for Music
Information Retrieval Conference. Citeseer.
Kam-Chuen Jim, Clyde Lee Giles, and Bill G Horne.
1996. An analysis of noise in recurrent neural net-
works: convergence and generalization. Neural Net-
works, IEEE Transactions on, 7(6):1424–1438.
Andrej Karpathy, Justin Johnson, and Fei-Fei Li. 2015.
Visualizing and understanding recurrent networks.
CoRR, abs/1506.02078.
Jose PG Mahedero, ´Alvaro Martinez, Pedro Cano,
Markus Koppenberger, and Fabien Gouyon. 2005.
Natural language processing of lyrics. In Proceed-
ings of the 13th annual ACM international confer-
ence on Multimedia, pages 475–478. ACM.
Eric Malmi, Pyry Takala, Hannu Toivonen, Tapani
Raiko, and Aristides Gionis. 2015. Dopelearning:
A computational approach to rap lyrics generation.
arXiv preprint arXiv:1505.04771.
Hugo Gonc¸alo Oliveira, Raquel Herv´as, Alberto D´ıaz,
and Pablo Gerv´as. 2014. Adapting a generic plat-
form for poetry generation to produce spanish po-
ems. In 5th International Conference on Computa-
tional Creativity, ICCC.
Sravana Reddy and Kevin Knight. 2011. Unsuper-
vised discovery of rhyme schemes. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies: short papers-Volume 2, pages 77–82. As-
sociation for Computational Linguistics.
Ilya Sutskever, James Martens, and Geoffrey E Hin-
ton. 2011. Generating text with recurrent neural
networks. In Proceedings of the 28th International
Conference on Machine Learning (ICML-11), pages
1017–1024.
Dekai Wu, Karteek Addanki, Markus Saers, and
Meriem Beloucif. 2013. Learning to freestyle:
Hip hop challenge-response induction via transduc-
tion rule segmentation. In 2013 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP 2013), Seattle, Washington, USA.
</reference>
<page confidence="0.996265">
1924
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.805109">
<title confidence="0.999952">GhostWriter: Using an LSTM for Automatic Rap Lyric Generation</title>
<author confidence="0.999485">Peter Potash</author>
<author confidence="0.999485">Alexey Romanov</author>
<author confidence="0.999485">Anna</author>
<affiliation confidence="0.9999165">Dept. of Computer University of Massachusetts</affiliation>
<address confidence="0.811005">Lowell, MA</address>
<abstract confidence="0.999580625">This paper demonstrates the effectiveness of a Long Short-Term Memory language model in our initial efforts to generate unconstrained rap lyrics. The goal of this model is to generate lyrics that are similar in style to that of a given rapper, but not identical to existing lyrics: this is the task of ghostwriting. Unlike previous work, which defines explicit templates for lyric generation, our model defines its own rhyme scheme, line length, and verse length. Our experiments show that a Long Short-Term Memory language model produces better “ghostwritten” lyrics than a baseline model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>tions</author>
</authors>
<booktitle>In Proceedings of The Ninth International Conference on Language Resources and Evaluation (LREC).</booktitle>
<marker>tions, </marker>
<rawString>tions. In Proceedings of The Ninth International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriele Barbieri</author>
<author>Franc¸ois Pachet</author>
<author>Pierre Roy</author>
<author>Mirko Degli Esposti</author>
</authors>
<title>Markov constraints for generating lyrics with style. In</title>
<date>2012</date>
<booktitle>ECAI,</booktitle>
<pages>115--120</pages>
<contexts>
<context position="2679" citStr="Barbieri et al., 2012" startWordPosition="413" endWordPosition="416"> (RNNs) for text generation. In their works, the authors use an RNN to create a language model at the character level. The results are inspiring, as the models learn various grammatical and punctuation rules, such as opening and closing parentheses, plus learning a large vocabulary of English words at the character level. Graves (2013) uses a variation of an RNN called LSTM architecture which creates a better language model than a regular RNN. Text generation for artistic purposes, such as poetry and lyrics, has also been explored, often using templates and constraints (Oliveira et al., 2014; Barbieri et al., 2012). In regards to rap lyrics, Wu et al. (2013) present a system for rap lyric generation that produces a single line of lyrics that are meant to be a response to a single line of input. However, the work that is most similar to ours is that of Malmi et al. (2015). The authors create fixed 16-line verses, generating the verse line-byline using full lines from existing rap songs. The system predicts the best next line based on the previous lines, using a system that records an 81.9% accuracy predicting next lines in already existing verses. The feature that provides the greatest accuracy gain is a</context>
<context position="8045" citStr="Barbieri et al., 2012" startWordPosition="1334" endWordPosition="1337">l Hip-Hop (Rap) Lyrics Archive - OHHLA.com - Hip-Hop Since 19922. In the present lyrics generation experiments, we used the lyrics from the rapper Fabolous. For training, we used 219 verses with at least 175 words in each verse. We selected Fabolous because his lyrics produced the highest accuracy in the artist recognition experiments in (Hirjee and Brown, 2010a). We conjecture that because of this, he had the most consistent style, making him a good choice for initial experiments. 2http://www.ohhla.com/ 1920 4.2 Baseline To compare with the results of the LSTM model, we followed the work of (Barbieri et al., 2012) and created a Markov model for lyric generation. Since the goal of our work is to make an unsupervised system, we do not use any constraints or templates to produce the lyrics. Thus, our baseline simplifies to a basic n-gram model. Given a history of wk+n−1,...,wk, the system generates a new token t as follows: |wk,...,wk+n−1,•| where |wk...wk+n−1t |is the amount of times the the context wk+n−1,...,w1 is followed by t in the training data, and |wk...wk+n−1 • |is the amount of times the context appears followed by any token. There is the possibility that the context has never been encountered </context>
</contexts>
<marker>Barbieri, Pachet, Roy, Esposti, 2012</marker>
<rawString>Gabriele Barbieri, Franc¸ois Pachet, Pierre Roy, and Mirko Degli Esposti. 2012. Markov constraints for generating lyrics with style. In ECAI, pages 115– 120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fr´ed´eric Bastien</author>
<author>Pascal Lamblin</author>
<author>Razvan Pascanu</author>
<author>James Bergstra</author>
<author>Ian Goodfellow</author>
<author>Arnaud Bergeron</author>
<author>Nicolas Bouchard</author>
<author>David Warde-Farley</author>
<author>Yoshua Bengio</author>
</authors>
<title>Theano: new features and speed improvements. arXiv preprint arXiv:1211.5590.</title>
<date>2012</date>
<contexts>
<context position="9858" citStr="Bastien et al., 2012" startWordPosition="1644" endWordPosition="1647">ation for this is that it allows us to capture long-range dependencies, which makes it into a better baseline comparison for an LSTM. 4.3 Model Initialization When producing lyrics with either the LSTM or baseline model, we initialize with the “&lt;startVerse&gt;” token. Once the model produces a token, it becomes part of the context for the next step of token generation. Our models are closed in the sense that they only produce tokens that appear in the training vocabulary. 4.4 LSTM Implementation We used a Python implementation of an LSTM from Jonathan Raiman3. The LSTM is built on top of Theano (Bastien et al., 2012; Bergstra et al., 2010). Following (Graves, 2013), we set the amount of LSTM inputs/outputs to be equal to the vocabulary size. Also, to avoid the vanishing gradient problem when training RNNs, we clip the gradients in the range [-1,1]. We train our LSTM model using a Tesla K40 GPU on a single workstation. 5 Evaluation Methods In this section, we present automated methods for evaluating the quality of generated lyrics. Ideally, judging system output in terms of, e.g. fluency, should be conducted using manual evaluation. However, conducting formal human evaluation is somewhat problematic. For </context>
</contexts>
<marker>Bastien, Lamblin, Pascanu, Bergstra, Goodfellow, Bergeron, Bouchard, Warde-Farley, Bengio, 2012</marker>
<rawString>Fr´ed´eric Bastien, Pascal Lamblin, Razvan Pascanu, James Bergstra, Ian Goodfellow, Arnaud Bergeron, Nicolas Bouchard, David Warde-Farley, and Yoshua Bengio. 2012. Theano: new features and speed improvements. arXiv preprint arXiv:1211.5590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Bergstra</author>
<author>Olivier Breuleux</author>
<author>Fr´ed´eric Bastien</author>
<author>Pascal Lamblin</author>
<author>Razvan Pascanu</author>
<author>Guillaume Desjardins</author>
<author>Joseph Turian</author>
<author>David Warde-Farley</author>
<author>Yoshua Bengio</author>
</authors>
<title>Theano: a cpu and gpu math expression compiler.</title>
<date>2010</date>
<booktitle>In Proceedings of the Python for scientific computing conference (SciPy),</booktitle>
<volume>4</volume>
<pages>3</pages>
<location>Austin, TX.</location>
<contexts>
<context position="9882" citStr="Bergstra et al., 2010" startWordPosition="1648" endWordPosition="1651"> it allows us to capture long-range dependencies, which makes it into a better baseline comparison for an LSTM. 4.3 Model Initialization When producing lyrics with either the LSTM or baseline model, we initialize with the “&lt;startVerse&gt;” token. Once the model produces a token, it becomes part of the context for the next step of token generation. Our models are closed in the sense that they only produce tokens that appear in the training vocabulary. 4.4 LSTM Implementation We used a Python implementation of an LSTM from Jonathan Raiman3. The LSTM is built on top of Theano (Bastien et al., 2012; Bergstra et al., 2010). Following (Graves, 2013), we set the amount of LSTM inputs/outputs to be equal to the vocabulary size. Also, to avoid the vanishing gradient problem when training RNNs, we clip the gradients in the range [-1,1]. We train our LSTM model using a Tesla K40 GPU on a single workstation. 5 Evaluation Methods In this section, we present automated methods for evaluating the quality of generated lyrics. Ideally, judging system output in terms of, e.g. fluency, should be conducted using manual evaluation. However, conducting formal human evaluation is somewhat problematic. For a full qualitative evalu</context>
</contexts>
<marker>Bergstra, Breuleux, Bastien, Lamblin, Pascanu, Desjardins, Turian, Warde-Farley, Bengio, 2010</marker>
<rawString>James Bergstra, Olivier Breuleux, Fr´ed´eric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. 2010. Theano: a cpu and gpu math expression compiler. In Proceedings of the Python for scientific computing conference (SciPy), volume 4, page 3. Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Graves</author>
</authors>
<title>Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.</title>
<date>2013</date>
<contexts>
<context position="2000" citStr="Graves, 2013" startWordPosition="303" endWordPosition="304">cs. To accomplish this, we must create a language model to produce text, while also understanding what ’style’ means in a quantitative sense. The contribution of this paper is three-fold: (1) we present the ghostwriting problem of producing similar yet different lyrics; (2) we present computational, quantitative evaluation methods for these 1http://www.rap-rebirth.com/, http://www.precisionwrittens.com/ rap-ghostwriters-for-hire/ two aspects; (3) we evaluate the performance of a Long Short-Term Memory (LSTM) vs n-gram model for this problem. 2 Related Work Recent work (Sutskever et al., 2011; Graves, 2013) has shown the effectiveness of Recurrent Neural Networks (RNNs) for text generation. In their works, the authors use an RNN to create a language model at the character level. The results are inspiring, as the models learn various grammatical and punctuation rules, such as opening and closing parentheses, plus learning a large vocabulary of English words at the character level. Graves (2013) uses a variation of an RNN called LSTM architecture which creates a better language model than a regular RNN. Text generation for artistic purposes, such as poetry and lyrics, has also been explored, often</context>
<context position="4588" citStr="Graves, 2013" startWordPosition="739" endWordPosition="740">ic generation, our goal is to build a model that does not require templates/constraints to generate lyrics, while also being able to produce full verses, as opposed to single lines. The system must be able to model general human language in order to produce fluent lyrics, but it must also be able to model the style of a target artist, by understanding the artist’s vocabulary and rhythmic style, in order to fully execute the ghostwriting task of producing similar yet new lyrics. 3.1 LSTM Here we will give a very brief overview of RNNs and LSTMs. For a more detailed explanation please refer to (Graves, 2013). The foundation of an RNN (of which an LSTM is specific architecture) is a word embedding E that provides a vector representation for each of the words in our corpus. Given a history of words wk, ..., w0 we want to determine P(wk+1|wk, ..., w0; E, Φ), where Φ is a set of parameters used by our model. In the context of an RNN we define this probability by: P(wk+1|wk,..., w0; E, Φ) = f(x, s) (1) At each time-step the RNN computes f given an observation x and a previous state s. The input goes through a transformation where it passes through one or several hidden layers. The LSTM model uses a sp</context>
<context position="9908" citStr="Graves, 2013" startWordPosition="1653" endWordPosition="1654"> dependencies, which makes it into a better baseline comparison for an LSTM. 4.3 Model Initialization When producing lyrics with either the LSTM or baseline model, we initialize with the “&lt;startVerse&gt;” token. Once the model produces a token, it becomes part of the context for the next step of token generation. Our models are closed in the sense that they only produce tokens that appear in the training vocabulary. 4.4 LSTM Implementation We used a Python implementation of an LSTM from Jonathan Raiman3. The LSTM is built on top of Theano (Bastien et al., 2012; Bergstra et al., 2010). Following (Graves, 2013), we set the amount of LSTM inputs/outputs to be equal to the vocabulary size. Also, to avoid the vanishing gradient problem when training RNNs, we clip the gradients in the range [-1,1]. We train our LSTM model using a Tesla K40 GPU on a single workstation. 5 Evaluation Methods In this section, we present automated methods for evaluating the quality of generated lyrics. Ideally, judging system output in terms of, e.g. fluency, should be conducted using manual evaluation. However, conducting formal human evaluation is somewhat problematic. For a full qualitative evaluation of a given artist th</context>
</contexts>
<marker>Graves, 2013</marker>
<rawString>Alex Graves. 2013. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hussein Hirjee</author>
<author>Daniel Brown</author>
</authors>
<title>Using automated rhyme detection to characterize rhyming style in rap music.</title>
<date>2010</date>
<contexts>
<context position="6758" citStr="Hirjee and Brown, 2010" startWordPosition="1119" endWordPosition="1122">rackets and indentation in C++ code. In their model, certain LSTM cells activated specifically when encountering end of the line. We believe learning rhymes at the end of the line is conceptually similar to such tasks. 3.3 Verse Structure and Rhyme Inference The goal of our model is to not just generate lyrics, but generate the structure for the lyrics as well. To do this, we have added “&lt;endLine&gt;” and “&lt;endVerse&gt;” tokens to the lyrics. From this, the system will generate its own line breaks, while also defining when a generated verse ends. This allows us to analyze non-rhyming features from (Hirjee and Brown, 2010a), such as number of syllables per line and number of lines per verse. We also desire that, by using the “&lt;endLine&gt;” token, the system has a better chance of understanding rhyme schemes used by an artist. For example, the LSTM can capture the pattern of “came &lt;endLine&gt;” followed shortly by “name &lt;endLine&gt;” to understand that “came” and “name” are a rhyming pair. To do this effectively, the system would need sufficient training data where rhyming pairs occur frequently enough to actually dictate a pattern, similar to (Reddy and Knight, 2011; Addanki and Wu, 2013). 4 Experimental Design 4.1 Dat</context>
<context position="12452" citStr="Hirjee and Brown, 2010" startWordPosition="2076" endWordPosition="2079">−1,t |(2) P(wk+n = t|wk+n−2, ..., wk) = |wk,...,wk+n−2,•,t| 1921 where N is the total number of documents (verses, in our case), nj is the number of verses that contains term j and fij is the frequency of term j in the ith verse. Using this matrix, we can calculate the cosine distance between verses and use it as a measure of similarity. When discussing similarity, we refer to the max similarity: of all verses it is most similar to, exactly how similar is it? The lower the max similarity score, the more novel the lyrics. 5.2 Numerical features of the lyrics We also produced the features from (Hirjee and Brown, 2010a) for our generated verses. The statistics of these features are meant to represent how effective we are in modeling an artist’s style. The point of the system is not to produce arbitrary rhymes; it is to produce rhyme types and rhyme frequency that are similar to the target artist. Following (Malmi et al., 2015), the rhyme feature we examine in this work is rhyme density. Rhyme density is defined as the total number of rhymed syllables divided by the total number of syllables. 6 Results For the lyrics generation experiments reported here, we used the rapper Fabolous as the artist whose style</context>
</contexts>
<marker>Hirjee, Brown, 2010</marker>
<rawString>Hussein Hirjee and Daniel Brown. 2010a. Using automated rhyme detection to characterize rhyming style in rap music.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hussein Hirjee</author>
<author>Daniel G Brown</author>
</authors>
<title>Rhyme analyzer: An analysis tool for rap lyrics.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th International Society for Music Information Retrieval Conference. Citeseer.</booktitle>
<contexts>
<context position="6758" citStr="Hirjee and Brown, 2010" startWordPosition="1119" endWordPosition="1122">rackets and indentation in C++ code. In their model, certain LSTM cells activated specifically when encountering end of the line. We believe learning rhymes at the end of the line is conceptually similar to such tasks. 3.3 Verse Structure and Rhyme Inference The goal of our model is to not just generate lyrics, but generate the structure for the lyrics as well. To do this, we have added “&lt;endLine&gt;” and “&lt;endVerse&gt;” tokens to the lyrics. From this, the system will generate its own line breaks, while also defining when a generated verse ends. This allows us to analyze non-rhyming features from (Hirjee and Brown, 2010a), such as number of syllables per line and number of lines per verse. We also desire that, by using the “&lt;endLine&gt;” token, the system has a better chance of understanding rhyme schemes used by an artist. For example, the LSTM can capture the pattern of “came &lt;endLine&gt;” followed shortly by “name &lt;endLine&gt;” to understand that “came” and “name” are a rhyming pair. To do this effectively, the system would need sufficient training data where rhyming pairs occur frequently enough to actually dictate a pattern, similar to (Reddy and Knight, 2011; Addanki and Wu, 2013). 4 Experimental Design 4.1 Dat</context>
<context position="12452" citStr="Hirjee and Brown, 2010" startWordPosition="2076" endWordPosition="2079">−1,t |(2) P(wk+n = t|wk+n−2, ..., wk) = |wk,...,wk+n−2,•,t| 1921 where N is the total number of documents (verses, in our case), nj is the number of verses that contains term j and fij is the frequency of term j in the ith verse. Using this matrix, we can calculate the cosine distance between verses and use it as a measure of similarity. When discussing similarity, we refer to the max similarity: of all verses it is most similar to, exactly how similar is it? The lower the max similarity score, the more novel the lyrics. 5.2 Numerical features of the lyrics We also produced the features from (Hirjee and Brown, 2010a) for our generated verses. The statistics of these features are meant to represent how effective we are in modeling an artist’s style. The point of the system is not to produce arbitrary rhymes; it is to produce rhyme types and rhyme frequency that are similar to the target artist. Following (Malmi et al., 2015), the rhyme feature we examine in this work is rhyme density. Rhyme density is defined as the total number of rhymed syllables divided by the total number of syllables. 6 Results For the lyrics generation experiments reported here, we used the rapper Fabolous as the artist whose style</context>
</contexts>
<marker>Hirjee, Brown, 2010</marker>
<rawString>Hussein Hirjee and Daniel G Brown. 2010b. Rhyme analyzer: An analysis tool for rap lyrics. In Proceedings of the 11th International Society for Music Information Retrieval Conference. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kam-Chuen Jim</author>
<author>Clyde Lee Giles</author>
<author>Bill G Horne</author>
</authors>
<title>An analysis of noise in recurrent neural networks: convergence and generalization. Neural Networks,</title>
<date>1996</date>
<journal>IEEE Transactions on,</journal>
<volume>7</volume>
<issue>6</issue>
<marker>Jim, Giles, Horne, 1996</marker>
<rawString>Kam-Chuen Jim, Clyde Lee Giles, and Bill G Horne. 1996. An analysis of noise in recurrent neural networks: convergence and generalization. Neural Networks, IEEE Transactions on, 7(6):1424–1438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrej Karpathy</author>
<author>Justin Johnson</author>
<author>Fei-Fei Li</author>
</authors>
<title>Visualizing and understanding recurrent networks.</title>
<date>2015</date>
<tech>CoRR, abs/1506.02078.</tech>
<marker>Karpathy, Johnson, Li, 2015</marker>
<rawString>Andrej Karpathy, Justin Johnson, and Fei-Fei Li. 2015. Visualizing and understanding recurrent networks. CoRR, abs/1506.02078.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jose PG Mahedero</author>
<author>´Alvaro Martinez</author>
<author>Pedro Cano</author>
<author>Markus Koppenberger</author>
<author>Fabien Gouyon</author>
</authors>
<title>Natural language processing of lyrics.</title>
<date>2005</date>
<booktitle>In Proceedings of the 13th annual ACM international conference on Multimedia,</booktitle>
<pages>475--478</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="11416" citStr="Mahedero et al., 2005" startWordPosition="1905" endWordPosition="1908"> the present experiments that focus on a single artist, it is hardly feasible for larger-scale studies that will use our full data set that contains the lyrics of 14 different artists. We therefore propose an automated evaluation method which we believe is able to capture two critical aspects of ghostwriting, which are in fact quite tricky to capture together: being similar, yet different. 5.1 Similarity to existing lyrics In order to evaluate the novelty of generated lyrics, we compare the similarity of the generated lyrics to the lyrics in our training set. We used an algorithm proposed by (Mahedero et al., 2005) for calculating the similarity between produced lyrics and all verses from the same artist. This algorithm is based on the well-known Inverse Document Frequency, using cosine on document vectors to calculate distance. First, we build the Term-Document Matrix with weights for each term in each song: wij = fijlog(njN ) (4) 3https://github.com/JonathanRaiman/ theano_lstm P(wk+n = t|wk+n−1, ..., wk) = |wk,...,wk+n−1,t |(2) P(wk+n = t|wk+n−2, ..., wk) = |wk,...,wk+n−2,•,t| 1921 where N is the total number of documents (verses, in our case), nj is the number of verses that contains term j and fij i</context>
</contexts>
<marker>Mahedero, Martinez, Cano, Koppenberger, Gouyon, 2005</marker>
<rawString>Jose PG Mahedero, ´Alvaro Martinez, Pedro Cano, Markus Koppenberger, and Fabien Gouyon. 2005. Natural language processing of lyrics. In Proceedings of the 13th annual ACM international conference on Multimedia, pages 475–478. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Malmi</author>
</authors>
<title>Pyry Takala, Hannu Toivonen, Tapani Raiko, and Aristides Gionis.</title>
<date>2015</date>
<marker>Malmi, 2015</marker>
<rawString>Eric Malmi, Pyry Takala, Hannu Toivonen, Tapani Raiko, and Aristides Gionis. 2015. Dopelearning: A computational approach to rap lyrics generation. arXiv preprint arXiv:1505.04771.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Gonc¸alo Oliveira</author>
<author>Raquel Herv´as</author>
<author>Alberto D´ıaz</author>
<author>Pablo Gerv´as</author>
</authors>
<title>Adapting a generic platform for poetry generation to produce spanish poems.</title>
<date>2014</date>
<booktitle>In 5th International Conference on Computational Creativity, ICCC.</booktitle>
<marker>Oliveira, Herv´as, D´ıaz, Gerv´as, 2014</marker>
<rawString>Hugo Gonc¸alo Oliveira, Raquel Herv´as, Alberto D´ıaz, and Pablo Gerv´as. 2014. Adapting a generic platform for poetry generation to produce spanish poems. In 5th International Conference on Computational Creativity, ICCC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sravana Reddy</author>
<author>Kevin Knight</author>
</authors>
<title>Unsupervised discovery of rhyme schemes.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2,</booktitle>
<pages>77--82</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7304" citStr="Reddy and Knight, 2011" startWordPosition="1212" endWordPosition="1215"> This allows us to analyze non-rhyming features from (Hirjee and Brown, 2010a), such as number of syllables per line and number of lines per verse. We also desire that, by using the “&lt;endLine&gt;” token, the system has a better chance of understanding rhyme schemes used by an artist. For example, the LSTM can capture the pattern of “came &lt;endLine&gt;” followed shortly by “name &lt;endLine&gt;” to understand that “came” and “name” are a rhyming pair. To do this effectively, the system would need sufficient training data where rhyming pairs occur frequently enough to actually dictate a pattern, similar to (Reddy and Knight, 2011; Addanki and Wu, 2013). 4 Experimental Design 4.1 Dataset We collected songs from 14 artists from the site The Original Hip-Hop (Rap) Lyrics Archive - OHHLA.com - Hip-Hop Since 19922. In the present lyrics generation experiments, we used the lyrics from the rapper Fabolous. For training, we used 219 verses with at least 175 words in each verse. We selected Fabolous because his lyrics produced the highest accuracy in the artist recognition experiments in (Hirjee and Brown, 2010a). We conjecture that because of this, he had the most consistent style, making him a good choice for initial experim</context>
</contexts>
<marker>Reddy, Knight, 2011</marker>
<rawString>Sravana Reddy and Kevin Knight. 2011. Unsupervised discovery of rhyme schemes. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 77–82. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya Sutskever</author>
<author>James Martens</author>
<author>Geoffrey E Hinton</author>
</authors>
<title>Generating text with recurrent neural networks.</title>
<date>2011</date>
<booktitle>In Proceedings of the 28th International Conference on Machine Learning (ICML-11),</booktitle>
<pages>1017--1024</pages>
<contexts>
<context position="1985" citStr="Sutskever et al., 2011" startWordPosition="299" endWordPosition="302"> similar yet unique lyrics. To accomplish this, we must create a language model to produce text, while also understanding what ’style’ means in a quantitative sense. The contribution of this paper is three-fold: (1) we present the ghostwriting problem of producing similar yet different lyrics; (2) we present computational, quantitative evaluation methods for these 1http://www.rap-rebirth.com/, http://www.precisionwrittens.com/ rap-ghostwriters-for-hire/ two aspects; (3) we evaluate the performance of a Long Short-Term Memory (LSTM) vs n-gram model for this problem. 2 Related Work Recent work (Sutskever et al., 2011; Graves, 2013) has shown the effectiveness of Recurrent Neural Networks (RNNs) for text generation. In their works, the authors use an RNN to create a language model at the character level. The results are inspiring, as the models learn various grammatical and punctuation rules, such as opening and closing parentheses, plus learning a large vocabulary of English words at the character level. Graves (2013) uses a variation of an RNN called LSTM architecture which creates a better language model than a regular RNN. Text generation for artistic purposes, such as poetry and lyrics, has also been </context>
</contexts>
<marker>Sutskever, Martens, Hinton, 2011</marker>
<rawString>Ilya Sutskever, James Martens, and Geoffrey E Hinton. 2011. Generating text with recurrent neural networks. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 1017–1024.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Karteek Addanki</author>
<author>Markus Saers</author>
<author>Meriem Beloucif</author>
</authors>
<title>Learning to freestyle: Hip hop challenge-response induction via transduction rule segmentation.</title>
<date>2013</date>
<booktitle>In 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013),</booktitle>
<location>Seattle, Washington, USA.</location>
<contexts>
<context position="2723" citStr="Wu et al. (2013)" startWordPosition="422" endWordPosition="425">uthors use an RNN to create a language model at the character level. The results are inspiring, as the models learn various grammatical and punctuation rules, such as opening and closing parentheses, plus learning a large vocabulary of English words at the character level. Graves (2013) uses a variation of an RNN called LSTM architecture which creates a better language model than a regular RNN. Text generation for artistic purposes, such as poetry and lyrics, has also been explored, often using templates and constraints (Oliveira et al., 2014; Barbieri et al., 2012). In regards to rap lyrics, Wu et al. (2013) present a system for rap lyric generation that produces a single line of lyrics that are meant to be a response to a single line of input. However, the work that is most similar to ours is that of Malmi et al. (2015). The authors create fixed 16-line verses, generating the verse line-byline using full lines from existing rap songs. The system predicts the best next line based on the previous lines, using a system that records an 81.9% accuracy predicting next lines in already existing verses. The feature that provides the greatest accuracy gain is a neural embedding of the lines, created from</context>
</contexts>
<marker>Wu, Addanki, Saers, Beloucif, 2013</marker>
<rawString>Dekai Wu, Karteek Addanki, Markus Saers, and Meriem Beloucif. 2013. Learning to freestyle: Hip hop challenge-response induction via transduction rule segmentation. In 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013), Seattle, Washington, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>