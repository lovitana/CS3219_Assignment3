<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9975145">
Intra-sentential Zero Anaphora Resolution
using Subject Sharing Recognition
</title>
<author confidence="0.902434">
Ryu Iida Kentaro Torisawa Chikara Hashimoto
Jong-Hoon Oh Julien Kloetzer
</author>
<affiliation confidence="0.968426">
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.5742">
Kyoto 619-0289, Japan
</address>
<email confidence="0.998916">
{ryu.iida,torisawa,ch,rovellia,julien}@nict.go.jp
</email>
<sectionHeader confidence="0.997389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906321428571">
In this work, we improve the performance
of intra-sentential zero anaphora resolu-
tion in Japanese using a novel method
of recognizing subject sharing relations.
In Japanese, a large portion of intra-
sentential zero anaphora can be regarded
as subject sharing relations between pred-
icates, that is, the subject of some predi-
cate is also the unrealized subject of other
predicates. We develop an accurate rec-
ognizer of subject sharing relations for
pairs of predicates in a single sentence,
and then construct a subject shared pred-
icate network, which is a set of predi-
cates that are linked by the subject shar-
ing relations recognized by our recognizer.
We finally combine our zero anaphora
resolution method exploiting the subject
shared predicate network and a state-of-
the-art ILP-based zero anaphora resolution
method. Our combined method achieved a
significant improvement over the the ILP-
based method alone on intra-sentential
zero anaphora resolution in Japanese. To
the best of our knowledge, this is the first
work to explicitly use an independent sub-
ject sharing recognizer in zero anaphora
resolution.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993725">
In ‘pro-dropped’ languages such as Japanese, Chi-
nese and Italian, pronouns are often unrealized in
text. For example, the subject of nomu (take) is
omitted in example (1).
</bodyText>
<equation confidence="0.44292575">
(1) Tomi-wa infuruenza-ni natta-node ,
Tom-TOP flu-IOBJ had-since punc
(ϕi-ga) kusuri-o non-da .
hei-SUBJ medicine-OBJ took period
</equation>
<bodyText confidence="0.985257208333333">
Since Tomi had the flu, (hei) took medicine.
Such unrealized pronouns are regarded as zero
anaphors, which are indicated using ϕ in liter-
ature, like ϕi-ga in example (1). Zero anaphor
refers to its antecedent somewhere. This phe-
nomenon of the reference is called zero anaphora.
In Japanese, about 60% of subjects appear as zero
anaphors in newspaper articles (Iida et al., 2007b),
and thus zero anaphora resolution is an essential
task for developing highly accurate machine trans-
lation and information extraction systems.
In this paper, we propose a novel method of re-
solving intra-sentential zero anaphora, in which a
subject zero anaphor refers to its antecedent in-
side a single sentence. This work does not ad-
dress inter-sentential zero anaphora, in which a
zero anaphor in a sentence refers to its antecedent
in another sentence. The novelty of our method
is in the use of subject sharing relations, which
are relations between two predicates that share a
subject by (zero) anaphora or coreference. For ex-
ample, in example (2), there are two subject shar-
ing relations for predicate pairs, advance-plan and
plan-dispatch, as illustrated in Figure 1.
</bodyText>
<figure confidence="0.7155328">
(2) seifui-wa (ϕi-ga) hisaichi-ni
governmenti-TOP iti-SUBJ disaster site-IOBJ
50 nin-o hakensuru koto-o (ϕi-ga)
50 people-OBJ dispatch COMP-OBJ iti-SUBJ
keikakusi junbisagyo-o susumeru .
</figure>
<figureCaption confidence="0.316986">
plan preparation-OBJ advance period
</figureCaption>
<bodyText confidence="0.987308272727273">
The governmenti plans that (iti) will dispatch
50 people to the disaster site and (iti) is
advancing its preparations.
The most straightforward method to recognize
subject sharing relations is to apply a (zero)
anaphora resolution system to a sentence and de-
tect such relations by recognizing (zero) anaphora,
like the relations represented by seifui and two
zero anaphors ϕi in Figure 1. However, to our
surprise, we found that a simple supervised clas-
sifier that exploits the local contexts surrounding
</bodyText>
<page confidence="0.969669">
2179
</page>
<note confidence="0.995897">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2179–2189,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figureCaption confidence="0.966114">
Figure 1: Example of subject shared predicate net-
work
</figureCaption>
<bodyText confidence="0.999927671641791">
predicates achieved a higher accuracy than that
of the straightforward method. This suggests that
just propagating the realized subject of a predi-
cate to the subject zero anaphor of other predicates
through recognized subject sharing relations (e.g.,
propagating subject government of advance to the
subject positions of plan and dispatch in Figure 1)
might lead to a higher accuracy in zero anaphora
resolution than the existing zero anaphora reso-
lution methods. In addition, a large portion of
zero anaphora can be regarded as subject shar-
ing relations (e.g., 39% of the intra-sentential zero
anaphora in the NAIST Text Corpus (Iida et al.,
2007b) are such cases). Hence, just by combining
our subject zero anaphora method with an existing
general anaphora resolution method that covers
other types of anaphora, significant improvement
of accuracy over all types of anaphora might be
achieved. This paper empirically shows that this
is actually the case through a series of experiments
in which we combine our method with an existing
ILP-based zero anaphora resolution method (Iida
and Poesio, 2011).
Our subject zero anaphora resolution method
constructs a subject shared predicate network
(SSPN), which is a network of predicates in which
subject sharing predicates are linked, from the
results of our accurate pairwise subject sharing
recognizer, which detects the predicate pairs that
share a subject. Zero anaphora resolution is done
by propagating the realized subject of a predi-
cate to the subject zero anaphor of other pred-
icates in the SSPN. An important point here is
that SSPN was introduced to solve the issue re-
lated to our pairwise subject sharing recognizer.
Our recognizer is applied only to the restricted
pairs of predicates in a sentence, such as predi-
cates that have a direct dependency relation be-
tween them. This is because our current recog-
nizer cannot achieve high accuracy for any pair
of predicates. In Figure 1, for instance, our rec-
ognizer can detect a subject sharing relation be-
tween advance and plan and another between plan
and dispatch, but it cannot detect one between ad-
vance and dispatch. However, in the SSPN, the
undetected relations can be derived by connecting
the two detected ones, and in the zero anaphora
resolution subject government of advance can be
successfully propagated to the subject position of
dispatch.
The rest of our paper is organized as follows.
In Section 2, we briefly overview previous work
on zero anaphora resolution. In Section 3, we
overview the procedure of our zero anaphora reso-
lution method. We explain the three types of sub-
ject sharing relations on which we focus and pro-
pose a method of pairwise subject sharing recog-
nition for the three types in Section 4. We eval-
uate how effectively our method recognizes sub-
ject sharing relations for these types in Section 5.
After that, we investigate the impact of explic-
itly introducing SSPNs in Section 6 and com-
pare our zero anaphora resolution method with a
state-of-the-art ILP-based method on the task of
intra-sentential subject zero anaphora resolution in
Section 7. Finally, in Section 8 we summarize this
work and discuss future directions.
</bodyText>
<sectionHeader confidence="0.999868" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.997048277777778">
Traditional approaches to zero anaphora reso-
lution are based on manually created heuristic
rules (Kameyama, 1986; Walker et al., 1994; Oku-
mura and Tamura, 1996; Nakaiwa and Shirai,
1996), which are mainly motivated by the rules
and preferences introduced in Centering The-
ory (Grosz et al., 1995). However, the research
trend of zero anaphora resolution has shifted from
such rule-based approaches to machine learning-
based approaches because in machine learning we
can easily integrate many different types of infor-
mation, such as morpho-syntactic, semantic and
discourse-related information. Researchers have
developed methods of zero anaphora resolution
for Chinese (Zhao and Ng, 2007; Chen and Ng,
2013), Japanese (Seki et al., 2002; Isozaki and Hi-
rao, 2003; Iida et al., 2007a; Taira et al., 2008;
Sasano et al., 2008; Sasano et al., 2009; Imamura
</bodyText>
<figure confidence="0.607958142857143">
hakensuru (dispatch)
hisaichi
(disaster site)
keikakusi (plan)
i=obj
subject
sharing
</figure>
<page confidence="0.975889">
2180
</page>
<bodyText confidence="0.999904090909091">
et al., 2009; Watanabe et al., 2010; Hayashibe et
al., 2011; Iida and Poesio, 2011; Yoshikawa et al.,
2011; Hangyo et al., 2013; Yoshino et al., 2013)
and Italian (Iida and Poesio, 2011). One critical
issue in zero anaphora resolution is optimizing the
outputs of sub-problems (e.g., zero anaphor detec-
tion and antecedent identification). Recent works
by Watanabe et al. (2010), Iida and Poesio (2011)
and Yoshikawa et al. (2011) revealed that joint in-
ference improves the overall performance of zero
anaphora resolution. We employed one of these
works as a baseline in Section 6.
Concerning subject sharing recognition, re-
lated methods have been explored for pronominal
anaphora (Yang et al., 2005) or coreference reso-
lution (Bean and Riloff, 2004; Bansal and Klein,
2012). In these methods, the semantic compatibil-
ity between the contexts surrounding an anaphor
and its antecedent (e.g., the compatibility of verbs
kidnap and release given some arguments) was
automatically extracted from raw texts in an un-
supervised manner and used as features in a ma-
chine learning-based approach. However, because
the automatically acquired semantic compatibility
is not always true or applicable in the context of
any pair of an anaphor and its antecedent, the ef-
fectiveness of the compatibility features might be
weakened. In contrast, we accurately recognize
the explicit subject sharing relations and directly
use them for propagating the subject of some pred-
icate to the empty subject position of other pred-
icates instead of indirectly using the relations as
features.
</bodyText>
<sectionHeader confidence="0.9472835" genericHeader="method">
3 Zero anaphora resolution using subject
shared predicate network
</sectionHeader>
<bodyText confidence="0.982977857142857">
In this section, we first give an overview of the
procedure of our zero anaphora resolution method.
Intra-sentential zero anaphora resolution in our
method is performed in the following five steps,
as depicted in Figure 2.
Step 1 The pairwise subject sharing relations be-
tween two predicates in a sentence are recog-
nized by our subject sharing recognizer.
Step 2 A subject shared predicate network
(SSPN) is constructed based on the results of
pairwise subject sharing recognition.
Step 3 For each predicate in the set of the subject
shared predicates in the SSPN, a subject is
detected by our subject detector, if one exists.
</bodyText>
<figureCaption confidence="0.6418464">
Step 1: Pairwise subject sharing recognition
Step 2: Subject shared predicate
network (SSPN) construction
Figure 2: Procedure of our zero anaphora resolu-
tion method
</figureCaption>
<bodyText confidence="0.98550175862069">
Step 4 If a subject is detected, it is propagated to
the empty subject position of each predicate
in the subject shared predicates in the SSPN.
Step 5 For resolving the potential zero anaphora
that were not resolved until Step 4, we apply
the existing ILP-based method (Iida and Poe-
sio, 2011).
We define subject sharing relations as follows.
Two predicates have a subject sharing relation if
and only if they share the same subject that is re-
ferred to by (zero) anaphora or coreference. Note
that the shared subject does not need to be realized
in the text; it can appear as inter-sentential zero
anaphora or exophora. In Step 1, the pairwise sub-
ject sharing relations between two predicates are
recognized, but recognizing the relations between
any two predicates in a sentence remains difficult.
We thus focus on some typical types of predicate
pairs. The details of the predicate pair types will
be explained in Section 4.1.
Given the results of pairwise subject sharing
recognition, we construct an SSPN in Step 2. In
an SSPN, every predicate in a sentence is a node
and only the predicate pairs that were judged to be
subject sharing are connected by a link. The ma-
jor advantage of explicitly constructing an SSPN
is that it enables us to resolve zero anaphora even
Set of predicates
in a sentence
</bodyText>
<figure confidence="0.972523615384616">
Step 3: Subject detection
subject shared
predicates in SSPN
Step 4: Subject
propagation
Results of intra=sentential
zero anaphora resolution
no subject
other predicates
in SSPN
Step 5: Existing
zero anaphora
resolution
</figure>
<page confidence="0.98981">
2181
</page>
<bodyText confidence="0.999976558139535">
if a predicate with a subject zero anaphor does
not have any direct subject sharing relation with a
predicate with a subject, like predicates susumeru
(advance) and hakensuru (dispatch) in Figure 1.
By traversing the paths of the subject sharing re-
lations in the SSPN, such predicates can be con-
nected to successfully propagate the subject. The
effect of introducing SSPNs is empirically evalu-
ated in Section 6.
For use in Step 3, we create a subject detector,
which judges whether an argument to a predicate
is its subject using SVMlight 1, an implementation
of Support Vector Machine (Vapnik, 1998), with a
polynomial kernel of 2nd degree. The training in-
stances of the subject detector are extracted from
the predicate-argument relations2 in the NAIST
Text Corpus. The numbers of positive and nega-
tive instances are 35,304 and 104,250 respectively.
As features, we used the morpho-syntactic infor-
mation about the lemmas of the predicate and its
argument and the functional words following the
predicate and its argument. The results of subject
detection with 5-fold cross-validation demonstrate
that our subject detector accurately detects sub-
jects with performances of 0.949 in recall, 0.855
in precision, and 0.899 in F-score.
Note that our subject detector checks whether
each predicate in an SSPN has a syntactic sub-
ject among its arguments. An SSPN can include
more than one predicate, and each predicate may
have its own subject3. In this step, if two or more
distinct subjects are detected for predicates in an
SSPN, we use the most likely subject (i.e., the
subject with the highest SVM score outputted by
our subject detector) for subject propagation. Note
that subject propagation is not performed if the
subject position of a predicate is already filled.
Up to this point, the zero anaphora of the fol-
lowing three cases cannot be resolved: (i) no sub-
ject was detected for any predicate in a group
linked by the subject sharing relations in the
SSPN, (ii) no subject sharing relation was recog-
nized for a predicate in the SSPN and (iii) non-
</bodyText>
<footnote confidence="0.752829">
1http://svmlight.joachims.org/
</footnote>
<bodyText confidence="0.692439222222222">
2Note that if a predicate appears in a relative clause and
a noun modified by the clause is the semantic subject of the
predicate, the noun is not regarded as subject by our subject
detector.
3The subject sharing recognizer is likely to regard two
predicates, each of which has its own subject, as non-subject
sharing predicate pairs, but it is still logically possible that
they are judged as subject sharing predicate pairs hence as a
part of an SSPN.
</bodyText>
<figureCaption confidence="0.998891">
Figure 3: Example of DEP type
</figureCaption>
<bodyText confidence="0.999967142857143">
subject arguments were omitted as zero anaphors.
To resolve zero anaphora in these cases, we ap-
ply a state-of-the-art ILP-based zero anaphora res-
olution method (Iida and Poesio, 2011) in Step 5.
This method determines zero anaphor and its an-
tecedent by joint inference using the results of sub-
ject detection, zero anaphor detection and intra-
and inter-sentential antecedent identification. In
the original method by Iida and Poesio (2011),
the inter-sentential zero anaphora was resolved,
but in this work we focus on intra-sentential zero
anaphora. To adapt their method for our problem
setting, we simply removed the inter-sentential an-
tecedent identification model from their method.
</bodyText>
<sectionHeader confidence="0.993717" genericHeader="method">
4 Pairwise subject sharing recognition
</sectionHeader>
<bodyText confidence="0.999899555555556">
A key component in our zero anaphora resolu-
tion method is pairwise subject sharing recogni-
tion. In this work, we focus on three types of sub-
ject sharing relations (DEP, ADJ and PNP types)
as a first step because the instances belonging to
the three types occupy 62% of intra-sentential zero
anaphora that can be regarded as subject sharing.
We developed a method that recognizes each sub-
ject sharing type and evaluate it.
</bodyText>
<subsectionHeader confidence="0.996387">
4.1 Three types of subject sharing relations
</subsectionHeader>
<bodyText confidence="0.999892916666667">
We first describe the three types of subject sharing
relations we focus on.
DEP A typical type of subject sharing relation
is one between two predicates that have a syntac-
tical dependency relation. The relation between
two predicates, natta (have) and nonda (take), in
example (1) in Section 1 is classified as this type
because the two predicates have the same subject
Tomi (ϕi), as illustrated in Figure 3. We call this
type of subject sharing the DEP type.
ADJ This type is a subject sharing relation be-
tween two adjacent predicates, i.e., a predicate
</bodyText>
<figure confidence="0.9506118">
subj
i-obj
nonda (take)
obj
medicine
4)r (zero anaphor)
anaphoric relation
subj
Tomr
Influenza
subject sharing
natta (have)
2182
kikanakunatta (do not work)
chakurikusita (land) haitta (move onto)
</figure>
<figureCaption confidence="0.9999955">
Figure 4: Example of ADJ type
Figure 5: Example of PNP type
</figureCaption>
<bodyText confidence="0.999931222222222">
pairs that do not have any other predicate between
them in the surface order of a sentence. Although
two adjacent predicates in a sentence tend to share
the same subject, they sometimes cannot be cap-
tured as the DEP type due to a long-distance de-
pendency between predicates. For example, in ex-
ample (3), two adjacent predicates, land and move
onto, have the same subject but not a direct depen-
dency relation, as illustrated in Figure 4.
</bodyText>
<equation confidence="0.881684666666667">
(3) hikouki-wa bujini chakurikusi-ta-ga
airplane-TOP safely land-PAST-but
(ϕi-ga) yudouro-ni hait-ta-atoni
iti-SUBJ taxiway-IOBJ move onto-PAST-after
soujukan-ga kikanakunat-ta .
control stick-SUBJ do not work-PAST period
</equation>
<bodyText confidence="0.999362222222222">
The airplane safely landed, but its control
stick did not work after (iti) moved onto the
taxiway.
To cover such cases, we also take into account the
subject sharing relations of the ADJ type in which
two predicates appear adjacently in the surface or-
der.
PNP In addition to the above two types of re-
lations, in Japanese predicate pairs often have a
subject sharing relation when one of the predi-
cates syntactically depends on a noun (or noun
phrase) that in turn syntactically depends on the
other predicate. Example (4) is classified as such
a type because noun houshin (plan) is placed be-
tween two predicates, akirakanisita (unveil) and
tekkaisuru (abolish), in the dependency path and
predicates share subject chiji (governor), as illus-
trated in Figure 5.
</bodyText>
<equation confidence="0.37825125">
(4) chijii-wa (ϕi-ga) joukou-o
governor-TOP hei-SUBJ stipulation-OBJ
tekkaisuru houshin-o akirakanisi-ta .
abolish plan-TOP unveil-PAST period
</equation>
<bodyText confidence="0.975628038461538">
The governori unveiled his plan under which
(hei) will abolish the stipulation.
We call this type of subject sharing relation the
PNP type.
In this work, we solve the problem of subject
sharing recognition as a binary classification prob-
lem in which we classify whether two predicates
share the same subject. We solve this problem us-
ing a supervised approach. We independently ex-
tract the training instances for each type from a
corpus to which (zero) anaphora, coreference and
subjects were annotated. The binary labels of the
training instances are classified into the positive
class if the subject of the two predicates in an in-
stance is shared by coreference or (zero) anaphora,
and negative otherwise. To create a classifier, we
use SVMUght and experiment with both a linear
kernel and a polynomial kernel of 2nd degree.
As features, we use the feature set shown in
Table 1. Even though these features look simple,
we expect them to work well to capture the char-
acteristics of each subject sharing type. For ex-
ample, as shown in example (5), the (subject) case
marker of the argument (mother-SUBJ) between
two predicates natta (have) and katta (buy) is a
good indicator of non-subject sharing.
</bodyText>
<figure confidence="0.792806">
(5) Tomi-ga infuruenza-ni natta-node ,
Tom-SUBJ flu-IOBJ had-since punc
haha-ga kusuri-o katta .
mother-SUBJ medicine-OBJ buy-PAST period
</figure>
<figureCaption confidence="0.3989985">
Since Tom had the flu, his mother bought
medicine.
</figureCaption>
<bodyText confidence="0.9992444">
For recognizing the PNP type of subject sharing
relations, whether certain nouns appear between
two predicates is an important clue, e.g., koto
(complementizer) in example (6) and nouryoku
(ability) in example (7).
</bodyText>
<figure confidence="0.99881521875">
subj
soujukan
(control stick)
subject
sharing
subj
hikoukii
(airplane)
bujini
(safely)
i-obj
yudouro
(taxiway)
subj
(�i(zero anaphor)
anaphoric
relation
obj
houshin (plan)
adnom
subject
sharing
i-obj
subj
tekkaisuru (abolish)
chijii (governor)
anaphoric
relation
(ti (zero anaphor)
akirakanisita (unveil)
joukou (stipulation)
subj
</figure>
<page confidence="0.992773">
2183
</page>
<bodyText confidence="0.934436">
pi and pj stand for the left and right predicates in predicate pairs. np is the noun
phrase between pi and pj. bi (bj) stands for the bunsetsu-unity including pi (pj).
The features marked with * are only used for PNP type.
</bodyText>
<tableCaption confidence="0.995247">
Table 1: Features of subject sharing recognition
</tableCaption>
<figure confidence="0.96665129032258">
Name
Description
PoSi (PoSj)
PoS of pi (pj)
lemmai (lemmaj)
func wi (func wj)
casei (casej)
btw case
lemma of pi (pj)
function words following pi (pj)
case marker of arguments of pi (pj)
case marker of arguments that appeared between pi and pj
NpPoS*
Np lemma*
PoS of np
lemma of np
function words following np
case marker of dependents of np
noun class of np based on Kazama and Torisawa (2008)
func wnp*
casenp*
n class*
(6) seifui-wa (ϕi-ga) sono isetsu-o
government-TOP iti-SUBJ the relocation-OBJ
mitomeru koto-o kime-ta .
admit COMP-OBJ decide-PAST period
The governmenti decided that (iti) admits the
relocation.
(7) sono fune-wa (ϕi-ga) hayaku
the ship-TOP iti-SUBJ fast
hashiru nouryoku-o motteiru .
</figure>
<bodyText confidence="0.993039833333333">
run ability-OBJ have period
The shipi has an ability that (iti) runs fast.
To robustly capture this characteristic, we use as
features the discrete classes created by the noun
clustering algorithm proposed by Kazama and
Torisawa (2008). It follows the distributional hy-
pothesis, which states that semantically similar
words tend to appear in similar contexts (Harris,
1954). By treating the syntactic dependency re-
lations between words as ‘contexts,’ the clustering
method defines a probabilistic model of noun-verb
dependencies with hidden classes:
</bodyText>
<equation confidence="0.969337333333333">
∑
p(n, (v, r)) = p(n|c)p((v, r)|c)p(c)
c
</equation>
<bodyText confidence="0.999497125">
where n is a noun, v is a verb or noun on which n
depends by grammatical relation r (post-positions
in Japanese), and c is a hidden class. The depen-
dency relation frequencies were obtained from a
600-million page web corpus, and model parame-
ters p(n|c), p((v, r)|c) and p(c) were estimated us-
ing the EM algorithm (Hofmann, 1999). We clus-
tered one million nouns into 500 discrete classes
</bodyText>
<footnote confidence="0.828019666666667">
4A bunsetsu-unit is a Japanese base phrase consisting of
at least one content word optionally followed by functional
words.
</footnote>
<equation confidence="0.538977">
by assigning noun n to class c when the model pa-
rameter p(c|n) &gt; 0 (0 = 0.2).
</equation>
<sectionHeader confidence="0.7301825" genericHeader="method">
5 Experiment 1: pairwise subject
sharing recognition
</sectionHeader>
<bodyText confidence="0.999322666666667">
We first empirically evaluate the performance of
our pairwise subject sharing recognition for the
DEP, ADJ and PNP types.
</bodyText>
<subsectionHeader confidence="0.991481">
5.1 Experimental setting
</subsectionHeader>
<bodyText confidence="0.999767541666667">
The training data for the subject sharing recog-
nizer were generated from the NAIST Text Cor-
pus 1.4 (Iida et al., 2007b), in which (zero)
anaphora, coreference and subjects were manu-
ally annotated. We automatically extracted pairs
of predicates from the corpus. Since the original
NAIST Text Corpus has a wide variety of anno-
tation noise, we cleaned it up by the following
strategy. According to the annotation scheme in
the NAIST Text Corpus, predicate-argument rela-
tions were annotated for the ‘bare predicates’ even
if the predicates appear in passive or causative sen-
tences. In such cases, the annotation was difficult
and caused inconsistencies because the annotators
needed to imagine the predicate-argument rela-
tions for predicates that are not explicitly written,
considering case alternation caused by changes of
voice and so on. As such, to achieve a higher level
of consistency, we modified the annotation scheme
for predicate-argument relations by considering
‘surface predicates’ and re-annotated predicate-
argument relations in passive and causative cases,
thus reducing the risk of inconsistent annotations
caused by case alternation.
</bodyText>
<page confidence="0.985657">
2184
</page>
<table confidence="0.9998932">
type method Recall Precision F-score
DEP baseline 0.161 0.505 0.244
proposed (linear) 0.545 0.719 0.620
proposed (poly-2d) 0.578 0.732 0.646
ADJ baseline 0.143 0.414 0.212
proposed (linear) 0.011 0.604 0.021
proposed (poly-2d) 0.285 0.713 0.407
PNP baseline 0.154 0.329 0.210
proposed (linear) 0.028 0.844 0.053
proposed (poly-2d) 0.159 0.723 0.260
</table>
<tableCaption confidence="0.999782">
Table 2: Results of subject sharing recognition
</tableCaption>
<bodyText confidence="0.999984481481481">
Another important point is that in the NAIST
Text Corpus, if the antecedent of a zero anaphor is
not explicitly written in the corpus, it is simply an-
notated as ‘exophoric’, and the subject sharing re-
lations between two predicates whose subject was
annotated as exophoric cannot be captured. In
contrast, in our cleaning procedure, the annota-
tors additionally annotated such ‘exophoric’ sub-
ject sharing relations to take into account all sub-
ject sharing relations in the corpus.
The predicates in the corpus and their depen-
dency relations were detected based on the outputs
of a Japanese dependency parser, J.DepP5 (Yoshi-
naga and Kitsuregawa, 2009). We obtained 49,313
predicate pairs for the DEP type, 86,728 for the
ADJ type, and 27,117 for the PNP types. The num-
bers of positive instances of DEP, ADJ and PNP
types are 9,524, 13,104, and 2,363 respectively. To
evaluate the subject sharing recognition, we con-
ducted 5-fold cross-validation using these predi-
cate pairs and measured the performance using re-
call, precision and F-score.
Note that we also evaluated a baseline method
that recognizes subject sharing relations using the
results of the state-of-the-art zero anaphora resolu-
tion method (Iida and Poesio, 2011) and the sub-
ject detector at Step 3 in Section 3.
</bodyText>
<subsectionHeader confidence="0.993066">
5.2 Results: subject sharing recognition
</subsectionHeader>
<bodyText confidence="0.99968775">
We measured the performances of the baseline and
our subject sharing recognition method using re-
call, precision and F-score for each of the three
types of subject sharing relations, which are shown
in Table 2. The results demonstrate that all of the
proposed classifiers solved the problems with high
precision. In particular, for each type, the classi-
fier using a polynomial kernel achieved more than
</bodyText>
<footnote confidence="0.879983">
5http://www.tkl.iis.u-tokyo.ac.jp/˜ynaga/jdepp/
</footnote>
<bodyText confidence="0.9995054">
70% precision. We thus used the classifiers with
a polynomial kernel for evaluations in Section 6.
The results also show that the classifier using a
polynomial kernel for each type outperformed the
baseline method based on the state-of-the-art zero
anaphora resolution method. That is, the direct
subject sharing recognition using our classifiers
has the potential to lead to a significant improve-
ment in zero anaphora resolution, which we con-
firm through the experiments in Section 7.
Table 2 also shows that the classifier for the DEP
type outperformed those for all of the other types
in F-score. The difference reflects the wider vari-
ations of the problems in both ADJ and PNP com-
pared to the case of DEP. For example, to recog-
nize the PNP type of subject sharing relation, our
classifier needs to appropriately learn the compli-
cated relationship between two predicates and the
noun that intervenes between them, a problem we
do not need to consider for the DEP type.
</bodyText>
<sectionHeader confidence="0.935041" genericHeader="method">
6 Experiment 2: intra-sentential zero
</sectionHeader>
<subsectionHeader confidence="0.819662">
anaphora resolution between subjects
</subsectionHeader>
<bodyText confidence="0.999953933333333">
We next investigate the effect of introducing
SSPNs. In this experiment, we evaluated the per-
formance of intra-sentential zero anaphora resolu-
tion only between subjects, i.e., the positive in-
stances used in this experiment were limited to
the cases where the antecedent of a zero anaphor
is the realized subject of a predicate. We evalu-
ated a method of zero anaphora resolution using
only SSPNs, where intra-sentential zero anaphora
is resolved by the first four steps (Steps 1 to 4)
in Section 3. We compared it to a baseline that
only used the results of pairwise subject sharing
recognition without SSPNs: if the subject shar-
ing relation between two predicates is recognized
by our pairwise subject sharing recognizer and a
</bodyText>
<page confidence="0.974643">
2185
</page>
<table confidence="0.9999588">
Recall Precision F-score
DEP w/o SSPN 0.259 0.744 0.385
DEP with SSPN 0.284 0.744 0.411
ADJ w/o SSPN 0.182 0.554 0.274
ADJ with SSPN 0.193 0.561 0.288
PNP w/o SSPN 0.034 0.757 0.064
PNP with SSPN 0.033 0.780 0.064
DEP+ADJ w/o SSPN 0.315 0.602 0.413
DEP+ADJ with SSPN 0.354 0.604 0.447
DEP+PNP w/o SSPN 0.293 0.746 0.421
DEP+PNP with SSPN 0.324 0.749 0.453
ADJ+PNP w/o SSPN 0.191 0.558 0.285
ADJ+PNP with SSPN 0.203 0.566 0.299
DEP+ADJ+PNP w/o SSPN 0.324 0.604 0.422
DEP+ADJ+PNP with SSPN 0.365 0.607 0.456
</table>
<tableCaption confidence="0.999938">
Table 3: Results of intra-sentential zero anaphora resolution between subjects
</tableCaption>
<bodyText confidence="0.999620325581395">
single subject is detected by our subject detector
for one of the two predicates, then the subject fills
the empty subject position of the other predicate.
Note that in this baseline method, transitive sub-
ject propagation through more than one subject
sharing relation is not performed. Also, if mul-
tiple subjects are detected for a predicate, we used
the most likely subject to fill the subject position
of the predicate, as in our method.
We conducted 5-fold cross-validation using the
modified version of the NAIST Text Corpus pre-
sented in Section 5.1. In this evaluation, we
used the 8,473 subject zero anaphors that refer
to the subject antecedents (46% of all the intra-
sentential subject zero anaphora, in which a sub-
ject zero anaphor refers to the antecedent that are
not limited to subject) in the corpus. We mea-
sured the performance using recall, precision and
F-score for each of the three types of subject shar-
ing relations and their combinations. When com-
bining more than one subject sharing recognizer in
our method, we construct the SSPN using the sub-
ject sharing relations recognized by at least one
of those recognizers for transitive subject propa-
gation. On the other hand, in the baseline method,
the SSPN was not constructed and zero anaphoric
relations were identified using only the outputs of
our subject detector and one of those recognizers.
The experimental results shown in Table 3
clearly demonstrate that the method with SSPNs
for each type or a combination of the three types
consistently outperformed that without SSPNs ex-
cept for the PNP type. This result suggests that
multi-step propagation of subjects through more
than one subject sharing relation, as done in
SSPNs, is an effective way to propagate a sub-
ject to a subject position that cannot be reached
by a single subject sharing relation. Our results
also show that the F-score is improved by com-
bining different types of subject sharing relations,
and the best F-score, 0.456, was achieved when
we used all types of relations, i.e., in the case of
DEP+ADJ+PNP with SSPNs.
</bodyText>
<sectionHeader confidence="0.9758475" genericHeader="method">
7 Experiment 3: intra-sentential subject
zero anaphora resolution
</sectionHeader>
<bodyText confidence="0.9999765">
Finally, we evaluate the performance of intra-
sentential subject zero anaphora resolution. In the
previous section, we evaluated just a part of our
method, i.e., from Step 1 to Step 4 presented in
Section 3. In this section, we evaluate the whole
method, i.e., from Step 1 to Step 5, against 18,324
subject zero anaphors, which are all subject zero
anaphors annotated in our modified version of the
NAIST Text Corpus. As a baseline, we employed
Iida and Poesio (2011)’s method that was tuned
for intra-sentential zero anaphora resolution. The
baseline method solves the problems by applying
only Step 5 in Section 3 to all the predicates.
Our results in Table 4 show that all the meth-
ods using either each type or a combination of the
three types significantly outperformed the base-
line6. The best performing method was DEP+PNP,
which achieved 0.380 in F-score, which is 3.6%
</bodyText>
<footnote confidence="0.9318745">
6The significance was tested using McNemar’s testing
(P &lt; 0.01).
</footnote>
<page confidence="0.904782">
2186
</page>
<table confidence="0.999875666666667">
Recall Precision F-score
Baseline (Step 5) 0.345 0.344 0.344
+DEP with SSPN 0.388 0.363 0.375
+ADJ with SSPN 0.374 0.347 0.360
+PNP with SSPN 0.351 0.347 0.349
+DEP+ADJ with SSPN 0.399 0.355 0.376
+DEP+PNP with SSPN 0.394 0.366 0.380
+ADJ+PNP with SSPN 0.376 0.347 0.361
+DEP+ADJ+PNP with SSPN 0.401 0.356 0.377
</table>
<tableCaption confidence="0.99723">
Table 4: Results of intra-sentential subject zero anaphora resolution (Steps 1 to 5 vs. Step 5)
</tableCaption>
<table confidence="0.999931666666667">
Recall Precision F-score
Baseline (Step 5) 0.345 0.344 0.344
DEP with SSPN 0.131 0.744 0.223
ADJ with SSPN 0.089 0.561 0.154
PNP with SSPN 0.015 0.780 0.030
DEP+ADJ with SSPN 0.164 0.604 0.258
DEP+PNP with SSPN 0.150 0.749 0.250
ADJ+PNP with SSPN 0.094 0.566 0.161
DEP+ADJ+PNP with SSPN 0.169 0.607 0.264
</table>
<tableCaption confidence="0.999728">
Table 5: Results of intra-sentential subject zero anaphora resolution (Steps 1 to 4 vs. Step 5)
</tableCaption>
<bodyText confidence="0.999980791666667">
higher than the baseline. This suggests that
our method exploiting subject sharing relations
and SSPNs has a positive impact on accuracy of
general intra-sentential zero anaphora resolution
methods because about 84% of zero anaphors of
general intra-sentential zero anaphora appear as
subject zero anaphor in our corpus.
We also estimate how accurately the method us-
ing only the SSPNs evaluated in Section 6 resolves
intra-sentential subject zero anaphora in compari-
son to the baseline method. The results are shown
in Table 5 and demonstrate that the performance
of all the methods without Step 5 does not reach
that of the baseline method in F-score. However,
they retain high precision that ranges from 60% to
75%, preserving more than 10% of the recall on
the DEP, DEP+ADJ, DEP+PNP and DEP+ADJ+PNP
methods. Actually, in some of the potential ap-
plications of zero anaphora resolution, such as in-
formation extraction, methods with high precision
and low recall are preferable to ones with low pre-
cision and high recall. Our methods with SSPNs
alone might be usable in such applications because
of their high precision.
</bodyText>
<sectionHeader confidence="0.99906" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999942625">
In this paper, we introduced a subject shared pred-
icate network (SSPN), which is a network of
predicates that are linked by subject sharing re-
lations for resolving typical intra-sentential zero
anaphora. In our zero anaphora resolution method,
zero anaphoric relations are identified by propa-
gating a subject through subject sharing paths in
the SSPN. To construct SSPNs, we developed a
novel method of pairwise subject sharing recog-
nition using the local contexts that surround two
predicates and demonstrated that it can accurately
recognize subject sharing relations. We combined
our method of intra-sentential zero anaphora res-
olution with Iida and Poesio (2011)’s method and
achieved significantly better F-score than Iida and
Poesio (2011)’s method alone.
As future work, we are planning to use
commonsense knowledge, such as causal-
ity (Hashimoto et al., 2014) and script-like
knowledge (Sano et al., 2014), that has been
automatically acquired from big data for accurate
subject sharing recognition to improve inter-
sentential zero anaphora resolution for cases not
focused on in this work.
</bodyText>
<sectionHeader confidence="0.986599" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.720406">
Mohit Bansal and Dan Klein. 2012. Coreference se-
mantics from web features. In Proceedings of the
</bodyText>
<page confidence="0.97822">
2187
</page>
<reference confidence="0.999182390909091">
50th Annual Meeting of the Association for Compu-
tational Linguistics, pages 389–398.
David Bean and Ellen Riloff. 2004. Unsupervised
learning of contextual role knowledge for corefer-
ence resolution. In Proceedings of the Human Lan-
guage Technology Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics, pages 297–304.
Chen Chen and Vincent Ng. 2013. Chinese zero pro-
noun resolution: Some recent advances. In Proceed-
ings of the 2013 Conference on Empirical Methods
in Natural Language Processing, pages 1360–1365.
Barbara J. Grosz, Scott Weinstein, and Aravind K.
Joshi. 1995. Centering: A framework for model-
ing the local coherence of discourse. Computational
Linguistics, 21(2):203–225.
Masatsugu Hangyo, Daisuke Kawahara, and Sadao
Kurohashi. 2013. Japanese zero reference resolu-
tion considering exophora and author/reader men-
tions. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Process-
ing, pages 924–934.
Zellig Harris. 1954. Distributional structure. Word,
10(23):146–162.
Chikara Hashimoto, Kentaro Torisawa, Julien Kloetzer,
Motoki Sano, Istv´an Varga, Jong-Hoon Oh, and Yu-
taka Kidawara. 2014. Toward future scenario gener-
ation: Extracting event causality exploiting semantic
relation, context, and association features. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 987–997.
Yuta Hayashibe, Mamoru Komachi, and Yuji Mat-
sumoto. 2011. Japanese predicate argument struc-
ture analysis exploiting argument position and type.
In Proceedings of 5th International Joint Conference
on Natural Language Processing, pages 201–209.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Processing of the 22nd Annual Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 50–57.
Ryu Iida and Massimo Poesio. 2011. A cross-lingual
ILP solution to zero anaphora resolution. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, pages 804–813.
Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2007a.
Zero-anaphora resolution by learning rich syntactic
pattern features. ACM Transactions on Asian Lan-
guage Information Processing, Volume 6. Issue 4,
Article 12.
Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji
Matsumoto. 2007b. Annotating a Japanese text cor-
pus with predicate-argument and coreference rela-
tions. In Proceedings of the ACL Workshop: ‘Lin-
guistic Annotation Workshop’, pages 132–139.
Kenji Imamura, Kuniko Saito, and Tomoko Izumi.
2009. Discriminative approach to predicate-
argument structure analysis with zero-anaphora res-
olution. In Proceedings of the ACL-IJCNLP 2009
Conference Short Papers, pages 85–88.
Hideki Isozaki and Tsutomu Hirao. 2003. Japanese
zero pronoun resolution based on ranking rules and
machine learning. In Proceedings of the 2003 Con-
ference on Empirical Methods in Natural Language
Processing, pages 184–191.
Megumi Kameyama. 1986. A property-sharing con-
straint in centering. In Proceedings of the 24th An-
nual Meeting of the Association for Computational
Linguistics, pages 200–206.
Jun’ichi Kazama and Kentaro Torisawa. 2008. In-
ducing gazetteers for named entity recognition by
large-scale clustering of dependency relations. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 407–415.
Hiromi Nakaiwa and Satoshi Shirai. 1996. Anaphora
resolution of Japanese zero pronouns with deic-
tic reference. In Proceedings of the 16th Inter-
national Conference on Computational Linguistics,
pages 812–817.
Manabu Okumura and Kouji Tamura. 1996. Zero
pronoun resolution in Japanese discourse based on
Centering Theory. In Proceedings of the 16th Inter-
national Conference on Computational Linguistics,
pages 871–876.
Motoki Sano, Kentaro Torisawa, Julien Kloetzer,
Chikara Hashimoto, Istv´an Varga, and Jong-Hoon
Oh. 2014. Million-scale derivation of semantic re-
lations from a manually constructed predicate taxon-
omy. In Proceedings of the 25th International Con-
ference on Computational Linguistics, pages 1423–
1434.
Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-
hashi. 2008. A fully-lexicalized probabilistic model
for Japanese zero anaphora resolution. In Proceed-
ings of the 22nd International Conference on Com-
putational Linguistics, pages 769–776.
Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-
hashi. 2009. The effect of corpus size on case frame
acquisition for discourse analysis. In Proceedings of
Human Language Technologies: The 2009 Annual
Conference of the North American Chapter of the
Association for Computational Linguistics, pages
521–529.
Kazuhiro Seki, Atsushi Fujii, and Tetsuya Ishikawa.
2002. A probabilistic method for analyzing
Japanese anaphora integrating zero pronoun detec-
tion and resolution. In Proceedings of the 19th Inter-
national Conference on Computational Linguistics,
pages 911–917.
</reference>
<page confidence="0.822732">
2188
</page>
<reference confidence="0.999704441860465">
Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata.
2008. A Japanese predicate argument structure anal-
ysis using decision lists. In Proceedings of the 2008
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 523–532.
Vladimir N. Vapnik. 1998. Statistical Learning The-
ory. Adaptive and Learning Systems for Signal Pro-
cessing, Communications, and Control. John Wiley
&amp; Sons.
Marilyn Walker, Sharon Cote, and Masayo Iida. 1994.
Japanese discourse and the process of centering.
Computational Linguistics, 20(2):193–233.
Yotaro Watanabe, Masayuki Asahara, and Yuji Mat-
sumoto. 2010. A structured model for joint learn-
ing of argument roles and predicate senses. In Pro-
ceedings of the ACL 2010 Conference Short Papers,
pages 98–102.
Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005.
Improving pronoun resolution using statistics-based
semantic compatibility information. In Proceedings
of the 43rd Annual Meeting of the Association for
Computational Linguistics, pages 165–172.
Katsumasa Yoshikawa, Masayuki Asahara, and Yuji
Matsumoto. 2011. Jointly extracting Japanese
predicate-argument relation with Markov logic. In
Proceedings of 5th International Joint Conference
on Natural Language Processing, pages 1125–1133.
Naoki Yoshinaga and Masaru Kitsuregawa. 2009.
Polynomial to linear: Efficient classification with
conjunctive features. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1542–1551.
Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawa-
hara. 2013. Predicate argument structure analysis
using partially annotated corpora. In Proceedings
of the 6th International Joint Conference on Natural
Language Processing, pages 957–961.
Shanheng Zhao and Hwee Tou Ng. 2007. Identifica-
tion and resolution of Chinese zero pronouns: A ma-
chine learning approach. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, pages 541–550.
</reference>
<page confidence="0.996402">
2189
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341527">
<title confidence="0.9945115">Intra-sentential Zero Anaphora using Subject Sharing Recognition</title>
<author confidence="0.8780515">Ryu Iida Kentaro Torisawa Chikara Hashimoto Jong-Hoon Oh Julien Kloetzer</author>
<affiliation confidence="0.949172">National Institute of Information and Communications</affiliation>
<note confidence="0.52603">Kyoto 619-0289, Japan</note>
<abstract confidence="0.997388620689655">In this work, we improve the performance of intra-sentential zero anaphora resolution in Japanese using a novel method of recognizing subject sharing relations. In Japanese, a large portion of intrasentential zero anaphora can be regarded as subject sharing relations between predicates, that is, the subject of some predicate is also the unrealized subject of other predicates. We develop an accurate recognizer of subject sharing relations for pairs of predicates in a single sentence, then construct a shared predwhich is a set of predicates that are linked by the subject sharing relations recognized by our recognizer. We finally combine our zero anaphora resolution method exploiting the subject shared predicate network and a state-ofthe-art ILP-based zero anaphora resolution method. Our combined method achieved a significant improvement over the the ILPbased method alone on intra-sentential zero anaphora resolution in Japanese. To the best of our knowledge, this is the first work to explicitly use an independent subject sharing recognizer in zero anaphora resolution.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>389--398</pages>
<marker></marker>
<rawString>50th Annual Meeting of the Association for Computational Linguistics, pages 389–398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Bean</author>
<author>Ellen Riloff</author>
</authors>
<title>Unsupervised learning of contextual role knowledge for coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>297--304</pages>
<contexts>
<context position="8727" citStr="Bean and Riloff, 2004" startWordPosition="1357" endWordPosition="1360">; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related methods have been explored for pronominal anaphora (Yang et al., 2005) or coreference resolution (Bean and Riloff, 2004; Bansal and Klein, 2012). In these methods, the semantic compatibility between the contexts surrounding an anaphor and its antecedent (e.g., the compatibility of verbs kidnap and release given some arguments) was automatically extracted from raw texts in an unsupervised manner and used as features in a machine learning-based approach. However, because the automatically acquired semantic compatibility is not always true or applicable in the context of any pair of an anaphor and its antecedent, the effectiveness of the compatibility features might be weakened. In contrast, we accurately recogni</context>
</contexts>
<marker>Bean, Riloff, 2004</marker>
<rawString>David Bean and Ellen Riloff. 2004. Unsupervised learning of contextual role knowledge for coreference resolution. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 297–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Chen</author>
<author>Vincent Ng</author>
</authors>
<title>Chinese zero pronoun resolution: Some recent advances.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1360--1365</pages>
<contexts>
<context position="7743" citStr="Chen and Ng, 2013" startWordPosition="1199" endWordPosition="1202">tic rules (Kameyama, 1986; Walker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe </context>
</contexts>
<marker>Chen, Ng, 2013</marker>
<rawString>Chen Chen and Vincent Ng. 2013. Chinese zero pronoun resolution: Some recent advances. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1360–1365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Scott Weinstein</author>
<author>Aravind K Joshi</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="7333" citStr="Grosz et al., 1995" startWordPosition="1141" endWordPosition="1144">estigate the impact of explicitly introducing SSPNs in Section 6 and compare our zero anaphora resolution method with a state-of-the-art ILP-based method on the task of intra-sentential subject zero anaphora resolution in Section 7. Finally, in Section 8 we summarize this work and discuss future directions. 2 Related work Traditional approaches to zero anaphora resolution are based on manually created heuristic rules (Kameyama, 1986; Walker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site</context>
</contexts>
<marker>Grosz, Weinstein, Joshi, 1995</marker>
<rawString>Barbara J. Grosz, Scott Weinstein, and Aravind K. Joshi. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masatsugu Hangyo</author>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Japanese zero reference resolution considering exophora and author/reader mentions.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>924--934</pages>
<contexts>
<context position="8106" citStr="Hangyo et al., 2013" startWordPosition="1260" endWordPosition="1263">ne learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related methods have been explored for pronominal anaphora (Yang et al., 2005) or coreference resolution (</context>
</contexts>
<marker>Hangyo, Kawahara, Kurohashi, 2013</marker>
<rawString>Masatsugu Hangyo, Daisuke Kawahara, and Sadao Kurohashi. 2013. Japanese zero reference resolution considering exophora and author/reader mentions. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 924–934.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1954</date>
<journal>Distributional structure. Word,</journal>
<volume>10</volume>
<issue>23</issue>
<contexts>
<context position="21354" citStr="Harris, 1954" startWordPosition="3398" endWordPosition="3399">-TOP iti-SUBJ the relocation-OBJ mitomeru koto-o kime-ta . admit COMP-OBJ decide-PAST period The governmenti decided that (iti) admits the relocation. (7) sono fune-wa (ϕi-ga) hayaku the ship-TOP iti-SUBJ fast hashiru nouryoku-o motteiru . run ability-OBJ have period The shipi has an ability that (iti) runs fast. To robustly capture this characteristic, we use as features the discrete classes created by the noun clustering algorithm proposed by Kazama and Torisawa (2008). It follows the distributional hypothesis, which states that semantically similar words tend to appear in similar contexts (Harris, 1954). By treating the syntactic dependency relations between words as ‘contexts,’ the clustering method defines a probabilistic model of noun-verb dependencies with hidden classes: ∑ p(n, (v, r)) = p(n|c)p((v, r)|c)p(c) c where n is a noun, v is a verb or noun on which n depends by grammatical relation r (post-positions in Japanese), and c is a hidden class. The dependency relation frequencies were obtained from a 600-million page web corpus, and model parameters p(n|c), p((v, r)|c) and p(c) were estimated using the EM algorithm (Hofmann, 1999). We clustered one million nouns into 500 discrete cla</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. 1954. Distributional structure. Word, 10(23):146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Kentaro Torisawa</author>
<author>Julien Kloetzer</author>
<author>Motoki Sano</author>
<author>Istv´an Varga</author>
<author>Jong-Hoon Oh</author>
<author>Yutaka Kidawara</author>
</authors>
<title>Toward future scenario generation: Extracting event causality exploiting semantic relation, context, and association features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>987--997</pages>
<marker>Hashimoto, Torisawa, Kloetzer, Sano, Varga, Oh, Kidawara, 2014</marker>
<rawString>Chikara Hashimoto, Kentaro Torisawa, Julien Kloetzer, Motoki Sano, Istv´an Varga, Jong-Hoon Oh, and Yutaka Kidawara. 2014. Toward future scenario generation: Extracting event causality exploiting semantic relation, context, and association features. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 987–997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuta Hayashibe</author>
<author>Mamoru Komachi</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese predicate argument structure analysis exploiting argument position and type.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>201--209</pages>
<contexts>
<context position="8038" citStr="Hayashibe et al., 2011" startWordPosition="1248" endWordPosition="1251">e-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related methods have been explored for</context>
</contexts>
<marker>Hayashibe, Komachi, Matsumoto, 2011</marker>
<rawString>Yuta Hayashibe, Mamoru Komachi, and Yuji Matsumoto. 2011. Japanese predicate argument structure analysis exploiting argument position and type. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 201–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Processing of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>50--57</pages>
<contexts>
<context position="21900" citStr="Hofmann, 1999" startWordPosition="3489" endWordPosition="3490">ally similar words tend to appear in similar contexts (Harris, 1954). By treating the syntactic dependency relations between words as ‘contexts,’ the clustering method defines a probabilistic model of noun-verb dependencies with hidden classes: ∑ p(n, (v, r)) = p(n|c)p((v, r)|c)p(c) c where n is a noun, v is a verb or noun on which n depends by grammatical relation r (post-positions in Japanese), and c is a hidden class. The dependency relation frequencies were obtained from a 600-million page web corpus, and model parameters p(n|c), p((v, r)|c) and p(c) were estimated using the EM algorithm (Hofmann, 1999). We clustered one million nouns into 500 discrete classes 4A bunsetsu-unit is a Japanese base phrase consisting of at least one content word optionally followed by functional words. by assigning noun n to class c when the model parameter p(c|n) &gt; 0 (0 = 0.2). 5 Experiment 1: pairwise subject sharing recognition We first empirically evaluate the performance of our pairwise subject sharing recognition for the DEP, ADJ and PNP types. 5.1 Experimental setting The training data for the subject sharing recognizer were generated from the NAIST Text Corpus 1.4 (Iida et al., 2007b), in which (zero) an</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Processing of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Massimo Poesio</author>
</authors>
<title>A cross-lingual ILP solution to zero anaphora resolution.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>804--813</pages>
<contexts>
<context position="4958" citStr="Iida and Poesio, 2011" startWordPosition="749" endWordPosition="752">large portion of zero anaphora can be regarded as subject sharing relations (e.g., 39% of the intra-sentential zero anaphora in the NAIST Text Corpus (Iida et al., 2007b) are such cases). Hence, just by combining our subject zero anaphora method with an existing general anaphora resolution method that covers other types of anaphora, significant improvement of accuracy over all types of anaphora might be achieved. This paper empirically shows that this is actually the case through a series of experiments in which we combine our method with an existing ILP-based zero anaphora resolution method (Iida and Poesio, 2011). Our subject zero anaphora resolution method constructs a subject shared predicate network (SSPN), which is a network of predicates in which subject sharing predicates are linked, from the results of our accurate pairwise subject sharing recognizer, which detects the predicate pairs that share a subject. Zero anaphora resolution is done by propagating the realized subject of a predicate to the subject zero anaphor of other predicates in the SSPN. An important point here is that SSPN was introduced to solve the issue related to our pairwise subject sharing recognizer. Our recognizer is applied</context>
<context position="8061" citStr="Iida and Poesio, 2011" startWordPosition="1252" endWordPosition="1255">chine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related methods have been explored for pronominal anaphora (Y</context>
<context position="10692" citStr="Iida and Poesio, 2011" startWordPosition="1671" endWordPosition="1675">haring recognition. Step 3 For each predicate in the set of the subject shared predicates in the SSPN, a subject is detected by our subject detector, if one exists. Step 1: Pairwise subject sharing recognition Step 2: Subject shared predicate network (SSPN) construction Figure 2: Procedure of our zero anaphora resolution method Step 4 If a subject is detected, it is propagated to the empty subject position of each predicate in the subject shared predicates in the SSPN. Step 5 For resolving the potential zero anaphora that were not resolved until Step 4, we apply the existing ILP-based method (Iida and Poesio, 2011). We define subject sharing relations as follows. Two predicates have a subject sharing relation if and only if they share the same subject that is referred to by (zero) anaphora or coreference. Note that the shared subject does not need to be realized in the text; it can appear as inter-sentential zero anaphora or exophora. In Step 1, the pairwise subject sharing relations between two predicates are recognized, but recognizing the relations between any two predicates in a sentence remains difficult. We thus focus on some typical types of predicate pairs. The details of the predicate pair type</context>
<context position="14678" citStr="Iida and Poesio, 2011" startWordPosition="2334" endWordPosition="2337">ve clause and a noun modified by the clause is the semantic subject of the predicate, the noun is not regarded as subject by our subject detector. 3The subject sharing recognizer is likely to regard two predicates, each of which has its own subject, as non-subject sharing predicate pairs, but it is still logically possible that they are judged as subject sharing predicate pairs hence as a part of an SSPN. Figure 3: Example of DEP type subject arguments were omitted as zero anaphors. To resolve zero anaphora in these cases, we apply a state-of-the-art ILP-based zero anaphora resolution method (Iida and Poesio, 2011) in Step 5. This method determines zero anaphor and its antecedent by joint inference using the results of subject detection, zero anaphor detection and intraand inter-sentential antecedent identification. In the original method by Iida and Poesio (2011), the inter-sentential zero anaphora was resolved, but in this work we focus on intra-sentential zero anaphora. To adapt their method for our problem setting, we simply removed the inter-sentential antecedent identification model from their method. 4 Pairwise subject sharing recognition A key component in our zero anaphora resolution method is </context>
<context position="25133" citStr="Iida and Poesio, 2011" startWordPosition="3992" endWordPosition="3995">arser, J.DepP5 (Yoshinaga and Kitsuregawa, 2009). We obtained 49,313 predicate pairs for the DEP type, 86,728 for the ADJ type, and 27,117 for the PNP types. The numbers of positive instances of DEP, ADJ and PNP types are 9,524, 13,104, and 2,363 respectively. To evaluate the subject sharing recognition, we conducted 5-fold cross-validation using these predicate pairs and measured the performance using recall, precision and F-score. Note that we also evaluated a baseline method that recognizes subject sharing relations using the results of the state-of-the-art zero anaphora resolution method (Iida and Poesio, 2011) and the subject detector at Step 3 in Section 3. 5.2 Results: subject sharing recognition We measured the performances of the baseline and our subject sharing recognition method using recall, precision and F-score for each of the three types of subject sharing relations, which are shown in Table 2. The results demonstrate that all of the proposed classifiers solved the problems with high precision. In particular, for each type, the classifier using a polynomial kernel achieved more than 5http://www.tkl.iis.u-tokyo.ac.jp/˜ynaga/jdepp/ 70% precision. We thus used the classifiers with a polynomi</context>
<context position="30632" citStr="Iida and Poesio (2011)" startWordPosition="4897" endWordPosition="4900">chieved when we used all types of relations, i.e., in the case of DEP+ADJ+PNP with SSPNs. 7 Experiment 3: intra-sentential subject zero anaphora resolution Finally, we evaluate the performance of intrasentential subject zero anaphora resolution. In the previous section, we evaluated just a part of our method, i.e., from Step 1 to Step 4 presented in Section 3. In this section, we evaluate the whole method, i.e., from Step 1 to Step 5, against 18,324 subject zero anaphors, which are all subject zero anaphors annotated in our modified version of the NAIST Text Corpus. As a baseline, we employed Iida and Poesio (2011)’s method that was tuned for intra-sentential zero anaphora resolution. The baseline method solves the problems by applying only Step 5 in Section 3 to all the predicates. Our results in Table 4 show that all the methods using either each type or a combination of the three types significantly outperformed the baseline6. The best performing method was DEP+PNP, which achieved 0.380 in F-score, which is 3.6% 6The significance was tested using McNemar’s testing (P &lt; 0.01). 2186 Recall Precision F-score Baseline (Step 5) 0.345 0.344 0.344 +DEP with SSPN 0.388 0.363 0.375 +ADJ with SSPN 0.374 0.347 </context>
</contexts>
<marker>Iida, Poesio, 2011</marker>
<rawString>Ryu Iida and Massimo Poesio. 2011. A cross-lingual ILP solution to zero anaphora resolution. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 804–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Zero-anaphora resolution by learning rich syntactic pattern features.</title>
<date>2007</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>6</volume>
<contexts>
<context position="2098" citStr="Iida et al., 2007" startWordPosition="311" endWordPosition="314">n, pronouns are often unrealized in text. For example, the subject of nomu (take) is omitted in example (1). (1) Tomi-wa infuruenza-ni natta-node , Tom-TOP flu-IOBJ had-since punc (ϕi-ga) kusuri-o non-da . hei-SUBJ medicine-OBJ took period Since Tomi had the flu, (hei) took medicine. Such unrealized pronouns are regarded as zero anaphors, which are indicated using ϕ in literature, like ϕi-ga in example (1). Zero anaphor refers to its antecedent somewhere. This phenomenon of the reference is called zero anaphora. In Japanese, about 60% of subjects appear as zero anaphors in newspaper articles (Iida et al., 2007b), and thus zero anaphora resolution is an essential task for developing highly accurate machine translation and information extraction systems. In this paper, we propose a novel method of resolving intra-sentential zero anaphora, in which a subject zero anaphor refers to its antecedent inside a single sentence. This work does not address inter-sentential zero anaphora, in which a zero anaphor in a sentence refers to its antecedent in another sentence. The novelty of our method is in the use of subject sharing relations, which are relations between two predicates that share a subject by (zero</context>
<context position="4504" citStr="Iida et al., 2007" startWordPosition="679" endWordPosition="682">ccuracy than that of the straightforward method. This suggests that just propagating the realized subject of a predicate to the subject zero anaphor of other predicates through recognized subject sharing relations (e.g., propagating subject government of advance to the subject positions of plan and dispatch in Figure 1) might lead to a higher accuracy in zero anaphora resolution than the existing zero anaphora resolution methods. In addition, a large portion of zero anaphora can be regarded as subject sharing relations (e.g., 39% of the intra-sentential zero anaphora in the NAIST Text Corpus (Iida et al., 2007b) are such cases). Hence, just by combining our subject zero anaphora method with an existing general anaphora resolution method that covers other types of anaphora, significant improvement of accuracy over all types of anaphora might be achieved. This paper empirically shows that this is actually the case through a series of experiments in which we combine our method with an existing ILP-based zero anaphora resolution method (Iida and Poesio, 2011). Our subject zero anaphora resolution method constructs a subject shared predicate network (SSPN), which is a network of predicates in which subj</context>
<context position="7816" citStr="Iida et al., 2007" startWordPosition="1213" endWordPosition="1216">Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) reveale</context>
<context position="22478" citStr="Iida et al., 2007" startWordPosition="3585" endWordPosition="3588"> using the EM algorithm (Hofmann, 1999). We clustered one million nouns into 500 discrete classes 4A bunsetsu-unit is a Japanese base phrase consisting of at least one content word optionally followed by functional words. by assigning noun n to class c when the model parameter p(c|n) &gt; 0 (0 = 0.2). 5 Experiment 1: pairwise subject sharing recognition We first empirically evaluate the performance of our pairwise subject sharing recognition for the DEP, ADJ and PNP types. 5.1 Experimental setting The training data for the subject sharing recognizer were generated from the NAIST Text Corpus 1.4 (Iida et al., 2007b), in which (zero) anaphora, coreference and subjects were manually annotated. We automatically extracted pairs of predicates from the corpus. Since the original NAIST Text Corpus has a wide variety of annotation noise, we cleaned it up by the following strategy. According to the annotation scheme in the NAIST Text Corpus, predicate-argument relations were annotated for the ‘bare predicates’ even if the predicates appear in passive or causative sentences. In such cases, the annotation was difficult and caused inconsistencies because the annotators needed to imagine the predicate-argument rela</context>
</contexts>
<marker>Iida, Inui, Matsumoto, 2007</marker>
<rawString>Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2007a. Zero-anaphora resolution by learning rich syntactic pattern features. ACM Transactions on Asian Language Information Processing, Volume 6. Issue 4, Article 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Mamoru Komachi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Annotating a Japanese text corpus with predicate-argument and coreference relations.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop: ‘Linguistic Annotation Workshop’,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="2098" citStr="Iida et al., 2007" startWordPosition="311" endWordPosition="314">n, pronouns are often unrealized in text. For example, the subject of nomu (take) is omitted in example (1). (1) Tomi-wa infuruenza-ni natta-node , Tom-TOP flu-IOBJ had-since punc (ϕi-ga) kusuri-o non-da . hei-SUBJ medicine-OBJ took period Since Tomi had the flu, (hei) took medicine. Such unrealized pronouns are regarded as zero anaphors, which are indicated using ϕ in literature, like ϕi-ga in example (1). Zero anaphor refers to its antecedent somewhere. This phenomenon of the reference is called zero anaphora. In Japanese, about 60% of subjects appear as zero anaphors in newspaper articles (Iida et al., 2007b), and thus zero anaphora resolution is an essential task for developing highly accurate machine translation and information extraction systems. In this paper, we propose a novel method of resolving intra-sentential zero anaphora, in which a subject zero anaphor refers to its antecedent inside a single sentence. This work does not address inter-sentential zero anaphora, in which a zero anaphor in a sentence refers to its antecedent in another sentence. The novelty of our method is in the use of subject sharing relations, which are relations between two predicates that share a subject by (zero</context>
<context position="4504" citStr="Iida et al., 2007" startWordPosition="679" endWordPosition="682">ccuracy than that of the straightforward method. This suggests that just propagating the realized subject of a predicate to the subject zero anaphor of other predicates through recognized subject sharing relations (e.g., propagating subject government of advance to the subject positions of plan and dispatch in Figure 1) might lead to a higher accuracy in zero anaphora resolution than the existing zero anaphora resolution methods. In addition, a large portion of zero anaphora can be regarded as subject sharing relations (e.g., 39% of the intra-sentential zero anaphora in the NAIST Text Corpus (Iida et al., 2007b) are such cases). Hence, just by combining our subject zero anaphora method with an existing general anaphora resolution method that covers other types of anaphora, significant improvement of accuracy over all types of anaphora might be achieved. This paper empirically shows that this is actually the case through a series of experiments in which we combine our method with an existing ILP-based zero anaphora resolution method (Iida and Poesio, 2011). Our subject zero anaphora resolution method constructs a subject shared predicate network (SSPN), which is a network of predicates in which subj</context>
<context position="7816" citStr="Iida et al., 2007" startWordPosition="1213" endWordPosition="1216">Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) reveale</context>
<context position="22478" citStr="Iida et al., 2007" startWordPosition="3585" endWordPosition="3588"> using the EM algorithm (Hofmann, 1999). We clustered one million nouns into 500 discrete classes 4A bunsetsu-unit is a Japanese base phrase consisting of at least one content word optionally followed by functional words. by assigning noun n to class c when the model parameter p(c|n) &gt; 0 (0 = 0.2). 5 Experiment 1: pairwise subject sharing recognition We first empirically evaluate the performance of our pairwise subject sharing recognition for the DEP, ADJ and PNP types. 5.1 Experimental setting The training data for the subject sharing recognizer were generated from the NAIST Text Corpus 1.4 (Iida et al., 2007b), in which (zero) anaphora, coreference and subjects were manually annotated. We automatically extracted pairs of predicates from the corpus. Since the original NAIST Text Corpus has a wide variety of annotation noise, we cleaned it up by the following strategy. According to the annotation scheme in the NAIST Text Corpus, predicate-argument relations were annotated for the ‘bare predicates’ even if the predicates appear in passive or causative sentences. In such cases, the annotation was difficult and caused inconsistencies because the annotators needed to imagine the predicate-argument rela</context>
</contexts>
<marker>Iida, Komachi, Inui, Matsumoto, 2007</marker>
<rawString>Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Matsumoto. 2007b. Annotating a Japanese text corpus with predicate-argument and coreference relations. In Proceedings of the ACL Workshop: ‘Linguistic Annotation Workshop’, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Imamura</author>
<author>Kuniko Saito</author>
<author>Tomoko Izumi</author>
</authors>
<title>Discriminative approach to predicateargument structure analysis with zero-anaphora resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>85--88</pages>
<marker>Imamura, Saito, Izumi, 2009</marker>
<rawString>Kenji Imamura, Kuniko Saito, and Tomoko Izumi. 2009. Discriminative approach to predicateargument structure analysis with zero-anaphora resolution. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 85–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Tsutomu Hirao</author>
</authors>
<title>Japanese zero pronoun resolution based on ranking rules and machine learning.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>184--191</pages>
<contexts>
<context position="7797" citStr="Isozaki and Hirao, 2003" startWordPosition="1208" endWordPosition="1212">kumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et</context>
</contexts>
<marker>Isozaki, Hirao, 2003</marker>
<rawString>Hideki Isozaki and Tsutomu Hirao. 2003. Japanese zero pronoun resolution based on ranking rules and machine learning. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, pages 184–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megumi Kameyama</author>
</authors>
<title>A property-sharing constraint in centering.</title>
<date>1986</date>
<booktitle>In Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>200--206</pages>
<contexts>
<context position="7150" citStr="Kameyama, 1986" startWordPosition="1112" endWordPosition="1113">sharing recognition for the three types in Section 4. We evaluate how effectively our method recognizes subject sharing relations for these types in Section 5. After that, we investigate the impact of explicitly introducing SSPNs in Section 6 and compare our zero anaphora resolution method with a state-of-the-art ILP-based method on the task of intra-sentential subject zero anaphora resolution in Section 7. Finally, in Section 8 we summarize this work and discuss future directions. 2 Related work Traditional approaches to zero anaphora resolution are based on manually created heuristic rules (Kameyama, 1986; Walker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japan</context>
</contexts>
<marker>Kameyama, 1986</marker>
<rawString>Megumi Kameyama. 1986. A property-sharing constraint in centering. In Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics, pages 200–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Inducing gazetteers for named entity recognition by large-scale clustering of dependency relations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>407--415</pages>
<contexts>
<context position="20667" citStr="Kazama and Torisawa (2008)" startWordPosition="3296" endWordPosition="3299">edicates in predicate pairs. np is the noun phrase between pi and pj. bi (bj) stands for the bunsetsu-unity including pi (pj). The features marked with * are only used for PNP type. Table 1: Features of subject sharing recognition Name Description PoSi (PoSj) PoS of pi (pj) lemmai (lemmaj) func wi (func wj) casei (casej) btw case lemma of pi (pj) function words following pi (pj) case marker of arguments of pi (pj) case marker of arguments that appeared between pi and pj NpPoS* Np lemma* PoS of np lemma of np function words following np case marker of dependents of np noun class of np based on Kazama and Torisawa (2008) func wnp* casenp* n class* (6) seifui-wa (ϕi-ga) sono isetsu-o government-TOP iti-SUBJ the relocation-OBJ mitomeru koto-o kime-ta . admit COMP-OBJ decide-PAST period The governmenti decided that (iti) admits the relocation. (7) sono fune-wa (ϕi-ga) hayaku the ship-TOP iti-SUBJ fast hashiru nouryoku-o motteiru . run ability-OBJ have period The shipi has an ability that (iti) runs fast. To robustly capture this characteristic, we use as features the discrete classes created by the noun clustering algorithm proposed by Kazama and Torisawa (2008). It follows the distributional hypothesis, which s</context>
</contexts>
<marker>Kazama, Torisawa, 2008</marker>
<rawString>Jun’ichi Kazama and Kentaro Torisawa. 2008. Inducing gazetteers for named entity recognition by large-scale clustering of dependency relations. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 407–415.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiromi Nakaiwa</author>
<author>Satoshi Shirai</author>
</authors>
<title>Anaphora resolution of Japanese zero pronouns with deictic reference.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>812--817</pages>
<contexts>
<context position="7224" citStr="Nakaiwa and Shirai, 1996" startWordPosition="1123" endWordPosition="1126">te how effectively our method recognizes subject sharing relations for these types in Section 5. After that, we investigate the impact of explicitly introducing SSPNs in Section 6 and compare our zero anaphora resolution method with a state-of-the-art ILP-based method on the task of intra-sentential subject zero anaphora resolution in Section 7. Finally, in Section 8 we summarize this work and discuss future directions. 2 Related work Traditional approaches to zero anaphora resolution are based on manually created heuristic rules (Kameyama, 1986; Walker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira</context>
</contexts>
<marker>Nakaiwa, Shirai, 1996</marker>
<rawString>Hiromi Nakaiwa and Satoshi Shirai. 1996. Anaphora resolution of Japanese zero pronouns with deictic reference. In Proceedings of the 16th International Conference on Computational Linguistics, pages 812–817.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manabu Okumura</author>
<author>Kouji Tamura</author>
</authors>
<title>Zero pronoun resolution in Japanese discourse based on Centering Theory.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>871--876</pages>
<contexts>
<context position="7197" citStr="Okumura and Tamura, 1996" startWordPosition="1118" endWordPosition="1122">es in Section 4. We evaluate how effectively our method recognizes subject sharing relations for these types in Section 5. After that, we investigate the impact of explicitly introducing SSPNs in Section 6 and compare our zero anaphora resolution method with a state-of-the-art ILP-based method on the task of intra-sentential subject zero anaphora resolution in Section 7. Finally, in Section 8 we summarize this work and discuss future directions. 2 Related work Traditional approaches to zero anaphora resolution are based on manually created heuristic rules (Kameyama, 1986; Walker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003</context>
</contexts>
<marker>Okumura, Tamura, 1996</marker>
<rawString>Manabu Okumura and Kouji Tamura. 1996. Zero pronoun resolution in Japanese discourse based on Centering Theory. In Proceedings of the 16th International Conference on Computational Linguistics, pages 871–876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Motoki Sano</author>
<author>Kentaro Torisawa</author>
<author>Julien Kloetzer</author>
<author>Chikara Hashimoto</author>
<author>Istv´an Varga</author>
<author>Jong-Hoon Oh</author>
</authors>
<title>Million-scale derivation of semantic relations from a manually constructed predicate taxonomy.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics,</booktitle>
<pages>1423--1434</pages>
<marker>Sano, Torisawa, Kloetzer, Hashimoto, Varga, Oh, 2014</marker>
<rawString>Motoki Sano, Kentaro Torisawa, Julien Kloetzer, Chikara Hashimoto, Istv´an Varga, and Jong-Hoon Oh. 2014. Million-scale derivation of semantic relations from a manually constructed predicate taxonomy. In Proceedings of the 25th International Conference on Computational Linguistics, pages 1423– 1434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryohei Sasano</author>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>A fully-lexicalized probabilistic model for Japanese zero anaphora resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>769--776</pages>
<contexts>
<context position="7858" citStr="Sasano et al., 2008" startWordPosition="1221" endWordPosition="1224">nly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overal</context>
</contexts>
<marker>Sasano, Kawahara, Kurohashi, 2008</marker>
<rawString>Ryohei Sasano, Daisuke Kawahara, and Sadao Kurohashi. 2008. A fully-lexicalized probabilistic model for Japanese zero anaphora resolution. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 769–776.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryohei Sasano</author>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>The effect of corpus size on case frame acquisition for discourse analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>521--529</pages>
<contexts>
<context position="7879" citStr="Sasano et al., 2009" startWordPosition="1225" endWordPosition="1228">rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero</context>
</contexts>
<marker>Sasano, Kawahara, Kurohashi, 2009</marker>
<rawString>Ryohei Sasano, Daisuke Kawahara, and Sadao Kurohashi. 2009. The effect of corpus size on case frame acquisition for discourse analysis. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 521–529.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazuhiro Seki</author>
<author>Atsushi Fujii</author>
<author>Tetsuya Ishikawa</author>
</authors>
<title>A probabilistic method for analyzing Japanese anaphora integrating zero pronoun detection and resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>911--917</pages>
<contexts>
<context position="7772" citStr="Seki et al., 2002" startWordPosition="1204" endWordPosition="1207">ker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesi</context>
</contexts>
<marker>Seki, Fujii, Ishikawa, 2002</marker>
<rawString>Kazuhiro Seki, Atsushi Fujii, and Tetsuya Ishikawa. 2002. A probabilistic method for analyzing Japanese anaphora integrating zero pronoun detection and resolution. In Proceedings of the 19th International Conference on Computational Linguistics, pages 911–917.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hirotoshi Taira</author>
<author>Sanae Fujita</author>
<author>Masaaki Nagata</author>
</authors>
<title>A Japanese predicate argument structure analysis using decision lists.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--532</pages>
<contexts>
<context position="7837" citStr="Taira et al., 2008" startWordPosition="1217" endWordPosition="1220">1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inferenc</context>
</contexts>
<marker>Taira, Fujita, Nagata, 2008</marker>
<rawString>Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata. 2008. A Japanese predicate argument structure analysis using decision lists. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 523–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory. Adaptive and Learning Systems for Signal Processing, Communications, and Control.</title>
<date>1998</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="12527" citStr="Vapnik, 1998" startWordPosition="1980" endWordPosition="1981">olution 2181 if a predicate with a subject zero anaphor does not have any direct subject sharing relation with a predicate with a subject, like predicates susumeru (advance) and hakensuru (dispatch) in Figure 1. By traversing the paths of the subject sharing relations in the SSPN, such predicates can be connected to successfully propagate the subject. The effect of introducing SSPNs is empirically evaluated in Section 6. For use in Step 3, we create a subject detector, which judges whether an argument to a predicate is its subject using SVMlight 1, an implementation of Support Vector Machine (Vapnik, 1998), with a polynomial kernel of 2nd degree. The training instances of the subject detector are extracted from the predicate-argument relations2 in the NAIST Text Corpus. The numbers of positive and negative instances are 35,304 and 104,250 respectively. As features, we used the morpho-syntactic information about the lemmas of the predicate and its argument and the functional words following the predicate and its argument. The results of subject detection with 5-fold cross-validation demonstrate that our subject detector accurately detects subjects with performances of 0.949 in recall, 0.855 in p</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. Adaptive and Learning Systems for Signal Processing, Communications, and Control. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Sharon Cote</author>
<author>Masayo Iida</author>
</authors>
<title>Japanese discourse and the process of centering.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="7171" citStr="Walker et al., 1994" startWordPosition="1114" endWordPosition="1117">ion for the three types in Section 4. We evaluate how effectively our method recognizes subject sharing relations for these types in Section 5. After that, we investigate the impact of explicitly introducing SSPNs in Section 6 and compare our zero anaphora resolution method with a state-of-the-art ILP-based method on the task of intra-sentential subject zero anaphora resolution in Section 7. Finally, in Section 8 we summarize this work and discuss future directions. 2 Related work Traditional approaches to zero anaphora resolution are based on manually created heuristic rules (Kameyama, 1986; Walker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 200</context>
</contexts>
<marker>Walker, Cote, Iida, 1994</marker>
<rawString>Marilyn Walker, Sharon Cote, and Masayo Iida. 1994. Japanese discourse and the process of centering. Computational Linguistics, 20(2):193–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yotaro Watanabe</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>A structured model for joint learning of argument roles and predicate senses.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>98--102</pages>
<contexts>
<context position="8014" citStr="Watanabe et al., 2010" startWordPosition="1244" endWordPosition="1247">s shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related method</context>
</contexts>
<marker>Watanabe, Asahara, Matsumoto, 2010</marker>
<rawString>Yotaro Watanabe, Masayuki Asahara, and Yuji Matsumoto. 2010. A structured model for joint learning of argument roles and predicate senses. In Proceedings of the ACL 2010 Conference Short Papers, pages 98–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>Improving pronoun resolution using statistics-based semantic compatibility information.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>165--172</pages>
<contexts>
<context position="8678" citStr="Yang et al., 2005" startWordPosition="1349" endWordPosition="1352">1; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related methods have been explored for pronominal anaphora (Yang et al., 2005) or coreference resolution (Bean and Riloff, 2004; Bansal and Klein, 2012). In these methods, the semantic compatibility between the contexts surrounding an anaphor and its antecedent (e.g., the compatibility of verbs kidnap and release given some arguments) was automatically extracted from raw texts in an unsupervised manner and used as features in a machine learning-based approach. However, because the automatically acquired semantic compatibility is not always true or applicable in the context of any pair of an anaphor and its antecedent, the effectiveness of the compatibility features migh</context>
</contexts>
<marker>Yang, Su, Tan, 2005</marker>
<rawString>Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005. Improving pronoun resolution using statistics-based semantic compatibility information. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 165–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsumasa Yoshikawa</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Jointly extracting Japanese predicate-argument relation with Markov logic.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>1125--1133</pages>
<contexts>
<context position="8085" citStr="Yoshikawa et al., 2011" startWordPosition="1256" endWordPosition="1259">roaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related methods have been explored for pronominal anaphora (Yang et al., 2005) or cor</context>
</contexts>
<marker>Yoshikawa, Asahara, Matsumoto, 2011</marker>
<rawString>Katsumasa Yoshikawa, Masayuki Asahara, and Yuji Matsumoto. 2011. Jointly extracting Japanese predicate-argument relation with Markov logic. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1125–1133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoki Yoshinaga</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Polynomial to linear: Efficient classification with conjunctive features.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1542--1551</pages>
<contexts>
<context position="24559" citStr="Yoshinaga and Kitsuregawa, 2009" startWordPosition="3899" endWordPosition="3903">t point is that in the NAIST Text Corpus, if the antecedent of a zero anaphor is not explicitly written in the corpus, it is simply annotated as ‘exophoric’, and the subject sharing relations between two predicates whose subject was annotated as exophoric cannot be captured. In contrast, in our cleaning procedure, the annotators additionally annotated such ‘exophoric’ subject sharing relations to take into account all subject sharing relations in the corpus. The predicates in the corpus and their dependency relations were detected based on the outputs of a Japanese dependency parser, J.DepP5 (Yoshinaga and Kitsuregawa, 2009). We obtained 49,313 predicate pairs for the DEP type, 86,728 for the ADJ type, and 27,117 for the PNP types. The numbers of positive instances of DEP, ADJ and PNP types are 9,524, 13,104, and 2,363 respectively. To evaluate the subject sharing recognition, we conducted 5-fold cross-validation using these predicate pairs and measured the performance using recall, precision and F-score. Note that we also evaluated a baseline method that recognizes subject sharing relations using the results of the state-of-the-art zero anaphora resolution method (Iida and Poesio, 2011) and the subject detector </context>
</contexts>
<marker>Yoshinaga, Kitsuregawa, 2009</marker>
<rawString>Naoki Yoshinaga and Masaru Kitsuregawa. 2009. Polynomial to linear: Efficient classification with conjunctive features. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1542–1551.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koichiro Yoshino</author>
<author>Shinsuke Mori</author>
<author>Tatsuya Kawahara</author>
</authors>
<title>Predicate argument structure analysis using partially annotated corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of the 6th International Joint Conference on Natural Language Processing,</booktitle>
<pages>957--961</pages>
<contexts>
<context position="8129" citStr="Yoshino et al., 2013" startWordPosition="1264" endWordPosition="1267">sily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recent works by Watanabe et al. (2010), Iida and Poesio (2011) and Yoshikawa et al. (2011) revealed that joint inference improves the overall performance of zero anaphora resolution. We employed one of these works as a baseline in Section 6. Concerning subject sharing recognition, related methods have been explored for pronominal anaphora (Yang et al., 2005) or coreference resolution (Bean and Riloff, 2004; </context>
</contexts>
<marker>Yoshino, Mori, Kawahara, 2013</marker>
<rawString>Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawahara. 2013. Predicate argument structure analysis using partially annotated corpora. In Proceedings of the 6th International Joint Conference on Natural Language Processing, pages 957–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shanheng Zhao</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Identification and resolution of Chinese zero pronouns: A machine learning approach.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>541--550</pages>
<contexts>
<context position="7723" citStr="Zhao and Ng, 2007" startWordPosition="1195" endWordPosition="1198">ally created heuristic rules (Kameyama, 1986; Walker et al., 1994; Okumura and Tamura, 1996; Nakaiwa and Shirai, 1996), which are mainly motivated by the rules and preferences introduced in Centering Theory (Grosz et al., 1995). However, the research trend of zero anaphora resolution has shifted from such rule-based approaches to machine learningbased approaches because in machine learning we can easily integrate many different types of information, such as morpho-syntactic, semantic and discourse-related information. Researchers have developed methods of zero anaphora resolution for Chinese (Zhao and Ng, 2007; Chen and Ng, 2013), Japanese (Seki et al., 2002; Isozaki and Hirao, 2003; Iida et al., 2007a; Taira et al., 2008; Sasano et al., 2008; Sasano et al., 2009; Imamura hakensuru (dispatch) hisaichi (disaster site) keikakusi (plan) i=obj subject sharing 2180 et al., 2009; Watanabe et al., 2010; Hayashibe et al., 2011; Iida and Poesio, 2011; Yoshikawa et al., 2011; Hangyo et al., 2013; Yoshino et al., 2013) and Italian (Iida and Poesio, 2011). One critical issue in zero anaphora resolution is optimizing the outputs of sub-problems (e.g., zero anaphor detection and antecedent identification). Recen</context>
</contexts>
<marker>Zhao, Ng, 2007</marker>
<rawString>Shanheng Zhao and Hwee Tou Ng. 2007. Identification and resolution of Chinese zero pronouns: A machine learning approach. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 541–550.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>