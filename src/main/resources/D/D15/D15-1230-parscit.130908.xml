<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.234033">
<title confidence="0.996992">
Discourse Planning with an N-gram Model of Relations
</title>
<author confidence="0.99812">
Or Biran Kathleen McKeown
</author>
<affiliation confidence="0.999937">
Columbia University Columbia University
</affiliation>
<email confidence="0.997027">
orb@cs.columbia.edu kathy@cs.columbia.edu
</email>
<sectionHeader confidence="0.99736" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999223125">
While it has been established that transi-
tions between discourse relations are im-
portant for coherence, such information
has not so far been used to aid in lan-
guage generation. We introduce an ap-
proach to discourse planning for concept-
to-text generation systems which simul-
taneously determines the order of mes-
sages and the discourse relations between
them. This approach makes it straightfor-
ward to use statistical transition models,
such as n-gram models of discourse re-
lations learned from an annotated corpus.
We show that using such a model signif-
icantly improves the quality of the gener-
ated text as judged by humans.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999960545454546">
Discourse planning is a subtask of Natural Lan-
guage Generation (NLG), concerned with deter-
mining the ordering of messages in a document
and the discourse relations that hold among them
(Reiter and Dale, 2000). Early approaches to dis-
course planning used manually written rules, often
based on schemas (McKeown, 1985) or on Rhetor-
ical Structure Theory (RST) (Mann and Thomp-
son, 1987; Hovy, 1993; Power, 2000). In the
past decade, various statistical approaches have
emerged (Duboue and McKeown, 2001; Dimitro-
manolaki and Androutsopoulos, 2003; Soricut and
Marcu, 2006; Konstas and Lapata, 2013). Other
relevant statistical approaches to content ordering
can also be found in the summarization literature
(Barzilay et al., 2001; Lapata, 2003; Bollegala
et al., 2005). These approaches overwhelmingly
focus on determining the best order of messages
using semantic conent, while discourse relations
are in most cases either determined by manually-
written derivation rules or completely ignored.
Meanwhile, researchers working on discourse
relation disambiguation have observed that the se-
quence of discourse relations itself, independently
of content, helps in disambiguating adjacent re-
lations (Wellner et al., 2006; Pitler et al., 2008).
Sequential discourse information has been used
successfully in discourse parsing (Ghosh et al.,
2011; Feng and Hirst, 2014), and discourse struc-
ture was shown to be as important for text co-
herence as entity-based content structure (Lin et
al., 2011; Feng et al., 2014). Surprisingly, so
far, discourse sequential information from exist-
ing discourse-annotated corpora, such as the Penn
Discourse Treebank (PDTB) (Prasad et al., 2008)
has not been used in generation.
In this paper, we present an NLG framework
that generates texts from existing semantic web
ontologies. We use an n-gram model of discourse
relations to perform discourse planning for these
stories. Through a crowd-sourced human evalua-
tion, we show that the ordering of our documents
and the choice of discourse relations is signifi-
cantly better when using this model.
</bodyText>
<sectionHeader confidence="0.995302" genericHeader="method">
2 Generation Framework
</sectionHeader>
<bodyText confidence="0.99996725">
In concept-to-text generation pipelines, discourse
planning typically occurs after the content selec-
tion stage. The input, therefore, is an unordered
set of messages that are not yet realized: instead
of being represented as text, the messages have a
structured semantic representation.
In this paper, we generate comparison stories,
describing and comparing two similar entities,
from an RDF ontology. The RDF semantic rep-
resentation is commonly used in semantic web re-
sources and free ontologies. An RDF message
(called a triple) has three parts: a subject, a pred-
icate and an object. For each story, we consider
any triple whose subject is one of the participating
entities as a potential message to be generated. We
do only minimal processing on these messages:
</bodyText>
<page confidence="0.906373">
1973
</page>
<note confidence="0.654694">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1973–1977,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999988363636364">
where two triples have the same subject and pred-
icate but different objects, we merge them into a
single message with multiple objects; and where
two triples have the same subject and object but
different predicates, we merge them into a single
message with multiple predicates.
Next, we build the set of potential discourse re-
lations between all messages. We use the PDTB
class-level relations, of which there are four: ex-
pansion, comparison, contingency and temporal.
Each is an abstraction of a family of more specific
relations, such as cause, concession, etc. We do
not differentiate between explicit and implicit re-
lations, and treat entrel as a type of expansion.
Potential discourse relations are implied in the
semantics of the triples: messages that contain the
same predicate and object may have an expansion
relation among them (e.g. “John has a ball. Mary
also has a ball”). Messages that contain the same
predicate but different subjects and objects may
have a comparison relation (e.g. “John likes ap-
ples but Mary likes oranges”).
Specific predicate pairs will also have specific
potential relations among them - for example,
“birth place” and “residence” have a temporal re-
lation (when applied to the same subject). The
same is true for contingency relations (e.g., “city”
and “country” for the same subject - if the sub-
ject is in a city, it implies which country it is in).
We manually annotated the 59 predicate pairs that
had potential temporal and contingency relations,
as well as 8 pairs with special potential compari-
son relations (e.g., “birth place” and “residence” if
the subject is the same but the object is not).
Once the potential relations are identified, we
have a directed multigraph where each vertex is
a message and each edge is a potential relation.
There can be multiple edges between any two ver-
tices, since messages may have more than one po-
tential relation among them.
Once the graph is ready, we perform content se-
lection. Given a desired number of messages to
generate, we choose the set of messages that max-
imizes the number of edges in the resulting sub-
graph (thus ensuring that the selected messages
are discourse-coherent). If there are multiple such
sets, we choose one at random.
The task we are focused on in this paper is dis-
course planning, which in our formulation is the
task of finding a Hamiltonian path through the se-
lected subgraph, thus simultaneously selecting the
order of the messages (nodes) as well as the rela-
tions (edges) that connect them. Our approach for
choosing the best path is discussed in the next sec-
tion. For the remainder of this section, we describe
our simple implementations of the next stages of
generation: sentence planning and realization.
For each of the four discourse relations we use,
we selected a few explicit connectives from the
PDTB that are often used to convey them. We
specifically chose connectives that apply to the en-
tire range of class-level relations (e.g., for compar-
ison we chose “while” - since it applies to both
contrast and concession in the PDTB, but not “in
contrast” which applies only to the former). We
also chose only those connectives which have the
structure [ARG1 connective ARG2] or [ARG1.
connective, ARG2]. During realization, we arbi-
trarily choose a connective to realize the relation.
Since the ordering and relations between mes-
sages is determined by the discourse plan, sen-
tence planning falls naturally out of it: sentence
breaks occur where the connective pattern creates
them, or where there is no relation between adja-
cent messages.
To realize the messages themselves, we follow
a single pattern: “the [predicate(s)] of [subject]
(is/are) [object(s)]”. Simple rules are used to plu-
ralize the predicate when there are multiple objects
and to create lists of multiples objects or predi-
cates where needed.
These basic solutions for the various stages of
NLG produce texts that are rich enough to be ac-
ceptable for human readers, but which have rel-
atively little variation in grammatical and lexical
quality. This crucial combination allows us to per-
form a human study to specifically evaluate the
discourse planning component.
</bodyText>
<sectionHeader confidence="0.988924" genericHeader="method">
3 Discourse Planning
</sectionHeader>
<bodyText confidence="0.99988025">
As explained in the previous section, we formu-
late the discourse planning task as finding a path
through a multigraph of potential relations be-
tween messages. One major component of what
makes a good path is the sequence of content:
some content is more central and should appear
earlier, for example; and some predicates and ob-
jects are semantically related and should appear
near one another. In this paper we focus on a com-
ponent that has so far been neglected in generation
- the sequence of discourse relations - while try-
ing to minimize the effect that content semantics
</bodyText>
<page confidence="0.984622">
1974
</page>
<bodyText confidence="0.999966461538461">
have on the evaluation (other than the semantics
implicit in the relations). In order to quantify the
likelihood of a sequence of relations, we build an
n-gram model from a discourse-annotated corpus.
An n-gram model measures the transitional
probabilities for sequences of the units that the n-
grams are composed of. In this case, the units are
discourse relations. The probability of a particu-
lar sequence of relations of length n + 1 given an
existing subsequence of length n is computed as
a fraction of the number of times it appears in the
corpus and the number of times the subsequence
appears in the corpus, i.e.
</bodyText>
<equation confidence="0.991635">
C(ri−n, ..., ri−1, ri)
P(ri|ri−n, ..., ri−1) = C(ri−n, ..., ri−1)
</equation>
<bodyText confidence="0.9977264">
Where C(s) is the number of times sequence s ap-
pears in the corpus. Using this model to generate
a discourse plan given a potential relation multi-
graph is a stochastic process: at each stage, we
choose the next relation edge out of the last cho-
sen message vertex (the first vertex is chosen at
random) based on the selected sequence of rela-
tion edges and the probabilities for the next rela-
tion in the model. Once a vertex is added to the
path edges leading to it can no longer be selected.
</bodyText>
<sectionHeader confidence="0.999458" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.997069652173913">
One method for evaluating a discourse plan in-
dependently of content is to produce pairs of
generated short text documents, each containing
the same content, but with different ordering and
discourse relations (as dictated by the discourse
plan). The only obvious way to decide which text
is better is to have human judges make that de-
cision. It is important to minimize the effects of
other qualities of the texts (differences in content,
word choice, grammatical style, etc.) as much as
possible, so that the judgement is based only on
the differences in order and discourse.
We used DBPedia (Auer et al., 2007) - an RDF
ontology extracted from Wikipedia - to generate
content. Each document generated was a compar-
ison story of two entities in a single category (i.e.,
the messages in the stories were selected, as de-
scribed in Section 2, from the set of triples where
one of the entities was the subject). In order to
experiment with different domains, we used four
different categories: Office Holder (i.e., a per-
son holding office such as a President or a Judge);
River; Television Show; and Military Unit. The
</bodyText>
<figureCaption confidence="0.997802">
Figure 1: Sample pair of comparison stories
</figureCaption>
<bodyText confidence="0.999923916666667">
entity pairs from each category were chosen at ran-
dom but were required to have at least 8 predicates
and 3 objects in common, so that they were some-
what semantically related.
To ensure that human judges can easily tell
the differences between the stories on a sentential
level, we limited the size of each story to 4 mes-
sages. For each pair of stories, everything but the
discourse plan (i.e. the content selection, the real-
ization of messages and the lexical choice of con-
nectives) was identical. Figure 1 shows an exam-
ple pair of stories from the Office Holder category.
</bodyText>
<subsectionHeader confidence="0.875533">
4.1 Experiments
</subsectionHeader>
<bodyText confidence="0.999032545454545">
We conducted two crowd sourced experiments on
the CrowdFlower platform. Each question con-
sisted of two short stories that are completely iden-
tical in content, but each generated with a different
discourse planner. The human judge was asked to
decide which of the stories has a better flow (or
whether they are equally good), and then to give
each of the stories a score from 1 to 5, paying spe-
cific attention to the ordering of the prepositions
and the relations between them. The stories were
presented in a random order and were not given
labels, to avoid bias. We generated 125 pairs of
stories from each category - a total of 500 - for
each experiment.
Each question was presented to three judges.
In each experiment, there was complete disagree-
ment among the three annotators in approximately
15% of the questions, and those were discarded.
In approximately 20% there was complete agree-
ment, and in the rest of the questions there were
two judges who agreed and one who disagreed.
We also computed inter-annotator agreement us-
ing Cohen’s Kappa for 217 pairs of judges who
The birth place of Allen J. Ellender is Montegut,
Louisiana, while the death place of Allen J. El-
lender is Maryland. The birth place of Robert E.
Quinn is Phoenix, Rhode Island. Subsequently, the
death place of Robert E. Quinn is Rhode Island.
The birth place of Allen J. Ellender is Montegut,
Louisiana. In comparison, the birth place of Robert
E. Quinn is Phoenix, Rhode Island. The death
place of Robert E. Quinn is Rhode Island, but the
death place of Allen J. Ellender is Maryland.
</bodyText>
<page confidence="0.982261">
1975
</page>
<table confidence="0.999817142857143">
Quality comparison Avg. score
Base Equal Pdtb Base Pdtb
Of. Holder 27.4% 30.2% 42.5% 3.67 3.76
TV Show 34.3% 25.7% 40% 3.79 3.8
Mil. Unit 32.3% 23.2% 44.4% 3.69 3.84
River 39.2% 23.5% 37.3% 3.71 3.72
Total 34% 25% 41% 3.72 3.78
</table>
<tableCaption confidence="0.8055605">
Table 1: Results for the comparison between the
PDTB n-gram model and the baseline
</tableCaption>
<table confidence="0.999896428571429">
Quality comparison Avg. score
Pdtb Equal Wiki Pdtb Wiki
Of. Holder 33.6% 14.5% 51.8% 3.51 3.65
TV Show 43.2% 8.1% 48.6% 3.62 3.65
Mil. Unit 40.4% 14.4% 45.2% 3.65 3.67
River 41.1% 11.2% 47.7% 3.68 3.7
Total 39.6% 12% 48.4% 3.61 3.67
</table>
<tableCaption confidence="0.967821">
Table 2: Results for the comparison between the
</tableCaption>
<bodyText confidence="0.994231052631579">
Wikipedia model and the PDTB model
both answered at least 10 of the same questions.
The average kappa value was 0.5, suggesting rea-
sonable agreement.
In the first experiment, we compared stories
generated by a planner using an n-gram model ex-
tracted from the PDTB with stories generated by
a baseline planner, where all edges have identical
probabilities. The results are shown in Table 1.
In the second experiment, we used a PDTB
shallow discourse parser we developed (Biran and
McKeown, 2015) to create a discourse-annotated
version of the English Wikipedia. We then com-
pared stories generated by a planner using an n-
gram model extracted from the parsed Wikipedia
corpus with those generated by a planner using the
PDTB model. The results are shown in Table 2.
The total results in both tables are statistically
significant (p &lt; 0.05).
</bodyText>
<subsectionHeader confidence="0.980523">
4.2 Discussion
</subsectionHeader>
<bodyText confidence="0.99999475">
The results in Table 1 show that the judges signif-
icantly preferred the stories created by the n-gram
model-based planner to those created by the base-
line planner, both in terms of the three-way deci-
sion and in terms of the numeric score. This is true
for the total set as well as every specific topic, ex-
cept for River. This may be because the predicates
in the River category are much more cohesive than
in other categories: virtually all predicates related
to rivers describe an aspect of the location of the
river. That fact may make it easier for a random
planner to produce a story that seems coherent.
Note, however, that while the judges preferred the
baseline story more often in the River questions,
the average score is higher for the model, which
suggests that when the baseline was better it was
only mildly so, while when the model was better
is was significantly so.
The results in Table 2 show that the Wikipedia-
based model produces better results than the
PDTB-based model. We hypothesize that it is for
two reasons. First, Wikipedia contains definitional
texts and is closer in style and content to the stories
we produce than the PDTB, which contains WSJ
articles. Temporal relations constitute about 10%
of both corpora, but contingency and comparison
relations each make up almost 20% of the PDTB,
while in Wikipedia they span only 10% and 12%
of the corpus, respectively, making the share of ex-
pansion relations much larger. Second, since the
PDTB is small, higher-order n-grams are sparsely
found, which can add noise to the model. The
Wikipedia corpus is significantly larger and does
not suffer from this problem.
The differences in average scores seen in the ex-
periments are relatively small. That is expected,
since we have eliminated the content coherence
factor, which is known to be significant. In addi-
tion, while judges were specifically asked to fo-
cus on the order of messages and relations be-
tween them, there is inevitably some noise due to
accidental lexical or syntactic mismatches, order-
ing that is awkward content-wise, and other side-
effects of the generation framework we employed.
</bodyText>
<sectionHeader confidence="0.987829" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999669473684211">
We introduced an approach to discourse planning
that relies on a potential discourse multigraph, al-
lowing for an n-gram model of relations to drive
the discourse plan and efficiently determine both
the ordering and the relations between messages.
We conducted two experiments, comparing sto-
ries generated with different discourse planners.
The first shows that an n-gram model-based plan-
ner significantly outperforms the random baseline.
The second suggests that using an n-gram model
derived from a corpus that is larger and closer
in style and content, though less accurately anno-
tated, can further improve results.
In future work, we intend to combine this
discourse-based view of coherence with a content-
based view to create a unified statistical discourse
planner. In addition, we will explore additional
stochastic models of discourse that look at other,
non-sequential collocational information.
</bodyText>
<page confidence="0.993823">
1976
</page>
<sectionHeader confidence="0.996174" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9989185">
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives.
2007. Dbpedia: a nucleus for a web of open data.
In Proceedings of the 6th international The seman-
tic web and 2nd Asian conference on Asian semantic
web conference, ISWC’07/ASWC’07, pages 722–
735, Berlin, Heidelberg. Springer-Verlag.
Regina Barzilay, Noemie Elhadad, and Kathleen R.
McKeown. 2001. Sentence ordering in multidocu-
ment summarization. In Proceedings of the First In-
ternational Conference on Human Language Tech-
nology Research, HLT ’01, pages 1–7, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Or Biran and Kathleen McKeown. 2015. Pdtb dis-
course parsing as a tagging task: The two taggers
approach. In Proceedings of the 16th Annual SIG-
dial Meeting on Discourse and Dialogue, SIGDIAL
2015, Prague, Czech Republic.
Danushka Bollegala, Naoaki Okazaki, and Mitsuru
Ishizuka. 2005. A machine learning approach
to sentence ordering for multidocument summa-
rization and its evaluation. In Natural Lan-
guage Processing–IJCNLP 2005, pages 624–635.
Springer.
Aggeliki Dimitromanolaki and Ion Androutsopoulos.
2003. Learning to order facts for discourse plan-
ning in natural language generation. arXiv preprint
cs/0306062.
Pablo A. Duboue and Kathleen R. McKeown. 2001.
Empirically estimating order constraints for content
planning in generation. In Proceedings of 39th An-
nual Meeting of the Association for Computational
Linguistics, pages 172–179, Toulouse, France, July.
Association for Computational Linguistics.
Vanessa Wei Feng and Graeme Hirst. 2014. A Linear-
Time Bottom-Up Discourse Parser with Constraints
and Post-Editing. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational
Linguistics, pages 511–521, Baltimore, Maryland,
June. Association for Computational Linguistics.
Vanessa Wei Feng, Ziheng Lin, Graeme Hirst, and Sin-
gapore Press Holdings. 2014. The impact of deep
hierarchical discourse structures in the evaluation of
text coherence. In Proceedings of the 25th Interna-
tional Conference on Computational Linguistics.
Sucheta Ghosh, Richard Johansson, Giuseppe Ric-
cardi, and Sara Tonelli. 2011. Shallow discourse
parsing with conditional random fields. In Proceed-
ings of 5th International Joint Conference on Natu-
ral Language Processing, pages 1071–1079.
Eduard H. Hovy. 1993. Automated discourse genera-
tion using discourse structure relations. Artif. Intell.,
63(1-2):341–385, October.
Ioannis Konstas and Mirella Lapata. 2013. Induc-
ing document plans for concept-to-text generation.
In Proceedings of the 2013 Conference on Em-
pirical Methods in Natural Language Processing,
pages 1503–1514, Seattle, Washington, USA, Oc-
tober. Association for Computational Linguistics.
Mirella Lapata. 2003. Probabilistic text structuring:
Experiments with sentence ordering. In Proceed-
ings of the 41st Annual Meeting on Association for
Computational Linguistics - Volume 1, ACL ’03,
pages 545–552, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011.
Automatically evaluating text coherence using dis-
course relations. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies-Volume
1, pages 997–1006. Association for Computational
Linguistics.
William C. Mann and Sandra A. Thompson. 1987.
Rhetorical Structure Theory: A theory of text orga-
nization. Technical Report ISI/RS-87-190, ISI.
Kathleen R. McKeown. 1985. Discourse strategies
for generating natural-language text. Artif. Intell.,
27(1):1–41, September.
Emily Pitler, Mridhula Raghupathy, Hena Mehta, Ani
Nenkova, Alan Lee, and Aravind K Joshi. 2008.
Easily identifiable discourse relations.
Richard Power. 2000. Planning texts by constraint
satisfaction. In Proceedings of the 18th Conference
on Computational Linguistics - Volume 2, COLING
’00, pages 642–648, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The penn discourse treebank 2.0. In
In Proceedings of LREC.
Ehud Reiter and Robert Dale. 2000. Building natu-
ral language generation systems, volume 33. Cam-
bridge university press.
Radu Soricut and Daniel Marcu. 2006. Discourse
generation using utility-trained coherence models.
In Proceedings of the COLING/ACL on Main Con-
ference Poster Sessions, COLING-ACL ’06, pages
803–810, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Ben Wellner, James Pustejovsky, Catherine Havasi,
Anna Rumshisky, and Roser Saur´ı. 2006. Clas-
sification of discourse coherence relations: An ex-
ploratory study using multiple knowledge sources.
In Proceedings of the 7th SIGdial Workshop on Dis-
course and Dialogue, SigDIAL ’06, pages 117–125,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.995695">
1977
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.954401">
<title confidence="0.999049">Discourse Planning with an N-gram Model of Relations</title>
<author confidence="0.999727">Or Biran Kathleen McKeown</author>
<affiliation confidence="0.999997">Columbia University Columbia University</affiliation>
<email confidence="0.999249">orb@cs.columbia.edukathy@cs.columbia.edu</email>
<abstract confidence="0.997394705882353">While it has been established that transitions between discourse relations are important for coherence, such information has not so far been used to aid in language generation. We introduce an approach to discourse planning for conceptto-text generation systems which simultaneously determines the order of messages and the discourse relations between them. This approach makes it straightforward to use statistical transition models, such as n-gram models of discourse relations learned from an annotated corpus. We show that using such a model significantly improves the quality of the generated text as judged by humans.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: a nucleus for a web of open data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC’07/ASWC’07,</booktitle>
<pages>722--735</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="10423" citStr="Auer et al., 2007" startWordPosition="1691" endWordPosition="1694">ation One method for evaluating a discourse plan independently of content is to produce pairs of generated short text documents, each containing the same content, but with different ordering and discourse relations (as dictated by the discourse plan). The only obvious way to decide which text is better is to have human judges make that decision. It is important to minimize the effects of other qualities of the texts (differences in content, word choice, grammatical style, etc.) as much as possible, so that the judgement is based only on the differences in order and discourse. We used DBPedia (Auer et al., 2007) - an RDF ontology extracted from Wikipedia - to generate content. Each document generated was a comparison story of two entities in a single category (i.e., the messages in the stories were selected, as described in Section 2, from the set of triples where one of the entities was the subject). In order to experiment with different domains, we used four different categories: Office Holder (i.e., a person holding office such as a President or a Judge); River; Television Show; and Military Unit. The Figure 1: Sample pair of comparison stories entity pairs from each category were chosen at random</context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: a nucleus for a web of open data. In Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC’07/ASWC’07, pages 722– 735, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Sentence ordering in multidocument summarization.</title>
<date>2001</date>
<booktitle>In Proceedings of the First International Conference on Human Language Technology Research, HLT ’01,</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1534" citStr="Barzilay et al., 2001" startWordPosition="231" endWordPosition="234">ering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2001</marker>
<rawString>Regina Barzilay, Noemie Elhadad, and Kathleen R. McKeown. 2001. Sentence ordering in multidocument summarization. In Proceedings of the First International Conference on Human Language Technology Research, HLT ’01, pages 1–7, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Or Biran</author>
<author>Kathleen McKeown</author>
</authors>
<title>Pdtb discourse parsing as a tagging task: The two taggers approach.</title>
<date>2015</date>
<booktitle>In Proceedings of the 16th Annual SIGdial Meeting on Discourse and Dialogue, SIGDIAL 2015,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="14215" citStr="Biran and McKeown, 2015" startWordPosition="2350" endWordPosition="2353"> 45.2% 3.65 3.67 River 41.1% 11.2% 47.7% 3.68 3.7 Total 39.6% 12% 48.4% 3.61 3.67 Table 2: Results for the comparison between the Wikipedia model and the PDTB model both answered at least 10 of the same questions. The average kappa value was 0.5, suggesting reasonable agreement. In the first experiment, we compared stories generated by a planner using an n-gram model extracted from the PDTB with stories generated by a baseline planner, where all edges have identical probabilities. The results are shown in Table 1. In the second experiment, we used a PDTB shallow discourse parser we developed (Biran and McKeown, 2015) to create a discourse-annotated version of the English Wikipedia. We then compared stories generated by a planner using an ngram model extracted from the parsed Wikipedia corpus with those generated by a planner using the PDTB model. The results are shown in Table 2. The total results in both tables are statistically significant (p &lt; 0.05). 4.2 Discussion The results in Table 1 show that the judges significantly preferred the stories created by the n-gram model-based planner to those created by the baseline planner, both in terms of the three-way decision and in terms of the numeric score. Th</context>
</contexts>
<marker>Biran, McKeown, 2015</marker>
<rawString>Or Biran and Kathleen McKeown. 2015. Pdtb discourse parsing as a tagging task: The two taggers approach. In Proceedings of the 16th Annual SIGdial Meeting on Discourse and Dialogue, SIGDIAL 2015, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danushka Bollegala</author>
<author>Naoaki Okazaki</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>A machine learning approach to sentence ordering for multidocument summarization and its evaluation.</title>
<date>2005</date>
<booktitle>In Natural Language Processing–IJCNLP</booktitle>
<pages>624--635</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1573" citStr="Bollegala et al., 2005" startWordPosition="237" endWordPosition="240">he discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Feng and Hirst, 2014), and </context>
</contexts>
<marker>Bollegala, Okazaki, Ishizuka, 2005</marker>
<rawString>Danushka Bollegala, Naoaki Okazaki, and Mitsuru Ishizuka. 2005. A machine learning approach to sentence ordering for multidocument summarization and its evaluation. In Natural Language Processing–IJCNLP 2005, pages 624–635. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aggeliki Dimitromanolaki</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>Learning to order facts for discourse planning in natural language generation. arXiv preprint cs/0306062.</title>
<date>2003</date>
<contexts>
<context position="1350" citStr="Dimitromanolaki and Androutsopoulos, 2003" startWordPosition="203" endWordPosition="207"> model significantly improves the quality of the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of con</context>
</contexts>
<marker>Dimitromanolaki, Androutsopoulos, 2003</marker>
<rawString>Aggeliki Dimitromanolaki and Ion Androutsopoulos. 2003. Learning to order facts for discourse planning in natural language generation. arXiv preprint cs/0306062.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo A Duboue</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Empirically estimating order constraints for content planning in generation.</title>
<date>2001</date>
<booktitle>In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>172--179</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Toulouse, France,</location>
<contexts>
<context position="1307" citStr="Duboue and McKeown, 2001" startWordPosition="199" endWordPosition="202"> We show that using such a model significantly improves the quality of the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of disco</context>
</contexts>
<marker>Duboue, McKeown, 2001</marker>
<rawString>Pablo A. Duboue and Kathleen R. McKeown. 2001. Empirically estimating order constraints for content planning in generation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 172–179, Toulouse, France, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Wei Feng</author>
<author>Graeme Hirst</author>
</authors>
<title>A LinearTime Bottom-Up Discourse Parser with Constraints and Post-Editing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>511--521</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="2167" citStr="Feng and Hirst, 2014" startWordPosition="320" endWordPosition="323">03; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Feng and Hirst, 2014), and discourse structure was shown to be as important for text coherence as entity-based content structure (Lin et al., 2011; Feng et al., 2014). Surprisingly, so far, discourse sequential information from existing discourse-annotated corpora, such as the Penn Discourse Treebank (PDTB) (Prasad et al., 2008) has not been used in generation. In this paper, we present an NLG framework that generates texts from existing semantic web ontologies. We use an n-gram model of discourse relations to perform discourse planning for these stories. Through a crowd-sourced human evaluation, we show that the </context>
</contexts>
<marker>Feng, Hirst, 2014</marker>
<rawString>Vanessa Wei Feng and Graeme Hirst. 2014. A LinearTime Bottom-Up Discourse Parser with Constraints and Post-Editing. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 511–521, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Wei Feng</author>
<author>Ziheng Lin</author>
<author>Graeme Hirst</author>
<author>Singapore Press Holdings</author>
</authors>
<title>The impact of deep hierarchical discourse structures in the evaluation of text coherence.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="2312" citStr="Feng et al., 2014" startWordPosition="346" endWordPosition="349">relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Feng and Hirst, 2014), and discourse structure was shown to be as important for text coherence as entity-based content structure (Lin et al., 2011; Feng et al., 2014). Surprisingly, so far, discourse sequential information from existing discourse-annotated corpora, such as the Penn Discourse Treebank (PDTB) (Prasad et al., 2008) has not been used in generation. In this paper, we present an NLG framework that generates texts from existing semantic web ontologies. We use an n-gram model of discourse relations to perform discourse planning for these stories. Through a crowd-sourced human evaluation, we show that the ordering of our documents and the choice of discourse relations is significantly better when using this model. 2 Generation Framework In concept-</context>
</contexts>
<marker>Feng, Lin, Hirst, Holdings, 2014</marker>
<rawString>Vanessa Wei Feng, Ziheng Lin, Graeme Hirst, and Singapore Press Holdings. 2014. The impact of deep hierarchical discourse structures in the evaluation of text coherence. In Proceedings of the 25th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sucheta Ghosh</author>
<author>Richard Johansson</author>
<author>Giuseppe Riccardi</author>
<author>Sara Tonelli</author>
</authors>
<title>Shallow discourse parsing with conditional random fields.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>1071--1079</pages>
<contexts>
<context position="2144" citStr="Ghosh et al., 2011" startWordPosition="316" endWordPosition="319">l., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Feng and Hirst, 2014), and discourse structure was shown to be as important for text coherence as entity-based content structure (Lin et al., 2011; Feng et al., 2014). Surprisingly, so far, discourse sequential information from existing discourse-annotated corpora, such as the Penn Discourse Treebank (PDTB) (Prasad et al., 2008) has not been used in generation. In this paper, we present an NLG framework that generates texts from existing semantic web ontologies. We use an n-gram model of discourse relations to perform discourse planning for these stories. Through a crowd-sourced human evalua</context>
</contexts>
<marker>Ghosh, Johansson, Riccardi, Tonelli, 2011</marker>
<rawString>Sucheta Ghosh, Richard Johansson, Giuseppe Riccardi, and Sara Tonelli. 2011. Shallow discourse parsing with conditional random fields. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1071–1079.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
</authors>
<title>Automated discourse generation using discourse structure relations.</title>
<date>1993</date>
<journal>Artif. Intell.,</journal>
<pages>63--1</pages>
<contexts>
<context position="1202" citStr="Hovy, 1993" startWordPosition="186" endWordPosition="187">tion models, such as n-gram models of discourse relations learned from an annotated corpus. We show that using such a model significantly improves the quality of the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Mea</context>
</contexts>
<marker>Hovy, 1993</marker>
<rawString>Eduard H. Hovy. 1993. Automated discourse generation using discourse structure relations. Artif. Intell., 63(1-2):341–385, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Konstas</author>
<author>Mirella Lapata</author>
</authors>
<title>Inducing document plans for concept-to-text generation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1503--1514</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="1402" citStr="Konstas and Lapata, 2013" startWordPosition="212" endWordPosition="215">udged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (We</context>
</contexts>
<marker>Konstas, Lapata, 2013</marker>
<rawString>Ioannis Konstas and Mirella Lapata. 2013. Inducing document plans for concept-to-text generation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1503–1514, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with sentence ordering.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>545--552</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1548" citStr="Lapata, 2003" startWordPosition="235" endWordPosition="236">document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Fe</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 545–552, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ziheng Lin</author>
<author>Hwee Tou Ng</author>
<author>Min-Yen Kan</author>
</authors>
<title>Automatically evaluating text coherence using discourse relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>997--1006</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2292" citStr="Lin et al., 2011" startWordPosition="342" endWordPosition="345">, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Feng and Hirst, 2014), and discourse structure was shown to be as important for text coherence as entity-based content structure (Lin et al., 2011; Feng et al., 2014). Surprisingly, so far, discourse sequential information from existing discourse-annotated corpora, such as the Penn Discourse Treebank (PDTB) (Prasad et al., 2008) has not been used in generation. In this paper, we present an NLG framework that generates texts from existing semantic web ontologies. We use an n-gram model of discourse relations to perform discourse planning for these stories. Through a crowd-sourced human evaluation, we show that the ordering of our documents and the choice of discourse relations is significantly better when using this model. 2 Generation F</context>
</contexts>
<marker>Lin, Ng, Kan, 2011</marker>
<rawString>Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011. Automatically evaluating text coherence using discourse relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 997–1006. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: A theory of text organization.</title>
<date>1987</date>
<tech>Technical Report ISI/RS-87-190, ISI.</tech>
<contexts>
<context position="1190" citStr="Mann and Thompson, 1987" startWordPosition="181" endWordPosition="185">to use statistical transition models, such as n-gram models of discourse relations learned from an annotated corpus. We show that using such a model significantly improves the quality of the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely </context>
</contexts>
<marker>Mann, Thompson, 1987</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1987. Rhetorical Structure Theory: A theory of text organization. Technical Report ISI/RS-87-190, ISI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Discourse strategies for generating natural-language text.</title>
<date>1985</date>
<journal>Artif. Intell.,</journal>
<volume>27</volume>
<issue>1</issue>
<contexts>
<context position="1125" citStr="McKeown, 1985" startWordPosition="172" endWordPosition="173">ns between them. This approach makes it straightforward to use statistical transition models, such as n-gram models of discourse relations learned from an annotated corpus. We show that using such a model significantly improves the quality of the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases eit</context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>Kathleen R. McKeown. 1985. Discourse strategies for generating natural-language text. Artif. Intell., 27(1):1–41, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Mridhula Raghupathy</author>
<author>Hena Mehta</author>
<author>Ani Nenkova</author>
<author>Alan Lee</author>
<author>Aravind K Joshi</author>
</authors>
<title>Easily identifiable discourse relations.</title>
<date>2008</date>
<contexts>
<context position="2042" citStr="Pitler et al., 2008" startWordPosition="302" endWordPosition="305">tistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Feng and Hirst, 2014), and discourse structure was shown to be as important for text coherence as entity-based content structure (Lin et al., 2011; Feng et al., 2014). Surprisingly, so far, discourse sequential information from existing discourse-annotated corpora, such as the Penn Discourse Treebank (PDTB) (Prasad et al., 2008) has not been used in generation. In this paper, we present an NLG framework that generates texts from existing semantic web ontologies. We use an n-gram model of dis</context>
</contexts>
<marker>Pitler, Raghupathy, Mehta, Nenkova, Lee, Joshi, 2008</marker>
<rawString>Emily Pitler, Mridhula Raghupathy, Hena Mehta, Ani Nenkova, Alan Lee, and Aravind K Joshi. 2008. Easily identifiable discourse relations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Power</author>
</authors>
<title>Planning texts by constraint satisfaction.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th Conference on Computational Linguistics -</booktitle>
<volume>2</volume>
<pages>642--648</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1216" citStr="Power, 2000" startWordPosition="188" endWordPosition="189"> such as n-gram models of discourse relations learned from an annotated corpus. We show that using such a model significantly improves the quality of the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, resear</context>
</contexts>
<marker>Power, 2000</marker>
<rawString>Richard Power. 2000. Planning texts by constraint satisfaction. In Proceedings of the 18th Conference on Computational Linguistics - Volume 2, COLING ’00, pages 642–648, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The penn discourse treebank 2.0. In</title>
<date>2008</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="2476" citStr="Prasad et al., 2008" startWordPosition="368" endWordPosition="371">mbiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambiguating adjacent relations (Wellner et al., 2006; Pitler et al., 2008). Sequential discourse information has been used successfully in discourse parsing (Ghosh et al., 2011; Feng and Hirst, 2014), and discourse structure was shown to be as important for text coherence as entity-based content structure (Lin et al., 2011; Feng et al., 2014). Surprisingly, so far, discourse sequential information from existing discourse-annotated corpora, such as the Penn Discourse Treebank (PDTB) (Prasad et al., 2008) has not been used in generation. In this paper, we present an NLG framework that generates texts from existing semantic web ontologies. We use an n-gram model of discourse relations to perform discourse planning for these stories. Through a crowd-sourced human evaluation, we show that the ordering of our documents and the choice of discourse relations is significantly better when using this model. 2 Generation Framework In concept-to-text generation pipelines, discourse planning typically occurs after the content selection stage. The input, therefore, is an unordered set of messages that are </context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The penn discourse treebank 2.0. In In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building natural language generation systems, volume 33. Cambridge university press.</title>
<date>2000</date>
<contexts>
<context position="1017" citStr="Reiter and Dale, 2000" startWordPosition="154" endWordPosition="157">or conceptto-text generation systems which simultaneously determines the order of messages and the discourse relations between them. This approach makes it straightforward to use statistical transition models, such as n-gram models of discourse relations learned from an annotated corpus. We show that using such a model significantly improves the quality of the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on d</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Ehud Reiter and Robert Dale. 2000. Building natural language generation systems, volume 33. Cambridge university press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Discourse generation using utility-trained coherence models.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main Conference Poster Sessions, COLING-ACL ’06,</booktitle>
<pages>803--810</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1375" citStr="Soricut and Marcu, 2006" startWordPosition="208" endWordPosition="211">f the generated text as judged by humans. 1 Introduction Discourse planning is a subtask of Natural Language Generation (NLG), concerned with determining the ordering of messages in a document and the discourse relations that hold among them (Reiter and Dale, 2000). Early approaches to discourse planning used manually written rules, often based on schemas (McKeown, 1985) or on Rhetorical Structure Theory (RST) (Mann and Thompson, 1987; Hovy, 1993; Power, 2000). In the past decade, various statistical approaches have emerged (Duboue and McKeown, 2001; Dimitromanolaki and Androutsopoulos, 2003; Soricut and Marcu, 2006; Konstas and Lapata, 2013). Other relevant statistical approaches to content ordering can also be found in the summarization literature (Barzilay et al., 2001; Lapata, 2003; Bollegala et al., 2005). These approaches overwhelmingly focus on determining the best order of messages using semantic conent, while discourse relations are in most cases either determined by manuallywritten derivation rules or completely ignored. Meanwhile, researchers working on discourse relation disambiguation have observed that the sequence of discourse relations itself, independently of content, helps in disambigua</context>
</contexts>
<marker>Soricut, Marcu, 2006</marker>
<rawString>Radu Soricut and Daniel Marcu. 2006. Discourse generation using utility-trained coherence models. In Proceedings of the COLING/ACL on Main Conference Poster Sessions, COLING-ACL ’06, pages 803–810, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Wellner</author>
<author>James Pustejovsky</author>
<author>Catherine Havasi</author>
<author>Anna Rumshisky</author>
<author>Roser Saur´ı</author>
</authors>
<title>Classification of discourse coherence relations: An exploratory study using multiple knowledge sources.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, SigDIAL ’06,</booktitle>
<pages>117--125</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Wellner, Pustejovsky, Havasi, Rumshisky, Saur´ı, 2006</marker>
<rawString>Ben Wellner, James Pustejovsky, Catherine Havasi, Anna Rumshisky, and Roser Saur´ı. 2006. Classification of discourse coherence relations: An exploratory study using multiple knowledge sources. In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, SigDIAL ’06, pages 117–125, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>