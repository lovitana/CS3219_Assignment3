<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.080606">
<title confidence="0.990021">
Extraction and generalisation of variables from scientific publications
</title>
<author confidence="0.999031">
Erwin Marsi, Pinar ¨Ozt¨urk
</author>
<affiliation confidence="0.999651">
Department of Computer and Information Science
Norwegian University of Science and Technology (NTNU)
</affiliation>
<email confidence="0.992352">
{emarsi,pinar}@idi.ntnu.no
</email>
<sectionHeader confidence="0.99731" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999930230769231">
Scientific theories and models in Earth sci-
ence typically involve changing variables
and their complex interactions, including
correlations, causal relations and chains
of positive/negative feedback loops. Vari-
ables tend to be complex rather than
atomic entities and expressed as noun
phrases containing multiple modifiers, e.g.
oxygen depletion in the upper 500 m of
the ocean or timing and magnitude of sur-
face temperature evolution in the Southern
Hemisphere in deglacial proxy records.
Text mining from Earth science literature
is therefore significantly different from
biomedical text mining and requires dif-
ferent approaches and methods. Our ap-
proach aims at automatically locating and
extracting variables and their direction of
variation: increasing, decreasing or just
changing. Variables are initially extracted
by matching tree patterns onto the syntax
trees of the source texts. Next, variables
are generalised in order to enhance their
similarity, facilitating hierarchical search
and inference. This generalisation is ac-
complished by progressive pruning of syn-
tax trees using a set of tree transformation
operations. Text mining results are pre-
sented as a browsable variable hierarchy
which allows users to inspect all mentions
of a particular variable type in the text as
well as any generalisations or specialisa-
tions. The approach is demonstrated on a
corpus of 10k abstracts of Nature publica-
tions in the field of Marine science. We
discuss experiences with this early proto-
type and outline a number of possible im-
provements and directions for future re-
search.
</bodyText>
<sectionHeader confidence="0.999412" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999467769230769">
Text mining of scientific literature originates from
efforts to cope with the ever growing flood of pub-
lications in biomedicine (Swanson, 1986; Swan-
son, 1988; Swanson and Smalheiser, 1997; Hearst,
1999; Ananiadou et al., 2006; Zweigenbaum et
al., 2007; Cohen and Hersh, 2005; Krallinger
et al., 2008; Rodriguez-Esteban, 2009; Zweigen-
baum and Demner-Fushman, 2009; Ananiadou et
al., 2010; Simpson and Demner-Fushman, 2012;
Ananiadou et al., 2014). Consequently the re-
sulting approaches, methods, tools and applica-
tions – as well as data, corpora and evaluation
tasks – are rooted in the paradigm of biomedi-
cal research and its conceptual framework. Typ-
ical source text consists of abstracts from PubMed
or full-text articles from PubMed Central. Stan-
dard tasks include recognition, normalisation and
mapping of biological entities (e.g., genes, pro-
teins, drugs, symptoms and diseases), extraction
of biological relations (e.g., protein-protein inter-
action, disease-gene associations or drug-drug in-
teraction) or bio-event extraction (e.g., regulation
or inhibition events and their participants). There
are extensive ontologies like the Gene Ontology
(Consortium, 2001), annotated corpora like the
GENIA (Kim et al., 2003) and BioInfer (Pyysalo
et al., 2007) corpora and dedicated shared tasks in-
cluding BioCreative (Hirschman et al., 2005) and
BioNLP (Pyysalo et al., 2012). In short, there is
a whole infrastructure supporting biomedical text
mining (Cohen and Hunter, 2008).
Text mining is now spreading out to other scien-
tific disciplines, notably in the humanities and so-
cial sciences (O’Connor et al., 2011), holding the
promise for knowledge discovery from large text
collections. Our own research targets text min-
ing in the field of Earth science, more specifically
in Oceanography or Marine science, with a focus
on climate change. As text mining efforts in this
</bodyText>
<page confidence="0.97488">
505
</page>
<note confidence="0.6584815">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 505–511,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999902176470588">
area are extremely rare (Ekstrom and Lau, 2008;
Vossen et al., 2010; Zhang et al., 2013; Marsi et
al., 2014; Aamot, 2014), it is not surprising that a
corresponding infrastructure is mostly lacking. In
addition, however, we found that due to significant
differences between the conceptual frameworks of
biomedicine and marine science, simply “porting”
the biomedical text mining infrastructure to an-
other domain will not suffice.
One major difference is that the biomedical en-
tities of interest are relatively well defined – genes,
proteins, organisms, species, drugs, diseases, etc.
– and typically expressed as proper nouns. In con-
trast, defining the entities of interest in marine sci-
ence turns out to be much harder. Not only does it
seem to be more open-ended in nature, the entities
themselves tend to be complex and expressed as
noun phrases containing multiple modifiers, giv-
ing rise to examples like oxygen depletion in the
upper 500 m of the ocean or timing and magnitude
of surface temperature evolution in the Southern
Hemisphere in deglacial proxy records.
Given the difficulties with entities, we pro-
pose to concentrate first on text mining of events,
leaving entities underspecified for the time being.
Theories and models in marine science are char-
acterised by changing variables and their com-
plex interactions, including correlations, causal re-
lations and chains of positive/negative feedback
loops. Many marine scientists are interested in
finding evidence – or counter-evidence – in the lit-
erature for events of change and their relations.
Here we present ongoing work to automatically
locate and extract variables and their direction of
variation: increasing, decreasing or just changing.
Examples are given in Table 1.
Since many of these changing variables are long
and complex expressions, their frequency of oc-
currence tends to be low, making the discovery of
relations among different variables harder. As a
partial solution to this problem, we propose pro-
gressive pruning of syntax trees using a set of tree
transformation operations. For example, general-
ising oxygen depletion in the upper 500 m of the
ocean to oxygen depletion in the ocean and sub-
sequently to the much more frequent oxygen de-
pletion. Text mining results are then presented as
a browsable variable hierarchy which allows users
to inspect all mentions of a particular variable type
in the text as well as any generalisations or special-
isations.
</bodyText>
<sectionHeader confidence="0.935487" genericHeader="method">
2 Variable extraction
</sectionHeader>
<bodyText confidence="0.999905765957447">
Our text material consists of 10k abstracts from
journals published by Nature Publishing Group.
Search terms obtained from domain experts were
used to query Nature’s OpenSearch API1 for pub-
lications in a limited range of relevant journals,
after 1997, retrieving records including title and
abstract. The top-10k abstracts matching most
search terms were selected for further processing
with CoreNLP (Manning et al., 2014), including
tokenisation, sentence splitting, POS tagging, lem-
matisation and parsing. Lemmatised parse trees
were obtained by substituting terminals with their
lemmas. The resulting new corpus contains 9,586
article abstracts, 59,787 sentences and approxi-
mately 4M tokens.
Methods for information extraction broadly rely
on either knowledge-based pattern matching or su-
pervised machine learning (Sarawagi, 2008). Al-
though ML approaches are currently dominant in
IE research, rule-based systems have several ad-
vantages, including: (a) the rules are interpretable
and thus suitable for rapid development and do-
main transfer; and (b) humans and machines
can contribute to the same model (Valenzuela-
Esc´arcega et al., 2015). In our case, patterns of-
fered more flexibility in exploring the domain,
whereas the manual annotation required for ML
demands more commitment to a precise definition
of entities, relations and events, which we found
hard to achieve at this stage. Tree pattern match-
ing is applied to lemmatised syntax trees using the
Tregex engine (Levy and Andrew, 2006), which
supports a compact language for writing regular
expressions over trees; see Table 1 for examples
of patterns and matching phrases. For instance,
the pattern for a decreasing variable is defined as
a noun phrase (NP) that is immediately dominated
(&gt;) by a verb phrase (VP), which in turn is headed
by (&lt;&lt;#) the lemma reduce. Similarly, the pat-
tern for increase describes an NP dominated by
a prepositional phrase (PP) that is headed by the
preposition in or of; in addition, this PP must be
preceded by an NP sister node (S,) headed by the
lemma increase.
Patterns were generated by instantiating a small
set of hand-written pattern templates, drawing
from manually created lists of verbs and nouns ex-
</bodyText>
<footnote confidence="0.990144">
1http://www.nature.com/developers/
documentation/api-references/
opensearch-api
</footnote>
<page confidence="0.998008">
506
</page>
<tableCaption confidence="0.999742">
Table 1: Examples of tree patterns and matching variables
</tableCaption>
<table confidence="0.770779714285714">
Direction: Tree pattern: Matched variable in sentence:
Change NP &lt;- (/NN/=d1 &lt; variability Thus the annual, Milankovitch and continuum temperature
$ /NN/) !$. PP variability together represent the response to deterministic inso-
lation forcing.
Increase NP &gt; (PP &lt;&lt;# (in|of) $, The record reveals a linear increase in annual temperature be-
(NP &lt;&lt;# increase)) tween 1958 and 2010 by 2.4 +/-1.2 degreesC ...
Decrease NP &gt; (VP &lt;&lt;# reduce ) Some researchers have observed that abundant natural gas substi-
</table>
<tableCaption confidence="0.431543">
tuting for coal could reduce carbon dioxide (CO2) emissions.
</tableCaption>
<bodyText confidence="0.999740333333333">
pressing change, increase or decrease. The pat-
terns cover expression as a main verb (X increases,
something increases X), attributive use of verbs
(increasing temperature, temperature is increas-
ing), head of NP (a temperature increase) or NP
with PP modifier (increase in temperature). The
total number of patterns is 320: 90 for change, 122
for increase, 108 for decrease (see supplements for
a full list). The total number of matched variables
in the corpus is 21,817: 9,352 for change, 7,400
for increase and 5,065 for decrease.
Some variables do not exactly correspond to a
node, i.e., not every variable is a valid syntac-
tic phrase. For instance, the pattern for Change
in Table 1 matches the NP the annual, Mi-
lankovitch and continuum temperature variabil-
ity, whereas the actual variable is the annual, Mi-
lankovitch and continuum temperature. This is
corrected in a post-processing step that deletes
the variability node from the extracted subtree
and substring. For this purpose, the pattern
contains an assignment of the name d1 to the
node directly dominating the lemma variability
(/NN/=d1 &lt; variability)), allowing acor-
responding tree operation to delete this node,
which is implemented using the Tsurgeon coun-
terpart of Tregex.
</bodyText>
<sectionHeader confidence="0.980822" genericHeader="method">
3 Variable generalisation
</sectionHeader>
<bodyText confidence="0.999239269230769">
Since many of the extracted variables are long and
complex expressions, their frequency is low. The
most frequent variables are generic terms (climate
1207, temperature 156, global climate 73), but
over 66% is unique. This evidently impedes the
discovery of relations among variables. As a par-
tial solution to this problem, variables are gener-
alised by progressive pruning of syntax trees using
a set of tree transformation operations.
Figure 1 shows an example of generalisation
by iterative tree pruning. The first transformation
STRIP INIT DT strips the initial determiner from
the NP. Next, COORD 3.1 deletes everything but
the first conjunct from a coordinated structure of
three NPs, resulting in annual temperature, which
is finally reduced to just temperature by stripping
the premodifier (STRIP PREMOD 1 ). An anal-
ogous procedure is applied to the other two con-
juncts of the coordinated structure.
Tree transformations are implemented using
Tsurgeon (Levy and Andrew, 2006): Tregex pat-
terns match the syntactic structures of interest,
whereas an associated Tsurgeon operation deletes
selected nodes (see supplements for details). The
transformations are ordered in four groups. The
first group handles coordination of two to four
conjuncts (cf. Figure 1) – at the phrase level or the
lexical level – as well as cases of ellipsis (e.g. hail-
storm frequency and intensity into hailstorm fre-
quency and hailstorm intensity). The second group
strips bracketed material in parenthetical and list
structures. The third group deletes non-restrictive
relative clauses and other non-restrictive modi-
fiers preceded by a comma. The final group pro-
gressively strips premodifiers (mainly adjectives)
from left to right and postmodifiers (PPs, relative
clauses) from right to left . Since different trans-
formation may arrive at the same generalisation
(e.g. temperature in Figure 1), duplicates are fil-
tered out. After filtering, 150,716 variables re-
mained, which is 4.86 times the number of orig-
inally extracted variables.
As mentioned, the point of generalisation is to
find relations among variables. In Table 1, for ex-
ample, both the annual, Milankovitch and contin-
uum temperature variability and annual temper-
ature between 1958 and 2010 are generalised to
annual temperature. However, many generalised
variables are unique and thus serve no purpose in
relating variables. Retaining only original vari-
ables and generalised variables with at least two
mentions yields a total of 17,613 variable types.
</bodyText>
<page confidence="0.990744">
507
</page>
<figureCaption confidence="0.9928185">
Figure 2: Partial screenshot of user interface showing variable type hierarchy (left) and linked variable
mentions in text (right) where colour encodes change (green), increase (red) or decrease (blue)
</figureCaption>
<table confidence="0.997519555555556">
the annual , Milankovitch and continuum temperature
STRIP INIT DT → annual, Milankovitch and
continuum temperature
COORD 3.1 → annual temperature
STRIP PREMOD 1 → temperature
COORDI 3.2 → Milankovitch temperature
STRIP PREMOD 1 → temperature
COORD 3.3 → continuum temperature
STRIP PREMOD 1 → temperature
</table>
<figureCaption confidence="0.96692">
Figure 1: Example of generalisation by iterative
tree pruning
</figureCaption>
<sectionHeader confidence="0.995576" genericHeader="method">
4 User interface
</sectionHeader>
<bodyText confidence="0.999994136363636">
The output of the text mining step can be regarded
as a directed graph where the nodes are variable
types and the edges point from a more specific
variable to a more general variable (as a result of
a particular tree transformation). Each variable
type is also linked to a set of tokens, i.e. variable
mentions in the text which are either changing, in-
creasing or decreasing. Figure 2 shows how this
information is presented to the user in a browser
(see supplements for full version). The left panel
lists the variable types, ordered from most gen-
eral to most specific and, secondary, on decreas-
ing token frequency. Links point to more spe-
cific/general variables types, as well as to chang-
ing/increasing/decreasing variable mentions in the
text. The right panel shows the source text, where
colour encodes changing (green), increasing (red)
or decreasing (blue) variable mentions, which are
linked to their most specific variable type. This
setup allows users to quickly explore variables, for
example, finding abstracts containing a variable of
interest and from there to related variables.
</bodyText>
<sectionHeader confidence="0.999821" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9999259375">
We have argued that the paradigm established in
biomedical text mining does not transfer directly
to other scientific domains like Earth science. A
new approach was proposed for extracting vari-
ables and their direction of variation (increasing,
decreasing or just changing), focusing on events
rather than entities. A generic system based on
syntactic pattern matching and tree transforma-
tions was described for extraction and subsequent
generalisation of variable events. Text mining
results are presented in an innovative way as a
browsable hierarchy ranging from most general
to most specific variables, with links to their tex-
tual instances. In addition, a first text corpus in
marine science was produced, including automati-
cally annotated change events. Our corpus as well
as the extracted variables are publicly available2.
We think our approach to extraction is generalis-
able to other domains where the entities of inter-
est are common nouns or complex noun phrases
rather the proper nouns, e.g. in nanotechnology &amp;
nanoscience (Kostoff et al., 2007).
To the best of our knowledge, there are currently
no other systems for text mining in Earth science
which we can compare our results with, nor are
there any benchmark data sets for our task. Most
related is (Marsi et al., 2014), but their definition
of variables is more restricted and their pilot cor-
pus is too small for evaluation purposes. Report-
ing on our ongoing work now, future work will
include an evaluation by asking domain exports to
judge the correctness of extracted variables as well
</bodyText>
<footnote confidence="0.9970115">
2https://dl.dropboxusercontent.com/u/
2370516/emnlp15_corpus.zip
</footnote>
<page confidence="0.995893">
508
</page>
<bodyText confidence="0.999857744680851">
as their generalisations in the given context.
Preliminary observations indicate that most
problems originate from syntactic parsing errors,
in particular well-known ambiguities in coordi-
nation and PP-attachment. As a result, patterns
may either fail to match or match unintentionally,
yielding incomplete or incoherent variables. Since
many sentences are long, complex and domain-
specific, it comes as no surprise that the parser of-
ten fails to correctly resolve well-known ambigui-
ties in coordination and PP-attachment. However,
with pattern matching on strings and/or POS tags
instead of syntax trees, determining boundaries of
variables would be problematic. False positives
also occur because of different semantics of the
same pattern, e.g. change in western Europe is
unlikely to mean literally that the European con-
tinent is changing, neither does changes in less
than a few thousand years imply that past years
are changing.
At the same time, certain false negatives are
beyond the power of pattern matching. For in-
stance, variation may be entailed rather than ex-
plicitly stated: ocean acidification entails increas-
ing acidity of ocean water and Arctic warming en-
tails increasing temperature in the Arctic region.
This is closely related to textual entailment (An-
droutsopoulos and Malakasiotis, 2010; Dagan et
al., 2006), requiring inference in combination with
domain knowledge. A related matter is nega-
tion (no increase in global temperature), which
can even be expressed in non-trivial ways (tem-
perature remained constant) (Morante and Daele-
mans, 2009). Variables were also found to be re-
cursive or embedded, expressing “a change of a
change”. For example, reduce subseasonal tem-
perature variance implies both a change in tem-
perature as well as a decrease of this temperature
change. The current visualisation falls short in
these cases, as HTML browsers cannot render a
link in a link.
Generalisation by tree pruning appears to work
quite well as long as the parse is correct. How-
ever, pruning by itself is insufficient and should
be supplemented with other methods. For in-
stance, linking named entities like species, chemi-
cals or locations to unique concepts in appropriate
ontologies/taxonomies would support generalisa-
tions such as iron is a metal or a diatom is a plank-
ton. Generalisation also bears a strong resem-
blance to other text-to-text generation tasks such
as paraphrasing (Androutsopoulos and Malakasio-
tis, 2010), sentence compression (Jing, 2000) and
sentence simplification (Shardlow, 2014). Given
suitable training data, ML approaches may there-
fore be applied, e.g. (Knight and Marcu, 2002;
Cohn and Lapata, 2009).
The most general variables are probably too
generic to be of much help to a user, e.g. con-
centration, rate, level, etc. Likewise, climate is by
far the most frequent changing variable due to the
frequently occurring collocation climate change.
In addition, variables often contain references to
previously mentioned entities – anaphoric it being
the ultimate example of this – suggesting a need
for co-reference resolution (Miwa et al., 2012).
Yet another future direction is to structurally
model variables as opposed to a possibly over-
simplified generalisation. Similar to nominal SRL,
one can define relevant arguments including fre-
quency (e.g. annual), temporal scope (between
1958 and 2010), location, etc. The most generic
variables mentioned earlier in fact provide a good
basis for such modelling.
Extraction and generalisation of variables pro-
vides a basis for building systems supporting
knowledge discovery. One approach is min-
ing associations between variables frequently co-
occurring in the same sentence or abstract (Jenssen
et al., 2001; Hashimoto et al., 2012)) More precise
results can be expected by extracting causal re-
lations between change events (Chang and Choi,
2005; Blanco et al., 2008; Raja et al., 2013).
Pairs of change events – causally or otherwise
associated – obtained from different publications
can be chained together, possibly in combina-
tion with domain knowledge, in order to gener-
ate new hypotheses, as pioneered in the work on
literature-based knowledge discovery (Swanson,
1986; Swanson, 1988; Swanson and Smalheiser,
1997). Automatic extraction and generalisation of
variables from scientific publications thus paves
the way for future research on text mining in Earth
science.
</bodyText>
<sectionHeader confidence="0.992374" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.586251">
Financial aid from the European Commission
(OCEAN-CERTAIN, FP7-ENV-2013-6.1-1; no:
603773) is gratefully acknowledged. We thank
Murat Van Ardelan for sharing his knowledge of
Marine science and the anonymous reviewers for
their valuable comments.
</bodyText>
<page confidence="0.997655">
509
</page>
<sectionHeader confidence="0.977618" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997744568807339">
Elias Aamot. 2014. Literature-based discovery for
oceanographic climate science. In Proceedings of
the Student Research Workshop at the 14th Confer-
ence of the European Chapter of the Association
for Computational Linguistics, pages 1–10, Gothen-
burg, Sweden, April. Association for Computational
Linguistics.
Sophia Ananiadou, Douglas B. Kell, and Jun I. Tsu-
jii. 2006. Text mining and its potential applications
in systems biology. Trends Biotechnol, 24(12):571–
579, December.
Sophia Ananiadou, Sampo Pyysalo, Jun’ichi Tsujii,
and Douglas B. Kell. 2010. Event extraction
for systems biology by text mining the literature.
Trends in biotechnology, 28(7):381–390, July.
Sophia Ananiadou, Paul Thompson, Raheel Nawaz,
John McNaught, and Douglas B Kell. 2014. Event-
based text mining for biology and functional ge-
nomics. Briefings in functional genomics, page
elu015.
Ion Androutsopoulos and Prodromos Malakasiotis.
2010. A survey of paraphrasing and textual entail-
ment methods. Journal of Artificial Intelligence Re-
search, 38:135–187, May.
Eduardo Blanco, Nuria Castell, and Dan I Moldovan.
2008. Causal relation extraction. In LREC, pages
310–313.
Du-Seong Chang and Key-Sun Choi. 2005. Causal re-
lation extraction using cue phrase and lexical pair
probabilities. In Natural Language Processing–
IJCNLP 2004, pages 61–70. Springer.
Aaron M. Cohen and William R. Hersh. 2005. A
survey of current work in biomedical text mining.
Briefings in Bioinformatics, 6(1):57–71, March.
Kevin Bretonnel Cohen and Lawrence Hunter. 2008.
Getting Started in Text Mining. PLoS Comput Biol,
4(1):e20+, January.
Trevor Cohn and Mirella Lapata. 2009. Sentence
compression as tree transduction. J. Artif. Int. Res.,
34(1):637–674.
The Gene Ontology Consortium. 2001. Creating the
gene ontology resource: Design and implementa-
tion. Genome Research, 11(8):1425–1433, August.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The PASCAL Recognising Textual Entail-
ment challenge. Machine Learning Challenges,
pages 177–190.
Julia A Ekstrom and Gloria T Lau. 2008. Exploratory
text mining of ocean law to measure overlapping
agency and jurisdictional authority. In Proceedings
of the 2008 international conference on Digital gov-
ernment research, pages 53–62. Digital Government
Society of North America.
Chikara Hashimoto, Kentaro Torisawa, Stijn
De Saeger, Jong H. Oh, and Jun’ichi Kazama.
2012. Excitatory or inhibitory: A new semantic
orientation extracts contradiction and causality
from the web. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, EMNLP-CoNLL ’12, pages
619–630, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Marti A. Hearst. 1999. Untangling text data mining.
In Proceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics on Compu-
tational Linguistics, ACL ’99, pages 3–10, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Lynette Hirschman, Alexander Yeh, Christian
Blaschke, and Alfonso Valencia. 2005. Overview
of BioCreAtIvE: critical assessment of informa-
tion extraction for biology. BMC Bioinformatics,
6(Suppl 1):S1+.
T. K. Jenssen, A. Laegreid, J. Komorowski, and
E. Hovig. 2001. A literature network of human
genes for high-throughput analysis of gene expres-
sion. Nat Genet, 28:21–28.
Hongyan Jing. 2000. Sentence reduction for auto-
matic text summarization. In Proceedings of the
sixth conference on Applied natural language pro-
cessing, pages 310–315. Association for Computa-
tional Linguistics.
J. D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE-
NIA corpus—a semantically annotated corpus for
bio-textmining. Bioinformatics, 19(suppl 1):i180–
i182, July.
Kevin Knight and Daniel Marcu. 2002. Summariza-
tion beyond sentence extraction: A probabilistic ap-
proach to sentence compression. Artificial Intelli-
gence, 139(1):91–107.
Ronald N. Kostoff, Raymond G. Koytcheff, and Clif-
ford G.Y. Lau. 2007. Global nanotechnology re-
search literature overview. Technological Forecast-
ing and Social Change, 74(9):1733 – 1747. Three
Special Sections: Assessment of China’s and India’s
Science and Technology Literature Nanotechnology
Policy Minding the Gap: Previewing the Potential of
Breakthrough Technologies.
Martin Krallinger, Alfonso Valencia, and Lynette
Hirschman. 2008. Linking genes to literature:
text mining, information extraction, and retrieval ap-
plications for biology. Genome Biology, 9(Suppl
2):S8+, September.
Roger Levy and Galen Andrew. 2006. Tregex and
Tsurgeon: tools for querying and manipulating tree
data structures. In Proceedings of the fifth interna-
tional conference on Language Resources and Eval-
uation, pages 2231–2234.
</reference>
<page confidence="0.983375">
510
</page>
<reference confidence="0.999795306122449">
Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Proceedings of 52nd
Annual Meeting of the Association for Computa-
tional Linguistics: System Demonstrations, pages
55–60.
Erwin Marsi, Pinar Ozt¨urk, Elias Aamot, Gleb Sizov,
and Murat V Ardelan. 2014. Towards text mining in
climate science: Extraction of quantitative variables
and their relations. In Proceedings of the Fourth
Workshop on Building and Evaluating Resources for
Health and Biomedical Text Processing, Reykjavik,
Iceland.
Makoto Miwa, Paul Thompson, and Sophia Ana-
niadou. 2012. Boosting automatic event ex-
traction from the literature using domain adapta-
tion and coreference resolution. Bioinformatics,
28(13):1759–1765.
Roser Morante and Walter Daelemans. 2009. Learn-
ing the scope of hedge cues in biomedical texts.
In Proceedings of the Workshop on Current Trends
in Biomedical Natural Language Processing, pages
28–36. Association for Computational Linguistics.
Brendan O’Connor, David Bamman, and Noah Smith.
2011. Computational text analysis for social sci-
ence: Model assumptions and complexity. In Pro-
ceedings of the Second Workshop on Computational
Social Science and the Wisdom of the Crowds (NIPS
2011).
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjorne, Jorma Boberg, Jouni Jarvinen, and Tapio
Salakoski. 2007. BioInfer: a corpus for information
extraction in the biomedical domain. BMC Bioin-
formatics, 8:50.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun’ichi Tsujii, and Sophia Ananiadou. 2012.
Overview of the ID, EPI and REL tasks of BioNLP
shared task 2011. BMC Bioinformatics, 13(Suppl
11):S2+, June.
Kalpana Raja, Suresh Subramani, and Jeyakumar
Natarajan. 2013. Ppinterfinder–a mining tool for
extracting causal relations on human proteins from
literature. Database (Oxford), 2013:bas052.
Raul Rodriguez-Esteban. 2009. Biomedical Text
Mining and Its Applications. PLoS Comput Biol,
5(12):e1000597+, December.
Sunita Sarawagi. 2008. Information extraction.
Found. Trends databases, 1(3):261–377, March.
Matthew Shardlow. 2014. A survey of automated text
simplification. International Journal of Advanced
Computer Science and Applications, 4(1).
Matthew S. Simpson and Dina Demner-Fushman.
2012. Biomedical Text Mining: A Survey of Re-
cent Progress. In Charu C. Aggarwal and ChengXi-
ang Zhai, editors, Mining Text Data, pages 465–517.
Springer US.
Don R. Swanson and Neil R. Smalheiser. 1997. An
interactive system for finding complementary liter-
atures: a stimulus to scientific discovery. Artificial
Intelligence, 91(2):183–203, April.
Don R. Swanson. 1986. Fish oil, raynaud’s syndrome,
and undiscovered public knowledge. Perspectives in
biology and medicine, 30(1):7–18.
Don R. Swanson. 1988. Migraine and magnesium:
eleven neglected connections. Perspectives in Biol-
ogy and Medicine, 31(4):526–557.
Marco A. Valenzuela-Esc´arcega, Gustave Hahn-
Powell, Thomas Hicks, and Mihai Surdeanu. 2015.
A domain-independent rule-based framework for
event extraction. In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing of the Assian Fed-
eration of Natural Language Processing: Software
Demonstrations (ACL-IJCNLP).
Piek Vossen, German Rigau, Eneko Agirre, Aitor
Soroa, Monica Monachini, and Roberto Bartolini.
2010. KYOTO: an open platform for mining facts.
In Proceedings of the 6th Workshop on Ontologies
and Lexical Resources , pages 1–10, Beijing, China,
August. Coling 2010 Organizing Committee.
Ce Zhang, Vidhya Govindaraju, Jackson Borchardt,
Tim Foltz, Christopher R´e, and Shanan Peters.
2013. GeoDeepDive: Statistical inference using fa-
miliar data-processing languages. In Proceedings of
the 2013 ACM SIGMOD International Conference
on Management of Data, SIGMOD ’13, pages 993–
996, New York, NY, USA. ACM.
Pierre Zweigenbaum and Dina Demner-Fushman.
2009. Advanced Literature-Mining Tools. In David
Edwards, Jason Stajich, and David Hansen, editors,
Bioinformatics, pages 347–380. Springer New York.
Pierre Zweigenbaum, Dina Demner-Fushman, Hong
Yu, and Kevin B. Cohen. 2007. Frontiers of
biomedical text mining: current progress. Briefings
in Bioinformatics, 8(5):358–375, September.
</reference>
<page confidence="0.997714">
511
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.883927">
<title confidence="0.997147">Extraction and generalisation of variables from scientific publications</title>
<author confidence="0.986214">Pinar Marsi</author>
<affiliation confidence="0.993305">Department of Computer and Information Norwegian University of Science and Technology</affiliation>
<abstract confidence="0.997592425">Scientific theories and models in Earth scitypically involve changing and their complex interactions, including correlations, causal relations and chains of positive/negative feedback loops. Variables tend to be complex rather than atomic entities and expressed as noun phrases containing multiple modifiers, e.g. oxygen depletion in the upper 500 m of ocean or timing of surface temperature evolution in the Southern in deglacial proxy Text mining from Earth science literature is therefore significantly different from biomedical text mining and requires different approaches and methods. Our approach aims at automatically locating and extracting variables and their direction of just Variables are initially extracted by matching tree patterns onto the syntax trees of the source texts. Next, variables are generalised in order to enhance their similarity, facilitating hierarchical search and inference. This generalisation is accomplished by progressive pruning of syntax trees using a set of tree transformation operations. Text mining results are presented as a browsable variable hierarchy which allows users to inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Elias Aamot</author>
</authors>
<title>Literature-based discovery for oceanographic climate science.</title>
<date>2014</date>
<booktitle>In Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Gothenburg, Sweden,</location>
<contexts>
<context position="4020" citStr="Aamot, 2014" startWordPosition="594" endWordPosition="595">al sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus on climate change. As text mining efforts in this 505 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 505–511, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. area are extremely rare (Ekstrom and Lau, 2008; Vossen et al., 2010; Zhang et al., 2013; Marsi et al., 2014; Aamot, 2014), it is not surprising that a corresponding infrastructure is mostly lacking. In addition, however, we found that due to significant differences between the conceptual frameworks of biomedicine and marine science, simply “porting” the biomedical text mining infrastructure to another domain will not suffice. One major difference is that the biomedical entities of interest are relatively well defined – genes, proteins, organisms, species, drugs, diseases, etc. – and typically expressed as proper nouns. In contrast, defining the entities of interest in marine science turns out to be much harder. </context>
</contexts>
<marker>Aamot, 2014</marker>
<rawString>Elias Aamot. 2014. Literature-based discovery for oceanographic climate science. In Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 1–10, Gothenburg, Sweden, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Ananiadou</author>
<author>Douglas B Kell</author>
<author>Jun I Tsujii</author>
</authors>
<title>Text mining and its potential applications in systems biology.</title>
<date>2006</date>
<journal>Trends Biotechnol,</journal>
<volume>24</volume>
<issue>12</issue>
<pages>579</pages>
<contexts>
<context position="2056" citStr="Ananiadou et al., 2006" startWordPosition="299" endWordPosition="302">y which allows users to inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological enti</context>
</contexts>
<marker>Ananiadou, Kell, Tsujii, 2006</marker>
<rawString>Sophia Ananiadou, Douglas B. Kell, and Jun I. Tsujii. 2006. Text mining and its potential applications in systems biology. Trends Biotechnol, 24(12):571– 579, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Ananiadou</author>
<author>Sampo Pyysalo</author>
<author>Jun’ichi Tsujii</author>
<author>Douglas B Kell</author>
</authors>
<title>Event extraction for systems biology by text mining the literature. Trends in biotechnology,</title>
<date>2010</date>
<volume>28</volume>
<issue>7</issue>
<contexts>
<context position="2217" citStr="Ananiadou et al., 2010" startWordPosition="322" endWordPosition="325">rated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or d</context>
</contexts>
<marker>Ananiadou, Pyysalo, Tsujii, Kell, 2010</marker>
<rawString>Sophia Ananiadou, Sampo Pyysalo, Jun’ichi Tsujii, and Douglas B. Kell. 2010. Event extraction for systems biology by text mining the literature. Trends in biotechnology, 28(7):381–390, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Ananiadou</author>
<author>Paul Thompson</author>
<author>Raheel Nawaz</author>
<author>John McNaught</author>
<author>Douglas B Kell</author>
</authors>
<title>Eventbased text mining for biology and functional genomics. Briefings in functional genomics,</title>
<date>2014</date>
<pages>015</pages>
<contexts>
<context position="2276" citStr="Ananiadou et al., 2014" startWordPosition="330" endWordPosition="333">in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or drug-drug interaction) or bio-event extraction (e.g., regula</context>
</contexts>
<marker>Ananiadou, Thompson, Nawaz, McNaught, Kell, 2014</marker>
<rawString>Sophia Ananiadou, Paul Thompson, Raheel Nawaz, John McNaught, and Douglas B Kell. 2014. Eventbased text mining for biology and functional genomics. Briefings in functional genomics, page elu015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ion Androutsopoulos</author>
<author>Prodromos Malakasiotis</author>
</authors>
<title>A survey of paraphrasing and textual entailment methods.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>38--135</pages>
<contexts>
<context position="17657" citStr="Androutsopoulos and Malakasiotis, 2010" startWordPosition="2708" endWordPosition="2712">ositives also occur because of different semantics of the same pattern, e.g. change in western Europe is unlikely to mean literally that the European continent is changing, neither does changes in less than a few thousand years imply that past years are changing. At the same time, certain false negatives are beyond the power of pattern matching. For instance, variation may be entailed rather than explicitly stated: ocean acidification entails increasing acidity of ocean water and Arctic warming entails increasing temperature in the Arctic region. This is closely related to textual entailment (Androutsopoulos and Malakasiotis, 2010; Dagan et al., 2006), requiring inference in combination with domain knowledge. A related matter is negation (no increase in global temperature), which can even be expressed in non-trivial ways (temperature remained constant) (Morante and Daelemans, 2009). Variables were also found to be recursive or embedded, expressing “a change of a change”. For example, reduce subseasonal temperature variance implies both a change in temperature as well as a decrease of this temperature change. The current visualisation falls short in these cases, as HTML browsers cannot render a link in a link. Generalis</context>
</contexts>
<marker>Androutsopoulos, Malakasiotis, 2010</marker>
<rawString>Ion Androutsopoulos and Prodromos Malakasiotis. 2010. A survey of paraphrasing and textual entailment methods. Journal of Artificial Intelligence Research, 38:135–187, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduardo Blanco</author>
<author>Nuria Castell</author>
<author>Dan I Moldovan</author>
</authors>
<title>Causal relation extraction.</title>
<date>2008</date>
<booktitle>In LREC,</booktitle>
<pages>310--313</pages>
<contexts>
<context position="20202" citStr="Blanco et al., 2008" startWordPosition="3105" endWordPosition="3108">e can define relevant arguments including frequency (e.g. annual), temporal scope (between 1958 and 2010), location, etc. The most generic variables mentioned earlier in fact provide a good basis for such modelling. Extraction and generalisation of variables provides a basis for building systems supporting knowledge discovery. One approach is mining associations between variables frequently cooccurring in the same sentence or abstract (Jenssen et al., 2001; Hashimoto et al., 2012)) More precise results can be expected by extracting causal relations between change events (Chang and Choi, 2005; Blanco et al., 2008; Raja et al., 2013). Pairs of change events – causally or otherwise associated – obtained from different publications can be chained together, possibly in combination with domain knowledge, in order to generate new hypotheses, as pioneered in the work on literature-based knowledge discovery (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997). Automatic extraction and generalisation of variables from scientific publications thus paves the way for future research on text mining in Earth science. Acknowledgments Financial aid from the European Commission (OCEAN-CERTAIN, FP7-ENV-2013-6.1</context>
</contexts>
<marker>Blanco, Castell, Moldovan, 2008</marker>
<rawString>Eduardo Blanco, Nuria Castell, and Dan I Moldovan. 2008. Causal relation extraction. In LREC, pages 310–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Du-Seong Chang</author>
<author>Key-Sun Choi</author>
</authors>
<title>Causal relation extraction using cue phrase and lexical pair probabilities.</title>
<date>2005</date>
<booktitle>In Natural Language Processing– IJCNLP 2004,</booktitle>
<pages>61--70</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="20181" citStr="Chang and Choi, 2005" startWordPosition="3101" endWordPosition="3104">lar to nominal SRL, one can define relevant arguments including frequency (e.g. annual), temporal scope (between 1958 and 2010), location, etc. The most generic variables mentioned earlier in fact provide a good basis for such modelling. Extraction and generalisation of variables provides a basis for building systems supporting knowledge discovery. One approach is mining associations between variables frequently cooccurring in the same sentence or abstract (Jenssen et al., 2001; Hashimoto et al., 2012)) More precise results can be expected by extracting causal relations between change events (Chang and Choi, 2005; Blanco et al., 2008; Raja et al., 2013). Pairs of change events – causally or otherwise associated – obtained from different publications can be chained together, possibly in combination with domain knowledge, in order to generate new hypotheses, as pioneered in the work on literature-based knowledge discovery (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997). Automatic extraction and generalisation of variables from scientific publications thus paves the way for future research on text mining in Earth science. Acknowledgments Financial aid from the European Commission (OCEAN-CERT</context>
</contexts>
<marker>Chang, Choi, 2005</marker>
<rawString>Du-Seong Chang and Key-Sun Choi. 2005. Causal relation extraction using cue phrase and lexical pair probabilities. In Natural Language Processing– IJCNLP 2004, pages 61–70. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron M Cohen</author>
<author>William R Hersh</author>
</authors>
<title>A survey of current work in biomedical text mining.</title>
<date>2005</date>
<journal>Briefings in Bioinformatics,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="2105" citStr="Cohen and Hersh, 2005" startWordPosition="307" endWordPosition="310">particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and </context>
</contexts>
<marker>Cohen, Hersh, 2005</marker>
<rawString>Aaron M. Cohen and William R. Hersh. 2005. A survey of current work in biomedical text mining. Briefings in Bioinformatics, 6(1):57–71, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Bretonnel Cohen</author>
<author>Lawrence Hunter</author>
</authors>
<date>2008</date>
<journal>Getting Started in Text Mining. PLoS Comput Biol,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="3306" citStr="Cohen and Hunter, 2008" startWordPosition="480" endWordPosition="483">, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or drug-drug interaction) or bio-event extraction (e.g., regulation or inhibition events and their participants). There are extensive ontologies like the Gene Ontology (Consortium, 2001), annotated corpora like the GENIA (Kim et al., 2003) and BioInfer (Pyysalo et al., 2007) corpora and dedicated shared tasks including BioCreative (Hirschman et al., 2005) and BioNLP (Pyysalo et al., 2012). In short, there is a whole infrastructure supporting biomedical text mining (Cohen and Hunter, 2008). Text mining is now spreading out to other scientific disciplines, notably in the humanities and social sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus on climate change. As text mining efforts in this 505 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 505–511, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. area ar</context>
</contexts>
<marker>Cohen, Hunter, 2008</marker>
<rawString>Kevin Bretonnel Cohen and Lawrence Hunter. 2008. Getting Started in Text Mining. PLoS Comput Biol, 4(1):e20+, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence compression as tree transduction.</title>
<date>2009</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="18991" citStr="Cohn and Lapata, 2009" startWordPosition="2919" endWordPosition="2922">insufficient and should be supplemented with other methods. For instance, linking named entities like species, chemicals or locations to unique concepts in appropriate ontologies/taxonomies would support generalisations such as iron is a metal or a diatom is a plankton. Generalisation also bears a strong resemblance to other text-to-text generation tasks such as paraphrasing (Androutsopoulos and Malakasiotis, 2010), sentence compression (Jing, 2000) and sentence simplification (Shardlow, 2014). Given suitable training data, ML approaches may therefore be applied, e.g. (Knight and Marcu, 2002; Cohn and Lapata, 2009). The most general variables are probably too generic to be of much help to a user, e.g. concentration, rate, level, etc. Likewise, climate is by far the most frequent changing variable due to the frequently occurring collocation climate change. In addition, variables often contain references to previously mentioned entities – anaphoric it being the ultimate example of this – suggesting a need for co-reference resolution (Miwa et al., 2012). Yet another future direction is to structurally model variables as opposed to a possibly oversimplified generalisation. Similar to nominal SRL, one can de</context>
</contexts>
<marker>Cohn, Lapata, 2009</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2009. Sentence compression as tree transduction. J. Artif. Int. Res., 34(1):637–674.</rawString>
</citation>
<citation valid="true">
<title>The Gene Ontology Consortium.</title>
<date>2001</date>
<journal>Genome Research,</journal>
<volume>11</volume>
<issue>8</issue>
<marker>2001</marker>
<rawString>The Gene Ontology Consortium. 2001. Creating the gene ontology resource: Design and implementation. Genome Research, 11(8):1425–1433, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The PASCAL Recognising Textual Entailment challenge. Machine Learning Challenges,</title>
<date>2006</date>
<pages>177--190</pages>
<contexts>
<context position="17678" citStr="Dagan et al., 2006" startWordPosition="2713" endWordPosition="2716"> semantics of the same pattern, e.g. change in western Europe is unlikely to mean literally that the European continent is changing, neither does changes in less than a few thousand years imply that past years are changing. At the same time, certain false negatives are beyond the power of pattern matching. For instance, variation may be entailed rather than explicitly stated: ocean acidification entails increasing acidity of ocean water and Arctic warming entails increasing temperature in the Arctic region. This is closely related to textual entailment (Androutsopoulos and Malakasiotis, 2010; Dagan et al., 2006), requiring inference in combination with domain knowledge. A related matter is negation (no increase in global temperature), which can even be expressed in non-trivial ways (temperature remained constant) (Morante and Daelemans, 2009). Variables were also found to be recursive or embedded, expressing “a change of a change”. For example, reduce subseasonal temperature variance implies both a change in temperature as well as a decrease of this temperature change. The current visualisation falls short in these cases, as HTML browsers cannot render a link in a link. Generalisation by tree pruning</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The PASCAL Recognising Textual Entailment challenge. Machine Learning Challenges, pages 177–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia A Ekstrom</author>
<author>Gloria T Lau</author>
</authors>
<title>Exploratory text mining of ocean law to measure overlapping agency and jurisdictional authority.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 international conference on Digital government research,</booktitle>
<pages>53--62</pages>
<publisher>North America.</publisher>
<contexts>
<context position="3945" citStr="Ekstrom and Lau, 2008" startWordPosition="578" endWordPosition="581">ow spreading out to other scientific disciplines, notably in the humanities and social sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus on climate change. As text mining efforts in this 505 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 505–511, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. area are extremely rare (Ekstrom and Lau, 2008; Vossen et al., 2010; Zhang et al., 2013; Marsi et al., 2014; Aamot, 2014), it is not surprising that a corresponding infrastructure is mostly lacking. In addition, however, we found that due to significant differences between the conceptual frameworks of biomedicine and marine science, simply “porting” the biomedical text mining infrastructure to another domain will not suffice. One major difference is that the biomedical entities of interest are relatively well defined – genes, proteins, organisms, species, drugs, diseases, etc. – and typically expressed as proper nouns. In contrast, defini</context>
</contexts>
<marker>Ekstrom, Lau, 2008</marker>
<rawString>Julia A Ekstrom and Gloria T Lau. 2008. Exploratory text mining of ocean law to measure overlapping agency and jurisdictional authority. In Proceedings of the 2008 international conference on Digital government research, pages 53–62. Digital Government Society of North America.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Chikara Hashimoto</author>
<author>Kentaro Torisawa</author>
<author>Stijn De Saeger</author>
<author>Jong H Oh</author>
<author>Jun’ichi Kazama</author>
</authors>
<title>Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>619--630</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Hashimoto, Torisawa, De Saeger, Oh, Kazama, 2012</marker>
<rawString>Chikara Hashimoto, Kentaro Torisawa, Stijn De Saeger, Jong H. Oh, and Jun’ichi Kazama. 2012. Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 619–630, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Untangling text data mining.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99,</booktitle>
<pages>3--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2032" citStr="Hearst, 1999" startWordPosition="297" endWordPosition="298">iable hierarchy which allows users to inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and ma</context>
</contexts>
<marker>Hearst, 1999</marker>
<rawString>Marti A. Hearst. 1999. Untangling text data mining. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99, pages 3–10, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Alexander Yeh</author>
<author>Christian Blaschke</author>
<author>Alfonso Valencia</author>
</authors>
<title>Overview of BioCreAtIvE: critical assessment of information extraction for biology.</title>
<date>2005</date>
<journal>BMC Bioinformatics,</journal>
<volume>6</volume>
<pages>1--1</pages>
<contexts>
<context position="3170" citStr="Hirschman et al., 2005" startWordPosition="459" endWordPosition="462">rticles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or drug-drug interaction) or bio-event extraction (e.g., regulation or inhibition events and their participants). There are extensive ontologies like the Gene Ontology (Consortium, 2001), annotated corpora like the GENIA (Kim et al., 2003) and BioInfer (Pyysalo et al., 2007) corpora and dedicated shared tasks including BioCreative (Hirschman et al., 2005) and BioNLP (Pyysalo et al., 2012). In short, there is a whole infrastructure supporting biomedical text mining (Cohen and Hunter, 2008). Text mining is now spreading out to other scientific disciplines, notably in the humanities and social sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus on climate change. As text mining efforts in this 505 Proceedings of the 2015 Conference on Empirical Methods in Natur</context>
</contexts>
<marker>Hirschman, Yeh, Blaschke, Valencia, 2005</marker>
<rawString>Lynette Hirschman, Alexander Yeh, Christian Blaschke, and Alfonso Valencia. 2005. Overview of BioCreAtIvE: critical assessment of information extraction for biology. BMC Bioinformatics, 6(Suppl 1):S1+.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Jenssen</author>
<author>A Laegreid</author>
<author>J Komorowski</author>
<author>E Hovig</author>
</authors>
<title>A literature network of human genes for high-throughput analysis of gene expression.</title>
<date>2001</date>
<journal>Nat Genet,</journal>
<pages>28--21</pages>
<contexts>
<context position="20043" citStr="Jenssen et al., 2001" startWordPosition="3079" endWordPosition="3082">t al., 2012). Yet another future direction is to structurally model variables as opposed to a possibly oversimplified generalisation. Similar to nominal SRL, one can define relevant arguments including frequency (e.g. annual), temporal scope (between 1958 and 2010), location, etc. The most generic variables mentioned earlier in fact provide a good basis for such modelling. Extraction and generalisation of variables provides a basis for building systems supporting knowledge discovery. One approach is mining associations between variables frequently cooccurring in the same sentence or abstract (Jenssen et al., 2001; Hashimoto et al., 2012)) More precise results can be expected by extracting causal relations between change events (Chang and Choi, 2005; Blanco et al., 2008; Raja et al., 2013). Pairs of change events – causally or otherwise associated – obtained from different publications can be chained together, possibly in combination with domain knowledge, in order to generate new hypotheses, as pioneered in the work on literature-based knowledge discovery (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997). Automatic extraction and generalisation of variables from scientific publications thus</context>
</contexts>
<marker>Jenssen, Laegreid, Komorowski, Hovig, 2001</marker>
<rawString>T. K. Jenssen, A. Laegreid, J. Komorowski, and E. Hovig. 2001. A literature network of human genes for high-throughput analysis of gene expression. Nat Genet, 28:21–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyan Jing</author>
</authors>
<title>Sentence reduction for automatic text summarization.</title>
<date>2000</date>
<booktitle>In Proceedings of the sixth conference on Applied natural language processing,</booktitle>
<pages>310--315</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="18822" citStr="Jing, 2000" startWordPosition="2896" endWordPosition="2897">sers cannot render a link in a link. Generalisation by tree pruning appears to work quite well as long as the parse is correct. However, pruning by itself is insufficient and should be supplemented with other methods. For instance, linking named entities like species, chemicals or locations to unique concepts in appropriate ontologies/taxonomies would support generalisations such as iron is a metal or a diatom is a plankton. Generalisation also bears a strong resemblance to other text-to-text generation tasks such as paraphrasing (Androutsopoulos and Malakasiotis, 2010), sentence compression (Jing, 2000) and sentence simplification (Shardlow, 2014). Given suitable training data, ML approaches may therefore be applied, e.g. (Knight and Marcu, 2002; Cohn and Lapata, 2009). The most general variables are probably too generic to be of much help to a user, e.g. concentration, rate, level, etc. Likewise, climate is by far the most frequent changing variable due to the frequently occurring collocation climate change. In addition, variables often contain references to previously mentioned entities – anaphoric it being the ultimate example of this – suggesting a need for co-reference resolution (Miwa </context>
</contexts>
<marker>Jing, 2000</marker>
<rawString>Hongyan Jing. 2000. Sentence reduction for automatic text summarization. In Proceedings of the sixth conference on Applied natural language processing, pages 310–315. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Kim</author>
<author>T Ohta</author>
<author>Y Tateisi</author>
<author>J Tsujii</author>
</authors>
<title>GENIA corpus—a semantically annotated corpus for bio-textmining.</title>
<date>2003</date>
<booktitle>Bioinformatics, 19(suppl 1):i180– i182,</booktitle>
<contexts>
<context position="3052" citStr="Kim et al., 2003" startWordPosition="441" endWordPosition="444">ical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or drug-drug interaction) or bio-event extraction (e.g., regulation or inhibition events and their participants). There are extensive ontologies like the Gene Ontology (Consortium, 2001), annotated corpora like the GENIA (Kim et al., 2003) and BioInfer (Pyysalo et al., 2007) corpora and dedicated shared tasks including BioCreative (Hirschman et al., 2005) and BioNLP (Pyysalo et al., 2012). In short, there is a whole infrastructure supporting biomedical text mining (Cohen and Hunter, 2008). Text mining is now spreading out to other scientific disciplines, notably in the humanities and social sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus </context>
</contexts>
<marker>Kim, Ohta, Tateisi, Tsujii, 2003</marker>
<rawString>J. D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GENIA corpus—a semantically annotated corpus for bio-textmining. Bioinformatics, 19(suppl 1):i180– i182, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: A probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<volume>139</volume>
<issue>1</issue>
<contexts>
<context position="18967" citStr="Knight and Marcu, 2002" startWordPosition="2915" endWordPosition="2918">r, pruning by itself is insufficient and should be supplemented with other methods. For instance, linking named entities like species, chemicals or locations to unique concepts in appropriate ontologies/taxonomies would support generalisations such as iron is a metal or a diatom is a plankton. Generalisation also bears a strong resemblance to other text-to-text generation tasks such as paraphrasing (Androutsopoulos and Malakasiotis, 2010), sentence compression (Jing, 2000) and sentence simplification (Shardlow, 2014). Given suitable training data, ML approaches may therefore be applied, e.g. (Knight and Marcu, 2002; Cohn and Lapata, 2009). The most general variables are probably too generic to be of much help to a user, e.g. concentration, rate, level, etc. Likewise, climate is by far the most frequent changing variable due to the frequently occurring collocation climate change. In addition, variables often contain references to previously mentioned entities – anaphoric it being the ultimate example of this – suggesting a need for co-reference resolution (Miwa et al., 2012). Yet another future direction is to structurally model variables as opposed to a possibly oversimplified generalisation. Similar to</context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>Kevin Knight and Daniel Marcu. 2002. Summarization beyond sentence extraction: A probabilistic approach to sentence compression. Artificial Intelligence, 139(1):91–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald N Kostoff</author>
<author>Raymond G Koytcheff</author>
<author>Clifford G Y Lau</author>
</authors>
<title>Global nanotechnology research literature overview.</title>
<date>2007</date>
<booktitle>Technological Forecasting and Social Change, 74(9):1733 – 1747. Three Special Sections: Assessment of China’s and India’s Science and Technology Literature Nanotechnology Policy Minding the Gap: Previewing the Potential of Breakthrough Technologies.</booktitle>
<contexts>
<context position="15781" citStr="Kostoff et al., 2007" startWordPosition="2422" endWordPosition="2425">t generalisation of variable events. Text mining results are presented in an innovative way as a browsable hierarchy ranging from most general to most specific variables, with links to their textual instances. In addition, a first text corpus in marine science was produced, including automatically annotated change events. Our corpus as well as the extracted variables are publicly available2. We think our approach to extraction is generalisable to other domains where the entities of interest are common nouns or complex noun phrases rather the proper nouns, e.g. in nanotechnology &amp; nanoscience (Kostoff et al., 2007). To the best of our knowledge, there are currently no other systems for text mining in Earth science which we can compare our results with, nor are there any benchmark data sets for our task. Most related is (Marsi et al., 2014), but their definition of variables is more restricted and their pilot corpus is too small for evaluation purposes. Reporting on our ongoing work now, future work will include an evaluation by asking domain exports to judge the correctness of extracted variables as well 2https://dl.dropboxusercontent.com/u/ 2370516/emnlp15_corpus.zip 508 as their generalisations in the</context>
</contexts>
<marker>Kostoff, Koytcheff, Lau, 2007</marker>
<rawString>Ronald N. Kostoff, Raymond G. Koytcheff, and Clifford G.Y. Lau. 2007. Global nanotechnology research literature overview. Technological Forecasting and Social Change, 74(9):1733 – 1747. Three Special Sections: Assessment of China’s and India’s Science and Technology Literature Nanotechnology Policy Minding the Gap: Previewing the Potential of Breakthrough Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Krallinger</author>
<author>Alfonso Valencia</author>
<author>Lynette Hirschman</author>
</authors>
<title>Linking genes to literature: text mining, information extraction, and retrieval applications for biology. Genome Biology, 9(Suppl 2):S8+,</title>
<date>2008</date>
<contexts>
<context position="2130" citStr="Krallinger et al., 2008" startWordPosition="311" endWordPosition="314">e in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of </context>
</contexts>
<marker>Krallinger, Valencia, Hirschman, 2008</marker>
<rawString>Martin Krallinger, Alfonso Valencia, and Lynette Hirschman. 2008. Linking genes to literature: text mining, information extraction, and retrieval applications for biology. Genome Biology, 9(Suppl 2):S8+, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Galen Andrew</author>
</authors>
<title>Tregex and Tsurgeon: tools for querying and manipulating tree data structures.</title>
<date>2006</date>
<booktitle>In Proceedings of the fifth international conference on Language Resources and Evaluation,</booktitle>
<pages>2231--2234</pages>
<contexts>
<context position="7857" citStr="Levy and Andrew, 2006" startWordPosition="1185" endWordPosition="1188">inant in IE research, rule-based systems have several advantages, including: (a) the rules are interpretable and thus suitable for rapid development and domain transfer; and (b) humans and machines can contribute to the same model (ValenzuelaEsc´arcega et al., 2015). In our case, patterns offered more flexibility in exploring the domain, whereas the manual annotation required for ML demands more commitment to a precise definition of entities, relations and events, which we found hard to achieve at this stage. Tree pattern matching is applied to lemmatised syntax trees using the Tregex engine (Levy and Andrew, 2006), which supports a compact language for writing regular expressions over trees; see Table 1 for examples of patterns and matching phrases. For instance, the pattern for a decreasing variable is defined as a noun phrase (NP) that is immediately dominated (&gt;) by a verb phrase (VP), which in turn is headed by (&lt;&lt;#) the lemma reduce. Similarly, the pattern for increase describes an NP dominated by a prepositional phrase (PP) that is headed by the preposition in or of; in addition, this PP must be preceded by an NP sister node (S,) headed by the lemma increase. Patterns were generated by instantiat</context>
<context position="11512" citStr="Levy and Andrew, 2006" startWordPosition="1760" endWordPosition="1763">sive pruning of syntax trees using a set of tree transformation operations. Figure 1 shows an example of generalisation by iterative tree pruning. The first transformation STRIP INIT DT strips the initial determiner from the NP. Next, COORD 3.1 deletes everything but the first conjunct from a coordinated structure of three NPs, resulting in annual temperature, which is finally reduced to just temperature by stripping the premodifier (STRIP PREMOD 1 ). An analogous procedure is applied to the other two conjuncts of the coordinated structure. Tree transformations are implemented using Tsurgeon (Levy and Andrew, 2006): Tregex patterns match the syntactic structures of interest, whereas an associated Tsurgeon operation deletes selected nodes (see supplements for details). The transformations are ordered in four groups. The first group handles coordination of two to four conjuncts (cf. Figure 1) – at the phrase level or the lexical level – as well as cases of ellipsis (e.g. hailstorm frequency and intensity into hailstorm frequency and hailstorm intensity). The second group strips bracketed material in parenthetical and list structures. The third group deletes non-restrictive relative clauses and other non-r</context>
</contexts>
<marker>Levy, Andrew, 2006</marker>
<rawString>Roger Levy and Galen Andrew. 2006. Tregex and Tsurgeon: tools for querying and manipulating tree data structures. In Proceedings of the fifth international conference on Language Resources and Evaluation, pages 2231–2234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Mihai Surdeanu</author>
<author>John Bauer</author>
<author>Jenny Finkel</author>
<author>Steven J Bethard</author>
<author>David McClosky</author>
</authors>
<title>The Stanford CoreNLP natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,</booktitle>
<pages>55--60</pages>
<contexts>
<context position="6782" citStr="Manning et al., 2014" startWordPosition="1025" endWordPosition="1028">sented as a browsable variable hierarchy which allows users to inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. 2 Variable extraction Our text material consists of 10k abstracts from journals published by Nature Publishing Group. Search terms obtained from domain experts were used to query Nature’s OpenSearch API1 for publications in a limited range of relevant journals, after 1997, retrieving records including title and abstract. The top-10k abstracts matching most search terms were selected for further processing with CoreNLP (Manning et al., 2014), including tokenisation, sentence splitting, POS tagging, lemmatisation and parsing. Lemmatised parse trees were obtained by substituting terminals with their lemmas. The resulting new corpus contains 9,586 article abstracts, 59,787 sentences and approximately 4M tokens. Methods for information extraction broadly rely on either knowledge-based pattern matching or supervised machine learning (Sarawagi, 2008). Although ML approaches are currently dominant in IE research, rule-based systems have several advantages, including: (a) the rules are interpretable and thus suitable for rapid developmen</context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP natural language processing toolkit. In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 55–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin Marsi</author>
<author>Pinar Ozt¨urk</author>
<author>Elias Aamot</author>
<author>Gleb Sizov</author>
<author>Murat V Ardelan</author>
</authors>
<title>Towards text mining in climate science: Extraction of quantitative variables and their relations.</title>
<date>2014</date>
<booktitle>In Proceedings of the Fourth Workshop on Building and Evaluating Resources for Health and Biomedical Text Processing,</booktitle>
<location>Reykjavik, Iceland.</location>
<marker>Marsi, Ozt¨urk, Aamot, Sizov, Ardelan, 2014</marker>
<rawString>Erwin Marsi, Pinar Ozt¨urk, Elias Aamot, Gleb Sizov, and Murat V Ardelan. 2014. Towards text mining in climate science: Extraction of quantitative variables and their relations. In Proceedings of the Fourth Workshop on Building and Evaluating Resources for Health and Biomedical Text Processing, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Miwa</author>
<author>Paul Thompson</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Boosting automatic event extraction from the literature using domain adaptation and coreference resolution.</title>
<date>2012</date>
<journal>Bioinformatics,</journal>
<volume>28</volume>
<issue>13</issue>
<contexts>
<context position="19435" citStr="Miwa et al., 2012" startWordPosition="2989" endWordPosition="2992">2000) and sentence simplification (Shardlow, 2014). Given suitable training data, ML approaches may therefore be applied, e.g. (Knight and Marcu, 2002; Cohn and Lapata, 2009). The most general variables are probably too generic to be of much help to a user, e.g. concentration, rate, level, etc. Likewise, climate is by far the most frequent changing variable due to the frequently occurring collocation climate change. In addition, variables often contain references to previously mentioned entities – anaphoric it being the ultimate example of this – suggesting a need for co-reference resolution (Miwa et al., 2012). Yet another future direction is to structurally model variables as opposed to a possibly oversimplified generalisation. Similar to nominal SRL, one can define relevant arguments including frequency (e.g. annual), temporal scope (between 1958 and 2010), location, etc. The most generic variables mentioned earlier in fact provide a good basis for such modelling. Extraction and generalisation of variables provides a basis for building systems supporting knowledge discovery. One approach is mining associations between variables frequently cooccurring in the same sentence or abstract (Jenssen et a</context>
</contexts>
<marker>Miwa, Thompson, Ananiadou, 2012</marker>
<rawString>Makoto Miwa, Paul Thompson, and Sophia Ananiadou. 2012. Boosting automatic event extraction from the literature using domain adaptation and coreference resolution. Bioinformatics, 28(13):1759–1765.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of hedge cues in biomedical texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="17913" citStr="Morante and Daelemans, 2009" startWordPosition="2747" endWordPosition="2751"> the same time, certain false negatives are beyond the power of pattern matching. For instance, variation may be entailed rather than explicitly stated: ocean acidification entails increasing acidity of ocean water and Arctic warming entails increasing temperature in the Arctic region. This is closely related to textual entailment (Androutsopoulos and Malakasiotis, 2010; Dagan et al., 2006), requiring inference in combination with domain knowledge. A related matter is negation (no increase in global temperature), which can even be expressed in non-trivial ways (temperature remained constant) (Morante and Daelemans, 2009). Variables were also found to be recursive or embedded, expressing “a change of a change”. For example, reduce subseasonal temperature variance implies both a change in temperature as well as a decrease of this temperature change. The current visualisation falls short in these cases, as HTML browsers cannot render a link in a link. Generalisation by tree pruning appears to work quite well as long as the parse is correct. However, pruning by itself is insufficient and should be supplemented with other methods. For instance, linking named entities like species, chemicals or locations to unique </context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. Learning the scope of hedge cues in biomedical texts. In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing, pages 28–36. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>David Bamman</author>
<author>Noah Smith</author>
</authors>
<title>Computational text analysis for social science: Model assumptions and complexity.</title>
<date>2011</date>
<booktitle>In Proceedings of the Second Workshop on Computational Social Science and the Wisdom of the Crowds (NIPS</booktitle>
<marker>O’Connor, Bamman, Smith, 2011</marker>
<rawString>Brendan O’Connor, David Bamman, and Noah Smith. 2011. Computational text analysis for social science: Model assumptions and complexity. In Proceedings of the Second Workshop on Computational Social Science and the Wisdom of the Crowds (NIPS 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Juho Heimonen</author>
<author>Jari Bjorne</author>
<author>Jorma Boberg</author>
<author>Jouni Jarvinen</author>
<author>Tapio Salakoski</author>
</authors>
<title>BioInfer: a corpus for information extraction in the biomedical domain.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<contexts>
<context position="3088" citStr="Pyysalo et al., 2007" startWordPosition="447" endWordPosition="450"> framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or drug-drug interaction) or bio-event extraction (e.g., regulation or inhibition events and their participants). There are extensive ontologies like the Gene Ontology (Consortium, 2001), annotated corpora like the GENIA (Kim et al., 2003) and BioInfer (Pyysalo et al., 2007) corpora and dedicated shared tasks including BioCreative (Hirschman et al., 2005) and BioNLP (Pyysalo et al., 2012). In short, there is a whole infrastructure supporting biomedical text mining (Cohen and Hunter, 2008). Text mining is now spreading out to other scientific disciplines, notably in the humanities and social sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus on climate change. As text mining ef</context>
</contexts>
<marker>Pyysalo, Ginter, Heimonen, Bjorne, Boberg, Jarvinen, Salakoski, 2007</marker>
<rawString>Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari Bjorne, Jorma Boberg, Jouni Jarvinen, and Tapio Salakoski. 2007. BioInfer: a corpus for information extraction in the biomedical domain. BMC Bioinformatics, 8:50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Tomoko Ohta</author>
<author>Rafal Rak</author>
<author>Dan Sullivan</author>
<author>Chunhong Mao</author>
<author>Chunxia Wang</author>
<author>Bruno Sobral</author>
<author>Jun’ichi Tsujii</author>
<author>Sophia Ananiadou</author>
</authors>
<date>2012</date>
<booktitle>Overview of the ID, EPI and REL tasks of BioNLP shared task 2011. BMC Bioinformatics, 13(Suppl 11):S2+,</booktitle>
<contexts>
<context position="3204" citStr="Pyysalo et al., 2012" startWordPosition="465" endWordPosition="468">d tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or drug-drug interaction) or bio-event extraction (e.g., regulation or inhibition events and their participants). There are extensive ontologies like the Gene Ontology (Consortium, 2001), annotated corpora like the GENIA (Kim et al., 2003) and BioInfer (Pyysalo et al., 2007) corpora and dedicated shared tasks including BioCreative (Hirschman et al., 2005) and BioNLP (Pyysalo et al., 2012). In short, there is a whole infrastructure supporting biomedical text mining (Cohen and Hunter, 2008). Text mining is now spreading out to other scientific disciplines, notably in the humanities and social sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus on climate change. As text mining efforts in this 505 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 505–</context>
</contexts>
<marker>Pyysalo, Ohta, Rak, Sullivan, Mao, Wang, Sobral, Tsujii, Ananiadou, 2012</marker>
<rawString>Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sullivan, Chunhong Mao, Chunxia Wang, Bruno Sobral, Jun’ichi Tsujii, and Sophia Ananiadou. 2012. Overview of the ID, EPI and REL tasks of BioNLP shared task 2011. BMC Bioinformatics, 13(Suppl 11):S2+, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kalpana Raja</author>
<author>Suresh Subramani</author>
<author>Jeyakumar Natarajan</author>
</authors>
<title>Ppinterfinder–a mining tool for extracting causal relations on human proteins from literature. Database</title>
<date>2013</date>
<location>(Oxford),</location>
<contexts>
<context position="20222" citStr="Raja et al., 2013" startWordPosition="3109" endWordPosition="3112"> arguments including frequency (e.g. annual), temporal scope (between 1958 and 2010), location, etc. The most generic variables mentioned earlier in fact provide a good basis for such modelling. Extraction and generalisation of variables provides a basis for building systems supporting knowledge discovery. One approach is mining associations between variables frequently cooccurring in the same sentence or abstract (Jenssen et al., 2001; Hashimoto et al., 2012)) More precise results can be expected by extracting causal relations between change events (Chang and Choi, 2005; Blanco et al., 2008; Raja et al., 2013). Pairs of change events – causally or otherwise associated – obtained from different publications can be chained together, possibly in combination with domain knowledge, in order to generate new hypotheses, as pioneered in the work on literature-based knowledge discovery (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997). Automatic extraction and generalisation of variables from scientific publications thus paves the way for future research on text mining in Earth science. Acknowledgments Financial aid from the European Commission (OCEAN-CERTAIN, FP7-ENV-2013-6.1-1; no: 603773) is g</context>
</contexts>
<marker>Raja, Subramani, Natarajan, 2013</marker>
<rawString>Kalpana Raja, Suresh Subramani, and Jeyakumar Natarajan. 2013. Ppinterfinder–a mining tool for extracting causal relations on human proteins from literature. Database (Oxford), 2013:bas052.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raul Rodriguez-Esteban</author>
</authors>
<title>Biomedical Text Mining and Its Applications.</title>
<date>2009</date>
<journal>PLoS Comput Biol,</journal>
<volume>5</volume>
<issue>12</issue>
<contexts>
<context position="2155" citStr="Rodriguez-Esteban, 2009" startWordPosition="315" endWordPosition="316">any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g</context>
</contexts>
<marker>Rodriguez-Esteban, 2009</marker>
<rawString>Raul Rodriguez-Esteban. 2009. Biomedical Text Mining and Its Applications. PLoS Comput Biol, 5(12):e1000597+, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
</authors>
<title>Information extraction.</title>
<date>2008</date>
<journal>Found. Trends databases,</journal>
<volume>1</volume>
<issue>3</issue>
<contexts>
<context position="7193" citStr="Sarawagi, 2008" startWordPosition="1081" endWordPosition="1082">of relevant journals, after 1997, retrieving records including title and abstract. The top-10k abstracts matching most search terms were selected for further processing with CoreNLP (Manning et al., 2014), including tokenisation, sentence splitting, POS tagging, lemmatisation and parsing. Lemmatised parse trees were obtained by substituting terminals with their lemmas. The resulting new corpus contains 9,586 article abstracts, 59,787 sentences and approximately 4M tokens. Methods for information extraction broadly rely on either knowledge-based pattern matching or supervised machine learning (Sarawagi, 2008). Although ML approaches are currently dominant in IE research, rule-based systems have several advantages, including: (a) the rules are interpretable and thus suitable for rapid development and domain transfer; and (b) humans and machines can contribute to the same model (ValenzuelaEsc´arcega et al., 2015). In our case, patterns offered more flexibility in exploring the domain, whereas the manual annotation required for ML demands more commitment to a precise definition of entities, relations and events, which we found hard to achieve at this stage. Tree pattern matching is applied to lemmati</context>
</contexts>
<marker>Sarawagi, 2008</marker>
<rawString>Sunita Sarawagi. 2008. Information extraction. Found. Trends databases, 1(3):261–377, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Shardlow</author>
</authors>
<title>A survey of automated text simplification.</title>
<date>2014</date>
<journal>International Journal of Advanced Computer Science and Applications,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="18867" citStr="Shardlow, 2014" startWordPosition="2901" endWordPosition="2902">ralisation by tree pruning appears to work quite well as long as the parse is correct. However, pruning by itself is insufficient and should be supplemented with other methods. For instance, linking named entities like species, chemicals or locations to unique concepts in appropriate ontologies/taxonomies would support generalisations such as iron is a metal or a diatom is a plankton. Generalisation also bears a strong resemblance to other text-to-text generation tasks such as paraphrasing (Androutsopoulos and Malakasiotis, 2010), sentence compression (Jing, 2000) and sentence simplification (Shardlow, 2014). Given suitable training data, ML approaches may therefore be applied, e.g. (Knight and Marcu, 2002; Cohn and Lapata, 2009). The most general variables are probably too generic to be of much help to a user, e.g. concentration, rate, level, etc. Likewise, climate is by far the most frequent changing variable due to the frequently occurring collocation climate change. In addition, variables often contain references to previously mentioned entities – anaphoric it being the ultimate example of this – suggesting a need for co-reference resolution (Miwa et al., 2012). Yet another future direction i</context>
</contexts>
<marker>Shardlow, 2014</marker>
<rawString>Matthew Shardlow. 2014. A survey of automated text simplification. International Journal of Advanced Computer Science and Applications, 4(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Simpson</author>
<author>Dina Demner-Fushman</author>
</authors>
<title>Biomedical Text Mining: A Survey of Recent Progress.</title>
<date>2012</date>
<booktitle>In Charu C. Aggarwal and ChengXiang Zhai, editors, Mining Text Data,</booktitle>
<pages>465--517</pages>
<publisher>Springer US.</publisher>
<contexts>
<context position="2251" citStr="Simpson and Demner-Fushman, 2012" startWordPosition="326" endWordPosition="329"> abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, disease-gene associations or drug-drug interaction) or bio-event</context>
</contexts>
<marker>Simpson, Demner-Fushman, 2012</marker>
<rawString>Matthew S. Simpson and Dina Demner-Fushman. 2012. Biomedical Text Mining: A Survey of Recent Progress. In Charu C. Aggarwal and ChengXiang Zhai, editors, Mining Text Data, pages 465–517. Springer US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
<author>Neil R Smalheiser</author>
</authors>
<title>An interactive system for finding complementary literatures: a stimulus to scientific discovery.</title>
<date>1997</date>
<journal>Artificial Intelligence,</journal>
<volume>91</volume>
<issue>2</issue>
<contexts>
<context position="2018" citStr="Swanson and Smalheiser, 1997" startWordPosition="293" endWordPosition="296">e presented as a browsable variable hierarchy which allows users to inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normal</context>
</contexts>
<marker>Swanson, Smalheiser, 1997</marker>
<rawString>Don R. Swanson and Neil R. Smalheiser. 1997. An interactive system for finding complementary literatures: a stimulus to scientific discovery. Artificial Intelligence, 91(2):183–203, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
</authors>
<title>Fish oil, raynaud’s syndrome, and undiscovered public knowledge. Perspectives in biology and medicine,</title>
<date>1986</date>
<pages>30--1</pages>
<contexts>
<context position="1973" citStr="Swanson, 1986" startWordPosition="288" endWordPosition="289">ations. Text mining results are presented as a browsable variable hierarchy which allows users to inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Centra</context>
</contexts>
<marker>Swanson, 1986</marker>
<rawString>Don R. Swanson. 1986. Fish oil, raynaud’s syndrome, and undiscovered public knowledge. Perspectives in biology and medicine, 30(1):7–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
</authors>
<title>Migraine and magnesium: eleven neglected connections.</title>
<date>1988</date>
<booktitle>Perspectives in Biology and Medicine,</booktitle>
<pages>31--4</pages>
<contexts>
<context position="1988" citStr="Swanson, 1988" startWordPosition="290" endWordPosition="292">ning results are presented as a browsable variable hierarchy which allows users to inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tas</context>
</contexts>
<marker>Swanson, 1988</marker>
<rawString>Don R. Swanson. 1988. Migraine and magnesium: eleven neglected connections. Perspectives in Biology and Medicine, 31(4):526–557.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marco A Valenzuela-Esc´arcega</author>
<author>Gustave HahnPowell</author>
<author>Thomas Hicks</author>
<author>Mihai Surdeanu</author>
</authors>
<title>A domain-independent rule-based framework for event extraction.</title>
<date>2015</date>
<booktitle>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Assian Federation of Natural Language Processing: Software Demonstrations (ACL-IJCNLP).</booktitle>
<marker>Valenzuela-Esc´arcega, HahnPowell, Hicks, Surdeanu, 2015</marker>
<rawString>Marco A. Valenzuela-Esc´arcega, Gustave HahnPowell, Thomas Hicks, and Mihai Surdeanu. 2015. A domain-independent rule-based framework for event extraction. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Assian Federation of Natural Language Processing: Software Demonstrations (ACL-IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
<author>German Rigau</author>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
<author>Monica Monachini</author>
<author>Roberto Bartolini</author>
</authors>
<title>KYOTO: an open platform for mining facts.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 6th Workshop on Ontologies and Lexical Resources ,</booktitle>
<pages>1--10</pages>
<location>Beijing, China,</location>
<contexts>
<context position="3966" citStr="Vossen et al., 2010" startWordPosition="582" endWordPosition="585">er scientific disciplines, notably in the humanities and social sciences (O’Connor et al., 2011), holding the promise for knowledge discovery from large text collections. Our own research targets text mining in the field of Earth science, more specifically in Oceanography or Marine science, with a focus on climate change. As text mining efforts in this 505 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 505–511, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. area are extremely rare (Ekstrom and Lau, 2008; Vossen et al., 2010; Zhang et al., 2013; Marsi et al., 2014; Aamot, 2014), it is not surprising that a corresponding infrastructure is mostly lacking. In addition, however, we found that due to significant differences between the conceptual frameworks of biomedicine and marine science, simply “porting” the biomedical text mining infrastructure to another domain will not suffice. One major difference is that the biomedical entities of interest are relatively well defined – genes, proteins, organisms, species, drugs, diseases, etc. – and typically expressed as proper nouns. In contrast, defining the entities of in</context>
</contexts>
<marker>Vossen, Rigau, Agirre, Soroa, Monachini, Bartolini, 2010</marker>
<rawString>Piek Vossen, German Rigau, Eneko Agirre, Aitor Soroa, Monica Monachini, and Roberto Bartolini. 2010. KYOTO: an open platform for mining facts. In Proceedings of the 6th Workshop on Ontologies and Lexical Resources , pages 1–10, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ce Zhang</author>
<author>Vidhya Govindaraju</author>
<author>Jackson Borchardt</author>
<author>Tim Foltz</author>
<author>Christopher R´e</author>
<author>Shanan Peters</author>
</authors>
<title>GeoDeepDive: Statistical inference using familiar data-processing languages.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data, SIGMOD ’13,</booktitle>
<pages>993--996</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Zhang, Govindaraju, Borchardt, Foltz, R´e, Peters, 2013</marker>
<rawString>Ce Zhang, Vidhya Govindaraju, Jackson Borchardt, Tim Foltz, Christopher R´e, and Shanan Peters. 2013. GeoDeepDive: Statistical inference using familiar data-processing languages. In Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data, SIGMOD ’13, pages 993– 996, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
<author>Dina Demner-Fushman</author>
</authors>
<title>Advanced Literature-Mining Tools. In</title>
<date>2009</date>
<pages>347--380</pages>
<editor>David Edwards, Jason Stajich, and David Hansen, editors, Bioinformatics,</editor>
<publisher>Springer</publisher>
<location>New York.</location>
<contexts>
<context position="2193" citStr="Zweigenbaum and Demner-Fushman, 2009" startWordPosition="317" endWordPosition="321">ecialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, proteins, drugs, symptoms and diseases), extraction of biological relations (e.g., protein-protein interaction, diseas</context>
</contexts>
<marker>Zweigenbaum, Demner-Fushman, 2009</marker>
<rawString>Pierre Zweigenbaum and Dina Demner-Fushman. 2009. Advanced Literature-Mining Tools. In David Edwards, Jason Stajich, and David Hansen, editors, Bioinformatics, pages 347–380. Springer New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
<author>Dina Demner-Fushman</author>
<author>Hong Yu</author>
<author>Kevin B Cohen</author>
</authors>
<title>Frontiers of biomedical text mining: current progress.</title>
<date>2007</date>
<journal>Briefings in Bioinformatics,</journal>
<volume>8</volume>
<issue>5</issue>
<contexts>
<context position="2082" citStr="Zweigenbaum et al., 2007" startWordPosition="303" endWordPosition="306">inspect all mentions of a particular variable type in the text as well as any generalisations or specialisations. The approach is demonstrated on a corpus of 10k abstracts of Nature publications in the field of Marine science. We discuss experiences with this early prototype and outline a number of possible improvements and directions for future research. 1 Introduction Text mining of scientific literature originates from efforts to cope with the ever growing flood of publications in biomedicine (Swanson, 1986; Swanson, 1988; Swanson and Smalheiser, 1997; Hearst, 1999; Ananiadou et al., 2006; Zweigenbaum et al., 2007; Cohen and Hersh, 2005; Krallinger et al., 2008; Rodriguez-Esteban, 2009; Zweigenbaum and Demner-Fushman, 2009; Ananiadou et al., 2010; Simpson and Demner-Fushman, 2012; Ananiadou et al., 2014). Consequently the resulting approaches, methods, tools and applications – as well as data, corpora and evaluation tasks – are rooted in the paradigm of biomedical research and its conceptual framework. Typical source text consists of abstracts from PubMed or full-text articles from PubMed Central. Standard tasks include recognition, normalisation and mapping of biological entities (e.g., genes, protein</context>
</contexts>
<marker>Zweigenbaum, Demner-Fushman, Yu, Cohen, 2007</marker>
<rawString>Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu, and Kevin B. Cohen. 2007. Frontiers of biomedical text mining: current progress. Briefings in Bioinformatics, 8(5):358–375, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>