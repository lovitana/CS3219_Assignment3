<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.923669">
Syntax-based Rewriting for Simultaneous Machine Translation
</title>
<author confidence="0.996546">
He He
</author>
<affiliation confidence="0.710061428571429">
Computer Science
University of Maryland
hhe@cs.umd.edu
Computer Science
University of Colorado
{Alvin.Grissom,
Jordan.Boyd.Graber}
</affiliation>
<email confidence="0.959888">
@colorado.edu
</email>
<affiliation confidence="0.8953105">
Computer Science and UMIACS
University of Maryland
</affiliation>
<email confidence="0.954808">
hal@cs.umd.edu
</email>
<note confidence="0.933832">
Alvin Grissom II, Jordan Boyd-Graber Hal Daumé III
</note>
<sectionHeader confidence="0.97693" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999716578947369">
Divergent word order between languages
causes delay in simultaneous machine
translation. We present a sentence rewrit-
ing method that generates more mono-
tonic translations to improve the speed-
accuracy tradeoff. We design grammati-
cality and meaning-preserving syntactic
transformation rules that operate on con-
stituent parse trees. We apply the rules
to reference translations to make their
word order closer to the source language
word order. On Japanese-English transla-
tion (two languages with substantially dif-
ferent structure), incorporating the rewrit-
ten, more monotonic reference translation
into a phrase-based machine translation
system enables better translations faster
than a baseline system that only uses gold
reference translations.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999859610169491">
Simultaneous interpretation is challenging because
it demands both quality and speed. Conventional
batch translation waits until the entire sentence is
completed before starting to translate. This merely
optimizes translation quality and often introduces
undesirable lag between the speaker and the audi-
ence. Simultaneous interpretation instead requires
a tradeoff between quality and speed. A common
strategy is to translate independently translatable
segments as soon as possible. Various segmenta-
tion methods (Fujita et al., 2013; Oda et al., 2014)
reduce translation delay; they are limited, however,
by the unavoidable word reordering between lan-
guages with drastically different word orders. We
show an example of Japanese-English translation
in Figure 1. Consider the batch translation: in En-
glish, the verb change comes immediately after the
subject We, whereas in Japanese it comes at the end
of the sentence; therefore, to produce an intelligible
English sentence, we must translate the object after
the final verb is observed, resulting in one large and
painfully delayed segment.
To reduce structural discrepancy, we can apply
syntactic transformations to make the word order
of one language closer to the other. Consider the
monotone translation in Figure 1. By passivizing
the English sentence, we can cache the subject and
begin translating before observing the final verb.
Furthermore, by using the English possessive, we
mimic the order of the Japanese genitive construc-
tion. These transformations enable us to divide the
input into shorter segments, thus reducing transla-
tion delay.
To produce such monotone translations, a
straightforward approach is to incorporate inter-
pretation data into the learning of a machine trans-
lation (MT) system, because human interpreters
use a variety of strategies (Shimizu et al., 2014;
Camayd-Freixas, 2011; Tohyama and Matsubara,
2006) to fine-tune the word order. Shimizu et
al. (2013) shows that this approach improves the
speed-accuracy tradeoff. However, existing paral-
lel simultaneous interpretation corpora (Shimizu
et al., 2014; Matsubara et al., 2002; Bendazzoli
and Sandrelli, 2005) are often small, and collecting
new data is expensive due to the inherent costs of
recording and transcribing speeches (Paulik and
Waibel, 2010). In addition, due to the intense time
pressure during interpretation, human interpreta-
tion has the disadvantage of simpler, less precise
diction (Camayd-Freixas, 2011; Al-Khanji et al.,
2000) compared to human translations done at the
translator’s leisure, allowing for more introspection
and precise word choice.
We aim to address the data scarcity problem and
combine translators’ lexical precision and inter-
preters’ syntactic flexibility. We propose to rewrite
the reference translation in a way that uses the
original lexicon, obeys standard grammar rules of
</bodyText>
<page confidence="0.987068">
55
</page>
<note confidence="0.96828125">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 55–64,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
Source: ��� ��� �� � ��� �� ��� �
We-TOP government-GEN structure and composition-ACC change should COP
</note>
<figure confidence="0.15387825">
Batch: ���  ||�������������� �
We should change the structure and composition of the government
Monotone: R/Z6J:  ||a96D  ||WV3,A ,*�  ||������
the government’s structure and composition should be changed by us
</figure>
<figureCaption confidence="0.952863333333333">
Figure 1: Divergent word order between language pairs can cause long delays in simultaneous translation:
Segments (||) mark the portions of the sentence that can be translated together. (Case markers: topic (TOP),
genitive (GEN), accusative (ACC), copula (COP).)
</figureCaption>
<bodyText confidence="0.999974555555556">
the target language, preserves the original seman-
tics, and yields more monotonic translations. We
then train the MT system with the rewritten refer-
ences so that it learns how to produce low-latency
translations from the data. A data-driven approach
to learning these rewriting rules is hampered by
the dearth of parallel data: we have few examples
of text that have been both interpreted and trans-
lated. Therefore, we design syntactic transforma-
tion rules based on linguistic analysis of the source
and the target languages. We apply these rules to
parsed text and decide whether to accept the rewrit-
ten sentence based on the amount of delay reduc-
tion. In this work, we focus on Japanese to English
translation, because (i) Japanese and English have
significantly different word orders (SOV vs. SVO);
and consequently, (ii) the syntactic constituents re-
quired earlier by an English sentence often come
late in the corresponding Japanese sentence.
We evaluate our approach using standard ma-
chine translation data (the Reuters newsfeed
Japanese-English corpus) in a simultaneous trans-
lation setting. Our experimental results show that
including the rewritten references into the learning
of a phrase-based MT system results in a better
speed-accuracy tradeoff against both the original
and the rewritten reference translations.
</bodyText>
<sectionHeader confidence="0.915149" genericHeader="introduction">
2 The Problem of Delay Reduction
</sectionHeader>
<bodyText confidence="0.99987645">
Simultaneous interpretation has two goals: produc-
ing good translations and producing them promptly.
However, most existing parallel corpora and MT
systems do not address the issue of delay during
translation. We explicitly adapt the training data
by rewriting rules to reduce delay. We first define
translation delay and describe—in general terms—
our rewriting rules. In the next section, we describe
the rules in more detail.
While we are motivated by real-time interpreta-
tion, to simplify our problem, we assume that we
have perfect text input. Given this constraint, a typ-
ical simultaneous interpretation system (Sridhar et
al., 2013; Fujita et al., 2013; Oda et al., 2014) pro-
duces partial translations of consecutive segments
in the source sentence and concatenates them to
produce a complete translation. We define the trans-
lation delay of a sentence as the average number
of tokens the system has to observe between trans-
lation of two consecutive segments (denoted by #
words/seg).1 For instance, the minimum delay of
1 word/seg is achieved when we translate immedi-
ately upon hearing a word. At test time, when the
input is segmented, the delay is the average seg-
ment length. During the data preprocessing step of
rewriting, we calculate delay from word alignments
(Section 4).
Given a reference batch translation x, we ap-
ply a set of rewriting rules R to x to minimize its
delay. A rewriting rule r E R is a mapping that
takes the constituent parse tree of x as input and
outputs a modified parse tree, which specifies a
rewritten sentence x&apos;. The tree-editing operation
includes node deletion, insertion, and swapping, as
well as induced changes of word form and node
label. A valid transformation rule should rearrange
constituents in x to follow the word order of the
input sentence as closely as possible, subject to
grammatical constraints and preservation of the
original meaning.
</bodyText>
<footnote confidence="0.5894175">
1Ideally, delay should be based on time lapse. However,
timestamping is not applicable to typical MT corpus, therefore
we approximate it by number of tokens and ignore decoding
time.
</footnote>
<page confidence="0.998667">
56
</page>
<sectionHeader confidence="0.993376" genericHeader="method">
3 Transformation Rules
</sectionHeader>
<bodyText confidence="0.999880666666667">
We design a variety of syntactic transformation
rules for Japanese-English translation motivated by
their structural differences. Our rules cover verb,
noun, and clause reordering. While we specifi-
cally focus on Japanese to English, many rules are
broadly applicable to SOV to SVO languages.
</bodyText>
<subsectionHeader confidence="0.998828">
3.1 Verb Phrases
</subsectionHeader>
<bodyText confidence="0.99994332">
The most significant difference between Japanese
and English is that the head of a verb phrase comes
at the end of Japanese sentences. In English, it occu-
pies one of the initial positions. We now introduce
rules that can postpone a head verb.
Passivization and Activization In Japanese, the
standard structure of a sentence is NP1 NP2 verb,
where case markers following the verb indicate
the voice of the sentence. However, in English, we
have NP1 verb NP2, where the form of the verb
indicates its voice. Changing the voice is particu-
larly useful when NP2 (object in an active-voice
sentence and subject in a passive-voice sentence)
is long. By reversing positions of verb and NP2,
we are not held back by the upcoming verb and can
start to translate NP2 immediately. Figure 1 shows
an example in which passive voice can help make
the target and source word orders more compatible,
but it is not the case that passivizing every sentence
would be a good idea; sometimes making a pas-
sive sentence active makes the word orders more
compatible if the objects are relatively short:
O: The talk was denied by the boycott group
spokesman.
R: The boycott group spokesman denied the talk.
Quotative Verbs Quotative verbs are verbs that,
syntactically and semantically, resemble said and
often start an independent clause. Such verbs are
frequent, especially in news, and can be moved to
the end of a sentence:
O: They announced that the president will re-
structure the division.
R: The president will restructure the division,
they announced.
In addition to quotative verbs, candidates typi-
cally include factive (e.g., know, realize, observe),
factive-like (e.g., announce, determine), belief (e.g.,
believe, think, suspect), and antifactive (e.g., doubt,
deny) verbs. When these verbs are followed by a
clause (S or SBAR), we move the verb and its sub-
ject to the end of the clause.
While some exploratory work automatically ex-
tracts factive verbs, to our knowledge, an exhaus-
tive list does not exist. To obtain a list with rea-
sonable coverage, we exploit the fact that Japanese
has an unambiguous quotative particle, to, that pre-
cedes such verbs.2 We identify all of the verbs in
the Kyoto corpus (Neubig, 2011) marked by the
quotative particle and translate them into English.
We then use these as our quotative verbs.3
</bodyText>
<subsectionHeader confidence="0.999252">
3.2 Noun Phrases
</subsectionHeader>
<bodyText confidence="0.99463075862069">
Another difference between Japanese and English
lies in the order of adjectives and the nouns they
modify. We identify two situations where we can
take advantage of the flexibility of English gram-
mar to favor sentence structures consistent with
positions of nouns in Japanese.
Genitive Reordering In Japanese, genitive con-
structions always occur in the form of X no Y,
where Y belongs to X. In English, however, the
order may be reversed through the of construction.
Therefore, we transform constructions NP1 of NP2
to possessives using the apostrophe-s, NP2’(s) NP1
(Figure 1). We use simple heuristics to decide if
such a transformation is valid. For example, when
X / Y contains proper nouns (e.g., the City of New
York), numbers (e.g., seven pounds of sugar), or
pronouns (e.g., most of them), changing them to the
possessive case is not legal.
that Clause In English, clauses are often modi-
fied through a pleonastic pronoun. E.g., It is ADJP
to/that SBAR/S. In Japanese, however, the subject
(clause) is usually put at the beginning. To be con-
sistent with the Japanese word order, we move the
modified clause to the start of the sentence: To
S/SBAR is ADJP. The rewritten English sentence
is still grammatical, although its structure is less
frequent in common English usage. For example,
O: It is important to remain watchful.
R: To remain watchful is important.
</bodyText>
<footnote confidence="0.770861166666667">
2We use a morphological analyzer to distinguish between
the conjunction and quotative particles. Examples of words
marked by this particle include J,hL6 (expect), ,a7
(say), &apos;uV,;bL6 (seem), 16 (assume), TpL&apos;6 (believe)
and so on.
3We also include the phrase It looks like.
</footnote>
<page confidence="0.995343">
57
</page>
<figure confidence="0.999680658536585">
Input: S (a) Detection: S (b) Modification: S
NP VP NP1 VP NP VP
NP2
VB*
is
PP
the
new
VBN
world
loved
IN
NP
swap NP1 and NP2
insert “be” before VB*
insert “by” before NP2
PRP
VBP
NP
We
love DT
NN
the
new
world
JJ
NN
JJ
VBZ
DT
VP
(c) Evaluation: by PRP
Target: We love the new world New target: The new world is loved by us
us
Source:
Delay:
We new world the love
1 4
Source: We new world the love
Delay:
2 1 2
</figure>
<figureCaption confidence="0.9886035">
Figure 2: An example of applying the passivization rule to create a translation reference that is more
monotonic.
</figureCaption>
<subsectionHeader confidence="0.99869">
3.3 Conjunction Clause
</subsectionHeader>
<bodyText confidence="0.984848">
In Japanese, clausal conjunctions are often marked
at the end of the initial clause of a compound sen-
tence. In English, however, the order of clauses is
more flexible. We can therefore reduce delay by
reordering the English clauses to mirror how they
typically appear in Japanese. Below we describe
rules reversing the order of clauses connected by
these conjunctions:
</bodyText>
<listItem confidence="0.999876333333333">
• Clausal conjunctions: because (of), in order
to
• Contrastive conjunctions: despite, even
though, although
• Conditionals: (even) if, as a result (of)
• Misc: according to
</listItem>
<bodyText confidence="0.9980913125">
In standard Japanese, such conjunctions include
no de, kara, de mo and so on. The sentence often
appears in the form of S2 conj, S1. In English,
however, two common constructions are
S1 conj S2: We should march because win-
ter is coming.
conj S2, S1: Because winter is coming, we
should march.
To follow the Japanese clause order, we adapt the
above two constructions to
S2, conj’ S1: Winter is coming, because of
this, we should march.
Here conj’ represents the original conjunction
word appended with simple pronouns/phrases to
refer to S2. For example, because → because of
this, even if → even if this is the case.
</bodyText>
<sectionHeader confidence="0.940592" genericHeader="method">
4 Sentence Rewriting Process
</sectionHeader>
<bodyText confidence="0.954827333333333">
We now turn our attention to the implementation of
the syntactic transformation rules described above.
Applying a transformation consists of three steps:
</bodyText>
<listItem confidence="0.987056333333333">
1. Detection: Identify nodes in the parse tree for
which the transformation is applicable;
2. Modification: Transform nodes and labels;
3. Evaluation: Compute delay reduction, and
decide whether to accept the rewritten sen-
tence.
</listItem>
<bodyText confidence="0.9986954375">
Figure 2 illustrates the process using passivization
as an example. In the detection step, we find the
subtree that satisfies the condition of applying a
rule. In this case, we look for an S node whose chil-
dren include an NP (denoted by NP1), the subject,
and a VP to its right, such that the VP node has
a leaf VB*, the main verb,4 followed by another
NP (denoted by NP2), the object. We allow the par-
ent nodes (S and VP) to have additional children
besides the matched ones. They are not affected
during the transformation. In the modification step,
we swap the subject node and object node; we add
the verb be in its correct form by checking the tense
of the verb and the form of NP2;5and we add the
preposition by before the subject. The process is
executed recursively throughout the parse tree.
</bodyText>
<footnote confidence="0.995401">
4The main verb excludes be and have when it indicates
tense (e.g., have done).
5We use the Nodebox linguistic library (https://www.
nodebox.net/code) to detect and modify word forms.
</footnote>
<page confidence="0.998136">
58
</page>
<bodyText confidence="0.999909733333333">
Although our rules are designed to minimize
long range reordering, there are exceptions.6 Thus
applying a rule does not always reduce delay. In
the evaluation step, we compare translation delay
before and after applying the rule. We accept a
rewritten sentence if its delay is reduced; other-
wise, we revert to the input sentence. Since we do
not segment sentences during rewriting, we must
estimate the delay.
To estimate the delay, we use word alignments.
Figure 2c shows the source Japanese sentence in
its word-for-word English translation and align-
ments from the target words to the source words.
The first English word, We, is aligned to the first
Japanese word; it can thus be treated as an inde-
pendent segment and translated immediately. The
second English word, love, is aligned to the last
Japanese word, which means the system cannot
start to translate until four more Japanese words
are revealed. This alignment therefore forms a seg-
ment with delay of four words/seg. Alignments of
the following words come before the source word
aligned to love; hence, they are already translated
in the previous segment and we do not double count
their delay. In this example, the delay of the orig-
inal sentence is 2.5 word/seg; after rewriting, it
is reduced to 1.7 word/seg. Therefore, we accept
the rewritten sentence. However, when the subject
phrase is long and the object phrase is short, a swap
may not reduce delay.
We can now formally define the delay. Let ei be
the ith target word in the input sentence x and ai
be the maximum index among indices of source
words that ei aligned to. We define the delay of ei
as di = max(0, ai − maxj&lt;i aj). The delay of x is
then EN i=1 di/N, where the sum is over all aligned
words except punctuation and stopwords.
Given a set of rules, we need to decide which
rules to apply and in what order. Fortunately, our
rules have little interaction with each other, and
the order of application has a negligible effect. We
apply the rules, roughly, sequentially in order of
complexity: if the output of current rule is not ac-
cepted, the sentence is reverted to the last accepted
version.
</bodyText>
<table confidence="0.999508">
Train Tune Test
Ja 21.3M 30.2k 23.3k
En-GD 16.8M 23.8k 18.5k
En-RW 16.8M 24.1k 18.7k
</table>
<tableCaption confidence="0.997488">
Table 1: Number of words in the training, tuning,
</tableCaption>
<bodyText confidence="0.7302615">
and test datasets. En-GD and En-RW represent the
gold reference set and the rewritten reference set.
</bodyText>
<sectionHeader confidence="0.999082" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999991043478261">
We evaluate our method on the Reuters Japanese-
English corpus of news articles (Utiyama and Isa-
hara, 2003). For training the MT system, we also
include the EIJIRO dictionary entries and the ac-
companying example sentences.7 Statistics of the
dataset are shown in Table 1. The rewritten trans-
lation is generally slightly longer than the gold
translation because our rewriting often involves
inserting pronouns (e.g. it, this) for antecedents.
We use the TreebankWordTokenizer
from NLTK (Bird et al., 2009) to tokenize En-
glish sentences and Kuromoji Japanese mor-
phological analyzer8 to tokenize Japanese sen-
tences. Our phrase-based MT system is trained
by Moses (Koehn et al., 2003) with standard
parameters settings. We use GIZA++ (Och and
Ney, 2003) for word alignment and k-best batch
MIRA (Cherry and Foster, 2012) for tuning. The
translation quality is evaluated by BLEU (Papineni
et al., 2002) and RIBES (Isozaki et al., 2010).9 To
obtain the parse trees for English sentences, we use
the Stanford Parser (Klein and Manning, 2003) and
the included English model.
</bodyText>
<subsectionHeader confidence="0.999634">
5.1 Quality of Rewritten Translations
</subsectionHeader>
<bodyText confidence="0.996923625">
After applying the rewriting rules (Section 4), Ta-
ble 2 shows the percentage of sentences that are
candidates and how many rewrites are accepted.
The most generalizable rules are passivization and
delaying quotative verbs. We rewrite 32.2% of sen-
tences, reducing the delay from 9.9 words/seg to
6.3 words/seg per segment for rewritten sentences
and from 7.8 words/seg to 6.7 words/seg overall.
</bodyText>
<footnote confidence="0.997719875">
6For example, in clause transformation, the Japanese con-
junction moshi, which is clause initial, may appear at the
beginning of a sentence to emphasize conditionals, although
its appearance is relatively rare.
7Available at http://eijiro.jp
8Available at http://www.atilika.org/
9In contrast to BLEU, RIBES is an order-sensitive metric
commonly used for translation between Japanese and English.
</footnote>
<page confidence="0.997508">
59
</page>
<table confidence="0.959226333333333">
verb voice noun conj.
Applicable % 39.9 50.0 26.4 4.8
Accepted % 22.5 24.0 51.2 38.4
</table>
<tableCaption confidence="0.986925">
Table 2: Percentage of sentences that each rule
</tableCaption>
<bodyText confidence="0.970823307692308">
category can be applied to (Applicable) and the
percentage of sentences for which the rule results
in a more monotonic sentence (Accepted).
We evaluate the quality of our rewritten sen-
tences from two perspectives: grammaticality and
preserved semantics. To examine how close the
rewritten sentences are to standard English, we
train a 5-gram language model using the English
data from the Europarl corpus, consisting of 46
million words, and use it to compute perplexity.
Rewriting references increases the perplexity un-
der the language model only slightly: from 332.0
to 335.4. To ensure that rewrites leave meaning
unchanged, we use the SEMAFOR semantic role
labeler (Das et al., 2014) on the original and mod-
ified sentence; for each role-labeled token in the
reference sentence, we examine its corresponding
role in the rewritten sentence and calculate the aver-
age accuracy acrosss all sentences. Even ignoring
benign lexical changes—for example, he becom-
ing him in a passivized sentence—95.5% of the
words retain their semantic roles in the rewritten
sentences.
Although our rules are conservative to minimize
corruption, some errors are unavoidable propaga-
tion of parser errors. For example, the sentence the
London Stock Exchange closes at 1230 GMT today
is parsed as:10
(S (NP the London Stock Exchange)
(VP (VBZ closes)
(PP at 1230)
(NP GMT today)))
GMT today is separated from the PP as an NP and is
mistaken as the object. The passive version is then
GMT today is closed at 1230 by the London Stock
Exchange. Such errors could be reduced by skip-
ping nodes with low inside/outside scores given
by the parser, or skipping low-frequency patterns.
However, we leave this for future work.
</bodyText>
<subsectionHeader confidence="0.998068">
5.2 Segmentation
</subsectionHeader>
<bodyText confidence="0.972183684210526">
At test time, we use right probability (Fujita et
al., 2013, RP) to decide when to start translating a
10For simplicity we show the shallow parse only.
sentence. As we read in the source Japanese sen-
tence, if the input segment matches an entry in
the learned phrase table, we query the RP of the
Japanese/English phrase pair. A higher RP indicates
that the English translation of this Japanese phrase
will likely be followed by the translation of the
next Japanese phrase. In other words, translation
of the two consecutive Japanese phrases is mono-
tonic, thus, we can begin translating immediately.
Following (Fujita et al., 2013), if the RP of the
current phrase is lower than a fixed threshold, we
cache the current phrase and wait for more words
from the source sentence; otherwise, we translate
all cached phrases. Finally, translations of segments
are concatenated to form a complete translation of
the input sentence.
</bodyText>
<subsectionHeader confidence="0.998534">
5.3 Speed/Accuracy Trade-off
</subsectionHeader>
<bodyText confidence="0.999851">
To show the effect of rewritten references, we com-
pare the following MT systems:
</bodyText>
<listItem confidence="0.975744714285714">
• GD: only gold reference translations;
• RW: only rewritten reference translations;
• RW+GD: both gold and the rewritten refer-
ences; and
• RW-LM+GD: using gold reference transla-
tions but using the rewritten references for
training the LM and for tuning.
</listItem>
<bodyText confidence="0.999849208333333">
For RW+GD and RW-LM+GD, we interpolate the
language models of GD and RW. The interpolat-
ing weight is tuned with the rewritten sentences.
For RW+GD, we combine the translation models
(phrase tables and reordering tables) of RW and
GD by fill-up combination (Bisazza et al., 2011),
where all entries in the tables of RW are preserved
and entries from the tables of GD are added if new.
Increasing the RP threshold increases interpreta-
tion delay but improves the quality of the transla-
tion. We set the RP threshold at 0.0, 0.2, 0.4, 0.8
and finally 1.0 (equivalent to batch translation).
Figure 3 shows the BLEU/RIBES scores vs. the
number of words per segement as we increase the
threshold. Rewritten sentences alone do not sig-
nificantly improve over the baseline. We suspect
this is because the transformation rules sometimes
generate ungrammatical sentences due to parsing
errors, which impairs learning. However, combin-
ing RW and GD results in a better speed-accuracy
tradeoff: the RW+GD curve completely dominates
other curves in Figure 3a, 3c. Thus, using more
monotone translations improves simultaneous ma-
chine translation, and because RW-LM+GD is about
</bodyText>
<page confidence="0.970041">
60
</page>
<figure confidence="0.9986005">
62.5
62.0
61.5
RIBES
61.0
60.5
60.0
18
17
16
BLEU
15
14
13
12
RW+GD
RW-LM+GD
RW
GD
5 10 15 20 25 30 35
Average # of words per segment
RW+GD
RW-LM+GD
RW
GD
59.50 5 10 15 20 25 30 35
Average # of words per segment
110
(a) BLEU w.r.t. gold ref (b) RIBES w.r.t. gold ref
18
17
16
15
14
13
12
11
100 5 10 15 20 25 30 35
Average # of words per segment
(c) BLEU w.r.t. rewritten ref (d) RIBES w.r.t. rewritten ref
</figure>
<figureCaption confidence="0.970171">
Figure 3: Speed/accuracy tradeoff curves: BLEU (left) / RIBES (right) versus translation delay (average
number of words per segment).
</figureCaption>
<figure confidence="0.997258166666667">
BLEU
RW+GD
RW-LM+GD
RW
GD
RIBES
62.0
61.0
62.5
61.5
59.50 5 10 15 20 25 30 35
Average # of words per segment
RW+GD
RW-LM+GD
RW
GD
60.5
60.0
</figure>
<bodyText confidence="0.993666636363637">
the same as GD, the major improvement likely
comes from the translation model from rewritten
sentences.
The right two plots recapitulate the evaluation
with the RIBES metric. This result is less clear, as
MT systems are optimized for BLEU and RIBES
penalizes word reordering, making it difficult to
compare systems that intentionally change word
order. Nevertheless, RW is comparable to GD on
gold references and superior to the baseline on
rewritten references.
</bodyText>
<subsectionHeader confidence="0.998242">
5.4 Effect on Verbs
</subsectionHeader>
<bodyText confidence="0.99993325">
Rewriting training data not only creates lower la-
tency simultaneous translations, but it also im-
proves batch translation. One reason is that SOV
to SVO translation often drops the verb because of
long range reordering. (We see this for Japanese
here, but this is also true for German.) Similar word
orders in the source and target results in less re-
ordering and improves phrase-based MT (Collins
</bodyText>
<table confidence="0.679641">
Translation
GD RW RW+GD Gold ref
# of verbs 1971 2050 2224 2731
</table>
<tableCaption confidence="0.853047">
Table 3: Number of verbs in the test set transla-
</tableCaption>
<bodyText confidence="0.99805125">
tion produced by different models and the gold
reference translation. Boldface indicates the num-
ber is significantly larger than others (excluding
the gold ref) according to two-sample t-tests with
p &lt; 0.001.
et al., 2005; Xu et al., 2009). Table 3 shows the
number of verbs in the translations of the test sen-
tences produced by GD, RW, RW+GD, as well as
the number in the gold reference translation. Both
RW and RW+GD produce more verbs (a statistically
significant result), although RW+GD captures the
most verbs.
</bodyText>
<page confidence="0.998348">
61
</page>
<bodyText confidence="0.971689">
he also said that the real dangers for the euro lay in the
Ref potential for divergences in the domestic policy needs
among the various participating nations of the single
currency.
he also for the euro, is a real danger to launch a single
GD currency in many different countries and domestic
policies on the need for the possibility of a difference.
he also for the euro is a real danger to launch a single
currency in many different countries and domestic
policies to the needs of the possibility of a difference,
he said.
</bodyText>
<tableCaption confidence="0.926343">
Table 4: Example of translation produced by GD
and RW.
</tableCaption>
<subsectionHeader confidence="0.946428">
5.5 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999574375">
Table 4 compares translations by GD and RW. RW
correctly puts the verb said at the end, while GD
drops the final verb. However, RW still produces he
at the beginning (also the first word in the Japanese
source sentence). This is because our current seg-
mentation strategy do not preserve words for later
translation—a note-taking strategy used by human
interpreters.
</bodyText>
<sectionHeader confidence="0.999842" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999949574074074">
Previous approaches to simultaneous machine
translation have employed explicit interpretation
strategies for coping with delay. Two major ap-
proaches are segmentation and prediction.
Most segmentation strategies are based on
heuristics, such as pauses in speech (Fügen et
al., 2007; Bangalore et al., 2009), comma predic-
tion (Sridhar et al., 2013) and phrase reordering
probability (Fujita et al., 2013). Learning-based
methods have also been proposed. Oda et al. (2014)
find segmentations that maximize the BLEU score
of the final concatenated translation by dynamic
programming. Grissom II et al. (2014) formulate
simultaneous translation as a sequential decision
making problem and uses reinforcement learning
to decide when to translate. One limitation of these
methods is that when learning with standard batch
MT corpus, their gain can be restricted by natural
word reordering between the source and the target
sentences, as explained in Section 1.
In an SOV-SVO context, methods to predict un-
seen words are proposed to alleviate the above re-
striction. Matsubara et al. (1999) predict the En-
glish verb in the target sentence and integrates it
syntactically. Grissom II et al. (2014) predict the fi-
nal verb in the source sentence and decide when to
use the predicted verb with reinforcement learning.
Nevertheless, unless the predictor considers con-
textual and background information, which human
interpreters often rely on for prediction (Hönig,
1997; Camayd-Freixas, 2011), such a prediction
task is inherently hard.
Unlike previous approaches to simultaneous
translation, we directly adapt the training data and
transform a translated sentence to an “interpreted”
one. We can, therefore, take advantage of the abun-
dance of parallel batch-translated corpora for train-
ing a simultaneous MT system. In addition, as a data
preprocessing step, our approach is orthogonal to
the others, with which it can be easily combined.
This work is also related to preprocessing re-
ordering approaches (Xu et al., 2009; Collins et
al., 2005; Galley and Manning, 2008; Hoshino et
al., 2013; Hoshino et al., 2014) in batch MT for
language pairs with substantially different word or-
ders. However, our problem is different in several
ways. First, while the approaches resemble each
other, our motivation is to reduce translation delay.
Second, they reorder the source sentence, which is
nontrivial and time-consuming when the sentence
is incrementally revealed. Third, rewriting the tar-
get sentence requires the output to be grammatical
(for it to be used as reference translation), which is
not a concern when rewriting source sentences.
</bodyText>
<sectionHeader confidence="0.998451" genericHeader="method">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99994695">
Training MT systems with more monotonic
(interpretation-like) sentences improves the speed-
accuracy tradeoff for simultaneous machine trans-
lation. By designing syntactic transformations and
rewriting batch translations into more monotonic
translations, we reduce the translation delay. MT
systems trained on the rewritten reference transla-
tions learn interpretation strategies implicitly from
the data.
Our rewrites are based on linguistic knowledge
and inspired by techniques used by human inter-
preters. They cover a wide range of reordering phe-
nomena between Japanese and English, and more
generally, between SOV and SVO languages. A nat-
ural extension is to automatically extract such rules
from parallel corpora. While there exist approaches
that extract syntactic tree transformation rules auto-
matically, one of the difficulties is that most parallel
corpora is dominated by lexical paraphrasing in-
stead of syntactic paraphrasing.
</bodyText>
<sectionHeader confidence="0.492715" genericHeader="conclusions">
RW
</sectionHeader>
<page confidence="0.997216">
62
</page>
<sectionHeader confidence="0.99816" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999525">
This work was supported by NSF grant IIS-
1320538. Boyd-Graber is also partially supported
by NSF grants CCF-1409287 and NCSE-1422492.
Daumé III and He are also partially supported by
NSF grant IIS-0964681. Any opinions, findings,
conclusions, or recommendations expressed here
are those of the authors and do not necessarily re-
flect the view of the sponsor.
</bodyText>
<sectionHeader confidence="0.997789" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999680957446808">
Raja Al-Khanji, Said El-Shiyab, and Riyadh Hussein.
2000. On the use of compensatory strategies in si-
multaneous interpretation. Journal des Traducteurs,
45(3):548–577.
Srinivas Bangalore, Vivek Kumar Rangarajan Srid-
har, Prakash Kolan, Ladan Golipour, and Aura
Jimene. 2009. Real-time incremental speech-to-
speech translation of dialogs. In Proceedings of the
Conference of the North American Chapter of the As-
sociation for Computational Linguistics (NAACL).
Claudio Bendazzoli and Annalisa Sandrelli. 2005. An
approach to corpus-based interpreting studies: De-
veloping EPIC (european parliament interpreting
corpus). In Proceedings of Challenges of Multidi-
mensional Translation.
Steven Bird, Ewan Klein, and Edward Loper.
2009. Natural Language Processing with Python.
O’Reilly Media.
Arianna Bisazza, Nick Ruiz, and Marcello Federico.
2011. Fill-up versus interpolation methods for
phrase-based SMT adaptation. In Proceedings of In-
ternational Workshop on Spoken Language Transla-
tion (IWSLT).
Erik Camayd-Freixas. 2011. Cognitive theory of si-
multaneous interpreting and training. In Proceed-
ings of the 52nd Conference of the American Trans-
lators Association.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the Conference of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL).
Michael Collins, Philipp Koehn, and Ivona Kuˇcerová.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the annual meet-
ing of the Association for Computational Linguistics
(ACL).
Dipanjan Das, Desai Chen, André F. T. Martins, Nathan
Schneider, , and Noah A. Smith. 2014. Frame-
semantic parsing. Computational Linguistics, 40(1).
Christian Fügen, Alex Waibel, , and Muntsin Kolss.
2007. Simultaneous translation of lectures and
speeches. Machine Translation, 21(4):209–252.
Tomoki Fujita, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2013. Simple,
lexicalized choice of translation timing for simulta-
neous speech translation. In Proceedings of Inter-
speech.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of Empirical Methods in Nat-
ural Language Processing (EMNLP).
Alvin C. Grissom II, He He, Jordan Boyd-Graber, John
Morgan, and Hal Daumé III. 2014. Don’t until
the final verb wait: Reinforcement learning for si-
multaneous machine translation. In Proceedings of
Empirical Methods in Natural Language Processing
(EMNLP).
Hans G. Hönig. 1997. Using text mappings in teach-
ing consecutive interpreting. Translation and Trans-
lation Theory, pages 19–34.
Sho Hoshino, Yusuke Miyao, Katsuhito Sudoh, and
Masaaki Nagata. 2013. Two-stage pre-ordering for
Japanese-to-English statistical machine translation.
In International Joint Conference on Artificial Intel-
ligence (IJCNLP).
Sho Hoshino, Hubert Soyer, Yusuke Miyao, and Akiko
Aizawa. 2014. Japanese to english machine transla-
tion using preordering and compositional distributed
semantics. In Workshop on Asian Translation.
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito
Sudoh, and Hajime Tsukada. 2010. Automatic
evaluation of translation quality for distant language
pairs. In Proceedings of Empirical Methods in Nat-
ural Language Processing (EMNLP).
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of the an-
nual meeting of the Association for Computational
Linguistics (ACL).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Brooke Cowan
Nicola Bertoldi, Wade Shen, Richard Zens Chris-
tine Moran, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbs. 2003. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the annual meeting of the Associa-
tion for Computational Linguistics (ACL).
Shigeki Matsubara, Katsuhiko Toyama, and Yasuyoshi
Inagaki. 1999. Sync/trans: Simultaneous machine
interpretation between English and Japanese. In Ad-
vanced Topics in Artificial Intelligence, pages 134–
143. Springer.
Shigeki Matsubara, Akira Takagi, Nobuo Kawaguchi,
and Yasuyoshi Inagaki. 2002. Bilingual spoken
</reference>
<page confidence="0.987228">
63
</page>
<reference confidence="0.998204607142857">
monologue corpus for simultaneous machine inter-
pretation research. In Proceedings of the Language
Resources and Evaluation Conference (LREC).
Graham Neubig. 2011. The Kyoto free translation task.
Available online at http://www. phontron. com/kftt.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Yusuke Oda, Graham Neubig, Sakriani Sakti, Tomoki
Toda, and Satoshi Nakamura. 2014. Optimizing seg-
mentation strategies for simultaneous speech transla-
tion. In Proceedings of the Association for Compu-
tational Linguistics (ACL), June.
Kishore Papineni, Salim Roukos, Todd Ward, , and
Wei-Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the annual meeting of the Association for Computa-
tional Linguistics (ACL).
Matthias Paulik and Alex Waibel. 2010. Spoken lan-
guage translation from parallel speech audio: Simul-
taneous interpretation as slt training data. In Pro-
ceedings of the International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP).
Hiroaki Shimizu, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2013. Con-
structing a speech translation system using simulta-
neous interpretation data. In Proceedings of Inter-
national Workshop on Spoken Language Translation
(IWSLT).
Hiroaki Shimizu, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2014. Collec-
tion of a simultaneous translation corpus for compar-
ative analysis. In International Language Resources
and Evaluation (LREC).
Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas
Bangalore Andrej Ljolje, and Rathinavelu Chengal-
varayan. 2013. Segmentation strategies for stream-
ing speech translation. In Proceedings of the Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics (NAACL).
Hitomi Tohyama and Shigeki Matsubara. 2006. Col-
lection of simultaneous interpreting patterns by us-
ing bilingual spoken monologue corpus. In Proceed-
ings of the Language Resources and Evaluation Con-
ference (LREC).
Masao Utiyama and Hitoshi Isahara. 2003. Reliable
measures for aligning japanese-english news articles
and sentences. In Proceedings of the annual meet-
ing of the Association for Computational Linguistics
(ACL).
Peng Xu, Jaeho Kang, Michael Ringgaard, , and Franz
Och. 2009. Using a dependency parser to improve
SMT for subject-object-verb language. In Proceed-
ings of the Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL).
</reference>
<page confidence="0.999403">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.792008">
<title confidence="0.999721">Syntax-based Rewriting for Simultaneous Machine Translation</title>
<author confidence="0.928678">He</author>
<affiliation confidence="0.992266">Computer University of</affiliation>
<email confidence="0.997409">hhe@cs.umd.edu</email>
<affiliation confidence="0.9782145">Computer University of</affiliation>
<email confidence="0.995622">@colorado.edu</email>
<affiliation confidence="0.9940315">Science and University of</affiliation>
<email confidence="0.997703">hal@cs.umd.edu</email>
<author confidence="0.92227">Alvin Grissom Jordan Boyd-Graber Hal Daumé</author>
<abstract confidence="0.9994426">Divergent word order between languages causes delay in simultaneous machine translation. We present a sentence rewriting method that generates more monotonic translations to improve the speedaccuracy tradeoff. We design grammaticality and meaning-preserving syntactic transformation rules that operate on constituent parse trees. We apply the rules to reference translations to make their word order closer to the source language word order. On Japanese-English translation (two languages with substantially different structure), incorporating the rewritten, more monotonic reference translation into a phrase-based machine translation system enables better translations faster than a baseline system that only uses gold reference translations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Raja Al-Khanji</author>
<author>Said El-Shiyab</author>
<author>Riyadh Hussein</author>
</authors>
<title>On the use of compensatory strategies in simultaneous interpretation.</title>
<date>2000</date>
<journal>Journal des Traducteurs,</journal>
<volume>45</volume>
<issue>3</issue>
<contexts>
<context position="3579" citStr="Al-Khanji et al., 2000" startWordPosition="507" endWordPosition="510">; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (Camayd-Freixas, 2011; Al-Khanji et al., 2000) compared to human translations done at the translator’s leisure, allowing for more introspection and precise word choice. We aim to address the data scarcity problem and combine translators’ lexical precision and interpreters’ syntactic flexibility. We propose to rewrite the reference translation in a way that uses the original lexicon, obeys standard grammar rules of 55 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 55–64, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Source: ��� ��� �� � ��� �� ��� � </context>
</contexts>
<marker>Al-Khanji, El-Shiyab, Hussein, 2000</marker>
<rawString>Raja Al-Khanji, Said El-Shiyab, and Riyadh Hussein. 2000. On the use of compensatory strategies in simultaneous interpretation. Journal des Traducteurs, 45(3):548–577.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Vivek Kumar Rangarajan Sridhar</author>
<author>Prakash Kolan</author>
<author>Ladan Golipour</author>
<author>Aura Jimene</author>
</authors>
<title>Real-time incremental speech-tospeech translation of dialogs.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="27618" citStr="Bangalore et al., 2009" startWordPosition="4490" endWordPosition="4493">he verb said at the end, while GD drops the final verb. However, RW still produces he at the beginning (also the first word in the Japanese source sentence). This is because our current segmentation strategy do not preserve words for later translation—a note-taking strategy used by human interpreters. 6 Related Work Previous approaches to simultaneous machine translation have employed explicit interpretation strategies for coping with delay. Two major approaches are segmentation and prediction. Most segmentation strategies are based on heuristics, such as pauses in speech (Fügen et al., 2007; Bangalore et al., 2009), comma prediction (Sridhar et al., 2013) and phrase reordering probability (Fujita et al., 2013). Learning-based methods have also been proposed. Oda et al. (2014) find segmentations that maximize the BLEU score of the final concatenated translation by dynamic programming. Grissom II et al. (2014) formulate simultaneous translation as a sequential decision making problem and uses reinforcement learning to decide when to translate. One limitation of these methods is that when learning with standard batch MT corpus, their gain can be restricted by natural word reordering between the source and </context>
</contexts>
<marker>Bangalore, Sridhar, Kolan, Golipour, Jimene, 2009</marker>
<rawString>Srinivas Bangalore, Vivek Kumar Rangarajan Sridhar, Prakash Kolan, Ladan Golipour, and Aura Jimene. 2009. Real-time incremental speech-tospeech translation of dialogs. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Bendazzoli</author>
<author>Annalisa Sandrelli</author>
</authors>
<title>An approach to corpus-based interpreting studies: Developing EPIC (european parliament interpreting corpus).</title>
<date>2005</date>
<booktitle>In Proceedings of Challenges of Multidimensional Translation.</booktitle>
<contexts>
<context position="3242" citStr="Bendazzoli and Sandrelli, 2005" startWordPosition="457" endWordPosition="460"> enable us to divide the input into shorter segments, thus reducing translation delay. To produce such monotone translations, a straightforward approach is to incorporate interpretation data into the learning of a machine translation (MT) system, because human interpreters use a variety of strategies (Shimizu et al., 2014; Camayd-Freixas, 2011; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (Camayd-Freixas, 2011; Al-Khanji et al., 2000) compared to human translations done at the translator’s leisure, allowing for more introspection and precise word choice. We aim to address the data scarcity problem and combine translators’ lexical precision and interpreters’ syntactic flexibility. We propose t</context>
</contexts>
<marker>Bendazzoli, Sandrelli, 2005</marker>
<rawString>Claudio Bendazzoli and Annalisa Sandrelli. 2005. An approach to corpus-based interpreting studies: Developing EPIC (european parliament interpreting corpus). In Proceedings of Challenges of Multidimensional Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python. O’Reilly Media.</booktitle>
<contexts>
<context position="18453" citStr="Bird et al., 2009" startWordPosition="2970" endWordPosition="2973"> and test datasets. En-GD and En-RW represent the gold reference set and the rewritten reference set. 5 Experiments We evaluate our method on the Reuters JapaneseEnglish corpus of news articles (Utiyama and Isahara, 2003). For training the MT system, we also include the EIJIRO dictionary entries and the accompanying example sentences.7 Statistics of the dataset are shown in Table 1. The rewritten translation is generally slightly longer than the gold translation because our rewriting often involves inserting pronouns (e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters settings. We use GIZA++ (Och and Ney, 2003) for word alignment and k-best batch MIRA (Cherry and Foster, 2012) for tuning. The translation quality is evaluated by BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010).9 To obtain the parse trees for English sentences, we use the Stanford Parser (Klein and Manning, 2003) and the included English model. 5.1 Quality of Rewritten Translations</context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python. O’Reilly Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arianna Bisazza</author>
<author>Nick Ruiz</author>
<author>Marcello Federico</author>
</authors>
<title>Fill-up versus interpolation methods for phrase-based SMT adaptation.</title>
<date>2011</date>
<booktitle>In Proceedings of International Workshop on Spoken Language Translation (IWSLT).</booktitle>
<contexts>
<context position="23258" citStr="Bisazza et al., 2011" startWordPosition="3741" endWordPosition="3744">de-off To show the effect of rewritten references, we compare the following MT systems: • GD: only gold reference translations; • RW: only rewritten reference translations; • RW+GD: both gold and the rewritten references; and • RW-LM+GD: using gold reference translations but using the rewritten references for training the LM and for tuning. For RW+GD and RW-LM+GD, we interpolate the language models of GD and RW. The interpolating weight is tuned with the rewritten sentences. For RW+GD, we combine the translation models (phrase tables and reordering tables) of RW and GD by fill-up combination (Bisazza et al., 2011), where all entries in the tables of RW are preserved and entries from the tables of GD are added if new. Increasing the RP threshold increases interpretation delay but improves the quality of the translation. We set the RP threshold at 0.0, 0.2, 0.4, 0.8 and finally 1.0 (equivalent to batch translation). Figure 3 shows the BLEU/RIBES scores vs. the number of words per segement as we increase the threshold. Rewritten sentences alone do not significantly improve over the baseline. We suspect this is because the transformation rules sometimes generate ungrammatical sentences due to parsing error</context>
</contexts>
<marker>Bisazza, Ruiz, Federico, 2011</marker>
<rawString>Arianna Bisazza, Nick Ruiz, and Marcello Federico. 2011. Fill-up versus interpolation methods for phrase-based SMT adaptation. In Proceedings of International Workshop on Spoken Language Translation (IWSLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Camayd-Freixas</author>
</authors>
<title>Cognitive theory of simultaneous interpreting and training.</title>
<date>2011</date>
<booktitle>In Proceedings of the 52nd Conference of the American Translators Association.</booktitle>
<contexts>
<context position="2956" citStr="Camayd-Freixas, 2011" startWordPosition="419" endWordPosition="420">onotone translation in Figure 1. By passivizing the English sentence, we can cache the subject and begin translating before observing the final verb. Furthermore, by using the English possessive, we mimic the order of the Japanese genitive construction. These transformations enable us to divide the input into shorter segments, thus reducing translation delay. To produce such monotone translations, a straightforward approach is to incorporate interpretation data into the learning of a machine translation (MT) system, because human interpreters use a variety of strategies (Shimizu et al., 2014; Camayd-Freixas, 2011; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (Camayd-Freixas, 2011; </context>
<context position="28791" citStr="Camayd-Freixas, 2011" startWordPosition="4672" endWordPosition="4673"> natural word reordering between the source and the target sentences, as explained in Section 1. In an SOV-SVO context, methods to predict unseen words are proposed to alleviate the above restriction. Matsubara et al. (1999) predict the English verb in the target sentence and integrates it syntactically. Grissom II et al. (2014) predict the final verb in the source sentence and decide when to use the predicted verb with reinforcement learning. Nevertheless, unless the predictor considers contextual and background information, which human interpreters often rely on for prediction (Hönig, 1997; Camayd-Freixas, 2011), such a prediction task is inherently hard. Unlike previous approaches to simultaneous translation, we directly adapt the training data and transform a translated sentence to an “interpreted” one. We can, therefore, take advantage of the abundance of parallel batch-translated corpora for training a simultaneous MT system. In addition, as a data preprocessing step, our approach is orthogonal to the others, with which it can be easily combined. This work is also related to preprocessing reordering approaches (Xu et al., 2009; Collins et al., 2005; Galley and Manning, 2008; Hoshino et al., 2013;</context>
</contexts>
<marker>Camayd-Freixas, 2011</marker>
<rawString>Erik Camayd-Freixas. 2011. Cognitive theory of simultaneous interpreting and training. In Proceedings of the 52nd Conference of the American Translators Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>George Foster</author>
</authors>
<title>Batch tuning strategies for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="18765" citStr="Cherry and Foster, 2012" startWordPosition="3020" endWordPosition="3023">ccompanying example sentences.7 Statistics of the dataset are shown in Table 1. The rewritten translation is generally slightly longer than the gold translation because our rewriting often involves inserting pronouns (e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters settings. We use GIZA++ (Och and Ney, 2003) for word alignment and k-best batch MIRA (Cherry and Foster, 2012) for tuning. The translation quality is evaluated by BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010).9 To obtain the parse trees for English sentences, we use the Stanford Parser (Klein and Manning, 2003) and the included English model. 5.1 Quality of Rewritten Translations After applying the rewriting rules (Section 4), Table 2 shows the percentage of sentences that are candidates and how many rewrites are accepted. The most generalizable rules are passivization and delaying quotative verbs. We rewrite 32.2% of sentences, reducing the delay from 9.9 words/seg to 6.3 words/seg pe</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kuˇcerová</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</booktitle>
<marker>Collins, Koehn, Kuˇcerová, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kuˇcerová. 2005. Clause restructuring for statistical machine translation. In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Desai Chen</author>
<author>André F T Martins</author>
<author>Nathan Schneider</author>
</authors>
<title>Framesemantic parsing.</title>
<date>2014</date>
<journal>Computational Linguistics,</journal>
<volume>40</volume>
<issue>1</issue>
<contexts>
<context position="20667" citStr="Das et al., 2014" startWordPosition="3315" endWordPosition="3318">s for which the rule results in a more monotonic sentence (Accepted). We evaluate the quality of our rewritten sentences from two perspectives: grammaticality and preserved semantics. To examine how close the rewritten sentences are to standard English, we train a 5-gram language model using the English data from the Europarl corpus, consisting of 46 million words, and use it to compute perplexity. Rewriting references increases the perplexity under the language model only slightly: from 332.0 to 335.4. To ensure that rewrites leave meaning unchanged, we use the SEMAFOR semantic role labeler (Das et al., 2014) on the original and modified sentence; for each role-labeled token in the reference sentence, we examine its corresponding role in the rewritten sentence and calculate the average accuracy acrosss all sentences. Even ignoring benign lexical changes—for example, he becoming him in a passivized sentence—95.5% of the words retain their semantic roles in the rewritten sentences. Although our rules are conservative to minimize corruption, some errors are unavoidable propagation of parser errors. For example, the sentence the London Stock Exchange closes at 1230 GMT today is parsed as:10 (S (NP the</context>
</contexts>
<marker>Das, Chen, Martins, Schneider, 2014</marker>
<rawString>Dipanjan Das, Desai Chen, André F. T. Martins, Nathan Schneider, , and Noah A. Smith. 2014. Framesemantic parsing. Computational Linguistics, 40(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Fügen</author>
<author>Alex Waibel</author>
</authors>
<title>Simultaneous translation of lectures and speeches.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>4</issue>
<marker>Fügen, Waibel, 2007</marker>
<rawString>Christian Fügen, Alex Waibel, , and Muntsin Kolss. 2007. Simultaneous translation of lectures and speeches. Machine Translation, 21(4):209–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoki Fujita</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Simple, lexicalized choice of translation timing for simultaneous speech translation.</title>
<date>2013</date>
<booktitle>In Proceedings of Interspeech.</booktitle>
<contexts>
<context position="1629" citStr="Fujita et al., 2013" startWordPosition="214" endWordPosition="217">ster than a baseline system that only uses gold reference translations. 1 Introduction Simultaneous interpretation is challenging because it demands both quality and speed. Conventional batch translation waits until the entire sentence is completed before starting to translate. This merely optimizes translation quality and often introduces undesirable lag between the speaker and the audience. Simultaneous interpretation instead requires a tradeoff between quality and speed. A common strategy is to translate independently translatable segments as soon as possible. Various segmentation methods (Fujita et al., 2013; Oda et al., 2014) reduce translation delay; they are limited, however, by the unavoidable word reordering between languages with drastically different word orders. We show an example of Japanese-English translation in Figure 1. Consider the batch translation: in English, the verb change comes immediately after the subject We, whereas in Japanese it comes at the end of the sentence; therefore, to produce an intelligible English sentence, we must translate the object after the final verb is observed, resulting in one large and painfully delayed segment. To reduce structural discrepancy, we can</context>
<context position="6736" citStr="Fujita et al., 2013" startWordPosition="985" endWordPosition="988">ls: producing good translations and producing them promptly. However, most existing parallel corpora and MT systems do not address the issue of delay during translation. We explicitly adapt the training data by rewriting rules to reduce delay. We first define translation delay and describe—in general terms— our rewriting rules. In the next section, we describe the rules in more detail. While we are motivated by real-time interpretation, to simplify our problem, we assume that we have perfect text input. Given this constraint, a typical simultaneous interpretation system (Sridhar et al., 2013; Fujita et al., 2013; Oda et al., 2014) produces partial translations of consecutive segments in the source sentence and concatenates them to produce a complete translation. We define the translation delay of a sentence as the average number of tokens the system has to observe between translation of two consecutive segments (denoted by # words/seg).1 For instance, the minimum delay of 1 word/seg is achieved when we translate immediately upon hearing a word. At test time, when the input is segmented, the delay is the average segment length. During the data preprocessing step of rewriting, we calculate delay from w</context>
<context position="21750" citStr="Fujita et al., 2013" startWordPosition="3494" endWordPosition="3497">le propagation of parser errors. For example, the sentence the London Stock Exchange closes at 1230 GMT today is parsed as:10 (S (NP the London Stock Exchange) (VP (VBZ closes) (PP at 1230) (NP GMT today))) GMT today is separated from the PP as an NP and is mistaken as the object. The passive version is then GMT today is closed at 1230 by the London Stock Exchange. Such errors could be reduced by skipping nodes with low inside/outside scores given by the parser, or skipping low-frequency patterns. However, we leave this for future work. 5.2 Segmentation At test time, we use right probability (Fujita et al., 2013, RP) to decide when to start translating a 10For simplicity we show the shallow parse only. sentence. As we read in the source Japanese sentence, if the input segment matches an entry in the learned phrase table, we query the RP of the Japanese/English phrase pair. A higher RP indicates that the English translation of this Japanese phrase will likely be followed by the translation of the next Japanese phrase. In other words, translation of the two consecutive Japanese phrases is monotonic, thus, we can begin translating immediately. Following (Fujita et al., 2013), if the RP of the current ph</context>
<context position="27715" citStr="Fujita et al., 2013" startWordPosition="4505" endWordPosition="4508">ng (also the first word in the Japanese source sentence). This is because our current segmentation strategy do not preserve words for later translation—a note-taking strategy used by human interpreters. 6 Related Work Previous approaches to simultaneous machine translation have employed explicit interpretation strategies for coping with delay. Two major approaches are segmentation and prediction. Most segmentation strategies are based on heuristics, such as pauses in speech (Fügen et al., 2007; Bangalore et al., 2009), comma prediction (Sridhar et al., 2013) and phrase reordering probability (Fujita et al., 2013). Learning-based methods have also been proposed. Oda et al. (2014) find segmentations that maximize the BLEU score of the final concatenated translation by dynamic programming. Grissom II et al. (2014) formulate simultaneous translation as a sequential decision making problem and uses reinforcement learning to decide when to translate. One limitation of these methods is that when learning with standard batch MT corpus, their gain can be restricted by natural word reordering between the source and the target sentences, as explained in Section 1. In an SOV-SVO context, methods to predict unseen</context>
</contexts>
<marker>Fujita, Neubig, Sakti, Toda, Nakamura, 2013</marker>
<rawString>Tomoki Fujita, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2013. Simple, lexicalized choice of translation timing for simultaneous speech translation. In Proceedings of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>A simple and effective hierarchical phrase reordering model.</title>
<date>2008</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="29368" citStr="Galley and Manning, 2008" startWordPosition="4761" endWordPosition="4764"> prediction (Hönig, 1997; Camayd-Freixas, 2011), such a prediction task is inherently hard. Unlike previous approaches to simultaneous translation, we directly adapt the training data and transform a translated sentence to an “interpreted” one. We can, therefore, take advantage of the abundance of parallel batch-translated corpora for training a simultaneous MT system. In addition, as a data preprocessing step, our approach is orthogonal to the others, with which it can be easily combined. This work is also related to preprocessing reordering approaches (Xu et al., 2009; Collins et al., 2005; Galley and Manning, 2008; Hoshino et al., 2013; Hoshino et al., 2014) in batch MT for language pairs with substantially different word orders. However, our problem is different in several ways. First, while the approaches resemble each other, our motivation is to reduce translation delay. Second, they reorder the source sentence, which is nontrivial and time-consuming when the sentence is incrementally revealed. Third, rewriting the target sentence requires the output to be grammatical (for it to be used as reference translation), which is not a concern when rewriting source sentences. 7 Conclusion Training MT system</context>
</contexts>
<marker>Galley, Manning, 2008</marker>
<rawString>Michel Galley and Christopher D. Manning. 2008. A simple and effective hierarchical phrase reordering model. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alvin C Grissom He He</author>
<author>Jordan Boyd-Graber</author>
<author>John Morgan</author>
<author>Hal Daumé</author>
</authors>
<title>Don’t until the final verb wait: Reinforcement learning for simultaneous machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<marker>He, Boyd-Graber, Morgan, Daumé, 2014</marker>
<rawString>Alvin C. Grissom II, He He, Jordan Boyd-Graber, John Morgan, and Hal Daumé III. 2014. Don’t until the final verb wait: Reinforcement learning for simultaneous machine translation. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans G Hönig</author>
</authors>
<title>Using text mappings in teaching consecutive interpreting. Translation and Translation Theory,</title>
<date>1997</date>
<pages>pages</pages>
<contexts>
<context position="28768" citStr="Hönig, 1997" startWordPosition="4670" endWordPosition="4671">restricted by natural word reordering between the source and the target sentences, as explained in Section 1. In an SOV-SVO context, methods to predict unseen words are proposed to alleviate the above restriction. Matsubara et al. (1999) predict the English verb in the target sentence and integrates it syntactically. Grissom II et al. (2014) predict the final verb in the source sentence and decide when to use the predicted verb with reinforcement learning. Nevertheless, unless the predictor considers contextual and background information, which human interpreters often rely on for prediction (Hönig, 1997; Camayd-Freixas, 2011), such a prediction task is inherently hard. Unlike previous approaches to simultaneous translation, we directly adapt the training data and transform a translated sentence to an “interpreted” one. We can, therefore, take advantage of the abundance of parallel batch-translated corpora for training a simultaneous MT system. In addition, as a data preprocessing step, our approach is orthogonal to the others, with which it can be easily combined. This work is also related to preprocessing reordering approaches (Xu et al., 2009; Collins et al., 2005; Galley and Manning, 2008</context>
</contexts>
<marker>Hönig, 1997</marker>
<rawString>Hans G. Hönig. 1997. Using text mappings in teaching consecutive interpreting. Translation and Translation Theory, pages 19–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sho Hoshino</author>
<author>Yusuke Miyao</author>
<author>Katsuhito Sudoh</author>
<author>Masaaki Nagata</author>
</authors>
<title>Two-stage pre-ordering for Japanese-to-English statistical machine translation.</title>
<date>2013</date>
<booktitle>In International Joint Conference on Artificial Intelligence (IJCNLP).</booktitle>
<contexts>
<context position="29390" citStr="Hoshino et al., 2013" startWordPosition="4765" endWordPosition="4768">Camayd-Freixas, 2011), such a prediction task is inherently hard. Unlike previous approaches to simultaneous translation, we directly adapt the training data and transform a translated sentence to an “interpreted” one. We can, therefore, take advantage of the abundance of parallel batch-translated corpora for training a simultaneous MT system. In addition, as a data preprocessing step, our approach is orthogonal to the others, with which it can be easily combined. This work is also related to preprocessing reordering approaches (Xu et al., 2009; Collins et al., 2005; Galley and Manning, 2008; Hoshino et al., 2013; Hoshino et al., 2014) in batch MT for language pairs with substantially different word orders. However, our problem is different in several ways. First, while the approaches resemble each other, our motivation is to reduce translation delay. Second, they reorder the source sentence, which is nontrivial and time-consuming when the sentence is incrementally revealed. Third, rewriting the target sentence requires the output to be grammatical (for it to be used as reference translation), which is not a concern when rewriting source sentences. 7 Conclusion Training MT systems with more monotonic </context>
</contexts>
<marker>Hoshino, Miyao, Sudoh, Nagata, 2013</marker>
<rawString>Sho Hoshino, Yusuke Miyao, Katsuhito Sudoh, and Masaaki Nagata. 2013. Two-stage pre-ordering for Japanese-to-English statistical machine translation. In International Joint Conference on Artificial Intelligence (IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sho Hoshino</author>
<author>Hubert Soyer</author>
<author>Yusuke Miyao</author>
<author>Akiko Aizawa</author>
</authors>
<title>Japanese to english machine translation using preordering and compositional distributed semantics.</title>
<date>2014</date>
<booktitle>In Workshop on Asian Translation.</booktitle>
<contexts>
<context position="29413" citStr="Hoshino et al., 2014" startWordPosition="4769" endWordPosition="4772"> such a prediction task is inherently hard. Unlike previous approaches to simultaneous translation, we directly adapt the training data and transform a translated sentence to an “interpreted” one. We can, therefore, take advantage of the abundance of parallel batch-translated corpora for training a simultaneous MT system. In addition, as a data preprocessing step, our approach is orthogonal to the others, with which it can be easily combined. This work is also related to preprocessing reordering approaches (Xu et al., 2009; Collins et al., 2005; Galley and Manning, 2008; Hoshino et al., 2013; Hoshino et al., 2014) in batch MT for language pairs with substantially different word orders. However, our problem is different in several ways. First, while the approaches resemble each other, our motivation is to reduce translation delay. Second, they reorder the source sentence, which is nontrivial and time-consuming when the sentence is incrementally revealed. Third, rewriting the target sentence requires the output to be grammatical (for it to be used as reference translation), which is not a concern when rewriting source sentences. 7 Conclusion Training MT systems with more monotonic (interpretation-like) s</context>
</contexts>
<marker>Hoshino, Soyer, Miyao, Aizawa, 2014</marker>
<rawString>Sho Hoshino, Hubert Soyer, Yusuke Miyao, and Akiko Aizawa. 2014. Japanese to english machine translation using preordering and compositional distributed semantics. In Workshop on Asian Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Tsutomu Hirao</author>
<author>Kevin Duh</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
</authors>
<title>Automatic evaluation of translation quality for distant language pairs.</title>
<date>2010</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="18879" citStr="Isozaki et al., 2010" startWordPosition="3039" endWordPosition="3042">y slightly longer than the gold translation because our rewriting often involves inserting pronouns (e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters settings. We use GIZA++ (Och and Ney, 2003) for word alignment and k-best batch MIRA (Cherry and Foster, 2012) for tuning. The translation quality is evaluated by BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010).9 To obtain the parse trees for English sentences, we use the Stanford Parser (Klein and Manning, 2003) and the included English model. 5.1 Quality of Rewritten Translations After applying the rewriting rules (Section 4), Table 2 shows the percentage of sentences that are candidates and how many rewrites are accepted. The most generalizable rules are passivization and delaying quotative verbs. We rewrite 32.2% of sentences, reducing the delay from 9.9 words/seg to 6.3 words/seg per segment for rewritten sentences and from 7.8 words/seg to 6.7 words/seg overall. 6For example, in clause transfo</context>
</contexts>
<marker>Isozaki, Hirao, Duh, Sudoh, Tsukada, 2010</marker>
<rawString>Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada. 2010. Automatic evaluation of translation quality for distant language pairs. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="18983" citStr="Klein and Manning, 2003" startWordPosition="3056" endWordPosition="3059">e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters settings. We use GIZA++ (Och and Ney, 2003) for word alignment and k-best batch MIRA (Cherry and Foster, 2012) for tuning. The translation quality is evaluated by BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010).9 To obtain the parse trees for English sentences, we use the Stanford Parser (Klein and Manning, 2003) and the included English model. 5.1 Quality of Rewritten Translations After applying the rewriting rules (Section 4), Table 2 shows the percentage of sentences that are candidates and how many rewrites are accepted. The most generalizable rules are passivization and delaying quotative verbs. We rewrite 32.2% of sentences, reducing the delay from 9.9 words/seg to 6.3 words/seg per segment for rewritten sentences and from 7.8 words/seg to 6.7 words/seg overall. 6For example, in clause transformation, the Japanese conjunction moshi, which is clause initial, may appear at the beginning of a sente</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Brooke Cowan Nicola Bertoldi</author>
<author>Wade Shen</author>
</authors>
<title>Richard Zens Christine Moran, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="18629" citStr="Koehn et al., 2003" startWordPosition="2998" endWordPosition="3001">s of news articles (Utiyama and Isahara, 2003). For training the MT system, we also include the EIJIRO dictionary entries and the accompanying example sentences.7 Statistics of the dataset are shown in Table 1. The rewritten translation is generally slightly longer than the gold translation because our rewriting often involves inserting pronouns (e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters settings. We use GIZA++ (Och and Ney, 2003) for word alignment and k-best batch MIRA (Cherry and Foster, 2012) for tuning. The translation quality is evaluated by BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010).9 To obtain the parse trees for English sentences, we use the Stanford Parser (Klein and Manning, 2003) and the included English model. 5.1 Quality of Rewritten Translations After applying the rewriting rules (Section 4), Table 2 shows the percentage of sentences that are candidates and how many rewrites are accepted. The most generalizable rules </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Shen, 2003</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Brooke Cowan Nicola Bertoldi, Wade Shen, Richard Zens Christine Moran, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbs. 2003. Moses: Open source toolkit for statistical machine translation. In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shigeki Matsubara</author>
<author>Katsuhiko Toyama</author>
<author>Yasuyoshi Inagaki</author>
</authors>
<title>Sync/trans: Simultaneous machine interpretation between English and Japanese.</title>
<date>1999</date>
<booktitle>In Advanced Topics in Artificial Intelligence,</booktitle>
<pages>134--143</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="28394" citStr="Matsubara et al. (1999)" startWordPosition="4610" endWordPosition="4613"> al. (2014) find segmentations that maximize the BLEU score of the final concatenated translation by dynamic programming. Grissom II et al. (2014) formulate simultaneous translation as a sequential decision making problem and uses reinforcement learning to decide when to translate. One limitation of these methods is that when learning with standard batch MT corpus, their gain can be restricted by natural word reordering between the source and the target sentences, as explained in Section 1. In an SOV-SVO context, methods to predict unseen words are proposed to alleviate the above restriction. Matsubara et al. (1999) predict the English verb in the target sentence and integrates it syntactically. Grissom II et al. (2014) predict the final verb in the source sentence and decide when to use the predicted verb with reinforcement learning. Nevertheless, unless the predictor considers contextual and background information, which human interpreters often rely on for prediction (Hönig, 1997; Camayd-Freixas, 2011), such a prediction task is inherently hard. Unlike previous approaches to simultaneous translation, we directly adapt the training data and transform a translated sentence to an “interpreted” one. We ca</context>
</contexts>
<marker>Matsubara, Toyama, Inagaki, 1999</marker>
<rawString>Shigeki Matsubara, Katsuhiko Toyama, and Yasuyoshi Inagaki. 1999. Sync/trans: Simultaneous machine interpretation between English and Japanese. In Advanced Topics in Artificial Intelligence, pages 134– 143. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shigeki Matsubara</author>
<author>Akira Takagi</author>
<author>Nobuo Kawaguchi</author>
<author>Yasuyoshi Inagaki</author>
</authors>
<title>Bilingual spoken monologue corpus for simultaneous machine interpretation research.</title>
<date>2002</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="3209" citStr="Matsubara et al., 2002" startWordPosition="453" endWordPosition="456">n. These transformations enable us to divide the input into shorter segments, thus reducing translation delay. To produce such monotone translations, a straightforward approach is to incorporate interpretation data into the learning of a machine translation (MT) system, because human interpreters use a variety of strategies (Shimizu et al., 2014; Camayd-Freixas, 2011; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (Camayd-Freixas, 2011; Al-Khanji et al., 2000) compared to human translations done at the translator’s leisure, allowing for more introspection and precise word choice. We aim to address the data scarcity problem and combine translators’ lexical precision and interpreters’ sy</context>
</contexts>
<marker>Matsubara, Takagi, Kawaguchi, Inagaki, 2002</marker>
<rawString>Shigeki Matsubara, Akira Takagi, Nobuo Kawaguchi, and Yasuyoshi Inagaki. 2002. Bilingual spoken monologue corpus for simultaneous machine interpretation research. In Proceedings of the Language Resources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
</authors>
<title>The Kyoto free translation task. Available online at http://www.</title>
<date>2011</date>
<tech>phontron. com/kftt.</tech>
<contexts>
<context position="10695" citStr="Neubig, 2011" startWordPosition="1643" endWordPosition="1644">lude factive (e.g., know, realize, observe), factive-like (e.g., announce, determine), belief (e.g., believe, think, suspect), and antifactive (e.g., doubt, deny) verbs. When these verbs are followed by a clause (S or SBAR), we move the verb and its subject to the end of the clause. While some exploratory work automatically extracts factive verbs, to our knowledge, an exhaustive list does not exist. To obtain a list with reasonable coverage, we exploit the fact that Japanese has an unambiguous quotative particle, to, that precedes such verbs.2 We identify all of the verbs in the Kyoto corpus (Neubig, 2011) marked by the quotative particle and translate them into English. We then use these as our quotative verbs.3 3.2 Noun Phrases Another difference between Japanese and English lies in the order of adjectives and the nouns they modify. We identify two situations where we can take advantage of the flexibility of English grammar to favor sentence structures consistent with positions of nouns in Japanese. Genitive Reordering In Japanese, genitive constructions always occur in the form of X no Y, where Y belongs to X. In English, however, the order may be reversed through the of construction. Theref</context>
</contexts>
<marker>Neubig, 2011</marker>
<rawString>Graham Neubig. 2011. The Kyoto free translation task. Available online at http://www. phontron. com/kftt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="18698" citStr="Och and Ney, 2003" startWordPosition="3009" endWordPosition="3012">stem, we also include the EIJIRO dictionary entries and the accompanying example sentences.7 Statistics of the dataset are shown in Table 1. The rewritten translation is generally slightly longer than the gold translation because our rewriting often involves inserting pronouns (e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters settings. We use GIZA++ (Och and Ney, 2003) for word alignment and k-best batch MIRA (Cherry and Foster, 2012) for tuning. The translation quality is evaluated by BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010).9 To obtain the parse trees for English sentences, we use the Stanford Parser (Klein and Manning, 2003) and the included English model. 5.1 Quality of Rewritten Translations After applying the rewriting rules (Section 4), Table 2 shows the percentage of sentences that are candidates and how many rewrites are accepted. The most generalizable rules are passivization and delaying quotative verbs. We rewrite 32.2% of s</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Oda</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Optimizing segmentation strategies for simultaneous speech translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="1648" citStr="Oda et al., 2014" startWordPosition="218" endWordPosition="221">system that only uses gold reference translations. 1 Introduction Simultaneous interpretation is challenging because it demands both quality and speed. Conventional batch translation waits until the entire sentence is completed before starting to translate. This merely optimizes translation quality and often introduces undesirable lag between the speaker and the audience. Simultaneous interpretation instead requires a tradeoff between quality and speed. A common strategy is to translate independently translatable segments as soon as possible. Various segmentation methods (Fujita et al., 2013; Oda et al., 2014) reduce translation delay; they are limited, however, by the unavoidable word reordering between languages with drastically different word orders. We show an example of Japanese-English translation in Figure 1. Consider the batch translation: in English, the verb change comes immediately after the subject We, whereas in Japanese it comes at the end of the sentence; therefore, to produce an intelligible English sentence, we must translate the object after the final verb is observed, resulting in one large and painfully delayed segment. To reduce structural discrepancy, we can apply syntactic tr</context>
<context position="6755" citStr="Oda et al., 2014" startWordPosition="989" endWordPosition="992">anslations and producing them promptly. However, most existing parallel corpora and MT systems do not address the issue of delay during translation. We explicitly adapt the training data by rewriting rules to reduce delay. We first define translation delay and describe—in general terms— our rewriting rules. In the next section, we describe the rules in more detail. While we are motivated by real-time interpretation, to simplify our problem, we assume that we have perfect text input. Given this constraint, a typical simultaneous interpretation system (Sridhar et al., 2013; Fujita et al., 2013; Oda et al., 2014) produces partial translations of consecutive segments in the source sentence and concatenates them to produce a complete translation. We define the translation delay of a sentence as the average number of tokens the system has to observe between translation of two consecutive segments (denoted by # words/seg).1 For instance, the minimum delay of 1 word/seg is achieved when we translate immediately upon hearing a word. At test time, when the input is segmented, the delay is the average segment length. During the data preprocessing step of rewriting, we calculate delay from word alignments (Sec</context>
<context position="27782" citStr="Oda et al. (2014)" startWordPosition="4515" endWordPosition="4518">use our current segmentation strategy do not preserve words for later translation—a note-taking strategy used by human interpreters. 6 Related Work Previous approaches to simultaneous machine translation have employed explicit interpretation strategies for coping with delay. Two major approaches are segmentation and prediction. Most segmentation strategies are based on heuristics, such as pauses in speech (Fügen et al., 2007; Bangalore et al., 2009), comma prediction (Sridhar et al., 2013) and phrase reordering probability (Fujita et al., 2013). Learning-based methods have also been proposed. Oda et al. (2014) find segmentations that maximize the BLEU score of the final concatenated translation by dynamic programming. Grissom II et al. (2014) formulate simultaneous translation as a sequential decision making problem and uses reinforcement learning to decide when to translate. One limitation of these methods is that when learning with standard batch MT corpus, their gain can be restricted by natural word reordering between the source and the target sentences, as explained in Section 1. In an SOV-SVO context, methods to predict unseen words are proposed to alleviate the above restriction. Matsubara e</context>
</contexts>
<marker>Oda, Neubig, Sakti, Toda, Nakamura, 2014</marker>
<rawString>Yusuke Oda, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2014. Optimizing segmentation strategies for simultaneous speech translation. In Proceedings of the Association for Computational Linguistics (ACL), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="18846" citStr="Papineni et al., 2002" startWordPosition="3033" endWordPosition="3036"> rewritten translation is generally slightly longer than the gold translation because our rewriting often involves inserting pronouns (e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters settings. We use GIZA++ (Och and Ney, 2003) for word alignment and k-best batch MIRA (Cherry and Foster, 2012) for tuning. The translation quality is evaluated by BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010).9 To obtain the parse trees for English sentences, we use the Stanford Parser (Klein and Manning, 2003) and the included English model. 5.1 Quality of Rewritten Translations After applying the rewriting rules (Section 4), Table 2 shows the percentage of sentences that are candidates and how many rewrites are accepted. The most generalizable rules are passivization and delaying quotative verbs. We rewrite 32.2% of sentences, reducing the delay from 9.9 words/seg to 6.3 words/seg per segment for rewritten sentences and from 7.8 words/seg to 6.7 words/seg overall</context>
</contexts>
<marker>Papineni, Roukos, Ward, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, , and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Paulik</author>
<author>Alex Waibel</author>
</authors>
<title>Spoken language translation from parallel speech audio: Simultaneous interpretation as slt training data.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</booktitle>
<contexts>
<context position="3387" citStr="Paulik and Waibel, 2010" startWordPosition="480" endWordPosition="483"> is to incorporate interpretation data into the learning of a machine translation (MT) system, because human interpreters use a variety of strategies (Shimizu et al., 2014; Camayd-Freixas, 2011; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (Camayd-Freixas, 2011; Al-Khanji et al., 2000) compared to human translations done at the translator’s leisure, allowing for more introspection and precise word choice. We aim to address the data scarcity problem and combine translators’ lexical precision and interpreters’ syntactic flexibility. We propose to rewrite the reference translation in a way that uses the original lexicon, obeys standard grammar rules of 55 Proceedings of the 2015 Conferenc</context>
</contexts>
<marker>Paulik, Waibel, 2010</marker>
<rawString>Matthias Paulik and Alex Waibel. 2010. Spoken language translation from parallel speech audio: Simultaneous interpretation as slt training data. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroaki Shimizu</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Constructing a speech translation system using simultaneous interpretation data. In</title>
<date>2013</date>
<booktitle>Proceedings of International Workshop on Spoken Language Translation (IWSLT).</booktitle>
<contexts>
<context position="3037" citStr="Shimizu et al. (2013)" startWordPosition="430" endWordPosition="433">he the subject and begin translating before observing the final verb. Furthermore, by using the English possessive, we mimic the order of the Japanese genitive construction. These transformations enable us to divide the input into shorter segments, thus reducing translation delay. To produce such monotone translations, a straightforward approach is to incorporate interpretation data into the learning of a machine translation (MT) system, because human interpreters use a variety of strategies (Shimizu et al., 2014; Camayd-Freixas, 2011; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (Camayd-Freixas, 2011; Al-Khanji et al., 2000) compared to human translations done at the translator’s l</context>
</contexts>
<marker>Shimizu, Neubig, Sakti, Toda, Nakamura, 2013</marker>
<rawString>Hiroaki Shimizu, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2013. Constructing a speech translation system using simultaneous interpretation data. In Proceedings of International Workshop on Spoken Language Translation (IWSLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroaki Shimizu</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Collection of a simultaneous translation corpus for comparative analysis.</title>
<date>2014</date>
<booktitle>In International Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="2934" citStr="Shimizu et al., 2014" startWordPosition="415" endWordPosition="418"> other. Consider the monotone translation in Figure 1. By passivizing the English sentence, we can cache the subject and begin translating before observing the final verb. Furthermore, by using the English possessive, we mimic the order of the Japanese genitive construction. These transformations enable us to divide the input into shorter segments, thus reducing translation delay. To produce such monotone translations, a straightforward approach is to incorporate interpretation data into the learning of a machine translation (MT) system, because human interpreters use a variety of strategies (Shimizu et al., 2014; Camayd-Freixas, 2011; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (</context>
</contexts>
<marker>Shimizu, Neubig, Sakti, Toda, Nakamura, 2014</marker>
<rawString>Hiroaki Shimizu, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2014. Collection of a simultaneous translation corpus for comparative analysis. In International Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivek Kumar Rangarajan Sridhar</author>
<author>John Chen</author>
<author>Srinivas Bangalore Andrej Ljolje</author>
<author>Rathinavelu Chengalvarayan</author>
</authors>
<title>Segmentation strategies for streaming speech translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="6715" citStr="Sridhar et al., 2013" startWordPosition="981" endWordPosition="984">rpretation has two goals: producing good translations and producing them promptly. However, most existing parallel corpora and MT systems do not address the issue of delay during translation. We explicitly adapt the training data by rewriting rules to reduce delay. We first define translation delay and describe—in general terms— our rewriting rules. In the next section, we describe the rules in more detail. While we are motivated by real-time interpretation, to simplify our problem, we assume that we have perfect text input. Given this constraint, a typical simultaneous interpretation system (Sridhar et al., 2013; Fujita et al., 2013; Oda et al., 2014) produces partial translations of consecutive segments in the source sentence and concatenates them to produce a complete translation. We define the translation delay of a sentence as the average number of tokens the system has to observe between translation of two consecutive segments (denoted by # words/seg).1 For instance, the minimum delay of 1 word/seg is achieved when we translate immediately upon hearing a word. At test time, when the input is segmented, the delay is the average segment length. During the data preprocessing step of rewriting, we c</context>
<context position="27659" citStr="Sridhar et al., 2013" startWordPosition="4497" endWordPosition="4500"> final verb. However, RW still produces he at the beginning (also the first word in the Japanese source sentence). This is because our current segmentation strategy do not preserve words for later translation—a note-taking strategy used by human interpreters. 6 Related Work Previous approaches to simultaneous machine translation have employed explicit interpretation strategies for coping with delay. Two major approaches are segmentation and prediction. Most segmentation strategies are based on heuristics, such as pauses in speech (Fügen et al., 2007; Bangalore et al., 2009), comma prediction (Sridhar et al., 2013) and phrase reordering probability (Fujita et al., 2013). Learning-based methods have also been proposed. Oda et al. (2014) find segmentations that maximize the BLEU score of the final concatenated translation by dynamic programming. Grissom II et al. (2014) formulate simultaneous translation as a sequential decision making problem and uses reinforcement learning to decide when to translate. One limitation of these methods is that when learning with standard batch MT corpus, their gain can be restricted by natural word reordering between the source and the target sentences, as explained in Sec</context>
</contexts>
<marker>Sridhar, Chen, Ljolje, Chengalvarayan, 2013</marker>
<rawString>Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas Bangalore Andrej Ljolje, and Rathinavelu Chengalvarayan. 2013. Segmentation strategies for streaming speech translation. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitomi Tohyama</author>
<author>Shigeki Matsubara</author>
</authors>
<title>Collection of simultaneous interpreting patterns by using bilingual spoken monologue corpus.</title>
<date>2006</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="2986" citStr="Tohyama and Matsubara, 2006" startWordPosition="421" endWordPosition="424"> Figure 1. By passivizing the English sentence, we can cache the subject and begin translating before observing the final verb. Furthermore, by using the English possessive, we mimic the order of the Japanese genitive construction. These transformations enable us to divide the input into shorter segments, thus reducing translation delay. To produce such monotone translations, a straightforward approach is to incorporate interpretation data into the learning of a machine translation (MT) system, because human interpreters use a variety of strategies (Shimizu et al., 2014; Camayd-Freixas, 2011; Tohyama and Matsubara, 2006) to fine-tune the word order. Shimizu et al. (2013) shows that this approach improves the speed-accuracy tradeoff. However, existing parallel simultaneous interpretation corpora (Shimizu et al., 2014; Matsubara et al., 2002; Bendazzoli and Sandrelli, 2005) are often small, and collecting new data is expensive due to the inherent costs of recording and transcribing speeches (Paulik and Waibel, 2010). In addition, due to the intense time pressure during interpretation, human interpretation has the disadvantage of simpler, less precise diction (Camayd-Freixas, 2011; Al-Khanji et al., 2000) compar</context>
</contexts>
<marker>Tohyama, Matsubara, 2006</marker>
<rawString>Hitomi Tohyama and Shigeki Matsubara. 2006. Collection of simultaneous interpreting patterns by using bilingual spoken monologue corpus. In Proceedings of the Language Resources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Reliable measures for aligning japanese-english news articles and sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="18056" citStr="Utiyama and Isahara, 2003" startWordPosition="2908" endWordPosition="2912">r rules have little interaction with each other, and the order of application has a negligible effect. We apply the rules, roughly, sequentially in order of complexity: if the output of current rule is not accepted, the sentence is reverted to the last accepted version. Train Tune Test Ja 21.3M 30.2k 23.3k En-GD 16.8M 23.8k 18.5k En-RW 16.8M 24.1k 18.7k Table 1: Number of words in the training, tuning, and test datasets. En-GD and En-RW represent the gold reference set and the rewritten reference set. 5 Experiments We evaluate our method on the Reuters JapaneseEnglish corpus of news articles (Utiyama and Isahara, 2003). For training the MT system, we also include the EIJIRO dictionary entries and the accompanying example sentences.7 Statistics of the dataset are shown in Table 1. The rewritten translation is generally slightly longer than the gold translation because our rewriting often involves inserting pronouns (e.g. it, this) for antecedents. We use the TreebankWordTokenizer from NLTK (Bird et al., 2009) to tokenize English sentences and Kuromoji Japanese morphological analyzer8 to tokenize Japanese sentences. Our phrase-based MT system is trained by Moses (Koehn et al., 2003) with standard parameters s</context>
</contexts>
<marker>Utiyama, Isahara, 2003</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2003. Reliable measures for aligning japanese-english news articles and sentences. In Proceedings of the annual meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Xu</author>
<author>Jaeho Kang</author>
<author>Michael Ringgaard</author>
</authors>
<title>Using a dependency parser to improve SMT for subject-object-verb language.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="26053" citStr="Xu et al., 2009" startWordPosition="4228" endWordPosition="4231">n is that SOV to SVO translation often drops the verb because of long range reordering. (We see this for Japanese here, but this is also true for German.) Similar word orders in the source and target results in less reordering and improves phrase-based MT (Collins Translation GD RW RW+GD Gold ref # of verbs 1971 2050 2224 2731 Table 3: Number of verbs in the test set translation produced by different models and the gold reference translation. Boldface indicates the number is significantly larger than others (excluding the gold ref) according to two-sample t-tests with p &lt; 0.001. et al., 2005; Xu et al., 2009). Table 3 shows the number of verbs in the translations of the test sentences produced by GD, RW, RW+GD, as well as the number in the gold reference translation. Both RW and RW+GD produce more verbs (a statistically significant result), although RW+GD captures the most verbs. 61 he also said that the real dangers for the euro lay in the Ref potential for divergences in the domestic policy needs among the various participating nations of the single currency. he also for the euro, is a real danger to launch a single GD currency in many different countries and domestic policies on the need for th</context>
<context position="29320" citStr="Xu et al., 2009" startWordPosition="4753" endWordPosition="4756">ch human interpreters often rely on for prediction (Hönig, 1997; Camayd-Freixas, 2011), such a prediction task is inherently hard. Unlike previous approaches to simultaneous translation, we directly adapt the training data and transform a translated sentence to an “interpreted” one. We can, therefore, take advantage of the abundance of parallel batch-translated corpora for training a simultaneous MT system. In addition, as a data preprocessing step, our approach is orthogonal to the others, with which it can be easily combined. This work is also related to preprocessing reordering approaches (Xu et al., 2009; Collins et al., 2005; Galley and Manning, 2008; Hoshino et al., 2013; Hoshino et al., 2014) in batch MT for language pairs with substantially different word orders. However, our problem is different in several ways. First, while the approaches resemble each other, our motivation is to reduce translation delay. Second, they reorder the source sentence, which is nontrivial and time-consuming when the sentence is incrementally revealed. Third, rewriting the target sentence requires the output to be grammatical (for it to be used as reference translation), which is not a concern when rewriting s</context>
</contexts>
<marker>Xu, Kang, Ringgaard, 2009</marker>
<rawString>Peng Xu, Jaeho Kang, Michael Ringgaard, , and Franz Och. 2009. Using a dependency parser to improve SMT for subject-object-verb language. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>