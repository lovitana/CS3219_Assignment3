<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000026">
<title confidence="0.996068">
Neural Networks for Open Domain Targeted Sentiment
</title>
<author confidence="0.980411">
Meishan Zhang and Yue Zhang and Duy-Tin Vo
</author>
<affiliation confidence="0.977356">
Singapore University of Technology and Design
</affiliation>
<email confidence="0.615019">
{meishan zhang, yue zhang}@sutd.edu.sg,
duytin vo@mymail.sutd.edu.sg
</email>
<sectionHeader confidence="0.991596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99977965">
Open domain targeted sentiment is the
joint information extraction task that finds
target mentions together with the senti-
ment towards each mention from a text
corpus. The task is typically modeled as a
sequence labeling problem, and solved us-
ing state-of-the-art labelers such as CRF.
We empirically study the effect of word
embeddings and automatic feature combi-
nations on the task by extending a CRF
baseline using neural networks, which
have demonstrated large potentials for
sentiment analysis. Results show that the
neural model can give better results by
significantly increasing the recall. In ad-
dition, we propose a novel integration of
neural and discrete features, which com-
bines their relative advantages, leading to
significantly higher results compared to
both baselines.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98199184">
Targeted sentiment analysis has drawn growing re-
search interests over the past few years. Compared
with traditional sentiment analysis tasks, which
extract the overall sentiment of a document, a sen-
tence or a tweet, targeted sentiment analysis ex-
tracts the sentiment over given targeted entities
from a text, and therefore is practically more infor-
mative. An example is shown in Figure 1. There
are at least two practical scenarios:
(1) Certain entities of concern are specified, and
the requirement is to extract the sentiment to-
wards their mentions in a text. For exam-
ple, one can be interested in the sentiment
towards Google Inc., Microsoft and Face-
book in financial news texts, or the sentiment
towards Manchester United, Liverpool and
Chelsea in tweets.
So excited to meet my [baby Farah]+ !!!
[Baseball Warehouse]+ : easy to under-
stand information.
The [#Afghan #Parlaiment Speaker]−
should Resign .
Saw [Erykah Badu]− last night , vile
venue unfortunately .
[AW service]0 will be back at work.
</bodyText>
<figureCaption confidence="0.996895">
Figure 1: Targeted sentiment analysis.
</figureCaption>
<bodyText confidence="0.991740482758621">
(2) No specified target is given, and the require-
ment is to find sentiments towards entities in
the open domain. For example, one might be
interested extracting the mentions to all per-
sons and organizations, together with the sen-
timents towards each mention, from a news
archive or a collection of novels.
There are two sub tasks in targeted sentiment
analysis, namely entity recognition and sentiment
classification for each entity mention which ap-
ply to both scenarios above. In scenario (1), en-
tity recognition is relatively trivial, and can typ-
ically be achieved by pattern matching. Partly
due to this reason, most previous work has ad-
dressed targeted sentiment analysis as a pure clas-
sification task, assuming that target mentions have
been given (Jiang et al., 2011; Chen et al., 2012;
Dong et al., 2014; Vo and Zhang, 2015). For
scenario (2), a named entity recognition (NER)
system can be used to extract targets, before the
same targeted sentiment classification algorithms
are applied. There has also been work that con-
centrates on extracting opinion targets (Jin et al.,
2009; Jakob and Gurevych, 2010). In both cases,
the data in Figure 1 can be used for training senti-
ment classifiers.
Mitchell et al. (2013) took a different ap-
proach, extracting named entities and their senti-
ment classes jointly. They model the joint task
</bodyText>
<page confidence="0.960616">
612
</page>
<note confidence="0.85093425">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 612–621,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
sentence: So excited to meet my baby Farah !!!
collapsed: O O O O O B+ I+ O
</note>
<figure confidence="0.971791">
(b) collapsed
</figure>
<figureCaption confidence="0.976946">
Figure 2: Pipeline, joint and collapsed models for
open targeted sentiment analysis.
</figureCaption>
<bodyText confidence="0.99998496">
as an extension to the NER task, where an extra
sentiment label is assigned to each named entity,
in addition to the entity label. As a result, the
task can be solved using sequence labeling meth-
ods. As claimed by Mitchell et al. (2013), the
joint task is particularly suitable when no extra re-
sources are available for training separate syntac-
tic analyzers or name entity recognizers. Such sit-
uations can include tweets and low-resource lan-
guages/domains. Interestingly, because of con-
taining entity information, the annotation in Fig-
ure 1 suffices for training joint entity and senti-
ment labels even if it is the only resource available.
The annotations in Figure 1 can be transformed
into label sequences, as shown in Figure 2. Fig-
ure 2 consists of two types of labels, where the
B/I/O labels indicate span boundaries, and the +/-
/0 labels indicate sentiment classes. The two types
of labels can be assigned in a span→sentiment
pipeline, or jointly as a multi-label task. Alterna-
tively, as shown in Figure 2(b), the two types of la-
bels can be collapsed into a joint label, such as B+
and I-, indicating the beginning of a positive entity
and the middle of a negative entity, respectively.
The collapsed labels allow joint entity recognition
and sentiment classification to be achieved using a
standard sequence labeler.
Mitchell et al. (2013) compare a pipeline model,
a joint model and a collapsed model under the
same conditional random field (CRF) framework,
finding that the pipeline method outperforms the
joint model on a tweet dataset. Intuitively, the in-
teraction between entity boundaries and sentiment
classes might not be as strong as that between
more closely-coupled sources of information, such
as word boundaries and POS (Zhang and Clark,
2008), or named entities and constituents (Finkel
and Manning, 2009), for which joint models sig-
nificantly outperform pipeline models. On the
other hand, there do exist cases where entity
boundaries and sentiment classes reinforce each
other. For example, in a tweet such as ‘I like X.’,
the contextual pattern indicate both a positive sen-
timent and an entity in the place of X.
Recently, neural network models have been in-
creasingly used for sentiment analysis (Socher et
al., 2013; Kalchbrenner et al., 2014; dos San-
tos and Gatti, 2014), achieving highly competi-
tive results, which show large potentials of neu-
ral network models for this task. The main ad-
vantages of neural networks are two-fold. First,
neural models use real-valued hidden layers to au-
tomatically learn feature combinations, which can
capture complex semantic information that are dif-
ficult to express using traditional discrete man-
ual features. Second, neural networks take dis-
tributed word embeddings as inputs, which can be
trained from large-scale raw text, thus alleviating
the scarcity of annotated data to some extent. In
this paper, we exploit structured neural models for
open targeted sentiment.
We take the CRF model of Mitchell et al. (2013)
as the baseline, and explore two research ques-
tions. First, we make an empirical comparison be-
tween discrete and neural CRF models, and fur-
ther combine the strengths of each model via fea-
ture integration. Second, we compare the effects
of the pipeline, joint and collapsed models for
open targeted sentiment analysis under the neu-
ral model settings. Our experiments show that the
neural model gives competitive results compared
with the discrete baseline, with relatively higher
recalls. In addition, the integrated model signifi-
cantly improves over both the discrete and the neu-
ral models.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998596153846154">
Targeted sentiment analysis is closely related prior
work on aspect-oriented (Hu and Liu, 2004),
feature-oriented (Popescu and Etzioni, 2007) and
topic-oriented (Yi et al., 2003) sentiment analysis.
These related tasks are typically concentrated on
product review settings. In contrast, targeted sen-
timent analysis has a more general setting.
Recently, Wang et al. (2011) proposed a topic-
oriented model, which extracts sentiments towards
certain topics from tweets. Topics in their model
resemble targets in our work, although topics are
represented by hashtags, which exists in 14.6%
tweets and 27.5% subjective tweets (Wang et al.,
</bodyText>
<figure confidence="0.9504515">
sentence: So excited to meet my baby Farah !!!
entity: O O O O O B I O
sentiment: Φ Φ Φ Φ Φ + + Φ
(a) pipeline or joint
</figure>
<page confidence="0.998287">
613
</page>
<bodyText confidence="0.996382745098039">
2011). In contrast, targeted sentiment analysis
can identify all the mentions to target entities in
tweets, thereby having a larger coverage. The
drawback is that the identification of mentions is
subject to errors, and thus suffers a lower preci-
sion compared to hashtag matching.
Sequence labeling models have been used for
extracting opinions and target entities as a joint
task. Jin et al. (2009) use HMM to extract opinion-
baring expressions and opinion targets. Li et al.
(2010) improve the results by using CRF to iden-
tify the opinion expressions and targets jointly.
The task is sometimes referred to as fine-grained
sentiment analysis (Wiebe et al., 2005). It is differ-
ent from our setting in that the predicate-argument
relation between opinion-baring expressions and
target entities are not explicitly modeled.
Recently, Yang and Cardie (2013) use CRF to
extract opinion-baring expressions, opinion hold-
ers and opinion targets simultaneously. Their
method is also centralized on opinion-baring ex-
pressions and therefore in line with Jin et al.
(2009) and Li et al. (2010). In contrast, targeted
sentiment analysis directly studies entity mentions
and the sentiment on each mention, without ex-
plicitly modeling the way in which the opinion is
expressed. As a result, our task is more useful for
applications such as broad-stroke reputation man-
agement, but offer less fine-grained operational in-
sight. It requires less fine-grained manual annota-
tion.
As discussed in the introduction, targeted sen-
timent analysis falls into two main settings. The
first is targeted sentiment classification, assum-
ing that entity mentions are given. Most previous
work fall under this category (Jiang et al., 2011;
Chen et al., 2012; Dong et al., 2014). The sec-
ond is open domain targeted sentiment, which has
been discussed by Mitchell et al. (2013). The task
jointly extracts entities and sentiment classes, and
is analogous to joint entity and relation extraction
(Li and Ji, 2014) in that both are information ex-
traction tasks with multi-label outputs.
Our work is related to the line of work on us-
ing neural networks for sentiment analysis. Socher
et al. (2011) use recursive auto-encoders for senti-
ment analysis on the sentence level. They further
extend the method to a syntactic treebank anno-
tated with sentiment labels (Socher et al., 2013).
More recently, Kalchbrenner et al. (2014) use a
dynamic pooling network to include the structure
</bodyText>
<figure confidence="0.855448">
step 1: entity
step 2: sentiment
(a) pipeline
(b) joint
(c) collapsed
</figure>
<figureCaption confidence="0.995561">
Figure 3: Discrete CRF models for pipeline, joint
and collapsed targeted sentiment labeling.
</figureCaption>
<bodyText confidence="0.989930388888889">
of a sentence automatically, before classifying its
sentiment. Zhou et al. (2014) apply deep belief
networks for semi-supervised sentiment classifica-
tion. dos Santos and Gatti (2014) use deep convo-
lution neural networks with rich features to clas-
sify sentiments over tweets and movie reviews.
These methods use different models to represent
sentence structures, performing sentiment analysis
on the sentence level, without modeling targets.
Dong et al. (2014) perform targeted sentiment
classification by using a recursive neural network
to model the transmission of sentiment signal from
opinion baring expressions to a target. They as-
sume that the target mention is given, and perform
three-way sentiment classification. In contrast, we
apply a structural neural model for open domain
targeted sentiment analysis, identifying and clas-
sifying all targets in a sentence simultaneously.
</bodyText>
<sectionHeader confidence="0.995693" genericHeader="method">
3 Discrete CRF Baselines
</sectionHeader>
<bodyText confidence="0.980424666666667">
As shown in Figure 2, the input x� to our tasks is a
word sequence. Assuming no external resources,
there is no POS given to each input word xi. For
</bodyText>
<figure confidence="0.999066786885246">
··· ■
�
�
■ ···
O
I
B
u
u
u
· · ·
· · ·
· · ·
my baby Farah
my (O)
baby (B)
Farah (I)
··· ■ Φ
� + + ■ ···
u
u
u
· · ·
· · ·
· · ·
my baby Farah
Φ
u
··· ■
■ ···
+
u
O
B
I
··· ■
■ ···
�
�
u
u
u
· · ·
· · ·
· · ·
�+ �
u
··· ■
�
�
■ ···
I+
B+
O
u
u
u
· · ·
· · ·
· · ·
my baby Farah
</figure>
<page confidence="0.99321">
614
</page>
<bodyText confidence="0.999897851851852">
the pipeline and collapsed tasks, there is a single
output label sequence ~y. For the joint task, there
are two label sequences y~and ~z, for entity and sen-
timent labels, respectively. We take the models of
Mitchell et al. (2013) as our baseline, which are
standard CRFs with discrete manual features. To
facilitate comparison between the discrete base-
line and our neural models, we give a unified for-
mulation to all the models in this paper, introduc-
ing the neural and integrated models as extensions
to the discrete models.
The baseline CRF structures for pipeline, joint
and collapsed targeted sentiment analysis are
shown in Figure 3(a), 3(b) and 3(c), respectively.
In the figures, the input features are represented as
black and white circles, indicating that they take
0/1 binary values. The labels O, B and I indi-
cate a non-target, the beginning of a target, and
part of a target, respectively. The labels +, −,
0 and Φ indicate positive, negative, neutral and
NULL sentiments, respectively. The NULL sen-
timent is assigned to O entities automatically, and
modeled as a hidden variable in the pipeline and
joint CRFs.1 The collapsed labels take combined
meanings from their components.
The links between labels and inputs represent
output clique potentials:
</bodyText>
<equation confidence="0.946939">
n o
Ψ(~x,yi) = exp θ~ · ~f(~x, yi) ,
</equation>
<bodyText confidence="0.9826952">
where ~f(~x, yi), is a discrete manual feature vector,
~
and θ is the model parameter vector.
The links between labels represent edge clique
potentials:
</bodyText>
<equation confidence="0.964166">
n o
Φ(~x, yi, yi−1) = exp τ(yi, yi−1) ,
</equation>
<bodyText confidence="0.9421497">
where τ(yi, yi−1) is the transition weight, which
is also a model parameter.
For both the pipeline and collapsed models, the
conditional probability of a label sequence given
an input sequence is:
surface features
word identity; word length; message length;
punctuation characters; has digit; has dash; is lower case;
is 3 or 4 letters; first letter capitalized; sentence position;
more than one letter capitalized; Jerboa features;
</bodyText>
<subsectionHeader confidence="0.831485">
linguistic features
</subsectionHeader>
<bodyText confidence="0.9322256">
function words; can syllabify; curse words;
laugh words; words for good, bad, no, my;
intensifiers; slang words; abbreviations;
common verb endings; common noun endings;
subjective suffixes and prefixes;
</bodyText>
<subsectionHeader confidence="0.500388">
cluster features
</subsectionHeader>
<bodyText confidence="0.77426">
Brown cluster at length 3; Brown cluster at length 5;
</bodyText>
<subsectionHeader confidence="0.814721">
sentiment features
</subsectionHeader>
<bodyText confidence="0.88431">
is sentiment-bearing word; prior sentiment polarity;
</bodyText>
<tableCaption confidence="0.979286">
Table 1: Discrete features.
</tableCaption>
<bodyText confidence="0.985506">
For the joint model, we apply a multi-label CRF
structure, where there are two separate sets of
output clique potentials Ψ1(~x,yi) and Ψ2(~x,zi)
and two separate sets of edge clique potentials
Φ1(~x, yi, yi−1) and Φ2(~x, zi, zi−1) for the label
sets {B, I, O} and {+,−,0}, respectively. In
the Figure 3(b), there are also links between the
span label yi and the sentiment label zi for each
word xi. These links indicate label dependencies,
which are constraints for decoding. For example,
if yi = O, then zi must be φ.
We apply Viterbi decoding for all tasks, and
training is performed using a max-margin objec-
tive, which is discussed in Section 6. Our training
algorithm is different from that of Mitchell et al.
(2013), but gives similar discrete CRF accuracies
in our experiments. Wang and Mori (2009) also
applied a max-margin trainig strategy to train CRF
models. The set of features is taken from Mitchell
et al. (2013) without changes, as shown in Table
1. Here the cluster features refer to Brown word
clusters (Brown et al., 1992).
where Z(~x) is the partition function:
</bodyText>
<equation confidence="0.9981996">
XZ(~x) = � Y|x |Ψ(~x, y0i) Y |x |�Φ(~x, y0 i, y0 i−1) ,
~y1 i=1 j=1
P(~y|~x) =
Y |x |Ψ(~x, yi)
i=1
|x|
Y Φ(~x, yi, yi−1)
j=1
,
Z(~x)
</equation>
<bodyText confidence="0.58688375">
1Note the difference between neural and NULL senti-
ments. The former indicates that a target does not bare any
sentiment, and the latter simply means that the term is not a
part of a target.
</bodyText>
<sectionHeader confidence="0.998896" genericHeader="method">
4 Neural Models
</sectionHeader>
<bodyText confidence="0.999502666666667">
We extend the discrete baseline system with two
salient changes, which are illustrated in Figure 4.
First, the input discrete features are replaced with
continuous word embeddings. Each node in the
input takes a real value between 0 and 1, as repre-
sented by grey nodes in Figure 4. Second, a hidden
</bodyText>
<page confidence="0.985695">
615
</page>
<figure confidence="0.998569984251968">
O
~ B �
· · ·
· · ·
11
0
· · ·
· · ·
I
my
baby
Farah
· · · �
�
�
■ ···
O
I
B
11
11
11
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
step 1: entity
my (O) baby (B) Farah (I)
step 2: sentiment
(a) pipeline
my baby Farah
· · · �
· · · �
· · ·
· · ·
O
4)
u
11
�
�
· · ·
· · ·
B
u
11
+
�
�
· · ·
· · ·
+
u
11
I
� · · ·
� · · ·
(b) joint
�+ _ + ■ ···
u
· · ·
· · ·
· · ·■ 4)
· · ·
· · ·
u
u
· · ·
· · ·
my baby Farah
step 1: entity
my (O) baby (B) Farah (I)
step 2: sentiment
(a) pipeline
my baby Farah
(b) joint
4) _ + _ +
· · ·
· · · · · ·
u
0
· · ·
O
4)
� + �
11
~ B �
· · ·
· · · · · ·
11
0
· · ·
+
I
my
baby
Farah
· · · �
�
�
� · · ·
O
I+
B+
11
11
11
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
O
~ B+ �
11
0
· · · · · ·
my baby Farah
I
· · ·
· · ·
(c) collapsed
(c) collapsed (c) collapsed
(c) collapsed
</figure>
<figureCaption confidence="0.99976925">
Figure 4: Neural networks for pipeline, joint and
Figure 5: Integrated models for pipeline, joint and
Figure 4: Neural networks for pipeline, joint and Figure 5: Integrated models for pipeline, joint and
collapsed targeted sentiment labeling.
</figureCaption>
<bodyText confidence="0.915545142857143">
collapsed targeted sentiment labeling.
collapsed targeted sentiment labeling. collapsed targeted sentiment labeling.
neural layer h~ is added between the input nodes x~
and the label nodes yi.
Formally, the links between the input nodes x~
and the hidden nodes ~hi for the node yi in Figure
4 represent a feature combination function:
</bodyText>
<equation confidence="0.9894905">
(~hi =tanh W.(e(~xi_2) ® e(~xi_1) ® e(~xi)
)® e(~xi+1) ® e(~xi+2)) +~b
</equation>
<bodyText confidence="0.9903146">
where e is the embedding lookup function, ® is
the vector concatenation function, the matrix W
and vector b~ are model parameters and tanh is the
activation function.
The output clique potential of yi becomes:
</bodyText>
<equation confidence="0.876406">
{IF(~x,yi) = exp σ~ · ~hi
</equation>
<bodyText confidence="0.999833142857143">
using a hidden layer for automatic feature com-
binations, the neural model is free of manual fea-
tures, and can benefit from unsupervised embed-
dings. Decoding and training are performed using
the same algorithms as the baseline.
The major neural architectures in Figure 4 have
been explored as conditional neural fields by Peng
et al. (2009) and neural conditional random fields
by Do et al. (2010), and is connected to the
sentence-level likelihood neural networks of Col-
lobert et al. (2011), as pointed out by Wang and
Manning (2013b). The main differences between
our model and the prior work are in the multi-label
settings and training details.
</bodyText>
<sectionHeader confidence="0.999726" genericHeader="method">
5 Integrated Models
</sectionHeader>
<bodyText confidence="0.997522333333333">
where σ~ is a model parameter, and the edge clique
where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neu-
Gleaning different sources of information, neu-
potentials remain the same as the baseline. By
ral features and discrete linear features comple-
potentials remain the same as the baseline. By ral features and discrete linear features comple-
</bodyText>
<page confidence="0.976824">
616
</page>
<bodyText confidence="0.98726496">
ments each other. As a result, a model that in-
tegrates both features can potentially achieve per-
formance improvements. Most work attempts to
add neural word embeddings into a discrete linear
model (Turian et al., 2010; Yu et al., 2013; Guo et
al., 2014), or add discreted features into a neural
model (Ma et al., 2014). We make a novel combi-
nation of the discrete models and the neural mod-
els by integrating both types of inputs into a same
CRF framework.2
The architectures of the integrated models are
shown in Figure 5. The main difference between
Figure 5 and Figure 3 is the input layer. The inte-
grated model takes both continuous word embed-
dings, which are shown in grey nodes, and dis-
crete manual features, which are shown in black
or white nodes, as the input.
A separate hidden layer is given to each type of
input nodes, with the hidden layer for the embed-
dings being the same as the neural baseline:
where (~xn, ~yn)|Nn=1 are the set of training ex-
amples, λ is a regularization parameter, and
l(~xn, ~yn, O) is the loss function towards one ex-
ample (~xn, ~yn).
The loss function is defined as:
</bodyText>
<equation confidence="0.998896333333333">
l(~xn, ~yn, O) = max (s(~xn, ~y, O) + δ(~y, ~yn))
y
− s(~xn, ~yn, O),
</equation>
<bodyText confidence="0.9966819">
where s(~x, ~y, O) = logP(~y|~x) is the log proba-
bility of ~y, and δ(~y, ~yn) is the Hamming distance
between y~and ~yn.
We use online learning to train model parame-
ters, updating the parameters using the AdaGrad
algorithm (Duchi et al., 2011). One thing to note
is that, our objective function is not differentiable
because of the loss function l(~xn, ~yn, O). Thus we
use sub-gradients for l(~xn, ~yn, O) instead, which
can be computed by the formula:
</bodyText>
<figure confidence="0.684104833333333">
(~hi =tanh W · (e(~xi−2) ⊕ e(~xi−1) ⊕ e(~xi) ∂l(~xn, ~yn, O) ∂s(~xn, ~ˆy, O) ∂s(~xn, ~yn, O)
∂O
∂O ,
∂O
⊕ e(~xi+1) ⊕ e(~xi+2)) + ) where y~ˆ is the predicted label sequence which cor-
~b
</figure>
<bodyText confidence="0.996877">
The hidden nodes ~gi between the discrete features
and the node yi are:
</bodyText>
<equation confidence="0.965218">
( )
~gi = tanh θ~ · ~f(~x, yi)
</equation>
<bodyText confidence="0.619936">
Finally, the output clique potential of yi becomes:
</bodyText>
<equation confidence="0.9945365">
{ �
~Ψ(~x, yi) = exp σ~ · (~hi ⊕ ~gi)
</equation>
<bodyText confidence="0.999744">
The edge clique potentials remain the same as the
baseline models; the same training and decoding
algorithms are used.
</bodyText>
<sectionHeader confidence="0.997092" genericHeader="method">
6 Training
</sectionHeader>
<bodyText confidence="0.99965725">
We use a max-margin objective to train our model
parameters O, which consist of ~θ, τ, W, b~ and σ~
for each model. The objective function is defined
as:
</bodyText>
<equation confidence="0.727507">
λ
l(~xn, ~yn, O) + 2 k O k2,
</equation>
<bodyText confidence="0.995095259259259">
2Wang and Manning (2013a) also investigated the inte-
gration of discrete and neural features in CRF models. They
compared the effect of integration without hidden layers (i.e.
Turian et al. (2010)) and with hidden layers (i.e. our meth-
ods) for NER and chunking, finding that the formal outper-
forms the latter. Our results are different from theirs, and a
hidden layer gives significant improvements to the targeted
sentiment analysis task.
responds to l(~xn, ~yn, O).
Maximum-likelihood training is a commonly
used alternative to max-margin training for neu-
ral networks. It has been applied to the models
of Do et al. (2010) and Collobert et al. (2011),
for example. However, our experiments show that
maximum-likelihood training cannot be applied to
open-domain targeted sentiment tasks. Although
giving comparable overall accuracies in both en-
tity and sentiment labels, it suffers from unbal-
anced sentiment labels, assigning the neutral sen-
timent to most entities. This problem can be ad-
dressed by imposing a polarity-sensitive cost to
the training, such as the sentence-level averaged
F1-score between positive, negative and neutral la-
bels. We skip these results due to space limita-
tions. In contrast, max-margin training does not
suffer from the label skew issue, thanks to the use
of Hamming loss in the objective function.
</bodyText>
<sectionHeader confidence="0.999928" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99918">
7.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.99003425">
Data: We use the data of Mitchell et al. (2013)3
to conduct all the experiments, which consist of
entity and sentiment annotations on both English
and Spanish tweets. Simple normalizations are
</bodyText>
<footnote confidence="0.552513">
3http://www.m-mitchell.com/code/index.html
</footnote>
<equation confidence="0.922135">
N
1
L(O) =
N
n=1
</equation>
<page confidence="0.992566">
617
</page>
<table confidence="0.997673333333333">
Domain #Sent #Entities #+ #- #0
English 2,350 3,288 707 275 2,306
Spanish 5,145 6,658 1,555 1,007 4,096
</table>
<tableCaption confidence="0.99957">
Table 2: Experimental corpus statistics.
</tableCaption>
<bodyText confidence="0.999860128205128">
conducted to replace all usernames and URLs into
the special tokens (username) and (url), respec-
tively. Following Mitchell et al. (2013), we report
ten-fold cross-validation results. During training,
we split 10% of the training corpus as the devel-
opment corpus to tune hyper-parameters. Table 2
shows the corpus statistics.
Parameters: For all the neural models, we set
the hidden layer size |h |for neural features to 200,
the hidden layer size |g |for discrete features to
30, the initial learning rate for adagrad to 0.01 and
the regularization parameter A to 10−8. English
and Spanish word embeddings are trained using
the word2vec tool4, with respective corpora of 20
minion random tweets crawled by tweet API5. The
size of word embeddings is 100. For English, there
are 8,061 unique words, for which 25% are out of
word embedding vocabulary (OOE) words, while
for Spanish, there are 14,648 unique words, for
which 15% are OOE words.
Metrics: We take full-span metrics for evalua-
tion, which is different from Mitchell et al. (2013),
who evaluate mainly the beginning of spans. We
measure the precision, recall and F-score of entity
recognition (Entity), targeted sentiment analysis
(SA) (both entity and sentiment), and targeted sub-
jectivity detection (Subjectivity) (both entity and
subjectivity, namely merging the + and - labels as
“1” label, and performing two-way 0/1 subjectiv-
ity classification on entities). For SA, an entity is
taken as correct only when the span and the sen-
timent are both correctly recognized. Similarly,
for Subjectivity, an entity is taken as correct only
when both the span and the subjectivity are cor-
rectly recognized.
Code: We make the C++ implementations of
the discrete, neural and combined models avail-
able and GPL, at https://github.com/
SUTDNLP/OpenTargetedSentiment.
</bodyText>
<subsectionHeader confidence="0.999932">
7.2 Comparing Neural and Discrete Models
</subsectionHeader>
<bodyText confidence="0.9996325">
The main results on both the English and Span-
ish dataset are shown in Table 3, which are mea-
</bodyText>
<footnote confidence="0.99958">
4https://code.google.com/p/word2vec/
5https://dev.twitter.com/
</footnote>
<figure confidence="0.914478">
.6 0.7 0.8 0.9 1
discrete
(b) Spanish
</figure>
<figureCaption confidence="0.999955">
Figure 6: Labeling accuracy comparisons.
</figureCaption>
<bodyText confidence="0.999979178571429">
sured on the pipeline, the joint and the collapsed
tasks, respectively. As can be seen from the ta-
ble, the neural models give higher F-scores than
the discrete CRF models on the English dataset,
while comparable overall F-scores on the Spanish
dataset. The gains on English are mostly attributed
to improved recalls, while the precision of the neu-
ral CRF models are relatively lower. A likely rea-
son for this observation is that the neural model
takes embedding inputs, which allow semantically
similar words to be represented with similar vec-
tors. As a result, the neural model can better cap-
ture patterns that do not occur in the training data.
In contrast, the discrete model is based on man-
ually defined binary features, which do not fire if
not contained in the training data. Because dis-
crete feature instantiation is based on exact match-
ing, the discrete model gives a relatively higher
precision.
To further contrast the discrete and neural mod-
els, we draw the per-word accuracies of sentiment
labels according to both models in Figure 6. In
the figure, each dot represents the accuracy of a
sentence, measured in the pipeline task. The dots
for both English and Spanish are scattered from
the reverse diagonal, showing that the two mod-
els make very different errors, which suggests that
model integration can lead to better accuracies.
</bodyText>
<subsectionHeader confidence="0.990627">
7.3 The Integrated Model
</subsectionHeader>
<bodyText confidence="0.9998919">
As shown in Table 3, the integrated model com-
bines the relative advantages of both pure models,
improving the recall over the discrete model and
the precision over the neural model. In most cases,
it gives the best results in terms of both precision
and recall. For the English pipeline model, the
integrated model improves the entity recognition
F-score from 43.84% to 55.67% (significant with
p &lt; 10−5 by pair-wise t-test) as compared to the
discrete baseline, namely Mitchell et al. (2013).
</bodyText>
<figure confidence="0.996960764705882">
1
neural
0.9
0.8
0.7
0.6
0
.6 0.7 0.8 0.9 1
discrete
(a) English
neural
0.9
0.8
0.7
0.6
0
1
</figure>
<page confidence="0.980556">
618
</page>
<table confidence="0.9982254">
English Spanish
Model Entity SA Entity SA
P R F P R F P R F P R F
Pipeline
discrete 59.37 34.83 43.84 42.97 25.21 31.73 70.77 47.75 57.00 46.55 31.38 37.47
neural 53.64 44.87 48.67 37.53 31.38 34.04 65.59 47.82 55.27 41.50 30.27 34.98
integrated 60.69 51.63 55.67 43.71 37.12 40.06 70.23 62.00 65.76 45.99 40.57 43.04
Joint
discrete 59.55 34.06 43.30 43.09 24.67 31.35 71.08 47.56 56.96 46.36 31.02 37.15
neural 54.45 42.12 47.17 37.55 28.95 32.45 65.05 47.79 55.07 40.28 29.58 34.09
integrated 61.47 49.28 54.59 44.62 35.84 39.67 71.32 61.11 65.74 46.67 39.99 43.02
Collapsed
discrete 64.16 26.03 36.95 48.35 19.64 27.86 73.18 35.11 47.42 49.85 23.91 32.30
neural 58.53 37.25 45.30 43.12 27.44 33.36 67.43 43.2 52.64 42.61 27.27 33.25
integrated 63.55 44.98 52.58 46.32 32.84 38.36 73.51 53.3 61.71 47.69 34.53 40.00
</table>
<tableCaption confidence="0.999389">
Table 3: Main results.
</tableCaption>
<figureCaption confidence="0.999204">
Figure 7: Effect of fine-tuning (+T — with fine-
tuning; -T — without fine-tuning).
</figureCaption>
<bodyText confidence="0.969579333333333">
The overall SA score is improved from 31.73% to
40.06% (p &lt; 10−5). Similar improvements are
achieved to the other test datasets.
</bodyText>
<subsectionHeader confidence="0.994834">
7.4 Fine-tuning Word Embeddings
</subsectionHeader>
<bodyText confidence="0.998381125">
In the experiments above, word embeddings are
fine-tuned for the neural models, but not for the
integrated models. By fine-tuning, embeddings of
in-vocabulary words are treated as model parame-
ters, and updated with other parameters in super-
vised training. This can improve the accuracy of
the model by significantly enlarging the parameter
space. However, it can make the embeddings of
OOV words less useful to the model, because the
hidden layers are tuned with adjusted embeddings.
Figure 7 shows the effectiveness of fine-tuning
on the neural and integrated models using the
Spanish data. Similar findings apply to the En-
glish data. The neural model heavily relies on
fine-tuning of embeddings, and a likely reason is
that manual discrete features offer sufficient pa-
rameters for capturing in-vocabulary patterns. On
the other hand, thanks to the rich discrete features
in parameter space, the integrated model does not
rely on fine-tuning of word embeddings, which
even caused slight overfitting and reduced the per-
formances. This makes the non-fine-tuned inte-
grated model potentially advantageous in handling
test data with many OOV words.
</bodyText>
<subsectionHeader confidence="0.687716">
7.5 Comparing pipeline, joint and collapsed
models
</subsectionHeader>
<bodyText confidence="0.999879083333333">
Mitchell et al. (2013) find that for discrete CRF,
the pipeline task gives competitive overall perfor-
mances compared with the joint task. This sug-
gests a relatively weak connection between entity
boundary information and sentiment classes. We
re-examine the comparisons under the neural net-
work setting, where automatic feature combina-
tions can be useful in capturing more subtle cor-
relations between two sources of information.
As shown in Table 3, the overall results are sim-
ilar to those of Mitchell et al. (2013), with both
the neural and the integrated models demonstrat-
ing the same trends as the discrete baselines. A
more detail analysis, however, shows some rela-
tive strengths of the joint task. Table 4 give the
precision, recall and F-scores of subjectivity, and
those of SA excluding neutral sentiment labels on
the Spanish data. Findings on the English dataset
are consistent.
The latter metrics highlight sentiment polarities,
which can be relatively more useful. The joint task
gives better F-scores on both metrics, which sug-
gest that is a considerable choice for open targeted
sentiment. When there is external resource for en-
</bodyText>
<figure confidence="0.998501384615385">
(a) Neural (b) Integrated
35
30
25
20
pipeline joint collapsed
-T +T
44
42
40
38
pipeline joint collapsed
-T +T
</figure>
<page confidence="0.987834">
619
</page>
<table confidence="0.998306166666667">
Subjectivity SA/0
Model
P R F P R F
pipeline 47.92 42.26 44.84 42.93 18.02 25.14
joint 49.17 42.13 45.32 40.93 21.62 27.93
collapsed 49.63 35.94 41.63 42.10 15.62 22.49
</table>
<tableCaption confidence="0.99985">
Table 4: Results on subjectivity and polarity.
</tableCaption>
<bodyText confidence="0.999876333333333">
tity recognition, the pipeline can be a favorable
choice. On the other hand, although useful for
some joint sequence labeling task (Ng and Low,
2004), the collapsed task does not seem to address
the joint sentiment task as effectively. We find this
result empirical, but consistent across our datasets.
</bodyText>
<sectionHeader confidence="0.998456" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999979363636364">
We explored open domain targeted sentiment
analysis using neural network models, which
gave competitive results when evaluated against
a strong discrete CRF baseline, with relatively
higher recalls. Given complementary error dis-
tributions by the discrete and neural CRFs, we
proposed a novel combination which significantly
outperformed both models. Under the neural set-
ting, we find that it is preferable to solve open tar-
geted sentiment as a pipeline or joint multi-label
task, but not as a joint task with collapsed labels.
</bodyText>
<sectionHeader confidence="0.997237" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999809666666667">
We thank the anonymous reviewers for their con-
structive comments, which helped to improve the
paper. This work is supported by the Singapore
Ministry of Education (MOE) AcRF Tier 2 grant
T2MOE201301 and SRG ISTD 2012 038 from
Singapore University of Technology and Design.
</bodyText>
<sectionHeader confidence="0.9979" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9990978">
Peter F Brown, Peter V Desouza, Robert L Mercer,
Vincent J Della Pietra, and Jenifer C Lai. 1992.
Class-based n-gram models of natural language.
Computational linguistics, 18(4):467–479.
Lu Chen, Wenbo Wang, Meenakshi Nagarajan, Shao-
jun Wang, and Amit P Sheth. 2012. Extracting
diverse sentiment expressions with target-dependent
polarity from twitter. In ICWSM.
R. Collobert, J. Weston, L. Bottou, M. Karlen,
K. Kavukcuoglu, and P. Kuksa. 2011. Natural lan-
guage processing (almost) from scratch. Journal of
Machine Learning Research, 12:2493–2537.
Trinh Do, Thierry Arti, et al. 2010. Neural conditional
random fields. In International Conference on Arti-
ficial Intelligence and Statistics, pages 177–184.
Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming
Zhou, and Ke Xu. 2014. Adaptive recursive neural
network for target-dependent twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(Volume 2: Short Papers), pages 49–54.
Cicero dos Santos and Maira Gatti. 2014. Deep con-
volutional neural networks for sentiment analysis
of short texts. In Proceedings of COLING 2014,
the 25th International Conference on Computational
Linguistics: Technical Papers, pages 69–78.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. The Journal of Ma-
chine Learning Research, 12:2121–2159.
Jenny Rose Finkel and Christopher D Manning. 2009.
Joint parsing and named entity recognition. In Pro-
ceedings of Human Language Technologies: The
2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 326–334.
Jiang Guo, Wanxiang Che, Haifeng Wang, and Ting
Liu. 2014. Revisiting embedding features for sim-
ple semi-supervised learning. In Proceedings of the
2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 110–120.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 168–177.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single-and cross-domain setting
with conditional random fields. In Proceedings of
the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1035–1045.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
timent classification. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
151–160.
Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009.
A novel lexicalized hmm-based learning framework
for web opinion mining. In Proceedings of the
26th Annual International Conference on Machine
Learning, pages 465–472.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for
modelling sentences. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers), pages
655–665.
Qi Li and Heng Ji. 2014. Incremental joint extraction
of entity mentions and relations. In Proceedings of
the Association for Computational Linguistics.
</reference>
<page confidence="0.970334">
620
</page>
<reference confidence="0.999856489795918">
Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,
Ying-Ju Xia, Shu Zhang, and Hao Yu. 2010.
Structure-aware review mining and summarization.
In Proceedings of the 23rd International Conference
on Computational Linguistics, pages 653–661.
Ji Ma, Yue Zhang, and Jingbo Zhu. 2014. Tagging
the web: Building a robust web tagger with neural
network. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 144–154.
Margaret Mitchell, Jacqui Aguilar, Theresa Wilson,
and Benjamin Van Durme. 2013. Open domain tar-
geted sentiment. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1643–1654.
Hwee Tou Ng and Jin Kiat Low. 2004. Chinese part-
of-speech tagging: One-at-a-time or all-at-once?
word-based or character-based? In EMNLP, pages
277–284.
Jian Peng, Liefeng Bo, and Jinbo Xu. 2009. Condi-
tional neural fields. In Advances in neural informa-
tion processing systems, pages 1419–1427.
Ana-Maria Popescu and Orena Etzioni. 2007. Extract-
ing product features and opinions from reviews. In
Natural language processing and text mining, pages
9–28. Springer.
Richard Socher, Jeffrey Pennington, Eric H Huang,
Andrew Y Ng, and Christopher D Manning. 2011.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 151–161.
Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the conference on
empirical methods in natural language processing
(EMNLP), volume 1631, page 1642.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 384–394.
Duy-Tin Vo and Yue Zhang. 2015. Target-dependent
twitter sentiment classification with rich automatic
features. In Proceedings of the Twenty-Fourth Inter-
national Joint Conference on Artificial Intelligence
(IJCAI2015), pages 1347–1353.
Mengqiu Wang and Christopher D. Manning. 2013a.
Effect of non-linear deep architecture in sequence
labeling. In Proceedings of the Sixth International
Joint Conference on Natural Language Processing,
pages 1285–1291.
Sida Wang and Christopher Manning. 2013b. Fast
dropout training. In Proceedings of the 30th Inter-
national Conference on Machine Learning (ICML-
13), pages 118–126.
Yang Wang and Greg Mori. 2009. Max-margin hidden
conditional random fields for human action recogni-
tion. In Computer Vision and Pattern Recognition,
2009. CVPR 2009. IEEE Conference on, pages 872–
879.
Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou,
and Ming Zhang. 2011. Topic sentiment analysis
in twitter: a graph-based hashtag sentiment classifi-
cation approach. In Proceedings of the 20th ACM
international conference on Information and knowl-
edge management, pages 1031–1040.
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language resources and evalua-
tion, 39(2-3):165–210.
Bishan Yang and Claire Cardie. 2013. Joint infer-
ence for fine-grained opinion extraction. In ACL (1),
pages 1640–1649.
Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu, and
Wayne Niblack. 2003. Sentiment analyzer: Extract-
ing sentiments about a given topic using natural lan-
guage processing techniques. In Data Mining, 2003.
ICDM 2003. Third IEEE International Conference
on, pages 427–434.
Mo Yu, Tiejun Zhao, Daxiang Dong, Hao Tian, and
Dianhai Yu. 2013. Compound embedding features
for semi-supervised learning. In Proceedings of the
2013 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 563–568.
Yue Zhang and Stephen Clark. 2008. Joint word seg-
mentation and POS tagging using a single percep-
tron. In Proceedings of ACL-08: HLT, pages 888–
896.
Shusen Zhou, Qingcai Chen, Xiaolong Wang, and Xi-
aoling Li. 2014. Hybrid deep belief networks for
semi-supervised sentiment classification. In Pro-
ceedings of COLING 2014, the 25th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 1341–1349.
</reference>
<page confidence="0.998312">
621
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.907932">
<title confidence="0.998609">Neural Networks for Open Domain Targeted Sentiment</title>
<author confidence="0.999712">Zhang Zhang</author>
<affiliation confidence="0.978481">Singapore University of Technology and</affiliation>
<abstract confidence="0.995765782608696">zhang, yue duytin vo@mymail.sutd.edu.sg Abstract Open domain targeted sentiment is the joint information extraction task that finds target mentions together with the sentiment towards each mention from a text corpus. The task is typically modeled as a sequence labeling problem, and solved using state-of-the-art labelers such as CRF. We empirically study the effect of word embeddings and automatic feature combinations on the task by extending a CRF baseline using neural networks, which have demonstrated large potentials for sentiment analysis. Results show that the neural model can give better results by significantly increasing the recall. In addition, we propose a novel integration of neural and discrete features, which combines their relative advantages, leading to significantly higher results compared to both baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V Desouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="15422" citStr="Brown et al., 1992" startWordPosition="2538" endWordPosition="2541">label dependencies, which are constraints for decoding. For example, if yi = O, then zi must be φ. We apply Viterbi decoding for all tasks, and training is performed using a max-margin objective, which is discussed in Section 6. Our training algorithm is different from that of Mitchell et al. (2013), but gives similar discrete CRF accuracies in our experiments. Wang and Mori (2009) also applied a max-margin trainig strategy to train CRF models. The set of features is taken from Mitchell et al. (2013) without changes, as shown in Table 1. Here the cluster features refer to Brown word clusters (Brown et al., 1992). where Z(~x) is the partition function: XZ(~x) = � Y|x |Ψ(~x, y0i) Y |x |�Φ(~x, y0 i, y0 i−1) , ~y1 i=1 j=1 P(~y|~x) = Y |x |Ψ(~x, yi) i=1 |x| Y Φ(~x, yi, yi−1) j=1 , Z(~x) 1Note the difference between neural and NULL sentiments. The former indicates that a target does not bare any sentiment, and the latter simply means that the term is not a part of a target. 4 Neural Models We extend the discrete baseline system with two salient changes, which are illustrated in Figure 4. First, the input discrete features are replaced with continuous word embeddings. Each node in the input takes a real val</context>
</contexts>
<marker>Brown, Desouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F Brown, Peter V Desouza, Robert L Mercer, Vincent J Della Pietra, and Jenifer C Lai. 1992. Class-based n-gram models of natural language. Computational linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Chen</author>
<author>Wenbo Wang</author>
<author>Meenakshi Nagarajan</author>
<author>Shaojun Wang</author>
<author>Amit P Sheth</author>
</authors>
<title>Extracting diverse sentiment expressions with target-dependent polarity from twitter.</title>
<date>2012</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="2851" citStr="Chen et al., 2012" startWordPosition="445" endWordPosition="448">to all persons and organizations, together with the sentiments towards each mention, from a news archive or a collection of novels. There are two sub tasks in targeted sentiment analysis, namely entity recognition and sentiment classification for each entity mention which apply to both scenarios above. In scenario (1), entity recognition is relatively trivial, and can typically be achieved by pattern matching. Partly due to this reason, most previous work has addressed targeted sentiment analysis as a pure classification task, assuming that target mentions have been given (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014; Vo and Zhang, 2015). For scenario (2), a named entity recognition (NER) system can be used to extract targets, before the same targeted sentiment classification algorithms are applied. There has also been work that concentrates on extracting opinion targets (Jin et al., 2009; Jakob and Gurevych, 2010). In both cases, the data in Figure 1 can be used for training sentiment classifiers. Mitchell et al. (2013) took a different approach, extracting named entities and their sentiment classes jointly. They model the joint task 612 Proceedings of the 2015 Conference on Empirical </context>
<context position="9838" citStr="Chen et al., 2012" startWordPosition="1571" endWordPosition="1574">sentiment analysis directly studies entity mentions and the sentiment on each mention, without explicitly modeling the way in which the opinion is expressed. As a result, our task is more useful for applications such as broad-stroke reputation management, but offer less fine-grained operational insight. It requires less fine-grained manual annotation. As discussed in the introduction, targeted sentiment analysis falls into two main settings. The first is targeted sentiment classification, assuming that entity mentions are given. Most previous work fall under this category (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014). The second is open domain targeted sentiment, which has been discussed by Mitchell et al. (2013). The task jointly extracts entities and sentiment classes, and is analogous to joint entity and relation extraction (Li and Ji, 2014) in that both are information extraction tasks with multi-label outputs. Our work is related to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Soc</context>
</contexts>
<marker>Chen, Wang, Nagarajan, Wang, Sheth, 2012</marker>
<rawString>Lu Chen, Wenbo Wang, Meenakshi Nagarajan, Shaojun Wang, and Amit P Sheth. 2012. Extracting diverse sentiment expressions with target-dependent polarity from twitter. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
<author>J Weston</author>
<author>L Bottou</author>
<author>M Karlen</author>
<author>K Kavukcuoglu</author>
<author>P Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="18266" citStr="Collobert et al. (2011)" startWordPosition="3174" endWordPosition="3178">or b~ are model parameters and tanh is the activation function. The output clique potential of yi becomes: {IF(~x,yi) = exp σ~ · ~hi using a hidden layer for automatic feature combinations, the neural model is free of manual features, and can benefit from unsupervised embeddings. Decoding and training are performed using the same algorithms as the baseline. The major neural architectures in Figure 4 have been explored as conditional neural fields by Peng et al. (2009) and neural conditional random fields by Do et al. (2010), and is connected to the sentence-level likelihood neural networks of Collobert et al. (2011), as pointed out by Wang and Manning (2013b). The main differences between our model and the prior work are in the multi-label settings and training details. 5 Integrated Models where σ~ is a model parameter, and the edge clique where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete linear features complepotentials remain the same as the baseline. By ral features and discrete linear features comple616 ments each other. As a result, a m</context>
<context position="21803" citStr="Collobert et al. (2011)" startWordPosition="3806" endWordPosition="3809">so investigated the integration of discrete and neural features in CRF models. They compared the effect of integration without hidden layers (i.e. Turian et al. (2010)) and with hidden layers (i.e. our methods) for NER and chunking, finding that the formal outperforms the latter. Our results are different from theirs, and a hidden layer gives significant improvements to the targeted sentiment analysis task. responds to l(~xn, ~yn, O). Maximum-likelihood training is a commonly used alternative to max-margin training for neural networks. It has been applied to the models of Do et al. (2010) and Collobert et al. (2011), for example. However, our experiments show that maximum-likelihood training cannot be applied to open-domain targeted sentiment tasks. Although giving comparable overall accuracies in both entity and sentiment labels, it suffers from unbalanced sentiment labels, assigning the neutral sentiment to most entities. This problem can be addressed by imposing a polarity-sensitive cost to the training, such as the sentence-level averaged F1-score between positive, negative and neutral labels. We skip these results due to space limitations. In contrast, max-margin training does not suffer from the la</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trinh Do</author>
<author>Thierry Arti</author>
</authors>
<title>Neural conditional random fields.</title>
<date>2010</date>
<booktitle>In International Conference on Artificial Intelligence and Statistics,</booktitle>
<pages>177--184</pages>
<marker>Do, Arti, 2010</marker>
<rawString>Trinh Do, Thierry Arti, et al. 2010. Neural conditional random fields. In International Conference on Artificial Intelligence and Statistics, pages 177–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Dong</author>
<author>Furu Wei</author>
<author>Chuanqi Tan</author>
<author>Duyu Tang</author>
<author>Ming Zhou</author>
<author>Ke Xu</author>
</authors>
<title>Adaptive recursive neural network for target-dependent twitter sentiment classification.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>49--54</pages>
<contexts>
<context position="2870" citStr="Dong et al., 2014" startWordPosition="449" endWordPosition="452">organizations, together with the sentiments towards each mention, from a news archive or a collection of novels. There are two sub tasks in targeted sentiment analysis, namely entity recognition and sentiment classification for each entity mention which apply to both scenarios above. In scenario (1), entity recognition is relatively trivial, and can typically be achieved by pattern matching. Partly due to this reason, most previous work has addressed targeted sentiment analysis as a pure classification task, assuming that target mentions have been given (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014; Vo and Zhang, 2015). For scenario (2), a named entity recognition (NER) system can be used to extract targets, before the same targeted sentiment classification algorithms are applied. There has also been work that concentrates on extracting opinion targets (Jin et al., 2009; Jakob and Gurevych, 2010). In both cases, the data in Figure 1 can be used for training sentiment classifiers. Mitchell et al. (2013) took a different approach, extracting named entities and their sentiment classes jointly. They model the joint task 612 Proceedings of the 2015 Conference on Empirical Methods in Natural </context>
<context position="9858" citStr="Dong et al., 2014" startWordPosition="1575" endWordPosition="1578">directly studies entity mentions and the sentiment on each mention, without explicitly modeling the way in which the opinion is expressed. As a result, our task is more useful for applications such as broad-stroke reputation management, but offer less fine-grained operational insight. It requires less fine-grained manual annotation. As discussed in the introduction, targeted sentiment analysis falls into two main settings. The first is targeted sentiment classification, assuming that entity mentions are given. Most previous work fall under this category (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014). The second is open domain targeted sentiment, which has been discussed by Mitchell et al. (2013). The task jointly extracts entities and sentiment classes, and is analogous to joint entity and relation extraction (Li and Ji, 2014) in that both are information extraction tasks with multi-label outputs. Our work is related to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Socher et al., 2013). M</context>
<context position="11176" citStr="Dong et al. (2014)" startWordPosition="1781" endWordPosition="1784"> 1: entity step 2: sentiment (a) pipeline (b) joint (c) collapsed Figure 3: Discrete CRF models for pipeline, joint and collapsed targeted sentiment labeling. of a sentence automatically, before classifying its sentiment. Zhou et al. (2014) apply deep belief networks for semi-supervised sentiment classification. dos Santos and Gatti (2014) use deep convolution neural networks with rich features to classify sentiments over tweets and movie reviews. These methods use different models to represent sentence structures, performing sentiment analysis on the sentence level, without modeling targets. Dong et al. (2014) perform targeted sentiment classification by using a recursive neural network to model the transmission of sentiment signal from opinion baring expressions to a target. They assume that the target mention is given, and perform three-way sentiment classification. In contrast, we apply a structural neural model for open domain targeted sentiment analysis, identifying and classifying all targets in a sentence simultaneously. 3 Discrete CRF Baselines As shown in Figure 2, the input x� to our tasks is a word sequence. Assuming no external resources, there is no POS given to each input word xi. For</context>
</contexts>
<marker>Dong, Wei, Tan, Tang, Zhou, Xu, 2014</marker>
<rawString>Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming Zhou, and Ke Xu. 2014. Adaptive recursive neural network for target-dependent twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cicero dos Santos</author>
<author>Maira Gatti</author>
</authors>
<title>Deep convolutional neural networks for sentiment analysis of short texts.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>69--78</pages>
<contexts>
<context position="6067" citStr="Santos and Gatti, 2014" startWordPosition="972" endWordPosition="976">ly-coupled sources of information, such as word boundaries and POS (Zhang and Clark, 2008), or named entities and constituents (Finkel and Manning, 2009), for which joint models significantly outperform pipeline models. On the other hand, there do exist cases where entity boundaries and sentiment classes reinforce each other. For example, in a tweet such as ‘I like X.’, the contextual pattern indicate both a positive sentiment and an entity in the place of X. Recently, neural network models have been increasingly used for sentiment analysis (Socher et al., 2013; Kalchbrenner et al., 2014; dos Santos and Gatti, 2014), achieving highly competitive results, which show large potentials of neural network models for this task. The main advantages of neural networks are two-fold. First, neural models use real-valued hidden layers to automatically learn feature combinations, which can capture complex semantic information that are difficult to express using traditional discrete manual features. Second, neural networks take distributed word embeddings as inputs, which can be trained from large-scale raw text, thus alleviating the scarcity of annotated data to some extent. In this paper, we exploit structured neura</context>
<context position="10899" citStr="Santos and Gatti (2014)" startWordPosition="1740" endWordPosition="1743"> recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Socher et al., 2013). More recently, Kalchbrenner et al. (2014) use a dynamic pooling network to include the structure step 1: entity step 2: sentiment (a) pipeline (b) joint (c) collapsed Figure 3: Discrete CRF models for pipeline, joint and collapsed targeted sentiment labeling. of a sentence automatically, before classifying its sentiment. Zhou et al. (2014) apply deep belief networks for semi-supervised sentiment classification. dos Santos and Gatti (2014) use deep convolution neural networks with rich features to classify sentiments over tweets and movie reviews. These methods use different models to represent sentence structures, performing sentiment analysis on the sentence level, without modeling targets. Dong et al. (2014) perform targeted sentiment classification by using a recursive neural network to model the transmission of sentiment signal from opinion baring expressions to a target. They assume that the target mention is given, and perform three-way sentiment classification. In contrast, we apply a structural neural model for open do</context>
</contexts>
<marker>Santos, Gatti, 2014</marker>
<rawString>Cicero dos Santos and Maira Gatti. 2014. Deep convolutional neural networks for sentiment analysis of short texts. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 69–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Duchi</author>
<author>Elad Hazan</author>
<author>Yoram Singer</author>
</authors>
<title>Adaptive subgradient methods for online learning and stochastic optimization.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>12--2121</pages>
<contexts>
<context position="20250" citStr="Duchi et al., 2011" startWordPosition="3526" endWordPosition="3529">en to each type of input nodes, with the hidden layer for the embeddings being the same as the neural baseline: where (~xn, ~yn)|Nn=1 are the set of training examples, λ is a regularization parameter, and l(~xn, ~yn, O) is the loss function towards one example (~xn, ~yn). The loss function is defined as: l(~xn, ~yn, O) = max (s(~xn, ~y, O) + δ(~y, ~yn)) y − s(~xn, ~yn, O), where s(~x, ~y, O) = logP(~y|~x) is the log probability of ~y, and δ(~y, ~yn) is the Hamming distance between y~and ~yn. We use online learning to train model parameters, updating the parameters using the AdaGrad algorithm (Duchi et al., 2011). One thing to note is that, our objective function is not differentiable because of the loss function l(~xn, ~yn, O). Thus we use sub-gradients for l(~xn, ~yn, O) instead, which can be computed by the formula: (~hi =tanh W · (e(~xi−2) ⊕ e(~xi−1) ⊕ e(~xi) ∂l(~xn, ~yn, O) ∂s(~xn, ~ˆy, O) ∂s(~xn, ~yn, O) ∂O ∂O , ∂O ⊕ e(~xi+1) ⊕ e(~xi+2)) + ) where y~ˆ is the predicted label sequence which cor~b The hidden nodes ~gi between the discrete features and the node yi are: ( ) ~gi = tanh θ~ · ~f(~x, yi) Finally, the output clique potential of yi becomes: { � ~Ψ(~x, yi) = exp σ~ · (~hi ⊕ ~gi) The edge cl</context>
</contexts>
<marker>Duchi, Hazan, Singer, 2011</marker>
<rawString>John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121–2159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint parsing and named entity recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>326--334</pages>
<contexts>
<context position="5597" citStr="Finkel and Manning, 2009" startWordPosition="894" endWordPosition="897">apsed labels allow joint entity recognition and sentiment classification to be achieved using a standard sequence labeler. Mitchell et al. (2013) compare a pipeline model, a joint model and a collapsed model under the same conditional random field (CRF) framework, finding that the pipeline method outperforms the joint model on a tweet dataset. Intuitively, the interaction between entity boundaries and sentiment classes might not be as strong as that between more closely-coupled sources of information, such as word boundaries and POS (Zhang and Clark, 2008), or named entities and constituents (Finkel and Manning, 2009), for which joint models significantly outperform pipeline models. On the other hand, there do exist cases where entity boundaries and sentiment classes reinforce each other. For example, in a tweet such as ‘I like X.’, the contextual pattern indicate both a positive sentiment and an entity in the place of X. Recently, neural network models have been increasingly used for sentiment analysis (Socher et al., 2013; Kalchbrenner et al., 2014; dos Santos and Gatti, 2014), achieving highly competitive results, which show large potentials of neural network models for this task. The main advantages of</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D Manning. 2009. Joint parsing and named entity recognition. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 326–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Guo</author>
<author>Wanxiang Che</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
</authors>
<title>Revisiting embedding features for simple semi-supervised learning.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>110--120</pages>
<contexts>
<context position="19085" citStr="Guo et al., 2014" startWordPosition="3311" endWordPosition="3314">meter, and the edge clique where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete linear features complepotentials remain the same as the baseline. By ral features and discrete linear features comple616 ments each other. As a result, a model that integrates both features can potentially achieve performance improvements. Most work attempts to add neural word embeddings into a discrete linear model (Turian et al., 2010; Yu et al., 2013; Guo et al., 2014), or add discreted features into a neural model (Ma et al., 2014). We make a novel combination of the discrete models and the neural models by integrating both types of inputs into a same CRF framework.2 The architectures of the integrated models are shown in Figure 5. The main difference between Figure 5 and Figure 3 is the input layer. The integrated model takes both continuous word embeddings, which are shown in grey nodes, and discrete manual features, which are shown in black or white nodes, as the input. A separate hidden layer is given to each type of input nodes, with the hidden layer </context>
</contexts>
<marker>Guo, Che, Wang, Liu, 2014</marker>
<rawString>Jiang Guo, Wanxiang Che, Haifeng Wang, and Ting Liu. 2014. Revisiting embedding features for simple semi-supervised learning. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 110–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="7454" citStr="Hu and Liu, 2004" startWordPosition="1191" endWordPosition="1194">parison between discrete and neural CRF models, and further combine the strengths of each model via feature integration. Second, we compare the effects of the pipeline, joint and collapsed models for open targeted sentiment analysis under the neural model settings. Our experiments show that the neural model gives competitive results compared with the discrete baseline, with relatively higher recalls. In addition, the integrated model significantly improves over both the discrete and the neural models. 2 Related Work Targeted sentiment analysis is closely related prior work on aspect-oriented (Hu and Liu, 2004), feature-oriented (Popescu and Etzioni, 2007) and topic-oriented (Yi et al., 2003) sentiment analysis. These related tasks are typically concentrated on product review settings. In contrast, targeted sentiment analysis has a more general setting. Recently, Wang et al. (2011) proposed a topicoriented model, which extracts sentiments towards certain topics from tweets. Topics in their model resemble targets in our work, although topics are represented by hashtags, which exists in 14.6% tweets and 27.5% subjective tweets (Wang et al., sentence: So excited to meet my baby Farah !!! entity: O O O </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single-and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1035--1045</pages>
<contexts>
<context position="3174" citStr="Jakob and Gurevych, 2010" startWordPosition="497" endWordPosition="500"> (1), entity recognition is relatively trivial, and can typically be achieved by pattern matching. Partly due to this reason, most previous work has addressed targeted sentiment analysis as a pure classification task, assuming that target mentions have been given (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014; Vo and Zhang, 2015). For scenario (2), a named entity recognition (NER) system can be used to extract targets, before the same targeted sentiment classification algorithms are applied. There has also been work that concentrates on extracting opinion targets (Jin et al., 2009; Jakob and Gurevych, 2010). In both cases, the data in Figure 1 can be used for training sentiment classifiers. Mitchell et al. (2013) took a different approach, extracting named entities and their sentiment classes jointly. They model the joint task 612 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 612–621, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. sentence: So excited to meet my baby Farah !!! collapsed: O O O O O B+ I+ O (b) collapsed Figure 2: Pipeline, joint and collapsed models for open targeted sentiment analysis. as </context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting opinion targets in a single-and cross-domain setting with conditional random fields. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1035–1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>151--160</pages>
<contexts>
<context position="2832" citStr="Jiang et al., 2011" startWordPosition="441" endWordPosition="444">acting the mentions to all persons and organizations, together with the sentiments towards each mention, from a news archive or a collection of novels. There are two sub tasks in targeted sentiment analysis, namely entity recognition and sentiment classification for each entity mention which apply to both scenarios above. In scenario (1), entity recognition is relatively trivial, and can typically be achieved by pattern matching. Partly due to this reason, most previous work has addressed targeted sentiment analysis as a pure classification task, assuming that target mentions have been given (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014; Vo and Zhang, 2015). For scenario (2), a named entity recognition (NER) system can be used to extract targets, before the same targeted sentiment classification algorithms are applied. There has also been work that concentrates on extracting opinion targets (Jin et al., 2009; Jakob and Gurevych, 2010). In both cases, the data in Figure 1 can be used for training sentiment classifiers. Mitchell et al. (2013) took a different approach, extracting named entities and their sentiment classes jointly. They model the joint task 612 Proceedings of the 2015 Confe</context>
<context position="9819" citStr="Jiang et al., 2011" startWordPosition="1567" endWordPosition="1570"> contrast, targeted sentiment analysis directly studies entity mentions and the sentiment on each mention, without explicitly modeling the way in which the opinion is expressed. As a result, our task is more useful for applications such as broad-stroke reputation management, but offer less fine-grained operational insight. It requires less fine-grained manual annotation. As discussed in the introduction, targeted sentiment analysis falls into two main settings. The first is targeted sentiment classification, assuming that entity mentions are given. Most previous work fall under this category (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014). The second is open domain targeted sentiment, which has been discussed by Mitchell et al. (2013). The task jointly extracts entities and sentiment classes, and is analogous to joint entity and relation extraction (Li and Ji, 2014) in that both are information extraction tasks with multi-label outputs. Our work is related to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with se</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 151–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
<author>Rohini K Srihari</author>
</authors>
<title>A novel lexicalized hmm-based learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning,</booktitle>
<pages>465--472</pages>
<contexts>
<context position="3147" citStr="Jin et al., 2009" startWordPosition="493" endWordPosition="496">above. In scenario (1), entity recognition is relatively trivial, and can typically be achieved by pattern matching. Partly due to this reason, most previous work has addressed targeted sentiment analysis as a pure classification task, assuming that target mentions have been given (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014; Vo and Zhang, 2015). For scenario (2), a named entity recognition (NER) system can be used to extract targets, before the same targeted sentiment classification algorithms are applied. There has also been work that concentrates on extracting opinion targets (Jin et al., 2009; Jakob and Gurevych, 2010). In both cases, the data in Figure 1 can be used for training sentiment classifiers. Mitchell et al. (2013) took a different approach, extracting named entities and their sentiment classes jointly. They model the joint task 612 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 612–621, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. sentence: So excited to meet my baby Farah !!! collapsed: O O O O O B+ I+ O (b) collapsed Figure 2: Pipeline, joint and collapsed models for open targe</context>
<context position="8516" citStr="Jin et al. (2009)" startWordPosition="1366" endWordPosition="1369">presented by hashtags, which exists in 14.6% tweets and 27.5% subjective tweets (Wang et al., sentence: So excited to meet my baby Farah !!! entity: O O O O O B I O sentiment: Φ Φ Φ Φ Φ + + Φ (a) pipeline or joint 613 2011). In contrast, targeted sentiment analysis can identify all the mentions to target entities in tweets, thereby having a larger coverage. The drawback is that the identification of mentions is subject to errors, and thus suffers a lower precision compared to hashtag matching. Sequence labeling models have been used for extracting opinions and target entities as a joint task. Jin et al. (2009) use HMM to extract opinionbaring expressions and opinion targets. Li et al. (2010) improve the results by using CRF to identify the opinion expressions and targets jointly. The task is sometimes referred to as fine-grained sentiment analysis (Wiebe et al., 2005). It is different from our setting in that the predicate-argument relation between opinion-baring expressions and target entities are not explicitly modeled. Recently, Yang and Cardie (2013) use CRF to extract opinion-baring expressions, opinion holders and opinion targets simultaneously. Their method is also centralized on opinion-bar</context>
</contexts>
<marker>Jin, Ho, Srihari, 2009</marker>
<rawString>Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009. A novel lexicalized hmm-based learning framework for web opinion mining. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A convolutional neural network for modelling sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>655--665</pages>
<contexts>
<context position="6038" citStr="Kalchbrenner et al., 2014" startWordPosition="967" endWordPosition="970">rong as that between more closely-coupled sources of information, such as word boundaries and POS (Zhang and Clark, 2008), or named entities and constituents (Finkel and Manning, 2009), for which joint models significantly outperform pipeline models. On the other hand, there do exist cases where entity boundaries and sentiment classes reinforce each other. For example, in a tweet such as ‘I like X.’, the contextual pattern indicate both a positive sentiment and an entity in the place of X. Recently, neural network models have been increasingly used for sentiment analysis (Socher et al., 2013; Kalchbrenner et al., 2014; dos Santos and Gatti, 2014), achieving highly competitive results, which show large potentials of neural network models for this task. The main advantages of neural networks are two-fold. First, neural models use real-valued hidden layers to automatically learn feature combinations, which can capture complex semantic information that are difficult to express using traditional discrete manual features. Second, neural networks take distributed word embeddings as inputs, which can be trained from large-scale raw text, thus alleviating the scarcity of annotated data to some extent. In this paper</context>
<context position="10498" citStr="Kalchbrenner et al. (2014)" startWordPosition="1680" endWordPosition="1683">s open domain targeted sentiment, which has been discussed by Mitchell et al. (2013). The task jointly extracts entities and sentiment classes, and is analogous to joint entity and relation extraction (Li and Ji, 2014) in that both are information extraction tasks with multi-label outputs. Our work is related to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Socher et al., 2013). More recently, Kalchbrenner et al. (2014) use a dynamic pooling network to include the structure step 1: entity step 2: sentiment (a) pipeline (b) joint (c) collapsed Figure 3: Discrete CRF models for pipeline, joint and collapsed targeted sentiment labeling. of a sentence automatically, before classifying its sentiment. Zhou et al. (2014) apply deep belief networks for semi-supervised sentiment classification. dos Santos and Gatti (2014) use deep convolution neural networks with rich features to classify sentiments over tweets and movie reviews. These methods use different models to represent sentence structures, performing sentimen</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 655–665.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Heng Ji</author>
</authors>
<title>Incremental joint extraction of entity mentions and relations.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="10090" citStr="Li and Ji, 2014" startWordPosition="1613" endWordPosition="1616">t, but offer less fine-grained operational insight. It requires less fine-grained manual annotation. As discussed in the introduction, targeted sentiment analysis falls into two main settings. The first is targeted sentiment classification, assuming that entity mentions are given. Most previous work fall under this category (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014). The second is open domain targeted sentiment, which has been discussed by Mitchell et al. (2013). The task jointly extracts entities and sentiment classes, and is analogous to joint entity and relation extraction (Li and Ji, 2014) in that both are information extraction tasks with multi-label outputs. Our work is related to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Socher et al., 2013). More recently, Kalchbrenner et al. (2014) use a dynamic pooling network to include the structure step 1: entity step 2: sentiment (a) pipeline (b) joint (c) collapsed Figure 3: Discrete CRF models for pipeline, joint and collapsed ta</context>
</contexts>
<marker>Li, Ji, 2014</marker>
<rawString>Qi Li and Heng Ji. 2014. Incremental joint extraction of entity mentions and relations. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Chao Han</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
<author>Ying-Ju Xia</author>
<author>Shu Zhang</author>
<author>Hao Yu</author>
</authors>
<title>Structure-aware review mining and summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>653--661</pages>
<contexts>
<context position="8599" citStr="Li et al. (2010)" startWordPosition="1380" endWordPosition="1383">g et al., sentence: So excited to meet my baby Farah !!! entity: O O O O O B I O sentiment: Φ Φ Φ Φ Φ + + Φ (a) pipeline or joint 613 2011). In contrast, targeted sentiment analysis can identify all the mentions to target entities in tweets, thereby having a larger coverage. The drawback is that the identification of mentions is subject to errors, and thus suffers a lower precision compared to hashtag matching. Sequence labeling models have been used for extracting opinions and target entities as a joint task. Jin et al. (2009) use HMM to extract opinionbaring expressions and opinion targets. Li et al. (2010) improve the results by using CRF to identify the opinion expressions and targets jointly. The task is sometimes referred to as fine-grained sentiment analysis (Wiebe et al., 2005). It is different from our setting in that the predicate-argument relation between opinion-baring expressions and target entities are not explicitly modeled. Recently, Yang and Cardie (2013) use CRF to extract opinion-baring expressions, opinion holders and opinion targets simultaneously. Their method is also centralized on opinion-baring expressions and therefore in line with Jin et al. (2009) and Li et al. (2010). </context>
</contexts>
<marker>Li, Han, Huang, Zhu, Xia, Zhang, Yu, 2010</marker>
<rawString>Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, and Hao Yu. 2010. Structure-aware review mining and summarization. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 653–661.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ji Ma</author>
<author>Yue Zhang</author>
<author>Jingbo Zhu</author>
</authors>
<title>Tagging the web: Building a robust web tagger with neural network.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>144--154</pages>
<contexts>
<context position="19150" citStr="Ma et al., 2014" startWordPosition="3323" endWordPosition="3326">edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete linear features complepotentials remain the same as the baseline. By ral features and discrete linear features comple616 ments each other. As a result, a model that integrates both features can potentially achieve performance improvements. Most work attempts to add neural word embeddings into a discrete linear model (Turian et al., 2010; Yu et al., 2013; Guo et al., 2014), or add discreted features into a neural model (Ma et al., 2014). We make a novel combination of the discrete models and the neural models by integrating both types of inputs into a same CRF framework.2 The architectures of the integrated models are shown in Figure 5. The main difference between Figure 5 and Figure 3 is the input layer. The integrated model takes both continuous word embeddings, which are shown in grey nodes, and discrete manual features, which are shown in black or white nodes, as the input. A separate hidden layer is given to each type of input nodes, with the hidden layer for the embeddings being the same as the neural baseline: where (</context>
</contexts>
<marker>Ma, Zhang, Zhu, 2014</marker>
<rawString>Ji Ma, Yue Zhang, and Jingbo Zhu. 2014. Tagging the web: Building a robust web tagger with neural network. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 144–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Mitchell</author>
<author>Jacqui Aguilar</author>
<author>Theresa Wilson</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Open domain targeted sentiment.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1643--1654</pages>
<marker>Mitchell, Aguilar, Wilson, Van Durme, 2013</marker>
<rawString>Margaret Mitchell, Jacqui Aguilar, Theresa Wilson, and Benjamin Van Durme. 2013. Open domain targeted sentiment. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1643–1654.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Jin Kiat Low</author>
</authors>
<title>Chinese partof-speech tagging: One-at-a-time or all-at-once? word-based or character-based? In</title>
<date>2004</date>
<booktitle>EMNLP,</booktitle>
<pages>277--284</pages>
<contexts>
<context position="30872" citStr="Ng and Low, 2004" startWordPosition="5273" endWordPosition="5276">-scores on both metrics, which suggest that is a considerable choice for open targeted sentiment. When there is external resource for en(a) Neural (b) Integrated 35 30 25 20 pipeline joint collapsed -T +T 44 42 40 38 pipeline joint collapsed -T +T 619 Subjectivity SA/0 Model P R F P R F pipeline 47.92 42.26 44.84 42.93 18.02 25.14 joint 49.17 42.13 45.32 40.93 21.62 27.93 collapsed 49.63 35.94 41.63 42.10 15.62 22.49 Table 4: Results on subjectivity and polarity. tity recognition, the pipeline can be a favorable choice. On the other hand, although useful for some joint sequence labeling task (Ng and Low, 2004), the collapsed task does not seem to address the joint sentiment task as effectively. We find this result empirical, but consistent across our datasets. 8 Conclusion We explored open domain targeted sentiment analysis using neural network models, which gave competitive results when evaluated against a strong discrete CRF baseline, with relatively higher recalls. Given complementary error distributions by the discrete and neural CRFs, we proposed a novel combination which significantly outperformed both models. Under the neural setting, we find that it is preferable to solve open targeted sent</context>
</contexts>
<marker>Ng, Low, 2004</marker>
<rawString>Hwee Tou Ng and Jin Kiat Low. 2004. Chinese partof-speech tagging: One-at-a-time or all-at-once? word-based or character-based? In EMNLP, pages 277–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Peng</author>
<author>Liefeng Bo</author>
<author>Jinbo Xu</author>
</authors>
<title>Conditional neural fields.</title>
<date>2009</date>
<booktitle>In Advances in neural information processing systems,</booktitle>
<pages>1419--1427</pages>
<contexts>
<context position="18115" citStr="Peng et al. (2009)" startWordPosition="3150" endWordPosition="3153">xi_1) ® e(~xi) )® e(~xi+1) ® e(~xi+2)) +~b where e is the embedding lookup function, ® is the vector concatenation function, the matrix W and vector b~ are model parameters and tanh is the activation function. The output clique potential of yi becomes: {IF(~x,yi) = exp σ~ · ~hi using a hidden layer for automatic feature combinations, the neural model is free of manual features, and can benefit from unsupervised embeddings. Decoding and training are performed using the same algorithms as the baseline. The major neural architectures in Figure 4 have been explored as conditional neural fields by Peng et al. (2009) and neural conditional random fields by Do et al. (2010), and is connected to the sentence-level likelihood neural networks of Collobert et al. (2011), as pointed out by Wang and Manning (2013b). The main differences between our model and the prior work are in the multi-label settings and training details. 5 Integrated Models where σ~ is a model parameter, and the edge clique where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete line</context>
</contexts>
<marker>Peng, Bo, Xu, 2009</marker>
<rawString>Jian Peng, Liefeng Bo, and Jinbo Xu. 2009. Conditional neural fields. In Advances in neural information processing systems, pages 1419–1427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Orena Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2007</date>
<booktitle>In Natural language processing and text mining,</booktitle>
<pages>9--28</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="7500" citStr="Popescu and Etzioni, 2007" startWordPosition="1196" endWordPosition="1199">RF models, and further combine the strengths of each model via feature integration. Second, we compare the effects of the pipeline, joint and collapsed models for open targeted sentiment analysis under the neural model settings. Our experiments show that the neural model gives competitive results compared with the discrete baseline, with relatively higher recalls. In addition, the integrated model significantly improves over both the discrete and the neural models. 2 Related Work Targeted sentiment analysis is closely related prior work on aspect-oriented (Hu and Liu, 2004), feature-oriented (Popescu and Etzioni, 2007) and topic-oriented (Yi et al., 2003) sentiment analysis. These related tasks are typically concentrated on product review settings. In contrast, targeted sentiment analysis has a more general setting. Recently, Wang et al. (2011) proposed a topicoriented model, which extracts sentiments towards certain topics from tweets. Topics in their model resemble targets in our work, although topics are represented by hashtags, which exists in 14.6% tweets and 27.5% subjective tweets (Wang et al., sentence: So excited to meet my baby Farah !!! entity: O O O O O B I O sentiment: Φ Φ Φ Φ Φ + + Φ (a) pipel</context>
</contexts>
<marker>Popescu, Etzioni, 2007</marker>
<rawString>Ana-Maria Popescu and Orena Etzioni. 2007. Extracting product features and opinions from reviews. In Natural language processing and text mining, pages 9–28. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Jeffrey Pennington</author>
<author>Eric H Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Semi-supervised recursive autoencoders for predicting sentiment distributions.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>151--161</pages>
<contexts>
<context position="10272" citStr="Socher et al. (2011)" startWordPosition="1645" endWordPosition="1648">main settings. The first is targeted sentiment classification, assuming that entity mentions are given. Most previous work fall under this category (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014). The second is open domain targeted sentiment, which has been discussed by Mitchell et al. (2013). The task jointly extracts entities and sentiment classes, and is analogous to joint entity and relation extraction (Li and Ji, 2014) in that both are information extraction tasks with multi-label outputs. Our work is related to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Socher et al., 2013). More recently, Kalchbrenner et al. (2014) use a dynamic pooling network to include the structure step 1: entity step 2: sentiment (a) pipeline (b) joint (c) collapsed Figure 3: Discrete CRF models for pipeline, joint and collapsed targeted sentiment labeling. of a sentence automatically, before classifying its sentiment. Zhou et al. (2014) apply deep belief networks for semi-supervised sentiment classification. </context>
</contexts>
<marker>Socher, Pennington, Huang, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Jeffrey Pennington, Eric H Huang, Andrew Y Ng, and Christopher D Manning. 2011. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 151–161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Y Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of the conference on empirical methods in natural language processing (EMNLP),</booktitle>
<volume>volume</volume>
<pages>1631--1642</pages>
<contexts>
<context position="6011" citStr="Socher et al., 2013" startWordPosition="963" endWordPosition="966">es might not be as strong as that between more closely-coupled sources of information, such as word boundaries and POS (Zhang and Clark, 2008), or named entities and constituents (Finkel and Manning, 2009), for which joint models significantly outperform pipeline models. On the other hand, there do exist cases where entity boundaries and sentiment classes reinforce each other. For example, in a tweet such as ‘I like X.’, the contextual pattern indicate both a positive sentiment and an entity in the place of X. Recently, neural network models have been increasingly used for sentiment analysis (Socher et al., 2013; Kalchbrenner et al., 2014; dos Santos and Gatti, 2014), achieving highly competitive results, which show large potentials of neural network models for this task. The main advantages of neural networks are two-fold. First, neural models use real-valued hidden layers to automatically learn feature combinations, which can capture complex semantic information that are difficult to express using traditional discrete manual features. Second, neural networks take distributed word embeddings as inputs, which can be trained from large-scale raw text, thus alleviating the scarcity of annotated data to</context>
<context position="10455" citStr="Socher et al., 2013" startWordPosition="1674" endWordPosition="1677">012; Dong et al., 2014). The second is open domain targeted sentiment, which has been discussed by Mitchell et al. (2013). The task jointly extracts entities and sentiment classes, and is analogous to joint entity and relation extraction (Li and Ji, 2014) in that both are information extraction tasks with multi-label outputs. Our work is related to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Socher et al., 2013). More recently, Kalchbrenner et al. (2014) use a dynamic pooling network to include the structure step 1: entity step 2: sentiment (a) pipeline (b) joint (c) collapsed Figure 3: Discrete CRF models for pipeline, joint and collapsed targeted sentiment labeling. of a sentence automatically, before classifying its sentiment. Zhou et al. (2014) apply deep belief networks for semi-supervised sentiment classification. dos Santos and Gatti (2014) use deep convolution neural networks with rich features to classify sentiments over tweets and movie reviews. These methods use different models to represe</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the conference on empirical methods in natural language processing (EMNLP), volume 1631, page 1642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev-Arie Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>384--394</pages>
<contexts>
<context position="19049" citStr="Turian et al., 2010" startWordPosition="3303" endWordPosition="3306">grated Models where σ~ is a model parameter, and the edge clique where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete linear features complepotentials remain the same as the baseline. By ral features and discrete linear features comple616 ments each other. As a result, a model that integrates both features can potentially achieve performance improvements. Most work attempts to add neural word embeddings into a discrete linear model (Turian et al., 2010; Yu et al., 2013; Guo et al., 2014), or add discreted features into a neural model (Ma et al., 2014). We make a novel combination of the discrete models and the neural models by integrating both types of inputs into a same CRF framework.2 The architectures of the integrated models are shown in Figure 5. The main difference between Figure 5 and Figure 3 is the input layer. The integrated model takes both continuous word embeddings, which are shown in grey nodes, and discrete manual features, which are shown in black or white nodes, as the input. A separate hidden layer is given to each type of</context>
<context position="21347" citStr="Turian et al. (2010)" startWordPosition="3731" endWordPosition="3734"> tanh θ~ · ~f(~x, yi) Finally, the output clique potential of yi becomes: { � ~Ψ(~x, yi) = exp σ~ · (~hi ⊕ ~gi) The edge clique potentials remain the same as the baseline models; the same training and decoding algorithms are used. 6 Training We use a max-margin objective to train our model parameters O, which consist of ~θ, τ, W, b~ and σ~ for each model. The objective function is defined as: λ l(~xn, ~yn, O) + 2 k O k2, 2Wang and Manning (2013a) also investigated the integration of discrete and neural features in CRF models. They compared the effect of integration without hidden layers (i.e. Turian et al. (2010)) and with hidden layers (i.e. our methods) for NER and chunking, finding that the formal outperforms the latter. Our results are different from theirs, and a hidden layer gives significant improvements to the targeted sentiment analysis task. responds to l(~xn, ~yn, O). Maximum-likelihood training is a commonly used alternative to max-margin training for neural networks. It has been applied to the models of Do et al. (2010) and Collobert et al. (2011), for example. However, our experiments show that maximum-likelihood training cannot be applied to open-domain targeted sentiment tasks. Althoug</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duy-Tin Vo</author>
<author>Yue Zhang</author>
</authors>
<title>Target-dependent twitter sentiment classification with rich automatic features.</title>
<date>2015</date>
<booktitle>In Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI2015),</booktitle>
<pages>1347--1353</pages>
<contexts>
<context position="2891" citStr="Vo and Zhang, 2015" startWordPosition="453" endWordPosition="456">ther with the sentiments towards each mention, from a news archive or a collection of novels. There are two sub tasks in targeted sentiment analysis, namely entity recognition and sentiment classification for each entity mention which apply to both scenarios above. In scenario (1), entity recognition is relatively trivial, and can typically be achieved by pattern matching. Partly due to this reason, most previous work has addressed targeted sentiment analysis as a pure classification task, assuming that target mentions have been given (Jiang et al., 2011; Chen et al., 2012; Dong et al., 2014; Vo and Zhang, 2015). For scenario (2), a named entity recognition (NER) system can be used to extract targets, before the same targeted sentiment classification algorithms are applied. There has also been work that concentrates on extracting opinion targets (Jin et al., 2009; Jakob and Gurevych, 2010). In both cases, the data in Figure 1 can be used for training sentiment classifiers. Mitchell et al. (2013) took a different approach, extracting named entities and their sentiment classes jointly. They model the joint task 612 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, </context>
</contexts>
<marker>Vo, Zhang, 2015</marker>
<rawString>Duy-Tin Vo and Yue Zhang. 2015. Target-dependent twitter sentiment classification with rich automatic features. In Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI2015), pages 1347–1353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Christopher D Manning</author>
</authors>
<title>Effect of non-linear deep architecture in sequence labeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>1285--1291</pages>
<contexts>
<context position="18308" citStr="Wang and Manning (2013" startWordPosition="3183" endWordPosition="3186">activation function. The output clique potential of yi becomes: {IF(~x,yi) = exp σ~ · ~hi using a hidden layer for automatic feature combinations, the neural model is free of manual features, and can benefit from unsupervised embeddings. Decoding and training are performed using the same algorithms as the baseline. The major neural architectures in Figure 4 have been explored as conditional neural fields by Peng et al. (2009) and neural conditional random fields by Do et al. (2010), and is connected to the sentence-level likelihood neural networks of Collobert et al. (2011), as pointed out by Wang and Manning (2013b). The main differences between our model and the prior work are in the multi-label settings and training details. 5 Integrated Models where σ~ is a model parameter, and the edge clique where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete linear features complepotentials remain the same as the baseline. By ral features and discrete linear features comple616 ments each other. As a result, a model that integrates both features can pot</context>
<context position="21175" citStr="Wang and Manning (2013" startWordPosition="3704" endWordPosition="3707"> ∂O ∂O , ∂O ⊕ e(~xi+1) ⊕ e(~xi+2)) + ) where y~ˆ is the predicted label sequence which cor~b The hidden nodes ~gi between the discrete features and the node yi are: ( ) ~gi = tanh θ~ · ~f(~x, yi) Finally, the output clique potential of yi becomes: { � ~Ψ(~x, yi) = exp σ~ · (~hi ⊕ ~gi) The edge clique potentials remain the same as the baseline models; the same training and decoding algorithms are used. 6 Training We use a max-margin objective to train our model parameters O, which consist of ~θ, τ, W, b~ and σ~ for each model. The objective function is defined as: λ l(~xn, ~yn, O) + 2 k O k2, 2Wang and Manning (2013a) also investigated the integration of discrete and neural features in CRF models. They compared the effect of integration without hidden layers (i.e. Turian et al. (2010)) and with hidden layers (i.e. our methods) for NER and chunking, finding that the formal outperforms the latter. Our results are different from theirs, and a hidden layer gives significant improvements to the targeted sentiment analysis task. responds to l(~xn, ~yn, O). Maximum-likelihood training is a commonly used alternative to max-margin training for neural networks. It has been applied to the models of Do et al. (2010)</context>
</contexts>
<marker>Wang, Manning, 2013</marker>
<rawString>Mengqiu Wang and Christopher D. Manning. 2013a. Effect of non-linear deep architecture in sequence labeling. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 1285–1291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sida Wang</author>
<author>Christopher Manning</author>
</authors>
<title>Fast dropout training.</title>
<date>2013</date>
<booktitle>In Proceedings of the 30th International Conference on Machine Learning (ICML13),</booktitle>
<pages>118--126</pages>
<contexts>
<context position="18308" citStr="Wang and Manning (2013" startWordPosition="3183" endWordPosition="3186">activation function. The output clique potential of yi becomes: {IF(~x,yi) = exp σ~ · ~hi using a hidden layer for automatic feature combinations, the neural model is free of manual features, and can benefit from unsupervised embeddings. Decoding and training are performed using the same algorithms as the baseline. The major neural architectures in Figure 4 have been explored as conditional neural fields by Peng et al. (2009) and neural conditional random fields by Do et al. (2010), and is connected to the sentence-level likelihood neural networks of Collobert et al. (2011), as pointed out by Wang and Manning (2013b). The main differences between our model and the prior work are in the multi-label settings and training details. 5 Integrated Models where σ~ is a model parameter, and the edge clique where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete linear features complepotentials remain the same as the baseline. By ral features and discrete linear features comple616 ments each other. As a result, a model that integrates both features can pot</context>
<context position="21175" citStr="Wang and Manning (2013" startWordPosition="3704" endWordPosition="3707"> ∂O ∂O , ∂O ⊕ e(~xi+1) ⊕ e(~xi+2)) + ) where y~ˆ is the predicted label sequence which cor~b The hidden nodes ~gi between the discrete features and the node yi are: ( ) ~gi = tanh θ~ · ~f(~x, yi) Finally, the output clique potential of yi becomes: { � ~Ψ(~x, yi) = exp σ~ · (~hi ⊕ ~gi) The edge clique potentials remain the same as the baseline models; the same training and decoding algorithms are used. 6 Training We use a max-margin objective to train our model parameters O, which consist of ~θ, τ, W, b~ and σ~ for each model. The objective function is defined as: λ l(~xn, ~yn, O) + 2 k O k2, 2Wang and Manning (2013a) also investigated the integration of discrete and neural features in CRF models. They compared the effect of integration without hidden layers (i.e. Turian et al. (2010)) and with hidden layers (i.e. our methods) for NER and chunking, finding that the formal outperforms the latter. Our results are different from theirs, and a hidden layer gives significant improvements to the targeted sentiment analysis task. responds to l(~xn, ~yn, O). Maximum-likelihood training is a commonly used alternative to max-margin training for neural networks. It has been applied to the models of Do et al. (2010)</context>
</contexts>
<marker>Wang, Manning, 2013</marker>
<rawString>Sida Wang and Christopher Manning. 2013b. Fast dropout training. In Proceedings of the 30th International Conference on Machine Learning (ICML13), pages 118–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Wang</author>
<author>Greg Mori</author>
</authors>
<title>Max-margin hidden conditional random fields for human action recognition.</title>
<date>2009</date>
<booktitle>In Computer Vision and Pattern Recognition,</booktitle>
<pages>872--879</pages>
<contexts>
<context position="15187" citStr="Wang and Mori (2009)" startWordPosition="2497" endWordPosition="2500">tentials Φ1(~x, yi, yi−1) and Φ2(~x, zi, zi−1) for the label sets {B, I, O} and {+,−,0}, respectively. In the Figure 3(b), there are also links between the span label yi and the sentiment label zi for each word xi. These links indicate label dependencies, which are constraints for decoding. For example, if yi = O, then zi must be φ. We apply Viterbi decoding for all tasks, and training is performed using a max-margin objective, which is discussed in Section 6. Our training algorithm is different from that of Mitchell et al. (2013), but gives similar discrete CRF accuracies in our experiments. Wang and Mori (2009) also applied a max-margin trainig strategy to train CRF models. The set of features is taken from Mitchell et al. (2013) without changes, as shown in Table 1. Here the cluster features refer to Brown word clusters (Brown et al., 1992). where Z(~x) is the partition function: XZ(~x) = � Y|x |Ψ(~x, y0i) Y |x |�Φ(~x, y0 i, y0 i−1) , ~y1 i=1 j=1 P(~y|~x) = Y |x |Ψ(~x, yi) i=1 |x| Y Φ(~x, yi, yi−1) j=1 , Z(~x) 1Note the difference between neural and NULL sentiments. The former indicates that a target does not bare any sentiment, and the latter simply means that the term is not a part of a target. 4</context>
</contexts>
<marker>Wang, Mori, 2009</marker>
<rawString>Yang Wang and Greg Mori. 2009. Max-margin hidden conditional random fields for human action recognition. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 872– 879.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaolong Wang</author>
<author>Furu Wei</author>
<author>Xiaohua Liu</author>
<author>Ming Zhou</author>
<author>Ming Zhang</author>
</authors>
<title>Topic sentiment analysis in twitter: a graph-based hashtag sentiment classification approach.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<pages>1031--1040</pages>
<contexts>
<context position="7730" citStr="Wang et al. (2011)" startWordPosition="1230" endWordPosition="1233">iments show that the neural model gives competitive results compared with the discrete baseline, with relatively higher recalls. In addition, the integrated model significantly improves over both the discrete and the neural models. 2 Related Work Targeted sentiment analysis is closely related prior work on aspect-oriented (Hu and Liu, 2004), feature-oriented (Popescu and Etzioni, 2007) and topic-oriented (Yi et al., 2003) sentiment analysis. These related tasks are typically concentrated on product review settings. In contrast, targeted sentiment analysis has a more general setting. Recently, Wang et al. (2011) proposed a topicoriented model, which extracts sentiments towards certain topics from tweets. Topics in their model resemble targets in our work, although topics are represented by hashtags, which exists in 14.6% tweets and 27.5% subjective tweets (Wang et al., sentence: So excited to meet my baby Farah !!! entity: O O O O O B I O sentiment: Φ Φ Φ Φ Φ + + Φ (a) pipeline or joint 613 2011). In contrast, targeted sentiment analysis can identify all the mentions to target entities in tweets, thereby having a larger coverage. The drawback is that the identification of mentions is subject to error</context>
</contexts>
<marker>Wang, Wei, Liu, Zhou, Zhang, 2011</marker>
<rawString>Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou, and Ming Zhang. 2011. Topic sentiment analysis in twitter: a graph-based hashtag sentiment classification approach. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 1031–1040.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. Language resources and evaluation,</title>
<date>2005</date>
<pages>39--2</pages>
<contexts>
<context position="8779" citStr="Wiebe et al., 2005" startWordPosition="1409" endWordPosition="1412">ysis can identify all the mentions to target entities in tweets, thereby having a larger coverage. The drawback is that the identification of mentions is subject to errors, and thus suffers a lower precision compared to hashtag matching. Sequence labeling models have been used for extracting opinions and target entities as a joint task. Jin et al. (2009) use HMM to extract opinionbaring expressions and opinion targets. Li et al. (2010) improve the results by using CRF to identify the opinion expressions and targets jointly. The task is sometimes referred to as fine-grained sentiment analysis (Wiebe et al., 2005). It is different from our setting in that the predicate-argument relation between opinion-baring expressions and target entities are not explicitly modeled. Recently, Yang and Cardie (2013) use CRF to extract opinion-baring expressions, opinion holders and opinion targets simultaneously. Their method is also centralized on opinion-baring expressions and therefore in line with Jin et al. (2009) and Li et al. (2010). In contrast, targeted sentiment analysis directly studies entity mentions and the sentiment on each mention, without explicitly modeling the way in which the opinion is expressed. </context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language resources and evaluation, 39(2-3):165–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bishan Yang</author>
<author>Claire Cardie</author>
</authors>
<title>Joint inference for fine-grained opinion extraction.</title>
<date>2013</date>
<booktitle>In ACL (1),</booktitle>
<pages>1640--1649</pages>
<contexts>
<context position="8969" citStr="Yang and Cardie (2013)" startWordPosition="1436" endWordPosition="1439">rs a lower precision compared to hashtag matching. Sequence labeling models have been used for extracting opinions and target entities as a joint task. Jin et al. (2009) use HMM to extract opinionbaring expressions and opinion targets. Li et al. (2010) improve the results by using CRF to identify the opinion expressions and targets jointly. The task is sometimes referred to as fine-grained sentiment analysis (Wiebe et al., 2005). It is different from our setting in that the predicate-argument relation between opinion-baring expressions and target entities are not explicitly modeled. Recently, Yang and Cardie (2013) use CRF to extract opinion-baring expressions, opinion holders and opinion targets simultaneously. Their method is also centralized on opinion-baring expressions and therefore in line with Jin et al. (2009) and Li et al. (2010). In contrast, targeted sentiment analysis directly studies entity mentions and the sentiment on each mention, without explicitly modeling the way in which the opinion is expressed. As a result, our task is more useful for applications such as broad-stroke reputation management, but offer less fine-grained operational insight. It requires less fine-grained manual annota</context>
</contexts>
<marker>Yang, Cardie, 2013</marker>
<rawString>Bishan Yang and Claire Cardie. 2013. Joint inference for fine-grained opinion extraction. In ACL (1), pages 1640–1649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeonghee Yi</author>
<author>Tetsuya Nasukawa</author>
<author>Razvan Bunescu</author>
<author>Wayne Niblack</author>
</authors>
<title>Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques.</title>
<date>2003</date>
<booktitle>In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on,</booktitle>
<pages>427--434</pages>
<contexts>
<context position="7537" citStr="Yi et al., 2003" startWordPosition="1202" endWordPosition="1205"> each model via feature integration. Second, we compare the effects of the pipeline, joint and collapsed models for open targeted sentiment analysis under the neural model settings. Our experiments show that the neural model gives competitive results compared with the discrete baseline, with relatively higher recalls. In addition, the integrated model significantly improves over both the discrete and the neural models. 2 Related Work Targeted sentiment analysis is closely related prior work on aspect-oriented (Hu and Liu, 2004), feature-oriented (Popescu and Etzioni, 2007) and topic-oriented (Yi et al., 2003) sentiment analysis. These related tasks are typically concentrated on product review settings. In contrast, targeted sentiment analysis has a more general setting. Recently, Wang et al. (2011) proposed a topicoriented model, which extracts sentiments towards certain topics from tweets. Topics in their model resemble targets in our work, although topics are represented by hashtags, which exists in 14.6% tweets and 27.5% subjective tweets (Wang et al., sentence: So excited to meet my baby Farah !!! entity: O O O O O B I O sentiment: Φ Φ Φ Φ Φ + + Φ (a) pipeline or joint 613 2011). In contrast, </context>
</contexts>
<marker>Yi, Nasukawa, Bunescu, Niblack, 2003</marker>
<rawString>Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu, and Wayne Niblack. 2003. Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on, pages 427–434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mo Yu</author>
<author>Tiejun Zhao</author>
<author>Daxiang Dong</author>
<author>Hao Tian</author>
<author>Dianhai Yu</author>
</authors>
<title>Compound embedding features for semi-supervised learning.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>563--568</pages>
<contexts>
<context position="19066" citStr="Yu et al., 2013" startWordPosition="3307" endWordPosition="3310">~ is a model parameter, and the edge clique where σ~ is a model parameter, and the edge clique Gleaning different sources of information, neuGleaning different sources of information, neupotentials remain the same as the baseline. By ral features and discrete linear features complepotentials remain the same as the baseline. By ral features and discrete linear features comple616 ments each other. As a result, a model that integrates both features can potentially achieve performance improvements. Most work attempts to add neural word embeddings into a discrete linear model (Turian et al., 2010; Yu et al., 2013; Guo et al., 2014), or add discreted features into a neural model (Ma et al., 2014). We make a novel combination of the discrete models and the neural models by integrating both types of inputs into a same CRF framework.2 The architectures of the integrated models are shown in Figure 5. The main difference between Figure 5 and Figure 3 is the input layer. The integrated model takes both continuous word embeddings, which are shown in grey nodes, and discrete manual features, which are shown in black or white nodes, as the input. A separate hidden layer is given to each type of input nodes, wit</context>
</contexts>
<marker>Yu, Zhao, Dong, Tian, Yu, 2013</marker>
<rawString>Mo Yu, Tiejun Zhao, Daxiang Dong, Hao Tian, and Dianhai Yu. 2013. Compound embedding features for semi-supervised learning. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 563–568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Joint word segmentation and POS tagging using a single perceptron.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>888--896</pages>
<contexts>
<context position="5534" citStr="Zhang and Clark, 2008" startWordPosition="885" endWordPosition="888"> and the middle of a negative entity, respectively. The collapsed labels allow joint entity recognition and sentiment classification to be achieved using a standard sequence labeler. Mitchell et al. (2013) compare a pipeline model, a joint model and a collapsed model under the same conditional random field (CRF) framework, finding that the pipeline method outperforms the joint model on a tweet dataset. Intuitively, the interaction between entity boundaries and sentiment classes might not be as strong as that between more closely-coupled sources of information, such as word boundaries and POS (Zhang and Clark, 2008), or named entities and constituents (Finkel and Manning, 2009), for which joint models significantly outperform pipeline models. On the other hand, there do exist cases where entity boundaries and sentiment classes reinforce each other. For example, in a tweet such as ‘I like X.’, the contextual pattern indicate both a positive sentiment and an entity in the place of X. Recently, neural network models have been increasingly used for sentiment analysis (Socher et al., 2013; Kalchbrenner et al., 2014; dos Santos and Gatti, 2014), achieving highly competitive results, which show large potentials</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. Joint word segmentation and POS tagging using a single perceptron. In Proceedings of ACL-08: HLT, pages 888– 896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shusen Zhou</author>
<author>Qingcai Chen</author>
<author>Xiaolong Wang</author>
<author>Xiaoling Li</author>
</authors>
<title>Hybrid deep belief networks for semi-supervised sentiment classification.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>1341--1349</pages>
<contexts>
<context position="10798" citStr="Zhou et al. (2014)" startWordPosition="1726" endWordPosition="1729">ed to the line of work on using neural networks for sentiment analysis. Socher et al. (2011) use recursive auto-encoders for sentiment analysis on the sentence level. They further extend the method to a syntactic treebank annotated with sentiment labels (Socher et al., 2013). More recently, Kalchbrenner et al. (2014) use a dynamic pooling network to include the structure step 1: entity step 2: sentiment (a) pipeline (b) joint (c) collapsed Figure 3: Discrete CRF models for pipeline, joint and collapsed targeted sentiment labeling. of a sentence automatically, before classifying its sentiment. Zhou et al. (2014) apply deep belief networks for semi-supervised sentiment classification. dos Santos and Gatti (2014) use deep convolution neural networks with rich features to classify sentiments over tweets and movie reviews. These methods use different models to represent sentence structures, performing sentiment analysis on the sentence level, without modeling targets. Dong et al. (2014) perform targeted sentiment classification by using a recursive neural network to model the transmission of sentiment signal from opinion baring expressions to a target. They assume that the target mention is given, and pe</context>
</contexts>
<marker>Zhou, Chen, Wang, Li, 2014</marker>
<rawString>Shusen Zhou, Qingcai Chen, Xiaolong Wang, and Xiaoling Li. 2014. Hybrid deep belief networks for semi-supervised sentiment classification. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1341–1349.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>