<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000138">
<title confidence="0.998506">
Birds of a Feather Linked Together:
A Discriminative Topic Model using Link-based Priors
</title>
<author confidence="0.998023">
Weiwei Yang
</author>
<affiliation confidence="0.995945">
Computer Science
University of Maryland
</affiliation>
<address confidence="0.882887">
College Park, MD
</address>
<email confidence="0.998854">
wwyang@cs.umd.edu
</email>
<author confidence="0.992247">
Jordan Boyd-Graber
</author>
<affiliation confidence="0.9963715">
Computer Science
University of Colorado
</affiliation>
<address confidence="0.4859505">
Boulder, CO
Jordan.Boyd.Graber@
</address>
<email confidence="0.839524">
colorado.edu
</email>
<author confidence="0.911986">
Philip Resnik
</author>
<affiliation confidence="0.9053305">
Linguistics and UMIACS
University of Maryland
</affiliation>
<address confidence="0.877705">
College Park, MD
</address>
<email confidence="0.999301">
resnik@umd.edu
</email>
<sectionHeader confidence="0.99391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999700230769231">
A wide range of applications, from social
media to scientific literature analysis, in-
volve graphs in which documents are con-
nected by links. We introduce a topic
model for link prediction based on the in-
tuition that linked documents will tend to
have similar topic distributions, integrat-
ing a max-margin learning criterion and
lexical term weights in the loss function.
We validate our approach on the tweets
from 2,000 Sina Weibo users and evalu-
ate our model’s reconstruction of the so-
cial network.
</bodyText>
<sectionHeader confidence="0.998803" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999944815384616">
Many application areas for text analysis involve
documents connected by links of one or more
types—for example, analysis of scientific pa-
pers (citations, co-authorship), Web pages (hyper-
links), legislation (co-sponsorship, citations), and
social media (followers, mentions, etc.). In this
paper we work within the widely used framework
of topic modeling (Blei et al., 2003, LDA) to de-
velop a model that is simple and intuitive, but
which identifies high quality topics while also ac-
curately predicting link structure.
Our work here is inspired by the phenomenon
of homophily, the tendency of people to associate
with others who are like themselves (McPherson
et al., 2001). As manifested in social networks,
the intuition is that people who are associated with
one another are likely to discuss similar topics, and
vice versa. The new topic model we propose there-
fore takes association links into account so that a
document’s topic distribution is influenced by the
topic distributions of its neighbors. Specifically,
we propose a joint model that uses link structure
to define clusters (cliques) of documents and, fol-
lowing the intuition that documents in the same
cluster are likely to have similar topic distribu-
tions, assigns each cluster its own separate Dirich-
let prior over the cluster’s topic distribution. This
use of priors is consistent with previous work that
has shown document-topic priors to be useful in
encoding various types of prior knowledge and
improving topic modeling performance (Mimno
and McCallum, 2008). We then use distributed
representations to “seed” the topic representations
before getting down to modeling the documents.
Our joint objective function uses a discriminative,
max-margin approach (Zhu et al., 2012; Zhu et
al., 2014) to both model the contents of documents
and produce good predictions of links; in addition,
it improves prediction by including lexical terms
in the decision function (Nguyen et al., 2013).
Our baseline for comparison is the Relational
Topic Model (Chang and Blei, 2010, henceforth
RTM), which jointly captures topics and binary
link indicators in a style similar to supervised
LDA (McAuliffe and Blei, 2008, sLDA), instead
of modeling links alone, e.g., as in the Latent
Multi-group Membership Graph model (Kim and
Leskovec, 2012, LMMG). We also compare our
approach with Daum´e III (2009), who uses docu-
ment links to create a Markov random topic field
(MRTF). Daum´e does not, however, look at link
prediction, as his upstream model (Mimno and
McCallum, 2008) only generates documents con-
ditioned on links. In contrast, our downstream
model allows the prediction of links, like RTM.
Our model’s primary contribution is in its novel
combination of a straightforward joint modeling
approach, max-margin learning, and exploitation
of lexical information in both topic seeding and
regression, yielding a simple but effective model
for topic-informed discriminative link prediction.
Like other topic models which treat binary values
“probabilistically”, our model can convert binary
link indicators into non-zero weights, with poten-
tial application to improving models like Volkova
</bodyText>
<page confidence="0.969927">
261
</page>
<note confidence="0.9344675">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 261–266,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figureCaption confidence="0.916444">
Figure 1: A graphical model of our model for two
documents. The contribution of our model is the
</figureCaption>
<bodyText confidence="0.962410153846154">
use of document clusters (π), the use of words (w)
in the prediction of document links (y), and a max-
margin objective.
et al. (2014), who use neighbor relationships to
improve prediction of user-level attributes.
Our corpus is collected from Sina Weibo with
three types of links between documents. We first
conduct a reality check of our model against LDA
and MRTF and then perform link prediction tasks.
We demonstrate improvements in link prediction
as measured by predictive link rank and provide
both qualitative and quantitative perspectives on
the improvements achieved by the model.
</bodyText>
<sectionHeader confidence="0.97272" genericHeader="method">
2 Discriminative Links from Topics
</sectionHeader>
<bodyText confidence="0.8135625">
Figure 1 is a two-document segment of our model,
which has the following generative process:
</bodyText>
<figure confidence="0.582675142857143">
1. For each related-document cluster l ∈ {1, ... ,L}
Draw πt ∼ Dir(α&apos;)
2. For each topic k ∈ {1, ... , K}
(a) Draw word distribution φk ∼ Dir(β)
(b) Draw topic regression parameter ηk ∼ N(0, ν2)
3. For each word v ∈ {1, ... ,V }
Draw lexical regression parameter τv ∼ N(0, ν2)
4. For each document d ∈ {1, ... , D}
(a) Draw topic proportions θd ∼ Dir(απtd)
(b) For each word td,n in document d
i. Draw a topic assignment zd,n ∼ Mult(θd)
ii. Draw a word td,n ∼ Mult(φzd,n)
5. For each linked pair of documents d and d&apos;
Draw binary link indicator
</figure>
<bodyText confidence="0.978482866666667">
yd,d&apos;|zd, zd&apos;, wd, wd&apos; ∼ Ψ(·|zd, zd&apos;, wd, wd&apos;, η, τ)
Step 1: Identifying birds of a feather. Prior
to the generative process, given a training set of
documents and document-to-document links, we
begin by identifying small clusters or cliques us-
ing strongly connected components, which auto-
matically determines the number of clusters from
the link graph. Intuitively, documents in the same
clique are likely to have similar topic distributions.
Therefore, each of the L cliques l (the “birds of a
feather” of our title) is assigned a separate Dirich-
let prior πl over K topics.
Step 2a: Using seed words to improve topic
quality. To improve topic quality, we identify
seed words for the K topics using distributed lexi-
cal representations: the key idea is to complement
the more global information captured in LDA-
style topics with representations based on local
contextual information. We cluster the most fre-
quent words’ word2vec representations (Mikolov
et al., 2013) into K word-clusters using the k-
means algorithm, based on the training corpus.1
We then enforce a one-to-one association between
these discovered word clusters and the K top-
ics. For any word token wd,n whose word type
is in cluster k, the associated topic assignment
zd,n can only be k. To choose topic k’s seed
words, within its word-cluster we compute each
word wk,i’s skip-gram transition probability sum
Sk,i to the other words as
</bodyText>
<equation confidence="0.988191">
Nk
Sk,i = p(wk,j  |wk,i), (1)
j=1,j7�i
</equation>
<bodyText confidence="0.995828111111111">
where Nk denotes the number of words in topic k.
We then select the three words with the highest
sum of transition probabilities as the seed words
for topic k. In the sampling process (Section 3),
seed words are only assigned to their correspond-
ing topics, similar to the use of hard constraints by
Andrzejewski and Zhu (2009).
Steps 2b-3: Link regression parameters.
Given two documents d and d&apos;, we want to pre-
dict whether they are linked by taking advantage
of their topic patterns: the more similar two docu-
ments are, the more likely it is that they should be
linked together. Like RTM, we will compute a re-
gression in Step 5 using the topic distributions of
d and d&apos;; however, we follow Nguyen et al. (2013)
by also including a document’s word-level distri-
bution as a regression input.2 The regression value
of document d and d&apos; is
</bodyText>
<equation confidence="0.959641">
Rd,d&apos; = 77T(zd o zd�) + τT(wd o wd&apos;), (2)
</equation>
<bodyText confidence="0.9998065">
where zd = Nd &amp; zd,n, and wd = Nd &amp; wd,n;
o denotes the Hadamard product; 77 and τ are the
</bodyText>
<footnote confidence="0.85893525">
1In the experiment, seed words must appear at least 1,000
times.
2Both approaches contrast with the links-only approach
of Kim and Leskovec (2012).
</footnote>
<figure confidence="0.958240333333333">
η
α α&apos; π yd,d&apos; φ β
K
ed&apos; zd&apos;,n wd&apos;,n
Nd&apos;
ed zd,n wd,n
Nd
L
τ
</figure>
<page confidence="0.985143">
262
</page>
<bodyText confidence="0.99721525">
weight vectors for topic-based and lexically-based
predictions, respectively.
Step 4: Generating documents. Documents
are generated as in LDA, where each document’s
topic distribution 0 is drawn from the cluster’s
topic prior (a parametric analog to the HDP of Teh
et al. (2006)) and each word’s topic assignment is
drawn from the document’s topic distribution (ex-
cept for seed words, as described above).
Step 5: Generating links. Our model is a
“downstream” supervised topic model, i.e., the
prediction of the observable variable (here, docu-
ment links) is informed by the documents’ topic
distributions, as in sLDA (Blei and McAuliffe,
2007). In contrast to Chang and Blei (2010), who
use a sigmoid as their link prediction function Ψ,
we instead use hinge loss: the probability Ψ that
two documents d and d&apos; are linked is p(yd,d0 = 1  |zd, zd0, wd, wd0) = exp(−2c max(0, ζd,d0)),
where c is the regularization parameter. In the
hinge loss function, ζd,d0 is
</bodyText>
<equation confidence="0.993822">
ζd,d0 = 1 − yd,d0Rd,d0. (3)
</equation>
<sectionHeader confidence="0.990865" genericHeader="method">
3 Posterior Inference
</sectionHeader>
<bodyText confidence="0.99879225">
Sampling Topics. Following Polson and Scott
(2011), by introducing an auxiliary variable λd,d0,
we derive the conditional probability of a topic as-
signment
</bodyText>
<equation confidence="0.969554625">
p(zd,n = k  |z−d,n, w−d,n, wd,n = v)
N−d,n
k,v + β
∝ × N−d,n + (Y7r—d,n ×
Nk .d&apos;n + V β ( d,k ld,k )
TTexp �— (c(d,d0 + λd,d0)2 (4)
dl tad d0 ) ,
d
</equation>
<bodyText confidence="0.9999805">
where Nk,v denotes the count of word v assigned
to topic k; Nd,k is the number of tokens in doc-
ument d that are assigned to topic k.3 Marginal
counts are denoted by ·; −d,n denotes that the
count excludes token n in document d; d&apos; denotes
the indexes of documents which are linked to doc-
</bodyText>
<equation confidence="0.977145571428572">
ument d; π−d,n
ld,k is estimated based on the maximal
path assumption (Wallach, 2008)
&amp;0ES(ld) N−d,n
d0,k + α&apos;
&amp;0ES(ld) N−d,n
d0,� + Kα&apos;
</equation>
<bodyText confidence="0.998991">
where S(ld) denotes the cluster which contains
document d (Step 1 in the generative process).
</bodyText>
<footnote confidence="0.971935">
3More details here and throughout this section appear in
the supplementary materials.
</footnote>
<bodyText confidence="0.9003671">
Optimizing topic and lexical regression pa-
rameters. While topic regression parameters 77
and lexical regression parameters •r can be sam-
pled (Zhu et al., 2014), the associated covariance
matrix is huge (approximately 12K × 12K in our
experiments). Instead, we optimize these parame-
ters using L-BFGS.
Sampling auxiliary variables. The like-
lihood of auxiliary variables A follows a
generalized inverse Gaussian distribution
</bodyText>
<equation confidence="0.93471">
GIG(λd,d0; 12, 1, c2ζ2d,d0). Thus we sample
λ−1
d,d0 from a an inverse Gaussian distribution
p(λ−&apos;  |z, w, η, τ) = IG λd d0; r1 , 1. (6)
i 1
c |(1
|
</equation>
<sectionHeader confidence="0.999052" genericHeader="method">
4 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.705678">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999987">
We crawl data from Sina Weibo, the largest
Chinese micro-blog platform. The dataset con-
tains 2,000 randomly-selected verified users, each
represented by a single document aggregating all
the user’s posts. We also crawl links between pairs
of users when both are in our dataset. Links cor-
respond to three types of interactions on Weibo:
mentioning, retweeting and following.4
</bodyText>
<subsectionHeader confidence="0.991882">
4.2 Perplexity Results
</subsectionHeader>
<bodyText confidence="0.99995795">
As an initial reality check, we first apply a simpli-
fied version of our model which only uses user in-
teractions for topic modeling and does not predict
links. This permits a direct comparison of our
model’s performance against LDA and Markov
random topic fields (Daum´e III, 2009, MRTF) by
evaluating perplexity.
We set α = α&apos; = 15 and run the models on
20 topics for all models in this and following sec-
tions. The results are the average values of five
independent runs. Following Daum´e, in each run,
for each document, 80% of its tokens are randomly
selected for training and the remaining 20% are
for test. As the training corpus is generated ran-
domly, seeding is not applied in this section. The
results are given in Table 1, where I- denotes that
the model incorporates user interactions.
The results confirm that our model outperforms
both LDA and MRTF and that its use of user inter-
actions holds promise.
</bodyText>
<footnote confidence="0.77722225">
4We use ICTCLAS (Zhang et al., 2003) for segmentation.
After stopword and low-frequency word removal, the vocab-
ulary includes 12,257 words, with —755 tokens per document
and 5,404 links.
</footnote>
<equation confidence="0.934249">
π−d,n
ld,k =
, (5)
</equation>
<page confidence="0.971161">
263
</page>
<figure confidence="0.998788318181818">
(a) Mentioning (b) Retweeting (c) Following
76.7
118.55
82.44
110.99
119.70
73.31
98.99
76.71
101.34
120.18
104.65
74.38
103.79
117.19
123.64
82.13
100.09
72.89
114.85
40 50 60 70 80 60 70 80 90 100 110 80 90 100 110 120
RTM IS-RTM Lex-IS-RTM MED-RTM IS-MED-RTM Lex-IS-MED-RTM
</figure>
<figureCaption confidence="0.9161195">
Figure 2: Lex-IS-MED-RTM, combining all three extensions, performs the best on predicting mention-
ing and following links, although IS-RTM achieves a close value on mentioning links and even a slightly
better value on retweeting links. User interactions (denoted by “I”) sometimes bring down the perfor-
mance, as cluster priors are not applied in this intrinsic evaluation.
</figureCaption>
<table confidence="0.998808888888889">
Link Model Perplexity
– LDA 2605.06
MRTF 2582.08
Mentioning
I-LDA 2522.58
Retweeting MRTF 2588.30
I-LDA 2519.27
Following MRTF 2587.26
I-LDA 2530.67
</table>
<tableCaption confidence="0.998325">
Table 1: Our simplified model I-LDA achieves
</tableCaption>
<bodyText confidence="0.658853666666667">
lower perplexities than both LDA and MRTF,
by incorporating different cliques extracted from
three types of user interactions.
</bodyText>
<subsectionHeader confidence="0.997584">
4.3 Link Prediction Results
</subsectionHeader>
<bodyText confidence="0.99366253125">
In this section, we apply our model on link pre-
diction tasks and evaluate by predictive link rank
(PLR). A document’s PLR is the average rank,
among all documents, of the documents to which
it actually links. This means that lower values of
PLR are better.
Figure 2 breaks out the 5-fold cross validation
results and the distinct extensions of RTM.5 The
results support the value in combining all three
extensions using Lex-IS-MED-RTM, although for
mentioning and retweeting, Lex-IS-MED-RTM
and IS-RTM are quite close.
Applying user interactions does not always pro-
duce improvements. This is because in our in-
trinsic evaluation, we assume that the links on the
test set are not observable and cluster priors are
5IS- denotes that the model incorporates user interactions
and seed words, Lex- means that lexical terms were included
in the link probability function (Equation 3), and MED- de-
notes max-margin learning (Zhu et al., 2014; Zhu et al.,
2012). Each type of link is applied separately; e.g., in Fig-
ure 2(a) results are based only on mentioning links, ignoring
retweeting and following links.
not applied. However, according to the training
performance (extrinsic evaluations which we are
still in progress), user interactions do benefit link
prediction performance when links are partially
available, e.g., suggesting more links based on ob-
served links. In contrast, hinge loss and lexical
term weights do not depend on metadata availabil-
ity and generally produce improvements in link
prediction performance.
</bodyText>
<subsectionHeader confidence="0.997282">
4.4 Illustrative Example
</subsectionHeader>
<bodyText confidence="0.999983666666667">
We illustrate model behavior qualitatively by look-
ing at two test set users, designated A and B.
User A is a reporter who runs “We Media” on
his account, sending news items to followers, and
B is a consultant with a wide range of interests.
Their tweets reveal that both are interested in so-
cial news—a topic emphasizing words like soci-
ety, country, government, laws, leaders, political
party, news, etc. Both often retweet news re-
lated to unfairness in society and local govern-
ment scandals (government, police, leaders, party,
policy, chief secretary). For example, User A
retweeted a report that a person about to be exe-
cuted was unable to take a photo with his family
before his execution, writing I feel heartbroken.
User B retweeted news that a mayor was fired and
investigated because of a bribe; in his retweet, he
expresses his dissatisfaction with what the mayor
did when he was in power. In addition, User A fol-
lows new technology (smart phone, Apple, Sam-
sung, software, hardware, etc.) and B is interested
in food (snacks, noodles, wine, fish, etc.).
As ground truth, there is a mentioning link
from A to B; Table 2 shows this link’s PLR in
the mentioning models, which generally improves
with model sophistication. The mentioning tweet
is a news item that is consistent with the model’s
</bodyText>
<page confidence="0.994326">
264
</page>
<table confidence="0.978979428571429">
Model RTM IS-RTM Lex-IS-RTM MED-RTM IS-MED-RTM Lex-IS-MED-RTM
PLR of the Link 24 10 9 74 18 26
Social News User A 0.018 0.021 0.034 0.016 0.027 0.030
Topic Proportion
User B 0.309 0.413 0.408 0.318 0.355 0.392
Table 2: Data for Illustrative Example
Model RTM IS-RTM Lex-IS-RTM MED-RTM IS-MED-RTM Lex-IS-MED-RTM
Topic PMI 1.186 1.224 1.216 1.214 1.294 1.229
Average Linked Pairs 0.2403 0.3692 0.4031 0.7220 0.6321 0.7668
Regression
Values
All Pairs 0.06636 0.07729 0.08020 0.2482 0.2041 0.2428
Ratio 3.621 4.777 5.026 2.909 3.097 3.158
SD/Avg 0.9415 1.2081 1.2671 0.6364 0.7254 0.7353
</table>
<tableCaption confidence="0.99759">
Table 3: Values for Quantitative Analysis
</tableCaption>
<bodyText confidence="0.999878333333333">
characterization of the users’ interests (particu-
larly social news and technology): a Samsung
Galaxy S4 exploded and caused a fire while charg-
ing. Consistent with intuition, the prevalence of
the social news topic also generally increases as
the models grow more sophisticated.6
</bodyText>
<subsectionHeader confidence="0.998742">
4.5 Quantitative Analysis
</subsectionHeader>
<bodyText confidence="0.999902347826087">
Topic Quality. Automatic coherence detec-
tion (Lau et al., 2014) is an alternative to manual
evaluations of topic quality (Chang et al., 2009).
In each topic, the top n words’ average pointwise
mutual information (PMI)—based on a reference
corpus—serves as a measure of topic coherence.7
Topic quality improves with user interactions
and max-margin learning (Table 3). PMI drops
when lexical terms are added to the link probabil-
ity function, however. This is consistent with the
role of lexical terms in the model; their purpose
is to improve link prediction performance, not im-
prove topic quality.
Average Regression Value. One way to assess
the quality of link prediction is to compare the
scores of (ground-truth) linked documents to doc-
uments in general. In Table 3, the Average Re-
gression Values show this comparison as a ratio.
The higher the ratio, the more linked document
pairs differ from unlinked pairs, which means that
linked documents are easier to distinguish. This
ratio improves as RTM extensions are added, indi-
cating better link modeling quality.
</bodyText>
<footnote confidence="0.995371285714286">
6Numerically its proportion is consistently lower for
User A, whose interests are more diverse.
7We set n = 20 and use a reference corpus of 1,143,525
news items from Sogou Lab, comprising items from June to
July 2012, http://www.sogou.com/labs/dl/ca.
html. Each averages ∼347 tokens, using the same segmen-
tation scheme as the experimental corpus.
</footnote>
<bodyText confidence="0.9997697">
In the SD/Avg row of Table 3, we also compute
a ratio of standard deviations to mean values. Ra-
tios given by the models with hinge loss are lower
than those not using hinge loss. This means that
the regression values given by the models with
hinge loss are more concentrated around the av-
erage value, suggesting that these models can bet-
ter identify linked pairs, even though the ratio of
linked pairs’ average regression value to all pairs’
average value is lower.
</bodyText>
<sectionHeader confidence="0.998043" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999801363636364">
We introduce a new topic model that takes ad-
vantage of document links, incorporating link in-
formation straightforwardly by deriving clusters
from the link graph and assigning each cluster
a separate Dirichlet prior. We also take advan-
tage of locally-derived distributed representations
to “seed” the model’s latent topics in an informed
way, and we integrate max-margin prediction and
lexical regression to improve link prediction qual-
ity. Our quantitative results show improvements in
predictive link rank, and our qualitative and quan-
titative analysis illustrate that the model’s behavior
is intuitively plausible.
In future work, we plan to engage in further
model analysis and comparison, to explore al-
terations to model structure, e.g. introducing
hierarchical topic models, to use other cluster-
ing methods to obtain priors, and to explore the
value of predicted links for downstream tasks
such as friend recommendation (Pennacchiotti
and Gurumurthy, 2011) and inference of user at-
tributes (Volkova et al., 2014).
</bodyText>
<page confidence="0.997195">
265
</page>
<sectionHeader confidence="0.996531" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999956375">
We thank Hal Daum´e III for providing his code.
This work was supported in part by NSF award
1211153. Boyd-Graber is supported by NSF
Grants CCF-1409287, IIS-1320538, and NCSE-
1422492. Any opinions, findings, conclusions, or
recommendations expressed here are those of the
authors and do not necessarily reflect the view of
the sponsor.
</bodyText>
<sectionHeader confidence="0.998462" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999458975308642">
David Andrzejewski and Xiaojin Zhu. 2009. Latent
Dirichlet allocation with topic-in-set knowledge. In
Conference of the North American Chapter of the
Association for Computational Linguistics.
David M. Blei and Jon D. McAuliffe. 2007. Super-
vised topic models. In Proceedings of Advances in
Neural Information Processing Systems.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Jonathan Chang and David M. Blei. 2010. Hierarchi-
cal relational models for document networks. The
Annals of Applied Statistics, pages 124–150.
Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L.
Boyd-Graber, and David M. Blei. 2009. Reading
tea leaves: How humans interpret topic models. In
Proceedings ofAdvances in Neural Information Pro-
cessing Systems.
Hal Daum´e III. 2009. Markov random topic fields.
In Proceedings of the Association for Computational
Linguistics.
Myunghwan Kim and Jure Leskovec. 2012. La-
tent multi-group membership graph model. In Pro-
ceedings of the International Conference of Machine
Learning.
Jey Han Lau, David Newman, and Timothy Baldwin.
2014. Machine reading tea leaves: Automatically
evaluating topic coherence and topic model quality.
In Proceedings of the Association for Computational
Linguistics.
Jon D. McAuliffe and David M. Blei. 2008. Super-
vised topic models. In Proceedings of Advances in
Neural Information Processing Systems.
Miller McPherson, Lynn Smith-Lovin, and James M.
Cook. 2001. Birds of a feather: Homophily in social
networks. Annual Review of Sociology, pages 415–
444.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of Advances in Neural Informa-
tion Processing Systems.
David M. Mimno and Andrew McCallum. 2008.
Topic models conditioned on arbitrary features with
Dirichlet-multinomial regression. In Proceedings of
Uncertainty in Artificial Intelligence.
Viet-An Nguyen, Jordan L. Boyd-Graber, and Philip
Resnik. 2013. Lexical and hierarchical topic regres-
sion. In Proceedings of Advances in Neural Infor-
mation Processing Systems.
Marco Pennacchiotti and Siva Gurumurthy. 2011. In-
vestigating topic models for social media user rec-
ommendation. In Proceedings of World Wide Web
Conference.
Nicholas G. Polson and Steven L. Scott. 2011.
Data augmentation for support vector machines.
Bayesian Analysis, 6(1):1–23.
Yee Whye Teh, Michael I. Jordan, Matthew J. Beal,
and David M. Blei. 2006. Hierarchical Dirichlet
processes. Journal of the American Statistical Asso-
ciation, 101(476):1566–1581.
Svitlana Volkova, Glen Coppersmith, and Benjamin
Van Durme. 2014. Inferring user political prefer-
ences from streaming communications. In Proceed-
ings of the Association for Computational Linguis-
tics.
Hanna M. Wallach. 2008. Structured topic models for
language. Ph.D. thesis, University of Cambridge.
Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun
Liu. 2003. HHMM-based Chinese lexical analyzer
ICTCLAS. In Proceedings of the second SIGHAN
workshop on Chinese language processing-Volume
17.
Jun Zhu, Amr Ahmed, and Eric P. Xing. 2012.
MedLDA: Maximum margin supervised topic mod-
els. Journal of Machine Learning Research,
13(1):2237–2278.
Jun Zhu, Ning Chen, Hugh Perkins, and Bo Zhang.
2014. Gibbs max-margin topic models with data
augmentation. Journal of Machine Learning Re-
search, 15(1).
</reference>
<page confidence="0.998473">
266
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.170125">
<title confidence="0.999321">Birds of a Feather Linked Together: A Discriminative Topic Model using Link-based Priors</title>
<author confidence="0.981029">Weiwei</author>
<affiliation confidence="0.9926685">Computer University of</affiliation>
<address confidence="0.626424">College Park,</address>
<email confidence="0.999796">wwyang@cs.umd.edu</email>
<author confidence="0.97704">Jordan</author>
<affiliation confidence="0.845062">Computer University of Boulder,</affiliation>
<email confidence="0.999789">colorado.edu</email>
<author confidence="0.935911">Philip</author>
<affiliation confidence="0.9807025">Linguistics and University of</affiliation>
<address confidence="0.640872">College Park,</address>
<email confidence="0.999865">resnik@umd.edu</email>
<abstract confidence="0.992401">A wide range of applications, from social media to scientific literature analysis, involve graphs in which documents are connected by links. We introduce a topic model for link prediction based on the intuition that linked documents will tend to have similar topic distributions, integrating a max-margin learning criterion and lexical term weights in the loss function. We validate our approach on the tweets from 2,000 Sina Weibo users and evaluate our model’s reconstruction of the social network.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Andrzejewski</author>
<author>Xiaojin Zhu</author>
</authors>
<title>Latent Dirichlet allocation with topic-in-set knowledge.</title>
<date>2009</date>
<booktitle>In Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7362" citStr="Andrzejewski and Zhu (2009)" startWordPosition="1175" endWordPosition="1178">pics. For any word token wd,n whose word type is in cluster k, the associated topic assignment zd,n can only be k. To choose topic k’s seed words, within its word-cluster we compute each word wk,i’s skip-gram transition probability sum Sk,i to the other words as Nk Sk,i = p(wk,j |wk,i), (1) j=1,j7�i where Nk denotes the number of words in topic k. We then select the three words with the highest sum of transition probabilities as the seed words for topic k. In the sampling process (Section 3), seed words are only assigned to their corresponding topics, similar to the use of hard constraints by Andrzejewski and Zhu (2009). Steps 2b-3: Link regression parameters. Given two documents d and d&apos;, we want to predict whether they are linked by taking advantage of their topic patterns: the more similar two documents are, the more likely it is that they should be linked together. Like RTM, we will compute a regression in Step 5 using the topic distributions of d and d&apos;; however, we follow Nguyen et al. (2013) by also including a document’s word-level distribution as a regression input.2 The regression value of document d and d&apos; is Rd,d&apos; = 77T(zd o zd�) + τT(wd o wd&apos;), (2) where zd = Nd &amp; zd,n, and wd = Nd &amp; wd,n; o den</context>
</contexts>
<marker>Andrzejewski, Zhu, 2009</marker>
<rawString>David Andrzejewski and Xiaojin Zhu. 2009. Latent Dirichlet allocation with topic-in-set knowledge. In Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Jon D McAuliffe</author>
</authors>
<title>Supervised topic models.</title>
<date>2007</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="8862" citStr="Blei and McAuliffe, 2007" startWordPosition="1440" endWordPosition="1443"> topic-based and lexically-based predictions, respectively. Step 4: Generating documents. Documents are generated as in LDA, where each document’s topic distribution 0 is drawn from the cluster’s topic prior (a parametric analog to the HDP of Teh et al. (2006)) and each word’s topic assignment is drawn from the document’s topic distribution (except for seed words, as described above). Step 5: Generating links. Our model is a “downstream” supervised topic model, i.e., the prediction of the observable variable (here, document links) is informed by the documents’ topic distributions, as in sLDA (Blei and McAuliffe, 2007). In contrast to Chang and Blei (2010), who use a sigmoid as their link prediction function Ψ, we instead use hinge loss: the probability Ψ that two documents d and d&apos; are linked is p(yd,d0 = 1 |zd, zd0, wd, wd0) = exp(−2c max(0, ζd,d0)), where c is the regularization parameter. In the hinge loss function, ζd,d0 is ζd,d0 = 1 − yd,d0Rd,d0. (3) 3 Posterior Inference Sampling Topics. Following Polson and Scott (2011), by introducing an auxiliary variable λd,d0, we derive the conditional probability of a topic assignment p(zd,n = k |z−d,n, w−d,n, wd,n = v) N−d,n k,v + β ∝ × N−d,n + (Y7r—d,n × Nk .</context>
</contexts>
<marker>Blei, McAuliffe, 2007</marker>
<rawString>David M. Blei and Jon D. McAuliffe. 2007. Supervised topic models. In Proceedings of Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="1269" citStr="Blei et al., 2003" startWordPosition="183" endWordPosition="186">butions, integrating a max-margin learning criterion and lexical term weights in the loss function. We validate our approach on the tweets from 2,000 Sina Weibo users and evaluate our model’s reconstruction of the social network. 1 Introduction Many application areas for text analysis involve documents connected by links of one or more types—for example, analysis of scientific papers (citations, co-authorship), Web pages (hyperlinks), legislation (co-sponsorship, citations), and social media (followers, mentions, etc.). In this paper we work within the widely used framework of topic modeling (Blei et al., 2003, LDA) to develop a model that is simple and intuitive, but which identifies high quality topics while also accurately predicting link structure. Our work here is inspired by the phenomenon of homophily, the tendency of people to associate with others who are like themselves (McPherson et al., 2001). As manifested in social networks, the intuition is that people who are associated with one another are likely to discuss similar topics, and vice versa. The new topic model we propose therefore takes association links into account so that a document’s topic distribution is influenced by the topic </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>David M Blei</author>
</authors>
<title>Hierarchical relational models for document networks. The Annals of Applied Statistics,</title>
<date>2010</date>
<pages>124--150</pages>
<contexts>
<context position="2929" citStr="Chang and Blei, 2010" startWordPosition="445" endWordPosition="448">eful in encoding various types of prior knowledge and improving topic modeling performance (Mimno and McCallum, 2008). We then use distributed representations to “seed” the topic representations before getting down to modeling the documents. Our joint objective function uses a discriminative, max-margin approach (Zhu et al., 2012; Zhu et al., 2014) to both model the contents of documents and produce good predictions of links; in addition, it improves prediction by including lexical terms in the decision function (Nguyen et al., 2013). Our baseline for comparison is the Relational Topic Model (Chang and Blei, 2010, henceforth RTM), which jointly captures topics and binary link indicators in a style similar to supervised LDA (McAuliffe and Blei, 2008, sLDA), instead of modeling links alone, e.g., as in the Latent Multi-group Membership Graph model (Kim and Leskovec, 2012, LMMG). We also compare our approach with Daum´e III (2009), who uses document links to create a Markov random topic field (MRTF). Daum´e does not, however, look at link prediction, as his upstream model (Mimno and McCallum, 2008) only generates documents conditioned on links. In contrast, our downstream model allows the prediction of l</context>
<context position="8900" citStr="Chang and Blei (2010)" startWordPosition="1447" endWordPosition="1450">ns, respectively. Step 4: Generating documents. Documents are generated as in LDA, where each document’s topic distribution 0 is drawn from the cluster’s topic prior (a parametric analog to the HDP of Teh et al. (2006)) and each word’s topic assignment is drawn from the document’s topic distribution (except for seed words, as described above). Step 5: Generating links. Our model is a “downstream” supervised topic model, i.e., the prediction of the observable variable (here, document links) is informed by the documents’ topic distributions, as in sLDA (Blei and McAuliffe, 2007). In contrast to Chang and Blei (2010), who use a sigmoid as their link prediction function Ψ, we instead use hinge loss: the probability Ψ that two documents d and d&apos; are linked is p(yd,d0 = 1 |zd, zd0, wd, wd0) = exp(−2c max(0, ζd,d0)), where c is the regularization parameter. In the hinge loss function, ζd,d0 is ζd,d0 = 1 − yd,d0Rd,d0. (3) 3 Posterior Inference Sampling Topics. Following Polson and Scott (2011), by introducing an auxiliary variable λd,d0, we derive the conditional probability of a topic assignment p(zd,n = k |z−d,n, w−d,n, wd,n = v) N−d,n k,v + β ∝ × N−d,n + (Y7r—d,n × Nk .d&apos;n + V β ( d,k ld,k ) TTexp �— (c(d,d</context>
</contexts>
<marker>Chang, Blei, 2010</marker>
<rawString>Jonathan Chang and David M. Blei. 2010. Hierarchical relational models for document networks. The Annals of Applied Statistics, pages 124–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Sean Gerrish</author>
<author>Chong Wang</author>
<author>Jordan L Boyd-Graber</author>
<author>David M Blei</author>
</authors>
<title>Reading tea leaves: How humans interpret topic models.</title>
<date>2009</date>
<booktitle>In Proceedings ofAdvances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="17178" citStr="Chang et al., 2009" startWordPosition="2818" endWordPosition="2821">36 0.07729 0.08020 0.2482 0.2041 0.2428 Ratio 3.621 4.777 5.026 2.909 3.097 3.158 SD/Avg 0.9415 1.2081 1.2671 0.6364 0.7254 0.7353 Table 3: Values for Quantitative Analysis characterization of the users’ interests (particularly social news and technology): a Samsung Galaxy S4 exploded and caused a fire while charging. Consistent with intuition, the prevalence of the social news topic also generally increases as the models grow more sophisticated.6 4.5 Quantitative Analysis Topic Quality. Automatic coherence detection (Lau et al., 2014) is an alternative to manual evaluations of topic quality (Chang et al., 2009). In each topic, the top n words’ average pointwise mutual information (PMI)—based on a reference corpus—serves as a measure of topic coherence.7 Topic quality improves with user interactions and max-margin learning (Table 3). PMI drops when lexical terms are added to the link probability function, however. This is consistent with the role of lexical terms in the model; their purpose is to improve link prediction performance, not improve topic quality. Average Regression Value. One way to assess the quality of link prediction is to compare the scores of (ground-truth) linked documents to docum</context>
</contexts>
<marker>Chang, Gerrish, Wang, Boyd-Graber, Blei, 2009</marker>
<rawString>Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L. Boyd-Graber, and David M. Blei. 2009. Reading tea leaves: How humans interpret topic models. In Proceedings ofAdvances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Markov random topic fields.</title>
<date>2009</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<marker>Daum´e, 2009</marker>
<rawString>Hal Daum´e III. 2009. Markov random topic fields. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myunghwan Kim</author>
<author>Jure Leskovec</author>
</authors>
<title>Latent multi-group membership graph model.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference of Machine Learning.</booktitle>
<contexts>
<context position="3190" citStr="Kim and Leskovec, 2012" startWordPosition="485" endWordPosition="488">ve function uses a discriminative, max-margin approach (Zhu et al., 2012; Zhu et al., 2014) to both model the contents of documents and produce good predictions of links; in addition, it improves prediction by including lexical terms in the decision function (Nguyen et al., 2013). Our baseline for comparison is the Relational Topic Model (Chang and Blei, 2010, henceforth RTM), which jointly captures topics and binary link indicators in a style similar to supervised LDA (McAuliffe and Blei, 2008, sLDA), instead of modeling links alone, e.g., as in the Latent Multi-group Membership Graph model (Kim and Leskovec, 2012, LMMG). We also compare our approach with Daum´e III (2009), who uses document links to create a Markov random topic field (MRTF). Daum´e does not, however, look at link prediction, as his upstream model (Mimno and McCallum, 2008) only generates documents conditioned on links. In contrast, our downstream model allows the prediction of links, like RTM. Our model’s primary contribution is in its novel combination of a straightforward joint modeling approach, max-margin learning, and exploitation of lexical information in both topic seeding and regression, yielding a simple but effective model f</context>
<context position="8152" citStr="Kim and Leskovec (2012)" startWordPosition="1322" endWordPosition="1325">e similar two documents are, the more likely it is that they should be linked together. Like RTM, we will compute a regression in Step 5 using the topic distributions of d and d&apos;; however, we follow Nguyen et al. (2013) by also including a document’s word-level distribution as a regression input.2 The regression value of document d and d&apos; is Rd,d&apos; = 77T(zd o zd�) + τT(wd o wd&apos;), (2) where zd = Nd &amp; zd,n, and wd = Nd &amp; wd,n; o denotes the Hadamard product; 77 and τ are the 1In the experiment, seed words must appear at least 1,000 times. 2Both approaches contrast with the links-only approach of Kim and Leskovec (2012). η α α&apos; π yd,d&apos; φ β K ed&apos; zd&apos;,n wd&apos;,n Nd&apos; ed zd,n wd,n Nd L τ 262 weight vectors for topic-based and lexically-based predictions, respectively. Step 4: Generating documents. Documents are generated as in LDA, where each document’s topic distribution 0 is drawn from the cluster’s topic prior (a parametric analog to the HDP of Teh et al. (2006)) and each word’s topic assignment is drawn from the document’s topic distribution (except for seed words, as described above). Step 5: Generating links. Our model is a “downstream” supervised topic model, i.e., the prediction of the observable variable (</context>
</contexts>
<marker>Kim, Leskovec, 2012</marker>
<rawString>Myunghwan Kim and Jure Leskovec. 2012. Latent multi-group membership graph model. In Proceedings of the International Conference of Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jey Han Lau</author>
<author>David Newman</author>
<author>Timothy Baldwin</author>
</authors>
<title>Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="17100" citStr="Lau et al., 2014" startWordPosition="2805" endWordPosition="2808"> 0.2403 0.3692 0.4031 0.7220 0.6321 0.7668 Regression Values All Pairs 0.06636 0.07729 0.08020 0.2482 0.2041 0.2428 Ratio 3.621 4.777 5.026 2.909 3.097 3.158 SD/Avg 0.9415 1.2081 1.2671 0.6364 0.7254 0.7353 Table 3: Values for Quantitative Analysis characterization of the users’ interests (particularly social news and technology): a Samsung Galaxy S4 exploded and caused a fire while charging. Consistent with intuition, the prevalence of the social news topic also generally increases as the models grow more sophisticated.6 4.5 Quantitative Analysis Topic Quality. Automatic coherence detection (Lau et al., 2014) is an alternative to manual evaluations of topic quality (Chang et al., 2009). In each topic, the top n words’ average pointwise mutual information (PMI)—based on a reference corpus—serves as a measure of topic coherence.7 Topic quality improves with user interactions and max-margin learning (Table 3). PMI drops when lexical terms are added to the link probability function, however. This is consistent with the role of lexical terms in the model; their purpose is to improve link prediction performance, not improve topic quality. Average Regression Value. One way to assess the quality of link p</context>
</contexts>
<marker>Lau, Newman, Baldwin, 2014</marker>
<rawString>Jey Han Lau, David Newman, and Timothy Baldwin. 2014. Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon D McAuliffe</author>
<author>David M Blei</author>
</authors>
<title>Supervised topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="3067" citStr="McAuliffe and Blei, 2008" startWordPosition="466" endWordPosition="469">tributed representations to “seed” the topic representations before getting down to modeling the documents. Our joint objective function uses a discriminative, max-margin approach (Zhu et al., 2012; Zhu et al., 2014) to both model the contents of documents and produce good predictions of links; in addition, it improves prediction by including lexical terms in the decision function (Nguyen et al., 2013). Our baseline for comparison is the Relational Topic Model (Chang and Blei, 2010, henceforth RTM), which jointly captures topics and binary link indicators in a style similar to supervised LDA (McAuliffe and Blei, 2008, sLDA), instead of modeling links alone, e.g., as in the Latent Multi-group Membership Graph model (Kim and Leskovec, 2012, LMMG). We also compare our approach with Daum´e III (2009), who uses document links to create a Markov random topic field (MRTF). Daum´e does not, however, look at link prediction, as his upstream model (Mimno and McCallum, 2008) only generates documents conditioned on links. In contrast, our downstream model allows the prediction of links, like RTM. Our model’s primary contribution is in its novel combination of a straightforward joint modeling approach, max-margin lear</context>
</contexts>
<marker>McAuliffe, Blei, 2008</marker>
<rawString>Jon D. McAuliffe and David M. Blei. 2008. Supervised topic models. In Proceedings of Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miller McPherson</author>
<author>Lynn Smith-Lovin</author>
<author>James M Cook</author>
</authors>
<title>Birds of a feather: Homophily in social networks. Annual Review of Sociology,</title>
<date>2001</date>
<pages>415--444</pages>
<contexts>
<context position="1569" citStr="McPherson et al., 2001" startWordPosition="233" endWordPosition="236">documents connected by links of one or more types—for example, analysis of scientific papers (citations, co-authorship), Web pages (hyperlinks), legislation (co-sponsorship, citations), and social media (followers, mentions, etc.). In this paper we work within the widely used framework of topic modeling (Blei et al., 2003, LDA) to develop a model that is simple and intuitive, but which identifies high quality topics while also accurately predicting link structure. Our work here is inspired by the phenomenon of homophily, the tendency of people to associate with others who are like themselves (McPherson et al., 2001). As manifested in social networks, the intuition is that people who are associated with one another are likely to discuss similar topics, and vice versa. The new topic model we propose therefore takes association links into account so that a document’s topic distribution is influenced by the topic distributions of its neighbors. Specifically, we propose a joint model that uses link structure to define clusters (cliques) of documents and, following the intuition that documents in the same cluster are likely to have similar topic distributions, assigns each cluster its own separate Dirichlet pr</context>
</contexts>
<marker>McPherson, Smith-Lovin, Cook, 2001</marker>
<rawString>Miller McPherson, Lynn Smith-Lovin, and James M. Cook. 2001. Birds of a feather: Homophily in social networks. Annual Review of Sociology, pages 415– 444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="6562" citStr="Mikolov et al., 2013" startWordPosition="1036" endWordPosition="1039">k graph. Intuitively, documents in the same clique are likely to have similar topic distributions. Therefore, each of the L cliques l (the “birds of a feather” of our title) is assigned a separate Dirichlet prior πl over K topics. Step 2a: Using seed words to improve topic quality. To improve topic quality, we identify seed words for the K topics using distributed lexical representations: the key idea is to complement the more global information captured in LDAstyle topics with representations based on local contextual information. We cluster the most frequent words’ word2vec representations (Mikolov et al., 2013) into K word-clusters using the kmeans algorithm, based on the training corpus.1 We then enforce a one-to-one association between these discovered word clusters and the K topics. For any word token wd,n whose word type is in cluster k, the associated topic assignment zd,n can only be k. To choose topic k’s seed words, within its word-cluster we compute each word wk,i’s skip-gram transition probability sum Sk,i to the other words as Nk Sk,i = p(wk,j |wk,i), (1) j=1,j7�i where Nk denotes the number of words in topic k. We then select the three words with the highest sum of transition probabiliti</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Proceedings of Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Mimno</author>
<author>Andrew McCallum</author>
</authors>
<title>Topic models conditioned on arbitrary features with Dirichlet-multinomial regression.</title>
<date>2008</date>
<booktitle>In Proceedings of Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="2426" citStr="Mimno and McCallum, 2008" startWordPosition="368" endWordPosition="371"> so that a document’s topic distribution is influenced by the topic distributions of its neighbors. Specifically, we propose a joint model that uses link structure to define clusters (cliques) of documents and, following the intuition that documents in the same cluster are likely to have similar topic distributions, assigns each cluster its own separate Dirichlet prior over the cluster’s topic distribution. This use of priors is consistent with previous work that has shown document-topic priors to be useful in encoding various types of prior knowledge and improving topic modeling performance (Mimno and McCallum, 2008). We then use distributed representations to “seed” the topic representations before getting down to modeling the documents. Our joint objective function uses a discriminative, max-margin approach (Zhu et al., 2012; Zhu et al., 2014) to both model the contents of documents and produce good predictions of links; in addition, it improves prediction by including lexical terms in the decision function (Nguyen et al., 2013). Our baseline for comparison is the Relational Topic Model (Chang and Blei, 2010, henceforth RTM), which jointly captures topics and binary link indicators in a style similar to</context>
</contexts>
<marker>Mimno, McCallum, 2008</marker>
<rawString>David M. Mimno and Andrew McCallum. 2008. Topic models conditioned on arbitrary features with Dirichlet-multinomial regression. In Proceedings of Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-An Nguyen</author>
<author>Jordan L Boyd-Graber</author>
<author>Philip Resnik</author>
</authors>
<title>Lexical and hierarchical topic regression.</title>
<date>2013</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="2848" citStr="Nguyen et al., 2013" startWordPosition="432" endWordPosition="435">rs is consistent with previous work that has shown document-topic priors to be useful in encoding various types of prior knowledge and improving topic modeling performance (Mimno and McCallum, 2008). We then use distributed representations to “seed” the topic representations before getting down to modeling the documents. Our joint objective function uses a discriminative, max-margin approach (Zhu et al., 2012; Zhu et al., 2014) to both model the contents of documents and produce good predictions of links; in addition, it improves prediction by including lexical terms in the decision function (Nguyen et al., 2013). Our baseline for comparison is the Relational Topic Model (Chang and Blei, 2010, henceforth RTM), which jointly captures topics and binary link indicators in a style similar to supervised LDA (McAuliffe and Blei, 2008, sLDA), instead of modeling links alone, e.g., as in the Latent Multi-group Membership Graph model (Kim and Leskovec, 2012, LMMG). We also compare our approach with Daum´e III (2009), who uses document links to create a Markov random topic field (MRTF). Daum´e does not, however, look at link prediction, as his upstream model (Mimno and McCallum, 2008) only generates documents c</context>
<context position="7748" citStr="Nguyen et al. (2013)" startWordPosition="1246" endWordPosition="1249">hest sum of transition probabilities as the seed words for topic k. In the sampling process (Section 3), seed words are only assigned to their corresponding topics, similar to the use of hard constraints by Andrzejewski and Zhu (2009). Steps 2b-3: Link regression parameters. Given two documents d and d&apos;, we want to predict whether they are linked by taking advantage of their topic patterns: the more similar two documents are, the more likely it is that they should be linked together. Like RTM, we will compute a regression in Step 5 using the topic distributions of d and d&apos;; however, we follow Nguyen et al. (2013) by also including a document’s word-level distribution as a regression input.2 The regression value of document d and d&apos; is Rd,d&apos; = 77T(zd o zd�) + τT(wd o wd&apos;), (2) where zd = Nd &amp; zd,n, and wd = Nd &amp; wd,n; o denotes the Hadamard product; 77 and τ are the 1In the experiment, seed words must appear at least 1,000 times. 2Both approaches contrast with the links-only approach of Kim and Leskovec (2012). η α α&apos; π yd,d&apos; φ β K ed&apos; zd&apos;,n wd&apos;,n Nd&apos; ed zd,n wd,n Nd L τ 262 weight vectors for topic-based and lexically-based predictions, respectively. Step 4: Generating documents. Documents are generat</context>
</contexts>
<marker>Nguyen, Boyd-Graber, Resnik, 2013</marker>
<rawString>Viet-An Nguyen, Jordan L. Boyd-Graber, and Philip Resnik. 2013. Lexical and hierarchical topic regression. In Proceedings of Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Siva Gurumurthy</author>
</authors>
<title>Investigating topic models for social media user recommendation.</title>
<date>2011</date>
<booktitle>In Proceedings of World Wide Web Conference.</booktitle>
<marker>Pennacchiotti, Gurumurthy, 2011</marker>
<rawString>Marco Pennacchiotti and Siva Gurumurthy. 2011. Investigating topic models for social media user recommendation. In Proceedings of World Wide Web Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas G Polson</author>
<author>Steven L Scott</author>
</authors>
<title>Data augmentation for support vector machines.</title>
<date>2011</date>
<journal>Bayesian Analysis,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="9279" citStr="Polson and Scott (2011)" startWordPosition="1514" endWordPosition="1517">odel is a “downstream” supervised topic model, i.e., the prediction of the observable variable (here, document links) is informed by the documents’ topic distributions, as in sLDA (Blei and McAuliffe, 2007). In contrast to Chang and Blei (2010), who use a sigmoid as their link prediction function Ψ, we instead use hinge loss: the probability Ψ that two documents d and d&apos; are linked is p(yd,d0 = 1 |zd, zd0, wd, wd0) = exp(−2c max(0, ζd,d0)), where c is the regularization parameter. In the hinge loss function, ζd,d0 is ζd,d0 = 1 − yd,d0Rd,d0. (3) 3 Posterior Inference Sampling Topics. Following Polson and Scott (2011), by introducing an auxiliary variable λd,d0, we derive the conditional probability of a topic assignment p(zd,n = k |z−d,n, w−d,n, wd,n = v) N−d,n k,v + β ∝ × N−d,n + (Y7r—d,n × Nk .d&apos;n + V β ( d,k ld,k ) TTexp �— (c(d,d0 + λd,d0)2 (4) dl tad d0 ) , d where Nk,v denotes the count of word v assigned to topic k; Nd,k is the number of tokens in document d that are assigned to topic k.3 Marginal counts are denoted by ·; −d,n denotes that the count excludes token n in document d; d&apos; denotes the indexes of documents which are linked to document d; π−d,n ld,k is estimated based on the maximal path a</context>
</contexts>
<marker>Polson, Scott, 2011</marker>
<rawString>Nicholas G. Polson and Steven L. Scott. 2011. Data augmentation for support vector machines. Bayesian Analysis, 6(1):1–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
<author>Michael I Jordan</author>
<author>Matthew J Beal</author>
<author>David M Blei</author>
</authors>
<title>Hierarchical Dirichlet processes.</title>
<date>2006</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>101</volume>
<issue>476</issue>
<contexts>
<context position="8497" citStr="Teh et al. (2006)" startWordPosition="1383" endWordPosition="1386"> 77T(zd o zd�) + τT(wd o wd&apos;), (2) where zd = Nd &amp; zd,n, and wd = Nd &amp; wd,n; o denotes the Hadamard product; 77 and τ are the 1In the experiment, seed words must appear at least 1,000 times. 2Both approaches contrast with the links-only approach of Kim and Leskovec (2012). η α α&apos; π yd,d&apos; φ β K ed&apos; zd&apos;,n wd&apos;,n Nd&apos; ed zd,n wd,n Nd L τ 262 weight vectors for topic-based and lexically-based predictions, respectively. Step 4: Generating documents. Documents are generated as in LDA, where each document’s topic distribution 0 is drawn from the cluster’s topic prior (a parametric analog to the HDP of Teh et al. (2006)) and each word’s topic assignment is drawn from the document’s topic distribution (except for seed words, as described above). Step 5: Generating links. Our model is a “downstream” supervised topic model, i.e., the prediction of the observable variable (here, document links) is informed by the documents’ topic distributions, as in sLDA (Blei and McAuliffe, 2007). In contrast to Chang and Blei (2010), who use a sigmoid as their link prediction function Ψ, we instead use hinge loss: the probability Ψ that two documents d and d&apos; are linked is p(yd,d0 = 1 |zd, zd0, wd, wd0) = exp(−2c max(0, ζd,d0</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and David M. Blei. 2006. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101(476):1566–1581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svitlana Volkova</author>
<author>Glen Coppersmith</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Inferring user political preferences from streaming communications.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<marker>Volkova, Coppersmith, Van Durme, 2014</marker>
<rawString>Svitlana Volkova, Glen Coppersmith, and Benjamin Van Durme. 2014. Inferring user political preferences from streaming communications. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanna M Wallach</author>
</authors>
<title>Structured topic models for language.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<contexts>
<context position="9904" citStr="Wallach, 2008" startWordPosition="1641" endWordPosition="1642">ucing an auxiliary variable λd,d0, we derive the conditional probability of a topic assignment p(zd,n = k |z−d,n, w−d,n, wd,n = v) N−d,n k,v + β ∝ × N−d,n + (Y7r—d,n × Nk .d&apos;n + V β ( d,k ld,k ) TTexp �— (c(d,d0 + λd,d0)2 (4) dl tad d0 ) , d where Nk,v denotes the count of word v assigned to topic k; Nd,k is the number of tokens in document d that are assigned to topic k.3 Marginal counts are denoted by ·; −d,n denotes that the count excludes token n in document d; d&apos; denotes the indexes of documents which are linked to document d; π−d,n ld,k is estimated based on the maximal path assumption (Wallach, 2008) &amp;0ES(ld) N−d,n d0,k + α&apos; &amp;0ES(ld) N−d,n d0,� + Kα&apos; where S(ld) denotes the cluster which contains document d (Step 1 in the generative process). 3More details here and throughout this section appear in the supplementary materials. Optimizing topic and lexical regression parameters. While topic regression parameters 77 and lexical regression parameters •r can be sampled (Zhu et al., 2014), the associated covariance matrix is huge (approximately 12K × 12K in our experiments). Instead, we optimize these parameters using L-BFGS. Sampling auxiliary variables. The likelihood of auxiliary variables </context>
</contexts>
<marker>Wallach, 2008</marker>
<rawString>Hanna M. Wallach. 2008. Structured topic models for language. Ph.D. thesis, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua-Ping Zhang</author>
<author>Hong-Kui Yu</author>
<author>De-Yi Xiong</author>
<author>Qun Liu</author>
</authors>
<title>HHMM-based Chinese lexical analyzer ICTCLAS.</title>
<date>2003</date>
<booktitle>In Proceedings of the second SIGHAN workshop on Chinese language processing-Volume 17.</booktitle>
<contexts>
<context position="12088" citStr="Zhang et al., 2003" startWordPosition="2005" endWordPosition="2008">5 and run the models on 20 topics for all models in this and following sections. The results are the average values of five independent runs. Following Daum´e, in each run, for each document, 80% of its tokens are randomly selected for training and the remaining 20% are for test. As the training corpus is generated randomly, seeding is not applied in this section. The results are given in Table 1, where I- denotes that the model incorporates user interactions. The results confirm that our model outperforms both LDA and MRTF and that its use of user interactions holds promise. 4We use ICTCLAS (Zhang et al., 2003) for segmentation. After stopword and low-frequency word removal, the vocabulary includes 12,257 words, with —755 tokens per document and 5,404 links. π−d,n ld,k = , (5) 263 (a) Mentioning (b) Retweeting (c) Following 76.7 118.55 82.44 110.99 119.70 73.31 98.99 76.71 101.34 120.18 104.65 74.38 103.79 117.19 123.64 82.13 100.09 72.89 114.85 40 50 60 70 80 60 70 80 90 100 110 80 90 100 110 120 RTM IS-RTM Lex-IS-RTM MED-RTM IS-MED-RTM Lex-IS-MED-RTM Figure 2: Lex-IS-MED-RTM, combining all three extensions, performs the best on predicting mentioning and following links, although IS-RTM achieves a </context>
</contexts>
<marker>Zhang, Yu, Xiong, Liu, 2003</marker>
<rawString>Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun Liu. 2003. HHMM-based Chinese lexical analyzer ICTCLAS. In Proceedings of the second SIGHAN workshop on Chinese language processing-Volume 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Amr Ahmed</author>
<author>Eric P Xing</author>
</authors>
<title>MedLDA: Maximum margin supervised topic models.</title>
<date>2012</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="2640" citStr="Zhu et al., 2012" startWordPosition="398" endWordPosition="401">e intuition that documents in the same cluster are likely to have similar topic distributions, assigns each cluster its own separate Dirichlet prior over the cluster’s topic distribution. This use of priors is consistent with previous work that has shown document-topic priors to be useful in encoding various types of prior knowledge and improving topic modeling performance (Mimno and McCallum, 2008). We then use distributed representations to “seed” the topic representations before getting down to modeling the documents. Our joint objective function uses a discriminative, max-margin approach (Zhu et al., 2012; Zhu et al., 2014) to both model the contents of documents and produce good predictions of links; in addition, it improves prediction by including lexical terms in the decision function (Nguyen et al., 2013). Our baseline for comparison is the Relational Topic Model (Chang and Blei, 2010, henceforth RTM), which jointly captures topics and binary link indicators in a style similar to supervised LDA (McAuliffe and Blei, 2008, sLDA), instead of modeling links alone, e.g., as in the Latent Multi-group Membership Graph model (Kim and Leskovec, 2012, LMMG). We also compare our approach with Daum´e </context>
<context position="14211" citStr="Zhu et al., 2012" startWordPosition="2342" endWordPosition="2345">nsions of RTM.5 The results support the value in combining all three extensions using Lex-IS-MED-RTM, although for mentioning and retweeting, Lex-IS-MED-RTM and IS-RTM are quite close. Applying user interactions does not always produce improvements. This is because in our intrinsic evaluation, we assume that the links on the test set are not observable and cluster priors are 5IS- denotes that the model incorporates user interactions and seed words, Lex- means that lexical terms were included in the link probability function (Equation 3), and MED- denotes max-margin learning (Zhu et al., 2014; Zhu et al., 2012). Each type of link is applied separately; e.g., in Figure 2(a) results are based only on mentioning links, ignoring retweeting and following links. not applied. However, according to the training performance (extrinsic evaluations which we are still in progress), user interactions do benefit link prediction performance when links are partially available, e.g., suggesting more links based on observed links. In contrast, hinge loss and lexical term weights do not depend on metadata availability and generally produce improvements in link prediction performance. 4.4 Illustrative Example We illust</context>
</contexts>
<marker>Zhu, Ahmed, Xing, 2012</marker>
<rawString>Jun Zhu, Amr Ahmed, and Eric P. Xing. 2012. MedLDA: Maximum margin supervised topic models. Journal of Machine Learning Research, 13(1):2237–2278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Ning Chen</author>
<author>Hugh Perkins</author>
<author>Bo Zhang</author>
</authors>
<title>Gibbs max-margin topic models with data augmentation.</title>
<date>2014</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="2659" citStr="Zhu et al., 2014" startWordPosition="402" endWordPosition="405">ocuments in the same cluster are likely to have similar topic distributions, assigns each cluster its own separate Dirichlet prior over the cluster’s topic distribution. This use of priors is consistent with previous work that has shown document-topic priors to be useful in encoding various types of prior knowledge and improving topic modeling performance (Mimno and McCallum, 2008). We then use distributed representations to “seed” the topic representations before getting down to modeling the documents. Our joint objective function uses a discriminative, max-margin approach (Zhu et al., 2012; Zhu et al., 2014) to both model the contents of documents and produce good predictions of links; in addition, it improves prediction by including lexical terms in the decision function (Nguyen et al., 2013). Our baseline for comparison is the Relational Topic Model (Chang and Blei, 2010, henceforth RTM), which jointly captures topics and binary link indicators in a style similar to supervised LDA (McAuliffe and Blei, 2008, sLDA), instead of modeling links alone, e.g., as in the Latent Multi-group Membership Graph model (Kim and Leskovec, 2012, LMMG). We also compare our approach with Daum´e III (2009), who use</context>
<context position="10295" citStr="Zhu et al., 2014" startWordPosition="1701" endWordPosition="1704">nts are denoted by ·; −d,n denotes that the count excludes token n in document d; d&apos; denotes the indexes of documents which are linked to document d; π−d,n ld,k is estimated based on the maximal path assumption (Wallach, 2008) &amp;0ES(ld) N−d,n d0,k + α&apos; &amp;0ES(ld) N−d,n d0,� + Kα&apos; where S(ld) denotes the cluster which contains document d (Step 1 in the generative process). 3More details here and throughout this section appear in the supplementary materials. Optimizing topic and lexical regression parameters. While topic regression parameters 77 and lexical regression parameters •r can be sampled (Zhu et al., 2014), the associated covariance matrix is huge (approximately 12K × 12K in our experiments). Instead, we optimize these parameters using L-BFGS. Sampling auxiliary variables. The likelihood of auxiliary variables A follows a generalized inverse Gaussian distribution GIG(λd,d0; 12, 1, c2ζ2d,d0). Thus we sample λ−1 d,d0 from a an inverse Gaussian distribution p(λ−&apos; |z, w, η, τ) = IG λd d0; r1 , 1. (6) i 1 c |(1 | 4 Experimental Results 4.1 Dataset We crawl data from Sina Weibo, the largest Chinese micro-blog platform. The dataset contains 2,000 randomly-selected verified users, each represented by a</context>
<context position="14192" citStr="Zhu et al., 2014" startWordPosition="2338" endWordPosition="2341"> the distinct extensions of RTM.5 The results support the value in combining all three extensions using Lex-IS-MED-RTM, although for mentioning and retweeting, Lex-IS-MED-RTM and IS-RTM are quite close. Applying user interactions does not always produce improvements. This is because in our intrinsic evaluation, we assume that the links on the test set are not observable and cluster priors are 5IS- denotes that the model incorporates user interactions and seed words, Lex- means that lexical terms were included in the link probability function (Equation 3), and MED- denotes max-margin learning (Zhu et al., 2014; Zhu et al., 2012). Each type of link is applied separately; e.g., in Figure 2(a) results are based only on mentioning links, ignoring retweeting and following links. not applied. However, according to the training performance (extrinsic evaluations which we are still in progress), user interactions do benefit link prediction performance when links are partially available, e.g., suggesting more links based on observed links. In contrast, hinge loss and lexical term weights do not depend on metadata availability and generally produce improvements in link prediction performance. 4.4 Illustrativ</context>
</contexts>
<marker>Zhu, Chen, Perkins, Zhang, 2014</marker>
<rawString>Jun Zhu, Ning Chen, Hugh Perkins, and Bo Zhang. 2014. Gibbs max-margin topic models with data augmentation. Journal of Machine Learning Research, 15(1).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>