<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.995846">
Monotone Submodularity in Opinion Summaries
</title>
<author confidence="0.944043">
Jayanth Jayanth Jayaprakash Sundararaj Pushpak Bhattacharyya
</author>
<affiliation confidence="0.943249">
IIT Bombay IIT Bombay IIT Bombay
</affiliation>
<note confidence="0.605847">
jayanthjaiswal10 osjayaprakash pb
</note>
<email confidence="0.963916">
@cse.iitb.ac.in @gmail.com @cse.iitb.ac.in
</email>
<sectionHeader confidence="0.993141" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999882761904762">
Opinion summarization is the task of pro-
ducing the summary of a text, such that the
summary also preserves the sentiment of
the text. Opinion Summarization is thus a
trade-off between summarization and sen-
timent analysis. The demand of com-
pression may drop sentiment bearing sen-
tences, and the demand of sentiment de-
tection may bring in redundant sentences.
We harness the power of submodularity
to strike a balance between two conflict-
ing requirements. We investigate an in-
cipient class of submodular functions for
the problem, and a partial enumeration
based greedy algorithm that has perfor-
mance guarantee of 63%. Our functions
generate summaries such that there is good
correlation between document sentiment
and summary sentiment along with good
ROUGE score, which outperforms the-
state-of-the-art algorithms.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999124347826087">
Sentiment Analysis is often addressed as a classi-
fication task, which aims at determining the sen-
timent of a word, sentence, paragraph or a docu-
ment as a whole into positive, negative or neutral
classes (Pang et al., 2002). Summarization, on the
other hand is the task of aggregating and represent-
ing information content from a single document or
multiple documents in a brief and fluent manner.
Due to the explosive growth of data, fine grained
sentiment analysis as well as summarization on the
whole chunk of data can be a very time-consuming
task. Sentiment Analysis also requires filtering of
text portions as either objective (factual informa-
tion) or subjective (expressing some sentiment or
opinion) during pre-processing and then, classify-
ing the subjective extracts as positive or negative.
Subjective extracts can also be provided to users
as a summary of the sentiment-oriented content
of the reviews in search engines. In this paper,
we address the problem of generic extractive sum-
marization of reviews, a task commonly known as
Opinion Summarization (Liu, 2012). The goals of
opinion summarization are:
</bodyText>
<listItem confidence="0.9599446">
1. Present a short summary that conveys the
essence as well as the sentiment of the review
2. Provide a short subjective extract to NLP
pipeline for faster execution (e.g. sentiment
analysis, review clustering etc.).
</listItem>
<bodyText confidence="0.685882666666667">
In this paper, we use movie reviews for opinion
summarization task as they often have the follow-
ing parts:
</bodyText>
<listItem confidence="0.99481575">
1. Plot - Description of the story, which is fac-
tual in nature
2. Critique - Opinion about the movie, which is
sentiment bearing
</listItem>
<bodyText confidence="0.999828333333333">
Clearly, opinion summary to be generated will
have a trade-off between the two opposing parts
- subjective critique and objective plot. Our goal
is to strike a balance through linear combination of
suitable submodular functions in our paper. Joint
models of relevance and subjectivity have a great
benefit in that they have a large degree of freedom
as far as controlling redundancy goes. In con-
trast, conventional two-stage approach Pang and
Lee (2004), which first generate candidate sub-
jective sentences using min-cut and then selects
top subjective sentences within budget to generate
a summary, have less computational complexity
than joint models. However, two-stage approaches
are suboptimal for text summarization. For ex-
ample, when we select subjective sentences first,
the sentiment as well information content may be-
come redundant for a particular aspect. On the
</bodyText>
<page confidence="0.983111">
169
</page>
<note confidence="0.985121">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 169–178,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.99950956">
other hand, when we extract sentences first, an im-
portant subjective sentence may fail to be selected,
simply because it is long. The two stage conflict
in the sense that the demand of compression may
drop sentiment bearing sentences, and the demand
of sentiment detection may bring in redundant sen-
tences. We then, use partial enumeration based
greedy algorithm (Khuller et al., 1999), which
gives performance guarantee of (1− e−1) ≈ 0.632
(Sviridenko, 2004). The performance guarantee
reported is better than simple greedy algorithm,
used by Lin and Bilmes (2010) as their proof is
erroneous (Morita et al., 2013). Further, the same
greedy algorithm, which was used again in Lin and
Bilmes (2011) gives only performance guarantee
of 12(1− el) ≈ 0.316 (Khuller et al., 1999).
The rest of the paper is as follows - in the next
section, we look at previous work and establish
further motivation for our work. Following that,
we build the theory and formulate suitable objec-
tives for opinion summarization task. In the final
section, we present results based on implementa-
tion and testing of the functions. Experimental re-
sults show that the functions outperform the-state-
of-the-art methods.
</bodyText>
<sectionHeader confidence="0.996213" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.99979953125">
Automatically generating opinion summaries
from large review text corpora has long been stud-
ied in both information retrieval and natural lan-
guage processing.
In (Pang and Lee, 2004), a mincut-based algo-
rithm was proposed to classify each sentence as
being subjective or objective. The purpose of this
work was to remove objective sentences from re-
views to improve document level sentiment classi-
fication. Interestingly, the cut functions are sym-
metrical and submodular, and the problem of find-
ing min-cut is equivalent to minimizing a symmet-
ric submodular function.
Lerman et al. (2009) proposed three different
models - sentiment match (SM), sentiment match
+ aspect coverage (SMAC) and sentiment-aspect
match (SAM) to perform summarization of re-
views of a product. The first model is called sen-
timent match (SM), which extracts sentences so
that the average sentiment of the summary is as
close as possible to the average sentiment rating
of reviews of the entity i.e. low MISMATCH
but with high sentiment INTENSITY. The sec-
ond model, called sentiment match + aspect cov-
erage (SMAC), builds a summary that trades-off
between DIVERSITY, maximally covering impor-
tant aspects and MISMATCH, matching the over-
all sentiment of the entity along with high INTEN-
SITY. The third model, called sentiment-aspect
match (SAM), not only attempts to cover impor-
tant aspects, but cover them with appropriate sen-
timent using KL-Divergence function. Here, IN-
TENSITY and DIVERSITY in the first two mod-
els are linear monotone submodular functions,
while KL-Divergence function i.e. relative en-
tropy in last model, unlike entropy is not mono-
tone submodular.
In (Nishikawa et al., 2010b), a more sophis-
ticated summarization technique was proposed,
which generates a traditional text summary by se-
lecting and ordering sentences taken from multi-
ple reviews, considering both informativeness and
readability of the final summary. The readability
score in this paper would have been linear mono-
tone submodular function, if the negative polarity
was not penalizing. In (Nishikawa et al., 2010a),
the authors further studied this problem using an
integer linear programming formulation.
On the other hand, Lin et al .(2011) treated the
task of generic summarization as monotone sub-
modular function maximization. Further, they ar-
gued that monotone non-decreasing submodular
functions are an ideal class of functions to inves-
tigate for document summarization. They also
show, in fact, that many well-established meth-
ods for summarization (Carbonell and Goldstein,
1998; Filatova, 2004; Riedhammer et al., 2010)
correspond to submodular function optimization,
a property not explicitly mentioned in these publi-
cations. Since many authors either in summariza-
tion or opinion summarization have used functions
similar to submodular functions as objective, we
can take this fact as testament to the value of sub-
modular functions for opinion summarization.
</bodyText>
<sectionHeader confidence="0.997147" genericHeader="method">
3 Theoretical Background
</sectionHeader>
<subsectionHeader confidence="0.999753">
3.1 Introduction to Submodular Functions
</subsectionHeader>
<bodyText confidence="0.999100375">
A submodular function is a set function (f : 2v →
R) having a natural diminishing returns property.
Diminishing returns property holds if the differ-
ence in the value of the function that a single ele-
ment makes when added to an input set decreases
as the size of the input set increases i.e. for every
A, B C_ V with A C_ B and every x E V \B, we
have that f(AU{x})−f(A) ≥ f(BU{x})−f(B).
</bodyText>
<page confidence="0.993331">
170
</page>
<bodyText confidence="0.999613352941176">
A submodular function f is monotone if for every
A C_ B, we have that f(A) G f(B).
The extractive summarization task can be mod-
eled as optimization problem i.e. finding a set
S C_ V (S is set of sentences in summary, V is
set of sentences in Document) which maximizes a
submodular function f(S) subject to budget con-
straints. In the following section, we will justify
the use of submodular function for opinion sum-
marization. Another advantage of choosing mono-
tone submodular function is that there exists a
polynomial-time greedy algorithm for constrained
monotone submodular objective. The greedy al-
gorithm guarantees that the summary solution ob-
tained is almost as good as (63%) the best possi-
ble summary solution according to the objective
(Sviridenko, 2004; Wolsey, 1982).
</bodyText>
<subsectionHeader confidence="0.984822">
3.2 Submodularity in Opinion
Summarization
</subsectionHeader>
<bodyText confidence="0.99270925">
Opinion Summarization should be modeled as
a monotone submodular optimization problem,
since opinion summary also holds following prop-
erties:
</bodyText>
<listItem confidence="0.944170333333333">
1. Monotonicity - As more sentences are added
to opinion summary, subjectivity increases
along with information content as opinion-
ated words are being added.
2. Diminishing Return - If multiple sentences of
varying intensity are added to opinion sum-
</listItem>
<bodyText confidence="0.8458405">
mary, the effect of a lower intensity polarity
bearing sentence is diluted in the presence of
a higher intensity one.
To show that opinion summarization inherently
follow the diminishing return property, consider
the following sentences1 with positive polarity:
</bodyText>
<listItem confidence="0.992098">
A: “Even the acting in From Hell is solid, with the
dreamy Depp turning in a typically strong perfor-
mance and deftly handling a British accent.”
B: “Worth mentioning are the supporting roles by
Ians Holm and Richardsonlog.”
</listItem>
<bodyText confidence="0.995707428571429">
(A U B) : “Even the acting in From Hell is solid,
with the dreamy Depp turning in a typically strong
performance and deftly handling a British accent.
Worth mentioning are the supporting roles by Ians
Holm and Richardsonlog.” Compare A and its su-
perset, A U B as candidate summaries. Sentence
A and B convey positive sentiment, but sentence
</bodyText>
<footnote confidence="0.89045">
1http://www.imdb.com/reviews/295/29590.html
</footnote>
<bodyText confidence="0.999133">
B has less intensity compared to sentence A. After
reading the text (A U B), it is clear that the effect of
sentence B has diminished in front of sentence A,
though both are of same polarity. B can be thus,
removed from the candidate summary as it does
a diminishing addition in presence of sentence A
to the positive sentiment over the &amp;quot;acting&amp;quot; aspect
of the entity &amp;quot;movie&amp;quot;. The diminishing return not
only holds for same polarity but also, for opposite
polarity. Consider another example2:
</bodyText>
<listItem confidence="0.5348042">
A: “The movie is predictive with foreseeable end-
ing.”
B: “Still it’s very well-done that no movie in this
entire year has a scene that evokes pure joy as this
does.”
</listItem>
<bodyText confidence="0.999130264705882">
(A U B) : “The movie is predictive with foresee-
able ending. Still it’s very well-done that no movie
in this entire year has a scene that evokes pure joy
as this does.” Compare B and its superset, A U
B as candidate summaries. Sentence A has neg-
ative sentiment whereas sentence B conveys posi-
tive sentiment with more intensity. When we read
the text (A U B), it is clear that the effect of sen-
tence A has diminished in front of sentence B in
text , as usually polarity of higher intensity dom-
inates over the polarity of lower intensity. Now,
consider a general example3,
“Laurence plays Neo’s mentor Morpheus and he
does an excellent job of it. His lines flow with con-
fidence and style that makes his acting unique and
interesting. The movie has lot of special effects
and action-packed scenes with part of the appeal
has philosophical and religious underpinnings.”
If the budget for summary had been only two
subjective sentences, then picking up first two
would have redundantly captured only single as-
pect (i.e. acting) and the redundancy of the con-
cept (acting) also causes a diminishing return of
the second sentence because of the difference in
sentiment intensity. However, picking the last
sentence with either one of the first two would
have not just covered both the aspects (i.e. acting
and visual effects) but since, the sentences are not
overlapping in aspects, there would not have been
any diminishing return of sentiment on shared as-
pect (acting). Thus, it can be verified that opinion
polarity also holds submodular property of dimin-
ishing return, if they are on the same aspect of a
distinct entity.
</bodyText>
<footnote confidence="0.9992435">
2http://www.imdb.com/reviews/159/15918.html
3http://www.imdb.com/title/tt0133093/reviews
</footnote>
<page confidence="0.997521">
171
</page>
<sectionHeader confidence="0.998057" genericHeader="method">
4 Formulation
</sectionHeader>
<bodyText confidence="0.999973">
Let V represent the set of the sentences in a doc-
ument. The task of extractive opinion summariza-
tion is to select a subset S E V to represent the
entirety (ground set V ) . Obviously, we should
have |S |&lt; |V  |as it is a summary and should be
small. Therefore, constraints on S can naturally be
modeled as knapsack constraints:
</bodyText>
<equation confidence="0.982623">
X ci &lt; b (1)
iES
</equation>
<bodyText confidence="0.997036">
where ci is the non-negative cost of selecting
unit i (e.g., the number of words in the sentence)
and b is our budget. If we use a set function
F : 2V —* R to measure the quality of the sum-
mary set S, the summarization problem can then
be formalized as the following combinatorial opti-
mization problem:
</bodyText>
<listItem confidence="0.767969">
1. A1 : Modular Function
</listItem>
<bodyText confidence="0.79524825">
A1(S) is simple linear function, which is sum
of weighted subjective scores for each sen-
tence. No budgeting constraints are added to
this formulation.
</bodyText>
<equation confidence="0.9993655">
A1(S) = X X sj * wi (6)
i jE(PinS)
</equation>
<bodyText confidence="0.9981643">
Here Pi; i = 1...K is a partition of the ground
set V (i.e., UiPi = V ), which contains sen-
tences pertaining to different distinct aspects.
wi are the weights of the partitions, based on
the corresponding aspects. sj is the subjec-
tive score of the sentence j in summary. The
subjective score sj is calculated using senti-
wordnet as sum of the positive score E [0, 1]
and negative score E [0, 1] (Esuli and Sebas-
tiani, 2006).
</bodyText>
<equation confidence="0.994506">
XS* E argmaxScV F(S) s.t. ci &lt; b (2)
iES
</equation>
<bodyText confidence="0.999867666666667">
where F (S) , total utility of summary is given as
a linear combination of L(S), relevance and A(S),
subjective coverage of aspects.
</bodyText>
<equation confidence="0.999762">
Xsj = (pos(word) + neg(word))
wordEj
(7)
F(S) = αL(S) + QA(S) (3)
</equation>
<bodyText confidence="0.999729153846154">
This formulation clearly brings out the trade-off
between the subjective and the objective part. The
intuition behind the combination of sentiment and
aspect coverage in same function A(S) is that opin-
ion polarity holds submodular property of dimin-
ishing return only if the set of sentences talk about
common aspect of the same entity as discussed
in previous section. L(S) , relevance is modeled
same as in (Lin and Bilmes, 2011) as it captures
the summary property, while our novel function,
A(S) has been modeled differently through a suit-
able submodular function such that it captures the
subjectivity property.
</bodyText>
<listItem confidence="0.673929">
2. A2 : Budget-additive Function
</listItem>
<bodyText confidence="0.998081142857143">
A2(S) is an extension to A1(S), where max-
imum subjectivity score is restricted with
budget based on aspect. Here, λ E [0, 1]
is threshold coefficient for budget additive
function to avoid redundancy of high senti-
ment on same aspect. When aspect i is satu-
rated by S (min(PjE(PinS) sj, λ) = λ), any
new sentence j cannot further improve cov-
erage over i and thus, other aspects, which
are not yet saturated will have a better chance
of being covered. This formulation ensures
that produced summary is diverse enough and
conveys sentiment about different aspects by
budgeting.
</bodyText>
<equation confidence="0.9941204">
X
A2(S) =
i
Xmin(
jE(PinS)
sj, λi) * wi (8)
L(S) = X min{ci(S),γci(V )} (4)
iEV
Xci(S) = wi,j (5)
jES
</equation>
<bodyText confidence="0.995058333333333">
Here, wi,j &gt; 0 measures the similarity between
ith and jth sentences and ci(S) measures the sim-
ilarity of summary with the document.
Since, A(S), subjective coverage of aspects has
to be modeled as monotone submodular function,
it has been formulated as :
</bodyText>
<listItem confidence="0.938478">
3. A3 : Polarity Partitioned Budget-additive
</listItem>
<sectionHeader confidence="0.51271" genericHeader="method">
Function
</sectionHeader>
<bodyText confidence="0.9993015">
In previous formulation we have not consid-
ered the polarity of the sentences. For ex-
ample, if an aspect have many positive sen-
tences with more intensity but few negative
</bodyText>
<page confidence="0.990857">
172
</page>
<bodyText confidence="0.999288">
sentences with less intensity, A2 more likely
to reward more positive sentences because of
intensity. In this formulation budgeting ap-
plied not only on aspect but polarity scores
too. This ensures that both positive and neg-
ative polarity sentences are part of summary.
</bodyText>
<listItem confidence="0.487084">
5. A5 : Polarity Partitioned Facility Location
Function
</listItem>
<bodyText confidence="0.99888275">
A5 is similar to A4, but for each aspect, A5
rewards two sentences with positive and neg-
ative polarity but with maximum subjectivity
scores in those polarity partitions.
</bodyText>
<equation confidence="0.9995832">
A3(S) = X Xmin( sj, λi) * wi A5(S) = X maxjE(PinSnPpos)sj * wi
i jE(PinSnPpos) i
X sj, λi) * wi X maxjE(PinSnPneg)sj * wi
+ min( (9) + (12)
jE(PinSnPneg) i
</equation>
<bodyText confidence="0.995509833333333">
Ppos and Pneg are the partition of the sen-
tences in the ground set V , based on their
sign of polarity score. The polarity score polj
for partitioning sentences into Ppos and Pneg
is calculated as difference of the positive and
negative score.
</bodyText>
<equation confidence="0.999565666666667">
polj = X (pos(word) − neg(word))
wordEj
(10)
</equation>
<bodyText confidence="0.999019">
Polarity based partitions bring out contrast
view on a particular aspect, which is simi-
lar to contrast view opinion summarization to
give the reader a direct comparative view of
different strong opinions.
</bodyText>
<listItem confidence="0.511957">
4. A4 : Facility Location Function
</listItem>
<bodyText confidence="0.9999577">
In this formulation, we model the facil-
ity location objective function (Krause and
Golovin, 2014) for opinion summarization as
choosing possible sentences (facilities) out
of document (set of locations) to serve as-
pects (customers) giving service of value sj.
If each aspect (customer) chooses the sen-
tences (facility) with the highest value, the to-
tal value provided to all aspects (customers)
is modeled by this set function.
</bodyText>
<equation confidence="0.9876705">
A4(S) = X maxjE(PinS)sj * wi (11)
i
</equation>
<bodyText confidence="0.993927538461538">
So A4 rewards only a sentence which has
maximum subjectivity score in each aspect.
Each of the above functions are monotone sub-
modular as the parameters sj and wi are positive.
Since the first function is linear, it is both submod-
ular and supermodular, thus modular. Budget ad-
ditive and facility location functions (Krause and
Golovin, 2014) are special types of monotone sub-
modular functions. Since, monotone submodular-
ity is preserved under non-negative linear combi-
nations, polarity based partitioned function, whose
sub-parts are monotone submodular is also mono-
tone submodular.
</bodyText>
<sectionHeader confidence="0.998809" genericHeader="method">
5 Experiment
</sectionHeader>
<bodyText confidence="0.999237409090909">
We have created Movie ontology tree manually
(figure 1). Further the ontology is enriched by
adding clue words to all aspects using wordnet
sense propagation algorithm (Esuli and Sebastiani,
2006) for three iterations. The algorithm does a
hard clustering of the sentences by assigning the
sentence aspect, which has maximum number of
clue words in that sentence. Clue words for ‘Plot’
aspect are story, script, storyline, chief, commu-
nicative, explain, narrate, narration, narrative,
narrator, report, reporter, scheme, schemer, script,
scriptural, storyteller, tell, write up..,.
For the experiments, we have used the polar-
ity dataset from Pang et al. (2004). The dataset
contains 1000 positive and 1000 negative movie
reviews with size varying between 700 to 1000
words. As summary generation is time consum-
ing task (DUC4 only used 25 summaries to eval-
uate the performance of systems), we picked 100
positive and 100 negative reviews randomly from
the dataset and their abstract summaries are gener-
ated manually with 200 words limit as budget for
</bodyText>
<footnote confidence="0.9606495">
4Document Understanding Conferences,
http://duc.nist.gov
</footnote>
<page confidence="0.99523">
173
</page>
<figureCaption confidence="0.999864">
Figure 1: Movie Ontology Tree
</figureCaption>
<bodyText confidence="0.97540646875">
evaluation. These 200 summaries are used as gold
standard for estimating ROUGE scores of system
generated summaries.
In the experiment, the partial enumeration based
greedy algorithm (Khuller et al., 1999) is used for
summary generation of 200 test documents within
budget of 200 words. The algorithm has two parts.
In the first part, the algorithm compares function
values of all feasible solutions (sets) of cardinal-
ity one or two. Let Summ1 be a feasible set of
cardinality one or two that has the largest value of
the objective function F(S). In the second part,
the algorithm enumerates all feasible sets of cardi-
nality three. The algorithm, then completes each
such set greedily and keeps the current solution
feasible with respect to the knapsack constraint.
Let Summ2 be the solution obtained in the second
part that has the largest value of objective function
over all choices of the starting set for the greedy
algorithm. Finally, the algorithm outputs Summ1
if F(Summ1) &gt; F(Summ2) else Summ2 oth-
erwise. The algorithm does O(n2) function cal-
culations in first part, while O(n5) in second part.
This algorithm gives a performance guarantee of
(1−e−1) for solving monotone submodular objec-
tive with knapsack constraint (Khuller et al., 1999;
Sviridenko, 2004). As far as we know, the algo-
rithm has not been implemented for such prob-
lems because of complexity constraints (Lin and
Bilmes, 2011).
Algorithm 1 Overall Algorithm - Summary Ex-
traction
</bodyText>
<figure confidence="0.8959058">
B &lt;-- 200
for Sentence s E Document V do
Assign sentence s to one of aspects in movie ontology.
end for
Summ1 &lt;-- argmax { F(S), such that S C_ V, |S |&lt; 3, and
cost(S) &lt; B }
Summ2 &lt;-- 0
for all S C_ V, |S|=3, and cost(S) &lt; B do
U &lt;-- V \S
while U =� 0 do
maxReturn &lt;-- 0.0
newSentence &lt;-- 0
for Sentence s E U do
S* &lt;-- S U fs}
F(S*) &lt;-- αL(S*) + (1 − α)A(S*)
return &lt;-- F(S∗)−F(S)
len(s)
if return &gt; maxReturn then
maxReturn &lt;-- return
newSentence &lt;-- s
end if
end for
if cost(S U fnewSentence}) &lt; B then
S &lt;-- S U fnewSentence}
end if
U &lt;-- U \fnewSentence}
end while
if F(S) &gt; F(Summ2) then
Summ2 &lt;-- S
end if
end for
if F(Summ1) &gt; F(Summ2) then
Summary &lt;-- Summ1
else
Summary &lt;-- Summ2
</figure>
<subsectionHeader confidence="0.532782">
end if
</subsectionHeader>
<bodyText confidence="0.9719498">
In the algorithm, the sentences are clustered in
different partitions, corresponding to different as-
pects in the ontology tree using the clue words.
In the experiment, hard clustering of the sentences
in aspect-based partitions is considered but soft-
clustering of the sentences will also work with this
approach, which has been left out to avoid further
parameter tuning for soft clustering assigments.
The weights of the partitions as well as the thresh-
old parameters for the A(S) are currently kept pro-
portional to the inverse of the depth of that aspect
in the ontology-tree as sentiment expressed on the
concepts at higher level in the ontology tree should
have more weightage.
∀ Aspects i,
</bodyText>
<equation confidence="0.977262666666667">
1
wi = λi =
Level(i)
</equation>
<page confidence="0.984937">
174
</page>
<bodyText confidence="0.999951">
The linear combination parameter Q is set as 1−
α to bring out the trade-off between relevance and
subjective coverage of aspects and α is varied from
0 to 1 with step size 0.05 to find optimal α. γ in
L(S) is set to 0.5. The parameter learning, esp. α
and its impact have been already studied in (Lin
and Bilmes, 2011) and thus, is not addressed in
the paper. We have used the same approach of grid
search to find the optimal value of α.
</bodyText>
<sectionHeader confidence="0.999935" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.992686789473684">
We use ROUGE (Lin, 2004) for evaluating the
content of summaries. We have used the 200 test
documents that are manually summarized as gold
standard data for ROUGE evaluation. For figuring
out the sentiment correlation between manual and
system generated summaries, we trained Naive
Bayes sentiment classifier (Pang et al., 2002) on
training data using bag of words approach with
features as unigrams and bigrams and then, us-
ing minimum Pearson’s chi-square score of 3 for
feature extraction (Pecina and Schlesinger, 2006)
before calculating the sentiment. The measure
of sentiment preservation is calculated as Pear-
son correlation between the sentiment score of the
document and the corresponding summary senti-
ment, both calculated by the Naive Bayes senti-
ment classifier while the measure of coverage of
information content is given by ROUGE-1 and
ROUGE-2 f-scores. Mathematically,
</bodyText>
<equation confidence="0.92135725">
Covariance(X, Y )
Correlation(X, Y ) =
std.dev(X) ∗ std.dev(Y)
(13)
</equation>
<bodyText confidence="0.973794625">
Here, random variable X is the sentiment score
of the document sample and random variable
Y is the sentiment score of the correspond-
ing summary sample. For 200 documents, it
will be [(X1, Y1), (X2, Y2),..., (X200, Y200)] sam-
ple points for the above correlation function.
Following five baselines are used for compari-
son:
</bodyText>
<listItem confidence="0.968257777777778">
1. Baseline-1/TOP : Sentences selected con-
secutively from the start of the review within
the budget.
2. Baseline-2/TOP-SUBJ : Sentences ranked
based on their subjectivity and then, selected
with in the budget.
3. Baseline-3/LER-SM : (Lerman et al., 2009)
Sentences which have sentiment close to doc-
ument sentiment are chosen as Summary. We
</listItem>
<bodyText confidence="0.964913666666667">
have used same NaiveBayes classifier (Pang
et al., 2002) trained on imdb corpus to predict
the sentiment of a sentence and document.
</bodyText>
<equation confidence="0.9890025">
�minS⊂V (|senti(V ) − senti(j)|) (14)
j∈S
</equation>
<listItem confidence="0.939885357142857">
4. Baseline-4/TEXTRANK : TextRank sum-
marizer is based on Graph based unsuper-
vised algorithm. Graph is constructed by cre-
ating a vertex for each sentence in the docu-
ment and edges between vertices based on the
number of words two sentences (of vertices)
have in common and then, ranking them by
applying PageRank to the resulting graph.
Summary is generated with sentences hav-
ing more vertex score (Mihalcea and Tarau,
2004).
5. Baseline-5/MINCUT : Mincut algorithm
(Pang and Lee, 2004) classifies the sentences
as subjective and objective sentences, by
</listItem>
<bodyText confidence="0.981923766666667">
finding minimum s-t cuts in graph of sen-
tences using maximum flow algorithm. In
the graph, each sentence is a vertex and the
edge between the vertex to the source or sink
is taken as probability of the sentence being
subjective or objective (individual scores).
To ensure the graph connectivity, edges are
drawn between every pair of sentence ver-
tices, with edge weights taken proportional to
the degree of proximity (association scores).
After maximum flow algorithm, the cut in
which source vertex lies is classified as sub-
jective and vice-versa. We pick top subjective
sentences within the budget as summary.
Among the five baselines, TOP and TOP-SUBJ
are simplistic. Though both TEXTRANK and
MINCUT were not originally proposed for opin-
ion summarization but a number of papers in opin-
ion summarization have built over these two meth-
ods and also, used them as baselines and thus,
comparing with the &amp;quot;well-known&amp;quot; baselines will
give the readers from the sentiment analysis field
an intuitive idea of the performance of our sys-
tem. MINCUT, however was reproposed specif-
ically for subjective summarization by Pang and
Lee (2004) and we use that formulation for com-
parison.
Table 1 compares the five functions with the
above baselines based on optimal values of trade-
off α. From the table, it can be inferred that all the
</bodyText>
<page confidence="0.993709">
175
</page>
<table confidence="0.999818636363636">
System ROUGE1 ROUGE2 S. Corr.
TOP 0.43001 0.16591 0.86144
TOP-SUBJ 0.41807 0.14362 0.82953
LER-SM 0.42608 0.14533 0.96545
TEXTRANK 0.41987 0.14644 0.88967
MINCUT 0.39368 0.11047 0.84017
Submod-A1 0.43223 0.15702 0.95306
Submod-A2 0.43594 0.15977 0.97538
Submod-A3 0.43247 0.15436 0.93155
Submod-A4 0.43602 0.15760 0.98566
Submod-A5 0.42976 0.15551 0.95415
</table>
<tableCaption confidence="0.9625585">
Table 1: ROUGE F-score and sentiment correla-
tion for optimal values of α with baselines 1-5
</tableCaption>
<bodyText confidence="0.98142225">
proposed functions not only outperform the base-
lines in terms of ROUGE scores for optimal pa-
rameters but also, give better correlation with the
document sentiment. This can be quantitively ver-
ified by test of significance, unpaired one-tailed
t-test without assuming equal variance between
the baselines and the systems. The p-values are
0.0203 and 0.0066 respectively for ROUGE-1 F
Score and Sentiment Correlation, justifying that
the performance improvement by our system over
the baselines is statistically significant at p &lt;
0.05. The main reason being that the functions
with optimal values of trade-off parameter α strike
out a balance between relevance and subjectivity.
Clearly, the facility location based monotone sub-
modular functions are the best choice as objective
for opinion summarization task as they select sen-
tences with maximum subjectivity (facilities giv-
ing best service).
Our system is able to access the information of
aspect and polarity of each sentence, while some
baselines do not. So, the improvement over the
baselines may be attributed to those additional in-
formation rather than the optimality of the par-
tial enumeration greedy algorithm over submodu-
lar functions. So, we therefore, introduced the fol-
lowing baseline to question this misdoubt on the
experiment:
</bodyText>
<sectionHeader confidence="0.428153" genericHeader="evaluation">
6. Baseline-6/LIN:
</sectionHeader>
<bodyText confidence="0.9391818">
In this baseline, the greedy algorithm (Lin and
Bilmes, 2010) is used for summary generation, us-
ing the same functions and information in the for-
mulation. This algorithm fills the empty summary
set greedily by adding a single sentence in each
</bodyText>
<table confidence="0.999619909090909">
System ROUGE1 ROUGE2 S. Corr.
LIN-A1 0.43112 0.15795 0.89850
LIN-A2 0.42704 0.15382 0.90212
LIN-A3 0.42612 0.15297 0.93155
LIN-A4 0.42688 0.15245 0.93905
LIN-A5 0.43359 0.15922 0.91019
Submod-A1 0.43223 0.15702 0.95306
Submod-A2 0.43594 0.15977 0.97538
Submod-A3 0.43247 0.15436 0.93155
Submod-A4 0.43602 0.15760 0.98566
Submod-A5 0.42976 0.15551 0.95415
</table>
<tableCaption confidence="0.978341">
Table 2: ROUGE F-score and sentiment correla-
tion for optimal values of α with baseline 6
</tableCaption>
<figure confidence="0.8409595">
Alpha vs Sentiment Correlation
Alpha
</figure>
<figureCaption confidence="0.8912615">
Figure 2: Sentiment Correlation vs α
iteration, which gives maximum return over cost
</figureCaption>
<bodyText confidence="0.973615681818182">
F(S∗)−F(S
ratio
( len(s) ), ensuring that current solution
is feasible with respect to the knapsack constraint
(cost(5 U {new5entence}) ≤ B). This algorithm
has a complexity of O(n2) but gives only perfor-
mance guarantee of 12(1− e1) ≈ 0.316 (Khuller et
al., 1999).
Table 2 compares the same five functions in our
system with (Lin and Bilmes, 2010) system based
on optimal values of tradeoff α. From the table,
it can be inferred that our system also outperforms
this baseline both in terms of ROUGE scores and
sentiment correlation, which can be quantitively
verified by test of significance, unpaired one-tailed
t-test without assuming equal variance between
the baselines and the systems. The p-values are
0.02517 and 0.003965 respectively for ROUGE-1
F Score and Sentiment Correlation, justifying that
the performance improvement by our system over
LIN system is statistically significant at p &lt; 0.05.
The figures 2 and 3 plot the value of senti-
</bodyText>
<figure confidence="0.971859952380952">
Sentiment Correlation (Document and Summary)
0.98
0.96
0.94
0.92
0.88
0.86
0.84
0.82
0.78
0.9
0.8
1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
A1
A2
A3
A4
A5
176
Alpha vs ROUGE-1 F-Score
</figure>
<figureCaption confidence="0.969385">
Figure 3: ROUGE-1 F-score vs α
</figureCaption>
<table confidence="0.970824666666667">
Sys ROUGE1 ROUGE2 Senti. Corr.
A1 0.43223 0.15702 0.84827
A2 0.43594 0.15977 0.88601
A3 0.43247 0.15436 0.87038
A4 0.43602 0.15760 0.87818
A5 0.42976 0.15551 0.90147
</table>
<tableCaption confidence="0.963558">
Table 3: Maximum ROUGE F-score and their cor-
responding sentiment correlation
</tableCaption>
<bodyText confidence="0.999842769230769">
ment correlation and ROUGE-1 F score for the
formulated submodular functions with respect to
the trade-off parameter, α respectively. Looking at
the graph 2, we can observe that more weightage
to relevance over subjective coverage of aspects
decreases the sentiment correlation, which was ex-
pected because the summary generated misses out
on subjective sentiment due to trade-off. Simi-
larly, by looking at the graph 3, we also observe
that more weightage to relevance over subjective
coverage of aspects increases the ROUGE score
as expected. The erratic behaviour in figure 3 can
be explained by arguing that subjective words are
also important for summary and thus, giving less
weightage to them over relevance, ROUGE score
will increase but not properly.
The table 3 presents the value of sentiment
correlation corresponding to maximum ROUGE
score (for α ≈ 1). Clearly, A4 and A2 have maxi-
mum ROUGE scores as they neglect polarities and
instead, reward on aspect based partitions, thus in-
creasing coverage. The table 4 presents the value
of ROUGE score corresponding to maximum sen-
timent correlation (for α ≈ 0). Clearly, A4 also has
maximum sentiment correlation as it rewards max-
imum subjectivity, irrespective of polarities and
</bodyText>
<table confidence="0.958879666666667">
Sys Senti. Corr. ROUGE1 ROUGE2
A1 0.95306 0.42572 0.14939
A2 0.97538 0.41764 0.14836
A3 0.93155 0.42415 0.14782
A4 0.98566 0.42492 0.14942
A5 0.95415 0.42572 0.14266
</table>
<tableCaption confidence="0.9205535">
Table 4: Maximum sentiment correlation and cor-
responding ROUGE F-Score
</tableCaption>
<bodyText confidence="0.999896">
the corresponding ROUGE-2 F-score is also high-
est among all functions. Tables 1 and 2 contain
the ROUGE F-score and sentiment correlation for
optimal values of α, found after grid search while
tables 3 and 4 contain the peak values in the fig-
ures 2 and 3. For example, table 3 contains the
peak value of ROUGE-1 F score from figure 3 and
the corresponding value of Sentiment Correlation
from figure 2, at the same α.
</bodyText>
<sectionHeader confidence="0.998377" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999973392857143">
In this paper, we show that conflict between sub-
jectivity and relevance naturally arises in opinion
summarization. To address this problem, we intro-
duce new monotone submodular functions that are
well suited to document summarization (Lin and
Bilmes, 2010; Lin and Bilmes, 2011; Morita et
al., 2013) by modeling two important properties of
opinion summary - relevance and subjective cover-
age of aspects. We then, design different possible
combinations of objective functions to model the
task. To solve the algorithm effectively, we use
the partial enumeration based algorithm, which
is though computationally expensive (O(n5) func-
tion calls), gives a performance guarantee of 63%
for an NP-hard problem like summarization (Mc-
Donald, 2007). We have justified the submodular
property of opinion summary through examples
and significant performance of the system over the
baselines. Further, this optimal trade-off between
relevance and subjectivity can be used to design
an evaluation framework for opinion summariza-
tion task as both part of the objective functions are
proportional to the ROUGE and Sentiment Corre-
lation respectively, which are widely used evalua-
tion measures (Kim et al., 2011). As opinion sum-
marization task lies in the intersection of opinion
mining and summarization problems, both IR and
NLP communities will benefit from our work.
</bodyText>
<figure confidence="0.9972920625">
0.44
A1
A2
A3
A4
A5
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Alpha
0.435
0.43
0.425
ROUGE-1
0.42
0.415
0.41
0.405
</figure>
<page confidence="0.979785">
177
</page>
<sectionHeader confidence="0.994098" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999867642105263">
Jaime Carbonell and Jade Goldstein. 1998. The use of
mmr, diversity-based reranking for reordering doc-
uments and producing summaries. In SIGIR, pages
335–336.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
wordnet: A publicly available lexical resource for
opinion mining. In Proceedings of LREC, volume 6,
pages 417–422.
Elena Filatova. 2004. Event-based extractive summa-
rization. In Proceedings of ACL Workshop on Sum-
marization, pages 104–111.
Samir Khuller, Anna Moss, and Joseph Seffi Naor.
1999. The budgeted maximum coverage problem.
Information Processing Letters, 70(1):39–45.
Hyun Duk Kim, Kavita Ganesan, Parikshit Sondhi, and
ChengXiang Zhai. 2011. Comprehensive review of
opinion summarization.
Andreas Krause and Daniel Golovin. 2014. Submod-
ular function maximization. In Tractability: Practi-
cal Approaches to Hard Problems (to appear). Cam-
bridge University Press, February.
Kevin Lerman, Sasha Blair-Goldensohn, and Ryan Mc-
Donald. 2009. Sentiment summarization: evalu-
ating and learning user preferences. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 514–522.
Hui Lin and Jeff Bilmes. 2010. Multi-document sum-
marization via budgeted maximization of submod-
ular functions. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 912–920.
Hui Lin and Jeff Bilmes. 2011. A class of submodu-
lar functions for document summarization. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies-Volume 1, pages 510–520.
Chin-Yew Lin. 2004. Rouge: A package for automatic
evaluation of summaries. In Text Summarization
Branches Out: Proceedings of the ACL-04 Work-
shop, pages 74–81.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Ryan McDonald. 2007. A study of global inference
algorithms in multi-document summarization. In
Advances in Information Retrieval, pages 557–564.
Springer.
Rada Mihalcea and Paul Tarau. 2004. Textrank:
Bringing order into texts. In Proceedings of
EMNLP, volume 4, page 275.
Hajime Morita, Hiroya Takamura, Ryohei Sasano, and
Manabu Okumura. 2013. Subtree extractive sum-
marization via submodular maximization. In Pro-
ceedings of 51st Annual Meeting of the Association
for Computational Linguistics (to appear).
Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Mat-
suo, and Genichiro Kikui. 2010a. Opinion summa-
rization with integer linear programming formula-
tion for sentence extraction and ordering. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics: Posters, pages 910–918.
Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Mat-
suo, and Genichiro Kikui. 2010b. Optimizing in-
formativeness and readability for sentiment summa-
rization. In Proceedings of the ACL 2010 Confer-
ence Short Papers, pages 325–330.
Bo Pang and Lillian Lee. 2004. A sentimental educa-
tion: Sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of
the 42nd annual meeting on Association for Compu-
tational Linguistics, page 271.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing-Volume 10, pages 79–86. As-
sociation for Computational Linguistics.
Pavel Pecina and Pavel Schlesinger. 2006. Combin-
ing association measures for collocation extraction.
In Proceedings of the COLING/ACL on Main con-
ference poster sessions, pages 651–658. Association
for Computational Linguistics.
Korbinian Riedhammer, Benoit Favre, and Dilek
Hakkani-Tür. 2010. Long story short–global unsu-
pervised models for keyphrase based meeting sum-
marization. Speech Communication, 52(10):801–
815.
Maxim Sviridenko. 2004. A note on maximizing a
submodular set function subject to a knapsack con-
straint. Operations Research Letters, 32(1):41–43.
Laurence A Wolsey. 1982. An analysis of the greedy
algorithm for the submodular set covering problem.
Combinatorica, 2(4):385–393.
</reference>
<page confidence="0.997181">
178
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.720531">
<title confidence="0.999905">Monotone Submodularity in Opinion Summaries</title>
<author confidence="0.988389">Jayanth Jayanth Jayaprakash Sundararaj Pushpak Bhattacharyya</author>
<affiliation confidence="0.880083">IIT Bombay IIT Bombay IIT Bombay</affiliation>
<abstract confidence="0.988548666666667">jayanthjaiswal10 osjayaprakash pb @cse.iitb.ac.in @gmail.com @cse.iitb.ac.in Abstract Opinion summarization is the task of producing the summary of a text, such that the summary also preserves the sentiment of the text. Opinion Summarization is thus a trade-off between summarization and sentiment analysis. The demand of compression may drop sentiment bearing sentences, and the demand of sentiment detection may bring in redundant sentences. We harness the power of submodularity to strike a balance between two conflicting requirements. We investigate an incipient class of submodular functions for the problem, and a partial enumeration based greedy algorithm that has performance guarantee of 63%. Our functions generate summaries such that there is good correlation between document sentiment and summary sentiment along with good ROUGE score, which outperforms thestate-of-the-art algorithms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of mmr, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In SIGIR,</booktitle>
<pages>335--336</pages>
<contexts>
<context position="7440" citStr="Carbonell and Goldstein, 1998" startWordPosition="1152" endWordPosition="1155">readability score in this paper would have been linear monotone submodular function, if the negative polarity was not penalizing. In (Nishikawa et al., 2010a), the authors further studied this problem using an integer linear programming formulation. On the other hand, Lin et al .(2011) treated the task of generic summarization as monotone submodular function maximization. Further, they argued that monotone non-decreasing submodular functions are an ideal class of functions to investigate for document summarization. They also show, in fact, that many well-established methods for summarization (Carbonell and Goldstein, 1998; Filatova, 2004; Riedhammer et al., 2010) correspond to submodular function optimization, a property not explicitly mentioned in these publications. Since many authors either in summarization or opinion summarization have used functions similar to submodular functions as objective, we can take this fact as testament to the value of submodular functions for opinion summarization. 3 Theoretical Background 3.1 Introduction to Submodular Functions A submodular function is a set function (f : 2v → R) having a natural diminishing returns property. Diminishing returns property holds if the differenc</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In SIGIR, pages 335–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>417--422</pages>
<contexts>
<context position="14025" citStr="Esuli and Sebastiani, 2006" startWordPosition="2270" endWordPosition="2274">: Modular Function A1(S) is simple linear function, which is sum of weighted subjective scores for each sentence. No budgeting constraints are added to this formulation. A1(S) = X X sj * wi (6) i jE(PinS) Here Pi; i = 1...K is a partition of the ground set V (i.e., UiPi = V ), which contains sentences pertaining to different distinct aspects. wi are the weights of the partitions, based on the corresponding aspects. sj is the subjective score of the sentence j in summary. The subjective score sj is calculated using sentiwordnet as sum of the positive score E [0, 1] and negative score E [0, 1] (Esuli and Sebastiani, 2006). XS* E argmaxScV F(S) s.t. ci &lt; b (2) iES where F (S) , total utility of summary is given as a linear combination of L(S), relevance and A(S), subjective coverage of aspects. Xsj = (pos(word) + neg(word)) wordEj (7) F(S) = αL(S) + QA(S) (3) This formulation clearly brings out the trade-off between the subjective and the objective part. The intuition behind the combination of sentiment and aspect coverage in same function A(S) is that opinion polarity holds submodular property of diminishing return only if the set of sentences talk about common aspect of the same entity as discussed in previou</context>
<context position="18511" citStr="Esuli and Sebastiani, 2006" startWordPosition="3022" endWordPosition="3025">e positive. Since the first function is linear, it is both submodular and supermodular, thus modular. Budget additive and facility location functions (Krause and Golovin, 2014) are special types of monotone submodular functions. Since, monotone submodularity is preserved under non-negative linear combinations, polarity based partitioned function, whose sub-parts are monotone submodular is also monotone submodular. 5 Experiment We have created Movie ontology tree manually (figure 1). Further the ontology is enriched by adding clue words to all aspects using wordnet sense propagation algorithm (Esuli and Sebastiani, 2006) for three iterations. The algorithm does a hard clustering of the sentences by assigning the sentence aspect, which has maximum number of clue words in that sentence. Clue words for ‘Plot’ aspect are story, script, storyline, chief, communicative, explain, narrate, narration, narrative, narrator, report, reporter, scheme, schemer, script, scriptural, storyteller, tell, write up..,. For the experiments, we have used the polarity dataset from Pang et al. (2004). The dataset contains 1000 positive and 1000 negative movie reviews with size varying between 700 to 1000 words. As summary generation </context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings of LREC, volume 6, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Filatova</author>
</authors>
<title>Event-based extractive summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL Workshop on Summarization,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="7456" citStr="Filatova, 2004" startWordPosition="1156" endWordPosition="1157"> would have been linear monotone submodular function, if the negative polarity was not penalizing. In (Nishikawa et al., 2010a), the authors further studied this problem using an integer linear programming formulation. On the other hand, Lin et al .(2011) treated the task of generic summarization as monotone submodular function maximization. Further, they argued that monotone non-decreasing submodular functions are an ideal class of functions to investigate for document summarization. They also show, in fact, that many well-established methods for summarization (Carbonell and Goldstein, 1998; Filatova, 2004; Riedhammer et al., 2010) correspond to submodular function optimization, a property not explicitly mentioned in these publications. Since many authors either in summarization or opinion summarization have used functions similar to submodular functions as objective, we can take this fact as testament to the value of submodular functions for opinion summarization. 3 Theoretical Background 3.1 Introduction to Submodular Functions A submodular function is a set function (f : 2v → R) having a natural diminishing returns property. Diminishing returns property holds if the difference in the value o</context>
</contexts>
<marker>Filatova, 2004</marker>
<rawString>Elena Filatova. 2004. Event-based extractive summarization. In Proceedings of ACL Workshop on Summarization, pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samir Khuller</author>
<author>Anna Moss</author>
<author>Joseph Seffi Naor</author>
</authors>
<title>The budgeted maximum coverage problem.</title>
<date>1999</date>
<journal>Information Processing Letters,</journal>
<volume>70</volume>
<issue>1</issue>
<contexts>
<context position="4079" citStr="Khuller et al., 1999" startWordPosition="626" endWordPosition="629">undant for a particular aspect. On the 169 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 169–178, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. other hand, when we extract sentences first, an important subjective sentence may fail to be selected, simply because it is long. The two stage conflict in the sense that the demand of compression may drop sentiment bearing sentences, and the demand of sentiment detection may bring in redundant sentences. We then, use partial enumeration based greedy algorithm (Khuller et al., 1999), which gives performance guarantee of (1− e−1) ≈ 0.632 (Sviridenko, 2004). The performance guarantee reported is better than simple greedy algorithm, used by Lin and Bilmes (2010) as their proof is erroneous (Morita et al., 2013). Further, the same greedy algorithm, which was used again in Lin and Bilmes (2011) gives only performance guarantee of 12(1− el) ≈ 0.316 (Khuller et al., 1999). The rest of the paper is as follows - in the next section, we look at previous work and establish further motivation for our work. Following that, we build the theory and formulate suitable objectives for opi</context>
<context position="19661" citStr="Khuller et al., 1999" startWordPosition="3196" endWordPosition="3199">ews with size varying between 700 to 1000 words. As summary generation is time consuming task (DUC4 only used 25 summaries to evaluate the performance of systems), we picked 100 positive and 100 negative reviews randomly from the dataset and their abstract summaries are generated manually with 200 words limit as budget for 4Document Understanding Conferences, http://duc.nist.gov 173 Figure 1: Movie Ontology Tree evaluation. These 200 summaries are used as gold standard for estimating ROUGE scores of system generated summaries. In the experiment, the partial enumeration based greedy algorithm (Khuller et al., 1999) is used for summary generation of 200 test documents within budget of 200 words. The algorithm has two parts. In the first part, the algorithm compares function values of all feasible solutions (sets) of cardinality one or two. Let Summ1 be a feasible set of cardinality one or two that has the largest value of the objective function F(S). In the second part, the algorithm enumerates all feasible sets of cardinality three. The algorithm, then completes each such set greedily and keeps the current solution feasible with respect to the knapsack constraint. Let Summ2 be the solution obtained in t</context>
<context position="29273" citStr="Khuller et al., 1999" startWordPosition="4781" endWordPosition="4784">02 0.95306 Submod-A2 0.43594 0.15977 0.97538 Submod-A3 0.43247 0.15436 0.93155 Submod-A4 0.43602 0.15760 0.98566 Submod-A5 0.42976 0.15551 0.95415 Table 2: ROUGE F-score and sentiment correlation for optimal values of α with baseline 6 Alpha vs Sentiment Correlation Alpha Figure 2: Sentiment Correlation vs α iteration, which gives maximum return over cost F(S∗)−F(S ratio ( len(s) ), ensuring that current solution is feasible with respect to the knapsack constraint (cost(5 U {new5entence}) ≤ B). This algorithm has a complexity of O(n2) but gives only performance guarantee of 12(1− e1) ≈ 0.316 (Khuller et al., 1999). Table 2 compares the same five functions in our system with (Lin and Bilmes, 2010) system based on optimal values of tradeoff α. From the table, it can be inferred that our system also outperforms this baseline both in terms of ROUGE scores and sentiment correlation, which can be quantitively verified by test of significance, unpaired one-tailed t-test without assuming equal variance between the baselines and the systems. The p-values are 0.02517 and 0.003965 respectively for ROUGE-1 F Score and Sentiment Correlation, justifying that the performance improvement by our system over LIN system </context>
</contexts>
<marker>Khuller, Moss, Naor, 1999</marker>
<rawString>Samir Khuller, Anna Moss, and Joseph Seffi Naor. 1999. The budgeted maximum coverage problem. Information Processing Letters, 70(1):39–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyun Duk Kim</author>
<author>Kavita Ganesan</author>
<author>Parikshit Sondhi</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Comprehensive review of opinion summarization.</title>
<date>2011</date>
<marker>Kim, Ganesan, Sondhi, Zhai, 2011</marker>
<rawString>Hyun Duk Kim, Kavita Ganesan, Parikshit Sondhi, and ChengXiang Zhai. 2011. Comprehensive review of opinion summarization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Krause</author>
<author>Daniel Golovin</author>
</authors>
<title>Submodular function maximization. In Tractability: Practical Approaches to Hard Problems (to appear).</title>
<date>2014</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="17352" citStr="Krause and Golovin, 2014" startWordPosition="2840" endWordPosition="2843">pos and Pneg are the partition of the sentences in the ground set V , based on their sign of polarity score. The polarity score polj for partitioning sentences into Ppos and Pneg is calculated as difference of the positive and negative score. polj = X (pos(word) − neg(word)) wordEj (10) Polarity based partitions bring out contrast view on a particular aspect, which is similar to contrast view opinion summarization to give the reader a direct comparative view of different strong opinions. 4. A4 : Facility Location Function In this formulation, we model the facility location objective function (Krause and Golovin, 2014) for opinion summarization as choosing possible sentences (facilities) out of document (set of locations) to serve aspects (customers) giving service of value sj. If each aspect (customer) chooses the sentences (facility) with the highest value, the total value provided to all aspects (customers) is modeled by this set function. A4(S) = X maxjE(PinS)sj * wi (11) i So A4 rewards only a sentence which has maximum subjectivity score in each aspect. Each of the above functions are monotone submodular as the parameters sj and wi are positive. Since the first function is linear, it is both submodula</context>
</contexts>
<marker>Krause, Golovin, 2014</marker>
<rawString>Andreas Krause and Daniel Golovin. 2014. Submodular function maximization. In Tractability: Practical Approaches to Hard Problems (to appear). Cambridge University Press, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Lerman</author>
<author>Sasha Blair-Goldensohn</author>
<author>Ryan McDonald</author>
</authors>
<title>Sentiment summarization: evaluating and learning user preferences.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>514--522</pages>
<contexts>
<context position="5487" citStr="Lerman et al. (2009)" startWordPosition="851" endWordPosition="854">the-art methods. 2 Previous Work Automatically generating opinion summaries from large review text corpora has long been studied in both information retrieval and natural language processing. In (Pang and Lee, 2004), a mincut-based algorithm was proposed to classify each sentence as being subjective or objective. The purpose of this work was to remove objective sentences from reviews to improve document level sentiment classification. Interestingly, the cut functions are symmetrical and submodular, and the problem of finding min-cut is equivalent to minimizing a symmetric submodular function. Lerman et al. (2009) proposed three different models - sentiment match (SM), sentiment match + aspect coverage (SMAC) and sentiment-aspect match (SAM) to perform summarization of reviews of a product. The first model is called sentiment match (SM), which extracts sentences so that the average sentiment of the summary is as close as possible to the average sentiment rating of reviews of the entity i.e. low MISMATCH but with high sentiment INTENSITY. The second model, called sentiment match + aspect coverage (SMAC), builds a summary that trades-off between DIVERSITY, maximally covering important aspects and MISMATC</context>
<context position="24302" citStr="Lerman et al., 2009" startWordPosition="4002" endWordPosition="4005">lation(X, Y ) = std.dev(X) ∗ std.dev(Y) (13) Here, random variable X is the sentiment score of the document sample and random variable Y is the sentiment score of the corresponding summary sample. For 200 documents, it will be [(X1, Y1), (X2, Y2),..., (X200, Y200)] sample points for the above correlation function. Following five baselines are used for comparison: 1. Baseline-1/TOP : Sentences selected consecutively from the start of the review within the budget. 2. Baseline-2/TOP-SUBJ : Sentences ranked based on their subjectivity and then, selected with in the budget. 3. Baseline-3/LER-SM : (Lerman et al., 2009) Sentences which have sentiment close to document sentiment are chosen as Summary. We have used same NaiveBayes classifier (Pang et al., 2002) trained on imdb corpus to predict the sentiment of a sentence and document. �minS⊂V (|senti(V ) − senti(j)|) (14) j∈S 4. Baseline-4/TEXTRANK : TextRank summarizer is based on Graph based unsupervised algorithm. Graph is constructed by creating a vertex for each sentence in the document and edges between vertices based on the number of words two sentences (of vertices) have in common and then, ranking them by applying PageRank to the resulting graph. Sum</context>
</contexts>
<marker>Lerman, Blair-Goldensohn, McDonald, 2009</marker>
<rawString>Kevin Lerman, Sasha Blair-Goldensohn, and Ryan McDonald. 2009. Sentiment summarization: evaluating and learning user preferences. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 514–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Lin</author>
<author>Jeff Bilmes</author>
</authors>
<title>Multi-document summarization via budgeted maximization of submodular functions.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>912--920</pages>
<contexts>
<context position="4259" citStr="Lin and Bilmes (2010)" startWordPosition="653" endWordPosition="656">2015. c�2015 Association for Computational Linguistics. other hand, when we extract sentences first, an important subjective sentence may fail to be selected, simply because it is long. The two stage conflict in the sense that the demand of compression may drop sentiment bearing sentences, and the demand of sentiment detection may bring in redundant sentences. We then, use partial enumeration based greedy algorithm (Khuller et al., 1999), which gives performance guarantee of (1− e−1) ≈ 0.632 (Sviridenko, 2004). The performance guarantee reported is better than simple greedy algorithm, used by Lin and Bilmes (2010) as their proof is erroneous (Morita et al., 2013). Further, the same greedy algorithm, which was used again in Lin and Bilmes (2011) gives only performance guarantee of 12(1− el) ≈ 0.316 (Khuller et al., 1999). The rest of the paper is as follows - in the next section, we look at previous work and establish further motivation for our work. Following that, we build the theory and formulate suitable objectives for opinion summarization task. In the final section, we present results based on implementation and testing of the functions. Experimental results show that the functions outperform the-</context>
<context position="28262" citStr="Lin and Bilmes, 2010" startWordPosition="4627" endWordPosition="4630"> best choice as objective for opinion summarization task as they select sentences with maximum subjectivity (facilities giving best service). Our system is able to access the information of aspect and polarity of each sentence, while some baselines do not. So, the improvement over the baselines may be attributed to those additional information rather than the optimality of the partial enumeration greedy algorithm over submodular functions. So, we therefore, introduced the following baseline to question this misdoubt on the experiment: 6. Baseline-6/LIN: In this baseline, the greedy algorithm (Lin and Bilmes, 2010) is used for summary generation, using the same functions and information in the formulation. This algorithm fills the empty summary set greedily by adding a single sentence in each System ROUGE1 ROUGE2 S. Corr. LIN-A1 0.43112 0.15795 0.89850 LIN-A2 0.42704 0.15382 0.90212 LIN-A3 0.42612 0.15297 0.93155 LIN-A4 0.42688 0.15245 0.93905 LIN-A5 0.43359 0.15922 0.91019 Submod-A1 0.43223 0.15702 0.95306 Submod-A2 0.43594 0.15977 0.97538 Submod-A3 0.43247 0.15436 0.93155 Submod-A4 0.43602 0.15760 0.98566 Submod-A5 0.42976 0.15551 0.95415 Table 2: ROUGE F-score and sentiment correlation for optimal va</context>
<context position="32570" citStr="Lin and Bilmes, 2010" startWordPosition="5319" endWordPosition="5322">ions. Tables 1 and 2 contain the ROUGE F-score and sentiment correlation for optimal values of α, found after grid search while tables 3 and 4 contain the peak values in the figures 2 and 3. For example, table 3 contains the peak value of ROUGE-1 F score from figure 3 and the corresponding value of Sentiment Correlation from figure 2, at the same α. 7 Conclusion In this paper, we show that conflict between subjectivity and relevance naturally arises in opinion summarization. To address this problem, we introduce new monotone submodular functions that are well suited to document summarization (Lin and Bilmes, 2010; Lin and Bilmes, 2011; Morita et al., 2013) by modeling two important properties of opinion summary - relevance and subjective coverage of aspects. We then, design different possible combinations of objective functions to model the task. To solve the algorithm effectively, we use the partial enumeration based algorithm, which is though computationally expensive (O(n5) function calls), gives a performance guarantee of 63% for an NP-hard problem like summarization (McDonald, 2007). We have justified the submodular property of opinion summary through examples and significant performance of the s</context>
</contexts>
<marker>Lin, Bilmes, 2010</marker>
<rawString>Hui Lin and Jeff Bilmes. 2010. Multi-document summarization via budgeted maximization of submodular functions. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 912–920.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Lin</author>
<author>Jeff Bilmes</author>
</authors>
<title>A class of submodular functions for document summarization.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume</booktitle>
<volume>1</volume>
<pages>510--520</pages>
<contexts>
<context position="4392" citStr="Lin and Bilmes (2011)" startWordPosition="676" endWordPosition="679"> may fail to be selected, simply because it is long. The two stage conflict in the sense that the demand of compression may drop sentiment bearing sentences, and the demand of sentiment detection may bring in redundant sentences. We then, use partial enumeration based greedy algorithm (Khuller et al., 1999), which gives performance guarantee of (1− e−1) ≈ 0.632 (Sviridenko, 2004). The performance guarantee reported is better than simple greedy algorithm, used by Lin and Bilmes (2010) as their proof is erroneous (Morita et al., 2013). Further, the same greedy algorithm, which was used again in Lin and Bilmes (2011) gives only performance guarantee of 12(1− el) ≈ 0.316 (Khuller et al., 1999). The rest of the paper is as follows - in the next section, we look at previous work and establish further motivation for our work. Following that, we build the theory and formulate suitable objectives for opinion summarization task. In the final section, we present results based on implementation and testing of the functions. Experimental results show that the functions outperform the-stateof-the-art methods. 2 Previous Work Automatically generating opinion summaries from large review text corpora has long been stud</context>
<context position="14697" citStr="Lin and Bilmes, 2011" startWordPosition="2388" endWordPosition="2391">(S) , total utility of summary is given as a linear combination of L(S), relevance and A(S), subjective coverage of aspects. Xsj = (pos(word) + neg(word)) wordEj (7) F(S) = αL(S) + QA(S) (3) This formulation clearly brings out the trade-off between the subjective and the objective part. The intuition behind the combination of sentiment and aspect coverage in same function A(S) is that opinion polarity holds submodular property of diminishing return only if the set of sentences talk about common aspect of the same entity as discussed in previous section. L(S) , relevance is modeled same as in (Lin and Bilmes, 2011) as it captures the summary property, while our novel function, A(S) has been modeled differently through a suitable submodular function such that it captures the subjectivity property. 2. A2 : Budget-additive Function A2(S) is an extension to A1(S), where maximum subjectivity score is restricted with budget based on aspect. Here, λ E [0, 1] is threshold coefficient for budget additive function to avoid redundancy of high sentiment on same aspect. When aspect i is saturated by S (min(PjE(PinS) sj, λ) = λ), any new sentence j cannot further improve coverage over i and thus, other aspects, which</context>
<context position="20857" citStr="Lin and Bilmes, 2011" startWordPosition="3394" endWordPosition="3397">he solution obtained in the second part that has the largest value of objective function over all choices of the starting set for the greedy algorithm. Finally, the algorithm outputs Summ1 if F(Summ1) &gt; F(Summ2) else Summ2 otherwise. The algorithm does O(n2) function calculations in first part, while O(n5) in second part. This algorithm gives a performance guarantee of (1−e−1) for solving monotone submodular objective with knapsack constraint (Khuller et al., 1999; Sviridenko, 2004). As far as we know, the algorithm has not been implemented for such problems because of complexity constraints (Lin and Bilmes, 2011). Algorithm 1 Overall Algorithm - Summary Extraction B &lt;-- 200 for Sentence s E Document V do Assign sentence s to one of aspects in movie ontology. end for Summ1 &lt;-- argmax { F(S), such that S C_ V, |S |&lt; 3, and cost(S) &lt; B } Summ2 &lt;-- 0 for all S C_ V, |S|=3, and cost(S) &lt; B do U &lt;-- V \S while U =� 0 do maxReturn &lt;-- 0.0 newSentence &lt;-- 0 for Sentence s E U do S* &lt;-- S U fs} F(S*) &lt;-- αL(S*) + (1 − α)A(S*) return &lt;-- F(S∗)−F(S) len(s) if return &gt; maxReturn then maxReturn &lt;-- return newSentence &lt;-- s end if end for if cost(S U fnewSentence}) &lt; B then S &lt;-- S U fnewSentence} end if U &lt;-- U \f</context>
<context position="22646" citStr="Lin and Bilmes, 2011" startWordPosition="3737" endWordPosition="3740">the partitions as well as the threshold parameters for the A(S) are currently kept proportional to the inverse of the depth of that aspect in the ontology-tree as sentiment expressed on the concepts at higher level in the ontology tree should have more weightage. ∀ Aspects i, 1 wi = λi = Level(i) 174 The linear combination parameter Q is set as 1− α to bring out the trade-off between relevance and subjective coverage of aspects and α is varied from 0 to 1 with step size 0.05 to find optimal α. γ in L(S) is set to 0.5. The parameter learning, esp. α and its impact have been already studied in (Lin and Bilmes, 2011) and thus, is not addressed in the paper. We have used the same approach of grid search to find the optimal value of α. 6 Results We use ROUGE (Lin, 2004) for evaluating the content of summaries. We have used the 200 test documents that are manually summarized as gold standard data for ROUGE evaluation. For figuring out the sentiment correlation between manual and system generated summaries, we trained Naive Bayes sentiment classifier (Pang et al., 2002) on training data using bag of words approach with features as unigrams and bigrams and then, using minimum Pearson’s chi-square score of 3 fo</context>
<context position="32592" citStr="Lin and Bilmes, 2011" startWordPosition="5323" endWordPosition="5326">ontain the ROUGE F-score and sentiment correlation for optimal values of α, found after grid search while tables 3 and 4 contain the peak values in the figures 2 and 3. For example, table 3 contains the peak value of ROUGE-1 F score from figure 3 and the corresponding value of Sentiment Correlation from figure 2, at the same α. 7 Conclusion In this paper, we show that conflict between subjectivity and relevance naturally arises in opinion summarization. To address this problem, we introduce new monotone submodular functions that are well suited to document summarization (Lin and Bilmes, 2010; Lin and Bilmes, 2011; Morita et al., 2013) by modeling two important properties of opinion summary - relevance and subjective coverage of aspects. We then, design different possible combinations of objective functions to model the task. To solve the algorithm effectively, we use the partial enumeration based algorithm, which is though computationally expensive (O(n5) function calls), gives a performance guarantee of 63% for an NP-hard problem like summarization (McDonald, 2007). We have justified the submodular property of opinion summary through examples and significant performance of the system over the baselin</context>
</contexts>
<marker>Lin, Bilmes, 2011</marker>
<rawString>Hui Lin and Jeff Bilmes. 2011. A class of submodular functions for document summarization. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 510–520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>Rouge: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop,</booktitle>
<pages>74--81</pages>
<contexts>
<context position="22800" citStr="Lin, 2004" startWordPosition="3770" endWordPosition="3771">ntiment expressed on the concepts at higher level in the ontology tree should have more weightage. ∀ Aspects i, 1 wi = λi = Level(i) 174 The linear combination parameter Q is set as 1− α to bring out the trade-off between relevance and subjective coverage of aspects and α is varied from 0 to 1 with step size 0.05 to find optimal α. γ in L(S) is set to 0.5. The parameter learning, esp. α and its impact have been already studied in (Lin and Bilmes, 2011) and thus, is not addressed in the paper. We have used the same approach of grid search to find the optimal value of α. 6 Results We use ROUGE (Lin, 2004) for evaluating the content of summaries. We have used the 200 test documents that are manually summarized as gold standard data for ROUGE evaluation. For figuring out the sentiment correlation between manual and system generated summaries, we trained Naive Bayes sentiment classifier (Pang et al., 2002) on training data using bag of words approach with features as unigrams and bigrams and then, using minimum Pearson’s chi-square score of 3 for feature extraction (Pecina and Schlesinger, 2006) before calculating the sentiment. The measure of sentiment preservation is calculated as Pearson corre</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pages 74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="2128" citStr="Liu, 2012" startWordPosition="322" endWordPosition="323">as well as summarization on the whole chunk of data can be a very time-consuming task. Sentiment Analysis also requires filtering of text portions as either objective (factual information) or subjective (expressing some sentiment or opinion) during pre-processing and then, classifying the subjective extracts as positive or negative. Subjective extracts can also be provided to users as a summary of the sentiment-oriented content of the reviews in search engines. In this paper, we address the problem of generic extractive summarization of reviews, a task commonly known as Opinion Summarization (Liu, 2012). The goals of opinion summarization are: 1. Present a short summary that conveys the essence as well as the sentiment of the review 2. Provide a short subjective extract to NLP pipeline for faster execution (e.g. sentiment analysis, review clustering etc.). In this paper, we use movie reviews for opinion summarization task as they often have the following parts: 1. Plot - Description of the story, which is factual in nature 2. Critique - Opinion about the movie, which is sentiment bearing Clearly, opinion summary to be generated will have a trade-off between the two opposing parts - subjectiv</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>A study of global inference algorithms in multi-document summarization.</title>
<date>2007</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<pages>557--564</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="33054" citStr="McDonald, 2007" startWordPosition="5393" endWordPosition="5395">s this problem, we introduce new monotone submodular functions that are well suited to document summarization (Lin and Bilmes, 2010; Lin and Bilmes, 2011; Morita et al., 2013) by modeling two important properties of opinion summary - relevance and subjective coverage of aspects. We then, design different possible combinations of objective functions to model the task. To solve the algorithm effectively, we use the partial enumeration based algorithm, which is though computationally expensive (O(n5) function calls), gives a performance guarantee of 63% for an NP-hard problem like summarization (McDonald, 2007). We have justified the submodular property of opinion summary through examples and significant performance of the system over the baselines. Further, this optimal trade-off between relevance and subjectivity can be used to design an evaluation framework for opinion summarization task as both part of the objective functions are proportional to the ROUGE and Sentiment Correlation respectively, which are widely used evaluation measures (Kim et al., 2011). As opinion summarization task lies in the intersection of opinion mining and summarization problems, both IR and NLP communities will benefit </context>
</contexts>
<marker>McDonald, 2007</marker>
<rawString>Ryan McDonald. 2007. A study of global inference algorithms in multi-document summarization. In Advances in Information Retrieval, pages 557–564. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>Textrank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<volume>4</volume>
<pages>275</pages>
<contexts>
<context position="24986" citStr="Mihalcea and Tarau, 2004" startWordPosition="4116" endWordPosition="4119"> are chosen as Summary. We have used same NaiveBayes classifier (Pang et al., 2002) trained on imdb corpus to predict the sentiment of a sentence and document. �minS⊂V (|senti(V ) − senti(j)|) (14) j∈S 4. Baseline-4/TEXTRANK : TextRank summarizer is based on Graph based unsupervised algorithm. Graph is constructed by creating a vertex for each sentence in the document and edges between vertices based on the number of words two sentences (of vertices) have in common and then, ranking them by applying PageRank to the resulting graph. Summary is generated with sentences having more vertex score (Mihalcea and Tarau, 2004). 5. Baseline-5/MINCUT : Mincut algorithm (Pang and Lee, 2004) classifies the sentences as subjective and objective sentences, by finding minimum s-t cuts in graph of sentences using maximum flow algorithm. In the graph, each sentence is a vertex and the edge between the vertex to the source or sink is taken as probability of the sentence being subjective or objective (individual scores). To ensure the graph connectivity, edges are drawn between every pair of sentence vertices, with edge weights taken proportional to the degree of proximity (association scores). After maximum flow algorithm, t</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. Textrank: Bringing order into texts. In Proceedings of EMNLP, volume 4, page 275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hajime Morita</author>
<author>Hiroya Takamura</author>
<author>Ryohei Sasano</author>
<author>Manabu Okumura</author>
</authors>
<title>Subtree extractive summarization via submodular maximization.</title>
<date>2013</date>
<booktitle>In Proceedings of 51st Annual Meeting of the Association for Computational Linguistics</booktitle>
<note>(to appear).</note>
<contexts>
<context position="4309" citStr="Morita et al., 2013" startWordPosition="662" endWordPosition="665">ics. other hand, when we extract sentences first, an important subjective sentence may fail to be selected, simply because it is long. The two stage conflict in the sense that the demand of compression may drop sentiment bearing sentences, and the demand of sentiment detection may bring in redundant sentences. We then, use partial enumeration based greedy algorithm (Khuller et al., 1999), which gives performance guarantee of (1− e−1) ≈ 0.632 (Sviridenko, 2004). The performance guarantee reported is better than simple greedy algorithm, used by Lin and Bilmes (2010) as their proof is erroneous (Morita et al., 2013). Further, the same greedy algorithm, which was used again in Lin and Bilmes (2011) gives only performance guarantee of 12(1− el) ≈ 0.316 (Khuller et al., 1999). The rest of the paper is as follows - in the next section, we look at previous work and establish further motivation for our work. Following that, we build the theory and formulate suitable objectives for opinion summarization task. In the final section, we present results based on implementation and testing of the functions. Experimental results show that the functions outperform the-stateof-the-art methods. 2 Previous Work Automatic</context>
<context position="32614" citStr="Morita et al., 2013" startWordPosition="5327" endWordPosition="5330">re and sentiment correlation for optimal values of α, found after grid search while tables 3 and 4 contain the peak values in the figures 2 and 3. For example, table 3 contains the peak value of ROUGE-1 F score from figure 3 and the corresponding value of Sentiment Correlation from figure 2, at the same α. 7 Conclusion In this paper, we show that conflict between subjectivity and relevance naturally arises in opinion summarization. To address this problem, we introduce new monotone submodular functions that are well suited to document summarization (Lin and Bilmes, 2010; Lin and Bilmes, 2011; Morita et al., 2013) by modeling two important properties of opinion summary - relevance and subjective coverage of aspects. We then, design different possible combinations of objective functions to model the task. To solve the algorithm effectively, we use the partial enumeration based algorithm, which is though computationally expensive (O(n5) function calls), gives a performance guarantee of 63% for an NP-hard problem like summarization (McDonald, 2007). We have justified the submodular property of opinion summary through examples and significant performance of the system over the baselines. Further, this opti</context>
</contexts>
<marker>Morita, Takamura, Sasano, Okumura, 2013</marker>
<rawString>Hajime Morita, Hiroya Takamura, Ryohei Sasano, and Manabu Okumura. 2013. Subtree extractive summarization via submodular maximization. In Proceedings of 51st Annual Meeting of the Association for Computational Linguistics (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitoshi Nishikawa</author>
<author>Takaaki Hasegawa</author>
<author>Yoshihiro Matsuo</author>
<author>Genichiro Kikui</author>
</authors>
<title>Opinion summarization with integer linear programming formulation for sentence extraction and ordering.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</booktitle>
<pages>910--918</pages>
<contexts>
<context position="6565" citStr="Nishikawa et al., 2010" startWordPosition="1023" endWordPosition="1026">d sentiment match + aspect coverage (SMAC), builds a summary that trades-off between DIVERSITY, maximally covering important aspects and MISMATCH, matching the overall sentiment of the entity along with high INTENSITY. The third model, called sentiment-aspect match (SAM), not only attempts to cover important aspects, but cover them with appropriate sentiment using KL-Divergence function. Here, INTENSITY and DIVERSITY in the first two models are linear monotone submodular functions, while KL-Divergence function i.e. relative entropy in last model, unlike entropy is not monotone submodular. In (Nishikawa et al., 2010b), a more sophisticated summarization technique was proposed, which generates a traditional text summary by selecting and ordering sentences taken from multiple reviews, considering both informativeness and readability of the final summary. The readability score in this paper would have been linear monotone submodular function, if the negative polarity was not penalizing. In (Nishikawa et al., 2010a), the authors further studied this problem using an integer linear programming formulation. On the other hand, Lin et al .(2011) treated the task of generic summarization as monotone submodular fu</context>
</contexts>
<marker>Nishikawa, Hasegawa, Matsuo, Kikui, 2010</marker>
<rawString>Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Matsuo, and Genichiro Kikui. 2010a. Opinion summarization with integer linear programming formulation for sentence extraction and ordering. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 910–918.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitoshi Nishikawa</author>
<author>Takaaki Hasegawa</author>
<author>Yoshihiro Matsuo</author>
<author>Genichiro Kikui</author>
</authors>
<title>Optimizing informativeness and readability for sentiment summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>325--330</pages>
<contexts>
<context position="6565" citStr="Nishikawa et al., 2010" startWordPosition="1023" endWordPosition="1026">d sentiment match + aspect coverage (SMAC), builds a summary that trades-off between DIVERSITY, maximally covering important aspects and MISMATCH, matching the overall sentiment of the entity along with high INTENSITY. The third model, called sentiment-aspect match (SAM), not only attempts to cover important aspects, but cover them with appropriate sentiment using KL-Divergence function. Here, INTENSITY and DIVERSITY in the first two models are linear monotone submodular functions, while KL-Divergence function i.e. relative entropy in last model, unlike entropy is not monotone submodular. In (Nishikawa et al., 2010b), a more sophisticated summarization technique was proposed, which generates a traditional text summary by selecting and ordering sentences taken from multiple reviews, considering both informativeness and readability of the final summary. The readability score in this paper would have been linear monotone submodular function, if the negative polarity was not penalizing. In (Nishikawa et al., 2010a), the authors further studied this problem using an integer linear programming formulation. On the other hand, Lin et al .(2011) treated the task of generic summarization as monotone submodular fu</context>
</contexts>
<marker>Nishikawa, Hasegawa, Matsuo, Kikui, 2010</marker>
<rawString>Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Matsuo, and Genichiro Kikui. 2010b. Optimizing informativeness and readability for sentiment summarization. In Proceedings of the ACL 2010 Conference Short Papers, pages 325–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>271</pages>
<contexts>
<context position="3076" citStr="Pang and Lee (2004)" startWordPosition="477" endWordPosition="480">they often have the following parts: 1. Plot - Description of the story, which is factual in nature 2. Critique - Opinion about the movie, which is sentiment bearing Clearly, opinion summary to be generated will have a trade-off between the two opposing parts - subjective critique and objective plot. Our goal is to strike a balance through linear combination of suitable submodular functions in our paper. Joint models of relevance and subjectivity have a great benefit in that they have a large degree of freedom as far as controlling redundancy goes. In contrast, conventional two-stage approach Pang and Lee (2004), which first generate candidate subjective sentences using min-cut and then selects top subjective sentences within budget to generate a summary, have less computational complexity than joint models. However, two-stage approaches are suboptimal for text summarization. For example, when we select subjective sentences first, the sentiment as well information content may become redundant for a particular aspect. On the 169 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 169–178, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computati</context>
<context position="5082" citStr="Pang and Lee, 2004" startWordPosition="787" endWordPosition="790"> 1999). The rest of the paper is as follows - in the next section, we look at previous work and establish further motivation for our work. Following that, we build the theory and formulate suitable objectives for opinion summarization task. In the final section, we present results based on implementation and testing of the functions. Experimental results show that the functions outperform the-stateof-the-art methods. 2 Previous Work Automatically generating opinion summaries from large review text corpora has long been studied in both information retrieval and natural language processing. In (Pang and Lee, 2004), a mincut-based algorithm was proposed to classify each sentence as being subjective or objective. The purpose of this work was to remove objective sentences from reviews to improve document level sentiment classification. Interestingly, the cut functions are symmetrical and submodular, and the problem of finding min-cut is equivalent to minimizing a symmetric submodular function. Lerman et al. (2009) proposed three different models - sentiment match (SM), sentiment match + aspect coverage (SMAC) and sentiment-aspect match (SAM) to perform summarization of reviews of a product. The first mode</context>
<context position="25048" citStr="Pang and Lee, 2004" startWordPosition="4125" endWordPosition="4128">g et al., 2002) trained on imdb corpus to predict the sentiment of a sentence and document. �minS⊂V (|senti(V ) − senti(j)|) (14) j∈S 4. Baseline-4/TEXTRANK : TextRank summarizer is based on Graph based unsupervised algorithm. Graph is constructed by creating a vertex for each sentence in the document and edges between vertices based on the number of words two sentences (of vertices) have in common and then, ranking them by applying PageRank to the resulting graph. Summary is generated with sentences having more vertex score (Mihalcea and Tarau, 2004). 5. Baseline-5/MINCUT : Mincut algorithm (Pang and Lee, 2004) classifies the sentences as subjective and objective sentences, by finding minimum s-t cuts in graph of sentences using maximum flow algorithm. In the graph, each sentence is a vertex and the edge between the vertex to the source or sink is taken as probability of the sentence being subjective or objective (individual scores). To ensure the graph connectivity, edges are drawn between every pair of sentence vertices, with edge weights taken proportional to the degree of proximity (association scores). After maximum flow algorithm, the cut in which source vertex lies is classified as subjective</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd annual meeting on Association for Computational Linguistics, page 271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10,</booktitle>
<pages>79--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1275" citStr="Pang et al., 2002" startWordPosition="187" endWordPosition="190">icting requirements. We investigate an incipient class of submodular functions for the problem, and a partial enumeration based greedy algorithm that has performance guarantee of 63%. Our functions generate summaries such that there is good correlation between document sentiment and summary sentiment along with good ROUGE score, which outperforms thestate-of-the-art algorithms. 1 Introduction Sentiment Analysis is often addressed as a classification task, which aims at determining the sentiment of a word, sentence, paragraph or a document as a whole into positive, negative or neutral classes (Pang et al., 2002). Summarization, on the other hand is the task of aggregating and representing information content from a single document or multiple documents in a brief and fluent manner. Due to the explosive growth of data, fine grained sentiment analysis as well as summarization on the whole chunk of data can be a very time-consuming task. Sentiment Analysis also requires filtering of text portions as either objective (factual information) or subjective (expressing some sentiment or opinion) during pre-processing and then, classifying the subjective extracts as positive or negative. Subjective extracts ca</context>
<context position="23104" citStr="Pang et al., 2002" startWordPosition="3814" endWordPosition="3817">ith step size 0.05 to find optimal α. γ in L(S) is set to 0.5. The parameter learning, esp. α and its impact have been already studied in (Lin and Bilmes, 2011) and thus, is not addressed in the paper. We have used the same approach of grid search to find the optimal value of α. 6 Results We use ROUGE (Lin, 2004) for evaluating the content of summaries. We have used the 200 test documents that are manually summarized as gold standard data for ROUGE evaluation. For figuring out the sentiment correlation between manual and system generated summaries, we trained Naive Bayes sentiment classifier (Pang et al., 2002) on training data using bag of words approach with features as unigrams and bigrams and then, using minimum Pearson’s chi-square score of 3 for feature extraction (Pecina and Schlesinger, 2006) before calculating the sentiment. The measure of sentiment preservation is calculated as Pearson correlation between the sentiment score of the document and the corresponding summary sentiment, both calculated by the Naive Bayes sentiment classifier while the measure of coverage of information content is given by ROUGE-1 and ROUGE-2 f-scores. Mathematically, Covariance(X, Y ) Correlation(X, Y ) = std.de</context>
<context position="24444" citStr="Pang et al., 2002" startWordPosition="4025" endWordPosition="4028">sentiment score of the corresponding summary sample. For 200 documents, it will be [(X1, Y1), (X2, Y2),..., (X200, Y200)] sample points for the above correlation function. Following five baselines are used for comparison: 1. Baseline-1/TOP : Sentences selected consecutively from the start of the review within the budget. 2. Baseline-2/TOP-SUBJ : Sentences ranked based on their subjectivity and then, selected with in the budget. 3. Baseline-3/LER-SM : (Lerman et al., 2009) Sentences which have sentiment close to document sentiment are chosen as Summary. We have used same NaiveBayes classifier (Pang et al., 2002) trained on imdb corpus to predict the sentiment of a sentence and document. �minS⊂V (|senti(V ) − senti(j)|) (14) j∈S 4. Baseline-4/TEXTRANK : TextRank summarizer is based on Graph based unsupervised algorithm. Graph is constructed by creating a vertex for each sentence in the document and edges between vertices based on the number of words two sentences (of vertices) have in common and then, ranking them by applying PageRank to the resulting graph. Summary is generated with sentences having more vertex score (Mihalcea and Tarau, 2004). 5. Baseline-5/MINCUT : Mincut algorithm (Pang and Lee, 2</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 79–86. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
<author>Pavel Schlesinger</author>
</authors>
<title>Combining association measures for collocation extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>651--658</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="23297" citStr="Pecina and Schlesinger, 2006" startWordPosition="3845" endWordPosition="3848">essed in the paper. We have used the same approach of grid search to find the optimal value of α. 6 Results We use ROUGE (Lin, 2004) for evaluating the content of summaries. We have used the 200 test documents that are manually summarized as gold standard data for ROUGE evaluation. For figuring out the sentiment correlation between manual and system generated summaries, we trained Naive Bayes sentiment classifier (Pang et al., 2002) on training data using bag of words approach with features as unigrams and bigrams and then, using minimum Pearson’s chi-square score of 3 for feature extraction (Pecina and Schlesinger, 2006) before calculating the sentiment. The measure of sentiment preservation is calculated as Pearson correlation between the sentiment score of the document and the corresponding summary sentiment, both calculated by the Naive Bayes sentiment classifier while the measure of coverage of information content is given by ROUGE-1 and ROUGE-2 f-scores. Mathematically, Covariance(X, Y ) Correlation(X, Y ) = std.dev(X) ∗ std.dev(Y) (13) Here, random variable X is the sentiment score of the document sample and random variable Y is the sentiment score of the corresponding summary sample. For 200 documents,</context>
</contexts>
<marker>Pecina, Schlesinger, 2006</marker>
<rawString>Pavel Pecina and Pavel Schlesinger. 2006. Combining association measures for collocation extraction. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 651–658. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Korbinian Riedhammer</author>
<author>Benoit Favre</author>
<author>Dilek Hakkani-Tür</author>
</authors>
<title>Long story short–global unsupervised models for keyphrase based meeting summarization.</title>
<date>2010</date>
<journal>Speech Communication,</journal>
<volume>52</volume>
<issue>10</issue>
<pages>815</pages>
<contexts>
<context position="7482" citStr="Riedhammer et al., 2010" startWordPosition="1158" endWordPosition="1161"> linear monotone submodular function, if the negative polarity was not penalizing. In (Nishikawa et al., 2010a), the authors further studied this problem using an integer linear programming formulation. On the other hand, Lin et al .(2011) treated the task of generic summarization as monotone submodular function maximization. Further, they argued that monotone non-decreasing submodular functions are an ideal class of functions to investigate for document summarization. They also show, in fact, that many well-established methods for summarization (Carbonell and Goldstein, 1998; Filatova, 2004; Riedhammer et al., 2010) correspond to submodular function optimization, a property not explicitly mentioned in these publications. Since many authors either in summarization or opinion summarization have used functions similar to submodular functions as objective, we can take this fact as testament to the value of submodular functions for opinion summarization. 3 Theoretical Background 3.1 Introduction to Submodular Functions A submodular function is a set function (f : 2v → R) having a natural diminishing returns property. Diminishing returns property holds if the difference in the value of the function that a sing</context>
</contexts>
<marker>Riedhammer, Favre, Hakkani-Tür, 2010</marker>
<rawString>Korbinian Riedhammer, Benoit Favre, and Dilek Hakkani-Tür. 2010. Long story short–global unsupervised models for keyphrase based meeting summarization. Speech Communication, 52(10):801– 815.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maxim Sviridenko</author>
</authors>
<title>A note on maximizing a submodular set function subject to a knapsack constraint.</title>
<date>2004</date>
<journal>Operations Research Letters,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="4153" citStr="Sviridenko, 2004" startWordPosition="639" endWordPosition="640">on Empirical Methods in Natural Language Processing, pages 169–178, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. other hand, when we extract sentences first, an important subjective sentence may fail to be selected, simply because it is long. The two stage conflict in the sense that the demand of compression may drop sentiment bearing sentences, and the demand of sentiment detection may bring in redundant sentences. We then, use partial enumeration based greedy algorithm (Khuller et al., 1999), which gives performance guarantee of (1− e−1) ≈ 0.632 (Sviridenko, 2004). The performance guarantee reported is better than simple greedy algorithm, used by Lin and Bilmes (2010) as their proof is erroneous (Morita et al., 2013). Further, the same greedy algorithm, which was used again in Lin and Bilmes (2011) gives only performance guarantee of 12(1− el) ≈ 0.316 (Khuller et al., 1999). The rest of the paper is as follows - in the next section, we look at previous work and establish further motivation for our work. Following that, we build the theory and formulate suitable objectives for opinion summarization task. In the final section, we present results based on</context>
<context position="9041" citStr="Sviridenko, 2004" startWordPosition="1422" endWordPosition="1423">on problem i.e. finding a set S C_ V (S is set of sentences in summary, V is set of sentences in Document) which maximizes a submodular function f(S) subject to budget constraints. In the following section, we will justify the use of submodular function for opinion summarization. Another advantage of choosing monotone submodular function is that there exists a polynomial-time greedy algorithm for constrained monotone submodular objective. The greedy algorithm guarantees that the summary solution obtained is almost as good as (63%) the best possible summary solution according to the objective (Sviridenko, 2004; Wolsey, 1982). 3.2 Submodularity in Opinion Summarization Opinion Summarization should be modeled as a monotone submodular optimization problem, since opinion summary also holds following properties: 1. Monotonicity - As more sentences are added to opinion summary, subjectivity increases along with information content as opinionated words are being added. 2. Diminishing Return - If multiple sentences of varying intensity are added to opinion summary, the effect of a lower intensity polarity bearing sentence is diluted in the presence of a higher intensity one. To show that opinion summarizat</context>
<context position="20723" citStr="Sviridenko, 2004" startWordPosition="3372" endWordPosition="3373">n completes each such set greedily and keeps the current solution feasible with respect to the knapsack constraint. Let Summ2 be the solution obtained in the second part that has the largest value of objective function over all choices of the starting set for the greedy algorithm. Finally, the algorithm outputs Summ1 if F(Summ1) &gt; F(Summ2) else Summ2 otherwise. The algorithm does O(n2) function calculations in first part, while O(n5) in second part. This algorithm gives a performance guarantee of (1−e−1) for solving monotone submodular objective with knapsack constraint (Khuller et al., 1999; Sviridenko, 2004). As far as we know, the algorithm has not been implemented for such problems because of complexity constraints (Lin and Bilmes, 2011). Algorithm 1 Overall Algorithm - Summary Extraction B &lt;-- 200 for Sentence s E Document V do Assign sentence s to one of aspects in movie ontology. end for Summ1 &lt;-- argmax { F(S), such that S C_ V, |S |&lt; 3, and cost(S) &lt; B } Summ2 &lt;-- 0 for all S C_ V, |S|=3, and cost(S) &lt; B do U &lt;-- V \S while U =� 0 do maxReturn &lt;-- 0.0 newSentence &lt;-- 0 for Sentence s E U do S* &lt;-- S U fs} F(S*) &lt;-- αL(S*) + (1 − α)A(S*) return &lt;-- F(S∗)−F(S) len(s) if return &gt; maxReturn th</context>
</contexts>
<marker>Sviridenko, 2004</marker>
<rawString>Maxim Sviridenko. 2004. A note on maximizing a submodular set function subject to a knapsack constraint. Operations Research Letters, 32(1):41–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence A Wolsey</author>
</authors>
<title>An analysis of the greedy algorithm for the submodular set covering problem.</title>
<date>1982</date>
<journal>Combinatorica,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="9056" citStr="Wolsey, 1982" startWordPosition="1424" endWordPosition="1425">nding a set S C_ V (S is set of sentences in summary, V is set of sentences in Document) which maximizes a submodular function f(S) subject to budget constraints. In the following section, we will justify the use of submodular function for opinion summarization. Another advantage of choosing monotone submodular function is that there exists a polynomial-time greedy algorithm for constrained monotone submodular objective. The greedy algorithm guarantees that the summary solution obtained is almost as good as (63%) the best possible summary solution according to the objective (Sviridenko, 2004; Wolsey, 1982). 3.2 Submodularity in Opinion Summarization Opinion Summarization should be modeled as a monotone submodular optimization problem, since opinion summary also holds following properties: 1. Monotonicity - As more sentences are added to opinion summary, subjectivity increases along with information content as opinionated words are being added. 2. Diminishing Return - If multiple sentences of varying intensity are added to opinion summary, the effect of a lower intensity polarity bearing sentence is diluted in the presence of a higher intensity one. To show that opinion summarization inherently </context>
</contexts>
<marker>Wolsey, 1982</marker>
<rawString>Laurence A Wolsey. 1982. An analysis of the greedy algorithm for the submodular set covering problem. Combinatorica, 2(4):385–393.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>